{
  "version": "1.0",
  "updated": "2025-12-12T11:54:28.513354",
  "count": 457,
  "entries": {
    "millidge2021applications": {
      "citation_key": "millidge2021applications",
      "title": "Applications of the Free Energy Principle to Machine Learning and Neuroscience",
      "authors": [
        "Beren Millidge"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2107.00140v1",
      "pdf_path": "data/pdfs/millidge2021applications.pdf",
      "added_date": "2025-12-12T11:03:48.928281",
      "abstract": "In this PhD thesis, we explore and apply methods inspired by the free energy principle to two important areas in machine learning and neuroscience. The free energy principle is a general mathematical theory of the necessary information-theoretic behaviours of systems that maintain a separation from their environment. A core postulate of the theory is that complex systems can be seen as performing variational Bayesian inference and minimizing an information-theoretic quantity called the variational free energy. The thesis is structured into three independent sections. Firstly, we focus on predictive coding, a neurobiologically plausible process theory derived from the free energy principle which argues that the primary function of the brain is to minimize prediction errors, showing how predictive coding can be scaled up and extended to be more biologically plausible, and elucidating its close links with other methods such as Kalman Filtering. Secondly, we study active inference, a neurobiologically grounded account of action through variational message passing, and investigate how these methods can be scaled up to match the performance of deep reinforcement learning methods. We additionally provide a detailed mathematical understanding of the nature and origin of the information-theoretic objectives that underlie exploratory behaviour. Finally, we investigate biologically plausible methods of credit assignment in the brain. We first demonstrate a close link between predictive coding and the backpropagation of error algorithm. We go on to propose novel and simpler algorithms which allow for backprop to be implemented in purely local, biologically plausible computations.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2107.00140.pdf"
      }
    },
    "c2025structural": {
      "citation_key": "c2025structural",
      "title": "Structural Basis for Negative Regulation of ABA Signaling by ROP11 GTPase",
      "authors": [
        "Zhao, C.",
        "Nadeem, H.",
        "Shukla, D."
      ],
      "year": 2025,
      "doi": "10.1101/2020.05.20.107185",
      "source": "biorxiv",
      "url": "https://www.biorxiv.org/content/10.1101/2020.05.20.107185",
      "pdf_path": "data/pdfs/c2025structural.pdf",
      "added_date": "2025-12-12T11:11:40.425596",
      "abstract": "Abscisic acid (ABA) is an essential plant hormone responsible for plant development and stress responses. Recent structural and biochemical studies have identified the key components involved in ABA signaling cascade, including PYR/PYL/RCAR receptors, protein phosphatases PP2C, and protein kinases SnRK2. The plant-specific, Roh-like (ROPs) small GTPases are negative regulators of ABA signal transduction by interacting with PP2C, which can shut off \"leaky\" ABA signal transduction caused by constitutive activity of monomeric PYR/PYL/RCAR receptors. However, the structural basis for negative regulation of ABA signaling by ROP GTPases remains elusive. In this study, we have utilized large-scale coarse-grained (10.05 milliseconds) and allatom molecular dynamics simulations and standard protein-protein binding free energy calculations to predict the complex structure of AtROP11 and phosphatase AtABI1. In addition, we have predicted the detailed complex association pathway and identified the critical residue pairs in AtROP11 and AtABI1 for complex stability. Overall, this study has established a powerful framework of using large-scale molecular simulations to predict unknown protein complex structures and suggested the molecular mechanism of the negative regulation of ABA signal transduction by small GTPases.",
      "venue": "biorxiv preprint",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://www.biorxiv.org/content/10.1101/2020.05.20.107185.full.pdf"
      }
    },
    "sheikhbahaee2024from": {
      "citation_key": "sheikhbahaee2024from",
      "title": "From Physics to Sentience: Deciphering the Semantics of the Free-Energy Principle and Evaluating its Claims",
      "authors": [
        "Zahra Sheikhbahaee",
        "Adam Safron",
        "Casper Hesp",
        "Guillaume Dumas"
      ],
      "year": 2024,
      "doi": "10.1016/j.plrev.2023.11.004",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2401.08873v1",
      "pdf_path": "data/pdfs/sheikhbahaee2024from.pdf",
      "added_date": "2025-12-12T11:24:46.248222",
      "abstract": "The Free-Energy Principle (FEP) [1-3] has been adopted in a variety of ambitious proposals that aim to characterize all adaptive, sentient, and cognitive systems within a unifying framework. Judging by the amount of attention it has received from the scientific community, the FEP has gained significant traction in these pursuits. The current target article represents an important iteration of this research paradigm in formally describing emergent dynamics rather than merely (quasi-)steady states. This affords more in-depth considerations of the spatio-temporal complexities of cross-scale causality - as we have encouraged and built towards in previous publications (e.g., [4-9]). In this spirit of constructive feedback, we submit a few technical comments on some of the matters that appear to require further attention, in order to improve the clarity, rigour, and applicability of this framework.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2401.08873.pdf"
      }
    },
    "shafiei2025distributionally": {
      "citation_key": "shafiei2025distributionally",
      "title": "Distributionally Robust Free Energy Principle for Decision-Making",
      "authors": [
        "Allahkaram Shafiei",
        "Hozefa Jesawada",
        "Karl Friston",
        "Giovanni Russo"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.13223v3",
      "pdf_path": "data/pdfs/shafiei2025distributionally.pdf",
      "added_date": "2025-12-12T11:24:46.252660",
      "abstract": "Despite their groundbreaking performance, autonomous agents can misbehave when training and environmental conditions become inconsistent, with minor mismatches leading to undesirable behaviors or even catastrophic failures. Robustness towards these training-environment ambiguities is a core requirement for intelligent agents and its fulfillment is a long-standing challenge towards their real-world deployments. Here, we introduce a Distributionally Robust Free Energy model (DR-FREE) that instills this core property by design. Combining a robust extension of the free energy principle with a resolution engine, DR-FREE wires robustness into the agent decision-making mechanisms. Across benchmark experiments, DR-FREE enables the agents to complete the task even when, in contrast, state-of-the-art models fail. This milestone may inspire both deployments in multi-agent settings and, at a perhaps deeper level, the quest for an explanation of how natural agents -- with little or no training -- survive in capricious environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.13223.pdf"
      }
    },
    "spisak2025selforthogonalizing": {
      "citation_key": "spisak2025selforthogonalizing",
      "title": "Self-orthogonalizing attractor neural networks emerging from the free energy principle",
      "authors": [
        "Tamas Spisak",
        "Karl Friston"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2505.22749v1",
      "pdf_path": "data/pdfs/spisak2025selforthogonalizing.pdf",
      "added_date": "2025-12-12T11:24:46.259873",
      "abstract": "Attractor dynamics are a hallmark of many complex systems, including the brain. Understanding how such self-organizing dynamics emerge from first principles is crucial for advancing our understanding of neuronal computations and the design of artificial intelligence systems. Here we formalize how attractor networks emerge from the free energy principle applied to a universal partitioning of random dynamical systems. Our approach obviates the need for explicitly imposed learning and inference rules and identifies emergent, but efficient and biologically plausible inference and learning dynamics for such self-organizing systems. These result in a collective, multi-level Bayesian active inference process. Attractors on the free energy landscape encode prior beliefs; inference integrates sensory data into posterior beliefs; and learning fine-tunes couplings to minimize long-term surprise. Analytically and via simulations, we establish that the proposed networks favor approximately orthogonalized attractor representations, a consequence of simultaneously optimizing predictive accuracy and model complexity. These attractors efficiently span the input subspace, enhancing generalization and the mutual information between hidden causes and observable effects. Furthermore, while random data presentation leads to symmetric and sparse couplings, sequential data fosters asymmetric couplings and non-equilibrium steady-state dynamics, offering a natural extension to conventional Boltzmann Machines. Our findings offer a unifying theory of self-organizing attractor networks, providing novel insights for AI and neuroscience.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2505.22749.pdf"
      }
    },
    "mayama2025bridging": {
      "citation_key": "mayama2025bridging",
      "title": "Bridging integrated information theory and the free-energy principle in living neuronal networks",
      "authors": [
        "Teruki Mayama",
        "Sota Shimizu",
        "Yuki Takano",
        "Dai Akita",
        "Hirokazu Takahashi"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.04084v1",
      "pdf_path": "data/pdfs/mayama2025bridging.pdf",
      "added_date": "2025-12-12T11:24:46.261660",
      "abstract": "The relationship between Integrated Information Theory (IIT) and the Free-Energy Principle (FEP) remains unresolved, particularly with respect to how integrated information, proposed as the intrinsic substrate of consciousness, behaves within variational Bayesian inference. We investigated this issue using dissociated neuronal cultures, previously shown to perform perceptual inference consistent with the FEP. Repeated stimulation from hidden sources induced robust source selectivity: variational free energy (VFE) decreased across sessions, whereas accuracy and Bayesian surprise (complexity) increased. Network-level analyses revealed that a proxy measure of integrated information and the size of the main complex followed a hill-shaped trajectory, with informational cores organizing diverse neuronal activity. Across experiments, integrated information correlated strongly and positively with Bayesian surprise, modestly and heterogeneously with accuracy, and showed no significant relationship with VFE. The positive coupling between Φ and Bayesian surprise likely reflects the diversity of activity observed in critical dynamics. These findings suggest that integrated information increases specifically during belief updating, when sensory inputs are most informative, rather than tracking model efficiency. The hill-shaped trajectory of Φ during inference can be functionally interpreted as a transition from exploration to exploitation. This work provides empirical evidence linking the physical account of consciousness advanced by IIT with the functional perspective offered by the FEP, contributing to a unified framework for the mechanisms and adaptive roles of phenomenology.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.04084.pdf"
      }
    },
    "albarracin2025resilience": {
      "citation_key": "albarracin2025resilience",
      "title": "Resilience and adaptability in self-evidencing systems",
      "authors": [
        "Mahault Albarracin",
        "Dalton A R Sakthivadivel"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.06897v1",
      "pdf_path": "data/pdfs/albarracin2025resilience.pdf",
      "added_date": "2025-12-12T11:24:46.263819",
      "abstract": "In this paper we will articulate a view of resilience under the free energy principle and vice versa. The free energy principle is about existence and identity, and resilience is the condition under which things exist at all. In previous work this has been investigated as modelling resilience using the free energy principle. We will extend that work by making the case that self-organisation under the free energy principle is about resilience, in the sense that identity is a constant process of self-reconfiguration, implying the existence of a self-model and the energy to reconfigure that self-model -- and hence, the resilience of a maintained identity under changes. A general framework for thinking about resilience in this context will be sketched out and some models will be provided using that framework.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.06897.pdf"
      }
    },
    "possati2025markov": {
      "citation_key": "possati2025markov",
      "title": "Markov Blanket Density and Free Energy Minimization",
      "authors": [
        "Luca M. Possati"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.05794v5",
      "pdf_path": "data/pdfs/possati2025markov.pdf",
      "added_date": "2025-12-12T11:24:46.265899",
      "abstract": "This paper presents a continuous, information-theoretic extension of the Free Energy Principle through the concept of Markov blanket density, i.e., a scalar field that quantifies the degree of conditional independence between internal and external states at each point in space (ranging from 0 for full coupling to 1 for full separation). It demonstrates that active inference dynamics, including the minimization of variational and expected free energy, naturally emerge from spatial gradients in this density, making Markov blanket density a necessary foundation for the Free Energy Principle. These ideas are developed through a mathematically framework that links density gradients to precise and testable dynamics, offering a foundation for novel predictions and simulation paradigms.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.05794.pdf"
      }
    },
    "li2023return": {
      "citation_key": "li2023return",
      "title": "Return to Lacan: an approach to digital twin mind with free energy principle",
      "authors": [
        "Lingyu Li",
        "Chunbo Li"
      ],
      "year": 2023,
      "doi": "10.3389/fpsyg.2025.1574650",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2309.06707v2",
      "pdf_path": "data/pdfs/li2023return.pdf",
      "added_date": "2025-12-12T11:24:46.268228",
      "abstract": "Free energy principle (FEP) is a burgeoning theory in theoretical neuroscience that provides a universal law for modelling living systems of any scale. Expecting a digital twin mind from this first principle, we propose a macro-level interpretation that bridge neuroscience and psychoanalysis through the lens of computational Lacanian psychoanalysis. In this article, we claim three fundamental parallels between FEP and Lacanian psychoanalysis, and suggest a FEP approach to formalizing Lacan's theory. Sharing the non-linear temporal structure that combines prediction and retrospection (logical time), both of two theories focus on epistemological questions that how systems represented themselves and external world, and those elements failed to be represented (lacks and free energy) significantly influence the systems' subsequent states. Additionally, the fundamental hypothesis of FEP that the precise state of environment is always concealed, accounts for object petit a, the core concept in Lacan's theory. With neuropsychoanalytic mapping from three orders (the Real, the Symbolic, and the Imaginary, RSI) onto brain regions, we propose a brain-wide FEP model for a minimal definition of Lacanian mind - composite state of RSI that is perturbated by desire running over the logical time. The FEP-RSI model involves three FEP units connected by respective free energy with a natural compliance with logical time, mimicking core dynamics of Lacanian mind. The biological plausibility of current model is considered from perspectives of cognitive neuroscience. In conclusion, the FEP-RSI model encapsulates a unified framework for digital twin modeling at the macro level.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2309.06707.pdf"
      }
    },
    "kim2024bayesian": {
      "citation_key": "kim2024bayesian",
      "title": "Bayesian Mechanics of Synaptic Learning under the Free Energy Principle",
      "authors": [
        "Chang Sub Kim"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.02972v1",
      "pdf_path": "data/pdfs/kim2024bayesian.pdf",
      "added_date": "2025-12-12T11:24:46.270173",
      "abstract": "The brain is a biological system comprising nerve cells and orchestrates its embodied agent's perception, behavior, and learning in the dynamic environment. The free energy principle (FEP) advocated by Karl Friston explicates the local, recurrent, and self-supervised neurodynamics of the brain's higher-order functions. In this paper, we continue to finesse the FEP through the physics-guided formulation; specifically, we apply our theory to synaptic learning by considering it an inference problem under the FEP and derive the governing equations, called Bayesian mechanics. Our study uncovers how the brain infers weight change and postsynaptic activity, conditioned on the presynaptic input, by deploying the generative models of the likelihood and prior belief. Consequently, we exemplify the synaptic plasticity in the brain with a simple model: we illustrate that the brain organizes an optimal trajectory in neural phase space during synaptic learning in continuous time, which variationally minimizes synaptic surprisal.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.02972.pdf"
      }
    },
    "bellingrath2024emergence": {
      "citation_key": "bellingrath2024emergence",
      "title": "The emergence of subjective temporality: the self-simulational theory of temporal extension from the perspective of the free energy principle",
      "authors": [
        "Jan Erik Bellingrath"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2404.12895v4",
      "pdf_path": "data/pdfs/bellingrath2024emergence.pdf",
      "added_date": "2025-12-12T11:24:46.271826",
      "abstract": "The self-simulational theory of temporal extension describes an information-theoretically formalized mechanism by which the width of subjective temporality emerges from the architecture of self-modelling. In this paper, the perspective of the free energy principle will be assumed, to cast the emergence of subjective temporality, along with a Bayesian mechanism for hierarchical duration estimation, from first principles of the physics of self-organization. Using active inference, a deep parametric generative model of temporal inference is simulated, which realizes the described dynamics on a computational level. Two biases (i.e. variations) of time-perception naturally emerge from the simulated computational model. This concerns the intentional binding effect (i.e. the compression of the temporal interval between voluntarily initiated actions and subsequent sensory consequences) and empirically documented alterations of subjective time experience in deep states of meditative absorption (i.e. in minimal phenomenal experience). Generally, numerous systematic and domain-specific alterations of subjective temporal experience are computationally explained in a unified manner, as enabled by integration with current active inference accounts mapping onto the respective domains. This concerns - next to more general scale-invariant effects of explicit timing and central tendency effects - the temporality-modulating role of valence, impulsivity, boredom, flow-states, near death-experiences, and various psychopathologies, amongst others. The self-simulational theory of temporal extension, from the perspective of the free energy principle, explains how the subjective temporal Now emerges and varies from first principles, accounting for why sometimes, subjective time seems to fly, and sometimes, moments feel like eternities; with the computational mechanism being readily deployable synthetically.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2404.12895.pdf"
      }
    },
    "costa2024probabilistic": {
      "citation_key": "costa2024probabilistic",
      "title": "Probabilistic Principles for Biophysics and Neuroscience: Entropy Production, Bayesian Mechanics & the Free-Energy Principle",
      "authors": [
        "Lancelot Da Costa"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.11735v1",
      "pdf_path": "data/pdfs/costa2024probabilistic.pdf",
      "added_date": "2025-12-12T11:24:46.274553",
      "abstract": "This thesis focuses on three fundamental aspects of biological systems; namely, entropy production, Bayesian mechanics, and the free-energy principle. The contributions are threefold: 1) We compute the entropy production for a greater class of systems than before, including almost any stationary diffusion process, such as degenerate diffusions where the driving noise does not act on all coordinates of the system. Importantly, this class of systems encompasses Markovian approximations of stochastic differential equations driven by colored noise, which is significant since biological systems at the macro- and meso-scale are generally subject to colored fluctuations. 2) We develop a Bayesian mechanics for biological and physical entities that interact with their environment in which we give sufficient and necessary conditions for the internal states of something to infer its external states, consistently with variational Bayesian inference in statistics and theoretical neuroscience. 3) We refine the constraints on Bayesian mechanics to obtain a description that is more specific to biological systems, called the free-energy principle. This says that active and internal states of biological systems unfold as minimising a quantity known as free energy. The mathematical foundation to the free-energy principle, presented here, unlocks a first principles approach to modeling and simulating behavior in neurobiology and artificial intelligence, by minimising free energy given a generative model of external and sensory states.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.11735.pdf"
      }
    },
    "tinker2024intrinsic": {
      "citation_key": "tinker2024intrinsic",
      "title": "Intrinsic Rewards for Exploration without Harm from Observational Noise: A Simulation Study Based on the Free Energy Principle",
      "authors": [
        "Theodore Jerome Tinker",
        "Kenji Doya",
        "Jun Tani"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2405.07473v1",
      "pdf_path": "data/pdfs/tinker2024intrinsic.pdf",
      "added_date": "2025-12-12T11:24:46.276662",
      "abstract": "In Reinforcement Learning (RL), artificial agents are trained to maximize numerical rewards by performing tasks. Exploration is essential in RL because agents must discover information before exploiting it. Two rewards encouraging efficient exploration are the entropy of action policy and curiosity for information gain. Entropy is well-established in literature, promoting randomized action selection. Curiosity is defined in a broad variety of ways in literature, promoting discovery of novel experiences. One example, prediction error curiosity, rewards agents for discovering observations they cannot accurately predict. However, such agents may be distracted by unpredictable observational noises known as curiosity traps. Based on the Free Energy Principle (FEP), this paper proposes hidden state curiosity, which rewards agents by the KL divergence between the predictive prior and posterior probabilities of latent variables. We trained six types of agents to navigate mazes: baseline agents without rewards for entropy or curiosity, and agents rewarded for entropy and/or either prediction error curiosity or hidden state curiosity. We find entropy and curiosity result in efficient exploration, especially both employed together. Notably, agents with hidden state curiosity demonstrate resilience against curiosity traps, which hinder agents with prediction error curiosity. This suggests implementing the FEP may enhance the robustness and generalization of RL models, potentially aligning the learning processes of artificial and biological agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2405.07473.pdf"
      }
    },
    "stamps2024active": {
      "citation_key": "stamps2024active",
      "title": "Active Inference Demonstrated with Artificial Spin Ice",
      "authors": [
        "Robert L. Stamps",
        "Rehana Begum Popy",
        "Johan van Lierop"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2401.12211v4",
      "pdf_path": "data/pdfs/stamps2024active.pdf",
      "added_date": "2025-12-12T11:24:46.278945",
      "abstract": "A numerical model of interacting nanomagnetic elements is used to demonstrate active inference with a three dimensional Artificial Spin Ice structure. It is shown that thermal fluctuations can drive this magnetic spin system to evolve under dynamic constraints imposed through interactions with an external environment as predicted by the neurological free energy principle and active inference. The structure is defined by two layers of magnetic nanoelements where one layer is a square Artificial Spin Ice geometry. The other magnetic layer functions as a sensory filter that mediates interaction between the external environment and the hidden Artificial Spin Ice layer. Spin dynamics displayed by the bilayer structure are shown to be well described using a continuous form of a neurological free energy principle that has been previously proposed as a high level description of certain biological neural processes. Numerical simulations demonstrate that this proposed bilayer geometry is able to reproduce theoretical results derived previously for examples of active inference in neurological contexts.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2401.12211.pdf"
      }
    },
    "friston2022free": {
      "citation_key": "friston2022free",
      "title": "The free energy principle made simpler but not too simple",
      "authors": [
        "Karl Friston",
        "Lancelot Da Costa",
        "Noor Sajid",
        "Conor Heins",
        "Kai Ueltzhöffer",
        "Grigorios A. Pavliotis",
        "Thomas Parr"
      ],
      "year": 2022,
      "doi": "10.1016/j.physrep.2023.07.001",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2201.06387v3",
      "pdf_path": "data/pdfs/friston2022free.pdf",
      "added_date": "2025-12-12T11:24:46.282869",
      "abstract": "This paper provides a concise description of the free energy principle, starting from a formulation of random dynamical systems in terms of a Langevin equation and ending with a Bayesian mechanics that can be read as a physics of sentience. It rehearses the key steps using standard results from statistical physics. These steps entail (i) establishing a particular partition of states based upon conditional independencies that inherit from sparsely coupled dynamics, (ii) unpacking the implications of this partition in terms of Bayesian inference and (iii) describing the paths of particular states with a variational principle of least action. Teleologically, the free energy principle offers a normative account of self-organisation in terms of optimal Bayesian design and decision-making, in the sense of maximising marginal likelihood or Bayesian model evidence. In summary, starting from a description of the world in terms of random dynamical systems, we end up with a description of self-organisation as sentient behaviour that can be interpreted as self-evidencing; namely, self-assembly, autopoiesis or active inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2201.06387.pdf"
      }
    },
    "fields2022free": {
      "citation_key": "fields2022free",
      "title": "The Free Energy Principle drives neuromorphic development",
      "authors": [
        "Chris Fields",
        "Karl Friston",
        "James F. Glazebrook",
        "Michael Levin",
        "Antonino Marcianò"
      ],
      "year": 2022,
      "doi": "10.1088/2634-4386/aca7de",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2207.09734v1",
      "pdf_path": "data/pdfs/fields2022free.pdf",
      "added_date": "2025-12-12T11:24:46.284992",
      "abstract": "We show how any system with morphological degrees of freedom and locally limited free energy will, under the constraints of the free energy principle, evolve toward a neuromorphic morphology that supports hierarchical computations in which each level of the hierarchy enacts a coarse-graining of its inputs, and dually a fine-graining of its outputs. Such hierarchies occur throughout biology, from the architectures of intracellular signal transduction pathways to the large-scale organization of perception and action cycles in the mammalian brain. Formally, the close formal connections between cone-cocone diagrams (CCCD) as models of quantum reference frames on the one hand, and between CCCDs and topological quantum field theories on the other, allow the representation of such computations in the fully-general quantum-computational framework of topological quantum neural networks.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2207.09734.pdf"
      }
    },
    "sakthivadivel2022regarding": {
      "citation_key": "sakthivadivel2022regarding",
      "title": "Regarding Flows Under the Free Energy Principle: A Comment on \"How Particular is the Physics of the Free Energy Principle?\" by Aguilera, Millidge, Tschantz, and Buckley",
      "authors": [
        "Dalton A R Sakthivadivel"
      ],
      "year": 2022,
      "doi": "10.1016/j.plrev.2022.05.009",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2205.07793v2",
      "pdf_path": "data/pdfs/sakthivadivel2022regarding.pdf",
      "added_date": "2025-12-12T11:24:46.286957",
      "abstract": "In a recent technical critique of the free energy principle (FEP) due to Aguilera-Millidge-Tschantz-Buckley, it is argued that there are a number of instances where the FEP$\\unicode{x2014}$as conventionally written, in terms of densities over states$\\unicode{x2014}$is uninformative about the dynamics of many physical systems, and by extension, many 'things.' In this informal comment on their critique, I highlight two points of interest where their derivations are largely correct, but where their arguments are not fatal to the FEP. I go on to conjecture that a path-based formulation of the FEP has key features which restore its explanatory power in broad physical regimes. Correspondingly, this piece takes the position that the application of a state-based formulation of the FEP is inappropriate for certain simple systems, but, that the FEP can be expected to hold regardless.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2205.07793.pdf"
      }
    },
    "ramstead2022some": {
      "citation_key": "ramstead2022some",
      "title": "Some Minimal Notes on Notation and Minima: A Comment on \"How Particular is the Physics of the Free Energy Principle?\" by Aguilera, Millidge, Tschantz, and Buckley",
      "authors": [
        "Maxwell J D Ramstead",
        "Dalton A R Sakthivadivel"
      ],
      "year": 2022,
      "doi": "10.1016/j.plrev.2022.05.005",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2204.13576v1",
      "pdf_path": "data/pdfs/ramstead2022some.pdf",
      "added_date": "2025-12-12T11:24:46.288772",
      "abstract": "We comment on a technical critique of the free energy principle in linear systems by Aguilera, Millidge, Tschantz, and Buckley, entitled \"How Particular is the Physics of the Free Energy Principle?\" Aguilera and colleagues identify an ambiguity in the flow of the mode of a system, and we discuss the context for this ambiguity in earlier papers, and their proposal of a more adequate interpretation of these equations. Following that, we discuss a misinterpretation in their treatment of surprisal and variational free energy, especially with respect to their gradients and their minima. In sum, we argue that the results in the target paper are accurate and stand up to rigorous scrutiny; we also highlight that they, nonetheless, do not undermine the FEP.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2204.13576.pdf"
      }
    },
    "ramstead2022one": {
      "citation_key": "ramstead2022one",
      "title": "One person's modus ponens...: Comment on \"The Markov blanket trick: On the scope of the free energy principle and active inference\" by Raja and colleagues (2021)",
      "authors": [
        "Maxwell J. D Ramstead"
      ],
      "year": 2022,
      "doi": "10.1016/j.plrev.2022.11.001",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2208.04275v1",
      "pdf_path": "data/pdfs/ramstead2022one.pdf",
      "added_date": "2025-12-12T11:24:46.290584",
      "abstract": "In this comment on \"The Markov blanket trick: On the scope of the free energy principle and active inference\" by Raja and colleagues (2021) in Physics of Life Reviews, I argue that the argument presented by the authors is valid; however, I claim that the argument contains a flawed premise, which undermines their conclusions. In addition, I argue that work on the FEP that has appeared since the target paper was published underwrites a cogent response to the issues that are raised by Raja and colleagues.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2208.04275.pdf"
      }
    },
    "heins2022sparse": {
      "citation_key": "heins2022sparse",
      "title": "Sparse coupling and Markov blankets: A comment on \"How particular is the physics of the Free Energy Principle?\" by Aguilera, Millidge, Tschantz and Buckley",
      "authors": [
        "Conor Heins",
        "Lancelot Da Costa"
      ],
      "year": 2022,
      "doi": "10.1016/j.plrev.2022.06.001",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2205.10190v2",
      "pdf_path": "data/pdfs/heins2022sparse.pdf",
      "added_date": "2025-12-12T11:24:46.292100",
      "abstract": "In this commentary, we respond to a technical analysis of the Free Energy Principle (hereafter: FEP) presented in \"How particular is the physics of the Free Energy Principle\" by Aguilera et al. In the target article, the authors analyzed certain sparsely coupled stochastic differential equations whose non-equilibrium steady-state densities are claimed--in previous FEP literature--to have a Markov blanket. The authors demonstrate that in general, Markov blankets are not guaranteed to follow from sparse coupling. The current commentary explains the relationship between sparse coupling and Markov blankets in the case of Gaussian steady-state densities. We precisely derive conditions under which causal coupling leads--or does not lead--to Markov blankets. Importantly, our derivations hold for both linear and non-linear stochastic differential equations. This result may shed light on the sorts of systems which we expect to have Markov blankets. Future work should focus on verifying whether these sorts of constraints are satisfied in realistic models of sparsely coupled systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2205.10190.pdf"
      }
    },
    "heins2022particular": {
      "citation_key": "heins2022particular",
      "title": "Particular flows and attracting sets: A comment on \"How particular is the physics of the Free Energy Principle?\" by Aguilera, Millidge, Tschantz and Buckley",
      "authors": [
        "Conor Heins"
      ],
      "year": 2022,
      "doi": "10.1016/j.plrev.2022.06.003",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2205.09595v1",
      "pdf_path": "data/pdfs/heins2022particular.pdf",
      "added_date": "2025-12-12T11:24:46.294012",
      "abstract": "In this commentary, I expand on the analysis of the recent article \"How particular is the physics of the Free Energy Principle?\" by Aguilera et al. by studying the flow fields of linear diffusions, and particularly the rotation of their attracting sets in the presence of different types of solenoidal coupling. This analysis sheds new light on previous claims made in the FEP literature (and contested in the target article) that the internal dynamics of stochastic systems can be cast performing a gradient flow on variational free energy, and thus endowed with an inferential interpretation, i.e., as if internal states are performing inference about states external to the system. I express general agreement with the target article's statement that the marginal flow of internal states does not point along variational free energy gradients evaluated at the most likely internal state (i.e., the conditional mode). However, in this commentary I focus on the flow of particular states (internal and blanket states) and their variational free energy gradients, and show that for a wide but restricted class of solenoidal couplings, the average flow of these systems point along variational free energy gradients. This licenses a different but perhaps stronger re-description of the flow of particular states as performing inference, which importantly holds at arbitrary points in state space, not just at the conditional modes.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2205.09595.pdf"
      }
    },
    "peltre2023local": {
      "citation_key": "peltre2023local",
      "title": "Local Max-Entropy and Free Energy Principles, Belief Diffusions and their Singularities",
      "authors": [
        "Olivier Peltre"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2310.02946v1",
      "pdf_path": "data/pdfs/peltre2023local.pdf",
      "added_date": "2025-12-12T11:24:46.295811",
      "abstract": "A comprehensive picture of three Bethe-Kikuchi variational principles including their relationship to belief propagation (BP) algorithms on hypergraphs is given. The structure of BP equations is generalized to define continuous-time diffusions, solving localized versions of the max-entropy principle (A), the variational free energy principle (B), and a less usual equilibrium free energy principle (C), Legendre dual to A. Both critical points of Bethe-Kikuchi functionals and stationary beliefs are shown to lie at the non-linear intersection of two constraint surfaces, enforcing energy conservation and marginal consistency respectively. The hypersurface of singular beliefs, accross which equilibria become unstable as the constraint surfaces meet tangentially, is described by polynomial equations in the convex polytope of consistent beliefs. This polynomial is expressed by a loop series expansion for graphs of binary variables.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2310.02946.pdf"
      }
    },
    "sawada2023humanrobot": {
      "citation_key": "sawada2023humanrobot",
      "title": "Human-Robot Kinaesthetic Interaction Based on Free Energy Principle",
      "authors": [
        "Hiroki Sawada",
        "Wataru Ohata",
        "Jun Tani"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2303.15213v1",
      "pdf_path": "data/pdfs/sawada2023humanrobot.pdf",
      "added_date": "2025-12-12T11:24:46.297637",
      "abstract": "The current study investigated possible human-robot kinaesthetic interaction using a variational recurrent neural network model, called PV-RNN, which is based on the free energy principle. Our prior robotic studies using PV-RNN showed that the nature of interactions between top-down expectation and bottom-up inference is strongly affected by a parameter, called the meta-prior, which regulates the complexity term in free energy.The study also compares the counter force generated when trained transitions are induced by a human experimenter and when untrained transitions are induced. Our experimental results indicated that (1) the human experimenter needs more/less force to induce trained transitions when $w$ is set with larger/smaller values, (2) the human experimenter needs more force to act on the robot when he attempts to induce untrained as opposed to trained movement pattern transitions. Our analysis of time development of essential variables and values in PV-RNN during bodily interaction clarified the mechanism by which gaps in actional intentions between the human experimenter and the robot can be manifested as reaction forces between them.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2303.15213.pdf"
      }
    },
    "liu2023neural": {
      "citation_key": "liu2023neural",
      "title": "A Neural Network Implementation for Free Energy Principle",
      "authors": [
        "Jingwei Liu"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2306.06792v1",
      "pdf_path": "data/pdfs/liu2023neural.pdf",
      "added_date": "2025-12-12T11:24:46.299672",
      "abstract": "The free energy principle (FEP), as an encompassing framework and a unified brain theory, has been widely applied to account for various problems in fields such as cognitive science, neuroscience, social interaction, and hermeneutics. As a computational model deeply rooted in math and statistics, FEP posits an optimization problem based on variational Bayes, which is solved either by dynamic programming or expectation maximization in practice. However, there seems to be a bottleneck in extending the FEP to machine learning and implementing such models with neural networks. This paper gives a preliminary attempt at bridging FEP and machine learning, via a classical neural network model, the Helmholtz machine. As a variational machine learning model, the Helmholtz machine is optimized by minimizing its free energy, the same objective as FEP. Although the Helmholtz machine is not temporal, it gives an ideal parallel to the vanilla FEP and the hierarchical model of the brain, under which the active inference and predictive coding could be formulated coherently. Besides a detailed theoretical discussion, the paper also presents a preliminary experiment to validate the hypothesis. By fine-tuning the trained neural network through active inference, the model performance is promoted to accuracy above 99\\%. In the meantime, the data distribution is continuously deformed to a salience that conforms to the model representation, as a result of active sampling.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2306.06792.pdf"
      }
    },
    "ramstead2023inner": {
      "citation_key": "ramstead2023inner",
      "title": "The inner screen model of consciousness: applying the free energy principle directly to the study of conscious experience",
      "authors": [
        "Maxwell J. D. Ramstead",
        "Mahault Albarracin",
        "Alex Kiefer",
        "Brennan Klein",
        "Chris Fields",
        "Karl Friston",
        "Adam Safron"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2305.02205v4",
      "pdf_path": "data/pdfs/ramstead2023inner.pdf",
      "added_date": "2025-12-12T11:24:46.301381",
      "abstract": "This paper presents a model of consciousness that follows directly from the free-energy principle (FEP). We first rehearse the classical and quantum formulations of the FEP. In particular, we consider the inner screen hypothesis that follows from the quantum information theoretic version of the FEP. We then review applications of the FEP to the known sparse (nested and hierarchical) neuro-anatomy of the brain. We focus on the holographic structure of the brain, and how this structure supports (overt and covert) action.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2305.02205.pdf"
      }
    },
    "fields2021free": {
      "citation_key": "fields2021free",
      "title": "A free energy principle for generic quantum systems",
      "authors": [
        "Chris Fields",
        "Karl Friston",
        "James F. Glazebrook",
        "Michael Levin"
      ],
      "year": 2021,
      "doi": "10.1016/j.pbiomolbio.2022.05.006",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.15242v1",
      "pdf_path": "data/pdfs/fields2021free.pdf",
      "added_date": "2025-12-12T11:24:46.303285",
      "abstract": "The Free Energy Principle (FEP) states that under suitable conditions of weak coupling, random dynamical systems with sufficient degrees of freedom will behave so as to minimize an upper bound, formalized as a variational free energy, on surprisal (a.k.a., self-information). This upper bound can be read as a Bayesian prediction error. Equivalently, its negative is a lower bound on Bayesian model evidence (a.k.a., marginal likelihood). In short, certain random dynamical systems evince a kind of self-evidencing. Here, we reformulate the FEP in the formal setting of spacetime-background free, scale-free quantum information theory. We show how generic quantum systems can be regarded as observers, which with the standard freedom of choice assumption become agents capable of assigning semantics to observational outcomes. We show how such agents minimize Bayesian prediction error in environments characterized by uncertainty, insufficient learning, and quantum contextuality. We show that in its quantum-theoretic formulation, the FEP is asymptotically equivalent to the Principle of Unitarity. Based on these results, we suggest that biological systems employ quantum coherence as a computational resource and - implicitly - as a communication resource. We summarize a number of problems for future research, particularly involving the resources required for classical communication and for detecting and responding to quantum context switches.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.15242.pdf"
      }
    },
    "aguilera2021how": {
      "citation_key": "aguilera2021how",
      "title": "How particular is the physics of the free energy principle?",
      "authors": [
        "Miguel Aguilera",
        "Beren Millidge",
        "Alexander Tschantz",
        "Christopher L. Buckley"
      ],
      "year": 2021,
      "doi": "10.1016/j.plrev.2021.11.001",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2105.11203v3",
      "pdf_path": "data/pdfs/aguilera2021how.pdf",
      "added_date": "2025-12-12T11:24:46.305322",
      "abstract": "The free energy principle (FEP) states that any dynamical system can be interpreted as performing Bayesian inference upon its surrounding environment. In this work, we examine in depth the assumptions required to derive the FEP in the simplest possible set of systems -- weakly-coupled non-equilibrium linear stochastic systems. Specifically, we explore (i) how general the requirements imposed on the statistical structure of a system are and (ii) how informative the FEP is about the behaviour of such systems. We discover that two requirements of the FEP -- the Markov blanket condition (i.e. a statistical boundary precluding direct coupling between internal and external states) and stringent restrictions on its solenoidal flows (i.e. tendencies driving a system out of equilibrium) -- are only valid for a very narrow space of parameters. Suitable systems require an absence of perception-action asymmetries that is highly unusual for living systems interacting with an environment. More importantly, we observe that a mathematically central step in the argument, connecting the behaviour of a system to variational inference, relies on an implicit equivalence between the dynamics of the average states of a system with the average of the dynamics of those states. This equivalence does not hold in general even for linear systems, since it requires an effective decoupling from the system's history of interactions. These observations are critical for evaluating the generality and applicability of the FEP and indicate the existence of significant problems of the theory in its current form. These issues make the FEP, as it stands, not straightforwardly applicable to the simple linear systems studied here and suggest that more development is needed before the theory could be applied to the kind of complex systems that describe living and cognitive processes.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2105.11203.pdf"
      }
    },
    "meera2022free": {
      "citation_key": "meera2022free",
      "title": "Free Energy Principle for the Noise Smoothness Estimation of Linear Systems with Colored Noise",
      "authors": [
        "Ajith Anil Meera",
        "Martijn Wisse"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2204.01796v1",
      "pdf_path": "data/pdfs/meera2022free.pdf",
      "added_date": "2025-12-12T11:24:46.308211",
      "abstract": "The free energy principle (FEP) from neuroscience provides a framework called active inference for the joint estimation and control of state space systems, subjected to colored noise. However, the active inference community has been challenged with the critical task of manually tuning the noise smoothness parameter. To solve this problem, we introduce a novel online noise smoothness estimator based on the idea of free energy principle. We mathematically show that our estimator can converge to the free energy optimum during smoothness estimation. Using this formulation, we introduce a joint state and noise smoothness observer design called DEMs. Through rigorous simulations, we show that DEMs outperforms state-of-the-art state observers with least state estimation error. Finally, we provide a proof of concept for DEMs by applying it on a real life robotics problem - state estimation of a quadrotor hovering in wind, demonstrating its practical use.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2204.01796.pdf"
      }
    },
    "murphy2022natural": {
      "citation_key": "murphy2022natural",
      "title": "Natural Language Syntax Complies with the Free-Energy Principle",
      "authors": [
        "Elliot Murphy",
        "Emma Holmes",
        "Karl Friston"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2210.15098v1",
      "pdf_path": "data/pdfs/murphy2022natural.pdf",
      "added_date": "2025-12-12T11:24:46.309857",
      "abstract": "Natural language syntax yields an unbounded array of hierarchically structured expressions. We claim that these are used in the service of active inference in accord with the free-energy principle (FEP). While conceptual advances alongside modelling and simulation work have attempted to connect speech segmentation and linguistic communication with the FEP, we extend this program to the underlying computations responsible for generating syntactic objects. We argue that recently proposed principles of economy in language design - such as \"minimal search\" criteria from theoretical syntax - adhere to the FEP. This affords a greater degree of explanatory power to the FEP - with respect to higher language functions - and offers linguistics a grounding in first principles with respect to computability. We show how both tree-geometric depth and a Kolmogorov complexity estimate (recruiting a Lempel-Ziv compression algorithm) can be used to accurately predict legal operations on syntactic workspaces, directly in line with formulations of variational free energy minimization. This is used to motivate a general principle of language design that we term Turing-Chomsky Compression (TCC). We use TCC to align concerns of linguists with the normative account of self-organization furnished by the FEP, by marshalling evidence from theoretical linguistics and psycholinguistics to ground core principles of efficient syntactic computation within active inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2210.15098.pdf"
      }
    },
    "peltre2022local": {
      "citation_key": "peltre2022local",
      "title": "Local Max-Entropy and Free Energy Principles Solved by Belief Propagation",
      "authors": [
        "Olivier Peltre"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2207.00841v1",
      "pdf_path": "data/pdfs/peltre2022local.pdf",
      "added_date": "2025-12-12T11:24:46.311453",
      "abstract": "A statistical system is classically defined on a set of microstates $E$ by a global energy function $H : E \\to \\mathbb{R}$, yielding Gibbs probability measures (softmins) $ρ^β(H)$ for every inverse temperature $β= T^{-1}$. Gibbs states are simultaneously characterized by free energy principles and the max-entropy principle, with dual constraints on inverse temperature $β$ and mean energy ${\\cal U}(β) = \\mathbb{E}_{ρ^β}[H]$ respectively. The Legendre transform relates these diverse variational principles which are unfortunately not tractable in high dimension.   The global energy is generally given as a sum $H(x) = \\sum_{\\rm a \\subset Ω} h_{\\rm a}(x_{|\\rm a})$ of local short-range interactions $h_{\\rm a} : E_{\\rm a} \\to \\mathbb{R}$ indexed by bounded subregions ${\\rm a} \\subset Ω$, and this local structure can be used to design good approximation schemes on thermodynamic functionals. We show that the generalized belief propagation (GBP) algorithm solves a collection of local variational principles, by converging to critical points of Bethe-Kikuchi approximations of the free energy $F(β)$, the Shannon entropy $S(\\cal U)$, and the variational free energy ${\\cal F}(β) = {\\cal U} - β^{-1} S(\\cal U)$, extending an initial correspondence by Yedidia et al. This local form of Legendre duality yields a possible degenerate relationship between mean energy ${\\cal U}$ and $β$.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2207.00841.pdf"
      }
    },
    "seth2022continuity": {
      "citation_key": "seth2022continuity",
      "title": "A continuity of Markov blanket interpretations under the Free Energy Principle",
      "authors": [
        "Anil Seth",
        "Tomasz Korbak",
        "Alexander Tschantz"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2201.06900v1",
      "pdf_path": "data/pdfs/seth2022continuity.pdf",
      "added_date": "2025-12-12T11:24:46.313381",
      "abstract": "Bruineberg and colleagues helpfully distinguish between instrumental and ontological interpretations of Markov blankets, exposing the dangers of using the former to make claims about the latter. However, proposing a sharp distinction neglects the value of recognising a continuum spanning from instrumental to ontological. This value extends to the related distinction between being and having a model.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2201.06900.pdf"
      }
    },
    "spector2022blankets": {
      "citation_key": "spector2022blankets",
      "title": "Blankets, Heat, and Why Free Energy Has Not Illuminated the Workings of the Brain",
      "authors": [
        "Donald Spector",
        "Daniel Graham"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2201.01668v2",
      "pdf_path": "data/pdfs/spector2022blankets.pdf",
      "added_date": "2025-12-12T11:24:46.315025",
      "abstract": "What can we hope to learn about brains from the free energy principle? In adopting the \"primordial soup\" physical model, Bruineberg et al. perpetuate the unsupported notion that the free energy principle has a meaningful physical--and neuronal--interpretation. We examine how minimization of free energy arises in physical contexts, and what this can and cannot tell us about brains.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2201.01668.pdf"
      }
    },
    "esaki2020sensorimotor": {
      "citation_key": "esaki2020sensorimotor",
      "title": "Sensorimotor Visual Perception on Embodied System Using Free Energy Principle",
      "authors": [
        "Kanako Esaki",
        "Tadayuki Matsumura",
        "Kiyoto Ito",
        "Hiroyuki Mizuno"
      ],
      "year": 2020,
      "doi": "10.1007/978-3-030-93736-2_62",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2006.06192v2",
      "pdf_path": "data/pdfs/esaki2020sensorimotor.pdf",
      "added_date": "2025-12-12T11:24:46.317432",
      "abstract": "We propose an embodied system based on the free energy principle (FEP) for sensorimotor visual perception. We evaluated it in a character-recognition task using the MNIST dataset. Although the FEP has successfully described a rule that living things obey mathematically and claims that a biological system continues to change its internal models and behaviors to minimize the difference in predicting sensory input, it is not enough to model sensorimotor visual perception. An embodiment of the system is the key to achieving sensorimotor visual perception. The proposed embodied system is configured by a body and memory. The body has an ocular motor system controlling the direction of eye gaze, which means that the eye can only observe a small focused area of the environment. The memory is not photographic, but is a generative model implemented with a variational autoencoder that contains prior knowledge about the environment, and that knowledge is classified. By limiting body and memory abilities and operating according to the FEP, the embodied system repeatedly takes action to obtain the next sensory input based on various potentials of future sensory inputs. In the evaluation, the inference of the environment was represented as an approximate posterior distribution of characters (0 - 9). As the number of repetitions increased, the attention area moved continuously, gradually reducing the uncertainty of characters. Finally, the probability of the correct character became the highest among the characters. Changing the initial attention position provides a different final distribution, suggesting that the proposed system has a confirmation bias.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2006.06192.pdf"
      }
    },
    "ramstead2020is": {
      "citation_key": "ramstead2020is",
      "title": "Is the free-energy principle a formal theory of semantics? From variational density dynamics to neural and phenotypic representations",
      "authors": [
        "Maxwell Ramstead",
        "Karl Friston",
        "Ines Hipolito"
      ],
      "year": 2020,
      "doi": "10.3390/e22080889",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2007.09291v3",
      "pdf_path": "data/pdfs/ramstead2020is.pdf",
      "added_date": "2025-12-12T11:24:46.318960",
      "abstract": "The aim of this paper is twofold: (1) to assess whether the construct of neural representations plays an explanatory role under the variational free-energy principle and its corollary process theory, active inference; and (2) if so, to assess which philosophical stance - in relation to the ontological and epistemological status of representations - is most appropriate. We focus on non-realist (deflationary and fictionalist-instrumentalist) approaches. We consider a deflationary account of mental representation, according to which the explanatorily relevant contents of neural representations are mathematical, rather than cognitive, and a fictionalist or instrumentalist account, according to which representations are scientifically useful fictions that serve explanatory (and other) aims. After reviewing the free-energy principle and active inference, we argue that the model of adaptive phenotypes under the free-energy principle can be used to furnish a formal semantics, enabling us to assign semantic content to specific phenotypic states (the internal states of a Markovian system that exists far from equilibrium). We propose a modified fictionalist account: an organism-centered fictionalism or instrumentalism. We argue that, under the free-energy principle, pursuing even a deflationary account of the content of neural representations licenses the appeal to the kind of semantic content involved in the aboutness or intentionality of cognitive systems; our position is thus coherent with, but rests on distinct assumptions from, the realist position. We argue that the free-energy principle thereby explains the aboutness or intentionality in living systems and hence their capacity to parse their sensory stream using an ontology or set of semantic factors.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2007.09291.pdf"
      }
    },
    "ogishima2021reinforced": {
      "citation_key": "ogishima2021reinforced",
      "title": "Reinforced Imitation Learning by Free Energy Principle",
      "authors": [
        "Ryoya Ogishima",
        "Izumi Karino",
        "Yasuo Kuniyoshi"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2107.11811v1",
      "pdf_path": "data/pdfs/ogishima2021reinforced.pdf",
      "added_date": "2025-12-12T11:24:46.321245",
      "abstract": "Reinforcement Learning (RL) requires a large amount of exploration especially in sparse-reward settings. Imitation Learning (IL) can learn from expert demonstrations without exploration, but it never exceeds the expert's performance and is also vulnerable to distributional shift between demonstration and execution. In this paper, we radically unify RL and IL based on Free Energy Principle (FEP). FEP is a unified Bayesian theory of the brain that explains perception, action and model learning by a common fundamental principle. We present a theoretical extension of FEP and derive an algorithm in which an agent learns the world model that internalizes expert demonstrations and at the same time uses the model to infer the current and future states and actions that maximize rewards. The algorithm thus reduces exploration costs by partially imitating experts as well as maximizing its return in a seamless way, resulting in a higher performance than the suboptimal expert. Our experimental results show that this approach is promising in visual control tasks especially in sparse-reward environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2107.11811.pdf"
      }
    },
    "bos2021free": {
      "citation_key": "bos2021free",
      "title": "Free Energy Principle for State and Input Estimation of a Quadcopter Flying in Wind",
      "authors": [
        "Fred Bos",
        "Ajith Anil Meera",
        "Dennis Benders",
        "Martijn Wisse"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2109.12052v1",
      "pdf_path": "data/pdfs/bos2021free.pdf",
      "added_date": "2025-12-12T11:24:46.322767",
      "abstract": "The free energy principle from neuroscience provides a brain-inspired perception scheme through a data-driven model learning algorithm called Dynamic Expectation Maximization (DEM). This paper aims at introducing an experimental design to provide the first experimental confirmation of the usefulness of DEM as a state and input estimator for real robots. Through a series of quadcopter flight experiments under unmodelled wind dynamics, we prove that DEM can leverage the information from colored noise for accurate state and input estimation through the use of generalized coordinates. We demonstrate the superior performance of DEM for state estimation under colored noise with respect to other benchmarks like State Augmentation, SMIKF and Kalman Filtering through its minimal estimation error. We demonstrate the similarities in the performance of DEM and Unknown Input Observer (UIO) for input estimation. The paper concludes by showing the influence of prior beliefs in shaping the accuracy-complexity trade-off during DEM's estimation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2109.12052.pdf"
      }
    },
    "kappel2021synapsecentric": {
      "citation_key": "kappel2021synapsecentric",
      "title": "A synapse-centric account of the free energy principle",
      "authors": [
        "David Kappel",
        "Christian Tetzlaff"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2103.12649v1",
      "pdf_path": "data/pdfs/kappel2021synapsecentric.pdf",
      "added_date": "2025-12-12T11:24:46.324822",
      "abstract": "The free energy principle (FEP) is a mathematical framework that describes how biological systems self-organize and survive in their environment. This principle provides insights on multiple scales, from high-level behavioral and cognitive functions such as attention or foraging, down to the dynamics of specialized cortical microcircuits, suggesting that the FEP manifests on several levels of brain function. Here, we apply the FEP to one of the smallest functional units of the brain: single excitatory synaptic connections. By focusing on an experimentally well understood biological system we are able to derive learning rules from first principles while keeping assumptions minimal. This synapse-centric account of the FEP predicts that synapses interact with the soma of the post-synaptic neuron through stochastic synaptic releases to probe their behavior and use back-propagating action potentials as feedback to update the synaptic weights. The emergent learning rules are regulated triplet STDP rules that depend only on the timing of the pre- and post-synaptic spikes and the internal states of the synapse. The parameters of the learning rules are fully determined by the parameters of the post-synaptic neuron model, suggesting a close interplay between the synaptic and somatic compartment and making precise predictions about the synaptic dynamics. The synapse-level uncertainties automatically lead to representations of uncertainty on the network level that manifest in ambiguous situations. We show that the FEP learning rules can be applied to spiking neural networks for supervised and unsupervised learning and for a closed loop learning task where a behaving agent interacts with an environment.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2103.12649.pdf"
      }
    },
    "millidge2021mathematical": {
      "citation_key": "millidge2021mathematical",
      "title": "A Mathematical Walkthrough and Discussion of the Free Energy Principle",
      "authors": [
        "Beren Millidge",
        "Anil Seth",
        "Christopher L Buckley"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2108.13343v2",
      "pdf_path": "data/pdfs/millidge2021mathematical.pdf",
      "added_date": "2025-12-12T11:24:46.326588",
      "abstract": "The Free-Energy-Principle (FEP) is an influential and controversial theory which postulates a deep and powerful connection between the stochastic thermodynamics of self-organization and learning through variational inference. Specifically, it claims that any self-organizing system which can be statistically separated from its environment, and which maintains itself at a non-equilibrium steady state, can be construed as minimizing an information-theoretic functional -- the variational free energy -- and thus performing variational Bayesian inference to infer the hidden state of its environment. This principle has also been applied extensively in neuroscience, and is beginning to make inroads in machine learning by spurring the construction of novel and powerful algorithms by which action, perception, and learning can all be unified under a single objective. While its expansive and often grandiose claims have spurred significant debates in both philosophy and theoretical neuroscience, the mathematical depth and lack of accessible introductions and tutorials for the core claims of the theory have often precluded a deep understanding within the literature. Here, we aim to provide a mathematically detailed, yet intuitive walk-through of the formulation and central claims of the FEP while also providing a discussion of the assumptions necessary and potential limitations of the theory. Additionally, since the FEP is a still a living theory, subject to internal controversy, change, and revision, we also present a detailed appendix highlighting and condensing current perspectives as well as controversies about the nature, applicability, and the mathematical assumptions and formalisms underlying the FEP.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2108.13343.pdf"
      }
    },
    "gershman2019what": {
      "citation_key": "gershman2019what",
      "title": "What does the free energy principle tell us about the brain?",
      "authors": [
        "Samuel J. Gershman"
      ],
      "year": 2019,
      "doi": "10.51628/001c.37270",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1901.07945v5",
      "pdf_path": "data/pdfs/gershman2019what.pdf",
      "added_date": "2025-12-12T11:24:46.328319",
      "abstract": "The free energy principle has been proposed as a unifying account of brain function. It is closely related, and in some cases subsumes, earlier unifying ideas such as Bayesian inference, predictive coding, and active learning. This article clarifies these connections, teasing apart distinctive and shared predictions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1901.07945.pdf"
      }
    },
    "laar2019application": {
      "citation_key": "laar2019application",
      "title": "Application of the Free Energy Principle to Estimation and Control",
      "authors": [
        "Thijs van de Laar",
        "Ayça Özçelikkale",
        "Henk Wymeersch"
      ],
      "year": 2019,
      "doi": "10.1109/TSP.2021.3095711",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1910.09823v3",
      "pdf_path": "data/pdfs/laar2019application.pdf",
      "added_date": "2025-12-12T11:24:46.330116",
      "abstract": "Based on a generative model (GM) and beliefs over hidden states, the free energy principle (FEP) enables an agent to sense and act by minimizing a free energy bound on Bayesian surprise. Inclusion of prior beliefs in the GM about desired states leads to active inference (ActInf). In this work, we aim to reveal connections between ActInf and stochastic optimal control. We reveal that, in contrast to standard cost and constraint-based solutions, ActInf gives rise to a minimization problem that includes both an information-theoretic surprise term and a model-predictive control cost term. We further show under which conditions both methodologies yield the same solution for estimation and control. For a case with linear Gaussian dynamics and a quadratic cost, we illustrate the performance of ActInf under varying system parameters and compare to classical solutions for estimation and control.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1910.09823.pdf"
      }
    },
    "annabi2020autonomous": {
      "citation_key": "annabi2020autonomous",
      "title": "Autonomous learning and chaining of motor primitives using the Free Energy Principle",
      "authors": [
        "Louis Annabi",
        "Alexandre Pitti",
        "Mathias Quoy"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2005.05151v1",
      "pdf_path": "data/pdfs/annabi2020autonomous.pdf",
      "added_date": "2025-12-12T11:24:46.333069",
      "abstract": "In this article, we apply the Free-Energy Principle to the question of motor primitives learning. An echo-state network is used to generate motor trajectories. We combine this network with a perception module and a controller that can influence its dynamics. This new compound network permits the autonomous learning of a repertoire of motor trajectories. To evaluate the repertoires built with our method, we exploit them in a handwriting task where primitives are chained to produce long-range sequences.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2005.05151.pdf"
      }
    },
    "ramstead2020neural": {
      "citation_key": "ramstead2020neural",
      "title": "Neural and phenotypic representation under the free-energy principle",
      "authors": [
        "Maxwell J. D. Ramstead",
        "Casper Hesp",
        "Alec Tschantz",
        "Ryan Smith",
        "Axel Constant",
        "Karl Friston"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2008.03238v2",
      "pdf_path": "data/pdfs/ramstead2020neural.pdf",
      "added_date": "2025-12-12T11:24:46.335093",
      "abstract": "The aim of this paper is to leverage the free-energy principle and its corollary process theory, active inference, to develop a generic, generalizable model of the representational capacities of living creatures; that is, a theory of phenotypic representation. Given their ubiquity, we are concerned with distributed forms of representation (e.g., population codes), whereby patterns of ensemble activity in living tissue come to represent the causes of sensory input or data. The active inference framework rests on the Markov blanket formalism, which allows us to partition systems of interest, such as biological systems, into internal states, external states, and the blanket (active and sensory) states that render internal and external states conditionally independent of each other. In this framework, the representational capacity of living creatures emerges as a consequence of their Markovian structure and nonequilibrium dynamics, which together entail a dual-aspect information geometry. This entails a modest representational capacity: internal states have an intrinsic information geometry that describes their trajectory over time in state space, as well as an extrinsic information geometry that allows internal states to encode (the parameters of) probabilistic beliefs about (fictive) external states. Building on this, we describe here how, in an automatic and emergent manner, information about stimuli can come to be encoded by groups of neurons bound by a Markov blanket; what is known as the neuronal packet hypothesis. As a concrete demonstration of this type of emergent representation, we present numerical simulations showing that self-organizing ensembles of active inference agents sharing the right kind of probabilistic generative model are able to encode recoverable information about a stimulus array.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2008.03238.pdf"
      }
    },
    "ortega2012free": {
      "citation_key": "ortega2012free",
      "title": "Free Energy and the Generalized Optimality Equations for Sequential Decision Making",
      "authors": [
        "Pedro A. Ortega",
        "Daniel A. Braun"
      ],
      "year": 2012,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1205.3997v1",
      "pdf_path": "data/pdfs/ortega2012free.pdf",
      "added_date": "2025-12-12T11:24:46.338741",
      "abstract": "The free energy functional has recently been proposed as a variational principle for bounded rational decision-making, since it instantiates a natural trade-off between utility gains and information processing costs that can be axiomatically derived. Here we apply the free energy principle to general decision trees that include both adversarial and stochastic environments. We derive generalized sequential optimality equations that not only include the Bellman optimality equations as a limit case, but also lead to well-known decision-rules such as Expectimax, Minimax and Expectiminimax. We show how these decision-rules can be derived from a single free energy principle that assigns a resource parameter to each node in the decision tree. These resource parameters express a concrete computational cost that can be measured as the amount of samples that are needed from the distribution that belongs to each node. The free energy principle therefore provides the normative basis for generalized optimality equations that account for both adversarial and stochastic environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1205.3997.pdf"
      }
    },
    "buckley2017free": {
      "citation_key": "buckley2017free",
      "title": "The free energy principle for action and perception: A mathematical review",
      "authors": [
        "Christopher L. Buckley",
        "Chang Sub Kim",
        "Simon McGregor",
        "Anil K. Seth"
      ],
      "year": 2017,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1705.09156v1",
      "pdf_path": "data/pdfs/buckley2017free.pdf",
      "added_date": "2025-12-12T11:24:46.340723",
      "abstract": "The 'free energy principle' (FEP) has been suggested to provide a unified theory of the brain, integrating data and theory relating to action, perception, and learning. The theory and implementation of the FEP combines insights from Helmholtzian 'perception as inference', machine learning theory, and statistical thermodynamics. Here, we provide a detailed mathematical evaluation of a suggested biologically plausible implementation of the FEP that has been widely used to develop the theory. Our objectives are (i) to describe within a single article the mathematical structure of this implementation of the FEP; (ii) provide a simple but complete agent-based model utilising the FEP; (iii) disclose the assumption structure of this implementation of the FEP to help elucidate its significance for the brain sciences.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1705.09156.pdf"
      }
    },
    "kim2017recognition": {
      "citation_key": "kim2017recognition",
      "title": "Recognition Dynamics in the Brain under the Free Energy Principle",
      "authors": [
        "Chang Sub Kim"
      ],
      "year": 2017,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1710.09118v3",
      "pdf_path": "data/pdfs/kim2017recognition.pdf",
      "added_date": "2025-12-12T11:24:46.342319",
      "abstract": "We formulate the computational processes of perception in the framework of the principle of least action by postulating the theoretical action as a time integral of the free energy in the brain sciences. The free energy principle is accordingly rephrased as that for autopoietic grounds all viable organisms attempt to minimize the sensory uncertainty about the unpredictable environment over a temporal horizon. By varying the informational action, we derive the brain's recognition dynamics (RD) which conducts Bayesian filtering of the external causes from noisy sensory inputs. Consequently, we effectively cast the gradient-descent scheme of minimizing the free energy into Hamiltonian mechanics by addressing only positions and momenta of the organisms' representations of the causal environment. To manifest the utility of our theory, we show how the RD may be implemented in a neuronally based biophysical model at a single-cell level and subsequently in a coarse-grained, hierarchical architecture of the brain. We also present formal solutions to the RD for a model brain in linear regime and analyze the perceptual trajectories around attractors in neural state space.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1710.09118.pdf"
      }
    },
    "mazzaglia2022free": {
      "citation_key": "mazzaglia2022free",
      "title": "The Free Energy Principle for Perception and Action: A Deep Learning Perspective",
      "authors": [
        "Pietro Mazzaglia",
        "Tim Verbelen",
        "Ozan Çatal",
        "Bart Dhoedt"
      ],
      "year": 2022,
      "doi": "10.3390/e24020301",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2207.06415v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:43:17.491102",
      "abstract": "The free energy principle, and its corollary active inference, constitute a bio-inspired theory that assumes biological agents act to remain in a restricted set of preferred states of the world, i.e., they minimize their free energy. Under this principle, biological agents learn a generative model of the world and plan actions in the future that will maintain the agent in an homeostatic state that satisfies its preferences. This framework lends itself to being realized in silico, as it comprehends important aspects that make it computationally affordable, such as variational inference and amortized planning. In this work, we investigate the tool of deep learning to design and realize artificial agents based on active inference, presenting a deep-learning oriented presentation of the free energy principle, surveying works that are relevant in both machine learning and active inference areas, and discussing the design choices that are involved in the implementation process. This manuscript probes newer perspectives for the active inference framework, grounding its theoretical aspects into more pragmatic affairs, offering a practical guide to active inference newcomers and a starting point for deep learning practitioners that would like to investigate implementations of the free energy principle.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2207.06415.pdf"
      }
    },
    "thomas2022knowledge": {
      "citation_key": "thomas2022knowledge",
      "title": "Knowledge as Fruits of Ignorance: A global Free Energy Principle of our way of thinking",
      "authors": [
        "Cailleteau Thomas"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2206.05684v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:43:17.500204",
      "abstract": "In this second article, we show a simple use of the Ignorance as defined in \"Jaynes & Shannon's Constrained Ignorance and Surprise\". By giving an example about the journey of a person, we believe to show some simple, obvious but mathematically encoded philosophical implications about how we could think, learn and memorize. In this basic model we will separate how we learn from Ignorance, and how we anticipate the world using Bayes formula, both should however be more entangled to best reflect reality. In fact, as we have seen after achieving this work, applying Ignorance on the system constituting a person finally turns out to be the global approach of its local counterpart on systems like neurons, cells and other complex probabilistic systems, described using the free energy principle, a much more complex and detailed approach. The aim of this article is therefore to show, as seen from a person, another aspect of the application of the free energy principle which represents the constrained Shannon's entropy, and leads to Bayes'formula. We show that, using only ignorance as a single quantity, and its minimization as the main process, we can take into account his understandings, assertions, doubts and assumptions about how he perceives the world, by describing them mathematically.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2206.05684.pdf"
      }
    },
    "friston2020some": {
      "citation_key": "friston2020some",
      "title": "Some interesting observations on the free energy principle",
      "authors": [
        "Karl Friston",
        "Lancelot Da Costa",
        "Thomas Parr"
      ],
      "year": 2020,
      "doi": "10.3390/e23081076",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2002.04501v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:43:17.508793",
      "abstract": "Biehl et al (2020) present some interesting observations on an early formulation of the free energy principle in (Friston, 2013). We use these observations to scaffold a discussion of the technical arguments that underwrite the free energy principle. This discussion focuses on solenoidal coupling between various (subsets of) states in sparsely coupled systems that possess a Markov blanket - and the distinction between exact and approximate Bayesian inference, implied by the ensuing Bayesian mechanics.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2002.04501.pdf"
      }
    },
    "biehl2020technical": {
      "citation_key": "biehl2020technical",
      "title": "A Technical Critique of Some Parts of the Free Energy Principle",
      "authors": [
        "Martin Biehl",
        "Felix A. Pollock",
        "Ryota Kanai"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2001.06408v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:43:17.515565",
      "abstract": "We summarize the original formulation of the free energy principle, and highlight some technical issues. We discuss how these issues affect related results involving generalised coordinates and, where appropriate, mention consequences for and reveal, up to now unacknowledged, differences to newer formulations of the free energy principle. In particular, we reveal that various definitions of the \"Markov blanket\" proposed in different works are not equivalent. We show that crucial steps in the free energy argument which involve rewriting the equations of motion of systems with Markov blankets, are not generally correct without additional (previously unstated) assumptions. We prove by counterexample that the original free energy lemma, when taken at face value, is wrong. We show further that this free energy lemma, when it does hold, implies equality of variational density and ergodic conditional density. The interpretation in terms of Bayesian inference hinges on this point, and we hence conclude that it is not sufficiently justified. Additionally, we highlight that the variational densities presented in newer formulations of the free energy principle and lemma are parameterised by different variables than in older works, leading to a substantially different interpretation of the theory. Note that we only highlight some specific problems in the discussed publications. These problems do not rule out conclusively that the general ideas behind the free energy principle are worth pursuing.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2001.06408.pdf"
      }
    },
    "bennett2025what": {
      "citation_key": "bennett2025what",
      "title": "What the F*ck Is Artificial General Intelligence?",
      "authors": [
        "Michael Timothy Bennett"
      ],
      "year": 2025,
      "doi": "10.1007/978-3-032-00686-8_4",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.23923v2",
      "pdf_path": "data/pdfs/bennett2025what.pdf",
      "added_date": "2025-12-12T11:49:31.219328",
      "abstract": "Artificial general intelligence (AGI) is an established field of research. Yet some have questioned if the term still has meaning. AGI has been subject to so much hype and speculation it has become something of a Rorschach test. Melanie Mitchell argues the debate will only be settled through long term, scientific investigation. To that end here is a short, accessible and provocative overview of AGI. I compare definitions of intelligence, settling on intelligence in terms of adaptation and AGI as an artificial scientist. Taking my cue from Sutton's Bitter Lesson I describe two foundational tools used to build adaptive systems: search and approximation. I compare pros, cons, hybrids and architectures like o3, AlphaGo, AERA, NARS and Hyperon. I then discuss overall meta-approaches to making systems behave more intelligently. I divide them into scale-maxing, simp-maxing, w-maxing based on the Bitter Lesson, Ockham's and Bennett's Razors. These maximise resources, simplicity of form, and the weakness of constraints on functionality. I discuss examples including AIXI, the free energy principle and The Embiggening of language models. I conclude that though scale-maxed approximation dominates, AGI will be a fusion of tools and meta-approaches. The Embiggening was enabled by improvements in hardware. Now the bottlenecks are sample and energy efficiency.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.23923.pdf"
      }
    },
    "lu2025semantic": {
      "citation_key": "lu2025semantic",
      "title": "A Semantic Generalization of Shannon's Information Theory and Applications",
      "authors": [
        "Chenguang Lu"
      ],
      "year": 2025,
      "doi": "10.3390/e27050461",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.15871v1",
      "pdf_path": "data/pdfs/lu2025semantic.pdf",
      "added_date": "2025-12-12T11:49:31.222045",
      "abstract": "Does semantic communication require a semantic information theory parallel to Shannon's information theory, or can Shannon's work be generalized for semantic communication? This paper advocates for the latter and introduces a semantic generalization of Shannon's information theory (G theory for short). The core idea is to replace the distortion constraint with the semantic constraint, achieved by utilizing a set of truth functions as a semantic channel. These truth functions enable the expressions of semantic distortion, semantic information measures, and semantic information loss. Notably, the maximum semantic information criterion is equivalent to the maximum likelihood criterion and similar to the Regularized Least Squares criterion. This paper shows G theory's applications to daily and electronic semantic communication, machine learning, constraint control, Bayesian confirmation, portfolio theory, and information value. The improvements in machine learning methods involve multilabel learning and classification, maximum mutual information classification, mixture models, and solving latent variables. Furthermore, insights from statistical physics are discussed: Shannon information is similar to free energy; semantic information to free energy in local equilibrium systems; and information efficiency to the efficiency of free energy in performing work. The paper also proposes refining Friston's minimum free energy principle into the maximum information efficiency principle. Lastly, it compares G theory with other semantic information theories and discusses its limitation in representing the semantics of complex data.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.15871.pdf"
      }
    },
    "fujii2025realworld": {
      "citation_key": "fujii2025realworld",
      "title": "Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model",
      "authors": [
        "Kentaro Fujii",
        "Shingo Murata"
      ],
      "year": 2025,
      "doi": "10.1109/LRA.2025.3636032",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2512.01924v1",
      "pdf_path": "data/pdfs/fujii2025realworld.pdf",
      "added_date": "2025-12-12T11:49:31.223686",
      "abstract": "Robots in uncertain real-world environments must perform both goal-directed and exploratory actions. However, most deep learning-based control methods neglect exploration and struggle under uncertainty. To address this, we adopt deep active inference, a framework that accounts for human goal-directed and exploratory actions. Yet, conventional deep active inference approaches face challenges due to limited environmental representation capacity and high computational cost in action selection. We propose a novel deep active inference framework that consists of a world model, an action model, and an abstract world model. The world model encodes environmental dynamics into hidden state representations at slow and fast timescales. The action model compresses action sequences into abstract actions using vector quantization, and the abstract world model predicts future slow states conditioned on the abstract action, enabling low-cost action selection. We evaluate the framework on object-manipulation tasks with a real-world robot. Results show that it achieves high success rates across diverse manipulation tasks and switches between goal-directed and exploratory actions in uncertain settings, while making action selection computationally tractable. These findings highlight the importance of modeling multiple timescale dynamics and abstracting actions and state transitions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2512.01924.pdf"
      }
    },
    "lapkovskis2025benchmarking": {
      "citation_key": "lapkovskis2025benchmarking",
      "title": "Benchmarking Dynamic SLO Compliance in Distributed Computing Continuum Systems",
      "authors": [
        "Alfreds Lapkovskis",
        "Boris Sedlak",
        "Sindri Magnússon",
        "Schahram Dustdar",
        "Praveen Kumar Donta"
      ],
      "year": 2025,
      "doi": "10.1109/EDGE67623.2025.00020",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.03274v1",
      "pdf_path": "data/pdfs/lapkovskis2025benchmarking.pdf",
      "added_date": "2025-12-12T11:49:31.225618",
      "abstract": "Ensuring Service Level Objectives (SLOs) in large-scale architectures, such as Distributed Computing Continuum Systems (DCCS), is challenging due to their heterogeneous nature and varying service requirements across different devices and applications. Additionally, unpredictable workloads and resource limitations lead to fluctuating performance and violated SLOs. To improve SLO compliance in DCCS, one possibility is to apply machine learning; however, the design choices are often left to the developer. To that extent, we provide a benchmark of Active Inference -- an emerging method from neuroscience -- against three established reinforcement learning algorithms (Deep Q-Network, Advantage Actor-Critic, and Proximal Policy Optimization). We consider a realistic DCCS use case: an edge device running a video conferencing application alongside a WebSocket server streaming videos. Using one of the respective algorithms, we continuously monitor key performance metrics, such as latency and bandwidth usage, to dynamically adjust parameters -- including the number of streams, frame rate, and resolution -- to optimize service quality and user experience. To test algorithms' adaptability to constant system changes, we simulate dynamically changing SLOs and both instant and gradual data-shift scenarios, such as network bandwidth limitations and fluctuating device thermal states. Although the evaluated algorithms all showed advantages and limitations, our findings demonstrate that Active Inference is a promising approach for ensuring SLO compliance in DCCS, offering lower memory usage, stable CPU utilization, and fast convergence.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.03274.pdf"
      }
    },
    "kavi2024from": {
      "citation_key": "kavi2024from",
      "title": "From Neuronal Packets to Thoughtseeds: A Hierarchical Model of Embodied Cognition in the Global Workspace",
      "authors": [
        "Prakash Chandra Kavi",
        "Gorka Zamora-López",
        "Daniel Ari Friedman"
      ],
      "year": 2024,
      "doi": "10.1371/journal.pcbi.1012973",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2408.15982v2",
      "pdf_path": "data/pdfs/kavi2024from.pdf",
      "added_date": "2025-12-12T11:49:31.228560",
      "abstract": "The emergence of cognition requires a framework that bridges evolutionary principles with neurocomputational mechanisms. This paper introduces the novel \"thoughtseed\" framework, proposing that cognition arises from the dynamic interaction of self-organizing units of embodied knowledge called \"thoughtseeds\" within the Global Workspace of consciousness. Leveraging foundational concepts from evolutionary theory, neuronal packets, and free energy principle, we propose a hierarchical model of cognitive states, comprising Neuronal Packet Domains (NPDs), Knowledge Domains (KDs), the thoughtseed network, and meta-cognition. This hierarchical interplay, mediated by nested Markov blankets and reciprocal message passing, facilitates the emergence of thoughtseeds as coherent patterns of activity that guide perception, action, and learning. Thoughtseeds, posited as fundamental units of thought, compete for dominance within the Global Workspace, with the dominant thoughtseed shaping conscious experience and guiding behavior. We present a mathematical framework grounded in active inference and dynamical systems theory to model thoughtseed dynamics and their contribution to the unitary nature of consciousness. The thoughtseed framework offers a promising step towards a novel, biologically-grounded model for understanding the organizing principles and emergence of embodied cognition, offering a unified account of cognitive phenomena, with potential applications in understanding consciousness, attention, and decision-making.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2408.15982.pdf"
      }
    },
    "yeganeh2024active": {
      "citation_key": "yeganeh2024active",
      "title": "Active Inference Meeting Energy-Efficient Control of Parallel and Identical Machines",
      "authors": [
        "Yavar Taheri Yeganeh",
        "Mohsen Jafari",
        "Andrea Matta"
      ],
      "year": 2024,
      "doi": "10.1007/978-3-031-82481-4_33",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.09322v2",
      "pdf_path": "data/pdfs/yeganeh2024active.pdf",
      "added_date": "2025-12-12T11:49:31.230656",
      "abstract": "We investigate the application of active inference in developing energy-efficient control agents for manufacturing systems. Active inference, rooted in neuroscience, provides a unified probabilistic framework integrating perception, learning, and action, with inherent uncertainty quantification elements. Our study explores deep active inference, an emerging field that combines deep learning with the active inference decision-making framework. Leveraging a deep active inference agent, we focus on controlling parallel and identical machine workstations to enhance energy efficiency. We address challenges posed by the problem's stochastic nature and delayed policy response by introducing tailored enhancements to existing agent architectures. Specifically, we introduce multi-step transition and hybrid horizon methods to mitigate the need for complex planning. Our experimental results demonstrate the effectiveness of these enhancements and highlight the potential of the active inference-based approach.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.09322.pdf"
      }
    },
    "wakayama2024active": {
      "citation_key": "wakayama2024active",
      "title": "Active Inference in Contextual Multi-Armed Bandits for Autonomous Robotic Exploration",
      "authors": [
        "Shohei Wakayama",
        "Alberto Candela",
        "Paul Hayne",
        "Nisar Ahmed"
      ],
      "year": 2024,
      "doi": "10.1109/TRO.2025.3577041",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2408.04119v2",
      "pdf_path": "data/pdfs/wakayama2024active.pdf",
      "added_date": "2025-12-12T11:49:31.232644",
      "abstract": "Autonomous selection of optimal options for data collection from multiple alternatives is challenging in uncertain environments. When secondary information about options is accessible, such problems can be framed as contextual multi-armed bandits (CMABs). Neuro-inspired active inference has gained interest for its ability to balance exploration and exploitation using the expected free energy objective function. Unlike previous studies that showed the effectiveness of active inference based strategy for CMABs using synthetic data, this study aims to apply active inference to realistic scenarios, using a simulated mineralogical survey site selection problem. Hyperspectral data from AVIRIS-NG at Cuprite, Nevada, serves as contextual information for predicting outcome probabilities, while geologists' mineral labels represent outcomes. Monte Carlo simulations assess the robustness of active inference against changing expert preferences. Results show that active inference requires fewer iterations than standard bandit approaches with real-world noisy and biased data, and performs better when outcome preferences vary online by adapting the selection strategy to align with expert shifts.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2408.04119.pdf"
      }
    },
    "oostrum2024concise": {
      "citation_key": "oostrum2024concise",
      "title": "A Concise Mathematical Description of Active Inference in Discrete Time",
      "authors": [
        "Jesse van Oostrum",
        "Carlotta Langer",
        "Nihat Ay"
      ],
      "year": 2024,
      "doi": "10.1016/j.jmp.2025.102921",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.07726v4",
      "pdf_path": "data/pdfs/oostrum2024concise.pdf",
      "added_date": "2025-12-12T11:49:31.235112",
      "abstract": "In this paper we present a concise mathematical description of active inference in discrete time. The main part of the paper serves as a basic introduction to the topic, including a detailed example of the action selection mechanism. The appendix discusses the more subtle mathematical details, targeting readers who have already studied the active inference literature but struggle to make sense of the mathematical details and derivations. Throughout, we emphasize precise and standard mathematical notation, ensuring consistency with existing texts and linking all equations to widely used references on active inference. Additionally, we provide Python code that implements the action selection and learning mechanisms described in this paper and is compatible with pymdp environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.07726.pdf"
      }
    },
    "paul2024predictive": {
      "citation_key": "paul2024predictive",
      "title": "On Predictive planning and counterfactual learning in active inference",
      "authors": [
        "Aswin Paul",
        "Takuya Isomura",
        "Adeel Razi"
      ],
      "year": 2024,
      "doi": "10.3390/e26060484",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2403.12417v1",
      "pdf_path": "data/pdfs/paul2024predictive.pdf",
      "added_date": "2025-12-12T11:49:31.237204",
      "abstract": "Given the rapid advancement of artificial intelligence, understanding the foundations of intelligent behaviour is increasingly important. Active inference, regarded as a general theory of behaviour, offers a principled approach to probing the basis of sophistication in planning and decision-making. In this paper, we examine two decision-making schemes in active inference based on 'planning' and 'learning from experience'. Furthermore, we also introduce a mixed model that navigates the data-complexity trade-off between these strategies, leveraging the strengths of both to facilitate balanced decision-making. We evaluate our proposed model in a challenging grid-world scenario that requires adaptability from the agent. Additionally, our model provides the opportunity to analyze the evolution of various parameters, offering valuable insights and contributing to an explainable framework for intelligent decision-making.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2403.12417.pdf"
      }
    },
    "tinguy2024exploring": {
      "citation_key": "tinguy2024exploring",
      "title": "Exploring and Learning Structure: Active Inference Approach in Navigational Agents",
      "authors": [
        "Daria de Tinguy",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2024,
      "doi": "10.1007/978-3-031-77138-5_7",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2408.05982v2",
      "pdf_path": "data/pdfs/tinguy2024exploring.pdf",
      "added_date": "2025-12-12T11:49:31.239264",
      "abstract": "Drawing inspiration from animal navigation strategies, we introduce a novel computational model for navigation and mapping, rooted in biologically inspired principles. Animals exhibit remarkable navigation abilities by efficiently using memory, imagination, and strategic decision-making to navigate complex and aliased environments. Building on these insights, we integrate traditional cognitive mapping approaches with an Active Inference Framework (AIF) to learn an environment structure in a few steps. Through the incorporation of topological mapping for long-term memory and AIF for navigation planning and structure learning, our model can dynamically apprehend environmental structures and expand its internal map with predicted beliefs during exploration. Comparative experiments with the Clone-Structured Graph (CSCG) model highlight our model's ability to rapidly learn environmental structures in a single episode, with minimal navigation overlap. this is achieved without prior knowledge of the dimensions of the environment or the type of observations, showcasing its robustness and effectiveness in navigating ambiguous environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2408.05982.pdf"
      }
    },
    "sloun2024active": {
      "citation_key": "sloun2024active",
      "title": "Active inference and deep generative modeling for cognitive ultrasound",
      "authors": [
        "Ruud JG van Sloun"
      ],
      "year": 2024,
      "doi": "10.1109/TUFFC.2024.3466290",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.13310v1",
      "pdf_path": "data/pdfs/sloun2024active.pdf",
      "added_date": "2025-12-12T11:49:31.241138",
      "abstract": "Ultrasound (US) has the unique potential to offer access to medical imaging to anyone, everywhere. Devices have become ultra-portable and cost-effective, akin to the stethoscope. Nevertheless US image quality and diagnostic efficacy are still highly operator- and patient-dependent. In difficult-to-image patients, image quality is often insufficient for reliable diagnosis. In this paper, we put forth that US imaging systems can be recast as information-seeking agents that engage in reciprocal interactions with their anatomical environment. Such agents autonomously adapt their transmit-receive sequences to fully personalize imaging and actively maximize information gain in-situ. To that end, we will show that the sequence of pulse-echo experiments that a US system performs can be interpreted as a perception-action loop: the action is the data acquisition, probing tissue with acoustic waves and recording reflections at the detection array, and perception is the inference of the anatomical and or functional state, potentially including associated diagnostic quantities. We then equip systems with a mechanism to actively reduce uncertainty and maximize diagnostic value across a sequence of experiments, treating action and perception jointly using Bayesian inference given generative models of the environment and action-conditional pulse-echo observations. Since the representation capacity of the generative models dictates both the quality of inferred anatomical states and the effectiveness of inferred sequences of future imaging actions, we will be greatly leveraging the enormous advances in deep generative modelling that are currently disrupting many fields and society at large. Finally, we show some examples of cognitive, closed-loop, US systems that perform active beamsteering and adaptive scanline selection, based on deep generative models that track anatomical belief states.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.13310.pdf"
      }
    },
    "tinguy2024learning": {
      "citation_key": "tinguy2024learning",
      "title": "Learning Dynamic Cognitive Map with Autonomous Navigation",
      "authors": [
        "Daria de Tinguy",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2024,
      "doi": "10.3389/fncom.2024.1498160",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2411.08447v1",
      "pdf_path": "data/pdfs/tinguy2024learning.pdf",
      "added_date": "2025-12-12T11:49:31.243719",
      "abstract": "Inspired by animal navigation strategies, we introduce a novel computational model to navigate and map a space rooted in biologically inspired principles. Animals exhibit extraordinary navigation prowess, harnessing memory, imagination, and strategic decision-making to traverse complex and aliased environments adeptly. Our model aims to replicate these capabilities by incorporating a dynamically expanding cognitive map over predicted poses within an Active Inference framework, enhancing our agent's generative model plasticity to novelty and environmental changes. Through structure learning and active inference navigation, our model demonstrates efficient exploration and exploitation, dynamically expanding its model capacity in response to anticipated novel un-visited locations and updating the map given new evidence contradicting previous beliefs. Comparative analyses in mini-grid environments with the Clone-Structured Cognitive Graph model (CSCG), which shares similar objectives, highlight our model's ability to rapidly learn environmental structures within a single episode, with minimal navigation overlap. Our model achieves this without prior knowledge of observation and world dimensions, underscoring its robustness and efficacy in navigating intricate environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2411.08447.pdf"
      }
    },
    "annicchiarico2024bayesian": {
      "citation_key": "annicchiarico2024bayesian",
      "title": "Bayesian model of individual learning to control a motor imagery BCI",
      "authors": [
        "Côme Annicchiarico",
        "Fabien Lotte",
        "Jérémie Mattout"
      ],
      "year": 2024,
      "doi": "10.3217/978-3-99161-014-4-083",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.05926v1",
      "pdf_path": "data/pdfs/annicchiarico2024bayesian.pdf",
      "added_date": "2025-12-12T11:49:31.245726",
      "abstract": "The cognitive mechanisms underlying subjects' self-regulation in Brain-Computer Interface (BCI) and neurofeedback (NF) training remain poorly understood. Yet, a mechanistic computational model of each individual learning trajectory is required to improve the reliability of BCI applications. The few existing attempts mostly rely on model-free (reinforcement learning) approaches. Hence, they cannot capture the strategy developed by each subject and neither finely predict their learning curve. In this study, we propose an alternative, model-based approach rooted in cognitive skill learning within the Active Inference framework. We show how BCI training may be framed as an inference problem under high uncertainties. We illustrate the proposed approach on a previously published synthetic Motor Imagery ERD laterality training. We show how simple changes in model parameters allow us to qualitatively match experimental results and account for various subject. In the near future, this approach may provide a powerful computational to model individual skill learning and thus optimize and finely characterize BCI training.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.05926.pdf"
      }
    },
    "chen2024why": {
      "citation_key": "chen2024why",
      "title": "Why collective behaviours self-organise to criticality: A primer on information-theoretic and thermodynamic utility measures",
      "authors": [
        "Qianyang Chen",
        "Mikhail Prokopenko"
      ],
      "year": 2024,
      "doi": "10.1098/rsos.241655",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2409.15668v3",
      "pdf_path": "data/pdfs/chen2024why.pdf",
      "added_date": "2025-12-12T11:49:31.247558",
      "abstract": "Collective behaviours are frequently observed to self-organise to criticality. Existing proposals to explain these phenomena are fragmented across disciplines and only partially answer the question. This primer compares the underlying, intrinsic, utilities that may explain the self-organisation of collective behaviours near criticality. We focus on information-driven approaches (predictive information, empowerment, and active inference), as well as an approach incorporating both information theory and thermodynamics (thermodynamic efficiency). By interpreting the Ising model as a perception-action loop, we compare how different intrinsic utilities shape collective behaviour and analyse the distinct characteristics that arise when each is optimised. In particular, we highlight that thermodynamic efficiency -- measuring the ratio of predictability gained by the system to its energy costs -- reaches its maximum at the critical regime. Finally, we propose the Principle of Super-efficiency, suggesting that collective behaviours self-organise to the critical regime where optimal efficiency is achieved with respect to the entropy reduction relative to the thermodynamic costs.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2409.15668.pdf"
      }
    },
    "bazargani2025brain": {
      "citation_key": "bazargani2025brain",
      "title": "Brain in the Dark: Design Principles for Neuromimetic Inference under the Free Energy Principle",
      "authors": [
        "Mehran H. Bazargani",
        "Szymon Urbas",
        "Karl Friston"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2502.08860v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:31.250616",
      "abstract": "Deep learning has revolutionised artificial intelligence (AI) by enabling automatic feature extraction and function approximation from raw data. However, it faces challenges such as a lack of out-of-distribution generalisation, catastrophic forgetting and poor interpretability. In contrast, biological neural networks, such as those in the human brain, do not suffer from these issues, inspiring AI researchers to explore neuromimetic deep learning, which aims to replicate brain mechanisms within AI models. A foundational theory for this approach is the Free Energy Principle (FEP), which despite its potential, is often considered too complex to understand and implement in AI as it requires an interdisciplinary understanding across a variety of fields. This paper seeks to demystify the FEP and provide a comprehensive framework for designing neuromimetic models with human-like perception capabilities. We present a roadmap for implementing these models and a Pytorch code repository for applying FEP in a predictive coding network.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2502.08860.pdf"
      }
    },
    "vries2025expected": {
      "citation_key": "vries2025expected",
      "title": "Expected Free Energy-based Planning as Variational Inference",
      "authors": [
        "Bert de Vries",
        "Wouter Nuijten",
        "Thijs van de Laar",
        "Wouter Kouw",
        "Sepideh Adamiat",
        "Tim Nisslbeck",
        "Mykola Lukashchuk",
        "Hoang Minh Huu Nguyen",
        "Marco Hidalgo Araya",
        "Raphael Tresor",
        "Thijs Jenneskens",
        "Ivana Nikoloska",
        "Raaja Ganapathy Subramanian",
        "Bart van Erp",
        "Dmitry Bagaev",
        "Albert Podusenko"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2504.14898v4",
      "pdf_path": "data/pdfs/vries2025expected.pdf",
      "added_date": "2025-12-12T11:49:31.255528",
      "abstract": "We address the problem of planning under uncertainty, where an agent must choose actions that not only achieve desired outcomes but also reduce uncertainty. Traditional methods often treat exploration and exploitation as separate objectives, lacking a unified inferential foundation. Active inference, grounded in the Free Energy Principle, provides such a foundation by minimizing Expected Free Energy (EFE), a cost function that combines utility with epistemic drives, such as ambiguity resolution and novelty seeking. However, the computational burden of EFE minimization had remained a significant obstacle to its scalability. In this paper, we show that EFE-based planning arises naturally from minimizing a variational free energy functional on a generative model augmented with preference and epistemic priors. This result reinforces theoretical consistency with the Free Energy Principle by casting planning under uncertainty itself as a form of variational inference. Our formulation yields policies that jointly support goal achievement and information gain, while incorporating a complexity term that accounts for bounded computational resources. This unifying framework connects and extends existing methods, enabling scalable, resource-aware implementations of active inference agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2504.14898.pdf"
      }
    },
    "kidera2025evaluation": {
      "citation_key": "kidera2025evaluation",
      "title": "Evaluation of \"As-Intended\" Vehicle Dynamics using the Active Inference Framework",
      "authors": [
        "Kazuharu Kidera",
        "Takuma Miyaguchi",
        "Hideyoshi Yanagisawa"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.00035v2",
      "pdf_path": "data/pdfs/kidera2025evaluation.pdf",
      "added_date": "2025-12-12T11:49:31.257232",
      "abstract": "We constructed a computational model of the driver's brain for steering tasks using the active inference framework, grounded in the free energy principle - a theory from computational neuroscience. This model enables quantitative estimation of how accurately the brain learns vehicle dynamics and performs appropriate steering, using a measure called variational free energy. Through driving simulator experiments, we observed strong correlations between variational free energy and both expert drivers' subjective \"as-intended\" scores and general participants' objective control performance. These results suggest that variational free energy provides a promising quantitative metric for evaluating whether a vehicle behaves \"as-intended.\"",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.00035.pdf"
      }
    },
    "kenny2025active": {
      "citation_key": "kenny2025active",
      "title": "Active Inference in Discrete State Spaces from First Principles",
      "authors": [
        "Patrick Kenny"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2511.20321v2",
      "pdf_path": "data/pdfs/kenny2025active.pdf",
      "added_date": "2025-12-12T11:49:31.259197",
      "abstract": "We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2511.20321.pdf"
      }
    },
    "jhajj2025graph": {
      "citation_key": "jhajj2025graph",
      "title": "Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning",
      "authors": [
        "Gaganpreet Jhajj",
        "Fuhua Lin"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2512.01878v1",
      "pdf_path": "data/pdfs/jhajj2025graph.pdf",
      "added_date": "2025-12-12T11:49:31.261485",
      "abstract": "In this work, we propose that reasoning in knowledge graph (KG) networks can be guided by surprise minimization. Entities that are close in graph distance will have lower surprise than those farther apart. This connects the Free Energy Principle (FEP) from neuroscience to KG systems, where the KG serves as the agent's generative model. We formalize surprise using the shortest-path distance in directed graphs and provide a framework for KG-based agents. Graph distance appears in graph neural networks as message passing depth and in model-based reinforcement learning as world model trajectories. This work-in-progress study explores whether distance-based surprise can extend recent work showing that syntax minimizes surprise and free energy via tree structures.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2512.01878.pdf"
      }
    },
    "esaki2025eperson": {
      "citation_key": "esaki2025eperson",
      "title": "e-person Architecture and Framework for Human-AI Co-adventure Relationship",
      "authors": [
        "Kanako Esaki",
        "Tadayuki Matsumura",
        "Yang Shao",
        "Hiroyuki Mizuno"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.22181v1",
      "pdf_path": "data/pdfs/esaki2025eperson.pdf",
      "added_date": "2025-12-12T11:49:31.263412",
      "abstract": "This paper proposes the e-person architecture for constructing a unified and incremental development of AI ethics. The e-person architecture takes the reduction of uncertainty through collaborative cognition and action with others as a unified basis for ethics. By classifying and defining uncertainty along two axes - (1) first, second, and third person perspectives, and (2) the difficulty of inference based on the depth of information - we support the development of unified and incremental development of AI ethics. In addition, we propose the e-person framework based on the free energy principle, which considers the reduction of uncertainty as a unifying principle of brain function, with the aim of implementing the e-person architecture, and we show our previous works and future challenges based on the proposed framework.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.22181.pdf"
      }
    },
    "nazemi2025active": {
      "citation_key": "nazemi2025active",
      "title": "Active Inference for Energy Control and Planning in Smart Buildings and Communities",
      "authors": [
        "Seyyed Danial Nazemi",
        "Mohsen A. Jafari",
        "Andrea Matta"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.18161v1",
      "pdf_path": "data/pdfs/nazemi2025active.pdf",
      "added_date": "2025-12-12T11:49:31.265203",
      "abstract": "Active Inference (AIF) is emerging as a powerful framework for decision-making under uncertainty, yet its potential in engineering applications remains largely unexplored. In this work, we propose a novel dual-layer AIF architecture that addresses both building-level and community-level energy management. By leveraging the free energy principle, each layer adapts to evolving conditions and handles partial observability without extensive sensor information and respecting data privacy. We validate the continuous AIF model against both a perfect optimization baseline and a reinforcement learning-based approach. We also test the community AIF framework under extreme pricing scenarios. The results highlight the model's robustness in handling abrupt changes. This study is the first to show how a distributed AIF works in engineering. It also highlights new opportunities for privacy-preserving and uncertainty-aware control strategies in engineering applications.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.18161.pdf"
      }
    },
    "donta2025resilient": {
      "citation_key": "donta2025resilient",
      "title": "Resilient by Design -- Active Inference for Distributed Continuum Intelligence",
      "authors": [
        "Praveen Kumar Donta",
        "Alfreds Lapkovskis",
        "Enzo Mingozzi",
        "Schahram Dustdar"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2511.07202v2",
      "pdf_path": "data/pdfs/donta2025resilient.pdf",
      "added_date": "2025-12-12T11:49:31.267481",
      "abstract": "Failures are the norm in highly complex and heterogeneous devices spanning the distributed computing continuum (DCC), from resource-constrained IoT and edge nodes to high-performance computing systems. Ensuring reliability and global consistency across these layers remains a major challenge, especially for AI-driven workloads requiring real-time, adaptive coordination. This work-in-progress paper introduces a Probabilistic Active Inference Resilience Agent (PAIR-Agent) to achieve resilience in DCC systems. PAIR-Agent performs three core operations: (i) constructing a causal fault graph from device logs, (ii) identifying faults while managing certainties and uncertainties using Markov blankets and the free energy principle, and (iii) autonomously healing issues through active inference. Through continuous monitoring and adaptive reconfiguration, the agent maintains service continuity and stability under diverse failure conditions. Theoretical validations confirm the reliability and effectiveness of the proposed framework.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2511.07202.pdf"
      }
    },
    "williams2025free": {
      "citation_key": "williams2025free",
      "title": "Free Energy and Network Structure: Breaking Scale-Free Behaviour Through Information Processing Constraints",
      "authors": [
        "Peter R Williams",
        "Zhan Chen"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2502.12654v1",
      "pdf_path": "data/pdfs/williams2025free.pdf",
      "added_date": "2025-12-12T11:49:31.269700",
      "abstract": "In this paper we show how The Free Energy Principle (FEP) can provide an explanation for why real-world networks deviate from scale-free behaviour, and how these characteristic deviations can emerge from constraints on information processing. We propose a minimal FEP model for node behaviour reveals three distinct regimes: when detection noise dominates, agents seek better information, reducing isolated agents compared to expectations from classical preferential attachment. In the optimal detection regime, super-linear growth emerges from compounded improvements in detection, belief, and action, which produce a preferred cluster scale. Finally, saturation effects occur as limits on the agent's information processing capabilities prevent indefinite cluster growth. These regimes produce the knee-shaped degree distributions observed in real networks, explaining them as signatures of agents with optimal information processing under constraints. We show that agents evolving under FEP principles provides a mechanism for preferential attachment, connecting agent psychology with the macroscopic network features that underpin the structure of real-world networks.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2502.12654.pdf"
      }
    },
    "wang2025bridging": {
      "citation_key": "wang2025bridging",
      "title": "Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation",
      "authors": [
        "Chaoran Wang",
        "Jingyuan Sun",
        "Yanhui Zhang",
        "Changju Wu"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2512.04404v1",
      "pdf_path": "data/pdfs/wang2025bridging.pdf",
      "added_date": "2025-12-12T11:49:31.271579",
      "abstract": "This paper proposes an Interactive Inference Behavior Tree (IIBT) framework that integrates behavior trees (BTs) with active inference under the free energy principle for distributed multi-robot decision-making. The proposed IIBT node extends conventional BTs with probabilistic reasoning, enabling online joint planning and execution across multiple robots. It remains fully compatible with standard BT architectures, allowing seamless integration into existing multi-robot control systems. Within this framework, multi-robot cooperation is formulated as a free-energy minimization process, where each robot dynamically updates its preference matrix based on perceptual inputs and peer intentions, thereby achieving adaptive coordination in partially observable and dynamic environments. The proposed approach is validated through both simulation and real-world experiments, including a multi-robot maze navigation and a collaborative manipulation task, compared against traditional BTs(https://youtu.be/KX_oT3IDTf4). Experimental results demonstrate that the IIBT framework reduces BT node complexity by over 70%, while maintaining robust, interpretable, and adaptive cooperative behavior under environmental uncertainty.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2512.04404.pdf"
      }
    },
    "dao2025boosting": {
      "citation_key": "dao2025boosting",
      "title": "Boosting MCTS with Free Energy Minimization",
      "authors": [
        "Mawaba Pascal Dao",
        "Adrian M. Peter"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2501.13083v1",
      "pdf_path": "data/pdfs/dao2025boosting.pdf",
      "added_date": "2025-12-12T11:49:31.273635",
      "abstract": "Active Inference, grounded in the Free Energy Principle, provides a powerful lens for understanding how agents balance exploration and goal-directed behavior in uncertain environments. Here, we propose a new planning framework, that integrates Monte Carlo Tree Search (MCTS) with active inference objectives to systematically reduce epistemic uncertainty while pursuing extrinsic rewards. Our key insight is that MCTS already renowned for its search efficiency can be naturally extended to incorporate free energy minimization by blending expected rewards with information gain. Concretely, the Cross-Entropy Method (CEM) is used to optimize action proposals at the root node, while tree expansions leverage reward modeling alongside intrinsic exploration bonuses. This synergy allows our planner to maintain coherent estimates of value and uncertainty throughout planning, without sacrificing computational tractability. Empirically, we benchmark our planner on a diverse set of continuous control tasks, where it demonstrates performance gains over both standalone CEM and MCTS with random rollouts.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2501.13083.pdf"
      }
    },
    "li2025trion": {
      "citation_key": "li2025trion",
      "title": "Trion ordering in the attractive three-color Hubbard model on a $π$-flux square lattice",
      "authors": [
        "Xiang Li",
        "Yumeng Li",
        "Quan Fu",
        "Yu Wang"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2512.06284v1",
      "pdf_path": "data/pdfs/li2025trion.pdf",
      "added_date": "2025-12-12T11:49:31.275781",
      "abstract": "Ultracold multicomponent fermions (atoms/molecules) loaded in optical lattices provide an ideal platform for simulating SU($N$) Hubbard models that host unconventional many-body quantum states beyond SU(2). A prime example is the attractive three-color Hubbard model, in which trion states emerge at strong coupling. Nevertheless, much of its trion ordering on two-dimensional lattices remains uncertain. Here, we employ the determinant quantum Monte Carlo (DQMC) method to simulate the attractive three-color Hubbard model on a $π$-flux square lattice at half filling. We show that color-dependent attractive interaction can induce coexisting charge density wave (CDW) and Néel ordered states in the three-color $π$-flux Hubbard model. In particular, enhanced charge fluctuations (cf. honeycomb lattice) cause much stronger Néel ordering on the $π$-flux square lattice. The coexisting charge and Néel orders survive up to a melting temperature, at which they vanish simultaneously. The Ginzburg-Landau (GL) analysis on the coexistence of CDW and Néel orders demonstrates how color-dependent Hubbard interactions stabilize coexisting orders from the perspective of GL free energy principle.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2512.06284.pdf"
      }
    },
    "walters2025free": {
      "citation_key": "walters2025free",
      "title": "Free Energy Risk Metrics for Systemically Safe AI: Gatekeeping Multi-Agent Study",
      "authors": [
        "Michael Walters",
        "Rafael Kaufmann",
        "Justice Sefas",
        "Thomas Kopinski"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2502.04249v1",
      "pdf_path": "data/pdfs/walters2025free.pdf",
      "added_date": "2025-12-12T11:49:31.278223",
      "abstract": "We investigate the Free Energy Principle as a foundation for measuring risk in agentic and multi-agent systems. From these principles we introduce a Cumulative Risk Exposure metric that is flexible to differing contexts and needs. We contrast this to other popular theories for safe AI that hinge on massive amounts of data or describing arbitrarily complex world models. In our framework, stakeholders need only specify their preferences over system outcomes, providing straightforward and transparent decision rules for risk governance and mitigation. This framework naturally accounts for uncertainty in both world model and preference model, allowing for decision-making that is epistemically and axiologically humble, parsimonious, and future-proof. We demonstrate this novel approach in a simplified autonomous vehicle environment with multi-agent vehicles whose driving policies are mediated by gatekeepers that evaluate, in an online fashion, the risk to the collective safety in their neighborhood, and intervene through each vehicle's policy when appropriate. We show that the introduction of gatekeepers in an AV fleet, even at low penetration, can generate significant positive externalities in terms of increased system safety.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2502.04249.pdf"
      }
    },
    "mcculloch2025selfevidencing": {
      "citation_key": "mcculloch2025selfevidencing",
      "title": "Self-Evidencing Through Hierarchical Gradient Decomposition: A Dissipative System That Maintains Non-Equilibrium Steady-State by Minimizing Variational Free Energy",
      "authors": [
        "Michael James McCulloch"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.17916v1",
      "pdf_path": "data/pdfs/mcculloch2025selfevidencing.pdf",
      "added_date": "2025-12-12T11:49:31.280255",
      "abstract": "The Free Energy Principle (FEP) states that self-organizing systems must minimize variational free energy to persist, but the path from principle to implementable algorithm has remained unclear. We present a constructive proof that the FEP can be realized through exact local credit assignment. The system decomposes gradient computation hierarchically: spatial credit via feedback alignment, temporal credit via eligibility traces, and structural credit via a Trophic Field Map (TFM) that estimates expected gradient magnitude for each connection block. We prove these mechanisms are exact at their respective levels and validate the central claim empirically: the TFM achieves 0.9693 Pearson correlation with oracle gradients. This exactness produces emergent capabilities including 98.6% retention after task interference, autonomous recovery from 75% structural damage, self-organized criticality (spectral radius p ~= 1.0$), and sample-efficient reinforcement learning on continuous control tasks without replay buffers. The architecture unifies Prigogine's dissipative structures, Friston's free energy minimization, and Hopfield's attractor dynamics, demonstrating that exact hierarchical inference over network topology can be implemented with local, biologically plausible rules.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.17916.pdf"
      }
    },
    "haryanto2025cognitive": {
      "citation_key": "haryanto2025cognitive",
      "title": "Cognitive Silicon: An Architectural Blueprint for Post-Industrial Computing Systems",
      "authors": [
        "Christoforus Yoga Haryanto",
        "Emily Lomempow"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2504.16622v1",
      "pdf_path": "data/pdfs/haryanto2025cognitive.pdf",
      "added_date": "2025-12-12T11:49:31.282151",
      "abstract": "Autonomous AI systems reveal foundational limitations in deterministic, human-authored computing architectures. This paper presents Cognitive Silicon: a hypothetical full-stack architectural framework projected toward 2035, exploring a possible trajectory for cognitive computing system design. The proposed architecture would integrate symbolic scaffolding, governed memory, runtime moral coherence, and alignment-aware execution across silicon-to-semantics layers. Our design grammar has emerged from dialectical co-design with LLMs under asymmetric epistemic conditions--creating structured friction to expose blind spots and trade-offs. The envisioned framework would establish mortality as a natural consequence of physical constraints, non-copyable tacit knowledge, and non-cloneable identity keys as cognitive-embodiment primitives. Core tensions (trust/agency, scaffolding/emergence, execution/governance) would function as central architectural pressures rather than edge cases. The architecture theoretically converges with the Free Energy Principle, potentially offering a formal account of how cognitive systems could maintain identity through prediction error minimization across physical and computational boundaries. The resulting framework aims to deliver a morally tractable cognitive infrastructure that could maintain human-alignment through irreversible hardware constraints and identity-bound epistemic mechanisms resistant to replication or subversion.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2504.16622.pdf"
      }
    },
    "yaron2025dissociated": {
      "citation_key": "yaron2025dissociated",
      "title": "Dissociated Neuronal Cultures as Model Systems for Self-Organized Prediction",
      "authors": [
        "Amit Yaron",
        "Zhuo Zhang",
        "Dai Akita",
        "Tomoyo Isoguchi Shiramatsu",
        "Zenas Chao",
        "Hirokazu Takahashi"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2501.18772v1",
      "pdf_path": "data/pdfs/yaron2025dissociated.pdf",
      "added_date": "2025-12-12T11:49:31.284789",
      "abstract": "Dissociated neuronal cultures provide a simplified yet effective model system for investigating self-organized prediction and information processing in neural networks. This review consolidates current research demonstrating that these in vitro networks display fundamental computational capabilities, including predictive coding, adaptive learning, goal-directed behavior, and deviance detection. We examine how these cultures develop critical dynamics optimized for information processing, detail the mechanisms underlying learning and memory formation, and explore the relevance of the free energy principle within these systems. Building on these insights, we discuss how findings from dissociated neuronal cultures inform the design of neuromorphic and reservoir computing architectures, with the potential to enhance energy efficiency and adaptive functionality in artificial intelligence. The reduced complexity of neuronal cultures allows for precise manipulation and systematic investigation, bridging theoretical frameworks with practical implementations in bio-inspired computing. Finally, we highlight promising future directions, emphasizing advancements in three-dimensional culture techniques, multi-compartment models, and brain organoids that deepen our understanding of hierarchical and predictive processes in both biological and artificial systems. This review aims to provide a comprehensive overview of how dissociated neuronal cultures contribute to neuroscience and artificial intelligence, ultimately paving the way for biologically inspired computing solutions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2501.18772.pdf"
      }
    },
    "kim2025emergence": {
      "citation_key": "kim2025emergence",
      "title": "Emergence of Goal-Directed Behaviors via Active Inference with Self-Prior",
      "authors": [
        "Dongmin Kim",
        "Hoshinori Kanazawa",
        "Naoto Yoshida",
        "Yasuo Kuniyoshi"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2504.11075v2",
      "pdf_path": "data/pdfs/kim2025emergence.pdf",
      "added_date": "2025-12-12T11:49:31.287067",
      "abstract": "Infants often exhibit goal-directed behaviors, such as reaching for a sensory stimulus, even when no external reward criterion is provided. These intrinsically motivated behaviors facilitate spontaneous exploration and learning of the body and environment during early developmental stages. Although computational modeling can offer insight into the mechanisms underlying such behaviors, many existing studies on intrinsic motivation focus primarily on how exploration contributes to acquiring external rewards. In this paper, we propose a novel density model for an agent's own multimodal sensory experiences, called the \"self-prior,\" and investigate whether it can autonomously induce goal-directed behavior. Integrated within an active inference framework based on the free energy principle, the self-prior generates behavioral references purely from an intrinsic process that minimizes mismatches between average past sensory experiences and current observations. This mechanism is also analogous to the acquisition and utilization of a body schema through continuous interaction with the environment. We examine this approach in a simulated environment and confirm that the agent spontaneously reaches toward a tactile stimulus. Our study implements intrinsically motivated behavior shaped by the agent's own sensory experiences, demonstrating the spontaneous emergence of intentional behavior during early development.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2504.11075.pdf"
      }
    },
    "yang2025quantifying": {
      "citation_key": "yang2025quantifying",
      "title": "Quantifying system-environment synergistic information by effective information decomposition",
      "authors": [
        "Mingzhe Yang",
        "Linli Pan",
        "Jiang Zhang"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2501.16676v1",
      "pdf_path": "data/pdfs/yang2025quantifying.pdf",
      "added_date": "2025-12-12T11:49:31.288998",
      "abstract": "What is the most crucial characteristic of a system with life activity? Currently, many theories have attempted to explain the most essential difference between living systems and general systems, such as the self-organization theory and the free energy principle, but there is a lack of a reasonable indicator that can measure to what extent a system can be regarded as a system with life characteristics, especially the lack of attention to the dynamic characteristics of life systems. In this article, we propose a new indicator at the level of dynamic mechanisms to measure the ability of a system to flexibly respond to the environment. We proved that this indicator satisfies the axiom system of multivariate information decomposition in the partial information decomposition (PID) framework. Through further disassembly and analysis of this indicator, we found that it is determined by the degree of entanglement between system and environmental variables in the dynamics and the magnitude of noise. We conducted measurements on cellular automata (CA), random Boolean networks, and real gene regulatory networks (GRN), verified its relationship with the type of CA and the Langton parameter, and identified that the feedback loops have high abilities to flexibly respond to the environment on the GRN. We also combined machine learning technology to prove that this framework can be applied in the case of unknown dynamics.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2501.16676.pdf"
      }
    },
    "li2025balancing": {
      "citation_key": "li2025balancing",
      "title": "Balancing Exploration and Cybersickness: Investigating Curiosity-Driven Behavior in Virtual Environments",
      "authors": [
        "Tangyao Li",
        "Yuyang Wang"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2501.04905v3",
      "pdf_path": "data/pdfs/li2025balancing.pdf",
      "added_date": "2025-12-12T11:49:31.291035",
      "abstract": "During virtual navigation, users exhibit varied interaction and navigation behaviors influenced by several factors. Existing theories and models have been developed to explain and predict these diverse patterns. While users often experience uncomfortable sensations, such as cybersickness, during virtual reality (VR) use, they do not always make optimal decisions to mitigate these effects. Although methods like reinforcement learning have been used to model decision-making processes, they typically rely on random selection to simulate actions, failing to capture the complexities of real navigation behavior. In this study, we propose curiosity as a key factor driving irrational decision-making, suggesting that users continuously balance exploration and cybersickness according to the free energy principle during virtual navigation. Our findings show that VR users generally adopt conservative strategies when navigating, with most participants displaying negative curiosity across trials. However, curiosity levels tend to rise when the virtual environment changes, illustrating the dynamic interplay between exploration and discomfort. This study provides a quantitative approach to decoding curiosity-driven behavior during virtual navigation, offering insights into how users balance exploration and the avoidance of cybersickness. Future research will further refine this model by incorporating additional psychological and environmental factors to improve the accuracy of navigation pattern predictions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2501.04905.pdf"
      }
    },
    "glybovets2025morphonas": {
      "citation_key": "glybovets2025morphonas",
      "title": "MorphoNAS: Embryogenic Neural Architecture Search Through Morphogen-Guided Development",
      "authors": [
        "Mykola Glybovets",
        "Sergii Medvid"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2507.13785v1",
      "pdf_path": "data/pdfs/glybovets2025morphonas.pdf",
      "added_date": "2025-12-12T11:49:31.293611",
      "abstract": "While biological neural networks develop from compact genomes using relatively simple rules, modern artificial neural architecture search methods mostly involve explicit and routine manual work. In this paper, we introduce MorphoNAS (Morphogenetic Neural Architecture Search), a system able to deterministically grow neural networks through morphogenetic self-organization inspired by the Free Energy Principle, reaction-diffusion systems, and gene regulatory networks. In MorphoNAS, simple genomes encode just morphogens dynamics and threshold-based rules of cellular development. Nevertheless, this leads to self-organization of a single progenitor cell into complex neural networks, while the entire process is built on local chemical interactions. Our evolutionary experiments focused on two different domains: structural targeting, in which MorphoNAS system was able to find fully successful genomes able to generate predefined random graph configurations (8-31 nodes); and functional performance on the CartPole control task achieving low complexity 6-7 neuron solutions when target network size minimization evolutionary pressure was applied. The evolutionary process successfully balanced between quality of of the final solutions and neural architecture search effectiveness. Overall, our findings suggest that the proposed MorphoNAS method is able to grow complex specific neural architectures, using simple developmental rules, which suggests a feasible biological route to adaptive and efficient neural architecture search.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2507.13785.pdf"
      }
    },
    "ghasimi2025new": {
      "citation_key": "ghasimi2025new",
      "title": "A New Approach for Knowledge Generation Using Active Inference",
      "authors": [
        "Jamshid Ghasimi",
        "Nazanin Movarraei"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2501.15105v1",
      "pdf_path": "data/pdfs/ghasimi2025new.pdf",
      "added_date": "2025-12-12T11:49:31.295643",
      "abstract": "There are various models proposed on how knowledge is generated in the human brain including the semantic networks model. Although this model has been widely studied and even computational models are presented, but, due to various limits and inefficiencies in the generation of different types of knowledge, its application is limited to semantic knowledge because of has been formed according to semantic memory and declarative knowledge and has many limits in explaining various procedural and conditional knowledge. Given the importance of providing an appropriate model for knowledge generation, especially in the areas of improving human cognitive functions or building intelligent machines, improving existing models in knowledge generation or providing more comprehensive models is of great importance. In the current study, based on the free energy principle of the brain, is the researchers proposed a model for generating three types of declarative, procedural, and conditional knowledge. While explaining different types of knowledge, this model is capable to compute and generate concepts from stimuli based on probabilistic mathematics and the action-perception process (active inference). The proposed model is unsupervised learning that can update itself using a combination of different stimuli as a generative model can generate new concepts of unsupervised received stimuli. In this model, the active inference process is used in the generation of procedural and conditional knowledge and the perception process is used to generate declarative knowledge.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2501.15105.pdf"
      }
    },
    "dang2025free": {
      "citation_key": "dang2025free",
      "title": "Free Energy-Inspired Cognitive Risk Integration for AV Navigation in Pedestrian-Rich Environments",
      "authors": [
        "Meiting Dang",
        "Yanping Wu",
        "Yafei Wang",
        "Dezong Zhao",
        "David Flynn",
        "Chongfeng Wei"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2507.20850v1",
      "pdf_path": "data/pdfs/dang2025free.pdf",
      "added_date": "2025-12-12T11:49:31.297828",
      "abstract": "Recent advances in autonomous vehicle (AV) behavior planning have shown impressive social interaction capabilities when interacting with other road users. However, achieving human-like prediction and decision-making in interactions with vulnerable road users remains a key challenge in complex multi-agent interactive environments. Existing research focuses primarily on crowd navigation for small mobile robots, which cannot be directly applied to AVs due to inherent differences in their decision-making strategies and dynamic boundaries. Moreover, pedestrians in these multi-agent simulations follow fixed behavior patterns that cannot dynamically respond to AV actions. To overcome these limitations, this paper proposes a novel framework for modeling interactions between the AV and multiple pedestrians. In this framework, a cognitive process modeling approach inspired by the Free Energy Principle is integrated into both the AV and pedestrian models to simulate more realistic interaction dynamics. Specifically, the proposed pedestrian Cognitive-Risk Social Force Model adjusts goal-directed and repulsive forces using a fused measure of cognitive uncertainty and physical risk to produce human-like trajectories. Meanwhile, the AV leverages this fused risk to construct a dynamic, risk-aware adjacency matrix for a Graph Convolutional Network within a Soft Actor-Critic architecture, allowing it to make more reasonable and informed decisions. Simulation results indicate that our proposed framework effectively improves safety, efficiency, and smoothness of AV navigation compared to the state-of-the-art method.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2507.20850.pdf"
      }
    },
    "casnici2025bioinspired": {
      "citation_key": "casnici2025bioinspired",
      "title": "Bio-Inspired Artificial Neural Networks based on Predictive Coding",
      "authors": [
        "Davide Casnici",
        "Charlotte Frenkel",
        "Justin Dauwels"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.08762v1",
      "pdf_path": "data/pdfs/casnici2025bioinspired.pdf",
      "added_date": "2025-12-12T11:49:31.299943",
      "abstract": "Backpropagation (BP) of errors is the backbone training algorithm for artificial neural networks (ANNs). It updates network weights through gradient descent to minimize a loss function representing the mismatch between predictions and desired outputs. BP uses the chain rule to propagate the loss gradient backward through the network hierarchy, allowing efficient weight updates. However, this process requires weight updates at every layer to rely on a global error signal generated at the network's output.   In contrast, the Hebbian model of synaptic plasticity states that weight updates are local, depending only on the activity of pre- and post-synaptic neurons. This suggests biological brains likely do not implement BP directly. Recently, Predictive Coding (PC) has gained interest as a biologically plausible alternative that updates weights using only local information. Originating from 1950s work on signal compression, PC was later proposed as a model of the visual cortex and formalized under the free energy principle, linking it to Bayesian inference and dynamical systems. PC weight updates rely solely on local information and provide theoretical advantages such as automatic scaling of gradients based on uncertainty.   This lecture notes column offers a novel, tutorial-style introduction to PC, focusing on its formulation, derivation, and connections to well-known optimization and signal processing algorithms such as BP and the Kalman Filter (KF). It aims to support existing literature by guiding readers from the mathematical foundations of PC to practical implementation, including Python examples using PyTorch.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.08762.pdf"
      }
    },
    "ororbia2025metarepresentational": {
      "citation_key": "ororbia2025metarepresentational",
      "title": "Meta-Representational Predictive Coding: Biomimetic Self-Supervised Learning",
      "authors": [
        "Alexander Ororbia",
        "Karl Friston",
        "Rajesh P. N. Rao"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.21796v1",
      "pdf_path": "data/pdfs/ororbia2025metarepresentational.pdf",
      "added_date": "2025-12-12T11:49:31.302829",
      "abstract": "Self-supervised learning has become an increasingly important paradigm in the domain of machine intelligence. Furthermore, evidence for self-supervised adaptation, such as contrastive formulations, has emerged in recent computational neuroscience and brain-inspired research. Nevertheless, current work on self-supervised learning relies on biologically implausible credit assignment -- in the form of backpropagation of errors -- and feedforward inference, typically a forward-locked pass. Predictive coding, in its mechanistic form, offers a biologically plausible means to sidestep these backprop-specific limitations. However, unsupervised predictive coding rests on learning a generative model of raw pixel input (akin to ``generative AI'' approaches), which entails predicting a potentially high dimensional input; on the other hand, supervised predictive coding, which learns a mapping between inputs to target labels, requires human annotation, and thus incurs the drawbacks of supervised learning. In this work, we present a scheme for self-supervised learning within a neurobiologically plausible framework that appeals to the free energy principle, constructing a new form of predictive coding that we call meta-representational predictive coding (MPC). MPC sidesteps the need for learning a generative model of sensory input (e.g., pixel-level features) by learning to predict representations of sensory input across parallel streams, resulting in an encoder-only learning and inference scheme. This formulation rests on active inference (in the form of sensory glimpsing) to drive the learning of representations, i.e., the representational dynamics are driven by sequences of decisions made by the model to sample informative portions of its sensorium.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.21796.pdf"
      }
    },
    "beck2025dynamic": {
      "citation_key": "beck2025dynamic",
      "title": "Dynamic Markov Blanket Detection for Macroscopic Physics Discovery",
      "authors": [
        "Jeff Beck",
        "Maxwell J. D. Ramstead"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2502.21217v1",
      "pdf_path": "data/pdfs/beck2025dynamic.pdf",
      "added_date": "2025-12-12T11:49:31.305126",
      "abstract": "The free energy principle (FEP), along with the associated constructs of Markov blankets and ontological potentials, have recently been presented as the core components of a generalized modeling method capable of mathematically describing arbitrary objects that persist in random dynamical systems; that is, a mathematical theory of ``every'' ``thing''. Here, we leverage the FEP to develop a mathematical physics approach to the identification of objects, object types, and the macroscopic, object-type-specific rules that govern their behavior. We take a generative modeling approach and use variational Bayesian expectation maximization to develop a dynamic Markov blanket detection algorithm that is capable of identifying and classifying macroscopic objects, given partial observation of microscopic dynamics. This unsupervised algorithm uses Bayesian attention to explicitly label observable microscopic elements according to their current role in a given system, as either the internal or boundary elements of a given macroscopic object; and it identifies macroscopic physical laws that govern how the object interacts with its environment. Because these labels are dynamic or evolve over time, the algorithm is capable of identifying complex objects that travel through fixed media or exchange matter with their environment. This approach leads directly to a flexible class of structured, unsupervised algorithms that sensibly partition complex many-particle or many-component systems into collections of interacting macroscopic subsystems, namely, ``objects'' or ``things''. We derive a few examples of this kind of macroscopic physics discovery algorithm and demonstrate its utility with simple numerical experiments, in which the algorithm correctly labels the components of Newton's cradle, a burning fuse, the Lorenz attractor, and a simulated cell.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2502.21217.pdf"
      }
    },
    "kawakami2025finding": {
      "citation_key": "kawakami2025finding",
      "title": "Finding Similar Objects and Active Inference for Surprise in Numenta Neocortex Model",
      "authors": [
        "Hajime Kawakami"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.21554v1",
      "pdf_path": "data/pdfs/kawakami2025finding.pdf",
      "added_date": "2025-12-12T11:49:31.311403",
      "abstract": "Jeff Hawkins and his colleagues in Numenta have proposed the thousand-brains system. This is a model of the structure and operation of the neocortex and is under investigation as a new form of artificial intelligence. In their study, learning and inference algorithms running on the system are proposed, where the prediction is an important function. The author believes that one of the most important capabilities of the neocortex in addition to prediction is the ability to make association, that is, to find the relationships between objects. Similarity is an important example of such relationships. In our study, algorithms that run on the thousand-brains system to find similarities are proposed. Although the setting for these algorithms is restricted, the author believes that the case it covers is fundamental. Karl Friston and his colleagues have studied the free-energy principle that explains how the brain actively infers the cause of a Shannon surprise. In our study, an algorithm is proposed for the thousand-brains system to make this inference. The problem of inferring what is being observed from the sensory data is a type of inverse problem, and the inference algorithms of the thousand-brains system and free-energy principle solve this problem in a Bayesian manner. Our inference algorithms can also be interpreted as Bayesian or non-Bayesian updating processes.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.21554.pdf"
      }
    },
    "fiderer2025work": {
      "citation_key": "fiderer2025work",
      "title": "The Work Capacity of Channels with Memory: Maximum Extractable Work in Percept-Action Loops",
      "authors": [
        "Lukas J. Fiderer",
        "Paul C. Barth",
        "Isaac D. Smith",
        "Hans J. Briegel"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2504.06209v1",
      "pdf_path": "data/pdfs/fiderer2025work.pdf",
      "added_date": "2025-12-12T11:49:31.313670",
      "abstract": "Predicting future observations plays a central role in machine learning, biology, economics, and many other fields. It lies at the heart of organizational principles such as the variational free energy principle and has even been shown -- based on the second law of thermodynamics -- to be necessary for reaching the fundamental energetic limits of sequential information processing. While the usefulness of the predictive paradigm is undisputed, complex adaptive systems that interact with their environment are more than just predictive machines: they have the power to act upon their environment and cause change. In this work, we develop a framework to analyze the thermodynamics of information processing in percept-action loops -- a model of agent-environment interaction -- allowing us to investigate the thermodynamic implications of actions and percepts on equal footing. To this end, we introduce the concept of work capacity -- the maximum rate at which an agent can expect to extract work from its environment. Our results reveal that neither of two previously established design principles for work-efficient agents -- maximizing predictive power and forgetting past actions -- remains optimal in environments where actions have observable consequences. Instead, a trade-off emerges: work-efficient agents must balance prediction and forgetting, as remembering past actions can reduce the available free energy. This highlights a fundamental departure from the thermodynamics of passive observation, suggesting that prediction and energy efficiency may be at odds in active learning systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2504.06209.pdf"
      }
    },
    "yokozawa2025deep": {
      "citation_key": "yokozawa2025deep",
      "title": "Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation",
      "authors": [
        "Riko Yokozawa",
        "Kentaro Fujii",
        "Yuta Nomura",
        "Shingo Murata"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.23258v1",
      "pdf_path": "data/pdfs/yokozawa2025deep.pdf",
      "added_date": "2025-12-12T11:49:31.315964",
      "abstract": "Autonomous robotic navigation in real-world environments requires exploration to acquire environmental information as well as goal-directed navigation in order to reach specified targets. Active inference (AIF) based on the free-energy principle provides a unified framework for these behaviors by minimizing the expected free energy (EFE), thereby combining epistemic and extrinsic values. To realize this practically, we propose a deep AIF framework that integrates a diffusion policy as the policy model and a multiple timescale recurrent state-space model (MTRSSM) as the world model. The diffusion policy generates diverse candidate actions while the MTRSSM predicts their long-horizon consequences through latent imagination, enabling action selection that minimizes EFE. Real-world navigation experiments demonstrated that our framework achieved higher success rates and fewer collisions compared with the baselines, particularly in exploration-demanding scenarios. These results highlight how AIF based on EFE minimization can unify exploration and goal-directed navigation in real-world robotic settings.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.23258.pdf"
      }
    },
    "nan2025nemori": {
      "citation_key": "nan2025nemori",
      "title": "Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science",
      "authors": [
        "Jiayan Nan",
        "Wenquan Ma",
        "Wenlong Wu",
        "Yize Chen"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.03341v3",
      "pdf_path": "data/pdfs/nan2025nemori.pdf",
      "added_date": "2025-12-12T11:49:31.319120",
      "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities, yet their inability to maintain persistent memory in long contexts limits their effectiveness as autonomous agents in long-term interactions. While existing memory systems have made progress, their reliance on arbitrary granularity for defining the basic memory unit and passive, rule-based mechanisms for knowledge extraction limits their capacity for genuine learning and evolution. To address these foundational limitations, we present Nemori, a novel self-organizing memory architecture inspired by human cognitive principles. Nemori's core innovation is twofold: First, its Two-Step Alignment Principle, inspired by Event Segmentation Theory, provides a principled, top-down method for autonomously organizing the raw conversational stream into semantically coherent episodes, solving the critical issue of memory granularity. Second, its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables the agent to proactively learn from prediction gaps, moving beyond pre-defined heuristics to achieve adaptive knowledge evolution. This offers a viable path toward handling the long-term, dynamic workflows of autonomous agents. Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that Nemori significantly outperforms prior state-of-the-art systems, with its advantage being particularly pronounced in longer contexts.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.03341.pdf"
      }
    },
    "idei2025scalable": {
      "citation_key": "idei2025scalable",
      "title": "Scalable predictive processing framework for multitask caregiving robots",
      "authors": [
        "Hayato Idei",
        "Tamon Miyake",
        "Tetsuya Ogata",
        "Yuichi Yamashita"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.25053v1",
      "pdf_path": "data/pdfs/idei2025scalable.pdf",
      "added_date": "2025-12-12T11:49:31.321665",
      "abstract": "The rapid aging of societies is intensifying demand for autonomous care robots; however, most existing systems are task-specific and rely on handcrafted preprocessing, limiting their ability to generalize across diverse scenarios. A prevailing theory in cognitive neuroscience proposes that the human brain operates through hierarchical predictive processing, which underlies flexible cognition and behavior by integrating multimodal sensory signals. Inspired by this principle, we introduce a hierarchical multimodal recurrent neural network grounded in predictive processing under the free-energy principle, capable of directly integrating over 30,000-dimensional visuo-proprioceptive inputs without dimensionality reduction. The model was able to learn two representative caregiving tasks, rigid-body repositioning and flexible-towel wiping, without task-specific feature engineering. We demonstrate three key properties: (i) self-organization of hierarchical latent dynamics that regulate task transitions, capture variability in uncertainty, and infer occluded states; (ii) robustness to degraded vision through visuo-proprioceptive integration; and (iii) asymmetric interference in multitask learning, where the more variable wiping task had little influence on repositioning, whereas learning the repositioning task led to a modest reduction in wiping performance, while the model maintained overall robustness. Although the evaluation was limited to simulation, these results establish predictive processing as a universal and scalable computational principle, pointing toward robust, flexible, and autonomous caregiving robots while offering theoretical insight into the human brain's ability to achieve flexible adaptation in uncertain real-world environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.25053.pdf"
      }
    },
    "ruffini2025algorithmic": {
      "citation_key": "ruffini2025algorithmic",
      "title": "The Algorithmic Regulator",
      "authors": [
        "Giulio Ruffini"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.10300v3",
      "pdf_path": "data/pdfs/ruffini2025algorithmic.pdf",
      "added_date": "2025-12-12T11:49:31.323900",
      "abstract": "The regulator theorem states that, under certain conditions, any optimal controller must embody a model of the system it regulates, grounding the idea that controllers embed, explicitly or implicitly, internal models of the controlled. This principle underpins neuroscience and predictive brain theories like the Free-Energy Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only proven in limited settings. Here, we treat the deterministic, closed, coupled world-regulator system $(W,R)$ as a single self-delimiting program $p$ via a constant-size wrapper that produces the world output string~$x$ fed to the regulator. We analyze regulation from the viewpoint of the algorithmic complexity of the output, $K(x)$. We define $R$ to be a \\emph{good algorithmic regulator} if it \\emph{reduces} the algorithmic complexity of the readout relative to a null (unregulated) baseline $\\varnothing$, i.e., \\[ Δ= K\\big(O_{W,\\varnothing}\\big) - K\\big(O_{W,R}\\big) > 0. \\] We then prove that the larger $Δ$ is, the more world-regulator pairs with high mutual algorithmic information are favored. More precisely, a complexity gap $Δ> 0$ yields \\[ \\Pr\\big((W,R)\\mid x\\big) \\le C\\,2^{\\,M(W{:}R)}\\,2^{-Δ}, \\] making low $M(W{:}R)$ exponentially unlikely as $Δ$ grows. This is an AIT version of the idea that ``the regulator contains a model of the world.'' The framework is distribution-free, applies to individual sequences, and complements the Internal Model Principle. Beyond this necessity claim, the same coding-theorem calculus singles out a \\emph{canonical scalar objective} and implicates a \\emph{planner}. On the realized episode, a regulator behaves \\emph{as if} it minimized the conditional description length of the readout.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.10300.pdf"
      }
    },
    "kouw2025message": {
      "citation_key": "kouw2025message",
      "title": "Message passing-based inference in an autoregressive active inference agent",
      "authors": [
        "Wouter M. Kouw",
        "Tim N. Nisslbeck",
        "Wouter L. N. Nuijten"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2509.25482v1",
      "pdf_path": "data/pdfs/kouw2025message.pdf",
      "added_date": "2025-12-12T11:49:31.326660",
      "abstract": "We present the design of an autoregressive active inference agent in the form of message passing on a factor graph. Expected free energy is derived and distributed across a planning graph. The proposed agent is validated on a robot navigation task, demonstrating exploration and exploitation in a continuous-valued observation space with bounded continuous-valued actions. Compared to a classical optimal controller, the agent modulates action based on predictive uncertainty, arriving later but with a better model of the robot's dynamics.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2509.25482.pdf"
      }
    },
    "schubert2025active": {
      "citation_key": "schubert2025active",
      "title": "Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions",
      "authors": [
        "Johan Schubert",
        "Farzad Kamrani",
        "Tove Gustavi"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.17450v1",
      "pdf_path": "data/pdfs/schubert2025active.pdf",
      "added_date": "2025-12-12T11:49:31.329604",
      "abstract": "We develop an active inference route-planning method for the autonomous control of intelligent agents. The aim is to reconnoiter a geographical area to maintain a common operational picture. To achieve this, we construct an evidence map that reflects our current understanding of the situation, incorporating both positive and \"negative\" sensor observations of possible target objects collected over time, and diffusing the evidence across the map as time progresses. The generative model of active inference uses Dempster-Shafer theory and a Gaussian sensor model, which provides input to the agent. The generative process employs a Bayesian approach to update a posterior probability distribution. We calculate the variational free energy for all positions within the area by assessing the divergence between a pignistic probability distribution of the evidence map and a posterior probability distribution of a target object based on the observations, including the level of surprise associated with receiving new observations. Using the free energy, we direct the agents' movements in a simulation by taking an incremental step toward a position that minimizes the free energy. This approach addresses the challenge of exploration and exploitation, allowing agents to balance searching extensive areas of the geographical map while tracking identified target objects.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.17450.pdf"
      }
    },
    "hinrichs2025geometric": {
      "citation_key": "hinrichs2025geometric",
      "title": "Geometric Hyperscanning of Affect under Active Inference",
      "authors": [
        "Nicolas Hinrichs",
        "Mahault Albarracin",
        "Dimitris Bolis",
        "Yuyue Jiang",
        "Leonardo Christov-Moore",
        "Leonhard Schilbach"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.08599v4",
      "pdf_path": "data/pdfs/hinrichs2025geometric.pdf",
      "added_date": "2025-12-12T11:49:31.331811",
      "abstract": "Second-person neuroscience holds social cognition as embodied meaning co-regulation through reciprocal interaction, modeled here as coupled active inference with affect emerging as inference over identity-relevant surprise. Each agent maintains a self-model that tracks violations in its predictive coherence while recursively modeling the other. Valence is computed from self-model prediction error, weighted by self-relevance, and modulated by prior affective states and by what we term temporal aiming, which captures affective appraisal over time. This accommodates shifts in the self-other boundary, allowing affect to emerge at individual and dyadic levels. We propose a novel method termed geometric hyperscanning, based on the Forman-Ricci curvature, to empirically operationalize these processes: it tracks topological reconfigurations in inter-brain networks, with its entro-py serving as a proxy for affective phase transitions such as rupture, co-regulation, and re-attunement.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.08599.pdf"
      }
    },
    "klar2025active": {
      "citation_key": "klar2025active",
      "title": "An Active Inference Model of Mouse Point-and-Click Behaviour",
      "authors": [
        "Markus Klar",
        "Sebastian Stein",
        "Fraser Paterson",
        "John H. Williamson",
        "Roderick Murray-Smith"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.14611v1",
      "pdf_path": "data/pdfs/klar2025active.pdf",
      "added_date": "2025-12-12T11:49:31.334933",
      "abstract": "We explore the use of Active Inference (AIF) as a computational user model for spatial pointing, a key problem in Human-Computer Interaction (HCI). We present an AIF agent with continuous state, action, and observation spaces, performing one-dimensional mouse pointing and clicking. We use a simple underlying dynamic system to model the mouse cursor dynamics with realistic perceptual delay. In contrast to previous optimal feedback control-based models, the agent's actions are selected by minimizing Expected Free Energy, solely based on preference distributions over percepts, such as observing clicking a button correctly. Our results show that the agent creates plausible pointing movements and clicks when the cursor is over the target, with similar end-point variance to human users. In contrast to other models of pointing, we incorporate fully probabilistic, predictive delay compensation into the agent. The agent shows distinct behaviour for differing target difficulties without the need to retune system parameters, as done in other approaches. We discuss the simulation results and emphasize the challenges in identifying the correct configuration of an AIF agent interacting with continuous systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.14611.pdf"
      }
    },
    "perez2025cognitive": {
      "citation_key": "perez2025cognitive",
      "title": "Cognitive Effort in the Two-Step Task: An Active Inference Drift-Diffusion Model Approach",
      "authors": [
        "Alvaro Garrido Perez",
        "Viktor Lemoine",
        "Amrapali Pednekar",
        "Yara Khaluf",
        "Pieter Simoens"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.04435v2",
      "pdf_path": "data/pdfs/perez2025cognitive.pdf",
      "added_date": "2025-12-12T11:49:31.337645",
      "abstract": "High-level theories rooted in the Bayesian Brain Hypothesis often frame cognitive effort as the cost of resolving the conflict between habits and optimal policies. In parallel, evidence accumulator models (EAMs) provide a mechanistic account of how effort arises from competition between the subjective values of available options. Although EAMs have been combined with frameworks like Reinforcement Learning to bridge the gap between high-level theories and process-level mechanisms, relatively less attention has been paid to their implications for a unified notion of cognitive effort. Here, we combine Active Inference (AIF) with the Drift-Diffusion Model (DDM) to investigate whether the resulting AIF-DDM can simultaneously account for effort arising from both habit violation and value discriminability. To our knowledge, this is the first time AIF has been combined with an EAM. We tested the AIF-DDM on a behavioral dataset from the two-step task and compared its predictions to an information-theoretic definition of cognitive effort based on AIF. The model's predictions successfully accounted for second-stage reaction times but failed to capture the dynamics of the first stage. We argue the latter discrepancy likely stems from the experimental design rather than a fundamental flaw in the model's assumptions about cognitive effort. Accordingly, we propose several modifications of the two-step task to better measure and isolate cognitive effort. Finally, we found that integrating the DDM significantly improved parameter recovery, which could help future studies to obtain more reliable parameter estimates.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.04435.pdf"
      }
    },
    "pezzato2025mobile": {
      "citation_key": "pezzato2025mobile",
      "title": "Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks",
      "authors": [
        "Corrado Pezzato",
        "Ozan Çatal",
        "Toon Van de Maele",
        "Riddhi J. Pitliya",
        "Tim Verbelen"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2507.17338v1",
      "pdf_path": "data/pdfs/pezzato2025mobile.pdf",
      "added_date": "2025-12-12T11:49:31.340071",
      "abstract": "Despite growing interest in active inference for robotic control, its application to complex, long-horizon tasks remains untested. We address this gap by introducing a fully hierarchical active inference architecture for goal-directed behavior in realistic robotic settings. Our model combines a high-level active inference model that selects among discrete skills realized via a whole-body active inference controller. This unified approach enables flexible skill composition, online adaptability, and recovery from task failures without requiring offline training. Evaluated on the Habitat Benchmark for mobile manipulation, our method outperforms state-of-the-art baselines across the three long-horizon tasks, demonstrating for the first time that active inference can scale to the complexity of modern robotics benchmarks.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2507.17338.pdf"
      }
    },
    "torzoni2025active": {
      "citation_key": "torzoni2025active",
      "title": "Active Digital Twins via Active Inference",
      "authors": [
        "Matteo Torzoni",
        "Domenico Maisto",
        "Andrea Manzoni",
        "Francesco Donnarumma",
        "Giovanni Pezzulo",
        "Alberto Corigliano"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.14453v1",
      "pdf_path": "data/pdfs/torzoni2025active.pdf",
      "added_date": "2025-12-12T11:49:31.342760",
      "abstract": "Digital twins are transforming engineering and applied sciences by enabling real-time monitoring, simulation, and predictive analysis of physical systems and processes. However, conventional digital twins rely primarily on passive data assimilation, which limits their adaptability in uncertain and dynamic environments. This paper introduces the active digital twin paradigm, based on active inference. Active inference is a neuroscience-inspired, Bayesian framework for probabilistic reasoning and predictive modeling that unifies inference, decision-making, and learning under a unique, free energy minimization objective. By formulating the evolution of the active digital twin as a partially observable Markov decision process, the active inference agent continuously refines its generative model through Bayesian updates and forecasts future states and observations. Decision-making emerges from an optimization process that balances pragmatic exploitation (maximizing goal-directed utility) and epistemic exploration or information gain (actively resolving uncertainty). Actions are dynamically planned to minimize expected free energy, which quantifies both the divergence between predicted and preferred future observations, and the epistemic value of expected information gain about hidden states. This approach enables a new level of autonomy and resilience in digital twins, offering superior spontaneous exploration capabilities. The proposed framework is assessed on the health monitoring and predictive maintenance of a railway bridge.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.14453.pdf"
      }
    },
    "nuijten2025active": {
      "citation_key": "nuijten2025active",
      "title": "Active Inference is a Subtype of Variational Inference",
      "authors": [
        "Wouter W. L. Nuijten",
        "Mykola Lukashchuk"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2511.18955v1",
      "pdf_path": "data/pdfs/nuijten2025active.pdf",
      "added_date": "2025-12-12T11:49:31.345414",
      "abstract": "Automated decision-making under uncertainty requires balancing exploitation and exploration. Classical methods treat these separately using heuristics, while Active Inference unifies them through Expected Free Energy (EFE) minimization. However, EFE minimization is computationally expensive, limiting scalability. We build on recent theory recasting EFE minimization as variational inference, formally unifying it with Planning-as-Inference and showing the epistemic drive as a unique entropic contribution. Our main contribution is a novel message-passing scheme for this unified objective, enabling scalable Active Inference in factored-state MDPs and overcoming high-dimensional planning intractability.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2511.18955.pdf"
      }
    },
    "kuhn2025addressing": {
      "citation_key": "kuhn2025addressing",
      "title": "Addressing the Subsumption Thesis: A Formal Bridge between Microeconomics and Active Inference",
      "authors": [
        "Noe Kuhn"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.05048v1",
      "pdf_path": "data/pdfs/kuhn2025addressing.pdf",
      "added_date": "2025-12-12T11:49:31.348097",
      "abstract": "As a unified theory of sentient behaviour, active inference is formally intertwined with multiple normative theories of optimal behaviour. Specifically, we address what we call the subsumption thesis: The claim that expected utility from economics, as an account of agency, is subsumed by active inference. To investigate this claim, we present multiple examples that challenge the subsumption thesis. To formally compare these two accounts of agency, we analyze the objective functions for MDPs and POMDPs. By imposing information-theoretic rationality bounds (ITBR) on the expected utility agent, we find that the resultant agency is equivalent to that of active inference in MDPs, but slightly different in POMDPs. Rather than being strictly resolved, the subsumption thesis motivates the construction of a formal bridge between active inference and expected utility. This highlights the necessary formal assumptions and frameworks to make these disparate accounts of agency commensurable.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.05048.pdf"
      }
    },
    "delavari2025perceptual": {
      "citation_key": "delavari2025perceptual",
      "title": "Perceptual Motor Learning with Active Inference Framework for Robust Lateral Control",
      "authors": [
        "Elahe Delavari",
        "John Moore",
        "Junho Hong",
        "Jaerock Kwon"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.01676v2",
      "pdf_path": "data/pdfs/delavari2025perceptual.pdf",
      "added_date": "2025-12-12T11:49:31.350645",
      "abstract": "This paper presents a novel Perceptual Motor Learning (PML) framework integrated with Active Inference (AIF) to enhance lateral control in Highly Automated Vehicles (HAVs). PML, inspired by human motor learning, emphasizes the seamless integration of perception and action, enabling efficient decision-making in dynamic environments. Traditional autonomous driving approaches--including modular pipelines, imitation learning, and reinforcement learning--struggle with adaptability, generalization, and computational efficiency. In contrast, PML with AIF leverages a generative model to minimize prediction error (\"surprise\") and actively shape vehicle control based on learned perceptual-motor representations. Our approach unifies deep learning with active inference principles, allowing HAVs to perform lane-keeping maneuvers with minimal data and without extensive retraining across different environments. Extensive experiments in the CARLA simulator demonstrate that PML with AIF enhances adaptability without increasing computational overhead while achieving performance comparable to conventional methods. These findings highlight the potential of PML-driven active inference as a robust alternative for real-world autonomous driving applications.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.01676.pdf"
      }
    },
    "schumann2025active": {
      "citation_key": "schumann2025active",
      "title": "Active inference as a unified model of collision avoidance behavior in human drivers",
      "authors": [
        "Julian F. Schumann",
        "Johan Engström",
        "Leif Johnson",
        "Matthew O'Kelly",
        "Joao Messias",
        "Jens Kober",
        "Arkady Zgonnikov"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.02215v4",
      "pdf_path": "data/pdfs/schumann2025active.pdf",
      "added_date": "2025-12-12T11:49:31.353547",
      "abstract": "Collision avoidance -- involving a rapid threat detection and quick execution of the appropriate evasive maneuver -- is a critical aspect of driving. However, existing models of human collision avoidance behavior are fragmented, focusing on specific scenarios or only describing certain aspects of the avoidance behavior, such as response times. This paper addresses these gaps by proposing a novel computational cognitive model of human collision avoidance behavior based on active inference. Active inference provides a unified approach to modeling human behavior: the minimization of free energy. Building on prior active inference work, our model incorporates established cognitive mechanisms such as evidence accumulation to simulate human responses in two distinct collision avoidance scenarios: front-to-rear lead vehicle braking and lateral incursion by an oncoming vehicle. We demonstrate that our model explains a wide range of previous empirical findings on human collision avoidance behavior. Specifically, the model closely reproduces both aggregate results from meta-analyses previously reported in the literature and detailed, scenario-specific effects observed in a recent driving simulator study, including response timing, maneuver selection, and execution. Our results highlight the potential of active inference as a unified framework for understanding and modeling human behavior in complex real-life driving tasks.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.02215.pdf"
      }
    },
    "maier2025from": {
      "citation_key": "maier2025from",
      "title": "From Artificial Intelligence to Active Inference: The Key to True AI and 6G World Brain [Invited]",
      "authors": [
        "Martin Maier"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2505.10569v1",
      "pdf_path": "data/pdfs/maier2025from.pdf",
      "added_date": "2025-12-12T11:49:31.355974",
      "abstract": "In his opening OFC plenary talk back in 2021, Alibaba Group's Yiqun Cai notably added in the follow-up Q&A that today's complex networks are more than computer science - they grow, they are life. This entails that future networks may be better viewed as techno-social systems that resemble biological superorganisms with brain-like cognitive capabilities. Fast-forwarding, there is now growing awareness that we have to completely change our networks from being static into being a living entity that would act as an AI-powered network `brain', as recently stated by Bruno Zerbib, Chief Technology and Innovation Officer of France's Orange, at the Mobile World Congress (MWC) 2025. Even though AI was front and center at both MWC and OFC 2025 and has been widely studied in the context of optical networks, there are currently no publications on active inference in optical (and less so mobile) networks available. Active inference is an ideal methodology for developing more advanced AI systems by biomimicking the way living intelligent systems work, while overcoming the limitations of today's AI related to training, learning, and explainability. Active inference is considered the key to true AI: Less artificial, more intelligent. The goal of this paper is twofold. First, we aim at enabling optical network researchers to conceptualize new research lines for future optical networks with human-AI interaction capabilities by introducing them to the main mathematical concepts of the active inference framework. Second, we demonstrate how to move AI research beyond the human brain toward the 6G world brain by exploring the role of mycorrhizal networks, the largest living organism on planet Earth, in the AI vision and R&D roadmap for the next decade and beyond laid out by Karl Friston, the father of active inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2505.10569.pdf"
      }
    },
    "wen2025framework": {
      "citation_key": "wen2025framework",
      "title": "A Framework for Inherently Safer AGI through Language-Mediated Active Inference",
      "authors": [
        "Bo Wen"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.05766v1",
      "pdf_path": "data/pdfs/wen2025framework.pdf",
      "added_date": "2025-12-12T11:49:31.358328",
      "abstract": "This paper proposes a novel framework for developing safe Artificial General Intelligence (AGI) by combining Active Inference principles with Large Language Models (LLMs). We argue that traditional approaches to AI safety, focused on post-hoc interpretability and reward engineering, have fundamental limitations. We present an architecture where safety guarantees are integrated into the system's core design through transparent belief representations and hierarchical value alignment. Our framework leverages natural language as a medium for representing and manipulating beliefs, enabling direct human oversight while maintaining computational tractability. The architecture implements a multi-agent system where agents self-organize according to Active Inference principles, with preferences and safety constraints flowing through hierarchical Markov blankets. We outline specific mechanisms for ensuring safety, including: (1) explicit separation of beliefs and preferences in natural language, (2) bounded rationality through resource-aware free energy minimization, and (3) compositional safety through modular agent structures. The paper concludes with a research agenda centered on the Abstraction and Reasoning Corpus (ARC) benchmark, proposing experiments to validate our framework's safety properties. Our approach offers a path toward AGI development that is inherently safer, rather than retrofitted with safety measures.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.05766.pdf"
      }
    },
    "torresan2025prior": {
      "citation_key": "torresan2025prior",
      "title": "Prior preferences in active inference agents: soft, hard, and goal shaping",
      "authors": [
        "Filippo Torresan",
        "Ryota Kanai",
        "Manuel Baltieri"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2512.03293v1",
      "pdf_path": "data/pdfs/torresan2025prior.pdf",
      "added_date": "2025-12-12T11:49:31.361347",
      "abstract": "Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2512.03293.pdf"
      }
    },
    "wei2025active": {
      "citation_key": "wei2025active",
      "title": "Active Inference through Incentive Design in Markov Decision Processes",
      "authors": [
        "Xinyi Wei",
        "Chongyang Shi",
        "Shuo Han",
        "Ahmed H. Hemida",
        "Charles A. Kamhoua",
        "Jie Fu"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2502.07065v1",
      "pdf_path": "data/pdfs/wei2025active.pdf",
      "added_date": "2025-12-12T11:49:31.363814",
      "abstract": "We present a method for active inference with partial observations in stochastic systems through incentive design, also known as the leader-follower game. Consider a leader agent who aims to infer a follower agent's type given a finite set of possible types. Different types of followers differ in either the dynamical model, the reward function, or both. We assume the leader can partially observe a follower's behavior in the stochastic system modeled as a Markov decision process, in which the follower takes an optimal policy to maximize a total reward. To improve inference accuracy and efficiency, the leader can offer side payments (incentives) to the followers such that different types of them, under the incentive design, can exhibit diverging behaviors that facilitate the leader's inference task. We show the problem of active inference through incentive design can be formulated as a special class of leader-follower games, where the leader's objective is to balance the information gain and cost of incentive design. The information gain is measured by the entropy of the estimated follower's type given partial observations. Furthermore, we demonstrate that this problem can be solved by reducing a single-level optimization through softmax temporal consistency between followers' policies and value functions. This reduction allows us to develop an efficient gradient-based algorithm. We utilize observable operators in the hidden Markov model (HMM) to compute the necessary gradients and demonstrate the effectiveness of our approach through experiments in stochastic grid world environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2502.07065.pdf"
      }
    },
    "pižurica2025hardwareoriented": {
      "citation_key": "pižurica2025hardwareoriented",
      "title": "A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment",
      "authors": [
        "Nikola Pižurica",
        "Nikola Milović",
        "Igor Jovančević",
        "Conor Heins",
        "Miguel de Prado"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.13177v1",
      "pdf_path": "data/pdfs/pižurica2025hardwareoriented.pdf",
      "added_date": "2025-12-12T11:49:31.366992",
      "abstract": "Active Inference (AIF) offers a robust framework for decision-making, yet its computational and memory demands pose challenges for deployment, especially in resource-constrained environments. This work presents a methodology that facilitates AIF's deployment by integrating pymdp's flexibility and efficiency with a unified, sparse, computational graph tailored for hardware-efficient execution. Our approach reduces latency by over 2x and memory by up to 35%, advancing the deployment of efficient AIF agents for real-time and embedded applications.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.13177.pdf"
      }
    },
    "maisto2025what": {
      "citation_key": "maisto2025what",
      "title": "What the flock knows that the birds do not: exploring the emergence of joint agency in multi-agent active inference",
      "authors": [
        "Domenico Maisto",
        "Davide Nuzzi",
        "Giovanni Pezzulo"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2511.10835v1",
      "pdf_path": "data/pdfs/maisto2025what.pdf",
      "added_date": "2025-12-12T11:49:31.370020",
      "abstract": "Collective behavior pervades biological systems, from flocks of birds to neural assemblies and human societies. Yet, how such collectives acquire functional properties -- such as joint agency or knowledge -- that transcend those of their individual components remains an open question. Here, we combine active inference and information-theoretic analyses to explore how a minimal system of interacting agents can give rise to joint agency and collective knowledge. We model flocking dynamics using multiple active inference agents, each minimizing its own free energy while coupling reciprocally with its neighbors. We show that as agents self-organize, their interactions define higher-order statistical boundaries (Markov blankets) enclosing a ``flock'' that can be treated as an emergent agent with its own sensory, active, and internal states. When exposed to external perturbations (a ``predator''), the flock exhibits faster, coordinated responses than individual agents, reflecting collective sensitivity to environmental change. Crucially, analyses of synergistic information reveal that the flock encodes information about the predator's location that is not accessible to every individual bird, demonstrating implicit collective knowledge. Together, these results show how informational coupling among active inference agents can generate new levels of autonomy and inference, providing a framework for understanding the emergence of (implicit) collective knowledge and joint agency.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2511.10835.pdf"
      }
    },
    "annicchiarico2025active": {
      "citation_key": "annicchiarico2025active",
      "title": "An Active Inference perspective on Neurofeedback Training",
      "authors": [
        "Côme Annicchiarico",
        "Fabien Lotte",
        "Jérémie Mattout"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2505.03308v1",
      "pdf_path": "data/pdfs/annicchiarico2025active.pdf",
      "added_date": "2025-12-12T11:49:31.373107",
      "abstract": "Neurofeedback training (NFT) aims to teach self-regulation of brain activity through real-time feedback, but suffers from highly variable outcomes and poorly understood mechanisms, hampering its validation. To address these issues, we propose a formal computational model of the NFT closed loop. Using Active Inference, a Bayesian framework modelling perception, action, and learning, we simulate agents interacting with an NFT environment. This enables us to test the impact of design choices (e.g., feedback quality, biomarker validity) and subject factors (e.g., prior beliefs) on training. Simulations show that training effectiveness is sensitive to feedback noise or bias, and to prior beliefs (highlighting the importance of guiding instructions), but also reveal that perfect feedback is insufficient to guarantee high performance. This approach provides a tool for assessing and predicting NFT variability, interpret empirical data, and potentially develop personalized training protocols.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2505.03308.pdf"
      }
    },
    "pitliya2025theory": {
      "citation_key": "pitliya2025theory",
      "title": "Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation",
      "authors": [
        "Riddhi J. Pitliya",
        "Ozan Çatal",
        "Toon Van de Maele",
        "Corrado Pezzato",
        "Tim Verbelen"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.00401v2",
      "pdf_path": "data/pdfs/pitliya2025theory.pdf",
      "added_date": "2025-12-12T11:49:31.375787",
      "abstract": "Theory of Mind (ToM) -- the ability to understand that others can have differing knowledge and goals -- enables agents to reason about others' beliefs while planning their own actions. We present a novel approach to multi-agent cooperation by implementing ToM within active inference. Unlike previous active inference approaches to multi-agent cooperation, our method neither relies on task-specific shared generative models nor requires explicit communication. In our framework, ToM-equipped agents maintain distinct representations of their own and others' beliefs and goals. ToM agents then use an extended and adapted version of the sophisticated inference tree-based planning algorithm to systematically explore joint policy spaces through recursive reasoning. We evaluate our approach through collision avoidance and foraging simulations. Results suggest that ToM agents cooperate better compared to non-ToM counterparts by being able to avoid collisions and reduce redundant efforts. Crucially, ToM agents accomplish this by inferring others' beliefs solely from observable behaviour and considering them when planning their own actions. Our approach shows potential for generalisable and scalable multi-agent systems while providing computational insights into ToM mechanisms.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.00401.pdf"
      }
    },
    "beckenbauer2025orchestrator": {
      "citation_key": "beckenbauer2025orchestrator",
      "title": "Orchestrator: Active Inference for Multi-Agent Systems in Long-Horizon Tasks",
      "authors": [
        "Lukas Beckenbauer",
        "Johannes-Lucas Loewe",
        "Ge Zheng",
        "Alexandra Brintrup"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2509.05651v1",
      "pdf_path": "data/pdfs/beckenbauer2025orchestrator.pdf",
      "added_date": "2025-12-12T11:49:31.378953",
      "abstract": "Complex, non-linear tasks challenge LLM-enhanced multi-agent systems (MAS) due to partial observability and suboptimal coordination. We propose Orchestrator, a novel MAS framework that leverages attention-inspired self-emergent coordination and reflective benchmarking to optimize global task performance. Orchestrator introduces a monitoring mechanism to track agent-environment dynamics, using active inference benchmarks to optimize system behavior. By tracking agent-to-agent and agent-to-environment interaction, Orchestrator mitigates the effects of partial observability and enables agents to approximate global task solutions more efficiently. We evaluate the framework on a series of maze puzzles of increasing complexity, demonstrating its effectiveness in enhancing coordination and performance in dynamic, non-linear environments with long-horizon objectives.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2509.05651.pdf"
      }
    },
    "tinguy2025zeroshot": {
      "citation_key": "tinguy2025zeroshot",
      "title": "Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference",
      "authors": [
        "Daria de tinguy",
        "Tim Verbelen",
        "Emilio Gamba",
        "Bart Dhoedt"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.09574v1",
      "pdf_path": "data/pdfs/tinguy2025zeroshot.pdf",
      "added_date": "2025-12-12T11:49:31.382048",
      "abstract": "Autonomous navigation in unfamiliar environments requires robots to simultaneously explore, localise, and plan under uncertainty, without relying on predefined maps or extensive training. We present a biologically inspired, Active Inference-based framework, Active Inference MAPping and Planning (AIMAPP). This model unifies mapping, localisation, and decision-making within a single generative model. Inspired by hippocampal navigation, it uses topological reasoning, place-cell encoding, and episodic memory to guide behaviour. The agent builds and updates a sparse topological map online, learns state transitions dynamically, and plans actions by minimising Expected Free Energy. This allows it to balance goal-directed and exploratory behaviours. We implemented a ROS-compatible navigation system that is sensor and robot-agnostic, capable of integrating with diverse hardware configurations. It operates in a fully self-supervised manner, is resilient to drift, and supports both exploration and goal-directed navigation without any pre-training. We demonstrate robust performance in large-scale real and simulated environments against state-of-the-art planning models, highlighting the system's adaptability to ambiguous observations, environmental changes, and sensor noise. The model offers a biologically inspired, modular solution to scalable, self-supervised navigation in unstructured settings. AIMAPP is available at https://github.com/decide-ugent/AIMAPP.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.09574.pdf"
      }
    },
    "tinguy2025navigation": {
      "citation_key": "tinguy2025navigation",
      "title": "Navigation and Exploration with Active Inference: from Biology to Industry",
      "authors": [
        "Daria de Tinguy",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.07269v2",
      "pdf_path": "data/pdfs/tinguy2025navigation.pdf",
      "added_date": "2025-12-12T11:49:31.385525",
      "abstract": "By building and updating internal cognitive maps, animals exhibit extraordinary navigation abilities in complex, dynamic environments. Inspired by these biological mechanisms, we present a real time robotic navigation system grounded in the Active Inference Framework (AIF). Our model incrementally constructs a topological map, infers the agent's location, and plans actions by minimising expected uncertainty and fulfilling perceptual goals without any prior training. Integrated into the ROS2 ecosystem, we validate its adaptability and efficiency across both 2D and 3D environments (simulated and real world), demonstrating competitive performance with traditional and state of the art exploration approaches while offering a biologically inspired navigation approach.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.07269.pdf"
      }
    },
    "krayani2025bayesian": {
      "citation_key": "krayani2025bayesian",
      "title": "Bayesian Active Inference for Intelligent UAV Anti-Jamming and Adaptive Trajectory Planning",
      "authors": [
        "Ali Krayani",
        "Seyedeh Fatemeh Sadati",
        "Lucio Marcenaro",
        "Carlo Regazzoni"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2512.05711v1",
      "pdf_path": "data/pdfs/krayani2025bayesian.pdf",
      "added_date": "2025-12-12T11:49:31.388179",
      "abstract": "This paper proposes a hierarchical trajectory planning framework for UAVs operating under adversarial jamming conditions. Leveraging Bayesian Active Inference, the approach combines expert-generated demonstrations with probabilistic generative modeling to encode high-level symbolic planning, low-level motion policies, and wireless signal feedback. During deployment, the UAV performs online inference to anticipate interference, localize jammers, and adapt its trajectory accordingly, without prior knowledge of jammer locations. Simulation results demonstrate that the proposed method achieves near-expert performance, significantly reducing communication interference and mission cost compared to model-free reinforcement learning baselines, while maintaining robust generalization in dynamic environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2512.05711.pdf"
      }
    },
    "pan2025active": {
      "citation_key": "pan2025active",
      "title": "Active Inference Framework for Closed-Loop Sensing, Communication, and Control in UAV Systems",
      "authors": [
        "Guangjin Pan",
        "Liping Bai",
        "Zhuojun Tian",
        "Hui Chen",
        "Mehdi Bennis",
        "Henk Wymeersch"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2509.14201v1",
      "pdf_path": "data/pdfs/pan2025active.pdf",
      "added_date": "2025-12-12T11:49:31.390930",
      "abstract": "Integrated sensing and communication (ISAC) is a core technology for 6G, and its application to closed-loop sensing, communication, and control (SCC) enables various services. Existing SCC solutions often treat sensing and control separately, leading to suboptimal performance and resource usage. In this work, we introduce the active inference framework (AIF) into SCC-enabled unmanned aerial vehicle (UAV) systems for joint state estimation, control, and sensing resource allocation. By formulating a unified generative model, the problem reduces to minimizing variational free energy for inference and expected free energy for action planning. Simulation results show that both control cost and sensing cost are reduced relative to baselines.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2509.14201.pdf"
      }
    },
    "paul2025simulating": {
      "citation_key": "paul2025simulating",
      "title": "Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model",
      "authors": [
        "Aswin Paul",
        "Moein Khajehnejad",
        "Forough Habibollahi",
        "Brett J. Kagan",
        "Adeel Razi"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.06980v1",
      "pdf_path": "data/pdfs/paul2025simulating.pdf",
      "added_date": "2025-12-12T11:49:31.394252",
      "abstract": "With recent and rapid advancements in artificial intelligence (AI), understanding the foundation of purposeful behaviour in autonomous agents is crucial for developing safe and efficient systems. While artificial neural networks have dominated the path to AI, recent studies are exploring the potential of biologically based systems, such as networks of living biological neuronal networks. Along with promises of high power and data efficiency, these systems may also inform more explainable and biologically plausible models. In this work, we propose a framework rooted in active inference, a general theory of behaviour, to model decision-making in embodied agents. Using experiment-informed generative models, we simulate decision-making processes in a simulated game-play environment, mirroring experimental setups that use biological neurons. Our results demonstrate learning in these agents, providing insights into the role of memory-based learning and predictive planning in intelligent decision-making. This work contributes to the growing field of explainable AI by offering a biologically grounded and scalable approach to understanding purposeful behaviour in agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.06980.pdf"
      }
    },
    "torresan2025active": {
      "citation_key": "torresan2025active",
      "title": "Active inference for action-unaware agents",
      "authors": [
        "Filippo Torresan",
        "Keisuke Suzuki",
        "Ryota Kanai",
        "Manuel Baltieri"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.12027v1",
      "pdf_path": "data/pdfs/torresan2025active.pdf",
      "added_date": "2025-12-12T11:49:31.397173",
      "abstract": "Active inference is a formal approach to study cognition based on the notion that adaptive agents can be seen as engaging in a process of approximate Bayesian inference, via the minimisation of variational and expected free energies. Minimising the former provides an account of perceptual processes and learning as evidence accumulation, while minimising the latter describes how agents select their actions over time. In this way, adaptive agents are able to maximise the likelihood of preferred observations or states, given a generative model of the environment. In the literature, however, different strategies have been proposed to describe how agents can plan their future actions. While they all share the notion that some kind of expected free energy offers an appropriate way to score policies, sequences of actions, in terms of their desirability, there are different ways to consider the contribution of past motor experience to the agent's future behaviour. In some approaches, agents are assumed to know their own actions, and use such knowledge to better plan for the future. In other approaches, agents are unaware of their actions, and must infer their motor behaviour from recent observations in order to plan for the future. This difference reflects a standard point of departure in two leading frameworks in motor control based on the presence, or not, of an efference copy signal representing knowledge about an agent's own actions. In this work we compare the performances of action-aware and action-unaware agents in two navigations tasks, showing how action-unaware agents can achieve performances comparable to action-aware ones while at a severe disadvantage.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.12027.pdf"
      }
    },
    "mišić2025active": {
      "citation_key": "mišić2025active",
      "title": "An Active Inference Model of Covert and Overt Visual Attention",
      "authors": [
        "Tin Mišić",
        "Karlo Koledić",
        "Fabio Bonsignorio",
        "Ivan Petrović",
        "Ivan Marković"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2505.03856v1",
      "pdf_path": "data/pdfs/mišić2025active.pdf",
      "added_date": "2025-12-12T11:49:31.400015",
      "abstract": "The ability to selectively attend to relevant stimuli while filtering out distractions is essential for agents that process complex, high-dimensional sensory input. This paper introduces a model of covert and overt visual attention through the framework of active inference, utilizing dynamic optimization of sensory precisions to minimize free-energy. The model determines visual sensory precisions based on both current environmental beliefs and sensory input, influencing attentional allocation in both covert and overt modalities. To test the effectiveness of the model, we analyze its behavior in the Posner cueing task and a simple target focus task using two-dimensional(2D) visual data. Reaction times are measured to investigate the interplay between exogenous and endogenous attention, as well as valid and invalid cueing. The results show that exogenous and valid cues generally lead to faster reaction times compared to endogenous and invalid cues. Furthermore, the model exhibits behavior similar to inhibition of return, where previously attended locations become suppressed after a specific cue-target onset asynchrony interval. Lastly, we investigate different aspects of overt attention and show that involuntary, reflexive saccades occur faster than intentional ones, but at the expense of adaptability.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2505.03856.pdf"
      }
    },
    "tinguy2025bioinspired": {
      "citation_key": "tinguy2025bioinspired",
      "title": "Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics",
      "authors": [
        "Daria de Tinguy",
        "Tim Verbelen",
        "Emilio Gamba",
        "Bart Dhoedt"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.07267v1",
      "pdf_path": "data/pdfs/tinguy2025bioinspired.pdf",
      "added_date": "2025-12-12T11:49:31.403343",
      "abstract": "Achieving fully autonomous exploration and navigation remains a critical challenge in robotics, requiring integrated solutions for localisation, mapping, decision-making and motion planning. Existing approaches either rely on strict navigation rules lacking adaptability or on pre-training, which requires large datasets. These AI methods are often computationally intensive or based on static assumptions, limiting their adaptability in dynamic or unknown environments. This paper introduces a bio-inspired agent based on the Active Inference Framework (AIF), which unifies mapping, localisation, and adaptive decision-making for autonomous navigation, including exploration and goal-reaching. Our model creates and updates a topological map of the environment in real-time, planning goal-directed trajectories to explore or reach objectives without requiring pre-training. Key contributions include a probabilistic reasoning framework for interpretable navigation, robust adaptability to dynamic changes, and a modular ROS2 architecture compatible with existing navigation systems. Our method was tested in simulated and real-world environments. The agent successfully explores large-scale simulated environments and adapts to dynamic obstacles and drift, proving to be comparable to other exploration strategies such as Gbplanner, FAEL and Frontiers. This approach offers a scalable and transparent approach for navigating complex, unstructured environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.07267.pdf"
      }
    },
    "ishida2025emergence": {
      "citation_key": "ishida2025emergence",
      "title": "Emergence of Active Inference from a Chemical Oscillator: A Constructive Approach to Pre-genetic Homeostasis",
      "authors": [
        "Takeshi Ishida"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.06323v1",
      "pdf_path": "data/pdfs/ishida2025emergence.pdf",
      "added_date": "2025-12-12T11:49:31.405924",
      "abstract": "How could primordial life, before the evolution of genetic systems, adapt to fluctuating environments and achieve homeostasis? This study proposes a minimal, chemically plausible model where homeostasis emerges from a simple chemical reaction network. It utilizes an internal Lotka-Volterra chemical oscillator as a \"search engine\" to periodically vary a protocell's pigmentation. The system then optimizes its internal state by evaluating the temporal correlation between these internal fluctuations and a single global metric,the cell's self-replication rate, through a mechanism termed \"antagonistic memory molecules.\" Numerical simulations demonstrate that the model can autonomously converge to and maintain the optimal temperature for its self-replication, even amidst significant environmental fluctuations. These findings provide a constructive proof-of-concept for how a core process of active inference can emerge from a simple physicochemical system, offering a concrete scenario for the acquisition of adaptive capabilities at the origin of life.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.06323.pdf"
      }
    },
    "wen2025missing": {
      "citation_key": "wen2025missing",
      "title": "The Missing Reward: Active Inference in the Era of Experience",
      "authors": [
        "Bo Wen"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.05619v1",
      "pdf_path": "data/pdfs/wen2025missing.pdf",
      "added_date": "2025-12-12T11:49:31.408653",
      "abstract": "This paper argues that Active Inference (AIF) provides a crucial foundation for developing autonomous AI agents capable of learning from experience without continuous human reward engineering. As AI systems begin to exhaust high-quality training data and rely on increasingly large human workforces for reward design, the current paradigm faces significant scalability challenges that could impede progress toward genuinely autonomous intelligence. The proposal for an ``Era of Experience,'' where agents learn from self-generated data, is a promising step forward. However, this vision still depends on extensive human engineering of reward functions, effectively shifting the bottleneck from data curation to reward curation. This highlights what we identify as the \\textbf{grounded-agency gap}: the inability of contemporary AI systems to autonomously formulate, adapt, and pursue objectives in response to changing circumstances. We propose that AIF can bridge this gap by replacing external reward signals with an intrinsic drive to minimize free energy, allowing agents to naturally balance exploration and exploitation through a unified Bayesian objective. By integrating Large Language Models as generative world models with AIF's principled decision-making framework, we can create agents that learn efficiently from experience while remaining aligned with human values. This synthesis offers a compelling path toward AI systems that can develop autonomously while adhering to both computational and physical constraints.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.05619.pdf"
      }
    },
    "pujol2025distributed": {
      "citation_key": "pujol2025distributed",
      "title": "Distributed Intelligence in the Computing Continuum with Active Inference",
      "authors": [
        "Victor Casamayor Pujol",
        "Boris Sedlak",
        "Tommaso Salvatori",
        "Karl Friston",
        "Schahram Dustdar"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2505.24618v1",
      "pdf_path": "data/pdfs/pujol2025distributed.pdf",
      "added_date": "2025-12-12T11:49:31.412259",
      "abstract": "The Computing Continuum (CC) is an emerging Internet-based computing paradigm that spans from local Internet of Things sensors and constrained edge devices to large-scale cloud data centers. Its goal is to orchestrate a vast array of diverse and distributed computing resources to support the next generation of Internet-based applications. However, the distributed, heterogeneous, and dynamic nature of CC platforms demands distributed intelligence for adaptive and resilient service management. This article introduces a distributed stream processing pipeline as a CC use case, where each service is managed by an Active Inference (AIF) agent. These agents collaborate to fulfill service needs specified by SLOiDs, a term we introduce to denote Service Level Objectives that are aware of its deployed devices, meaning that non-functional requirements must consider the characteristics of the hosting device. We demonstrate how AIF agents can be modeled and deployed alongside distributed services to manage them autonomously. Our experiments show that AIF agents achieve over 90% SLOiD fulfillment when using tested transition models, and around 80% when learning the models during deployment. We compare their performance to a multi-agent reinforcement learning algorithm, finding that while both approaches yield similar results, MARL requires extensive training, whereas AIF agents can operate effectively from the start. Additionally, we evaluate the behavior of AIF agents in offloading scenarios, observing a strong capacity for adaptation. Finally, we outline key research directions to advance AIF integration in CC platforms.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2505.24618.pdf"
      }
    },
    "wu2025think": {
      "citation_key": "wu2025think",
      "title": "Think How Your Teammates Think: Active Inference Can Benefit Decentralized Execution",
      "authors": [
        "Hao Wu",
        "Shoucheng Song",
        "Chang Yao",
        "Sheng Han",
        "Huaiyu Wan",
        "Youfang Lin",
        "Kai Lv"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2511.18761v1",
      "pdf_path": "data/pdfs/wu2025think.pdf",
      "added_date": "2025-12-12T11:49:31.415153",
      "abstract": "In multi-agent systems, explicit cognition of teammates' decision logic serves as a critical factor in facilitating coordination. Communication (i.e., ``\\textit{Tell}'') can assist in the cognitive development process by information dissemination, yet it is inevitably subject to real-world constraints such as noise, latency, and attacks. Therefore, building the understanding of teammates' decisions without communication remains challenging. To address this, we propose a novel non-communication MARL framework that realizes the construction of cognition through local observation-based modeling (i.e., \\textit{``Think''}). Our framework enables agents to model teammates' \\textbf{active inference} process. At first, the proposed method produces three teammate portraits: perception-belief-action. Specifically, we model the teammate's decision process as follows: 1) Perception: observing environments; 2) Belief: forming beliefs; 3) Action: making decisions. Then, we selectively integrate the belief portrait into the decision process based on the accuracy and relevance of the perception portrait. This enables the selection of cooperative teammates and facilitates effective collaboration. Extensive experiments on the SMAC, SMACv2, MPE, and GRF benchmarks demonstrate the superior performance of our method.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2511.18761.pdf"
      }
    },
    "yeganeh2025deep": {
      "citation_key": "yeganeh2025deep",
      "title": "Deep Active Inference Agents for Delayed and Long-Horizon Environments",
      "authors": [
        "Yavar Taheri Yeganeh",
        "Mohsen Jafari",
        "Andrea Matta"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2505.19867v1",
      "pdf_path": "data/pdfs/yeganeh2025deep.pdf",
      "added_date": "2025-12-12T11:49:31.418487",
      "abstract": "With the recent success of world-model agents, which extend the core idea of model-based reinforcement learning by learning a differentiable model for sample-efficient control across diverse tasks, active inference (AIF) offers a complementary, neuroscience-grounded paradigm that unifies perception, learning, and action within a single probabilistic framework powered by a generative model. Despite this promise, practical AIF agents still rely on accurate immediate predictions and exhaustive planning, a limitation that is exacerbated in delayed environments requiring plans over long horizons, tens to hundreds of steps. Moreover, most existing agents are evaluated on robotic or vision benchmarks which, while natural for biological agents, fall short of real-world industrial complexity. We address these limitations with a generative-policy architecture featuring (i) a multi-step latent transition that lets the generative model predict an entire horizon in a single look-ahead, (ii) an integrated policy network that enables the transition and receives gradients of the expected free energy, (iii) an alternating optimization scheme that updates model and policy from a replay buffer, and (iv) a single gradient step that plans over long horizons, eliminating exhaustive planning from the control loop. We evaluate our agent in an environment that mimics a realistic industrial scenario with delayed and long-horizon settings. The empirical results confirm the effectiveness of the proposed approach, demonstrating the coupled world-model with the AIF formalism yields an end-to-end probabilistic controller capable of effective decision making in delayed, long-horizon settings without handcrafted rewards or expensive planning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2505.19867.pdf"
      }
    },
    "hill2025structural": {
      "citation_key": "hill2025structural",
      "title": "Structural Plasticity as Active Inference: A Biologically-Inspired Architecture for Homeostatic Control",
      "authors": [
        "Brennen A. Hill"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2511.02241v3",
      "pdf_path": "data/pdfs/hill2025structural.pdf",
      "added_date": "2025-12-12T11:49:31.421641",
      "abstract": "Traditional neural networks, while powerful, rely on biologically implausible learning mechanisms such as global backpropagation. This paper introduces the Structurally Adaptive Predictive Inference Network (SAPIN), a novel computational model inspired by the principles of active inference and the morphological plasticity observed in biological neural cultures. SAPIN operates on a 2D grid where processing units, or cells, learn by minimizing local prediction errors. The model features two primary, concurrent learning mechanisms: a local, Hebbian-like synaptic plasticity rule based on the temporal difference between a cell's actual activation and its learned expectation, and a structural plasticity mechanism where cells physically migrate across the grid to optimize their information-receptive fields. This dual approach allows the network to learn both how to process information (synaptic weights) and also where to position its computational resources (network topology). We validated the SAPIN model on the classic Cart Pole reinforcement learning benchmark. Our results demonstrate that the architecture can successfully solve the CartPole task, achieving robust performance. The network's intrinsic drive to minimize prediction error and maintain homeostasis was sufficient to discover a stable balancing policy. We also found that while continual learning led to instability, locking the network's parameters after achieving success resulted in a stable policy. When evaluated for 100 episodes post-locking (repeated over 100 successful agents), the locked networks maintained an average 82% success rate.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2511.02241.pdf"
      }
    },
    "albarracin2025physics": {
      "citation_key": "albarracin2025physics",
      "title": "The Physics and Metaphysics of Social Powers: Bridging Cognitive Processing and Social Dynamics, a New Perspective on Power through Active Inference",
      "authors": [
        "Mahault Albarracin",
        "Sonia de Jager",
        "David Hyland",
        "Sarah Grace Manski"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2501.19368v3",
      "pdf_path": "data/pdfs/albarracin2025physics.pdf",
      "added_date": "2025-12-12T11:49:31.424631",
      "abstract": "The concept of power can be explored at several scales: from physical action and process effectuation, all the way to complex social dynamics. A spectrum-wide analysis of power requires attention to the fundamental principles that constrain these processes. In the social realm, the acquisition and maintenance of power is intertwined with both social interactions and cognitive processing capacity: socially-facilitated empowerment grants agents more information-processing capacities and opportunities, either by relying on others to bring about desired policies or ultimately outcomes, and/or by enjoying more information-processing possibilities as a result of relying on others for the reproduction of (material) tasks. The effects of social empowerment thus imply an increased ability to harness computation toward desired ends, thereby augmenting the evolution of a specific state space. Empowered individuals attract the attention of others, who contribute to increasing the scale of their access to various policies effectuating these state spaces. The presented argument posits that social power, in the context of active inference, is a function of several variables. As a result of its power-amplifying effects, this extended computational ability also buffers against possible vulnerabilities. We propose that individuals wield power not only by associating with others possessing desirable policies, but also by enhancing their ability to intake and compute information effectively. This dual mechanism is argued to create a cyclical, reinforcing pattern wherein the empowered are able to incrementally expand the scope of policies and state spaces available to them while minimizing risk-exposure.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2501.19368.pdf"
      }
    },
    "constant2025normative": {
      "citation_key": "constant2025normative",
      "title": "Normative active inference: A numerical proof of principle for a computational and economic legal analytic approach to AI governance",
      "authors": [
        "Axel Constant",
        "Mahault Albarracin",
        "Karl J. Friston"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2511.19334v1",
      "pdf_path": "data/pdfs/constant2025normative.pdf",
      "added_date": "2025-12-12T11:49:31.427981",
      "abstract": "This paper presents a computational account of how legal norms can influence the behavior of artificial intelligence (AI) agents, grounded in the active inference framework (AIF) that is informed by principles of economic legal analysis (ELA). The ensuing model aims to capture the complexity of human decision-making under legal constraints, offering a candidate mechanism for agent governance in AI systems, that is, the (auto)regulation of AI agents themselves rather than human actors in the AI industry. We propose that lawful and norm-sensitive AI behavior can be achieved through regulation by design, where agents are endowed with intentional control systems, or behavioral safety valves, that guide real-time decisions in accordance with normative expectations. To illustrate this, we simulate an autonomous driving scenario in which an AI agent must decide when to yield the right of way by balancing competing legal and pragmatic imperatives. The model formalizes how AIF can implement context-dependent preferences to resolve such conflicts, linking this mechanism to the conception of law as a scaffold for rational decision-making under uncertainty. We conclude by discussing how context-dependent preferences could function as safety mechanisms for autonomous agents, enhancing lawful alignment and risk mitigation in AI governance.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2511.19334.pdf"
      }
    },
    "sedlak2025multidimensional": {
      "citation_key": "sedlak2025multidimensional",
      "title": "Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods",
      "authors": [
        "Boris Sedlak",
        "Alireza Furutanpey",
        "Zihang Wang",
        "Víctor Casamayor Pujol",
        "Schahram Dustdar"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.10420v1",
      "pdf_path": "data/pdfs/sedlak2025multidimensional.pdf",
      "added_date": "2025-12-12T11:49:31.430783",
      "abstract": "Edge computing breaks with traditional autoscaling due to strict resource constraints, thus, motivating more flexible scaling behaviors using multiple elasticity dimensions. This work introduces an agent-based autoscaling framework that dynamically adjusts both hardware resources and internal service configurations to maximize requirements fulfillment in constrained environments. We compare four types of scaling agents: Active Inference, Deep Q Network, Analysis of Structural Knowledge, and Deep Active Inference, using two real-world processing services running in parallel: YOLOv8 for visual recognition and OpenCV for QR code detection. Results show all agents achieve acceptable SLO performance with varying convergence patterns. While the Deep Q Network benefits from pre-training, the structural analysis converges quickly, and the deep active inference agent combines theoretical foundations with practical scalability advantages. Our findings provide evidence for the viability of multi-dimensional agent-based autoscaling for edge environments and encourage future work in this research direction.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.10420.pdf"
      }
    },
    "hyland2025variational": {
      "citation_key": "hyland2025variational",
      "title": "On the Variational Costs of Changing Our Minds",
      "authors": [
        "David Hyland",
        "Mahault Albarracin"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2509.17957v1",
      "pdf_path": "data/pdfs/hyland2025variational.pdf",
      "added_date": "2025-12-12T11:49:31.433520",
      "abstract": "The human mind is capable of extraordinary achievements, yet it often appears to work against itself. It actively defends its cherished beliefs even in the face of contradictory evidence, conveniently interprets information to conform to desired narratives, and selectively searches for or avoids information to suit its various purposes. Despite these behaviours deviating from common normative standards for belief updating, we argue that such 'biases' are not inherently cognitive flaws, but rather an adaptive response to the significant pragmatic and cognitive costs associated with revising one's beliefs. This paper introduces a formal framework that aims to model the influence of these costs on our belief updating mechanisms.   We treat belief updating as a motivated variational decision, where agents weigh the perceived 'utility' of a belief against the informational cost required to adopt a new belief state, quantified by the Kullback-Leibler divergence from the prior to the variational posterior. We perform computational experiments to demonstrate that simple instantiations of this resource-rational model can be used to qualitatively emulate commonplace human behaviours, including confirmation bias and attitude polarisation. In doing so, we suggest that this framework makes steps toward a more holistic account of the motivated Bayesian mechanics of belief change and provides practical insights for predicting, compensating for, and correcting deviations from desired belief updating processes.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2509.17957.pdf"
      }
    },
    "duraisamy2025active": {
      "citation_key": "duraisamy2025active",
      "title": "Active Inference AI Systems for Scientific Discovery",
      "authors": [
        "Karthik Duraisamy"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.21329v3",
      "pdf_path": "data/pdfs/duraisamy2025active.pdf",
      "added_date": "2025-12-12T11:49:31.437006",
      "abstract": "The rapid evolution of artificial intelligence has led to expectations of transformative impact on science, yet current systems remain fundamentally limited in enabling genuine scientific discovery. This perspective contends that progress turns on closing three mutually reinforcing gaps in abstraction, reasoning and empirical grounding. Central to addressing these gaps is recognizing complementary cognitive modes: thinking as slow, iterative hypothesis generation -- exploring counterfactual spaces where physical laws can be temporarily violated to discover new patterns -- and reasoning as fast, deterministic validation, traversing established knowledge graphs to test consistency with known principles. Abstractions in this loop should be manipulable models that enable counterfactual prediction, causal attribution, and refinement. Design principles -- rather than a monolithic recipe -- are proposed for systems that reason in imaginary spaces and learn from the world: causal, multimodal models for internal simulation; persistent, uncertainty-aware scientific memory that distinguishes hypotheses from established claims; formal verification pathways coupled to computations and experiments. It is also argued that the inherent ambiguity in feedback from simulations and experiments, and underlying uncertainties make human judgment indispensable, not as a temporary scaffold but as a permanent architectural component. Evaluations must assess the system's ability to identify novel phenomena, propose falsifiable hypotheses, and efficiently guide experimental programs toward genuine discoveries.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.21329.pdf"
      }
    },
    "feng2025active": {
      "citation_key": "feng2025active",
      "title": "Active Multimodal Distillation for Few-shot Action Recognition",
      "authors": [
        "Weijia Feng",
        "Yichen Zhu",
        "Ruojia Zhang",
        "Chenyang Wang",
        "Fei Ma",
        "Xiaobao Wang",
        "Xiaobai Li"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.13322v1",
      "pdf_path": "data/pdfs/feng2025active.pdf",
      "added_date": "2025-12-12T11:49:31.439894",
      "abstract": "Owing to its rapid progress and broad application prospects, few-shot action recognition has attracted considerable interest. However, current methods are predominantly based on limited single-modal data, which does not fully exploit the potential of multimodal information. This paper presents a novel framework that actively identifies reliable modalities for each sample using task-specific contextual cues, thus significantly improving recognition performance. Our framework integrates an Active Sample Inference (ASI) module, which utilizes active inference to predict reliable modalities based on posterior distributions and subsequently organizes them accordingly. Unlike reinforcement learning, active inference replaces rewards with evidence-based preferences, making more stable predictions. Additionally, we introduce an active mutual distillation module that enhances the representation learning of less reliable modalities by transferring knowledge from more reliable ones. Adaptive multimodal inference is employed during the meta-test to assign higher weights to reliable modalities. Extensive experiments across multiple benchmarks demonstrate that our method significantly outperforms existing approaches.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.13322.pdf"
      }
    },
    "tinker2025curiositydriven": {
      "citation_key": "tinker2025curiositydriven",
      "title": "Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration",
      "authors": [
        "Theodore Jerome Tinker",
        "Kenji Doya",
        "Jun Tani"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.05013v4",
      "pdf_path": "data/pdfs/tinker2025curiositydriven.pdf",
      "added_date": "2025-12-12T11:49:31.443284",
      "abstract": "Human infants acquire language and action gradually through development, achieving strong generalization from minimal experience, whereas large language models require exposure to billions of training tokens. What mechanisms underlie such efficient developmental learning in humans? This study investigates this question through robot simulation experiments in which agents learn to perform actions associated with imperative sentences (e.g., \\textit{push red cube}) via curiosity-driven self-exploration. Our approach integrates the active inference framework with reinforcement learning, enabling intrinsically motivated developmental learning. The simulations reveal several key findings: i) Generalization improves markedly as the scale of compositional elements increases. ii) Curiosity combined with motor noise yields substantially better learning than exploration without curiosity. iii) Rote pairing of sentences and actions precedes the emergence of compositional generalization. iv) Simpler, prerequisite-like actions develop earlier than more complex actions that depend on them. v) When exception-handling rules were introduced -- where certain imperative sentences required executing inconsistent actions -- the robots successfully acquired these exceptions through exploration and displayed a U-shaped performance curve characteristic of representational redescription in child language learning. Together, these results suggest that curiosity-driven exploration and active inference provide a powerful account of how intrinsic motivation and hierarchical sensorimotor learning can jointly support scalable compositional generalization and exception handling in both humans and artificial agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.05013.pdf"
      }
    },
    "vyas2025towards": {
      "citation_key": "vyas2025towards",
      "title": "Towards smart and adaptive agents for active sensing on edge devices",
      "authors": [
        "Devendra Vyas",
        "Nikola Pižurica",
        "Nikola Milović",
        "Igor Jovančević",
        "Miguel de Prado",
        "Tim Verbelen"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2501.06262v2",
      "pdf_path": "data/pdfs/vyas2025towards.pdf",
      "added_date": "2025-12-12T11:49:31.446418",
      "abstract": "TinyML has made deploying deep learning models on low-power edge devices feasible, creating new opportunities for real-time perception in constrained environments. However, the adaptability of such deep learning methods remains limited to data drift adaptation, lacking broader capabilities that account for the environment's underlying dynamics and inherent uncertainty. Deep learning's scaling laws, which counterbalance this limitation by massively up-scaling data and model size, cannot be applied when deploying on the Edge, where deep learning limitations are further amplified as models are scaled down for deployment on resource-constrained devices.   This paper presents an innovative agentic system capable of performing on-device perception and planning, enabling active sensing on the edge. By incorporating active inference into our solution, our approach extends beyond deep learning capabilities, allowing the system to plan in dynamic environments while operating in real-time with a compact memory footprint of as little as 300 MB. We showcase our proposed system by creating and deploying a saccade agent connected to an IoT camera with pan and tilt capabilities on an NVIDIA Jetson embedded device. The saccade agent controls the camera's field of view following optimal policies derived from the active inference principles, simulating human-like saccadic motion for surveillance and robotics applications.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2501.06262.pdf"
      }
    },
    "kiefer2025intrinsic": {
      "citation_key": "kiefer2025intrinsic",
      "title": "Intrinsic motivation as constrained entropy maximization",
      "authors": [
        "Alex B. Kiefer"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2502.02962v3",
      "pdf_path": "data/pdfs/kiefer2025intrinsic.pdf",
      "added_date": "2025-12-12T11:49:31.449527",
      "abstract": "\"Intrinsic motivation\" refers to the capacity for intelligent systems to be motivated endogenously, i.e. by features of agential architecture itself rather than by learned associations between action and reward. This paper views active inference, empowerment, and other formal accounts of intrinsic motivation as variations on the theme of constrained maximum entropy inference, providing a general perspective on intrinsic motivation complementary to existing frameworks. The connection between free energy and empowerment noted in previous literature is further explored, and it is argued that the maximum-occupancy approach in practice incorporates an implicit model-evidence constraint.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2502.02962.pdf"
      }
    },
    "heins2025axiom": {
      "citation_key": "heins2025axiom",
      "title": "AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models",
      "authors": [
        "Conor Heins",
        "Toon Van de Maele",
        "Alexander Tschantz",
        "Hampus Linander",
        "Dimitrije Markovic",
        "Tommaso Salvatori",
        "Corrado Pezzato",
        "Ozan Catal",
        "Ran Wei",
        "Magnus Koudahl",
        "Marco Perin",
        "Karl Friston",
        "Tim Verbelen",
        "Christopher Buckley"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2505.24784v1",
      "pdf_path": "data/pdfs/heins2025axiom.pdf",
      "added_date": "2025-12-12T11:49:31.453031",
      "abstract": "Current deep reinforcement learning (DRL) approaches achieve state-of-the-art performance in various domains, but struggle with data efficiency compared to human learning, which leverages core priors about objects and their interactions. Active inference offers a principled framework for integrating sensory information with prior knowledge to learn a world model and quantify the uncertainty of its own beliefs and predictions. However, active inference models are usually crafted for a single task with bespoke knowledge, so they lack the domain flexibility typical of DRL approaches. To bridge this gap, we propose a novel architecture that integrates a minimal yet expressive set of core priors about object-centric dynamics and interactions to accelerate learning in low-data regimes. The resulting approach, which we call AXIOM, combines the usual data efficiency and interpretability of Bayesian approaches with the across-task generalization usually associated with DRL. AXIOM represents scenes as compositions of objects, whose dynamics are modeled as piecewise linear trajectories that capture sparse object-object interactions. The structure of the generative model is expanded online by growing and learning mixture models from single events and periodically refined through Bayesian model reduction to induce generalization. AXIOM masters various games within only 10,000 interaction steps, with both a small number of parameters compared to DRL, and without the computational expense of gradient-based optimization.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2505.24784.pdf"
      }
    },
    "vertegaal2025interactive": {
      "citation_key": "vertegaal2025interactive",
      "title": "Interactive Inference: A Neuromorphic Theory of Human-Computer Interaction",
      "authors": [
        "Roel Vertegaal",
        "Timothy Merritt",
        "Saul Greenberg",
        "Aneesh P. Tarun",
        "Zhen Li",
        "Zafeirios Fountas"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2502.05935v6",
      "pdf_path": "data/pdfs/vertegaal2025interactive.pdf",
      "added_date": "2025-12-12T11:49:31.456245",
      "abstract": "Neuromorphic Human-Computer Interaction (HCI) is a theoretical approach to designing better user experiences (UX) motivated by advances in the understanding of the neurophysiology of the brain. Inspired by the neuroscientific theory of Active Inference, Interactive Inference is a first example of such approach. It offers a simplified interpretation of Active Inference that allows designers to more readily apply this theory to design and evaluation. In Interactive Inference, user behaviour is modeled as Bayesian inference on progress and goal distributions that predicts the next action. We show how the error between goal and progress distributions, or Bayesian surprise, can be modeled as a simple mean square error of the signal-to-noise ratio (SNR) of a task. The problem is that the user's capacity to process Bayesian surprise follows the logarithm of this SNR. This means errors rise quickly once average capacity is exceeded. Our model allows the quantitative analysis of performance and error using one framework that can provide real-time estimates of the mental load in users that needs to be minimized by design. We show how three basic laws of HCI, Hick's Law, Fitts' Law and the Power Law can be expressed using our model. We then test the validity of the model by empirically measuring how well it predicts human performance and error in a car following task. Results suggest that driver processing capacity indeed is a logarithmic function of the SNR of the distance to a lead car. This result provides initial evidence that Interactive Interference can be useful as a new theoretical design tool.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2502.05935.pdf"
      }
    },
    "lerma2025nael": {
      "citation_key": "lerma2025nael",
      "title": "NAEL: Non-Anthropocentric Ethical Logic",
      "authors": [
        "Bianca Maria Lerma",
        "Rafael Peñaloza"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2510.14676v1",
      "pdf_path": "data/pdfs/lerma2025nael.pdf",
      "added_date": "2025-12-12T11:49:31.459925",
      "abstract": "We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical framework for artificial agents grounded in active inference and symbolic reasoning. Departing from conventional, human-centred approaches to AI ethics, NAEL formalizes ethical behaviour as an emergent property of intelligent systems minimizing global expected free energy in dynamic, multi-agent environments. We propose a neuro-symbolic architecture to allow agents to evaluate the ethical consequences of their actions in uncertain settings. The proposed system addresses the limitations of existing ethical models by allowing agents to develop context-sensitive, adaptive, and relational ethical behaviour without presupposing anthropomorphic moral intuitions. A case study involving ethical resource distribution illustrates NAEL's dynamic balancing of self-preservation, epistemic learning, and collective welfare.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2510.14676.pdf"
      }
    },
    "higham2025actively": {
      "citation_key": "higham2025actively",
      "title": "Actively Inferring Optimal Measurement Sequences",
      "authors": [
        "Catherine F. Higham",
        "Paul Henderson",
        "Roderick Murray-Smith"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2502.18142v1",
      "pdf_path": "data/pdfs/higham2025actively.pdf",
      "added_date": "2025-12-12T11:49:31.463269",
      "abstract": "Measurement of a physical quantity such as light intensity is an integral part of many reconstruction and decision scenarios but can be costly in terms of acquisition time, invasion of or damage to the environment and storage. Data minimisation and compliance with data protection laws is also an important consideration. Where there are a range of measurements that can be made, some may be more informative and compliant with the overall measurement objective than others. We develop an active sequential inference algorithm that uses the low dimensional representational latent space from a variational autoencoder (VAE) to choose which measurement to make next. Our aim is to recover high dimensional data by making as few measurements as possible. We adapt the VAE encoder to map partial data measurements on to the latent space of the complete data. The algorithm draws samples from this latent space and uses the VAE decoder to generate data conditional on the partial measurements. Estimated measurements are made on the generated data and fed back through the partial VAE encoder to the latent space where they can be evaluated prior to making a measurement. Starting from no measurements and a normal prior on the latent space, we consider alternative strategies for choosing the next measurement and updating the predictive posterior prior for the next step. The algorithm is illustrated using the Fashion MNIST dataset and a novel convolutional Hadamard pattern measurement basis. We see that useful patterns are chosen within 10 steps, leading to the convergence of the guiding generative images. Compared with using stochastic variational inference to infer the parameters of the posterior distribution for each generated data point individually, the partial VAE framework can efficiently process batches of generated data and obtains superior results with minimal measurements.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2502.18142.pdf"
      }
    },
    "fernando2025wanting": {
      "citation_key": "fernando2025wanting",
      "title": "Wanting to be Understood",
      "authors": [
        "Chrisantha Fernando",
        "Dylan Banarse",
        "Simon Osindero"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2504.06611v2",
      "pdf_path": "data/pdfs/fernando2025wanting.pdf",
      "added_date": "2025-12-12T11:49:31.466242",
      "abstract": "This paper explores an intrinsic motivation for mutual awareness, hypothesizing that humans possess a fundamental drive to understand and to be understood even in the absence of extrinsic rewards. Through simulations of the perceptual crossing paradigm, we explore the effect of various internal reward functions in reinforcement learning agents. The drive to understand is implemented as an active inference type artificial curiosity reward, whereas the drive to be understood is implemented through intrinsic rewards for imitation, influence/impressionability, and sub-reaction time anticipation of the other. Results indicate that while artificial curiosity alone does not lead to a preference for social interaction, rewards emphasizing reciprocal understanding successfully drive agents to prioritize interaction. We demonstrate that this intrinsic motivation can facilitate cooperation in tasks where only one agent receives extrinsic reward for the behaviour of the other.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2504.06611.pdf"
      }
    },
    "nuijten2025message": {
      "citation_key": "nuijten2025message",
      "title": "A Message Passing Realization of Expected Free Energy Minimization",
      "authors": [
        "Wouter W. L. Nuijten",
        "Mykola Lukashchuk",
        "Thijs van de Laar",
        "Bert de Vries"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.02197v1",
      "pdf_path": "data/pdfs/nuijten2025message.pdf",
      "added_date": "2025-12-12T11:49:31.470353",
      "abstract": "We present a message passing approach to Expected Free Energy (EFE) minimization on factor graphs, based on the theory introduced in arXiv:2504.14898. By reformulating EFE minimization as Variational Free Energy minimization with epistemic priors, we transform a combinatorial search problem into a tractable inference problem solvable through standard variational techniques. Applying our message passing method to factorized state-space models enables efficient policy inference. We evaluate our method on environments with epistemic uncertainty: a stochastic gridworld and a partially observable Minigrid task. Agents using our approach consistently outperform conventional KL-control agents on these tasks, showing more robust planning and efficient exploration under uncertainty. In the stochastic gridworld environment, EFE-minimizing agents avoid risky paths, while in the partially observable minigrid setting, they conduct more systematic information-seeking. This approach bridges active inference theory with practical implementations, providing empirical evidence for the efficiency of epistemic priors in artificial agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.02197.pdf"
      }
    },
    "laukkonen2025contemplative": {
      "citation_key": "laukkonen2025contemplative",
      "title": "Contemplative Artificial Intelligence",
      "authors": [
        "Ruben Laukkonen",
        "Fionn Inglis",
        "Shamil Chandaria",
        "Lars Sandved-Smith",
        "Edmundo Lopez-Sola",
        "Jakob Hohwy",
        "Jonathan Gold",
        "Adam Elwood"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2504.15125v3",
      "pdf_path": "data/pdfs/laukkonen2025contemplative.pdf",
      "added_date": "2025-12-12T11:49:31.473329",
      "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies may falter in the face of unpredictable self-improvement, hidden subgoals, and the sheer complexity of intelligent systems. Inspired by contemplative wisdom traditions, we show how four axiomatic principles can instil a resilient Wise World Model in AI systems. First, mindfulness enables self-monitoring and recalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal fixation and relaxes rigid priors. Third, non-duality dissolves adversarial self-other boundaries. Fourth, boundless care motivates the universal reduction of suffering. We find that prompting AI to reflect on these principles improves performance on the AILuminate Benchmark (d=.96) and boosts cooperation and joint-reward on the Prisoner's Dilemma task (d=7+). We offer detailed implementation strategies at the level of architectures, constitutions, and reinforcement on chain-of-thought. For future systems, active inference may offer the self-organizing and dynamic coupling capabilities needed to enact Contemplative AI in embodied agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2504.15125.pdf"
      }
    },
    "li2025robust": {
      "citation_key": "li2025robust",
      "title": "Robust Sampling for Active Statistical Inference",
      "authors": [
        "Puheng Li",
        "Tijana Zrnic",
        "Emmanuel Candès"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2511.08991v1",
      "pdf_path": "data/pdfs/li2025robust.pdf",
      "added_date": "2025-12-12T11:49:31.477309",
      "abstract": "Active statistical inference is a new method for inference with AI-assisted data collection. Given a budget on the number of labeled data points that can be collected and assuming access to an AI predictive model, the basic idea is to improve estimation accuracy by prioritizing the collection of labels where the model is most uncertain. The drawback, however, is that inaccurate uncertainty estimates can make active sampling produce highly noisy results, potentially worse than those from naive uniform sampling. In this work, we present robust sampling strategies for active statistical inference. Robust sampling ensures that the resulting estimator is never worse than the estimator using uniform sampling. Furthermore, with reliable uncertainty estimates, the estimator usually outperforms standard active inference. This is achieved by optimally interpolating between uniform and active sampling, depending on the quality of the uncertainty scores, and by using ideas from robust optimization. We demonstrate the utility of the method on a series of real datasets from computational social science and survey research.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2511.08991.pdf"
      }
    },
    "hashimoto2025toward": {
      "citation_key": "hashimoto2025toward",
      "title": "Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model",
      "authors": [
        "Saki Hashimoto",
        "Shoichi Hasegawa",
        "Tomochika Ishikawa",
        "Akira Taniguchi",
        "Yoshinobu Hagiwara",
        "Lotfi El Hafi",
        "Tadahiro Taniguchi"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2509.12754v1",
      "pdf_path": "data/pdfs/hashimoto2025toward.pdf",
      "added_date": "2025-12-12T11:49:31.480815",
      "abstract": "Robots operating in domestic and office environments must understand object ownership to correctly execute instructions such as ``Bring me my cup.'' However, ownership cannot be reliably inferred from visual features alone. To address this gap, we propose Active Ownership Learning (ActOwL), a framework that enables robots to actively generate and ask ownership-related questions to users. ActOwL employs a probabilistic generative model to select questions that maximize information gain, thereby acquiring ownership knowledge efficiently to improve learning efficiency. Additionally, by leveraging commonsense knowledge from Large Language Models (LLM), objects are pre-classified as either shared or owned, and only owned objects are targeted for questioning. Through experiments in a simulated home environment and a real-world laboratory setting, ActOwL achieved significantly higher ownership clustering accuracy with fewer questions than baseline methods. These findings demonstrate the effectiveness of combining active inference with LLM-guided commonsense reasoning, advancing the capability of robots to acquire ownership knowledge for practical and socially appropriate task execution.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2509.12754.pdf"
      }
    },
    "bramblett2025implicit": {
      "citation_key": "bramblett2025implicit",
      "title": "Implicit Coordination using Active Epistemic Inference for Multi-Robot Systems",
      "authors": [
        "Lauren Bramblett",
        "Jonathan Reasoner",
        "Nicola Bezzo"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2501.03907v2",
      "pdf_path": "data/pdfs/bramblett2025implicit.pdf",
      "added_date": "2025-12-12T11:49:31.483775",
      "abstract": "A Multi-robot system (MRS) provides significant advantages for intricate tasks such as environmental monitoring, underwater inspections, and space missions. However, addressing potential communication failures or the lack of communication infrastructure in these fields remains a challenge. A significant portion of MRS research presumes that the system can maintain communication with proximity constraints, but this approach does not solve situations where communication is either non-existent, unreliable, or poses a security risk. Some approaches tackle this issue using predictions about other robots while not communicating, but these methods generally only permit agents to utilize first-order reasoning, which involves reasoning based purely on their own observations. In contrast, to deal with this problem, our proposed framework utilizes Theory of Mind (ToM), employing higher-order reasoning by shifting a robot's perspective to reason about a belief of others observations. Our approach has two main phases: i) an efficient runtime plan adaptation using active inference to signal intentions and reason about a robot's own belief and the beliefs of others in the system, and ii) a hierarchical epistemic planning framework to iteratively reason about the current MRS mission state. The proposed framework outperforms greedy and first-order reasoning approaches and is validated using simulations and experiments with heterogeneous robotic systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2501.03907.pdf"
      }
    },
    "benrimoh2025role": {
      "citation_key": "benrimoh2025role",
      "title": "The Role of Affective States in Computational Psychiatry",
      "authors": [
        "David Benrimoh",
        "Ryan Smith",
        "Andreea O. Diaconescu",
        "Timothy Friesen",
        "Sara Jalali",
        "Nace Mikus",
        "Laura Gschwandtner",
        "Jay Gandhi",
        "Guillermo Horga",
        "Albert Powers"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.06049v1",
      "pdf_path": "data/pdfs/benrimoh2025role.pdf",
      "added_date": "2025-12-12T11:49:31.487300",
      "abstract": "Studying psychiatric illness has often been limited by difficulties in connecting symptoms and behavior to neurobiology. Computational psychiatry approaches promise to bridge this gap by providing formal accounts of the latent information processing changes that underlie the development and maintenance of psychiatric phenomena. Models based on these theories generate individual-level parameter estimates which can then be tested for relationships to neurobiology. In this review, we explore computational modelling approaches to one key aspect of health and illness: affect. We discuss strengths and limitations of key approaches to modelling affect, with a focus on reinforcement learning, active inference, the hierarchical gaussian filter, and drift-diffusion models. We find that, in this literature, affect is an important source of modulation in decision making, and has a bidirectional influence on how individuals infer both internal and external states. Highlighting the potential role of affect in information processing changes underlying symptom development, we extend an existing model of psychosis, where affective changes are influenced by increasing cortical noise and consequent increases in either perceived environmental instability or expected noise in sensory input, becoming part of a self-reinforcing process generating negatively valenced, over-weighted priors underlying positive symptom development. We then provide testable predictions from this model at computational, neurobiological, and phenomenological levels of description.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.06049.pdf"
      }
    },
    "corcoran2025integrated": {
      "citation_key": "corcoran2025integrated",
      "title": "Integrated information and predictive processing theories of consciousness: An adversarial collaborative review",
      "authors": [
        "Andrew W. Corcoran",
        "Andrew M. Haun",
        "Reinder Dorman",
        "Giulio Tononi",
        "Karl J. Friston",
        "Cyriel M. A. Pennartz",
        " TWCF",
        " :",
        "INTREPID Consortium"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2509.00555v1",
      "pdf_path": "data/pdfs/corcoran2025integrated.pdf",
      "added_date": "2025-12-12T11:49:31.490444",
      "abstract": "As neuroscientific theories of consciousness continue to proliferate, the need to assess their similarities and differences -- as well as their predictive and explanatory power -- becomes ever more pressing. Recently, a number of structured adversarial collaborations have been devised to test the competing predictions of several candidate theories of consciousness. In this review, we compare and contrast three theories being investigated in one such adversarial collaboration: Integrated Information Theory, Neurorepresentationalism, and Active Inference. We begin by presenting the core claims of each theory, before comparing them in terms of (1) the phenomena they seek to explain, (2) the sorts of explanations they avail, and (3) the methodological strategies they endorse. We then consider some of the inherent challenges of theory testing, and how adversarial collaboration addresses some of these difficulties. More specifically, we outline the key hypotheses that will be tested in this adversarial collaboration, and exemplify how contrasting empirical predictions may pertain to core and auxiliary components of each theory. Finally, we discuss how the data harvested across disparate experiments (and their replicates) may be formally integrated to provide a quantitative measure of the evidential support accrued under each theory. We suggest this approach to theory comparison may afford a useful metric for tracking the amount of scientific progress being made in consciousness research.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2509.00555.pdf"
      }
    },
    "khelloufi2025agi": {
      "citation_key": "khelloufi2025agi",
      "title": "AGI Enabled Solutions For IoX Layers Bottlenecks In Cyber-Physical-Social-Thinking Space",
      "authors": [
        "Amar Khelloufi",
        "Huansheng Ning",
        "Sahraoui Dhelim",
        "Jianguo Ding"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2506.22487v1",
      "pdf_path": "data/pdfs/khelloufi2025agi.pdf",
      "added_date": "2025-12-12T11:49:31.494229",
      "abstract": "The integration of the Internet of Everything (IoX) and Artificial General Intelligence (AGI) has given rise to a transformative paradigm aimed at addressing critical bottlenecks across sensing, network, and application layers in Cyber-Physical-Social Thinking (CPST) ecosystems. In this survey, we provide a systematic and comprehensive review of AGI-enhanced IoX research, focusing on three key components: sensing-layer data management, network-layer protocol optimization, and application-layer decision-making frameworks. Specifically, this survey explores how AGI can mitigate IoX bottlenecks challenges by leveraging adaptive sensor fusion, edge preprocessing, and selective attention mechanisms at the sensing layer, while resolving network-layer issues such as protocol heterogeneity and dynamic spectrum management, neuro-symbolic reasoning, active inference, and causal reasoning, Furthermore, the survey examines AGI-enabled frameworks for managing identity and relationship explosion. Key findings suggest that AGI-driven strategies, such as adaptive sensor fusion, edge preprocessing, and semantic modeling, offer novel solutions to sensing-layer data overload, network-layer protocol heterogeneity, and application-layer identity explosion. The survey underscores the importance of cross-layer integration, quantum-enabled communication, and ethical governance frameworks for future AGI-enabled IoX systems. Finally, the survey identifies unresolved challenges, such as computational requirements, scalability, and real-world validation, calling for further research to fully realize AGI's potential in addressing IoX bottlenecks. we believe AGI-enhanced IoX is emerging as a critical research field at the intersection of interconnected systems and advanced AI.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2506.22487.pdf"
      }
    },
    "baltieri2025coalgebraic": {
      "citation_key": "baltieri2025coalgebraic",
      "title": "A coalgebraic perspective on predictive processing",
      "authors": [
        "Manuel Baltieri",
        "Filippo Torresan",
        "Tomoya Nakai"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.16877v1",
      "pdf_path": "data/pdfs/baltieri2025coalgebraic.pdf",
      "added_date": "2025-12-12T11:49:31.497740",
      "abstract": "Predictive processing and active inference posit that the brain is a system performing Bayesian inference on the environment. By virtue of this, a prominent interpretation of predictive processing states that the generative model (a POMDP) encoded by the brain synchronises with the generative process (another POMDP) representing the environment while trying to explain what hidden properties of the world generated its sensory input. In this view, the brain is thought to become a copy of the environment. This claim has however been disputed, stressing the fact that a structural copy, or isomorphism as it is at times invoked to be, is not an accurate description of this process since the environment is necessarily more complex than the brain, and what matters is not the capacity to exactly recapitulate the veridical causal structure of the world. In this work, we make parts of this counterargument formal by using ideas from the theory of coalgebras, an abstract mathematical framework for dynamical systems that brings together work from automata theory, concurrency theory, probabilistic processes and other fields. To do so, we cast generative model and process, in the form of POMDPs, as coalgebras, and use maps between them to describe a form of consistency that goes beyond mere structural similarity, giving the necessary mathematical background to describe how different processes can be seen as behaviourally, rather than structurally, equivalent, i.e. how they can be seen as emitting the same observations, and thus minimise prediction error, over time without strict assumptions about structural similarity. In particular, we will introduce three standard notions of equivalence from the literature on coalgebras, evaluating them in the context of predictive processing and identifying the one closest to claims made by proponents of this framework.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.16877.pdf"
      }
    },
    "carl2025from": {
      "citation_key": "carl2025from",
      "title": "From Representation to Enactment: The ABC Framework of the Translating Mind",
      "authors": [
        "Michael Carl",
        "Takanori Mizowaki",
        "Aishvarya Raj",
        "Masaru Yamada",
        "Devi Sri Bandaru",
        "Yuxiang Wei",
        "Xinyue Ren"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2511.16811v1",
      "pdf_path": "data/pdfs/carl2025from.pdf",
      "added_date": "2025-12-12T11:49:31.501289",
      "abstract": "Building on the Extended Mind (EM) theory and radical enactivism, this article suggests an alternative to representation-based models of the mind. We lay out a novel ABC framework of the translating mind, in which translation is not the manipulation of static interlingual correspondences but an enacted activity, dynamically integrating affective, behavioral, and cognitive (ABC) processes. Drawing on Predictive Processing and (En)Active Inference, we argue that the translator's mind emerges, rather than being merely extended, through loops of brain-body-environment interactions. This non-representational account reframes translation as skillful participation in sociocultural practice, where meaning is co-created in real time through embodied interaction with texts, tools, and contexts.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2511.16811.pdf"
      }
    },
    "molloy2025iscpomdps": {
      "citation_key": "molloy2025iscpomdps",
      "title": "ISC-POMDPs: Partially Observed Markov Decision Processes with Initial-State Dependent Costs",
      "authors": [
        "Timothy L. Molloy"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2503.05030v1",
      "pdf_path": "data/pdfs/molloy2025iscpomdps.pdf",
      "added_date": "2025-12-12T11:49:31.505002",
      "abstract": "We introduce a class of partially observed Markov decision processes (POMDPs) with costs that can depend on both the value and (future) uncertainty associated with the initial state. These Initial-State Cost POMDPs (ISC-POMDPs) enable the specification of objectives relative to a priori unknown initial states, which is useful in applications such as robot navigation, controlled sensing, and active perception, that can involve controlling systems to revisit, remain near, or actively infer their initial states. By developing a recursive Bayesian fixed-point smoother to estimate the initial state that resembles the standard recursive Bayesian filter, we show that ISC-POMDPs can be treated as POMDPs with (potentially) belief-dependent costs. We demonstrate the utility of ISC-POMDPs, including their ability to select controls that resolve (future) uncertainty about (past) initial states, in simulation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2503.05030.pdf"
      }
    },
    "tang2025is": {
      "citation_key": "tang2025is",
      "title": "Is Active Persona Inference Necessary for Aligning Small Models to Personal Preferences?",
      "authors": [
        "Zilu Tang",
        "Afra Feyza Akyürek",
        "Ekin Akyürek",
        "Derry Wijaya"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2505.13257v2",
      "pdf_path": "data/pdfs/tang2025is.pdf",
      "added_date": "2025-12-12T11:49:31.512093",
      "abstract": "A prominent issue in aligning language models (LMs) to personalized preferences is underspecification -- the lack of information from users about their preferences. A popular trend of injecting such specification is adding a prefix (e.g. prior relevant conversations) to the current user's conversation to steer preference distribution. Most methods passively model personal preferences with prior example preferences pairs. We ask whether models benefit from actively inferring preference descriptions, and address this question by creating a synthetic personalized alignment dataset based on famous people with known public preferences. We then test how effective finetuned 1-8B size models are at inferring and aligning to personal preferences. Results show that higher-quality active prefixes lead to better generalization, more contextually faithful models, and less systematic biases across different protected attributes. All our results suggest active alignment can lead to a more controllable and efficient path for personalized alignment.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2505.13257.pdf"
      }
    },
    "hayashi2025universal": {
      "citation_key": "hayashi2025universal",
      "title": "Universal AI maximizes Variational Empowerment",
      "authors": [
        "Yusuke Hayashi",
        "Koichi Takahashi"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2502.15820v2",
      "pdf_path": "data/pdfs/hayashi2025universal.pdf",
      "added_date": "2025-12-12T11:49:31.515431",
      "abstract": "This paper presents a theoretical framework unifying AIXI -- a model of universal AI -- with variational empowerment as an intrinsic drive for exploration. We build on the existing framework of Self-AIXI -- a universal learning agent that predicts its own actions -- by showing how one of its established terms can be interpreted as a variational empowerment objective. We further demonstrate that universal AI's planning process can be cast as minimizing expected variational free energy (the core principle of active Inference), thereby revealing how universal AI agents inherently balance goal-directed behavior with uncertainty reduction curiosity). Moreover, we argue that power-seeking tendencies of universal AI agents can be explained not only as an instrumental strategy to secure future reward, but also as a direct consequence of empowerment maximization -- i.e. the agent's intrinsic drive to maintain or expand its own controllability in uncertain environments. Our main contribution is to show how these intrinsic motivations (empowerment, curiosity) systematically lead universal AI agents to seek and sustain high-optionality states. We prove that Self-AIXI asymptotically converges to the same performance as AIXI under suitable conditions, and highlight that its power-seeking behavior emerges naturally from both reward maximization and curiosity-driven exploration. Since AIXI can be view as a Bayes-optimal mathematical formulation for Artificial General Intelligence (AGI), our result can be useful for further discussion on AI safety and the controllability of AGI.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2502.15820.pdf"
      }
    },
    "webb2025use": {
      "citation_key": "webb2025use",
      "title": "The Use of Gaze-Derived Confidence of Inferred Operator Intent in Adjusting Safety-Conscious Haptic Assistance",
      "authors": [
        "Jeremy D. Webb",
        "Michael Bowman",
        "Songpo Li",
        "Xiaoli Zhang"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2504.03098v1",
      "pdf_path": "data/pdfs/webb2025use.pdf",
      "added_date": "2025-12-12T11:49:31.519244",
      "abstract": "Humans directly completing tasks in dangerous or hazardous conditions is not always possible where these tasks are increasingly be performed remotely by teleoperated robots. However, teleoperation is difficult since the operator feels a disconnect with the robot caused by missing feedback from several senses, including touch, and the lack of depth in the video feedback presented to the operator. To overcome this problem, the proposed system actively infers the operator's intent and provides assistance based on the predicted intent. Furthermore, a novel method of calculating confidence in the inferred intent modifies the human-in-the-loop control. The operator's gaze is employed to intuitively indicate the target before the manipulation with the robot begins. A potential field method is used to provide a guiding force towards the intended target, and a safety boundary reduces risk of damage. Modifying these assistances based on the confidence level in the operator's intent makes the control more natural, and gives the robot an intuitive understanding of its human master. Initial validation results show the ability of the system to improve accuracy, execution time, and reduce operator error.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2504.03098.pdf"
      }
    },
    "choudhury2025bedllm": {
      "citation_key": "choudhury2025bedllm",
      "title": "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design",
      "authors": [
        "Deepro Choudhury",
        "Sinead Williamson",
        "Adam Goliński",
        "Ning Miao",
        "Freddie Bickford Smith",
        "Michael Kirchhof",
        "Yizhe Zhang",
        "Tom Rainforth"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2508.21184v2",
      "pdf_path": "data/pdfs/choudhury2025bedllm.pdf",
      "added_date": "2025-12-12T11:49:31.522667",
      "abstract": "We propose a general-purpose approach for improving the ability of Large Language Models (LLMs) to intelligently and adaptively gather information from a user or other external source using the framework of sequential Bayesian experimental design (BED). This enables LLMs to act as effective multi-turn conversational agents and interactively interface with external environments. Our approach, which we call BED-LLM (Bayesian Experimental Design with Large Language Models), is based on iteratively choosing questions or queries that maximize the expected information gain (EIG) about the task of interest given the responses gathered previously. We show how this EIG can be formulated (and then estimated) in a principled way using a probabilistic model derived from the LLM's predictive distributions and provide detailed insights into key decisions in its construction and updating procedure. We find that BED-LLM achieves substantial gains in performance across a wide range of tests based on the 20 questions game and using the LLM to actively infer user preferences, compared to direct prompting of the LLM and other adaptive design strategies.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2508.21184.pdf"
      }
    },
    "alanova2025lightweight": {
      "citation_key": "alanova2025lightweight",
      "title": "Lightweight error mitigation strategies for post-training N:M activation sparsity in LLMs",
      "authors": [
        "Shirin Alanova",
        "Kristina Kazistova",
        "Ekaterina Galaeva",
        "Alina Kostromina",
        "Vladimir Smirnov",
        "Redko Dmitry",
        "Alexey Dontsov",
        "Maxim Zhelnin",
        "Evgeny Burnaev",
        "Egor Shvetsov"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2509.22166v1",
      "pdf_path": "data/pdfs/alanova2025lightweight.pdf",
      "added_date": "2025-12-12T11:49:31.526018",
      "abstract": "The demand for efficient large language model (LLM) inference has intensified the focus on sparsification techniques. While semi-structured (N:M) pruning is well-established for weights, its application to activation pruning remains underexplored despite its potential for dynamic, input-adaptive compression and reductions in I/O overhead. This work presents a comprehensive analysis of methods for post-training N:M activation pruning in LLMs. Across multiple LLMs, we demonstrate that pruning activations enables superior preservation of generative capabilities compared to weight pruning at equivalent sparsity levels. We evaluate lightweight, plug-and-play error mitigation techniques and pruning criteria, establishing strong hardware-friendly baselines that require minimal calibration. Furthermore, we explore sparsity patterns beyond NVIDIA's standard 2:4, showing that the 16:32 pattern achieves performance nearly on par with unstructured sparsity. However, considering the trade-off between flexibility and hardware implementation complexity, we focus on the 8:16 pattern as a superior candidate. Our findings provide both effective practical methods for activation pruning and a motivation for future hardware to support more flexible sparsity patterns. Our code is available https://anonymous.4open.science/r/Structured-Sparse-Activations-Inference-EC3C/README.md .",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2509.22166.pdf"
      }
    },
    "wan2025enhancing": {
      "citation_key": "wan2025enhancing",
      "title": "Enhancing Personalized Multi-Turn Dialogue with Curiosity Reward",
      "authors": [
        "Yanming Wan",
        "Jiaxing Wu",
        "Marwa Abdulhai",
        "Lior Shani",
        "Natasha Jaques"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2504.03206v3",
      "pdf_path": "data/pdfs/wan2025enhancing.pdf",
      "added_date": "2025-12-12T11:49:31.529982",
      "abstract": "Effective conversational agents like large language models (LLMs) must personalize their interactions to adapt to user preferences, personalities, and attributes across diverse domains like education and healthcare. Current methods like Reinforcement Learning from Human Feedback (RLHF), often prioritize helpfulness and safety but fall short in fostering truly empathetic, adaptive, and personalized dialogues. Existing personalization approaches typically rely on extensive user history, limiting their effectiveness for new or context-limited users. To address these limitations, we propose leveraging a user model to incorporate a curiosity-based intrinsic reward into multi-turn RLHF. This novel reward mechanism encourages the LLM agent to actively infer user traits by optimizing conversations to improve its user model's accuracy. Consequently, the agent delivers more personalized interactions by learning more about the user. We demonstrate our method's effectiveness in two distinct domains: significantly improving personalization performance in a conversational recommendation task, and personalizing conversations for different learning styles in an educational setting. We show improved generalization capabilities compared to traditional multi-turn RLHF, all while maintaining conversation quality. Our method offers a promising solution for creating more personalized, adaptive, and engaging conversational agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2504.03206.pdf"
      }
    },
    "figueira2025comprehensive": {
      "citation_key": "figueira2025comprehensive",
      "title": "A comprehensive study on radial velocity signals using ESPRESSO: Pushing precision to the 10 cm/s level",
      "authors": [
        "P. Figueira",
        "J. P. Faria",
        "A. M. Silva",
        "A. Castro-González",
        "J. Gomes da Silva",
        "S. G. Sousa",
        "D. Bossini",
        "M. R. Zapatero-Osorio",
        "O. Balsalobre-Ruza",
        "J. Lillo-Box",
        "H. M. Tabernero",
        "V. Adibekyan",
        "R. Allart",
        "S. Benatti",
        "F. Bouchy",
        "A. Cabral",
        "S. Cristiani",
        "X. Dumusque",
        "J. I. González-Hernández",
        "N. Hara",
        "G. Lo Curto",
        "C. Lovis",
        "A. Mehner",
        "P. Molaro",
        "F. Pepe",
        "N. C. Santos",
        "D. Ségransan",
        "D. Sosnowska",
        "R. Rebolo",
        "A. Suárez Mascareño",
        "A. Sozzetti",
        "S. Udry",
        "B. Wehbe"
      ],
      "year": 2025,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2507.07514v1",
      "pdf_path": "data/pdfs/figueira2025comprehensive.pdf",
      "added_date": "2025-12-12T11:49:31.533325",
      "abstract": "We analyse ESPRESSO data for the stars HD10700, HD20794, HD102365, and HD304636 acquired via its Guaranteed Time Observations (GTO) programme. We characterise the stars' radial velocity (RV) signals down to a precision of 10 cm/s on timescales ranging from minutes to planetary periods falling within the host's habitable zone (HZ). We study the RV signature of pulsation, granulation, and stellar activity, inferring the potential presence of planets around these stars. Thus, we outline the population of planets that while undetectable remain compatible with the available data.   A simple model of stellar pulsations successfully reproduced the intra-night RV scatter of HD10700 down to a few cm/s. For HD102365 and HD20794, an additional source of scatter at the level of several 10 cm/s remains necessary to explain the data. A kima analysis was used to evaluate the number of planets supported by the nightly averaged time series of each of HD10700, HD102365, and HD304636, under the assumption that a quasi-periodic Gaussian process (GP) regression is able to model the activity signal. While a frequency analysis of HD10700 RVs is able to identify a periodic signal at 20d, when it is modelled along with the activity signal the signal is formally non-significant. ESPRESSO data on their own do not provide conclusive evidence for the existence of planets around these three stars.   ESPRESSO is shown to reach an on-sky RV precision of better than 10 cm/s on short timescales (<1h) and of 40 cm/s over 3.5 yr. A subdivision of the datasets showcases a precision reaching 20-30 cm/s over one year. These results impose stringent constraints on the impact of granulation mechanisms on RV. In spite of no detections, our analysis of HD10700 RVs demonstrates a sensitivity to planets with a mass of 1.7M$_{\\oplus}$ for periods of up to 100 d, and a mass of 2-5M$_{\\oplus}$ for the star's HZ. (abridged)",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2507.07514.pdf"
      }
    },
    "laar2023realising": {
      "citation_key": "laar2023realising",
      "title": "Realising Synthetic Active Inference Agents, Part II: Variational Message Updates",
      "authors": [
        "Thijs van de Laar",
        "Magnus Koudahl",
        "Bert de Vries"
      ],
      "year": 2023,
      "doi": "10.1162/neco_a_01713",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2306.02733v3",
      "pdf_path": "data/pdfs/laar2023realising.pdf",
      "added_date": "2025-12-12T11:49:31.537939",
      "abstract": "The Free Energy Principle (FEP) describes (biological) agents as minimising a variational Free Energy (FE) with respect to a generative model of their environment. Active Inference (AIF) is a corollary of the FEP that describes how agents explore and exploit their environment by minimising an expected FE objective. In two related papers, we describe a scalable, epistemic approach to synthetic AIF, by message passing on free-form Forney-style Factor Graphs (FFGs). A companion paper (part I) introduces a Constrained FFG (CFFG) notation that visually represents (generalised) FE objectives for AIF. The current paper (part II) derives message passing algorithms that minimise (generalised) FE objectives on a CFFG by variational calculus. A comparison between simulated Bethe and generalised FE agents illustrates how the message passing approach to synthetic AIF induces epistemic behaviour on a T-maze navigation task. Extension of the T-maze simulation to 1) learning goal statistics, and 2) a multi-agent bargaining setting, illustrate how this approach encourages reuse of nodes and updates in alternative settings. With a full message passing account of synthetic AIF agents, it becomes possible to derive and reuse message updates across models and move closer to industrial applications of synthetic AIF.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2306.02733.pdf"
      }
    },
    "yanagisawa2023modeling": {
      "citation_key": "yanagisawa2023modeling",
      "title": "Modeling arousal potential of epistemic emotions using Bayesian information gain: Inquiry cycle driven by free energy fluctuations",
      "authors": [
        "Hideyoshi Yanagisawa",
        "Shimon Honda"
      ],
      "year": 2023,
      "doi": "10.3389/fpsyg.2025.1438080",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2401.00007v1",
      "pdf_path": "data/pdfs/yanagisawa2023modeling.pdf",
      "added_date": "2025-12-12T11:49:31.541212",
      "abstract": "Epistemic emotions, such as curiosity and interest, drive the inquiry process. This study proposes a novel formulation of epistemic emotions such as curiosity and interest using two types of information gain generated by the principle of free energy minimization: Kullback-Leibler divergence(KLD) from Bayesian posterior to prior, which represents free energy reduction in recognition, and Bayesian surprise (BS), which represents the expected information gain by Bayesian prior update. By applying a Gaussian generative model with an additional uniform likelihood, we found that KLD and BS form an upward-convex function of surprise (minimized free energy and prediction error), similar to Berlyne's arousal potential functions, or the Wundt curve. We consider that the alternate maximization of BS and KLD generates an ideal inquiry cycle to approach the optimal arousal level with fluctuations in surprise, and that curiosity and interest drive to facilitate the cyclic process. We exhaustively analyzed the effects of prediction uncertainty (prior variance) and observation uncertainty (likelihood variance) on the peaks of the information gain function as optimal surprises. The results show that greater prediction uncertainty, meaning an open-minded attitude, and less observational uncertainty, meaning precise observation with attention, are expected to provide greater information gains through a greater range of exploration. The proposed mathematical framework unifies the free energy principle of the brain and the arousal potential theory to explain the Wundt curve as an information gain function and suggests an ideal inquiry process driven by epistemic emotions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2401.00007.pdf"
      }
    },
    "priorelli2023modeling": {
      "citation_key": "priorelli2023modeling",
      "title": "Modeling motor control in continuous-time Active Inference: a survey",
      "authors": [
        "Matteo Priorelli",
        "Federico Maggiore",
        "Antonella Maselli",
        "Francesco Donnarumma",
        "Domenico Maisto",
        "Francesco Mannella",
        "Ivilin Peev Stoianov",
        "Giovanni Pezzulo"
      ],
      "year": 2023,
      "doi": "10.1109/TCDS.2023.3338491",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2310.05144v1",
      "pdf_path": "data/pdfs/priorelli2023modeling.pdf",
      "added_date": "2025-12-12T11:49:31.545381",
      "abstract": "The way the brain selects and controls actions is still widely debated. Mainstream approaches based on Optimal Control focus on stimulus-response mappings that optimize cost functions. Ideomotor theory and cybernetics propose a different perspective: they suggest that actions are selected and controlled by activating action effects and by continuously matching internal predictions with sensations. Active Inference offers a modern formulation of these ideas, in terms of inferential mechanisms and prediction-error-based control, which can be linked to neural mechanisms of living organisms. This article provides a technical illustration of Active Inference models in continuous time and a brief survey of Active Inference models that solve four kinds of control problems; namely, the control of goal-directed reaching movements, active sensing, the resolution of multisensory conflict during movement and the integration of decision-making and motor control. Crucially, in Active Inference, all these different facets of motor control emerge from the same optimization process - namely, the minimization of Free Energy - and do not require designing separate cost functions. Therefore, Active Inference provides a unitary perspective on various aspects of motor control that can inform both the study of biological control mechanisms and the design of artificial and robotic systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2310.05144.pdf"
      }
    },
    "paul2023efficient": {
      "citation_key": "paul2023efficient",
      "title": "On efficient computation in active inference",
      "authors": [
        "Aswin Paul",
        "Noor Sajid",
        "Lancelot Da Costa",
        "Adeel Razi"
      ],
      "year": 2023,
      "doi": "10.1016/j.eswa.2024.124315",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2307.00504v1",
      "pdf_path": "data/pdfs/paul2023efficient.pdf",
      "added_date": "2025-12-12T11:49:31.548838",
      "abstract": "Despite being recognized as neurobiologically plausible, active inference faces difficulties when employed to simulate intelligent behaviour in complex environments due to its computational cost and the difficulty of specifying an appropriate target distribution for the agent. This paper introduces two solutions that work in concert to address these limitations. First, we present a novel planning algorithm for finite temporal horizons with drastically lower computational complexity. Second, inspired by Z-learning from control theory literature, we simplify the process of setting an appropriate target distribution for new and existing active inference planning schemes. Our first approach leverages the dynamic programming algorithm, known for its computational efficiency, to minimize the cost function used in planning through the Bellman-optimality principle. Accordingly, our algorithm recursively assesses the expected free energy of actions in the reverse temporal order. This improves computational efficiency by orders of magnitude and allows precise model learning and planning, even under uncertain conditions. Our method simplifies the planning process and shows meaningful behaviour even when specifying only the agent's final goal state. The proposed solutions make defining a target distribution from a goal state straightforward compared to the more complicated task of defining a temporally informed target distribution. The effectiveness of these methods is tested and demonstrated through simulations in standard grid-world tasks. These advances create new opportunities for various applications.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2307.00504.pdf"
      }
    },
    "ferraro2023symmetry": {
      "citation_key": "ferraro2023symmetry",
      "title": "Symmetry and Complexity in Object-Centric Deep Active Inference Models",
      "authors": [
        "Stefano Ferraro",
        "Toon Van de Maele",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2023,
      "doi": "10.1098/rsfs.2022.0077",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2304.14493v1",
      "pdf_path": "data/pdfs/ferraro2023symmetry.pdf",
      "added_date": "2025-12-12T11:49:31.552718",
      "abstract": "Humans perceive and interact with hundreds of objects every day. In doing so, they need to employ mental models of these objects and often exploit symmetries in the object's shape and appearance in order to learn generalizable and transferable skills. Active inference is a first principles approach to understanding and modeling sentient agents. It states that agents entertain a generative model of their environment, and learn and act by minimizing an upper bound on their surprisal, i.e. their Free Energy. The Free Energy decomposes into an accuracy and complexity term, meaning that agents favor the least complex model, that can accurately explain their sensory observations. In this paper, we investigate how inherent symmetries of particular objects also emerge as symmetries in the latent state space of the generative model learnt under deep active inference. In particular, we focus on object-centric representations, which are trained from pixels to predict novel object views as the agent moves its viewpoint. First, we investigate the relation between model complexity and symmetry exploitation in the state space. Second, we do a principal component analysis to demonstrate how the model encodes the principal axis of symmetry of the object in the latent space. Finally, we also demonstrate how more symmetrical representations can be exploited for better generalization in the context of manipulation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2304.14493.pdf"
      }
    },
    "zhang2023multimodal": {
      "citation_key": "zhang2023multimodal",
      "title": "Multi-Modal MPPI and Active Inference for Reactive Task and Motion Planning",
      "authors": [
        "Yuezhe Zhang",
        "Corrado Pezzato",
        "Elia Trevisan",
        "Chadi Salmi",
        "Carlos Hernández Corbato",
        "Javier Alonso-Mora"
      ],
      "year": 2023,
      "doi": "10.1109/LRA.2024.3426183",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2312.02328v2",
      "pdf_path": "data/pdfs/zhang2023multimodal.pdf",
      "added_date": "2025-12-12T11:49:31.556059",
      "abstract": "Task and Motion Planning (TAMP) has made strides in complex manipulation tasks, yet the execution robustness of the planned solutions remains overlooked. In this work, we propose a method for reactive TAMP to cope with runtime uncertainties and disturbances. We combine an Active Inference planner (AIP) for adaptive high-level action selection and a novel Multi-Modal Model Predictive Path Integral controller (M3P2I) for low-level control. This results in a scheme that simultaneously adapts both high-level actions and low-level motions. The AIP generates alternative symbolic plans, each linked to a cost function for M3P2I. The latter employs a physics simulator for diverse trajectory rollouts, deriving optimal control by weighing the different samples according to their cost. This idea enables blending different robot skills for fluid and reactive plan execution, accommodating plan adjustments at both the high and low levels to cope, for instance, with dynamic obstacles or disturbances that invalidate the current plan. We have tested our approach in simulations and real-world scenarios.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2312.02328.pdf"
      }
    },
    "tinguy2023spatial": {
      "citation_key": "tinguy2023spatial",
      "title": "Spatial and Temporal Hierarchy for Autonomous Navigation using Active Inference in Minigrid Environment",
      "authors": [
        "Daria de Tinguy",
        "Toon van de Maele",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2023,
      "doi": "10.3390/e26010083",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2312.05058v3",
      "pdf_path": "data/pdfs/tinguy2023spatial.pdf",
      "added_date": "2025-12-12T11:49:31.560173",
      "abstract": "Robust evidence suggests that humans explore their environment using a combination of topological landmarks and coarse-grained path integration. This approach relies on identifiable environmental features (topological landmarks) in tandem with estimations of distance and direction (coarse-grained path integration) to construct cognitive maps of the surroundings. This cognitive map is believed to exhibit a hierarchical structure, allowing efficient planning when solving complex navigation tasks. Inspired by human behaviour, this paper presents a scalable hierarchical active inference model for autonomous navigation, exploration, and goal-oriented behaviour. The model uses visual observation and motion perception to combine curiosity-driven exploration with goal-oriented behaviour. Motion is planned using different levels of reasoning, i.e., from context to place to motion. This allows for efficient navigation in new spaces and rapid progress toward a target. By incorporating these human navigational strategies and their hierarchical representation of the environment, this model proposes a new solution for autonomous navigation and exploration. The approach is validated through simulations in a mini-grid environment.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2312.05058.pdf"
      }
    },
    "sedlak2023equilibrium": {
      "citation_key": "sedlak2023equilibrium",
      "title": "Equilibrium in the Computing Continuum through Active Inference",
      "authors": [
        "Boris Sedlak",
        "Victor Casamayor Pujol",
        "Praveen Kumar Donta",
        "Schahram Dustdar"
      ],
      "year": 2023,
      "doi": "10.1016/j.future.2024.05.056",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2311.16769v1",
      "pdf_path": "data/pdfs/sedlak2023equilibrium.pdf",
      "added_date": "2025-12-12T11:49:31.564114",
      "abstract": "Computing Continuum (CC) systems are challenged to ensure the intricate requirements of each computational tier. Given the system's scale, the Service Level Objectives (SLOs) which are expressed as these requirements, must be broken down into smaller parts that can be decentralized. We present our framework for collaborative edge intelligence enabling individual edge devices to (1) develop a causal understanding of how to enforce their SLOs, and (2) transfer knowledge to speed up the onboarding of heterogeneous devices. Through collaboration, they (3) increase the scope of SLO fulfillment. We implemented the framework and evaluated a use case in which a CC system is responsible for ensuring Quality of Service (QoS) and Quality of Experience (QoE) during video streaming. Our results showed that edge devices required only ten training rounds to ensure four SLOs; furthermore, the underlying causal structures were also rationally explainable. The addition of new types of devices can be done a posteriori, the framework allowed them to reuse existing models, even though the device type had been unknown. Finally, rebalancing the load within a device cluster allowed individual edge devices to recover their SLO compliance after a network failure from 22% to 89%.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2311.16769.pdf"
      }
    },
    "wakayama2023observationaugmented": {
      "citation_key": "wakayama2023observationaugmented",
      "title": "Observation-Augmented Contextual Multi-Armed Bandits for Robotic Search and Exploration",
      "authors": [
        "Shohei Wakayama",
        "Nisar Ahmed"
      ],
      "year": 2023,
      "doi": "10.1109/LRA.2024.3448133",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2312.12583v2",
      "pdf_path": "data/pdfs/wakayama2023observationaugmented.pdf",
      "added_date": "2025-12-12T11:49:31.568199",
      "abstract": "We introduce a new variant of contextual multi-armed bandits (CMABs) called observation-augmented CMABs (OA-CMABs) wherein a robot uses extra outcome observations from an external information source, e.g. humans. In OA-CMABs, external observations are a function of context features and thus provide evidence on top of observed option outcomes to infer hidden parameters. However, if external data is error-prone, measures must be taken to preserve the correctness of inference. To this end, we derive a robust Bayesian inference process for OA-CMABs based on recently developed probabilistic semantic data association techniques, which handle complex mixture model parameter priors and hybrid discrete-continuous observation likelihoods for semantic external data sources. To cope with combined uncertainties in OA-CMABs, we also derive a new active inference algorithm for optimal option selection based on approximate expected free energy minimization. This generalizes prior work on CMAB active inference by accounting for faulty observations and non-Gaussian distributions. Results for a simulated deep space search site selection problem show that, even if incorrect semantic observations are provided externally, e.g. by scientists, efficient decision-making and robust parameter inference are still achieved in a wide variety of conditions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2312.12583.pdf"
      }
    },
    "heins2023collective": {
      "citation_key": "heins2023collective",
      "title": "Collective behavior from surprise minimization",
      "authors": [
        "Conor Heins",
        "Beren Millidge",
        "Lancelot da Costa",
        "Richard Mann",
        "Karl Friston",
        "Iain Couzin"
      ],
      "year": 2023,
      "doi": "10.1073/pnas.2320239121",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2307.14804v4",
      "pdf_path": "data/pdfs/heins2023collective.pdf",
      "added_date": "2025-12-12T11:49:31.571597",
      "abstract": "Collective motion is ubiquitous in nature; groups of animals, such as fish, birds, and ungulates appear to move as a whole, exhibiting a rich behavioral repertoire that ranges from directed movement to milling to disordered swarming. Typically, such macroscopic patterns arise from decentralized, local interactions among constituent components (e.g., individual fish in a school). Preeminent models of this process describe individuals as self-propelled particles, subject to self-generated motion and 'social forces' such as short-range repulsion and long-range attraction or alignment. However, organisms are not particles; they are probabilistic decision-makers. Here, we introduce an approach to modelling collective behavior based on active inference. This cognitive framework casts behavior as the consequence of a single imperative: to minimize surprise. We demonstrate that many empirically-observed collective phenomena, including cohesion, milling and directed motion, emerge naturally when considering behavior as driven by active Bayesian inference -- without explicitly building behavioral rules or goals into individual agents. Furthermore, we show that active inference can recover and generalize the classical notion of social forces as agents attempt to suppress prediction errors that conflict with their expectations. By exploring the parameter space of the belief-based model, we reveal non-trivial relationships between the individual beliefs and group properties like polarization and the tendency to visit different collective states. We also explore how individual beliefs about uncertainty determine collective decision-making accuracy. Finally, we show how agents can update their generative model over time, resulting in groups that are collectively more sensitive to external fluctuations and encode information more robustly.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2307.14804.pdf"
      }
    },
    "sergeantperthuis2023influence": {
      "citation_key": "sergeantperthuis2023influence",
      "title": "Influence of the Geometry of the world model on Curiosity Based Exploration",
      "authors": [
        "Grégoire Sergeant-Perthuis",
        "Nils Ruet",
        "David Rudrauf",
        "Dimitri Ognibene",
        "Yvain Tisserand"
      ],
      "year": 2023,
      "doi": "10.1007/s00422-024-01001-1",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2304.00188v2",
      "pdf_path": "data/pdfs/sergeantperthuis2023influence.pdf",
      "added_date": "2025-12-12T11:49:31.575047",
      "abstract": "In human spatial awareness, 3-D projective geometry structures information integration and action planning through perspective taking within an internal representation space. The way different perspectives are related and transform a world model defines a specific perception and imagination scheme. In mathematics, such collection of transformations corresponds to a 'group', whose 'actions' characterize the geometry of a space. Imbuing world models with a group structure may capture different agents' spatial awareness and affordance schemes. We used group action as a special class of policies for perspective-dependent control. We explored how such geometric structure impacts agents' behavior, comparing how the Euclidean versus projective groups act on epistemic value in active inference, drive curiosity, and exploration behaviors. We formally demonstrate and simulate how the groups induce distinct behaviors in a simple search task. The projective group's nonlinear magnification of information transformed epistemic value according to the choice of frame, generating behaviors of approach toward an object of interest. The projective group structure within the agent's world model contains the Projective Consciousness Model, which is know to capture key features of consciousness. On the other hand, the Euclidean group had no effect on epistemic value : no action was better than the initial idle state. In structuring a priori an agent's internal representation, we show how geometry can play a key role in information integration and action planning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2304.00188.pdf"
      }
    },
    "friston2023variational": {
      "citation_key": "friston2023variational",
      "title": "A variational synthesis of evolutionary and developmental dynamics",
      "authors": [
        "Karl Friston",
        "Daniel Ari Friedman",
        "Axel Constant",
        "V. Bleu Knight",
        "Thomas Parr",
        "John O. Campbell"
      ],
      "year": 2023,
      "doi": "10.3390/e25070964",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2303.04898v1",
      "pdf_path": "data/pdfs/friston2023variational.pdf",
      "added_date": "2025-12-12T11:49:31.579380",
      "abstract": "This paper introduces a variational formulation of natural selection, paying special attention to the nature of \"things\" and the way that different \"kinds\" of \"things\" are individuated from - and influence - each other. We use the Bayesian mechanics of particular partitions to understand how slow phylogenetic processes constrain - and are constrained by - fast, phenotypic processes. The main result is a formulation of adaptive fitness as a path integral of phenotypic fitness. Paths of least action, at the phenotypic and phylogenetic scales, can then be read as inference and learning processes, respectively. In this view, a phenotype actively infers the state of its econiche under a generative model, whose parameters are learned via natural (bayesian model selection). The ensuing variational synthesis features some unexpected aspects. Perhaps the most notable is that it is not possible to describe or model a population of conspecifics per se. Rather, it is necessary to consider populations - and nested meta-populations - of different natural kinds that influence each other. This paper is limited to a description of the mathematical apparatus and accompanying ideas. Subsequent work will use these methods for simulations and numerical analyses - and identify points of contact with related mathematical formulations of evolution.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2303.04898.pdf"
      }
    },
    "oyama2024modeling": {
      "citation_key": "oyama2024modeling",
      "title": "Modeling Autonomous Shifts Between Focus State and Mind-Wandering Using a Predictive-Coding-Inspired Variational RNN Model",
      "authors": [
        "Henrique Oyama",
        "Jun Tani"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2412.15620v1",
      "pdf_path": "data/pdfs/oyama2024modeling.pdf",
      "added_date": "2025-12-12T11:49:31.587503",
      "abstract": "The current study investigates possible neural mechanisms underling autonomous shifts between focus state and mind-wandering by conducting model simulation experiments. On this purpose, we modeled perception processes of continuous sensory sequences using our previous proposed variational RNN model which was developed based on the free energy principle. The current study extended this model by introducing an adaptation mechanism of a meta-level parameter, referred to as the meta-prior $\\mathbf{w}$, which regulates the complexity term in the free energy. Our simulation experiments demonstrated that autonomous shifts between focused perception and mind-wandering take place when $\\mathbf{w}$ switches between low and high values associated with decrease and increase of the average reconstruction error over the past window. In particular, high $\\mathbf{w}$ prioritized top-down predictions while low $\\mathbf{w}$ emphasized bottom-up sensations. This paper explores how our experiment results align with existing studies and highlights their potential for future research.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2412.15620.pdf"
      }
    },
    "goehle2024dynamics": {
      "citation_key": "goehle2024dynamics",
      "title": "Dynamics of An Information Theoretic Analog of Two Masses on a Spring",
      "authors": [
        "Geoff Goehle",
        "Christopher Griffin"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2407.03074v2",
      "pdf_path": "data/pdfs/goehle2024dynamics.pdf",
      "added_date": "2025-12-12T11:49:31.591022",
      "abstract": "In this short communication we investigate an information theoretic analogue of the classic two masses on spring system, arising from a physical interpretation of Friston's free energy principle in the theory of learning in a system of agents. Using methods from classical mechanics on manifolds, we define a kinetic energy term using the Fisher metric on distributions and a potential energy function defined in terms of stress on the agents' beliefs. The resulting Lagrangian (Hamiltonian) produces a variation of the classic DeGroot dynamics. In the two agent case, the potential function is defined using the Jeffrey's divergence and the resulting dynamics are characterized by a non-linear spring. These dynamics produce trajectories that resemble flows on tori but are shown numerically to produce chaos near the boundary of the space. We then investigate persuasion as an information theoretic control problem where analysis indicates that manipulating peer pressure with a fixed target is a more stable approach to altering an agent's belief than providing a slowly changing belief state that approaches the target.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2407.03074.pdf"
      }
    },
    "dodigcrnkovic2024exploring": {
      "citation_key": "dodigcrnkovic2024exploring",
      "title": "Exploring Cognition through Morphological Info-Computational Framework",
      "authors": [
        "Gordana Dodig-Crnkovic"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2412.00748v1",
      "pdf_path": "data/pdfs/dodigcrnkovic2024exploring.pdf",
      "added_date": "2025-12-12T11:49:31.594848",
      "abstract": "Traditionally, cognition has been considered a uniquely human capability involving perception, memory, learning, reasoning, and problem-solving. However, recent research shows that cognition is a fundamental ability shared by all living beings, from single cells to complex organisms. This chapter takes an info-computational approach (ICON), viewing natural structures as information and the processes of change in these structures as computations. It is a relational framework dependent on the perspective of a cognizing observer/cognizer. Informational structures are properties of the material substrate, and when focusing on the behavior of the substrate, we discuss morphological computing (MC). ICON and MC are complementary perspectives for a cognizer. Information and computation are inseparably connected with cognition. This chapter explores research connecting nature as a computational structure for a cognizer, with morphological computation, morphogenesis, agency, extended cognition, and extended evolutionary synthesis, using examples of the free energy principle and active inference. It introduces theoretical and practical approaches challenging traditional computational models of cognition limited to abstract symbol processing, highlighting the computational capacities inherent in the material substrate (embodiment). Understanding the embodiment of cognition through its morphological computational basis is crucial for biology, evolution, intelligence theory, AI, robotics, and other fields.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2412.00748.pdf"
      }
    },
    "prakki2024active": {
      "citation_key": "prakki2024active",
      "title": "Active Inference for Self-Organizing Multi-LLM Systems: A Bayesian Thermodynamic Approach to Adaptation",
      "authors": [
        "Rithvik Prakki"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2412.10425v3",
      "pdf_path": "data/pdfs/prakki2024active.pdf",
      "added_date": "2025-12-12T11:49:31.598748",
      "abstract": "This paper introduces a novel approach to creating adaptive language agents by integrating active inference with large language models (LLMs). While LLMs demonstrate remarkable capabilities, their reliance on static prompts limits adaptation to new information and changing environments. We address this by implementing an active inference framework that acts as a cognitive layer above an LLM-based agent, dynamically adjusting prompts and search strategies through principled information-seeking behavior. Our framework models the environment using three state factors (prompt, search, and information states) with seven observation modalities capturing quality metrics. By framing the agent's learning through the free energy principle, we enable systematic exploration of prompt combinations and search strategies. Experimental results demonstrate the effectiveness of this approach, with the agent developing accurate models of environment dynamics evidenced by emergent structure in observation matrices. Action selection patterns reveal sophisticated exploration-exploitation behavior, transitioning from initial information-gathering to targeted prompt testing. The integration of thermodynamic principles with language model capabilities provides a principled framework for creating robust, adaptable agents, extending active inference beyond traditional low-dimensional control problems to high-dimensional, language-driven environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2412.10425.pdf"
      }
    },
    "costa2024active": {
      "citation_key": "costa2024active",
      "title": "Active Inference as a Model of Agency",
      "authors": [
        "Lancelot Da Costa",
        "Samuel Tenka",
        "Dominic Zhao",
        "Noor Sajid"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2401.12917v1",
      "pdf_path": "data/pdfs/costa2024active.pdf",
      "added_date": "2025-12-12T11:49:31.603047",
      "abstract": "Is there a canonical way to think of agency beyond reward maximisation? In this paper, we show that any type of behaviour complying with physically sound assumptions about how macroscopic biological agents interact with the world canonically integrates exploration and exploitation in the sense of minimising risk and ambiguity about states of the world. This description, known as active inference, refines the free energy principle, a popular descriptive framework for action and perception originating in neuroscience. Active inference provides a normative Bayesian framework to simulate and model agency that is widely used in behavioural neuroscience, reinforcement learning (RL) and robotics. The usefulness of active inference for RL is three-fold. \\emph{a}) Active inference provides a principled solution to the exploration-exploitation dilemma that usefully simulates biological agency. \\emph{b}) It provides an explainable recipe to simulate behaviour, whence behaviour follows as an explainable mixture of exploration and exploitation under a generative world model, and all differences in behaviour are explicit in differences in world model. \\emph{c}) This framework is universal in the sense that it is theoretically possible to rewrite any RL algorithm conforming to the descriptive assumptions of active inference as an active inference algorithm. Thus, active inference can be used as a tool to uncover and compare the commitments and assumptions of more specific models of agency.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2401.12917.pdf"
      }
    },
    "friston2024framework": {
      "citation_key": "friston2024framework",
      "title": "A framework for the use of generative modelling in non-equilibrium statistical mechanics",
      "authors": [
        "Karl J Friston",
        "Maxwell J D Ramstead",
        "Dalton A R Sakthivadivel"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.11630v4",
      "pdf_path": "data/pdfs/friston2024framework.pdf",
      "added_date": "2025-12-12T11:49:31.606546",
      "abstract": "We discuss an approach to mathematically modelling systems made of objects that are coupled together, using generative models of the dependence relationships between states (or trajectories) of the things comprising such systems. This broad class includes open or non-equilibrium systems and is especially relevant to self-organising systems. The ensuing variational free energy principle (FEP) has certain advantages over using random dynamical systems explicitly, notably, by being more tractable and offering a parsimonious explanation of why the joint system evolves in the way that it does, based on the properties of the coupling between system components. The FEP is a method whose use allows us to build a model of the dynamics of an object as if it were a process of variational inference, because variational free energy (or surprisal) is a Lyapunov function for its dynamics. In short, we argue that using generative models to represent and track relations amongst subsystems leads us to a particular statistical theory of interacting systems. Conversely, this theory enables us to construct nested models that respect the known relations amongst subsystems. We point out that the fact that a physical object conforms to the FEP does not necessarily imply that this object performs inference in the literal sense; rather, it is a useful explanatory fiction which replaces the `explicit' dynamics of the object with an `implicit' flow on free energy gradients -- a fiction that may or may not be entertained by the object itself.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.11630.pdf"
      }
    },
    "pazem2024free": {
      "citation_key": "pazem2024free",
      "title": "Free Energy Projective Simulation (FEPS): Active inference with interpretability",
      "authors": [
        "Joséphine Pazem",
        "Marius Krumm",
        "Alexander Q. Vining",
        "Lukas J. Fiderer",
        "Hans J. Briegel"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2411.14991v1",
      "pdf_path": "data/pdfs/pazem2024free.pdf",
      "added_date": "2025-12-12T11:49:31.610805",
      "abstract": "In the last decade, the free energy principle (FEP) and active inference (AIF) have achieved many successes connecting conceptual models of learning and cognition to mathematical models of perception and action. This effort is driven by a multidisciplinary interest in understanding aspects of self-organizing complex adaptive systems, including elements of agency. Various reinforcement learning (RL) models performing active inference have been proposed and trained on standard RL tasks using deep neural networks. Recent work has focused on improving such agents' performance in complex environments by incorporating the latest machine learning techniques. In this paper, we take an alternative approach. Within the constraints imposed by the FEP and AIF, we attempt to model agents in an interpretable way without deep neural networks by introducing Free Energy Projective Simulation (FEPS). Using internal rewards only, FEPS agents build a representation of their partially observable environments with which they interact. Following AIF, the policy to achieve a given task is derived from this world model by minimizing the expected free energy. Leveraging the interpretability of the model, techniques are introduced to deal with long-term goals and reduce prediction errors caused by erroneous hidden state estimation. We test the FEPS model on two RL environments inspired from behavioral biology: a timed response task and a navigation task in a partially observable grid. Our results show that FEPS agents fully resolve the ambiguity of both environments by appropriately contextualizing their observations based on prediction accuracy only. In addition, they infer optimal policies flexibly for any target observation in the environment.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2411.14991.pdf"
      }
    },
    "gambetta2024learning": {
      "citation_key": "gambetta2024learning",
      "title": "Learning by Surprise: Surplexity for Mitigating Model Collapse in Generative AI",
      "authors": [
        "Daniele Gambetta",
        "Gizem Gezici",
        "Fosca Giannotti",
        "Dino Pedreschi",
        "Alistair Knott",
        "Luca Pappalardo"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.12341v3",
      "pdf_path": "data/pdfs/gambetta2024learning.pdf",
      "added_date": "2025-12-12T11:49:31.614850",
      "abstract": "As synthetic content increasingly infiltrates the web, generative AI models may be retrained on their own outputs: a process termed \"autophagy\". This leads to model collapse: a progressive loss of performance and diversity across generations. Recent studies have examined the emergence of model collapse across various generative AI models and data types, and have proposed mitigation strategies that rely on incorporating human-authored content. However, current characterizations of model collapse remain limited, and existing mitigation methods assume reliable knowledge of whether training data is human-authored or AI-generated. In this paper, we address these gaps by introducing new measures that characterise collapse directly from a model's next-token probability distributions, rather than from properties of AI-generated text. Using these measures, we show that the degree of collapse depends on the complexity of the initial training set, as well as on the extent of autophagy. Our experiments prompt a new suggestion: that model collapse occurs when a model trains on data that does not \"surprise\" it. We express this hypothesis in terms of the well-known Free Energy Principle in cognitive science. Building on this insight, we propose a practical mitigation strategy: filtering training items by high surplexity, maximising the surprise of the model. Unlike existing methods, this approach does not require distinguishing between human- and AI-generated data. Experiments across datasets and models demonstrate that our strategy is at least as effective as human-data baselines, and even more effective in reducing distributional skewedness. Our results provide a richer understanding of model collapse and point toward more resilient approaches for training generative AI systems in environments increasingly saturated with synthetic data.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.12341.pdf"
      }
    },
    "weinstein2024internal": {
      "citation_key": "weinstein2024internal",
      "title": "An Internal Model Principle For Robots",
      "authors": [
        "Vadim K. Weinstein",
        "Tamara Alshammari",
        "Kalle G. Timperi",
        "Mehdi Bennis",
        "Steven M. LaValle"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.11237v1",
      "pdf_path": "data/pdfs/weinstein2024internal.pdf",
      "added_date": "2025-12-12T11:49:31.618969",
      "abstract": "When designing a robot's internal system, one often makes assumptions about the structure of the intended environment of the robot. One may even assign meaning to various internal components of the robot in terms of expected environmental correlates. In this paper we want to make the distinction between robot's internal and external worlds clear-cut. Can the robot learn about its environment, relying only on internally available information, including the sensor data? Are there mathematical conditions on the internal robot system which can be internally verified and make the robot's internal system mirror the structure of the environment? We prove that sufficiency is such a mathematical principle, and mathematically describe the emergence of the robot's internal structure isomorphic or bisimulation equivalent to that of the environment. A connection to the free-energy principle is established, when sufficiency is interpreted as a limit case of surprise minimization. As such, we show that surprise minimization leads to having an internal model isomorphic to the environment. This also parallels the Good Regulator Principle which states that controlling a system sufficiently well means having a model of it. Unlike the mentioned theories, ours is discrete, and non-probabilistic.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.11237.pdf"
      }
    },
    "vijayaraghavan2024development": {
      "citation_key": "vijayaraghavan2024development",
      "title": "Development of Compositionality and Generalization through Interactive Learning of Language and Action of Robots",
      "authors": [
        "Prasanna Vijayaraghavan",
        "Jeffrey Frederic Queisser",
        "Sergio Verduzco Flores",
        "Jun Tani"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2403.19995v2",
      "pdf_path": "data/pdfs/vijayaraghavan2024development.pdf",
      "added_date": "2025-12-12T11:49:31.622529",
      "abstract": "Humans excel at applying learned behavior to unlearned situations. A crucial component of this generalization behavior is our ability to compose/decompose a whole into reusable parts, an attribute known as compositionality. One of the fundamental questions in robotics concerns this characteristic. \"How can linguistic compositionality be developed concomitantly with sensorimotor skills through associative learning, particularly when individuals only learn partial linguistic compositions and their corresponding sensorimotor patterns?\" To address this question, we propose a brain-inspired neural network model that integrates vision, proprioception, and language into a framework of predictive coding and active inference, based on the free-energy principle. The effectiveness and capabilities of this model were assessed through various simulation experiments conducted with a robot arm. Our results show that generalization in learning to unlearned verb-noun compositions, is significantly enhanced when training variations of task composition are increased. We attribute this to self-organized compositional structures in linguistic latent state space being influenced significantly by sensorimotor learning. Ablation studies show that visual attention and working memory are essential to accurately generate visuo-motor sequences to achieve linguistically represented goals. These insights advance our understanding of mechanisms underlying development of compositionality through interactions of linguistic and sensorimotor experience.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2403.19995.pdf"
      }
    },
    "collis2024learning": {
      "citation_key": "collis2024learning",
      "title": "Learning in Hybrid Active Inference Models",
      "authors": [
        "Poppy Collis",
        "Ryan Singh",
        "Paul F Kinghorn",
        "Christopher L Buckley"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2409.01066v1",
      "pdf_path": "data/pdfs/collis2024learning.pdf",
      "added_date": "2025-12-12T11:49:31.626804",
      "abstract": "An open problem in artificial intelligence is how systems can flexibly learn discrete abstractions that are useful for solving inherently continuous problems. Previous work in computational neuroscience has considered this functional integration of discrete and continuous variables during decision-making under the formalism of active inference (Parr, Friston & de Vries, 2017; Parr & Friston, 2018). However, their focus is on the expressive physical implementation of categorical decisions and the hierarchical mixed generative model is assumed to be known. As a consequence, it is unclear how this framework might be extended to learning. We therefore present a novel hierarchical hybrid active inference agent in which a high-level discrete active inference planner sits above a low-level continuous active inference controller. We make use of recent work in recurrent switching linear dynamical systems (rSLDS) which implement end-to-end learning of meaningful discrete representations via the piecewise linear decomposition of complex continuous dynamics (Linderman et al., 2016). The representations learned by the rSLDS inform the structure of the hybrid decision-making agent and allow us to (1) specify temporally-abstracted sub-goals in a method reminiscent of the options framework, (2) lift the exploration into discrete space allowing us to exploit information-theoretic exploration bonuses and (3) `cache' the approximate solutions to low-level problems in the discrete planner. We apply our model to the sparse Continuous Mountain Car task, demonstrating fast system identification via enhanced exploration and successful planning through the delineation of abstract sub-goals.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2409.01066.pdf"
      }
    },
    "nisslbeck2024coupled": {
      "citation_key": "nisslbeck2024coupled",
      "title": "Coupled autoregressive active inference agents for control of multi-joint dynamical systems",
      "authors": [
        "Tim N. Nisslbeck",
        "Wouter M. Kouw"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.10415v1",
      "pdf_path": "data/pdfs/nisslbeck2024coupled.pdf",
      "added_date": "2025-12-12T11:49:31.630762",
      "abstract": "We propose an active inference agent to identify and control a mechanical system with multiple bodies connected by joints. This agent is constructed from multiple scalar autoregressive model-based agents, coupled together by virtue of sharing memories. Each subagent infers parameters through Bayesian filtering and controls by minimizing expected free energy over a finite time horizon. We demonstrate that a coupled agent of this kind is able to learn the dynamics of a double mass-spring-damper system, and drive it to a desired position through a balance of explorative and exploitative actions. It outperforms the uncoupled subagents in terms of surprise and goal alignment.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.10415.pdf"
      }
    },
    "kouw2024planning": {
      "citation_key": "kouw2024planning",
      "title": "Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents",
      "authors": [
        "Wouter M. Kouw"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2409.01974v2",
      "pdf_path": "data/pdfs/kouw2024planning.pdf",
      "added_date": "2025-12-12T11:49:31.634771",
      "abstract": "In nature, active inference agents must learn how observations of the world represent the state of the agent. In engineering, the physics behind sensors is often known reasonably accurately and measurement functions can be incorporated into generative models. When a measurement function is non-linear, the transformed variable is typically approximated with a Gaussian distribution to ensure tractable inference. We show that Gaussian approximations that are sensitive to the curvature of the measurement function, such as a second-order Taylor approximation, produce a state-dependent ambiguity term. This induces a preference over states, based on how accurately the state can be inferred from the observation. We demonstrate this preference with a robot navigation experiment where agents plan trajectories.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2409.01974.pdf"
      }
    },
    "murraysmith2024active": {
      "citation_key": "murraysmith2024active",
      "title": "Active Inference and Human--Computer Interaction",
      "authors": [
        "Roderick Murray-Smith",
        "John H. Williamson",
        "Sebastian Stein"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2412.14741v1",
      "pdf_path": "data/pdfs/murraysmith2024active.pdf",
      "added_date": "2025-12-12T11:49:31.638769",
      "abstract": "Active Inference is a closed-loop computational theoretical basis for understanding behaviour, based on agents with internal probabilistic generative models that encode their beliefs about how hidden states in their environment cause their sensations. We review Active Inference and how it could be applied to model the human-computer interaction loop. Active Inference provides a coherent framework for managing generative models of humans, their environments, sensors and interface components. It informs off-line design and supports real-time, online adaptation. It provides model-based explanations for behaviours observed in HCI, and new tools to measure important concepts such as agency and engagement. We discuss how Active Inference offers a new basis for a theory of interaction in HCI, tools for design of modern, complex sensor-based systems, and integration of artificial intelligence technologies, enabling it to cope with diversity in human users and contexts. We discuss the practical challenges in implementing such Active Inference-based systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2412.14741.pdf"
      }
    },
    "dehouche2024enhancing": {
      "citation_key": "dehouche2024enhancing",
      "title": "Enhancing Population-based Search with Active Inference",
      "authors": [
        "Nassim Dehouche",
        "Daniel Friedman"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2408.09548v1",
      "pdf_path": "data/pdfs/dehouche2024enhancing.pdf",
      "added_date": "2025-12-12T11:49:31.642933",
      "abstract": "The Active Inference framework models perception and action as a unified process, where agents use probabilistic models to predict and actively minimize sensory discrepancies. In complement and contrast, traditional population-based metaheuristics rely on reactive environmental interactions without anticipatory adaptation. This paper proposes the integration of Active Inference into these metaheuristics to enhance performance through anticipatory environmental adaptation. We demonstrate this approach specifically with Ant Colony Optimization (ACO) on the Travelling Salesman Problem (TSP). Experimental results indicate that Active Inference can yield some improved solutions with only a marginal increase in computational cost, with interesting patterns of performance that relate to number and topology of nodes in the graph. Further work will characterize where and when different types of Active Inference augmentation of population metaheuristics may be efficacious.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2408.09548.pdf"
      }
    },
    "smithe2024structured": {
      "citation_key": "smithe2024structured",
      "title": "Structured Active Inference (Extended Abstract)",
      "authors": [
        "Toby St Clere Smithe"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.07577v1",
      "pdf_path": "data/pdfs/smithe2024structured.pdf",
      "added_date": "2025-12-12T11:49:31.646925",
      "abstract": "We introduce structured active inference, a large generalization and formalization of active inference using the tools of categorical systems theory. We cast generative models formally as systems \"on an interface\", with the latter being a compositional abstraction of the usual notion of Markov blanket; agents are then 'controllers' for their generative models, formally dual to them. This opens the active inference landscape to new horizons, such as: agents with structured interfaces (e.g. with 'mode-dependence', or that interact with computer APIs); agents that can manage other agents; and 'meta-agents', that use active inference to change their (internal or external) structure. With structured interfaces, we also gain structured ('typed') policies, which are amenable to formal verification, an important step towards safe artificial agents. Moreover, we can make use of categorical logic to describe express agents' goals as formal predicates, whose satisfaction may be dependent on the interaction context. This points towards powerful compositional tools to constrain and control self-organizing ensembles of agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.07577.pdf"
      }
    },
    "priorelli2024dynamic": {
      "citation_key": "priorelli2024dynamic",
      "title": "Dynamic planning in hierarchical active inference",
      "authors": [
        "Matteo Priorelli",
        "Ivilin Peev Stoianov"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2402.11658v3",
      "pdf_path": "data/pdfs/priorelli2024dynamic.pdf",
      "added_date": "2025-12-12T11:49:31.651230",
      "abstract": "By dynamic planning, we refer to the ability of the human brain to infer and impose motor trajectories related to cognitive decisions. A recent paradigm, active inference, brings fundamental insights into the adaptation of biological organisms, constantly striving to minimize prediction errors to restrict themselves to life-compatible states. Over the past years, many studies have shown how human and animal behaviors could be explained in terms of active inference - either as discrete decision-making or continuous motor control - inspiring innovative solutions in robotics and artificial intelligence. Still, the literature lacks a comprehensive outlook on effectively planning realistic actions in changing environments. Setting ourselves the goal of modeling complex tasks such as tool use, we delve into the topic of dynamic planning in active inference, keeping in mind two crucial aspects of biological behavior: the capacity to understand and exploit affordances for object manipulation, and to learn the hierarchical interactions between the self and the environment, including other agents. We start from a simple unit and gradually describe more advanced structures, comparing recently proposed design choices and providing basic examples. This study distances itself from traditional views centered on neural networks and reinforcement learning, and points toward a yet unexplored direction in active inference: hybrid representations in hierarchical models.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2402.11658.pdf"
      }
    },
    "esaki2024environmentcentric": {
      "citation_key": "esaki2024environmentcentric",
      "title": "Environment-Centric Active Inference",
      "authors": [
        "Kanako Esaki",
        "Tadayuki Matsumura",
        "Takeshi Kato",
        "Shunsuke Minusa",
        "Yang Shao",
        "Hiroyuki Mizuno"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2408.12777v1",
      "pdf_path": "data/pdfs/esaki2024environmentcentric.pdf",
      "added_date": "2025-12-12T11:49:31.655424",
      "abstract": "To handle unintended changes in the environment by agents, we propose an environment-centric active inference EC-AIF in which the Markov Blanket of active inference is defined starting from the environment. In normal active inference, the Markov Blanket is defined starting from the agent. That is, first the agent was defined as the entity that performs the \"action\" such as a robot or a person, then the environment was defined as other people or objects that are directly affected by the agent's \"action,\" and the boundary between the agent and the environment was defined as the Markov Blanket. This agent-centric definition does not allow the agent to respond to unintended changes in the environment caused by factors outside of the defined environment. In the proposed EC-AIF, there is no entity corresponding to an agent. The environment includes all observable things, including people and things conventionally considered to be the environment, as well as entities that perform \"actions\" such as robots and people. Accordingly, all states, including robots and people, are included in inference targets, eliminating unintended changes in the environment. The EC-AIF was applied to a robot arm and validated with an object transport task by the robot arm. The results showed that the robot arm successfully transported objects while responding to changes in the target position of the object and to changes in the orientation of another robot arm.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2408.12777.pdf"
      }
    },
    "albarracin2024modeling": {
      "citation_key": "albarracin2024modeling",
      "title": "Modeling Sustainable Resource Management using Active Inference",
      "authors": [
        "Mahault Albarracin",
        "Ines Hipolito",
        "Maria Raffa",
        "Paul Kinghorn"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.07593v1",
      "pdf_path": "data/pdfs/albarracin2024modeling.pdf",
      "added_date": "2025-12-12T11:49:31.659867",
      "abstract": "Active inference helps us simulate adaptive behavior and decision-making in biological and artificial agents. Building on our previous work exploring the relationship between active inference, well-being, resilience, and sustainability, we present a computational model of an agent learning sustainable resource management strategies in both static and dynamic environments. The agent's behavior emerges from optimizing its own well-being, represented by prior preferences, subject to beliefs about environmental dynamics. In a static environment, the agent learns to consistently consume resources to satisfy its needs. In a dynamic environment where resources deplete and replenish based on the agent's actions, the agent adapts its behavior to balance immediate needs with long-term resource availability. This demonstrates how active inference can give rise to sustainable and resilient behaviors in the face of changing environmental conditions. We discuss the implications of our model, its limitations, and suggest future directions for integrating more complex agent-environment interactions. Our work highlights active inference's potential for understanding and shaping sustainable behaviors.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.07593.pdf"
      }
    },
    "delavari2024towards": {
      "citation_key": "delavari2024towards",
      "title": "Towards Human-Like Driving: Active Inference in Autonomous Vehicle Control",
      "authors": [
        "Elahe Delavari",
        "John Moore",
        "Junho Hong",
        "Jaerock Kwon"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2407.07684v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:31.664024",
      "abstract": "This paper presents a novel approach to Autonomous Vehicle (AV) control through the application of active inference, a theory derived from neuroscience that conceptualizes the brain as a predictive machine. Traditional autonomous driving systems rely heavily on Modular Pipelines, Imitation Learning, or Reinforcement Learning, each with inherent limitations in adaptability, generalization, and computational efficiency. Active inference addresses these challenges by minimizing prediction error (termed \"surprise\") through a dynamic model that balances perception and action. Our method integrates active inference with deep learning to manage lateral control in AVs, enabling them to perform lane following maneuvers within a simulated urban environment. We demonstrate that our model, despite its simplicity, effectively learns and generalizes from limited data without extensive retraining, significantly reducing computational demands. The proposed approach not only enhances the adaptability and performance of AVs in dynamic scenarios but also aligns closely with human-like driving behavior, leveraging a generative model to predict and adapt to environmental changes. Results from extensive experiments in the CARLA simulator show promising outcomes, outperforming traditional methods in terms of adaptability and efficiency, thereby advancing the potential of active inference in real-world autonomous driving applications.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2407.07684.pdf"
      }
    },
    "whyte2024minimal": {
      "citation_key": "whyte2024minimal",
      "title": "On the Minimal Theory of Consciousness Implicit in Active Inference",
      "authors": [
        "Christopher J. Whyte",
        "Andrew W. Corcoran",
        "Jonathan Robinson",
        "Ryan Smith",
        "Rosalyn J. Moran",
        "Thomas Parr",
        "Karl J. Friston",
        "Anil K. Seth",
        "Jakob Hohwy"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.06633v2",
      "pdf_path": "data/pdfs/whyte2024minimal.pdf",
      "added_date": "2025-12-12T11:49:31.668369",
      "abstract": "The multifaceted nature of subjective experience poses a challenge to the study of consciousness. Traditional neuroscientific approaches often concentrate on isolated facets, such as perceptual awareness or the global state of consciousness and construct a theory around the relevant empirical paradigms and findings. Theories of consciousness are, therefore, often difficult to compare; indeed, there might be little overlap in the phenomena such theories aim to explain. Here, we take a different approach: starting with active inference, a first principles framework for modelling behaviour as (approximate) Bayesian inference, and building up to a minimal theory of consciousness, which emerges from the shared features of computational models derived under active inference. We review a body of work applying active inference models to the study of consciousness and argue that there is implicit in all these models a small set of theoretical commitments that point to a minimal (and testable) theory of consciousness.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.06633.pdf"
      }
    },
    "prakki2024demonstrating": {
      "citation_key": "prakki2024demonstrating",
      "title": "Demonstrating the Continual Learning Capabilities and Practical Application of Discrete-Time Active Inference",
      "authors": [
        "Rithvik Prakki"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.00240v1",
      "pdf_path": "data/pdfs/prakki2024demonstrating.pdf",
      "added_date": "2025-12-12T11:49:31.672360",
      "abstract": "Active inference is a mathematical framework for understanding how agents (biological or artificial) interact with their environments, enabling continual adaptation and decision-making. It combines Bayesian inference and free energy minimization to model perception, action, and learning in uncertain and dynamic contexts. Unlike reinforcement learning, active inference integrates exploration and exploitation seamlessly by minimizing expected free energy. In this paper, we present a continual learning framework for agents operating in discrete time environments, using active inference as the foundation. We derive the mathematical formulations of variational and expected free energy and apply them to the design of a self-learning research agent. This agent updates its beliefs and adapts its actions based on new data without manual intervention. Through experiments in changing environments, we demonstrate the agent's ability to relearn and refine its models efficiently, making it suitable for complex domains like finance and healthcare. The paper concludes by discussing how the proposed framework generalizes to other systems, positioning active inference as a flexible approach for adaptive AI.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.00240.pdf"
      }
    },
    "wei2024value": {
      "citation_key": "wei2024value",
      "title": "Value of Information and Reward Specification in Active Inference and POMDPs",
      "authors": [
        "Ran Wei"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2408.06542v1",
      "pdf_path": "data/pdfs/wei2024value.pdf",
      "added_date": "2025-12-12T11:49:31.676808",
      "abstract": "Expected free energy (EFE) is a central quantity in active inference which has recently gained popularity due to its intuitive decomposition of the expected value of control into a pragmatic and an epistemic component. While numerous conjectures have been made to justify EFE as a decision making objective function, the most widely accepted is still its intuitiveness and resemblance to variational free energy in approximate Bayesian inference. In this work, we take a bottom up approach and ask: taking EFE as given, what's the resulting agent's optimality gap compared with a reward-driven reinforcement learning (RL) agent, which is well understood? By casting EFE under a particular class of belief MDP and using analysis tools from RL theory, we show that EFE approximates the Bayes optimal RL policy via information value. We discuss the implications for objective specification of active inference agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2408.06542.pdf"
      }
    },
    "nuijten2024reactive": {
      "citation_key": "nuijten2024reactive",
      "title": "Reactive Environments for Active Inference Agents with RxEnvironments.jl",
      "authors": [
        "Wouter W. L. Nuijten",
        "Bert de Vries"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2409.11087v1",
      "pdf_path": "data/pdfs/nuijten2024reactive.pdf",
      "added_date": "2025-12-12T11:49:31.680995",
      "abstract": "Active Inference is a framework that emphasizes the interaction between agents and their environment. While the framework has seen significant advancements in the development of agents, the environmental models are often borrowed from reinforcement learning problems, which may not fully capture the complexity of multi-agent interactions or allow complex, conditional communication. This paper introduces Reactive Environments, a comprehensive paradigm that facilitates complex multi-agent communication. In this paradigm, both agents and environments are defined as entities encapsulated by boundaries with interfaces. This setup facilitates a robust framework for communication in nonequilibrium-Steady-State systems, allowing for complex interactions and information exchange. We present a Julia package RxEnvironments.jl, which is a specific implementation of Reactive Environments, where we utilize a Reactive Programming style for efficient implementation. The flexibility of this paradigm is demonstrated through its application to several complex, multi-agent environments. These case studies highlight the potential of Reactive Environments in modeling sophisticated systems of interacting agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2409.11087.pdf"
      }
    },
    "nguyen2024raif": {
      "citation_key": "nguyen2024raif",
      "title": "R-AIF: Solving Sparse-Reward Robotic Tasks from Pixels with Active Inference and World Models",
      "authors": [
        "Viet Dung Nguyen",
        "Zhizhuo Yang",
        "Christopher L. Buckley",
        "Alexander Ororbia"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2409.14216v1",
      "pdf_path": "data/pdfs/nguyen2024raif.pdf",
      "added_date": "2025-12-12T11:49:31.685696",
      "abstract": "Although research has produced promising results demonstrating the utility of active inference (AIF) in Markov decision processes (MDPs), there is relatively less work that builds AIF models in the context of environments and problems that take the form of partially observable Markov decision processes (POMDPs). In POMDP scenarios, the agent must infer the unobserved environmental state from raw sensory observations, e.g., pixels in an image. Additionally, less work exists in examining the most difficult form of POMDP-centered control: continuous action space POMDPs under sparse reward signals. In this work, we address issues facing the AIF modeling paradigm by introducing novel prior preference learning techniques and self-revision schedules to help the agent excel in sparse-reward, continuous action, goal-based robotic control POMDP environments. Empirically, we show that our agents offer improved performance over state-of-the-art models in terms of cumulative rewards, relative stability, and success rate. The code in support of this work can be found at https://github.com/NACLab/robust-active-inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2409.14216.pdf"
      }
    },
    "khan2024surprise": {
      "citation_key": "khan2024surprise",
      "title": "Surprise! Using Physiological Stress for Allostatic Regulation Under the Active Inference Framework [Pre-Print]",
      "authors": [
        "Imran Khan",
        "Robert Lowe"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.08471v1",
      "pdf_path": "data/pdfs/khan2024surprise.pdf",
      "added_date": "2025-12-12T11:49:31.689719",
      "abstract": "Allostasis proposes that long-term viability of a living system is achieved through anticipatory adjustments of its physiology and behaviour: emphasising physiological and affective stress as an adaptive state of adaptation that minimizes long-term prediction errors. More recently, the active inference framework (AIF) has also sought to explain action and long-term adaptation through the minimization of future errors (free energy), through the learning of statistical contingencies of the world, offering a formalism for allostatic regulation. We suggest that framing prediction errors through the lens of biological hormonal dynamics proposed by allostasis offers a way to integrate these two models together in a biologically-plausible manner. In this paper, we describe our initial work in developing a model that grounds prediction errors (surprisal) into the secretion of a physiological stress hormone (cortisol) acting as an adaptive, allostatic mediator on a homeostatically-controlled physiology. We evaluate this using a computational model in simulations using an active inference agent endowed with an artificial physiology, regulated through homeostatic and allostatic control in a stochastic environment. Our results find that allostatic functions of cortisol (stress), secreted as a function of prediction errors, provide adaptive advantages to the agent's long-term physiological regulation. We argue that the coupling of information-theoretic prediction errors to low-level, biological hormonal dynamics of stress can provide a computationally efficient model to long-term regulation for embodied intelligent systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.08471.pdf"
      }
    },
    "friston2024from": {
      "citation_key": "friston2024from",
      "title": "From pixels to planning: scale-free active inference",
      "authors": [
        "Karl Friston",
        "Conor Heins",
        "Tim Verbelen",
        "Lancelot Da Costa",
        "Tommaso Salvatori",
        "Dimitrije Markovic",
        "Alexander Tschantz",
        "Magnus Koudahl",
        "Christopher Buckley",
        "Thomas Parr"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2407.20292v1",
      "pdf_path": "data/pdfs/friston2024from.pdf",
      "added_date": "2025-12-12T11:49:31.694079",
      "abstract": "This paper describes a discrete state-space model -- and accompanying methods -- for generative modelling. This model generalises partially observed Markov decision processes to include paths as latent variables, rendering it suitable for active inference and learning in a dynamic setting. Specifically, we consider deep or hierarchical forms using the renormalisation group. The ensuing renormalising generative models (RGM) can be regarded as discrete homologues of deep convolutional neural networks or continuous state-space models in generalised coordinates of motion. By construction, these scale-invariant models can be used to learn compositionality over space and time, furnishing models of paths or orbits; i.e., events of increasing temporal depth and itinerancy. This technical note illustrates the automatic discovery, learning and deployment of RGMs using a series of applications. We start with image classification and then consider the compression and generation of movies and music. Finally, we apply the same variational principles to the learning of Atari-like games.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2407.20292.pdf"
      }
    },
    "krayani2024selfsupervised": {
      "citation_key": "krayani2024selfsupervised",
      "title": "Self-Supervised Path Planning in UAV-aided Wireless Networks based on Active Inference",
      "authors": [
        "Ali Krayani",
        "Khalid Khan",
        "Lucio Marcenaro",
        "Mario Marchese",
        "Carlo Regazzoni"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2403.13827v1",
      "pdf_path": "data/pdfs/krayani2024selfsupervised.pdf",
      "added_date": "2025-12-12T11:49:31.697829",
      "abstract": "This paper presents a novel self-supervised path-planning method for UAV-aided networks. First, we employed an optimizer to solve training examples offline and then used the resulting solutions as demonstrations from which the UAV can learn the world model to understand the environment and implicitly discover the optimizer's policy. UAV equipped with the world model can make real-time autonomous decisions and engage in online planning using active inference. During planning, UAV can score different policies based on the expected surprise, allowing it to choose among alternative futures. Additionally, UAV can anticipate the outcomes of its actions using the world model and assess the expected surprise in a self-supervised manner. Our method enables quicker adaptation to new situations and better performance than traditional RL, leading to broader generalizability.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2403.13827.pdf"
      }
    },
    "huang2024navigating": {
      "citation_key": "huang2024navigating",
      "title": "Navigating Autonomous Vehicle on Unmarked Roads with Diffusion-Based Motion Prediction and Active Inference",
      "authors": [
        "Yufei Huang",
        "Yulin Li",
        "Andrea Matta",
        "Mohsen Jafari"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.00211v1",
      "pdf_path": "data/pdfs/huang2024navigating.pdf",
      "added_date": "2025-12-12T11:49:31.702553",
      "abstract": "This paper presents a novel approach to improving autonomous vehicle control in environments lacking clear road markings by integrating a diffusion-based motion predictor within an Active Inference Framework (AIF). Using a simulated parking lot environment as a parallel to unmarked roads, we develop and test our model to predict and guide vehicle movements effectively. The diffusion-based motion predictor forecasts vehicle actions by leveraging probabilistic dynamics, while AIF aids in decision-making under uncertainty. Unlike traditional methods such as Model Predictive Control (MPC) and Reinforcement Learning (RL), our approach reduces computational demands and requires less extensive training, enhancing navigation safety and efficiency. Our results demonstrate the model's capability to navigate complex scenarios, marking significant progress in autonomous driving technology.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.00211.pdf"
      }
    },
    "amorese2024online": {
      "citation_key": "amorese2024online",
      "title": "Online Pareto-Optimal Decision-Making for Complex Tasks using Active Inference",
      "authors": [
        "Peter Amorese",
        "Shohei Wakayama",
        "Nisar Ahmed",
        "Morteza Lahijanian"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.11984v1",
      "pdf_path": "data/pdfs/amorese2024online.pdf",
      "added_date": "2025-12-12T11:49:31.710479",
      "abstract": "When a robot autonomously performs a complex task, it frequently must balance competing objectives while maintaining safety. This becomes more difficult in uncertain environments with stochastic outcomes. Enhancing transparency in the robot's behavior and aligning with user preferences are also crucial. This paper introduces a novel framework for multi-objective reinforcement learning that ensures safe task execution, optimizes trade-offs between objectives, and adheres to user preferences. The framework has two main layers: a multi-objective task planner and a high-level selector. The planning layer generates a set of optimal trade-off plans that guarantee satisfaction of a temporal logic task. The selector uses active inference to decide which generated plan best complies with user preferences and aids learning. Operating iteratively, the framework updates a parameterized learning model based on collected data. Case studies and benchmarks on both manipulation and mobile robots show that our framework outperforms other methods and (i) learns multiple optimal trade-offs, (ii) adheres to a user preference, and (iii) allows the user to adjust the balance between (i) and (ii).",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.11984.pdf"
      }
    },
    "ruizserra2024factorised": {
      "citation_key": "ruizserra2024factorised",
      "title": "Factorised Active Inference for Strategic Multi-Agent Interactions",
      "authors": [
        "Jaime Ruiz-Serra",
        "Patrick Sweeney",
        "Michael S. Harré"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2411.07362v2",
      "pdf_path": "data/pdfs/ruizserra2024factorised.pdf",
      "added_date": "2025-12-12T11:49:31.715046",
      "abstract": "Understanding how individual agents make strategic decisions within collectives is important for advancing fields as diverse as economics, neuroscience, and multi-agent systems. Two complementary approaches can be integrated to this end. The Active Inference framework (AIF) describes how agents employ a generative model to adapt their beliefs about and behaviour within their environment. Game theory formalises strategic interactions between agents with potentially competing objectives. To bridge the gap between the two, we propose a factorisation of the generative model whereby each agent maintains explicit, individual-level beliefs about the internal states of other agents, and uses them for strategic planning in a joint context. We apply our model to iterated general-sum games with two and three players, and study the ensemble effects of game transitions, where the agents' preferences (game payoffs) change over time. This non-stationarity, beyond that caused by reciprocal adaptation, reflects a more naturalistic environment in which agents need to adapt to changing social contexts. Finally, we present a dynamical analysis of key AIF quantities: the variational free energy (VFE) and the expected free energy (EFE) from numerical simulation data. The ensemble-level EFE allows us to characterise the basins of attraction of games with multiple Nash Equilibria under different conditions, and we find that it is not necessarily minimised at the aggregate level. By integrating AIF and game theory, we can gain deeper insights into how intelligent collectives emerge, learn, and optimise their actions in dynamic environments, both cooperative and non-cooperative.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2411.07362.pdf"
      }
    },
    "sedlak2024adaptive": {
      "citation_key": "sedlak2024adaptive",
      "title": "Adaptive Stream Processing on Edge Devices through Active Inference",
      "authors": [
        "Boris Sedlak",
        "Victor Casamayor Pujol",
        "Andrea Morichetta",
        "Praveen Kumar Donta",
        "Schahram Dustdar"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2409.17937v1",
      "pdf_path": "data/pdfs/sedlak2024adaptive.pdf",
      "added_date": "2025-12-12T11:49:31.719654",
      "abstract": "The current scenario of IoT is witnessing a constant increase on the volume of data, which is generated in constant stream, calling for novel architectural and logical solutions for processing it. Moving the data handling towards the edge of the computing spectrum guarantees better distribution of load and, in principle, lower latency and better privacy. However, managing such a structure is complex, especially when requirements, also referred to Service Level Objectives (SLOs), specified by applications' owners and infrastructure managers need to be ensured. Despite the rich number of proposals of Machine Learning (ML) based management solutions, researchers and practitioners yet struggle to guarantee long-term prediction and control, and accurate troubleshooting. Therefore, we present a novel ML paradigm based on Active Inference (AIF) -- a concept from neuroscience that describes how the brain constantly predicts and evaluates sensory information to decrease long-term surprise. We implement it and evaluate it in a heterogeneous real stream processing use case, where an AIF-based agent continuously optimizes the fulfillment of three SLOs for three autonomous driving services running on multiple devices. The agent used causal knowledge to gradually develop an understanding of how its actions are related to requirements fulfillment, and which configurations to favor. Through this approach, our agent requires up to thirty iterations to converge to the optimal solution, showing the capability of offering accurate results in a short amount of time. Furthermore, thanks to AIF and its causal structures, our method guarantees full transparency on the decision making, making the interpretation of the results and the troubleshooting effortless.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2409.17937.pdf"
      }
    },
    "danilenka2024adaptive": {
      "citation_key": "danilenka2024adaptive",
      "title": "Adaptive Active Inference Agents for Heterogeneous and Lifelong Federated Learning",
      "authors": [
        "Anastasiya Danilenka",
        "Alireza Furutanpey",
        "Victor Casamayor Pujol",
        "Boris Sedlak",
        "Anna Lackinger",
        "Maria Ganzha",
        "Marcin Paprzycki",
        "Schahram Dustdar"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.09099v2",
      "pdf_path": "data/pdfs/danilenka2024adaptive.pdf",
      "added_date": "2025-12-12T11:49:31.723575",
      "abstract": "Handling heterogeneity and unpredictability are two core problems in pervasive computing. The challenge is to seamlessly integrate devices with varying computational resources in a dynamic environment to form a cohesive system that can fulfill the needs of all participants. Existing work on adaptive systems typically focuses on optimizing individual variables or low-level Service Level Objectives (SLOs), such as constraining the usage of specific resources. While low-level control mechanisms permit fine-grained control over a system, they introduce considerable complexity, particularly in dynamic environments. To this end, we propose drawing from Active Inference (AIF), a neuroscientific framework for designing adaptive agents. Specifically, we introduce a conceptual agent for heterogeneous pervasive systems that permits setting global systems constraints as high-level SLOs. Instead of manually setting low-level SLOs, the system finds an equilibrium that can adapt to environmental changes. We demonstrate the viability of our AIF agents with an extensive experiment design, using heterogeneous and lifelong federated learning as an application scenario. We conduct our experiments on a physical testbed of devices with different resource types and vendor specifications. The results provide convincing evidence that an AIF agent can adapt a system to environmental changes. In particular, the AIF agent can balance competing SLOs in resource heterogeneous environments to ensure up to 98% fulfillment rate.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.09099.pdf"
      }
    },
    "hoyle2024phenomenology": {
      "citation_key": "hoyle2024phenomenology",
      "title": "The Phenomenology of Machine: A Comprehensive Analysis of the Sentience of the OpenAI-o1 Model Integrating Functionalism, Consciousness Theories, Active Inference, and AI Architectures",
      "authors": [
        "Victoria Violet Hoyle"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.00033v1",
      "pdf_path": "data/pdfs/hoyle2024phenomenology.pdf",
      "added_date": "2025-12-12T11:49:31.728126",
      "abstract": "This paper explores the hypothesis that the OpenAI-o1 model--a transformer-based AI trained with reinforcement learning from human feedback (RLHF)--displays characteristics of consciousness during its training and inference phases. Adopting functionalism, which argues that mental states are defined by their functional roles, we assess the possibility of AI consciousness. Drawing on theories from neuroscience, philosophy of mind, and AI research, we justify the use of functionalism and examine the model's architecture using frameworks like Integrated Information Theory (IIT) and active inference. The paper also investigates how RLHF influences the model's internal reasoning processes, potentially giving rise to consciousness-like experiences. We compare AI and human consciousness, addressing counterarguments such as the absence of a biological basis and subjective qualia. Our findings suggest that the OpenAI-o1 model shows aspects of consciousness, while acknowledging the ongoing debates surrounding AI sentience.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.00033.pdf"
      }
    },
    "shusterman2024active": {
      "citation_key": "shusterman2024active",
      "title": "An Active Inference Strategy for Prompting Reliable Responses from Large Language Models in Medical Practice",
      "authors": [
        "Roma Shusterman",
        "Allison C. Waters",
        "Shannon O`Neill",
        "Phan Luu",
        "Don M. Tucker"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2407.21051v1",
      "pdf_path": "data/pdfs/shusterman2024active.pdf",
      "added_date": "2025-12-12T11:49:31.732259",
      "abstract": "Continuing advances in Large Language Models (LLMs) in artificial intelligence offer important capacities in intuitively accessing and using medical knowledge in many contexts, including education and training as well as assessment and treatment. Most of the initial literature on LLMs in medicine has emphasized that LLMs are unsuitable for medical use because they are non-deterministic, may provide incorrect or harmful responses, and cannot be regulated to assure quality control. If these issues could be corrected, optimizing LLM technology could benefit patients and physicians by providing affordable, point-of-care medical knowledge. Our proposed framework refines LLM responses by restricting their primary knowledge base to domain-specific datasets containing validated medical information. Additionally, we introduce an actor-critic LLM prompting protocol based on active inference principles of human cognition, where a Therapist agent initially responds to patient queries, and a Supervisor agent evaluates and adjusts responses to ensure accuracy and reliability. We conducted a validation study where expert cognitive behaviour therapy for insomnia (CBT-I) therapists evaluated responses from the LLM in a blind format. Experienced human CBT-I therapists assessed responses to 100 patient queries, comparing LLM-generated responses with appropriate and inappropriate responses crafted by experienced CBT-I therapists. Results showed that LLM responses received high ratings from the CBT-I therapists, often exceeding those of therapist-generated appropriate responses. This structured approach aims to integrate advanced LLM technology into medical applications, meeting regulatory requirements for establishing the safe and effective use of special purpose validated LLMs in medicine.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2407.21051.pdf"
      }
    },
    "zrnic2024active": {
      "citation_key": "zrnic2024active",
      "title": "Active Statistical Inference",
      "authors": [
        "Tijana Zrnic",
        "Emmanuel J. Candès"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2403.03208v2",
      "pdf_path": "data/pdfs/zrnic2024active.pdf",
      "added_date": "2025-12-12T11:49:31.736854",
      "abstract": "Inspired by the concept of active learning, we propose active inference$\\unicode{x2013}$a methodology for statistical inference with machine-learning-assisted data collection. Assuming a budget on the number of labels that can be collected, the methodology uses a machine learning model to identify which data points would be most beneficial to label, thus effectively utilizing the budget. It operates on a simple yet powerful intuition: prioritize the collection of labels for data points where the model exhibits uncertainty, and rely on the model's predictions where it is confident. Active inference constructs provably valid confidence intervals and hypothesis tests while leveraging any black-box machine learning model and handling any data distribution. The key point is that it achieves the same level of accuracy with far fewer samples than existing baselines relying on non-adaptively-collected data. This means that for the same number of collected samples, active inference enables smaller confidence intervals and more powerful p-values. We evaluate active inference on datasets from public opinion research, census analysis, and proteomics.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2403.03208.pdf"
      }
    },
    "li2024enabling": {
      "citation_key": "li2024enabling",
      "title": "Enabling self-identification in intelligent agent: insights from computational psychoanalysis",
      "authors": [
        "Lingyu Li",
        "Chunbo Li"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2403.07664v1",
      "pdf_path": "data/pdfs/li2024enabling.pdf",
      "added_date": "2025-12-12T11:49:31.740944",
      "abstract": "Building upon prior framework of computational Lacanian psychoanalysis with the theory of active inference, this paper aims to further explore the concept of self-identification and its potential applications. Beginning with two classic paradigms in psychology, mirror self-recognition and rubber hand illusion, we suggest that imaginary identification is characterized by an integrated body schema with minimal free energy. Next, we briefly survey three dimensions of symbolic identification (sociological, psychoanalytic, and linguistical) and corresponding active inference accounts. To provide intuition, we respectively employ a convolutional neural network (CNN) and a multi-layer perceptron (MLP) supervised by ChatGPT to showcase optimization of free energy during motor skill and language mastery underlying identification formation. We then introduce Lacan's Graph II of desire, unifying imaginary and symbolic identification, and propose an illustrative model called FreeAgent. In concluding remarks, we discuss some key issues in the potential of computational Lacanian psychoanalysis to advance mental health and artificial intelligence, including digital twin mind, large language models as avatars of the Lacanian Other, and the feasibility of human-level artificial general intelligence with self-awareness in the context of post-structuralism.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2403.07664.pdf"
      }
    },
    "federici2024active": {
      "citation_key": "federici2024active",
      "title": "Active Inference for Closed-loop transmit beamsteering in Fetal Doppler Ultrasound",
      "authors": [
        "Beatrice Federici",
        "Ruud JG van Sloun",
        "Massimo Mischi"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.04869v1",
      "pdf_path": "data/pdfs/federici2024active.pdf",
      "added_date": "2025-12-12T11:49:31.745702",
      "abstract": "Doppler ultrasound is widely used to monitor fetal heart rate during labor and pregnancy. Unfortunately, it is highly sensitive to fetal and maternal movements, which can cause the displacement of the fetal heart with respect to the ultrasound beam, in turn reducing the Doppler signal-to-noise ratio and leading to erratic, noisy, or missing heart rate readings. To tackle this issue, we augment the conventional Doppler ultrasound system with a rational agent that autonomously steers the ultrasound beam to track the position of the fetal heart. The proposed cognitive ultrasound system leverages a sequential Monte Carlo method to infer the fetal heart position from the power Doppler signal, and employs a greedy information-seeking criterion to select the steering angle that minimizes the positional uncertainty for future timesteps. The fetal heart rate is then calculated using the Doppler signal at the estimated fetal heart position. Our results show that the system can accurately track the fetal heart position across challenging signal-to-noise ratio scenarios, mainly thanks to its dynamic transmit beam steering capability. Additionally, we find that optimizing the transmit beamsteering to minimize positional uncertainty also optimizes downstream heart rate estimation performance. In conclusion, this work showcases the power of closed-loop cognitive ultrasound in boosting the capabilities of traditional systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.04869.pdf"
      }
    },
    "champion2024reframing": {
      "citation_key": "champion2024reframing",
      "title": "Reframing the Expected Free Energy: Four Formulations and a Unification",
      "authors": [
        "Théophile Champion",
        "Howard Bowman",
        "Dimitrije Marković",
        "Marek Grześ"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2402.14460v1",
      "pdf_path": "data/pdfs/champion2024reframing.pdf",
      "added_date": "2025-12-12T11:49:31.749716",
      "abstract": "Active inference is a leading theory of perception, learning and decision making, which can be applied to neuroscience, robotics, psychology, and machine learning. Active inference is based on the expected free energy, which is mostly justified by the intuitive plausibility of its formulations, e.g., the risk plus ambiguity and information gain / pragmatic value formulations. This paper seek to formalize the problem of deriving these formulations from a single root expected free energy definition, i.e., the unification problem. Then, we study two settings, each one having its own root expected free energy definition. In the first setting, no justification for the expected free energy has been proposed to date, but all the formulations can be recovered from it. However, in this setting, the agent cannot have arbitrary prior preferences over observations. Indeed, only a limited class of prior preferences over observations is compatible with the likelihood mapping of the generative model. In the second setting, a justification of the root expected free energy definition is known, but this setting only accounts for two formulations, i.e., the risk over states plus ambiguity and entropy plus expected energy formulations.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2402.14460.pdf"
      }
    },
    "priorelli2024deep": {
      "citation_key": "priorelli2024deep",
      "title": "Deep hybrid models: infer and plan in a dynamic world",
      "authors": [
        "Matteo Priorelli",
        "Ivilin Peev Stoianov"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2402.10088v4",
      "pdf_path": "data/pdfs/priorelli2024deep.pdf",
      "added_date": "2025-12-12T11:49:31.754674",
      "abstract": "To determine an optimal plan for complex tasks, one often deals with dynamic and hierarchical relationships between several entities. Traditionally, such problems are tackled with optimal control, which relies on the optimization of cost functions; instead, a recent biologically-motivated proposal casts planning and control as an inference process. Active inference assumes that action and perception are two complementary aspects of life whereby the role of the former is to fulfill the predictions inferred by the latter. Here, we present an active inference approach that exploits discrete and continuous processing, based on three features: the representation of potential body configurations in relation to the objects of interest; the use of hierarchical relationships that enable the agent to easily interpret and flexibly expand its body schema for tool use; the definition of potential trajectories related to the agent's intentions, used to infer and plan with dynamic elements at different temporal scales. We evaluate this deep hybrid model on a habitual task: reaching a moving object after having picked a moving tool. We show that the model can tackle the presented task under different conditions. This study extends past work on planning as inference and advances an alternative direction to optimal control.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2402.10088.pdf"
      }
    },
    "narendra2024intentbased": {
      "citation_key": "narendra2024intentbased",
      "title": "Intent-based Meta-Scheduling in Programmable Networks: A Research Agenda",
      "authors": [
        "Nanjangud C. Narendra",
        "Ronak Kanthaliya",
        "Venkatareddy Akumalla"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2412.04232v3",
      "pdf_path": "data/pdfs/narendra2024intentbased.pdf",
      "added_date": "2025-12-12T11:49:31.758915",
      "abstract": "The emergence and growth of 5G and beyond 5G (B5G) networks has brought about the rise of so-called ''programmable'' networks, i.e., networks whose operational requirements are so stringent that they can only be met in an automated manner, with minimal/no human involvement. Any requirements on such a network would need to be formally specified via intents, which can represent user requirements in a formal yet understandable manner. Meeting the user requirements via intents would necessitate the rapid implementation of resource allocation and scheduling in the network. Also, given the expected size and geographical distribution of programmable networks, multiple resource scheduling implementations would need to be implemented at the same time. This would necessitate the use of a meta-scheduler that can coordinate the various schedulers and dynamically ensure optimal resource scheduling across the network.   To that end, in this position paper, we propose a research agenda for modeling, implementation, and inclusion of intent-based dynamic meta-scheduling in programmable networks. Our research agenda will be built on active inference, a type of causal inference. Active inference provides some level of autonomy to each scheduler while the meta-scheduler takes care of overall intent fulfillment. Our research agenda will comprise a strawman architecture for meta-scheduling and a set of research questions that need to be addressed to make intent-based dynamic meta-scheduling a reality.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2412.04232.pdf"
      }
    },
    "vega2024learning": {
      "citation_key": "vega2024learning",
      "title": "Learning EFSM Models with Registers in Guards",
      "authors": [
        "Germán Vega",
        "Roland Groz",
        "Catherine Oriat",
        "Michael Foster",
        "Neil Walkinshaw",
        "Adenilso Simão"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.07040v1",
      "pdf_path": "data/pdfs/vega2024learning.pdf",
      "added_date": "2025-12-12T11:49:31.763549",
      "abstract": "This paper presents an active inference method for Extended Finite State Machines, where inputs and outputs are parametrized, and transitions can be conditioned by guards involving input parameters and internal variables called registers. The method applies to (software) systems that cannot be reset, so it learns an EFSM model of the system on a single trace.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.07040.pdf"
      }
    },
    "catal2024belief": {
      "citation_key": "catal2024belief",
      "title": "Belief sharing: a blessing or a curse",
      "authors": [
        "Ozan Catal",
        "Toon Van de Maele",
        "Riddhi J. Pitliya",
        "Mahault Albarracin",
        "Candice Pattisapu",
        "Tim Verbelen"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2407.02465v1",
      "pdf_path": "data/pdfs/catal2024belief.pdf",
      "added_date": "2025-12-12T11:49:31.768111",
      "abstract": "When collaborating with multiple parties, communicating relevant information is of utmost importance to efficiently completing the tasks at hand. Under active inference, communication can be cast as sharing beliefs between free-energy minimizing agents, where one agent's beliefs get transformed into an observation modality for the other. However, the best approach for transforming beliefs into observations remains an open question. In this paper, we demonstrate that naively sharing posterior beliefs can give rise to the negative social dynamics of echo chambers and self-doubt. We propose an alternate belief sharing strategy which mitigates these issues.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2407.02465.pdf"
      }
    },
    "pattisapu2024free": {
      "citation_key": "pattisapu2024free",
      "title": "Free Energy in a Circumplex Model of Emotion",
      "authors": [
        "Candice Pattisapu",
        "Tim Verbelen",
        "Riddhi J. Pitliya",
        "Alex B. Kiefer",
        "Mahault Albarracin"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2407.02474v1",
      "pdf_path": "data/pdfs/pattisapu2024free.pdf",
      "added_date": "2025-12-12T11:49:31.772530",
      "abstract": "Previous active inference accounts of emotion translate fluctuations in free energy to a sense of emotion, mainly focusing on valence. However, in affective science, emotions are often represented as multi-dimensional. In this paper, we propose to adopt a Circumplex Model of emotion by mapping emotions into a two-dimensional spectrum of valence and arousal. We show how one can derive a valence and arousal signal from an agent's expected free energy, relating arousal to the entropy of posterior beliefs and valence to utility less expected utility. Under this formulation, we simulate artificial agents engaged in a search task. We show that the manipulation of priors and object presence results in commonsense variability in emotional states.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2407.02474.pdf"
      }
    },
    "varona2024exploring": {
      "citation_key": "varona2024exploring",
      "title": "Exploring Action-Centric Representations Through the Lens of Rate-Distortion Theory",
      "authors": [
        "Miguel de Llanza Varona",
        "Christopher L. Buckley",
        "Beren Millidge"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2409.08892v1",
      "pdf_path": "data/pdfs/varona2024exploring.pdf",
      "added_date": "2025-12-12T11:49:31.777106",
      "abstract": "Organisms have to keep track of the information in the environment that is relevant for adaptive behaviour. Transmitting information in an economical and efficient way becomes crucial for limited-resourced agents living in high-dimensional environments. The efficient coding hypothesis claims that organisms seek to maximize the information about the sensory input in an efficient manner. Under Bayesian inference, this means that the role of the brain is to efficiently allocate resources in order to make predictions about the hidden states that cause sensory data. However, neither of those frameworks accounts for how that information is exploited downstream, leaving aside the action-oriented role of the perceptual system. Rate-distortion theory, which defines optimal lossy compression under constraints, has gained attention as a formal framework to explore goal-oriented efficient coding. In this work, we explore action-centric representations in the context of rate-distortion theory. We also provide a mathematical definition of abstractions and we argue that, as a summary of the relevant details, they can be used to fix the content of action-centric representations. We model action-centric representations using VAEs and we find that such representations i) are efficient lossy compressions of the data; ii) capture the task-dependent invariances necessary to achieve successful behaviour; and iii) are not in service of reconstructing the data. Thus, we conclude that full reconstruction of the data is rarely needed to achieve optimal behaviour, consistent with a teleological approach to perception.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2409.08892.pdf"
      }
    },
    "vázquezgarcía2024review": {
      "citation_key": "vázquezgarcía2024review",
      "title": "A Review of Latent Representation Models in Neuroimaging",
      "authors": [
        "C. Vázquez-García",
        "F. J. Martínez-Murcia",
        "F. Segovia Román",
        "Juan M. Górriz"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2412.19844v1",
      "pdf_path": "data/pdfs/vázquezgarcía2024review.pdf",
      "added_date": "2025-12-12T11:49:31.781534",
      "abstract": "Neuroimaging data, particularly from techniques like MRI or PET, offer rich but complex information about brain structure and activity. To manage this complexity, latent representation models - such as Autoencoders, Generative Adversarial Networks (GANs), and Latent Diffusion Models (LDMs) - are increasingly applied. These models are designed to reduce high-dimensional neuroimaging data to lower-dimensional latent spaces, where key patterns and variations related to brain function can be identified. By modeling these latent spaces, researchers hope to gain insights into the biology and function of the brain, including how its structure changes with age or disease, or how it encodes sensory information, predicts and adapts to new inputs. This review discusses how these models are used for clinical applications, like disease diagnosis and progression monitoring, but also for exploring fundamental brain mechanisms such as active inference and predictive coding. These approaches provide a powerful tool for both understanding and simulating the brain's complex computational tasks, potentially advancing our knowledge of cognition, perception, and neural disorders.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2412.19844.pdf"
      }
    },
    "paolo2024call": {
      "citation_key": "paolo2024call",
      "title": "A call for embodied AI",
      "authors": [
        "Giuseppe Paolo",
        "Jonas Gonzalez-Billandon",
        "Balázs Kégl"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2402.03824v4",
      "pdf_path": "data/pdfs/paolo2024call.pdf",
      "added_date": "2025-12-12T11:49:31.786250",
      "abstract": "We propose Embodied AI as the next fundamental step in the pursuit of Artificial General Intelligence, juxtaposing it against current AI advancements, particularly Large Language Models. We traverse the evolution of the embodiment concept across diverse fields - philosophy, psychology, neuroscience, and robotics - to highlight how EAI distinguishes itself from the classical paradigm of static learning. By broadening the scope of Embodied AI, we introduce a theoretical framework based on cognitive architectures, emphasizing perception, action, memory, and learning as essential components of an embodied agent. This framework is aligned with Friston's active inference principle, offering a comprehensive approach to EAI development. Despite the progress made in the field of AI, substantial challenges, such as the formulation of a novel AI learning theory and the innovation of advanced hardware, persist. Our discussion lays down a foundational guideline for future Embodied AI research. Highlighting the importance of creating Embodied AI agents capable of seamless communication, collaboration, and coexistence with humans and other intelligent entities within real-world environments, we aim to steer the AI community towards addressing the multifaceted challenges and seizing the opportunities that lie ahead in the quest for AGI.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2402.03824.pdf"
      }
    },
    "collis2024hybrid": {
      "citation_key": "collis2024hybrid",
      "title": "Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical Planning and Control",
      "authors": [
        "Poppy Collis",
        "Ryan Singh",
        "Paul F Kinghorn",
        "Christopher L Buckley"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2408.10970v1",
      "pdf_path": "data/pdfs/collis2024hybrid.pdf",
      "added_date": "2025-12-12T11:49:31.790359",
      "abstract": "An open problem in artificial intelligence is how systems can flexibly learn discrete abstractions that are useful for solving inherently continuous problems. Previous work has demonstrated that a class of hybrid state-space model known as recurrent switching linear dynamical systems (rSLDS) discover meaningful behavioural units via the piecewise linear decomposition of complex continuous dynamics (Linderman et al., 2016). Furthermore, they model how the underlying continuous states drive these discrete mode switches. We propose that the rich representations formed by an rSLDS can provide useful abstractions for planning and control. We present a novel hierarchical model-based algorithm inspired by Active Inference in which a discrete MDP sits above a low-level linear-quadratic controller. The recurrent transition dynamics learned by the rSLDS allow us to (1) specify temporally-abstracted sub-goals in a method reminiscent of the options framework, (2) lift the exploration into discrete space allowing us to exploit information-theoretic exploration bonuses and (3) `cache' the approximate solutions to low-level problems in the discrete planner. We successfully apply our model to the sparse Continuous Mountain Car task, demonstrating fast system identification via enhanced exploration and non-trivial planning through the delineation of abstract sub-goals.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2408.10970.pdf"
      }
    },
    "dodigcrnkovic2024rethinking": {
      "citation_key": "dodigcrnkovic2024rethinking",
      "title": "Rethinking Cognition: Morphological Info-Computation and the Embodied Paradigm in Life and Artificial Intelligence",
      "authors": [
        "Gordana Dodig-Crnkovic"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2412.00751v1",
      "pdf_path": "data/pdfs/dodigcrnkovic2024rethinking.pdf",
      "added_date": "2025-12-12T11:49:31.795296",
      "abstract": "This study aims to place Lorenzo Magnanis Eco-Cognitive Computationalism within the broader context of current work on information, computation, and cognition. Traditionally, cognition was believed to be exclusive to humans and a result of brain activity. However, recent studies reveal it as a fundamental characteristic of all life forms, ranging from single cells to complex multicellular organisms and their networks. Yet, the literature and general understanding of cognition still largely remain human-brain-focused, leading to conceptual gaps and incoherency. This paper presents a variety of computational (information processing) approaches, including an info-computational approach to cognition, where natural structures represent information and dynamical processes on natural structures are regarded as computation, relative to an observing cognizing agent. We model cognition as a web of concurrent morphological computations, driven by processes of self-assembly, self-organisation, and autopoiesis across physical, chemical, and biological domains. We examine recent findings linking morphological computation, morphogenesis, agency, basal cognition, extended evolutionary synthesis, and active inference. We establish a connection to Magnanis Eco-Cognitive Computationalism and the idea of computational domestication of ignorant entities. Novel theoretical and applied insights question the boundaries of conventional computational models of cognition. The traditional models prioritize symbolic processing and often neglect the inherent constraints and potentialities in the physical embodiment of agents on different levels of organization. Gaining a better info-computational grasp of cognitive embodiment is crucial for the advancement of fields such as biology, evolutionary studies, artificial intelligence, robotics, medicine, and more.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2412.00751.pdf"
      }
    },
    "wang2024coreinfer": {
      "citation_key": "wang2024coreinfer",
      "title": "CoreInfer: Accelerating Large Language Model Inference with Semantics-Inspired Adaptive Sparse Activation",
      "authors": [
        "Qinsi Wang",
        "Saeed Vahidian",
        "Hancheng Ye",
        "Jianyang Gu",
        "Jianyi Zhang",
        "Yiran Chen"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2410.18311v1",
      "pdf_path": "data/pdfs/wang2024coreinfer.pdf",
      "added_date": "2025-12-12T11:49:31.799733",
      "abstract": "Large language models (LLMs) with billions of parameters have sparked a new wave of exciting AI applications. However, their high computational costs and memory demands during inference pose significant challenges. Adaptive sparse activation inference, which activates only a small number of neurons for each token, offers a novel way to accelerate model inference without degrading performance, showing great potential for resource-constrained hardware devices. Nevertheless, existing methods predict activated neurons based on individual tokens with additional MLP, which involve frequent changes in activation maps and resource calls, limiting the acceleration benefits of sparse activation. In this paper, we introduce CoreInfer, an MLP-free adaptive sparse activation inference method based on sentence-level prediction. Specifically, we propose the concept of sentence-wise core neurons, which refers to the subset of neurons most critical for a given sentence, and empirically demonstrate its effectiveness. To determine the core neurons, we explore the correlation between core neurons and the sentence's semantics. Remarkably, we discovered that core neurons exhibit both stability and similarity in relation to the sentence's semantics -- an insight overlooked by previous studies. Building on this finding, we further design two semantic-based methods for predicting core neurons to fit different input scenarios. In CoreInfer, the core neurons are determined during the pre-filling stage and fixed during the encoding stage, enabling zero-cost sparse inference. We evaluated the model generalization and task generalization of CoreInfer across various models and tasks. Notably, on an NVIDIA TITAN XP GPU, CoreInfer achieved a 10.33 times and 2.72 times speedup compared to the Huggingface implementation and PowerInfer, respectively.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2410.18311.pdf"
      }
    },
    "liu2024semantic": {
      "citation_key": "liu2024semantic",
      "title": "Semantic Trajectory Data Mining with LLM-Informed POI Classification",
      "authors": [
        "Yifan Liu",
        "Chenchen Kuai",
        "Haoxuan Ma",
        "Xishun Liao",
        "Brian Yueshuai He",
        "Jiaqi Ma"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2405.11715v2",
      "pdf_path": "data/pdfs/liu2024semantic.pdf",
      "added_date": "2025-12-12T11:49:31.804724",
      "abstract": "Human travel trajectory mining is crucial for transportation systems, enhancing route optimization, traffic management, and the study of human travel patterns. Previous rule-based approaches without the integration of semantic information show a limitation in both efficiency and accuracy. Semantic information, such as activity types inferred from Points of Interest (POI) data, can significantly enhance the quality of trajectory mining. However, integrating these insights is challenging, as many POIs have incomplete feature information, and current learning-based POI algorithms require the integrity of datasets to do the classification. In this paper, we introduce a novel pipeline for human travel trajectory mining. Our approach first leverages the strong inferential and comprehension capabilities of large language models (LLMs) to annotate POI with activity types and then uses a Bayesian-based algorithm to infer activity for each stay point in a trajectory. In our evaluation using the OpenStreetMap (OSM) POI dataset, our approach achieves a 93.4% accuracy and a 96.1% F-1 score in POI classification, and a 91.7% accuracy with a 92.3% F-1 score in activity inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2405.11715.pdf"
      }
    },
    "kundu2024algo": {
      "citation_key": "kundu2024algo",
      "title": "ALGO: Object-Grounded Visual Commonsense Reasoning for Open-World Egocentric Action Recognition",
      "authors": [
        "Sanjoy Kundu",
        "Shubham Trehan",
        "Sathyanarayanan N. Aakur"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2406.05722v1",
      "pdf_path": "data/pdfs/kundu2024algo.pdf",
      "added_date": "2025-12-12T11:49:31.809217",
      "abstract": "Learning to infer labels in an open world, i.e., in an environment where the target \"labels\" are unknown, is an important characteristic for achieving autonomy. Foundation models pre-trained on enormous amounts of data have shown remarkable generalization skills through prompting, particularly in zero-shot inference. However, their performance is restricted to the correctness of the target label's search space. In an open world, this target search space can be unknown or exceptionally large, which severely restricts the performance of such models. To tackle this challenging problem, we propose a neuro-symbolic framework called ALGO - Action Learning with Grounded Object recognition that uses symbolic knowledge stored in large-scale knowledge bases to infer activities in egocentric videos with limited supervision using two steps. First, we propose a neuro-symbolic prompting approach that uses object-centric vision-language models as a noisy oracle to ground objects in the video through evidence-based reasoning. Second, driven by prior commonsense knowledge, we discover plausible activities through an energy-based symbolic pattern theory framework and learn to ground knowledge-based action (verb) concepts in the video. Extensive experiments on four publicly available datasets (EPIC-Kitchens, GTEA Gaze, GTEA Gaze Plus) demonstrate its performance on open-world activity inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2406.05722.pdf"
      }
    },
    "jia2024analyzing": {
      "citation_key": "jia2024analyzing",
      "title": "Analyzing Consumer IoT Traffic from Security and Privacy Perspectives: a Comprehensive Survey",
      "authors": [
        "Yan Jia",
        "Yuxin Song",
        "Zihou Liu",
        "Qingyin Tan",
        "Yang Song",
        "Yu Zhang",
        "Zheli Liu"
      ],
      "year": 2024,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2403.16149v6",
      "pdf_path": "data/pdfs/jia2024analyzing.pdf",
      "added_date": "2025-12-12T11:49:31.814018",
      "abstract": "The Consumer Internet of Things (CIoT), a notable segment within the IoT domain, involves the integration of IoT technology into consumer electronics and devices, such as smart homes and smart wearables. Compared to traditional IoT fields, CIoT differs notably in target users, product types, and design approaches. While offering convenience to users, it also raises new security and privacy concerns. Network traffic analysis, a widely used technique in the security community, has been extensively applied to investigate these concerns about CIoT. Compared to traditional network traffic analysis in fields like mobile apps and websites, CIoT introduces unique characteristics that pose new challenges and research opportunities. Researchers have made significant contributions in this area. To aid researchers in understanding the application of traffic analysis tools for assessing CIoT security and privacy risks, this survey reviews 310 publications on traffic analysis within the CIoT security and privacy domain from January 2018 to June 2024, focusing on three research questions. Our work: 1) outlines the CIoT traffic analysis process and highlights its differences from general network traffic analysis. 2) summarizes and classifies existing research into four categories according to its application objectives: device fingerprinting, user activity inference, malicious traffic detection, and measurement. 3) explores emerging challenges and potential future research directions based on each step of the CIoT traffic analysis process. This will provide new insights to the community and guide the industry towards safer product designs.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2403.16149.pdf"
      }
    },
    "asadi2022quantum": {
      "citation_key": "asadi2022quantum",
      "title": "Quantum Entanglement and the Thermal Hadron",
      "authors": [
        "Pouya Asadi",
        "Varun Vaidya"
      ],
      "year": 2022,
      "doi": "10.1103/PhysRevD.107.054028",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2211.14333v1",
      "pdf_path": "data/pdfs/asadi2022quantum.pdf",
      "added_date": "2025-12-12T11:49:31.828100",
      "abstract": "This paper tests how effectively the bound states of strongly interacting gauge theories are amenable to an emergent description as a thermal ensemble. This description can be derived from a conjectured minimum free energy principle, with the entanglement entropy of two-parton subsystems playing the role of thermodynamic entropy. This allows us to calculate the ground state hadron spectrum and wavefunction over a wide range of parton masses without solving the Schrödinger equation. We carry out this analysis for certain illustrative models in 1+1 dimensions and discuss prospects for higher dimensions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2211.14333.pdf"
      }
    },
    "ramstead2022bayesian": {
      "citation_key": "ramstead2022bayesian",
      "title": "On Bayesian Mechanics: A Physics of and by Beliefs",
      "authors": [
        "Maxwell J. D. Ramstead",
        "Dalton A. R. Sakthivadivel",
        "Conor Heins",
        "Magnus Koudahl",
        "Beren Millidge",
        "Lancelot Da Costa",
        "Brennan Klein",
        "Karl J. Friston"
      ],
      "year": 2022,
      "doi": "10.1098/rsfs.2022.0029",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2205.11543v4",
      "pdf_path": "data/pdfs/ramstead2022bayesian.pdf",
      "added_date": "2025-12-12T11:49:31.832313",
      "abstract": "The aim of this paper is to introduce a field of study that has emerged over the last decade called Bayesian mechanics. Bayesian mechanics is a probabilistic mechanics, comprising tools that enable us to model systems endowed with a particular partition (i.e., into particles), where the internal states (or the trajectories of internal states) of a particular system encode the parameters of beliefs about external states (or their trajectories). These tools allow us to write down mechanical theories for systems that look as if they are estimating posterior probability distributions over the causes of their sensory states. This provides a formal language for modelling the constraints, forces, potentials, and other quantities determining the dynamics of such systems, especially as they entail dynamics on a space of beliefs (i.e., on a statistical manifold). Here, we will review the state of the art in the literature on the free energy principle, distinguishing between three ways in which Bayesian mechanics has been applied to particular systems (i.e., path-tracking, mode-tracking, and mode-matching). We go on to examine a duality between the free energy principle and the constrained maximum entropy principle, both of which lie at the heart of Bayesian mechanics, and discuss its implications.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2205.11543.pdf"
      }
    },
    "matsumoto2022goaldirected": {
      "citation_key": "matsumoto2022goaldirected",
      "title": "Goal-directed Planning and Goal Understanding by Active Inference: Evaluation Through Simulated and Physical Robot Experiments",
      "authors": [
        "Takazumi Matsumoto",
        "Wataru Ohata",
        "Fabien C. Y. Benureau",
        "Jun Tani"
      ],
      "year": 2022,
      "doi": "10.3390/e24040469",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2202.09976v1",
      "pdf_path": "data/pdfs/matsumoto2022goaldirected.pdf",
      "added_date": "2025-12-12T11:49:31.837000",
      "abstract": "We show that goal-directed action planning and generation in a teleological framework can be formulated using the free energy principle. The proposed model, which is built on a variational recurrent neural network model, is characterized by three essential features. These are that (1) goals can be specified for both static sensory states, e.g., for goal images to be reached and dynamic processes, e.g., for moving around an object, (2) the model can not only generate goal-directed action plans, but can also understand goals by sensory observation, and (3) the model generates future action plans for given goals based on the best estimate of the current state, inferred using past sensory observations. The proposed model is evaluated by conducting experiments on a simulated mobile agent as well as on a real humanoid robot performing object manipulation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2202.09976.pdf"
      }
    },
    "friston2022path": {
      "citation_key": "friston2022path",
      "title": "Path integrals, particular kinds, and strange things",
      "authors": [
        "Karl Friston",
        "Lancelot Da Costa",
        "Dalton A. R. Sakthivadivel",
        "Conor Heins",
        "Grigorios A. Pavliotis",
        "Maxwell Ramstead",
        "Thomas Parr"
      ],
      "year": 2022,
      "doi": "10.1016/j.plrev.2023.08.016",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2210.12761v3",
      "pdf_path": "data/pdfs/friston2022path.pdf",
      "added_date": "2025-12-12T11:49:31.841063",
      "abstract": "This paper describes a path integral formulation of the free energy principle. The ensuing account expresses the paths or trajectories that a particle takes as it evolves over time. The main results are a method or principle of least action that can be used to emulate the behaviour of particles in open exchange with their external milieu. Particles are defined by a particular partition, in which internal states are individuated from external states by active and sensory blanket states. The variational principle at hand allows one to interpret internal dynamics - of certain kinds of particles - as inferring external states that are hidden behind blanket states. We consider different kinds of particles, and to what extent they can be imbued with an elementary form of inference or sentience. Specifically, we consider the distinction between dissipative and conservative particles, inert and active particles and, finally, ordinary and strange particles. Strange particles can be described as inferring their own actions, endowing them with apparent autonomy or agency. In short - of the kinds of particles afforded by a particular partition - strange kinds may be apt for describing sentient behaviour.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2210.12761.pdf"
      }
    },
    "smithe2022mathematical": {
      "citation_key": "smithe2022mathematical",
      "title": "Mathematical Foundations for a Compositional Account of the Bayesian Brain",
      "authors": [
        "Toby St Clere Smithe"
      ],
      "year": 2022,
      "doi": "10.5287/ora-kzjqyop2d",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2212.12538v3",
      "pdf_path": "data/pdfs/smithe2022mathematical.pdf",
      "added_date": "2025-12-12T11:49:31.846013",
      "abstract": "This dissertation reports some first steps towards a compositional account of active inference and the Bayesian brain. Specifically, we use the tools of contemporary applied category theory to supply functorial semantics for approximate inference. To do so, we define on the `syntactic' side the new notion of Bayesian lens and show that Bayesian updating composes according to the compositional lens pattern. Using Bayesian lenses, and inspired by compositional game theory, we define fibrations of statistical games and classify various problems of statistical inference as corresponding sections: the chain rule of the relative entropy is formalized as a strict section, while maximum likelihood estimation and the free energy give lax sections. In the process, we introduce a new notion of `copy-composition'.   On the `semantic' side, we present a new formalization of general open dynamical systems (particularly: deterministic, stochastic, and random; and discrete- and continuous-time) as certain coalgebras of polynomial functors, which we show collect into monoidal opindexed categories (or, alternatively, into algebras for multicategories of generalized polynomial functors). We use these opindexed categories to define monoidal bicategories of cilia: dynamical systems which control lenses, and which supply the target for our functorial semantics. Accordingly, we construct functors which explain the bidirectional compositional structure of predictive coding neural circuits under the free energy principle, thereby giving a formal mathematical underpinning to the bidirectionality observed in the cortex. Along the way, we explain how to compose rate-coded neural circuits using an algebra for a multicategory of linear circuit diagrams, showing subsequently that this is subsumed by lenses and polynomial functors.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2212.12538.pdf"
      }
    },
    "smithe2022polynomial": {
      "citation_key": "smithe2022polynomial",
      "title": "Polynomial Life: the Structure of Adaptive Systems",
      "authors": [
        "Toby St Clere Smithe"
      ],
      "year": 2022,
      "doi": "10.4204/EPTCS.372.10",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2211.01831v1",
      "pdf_path": "data/pdfs/smithe2022polynomial.pdf",
      "added_date": "2025-12-12T11:49:31.850349",
      "abstract": "We extend our earlier work on the compositional structure of cybernetic systems in order to account for the embodiment of such systems. All their interactions proceed through their bodies' boundaries: sensations impinge on their surfaces, and actions correspond to changes in their configurations. We formalize this morphological perspective using polynomial functors. The 'internal universes' of systems are shown to constitute an indexed category of statistical games over polynomials; their dynamics form an indexed category of behaviours. We characterize 'active inference doctrines' as indexed functors between such categories, resolving a number of open problems in our earlier work, and pointing to a formalization of the 'free energy principle' as adjoint to such doctrines. We illustrate our framework through fundamental examples from biology, including homeostasis, morphogenesis, and autopoiesis, and suggest a formal connection between spatial navigation and the process of proof.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2211.01831.pdf"
      }
    },
    "heins2022pymdp": {
      "citation_key": "heins2022pymdp",
      "title": "pymdp: A Python library for active inference in discrete state spaces",
      "authors": [
        "Conor Heins",
        "Beren Millidge",
        "Daphne Demekas",
        "Brennan Klein",
        "Karl Friston",
        "Iain Couzin",
        "Alexander Tschantz"
      ],
      "year": 2022,
      "doi": "10.21105/joss.04098",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2201.03904v2",
      "pdf_path": "data/pdfs/heins2022pymdp.pdf",
      "added_date": "2025-12-12T11:49:31.855147",
      "abstract": "Active inference is an account of cognition and behavior in complex systems which brings together action, perception, and learning under the theoretical mantle of Bayesian inference. Active inference has seen growing applications in academic research, especially in fields that seek to model human or animal behavior. While in recent years, some of the code arising from the active inference literature has been written in open source languages like Python and Julia, to-date, the most popular software for simulating active inference agents is the DEM toolbox of SPM, a MATLAB library originally developed for the statistical analysis and modelling of neuroimaging data. Increasing interest in active inference, manifested both in terms of sheer number as well as diversifying applications across scientific disciplines, has thus created a need for generic, widely-available, and user-friendly code for simulating active inference in open-source scientific computing languages like Python. The Python package we present here, pymdp (see https://github.com/infer-actively/pymdp), represents a significant step in this direction: namely, we provide the first open-source package for simulating active inference with partially-observable Markov Decision Processes or POMDPs. We review the package's structure and explain its advantages like modular design and customizability, while providing in-text code blocks along the way to demonstrate how it can be used to build and run active inference processes with ease. We developed pymdp to increase the accessibility and exposure of the active inference framework to researchers, engineers, and developers with diverse disciplinary backgrounds. In the spirit of open-source software, we also hope that it spurs new innovation, development, and collaboration in the growing active inference community.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2201.03904.pdf"
      }
    },
    "krayani2022novel": {
      "citation_key": "krayani2022novel",
      "title": "A Novel Resource Allocation for Anti-jamming in Cognitive-UAVs: an Active Inference Approach",
      "authors": [
        "Ali Krayani",
        "Atm S. Alam",
        "Lucio Marcenaro",
        "Arumugam Nallanathan",
        "Carlo Regazzoni"
      ],
      "year": 2022,
      "doi": "10.1109/LCOMM.2022.3190971",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2208.05269v1",
      "pdf_path": "data/pdfs/krayani2022novel.pdf",
      "added_date": "2025-12-12T11:49:31.860213",
      "abstract": "This work proposes a novel resource allocation strategy for anti-jamming in Cognitive Radio using Active Inference ($\\textit{AIn}$), and a cognitive-UAV is employed as a case study. An Active Generalized Dynamic Bayesian Network (Active-GDBN) is proposed to represent the external environment that jointly encodes the physical signal dynamics and the dynamic interaction between UAV and jammer in the spectrum. We cast the action and planning as a Bayesian inference problem that can be solved by avoiding surprising states (minimizing abnormality) during online learning. Simulation results verify the effectiveness of the proposed $\\textit{AIn}$ approach in minimizing abnormalities (maximizing rewards) and has a high convergence speed by comparing it with the conventional Frequency Hopping and Q-learning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2208.05269.pdf"
      }
    },
    "biehl2022interpreting": {
      "citation_key": "biehl2022interpreting",
      "title": "Interpreting systems as solving POMDPs: a step towards a formal understanding of agency",
      "authors": [
        "Martin Biehl",
        "Nathaniel Virgo"
      ],
      "year": 2022,
      "doi": "10.1007/978-3-031-28719-0_2",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2209.01619v2",
      "pdf_path": "data/pdfs/biehl2022interpreting.pdf",
      "added_date": "2025-12-12T11:49:31.864815",
      "abstract": "Under what circumstances can a system be said to have beliefs and goals, and how do such agency-related features relate to its physical state? Recent work has proposed a notion of interpretation map, a function that maps the state of a system to a probability distribution representing its beliefs about an external world. Such a map is not completely arbitrary, as the beliefs it attributes to the system must evolve over time in a manner that is consistent with Bayes' theorem, and consequently the dynamics of a system constrain its possible interpretations. Here we build on this approach, proposing a notion of interpretation not just in terms of beliefs but in terms of goals and actions. To do this we make use of the existing theory of partially observable Markov processes (POMDPs): we say that a system can be interpreted as a solution to a POMDP if it not only admits an interpretation map describing its beliefs about the hidden state of a POMDP but also takes actions that are optimal according to its belief state. An agent is then a system together with an interpretation of this system as a POMDP solution. Although POMDPs are not the only possible formulation of what it means to have a goal, this nevertheless represents a step towards a more general formal definition of what it means for a system to be an agent.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2209.01619.pdf"
      }
    },
    "sakthivadivel2022worked": {
      "citation_key": "sakthivadivel2022worked",
      "title": "A Worked Example of the Bayesian Mechanics of Classical Objects",
      "authors": [
        "Dalton A R Sakthivadivel"
      ],
      "year": 2022,
      "doi": "10.1007/978-3-031-28719-0_21",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2206.12996v2",
      "pdf_path": "data/pdfs/sakthivadivel2022worked.pdf",
      "added_date": "2025-12-12T11:49:31.869817",
      "abstract": "Bayesian mechanics is a new approach to studying the mathematics and physics of interacting stochastic processes. Here, we provide a worked example of a physical mechanics for classical objects, which derives from a simple application thereof. We summarise the current state of the art of Bayesian mechanics in doing so. We also give a sketch of its connections to classical chaos, owing to a particular $\\mathcal{N}=2$ supersymmetry.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2206.12996.pdf"
      }
    },
    "friston2022designing": {
      "citation_key": "friston2022designing",
      "title": "Designing Ecosystems of Intelligence from First Principles",
      "authors": [
        "Karl J Friston",
        "Maxwell J D Ramstead",
        "Alex B Kiefer",
        "Alexander Tschantz",
        "Christopher L Buckley",
        "Mahault Albarracin",
        "Riddhi J Pitliya",
        "Conor Heins",
        "Brennan Klein",
        "Beren Millidge",
        "Dalton A R Sakthivadivel",
        "Toby St Clere Smithe",
        "Magnus Koudahl",
        "Safae Essafi Tremblay",
        "Capm Petersen",
        "Kaiser Fung",
        "Jason G Fox",
        "Steven Swanson",
        "Dan Mapes",
        "Gabriel René"
      ],
      "year": 2022,
      "doi": "10.1177/26339137231222481",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2212.01354v2",
      "pdf_path": "data/pdfs/friston2022designing.pdf",
      "added_date": "2025-12-12T11:49:31.874442",
      "abstract": "This white paper lays out a vision of research and development in the field of artificial intelligence for the next decade (and beyond). Its denouement is a cyber-physical ecosystem of natural and synthetic sense-making, in which humans are integral participants -- what we call ''shared intelligence''. This vision is premised on active inference, a formulation of adaptive behavior that can be read as a physics of intelligence, and which inherits from the physics of self-organization. In this context, we understand intelligence as the capacity to accumulate evidence for a generative model of one's sensed world -- also known as self-evidencing. Formally, this corresponds to maximizing (Bayesian) model evidence, via belief updating over several scales: i.e., inference, learning, and model selection. Operationally, this self-evidencing can be realized via (variational) message passing or belief propagation on a factor graph. Crucially, active inference foregrounds an existential imperative of intelligent systems; namely, curiosity or the resolution of uncertainty. This same imperative underwrites belief sharing in ensembles of agents, in which certain aspects (i.e., factors) of each agent's generative world model provide a common ground or frame of reference. Active inference plays a foundational role in this ecology of belief sharing -- leading to a formal account of collective intelligence that rests on shared narratives and goals. We also consider the kinds of communication protocols that must be developed to enable such an ecosystem of intelligences and motivate the development of a shared hyper-spatial modeling language and transaction protocol, as a first -- and key -- step towards such an ecology.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2212.01354.pdf"
      }
    },
    "taniguchi2022active": {
      "citation_key": "taniguchi2022active",
      "title": "Active Exploration based on Information Gain by Particle Filter for Efficient Spatial Concept Formation",
      "authors": [
        "Akira Taniguchi",
        "Yoshiki Tabuchi",
        "Tomochika Ishikawa",
        "Lotfi El Hafi",
        "Yoshinobu Hagiwara",
        "Tadahiro Taniguchi"
      ],
      "year": 2022,
      "doi": "10.1080/01691864.2023.2225175",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2211.10934v2",
      "pdf_path": "data/pdfs/taniguchi2022active.pdf",
      "added_date": "2025-12-12T11:49:31.879720",
      "abstract": "Autonomous robots need to learn the categories of various places by exploring their environments and interacting with users. However, preparing training datasets with linguistic instructions from users is time-consuming and labor-intensive. Moreover, effective exploration is essential for appropriate concept formation and rapid environmental coverage. To address this issue, we propose an active inference method, referred to as spatial concept formation with information gain-based active exploration (SpCoAE) that combines sequential Bayesian inference using particle filters and information gain-based destination determination in a probabilistic generative model. This study interprets the robot's action as a selection of destinations to ask the user, `What kind of place is this?' in the context of active inference. This study provides insights into the technical aspects of the proposed method, including active perception and exploration by the robot, and how the method can enable mobile robots to learn spatial concepts through active exploration. Our experiment demonstrated the effectiveness of the SpCoAE in efficiently determining a destination for learning appropriate spatial concepts in home environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2211.10934.pdf"
      }
    },
    "scholz2022inference": {
      "citation_key": "scholz2022inference",
      "title": "Inference of Affordances and Active Motor Control in Simulated Agents",
      "authors": [
        "Fedor Scholz",
        "Christian Gumbsch",
        "Sebastian Otte",
        "Martin V. Butz"
      ],
      "year": 2022,
      "doi": "10.3389/fnbot.2022.881673",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2202.11532v3",
      "pdf_path": "data/pdfs/scholz2022inference.pdf",
      "added_date": "2025-12-12T11:49:31.884295",
      "abstract": "Flexible, goal-directed behavior is a fundamental aspect of human life. Based on the free energy minimization principle, the theory of active inference formalizes the generation of such behavior from a computational neuroscience perspective. Based on the theory, we introduce an output-probabilistic, temporally predictive, modular artificial neural network architecture, which processes sensorimotor information, infers behavior-relevant aspects of its world, and invokes highly flexible, goal-directed behavior. We show that our architecture, which is trained end-to-end to minimize an approximation of free energy, develops latent states that can be interpreted as affordance maps. That is, the emerging latent states signal which actions lead to which effects dependent on the local context. In combination with active inference, we show that flexible, goal-directed behavior can be invoked, incorporating the emerging affordance maps. As a result, our simulated agent flexibly steers through continuous spaces, avoids collisions with obstacles, and prefers pathways that lead to the goal with high certainty. Additionally, we show that the learned agent is highly suitable for zero-shot generalization across environments: After training the agent in a handful of fixed environments with obstacles and other terrains affecting its behavior, it performs similarly well in procedurally generated environments containing different amounts of obstacles and terrains of various sizes at different locations.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2202.11532.pdf"
      }
    },
    "smithe2022open": {
      "citation_key": "smithe2022open",
      "title": "Open Dynamical Systems as Coalgebras for Polynomial Functors, with Application to Predictive Processing",
      "authors": [
        "Toby St. Clere Smithe"
      ],
      "year": 2022,
      "doi": "10.4204/EPTCS.380.18",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2206.03868v2",
      "pdf_path": "data/pdfs/smithe2022open.pdf",
      "added_date": "2025-12-12T11:49:31.889703",
      "abstract": "We present categories of open dynamical systems with general time evolution as categories of coalgebras opindexed by polynomial interfaces, and show how this extends the coalgebraic framework to capture common scientific applications such as ordinary differential equations, open Markov processes, and random dynamical systems. We then extend Spivak's operad Org to this setting, and construct associated monoidal categories whose morphisms represent hierarchical open systems; when their interfaces are simple, these categories supply canonical comonoid structures. We exemplify these constructions using the 'Laplace doctrine', which provides dynamical semantics for active inference, and indicate some connections to Bayesian inversion and coalgebraic logic.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2206.03868.pdf"
      }
    },
    "barp2022geometric": {
      "citation_key": "barp2022geometric",
      "title": "Geometric Methods for Sampling, Optimisation, Inference and Adaptive Agents",
      "authors": [
        "Alessandro Barp",
        "Lancelot Da Costa",
        "Guilherme França",
        "Karl Friston",
        "Mark Girolami",
        "Michael I. Jordan",
        "Grigorios A. Pavliotis"
      ],
      "year": 2022,
      "doi": "10.1016/bs.host.2022.03.005",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2203.10592v3",
      "pdf_path": "data/pdfs/barp2022geometric.pdf",
      "added_date": "2025-12-12T11:49:31.894738",
      "abstract": "In this chapter, we identify fundamental geometric structures that underlie the problems of sampling, optimisation, inference and adaptive decision-making. Based on this identification, we derive algorithms that exploit these geometric structures to solve these problems efficiently. We show that a wide range of geometric theories emerge naturally in these fields, ranging from measure-preserving processes, information divergences, Poisson geometry, and geometric integration. Specifically, we explain how (i) leveraging the symplectic geometry of Hamiltonian systems enable us to construct (accelerated) sampling and optimisation methods, (ii) the theory of Hilbertian subspaces and Stein operators provides a general methodology to obtain robust estimators, (iii) preserving the information geometry of decision-making yields adaptive agents that perform active inference. Throughout, we emphasise the rich connections between these fields; e.g., inference draws on sampling and optimisation, and adaptive decision-making assesses decisions by inferring their counterfactual consequences. Our exposition provides a conceptual overview of underlying ideas, rather than a technical discussion, which can be found in the references herein.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2203.10592.pdf"
      }
    },
    "fields2022neurons": {
      "citation_key": "fields2022neurons",
      "title": "Neurons as hierarchies of quantum reference frames",
      "authors": [
        "Chris Fields",
        "James F. Glazebrook",
        "Michael Levin"
      ],
      "year": 2022,
      "doi": "10.1016/j.biosystems.2022.104714",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2201.00921v1",
      "pdf_path": "data/pdfs/fields2022neurons.pdf",
      "added_date": "2025-12-12T11:49:31.899228",
      "abstract": "Conceptual and mathematical models of neurons have lagged behind empirical understanding for decades. Here we extend previous work in modeling biological systems with fully scale-independent quantum information-theoretic tools to develop a uniform, scalable representation of synapses, dendritic and axonal processes, neurons, and local networks of neurons. In this representation, hierarchies of quantum reference frames act as hierarchical active-inference systems. The resulting model enables specific predictions of correlations between synaptic activity, dendritic remodeling, and trophic reward. We summarize how the model may be generalized to nonneural cells and tissues in developmental and regenerative contexts.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2201.00921.pdf"
      }
    },
    "maisto2022interactive": {
      "citation_key": "maisto2022interactive",
      "title": "Interactive inference: a multi-agent model of cooperative joint actions",
      "authors": [
        "Domenico Maisto",
        "Francesco Donnarumma",
        "Giovanni Pezzulo"
      ],
      "year": 2022,
      "doi": "10.1109/TSMC.2023.3312585",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2210.13113v2",
      "pdf_path": "data/pdfs/maisto2022interactive.pdf",
      "added_date": "2025-12-12T11:49:31.904408",
      "abstract": "We advance a novel computational model of multi-agent, cooperative joint actions that is grounded in the cognitive framework of active inference. The model assumes that to solve a joint task, such as pressing together a red or blue button, two (or more) agents engage in a process of interactive inference. Each agent maintains probabilistic beliefs about the goal of the joint task (e.g., should we press the red or blue button?) and updates them by observing the other agent's movements, while in turn selecting movements that make his own intentions legible and easy to infer by the other agent (i.e., sensorimotor communication). Over time, the interactive inference aligns both the beliefs and the behavioral strategies of the agents, hence ensuring the success of the joint action. We exemplify the functioning of the model in two simulations. The first simulation illustrates a ''leaderless'' joint action. It shows that when two agents lack a strong preference about their joint task goal, they jointly infer it by observing each other's movements. In turn, this helps the interactive alignment of their beliefs and behavioral strategies. The second simulation illustrates a \"leader-follower\" joint action. It shows that when one agent (\"leader\") knows the true joint goal, it uses sensorimotor communication to help the other agent (\"follower\") infer it, even if doing this requires selecting a more costly individual plan. These simulations illustrate that interactive inference supports successful multi-agent joint actions and reproduces key cognitive and behavioral dynamics of \"leaderless\" and \"leader-follower\" joint actions observed in human-human experiments. In sum, interactive inference provides a cognitively inspired, formal framework to realize cooperative joint actions and consensus in multi-agent systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2210.13113.pdf"
      }
    },
    "ororbia2023mortal": {
      "citation_key": "ororbia2023mortal",
      "title": "Mortal Computation: A Foundation for Biomimetic Intelligence",
      "authors": [
        "Alexander Ororbia",
        "Karl Friston"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2311.09589v2",
      "pdf_path": "data/pdfs/ororbia2023mortal.pdf",
      "added_date": "2025-12-12T11:49:31.917082",
      "abstract": "This review motivates and synthesizes research efforts in neuroscience-inspired artificial intelligence and biomimetic computing in terms of mortal computation. Specifically, we characterize the notion of mortality by recasting ideas in biophysics, cybernetics, and cognitive science in terms of a theoretical foundation for sentient behavior. We frame the mortal computation thesis through the Markov blanket formalism and the circular causality entailed by inference, learning, and selection. The ensuing framework -- underwritten by the free energy principle -- could prove useful for guiding the construction of unconventional connectionist computational systems, neuromorphic intelligence, and chimeric agents, including sentient organoids, which stand to revolutionize the long-term future of embodied, enactive artificial intelligence and cognition research.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2311.09589.pdf"
      }
    },
    "brody2023quantum": {
      "citation_key": "brody2023quantum",
      "title": "Quantum formalism for cognitive psychology",
      "authors": [
        "Dorje C Brody"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2303.06055v1",
      "pdf_path": "data/pdfs/brody2023quantum.pdf",
      "added_date": "2025-12-12T11:49:31.921868",
      "abstract": "The cognitive state of mind concerning a range of choices to be made can effectively be modelled in terms of an element of a high-dimensional Hilbert space. The dynamics of the state of mind resulting form information acquisition is characterised by the von Neumann-Lüders projection postulate of quantum theory. This is shown to give rise to an uncertainty-minimising dynamical behaviour equivalent to the Bayesian updating, hence providing an alternative approach to characterising the dynamics of cognitive state that is consistent with the free energy principle in brain science. The quantum formalism however goes beyond the range of applicability of classical reasoning in explaining cognitive behaviours, thus opens up new and intriguing possibilities.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2303.06055.pdf"
      }
    },
    "jiang2023theory": {
      "citation_key": "jiang2023theory",
      "title": "A Theory of Human-Like Few-Shot Learning",
      "authors": [
        "Zhiying Jiang",
        "Rui Wang",
        "Dongbo Bu",
        "Ming Li"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2301.01047v1",
      "pdf_path": "data/pdfs/jiang2023theory.pdf",
      "added_date": "2025-12-12T11:49:31.927056",
      "abstract": "We aim to bridge the gap between our common-sense few-sample human learning and large-data machine learning. We derive a theory of human-like few-shot learning from von-Neuman-Landauer's principle. modelling human learning is difficult as how people learn varies from one to another. Under commonly accepted definitions, we prove that all human or animal few-shot learning, and major models including Free Energy Principle and Bayesian Program Learning that model such learning, approximate our theory, under Church-Turing thesis. We find that deep generative model like variational autoencoder (VAE) can be used to approximate our theory and perform significantly better than baseline models including deep neural networks, for image recognition, low resource language processing, and character recognition.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2301.01047.pdf"
      }
    },
    "costa2023towards": {
      "citation_key": "costa2023towards",
      "title": "Towards a Bayesian mechanics of metacognitive particles: A commentary on \"Path integrals, particular kinds, and strange things\" by Friston, Da Costa, Sakthivadivel, Heins, Pavliotis, Ramstead, and Parr",
      "authors": [
        "Lancelot Da Costa",
        "Lars Sandved-Smith"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2403.06981v1",
      "pdf_path": "data/pdfs/costa2023towards.pdf",
      "added_date": "2025-12-12T11:49:31.931764",
      "abstract": "What could metacognition look like in simple physical terms? We define metacognition as having beliefs about beliefs, which can be articulated very simply using the language of statistical physics and Bayesian mechanics. We introduce a typology between cognitive and metacognitive particles and develop an example of a metacognitive particle. This can be generalized to provide examples of higher forms of metacognition: i.e. particles having beliefs about beliefs about beliefs and so forth. We conclude by saying that the typology of particles laid down in the target article seems promising, for seemingly enabling a physics of cognition that builds upon and refines the free energy principle, toward a physical description of entities that specifically possess higher forms of cognition.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2403.06981.pdf"
      }
    },
    "carl2023empirical": {
      "citation_key": "carl2023empirical",
      "title": "Empirical Translation Process Research: Past and Possible Future Perspectives",
      "authors": [
        "Michael Carl"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2308.01368v1",
      "pdf_path": "data/pdfs/carl2023empirical.pdf",
      "added_date": "2025-12-12T11:49:31.936699",
      "abstract": "Over the past four decades, efforts have been made to develop and evaluate models for Empirical Translation Process Research (TPR), yet a comprehensive framework remains elusive. This article traces the evolution of empirical TPR within the CRITT TPR-DB tradition and proposes the Free Energy Principle (FEP) and Active Inference (AIF) as a framework for modeling deeply embedded translation processes. It introduces novel approaches for quantifying fundamental concepts of Relevance Theory (relevance, s-mode, i-mode), and establishes their relation to the Monitor Model, framing relevance maximization as a special case of minimizing free energy. FEP/AIF provides a mathematically rigorous foundation that enables modeling of deep temporal architectures in which embedded translation processes unfold on different timelines. This framework opens up exciting prospects for future research in predictive TPR, likely to enrich our comprehension of human translation processes, and making valuable contributions to the wider realm of translation studies and the design of cognitive architectures.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2308.01368.pdf"
      }
    },
    "prabhushankar2023stochastic": {
      "citation_key": "prabhushankar2023stochastic",
      "title": "Stochastic Surprisal: An inferential measurement of Free Energy in Neural Networks",
      "authors": [
        "Mohit Prabhushankar",
        "Ghassan AlRegib"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2302.05776v1",
      "pdf_path": "data/pdfs/prabhushankar2023stochastic.pdf",
      "added_date": "2025-12-12T11:49:31.941123",
      "abstract": "This paper conjectures and validates a framework that allows for action during inference in supervised neural networks. Supervised neural networks are constructed with the objective to maximize their performance metric in any given task. This is done by reducing free energy and its associated surprisal during training. However, the bottom-up inference nature of supervised networks is a passive process that renders them fallible to noise. In this paper, we provide a thorough background of supervised neural networks, both generative and discriminative, and discuss their functionality from the perspective of free energy principle. We then provide a framework for introducing action during inference. We introduce a new measurement called stochastic surprisal that is a function of the network, the input, and any possible action. This action can be any one of the outputs that the neural network has learnt, thereby lending stochasticity to the measurement. Stochastic surprisal is validated on two applications: Image Quality Assessment and Recognition under noisy conditions. We show that, while noise characteristics are ignored to make robust recognition, they are analyzed to estimate image quality scores. We apply stochastic surprisal on two applications, three datasets, and as a plug-in on twelve networks. In all, it provides a statistically significant increase among all measures. We conclude by discussing the implications of the proposed stochastic surprisal in other areas of cognitive psychology including expectancy-mismatch and abductive reasoning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2302.05776.pdf"
      }
    },
    "albarracin2023designing": {
      "citation_key": "albarracin2023designing",
      "title": "Designing explainable artificial intelligence with active inference: A framework for transparent introspection and decision-making",
      "authors": [
        "Mahault Albarracin",
        "Inês Hipólito",
        "Safae Essafi Tremblay",
        "Jason G. Fox",
        "Gabriel René",
        "Karl Friston",
        "Maxwell J. D. Ramstead"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2306.04025v1",
      "pdf_path": "data/pdfs/albarracin2023designing.pdf",
      "added_date": "2025-12-12T11:49:31.946348",
      "abstract": "This paper investigates the prospect of developing human-interpretable, explainable artificial intelligence (AI) systems based on active inference and the free energy principle. We first provide a brief overview of active inference, and in particular, of how it applies to the modeling of decision-making, introspection, as well as the generation of overt and covert actions. We then discuss how active inference can be leveraged to design explainable AI systems, namely, by allowing us to model core features of ``introspective'' processes and by generating useful, human-interpretable models of the processes involved in decision-making. We propose an architecture for explainable AI systems using active inference. This architecture foregrounds the role of an explicit hierarchical generative model, the operation of which enables the AI system to track and explain the factors that contribute to its own decisions, and whose structure is designed to be interpretable and auditable by human users. We outline how this architecture can integrate diverse sources of information to make informed decisions in an auditable manner, mimicking or reproducing aspects of human-like consciousness and introspection. Finally, we discuss the implications of our findings for future research in AI, and the potential ethical considerations of developing AI systems with (the appearance of) introspective capabilities.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2306.04025.pdf"
      }
    },
    "friston2023active": {
      "citation_key": "friston2023active",
      "title": "Active Inference and Intentional Behaviour",
      "authors": [
        "Karl J. Friston",
        "Tommaso Salvatori",
        "Takuya Isomura",
        "Alexander Tschantz",
        "Alex Kiefer",
        "Tim Verbelen",
        "Magnus Koudahl",
        "Aswin Paul",
        "Thomas Parr",
        "Adeel Razi",
        "Brett Kagan",
        "Christopher L. Buckley",
        "Maxwell J. D. Ramstead"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2312.07547v2",
      "pdf_path": "data/pdfs/friston2023active.pdf",
      "added_date": "2025-12-12T11:49:31.951249",
      "abstract": "Recent advances in theoretical biology suggest that basal cognition and sentient behaviour are emergent properties of in vitro cell cultures and neuronal networks, respectively. Such neuronal networks spontaneously learn structured behaviours in the absence of reward or reinforcement. In this paper, we characterise this kind of self-organisation through the lens of the free energy principle, i.e., as self-evidencing. We do this by first discussing the definitions of reactive and sentient behaviour in the setting of active inference, which describes the behaviour of agents that model the consequences of their actions. We then introduce a formal account of intentional behaviour, that describes agents as driven by a preferred endpoint or goal in latent state-spaces. We then investigate these forms of (reactive, sentient, and intentional) behaviour using simulations. First, we simulate the aforementioned in vitro experiments, in which neuronal cultures spontaneously learn to play Pong, by implementing nested, free energy minimising processes. The simulations are then used to deconstruct the ensuing predictive behaviour, leading to the distinction between merely reactive, sentient, and intentional behaviour, with the latter formalised in terms of inductive planning. This distinction is further studied using simple machine learning benchmarks (navigation in a grid world and the Tower of Hanoi problem), that show how quickly and efficiently adaptive behaviour emerges under an inductive form of active inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2312.07547.pdf"
      }
    },
    "koudahl2023realising": {
      "citation_key": "koudahl2023realising",
      "title": "Realising Synthetic Active Inference Agents, Part I: Epistemic Objectives and Graphical Specification Language",
      "authors": [
        "Magnus Koudahl",
        "Thijs van de Laar",
        "Bert de Vries"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2306.08014v2",
      "pdf_path": "data/pdfs/koudahl2023realising.pdf",
      "added_date": "2025-12-12T11:49:31.956224",
      "abstract": "The Free Energy Principle (FEP) is a theoretical framework for describing how (intelligent) systems self-organise into coherent, stable structures by minimising a free energy functional. Active Inference (AIF) is a corollary of the FEP that specifically details how systems that are able to plan for the future (agents) function by minimising particular free energy functionals that incorporate information seeking components. This paper is the first in a series of two where we derive a synthetic version of AIF on free form factor graphs. The present paper focuses on deriving a local version of the free energy functionals used for AIF. This enables us to construct a version of AIF which applies to arbitrary graphical models and interfaces with prior work on message passing algorithms. The resulting messages are derived in our companion paper. We also identify a gap in the graphical notation used for factor graphs. While factor graphs are great at expressing a generative model, they have so far been unable to specify the full optimisation problem including constraints. To solve this problem we develop Constrained Forney-style Factor Graph (CFFG) notation which permits a fully graphical description of variational inference objectives. We then proceed to show how CFFG's can be used to reconstruct prior algorithms for AIF as well as derive new ones. The latter is demonstrated by deriving an algorithm that permits direct policy inference for AIF agents, circumventing a long standing scaling issue that has so far hindered the application of AIF in industrial settings. We demonstrate our algorithm on the classic T-maze task and show that it reproduces the information seeking behaviour that is a hallmark feature of AIF.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2306.08014.pdf"
      }
    },
    "fields2023control": {
      "citation_key": "fields2023control",
      "title": "Control flow in active inference systems",
      "authors": [
        "Chris Fields",
        "Filippo Fabrocini",
        "Karl Friston",
        "James F. Glazebrook",
        "Hananel Hazan",
        "Michael Levin",
        "Antonino Marciano"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2303.01514v1",
      "pdf_path": "data/pdfs/fields2023control.pdf",
      "added_date": "2025-12-12T11:49:31.961573",
      "abstract": "Living systems face both environmental complexity and limited access to free-energy resources. Survival under these conditions requires a control system that can activate, or deploy, available perception and action resources in a context specific way. We show here that when systems are described as executing active inference driven by the free-energy principle (and hence can be considered Bayesian prediction-error minimizers), their control flow systems can always be represented as tensor networks (TNs). We show how TNs as control systems can be implmented within the general framework of quantum topological neural networks, and discuss the implications of these results for modeling biological systems at multiple scales.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2303.01514.pdf"
      }
    },
    "barbierchebbah2023approximate": {
      "citation_key": "barbierchebbah2023approximate",
      "title": "Approximate information maximization for bandit games",
      "authors": [
        "Alex Barbier-Chebbah",
        "Christian L. Vestergaard",
        "Jean-Baptiste Masson",
        "Etienne Boursier"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2310.12563v3",
      "pdf_path": "data/pdfs/barbierchebbah2023approximate.pdf",
      "added_date": "2025-12-12T11:49:31.966154",
      "abstract": "Entropy maximization and free energy minimization are general physical principles for modeling the dynamics of various physical systems. Notable examples include modeling decision-making within the brain using the free-energy principle, optimizing the accuracy-complexity trade-off when accessing hidden variables with the information bottleneck principle (Tishby et al., 2000), and navigation in random environments using information maximization (Vergassola et al., 2007). Built on this principle, we propose a new class of bandit algorithms that maximize an approximation to the information of a key variable within the system. To this end, we develop an approximated analytical physics-based representation of an entropy to forecast the information gain of each action and greedily choose the one with the largest information gain. This method yields strong performances in classical bandit settings. Motivated by its empirical success, we prove its asymptotic optimality for the two-armed bandit problem with Gaussian rewards. Owing to its ability to encompass the system's properties in a global physical functional, this approach can be efficiently adapted to more complex bandit settings, calling for further investigation of information maximization approaches for multi-armed bandit problems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2310.12563.pdf"
      }
    },
    "taniguchi2023world": {
      "citation_key": "taniguchi2023world",
      "title": "World Models and Predictive Coding for Cognitive and Developmental Robotics: Frontiers and Challenges",
      "authors": [
        "Tadahiro Taniguchi",
        "Shingo Murata",
        "Masahiro Suzuki",
        "Dimitri Ognibene",
        "Pablo Lanillos",
        "Emre Ugur",
        "Lorenzo Jamone",
        "Tomoaki Nakamura",
        "Alejandra Ciria",
        "Bruno Lara",
        "Giovanni Pezzulo"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2301.05832v1",
      "pdf_path": "data/pdfs/taniguchi2023world.pdf",
      "added_date": "2025-12-12T11:49:31.971444",
      "abstract": "Creating autonomous robots that can actively explore the environment, acquire knowledge and learn skills continuously is the ultimate achievement envisioned in cognitive and developmental robotics. Their learning processes should be based on interactions with their physical and social world in the manner of human learning and cognitive development. Based on this context, in this paper, we focus on the two concepts of world models and predictive coding. Recently, world models have attracted renewed attention as a topic of considerable interest in artificial intelligence. Cognitive systems learn world models to better predict future sensory observations and optimize their policies, i.e., controllers. Alternatively, in neuroscience, predictive coding proposes that the brain continuously predicts its inputs and adapts to model its own dynamics and control behavior in its environment. Both ideas may be considered as underpinning the cognitive development of robots and humans capable of continual or lifelong learning. Although many studies have been conducted on predictive coding in cognitive robotics and neurorobotics, the relationship between world model-based approaches in AI and predictive coding in robotics has rarely been discussed. Therefore, in this paper, we clarify the definitions, relationships, and status of current research on these topics, as well as missing pieces of world models and predictive coding in conjunction with crucially related concepts such as the free-energy principle and active inference in the context of cognitive and developmental robotics. Furthermore, we outline the frontiers and challenges involved in world models and predictive coding toward the further integration of AI and robotics, as well as the creation of robots with real cognitive and developmental capabilities in the future.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2301.05832.pdf"
      }
    },
    "maele2023integrating": {
      "citation_key": "maele2023integrating",
      "title": "Integrating cognitive map learning and active inference for planning in ambiguous environments",
      "authors": [
        "Toon Van de Maele",
        "Bart Dhoedt",
        "Tim Verbelen",
        "Giovanni Pezzulo"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2308.08307v1",
      "pdf_path": "data/pdfs/maele2023integrating.pdf",
      "added_date": "2025-12-12T11:49:31.977087",
      "abstract": "Living organisms need to acquire both cognitive maps for learning the structure of the world and planning mechanisms able to deal with the challenges of navigating ambiguous environments. Although significant progress has been made in each of these areas independently, the best way to integrate them is an open research question. In this paper, we propose the integration of a statistical model of cognitive map formation within an active inference agent that supports planning under uncertainty. Specifically, we examine the clone-structured cognitive graph (CSCG) model of cognitive map formation and compare a naive clone graph agent with an active inference-driven clone graph agent, in three spatial navigation scenarios. Our findings demonstrate that while both agents are effective in simple scenarios, the active inference agent is more effective when planning in challenging scenarios, in which sensory observations provide ambiguous information about location.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2308.08307.pdf"
      }
    },
    "collis2023understanding": {
      "citation_key": "collis2023understanding",
      "title": "Understanding Tool Discovery and Tool Innovation Using Active Inference",
      "authors": [
        "Poppy Collis",
        "Paul F Kinghorn",
        "Christopher L Buckley"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2311.03893v1",
      "pdf_path": "data/pdfs/collis2023understanding.pdf",
      "added_date": "2025-12-12T11:49:31.982092",
      "abstract": "The ability to invent new tools has been identified as an important facet of our ability as a species to problem solve in dynamic and novel environments. While the use of tools by artificial agents presents a challenging task and has been widely identified as a key goal in the field of autonomous robotics, far less research has tackled the invention of new tools by agents. In this paper, (1) we articulate the distinction between tool discovery and tool innovation by providing a minimal description of the two concepts under the formalism of active inference. We then (2) apply this description to construct a toy model of tool innovation by introducing the notion of tool affordances into the hidden states of the agent's probabilistic generative model. This particular state factorisation facilitates the ability to not just discover tools but invent them through the offline induction of an appropriate tool property. We discuss the implications of these preliminary results and outline future directions of research.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2311.03893.pdf"
      }
    },
    "kulveit2023predictive": {
      "citation_key": "kulveit2023predictive",
      "title": "Predictive Minds: LLMs As Atypical Active Inference Agents",
      "authors": [
        "Jan Kulveit",
        "Clem von Stengel",
        "Roman Leventov"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2311.10215v1",
      "pdf_path": "data/pdfs/kulveit2023predictive.pdf",
      "added_date": "2025-12-12T11:49:31.987500",
      "abstract": "Large language models (LLMs) like GPT are often conceptualized as passive predictors, simulators, or even stochastic parrots. We instead conceptualize LLMs by drawing on the theory of active inference originating in cognitive science and neuroscience. We examine similarities and differences between traditional active inference systems and LLMs, leading to the conclusion that, currently, LLMs lack a tight feedback loop between acting in the world and perceiving the impacts of their actions, but otherwise fit in the active inference paradigm. We list reasons why this loop may soon be closed, and possible consequences of this including enhanced model self-awareness and the drive to minimize prediction error by changing the world.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2311.10215.pdf"
      }
    },
    "vries2023toward": {
      "citation_key": "vries2023toward",
      "title": "Toward Design of Synthetic Active Inference Agents by Mere Mortals",
      "authors": [
        "Bert de Vries"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2307.14145v1",
      "pdf_path": "data/pdfs/vries2023toward.pdf",
      "added_date": "2025-12-12T11:49:31.992182",
      "abstract": "The theoretical properties of active inference agents are impressive, but how do we realize effective agents in working hardware and software on edge devices? This is an interesting problem because the computational load for policy exploration explodes exponentially, while the computational resources are very limited for edge devices. In this paper, we discuss the necessary features for a software toolbox that supports a competent non-expert engineer to develop working active inference agents. We introduce a toolbox-in-progress that aims to accelerate the democratization of active inference agents in a similar way as TensorFlow propelled applications of deep learning technology.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2307.14145.pdf"
      }
    },
    "champion2023deconstructing": {
      "citation_key": "champion2023deconstructing",
      "title": "Deconstructing deep active inference",
      "authors": [
        "Théophile Champion",
        "Marek Grześ",
        "Lisa Bonheme",
        "Howard Bowman"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2303.01618v2",
      "pdf_path": "data/pdfs/champion2023deconstructing.pdf",
      "added_date": "2025-12-12T11:49:31.997658",
      "abstract": "Active inference is a theory of perception, learning and decision making, which can be applied to neuroscience, robotics, and machine learning. Recently, reasearch has been taking place to scale up this framework using Monte-Carlo tree search and deep learning. The goal of this activity is to solve more complicated tasks using deep active inference. First, we review the existing literature, then, we progresively build a deep active inference agent. For two agents, we have experimented with five definitions of the expected free energy and three different action selection strategies. According to our experiments, the models able to solve the dSprites environment are the ones that maximise rewards. Finally, we compare the similarity of the representation learned by the layers of various agents using centered kernel alignment. Importantly, the agent maximising reward and the agent minimising expected free energy learn very similar representations except for the last layer of the critic network (reflecting the difference in learning objective), and the variance layers of the transition and encoder networks. We found that the reward maximising agent is a lot more certain than the agent minimising expected free energy. This is because the agent minimising expected free energy always picks the action down, and does not gather enough data for the other actions. In contrast, the agent maximising reward, keeps on selecting the actions left and right, enabling it to successfully solve the task. The only difference between those two agents is the epistemic value, which aims to make the outputs of the transition and encoder networks as close as possible. Thus, the agent minimising expected free energy picks a single action (down), and becomes an expert at predicting the future when selecting this action. This makes the KL divergence between the output of the transition and encoder networks small.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2303.01618.pdf"
      }
    },
    "tull2023active": {
      "citation_key": "tull2023active",
      "title": "Active Inference in String Diagrams: A Categorical Account of Predictive Processing and Free Energy",
      "authors": [
        "Sean Tull",
        "Johannes Kleiner",
        "Toby St Clere Smithe"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2308.00861v1",
      "pdf_path": "data/pdfs/tull2023active.pdf",
      "added_date": "2025-12-12T11:49:32.003285",
      "abstract": "We present a categorical formulation of the cognitive frameworks of Predictive Processing and Active Inference, expressed in terms of string diagrams interpreted in a monoidal category with copying and discarding. This includes diagrammatic accounts of generative models, Bayesian updating, perception, planning, active inference, and free energy. In particular we present a diagrammatic derivation of the formula for active inference via free energy minimisation, and establish a compositionality property for free energy, allowing free energy to be applied at all levels of an agent's generative model. Aside from aiming to provide a helpful graphical language for those familiar with active inference, we conversely hope that this article may provide a concise formulation and introduction to the framework.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2308.00861.pdf"
      }
    },
    "maele2023objectcentric": {
      "citation_key": "maele2023objectcentric",
      "title": "Object-Centric Scene Representations using Active Inference",
      "authors": [
        "Toon Van de Maele",
        "Tim Verbelen",
        "Pietro Mazzaglia",
        "Stefano Ferraro",
        "Bart Dhoedt"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2302.03288v1",
      "pdf_path": "data/pdfs/maele2023objectcentric.pdf",
      "added_date": "2025-12-12T11:49:32.008383",
      "abstract": "Representing a scene and its constituent objects from raw sensory data is a core ability for enabling robots to interact with their environment. In this paper, we propose a novel approach for scene understanding, leveraging a hierarchical object-centric generative model that enables an agent to infer object category and pose in an allocentric reference frame using active inference, a neuro-inspired framework for action and perception. For evaluating the behavior of an active vision agent, we also propose a new benchmark where, given a target viewpoint of a particular object, the agent needs to find the best matching viewpoint given a workspace with randomly positioned objects in 3D. We demonstrate that our active inference agent is able to balance epistemic foraging and goal-driven behavior, and outperforms both supervised and reinforcement learning baselines by a large margin.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2302.03288.pdf"
      }
    },
    "wei2023learning": {
      "citation_key": "wei2023learning",
      "title": "Learning An Active Inference Model of Driver Perception and Control: Application to Vehicle Car-Following",
      "authors": [
        "Ran Wei",
        "Anthony D. McDonald",
        "Alfredo Garcia",
        "Gustav Markkula",
        "Johan Engstrom",
        "Matthew O'Kelly"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2303.15201v2",
      "pdf_path": "data/pdfs/wei2023learning.pdf",
      "added_date": "2025-12-12T11:49:32.013902",
      "abstract": "In this paper we introduce a general estimation methodology for learning a model of human perception and control in a sensorimotor control task based upon a finite set of demonstrations. The model's structure consists of i the agent's internal representation of how the environment and associated observations evolve as a result of control actions and ii the agent's preferences over observable outcomes. We consider a model's structure specification consistent with active inference, a theory of human perception and behavior from cognitive science. According to active inference, the agent acts upon the world so as to minimize surprise defined as a measure of the extent to which an agent's current sensory observations differ from its preferred sensory observations. We propose a bi-level optimization approach to estimation which relies on a structural assumption on prior distributions that parameterize the statistical accuracy of the human agent's model of the environment. To illustrate the proposed methodology, we present the estimation of a model for car-following behavior based upon a naturalistic dataset. Overall, the results indicate that learning active inference models of human perception and control from data is a promising alternative to black-box models of driving.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2303.15201.pdf"
      }
    },
    "obite2023active": {
      "citation_key": "obite2023active",
      "title": "Active Inference for Sum Rate Maximization in UAV-Assisted Cognitive NOMA Networks",
      "authors": [
        "Felix Obite",
        "Ali Krayani",
        "Atm S. Alam",
        "Lucio Marcenaro",
        "Arumugam Nallanathan",
        "Carlo Regazzoni"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2309.11263v1",
      "pdf_path": "data/pdfs/obite2023active.pdf",
      "added_date": "2025-12-12T11:49:32.019634",
      "abstract": "Given the surge in wireless data traffic driven by the emerging Internet of Things (IoT), unmanned aerial vehicles (UAVs), cognitive radio (CR), and non-orthogonal multiple access (NOMA) have been recognized as promising techniques to overcome massive connectivity issues. As a result, there is an increasing need to intelligently improve the channel capacity of future wireless networks. Motivated by active inference from cognitive neuroscience, this paper investigates joint subchannel and power allocation for an uplink UAV-assisted cognitive NOMA network. Maximizing the sum rate is often a highly challenging optimization problem due to dynamic network conditions and power constraints. To address this challenge, we propose an active inference-based algorithm. We transform the sum rate maximization problem into abnormality minimization by utilizing a generalized state-space model to characterize the time-changing network environment. The problem is then solved using an Active Generalized Dynamic Bayesian Network (Active-GDBN). The proposed framework consists of an offline perception stage, in which a UAV employs a hierarchical GDBN structure to learn an optimal generative model of discrete subchannels and continuous power allocation. In the online active inference stage, the UAV dynamically selects discrete subchannels and continuous power to maximize the sum rate of secondary users. By leveraging the errors in each episode, the UAV can adapt its resource allocation policies and belief updating to improve its performance over time. Simulation results demonstrate the effectiveness of our proposed algorithm in terms of cumulative sum rate compared to benchmark schemes.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2309.11263.pdf"
      }
    },
    "safa2023active": {
      "citation_key": "safa2023active",
      "title": "Active Inference in Hebbian Learning Networks",
      "authors": [
        "Ali Safa",
        "Tim Verbelen",
        "Lars Keuninckx",
        "Ilja Ocket",
        "André Bourdoux",
        "Francky Catthoor",
        "Georges Gielen",
        "Gert Cauwenberghs"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2306.05053v2",
      "pdf_path": "data/pdfs/safa2023active.pdf",
      "added_date": "2025-12-12T11:49:32.024586",
      "abstract": "This work studies how brain-inspired neural ensembles equipped with local Hebbian plasticity can perform active inference (AIF) in order to control dynamical agents. A generative model capturing the environment dynamics is learned by a network composed of two distinct Hebbian ensembles: a posterior network, which infers latent states given the observations, and a state transition network, which predicts the next expected latent state given current state-action pairs. Experimental studies are conducted using the Mountain Car environment from the OpenAI gym suite, to study the effect of the various Hebbian network parameters on the task performance. It is shown that the proposed Hebbian AIF approach outperforms the use of Q-learning, while not requiring any replay buffer, as in typical reinforcement learning systems. These results motivate further investigations of Hebbian learning for the design of AIF networks that can learn environment dynamics without the need for revisiting past buffered experiences.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2306.05053.pdf"
      }
    },
    "liu2023tactile": {
      "citation_key": "liu2023tactile",
      "title": "Tactile Active Inference Reinforcement Learning for Efficient Robotic Manipulation Skill Acquisition",
      "authors": [
        "Zihao Liu",
        "Xing Liu",
        "Yizhai Zhang",
        "Zhengxiong Liu",
        "Panfeng Huang"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2311.11287v1",
      "pdf_path": "data/pdfs/liu2023tactile.pdf",
      "added_date": "2025-12-12T11:49:32.030313",
      "abstract": "Robotic manipulation holds the potential to replace humans in the execution of tedious or dangerous tasks. However, control-based approaches are not suitable due to the difficulty of formally describing open-world manipulation in reality, and the inefficiency of existing learning methods. Thus, applying manipulation in a wide range of scenarios presents significant challenges. In this study, we propose a novel method for skill learning in robotic manipulation called Tactile Active Inference Reinforcement Learning (Tactile-AIRL), aimed at achieving efficient training. To enhance the performance of reinforcement learning (RL), we introduce active inference, which integrates model-based techniques and intrinsic curiosity into the RL process. This integration improves the algorithm's training efficiency and adaptability to sparse rewards. Additionally, we utilize a vision-based tactile sensor to provide detailed perception for manipulation tasks. Finally, we employ a model-based approach to imagine and plan appropriate actions through free energy minimization. Simulation results demonstrate that our method achieves significantly high training efficiency in non-prehensile objects pushing tasks. It enables agents to excel in both dense and sparse reward tasks with just a few interaction episodes, surpassing the SAC baseline. Furthermore, we conduct physical experiments on a gripper screwing task using our method, which showcases the algorithm's rapid learning capability and its potential for practical applications.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2311.11287.pdf"
      }
    },
    "kamijo2023tactilebased": {
      "citation_key": "kamijo2023tactilebased",
      "title": "Tactile-based Active Inference for Force-Controlled Peg-in-Hole Insertions",
      "authors": [
        "Tatsuya Kamijo",
        "Ixchel G. Ramirez-Alpizar",
        "Enrique Coronado",
        "Gentiane Venture"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2309.15681v1",
      "pdf_path": "data/pdfs/kamijo2023tactilebased.pdf",
      "added_date": "2025-12-12T11:49:32.036145",
      "abstract": "Reinforcement Learning (RL) has shown great promise for efficiently learning force control policies in peg-in-hole tasks. However, robots often face difficulties due to visual occlusions by the gripper and uncertainties in the initial grasping pose of the peg. These challenges often restrict force-controlled insertion policies to situations where the peg is rigidly fixed to the end-effector. While vision-based tactile sensors offer rich tactile feedback that could potentially address these issues, utilizing them to learn effective tactile policies is both computationally intensive and difficult to generalize. In this paper, we propose a robust tactile insertion policy that can align the tilted peg with the hole using active inference, without the need for extensive training on large datasets. Our approach employs a dual-policy architecture: one policy focuses on insertion, integrating force control and RL to guide the object into the hole, while the other policy performs active inference based on tactile feedback to align the tilted peg with the hole. In real-world experiments, our dual-policy architecture achieved 90% success rate into a hole with a clearance of less than 0.1 mm, significantly outperforming previous methods that lack tactile sensory feedback (5%). To assess the generalizability of our alignment policy, we conducted experiments with five different pegs, demonstrating its effective adaptation to multiple objects.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2309.15681.pdf"
      }
    },
    "donnarumma2023integrating": {
      "citation_key": "donnarumma2023integrating",
      "title": "Integrating large language models and active inference to understand eye movements in reading and dyslexia",
      "authors": [
        "Francesco Donnarumma",
        "Mirco Frosolone",
        "Giovanni Pezzulo"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2308.04941v3",
      "pdf_path": "data/pdfs/donnarumma2023integrating.pdf",
      "added_date": "2025-12-12T11:49:32.041083",
      "abstract": "We present a novel computational model employing hierarchical active inference to simulate reading and eye movements. The model characterizes linguistic processing as inference over a hierarchical generative model, facilitating predictions and inferences at various levels of granularity, from syllables to sentences. Our approach combines the strengths of large language models for realistic textual predictions and active inference for guiding eye movements to informative textual information, enabling the testing of predictions. The model exhibits proficiency in reading both known and unknown words and sentences, adhering to the distinction between lexical and nonlexical routes in dual route theories of reading. Our model therefore provides a novel approach to understand the cognitive processes underlying reading and eye movements, within a predictive processing framework. Furthermore, our model can potentially aid in understanding how maladaptive predictive processing can produce reading deficits associated with dyslexia. As a proof of concept, we show that attenuating the contribution of priors during the reading process leads to incorrect inferences and a more fragmented reading style, characterized by a greater number of shorter saccades, aligning with empirical findings regarding eye movements in dyslexic individuals. In summary, our model represents a significant advancement in comprehending the cognitive processes involved in reading and eye movements, with potential implications for understanding dyslexia in terms of maladaptive inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2308.04941.pdf"
      }
    },
    "sedlak2023active": {
      "citation_key": "sedlak2023active",
      "title": "Active Inference on the Edge: A Design Study",
      "authors": [
        "Boris Sedlak",
        "Victor Casamayor Pujol",
        "Praveen Kumar Donta",
        "Schahram Dustdar"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2311.10607v1",
      "pdf_path": "data/pdfs/sedlak2023active.pdf",
      "added_date": "2025-12-12T11:49:32.046601",
      "abstract": "Machine Learning (ML) is a common tool to interpret and predict the behavior of distributed computing systems, e.g., to optimize the task distribution between devices. As more and more data is created by Internet of Things (IoT) devices, data processing and ML training are carried out by edge devices in close proximity. To ensure Quality of Service (QoS) throughout these operations, systems are supervised and dynamically adapted with the help of ML. However, as long as ML models are not retrained, they fail to capture gradual shifts in the variable distribution, leading to an inaccurate view of the system state. Moreover, as the prediction accuracy decreases, the reporting device should actively resolve uncertainties to improve the model's precision. Such a level of self-determination could be provided by Active Inference (ACI) -- a concept from neuroscience that describes how the brain constantly predicts and evaluates sensory information to decrease long-term surprise. We encompassed these concepts in a single action-perception cycle, which we implemented for distributed agents in a smart manufacturing use case. As a result, we showed how our ACI agent was able to quickly and traceably solve an optimization problem while fulfilling QoS requirements.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2311.10607.pdf"
      }
    },
    "demekas2023analytical": {
      "citation_key": "demekas2023analytical",
      "title": "An analytical model of active inference in the Iterated Prisoner's Dilemma",
      "authors": [
        "Daphne Demekas",
        "Conor Heins",
        "Brennan Klein"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2306.15494v2",
      "pdf_path": "data/pdfs/demekas2023analytical.pdf",
      "added_date": "2025-12-12T11:49:32.052146",
      "abstract": "This paper addresses a mathematically tractable model of the Prisoner's Dilemma using the framework of active inference. In this work, we design pairs of Bayesian agents that are tracking the joint game state of their and their opponent's choices in an Iterated Prisoner's Dilemma game. The specification of the agents' belief architecture in the form of a partially-observed Markov decision process allows careful and rigourous investigation into the dynamics of two-player gameplay, including the derivation of optimal conditions for phase transitions that are required to achieve certain game-theoretic steady states. We show that the critical time points governing the phase transition are linearly related to each other as a function of learning rate and the reward function. We then investigate the patterns that emerge when varying the agents' learning rates, as well as the relationship between the stochastic and deterministic solutions to the two-agent system.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2306.15494.pdf"
      }
    },
    "tinguy2023learning": {
      "citation_key": "tinguy2023learning",
      "title": "Learning Spatial and Temporal Hierarchies: Hierarchical Active Inference for navigation in Multi-Room Maze Environments",
      "authors": [
        "Daria de Tinguy",
        "Toon Van de Maele",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2309.09864v1",
      "pdf_path": "data/pdfs/tinguy2023learning.pdf",
      "added_date": "2025-12-12T11:49:32.057217",
      "abstract": "Cognitive maps play a crucial role in facilitating flexible behaviour by representing spatial and conceptual relationships within an environment. The ability to learn and infer the underlying structure of the environment is crucial for effective exploration and navigation. This paper introduces a hierarchical active inference model addressing the challenge of inferring structure in the world from pixel-based observations. We propose a three-layer hierarchical model consisting of a cognitive map, an allocentric, and an egocentric world model, combining curiosity-driven exploration with goal-oriented behaviour at the different levels of reasoning from context to place to motion. This allows for efficient exploration and goal-directed search in room-structured mini-grid environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2309.09864.pdf"
      }
    },
    "engström2023resolving": {
      "citation_key": "engström2023resolving",
      "title": "Resolving uncertainty on the fly: Modeling adaptive driving behavior as active inference",
      "authors": [
        "Johan Engström",
        "Ran Wei",
        "Anthony McDonald",
        "Alfredo Garcia",
        "Matt O'Kelly",
        "Leif Johnson"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2311.06417v1",
      "pdf_path": "data/pdfs/engström2023resolving.pdf",
      "added_date": "2025-12-12T11:49:32.062886",
      "abstract": "Understanding adaptive human driving behavior, in particular how drivers manage uncertainty, is of key importance for developing simulated human driver models that can be used in the evaluation and development of autonomous vehicles. However, existing traffic psychology models of adaptive driving behavior either lack computational rigor or only address specific scenarios and/or behavioral phenomena. While models developed in the fields of machine learning and robotics can effectively learn adaptive driving behavior from data, due to their black box nature, they offer little or no explanation of the mechanisms underlying the adaptive behavior. Thus, a generalizable, interpretable, computational model of adaptive human driving behavior is still lacking. This paper proposes such a model based on active inference, a behavioral modeling framework originating in computational neuroscience. The model offers a principled solution to how humans trade progress against caution through policy selection based on the single mandate to minimize expected free energy. This casts goal-seeking and information-seeking (uncertainty-resolving) behavior under a single objective function, allowing the model to seamlessly resolve uncertainty as a means to obtain its goals. We apply the model in two apparently disparate driving scenarios that require managing uncertainty, (1) driving past an occluding object and (2) visual time sharing between driving and a secondary task, and show how human-like adaptive driving behavior emerges from the single principle of expected free energy minimization.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2311.06417.pdf"
      }
    },
    "fallah2023active": {
      "citation_key": "fallah2023active",
      "title": "Active Inference-Based Optimization of Discriminative Neural Network Classifiers",
      "authors": [
        "Faezeh Fallah"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2306.02447v1",
      "pdf_path": "data/pdfs/fallah2023active.pdf",
      "added_date": "2025-12-12T11:49:32.068948",
      "abstract": "Commonly used objective functions (losses) for a supervised optimization of discriminative neural network classifiers were either distribution-based or metric-based. The distribution-based losses could compromise the generalization or cause classification biases towards the dominant classes of an imbalanced class-sample distribution. The metric-based losses could make the network model independent of any distribution and thus improve its generalization. However, they could still be biased towards the dominant classes and could suffer from discrepancies when a class was absent in both the reference (ground truth) and the predicted labels. In this paper, we proposed a novel optimization process which not only tackled the unbalancedness of the class-sample distribution of the training samples but also provided a mechanism to tackle errors in the reference labels of the training samples. This was achieved by proposing a novel algorithm to find candidate classification labels of the training samples from their prior probabilities and the currently estimated posteriors on the network and a novel objective function for the optimizations. The algorithm was the result of casting the generalized Kelly criterion for optimal betting into a multiclass classification problem. The proposed objective function was the expected free energy of a prospective active inference and could incorporate the candidate labels, the original reference labels, and the priors of the training samples while still being distribution-based. The incorporation of the priors into the optimization not only helped to tackle errors in the reference labels but also allowed to reduce classification biases towards the dominant classes by focusing the attention of the neural network on important but minority foreground classes.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2306.02447.pdf"
      }
    },
    "zhou2023partially": {
      "citation_key": "zhou2023partially",
      "title": "A Partially Observable Deep Multi-Agent Active Inference Framework for Resource Allocation in 6G and Beyond Wireless Communications Networks",
      "authors": [
        "Fuhui Zhou",
        "Rui Ding",
        "Qihui Wu",
        "Derrick Wing Kwan Ng",
        "Kai-Kit Wong",
        "Naofal Al-Dhahir"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2308.11402v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.074103",
      "abstract": "Resource allocation is of crucial importance in wireless communications. However, it is extremely challenging to design efficient resource allocation schemes for future wireless communication networks since the formulated resource allocation problems are generally non-convex and consist of various coupled variables. Moreover, the dynamic changes of practical wireless communication environment and user service requirements thirst for efficient real-time resource allocation. To tackle these issues, a novel partially observable deep multi-agent active inference (PODMAI) framework is proposed for realizing intelligent resource allocation. A belief based learning method is exploited for updating the policy by minimizing the variational free energy. A decentralized training with a decentralized execution multi-agent strategy is designed to overcome the limitations of the partially observable state information. Exploited the proposed framework, an intelligent spectrum allocation and trajectory optimization scheme is developed for a spectrum sharing unmanned aerial vehicle (UAV) network with dynamic transmission rate requirements as an example. Simulation results demonstrate that our proposed framework can significantly improve the sum transmission rate of the secondary network compared to various benchmark schemes. Moreover, the convergence speed of the proposed PODMAI is significantly improved compared with the conventional reinforcement learning framework. Overall, our proposed framework can enrich the intelligent resource allocation frameworks and pave the way for realizing real-time resource allocation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2308.11402.pdf"
      }
    },
    "maele2023bridging": {
      "citation_key": "maele2023bridging",
      "title": "Bridging Cognitive Maps: a Hierarchical Active Inference Model of Spatial Alternation Tasks and the Hippocampal-Prefrontal Circuit",
      "authors": [
        "Toon Van de Maele",
        "Bart Dhoedt",
        "Tim Verbelen",
        "Giovanni Pezzulo"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2308.11463v3",
      "pdf_path": "data/pdfs/maele2023bridging.pdf",
      "added_date": "2025-12-12T11:49:32.079798",
      "abstract": "Cognitive problem-solving benefits from cognitive maps aiding navigation and planning. Previous studies revealed that cognitive maps for physical space navigation involve hippocampal (HC) allocentric codes, while cognitive maps for abstract task space engage medial prefrontal cortex (mPFC) task-specific codes. Solving challenging cognitive tasks requires integrating these two types of maps. This is exemplified by spatial alternation tasks in multi-corridor settings, where animals like rodents are rewarded upon executing an alternation pattern in maze corridors. Existing studies demonstrated the HC - mPFC circuit's engagement in spatial alternation tasks and that its disruption impairs task performance. Yet, a comprehensive theory explaining how this circuit integrates task-related and spatial information is lacking. We advance a novel hierarchical active inference model clarifying how the HC - mPFC circuit enables the resolution of spatial alternation tasks, by merging physical and task-space cognitive maps. Through a series of simulations, we demonstrate that the model's dual layers acquire effective cognitive maps for navigation within physical (HC map) and task (mPFC map) spaces, using a biologically-inspired approach: a clone-structured cognitive graph. The model solves spatial alternation tasks through reciprocal interactions between the two layers. Importantly, disrupting inter-layer communication impairs difficult decisions, consistent with empirical findings. The same model showcases the ability to switch between multiple alternation rules. However, inhibiting message transmission between the two layers results in perseverative behavior, consistent with empirical findings. In summary, our model provides a mechanistic account of how the HC - mPFC circuit supports spatial alternation tasks and how its disruption impairs task performance.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2308.11463.pdf"
      }
    },
    "pezzulo2023neural": {
      "citation_key": "pezzulo2023neural",
      "title": "Neural representation in active inference: using generative models to interact with -- and understand -- the lived world",
      "authors": [
        "Giovanni Pezzulo",
        "Leo D'Amato",
        "Francesco Mannella",
        "Matteo Priorelli",
        "Toon Van de Maele",
        "Ivilin Peev Stoianov",
        "Karl Friston"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2310.14810v1",
      "pdf_path": "data/pdfs/pezzulo2023neural.pdf",
      "added_date": "2025-12-12T11:49:32.085502",
      "abstract": "This paper considers neural representation through the lens of active inference, a normative framework for understanding brain function. It delves into how living organisms employ generative models to minimize the discrepancy between predictions and observations (as scored with variational free energy). The ensuing analysis suggests that the brain learns generative models to navigate the world adaptively, not (or not solely) to understand it. Different living organisms may possess an array of generative models, spanning from those that support action-perception cycles to those that underwrite planning and imagination; namely, from \"explicit\" models that entail variables for predicting concurrent sensations, like objects, faces, or people - to \"action-oriented models\" that predict action outcomes. It then elucidates how generative models and belief dynamics might link to neural representation and the implications of different types of generative models for understanding an agent's cognitive capabilities in relation to its ecological niche. The paper concludes with open questions regarding the evolution of generative models and the development of advanced cognitive abilities - and the gradual transition from \"pragmatic\" to \"detached\" neural representations. The analysis on offer foregrounds the diverse roles that generative models play in cognitive processes and the evolution of neural representation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2310.14810.pdf"
      }
    },
    "obite2023intelligent": {
      "citation_key": "obite2023intelligent",
      "title": "Intelligent Resource Allocation for UAV-Based Cognitive NOMA Networks: An Active Inference Approach",
      "authors": [
        "Felix Obite",
        "Ali Krayani",
        "Atm S. Alam",
        "Lucio Marcenaro",
        "Arumugam Nallanathan",
        "Carlo Regazzoni"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2310.11070v1",
      "pdf_path": "data/pdfs/obite2023intelligent.pdf",
      "added_date": "2025-12-12T11:49:32.090654",
      "abstract": "Future wireless networks will need to improve adaptive resource allocation and decision-making to handle the increasing number of intelligent devices. Unmanned aerial vehicles (UAVs) are being explored for their potential in real-time decision-making. Moreover, cognitive non-orthogonal multiple access (Cognitive-NOMA) is envisioned as a remedy to address spectrum scarcity and enable massive connectivity. This paper investigates the design of joint subchannel and power allocation in an uplink UAV-based cognitive NOMA network. We aim to maximize the cumulative sum rate by jointly optimizing the subchannel and power allocation based on the UAV's mobility at each time step. This is often formulated as an optimization problem with random variables. However, conventional optimization algorithms normally introduce significant complexity, and machine learning methods often rely on large but partially representative datasets to build solution models, assuming stationary testing data. Consequently, inference strategies for non stationary events are often overlooked. In this study, we introduce a novel active inference-based learning approach, rooted in cognitive neuroscience, to solve this complex problem. The framework involves creating a training dataset using random or iterative methods to find suboptimal resource allocations. This dataset trains a mobile UAV offline, enabling it to learn a generative model of discrete subchannels and continuous power allocation. The UAV then uses this model for online inference. The method incrementally derives new generative models from training data by identifying dynamic equilibrium conditions between required actions and variables, represented within a unique dynamic Bayesian network. The proposed approach is validated through numerical simulations, showing efficient performance compared to suboptimal baseline schemes.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2310.11070.pdf"
      }
    },
    "hodson2023sophisticated": {
      "citation_key": "hodson2023sophisticated",
      "title": "Sophisticated Learning: A novel algorithm for active learning during model-based planning",
      "authors": [
        "Rowan Hodson",
        "Bruce Bassett",
        "Charel van Hoof",
        "Benjamin Rosman",
        "Mark Solms",
        "Jonathan P. Shock",
        "Ryan Smith"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2308.08029v2",
      "pdf_path": "data/pdfs/hodson2023sophisticated.pdf",
      "added_date": "2025-12-12T11:49:32.099488",
      "abstract": "We introduce Sophisticated Learning (SL), a planning-to-learn algorithm that embeds active parameter learning inside the Sophisticated Inference (SI) tree-search framework of Active Inference. Unlike SI -- which optimizes beliefs about hidden states -- SL also updates beliefs about model parameters within each simulated branch, enabling counterfactual reasoning about how future observations would improve subsequent planning.   We compared SL with Bayes-adaptive Reinforcement Learning (BARL) agents as well as with its parent algorithm, SI. Using a biologically inspired seasonal foraging task in which resources shift probabilistically over a 10x10 grid, we designed experiments that forced agents to balance probabilistic reward harvesting against information gathering.   In early trials, where rapid learning is vital, SL agents survive, on average, 8.2% longer than SI and 35% longer than Bayes-adaptive Reinforcement Learning. While both SL and SI showed equal convergence performance, SL reached this convergence 40% faster than SI. Additionally, SL showed robust out-performance of other algorithms in altered environment configurations.   Our results show that incorporating active learning into multi-step planning materially improves decision making under radical uncertainty, and reinforces the broader utility of Active Inference for modeling biologically relevant behavior.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2308.08029.pdf"
      }
    },
    "shi2023blind": {
      "citation_key": "shi2023blind",
      "title": "Blind CT Image Quality Assessment Using DDPM-derived Content and Transformer-based Evaluator",
      "authors": [
        "Yongyi Shi",
        "Wenjun Xia",
        "Ge Wang",
        "Xuanqin Mou"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2310.03118v1",
      "pdf_path": "data/pdfs/shi2023blind.pdf",
      "added_date": "2025-12-12T11:49:32.105644",
      "abstract": "Lowering radiation dose per view and utilizing sparse views per scan are two common CT scan modes, albeit often leading to distorted images characterized by noise and streak artifacts. Blind image quality assessment (BIQA) strives to evaluate perceptual quality in alignment with what radiologists perceive, which plays an important role in advancing low-dose CT reconstruction techniques. An intriguing direction involves developing BIQA methods that mimic the operational characteristic of the human visual system (HVS). The internal generative mechanism (IGM) theory reveals that the HVS actively deduces primary content to enhance comprehension. In this study, we introduce an innovative BIQA metric that emulates the active inference process of IGM. Initially, an active inference module, implemented as a denoising diffusion probabilistic model (DDPM), is constructed to anticipate the primary content. Then, the dissimilarity map is derived by assessing the interrelation between the distorted image and its primary content. Subsequently, the distorted image and dissimilarity map are combined into a multi-channel image, which is inputted into a transformer-based image quality evaluator. Remarkably, by exclusively utilizing this transformer-based quality evaluator, we won the second place in the MICCAI 2023 low-dose computed tomography perceptual image quality assessment grand challenge. Leveraging the DDPM-derived primary content, our approach further improves the performance on the challenge dataset.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2310.03118.pdf"
      }
    },
    "kiefer2023relative": {
      "citation_key": "kiefer2023relative",
      "title": "Relative representations for cognitive graphs",
      "authors": [
        "Alex B. Kiefer",
        "Christopher L. Buckley"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2309.04653v1",
      "pdf_path": "data/pdfs/kiefer2023relative.pdf",
      "added_date": "2025-12-12T11:49:32.115345",
      "abstract": "Although the latent spaces learned by distinct neural networks are not generally directly comparable, recent work in machine learning has shown that it is possible to use the similarities and differences among latent space vectors to derive \"relative representations\" with comparable representational power to their \"absolute\" counterparts, and which are nearly identical across models trained on similar data distributions. Apart from their intrinsic interest in revealing the underlying structure of learned latent spaces, relative representations are useful to compare representations across networks as a generic proxy for convergence, and for zero-shot model stitching.   In this work we examine an extension of relative representations to discrete state-space models, using Clone-Structured Cognitive Graphs (CSCGs) for 2D spatial localization and navigation as a test case. Our work shows that the probability vectors computed during message passing can be used to define relative representations on CSCGs, enabling effective communication across agents trained using different random initializations and training sequences, and on only partially similar spaces. We introduce a technique for zero-shot model stitching that can be applied post hoc, without the need for using relative representations during training. This exploratory work is intended as a proof-of-concept for the application of relative representations to the study of cognitive maps in neuroscience and AI.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2309.04653.pdf"
      }
    },
    "tinguy2023inferring": {
      "citation_key": "tinguy2023inferring",
      "title": "Inferring Hierarchical Structure in Multi-Room Maze Environments",
      "authors": [
        "Daria de Tinguy",
        "Toon Van de Maele",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2306.13546v1",
      "pdf_path": "data/pdfs/tinguy2023inferring.pdf",
      "added_date": "2025-12-12T11:49:32.121319",
      "abstract": "Cognitive maps play a crucial role in facilitating flexible behaviour by representing spatial and conceptual relationships within an environment. The ability to learn and infer the underlying structure of the environment is crucial for effective exploration and navigation. This paper introduces a hierarchical active inference model addressing the challenge of inferring structure in the world from pixel-based observations. We propose a three-layer hierarchical model consisting of a cognitive map, an allocentric, and an egocentric world model, combining curiosity-driven exploration with goal-oriented behaviour at the different levels of reasoning from context to place to motion. This allows for efficient exploration and goal-directed search in room-structured mini-grid environments.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2306.13546.pdf"
      }
    },
    "piriyakulkij2023active": {
      "citation_key": "piriyakulkij2023active",
      "title": "Active Preference Inference using Language Models and Probabilistic Reasoning",
      "authors": [
        "Wasu Top Piriyakulkij",
        "Volodymyr Kuleshov",
        "Kevin Ellis"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2312.12009v2",
      "pdf_path": "data/pdfs/piriyakulkij2023active.pdf",
      "added_date": "2025-12-12T11:49:32.127717",
      "abstract": "Actively inferring user preferences, for example by asking good questions, is important for any human-facing decision-making system. Active inference allows such systems to adapt and personalize themselves to nuanced individual preferences. To enable this ability for instruction-tuned large language models (LLMs), one may prompt them to ask users questions to infer their preferences, transforming the language models into more robust, interactive systems. However, out of the box, these models are not efficient at extracting preferences: the questions they generate are not informative, requiring a high number of user interactions and impeding the usability of the downstream system. In this work, we introduce an inference-time algorithm that helps LLMs quickly infer preferences by using more informative questions. Our algorithm uses a probabilistic model whose conditional distributions are defined by prompting an LLM, and returns questions that optimize expected entropy and expected model change. Results in a simplified interactive web shopping setting with real product items show that an LLM equipped with our entropy reduction algorithm outperforms baselines with the same underlying LLM on task performance while using fewer user interactions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2312.12009.pdf"
      }
    },
    "miyaguchi2023modeling": {
      "citation_key": "miyaguchi2023modeling",
      "title": "Modeling the sense of presence of remote participants in hybrid communication and its application to the design of avatar robot behavior",
      "authors": [
        "Takuma Miyaguchi",
        "Hideyoshi Yanagisawa"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2305.01665v1",
      "pdf_path": "data/pdfs/miyaguchi2023modeling.pdf",
      "added_date": "2025-12-12T11:49:32.133350",
      "abstract": "We formulated the sense of the presence of a remote participant in hybrid communication using a Bayesian framework. We also applied the knowledge gained from the simulation with the Bayesian model to the avatar robot's intervention behavior and encouraged the local participants to speak by intervening in the remote participant's behavior using an avatar robot. We then modeled the influence of the avatar robot's behavior on the local participants' statements using an active inference framework that included the presence of a remote participant as a latent variable. Based on the simulation results, we designed the gaze behavior of an avatar robot. Finally, we examined the effectiveness of the designed gaze behavior of the avatar robot. The gaze behavior expressed more of the remote participant's attention and interest in local participants, but local participants expressed fewer opinions in the meeting tasks. The results suggest that gaze behavior increased the presence of the remote participant and discouraged the local participant from speaking in the context of the experimental task. We believe that presence has a sufficiently large influence on whether participants want to express an opinion. It is worth investigating the influence of presence and its control methods using Bayesian models.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2305.01665.pdf"
      }
    },
    "joseph2023anomaly": {
      "citation_key": "joseph2023anomaly",
      "title": "Anomaly Detection via Learning-Based Sequential Controlled Sensing",
      "authors": [
        "Geethu Joseph",
        "Chen Zhong",
        "M. Cenk Gursoy",
        "Senem Velipasalar",
        "Pramod K. Varshney"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2312.00088v1",
      "pdf_path": "data/pdfs/joseph2023anomaly.pdf",
      "added_date": "2025-12-12T11:49:32.138938",
      "abstract": "In this paper, we address the problem of detecting anomalies among a given set of binary processes via learning-based controlled sensing. Each process is parameterized by a binary random variable indicating whether the process is anomalous. To identify the anomalies, the decision-making agent is allowed to observe a subset of the processes at each time instant. Also, probing each process has an associated cost. Our objective is to design a sequential selection policy that dynamically determines which processes to observe at each time with the goal to minimize the delay in making the decision and the total sensing cost. We cast this problem as a sequential hypothesis testing problem within the framework of Markov decision processes. This formulation utilizes both a Bayesian log-likelihood ratio-based reward and an entropy-based reward. The problem is then solved using two approaches: 1) a deep reinforcement learning-based approach where we design both deep Q-learning and policy gradient actor-critic algorithms; and 2) a deep active inference-based approach. Using numerical experiments, we demonstrate the efficacy of our algorithms and show that our algorithms adapt to any unknown statistical dependence pattern of the processes.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2312.00088.pdf"
      }
    },
    "huang2023reconstructing": {
      "citation_key": "huang2023reconstructing",
      "title": "Reconstructing human activities via coupling mobile phone data with location-based social networks",
      "authors": [
        "Le Huang",
        "Fan Xia",
        "Hui Chen",
        "Bowen Hu",
        "Xiao Zhou",
        "Chunxiao Li",
        "Yaohui Jin",
        "Yanyan Xu"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2306.03441v1",
      "pdf_path": "data/pdfs/huang2023reconstructing.pdf",
      "added_date": "2025-12-12T11:49:32.144850",
      "abstract": "In the era of big data, the ubiquity of location-aware portable devices provides an unprecedented opportunity to understand inhabitants' behavior and their interactions with the built environments. Among the widely used data resources, mobile phone data is the one passively collected and has the largest coverage in the population. However, mobile operators cannot pinpoint one user within meters, leading to the difficulties in activity inference. To that end, we propose a data analysis framework to identify user's activity via coupling the mobile phone data with location-based social networks (LBSN) data. The two datasets are integrated into a Bayesian inference module, considering people's circadian rhythms in both time and space. Specifically, the framework considers the pattern of arrival time to each type of facility and the spatial distribution of facilities. The former can be observed from the LBSN Data and the latter is provided by the points of interest (POIs) dataset. Taking Shanghai as an example, we reconstruct the activity chains of 1,000,000 active mobile phone users and analyze the temporal and spatial characteristics of each activity type. We assess the results with some official surveys and a real-world check-in dataset collected in Shanghai, indicating that the proposed method can capture and analyze human activities effectively. Next, we cluster users' inferred activity chains with a topic model to understand the behavior of different groups of users. This data analysis framework provides an example of reconstructing and understanding the activity of the population at an urban scale with big data fusion.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2306.03441.pdf"
      }
    },
    "kundu2023discovering": {
      "citation_key": "kundu2023discovering",
      "title": "Discovering Novel Actions from Open World Egocentric Videos with Object-Grounded Visual Commonsense Reasoning",
      "authors": [
        "Sanjoy Kundu",
        "Shubham Trehan",
        "Sathyanarayanan N. Aakur"
      ],
      "year": 2023,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2305.16602v2",
      "pdf_path": "data/pdfs/kundu2023discovering.pdf",
      "added_date": "2025-12-12T11:49:32.150009",
      "abstract": "Learning to infer labels in an open world, i.e., in an environment where the target ``labels'' are unknown, is an important characteristic for achieving autonomy. Foundation models, pre-trained on enormous amounts of data, have shown remarkable generalization skills through prompting, particularly in zero-shot inference. However, their performance is restricted to the correctness of the target label's search space, i.e., candidate labels provided in the prompt. This target search space can be unknown or exceptionally large in an open world, severely restricting their performance. To tackle this challenging problem, we propose a two-step, neuro-symbolic framework called ALGO - Action Learning with Grounded Object recognition that uses symbolic knowledge stored in large-scale knowledge bases to infer activities in egocentric videos with limited supervision. First, we propose a neuro-symbolic prompting approach that uses object-centric vision-language models as a noisy oracle to ground objects in the video through evidence-based reasoning. Second, driven by prior commonsense knowledge, we discover plausible activities through an energy-based symbolic pattern theory framework and learn to ground knowledge-based action (verb) concepts in the video. Extensive experiments on four publicly available datasets (EPIC-Kitchens, GTEA Gaze, GTEA Gaze Plus, and Charades-Ego) demonstrate its performance on open-world activity inference. We also show that ALGO can be extended to zero-shot inference and demonstrate its competitive performance on the Charades-Ego dataset.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2305.16602.pdf"
      }
    },
    "wirkuttis2021leading": {
      "citation_key": "wirkuttis2021leading",
      "title": "Leading or Following? Dyadic Robot Imitative Interaction Using the Active Inference Framework",
      "authors": [
        "Nadine Wirkuttis",
        "Jun Tani"
      ],
      "year": 2021,
      "doi": "10.1109/LRA.2021.3090015",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2103.02137v2",
      "pdf_path": "data/pdfs/wirkuttis2021leading.pdf",
      "added_date": "2025-12-12T11:49:32.158293",
      "abstract": "This study investigated how social interaction among robotic agents changes dynamically depending on the individual belief of action intention. In a set of simulation studies, we examine dyadic imitative interactions of robots using a variational recurrent neural network model. The model is based on the free energy principle such that a pair of interacting robots find themselves in a loop, attempting to predict and infer each other's actions using active inference. We examined how regulating the complexity term to minimize free energy determines the dynamic characteristics of networks and interactions. When one robot trained with tighter regulation and another trained with looser regulation interact, the latter tends to lead the interaction by exerting stronger action intention, while the former tends to follow by adapting to its observations. The study confirms that the dyadic imitative interaction becomes successful by achieving a high synchronization rate when a leader and a follower are determined by developing action intentions with strong belief and weak belief, respectively.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2103.02137.pdf"
      }
    },
    "laar2021active": {
      "citation_key": "laar2021active",
      "title": "Active Inference and Epistemic Value in Graphical Models",
      "authors": [
        "Thijs van de Laar",
        "Magnus Koudahl",
        "Bart van Erp",
        "Bert de Vries"
      ],
      "year": 2021,
      "doi": "10.3389/frobt.2022.794464",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2109.00541v2",
      "pdf_path": "data/pdfs/laar2021active.pdf",
      "added_date": "2025-12-12T11:49:32.164149",
      "abstract": "The Free Energy Principle (FEP) postulates that biological agents perceive and interact with their environment in order to minimize a Variational Free Energy (VFE) with respect to a generative model of their environment. The inference of a policy (future control sequence) according to the FEP is known as Active Inference (AIF). The AIF literature describes multiple VFE objectives for policy planning that lead to epistemic (information-seeking) behavior. However, most objectives have limited modeling flexibility. This paper approaches epistemic behavior from a constrained Bethe Free Energy (CBFE) perspective. Crucially, variational optimization of the CBFE can be expressed in terms of message passing on free-form generative models. The key intuition behind the CBFE is that we impose a point-mass constraint on predicted outcomes, which explicitly encodes the assumption that the agent will make observations in the future. We interpret the CBFE objective in terms of its constituent behavioral drives. We then illustrate resulting behavior of the CBFE by planning and interacting with a simulated T-maze environment. Simulations for the T-maze task illustrate how the CBFE agent exhibits an epistemic drive, and actively plans ahead to account for the impact of predicted outcomes. Compared to an EFE agent, the CBFE agent incurs expected reward in significantly more environmental scenarios. We conclude that CBFE optimization by message passing suggests a general mechanism for epistemic-aware AIF in free-form generative models.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2109.00541.pdf"
      }
    },
    "baioumy2021towards": {
      "citation_key": "baioumy2021towards",
      "title": "Towards Stochastic Fault-tolerant Control using Precision Learning and Active Inference",
      "authors": [
        "Mohamed Baioumy",
        "Corrado Pezzato",
        "Carlos Hernandez Corbato",
        "Nick Hawes",
        "Riccardo Ferrari"
      ],
      "year": 2021,
      "doi": "10.1007/978-3-030-93736-2_48",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2109.05870v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.170089",
      "abstract": "This work presents a fault-tolerant control scheme for sensory faults in robotic manipulators based on active inference. In the majority of existing schemes, a binary decision of whether a sensor is healthy (functional) or faulty is made based on measured data. The decision boundary is called a threshold and it is usually deterministic. Following a faulty decision, fault recovery is obtained by excluding the malfunctioning sensor. We propose a stochastic fault-tolerant scheme based on active inference and precision learning which does not require a priori threshold definitions to trigger fault recovery. Instead, the sensor precision, which represents its health status, is learned online in a model-free way allowing the system to gradually, and not abruptly exclude a failing unit. Experiments on a robotic manipulator show promising results and directions for future work are discussed.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2109.05870.pdf"
      }
    },
    "paul2021active": {
      "citation_key": "paul2021active",
      "title": "Active Inference for Stochastic Control",
      "authors": [
        "Aswin Paul",
        "Noor Sajid",
        "Manoj Gopalkrishnan",
        "Adeel Razi"
      ],
      "year": 2021,
      "doi": "10.1007/978-3-030-93736-2_47",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2108.12245v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.175256",
      "abstract": "Active inference has emerged as an alternative approach to control problems given its intuitive (probabilistic) formalism. However, despite its theoretical utility, computational implementations have largely been restricted to low-dimensional, deterministic settings. This paper highlights that this is a consequence of the inability to adequately model stochastic transition dynamics, particularly when an extensive policy (i.e., action trajectory) space must be evaluated during planning. Fortunately, recent advancements propose a modified planning algorithm for finite temporal horizons. We build upon this work to assess the utility of active inference for a stochastic control setting. For this, we simulate the classic windy grid-world task with additional complexities, namely: 1) environment stochasticity; 2) learning of transition dynamics; and 3) partial observability. Our results demonstrate the advantage of using active inference, compared to reinforcement learning, in both deterministic and stochastic settings.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2108.12245.pdf"
      }
    },
    "markovic2021empirical": {
      "citation_key": "markovic2021empirical",
      "title": "An empirical evaluation of active inference in multi-armed bandits",
      "authors": [
        "Dimitrije Markovic",
        "Hrvoje Stojic",
        "Sarah Schwoebel",
        "Stefan J. Kiebel"
      ],
      "year": 2021,
      "doi": "10.1016/j.neunet.2021.08.018",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2101.08699v4",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.181615",
      "abstract": "A key feature of sequential decision making under uncertainty is a need to balance between exploiting--choosing the best action according to the current knowledge, and exploring--obtaining information about values of other actions. The multi-armed bandit problem, a classical task that captures this trade-off, served as a vehicle in machine learning for developing bandit algorithms that proved to be useful in numerous industrial applications. The active inference framework, an approach to sequential decision making recently developed in neuroscience for understanding human and animal behaviour, is distinguished by its sophisticated strategy for resolving the exploration-exploitation trade-off. This makes active inference an exciting alternative to already established bandit algorithms. Here we derive an efficient and scalable approximate active inference algorithm and compare it to two state-of-the-art bandit algorithms: Bayesian upper confidence bound and optimistic Thompson sampling. This comparison is done on two types of bandit problems: a stationary and a dynamic switching bandit. Our empirical evaluation shows that the active inference algorithm does not produce efficient long-term behaviour in stationary bandits. However, in the more challenging switching bandit problem active inference performs substantially better than the two state-of-the-art bandit algorithms. The results open exciting venues for further research in theoretical and applied machine learning, as well as lend additional credibility to active inference as a general framework for studying human and animal behaviour.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2101.08699.pdf"
      }
    },
    "pöppel2021resonating": {
      "citation_key": "pöppel2021resonating",
      "title": "Resonating Minds -- Emergent Collaboration Through Hierarchical Active Inference",
      "authors": [
        "Jan Pöppel",
        "Sebastian Kahl",
        "Stefan Kopp"
      ],
      "year": 2021,
      "doi": "10.1007/s12559-021-09960-4",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.01210v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.187479",
      "abstract": "Working together on complex collaborative tasks requires agents to coordinate their actions. Doing this explicitly or completely prior to the actual interaction is not always possible nor sufficient. Agents also need to continuously understand the current actions of others and quickly adapt their own behavior appropriately. Here we investigate how efficient, automatic coordination processes at the level of mental states (intentions, goals), which we call belief resonance, can lead to collaborative situated problem-solving. We present a model of hierarchical active inference for collaborative agents (HAICA). It combines efficient Bayesian Theory of Mind processes with a perception-action system based on predictive processing and active inference. Belief resonance is realized by letting the inferred mental states of one agent influence another agent's predictive beliefs about its own goals and intentions. This way, the inferred mental states influence the agent's own task behavior without explicit collaborative reasoning. We implement and evaluate this model in the Overcooked domain, in which two agents with varying degrees of belief resonance team up to fulfill meal orders. Our results demonstrate that agents based on HAICA achieve a team performance comparable to recent state of the art approaches, while incurring much lower computational costs. We also show that belief resonance is especially beneficial in settings were the agents have asymmetric knowledge about the environment. The results indicate that belief resonance and active inference allow for quick and efficient agent coordination, and thus can serve as a building block for collaborative cognitive agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.01210.pdf"
      }
    },
    "laar2021chanceconstrained": {
      "citation_key": "laar2021chanceconstrained",
      "title": "Chance-Constrained Active Inference",
      "authors": [
        "Thijs van de Laar",
        "Ismail Senoz",
        "Ayça Özçelikkale",
        "Henk Wymeersch"
      ],
      "year": 2021,
      "doi": "10.1162/neco_a_01427",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2102.08792v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.193465",
      "abstract": "Active Inference (ActInf) is an emerging theory that explains perception and action in biological agents, in terms of minimizing a free energy bound on Bayesian surprise. Goal-directed behavior is elicited by introducing prior beliefs on the underlying generative model. In contrast to prior beliefs, which constrain all realizations of a random variable, we propose an alternative approach through chance constraints, which allow for a (typically small) probability of constraint violation, and demonstrate how such constraints can be used as intrinsic drivers for goal-directed behavior in ActInf. We illustrate how chance-constrained ActInf weights all imposed (prior) constraints on the generative model, allowing e.g., for a trade-off between robust control and empirical chance constraint violation. Secondly, we interpret the proposed solution within a message passing framework. Interestingly, the message passing interpretation is not only relevant to the context of ActInf, but also provides a general purpose approach that can account for chance constraints on graphical models. The chance constraint message updates can then be readily combined with other pre-derived message update rules, without the need for custom derivations. The proposed chance-constrained message passing framework thus accelerates the search for workable models in general, and can be used to complement message-passing formulations on generative neural models.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2102.08792.pdf"
      }
    },
    "kaufmann2021active": {
      "citation_key": "kaufmann2021active",
      "title": "An active inference model of collective intelligence",
      "authors": [
        "Rafael Kaufmann",
        "Pranav Gupta",
        "Jacob Taylor"
      ],
      "year": 2021,
      "doi": "10.3390/e23070830",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2104.01066v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.199221",
      "abstract": "To date, formal models of collective intelligence have lacked a plausible mathematical description of the relationship between local-scale interactions between highly autonomous sub-system components (individuals) and global-scale behavior of the composite system (the collective). In this paper we use the Active Inference Formulation (AIF), a framework for explaining the behavior of any non-equilibrium steady state system at any scale, to posit a minimal agent-based model that simulates the relationship between local individual-level interaction and collective intelligence (operationalized as system-level performance). We explore the effects of providing baseline AIF agents (Model 1) with specific cognitive capabilities: Theory of Mind (Model 2); Goal Alignment (Model 3), and Theory of Mind with Goal Alignment (Model 4). These stepwise transitions in sophistication of cognitive ability are motivated by the types of advancements plausibly required for an AIF agent to persist and flourish in an environment populated by other AIF agents, and have also recently been shown to map naturally to canonical steps in human cognitive ability. Illustrative results show that stepwise cognitive transitions increase system performance by providing complementary mechanisms for alignment between agents' local and global optima. Alignment emerges endogenously from the dynamics of interacting AIF agents themselves, rather than being imposed exogenously by incentives to agents' behaviors (contra existing computational models of collective intelligence) or top-down priors for collective behavior (contra existing multiscale simulations of AIF). These results shed light on the types of generic information-theoretic patterns conducive to collective intelligence in human and other complex adaptive systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2104.01066.pdf"
      }
    },
    "podusenko2021aida": {
      "citation_key": "podusenko2021aida",
      "title": "AIDA: An Active Inference-based Design Agent for Audio Processing Algorithms",
      "authors": [
        "Albert Podusenko",
        "Bart van Erp",
        "Magnus Koudahl",
        "Bert de Vries"
      ],
      "year": 2021,
      "doi": "10.3389/frsip.2022.842477",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.13366v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.205514",
      "abstract": "In this paper we present AIDA, which is an active inference-based agent that iteratively designs a personalized audio processing algorithm through situated interactions with a human client. The target application of AIDA is to propose on-the-spot the most interesting alternative values for the tuning parameters of a hearing aid (HA) algorithm, whenever a HA client is not satisfied with their HA performance. AIDA interprets searching for the \"most interesting alternative\" as an issue of optimal (acoustic) context-aware Bayesian trial design. In computational terms, AIDA is realized as an active inference-based agent with an Expected Free Energy criterion for trial design. This type of architecture is inspired by neuro-economic models on efficient (Bayesian) trial design in brains and implies that AIDA comprises generative probabilistic models for acoustic signals and user responses. We propose a novel generative model for acoustic signals as a sum of time-varying auto-regressive filters and a user response model based on a Gaussian Process Classifier. The full AIDA agent has been implemented in a factor graph for the generative model and all tasks (parameter learning, acoustic context classification, trial design, etc.) are realized by variational message passing on the factor graph. All verification and validation experiments and demonstrations are freely accessible at our GitHub repository.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.13366.pdf"
      }
    },
    "costa2021bayesian": {
      "citation_key": "costa2021bayesian",
      "title": "Bayesian Mechanics for Stationary Processes",
      "authors": [
        "Lancelot Da Costa",
        "Karl Friston",
        "Conor Heins",
        "Grigorios A. Pavliotis"
      ],
      "year": 2021,
      "doi": "10.1098/rspa.2021.0518",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2106.13830v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.211675",
      "abstract": "This paper develops a Bayesian mechanics for adaptive systems.   Firstly, we model the interface between a system and its environment with a Markov blanket. This affords conditions under which states internal to the blanket encode information about external states.   Second, we introduce dynamics and represent adaptive systems as Markov blankets at steady-state. This allows us to identify a wide class of systems whose internal states appear to infer external states, consistent with variational inference in Bayesian statistics and theoretical neuroscience.   Finally, we partition the blanket into sensory and active states. It follows that active states can be seen as performing active inference and well-known forms of stochastic control (such as PID control), which are prominent formulations of adaptive behaviour in theoretical biology and engineering.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2106.13830.pdf"
      }
    },
    "ramírezruiz2022complex": {
      "citation_key": "ramírezruiz2022complex",
      "title": "Complex behavior from intrinsic motivation to occupy action-state path space",
      "authors": [
        "Jorge Ramírez-Ruiz",
        "Dmytro Grytskyy",
        "Chiara Mastrogiuseppe",
        "Yamen Habib",
        "Rubén Moreno-Bote"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2205.10316v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.224705",
      "abstract": "Most theories of behavior posit that agents tend to maximize some form of reward or utility. However, animals very often move with curiosity and seem to be motivated in a reward-free manner. Here we abandon the idea of reward maximization, and propose that the goal of behavior is maximizing occupancy of future paths of actions and states. According to this maximum occupancy principle, rewards are the means to occupy path space, not the goal per se; goal-directedness simply emerges as rational ways of searching for resources so that movement, understood amply, never ends. We find that action-state path entropy is the only measure consistent with additivity and other intuitive properties of expected future action-state path occupancy. We provide analytical expressions that relate the optimal policy and state-value function, and prove convergence of our value iteration algorithm. Using discrete and continuous state tasks, including a high--dimensional controller, we show that complex behaviors such as `dancing', hide-and-seek and a basic form of altruistic behavior naturally result from the intrinsic motivation to occupy path space. All in all, we present a theory of behavior that generates both variability and goal-directedness in the absence of reward maximization.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2205.10316.pdf"
      }
    },
    "ramstead2022mapterritory": {
      "citation_key": "ramstead2022mapterritory",
      "title": "On the map-territory fallacy fallacy",
      "authors": [
        "Maxwell J D Ramstead",
        "Dalton A R Sakthivadivel",
        "Karl J Friston"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2208.06924v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.230685",
      "abstract": "This paper presents a meta-theory of the usage of the free energy principle (FEP) and examines its scope in the modelling of physical systems. We consider the so-called `map-territory fallacy' and the fallacious reification of model properties. By showing that the FEP is a consistent, physics-inspired theory of inferences of inferences, we disprove the assertion that the map-territory fallacy contradicts the principled usage of the FEP. As such, we argue that deploying the map-territory fallacy to criticise the use of the FEP and Bayesian mechanics itself constitutes a fallacy: what we call the {\\it map-territory fallacy fallacy}. In so doing, we emphasise a few key points: the uniqueness of the FEP as a model of particles or agents that model their environments; the restoration of convention to the FEP via its relation to the principle of constrained maximum entropy; the `Jaynes optimality' of the FEP under this relation; and finally, the way that this meta-theoretical approach to the FEP clarifies its utility and scope as a formal modelling tool. Taken together, these features make the FEP, uniquely, {\\it the} ideal model of generic systems in statistical physics.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2208.06924.pdf"
      }
    },
    "sakthivadivel2022towards": {
      "citation_key": "sakthivadivel2022towards",
      "title": "Towards a Geometry and Analysis for Bayesian Mechanics",
      "authors": [
        "Dalton A R Sakthivadivel"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2204.11900v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.236498",
      "abstract": "In this paper, a simple case of Bayesian mechanics under the free energy principle is formulated in axiomatic terms. We argue that any dynamical system with constraints on its dynamics necessarily looks as though it is performing inference against these constraints, and that in a non-isolated system, such constraints imply external environmental variables embedding the system. Using aspects of classical dynamical systems theory in statistical mechanics, we show that this inference is equivalent to a gradient ascent on the Shannon entropy functional, recovering an approximate Bayesian inference under a locally ergodic probability measure on the state space. We also use some geometric notions from dynamical systems theory$\\unicode{x2014}$namely, that the constraints constitute a gauge degree of freedom$\\unicode{x2014}$to elaborate on how the desire to stay self-organised can be read as a gauge force acting on the system. In doing so, a number of results of independent interest are given. Overall, we provide a related, but alternative, formalism to those driven purely by descriptions of random dynamical systems, and take a further step towards a comprehensive statement of the physics of self-organisation in formal mathematical language.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2204.11900.pdf"
      }
    },
    "kim2022free": {
      "citation_key": "kim2022free",
      "title": "Free energy and inference in living systems",
      "authors": [
        "Chang Sub Kim"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2203.14194v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.241842",
      "abstract": "Organisms are nonequilibrium, stationary systems self-organized via spontaneous symmetry breaking and undergoing metabolic cycles with broken detailed balance in the environment. The thermodynamic free-energy principle describes an organism's homeostasis as the regulation of biochemical work constrained by the physical free-energy cost. In contrast, recent research in neuroscience and theoretical biology explains a higher organism's homeostasis and allostasis as Bayesian inference facilitated by the informational free energy. As an integrated approach to living systems, this study presents a free-energy minimization theory overarching the essential features of both the thermodynamic and neuroscientific free-energy principles. Our results reveal that the perception and action of animals result from active inference entailed by free-energy minimization in the brain, and the brain operates as Schr{ö}dinger's machine conducting the neural mechanics of minimizing sensory uncertainty. A parsimonious model suggests that the Bayesian brain develops the optimal trajectories in neural manifolds and induces a dynamic bifurcation between neural attractors in the process of active inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2203.14194.pdf"
      }
    },
    "sennesh2022deriving": {
      "citation_key": "sennesh2022deriving",
      "title": "Deriving time-averaged active inference from control principles",
      "authors": [
        "Eli Sennesh",
        "Jordan Theriault",
        "Jan-Willem van de Meent",
        "Lisa Feldman Barrett",
        "Karen Quigley"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2208.10601v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.248391",
      "abstract": "Active inference offers a principled account of behavior as minimizing average sensory surprise over time. Applications of active inference to control problems have heretofore tended to focus on finite-horizon or discounted-surprise problems, despite deriving from the infinite-horizon, average-surprise imperative of the free-energy principle. Here we derive an infinite-horizon, average-surprise formulation of active inference from optimal control principles. Our formulation returns to the roots of active inference in neuroanatomy and neurophysiology, formally reconnecting active inference to optimal feedback control. Our formulation provides a unified objective functional for sensorimotor control and allows for reference states to vary over time.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2208.10601.pdf"
      }
    },
    "horibe2022investigating": {
      "citation_key": "horibe2022investigating",
      "title": "Investigating the impact of free energy based behavior on human in human-agent interaction",
      "authors": [
        "Kazuya Horibe",
        "Yuanxiang Fan",
        "Yutaka Nakamura",
        "Hiroshi Ishiguro"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2201.10164v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.253867",
      "abstract": "Humans communicate non-verbally by sharing physical rhythms, such as nodding and gestures, to involve each other. This sharing of physicality creates a sense of unity and makes humans feel involved with others. In this paper, we developed a new body motion generation system based on the free-energy principle (FEP), which not only responds passively but also prompts human actions. The proposed system consists of two modules, the sampling module, and the motion selection module. We conducted a subjective experiment to evaluate the \"feeling of interacting with the agent\" of the FEP based behavior. The results suggested that FEP based behaviors show more \"feeling of interacting with the agent\". Furthermore, we confirmed that the agent's gestures elicited subject gestures. This result not only reinforces the impression of feeling interaction but could also realization of agents that encourage people to change their behavior.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2201.10164.pdf"
      }
    },
    "wakayama2022active": {
      "citation_key": "wakayama2022active",
      "title": "Active Inference for Autonomous Decision-Making with Contextual Multi-Armed Bandits",
      "authors": [
        "Shohei Wakayama",
        "Nisar Ahmed"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2209.09185v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.260095",
      "abstract": "In autonomous robotic decision-making under uncertainty, the tradeoff between exploitation and exploration of available options must be considered. If secondary information associated with options can be utilized, such decision-making problems can often be formulated as contextual multi-armed bandits (CMABs). In this study, we apply active inference, which has been actively studied in the field of neuroscience in recent years, as an alternative action selection strategy for CMABs. Unlike conventional action selection strategies, it is possible to rigorously evaluate the uncertainty of each option when calculating the expected free energy (EFE) associated with the decision agent's probabilistic model, as derived from the free-energy principle. We specifically address the case where a categorical observation likelihood function is used, such that EFE values are analytically intractable. We introduce new approximation methods for computing the EFE based on variational and Laplace approximations. Extensive simulation study results demonstrate that, compared to other strategies, active inference generally requires far fewer iterations to identify optimal options and generally achieves superior cumulative regret, for relatively low extra computational cost.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2209.09185.pdf"
      }
    },
    "katayose2022unified": {
      "citation_key": "katayose2022unified",
      "title": "A unified theory of learning",
      "authors": [
        "Taisuke Katayose"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2203.16941v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.266032",
      "abstract": "Recently machine learning using neural networks (NN) has been developed, and many new methods have been suggested. These methods are optimized for the type of input data and work very effectively, but they cannot be used with any kind of input data universally. On the other hand, the human brain is universal for any kind of problem, and we will be able to construct artificial general intelligence if we can mimic the system of how the human brain works. We consider how the human brain learns things uniformly, and find that the essence of learning is the compression of information. We suggest a toy NN model which mimics the system of the human brain, and we show that the NN can compress the input information without ad hoc treatment, only by setting the loss function properly. The loss function is expressed as the sum of the self-information to remember and the loss of the information along with the compression, and its minimum corresponds to the self-information of the original data. To evaluate the self-information to remember, we provided the concept of memory. The memory expresses the compressed information, and the learning proceeds by referring to previous memories. There are many similarities between this NN and the human brain, and this NN is a realization of the free-energy principle which is considered to be a unified theory of the human brain. This work can be applied to any kind of data analysis and cognitive science.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2203.16941.pdf"
      }
    },
    "heins2022spin": {
      "citation_key": "heins2022spin",
      "title": "Spin glass systems as collective active inference",
      "authors": [
        "Conor Heins",
        "Brennan Klein",
        "Daphne Demekas",
        "Miguel Aguilera",
        "Christopher Buckley"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2207.06970v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.272139",
      "abstract": "An open question in the study of emergent behaviour in multi-agent Bayesian systems is the relationship, if any, between individual and collective inference. In this paper we explore the correspondence between generative models that exist at two distinct scales, using spin glass models as a sandbox system to investigate this question. We show that the collective dynamics of a specific type of active inference agent is equivalent to sampling from the stationary distribution of a spin glass system. A collective of specifically-designed active inference agents can thus be described as implementing a form of sampling-based inference (namely, from a Boltzmann machine) at the higher level. However, this equivalence is very fragile, breaking upon simple modifications to the generative models of the individual agents or the nature of their interactions. We discuss the implications of this correspondence and its fragility for the study of multiscale systems composed of Bayesian agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2207.06970.pdf"
      }
    },
    "millidge2022successor": {
      "citation_key": "millidge2022successor",
      "title": "Successor Representation Active Inference",
      "authors": [
        "Beren Millidge",
        "Christopher L Buckley"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2207.09897v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.278043",
      "abstract": "Recent work has uncovered close links between between classical reinforcement learning algorithms, Bayesian filtering, and Active Inference which lets us understand value functions in terms of Bayesian posteriors. An alternative, but less explored, model-free RL algorithm is the successor representation, which expresses the value function in terms of a successor matrix of expected future state occupancies. In this paper, we derive the probabilistic interpretation of the successor representation in terms of Bayesian filtering and thus design a novel active inference agent architecture utilizing successor representations instead of model-based planning. We demonstrate that active inference successor representations have significant advantages over current active inference agents in terms of planning horizon and computational cost. Moreover, we demonstrate how the successor representation agent can generalize to changing reward functions such as variants of the expected free energy.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2207.09897.pdf"
      }
    },
    "albarracin2022mapping": {
      "citation_key": "albarracin2022mapping",
      "title": "Mapping Husserlian phenomenology onto active inference",
      "authors": [
        "Mahault Albarracin",
        "Riddhi J. Pitliya",
        "Maxwell J. D. Ramstead",
        "Jeffrey Yoshimi"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2208.09058v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.284383",
      "abstract": "Phenomenology is the rigorous descriptive study of conscious experience. Recent attempts to formalize Husserlian phenomenology provide us with a mathematical model of perception as a function of prior knowledge and expectation. In this paper, we re-examine elements of Husserlian phenomenology through the lens of active inference. In doing so, we aim to advance the project of computational phenomenology, as recently outlined by proponents of active inference. We propose that key aspects of Husserl's descriptions of consciousness can be mapped onto aspects of the generative models associated with the active inference approach. We first briefly review active inference. We then discuss Husserl's phenomenology, with a focus on time consciousness. Finally, we present our mapping from Husserlian phenomenology to active inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2208.09058.pdf"
      }
    },
    "baioumy2022unbiased": {
      "citation_key": "baioumy2022unbiased",
      "title": "Unbiased Active Inference for Classical Control",
      "authors": [
        "Mohamed Baioumy",
        "Corrado Pezzato",
        "Riccardo Ferrari",
        "Nick Hawes"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2207.13409v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.290360",
      "abstract": "Active inference is a mathematical framework that originated in computational neuroscience. Recently, it has been demonstrated as a promising approach for constructing goal-driven behavior in robotics. Specifically, the active inference controller (AIC) has been successful on several continuous control and state-estimation tasks. Despite its relative success, some established design choices lead to a number of practical limitations for robot control. These include having a biased estimate of the state, and only an implicit model of control actions. In this paper, we highlight these limitations and propose an extended version of the unbiased active inference controller (u-AIC). The u-AIC maintains all the compelling benefits of the AIC and removes its limitations. Simulation results on a 2-DOF arm and experiments on a real 7-DOF manipulator show the improved performance of the u-AIC with respect to the standard AIC. The code can be found at https://github.com/cpezzato/unbiased_aic.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2207.13409.pdf"
      }
    },
    "schneider2022active": {
      "citation_key": "schneider2022active",
      "title": "Active Inference for Robotic Manipulation",
      "authors": [
        "Tim Schneider",
        "Boris Belousov",
        "Hany Abdulsamad",
        "Jan Peters"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2206.10313v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.296632",
      "abstract": "Robotic manipulation stands as a largely unsolved problem despite significant advances in robotics and machine learning in the last decades. One of the central challenges of manipulation is partial observability, as the agent usually does not know all physical properties of the environment and the objects it is manipulating in advance. A recently emerging theory that deals with partial observability in an explicit manner is Active Inference. It does so by driving the agent to act in a way that is not only goal-directed but also informative about the environment. In this work, we apply Active Inference to a hard-to-explore simulated robotic manipulation tasks, in which the agent has to balance a ball into a target zone. Since the reward of this task is sparse, in order to explore this environment, the agent has to learn to balance the ball without any extrinsic feedback, purely driven by its own curiosity. We show that the information-seeking behavior induced by Active Inference allows the agent to explore these challenging, sparse environments systematically. Finally, we conclude that using an information-seeking objective is beneficial in sparse environments and allows the agent to solve tasks in which methods that do not exhibit directed exploration fail.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2206.10313.pdf"
      }
    },
    "wauthier2022learning": {
      "citation_key": "wauthier2022learning",
      "title": "Learning Generative Models for Active Inference using Tensor Networks",
      "authors": [
        "Samuel T. Wauthier",
        "Bram Vanhecke",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2208.08713v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.302989",
      "abstract": "Active inference provides a general framework for behavior and learning in autonomous agents. It states that an agent will attempt to minimize its variational free energy, defined in terms of beliefs over observations, internal states and policies. Traditionally, every aspect of a discrete active inference model must be specified by hand, i.e. by manually defining the hidden state space structure, as well as the required distributions such as likelihood and transition probabilities. Recently, efforts have been made to learn state space representations automatically from observations using deep neural networks. In this paper, we present a novel approach of learning state spaces using quantum physics-inspired tensor networks. The ability of tensor networks to represent the probabilistic nature of quantum states as well as to reduce large state spaces makes tensor networks a natural candidate for active inference. We show how tensor networks can be used as a generative model for sequential data. Furthermore, we show how one can obtain beliefs from such a generative model and how an active inference agent can use these to compute the expected free energy. Finally, we demonstrate our method on the classic T-maze environment.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2208.08713.pdf"
      }
    },
    "bergen2022objectbased": {
      "citation_key": "bergen2022objectbased",
      "title": "Object-based active inference",
      "authors": [
        "Ruben S. van Bergen",
        "Pablo L. Lanillos"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2209.01258v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.313243",
      "abstract": "The world consists of objects: distinct entities possessing independent properties and dynamics. For agents to interact with the world intelligently, they must translate sensory inputs into the bound-together features that describe each object. These object-based representations form a natural basis for planning behavior. Active inference (AIF) is an influential unifying account of perception and action, but existing AIF models have not leveraged this important inductive bias. To remedy this, we introduce 'object-based active inference' (OBAI), marrying AIF with recent deep object-based neural networks. OBAI represents distinct objects with separate variational beliefs, and uses selective attention to route inputs to their corresponding object slots. Object representations are endowed with independent action-based dynamics. The dynamics and generative model are learned from experience with a simple environment (active multi-dSprites). We show that OBAI learns to correctly segment the action-perturbed objects from video input, and to manipulate these objects towards arbitrary goals.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2209.01258.pdf"
      }
    },
    "kiefer2022efficient": {
      "citation_key": "kiefer2022efficient",
      "title": "Efficient search of active inference policy spaces using k-means",
      "authors": [
        "Alex B. Kiefer",
        "Mahault Albarracin"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2209.02550v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.319688",
      "abstract": "We develop an approach to policy selection in active inference that allows us to efficiently search large policy spaces by mapping each policy to its embedding in a vector space. We sample the expected free energy of representative points in the space, then perform a more thorough policy search around the most promising point in this initial sample. We consider various approaches to creating the policy embedding space, and propose using k-means clustering to select representative points. We apply our technique to a goal-oriented graph-traversal problem, for which naive policy selection is intractable for even moderately large graphs.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2209.02550.pdf"
      }
    },
    "champion2022multimodal": {
      "citation_key": "champion2022multimodal",
      "title": "Multi-Modal and Multi-Factor Branching Time Active Inference",
      "authors": [
        "Théophile Champion",
        "Marek Grześ",
        "Howard Bowman"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2206.12503v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.325352",
      "abstract": "Active inference is a state-of-the-art framework for modelling the brain that explains a wide range of mechanisms such as habit formation, dopaminergic discharge and curiosity. Recently, two versions of branching time active inference (BTAI) based on Monte-Carlo tree search have been developed to handle the exponential (space and time) complexity class that occurs when computing the prior over all possible policies up to the time horizon. However, those two versions of BTAI still suffer from an exponential complexity class w.r.t the number of observed and latent variables being modelled. In the present paper, we resolve this limitation by first allowing the modelling of several observations, each of them having its own likelihood mapping. Similarly, we allow each latent state to have its own transition mapping. The inference algorithm then exploits the factorisation of the likelihood and transition mappings to accelerate the computation of the posterior. Those two optimisations were tested on the dSprites environment in which the metadata of the dSprites dataset was used as input to the model instead of the dSprites images. On this task, $BTAI_{VMP}$ (Champion et al., 2022b,a) was able to solve 96.9\\% of the task in 5.1 seconds, and $BTAI_{BF}$ (Champion et al., 2021a) was able to solve 98.6\\% of the task in 17.5 seconds. Our new approach ($BTAI_{3MF}$) outperformed both of its predecessors by solving the task completly (100\\%) in only 2.559 seconds. Finally, $BTAI_{3MF}$ has been implemented in a flexible and easy to use (python) package, and we developed a graphical user interface to enable the inspection of the model's beliefs, planning process and behaviour.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2206.12503.pdf"
      }
    },
    "smithe2022compositional": {
      "citation_key": "smithe2022compositional",
      "title": "Compositional Active Inference II: Polynomial Dynamics. Approximate Inference Doctrines",
      "authors": [
        "Toby St. Clere Smithe"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2208.12173v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.331738",
      "abstract": "We develop the compositional theory of active inference by introducing activity, functorially relating statistical games to the dynamical systems which play them, using the new notion of approximate inference doctrine. In order to exhibit such functors, we first develop the necessary theory of dynamical systems, using a generalization of the language of polynomial functors to supply compositional interfaces of the required types: with the resulting polynomially indexed categories of coalgebras, we construct monoidal bicategories of differential and dynamical ``hierarchical inference systems'', in which approximate inference doctrines have semantics. We then describe ``externally parameterized'' statistical games, and use them to construct two approximate inference doctrines found in the computational neuroscience literature, which we call the `Laplace' and the `Hebb-Laplace' doctrines: the former produces dynamical systems which optimize the posteriors of Gaussian models; and the latter produces systems which additionally optimize the parameters (or `weights') which determine their predictions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2208.12173.pdf"
      }
    },
    "tinguy2022home": {
      "citation_key": "tinguy2022home",
      "title": "Home Run: Finding Your Way Home by Imagining Trajectories",
      "authors": [
        "Daria de Tinguy",
        "Pietro Mazzaglia",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2208.10914v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.337942",
      "abstract": "When studying unconstrained behaviour and allowing mice to leave their cage to navigate a complex labyrinth, the mice exhibit foraging behaviour in the labyrinth searching for rewards, returning to their home cage now and then, e.g. to drink. Surprisingly, when executing such a ``home run'', the mice do not follow the exact reverse path, in fact, the entry path and home path have very little overlap. Recent work proposed a hierarchical active inference model for navigation, where the low level model makes inferences about hidden states and poses that explain sensory inputs, whereas the high level model makes inferences about moving between locations, effectively building a map of the environment. However, using this ``map'' for planning, only allows the agent to find trajectories that it previously explored, far from the observed mice's behaviour. In this paper, we explore ways of incorporating before-unvisited paths in the planning algorithm, by using the low level generative model to imagine potential, yet undiscovered paths. We demonstrate a proof of concept in a grid-world environment, showing how an agent can accurately predict a new, shorter path in the map leading to its starting point, using a generative model learnt from pixel-based observations.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2208.10914.pdf"
      }
    },
    "joshi2022blockchainbased": {
      "citation_key": "joshi2022blockchainbased",
      "title": "Blockchain-Based Decentralized Knowledge Marketplace Using Active Inference",
      "authors": [
        "Shashank Joshi",
        "Arhan Choudhury"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2210.01688v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.344540",
      "abstract": "A knowledge market can be described as a type of market where there is a consistent supply of data to satisfy the demand for information and is responsible for the mapping of potential problem solvers with the entities which need these solutions. It is possible to define them as value-exchange systems in which the dynamic features of the creation and exchange of intellectual assets serve as the fundamental drivers of the frequency, nature, and outcomes of interactions among various stakeholders. Furthermore, the provision of financial backing for research is an essential component in the process of developing a knowledge market that is capable of enduring over time, and it is also an essential driver of the progression of scientific investigation. This paper underlines flaws associated with the conventional knowledge-based market, including but not limited to excessive financing concentration, ineffective information exchange, a lack of security, mapping of entities, etc. The authors present a decentralized framework for the knowledge marketplace incorporating technologies such as blockchain, active inference, zero-knowledge proof, etc. The proposed decentralized framework provides not only an efficient mapping mechanism to map entities in the marketplace but also a more secure and controlled way to share knowledge and services among various stakeholders.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2210.01688.pdf"
      }
    },
    "yang2022neural": {
      "citation_key": "yang2022neural",
      "title": "A Neural Active Inference Model of Perceptual-Motor Learning",
      "authors": [
        "Zhizhuo Yang",
        "Gabriel J. Diaz",
        "Brett R. Fajen",
        "Reynold Bailey",
        "Alexander Ororbia"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2211.10419v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.350175",
      "abstract": "The active inference framework (AIF) is a promising new computational framework grounded in contemporary neuroscience that can produce human-like behavior through reward-based learning. In this study, we test the ability for the AIF to capture the role of anticipation in the visual guidance of action in humans through the systematic investigation of a visual-motor task that has been well-explored -- that of intercepting a target moving over a ground plane. Previous research demonstrated that humans performing this task resorted to anticipatory changes in speed intended to compensate for semi-predictable changes in target speed later in the approach. To capture this behavior, our proposed \"neural\" AIF agent uses artificial neural networks to select actions on the basis of a very short term prediction of the information about the task environment that these actions would reveal along with a long-term estimate of the resulting cumulative expected free energy. Systematic variation revealed that anticipatory behavior emerged only when required by limitations on the agent's movement capabilities, and only when the agent was able to estimate accumulated free energy over sufficiently long durations into the future. In addition, we present a novel formulation of the prior function that maps a multi-dimensional world-state to a uni-dimensional distribution of free-energy. Together, these results demonstrate the use of AIF as a plausible model of anticipatory visually guided behavior in humans.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2211.10419.pdf"
      }
    },
    "bauermeister2022role": {
      "citation_key": "bauermeister2022role",
      "title": "The Role of Valence and Meta-awareness in Mirror Self-recognition Using Hierarchical Active Inference",
      "authors": [
        "Jonathan Bauermeister",
        "Pablo Lanillos"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2208.13213v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.356387",
      "abstract": "The underlying processes that enable self-perception are crucial for understanding multisensory integration, body perception and action, and the development of the self. Previous computational models have overlooked an essential aspect: affective or emotional components cannot be uncoupled from the self-recognition process. Hence, here we propose a computational approach to study self-recognition that incorporates affect using state-of-the-art hierarchical active inference. We evaluated our model in a synthetic experiment inspired by the mirror self-recognition test, a benchmark for evaluating self-recognition in animals and humans alike. Results show that i) negative valence arises when the agent recognizes itself and learns something unexpected about its internal states. Furthermore, ii) the agent in the presence of strong prior expectations of a negative affective state will avoid the mirror altogether in anticipation of an undesired learning process. Both results are in line with current literature on human self-recognition.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2208.13213.pdf"
      }
    },
    "ferraro2022disentangling": {
      "citation_key": "ferraro2022disentangling",
      "title": "Disentangling Shape and Pose for Object-Centric Deep Active Inference Models",
      "authors": [
        "Stefano Ferraro",
        "Toon Van de Maele",
        "Pietro Mazzaglia",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2209.09097v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.362562",
      "abstract": "Active inference is a first principles approach for understanding the brain in particular, and sentient agents in general, with the single imperative of minimizing free energy. As such, it provides a computational account for modelling artificial intelligent agents, by defining the agent's generative model and inferring the model parameters, actions and hidden state beliefs. However, the exact specification of the generative model and the hidden state space structure is left to the experimenter, whose design choices influence the resulting behaviour of the agent. Recently, deep learning methods have been proposed to learn a hidden state space structure purely from data, alleviating the experimenter from this tedious design task, but resulting in an entangled, non-interpreteable state space. In this paper, we hypothesize that such a learnt, entangled state space does not necessarily yield the best model in terms of free energy, and that enforcing different factors in the state space can yield a lower model complexity. In particular, we consider the problem of 3D object representation, and focus on different instances of the ShapeNet dataset. We propose a model that factorizes object shape, pose and category, while still learning a representation for each factor using a deep neural network. We show that models, with best disentanglement properties, perform best when adopted by an active agent in reaching preferred observations.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2209.09097.pdf"
      }
    },
    "malekzadeh2022active": {
      "citation_key": "malekzadeh2022active",
      "title": "Active Inference and Reinforcement Learning: A unified inference on continuous state and action spaces under partial observability",
      "authors": [
        "Parvin Malekzadeh",
        "Konstantinos N. Plataniotis"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2212.07946v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.369282",
      "abstract": "Reinforcement learning (RL) has garnered significant attention for developing decision-making agents that aim to maximize rewards, specified by an external supervisor, within fully observable environments. However, many real-world problems involve partial observations, formulated as partially observable Markov decision processes (POMDPs). Previous studies have tackled RL in POMDPs by either incorporating the memory of past actions and observations or by inferring the true state of the environment from observed data. However, aggregating observed data over time becomes impractical in continuous spaces. Moreover, inference-based RL approaches often require many samples to perform well, as they focus solely on reward maximization and neglect uncertainty in the inferred state. Active inference (AIF) is a framework formulated in POMDPs and directs agents to select actions by minimizing a function called expected free energy (EFE). This supplies reward-maximizing (exploitative) behaviour, as in RL, with information-seeking (exploratory) behaviour. Despite this exploratory behaviour of AIF, its usage is limited to discrete spaces due to the computational challenges associated with EFE. In this paper, we propose a unified principle that establishes a theoretical connection between AIF and RL, enabling seamless integration of these two approaches and overcoming their aforementioned limitations in continuous space POMDP settings. We substantiate our findings with theoretical analysis, providing novel perspectives for utilizing AIF in the design of artificial agents. Experimental results demonstrate the superior learning capabilities of our method in solving continuous space partially observable tasks. Notably, our approach harnesses information-seeking exploration, enabling it to effectively solve reward-free problems and rendering explicit task reward design by an external supervisor optional.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2212.07946.pdf"
      }
    },
    "kiefer2022capsule": {
      "citation_key": "kiefer2022capsule",
      "title": "Capsule Networks as Generative Models",
      "authors": [
        "Alex B. Kiefer",
        "Beren Millidge",
        "Alexander Tschantz",
        "Christopher L. Buckley"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2209.02567v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.375382",
      "abstract": "Capsule networks are a neural network architecture specialized for visual scene recognition. Features and pose information are extracted from a scene and then dynamically routed through a hierarchy of vector-valued nodes called 'capsules' to create an implicit scene graph, with the ultimate aim of learning vision directly as inverse graphics. Despite these intuitions, however, capsule networks are not formulated as explicit probabilistic generative models; moreover, the routing algorithms typically used are ad-hoc and primarily motivated by algorithmic intuition. In this paper, we derive an alternative capsule routing algorithm utilizing iterative inference under sparsity constraints. We then introduce an explicit probabilistic generative model for capsule networks based on the self-attention operation in transformer networks and show how it is related to a variant of predictive coding networks using Von-Mises-Fisher (VMF) circular Gaussian distributions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2209.02567.pdf"
      }
    },
    "huebotter2022learning": {
      "citation_key": "huebotter2022learning",
      "title": "Learning Policies for Continuous Control via Transition Models",
      "authors": [
        "Justus Huebotter",
        "Serge Thill",
        "Marcel van Gerven",
        "Pablo Lanillos"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2209.08033v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.381537",
      "abstract": "It is doubtful that animals have perfect inverse models of their limbs (e.g., what muscle contraction must be applied to every joint to reach a particular location in space). However, in robot control, moving an arm's end-effector to a target position or along a target trajectory requires accurate forward and inverse models. Here we show that by learning the transition (forward) model from interaction, we can use it to drive the learning of an amortized policy. Hence, we revisit policy optimization in relation to the deep active inference framework and describe a modular neural network architecture that simultaneously learns the system dynamics from prediction errors and the stochastic policy that generates suitable continuous control commands to reach a desired reference position. We evaluated the model by comparing it against the baseline of a linear quadratic regulator, and conclude with additional steps to take toward human-like motor control.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2209.08033.pdf"
      }
    },
    "tramèr2022truth": {
      "citation_key": "tramèr2022truth",
      "title": "Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets",
      "authors": [
        "Florian Tramèr",
        "Reza Shokri",
        "Ayrton San Joaquin",
        "Hoang Le",
        "Matthew Jagielski",
        "Sanghyun Hong",
        "Nicholas Carlini"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2204.00032v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.387851",
      "abstract": "We introduce a new class of attacks on machine learning models. We show that an adversary who can poison a training dataset can cause models trained on this dataset to leak significant private details of training points belonging to other parties. Our active inference attacks connect two independent lines of work targeting the integrity and privacy of machine learning training data.   Our attacks are effective across membership inference, attribute inference, and data extraction. For example, our targeted attacks can poison <0.1% of the training dataset to boost the performance of inference attacks by 1 to 2 orders of magnitude. Further, an adversary who controls a significant fraction of the training data (e.g., 50%) can launch untargeted attacks that enable 8x more precise inference on all other users' otherwise-private data points.   Our results cast doubts on the relevance of cryptographic privacy guarantees in multiparty computation protocols for machine learning, if parties can arbitrarily select their share of training data.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2204.00032.pdf"
      }
    },
    "souza2022parallel": {
      "citation_key": "souza2022parallel",
      "title": "Parallel MCMC Without Embarrassing Failures",
      "authors": [
        "Daniel Augusto de Souza",
        "Diego Mesquita",
        "Samuel Kaski",
        "Luigi Acerbi"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2202.11154v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.394884",
      "abstract": "Embarrassingly parallel Markov Chain Monte Carlo (MCMC) exploits parallel computing to scale Bayesian inference to large datasets by using a two-step approach. First, MCMC is run in parallel on (sub)posteriors defined on data partitions. Then, a server combines local results. While efficient, this framework is very sensitive to the quality of subposterior sampling. Common sampling problems such as missing modes or misrepresentation of low-density regions are amplified -- instead of being corrected -- in the combination phase, leading to catastrophic failures. In this work, we propose a novel combination strategy to mitigate this issue. Our strategy, Parallel Active Inference (PAI), leverages Gaussian Process (GP) surrogate modeling and active learning. After fitting GPs to subposteriors, PAI (i) shares information between GP surrogates to cover missing modes; and (ii) uses active sampling to individually refine subposterior approximations. We validate PAI in challenging benchmarks, including heavy-tailed and multi-modal posteriors and a real-world application to computational neuroscience. Empirical results show that PAI succeeds where previous methods catastrophically fail, with a small communication overhead.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2202.11154.pdf"
      }
    },
    "meera2022reclaiming": {
      "citation_key": "meera2022reclaiming",
      "title": "Reclaiming saliency: rhythmic precision-modulated action and perception",
      "authors": [
        "Ajith Anil Meera",
        "Filip Novicky",
        "Thomas Parr",
        "Karl Friston",
        "Pablo Lanillos",
        "Noor Sajid"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2203.12652v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.402308",
      "abstract": "Computational models of visual attention in artificial intelligence and robotics have been inspired by the concept of a saliency map. These models account for the mutual information between the (current) visual information and its estimated causes. However, they fail to consider the circular causality between perception and action. In other words, they do not consider where to sample next, given current beliefs. Here, we reclaim salience as an active inference process that relies on two basic principles: uncertainty minimisation and rhythmic scheduling. For this, we make a distinction between attention and salience. Briefly, we associate attention with precision control, i.e., the confidence with which beliefs can be updated given sampled sensory data, and salience with uncertainty minimisation that underwrites the selection of future sensory data. Using this, we propose a new account of attention based on rhythmic precision-modulation and discuss its potential in robotics, providing numerical experiments that showcase advantages of precision-modulation for state and noise estimation, system identification and action selection for informative path planning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2203.12652.pdf"
      }
    },
    "wu2022aiotenabled": {
      "citation_key": "wu2022aiotenabled",
      "title": "An AIoT-enabled Autonomous Dementia Monitoring System",
      "authors": [
        "Xingyu Wu",
        "Jinyang Li"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2207.00804v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.408278",
      "abstract": "An autonomous Artificial Internet of Things (AIoT) system for elderly dementia patients monitoring in a smart home is presented. The system mainly implements two functions based on the activity inference of the sensor data, which are real time abnormal activity monitoring and trend prediction of disease related activities. Specifically, CASAS dataset is employed to train a Random Forest (RF) model for activity inference. Then, another RF model trained by the output data of activity inference is used for abnormal activity monitoring. Particularly, RF is chosen for these tasks because of its balanced trade offs between accuracy, time efficiency, flexibility, and interpretability. Moreover, Long Short Term Memory (LSTM) is utilised to forecast the disease related activity trend of a patient. Consequently, the accuracy of two RF classifiers designed for activity inference and abnormal activity detection is greater than 99 percent and 94 percent, respectively. Furthermore, using the duration of sleep as an example, the LSTM model achieves accurate and evident future trends prediction.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2207.00804.pdf"
      }
    },
    "liang2022m3vit": {
      "citation_key": "liang2022m3vit",
      "title": "M$^3$ViT: Mixture-of-Experts Vision Transformer for Efficient Multi-task Learning with Model-Accelerator Co-design",
      "authors": [
        "Hanxue Liang",
        "Zhiwen Fan",
        "Rishov Sarkar",
        "Ziyu Jiang",
        "Tianlong Chen",
        "Kai Zou",
        "Yu Cheng",
        "Cong Hao",
        "Zhangyang Wang"
      ],
      "year": 2022,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2210.14793v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.414981",
      "abstract": "Multi-task learning (MTL) encapsulates multiple learned tasks in a single model and often lets those tasks learn better jointly. However, when deploying MTL onto those real-world systems that are often resource-constrained or latency-sensitive, two prominent challenges arise: (i) during training, simultaneously optimizing all tasks is often difficult due to gradient conflicts across tasks; (ii) at inference, current MTL regimes have to activate nearly the entire model even to just execute a single task. Yet most real systems demand only one or two tasks at each moment, and switch between tasks as needed: therefore such all tasks activated inference is also highly inefficient and non-scalable. In this paper, we present a model-accelerator co-design framework to enable efficient on-device MTL. Our framework, dubbed M$^3$ViT, customizes mixture-of-experts (MoE) layers into a vision transformer (ViT) backbone for MTL, and sparsely activates task-specific experts during training. Then at inference with any task of interest, the same design allows for activating only the task-corresponding sparse expert pathway, instead of the full model. Our new model design is further enhanced by hardware-level innovations, in particular, a novel computation reordering scheme tailored for memory-constrained MTL that achieves zero-overhead switching between tasks and can scale to any number of experts. When executing single-task inference, M$^{3}$ViT achieves higher accuracies than encoder-focused MTL methods, while significantly reducing 88% inference FLOPs. When implemented on a hardware platform of one Xilinx ZCU104 FPGA, our co-design framework reduces the memory requirement by 2.4 times, while achieving energy efficiency up to 9.23 times higher than a comparable FPGA baseline. Code is available at: https://github.com/VITA-Group/M3ViT.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2210.14793.pdf"
      }
    },
    "kim2020bayesian": {
      "citation_key": "kim2020bayesian",
      "title": "Bayesian mechanics of perceptual inference and motor control in the brain",
      "authors": [
        "Chang Sub Kim"
      ],
      "year": 2020,
      "doi": "10.1007/s00422-021-00859-9",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2008.09927v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.424934",
      "abstract": "The free energy principle (FEP) in the neurosciences stipulates that all viable agents induce and minimize informational free energy in the brain to fit their environmental niche. In this study, we continue our effort to make the FEP a more physically principled formalism by implementing free energy minimization based on the principle of least action. We build a Bayesian mechanics (BM) by casting the formulation reported in the earlier publication (Kim 2018) to considering active inference beyond passive perception. The BM is a neural implementation of variational Bayes under the FEP in continuous time. The resulting BM is provided as an effective Hamilton's equation of motion and subject to the control signal arising from the brain's prediction errors at the proprioceptive level. To demonstrate the utility of our approach, we adopt a simple agent-based model and present a concrete numerical illustration of the brain performing recognition dynamics by integrating BM in neural phase space. Furthermore, we recapitulate the major theoretical architectures in the FEP by comparing our approach with the common state-space formulations.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2008.09927.pdf"
      }
    },
    "costa2020neural": {
      "citation_key": "costa2020neural",
      "title": "Neural dynamics under active inference: plausibility and efficiency of information processing",
      "authors": [
        "Lancelot Da Costa",
        "Thomas Parr",
        "Biswa Sengupta",
        "Karl Friston"
      ],
      "year": 2020,
      "doi": "10.3390/e23040454",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2001.08028v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.431474",
      "abstract": "Active inference is a normative framework for explaining behaviour under the free energy principle -- a theory of self-organisation originating in neuroscience. It specifies neuronal dynamics for state-estimation in terms of a descent on (variational) free energy -- a measure of the fit between an internal (generative) model and sensory observations. The free energy gradient is a prediction error -- plausibly encoded in the average membrane potentials of neuronal populations. Conversely, the expected probability of a state can be expressed in terms of neuronal firing rates. We show that this is consistent with current models of neuronal dynamics and establish face validity by synthesising plausible electrophysiological responses. We then show that these neuronal dynamics approximate natural gradient descent, a well-known optimisation algorithm from information geometry that follows the steepest descent of the objective in information space. We compare the information length of belief updating in both schemes, a measure of the distance traveled in information space that has a direct interpretation in terms of metabolic cost. We show that neural dynamics under active inference are metabolically efficient and suggest that neural representations in biological agents may evolve by approximating steepest descent in information space towards the point of optimal inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2001.08028.pdf"
      }
    },
    "himst2020deep": {
      "citation_key": "himst2020deep",
      "title": "Deep Active Inference for Partially Observable MDPs",
      "authors": [
        "Otto van der Himst",
        "Pablo Lanillos"
      ],
      "year": 2020,
      "doi": "10.1007/978-3-030-64919-7_8",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2009.03622v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.437928",
      "abstract": "Deep active inference has been proposed as a scalable approach to perception and action that deals with large policy and state spaces. However, current models are limited to fully observable domains. In this paper, we describe a deep active inference model that can learn successful policies directly from high-dimensional sensory inputs. The deep learning architecture optimizes a variant of the expected free energy and encodes the continuous state representation by means of a variational autoencoder. We show, in the OpenAI benchmark, that our approach has comparable or better performance than deep Q-learning, a state-of-the-art deep reinforcement learning algorithm.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2009.03622.pdf"
      }
    },
    "rood2020deep": {
      "citation_key": "rood2020deep",
      "title": "A deep active inference model of the rubber-hand illusion",
      "authors": [
        "Thomas Rood",
        "Marcel van Gerven",
        "Pablo Lanillos"
      ],
      "year": 2020,
      "doi": "10.1007/978-3-030-64919-7_10",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2008.07408v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.444601",
      "abstract": "Understanding how perception and action deal with sensorimotor conflicts, such as the rubber-hand illusion (RHI), is essential to understand how the body adapts to uncertain situations. Recent results in humans have shown that the RHI not only produces a change in the perceived arm location, but also causes involuntary forces. Here, we describe a deep active inference agent in a virtual environment, which we subjected to the RHI, that is able to account for these results. We show that our model, which deals with visual high-dimensional inputs, produces similar perceptual and force patterns to those found in humans.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2008.07408.pdf"
      }
    },
    "costa2020active": {
      "citation_key": "costa2020active",
      "title": "Active inference on discrete state-spaces: a synthesis",
      "authors": [
        "Lancelot Da Costa",
        "Thomas Parr",
        "Noor Sajid",
        "Sebastijan Veselic",
        "Victorita Neacsu",
        "Karl Friston"
      ],
      "year": 2020,
      "doi": "10.1016/j.jmp.2020.102447",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2001.07203v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.450653",
      "abstract": "Active inference is a normative principle underwriting perception, action, planning, decision-making and learning in biological or artificial agents. From its inception, its associated process theory has grown to incorporate complex generative models, enabling simulation of a wide range of complex behaviours. Due to successive developments in active inference, it is often difficult to see how its underlying principle relates to process theories and practical implementation. In this paper, we try to bridge this gap by providing a complete mathematical synthesis of active inference on discrete state-space models. This technical summary provides an overview of the theory, derives neuronal dynamics from first principles and relates this dynamics to biological processes. Furthermore, this paper provides a fundamental building block needed to understand active inference for mixed generative models; allowing continuous sensations to inform discrete representations. This paper may be used as follows: to guide research towards outstanding challenges, a practical guide on how to implement active inference to simulate experimental behaviour, or a pointer towards various in-silico neurophysiological responses that may be used to make empirical predictions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2001.07203.pdf"
      }
    },
    "baltieri2020predictions": {
      "citation_key": "baltieri2020predictions",
      "title": "Predictions in the eye of the beholder: an active inference account of Watt governors",
      "authors": [
        "Manuel Baltieri",
        "Christopher L. Buckley",
        "Jelle Bruineberg"
      ],
      "year": 2020,
      "doi": "10.1162/isal_a_00288",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2006.11495v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.457466",
      "abstract": "Active inference introduces a theory describing action-perception loops via the minimisation of variational (and expected) free energy or, under simplifying assumptions, (weighted) prediction error. Recently, active inference has been proposed as part of a new and unifying framework in the cognitive sciences: predictive processing. Predictive processing is often associated with traditional computational theories of the mind, strongly relying on internal representations presented in the form of generative models thought to explain different functions of living and cognitive systems. In this work, we introduce an active inference formulation of the Watt centrifugal governor, a system often portrayed as the canonical \"anti-representational\" metaphor for cognition. We identify a generative model of a steam engine for the governor, and derive a set of equations describing \"perception\" and \"action\" processes as a form of prediction error minimisation. In doing so, we firstly challenge the idea of generative models as explicit internal representations for cognitive systems, suggesting that such models serve only as implicit descriptions for an observer. Secondly, we consider current proposals of predictive processing as a theory of cognition, focusing on some of its potential shortcomings and in particular on the idea that virtually any system admits a description in terms of prediction error minimisation, suggesting that this theory may offer limited explanatory power for cognitive systems. Finally, as a silver lining we emphasise the instrumental role this framework can nonetheless play as a mathematical tool for modelling cognitive architectures interpreted in terms of Bayesian (active) inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2006.11495.pdf"
      }
    },
    "matsumoto2020goaldirected": {
      "citation_key": "matsumoto2020goaldirected",
      "title": "Goal-Directed Planning for Habituated Agents by Active Inference Using a Variational Recurrent Neural Network",
      "authors": [
        "Takazumi Matsumoto",
        "Jun Tani"
      ],
      "year": 2020,
      "doi": "10.3390/e22050564",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2005.14656v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.464133",
      "abstract": "It is crucial to ask how agents can achieve goals by generating action plans using only partial models of the world acquired through habituated sensory-motor experiences. Although many existing robotics studies use a forward model framework, there are generalization issues with high degrees of freedom. The current study shows that the predictive coding (PC) and active inference (AIF) frameworks, which employ a generative model, can develop better generalization by learning a prior distribution in a low dimensional latent state space representing probabilistic structures extracted from well habituated sensory-motor trajectories. In our proposed model, learning is carried out by inferring optimal latent variables as well as synaptic weights for maximizing the evidence lower bound, while goal-directed planning is accomplished by inferring latent variables for maximizing the estimated lower bound. Our proposed model was evaluated with both simple and complex robotic tasks in simulation, which demonstrated sufficient generalization in learning with limited training data by setting an intermediate value for a regularization coefficient. Furthermore, comparative simulation results show that the proposed model outperforms a conventional forward model in goal-directed planning, due to the learned prior confining the search of motor plans within the range of habituated trajectories.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2005.14656.pdf"
      }
    },
    "ohata2020investigation": {
      "citation_key": "ohata2020investigation",
      "title": "Investigation of the Sense of Agency in Social Cognition, based on frameworks of Predictive Coding and Active Inference: A simulation study on multimodal imitative interaction",
      "authors": [
        "Wataru Ohata",
        "Jun Tani"
      ],
      "year": 2020,
      "doi": "10.3389/fnbot.2020.00061",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2002.01632v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.470927",
      "abstract": "When agents interact socially with different intentions, conflicts are difficult to avoid. Although how agents can resolve such problems autonomously has not been determined, dynamic characteristics of agency may shed light on underlying mechanisms. The current study focused on the sense of agency (SoA), a specific aspect of agency referring to congruence between the agent's intention in acting and the outcome. Employing predictive coding and active inference as theoretical frameworks of perception and action generation, we hypothesize that regulation of complexity in the evidence lower bound of an agent's model should affect the strength of the agent's SoA and should have a critical impact on social interactions. We built a computational model of imitative interaction between a robot and a human via visuo-proprioceptive sensation with a variational Bayes recurrent neural network, and simulated the model in the form of pseudo-imitative interaction using recorded human body movement data. A key feature of the model is that each modality's complexity can be regulated differently with a hyperparameter assigned to each module. We first searched for an optimal setting that endows the model with appropriate coordination of multimodal sensation. This revealed that the vision module's complexity should be more tightly regulated than that of the proprioception module. Using the optimally trained model, we examined how changing the tightness of complexity regulation after training affects the strength of the SoA during interactions. The results showed that with looser regulation, an agent tends to act more egocentrically, without adapting to the other. In contrast, with tighter regulation, the agent tends to follow the other by adjusting its intention. We conclude that the tightness of complexity regulation crucially affects the strength of the SoA and the dynamics of interactions between agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2002.01632.pdf"
      }
    },
    "kouw2020online": {
      "citation_key": "kouw2020online",
      "title": "Online system identification in a Duffing oscillator by free energy minimisation",
      "authors": [
        "Wouter M Kouw"
      ],
      "year": 2020,
      "doi": "10.1007/978-3-030-64919-7_6",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2009.00845v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.478141",
      "abstract": "Online system identification is the estimation of parameters of a dynamical system, such as mass or friction coefficients, for each measurement of the input and output signals. Here, the nonlinear stochastic differential equation of a Duffing oscillator is cast to a generative model and dynamical parameters are inferred using variational message passing on a factor graph of the model. The approach is validated with an experiment on data from an electronic implementation of a Duffing oscillator. The proposed inference procedure performs as well as offline prediction error minimisation in a state-of-the-art nonlinear model.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2009.00845.pdf"
      }
    },
    "chame2020towards": {
      "citation_key": "chame2020towards",
      "title": "Towards hybrid primary intersubjectivity: a neural robotics library for human science",
      "authors": [
        "Hendry F. Chame",
        "Ahmadreza Ahmadi",
        "Jun Tani"
      ],
      "year": 2020,
      "doi": "10.3389/fpsyg.2020.584869",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2006.15948v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.484584",
      "abstract": "Human-robot interaction is becoming an interesting area of research in cognitive science, notably, for the study of social cognition. Interaction theorists consider primary intersubjectivity a non-mentalist, pre-theoretical, non-conceptual sort of processes that ground a certain level of communication and understanding, and provide support to higher-level cognitive skills. We argue this sort of low level cognitive interaction, where control is shared in dyadic encounters, is susceptible of study with neural robots. Hence, in this work we pursue three main objectives. Firstly, from the concept of active inference we study primary intersubjectivity as a second person perspective experience characterized by predictive engagement, where perception, cognition, and action are accounted for an hermeneutic circle in dyadic interaction. Secondly, we propose an open-source methodology named \\textit{neural robotics library} (NRL) for experimental human-robot interaction, and a demonstration program for interacting in real-time with a virtual Cartesian robot (VCBot). Lastly, through a study case, we discuss some ways human-robot (hybrid) intersubjectivity can contribute to human science research, such as to the fields of developmental psychology, educational technology, and cognitive rehabilitation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2006.15948.pdf"
      }
    },
    "kori2020abstracting": {
      "citation_key": "kori2020abstracting",
      "title": "Abstracting Deep Neural Networks into Concept Graphs for Concept Level Interpretability",
      "authors": [
        "Avinash Kori",
        "Parth Natekar",
        "Ganapathy Krishnamurthi",
        "Balaji Srinivasan"
      ],
      "year": 2020,
      "doi": "10.1007/978-3-030-93080-6_15",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2008.06457v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.490930",
      "abstract": "The black-box nature of deep learning models prevents them from being completely trusted in domains like biomedicine. Most explainability techniques do not capture the concept-based reasoning that human beings follow. In this work, we attempt to understand the behavior of trained models that perform image processing tasks in the medical domain by building a graphical representation of the concepts they learn. Extracting such a graphical representation of the model's behavior on an abstract, higher conceptual level would unravel the learnings of these models and would help us to evaluate the steps taken by the model for predictions. We show the application of our proposed implementation on two biomedical problems - brain tumor segmentation and fundus image classification. We provide an alternative graphical representation of the model by formulating a concept level graph as discussed above, which makes the problem of intervention to find active inference trails more tractable. Understanding these trails would provide an understanding of the hierarchy of the decision-making process followed by the model. [As well as overall nature of model]. Our framework is available at https://github.com/koriavinash1/BioExp",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2008.06457.pdf"
      }
    },
    "baltieri2020bayesian": {
      "citation_key": "baltieri2020bayesian",
      "title": "A Bayesian perspective on classical control",
      "authors": [
        "Manuel Baltieri"
      ],
      "year": 2020,
      "doi": "10.1109/IJCNN48605.2020.9206617",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2004.10288v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.497534",
      "abstract": "The connections between optimal control and Bayesian inference have long been recognised, with the field of stochastic (optimal) control combining these frameworks for the solution of partially observable control problems. In particular, for the linear case with quadratic functions and Gaussian noise, stochastic control has shown remarkable results in different fields, including robotics, reinforcement learning and neuroscience, especially thanks to the established duality of estimation and control processes. Following this idea we recently introduced a formulation of PID control, one of the most popular methods from classical control, based on active inference, a theory with roots in variational Bayesian methods, and applications in the biological and neural sciences. In this work, we highlight the advantages of our previous formulation and introduce new and more general ways to tackle some existing problems in current controller design procedures. In particular, we consider 1) a gradient-based tuning rule for the parameters (or gains) of a PID controller, 2) an implementation of multiple degrees of freedom for independent responses to different types of signals (e.g., two-degree-of-freedom PID), and 3) a novel time-domain formalisation of the performance-robustness trade-off in terms of tunable constraints (i.e., priors in a Bayesian model) of a single cost functional, variational free energy.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2004.10288.pdf"
      }
    },
    "gottwald2020two": {
      "citation_key": "gottwald2020two",
      "title": "The Two Kinds of Free Energy and the Bayesian Revolution",
      "authors": [
        "Sebastian Gottwald",
        "Daniel A. Braun"
      ],
      "year": 2020,
      "doi": "10.1371/journal.pcbi.1008420",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2004.11763v4",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.504176",
      "abstract": "The concept of free energy has its origins in 19th century thermodynamics, but has recently found its way into the behavioral and neural sciences, where it has been promoted for its wide applicability and has even been suggested as a fundamental principle of understanding intelligent behavior and brain function. We argue that there are essentially two different notions of free energy in current models of intelligent agency, that can both be considered as applications of Bayesian inference to the problem of action selection: one that appears when trading off accuracy and uncertainty based on a general maximum entropy principle, and one that formulates action selection in terms of minimizing an error measure that quantifies deviations of beliefs and policies from given reference models. The first approach provides a normative rule for action selection in the face of model uncertainty or when information processing capabilities are limited. The second approach directly aims to formulate the action selection problem as an inference problem in the context of Bayesian brain theories, also known as Active Inference in the literature. We elucidate the main ideas and discuss critical technical and conceptual issues revolving around these two notions of free energy that both claim to apply at all levels of decision-making, from the high-level deliberation of reasoning down to the low-level information processing of perception.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2004.11763.pdf"
      }
    },
    "idei2021emergence": {
      "citation_key": "idei2021emergence",
      "title": "Emergence of sensory attenuation based upon the free-energy principle",
      "authors": [
        "Hayato Idei",
        "Wataru Ohata",
        "Yuichi Yamashita",
        "Tetsuya Ogata",
        "Jun Tani"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2111.02666v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.528088",
      "abstract": "The brain attenuates its responses to self-produced exteroceptions (e.g., we cannot tickle ourselves). Is this phenomenon, known as sensory attenuation, enabled innately, or acquired through learning? Here, our simulation study using a multimodal hierarchical recurrent neural network model, based on variational free-energy minimization, shows that a mechanism for sensory attenuation can develop through learning of two distinct types of sensorimotor experience, involving self-produced or externally produced exteroceptions. For each sensorimotor context, a particular free-energy state emerged through interaction between top-down prediction with precision and bottom-up sensory prediction error from each sensory area. The executive area in the network served as an information hub. Consequently, shifts between the two sensorimotor contexts triggered transitions from one free-energy state to another in the network via executive control, which caused shifts between attenuating and amplifying prediction-error-induced responses in the sensory areas. This study situates emergence of sensory attenuation (or self-other distinction) in development of distinct free-energy states in the dynamic hierarchical neural system.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2111.02666.pdf"
      }
    },
    "meera2021brain": {
      "citation_key": "meera2021brain",
      "title": "A Brain Inspired Learning Algorithm for the Perception of a Quadrotor in Wind",
      "authors": [
        "Ajith Anil Meera",
        "Martijn Wisse"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2109.11971v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.536067",
      "abstract": "The quest for a brain-inspired learning algorithm for robots has culminated in the free energy principle from neuroscience that models the brain's perception and action as an optimization over its free energy objectives. Based on this idea, we propose an estimation algorithm for accurate output prediction of a quadrotor flying under unmodelled wind conditions. The key idea behind this work is the handling of unmodelled wind dynamics and the model's non-linearity errors as coloured noise in the system, and leveraging it for accurate output predictions. This paper provides the first experimental validation for the usefulness of generalized coordinates for robot perception using Dynamic Expectation Maximization (DEM). Through real flight experiments, we show that the estimator outperforms classical estimators with the least error in output predictions. Based on the experimental results, we extend the DEM algorithm for model order selection for complete black box identification. With this paper, we provide the first experimental validation of DEM applied to robot learning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2109.11971.pdf"
      }
    },
    "shin2021prior": {
      "citation_key": "shin2021prior",
      "title": "Prior Preference Learning from Experts:Designing a Reward with Active Inference",
      "authors": [
        "Jin young Shin",
        "Cheolhyeong Kim",
        "Hyung Ju Hwang"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2101.08937v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.544625",
      "abstract": "Active inference may be defined as Bayesian modeling of a brain with a biologically plausible model of the agent. Its primary idea relies on the free energy principle and the prior preference of the agent. An agent will choose an action that leads to its prior preference for a future observation. In this paper, we claim that active inference can be interpreted using reinforcement learning (RL) algorithms and find a theoretical connection between them. We extend the concept of expected free energy (EFE), which is a core quantity in active inference, and claim that EFE can be treated as a negative value function. Motivated by the concept of prior preference and a theoretical connection, we propose a simple but novel method for learning a prior preference from experts. This illustrates that the problem with inverse RL can be approached with a new perspective of active inference. Experimental results of prior preference learning show the possibility of active inference with EFE-based rewards and its application to an inverse RL problem.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2101.08937.pdf"
      }
    },
    "sajid2021active": {
      "citation_key": "sajid2021active",
      "title": "Active inference, Bayesian optimal design, and expected utility",
      "authors": [
        "Noor Sajid",
        "Lancelot Da Costa",
        "Thomas Parr",
        "Karl Friston"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2110.04074v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.553536",
      "abstract": "Active inference, a corollary of the free energy principle, is a formal way of describing the behavior of certain kinds of random dynamical systems that have the appearance of sentience. In this chapter, we describe how active inference combines Bayesian decision theory and optimal Bayesian design principles under a single imperative to minimize expected free energy. It is this aspect of active inference that allows for the natural emergence of information-seeking behavior. When removing prior outcomes preferences from expected free energy, active inference reduces to optimal Bayesian design, i.e., information gain maximization. Conversely, active inference reduces to Bayesian decision theory in the absence of ambiguity and relative risk, i.e., expected utility maximization. Using these limiting cases, we illustrate how behaviors differ when agents select actions that optimize expected utility, expected information gain, and expected free energy. Our T-maze simulations show optimizing expected free energy produces goal-directed information-seeking behavior while optimizing expected utility induces purely exploitive behavior and maximizing information gain engenders intrinsically motivated behavior.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2110.04074.pdf"
      }
    },
    "evans2021bounded": {
      "citation_key": "evans2021bounded",
      "title": "Bounded rationality for relaxing best response and mutual consistency: The Quantal Hierarchy model of decision-making",
      "authors": [
        "Benjamin Patrick Evans",
        "Mikhail Prokopenko"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2106.15844v5",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.561865",
      "abstract": "While game theory has been transformative for decision-making, the assumptions made can be overly restrictive in certain instances. In this work, we investigate some of the underlying assumptions of rationality, such as mutual consistency and best response, and consider ways to relax these assumptions using concepts from level-$k$ reasoning and quantal response equilibrium (QRE) respectively. Specifically, we propose an information-theoretic two-parameter model called the Quantal Hierarchy model, which can relax both mutual consistency and best response while still approximating level-$k$, QRE, or typical Nash equilibrium behaviour in the limiting cases. The model is based on a recursive form of the variational free energy principle, representing higher-order reasoning as (pseudo) sequential decision-making in extensive-form game tree. This representation enables us to treat simultaneous games in a similar manner to sequential games, where reasoning resources deplete throughout the game-tree. Bounds in player processing abilities are captured as information costs, where future branches of reasoning are discounted, implying a hierarchy of players where lower-level players have fewer processing resources. We demonstrate the effectiveness of the Quantal Hierarchy model in several canonical economic games, {both simultaneous and sequential}, using out-of-sample modelling.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2106.15844.pdf"
      }
    },
    "sahu2021rethinking": {
      "citation_key": "sahu2021rethinking",
      "title": "Rethinking Neural Networks With Benford's Law",
      "authors": [
        "Surya Kant Sahu",
        "Abhinav Java",
        "Arshad Shaikh",
        "Yannic Kilcher"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2102.03313v4",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.569974",
      "abstract": "Benford's Law (BL) or the Significant Digit Law defines the probability distribution of the first digit of numerical values in a data sample. This Law is observed in many naturally occurring datasets. It can be seen as a measure of naturalness of a given distribution and finds its application in areas like anomaly and fraud detection. In this work, we address the following question: Is the distribution of the Neural Network parameters related to the network's generalization capability? To that end, we first define a metric, MLH (Model Enthalpy), that measures the closeness of a set of numbers to Benford's Law and we show empirically that it is a strong predictor of Validation Accuracy. Second, we use MLH as an alternative to Validation Accuracy for Early Stopping, removing the need for a Validation set. We provide experimental evidence that even if the optimal size of the validation set is known before-hand, the peak test accuracy attained is lower than not using a validation set at all. Finally, we investigate the connection of BL to Free Energy Principle and First Law of Thermodynamics, showing that MLH is a component of the internal energy of the learning system and optimization as an analogy to minimizing the total energy to attain equilibrium.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2102.03313.pdf"
      }
    },
    "ramstead2021empire": {
      "citation_key": "ramstead2021empire",
      "title": "The empire strikes back: Some responses to Bruineberg and colleagues",
      "authors": [
        "Maxwell J. D. Ramstead"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.15528v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.580628",
      "abstract": "In their target paper, Bruineberg and colleagues provide us with a timely opportunity to discuss the formal constructs and philosophical implications of the free-energy principle. I critically discuss their proposed distinction between Pearl blankets and Friston blankets. I then critically assess the distinction between inference with a model and inference within a model in light of instrumentalist approaches to science.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.15528.pdf"
      }
    },
    "baltieri2021kalman": {
      "citation_key": "baltieri2021kalman",
      "title": "Kalman filters as the steady-state solution of gradient descent on variational free energy",
      "authors": [
        "Manuel Baltieri",
        "Takuya Isomura"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2111.10530v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.588324",
      "abstract": "The Kalman filter is an algorithm for the estimation of hidden variables in dynamical systems under linear Gauss-Markov assumptions with widespread applications across different fields. Recently, its Bayesian interpretation has received a growing amount of attention especially in neuroscience, robotics and machine learning. In neuroscience, in particular, models of perception and control under the banners of predictive coding, optimal feedback control, active inference and more generally the so-called Bayesian brain hypothesis, have all heavily relied on ideas behind the Kalman filter. Active inference, an algorithmic theory based on the free energy principle, specifically builds on approximate Bayesian inference methods proposing a variational account of neural computation and behaviour in terms of gradients of variational free energy. Using this ambitious framework, several works have discussed different possible relations between free energy minimisation and standard Kalman filters. With a few exceptions, however, such relations point at a mere qualitative resemblance or are built on a set of very diverse comparisons based on purported differences between free energy minimisation and Kalman filtering. In this work, we present a straightforward derivation of Kalman filters consistent with active inference via a variational treatment of free energy minimisation in terms of gradient descent. The approach considered here offers a more direct link between models of neural dynamics as gradient descent and standard accounts of perception and decision making based on probabilistic inference, further bridging the gap between hypotheses about neural implementation and computational principles in brain and behavioural sciences.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2111.10530.pdf"
      }
    },
    "ciria2021predictive": {
      "citation_key": "ciria2021predictive",
      "title": "Predictive Processing in Cognitive Robotics: a Review",
      "authors": [
        "Alejandra Ciria",
        "Guido Schillaci",
        "Giovanni Pezzulo",
        "Verena V. Hafner",
        "Bruno Lara"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2101.06611v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.594857",
      "abstract": "Predictive processing has become an influential framework in cognitive sciences. This framework turns the traditional view of perception upside down, claiming that the main flow of information processing is realized in a top-down hierarchical manner. Furthermore, it aims at unifying perception, cognition, and action as a single inferential process. However, in the related literature, the predictive processing framework and its associated schemes such as predictive coding, active inference, perceptual inference, free-energy principle, tend to be used interchangeably.   In the field of cognitive robotics there is no clear-cut distinction on which schemes have been implemented and under which assumptions. In this paper, working definitions are set with the main aim of analyzing the state of the art in cognitive robotics research working under the predictive processing framework as well as some related non-robotic models.   The analysis suggests that, first, both research in cognitive robotics implementations and non-robotic models needs to be extended to the study of how multiple exteroceptive modalities can be integrated into prediction error minimization schemes. Second, a relevant distinction found here is that cognitive robotics implementations tend to emphasize the learning of a generative model, while in non-robotics models it is almost absent. Third, despite the relevance for active inference, few cognitive robotics implementations examine the issues around control and whether it should result from the substitution of inverse models with proprioceptive predictions.   Finally, limited attention has been placed on precision weighting and the tracking of prediction error dynamics. These mechanisms should help to explore more complex behaviors and tasks in cognitive robotics research under the predictive processing framework.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2101.06611.pdf"
      }
    },
    "hoeffelen2021deep": {
      "citation_key": "hoeffelen2021deep",
      "title": "Deep Active Inference for Pixel-Based Discrete Control: Evaluation on the Car Racing Problem",
      "authors": [
        "Niels van Hoeffelen",
        "Pablo Lanillos"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2109.04155v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.603385",
      "abstract": "Despite the potential of active inference for visual-based control, learning the model and the preferences (priors) while interacting with the environment is challenging. Here, we study the performance of a deep active inference (dAIF) agent on OpenAI's car racing benchmark, where there is no access to the car's state. The agent learns to encode the world's state from high-dimensional input through unsupervised representation learning. State inference and control are learned end-to-end by optimizing the expected free energy. Results show that our model achieves comparable performance to deep Q-learning. However, vanilla dAIF does not reach state-of-the-art performance compared to other world model approaches. Hence, we discuss the current model implementation's limitations and potential architectures to overcome them.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2109.04155.pdf"
      }
    },
    "mazzaglia2021contrastive": {
      "citation_key": "mazzaglia2021contrastive",
      "title": "Contrastive Active Inference",
      "authors": [
        "Pietro Mazzaglia",
        "Tim Verbelen",
        "Bart Dhoedt"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2110.10083v4",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.611905",
      "abstract": "Active inference is a unifying theory for perception and action resting upon the idea that the brain maintains an internal model of the world by minimizing free energy. From a behavioral perspective, active inference agents can be seen as self-evidencing beings that act to fulfill their optimistic predictions, namely preferred outcomes or goals. In contrast, reinforcement learning requires human-designed rewards to accomplish any desired outcome. Although active inference could provide a more natural self-supervised objective for control, its applicability has been limited because of the shortcomings in scaling the approach to complex environments. In this work, we propose a contrastive objective for active inference that strongly reduces the computational burden in learning the agent's generative model and planning future actions. Our method performs notably better than likelihood-based active inference in image-based tasks, while also being computationally cheaper and easier to train. We compare to reinforcement learning agents that have access to human-designed reward functions, showing that our approach closely matches their performance. Finally, we also show that contrastive methods perform significantly better in the case of distractors in the environment and that our method is able to generalize goals to variations in the background. Website and code: https://contrastive-aif.github.io/",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2110.10083.pdf"
      }
    },
    "meo2021multimodal": {
      "citation_key": "meo2021multimodal",
      "title": "Multimodal VAE Active Inference Controller",
      "authors": [
        "Cristian Meo",
        "Pablo Lanillos"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2103.04412v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.619085",
      "abstract": "Active inference, a theoretical construct inspired by brain processing, is a promising alternative to control artificial agents. However, current methods do not yet scale to high-dimensional inputs in continuous control. Here we present a novel active inference torque controller for industrial arms that maintains the adaptive characteristics of previous proprioceptive approaches but also enables large-scale multimodal integration (e.g., raw images). We extended our previous mathematical formulation by including multimodal state representation learning using a linearly coupled multimodal variational autoencoder. We evaluated our model on a simulated 7DOF Franka Emika Panda robot arm and compared its behavior with a previous active inference baseline and the Panda built-in optimized controller. Results showed improved tracking and control in goal-directed reaching due to the increased representation power, high robustness to noise and adaptability in changes on the environmental conditions and robot parameters without the need to relearn the generative models nor parameters retuning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2103.04412.pdf"
      }
    },
    "meo2021adaptation": {
      "citation_key": "meo2021adaptation",
      "title": "Adaptation through prediction: multisensory active inference torque control",
      "authors": [
        "Cristian Meo",
        "Giovanni Franzese",
        "Corrado Pezzato",
        "Max Spahn",
        "Pablo Lanillos"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.06752v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.626039",
      "abstract": "Adaptation to external and internal changes is major for robotic systems in uncertain environments. Here we present a novel multisensory active inference torque controller for industrial arms that shows how prediction can be used to resolve adaptation. Our controller, inspired by the predictive brain hypothesis, improves the capabilities of current active inference approaches by incorporating learning and multimodal integration of low and high-dimensional sensor inputs (e.g., raw images) while simplifying the architecture. We performed a systematic evaluation of our model on a 7DoF Franka Emika Panda robot arm by comparing its behavior with previous active inference baselines and classic controllers, analyzing both qualitatively and quantitatively adaptation capabilities and control accuracy. Results showed improved control accuracy in goal-directed reaching with high noise rejection due to multimodal filtering, and adaptability to dynamical inertial changes, elasticity constraints and human disturbances without the need to relearn the model nor parameter retuning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.06752.pdf"
      }
    },
    "champion2021realising": {
      "citation_key": "champion2021realising",
      "title": "Realising Active Inference in Variational Message Passing: the Outcome-blind Certainty Seeker",
      "authors": [
        "Théophile Champion",
        "Marek Grześ",
        "Howard Bowman"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2104.11798v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.632992",
      "abstract": "Active inference is a state-of-the-art framework in neuroscience that offers a unified theory of brain function. It is also proposed as a framework for planning in AI. Unfortunately, the complex mathematics required to create new models -- can impede application of active inference in neuroscience and AI research. This paper addresses this problem by providing a complete mathematical treatment of the active inference framework -- in discrete time and state spaces -- and the derivation of the update equations for any new model. We leverage the theoretical connection between active inference and variational message passing as describe by John Winn and Christopher M. Bishop in 2005. Since, variational message passing is a well-defined methodology for deriving Bayesian belief update equations, this paper opens the door to advanced generative models for active inference. We show that using a fully factorized variational distribution simplifies the expected free energy -- that furnishes priors over policies -- so that agents seek unambiguous states. Finally, we consider future extensions that support deep tree searches for sequential policy optimisation -- based upon structure learning and belief propagation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2104.11798.pdf"
      }
    },
    "champion2021branching": {
      "citation_key": "champion2021branching",
      "title": "Branching Time Active Inference: empirical study and complexity class analysis",
      "authors": [
        "Théophile Champion",
        "Howard Bowman",
        "Marek Grześ"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2111.11276v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.639435",
      "abstract": "Active inference is a state-of-the-art framework for modelling the brain that explains a wide range of mechanisms such as habit formation, dopaminergic discharge and curiosity. However, recent implementations suffer from an exponential complexity class when computing the prior over all the possible policies up to the time horizon. Fountas et al (2020) used Monte Carlo tree search to address this problem, leading to very good results in two different tasks. Additionally, Champion et al (2021a) proposed a tree search approach based on (temporal) structure learning. This was enabled by the development of a variational message passing approach to active inference, which enables compositional construction of Bayesian networks for active inference. However, this message passing tree search approach, which we call branching-time active inference (BTAI), has never been tested empirically. In this paper, we present an experimental study of BTAI in the context of a maze solving agent. In this context, we show that both improved prior preferences and deeper search help mitigate the vulnerability to local minima. Then, we compare BTAI to standard active inference (AcI) on a graph navigation task. We show that for small graphs, both BTAI and AcI successfully solve the task. For larger graphs, AcI exhibits an exponential (space) complexity class, making the approach intractable. However, BTAI explores the space of policies more efficiently, successfully scaling to larger graphs. Then, BTAI was compared to the POMCP algorithm on the frozen lake environment. The experiments suggest that BTAI and the POMCP algorithm accumulate a similar amount of reward. Also, we describe when BTAI receives more rewards than the POMCP agent, and when the opposite is true. Finally, we compared BTAI to the approach of Fountas et al (2020) on the dSprites dataset, and we discussed the pros and cons of each approach.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2111.11276.pdf"
      }
    },
    "maisto2021active": {
      "citation_key": "maisto2021active",
      "title": "Active Inference Tree Search in Large POMDPs",
      "authors": [
        "Domenico Maisto",
        "Francesco Gregoretti",
        "Karl Friston",
        "Giovanni Pezzulo"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2103.13860v6",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.646122",
      "abstract": "The ability to plan ahead efficiently is key for both living organisms and artificial systems. Model-based planning and prospection are widely studied in cognitive neuroscience and artificial intelligence (AI), but from different perspectives--and with different desiderata in mind (biological realism versus scalability) that are difficult to reconcile. Here, we introduce a novel method to plan in POMDPs--Active Inference Tree Search (AcT)--that combines the normative character and biological realism of a leading planning theory in neuroscience (Active Inference) and the scalability of tree search methods in AI. This unification enhances both approaches. On the one hand, tree searches enable the biologically grounded, first principle method of active inference to be applied to large-scale problems. On the other hand, active inference provides a principled solution to the exploration-exploitation dilemma, which is often addressed heuristically in tree search methods. Our simulations show that AcT successfully navigates binary trees that are challenging for sampling-based methods, problems that require adaptive exploration, and the large POMDP problem 'RockSample'--in which AcT reproduces state-of-the-art POMDP solutions. Furthermore, we illustrate how AcT can be used to simulate neurophysiological responses (e.g., in the hippocampus and prefrontal cortex) of humans and other animals that solve large planning problems. These numerical analyses show that Active Tree Search is a principled realisation of neuroscientific and AI planning theories, which offer both biological realism and scalability.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2103.13860.pdf"
      }
    },
    "champion2021branching2": {
      "citation_key": "champion2021branching2",
      "title": "Branching Time Active Inference: the theory and its generality",
      "authors": [
        "Théophile Champion",
        "Lancelot Da Costa",
        "Howard Bowman",
        "Marek Grześ"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2111.11107v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.652762",
      "abstract": "Over the last 10 to 15 years, active inference has helped to explain various brain mechanisms from habit formation to dopaminergic discharge and even modelling curiosity. However, the current implementations suffer from an exponential (space and time) complexity class when computing the prior over all the possible policies up to the time-horizon. Fountas et al (2020) used Monte Carlo tree search to address this problem, leading to impressive results in two different tasks. In this paper, we present an alternative framework that aims to unify tree search and active inference by casting planning as a structure learning problem. Two tree search algorithms are then presented. The first propagates the expected free energy forward in time (i.e., towards the leaves), while the second propagates it backward (i.e., towards the root). Then, we demonstrate that forward and backward propagations are related to active inference and sophisticated inference, respectively, thereby clarifying the differences between those two planning strategies.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2111.11107.pdf"
      }
    },
    "baioumy2021solving": {
      "citation_key": "baioumy2021solving",
      "title": "On Solving a Stochastic Shortest-Path Markov Decision Process as Probabilistic Inference",
      "authors": [
        "Mohamed Baioumy",
        "Bruno Lacerda",
        "Paul Duckworth",
        "Nick Hawes"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2109.05866v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.658729",
      "abstract": "Previous work on planning as active inference addresses finite horizon problems and solutions valid for online planning. We propose solving the general Stochastic Shortest-Path Markov Decision Process (SSP MDP) as probabilistic inference. Furthermore, we discuss online and offline methods for planning under uncertainty. In an SSP MDP, the horizon is indefinite and unknown a priori. SSP MDPs generalize finite and infinite horizon MDPs and are widely used in the artificial intelligence community. Additionally, we highlight some of the differences between solving an MDP using dynamic programming approaches widely used in the artificial intelligence community and approaches used in the active inference community.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2109.05866.pdf"
      }
    },
    "champion2021branching3": {
      "citation_key": "champion2021branching3",
      "title": "Branching Time Active Inference with Bayesian Filtering",
      "authors": [
        "Théophile Champion",
        "Marek Grześ",
        "Howard Bowman"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.07406v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.665691",
      "abstract": "Branching Time Active Inference (Champion et al., 2021b,a) is a framework proposing to look at planning as a form of Bayesian model expansion. Its root can be found in Active Inference (Friston et al., 2016; Da Costa et al., 2020; Champion et al., 2021c), a neuroscientific framework widely used for brain modelling, as well as in Monte Carlo Tree Search (Browne et al., 2012), a method broadly applied in the Reinforcement Learning literature. Up to now, the inference of the latent variables was carried out by taking advantage of the flexibility offered by Variational Message Passing (Winn and Bishop, 2005), an iterative process that can be understood as sending messages along the edges of a factor graph (Forney, 2001). In this paper, we harness the efficiency of an alternative method for inference called Bayesian Filtering (Fox et al., 2003), which does not require the iteration of the update equations until convergence of the Variational Free Energy. Instead, this scheme alternates between two phases: integration of evidence and prediction of future states. Both of those phases can be performed efficiently and this provides a seventy times speed up over the state-of-the-art.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.07406.pdf"
      }
    },
    "noel2021online": {
      "citation_key": "noel2021online",
      "title": "Online reinforcement learning with sparse rewards through an active inference capsule",
      "authors": [
        "Alejandro Daniel Noel",
        "Charel van Hoof",
        "Beren Millidge"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2106.02390v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.672623",
      "abstract": "Intelligent agents must pursue their goals in complex environments with partial information and often limited computational capacity. Reinforcement learning methods have achieved great success by creating agents that optimize engineered reward functions, but which often struggle to learn in sparse-reward environments, generally require many environmental interactions to perform well, and are typically computationally very expensive. Active inference is a model-based approach that directs agents to explore uncertain states while adhering to a prior model of their goal behaviour. This paper introduces an active inference agent which minimizes the novel free energy of the expected future. Our model is capable of solving sparse-reward problems with a very high sample efficiency due to its objective function, which encourages directed exploration of uncertain states. Moreover, our model is computationally very light and can operate in a fully online manner while achieving comparable performance to offline RL methods. We showcase the capabilities of our model by solving the mountain car problem, where we demonstrate its superior exploration properties and its robustness to observation noise, which in fact improves performance. We also introduce a novel method for approximating the prior model from the reward function, which simplifies the expression of complex objectives and improves performance over previous active inference approaches.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2106.02390.pdf"
      }
    },
    "lanillos2021active": {
      "citation_key": "lanillos2021active",
      "title": "Active Inference in Robotics and Artificial Agents: Survey and Challenges",
      "authors": [
        "Pablo Lanillos",
        "Cristian Meo",
        "Corrado Pezzato",
        "Ajith Anil Meera",
        "Mohamed Baioumy",
        "Wataru Ohata",
        "Alexander Tschantz",
        "Beren Millidge",
        "Martijn Wisse",
        "Christopher L. Buckley",
        "Jun Tani"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.01871v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.679334",
      "abstract": "Active inference is a mathematical framework which originated in computational neuroscience as a theory of how the brain implements action, perception and learning. Recently, it has been shown to be a promising approach to the problems of state-estimation and control under uncertainty, as well as a foundation for the construction of goal-driven behaviours in robotics and artificial agents in general. Here, we review the state-of-the-art theory and implementations of active inference for state-estimation, control, planning and learning; describing current achievements with a particular focus on robotics. We showcase relevant experiments that illustrate its potential in terms of adaptation, generalization and robustness. Furthermore, we connect this approach with other frameworks and discuss its expected benefits and challenges: a unified framework with functional biological plausibility using variational Bayesian inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.01871.pdf"
      }
    },
    "baioumy2021faulttolerant": {
      "citation_key": "baioumy2021faulttolerant",
      "title": "Fault-tolerant Control of Robot Manipulators with Sensory Faults using Unbiased Active Inference",
      "authors": [
        "Mohamed Baioumy",
        "Corrado Pezzato",
        "Riccardo Ferrari",
        "Carlos Hernandez Corbato",
        "Nick Hawes"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2104.01817v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.686117",
      "abstract": "This work presents a novel fault-tolerant control scheme based on active inference. Specifically, a new formulation of active inference which, unlike previous solutions, provides unbiased state estimation and simplifies the definition of probabilistically robust thresholds for fault-tolerant control of robotic systems using the free-energy. The proposed solution makes use of the sensory prediction errors in the free-energy for the generation of residuals and thresholds for fault detection and isolation of sensory faults, and it does not require additional controllers for fault recovery. Results validating the benefits in a simulated 2-DOF manipulator are presented, and future directions to improve the current fault recovery approach are discussed.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2104.01817.pdf"
      }
    },
    "joseph2021anomaly": {
      "citation_key": "joseph2021anomaly",
      "title": "Anomaly Detection via Controlled Sensing and Deep Active Inference",
      "authors": [
        "Geethu Joseph",
        "Chen Zhong",
        "M. Cenk Gursoy",
        "Senem Velipasalar",
        "Pramod K. Varshney"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2105.06288v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.692178",
      "abstract": "In this paper, we address the anomaly detection problem where the objective is to find the anomalous processes among a given set of processes. To this end, the decision-making agent probes a subset of processes at every time instant and obtains a potentially erroneous estimate of the binary variable which indicates whether or not the corresponding process is anomalous. The agent continues to probe the processes until it obtains a sufficient number of measurements to reliably identify the anomalous processes. In this context, we develop a sequential selection algorithm that decides which processes to be probed at every instant to detect the anomalies with an accuracy exceeding a desired value while minimizing the delay in making the decision and the total number of measurements taken. Our algorithm is based on active inference which is a general framework to make sequential decisions in order to maximize the notion of free energy. We define the free energy using the objectives of the selection policy and implement the active inference framework using a deep neural network approximation. Using numerical experiments, we compare our algorithm with the state-of-the-art method based on deep actor-critic reinforcement learning and demonstrate the superior performance of our algorithm.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2105.06288.pdf"
      }
    },
    "smithe2021compositional": {
      "citation_key": "smithe2021compositional",
      "title": "Compositional Active Inference I: Bayesian Lenses. Statistical Games",
      "authors": [
        "Toby St. Clere Smithe"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2109.04461v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.698979",
      "abstract": "We introduce the concepts of Bayesian lens, characterizing the bidirectional structure of exact Bayesian inference, and statistical game, formalizing the optimization objectives of approximate inference problems. We prove that Bayesian inversions compose according to the compositional lens pattern, and exemplify statistical games with a number of classic statistical concepts, from maximum likelihood estimation to generalized variational Bayesian methods. This paper is the first in a series laying the foundations for a compositional account of the theory of active inference, and we therefore pay particular attention to statistical games with a free-energy objective.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2109.04461.pdf"
      }
    },
    "han2021goaldirected": {
      "citation_key": "han2021goaldirected",
      "title": "Goal-Directed Planning by Reinforcement Learning and Active Inference",
      "authors": [
        "Dongqi Han",
        "Kenji Doya",
        "Jun Tani"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2106.09938v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.706070",
      "abstract": "What is the difference between goal-directed and habitual behavior? We propose a novel computational framework of decision making with Bayesian inference, in which everything is integrated as an entire neural network model. The model learns to predict environmental state transitions by self-exploration and generating motor actions by sampling stochastic internal states ${z}$. Habitual behavior, which is obtained from the prior distribution of ${z}$, is acquired by reinforcement learning. Goal-directed behavior is determined from the posterior distribution of ${z}$ by planning, using active inference which optimizes the past, current and future ${z}$ by minimizing the variational free energy for the desired future observation constrained by the observed sensory sequence. We demonstrate the effectiveness of the proposed framework by experiments in a sensorimotor navigation task with camera observations and continuous motor actions.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2106.09938.pdf"
      }
    },
    "virgo2021interpreting": {
      "citation_key": "virgo2021interpreting",
      "title": "Interpreting Dynamical Systems as Bayesian Reasoners",
      "authors": [
        "Nathaniel Virgo",
        "Martin Biehl",
        "Simon McGregor"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.13523v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.716125",
      "abstract": "A central concept in active inference is that the internal states of a physical system parametrise probability measures over states of the external world. These can be seen as an agent's beliefs, expressed as a Bayesian prior or posterior. Here we begin the development of a general theory that would tell us when it is appropriate to interpret states as representing beliefs in this way. We focus on the case in which a system can be interpreted as performing either Bayesian filtering or Bayesian inference. We provide formal definitions of what it means for such an interpretation to exist, using techniques from category theory.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.13523.pdf"
      }
    },
    "annabi2021bidirectional": {
      "citation_key": "annabi2021bidirectional",
      "title": "Bidirectional Interaction between Visual and Motor Generative Models using Predictive Coding and Active Inference",
      "authors": [
        "Louis Annabi",
        "Alexandre Pitti",
        "Mathias Quoy"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2104.09163v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.722793",
      "abstract": "In this work, we build upon the Active Inference (AIF) and Predictive Coding (PC) frameworks to propose a neural architecture comprising a generative model for sensory prediction, and a distinct generative model for motor trajectories. We highlight how sequences of sensory predictions can act as rails guiding learning, control and online adaptation of motor trajectories. We furthermore inquire the effects of bidirectional interactions between the motor and the visual modules. The architecture is tested on the control of a simulated robotic arm learning to reproduce handwritten letters.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2104.09163.pdf"
      }
    },
    "schoeller2021trust": {
      "citation_key": "schoeller2021trust",
      "title": "Trust as Extended Control: Active Inference and User Feedback During Human-Robot Collaboration",
      "authors": [
        "Felix Schoeller",
        "Mark Miller",
        "Roy Salomon",
        "Karl J. Friston"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2104.11153v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.730028",
      "abstract": "To interact seamlessly with robots, users must infer the causes of a robot's behavior and be confident about that inference. Hence, trust is a necessary condition for human-robot collaboration (HRC). Despite its crucial role, it is largely unknown how trust emerges, develops, and supports human interactions with nonhuman artefacts. Here, we review the literature on trust, human-robot interaction, human-robot collaboration, and human interaction at large. Early models of trust suggest that trust entails a trade-off between benevolence and competence, while studies of human-to-human interaction emphasize the role of shared behavior and mutual knowledge in the gradual building of trust. We then introduce a model of trust as an agent's best explanation for reliable sensory exchange with an extended motor plant or partner. This model is based on the cognitive neuroscience of active inference and suggests that, in the context of HRC, trust can be cast in terms of virtual control over an artificial agent. In this setting, interactive feedback becomes a necessary component of the trustor's perception-action cycle. The resulting model has important implications for understanding human-robot interaction and collaboration, as it allows the traditional determinants of human trust to be defined in terms of active inference, information exchange and empowerment. Furthermore, this model suggests that boredom and surprise may be used as markers for under and over-reliance on the system. Finally, we examine the role of shared behavior in the genesis of trust, especially in the context of dyadic collaboration, suggesting important consequences for the acceptability and design of human-robot collaborative systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2104.11153.pdf"
      }
    },
    "lanillos2021neuroscienceinspired": {
      "citation_key": "lanillos2021neuroscienceinspired",
      "title": "Neuroscience-inspired perception-action in robotics: applying active inference for state estimation, control and self-perception",
      "authors": [
        "Pablo Lanillos",
        "Marcel van Gerven"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2105.04261v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.736754",
      "abstract": "Unlike robots, humans learn, adapt and perceive their bodies by interacting with the world. Discovering how the brain represents the body and generates actions is of major importance for robotics and artificial intelligence. Here we discuss how neuroscience findings open up opportunities to improve current estimation and control algorithms in robotics. In particular, how active inference, a mathematical formulation of how the brain resists a natural tendency to disorder, provides a unified recipe to potentially solve some of the major challenges in robotics, such as adaptation, robustness, flexibility, generalization and safe interaction. This paper summarizes some experiments and lessons learned from developing such a computational model on real embodied platforms, i.e., humanoid and industrial robots. Finally, we showcase the limitations and challenges that we are still facing to give robots human-like perception",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2105.04261.pdf"
      }
    },
    "maele2021disentangling": {
      "citation_key": "maele2021disentangling",
      "title": "Disentangling What and Where for 3D Object-Centric Representations Through Active Inference",
      "authors": [
        "Toon Van de Maele",
        "Tim Verbelen",
        "Ozan Catal",
        "Bart Dhoedt"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2108.11762v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.743997",
      "abstract": "Although modern object detection and classification models achieve high accuracy, these are typically constrained in advance on a fixed train set and are therefore not flexible to deal with novel, unseen object categories. Moreover, these models most often operate on a single frame, which may yield incorrect classifications in case of ambiguous viewpoints. In this paper, we propose an active inference agent that actively gathers evidence for object classifications, and can learn novel object categories over time. Drawing inspiration from the human brain, we build object-centric generative models composed of two information streams, a what- and a where-stream. The what-stream predicts whether the observed object belongs to a specific category, while the where-stream is responsible for representing the object in its internal 3D reference frame. We show that our agent (i) is able to learn representations for many object categories in an unsupervised way, (ii) achieves state-of-the-art classification accuracies, actively resolving ambiguity when required and (iii) identifies novel object categories. Furthermore, we validate our system in an end-to-end fashion where the agent is able to search for an object at a given pose from a pixel-based rendering. We believe that this is a first step towards building modular, intelligent systems that can be used for a wide range of tasks involving three dimensional objects.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2108.11762.pdf"
      }
    },
    "fermin2021insula": {
      "citation_key": "fermin2021insula",
      "title": "Insula Interoception, Active Inference and Feeling Representation",
      "authors": [
        "Alan S. R. Fermin",
        "Karl Friston",
        "Shigeto Yamawaki"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.12290v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.751162",
      "abstract": "The body sends interoceptive visceral information through deep brain structures to the cerebral cortex. The insula cortex, organized in hierarchical modules, is the major cortical region receiving interoceptive afferents and contains visceral topographic maps. Yet, the biological significance of the insula's modular architecture in relation to deep brain regions remains unsolved. In this opinion, we propose the Insula Hierarchical Modular Adaptive Interoception Control (IMAC) model to suggest that insula modules (granular, dysgranular and agranular subregions), forming networks with prefrontal (supplementary motor area, dorsolateral and ventromedial cortices) and striatum (posterior, dorsomedial and ventromedial) subregions, are specialized for higher-order interoceptive representations, recruited in a context-dependent manner to support habitual, model-based and exploratory adaptive behavior. We then discuss how insula interoceptive representations, or metaceptions, could give rise to conscious interoceptive feelings built up from low-order visceral representations and associated basic emotions located in deep interoceptive brain structures.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.12290.pdf"
      }
    },
    "burghardt2021robot": {
      "citation_key": "burghardt2021robot",
      "title": "Robot Localization and Navigation through Predictive Processing using LiDAR",
      "authors": [
        "Daniel Burghardt",
        "Pablo Lanillos"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2109.04139v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.757516",
      "abstract": "Knowing the position of the robot in the world is crucial for navigation. Nowadays, Bayesian filters, such as Kalman and particle-based, are standard approaches in mobile robotics. Recently, end-to-end learning has allowed for scaling-up to high-dimensional inputs and improved generalization. However, there are still limitations to providing reliable laser navigation. Here we show a proof-of-concept of the predictive processing-inspired approach to perception applied for localization and navigation using laser sensors, without the need for odometry. We learn the generative model of the laser through self-supervised learning and perform both online state-estimation and navigation through stochastic gradient descent on the variational free-energy bound. We evaluated the algorithm on a mobile robot (TIAGo Base) with a laser sensor (SICK) in Gazebo. Results showed improved state-estimation performance when comparing to a state-of-the-art particle filter in the absence of odometry. Furthermore, conversely to standard Bayesian estimation approaches our method also enables the robot to navigate when providing the desired goal by inferring the actions that minimize the prediction error.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2109.04139.pdf"
      }
    },
    "guigon2021computational": {
      "citation_key": "guigon2021computational",
      "title": "A computational theory for the production of limb movements",
      "authors": [
        "Emmanuel Guigon"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2107.00814v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.765084",
      "abstract": "Motor control is a fundamental process that underlies all voluntary behavioral responses. Several different theories based on different principles (task dynamics, equilibrium-point theory, passive-motion paradigm, active inference, optimal control) account for specific aspects of how actions are produced, but fail to provide a unified view on this problem. Here we propose a concise theory of motor control based on three principles: optimal feedback control, control with a receding time horizon, and task representation by a series of via-points updated at fixed frequency. By construction, the theory provides a suitable solution to the degrees-of-freedom problem, i.e. trajectory formation in the presence of redundancies and noise. We show through computer simulations that the theory also explains the production of discrete, continuous, rhythmic and temporally-constrained movements, and their parametric and statistical properties (scaling laws, power laws, speed/accuracy tradeoffs). The theory has no free parameters and only limited variations in its implementation details and in the nature of noise are necessary to guarantee its explanatory power.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2107.00814.pdf"
      }
    },
    "bolotta2021social": {
      "citation_key": "bolotta2021social",
      "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
      "authors": [
        "Samuele Bolotta",
        "Guillaume Dumas"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2112.15459v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.772362",
      "abstract": "This article introduces a three-axis framework indicating how AI can be informed by biological examples of social learning mechanisms. We argue that the complex human cognitive architecture owes a large portion of its expressive power to its ability to engage in social and cultural learning. However, the field of AI has mostly embraced a solipsistic perspective on intelligence. We thus argue that social interactions not only are largely unexplored in this field but also are an essential element of advanced cognitive ability, and therefore constitute metaphorically the dark matter of AI. In the first section, we discuss how social learning plays a key role in the development of intelligence. We do so by discussing social and cultural learning theories and empirical findings from social neuroscience. Then, we discuss three lines of research that fall under the umbrella of Social NeuroAI and can contribute to developing socially intelligent embodied agents in complex environments. First, neuroscientific theories of cognitive architecture, such as the global workspace theory and the attention schema theory, can enhance biological plausibility and help us understand how we could bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed to over time, and this is naturally incorporated by dynamical systems. Third, embodiment has been demonstrated to provide more sophisticated array of communicative signals. To conclude, we discuss the example of active inference, which offers powerful insights for developing agents that possess biological realism, can self-organize in time, and are socially embodied.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2112.15459.pdf"
      }
    },
    "palmieri2021unified": {
      "citation_key": "palmieri2021unified",
      "title": "A Unified View of Algorithms for Path Planning Using Probabilistic Inference on Factor Graphs",
      "authors": [
        "Francesco A. N. Palmieri",
        "Krishna R. Pattipati",
        "Giovanni Di Gennaro",
        "Giovanni Fioretti",
        "Francesco Verolla",
        "Amedeo Buonanno"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2106.10442v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.779279",
      "abstract": "Even if path planning can be solved using standard techniques from dynamic programming and control, the problem can also be approached using probabilistic inference. The algorithms that emerge using the latter framework bear some appealing characteristics that qualify the probabilistic approach as a powerful alternative to the more traditional control formulations. The idea of using estimation on stochastic models to solve control problems is not new and the inference approach considered here falls under the rubric of Active Inference (AI) and Control as Inference (CAI). In this work, we look at the specific recursions that arise from various cost functions that, although they may appear similar in scope, bear noticeable differences, at least when applied to typical path planning problems. We start by posing the path planning problem on a probabilistic factor graph, and show how the various algorithms translate into specific message composition rules. We then show how this unified approach, presented both in probability space and in log space, provides a very general framework that includes the Sum-product, the Max-product, Dynamic programming and mixed Reward/Entropy criteria-based algorithms. The framework also expands algorithmic design options for smoother or sharper policy distributions, including generalized Sum/Max-product algorithm, a Smooth Dynamic programming algorithm and modified versions of the Reward/Entropy recursions. We provide a comprehensive table of recursions and a comparison through simulations, first on a synthetic small grid with a single goal with obstacles, and then on a grid extrapolated from a real-world scene with multiple goals and a semantic map.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2106.10442.pdf"
      }
    },
    "chi2021pfirewall": {
      "citation_key": "chi2021pfirewall",
      "title": "PFirewall: Semantics-Aware Customizable Data Flow Control for Smart Home Privacy Protection",
      "authors": [
        "Haotian Chi",
        "Qiang Zeng",
        "Xiaojiang Du",
        "Lannan Luo"
      ],
      "year": 2021,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2101.10522v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.786214",
      "abstract": "Internet of Things (IoT) platforms enable users to deploy home automation applications. Meanwhile, privacy issues arise as large amounts of sensitive device data flow out to IoT platforms. Most of the data flowing out to a platform actually do not trigger automation actions, while homeowners currently have no control once devices are bound to the platform. We present PFirewall, a customizable data-flow control system to enhance the privacy of IoT platform users. PFirewall automatically generates data-minimization policies, which only disclose minimum amount of data to fulfill automation. In addition, PFirewall provides interfaces for homeowners to customize individual privacy preferences by defining user-specified policies. To enforce these policies, PFirewall transparently intervenes and mediates the communication between IoT devices and the platform, without modifying the platform, IoT devices, or hub. Evaluation results on four real-world testbeds show that PFirewall reduces IoT data sent to the platform by 97% without impairing home automation, and effectively mitigates user-activity inference/tracking attacks and other privacy risks.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2101.10522.pdf"
      }
    },
    "oliver2019active": {
      "citation_key": "oliver2019active",
      "title": "Active inference body perception and action for humanoid robots",
      "authors": [
        "Guillermo Oliver",
        "Pablo Lanillos",
        "Gordon Cheng"
      ],
      "year": 2019,
      "doi": "10.1109/TCDS.2021.3049907",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1906.03022v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.795542",
      "abstract": "Providing artificial agents with the same computational models of biological systems is a way to understand how intelligent behaviours may emerge. We present an active inference body perception and action model working for the first time in a humanoid robot. The model relies on the free energy principle proposed for the brain, where both perception and action goal is to minimise the prediction error through gradient descent on the variational free energy bound. The body state (latent variable) is inferred by minimising the difference between the observed (visual and proprioceptive) sensor values and the predicted ones. Simultaneously, the action makes sensory data sampling to better correspond to the prediction made by the inner model. We formalised and implemented the algorithm on the iCub robot and tested in 2D and 3D visual spaces for online adaptation to visual changes, sensory noise and discrepancies between the model and the real robot. We also compared our approach with classical inverse kinematics in a reaching task, analysing the suitability of such a neuroscience-inspired approach for real-world interaction. The algorithm gave the robot adaptive body perception and upper body reaching with head object tracking (toddler-like), and was able to incorporate visual features online (in a closed-loop manner) without increasing the computational complexity. Moreover, our model predicted involuntary actions in the presence of sensorimotor conflicts showing the path for a potential proof of active inference in humans.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1906.03022.pdf"
      }
    },
    "sancaktar2019endtoend": {
      "citation_key": "sancaktar2019endtoend",
      "title": "End-to-End Pixel-Based Deep Active Inference for Body Perception and Action",
      "authors": [
        "Cansu Sancaktar",
        "Marcel van Gerven",
        "Pablo Lanillos"
      ],
      "year": 2019,
      "doi": "10.1109/ICDL-EpiRob48136.2020.9278105",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2001.05847v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.802230",
      "abstract": "We present a pixel-based deep active inference algorithm (PixelAI) inspired by human body perception and action. Our algorithm combines the free-energy principle from neuroscience, rooted in variational inference, with deep convolutional decoders to scale the algorithm to directly deal with raw visual input and provide online adaptive inference. Our approach is validated by studying body perception and action in a simulated and a real Nao robot. Results show that our approach allows the robot to perform 1) dynamical body estimation of its arm using only monocular camera images and 2) autonomous reaching to \"imagined\" arm poses in the visual space. This suggests that robot and human body perception and action can be efficiently solved by viewing both as an active inference problem guided by ongoing sensory input.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2001.05847.pdf"
      }
    },
    "sajid2019active": {
      "citation_key": "sajid2019active",
      "title": "Active inference: demystified and compared",
      "authors": [
        "Noor Sajid",
        "Philip J. Ball",
        "Thomas Parr",
        "Karl J. Friston"
      ],
      "year": 2019,
      "doi": "10.1162/neco_a_01357",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1909.10863v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.808775",
      "abstract": "Active inference is a first principle account of how autonomous agents operate in dynamic, non-stationary environments. This problem is also considered in reinforcement learning (RL), but limited work exists on comparing the two approaches on the same discrete-state environments. In this paper, we provide: 1) an accessible overview of the discrete-state formulation of active inference, highlighting natural behaviors in active inference that are generally engineered in RL; 2) an explicit discrete-state comparison between active inference and RL on an OpenAI gym baseline. We begin by providing a condensed overview of the active inference literature, in particular viewing the various natural behaviors of active inference agents through the lens of RL. We show that by operating in a pure belief-based setting, active inference agents can carry out epistemic exploration, and account for uncertainty about their environment in a Bayes-optimal fashion. Furthermore, we show that the reliance on an explicit reward signal in RL is removed in active inference, where reward can simply be treated as another observation; even in the total absence of rewards, agent behaviors are learned through preference learning. We make these properties explicit by showing two scenarios in which active inference agents can infer behaviors in reward-free environments compared to both Q-learning and Bayesian model-based RL agents; by placing zero prior preferences over rewards and by learning the prior preferences over the observations corresponding to reward. We conclude by noting that this formalism can be applied to more complex settings if appropriate generative models can be formulated. In short, we aim to demystify the behavior of active inference agents by presenting an accessible discrete state-space and time formulation, and demonstrate these behaviors in a OpenAI gym environment, alongside RL agents.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1909.10863.pdf"
      }
    },
    "pezzato2019novel": {
      "citation_key": "pezzato2019novel",
      "title": "A Novel Adaptive Controller for Robot Manipulators based on Active Inference",
      "authors": [
        "Corrado Pezzato",
        "Riccardo Ferrari",
        "Carlos Hernandez"
      ],
      "year": 2019,
      "doi": "10.1109/LRA.2020.2974451",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1909.12768v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.816151",
      "abstract": "More adaptive controllers for robot manipulators are needed, which can deal with large model uncertainties. This paper presents a novel active inference controller (AIC) as an adaptive control scheme for industrial robots. This scheme is easily scalable to high degrees-of-freedom, and it maintains high performance even in the presence of large unmodeled dynamics. The proposed method is based on active inference, a promising neuroscientific theory of the brain, which describes a biologically plausible algorithm for perception and action. In this work, we formulate active inference from a control perspective, deriving a model-free control law which is less sensitive to unmodeled dynamics. The performance and the adaptive properties of the algorithm are compared to a state-of-the-art model reference adaptive controller (MRAC) in an experimental setup with a real 7-DOF robot arm. The results showed that the AIC outperformed the MRAC in terms of adaptability, providing a more general control law. This confirmed the relevance of active inference for robot control.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1909.12768.pdf"
      }
    },
    "baltieri2019nonmodular": {
      "citation_key": "baltieri2019nonmodular",
      "title": "Nonmodular architectures of cognitive systems based on active inference",
      "authors": [
        "Manuel Baltieri",
        "Christopher L. Buckley"
      ],
      "year": 2019,
      "doi": "10.1109/IJCNN.2019.8852048",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1903.09542v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.823656",
      "abstract": "In psychology and neuroscience it is common to describe cognitive systems as input/output devices where perceptual and motor functions are implemented in a purely feedforward, open-loop fashion. On this view, perception and action are often seen as encapsulated modules with limited interaction between them. While embodied and enactive approaches to cognitive science have challenged the idealisation of the brain as an input/output device, we argue that even the more recent attempts to model systems using closed-loop architectures still heavily rely on a strong separation between motor and perceptual functions. Previously, we have suggested that the mainstream notion of modularity strongly resonates with the separation principle of control theory. In this work we present a minimal model of a sensorimotor loop implementing an architecture based on the separation principle. We link this to popular formulations of perception and action in the cognitive sciences, and show its limitations when, for instance, external forces are not modelled by an agent. These forces can be seen as variables that an agent cannot directly control, i.e., a perturbation from the environment or an interference caused by other agents. As an alternative approach inspired by embodied cognitive science, we then propose a nonmodular architecture based on the active inference framework. We demonstrate the robustness of this architecture to unknown external inputs and show that the mechanism with which this is achieved in linear models is equivalent to integral control.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1903.09542.pdf"
      }
    },
    "gao2020freeenergy": {
      "citation_key": "gao2020freeenergy",
      "title": "A Free-Energy Principle for Representation Learning",
      "authors": [
        "Yansong Gao",
        "Pratik Chaudhari"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2002.12406v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.835339",
      "abstract": "This paper employs a formal connection of machine learning with thermodynamics to characterize the quality of learnt representations for transfer learning. We discuss how information-theoretic functional such as rate, distortion and classification loss of a model lie on a convex, so-called equilibrium surface.We prescribe dynamical processes to traverse this surface under constraints, e.g., an iso-classification process that trades off rate and distortion to keep the classification loss unchanged. We demonstrate how this process can be used for transferring representations from a source dataset to a target dataset while keeping the classification loss constant. Experimental validation of the theoretical results is provided on standard image-classification datasets.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2002.12406.pdf"
      }
    },
    "hipolito2020cognition": {
      "citation_key": "hipolito2020cognition",
      "title": "Cognition coming about: self-organisation and free-energy",
      "authors": [
        "Ines Hipolito",
        "Maxwell Ramstead",
        "Axel Constant",
        "Karl Friston"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2007.15205v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.842250",
      "abstract": "Wright and Bourkes compelling article rightly points out that existing models of embryogenesis fail to explain the mechanisms and functional significance of the dynamic connections among neurons. We pursue their account of Dynamic Logic by appealing to the Markov blanket formalism that underwrites the Free Energy Principle. We submit that this allows one to model embryogenesis as self-organisation in a dynamical system that minimises free-energy. The ensuing formalism may be extended to also explain the autonomous emergence of cognition, specifically in the brain, as a dynamic self-assembling process.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2007.15205.pdf"
      }
    },
    "zeng2020dynamicembedding": {
      "citation_key": "zeng2020dynamicembedding",
      "title": "DynamicEmbedding: Extending TensorFlow for Colossal-Scale Applications",
      "authors": [
        "Yun Zeng",
        "Siqi Zuo",
        "Dongcai Shen"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2004.08366v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.848682",
      "abstract": "One of the limitations of deep learning models with sparse features today stems from the predefined nature of their input, which requires a dictionary be defined prior to the training. With this paper we propose both a theory and a working system design which remove this limitation, and show that the resulting models are able to perform better and efficiently run at a much larger scale. Specifically, we achieve this by decoupling a model's content from its form to tackle architecture evolution and memory growth separately. To efficiently handle model growth, we propose a new neuron model, called DynamicCell, drawing inspiration from from the free energy principle [15] to introduce the concept of reaction to discharge non-digestive energy, which also subsumes gradient descent based approaches as its special cases. We implement DynamicCell by introducing a new server into TensorFlow to take over most of the work involving model growth. Consequently, it enables any existing deep learning models to efficiently handle arbitrary number of distinct sparse features (e.g., search queries), and grow incessantly without redefining the model. Most notably, one of our models, which has been reliably running in production for over a year, is capable of suggesting high quality keywords for advertisers of Google Smart Campaigns and achieved significant accuracy gains based on a challenging metric -- evidence that data-driven, self-evolving systems can potentially exceed the performance of traditional rule-based approaches.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2004.08366.pdf"
      }
    },
    "watson2020active": {
      "citation_key": "watson2020active",
      "title": "Active Inference or Control as Inference? A Unifying View",
      "authors": [
        "Joe Watson",
        "Abraham Imohiosen",
        "Jan Peters"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2010.00262v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.856252",
      "abstract": "Active inference (AI) is a persuasive theoretical framework from computational neuroscience that seeks to describe action and perception as inference-based computation. However, this framework has yet to provide practical sensorimotor control algorithms that are competitive with alternative approaches. In this work, we frame active inference through the lens of control as inference (CaI), a body of work that presents trajectory optimization as inference. From the wider view of `probabilistic numerics', CaI offers principled, numerically robust optimal control solvers that provide uncertainty quantification, and can scale to nonlinear problems with approximate inference. We show that AI may be framed as partially-observed CaI when the cost function is defined specifically in the observation states.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2010.00262.pdf"
      }
    },
    "costa2020reward": {
      "citation_key": "costa2020reward",
      "title": "Reward Maximisation through Discrete Active Inference",
      "authors": [
        "Lancelot Da Costa",
        "Noor Sajid",
        "Thomas Parr",
        "Karl Friston",
        "Ryan Smith"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2009.08111v4",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.863750",
      "abstract": "Active inference is a probabilistic framework for modelling the behaviour of biological and artificial agents, which derives from the principle of minimising free energy. In recent years, this framework has successfully been applied to a variety of situations where the goal was to maximise reward, offering comparable and sometimes superior performance to alternative approaches. In this paper, we clarify the connection between reward maximisation and active inference by demonstrating how and when active inference agents perform actions that are optimal for maximising reward. Precisely, we show the conditions under which active inference produces the optimal solution to the Bellman equation--a formulation that underlies several approaches to model-based reinforcement learning and control. On partially observed Markov decision processes, the standard active inference scheme can produce Bellman optimal actions for planning horizons of 1, but not beyond. In contrast, a recently developed recursive active inference scheme (sophisticated inference) can produce Bellman optimal actions on any finite temporal horizon. We append the analysis with a discussion of the broader relationship between active inference and reinforcement learning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2009.08111.pdf"
      }
    },
    "çatal2020deep": {
      "citation_key": "çatal2020deep",
      "title": "Deep Active Inference for Autonomous Robot Navigation",
      "authors": [
        "Ozan Çatal",
        "Samuel Wauthier",
        "Tim Verbelen",
        "Cedric De Boom",
        "Bart Dhoedt"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2003.03220v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.870663",
      "abstract": "Active inference is a theory that underpins the way biological agent's perceive and act in the real world. At its core, active inference is based on the principle that the brain is an approximate Bayesian inference engine, building an internal generative model to drive agents towards minimal surprise. Although this theory has shown interesting results with grounding in cognitive neuroscience, its application remains limited to simulations with small, predefined sensor and state spaces.   In this paper, we leverage recent advances in deep learning to build more complex generative models that can work without a predefined states space. State representations are learned end-to-end from real-world, high-dimensional sensory data such as camera frames. We also show that these generative models can be used to engage in active inference. To the best of our knowledge this is the first application of deep active inference for a real-world robot navigation task.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2003.03220.pdf"
      }
    },
    "tschantz2020reinforcement": {
      "citation_key": "tschantz2020reinforcement",
      "title": "Reinforcement Learning through Active Inference",
      "authors": [
        "Alexander Tschantz",
        "Beren Millidge",
        "Anil K. Seth",
        "Christopher L. Buckley"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2002.12636v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.878390",
      "abstract": "The central tenet of reinforcement learning (RL) is that agents seek to maximize the sum of cumulative rewards. In contrast, active inference, an emerging framework within cognitive and computational neuroscience, proposes that agents act to maximize the evidence for a biased generative model. Here, we illustrate how ideas from active inference can augment traditional RL approaches by (i) furnishing an inherent balance of exploration and exploitation, and (ii) providing a more flexible conceptualization of reward. Inspired by active inference, we develop and implement a novel objective for decision making, which we term the free energy of the expected future. We demonstrate that the resulting algorithm successfully balances exploration and exploitation, simultaneously achieving robust performance on several challenging RL benchmarks with sparse, well-shaped, and no rewards.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2002.12636.pdf"
      }
    },
    "çatal2020learning": {
      "citation_key": "çatal2020learning",
      "title": "Learning Perception and Planning with Deep Active Inference",
      "authors": [
        "Ozan Çatal",
        "Tim Verbelen",
        "Johannes Nauta",
        "Cedric De Boom",
        "Bart Dhoedt"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2001.11841v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.886125",
      "abstract": "Active inference is a process theory of the brain that states that all living organisms infer actions in order to minimize their (expected) free energy. However, current experiments are limited to predefined, often discrete, state spaces. In this paper we use recent advances in deep learning to learn the state space and approximate the necessary probability distributions to engage in active inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2001.11841.pdf"
      }
    },
    "fountas2020deep": {
      "citation_key": "fountas2020deep",
      "title": "Deep active inference agents using Monte-Carlo methods",
      "authors": [
        "Zafeirios Fountas",
        "Noor Sajid",
        "Pedro A. M. Mediano",
        "Karl Friston"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2006.04176v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.894007",
      "abstract": "Active inference is a Bayesian framework for understanding biological intelligence. The underlying theory brings together perception and action under one single imperative: minimizing free energy. However, despite its theoretical utility in explaining intelligence, computational implementations have been restricted to low-dimensional and idealized situations. In this paper, we present a neural architecture for building deep active inference agents operating in complex, continuous state-spaces using multiple forms of Monte-Carlo (MC) sampling. For this, we introduce a number of techniques, novel to active inference. These include: i) selecting free-energy-optimal policies via MC tree search, ii) approximating this optimal policy distribution via a feed-forward `habitual' network, iii) predicting future parameter belief updates using MC dropouts and, finally, iv) optimizing state transition precision (a high-end form of attention). Our approach enables agents to learn environmental dynamics efficiently, while maintaining task performance, in relation to reward-based counterparts. We illustrate this in a new toy environment, based on the dSprites data-set, and demonstrate that active inference agents automatically create disentangled representations that are apt for modeling state transitions. In a more complex Animal-AI environment, our agents (using the same neural architecture) are able to simulate future state transitions and actions (i.e., plan), to evince reward-directed navigation - despite temporary suspension of visual input. These results show that deep active inference - equipped with MC methods - provides a flexible framework to develop biologically-inspired intelligent agents, with applications in both machine learning and cognitive science.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2006.04176.pdf"
      }
    },
    "baltieri2020kalmanbucy": {
      "citation_key": "baltieri2020kalmanbucy",
      "title": "On Kalman-Bucy filters, linear quadratic control and active inference",
      "authors": [
        "Manuel Baltieri",
        "Christopher L. Buckley"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2005.06269v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.901250",
      "abstract": "Linear Quadratic Gaussian (LQG) control is a framework first introduced in control theory that provides an optimal solution to linear problems of regulation in the presence of uncertainty. This framework combines Kalman-Bucy filters for the estimation of hidden states with Linear Quadratic Regulators for the control of their dynamics. Nowadays, LQG is also a common paradigm in neuroscience, where it is used to characterise different approaches to sensorimotor control based on state estimators, forward and inverse models. According to this paradigm, perception can be seen as a process of Bayesian inference and action as a process of optimal control. Recently, active inference has been introduced as a process theory derived from a variational approximation of Bayesian inference problems that describes, among others, perception and action in terms of (variational and expected) free energy minimisation. Active inference relies on a mathematical formalism similar to LQG, but offers a rather different perspective on problems of sensorimotor control in biological systems based on a process of biased perception. In this note we compare the mathematical treatments of these two frameworks for linear systems, focusing on their respective assumptions and highlighting their commonalities and technical differences.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2005.06269.pdf"
      }
    },
    "millidge2020relationship": {
      "citation_key": "millidge2020relationship",
      "title": "On the Relationship Between Active Inference and Control as Inference",
      "authors": [
        "Beren Millidge",
        "Alexander Tschantz",
        "Anil K Seth",
        "Christopher L Buckley"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2006.12964v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.910469",
      "abstract": "Active Inference (AIF) is an emerging framework in the brain sciences which suggests that biological agents act to minimise a variational bound on model evidence. Control-as-Inference (CAI) is a framework within reinforcement learning which casts decision making as a variational inference problem. While these frameworks both consider action selection through the lens of variational inference, their relationship remains unclear. Here, we provide a formal comparison between them and demonstrate that the primary difference arises from how value is incorporated into their respective generative models. In the context of this comparison, we highlight several ways in which these frameworks can inform one another.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2006.12964.pdf"
      }
    },
    "baioumy2020active": {
      "citation_key": "baioumy2020active",
      "title": "Active Inference for Integrated State-Estimation, Control, and Learning",
      "authors": [
        "Mohamed Baioumy",
        "Paul Duckworth",
        "Bruno Lacerda",
        "Nick Hawes"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2005.05894v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.918498",
      "abstract": "This work presents an approach for control, state-estimation and learning model (hyper)parameters for robotic manipulators. It is based on the active inference framework, prominent in computational neuroscience as a theory of the brain, where behaviour arises from minimizing variational free-energy. The robotic manipulator shows adaptive and robust behaviour compared to state-of-the-art methods. Additionally, we show the exact relationship to classic methods such as PID control. Finally, we show that by learning a temporal parameter and model variances, our approach can deal with unmodelled dynamics, damps oscillations, and is robust against disturbances and poor initial parameters. The approach is validated on the `Franka Emika Panda' 7 DoF manipulator.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2005.05894.pdf"
      }
    },
    "pezzato2020active": {
      "citation_key": "pezzato2020active",
      "title": "Active Inference and Behavior Trees for Reactive Action Planning and Execution in Robotics",
      "authors": [
        "Corrado Pezzato",
        "Carlos Hernandez Corbato",
        "Stefan Bonhof",
        "Martijn Wisse"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2011.09756v4",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.926521",
      "abstract": "We propose a hybrid combination of active inference and behavior trees (BTs) for reactive action planning and execution in dynamic environments, showing how robotic tasks can be formulated as a free-energy minimization problem. The proposed approach allows handling partially observable initial states and improves the robustness of classical BTs against unexpected contingencies while at the same time reducing the number of nodes in a tree. In this work, we specify the nominal behavior offline, through BTs. However, in contrast to previous approaches, we introduce a new type of leaf node to specify the desired state to be achieved rather than an action to execute. The decision of which action to execute to reach the desired state is performed online through active inference. This results in continual online planning and hierarchical deliberation. By doing so, an agent can follow a predefined offline plan while still keeping the ability to locally adapt and take autonomous decisions at runtime, respecting safety constraints. We provide proof of convergence and robustness analysis, and we validate our method in two different mobile manipulators performing similar tasks, both in a simulated and real retail environment. The results showed improved runtime adaptability with a fraction of the hand-coded nodes compared to classical BTs.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2011.09756.pdf"
      }
    },
    "lanillos2020robot": {
      "citation_key": "lanillos2020robot",
      "title": "Robot self/other distinction: active inference meets neural networks learning in a mirror",
      "authors": [
        "Pablo Lanillos",
        "Jordi Pages",
        "Gordon Cheng"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2004.05473v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.934447",
      "abstract": "Self/other distinction and self-recognition are important skills for interacting with the world, as it allows humans to differentiate own actions from others and be self-aware. However, only a selected group of animals, mainly high order mammals such as humans, has passed the mirror test, a behavioural experiment proposed to assess self-recognition abilities. In this paper, we describe self-recognition as a process that is built on top of body perception unconscious mechanisms. We present an algorithm that enables a robot to perform non-appearance self-recognition on a mirror and distinguish its simple actions from other entities, by answering the following question: am I generating these sensations? The algorithm combines active inference, a theoretical model of perception and action in the brain, with neural network learning. The robot learns the relation between its actions and its body with the effect produced in the visual field and its body sensors. The prediction error generated between the models and the real observations during the interaction is used to infer the body configuration through free energy minimization and to accumulate evidence for recognizing its body. Experimental results on a humanoid robot show the reliability of the algorithm for different initial conditions, such as mirror recognition in any perspective, robot-robot distinction and human-robot differentiation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2004.05473.pdf"
      }
    },
    "ovalle2020modulation": {
      "citation_key": "ovalle2020modulation",
      "title": "Modulation of viability signals for self-regulatory control",
      "authors": [
        "Alvaro Ovalle",
        "Simon M. Lucas"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2007.09297v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.943779",
      "abstract": "We revisit the role of instrumental value as a driver of adaptive behavior. In active inference, instrumental or extrinsic value is quantified by the information-theoretic surprisal of a set of observations measuring the extent to which those observations conform to prior beliefs or preferences. That is, an agent is expected to seek the type of evidence that is consistent with its own model of the world. For reinforcement learning tasks, the distribution of preferences replaces the notion of reward. We explore a scenario in which the agent learns this distribution in a self-supervised manner. In particular, we highlight the distinction between observations induced by the environment and those pertaining more directly to the continuity of an agent in time. We evaluate our methodology in a dynamic environment with discrete time and actions. First with a surprisal minimizing model-free agent (in the RL sense) and then expanding to the model-based case to minimize the expected free energy.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2007.09297.pdf"
      }
    },
    "friston2020sophisticated": {
      "citation_key": "friston2020sophisticated",
      "title": "Sophisticated Inference",
      "authors": [
        "Karl Friston",
        "Lancelot Da Costa",
        "Danijar Hafner",
        "Casper Hesp",
        "Thomas Parr"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2006.04120v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.951826",
      "abstract": "Active inference offers a first principle account of sentient behaviour, from which special and important cases can be derived, e.g., reinforcement learning, active learning, Bayes optimal inference, Bayes optimal design, etc. Active inference resolves the exploitation-exploration dilemma in relation to prior preferences, by placing information gain on the same footing as reward or value. In brief, active inference replaces value functions with functionals of (Bayesian) beliefs, in the form of an expected (variational) free energy. In this paper, we consider a sophisticated kind of active inference, using a recursive form of expected free energy. Sophistication describes the degree to which an agent has beliefs about beliefs. We consider agents with beliefs about the counterfactual consequences of action for states of affairs and beliefs about those latent states. In other words, we move from simply considering beliefs about 'what would happen if I did that' to 'what would I believe about what would happen if I did that'. The recursive form of the free energy functional effectively implements a deep tree search over actions and outcomes in the future. Crucially, this search is over sequences of belief states, as opposed to states per se. We illustrate the competence of this scheme, using numerical simulations of deep decision problems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2006.04120.pdf"
      }
    },
    "millidge2020whence": {
      "citation_key": "millidge2020whence",
      "title": "Whence the Expected Free Energy?",
      "authors": [
        "Beren Millidge",
        "Alexander Tschantz",
        "Christopher L Buckley"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2004.08128v5",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.958987",
      "abstract": "The Expected Free Energy (EFE) is a central quantity in the theory of active inference. It is the quantity that all active inference agents are mandated to minimize through action, and its decomposition into extrinsic and intrinsic value terms is key to the balance of exploration and exploitation that active inference agents evince. Despite its importance, the mathematical origins of this quantity and its relation to the Variational Free Energy (VFE) remain unclear. In this paper, we investigate the origins of the EFE in detail and show that it is not simply \"the free energy in the future\". We present a functional that we argue is the natural extension of the VFE, but which actively discourages exploratory behaviour, thus demonstrating that exploration does not directly follow from free energy minimization into the future. We then develop a novel objective, the Free-Energy of the Expected Future (FEEF), which possesses both the epistemic component of the EFE as well as an intuitive mathematical grounding as the divergence between predicted and desired futures.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2004.08128.pdf"
      }
    },
    "daucé2020endeffect": {
      "citation_key": "daucé2020endeffect",
      "title": "End-Effect Exploration Drive for Effective Motor Learning",
      "authors": [
        "Emmanuel Daucé"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2006.15960v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.966333",
      "abstract": "Stemming on the idea that a key objective in reinforcement learning is to invert a target distribution of effects, end-effect drives are proposed as an effective way to implement goal-directed motor learning, in the absence of an explicit forward model. An end-effect model relies on a simple statistical recording of the effect of the current policy, here used as a substitute for the more resource-demanding forward models. When combined with a reward structure, it forms the core of a lightweight variational free energy minimization setup. The main difficulty lies in the maintenance of this simplified effect model together with the online update of the policy. When the prior target distribution is uniform, it provides a ways to learn an efficient exploration policy, consistently with the intrinsic curiosity principles. When combined with an extrinsic reward, our approach is finally shown to provide a faster training than traditional off-policy techniques.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2006.15960.pdf"
      }
    },
    "stetter2020learning": {
      "citation_key": "stetter2020learning",
      "title": "Learning intuitive physics and one-shot imitation using state-action-prediction self-organizing maps",
      "authors": [
        "Martin Stetter",
        "Elmar W. Lang"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2007.01647v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.973689",
      "abstract": "Human learning and intelligence work differently from the supervised pattern recognition approach adopted in most deep learning architectures. Humans seem to learn rich representations by exploration and imitation, build causal models of the world, and use both to flexibly solve new tasks. We suggest a simple but effective unsupervised model which develops such characteristics. The agent learns to represent the dynamical physical properties of its environment by intrinsically motivated exploration, and performs inference on this representation to reach goals. For this, a set of self-organizing maps which represent state-action pairs is combined with a causal model for sequence prediction. The proposed system is evaluated in the cartpole environment. After an initial phase of playful exploration, the agent can execute kinematic simulations of the environment's future, and use those for action planning. We demonstrate its performance on a set of several related, but different one-shot imitation tasks, which the agent flexibly solves in an active inference style.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2007.01647.pdf"
      }
    },
    "zakharov2020episodic": {
      "citation_key": "zakharov2020episodic",
      "title": "Episodic Memory for Learning Subjective-Timescale Models",
      "authors": [
        "Alexey Zakharov",
        "Matthew Crosby",
        "Zafeirios Fountas"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2010.01430v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.981297",
      "abstract": "In model-based learning, an agent's model is commonly defined over transitions between consecutive states of an environment even though planning often requires reasoning over multi-step timescales, with intermediate states either unnecessary, or worse, accumulating prediction error. In contrast, intelligent behaviour in biological organisms is characterised by the ability to plan over varying temporal scales depending on the context. Inspired by the recent works on human time perception, we devise a novel approach to learning a transition dynamics model, based on the sequences of episodic memories that define the agent's subjective timescale - over which it learns world dynamics and over which future planning is performed. We implement this in the framework of active inference and demonstrate that the resulting subjective-timescale model (STM) can systematically vary the temporal extent of its predictions while preserving the same computational efficiency. Additionally, we show that STM predictions are more likely to introduce future salient events (for example new objects coming into view), incentivising exploration of new areas of the environment. As a result, STM produces more informative action-conditioned roll-outs that assist the agent in making better decisions. We validate significant improvement in our STM agent's performance in the Animal-AI environment against a baseline system, trained using the environment's objective-timescale dynamics.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2010.01430.pdf"
      }
    },
    "seraj2020coordinated": {
      "citation_key": "seraj2020coordinated",
      "title": "Coordinated Control of UAVs for Human-Centered Active Sensing of Wildfires",
      "authors": [
        "Esmaeil Seraj",
        "Matthew Gombolay"
      ],
      "year": 2020,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/2006.07969v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.988979",
      "abstract": "Fighting wildfires is a precarious task, imperiling the lives of engaging firefighters and those who reside in the fire's path. Firefighters need online and dynamic observation of the firefront to anticipate a wildfire's unknown characteristics, such as size, scale, and propagation velocity, and to plan accordingly. In this paper, we propose a distributed control framework to coordinate a team of unmanned aerial vehicles (UAVs) for a human-centered active sensing of wildfires. We develop a dual-criterion objective function based on Kalman uncertainty residual propagation and weighted multi-agent consensus protocol, which enables the UAVs to actively infer the wildfire dynamics and parameters, track and monitor the fire transition, and safely manage human firefighters on the ground using acquired information. We evaluate our approach relative to prior work, showing significant improvements by reducing the environment's cumulative uncertainty residual by more than $ 10^2 $ and $ 10^5 $ times in firefront coverage performance to support human-robot teaming for firefighting. We also demonstrate our method on physical robots in a mock firefighting exercise.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/2006.07969.pdf"
      }
    },
    "ensslin2010inference": {
      "citation_key": "ensslin2010inference",
      "title": "Inference with minimal Gibbs free energy in information field theory",
      "authors": [
        "Torsten A. Ensslin",
        "Cornelius Weig"
      ],
      "year": 2010,
      "doi": "10.1103/PhysRevE.82.051112",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1004.2868v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:32.996462",
      "abstract": "Non-linear and non-Gaussian signal inference problems are difficult to tackle. Renormalization techniques permit us to construct good estimators for the posterior signal mean within information field theory (IFT), but the approximations and assumptions made are not very obvious. Here we introduce the simple concept of minimal Gibbs free energy to IFT, and show that previous renormalization results emerge naturally. They can be understood as being the Gaussian approximation to the full posterior probability, which has maximal cross information with it. We derive optimized estimators for three applications, to illustrate the usage of the framework: (i) reconstruction of a log-normal signal from Poissonian data with background counts and point spread function, as it is needed for gamma ray astronomy and for cosmography using photometric galaxy redshifts, (ii) inference of a Gaussian signal with unknown spectrum and (iii) inference of a Poissonian log-normal signal with unknown spectrum, the combination of (i) and (ii). Finally we explain how Gaussian knowledge states constructed by the minimal Gibbs free energy principle at different temperatures can be combined into a more accurate surrogate of the non-Gaussian posterior.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1004.2868.pdf"
      }
    },
    "sbragaglia2009continuum": {
      "citation_key": "sbragaglia2009continuum",
      "title": "Continuum Free-Energy formulation for a class of Lattice Boltzmann multiphase models",
      "authors": [
        "M. Sbragaglia",
        "H. Chen",
        "X. Shan",
        "S. Succi"
      ],
      "year": 2009,
      "doi": "10.1209/0295-5075/86/24005",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/0901.4799v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.004942",
      "abstract": "It is shown that the Shan-Chen (SC) model for non-ideal lattice fluids can be made compliant with a pseudo free-energy principle by simple addition of a gradient force, whose expression is uniquely specified in terms of the fluid density. This additional term is numerically shown to provide fairly negligible effects on the system evolution during phase-separation. To the best of our knowledge, these important properties of the SC model were not noted before. The approach developed in the present work is based on a continuum analysis: further extensions, more in line with a discrete lattice theory (X. Shan, {\\it Phys Rev E}, {\\bf 77} 066702 (2008)) can be envisaged for the future.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/0901.4799.pdf"
      }
    },
    "allahverdyan2014active": {
      "citation_key": "allahverdyan2014active",
      "title": "Active Inference for Binary Symmetric Hidden Markov Models",
      "authors": [
        "Armen E. Allahverdyan",
        "Aram Galstyan"
      ],
      "year": 2014,
      "doi": "10.1007/s10955-015-1321-y",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1411.0630v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.012546",
      "abstract": "We consider active maximum a posteriori (MAP) inference problem for Hidden Markov Models (HMM), where, given an initial MAP estimate of the hidden sequence, we select to label certain states in the sequence to improve the estimation accuracy of the remaining states. We develop an analytical approach to this problem for the case of binary symmetric HMMs, and obtain a closed form solution that relates the expected error reduction to model parameters under the specified active inference scheme. We then use this solution to determine most optimal active inference scheme in terms of error reduction, and examine the relation of those schemes to heuristic principles of uncertainty reduction and solution unicity.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1411.0630.pdf"
      }
    },
    "hansen2012lasso": {
      "citation_key": "hansen2012lasso",
      "title": "Lasso and probabilistic inequalities for multivariate point processes",
      "authors": [
        "Niels Richard Hansen",
        "Patricia Reynaud-Bouret",
        "Vincent Rivoirard"
      ],
      "year": 2012,
      "doi": "10.3150/13-BEJ562",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1208.0570v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.021137",
      "abstract": "Due to its low computational cost, Lasso is an attractive regularization method for high-dimensional statistical settings. In this paper, we consider multivariate counting processes depending on an unknown function parameter to be estimated by linear combinations of a fixed dictionary. To select coefficients, we propose an adaptive $\\ell_1$-penalization methodology, where data-driven weights of the penalty are derived from new Bernstein type inequalities for martingales. Oracle inequalities are established under assumptions on the Gram matrix of the dictionary. Nonasymptotic probabilistic results for multivariate Hawkes processes are proven, which allows us to check these assumptions by considering general dictionaries based on histograms, Fourier or wavelet bases. Motivated by problems of neuronal activity inference, we finally carry out a simulation study for multivariate Hawkes processes and compare our methodology with the adaptive Lasso procedure proposed by Zou in (J. Amer. Statist. Assoc. 101 (2006) 1418-1429). We observe an excellent behavior of our procedure. We rely on theoretical aspects for the essential question of tuning our methodology. Unlike adaptive Lasso of (J. Amer. Statist. Assoc. 101 (2006) 1418-1429), our tuning procedure is proven to be robust with respect to all the parameters of the problem, revealing its potential for concrete purposes, in particular in neuroscience.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1208.0570.pdf"
      }
    },
    "martins2014touch": {
      "citation_key": "martins2014touch",
      "title": "Touch attention Bayesian models for robotic active haptic exploration of heterogeneous surfaces",
      "authors": [
        "Ricardo Martins",
        "João Filipe Ferreira",
        "Jorge Dias"
      ],
      "year": 2014,
      "doi": "10.1109/IROS.2014.6942711",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1409.6226v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.028723",
      "abstract": "This work contributes to the development of active haptic exploration strategies of surfaces using robotic hands in environments with an unknown structure. The architecture of the proposed approach consists two main Bayesian models, implementing the touch attention mechanisms of the system. The model pi_per perceives and discriminates different categories of materials (haptic stimulus) integrating compliance and texture features extracted from haptic sensory data. The model pi_tar actively infers the next region of the workspace that should be explored by the robotic system, integrating the task information, the permanently updated saliency and uncertainty maps extracted from the perceived haptic stimulus map, as well as, inhibition-of-return mechanisms.   The experimental results demonstrate that the Bayesian model pi_per can be used to discriminate 10 different classes of materials with an average recognition rate higher than 90% . The generalization capability of the proposed models was demonstrated experimentally. The ATLAS robot, in the simulation, was able to perform the following of a discontinuity between two regions made of different materials with a divergence smaller than 1cm (30 trials). The tests were performed in scenarios with 3 different configurations of the discontinuity. The Bayesian models have demonstrated the capability to manage the uncertainty about the structure of the surfaces and sensory noise to make correct motor decisions from haptic percepts.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1409.6226.pdf"
      }
    },
    "karak2014hysteresis": {
      "citation_key": "karak2014hysteresis",
      "title": "Hysteresis between distinct modes of turbulent dynamos",
      "authors": [
        "Bidya Binay Karak",
        "Leonid L. Kitchatinov",
        "Axel Brandenburg"
      ],
      "year": 2014,
      "doi": "10.1088/0004-637X/803/2/95",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1411.0485v4",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.036816",
      "abstract": "Nonlinear mean-field models of the solar dynamo show long-term variability, which may be relevant to different states of activity inferred from long-term radiocarbon data. This paper is aimed to probe the dynamo hysteresis predicted by the recent mean-field models of Kitchatinov \\& Olemskoy (2010) with direct numerical simulations. We perform three-dimensional simulations of large-scale dynamos in a shearing box with helically forced turbulence. As initial condition, we either take a weak random magnetic field or we start from a snapshot of an earlier simulation. Two quasi-stable states are found to coexist in a certain range of parameters close to the onset of the large-scale dynamo. The simulations converge to one of these states depending on the initial conditions. When either the fractional helicity or the magnetic Prandtl number is increased between successive runs above the critical value for onset of the dynamo, the field strength jumps to a finite value. However, when the fractional helicity or the magnetic Prandtl number is then decreased again, the field strength stays at a similar value (strong field branch) even below the original onset. We also observe intermittent decaying phases away from the strong field branch close to the point where large-scale dynamo action is just possible. The dynamo hysteresis seen previously in mean-field models is thus reproduced by 3D simulations. Its possible relation to distinct modes of solar activity such as grand minima is discussed.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1411.0485.pdf"
      }
    },
    "miller2006abell": {
      "citation_key": "miller2006abell",
      "title": "Abell 2111: An Optical and Radio Study of the Richest Butcher-Oemler Cluster",
      "authors": [
        "Neal A. Miller",
        "William Oegerle",
        "John Hill"
      ],
      "year": 2006,
      "doi": "10.1086/503254",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/astro-ph/0602080v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.044461",
      "abstract": "We present an in-depth analysis of the Butcher-Oemler cluster A2111, including new optical spectroscopy plus a deep Very Large Array (VLA) radio continuum observation. These are combined with optical imaging from the Sloan Digital Sky Survey (SDSS) to assess the activity and properties of member galaxies. Prior X-ray studies have suggested A2111 is a head-on cluster merger, a dynamical state which might be connected to the high level of activity inferred from its blue fraction. We are able to directly assess this claim, using our spectroscopic data to identify 95 cluster members among 196 total galaxy spectra. These galaxy velocities do not themselves provide significant evidence for the merger interpretation, however they are consistent with it provided the system is viewed near the time of core passage and at a viewing angle >~30 degrees different from the merger axis. The SDSS data allow us to confirm the high blue fraction for A2111, f_b = 0.15 +/- 0.03 based on photometry alone and f_b = 0.23 +/- 0.03 using spectroscopic data to remove background galaxies. We are able to detect 175 optical sources from the SDSS in our VLA radio data, of which 35 have redshift information. We use the SDSS photometry to determine photometric redshifts for the remaining 140 radio-optical sources. In total we identify up to 26 cluster radio galaxies, 14 of which have spectroscopic redshifts. The optical spectroscopy and radio data reveal a substantial population of dusty starbursts within the cluster. The high blue fraction and prevalence of star formation is consistent with the hypothesis that dynamically-active clusters are associated with more active member galaxies than relaxed clusters.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/astro-ph/0602080.pdf"
      }
    },
    "baltieri2018modularity": {
      "citation_key": "baltieri2018modularity",
      "title": "The modularity of action and perception revisited using control theory and active inference",
      "authors": [
        "Manuel Baltieri",
        "Christopher L. Buckley"
      ],
      "year": 2018,
      "doi": "10.1162/isal_a_00031",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1806.02649v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.052202",
      "abstract": "The assumption that action and perception can be investigated independently is entrenched in theories, models and experimental approaches across the brain and mind sciences. In cognitive science, this has been a central point of contention between computationalist and 4Es (enactive, embodied, extended and embedded) theories of cognition, with the former embracing the \"classical sandwich\", modular, architecture of the mind and the latter actively denying this separation can be made. In this work we suggest that the modular independence of action and perception strongly resonates with the separation principle of control theory and furthermore that this principle provides formal criteria within which to evaluate the implications of the modularity of action and perception. We will also see that real-time feedback with the environment, often considered necessary for the definition of 4Es ideas, is not however a sufficient condition to avoid the \"classical sandwich\". Finally, we argue that an emerging framework in the cognitive and brain sciences, active inference, extends ideas derived from control theory to the study of biological systems while disposing of the separation principle, describing non-modular models of behaviour strongly aligned with 4Es theories of cognition.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1806.02649.pdf"
      }
    },
    "xie2018active": {
      "citation_key": "xie2018active",
      "title": "Active image restoration",
      "authors": [
        "Rongrong Xie",
        "Shengfeng Deng",
        "Weibing Deng",
        "Armen E. Allahverdyan"
      ],
      "year": 2018,
      "doi": "10.1103/PhysRevE.98.052108",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1809.08406v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.059209",
      "abstract": "We study active restoration of noise-corrupted images generated via the Gibbs probability of an Ising ferromagnet in external magnetic field. Ferromagnetism accounts for the prior expectation of data smoothness, i.e. a positive correlation between neighbouring pixels (Ising spins), while the magnetic field refers to the bias. The restoration is actively supervised by requesting the true values of certain pixels after a noisy observation. This additional information improves restoration of other pixels. The optimal strategy of active inference is not known for realistic (two-dimensional) images. We determine this strategy for the mean-field version of the model and show that it amounts to supervising the values of spins (pixels) that do not agree with the sign of the average magnetization. The strategy leads to a transparent analytical expression for the minimal Bayesian risk, and shows that there is a maximal number of pixels beyond of which the supervision is useless. We show numerically that this strategy applies for two-dimensional images away from the critical regime. Within this regime the strategy is outperformed by its local (adaptive) version, which supervises pixels that do not agree with their Bayesian estimate. We show on transparent examples how active supervising can be essential in recovering noise-corrupted images and advocate for a wider usage of active methods in image restoration.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1809.08406.pdf"
      }
    },
    "nasr2018comprehensive": {
      "citation_key": "nasr2018comprehensive",
      "title": "Comprehensive Privacy Analysis of Deep Learning: Passive and Active White-box Inference Attacks against Centralized and Federated Learning",
      "authors": [
        "Milad Nasr",
        "Reza Shokri",
        "Amir Houmansadr"
      ],
      "year": 2018,
      "doi": "10.1109/SP.2019.00065",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1812.00910v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.066255",
      "abstract": "Deep neural networks are susceptible to various inference attacks as they remember information about their training data. We design white-box inference attacks to perform a comprehensive privacy analysis of deep learning models. We measure the privacy leakage through parameters of fully trained models as well as the parameter updates of models during training. We design inference algorithms for both centralized and federated learning, with respect to passive and active inference attackers, and assuming different adversary prior knowledge.   We evaluate our novel white-box membership inference attacks against deep learning algorithms to trace their training data records. We show that a straightforward extension of the known black-box attacks to the white-box setting (through analyzing the outputs of activation functions) is ineffective. We therefore design new algorithms tailored to the white-box setting by exploiting the privacy vulnerabilities of the stochastic gradient descent algorithm, which is the algorithm used to train deep neural networks. We investigate the reasons why deep learning models may leak information about their training data. We then show that even well-generalized models are significantly susceptible to white-box membership inference attacks, by analyzing state-of-the-art pre-trained and publicly available models for the CIFAR dataset. We also show how adversarial participants, in the federated learning setting, can successfully run active membership inference attacks against other participants, even when the global model achieves high prediction accuracies.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1812.00910.pdf"
      }
    },
    "friston2019free": {
      "citation_key": "friston2019free",
      "title": "A free energy principle for a particular physics",
      "authors": [
        "Karl Friston"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1906.10184v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.073583",
      "abstract": "This monograph attempts a theory of every 'thing' that can be distinguished from other things in a statistical sense. The ensuing statistical independencies, mediated by Markov blankets, speak to a recursive composition of ensembles (of things) at increasingly higher spatiotemporal scales. This decomposition provides a description of small things; e.g., quantum mechanics - via the Schrodinger equation, ensembles of small things - via statistical mechanics and related fluctuation theorems, through to big things - via classical mechanics. These descriptions are complemented with a Bayesian mechanics for autonomous or active things. Although this work provides a formulation of every thing, its main contribution is to examine the implications of Markov blankets for self-organisation to nonequilibrium steady-state. In brief, we recover an information geometry and accompanying free energy principle that allows one to interpret the internal states of something as representing or making inferences about its external states. The ensuing Bayesian mechanics is compatible with quantum, statistical and classical mechanics and may offer a formal description of lifelike particles.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1906.10184.pdf"
      }
    },
    "çatal2019bayesian": {
      "citation_key": "çatal2019bayesian",
      "title": "Bayesian policy selection using active inference",
      "authors": [
        "Ozan Çatal",
        "Johannes Nauta",
        "Tim Verbelen",
        "Pieter Simoens",
        "Bart Dhoedt"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1904.08149v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.081080",
      "abstract": "Learning to take actions based on observations is a core requirement for artificial agents to be able to be successful and robust at their task. Reinforcement Learning (RL) is a well-known technique for learning such policies. However, current RL algorithms often have to deal with reward shaping, have difficulties generalizing to other environments and are most often sample inefficient. In this paper, we explore active inference and the free energy principle, a normative theory from neuroscience that explains how self-organizing biological systems operate by maintaining a model of the world and casting action selection as an inference problem. We apply this concept to a typical problem known to the RL community, the mountain car problem, and show how active inference encompasses both RL and learning from demonstrations.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1904.08149.pdf"
      }
    },
    "shimazaki2019principles": {
      "citation_key": "shimazaki2019principles",
      "title": "The principles of adaptation in organisms and machines I: machine learning, information theory, and thermodynamics",
      "authors": [
        "Hideaki Shimazaki"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1902.11233v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.088666",
      "abstract": "How do organisms recognize their environment by acquiring knowledge about the world, and what actions do they take based on this knowledge? This article examines hypotheses about organisms' adaptation to the environment from machine learning, information-theoretic, and thermodynamic perspectives. We start with constructing a hierarchical model of the world as an internal model in the brain, and review standard machine learning methods to infer causes by approximately learning the model under the maximum likelihood principle. This in turn provides an overview of the free energy principle for an organism, a hypothesis to explain perception and action from the principle of least surprise. Treating this statistical learning as communication between the world and brain, learning is interpreted as a process to maximize information about the world. We investigate how the classical theories of perception such as the infomax principle relates to learning the hierarchical model. We then present an approach to the recognition and learning based on thermodynamics, showing that adaptation by causal learning results in the second law of thermodynamics whereas inference dynamics that fuses observation with prior knowledge forms a thermodynamic process. These provide a unified view on the adaptation of organisms to the environment.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1902.11233.pdf"
      }
    },
    "safron2019bayesian": {
      "citation_key": "safron2019bayesian",
      "title": "Bayesian Analogical Cybernetics",
      "authors": [
        "Adam Safron"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1911.02362v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.095872",
      "abstract": "It has been argued that all of cognition can be understood in terms of Bayesian inference. It has also been argued that analogy is the core of cognition. Here I will propose that these perspectives are fully compatible, in that analogical reasoning can be described in terms of Bayesian inference and vice versa, and that both of these positions require a thorough cybernetic grounding in order to fulfill their promise as unifying frameworks for understanding minds. From the Bayesian perspective of the Free Energy Principle and Active Inference framework, thought is constituted by dynamics of cascading belief propagation through the nodes of probabilistic generative models specified by a cortical heterarchy \"rooted\" in action-perception cycles that ground the mind as an embodied control system for an autonomous agent. From the analogical structure mapping perspective, thought is constituted by the alignment and comparison of heterogeneous structural representations. Here I will propose that this core cognitive process for analogical reasoning is naturally implemented by predictive coding mechanisms. However, both Bayesian cognitive science and models of cognitive development via analogical reasoning require rich base domains and priors (or reliably learnable posteriors) from which they can commence the process of bootstrapping minds. Here in the spirit of the work of George Lakoff and Mark Johnson, I propose that embodiment provides many of the inductive biases that are usually described in terms of innate core knowledge. (Please note: this manuscript was written and finalized in 2012.)",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1911.02362.pdf"
      }
    },
    "baudot2019poincaréboltzmann": {
      "citation_key": "baudot2019poincaréboltzmann",
      "title": "The Poincaré-Boltzmann Machine: from Statistical Physics to Machine Learning and back",
      "authors": [
        "Pierre Baudot"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1907.06486v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.103365",
      "abstract": "This paper presents the computational methods of information cohomology applied to genetic expression in and in the companion paper and proposes its interpretations in terms of statistical physics and machine learning. In order to further underline the Hochschild cohomological nature af information functions and chain rules, following, the computation of the cohomology in low degrees is detailed to show more directly that the $k$ multivariate mutual-informations (I_k) are k-coboundaries. The k-cocycles condition corresponds to I_k=0, generalizing statistical independence. Hence the cohomology quantifies the statistical dependences and the obstruction to factorization. The topological approach allows to investigate information in the multivariate case without the assumptions of independent identically distributed variables and without mean field approximations. We develop the computationally tractable subcase of simplicial information cohomology represented by entropy H_k and information I_k landscapes and their respective paths. The I_1 component defines a self-internal energy U_k, and I_k,k>1 components define the contribution to a free energy G_k (the total correlation) of the k-body interactions. The set of information paths in simplicial structures is in bijection with the symmetric group and random processes, provides a trivial topological expression of the 2nd law of thermodynamic. The local minima of free-energy, related to conditional information negativity, and conditional independence, characterize a minimum free energy complex. This complex formalizes the minimum free-energy principle in topology, provides a definition of a complex system, and characterizes a multiplicity of local minima that quantifies the diversity observed in biology. I give an interpretation of this complex in terms of frustration in glass and of Van Der Walls k-body interactions for data points.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1907.06486.pdf"
      }
    },
    "tschantz2019scaling": {
      "citation_key": "tschantz2019scaling",
      "title": "Scaling active inference",
      "authors": [
        "Alexander Tschantz",
        "Manuel Baltieri",
        "Anil. K. Seth",
        "Christopher L. Buckley"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1911.10601v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.115495",
      "abstract": "In reinforcement learning (RL), agents often operate in partially observed and uncertain environments. Model-based RL suggests that this is best achieved by learning and exploiting a probabilistic model of the world. 'Active inference' is an emerging normative framework in cognitive and computational neuroscience that offers a unifying account of how biological agents achieve this. On this framework, inference, learning and action emerge from a single imperative to maximize the Bayesian evidence for a niched model of the world. However, implementations of this process have thus far been restricted to low-dimensional and idealized situations. Here, we present a working implementation of active inference that applies to high-dimensional tasks, with proof-of-principle results demonstrating efficient exploration and an order of magnitude increase in sample efficiency over strong model-free baselines. Our results demonstrate the feasibility of applying active inference at scale and highlight the operational homologies between active inference and current model-based approaches to RL.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1911.10601.pdf"
      }
    },
    "millidge2019deep": {
      "citation_key": "millidge2019deep",
      "title": "Deep Active Inference as Variational Policy Gradients",
      "authors": [
        "Beren Millidge"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1907.03876v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.123649",
      "abstract": "Active Inference is a theory of action arising from neuroscience which casts action and planning as a bayesian inference problem to be solved by minimizing a single quantity - the variational free energy. Active Inference promises a unifying account of action and perception coupled with a biologically plausible process theory. Despite these potential advantages, current implementations of Active Inference can only handle small, discrete policy and state-spaces and typically require the environmental dynamics to be known. In this paper we propose a novel deep Active Inference algorithm which approximates key densities using deep neural networks as flexible function approximators, which enables Active Inference to scale to significantly larger and more complex tasks. We demonstrate our approach on a suite of OpenAIGym benchmark tasks and obtain performance comparable with common reinforcement learning baselines. Moreover, our algorithm shows similarities with maximum entropy reinforcement learning and the policy gradients algorithm, which reveals interesting connections between the Active Inference framework and reinforcement learning.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1907.03876.pdf"
      }
    },
    "vasil2019world": {
      "citation_key": "vasil2019world",
      "title": "A World unto Itself: Human Communication as Active Inference",
      "authors": [
        "Jared Vasil",
        "Paul B. Badcock",
        "Axel Constant",
        "Karl Friston",
        "Maxwell J. D. Ramstead"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1906.10538v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.131364",
      "abstract": "Work in developmental psychology suggests that humans are predisposed to align their mental states with other individuals. This manifests principally in cooperative communication, that is, intentional communication geared towards aligning mental states. This viewpoint has received ample empirical support. However, this view lacks a formal grounding, and provides no precise neuroscientific hypotheses. To remedy this, we suggest an active inference approach to cooperative communication. We suggest that humans appear to possess an evolved adaptive prior belief that their mental states are aligned with those of conspecifics. Cooperative communication emerges as the principal means to gather evidence for this belief. Our approach has implications for the study of the usage, ontogeny, and cultural evolution of human communication.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1906.10538.pdf"
      }
    },
    "chame2019cognitive": {
      "citation_key": "chame2019cognitive",
      "title": "Cognitive and motor compliance in intentional human-robot interaction",
      "authors": [
        "Hendry Ferreira Chame",
        "Jun Tani"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1911.01753v4",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.138953",
      "abstract": "Embodiment and subjective experience in human-robot interaction are important aspects to consider when studying both natural cognition and adaptive robotics to human environments. Although several researches have focused on nonverbal communication and collaboration, the study of autonomous physical interaction has obtained less attention. From the perspective of neurorobotics, we investigate the relation between intentionality, motor compliance, cognitive compliance, and behavior emergence. We propose a variational model inspired by the principles of predictive coding and active inference to study intentionality and cognitive compliance, and an intermittent control concept for motor deliberation and compliance based on torque feed-back. Our experiments with the humanoid Torobo portrait interesting perspectives for the bio-inspired study of developmental and social processes.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1911.01753.pdf"
      }
    },
    "mohammadi2019text": {
      "citation_key": "mohammadi2019text",
      "title": "Text as Environment: A Deep Reinforcement Learning Text Readability Assessment Model",
      "authors": [
        "Hamid Mohammadi",
        "Seyed Hossein Khasteh",
        "Tahereh Firoozi",
        "Taha Samavati"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1912.05957v4",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.147292",
      "abstract": "Evaluating the readability of a text can significantly facilitate the precise expression of information in written form. The formulation of text readability assessment involves the identification of meaningful properties of the text regardless of its length. Sophisticated features and models are used to evaluate the comprehensibility of texts accurately. Despite this, the problem of assessing texts' readability efficiently remains relatively untouched. The efficiency of state-of-the-art text readability assessment models can be further improved using deep reinforcement learning models. Using a hard attention-based active inference technique, the proposed approach makes efficient use of input text and computational resources. Through the use of semi-supervised signals, the reinforcement learning model uses the minimum amount of text in order to determine text's readability. A comparison of the model on Weebit and Cambridge Exams with state-of-the-art models, such as the BERT text readability model, shows that it is capable of achieving state-of-the-art accuracy with a significantly smaller amount of input text than other models.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1912.05957.pdf"
      }
    },
    "roos2019active": {
      "citation_key": "roos2019active",
      "title": "Active Probabilistic Inference on Matrices for Pre-Conditioning in Stochastic Optimization",
      "authors": [
        "Filip de Roos",
        "Philipp Hennig"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1902.07557v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.155913",
      "abstract": "Pre-conditioning is a well-known concept that can significantly improve the convergence of optimization algorithms. For noise-free problems, where good pre-conditioners are not known a priori, iterative linear algebra methods offer one way to efficiently construct them. For the stochastic optimization problems that dominate contemporary machine learning, however, this approach is not readily available. We propose an iterative algorithm inspired by classic iterative linear solvers that uses a probabilistic model to actively infer a pre-conditioner in situations where Hessian-projections can only be constructed with strong Gaussian noise. The algorithm is empirically demonstrated to efficiently construct effective pre-conditioners for stochastic gradient descent and its variants. Experiments on problems of comparably low dimensionality show improved convergence. In very high-dimensional problems, such as those encountered in deep learning, the pre-conditioner effectively becomes an automatic learning-rate adaptation scheme, which we also empirically show to work well.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1902.07557.pdf"
      }
    },
    "loaizaganem2019deep": {
      "citation_key": "loaizaganem2019deep",
      "title": "Deep Random Splines for Point Process Intensity Estimation of Neural Population Data",
      "authors": [
        "Gabriel Loaiza-Ganem",
        "Sean M. Perkins",
        "Karen E. Schroeder",
        "Mark M. Churchland",
        "John P. Cunningham"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1903.02610v6",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.164231",
      "abstract": "Gaussian processes are the leading class of distributions on random functions, but they suffer from well known issues including difficulty scaling and inflexibility with respect to certain shape constraints (such as nonnegativity). Here we propose Deep Random Splines, a flexible class of random functions obtained by transforming Gaussian noise through a deep neural network whose output are the parameters of a spline. Unlike Gaussian processes, Deep Random Splines allow us to readily enforce shape constraints while inheriting the richness and tractability of deep generative models. We also present an observational model for point process data which uses Deep Random Splines to model the intensity function of each point process and apply it to neural population data to obtain a low-dimensional representation of spiking activity. Inference is performed via a variational autoencoder that uses a novel recurrent encoder architecture that can handle multiple point processes as input. We use a newly collected dataset where a primate completes a pedaling task, and observe better dimensionality reduction with our model than with competing alternatives.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1903.02610.pdf"
      }
    },
    "janati2019group": {
      "citation_key": "janati2019group",
      "title": "Group level MEG/EEG source imaging via optimal transport: minimum Wasserstein estimates",
      "authors": [
        "Hicham Janati",
        "Thomas Bazeille",
        "Bertrand Thirion",
        "Marco Cuturi",
        "Alexandre Gramfort"
      ],
      "year": 2019,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1902.04812v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.172671",
      "abstract": "Magnetoencephalography (MEG) and electroencephalogra-phy (EEG) are non-invasive modalities that measure the weak electromagnetic fields generated by neural activity. Inferring the location of the current sources that generated these magnetic fields is an ill-posed inverse problem known as source imaging. When considering a group study, a baseline approach consists in carrying out the estimation of these sources independently for each subject. The ill-posedness of each problem is typically addressed using sparsity promoting regularizations. A straightforward way to define a common pattern for these sources is then to average them. A more advanced alternative relies on a joint localization of sources for all subjects taken together, by enforcing some similarity across all estimated sources. An important advantage of this approach is that it consists in a single estimation in which all measurements are pooled together, making the inverse problem better posed. Such a joint estimation poses however a few challenges, notably the selection of a valid regularizer that can quantify such spatial similarities. We propose in this work a new procedure that can do so while taking into account the geometrical structure of the cortex. We call this procedure Minimum Wasserstein Estimates (MWE). The benefits of this model are twofold. First, joint inference allows to pool together the data of different brain geometries, accumulating more spatial information. Second, MWE are defined through Optimal Transport (OT) metrics which provide a tool to model spatial proximity between cortical sources of different subjects, hence not enforcing identical source location in the group. These benefits allow MWE to be more accurate than standard MEG source localization techniques. To support these claims, we perform source localization on realistic MEG simulations based on forward operators derived from MRI scans. On a visual task dataset, we demonstrate how MWE infer neural patterns similar to functional Magnetic Resonance Imaging (fMRI) maps.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1902.04812.pdf"
      }
    },
    "ueltzhöffer2017deep": {
      "citation_key": "ueltzhöffer2017deep",
      "title": "Deep Active Inference",
      "authors": [
        "Kai Ueltzhöffer"
      ],
      "year": 2017,
      "doi": "10.1007/s00422-018-0785-7",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1709.02341v5",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.180918",
      "abstract": "This work combines the free energy principle from cognitive neuroscience and the ensuing active inference dynamics with recent advances in variational inference in deep generative models, and evolution strategies to introduce the \"deep active inference\" agent. This agent minimises a variational free energy bound on the average surprise of its sensations, which is motivated by a homeostatic argument. It does so by optimising the parameters of a generative latent variable model of its sensory inputs, together with a variational density approximating the posterior distribution over the latent variables, given its observations, and by acting on its environment to actively sample input that is likely under this generative model. The internal dynamics of the agent are implemented using deep and recurrent neural networks, as used in machine learning, making the deep active inference agent a scalable and very flexible class of active inference agent. Using the mountain car problem, we show how goal directed behaviour can be implemented by defining appropriate priors on the latent states in the agent's model. Furthermore, we show that the deep active inference agent can learn a generative model of the environment, which can be sampled from to understand the agent's beliefs about the environment and its interaction therewith.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1709.02341.pdf"
      }
    },
    "baltieri2017active": {
      "citation_key": "baltieri2017active",
      "title": "An active inference implementation of phototaxis",
      "authors": [
        "Manuel Baltieri",
        "Christopher L. Buckley"
      ],
      "year": 2017,
      "doi": "10.1162/isal_a_011",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1707.01806v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.188339",
      "abstract": "Active inference is emerging as a possible unifying theory of perception and action in cognitive and computational neuroscience. On this theory, perception is a process of inferring the causes of sensory data by minimising the error between actual sensations and those predicted by an inner \\emph{generative} (probabilistic) model. Action on the other hand is drawn as a process that modifies the world such that the consequent sensory input meets expectations encoded in the same internal model. These two processes, inferring properties of the world and inferring actions needed to meet expectations, close the sensory/motor loop and suggest a deep symmetry between action and perception. In this work we present a simple agent-based model inspired by this new theory that offers insights on some of its central ideas. Previous implementations of active inference have typically examined a \"perception-oriented\" view of this theory, assuming that agents are endowed with a detailed generative model of their surrounding environment. In contrast, we present an \"action-oriented\" solution showing how adaptive behaviour can emerge even when agents operate with a simple model which bears little resemblance to their environment. We examine how various parameters of this formulation allow phototaxis and present an example of a different, \"pathological\" behaviour.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1707.01806.pdf"
      }
    },
    "benetka2017anticipating": {
      "citation_key": "benetka2017anticipating",
      "title": "Anticipating Information Needs Based on Check-in Activity",
      "authors": [
        "Jan R. Benetka",
        "Krisztian Balog",
        "Kjetil Nørvåg"
      ],
      "year": 2017,
      "doi": "10.1145/3018661.3018679",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1709.05749v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.196282",
      "abstract": "In this work we address the development of a smart personal assistant that is capable of anticipating a user's information needs based on a novel type of context: the person's activity inferred from her check-in records on a location-based social network. Our main contribution is a method that translates a check-in activity into an information need, which is in turn addressed with an appropriate information card. This task is challenging because of the large number of possible activities and related information needs, which need to be addressed in a mobile dashboard that is limited in size. Our approach considers each possible activity that might follow after the last (and already finished) activity, and selects the top information cards such that they maximize the likelihood of satisfying the user's information needs for all possible future scenarios. The proposed models also incorporate knowledge about the temporal dynamics of information needs. Using a combination of historical check-in data and manual assessments collected via crowdsourcing, we show experimentally the effectiveness of our approach.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1709.05749.pdf"
      }
    },
    "li2011topological": {
      "citation_key": "li2011topological",
      "title": "On the Topological Foundation of Learning and Memory",
      "authors": [
        "Xin Li"
      ],
      "year": 2011,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1103.1587v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.206237",
      "abstract": "We propose a formal foundation for cognition rooted in algebraic topology, built on a Homological Parity Principle. This posits that even-dimensional homology represents stable Structure/Context (e.g., generative models), while odd-dimensional homology represents dynamic Flow/Content (e.g., sensory/memory data). Cognition is governed by the Context-Content Uncertainty Principle (CCUP), a dynamical cycle aligning these parities. This framework distinguishes two modes: Inference (waking), where the scaffold predicts the flow (a Context-before-Content process); and Learning (sleep), an inverted Structure-before-Specificity process where memory traces sculpt the scaffold. This parity interpretation unifies cognitive functions like semantic and episodic memory and provides a structural generalization of existing theories, recasting Friston's Free Energy Principle and Tonini's Integrated Information in topological terms.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1103.1587.pdf"
      }
    },
    "campbell2010quantum": {
      "citation_key": "campbell2010quantum",
      "title": "Quantum Darwinism as a Darwinian process",
      "authors": [
        "John Campbell"
      ],
      "year": 2010,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1001.0745v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.214281",
      "abstract": "The Darwinian nature of Wojciech Zurek's theory of Quantum Darwinism is evaluated against the criteria of a Darwinian process as understood within Universal Darwinism. The characteristics of a Darwinian process are developed including the consequences of accumulated adaptations resulting in adaptive systems operating in accordance with Friston's free energy principle and employing environmental simulations. Quantum theory, as developed in Zurek's research program and encapsulated by his theory of Quantum Darwinism is discussed from the view that Zurek's derivation of the measurement axioms implies that the evolution of a quantum system entangled with environmental entities is determined solely by the nature of the entangled system. There need be no further logical foundation. Quantum Darwinism is found to conform to the Darwinian paradigm in unexpected detail and is thus may be considered a theory within the framework of Universal Darwinism. With the inclusion of Quantum Darwinism within Universal Darwinism and the explanatory power of Darwinian processes extended beyond biology and the social sciences to include the creation and evolution of scientific subject matter within particle physics, atomic physics and chemistry, it is suggested that Universal Darwinism may be considered a candidate 'Theory of Everything' as anticipated by David Deutsch.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1001.0745.pdf"
      }
    },
    "little2011learning": {
      "citation_key": "little2011learning",
      "title": "Learning in embodied action-perception loops through exploration",
      "authors": [
        "Daniel Y. Little",
        "Friedrich T. Sommer"
      ],
      "year": 2011,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1112.1125v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.222479",
      "abstract": "Although exploratory behaviors are ubiquitous in the animal kingdom, their computational underpinnings are still largely unknown. Behavioral Psychology has identified learning as a primary drive underlying many exploratory behaviors. Exploration is seen as a means for an animal to gather sensory data useful for reducing its ignorance about the environment. While related problems have been addressed in Data Mining and Reinforcement Learning, the computational modeling of learning-driven exploration by embodied agents is largely unrepresented.   Here, we propose a computational theory for learning-driven exploration based on the concept of missing information that allows an agent to identify informative actions using Bayesian inference. We demonstrate that when embodiment constraints are high, agents must actively coordinate their actions to learn efficiently. Compared to earlier approaches, our exploration policy yields more efficient learning across a range of worlds with diverse structures. The improved learning in turn affords greater success in general tasks including navigation and reward gathering. We conclude by discussing how the proposed theory relates to previous information-theoretic objectives of behavior, such as predictive information and the free energy principle, and how it might contribute to a general theory of exploratory behavior.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1112.1125.pdf"
      }
    },
    "rodrigues2012sense": {
      "citation_key": "rodrigues2012sense",
      "title": "Sense me: Supporting awareness in parent-child relationships through mobile sensing",
      "authors": [
        "José Rodrigues",
        "Rúben Gouveia",
        "Olga Lyra",
        "Evangelos Karapanos"
      ],
      "year": 2012,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1207.1820v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.230602",
      "abstract": "We introduce Senseμ (pronounced \"sense me\"), a mobile application that aims at supporting awareness in parent- child relationships through the sensing capabilities of mobile devices. We discuss the relevance of three types of awareness information: physical activity inferred from accelerometers, verbal activity during class hours inferred from microphones, and social activity inferred from Bluetooth pair-wise proximity sensing. We describe how we attempt to contextualize these sensing data with the goal of supporting parents' awareness of the educational performance and social wellbeing of their children, as well as motivating and sustaining a two-way communication between parents and teachers over the long term.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1207.1820.pdf"
      }
    },
    "ni2011cdtom": {
      "citation_key": "ni2011cdtom",
      "title": "CDTOM: A Context-driven Task-oriented Middleware for Pervasive Homecare Environment",
      "authors": [
        "Hongbo Ni",
        "Bessam Abdulrazak",
        "Daqing Zhang",
        "Shu Wu"
      ],
      "year": 2011,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1102.1152v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.238876",
      "abstract": "With the growing number of the elderly, we see a greater demand for home care, and the vision of pervasive computing is also floating into the domain of the household that aims to build a smart home which can assist inhabitants (users) to live more conveniently and harmoniously. Such health-care pervasive applications in smart home should focus on the inhabitant's goal or task in diverse situations, rather than the various complex devices and services. The core challenge for homecare design is to perceive the environment and assess occurring situations, thus allowing systems to behave intelligently according to the user's intent. Due to the dynamic and heterogeneous nature of pervasive computing environment, it is difficult for an average user to obtain right information and service and in right place at right time. This paper proposes a context-driven task-oriented middleware (CDTOM) to meet the challenge. The most important component is its task model that provides an adequate high-level description of user-oriented tasks and their related contexts. Leveraging the model multiple entities can easily exchange, share and reuse their knowledge. Based on the hierarchy of task ontology, a novel task recognition approach using CBR (case-based reasoning) is presented and the performance of task recognition is evaluated by task number, context size and time costing. Moreover, a dynamic mechanism for mapping the recognized task and services is also discussed. Finally, we present the design and implementation of our task supporting system (TSS) to aid an inhabitant's tasks in light of his lifestyle and environment conditions in pervasive homecare environment, and the results of the prototype system show that our middleware approach achieves good efficiency of context management and good accuracy of user's activity inference, and can improve efficiently quality of user's life.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1102.1152.pdf"
      }
    },
    "gottwald2018systems": {
      "citation_key": "gottwald2018systems",
      "title": "Systems of bounded rational agents with information-theoretic constraints",
      "authors": [
        "Sebastian Gottwald",
        "Daniel A. Braun"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1809.05897v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.247103",
      "abstract": "Specialization and hierarchical organization are important features of efficient collaboration in economical, artificial, and biological systems. Here, we investigate the hypothesis that both features can be explained by the fact that each entity of such a system is limited in a certain way. We propose an information-theoretic approach based on a Free Energy principle, in order to computationally analyze systems of bounded rational agents that deal with such limitations optimally. We find that specialization allows to focus on fewer tasks, thus leading to a more efficient execution, but in turn requires coordination in hierarchical structures of specialized experts and coordinating units. Our results suggest that hierarchical architectures of specialized units at lower levels that are coordinated by units at higher levels are optimal, given that each unit's information-processing capability is limited and conforms to constraints on complexity costs.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1809.05897.pdf"
      }
    },
    "oudeyer2018computational": {
      "citation_key": "oudeyer2018computational",
      "title": "Computational Theories of Curiosity-Driven Learning",
      "authors": [
        "Pierre-Yves Oudeyer"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1802.10546v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.255094",
      "abstract": "What are the functions of curiosity? What are the mechanisms of curiosity-driven learning? We approach these questions about the living using concepts and tools from machine learning and developmental robotics. We argue that curiosity-driven learning enables organisms to make discoveries to solve complex problems with rare or deceptive rewards. By fostering exploration and discovery of a diversity of behavioural skills, and ignoring these rewards, curiosity can be efficient to bootstrap learning when there is no information, or deceptive information, about local improvement towards these problems. We also explain the key role of curiosity for efficient learning of world models. We review both normative and heuristic computational frameworks used to understand the mechanisms of curiosity in humans, conceptualizing the child as a sense-making organism. These frameworks enable us to discuss the bi-directional causal links between curiosity and learning, and to provide new hypotheses about the fundamental role of curiosity in self-organizing developmental structures through curriculum learning. We present various developmental robotics experiments that study these mechanisms in action, both supporting these hypotheses to understand better curiosity in humans and opening new research avenues in machine learning and artificial intelligence. Finally, we discuss challenges for the design of experimental paradigms for studying curiosity in psychology and cognitive neuroscience.   Keywords: Curiosity, intrinsic motivation, lifelong learning, predictions, world model, rewards, free-energy principle, learning progress, machine learning, AI, developmental robotics, development, curriculum learning, self-organization.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1802.10546.pdf"
      }
    },
    "biehl2018expanding": {
      "citation_key": "biehl2018expanding",
      "title": "Expanding the Active Inference Landscape: More Intrinsic Motivations in the Perception-Action Loop",
      "authors": [
        "Martin Biehl",
        "Christian Guckelsberger",
        "Christoph Salge",
        "Simón C. Smith",
        "Daniel Polani"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1806.08083v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.263207",
      "abstract": "Active inference is an ambitious theory that treats perception, inference and action selection of autonomous agents under the heading of a single principle. It suggests biologically plausible explanations for many cognitive phenomena, including consciousness. In active inference, action selection is driven by an objective function that evaluates possible future actions with respect to current, inferred beliefs about the world. Active inference at its core is independent from extrinsic rewards, resulting in a high level of robustness across e.g.\\ different environments or agent morphologies. In the literature, paradigms that share this independence have been summarised under the notion of intrinsic motivations. In general and in contrast to active inference, these models of motivation come without a commitment to particular inference and action selection mechanisms. In this article, we study if the inference and action selection machinery of active inference can also be used by alternatives to the originally included intrinsic motivation. The perception-action loop explicitly relates inference and action selection to the environment and agent memory, and is consequently used as foundation for our analysis. We reconstruct the active inference approach, locate the original formulation within, and show how alternative intrinsic motivations can be used while keeping many of the original features intact. Furthermore, we illustrate the connection to universal reinforcement learning by means of our formalism. Active inference research may profit from comparisons of the dynamics induced by alternative intrinsic motivations. Research on intrinsic motivations may profit from an additional way to implement intrinsically motivated agents that also share the biological plausibility of active inference.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1806.08083.pdf"
      }
    },
    "ofner2018hybrid": {
      "citation_key": "ofner2018hybrid",
      "title": "Hybrid Active Inference",
      "authors": [
        "André Ofner",
        "Sebastian Stober"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1810.02647v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.271474",
      "abstract": "We describe a framework of hybrid cognition by formulating a hybrid cognitive agent that performs hierarchical active inference across a human and a machine part. We suggest that, in addition to enhancing human cognitive functions with an intelligent and adaptive interface, integrated cognitive processing could accelerate emergent properties within artificial intelligence. To establish this, a machine learning part learns to integrate into human cognition by explaining away multi-modal sensory measurements from the environment and physiology simultaneously with the brain signal. With ongoing training, the amount of predictable brain signal increases. This lends the agent the ability to self-supervise on increasingly high levels of cognitive processing in order to further minimize surprise in predicting the brain signal. Furthermore, with increasing level of integration, the access to sensory information about environment and physiology is substituted with access to their representation in the brain. While integrating into a joint embodiment of human and machine, human action and perception are treated as the machine's own. The framework can be implemented with invasive as well as non-invasive sensors for environment, body and brain interfacing. Online and offline training with different machine learning approaches are thinkable. Building on previous research on shared representation learning, we suggest a first implementation leading towards hybrid active inference with non-invasive brain interfacing and state of the art probabilistic deep learning methods. We further discuss how implementation might have effect on the meta-cognitive abilities of the described agent and suggest that with adequate implementation the machine part can continue to execute and build upon the learned cognitive processes autonomously.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1810.02647.pdf"
      }
    },
    "mladenović2018active": {
      "citation_key": "mladenović2018active",
      "title": "Active Inference for Adaptive BCI: application to the P300 Speller",
      "authors": [
        "Jelena Mladenović",
        "Jérémy Frey",
        "Emmanuel Maby",
        "Mateus Joffily",
        "Fabien Lotte",
        "Jeremie Mattout"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1805.09109v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.279795",
      "abstract": "Adaptive Brain-Computer interfaces (BCIs) have shown to improve performance, however a general and flexible framework to implement adaptive features is still lacking. We appeal to a generic Bayesian approach, called Active Inference (AI), to infer user's intentions or states and act in a way that optimizes performance. In realistic P300-speller simulations, AI outperforms traditional algorithms with an increase in bit rate between 18% and 59%, while offering a possibility of unifying various adaptive implementations within one generic framework.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1805.09109.pdf"
      }
    },
    "guttenberg2018being": {
      "citation_key": "guttenberg2018being",
      "title": "Being curious about the answers to questions: novelty search with learned attention",
      "authors": [
        "Nicholas Guttenberg",
        "Martin Biehl",
        "Nathaniel Virgo",
        "Ryota Kanai"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1806.00201v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.288023",
      "abstract": "We investigate the use of attentional neural network layers in order to learn a `behavior characterization' which can be used to drive novelty search and curiosity-based policies. The space is structured towards answering a particular distribution of questions, which are used in a supervised way to train the attentional neural network. We find that in a 2d exploration task, the structure of the space successfully encodes local sensory-motor contingencies such that even a greedy local `do the most novel action' policy with no reinforcement learning or evolution can explore the space quickly. We also apply this to a high/low number guessing game task, and find that guessing according to the learned attention profile performs active inference and can discover the correct number more quickly than an exact but passive approach.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1806.00201.pdf"
      }
    },
    "pitti2018ideas": {
      "citation_key": "pitti2018ideas",
      "title": "Ideas from Developmental Robotics and Embodied AI on the Questions of Ethics in Robots",
      "authors": [
        "Alexandre Pitti"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1803.07506v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.296200",
      "abstract": "Advances in Artificial Intelligence and robotics are currently questioning theethical framework of their applications to deal with potential drifts, as well as the way inwhich these algorithms learn because they will have a strong impact on the behavior ofrobots and the type of robots. interactions with people. We would like to highlight someprinciples and ideas from cognitive neuroscience and development sciences based on theimportance of the body for intelligence, contrary to the theory of the all-brain or all-algorithm, to represent the world and interacting with others, and their current applicationsin embodied AI and developmental robotics to propose models of architectures andmechanisms for agency, representation of the body, recognition of the intention of others,predictive coding, active inference, the role of feedback and error, imitation, artificialcuriosity and contextual learning. We will explain how these are important for the design ofautonomous systems and beyond what they can tell us for the ethics of systems.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1803.07506.pdf"
      }
    },
    "melis2018exploiting": {
      "citation_key": "melis2018exploiting",
      "title": "Exploiting Unintended Feature Leakage in Collaborative Learning",
      "authors": [
        "Luca Melis",
        "Congzheng Song",
        "Emiliano De Cristofaro",
        "Vitaly Shmatikov"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1805.04049v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.304688",
      "abstract": "Collaborative machine learning and related techniques such as federated learning allow multiple participants, each with his own training dataset, to build a joint model by training locally and periodically exchanging model updates. We demonstrate that these updates leak unintended information about participants' training data and develop passive and active inference attacks to exploit this leakage. First, we show that an adversarial participant can infer the presence of exact data points -- for example, specific locations -- in others' training data (i.e., membership inference). Then, we show how this adversary can infer properties that hold only for a subset of the training data and are independent of the properties that the joint model aims to capture. For example, he can infer when a specific person first appears in the photos used to train a binary gender classifier. We evaluate our attacks on a variety of tasks, datasets, and learning configurations, analyze their limitations, and discuss possible defenses.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1805.04049.pdf"
      }
    },
    "qin2018active": {
      "citation_key": "qin2018active",
      "title": "Active Anomaly Detection with Switching Cost",
      "authors": [
        "Fengfan Qin",
        "Da Chen",
        "Hui Feng",
        "Qing Zhao",
        "Tao Yang",
        "Bo Hu"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1810.11800v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.316642",
      "abstract": "The problem of detecting a single anomalous process among multiple independent processes is considered. Under a constraint on the number of processes that can be probed simultaneously, the decision maker should decide which processes to probe at each time and when to terminate the probing. Compared with previous work considering only the observation costs, the switching costs of switchings across processes also need to be taken into account in many practical scenarios. The objective is an active inference strategy that minimizes the Bayesian risk taking into account of the sample complexity, switching cost, as well as detection errors. Based on the framework of sequential design of experiments, we propose a low-complexity, low-switching deterministic policy for two scenarios where the total switching cost is negligible and the total switching cost is comparable to the total observation cost. We show that the proposed algorithm is asymptotically optimal in the former scenario and is order optimal in the latter scenario. Simulation results demonstrate strong performance in the finite regime for both scenarios.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1810.11800.pdf"
      }
    },
    "zhong2018afaprednet": {
      "citation_key": "zhong2018afaprednet",
      "title": "AFA-PredNet: The action modulation within predictive coding",
      "authors": [
        "Junpei Zhong",
        "Angelo Cangelosi",
        "Xinzheng Zhang",
        "Tetsuya Ogata"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1804.03826v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.325255",
      "abstract": "The predictive processing (PP) hypothesizes that the predictive inference of our sensorimotor system is encoded implicitly in the regularities between perception and action. We propose a neural architecture in which such regularities of active inference are encoded hierarchically. We further suggest that this encoding emerges during the embodied learning process when the appropriate action is selected to minimize the prediction error in perception. Therefore, this predictive stream in the sensorimotor loop is generated in a top-down manner. Specifically, it is constantly modulated by the motor actions and is updated by the bottom-up prediction error signals. In this way, the top-down prediction originally comes from the prior experience from both perception and action representing the higher levels of this hierarchical cognition. In our proposed embodied model, we extend the PredNet Network, a hierarchical predictive coding network, with the motor action units implemented by a multi-layer perceptron network (MLP) to modulate the network top-down prediction. Two experiments, a minimalistic world experiment, and a mobile robot experiment are conducted to evaluate the proposed model in a qualitative way. In the neural representation, it can be observed that the causal inference of predictive percept from motor actions can be also observed while the agent is interacting with the environment.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1804.03826.pdf"
      }
    },
    "berti2018starstar": {
      "citation_key": "berti2018starstar",
      "title": "StarStar Models: Process Analysis on top of Databases",
      "authors": [
        "Alessandro Berti",
        "Wil van der Aalst"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1811.08143v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.333783",
      "abstract": "Much time in process mining projects is spent on finding and understanding data sources and extracting the event data needed. As a result, only a fraction of time is spent actually applying techniques to discover, control and predict the business process. Moreover, there is a lack of techniques to display relationships on top of databases without the need to express a complex query to get the required information. In this paper, a novel modeling technique that works on top of databases is presented. This technique is able to show a multigraph representing activities inferred from database events, connected with edges that are annotated with frequency and performance information. The representation may be the entry point to apply advanced process mining techniques that work on classic event logs, as the model provides a simple way to retrieve a classic event log from a specified piece of model. Comparison with similar techniques and an empirical evaluation are provided.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1811.08143.pdf"
      }
    },
    "butz2018learning": {
      "citation_key": "butz2018learning",
      "title": "Learning, Planning, and Control in a Monolithic Neural Event Inference Architecture",
      "authors": [
        "Martin V. Butz",
        "David Bilkey",
        "Dania Humaidan",
        "Alistair Knott",
        "Sebastian Otte"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1809.07412v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.342060",
      "abstract": "We introduce REPRISE, a REtrospective and PRospective Inference SchEme, which learns temporal event-predictive models of dynamical systems. REPRISE infers the unobservable contextual event state and accompanying temporal predictive models that best explain the recently encountered sensorimotor experiences retrospectively. Meanwhile, it optimizes upcoming motor activities prospectively in a goal-directed manner. Here, REPRISE is implemented by a recurrent neural network (RNN), which learns temporal forward models of the sensorimotor contingencies generated by different simulated dynamic vehicles. The RNN is augmented with contextual neurons, which enable the encoding of distinct, but related, sensorimotor dynamics as compact event codes. We show that REPRISE concurrently learns to separate and approximate the encountered sensorimotor dynamics: it analyzes sensorimotor error signals adapting both internal contextual neural activities and connection weight values. Moreover, we show that REPRISE can exploit the learned model to induce goal-directed, model-predictive control, that is, approximate active inference: Given a goal state, the system imagines a motor command sequence optimizing it with the prospective objective to minimize the distance to the goal. The RNN activities thus continuously imagine the upcoming future and reflect on the recent past, optimizing the predictive model, the hidden neural state activities, and the upcoming motor activities. As a result, event-predictive neural encodings develop, which allow the invocation of highly effective and adaptive goal-directed sensorimotor control.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1809.07412.pdf"
      }
    },
    "perrinet2016active": {
      "citation_key": "perrinet2016active",
      "title": "Active inference, eye movements and oculomotor delays",
      "authors": [
        "Laurent Perrinet",
        "Rick Adams",
        "Karl Friston"
      ],
      "year": 2016,
      "doi": "10.1007/s00422-014-0620-8",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1610.05564v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.350818",
      "abstract": "This paper considers the problem of sensorimotor delays in the optimal control of (smooth) eye movements under uncertainty. Specifically, we consider delays in the visuo-oculomotor loop and their implications for active inference. Active inference uses a generalisation of Kalman filtering to provide Bayes optimal estimates of hidden states and action in generalized coordinates of motion. Representing hidden states in generalized coordinates provides a simple way of compensating for both sensory and oculomotor delays. The efficacy of this scheme is illustrated using neuronal simulations of pursuit initiation responses, with and without compensation. We then consider an extension of the gener-ative model to simulate smooth pursuit eye movements - in which the visuo-oculomotor system believes both the target and its centre of gaze are attracted to a (hidden) point moving in the visual field. Finally, the generative model is equipped with a hierarchical structure, so that it can recognise and remember unseen (occluded) trajectories and emit anticipatory responses. These simulations speak to a straightforward and neurobiologically plausible solution to the generic problem of integrating information from different sources with different temporal delays and the particular difficulties encountered when a system - like the oculomotor system - tries to control its environment with delayed signals.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1610.05564.pdf"
      }
    },
    "friedrich2016fast": {
      "citation_key": "friedrich2016fast",
      "title": "Fast Online Deconvolution of Calcium Imaging Data",
      "authors": [
        "Johannes Friedrich",
        "Pengcheng Zhou",
        "Liam Paninski"
      ],
      "year": 2016,
      "doi": "10.1371/journal.pcbi.1005423",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1609.00639v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.361692",
      "abstract": "Fluorescent calcium indicators are a popular means for observing the spiking activity of large neuronal populations, but extracting the activity of each neuron from raw fluorescence calcium imaging data is a nontrivial problem. We present a fast online active set method to solve this sparse non-negative deconvolution problem. Importantly, the algorithm progresses through each time series sequentially from beginning to end, thus enabling real-time online estimation of neural activity during the imaging session. Our algorithm is a generalization of the pool adjacent violators algorithm (PAVA) for isotonic regression and inherits its linear-time computational complexity. We gain remarkable increases in processing speed: more than one order of magnitude compared to currently employed state of the art convex solvers relying on interior point methods. Unlike these approaches, our method can exploit warm starts; therefore optimizing model hyperparameters only requires a handful of passes through the data. A minor modification can further improve the quality of activity inference by imposing a constraint on the minimum spike size. The algorithm enables real-time simultaneous deconvolution of $O(10^5)$ traces of whole-brain larval zebrafish imaging data on a laptop.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1609.00639.pdf"
      }
    },
    "özkural2017ultimate": {
      "citation_key": "özkural2017ultimate",
      "title": "Ultimate Intelligence Part III: Measures of Intelligence, Perception and Intelligent Agents",
      "authors": [
        "Eray Özkural"
      ],
      "year": 2017,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1709.03879v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.373108",
      "abstract": "We propose that operator induction serves as an adequate model of perception. We explain how to reduce universal agent models to operator induction. We propose a universal measure of operator induction fitness, and show how it can be used in a reinforcement learning model and a homeostasis (self-preserving) agent based on the free energy principle. We show that the action of the homeostasis agent can be explained by the operator induction model.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1709.03879.pdf"
      }
    },
    "vakili2017anomaly": {
      "citation_key": "vakili2017anomaly",
      "title": "Anomaly Detection in Hierarchical Data Streams under Unknown Models",
      "authors": [
        "Sattar Vakili",
        "Qing Zhao",
        "Chang Liu",
        "Chen-Nee Chuah"
      ],
      "year": 2017,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1709.03573v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.381570",
      "abstract": "We consider the problem of detecting a few targets among a large number of hierarchical data streams. The data streams are modeled as random processes with unknown and potentially heavy-tailed distributions. The objective is an active inference strategy that determines, sequentially, which data stream to collect samples from in order to minimize the sample complexity under a reliability constraint. We propose an active inference strategy that induces a biased random walk on the tree-structured hierarchy based on confidence bounds of sample statistics. We then establish its order optimality in terms of both the size of the search space (i.e., the number of data streams) and the reliability requirement. The results find applications in hierarchical heavy hitter detection, noisy group testing, and adaptive sampling for active learning, classification, and stochastic root finding.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1709.03573.pdf"
      }
    },
    "daucé2017toward": {
      "citation_key": "daucé2017toward",
      "title": "Toward predictive machine learning for active vision",
      "authors": [
        "Emmanuel Daucé"
      ],
      "year": 2017,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1710.10460v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.390454",
      "abstract": "We develop a comprehensive description of the active inference framework, as proposed by Friston (2010), under a machine-learning compliant perspective. Stemming from a biological inspiration and the auto-encoding principles, the sketch of a cognitive architecture is proposed that should provide ways to implement estimation-oriented control policies. Computer simulations illustrate the effectiveness of the approach through a foveated inspection of the input data. The pros and cons of the control policy are analyzed in detail, showing interesting promises in terms of processing compression. Though optimizing future posterior entropy over the actions set is shown enough to attain locally optimal action selection, offline calculation using class-specific saliency maps is shown better for it saves processing costs through saccades pathways pre-processing, with a negligible effect on the recognition/compression rates.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1710.10460.pdf"
      }
    },
    "huang2017active": {
      "citation_key": "huang2017active",
      "title": "Active Anomaly Detection in Heterogeneous Processes",
      "authors": [
        "Boshuang Huang",
        "Kobi Cohen",
        "Qing Zhao"
      ],
      "year": 2017,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1704.00766v3",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.399109",
      "abstract": "An active inference problem of detecting anomalies among heterogeneous processes is considered. At each time, a subset of processes can be probed. The objective is to design a sequential probing strategy that dynamically determines which processes to observe at each time and when to terminate the search so that the expected detection time is minimized under a constraint on the probability of misclassifying any process. This problem falls into the general setting of sequential design of experiments pioneered by Chernoff in 1959, in which a randomized strategy, referred to as the Chernoff test, was proposed and shown to be asymptotically optimal as the error probability approaches zero. For the problem considered in this paper, a low-complexity deterministic test is shown to enjoy the same asymptotic optimality while offering significantly better performance in the finite regime and faster convergence to the optimal rate function, especially when the number of processes is large. The computational complexity of the proposed test is also of a significantly lower order.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1704.00766.pdf"
      }
    },
    "choudhury2017bayesian": {
      "citation_key": "choudhury2017bayesian",
      "title": "Bayesian Active Edge Evaluation on Expensive Graphs",
      "authors": [
        "Sanjiban Choudhury",
        "Siddhartha Srinivasa",
        "Sebastian Scherer"
      ],
      "year": 2017,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1711.07329v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.407535",
      "abstract": "Robots operate in environments with varying implicit structure. For instance, a helicopter flying over terrain encounters a very different arrangement of obstacles than a robotic arm manipulating objects on a cluttered table top. State-of-the-art motion planning systems do not exploit this structure, thereby expending valuable planning effort searching for implausible solutions. We are interested in planning algorithms that actively infer the underlying structure of the valid configuration space during planning in order to find solutions with minimal effort. Consider the problem of evaluating edges on a graph to quickly discover collision-free paths. Evaluating edges is expensive, both for robots with complex geometries like robot arms, and for robots with limited onboard computation like UAVs. Until now, this challenge has been addressed via laziness i.e. deferring edge evaluation until absolutely necessary, with the hope that edges turn out to be valid. However, all edges are not alike in value - some have a lot of potentially good paths flowing through them, and some others encode the likelihood of neighbouring edges being valid. This leads to our key insight - instead of passive laziness, we can actively choose edges that reduce the uncertainty about the validity of paths. We show that this is equivalent to the Bayesian active learning paradigm of decision region determination (DRD). However, the DRD problem is not only combinatorially hard, but also requires explicit enumeration of all possible worlds. We propose a novel framework that combines two DRD algorithms, DIRECT and BISECT, to overcome both issues. We show that our approach outperforms several state-of-the-art algorithms on a spectrum of planning problems for mobile robots, manipulators and autonomous helicopters.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1711.07329.pdf"
      }
    },
    "kitchatinov2015parametric": {
      "citation_key": "kitchatinov2015parametric",
      "title": "Parametric Modulation of Dynamo Waves",
      "authors": [
        "Leonid Kitchatinov",
        "Alexander Nepomnyashchikh"
      ],
      "year": 2015,
      "doi": "10.1134/S1063773715070026",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1504.01837v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.415893",
      "abstract": "Long-term variations of solar activity, including the Grand minima, are believed to result from temporal variations of dynamo parameters. The simplest approximation of dynamo waves is applied to show that cyclic variations of the parameters can lead to an exponential growth or decay of magnetic oscillations depending on the variations frequency. There is no parametric resonance in a dynamo, however: the selective sensitivity to distinct frequencies, characteristic of resonant phenomena, is absent. A qualitative explanation for this finding is suggested. Nonlinear analysis of dynamo-waves reveals the hysteresis phenomenon found earlier in more advanced models. However, the simplified model allows a computation of a sufficiently large number of dynamo-cycles for constructing the distribution function of their amplitudes to reproduce qualitatively two modes of solar activity inferred recently from cosmogenic isotope content in natural archives.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1504.01837.pdf"
      }
    },
    "dashdorj2015semantic": {
      "citation_key": "dashdorj2015semantic",
      "title": "Semantic Enrichment of Mobile Phone Data Records Using Background Knowledge",
      "authors": [
        "Zolzaya Dashdorj",
        "Stanislav Sobolevsky",
        "Luciano Serafini",
        "Fabrizio Antonelli",
        "Carlo Ratti"
      ],
      "year": 2015,
      "doi": "10.1016/j.knosys.2017.11.038",
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1504.05895v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.424513",
      "abstract": "Every day, billions of mobile network events (i.e. CDRs) are generated by cellular phone operator companies. Latent in this data are inspiring insights about human actions and behaviors, the discovery of which is important because context-aware applications and services hold the key to user-driven, intelligent services, which can enhance our everyday lives such as social and economic development, urban planning, and health prevention. The major challenge in this area is that interpreting such a big stream of data requires a deep understanding of mobile network events' context through available background knowledge. This article addresses the issues in context awareness given heterogeneous and uncertain data of mobile network events missing reliable information on the context of this activity. The contribution of this research is a model from a combination of logical and statistical reasoning standpoints for enabling human activity inference in qualitative terms from open geographical data that aimed at improving the quality of human behaviors recognition tasks from CDRs. We use open geographical data, Openstreetmap (OSM), as a proxy for predicting the content of human activity in the area. The user study performed in Trento shows that predicted human activities (top level) match the survey data with around 93% overall accuracy. The extensive validation for predicting a more specific economic type of human activity performed in Barcelona, by employing credit card transaction data. The analysis identifies that appropriately normalized data on points of interest (POI) is a good proxy for predicting human economical activities, with 84% accuracy on average. So the model is proven to be efficient for predicting the context of human activity, when its total level could be efficiently observed from cell phone data records, missing contextual information however.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1504.05895.pdf"
      }
    },
    "graumoya2016planning": {
      "citation_key": "graumoya2016planning",
      "title": "Planning with Information-Processing Constraints and Model Uncertainty in Markov Decision Processes",
      "authors": [
        "Jordi Grau-Moya",
        "Felix Leibfried",
        "Tim Genewein",
        "Daniel A. Braun"
      ],
      "year": 2016,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1604.02080v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.433284",
      "abstract": "Information-theoretic principles for learning and acting have been proposed to solve particular classes of Markov Decision Problems. Mathematically, such approaches are governed by a variational free energy principle and allow solving MDP planning problems with information-processing constraints expressed in terms of a Kullback-Leibler divergence with respect to a reference distribution. Here we consider a generalization of such MDP planners by taking model uncertainty into account. As model uncertainty can also be formalized as an information-processing constraint, we can derive a unified solution from a single generalized variational principle. We provide a generalized value iteration scheme together with a convergence proof. As limit cases, this generalized scheme includes standard value iteration with a known model, Bayesian MDP planning, and robust planning. We demonstrate the benefits of this approach in a grid world simulation.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1604.02080.pdf"
      }
    },
    "biehl2018geometry": {
      "citation_key": "biehl2018geometry",
      "title": "Geometry of Friston's active inference",
      "authors": [
        "Martin Biehl"
      ],
      "year": 2018,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1811.08241v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.441625",
      "abstract": "We reconstruct Karl Friston's active inference and give a geometrical interpretation of it.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1811.08241.pdf"
      }
    },
    "fox2015contributions": {
      "citation_key": "fox2015contributions",
      "title": "Contributions to the Theory of Thermostated Systems II: Least Dissipation of Helmholtz Free Energy in Nano-Biology",
      "authors": [
        "Ronald F. Fox"
      ],
      "year": 2015,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1503.03350v2",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.450278",
      "abstract": "In this paper, we develop further the theory of thermostated systems along the lines of our earlier paper. Two results are highlighted: 1) in the Markov limit of the contracted description, a least dissipation of Helmholtz free energy principle is established; and 2) a detailed account of the appropriateness of this principle for nano-biology, including the evolution of life, is presented.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1503.03350.pdf"
      }
    },
    "mcgregor2015minimal": {
      "citation_key": "mcgregor2015minimal",
      "title": "A Minimal Active Inference Agent",
      "authors": [
        "Simon McGregor",
        "Manuel Baltieri",
        "Christopher L. Buckley"
      ],
      "year": 2015,
      "doi": null,
      "source": "arxiv",
      "url": "http://arxiv.org/abs/1503.04187v1",
      "pdf_path": null,
      "added_date": "2025-12-12T11:49:33.458540",
      "abstract": "Research on the so-called \"free-energy principle'' (FEP) in cognitive neuroscience is becoming increasingly high-profile. To date, introductions to this theory have proved difficult for many readers to follow, but it depends mainly upon two relatively simple ideas: firstly that normative or teleological values can be expressed as probability distributions (active inference), and secondly that approximate Bayesian reasoning can be effectively performed by gradient descent on model parameters (the free-energy principle). The notion of active inference is of great interest for a number of disciplines including cognitive science and artificial intelligence, as well as cognitive neuroscience, and deserves to be more widely known.   This paper attempts to provide an accessible introduction to active inference and informational free-energy, for readers from a range of scientific backgrounds. In this work introduce an agent-based model with an agent trying to make predictions about its position in a one-dimensional discretized world using methods from the FEP.",
      "venue": "arXiv",
      "citation_count": null,
      "metadata": {
        "pdf_url": "https://arxiv.org/pdf/1503.04187.pdf"
      }
    }
  }
}