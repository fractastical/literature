# PCA Loadings Summary

This document provides an interpretation of the Principal Component Analysis (PCA) 
loadings, showing which words contribute most to each principal component.

## Overview

- **Total Components Analyzed**: 5
- **Total Variance Explained**: 18.10%

## Component Analysis

### Principal Component 1 (PC1)

- **Variance Explained**: 4.42%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | learning | 0.2172 |
| 2 | markov | -0.2125 |
| 3 | aguilera | -0.1653 |
| 4 | brain | 0.1546 |
| 5 | particular | -0.1517 |
| 6 | synaptic | 0.1463 |
| 7 | comment | -0.1398 |
| 8 | blankets | -0.1333 |
| 9 | particular physics | -0.1263 |
| 10 | markov blankets | -0.1253 |
| 11 | blanket | -0.1226 |
| 12 | principle aguilera | -0.1224 |
| 13 | physics free | -0.1212 |
| 14 | markov blanket | -0.1170 |
| 15 | physics | -0.1144 |
| 16 | tschantz | -0.1130 |
| 17 | aguilera millidge | -0.1130 |
| 18 | tschantz buckley | -0.1130 |
| 19 | buckley | -0.1130 |
| 20 | millidge tschantz | -0.1130 |

#### Interpretation

**Positive contributors** (high loading): learning, brain, synaptic
**Negative contributors** (low loading): markov, aguilera, particular, comment, blankets

---

### Principal Component 2 (PC2)

- **Variance Explained**: 3.87%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | fep | 0.3745 |
| 2 | 2025 | -0.2671 |
| 3 | entropy | -0.1859 |
| 4 | systems | 0.1380 |
| 5 | brain | 0.1353 |
| 6 | learning | 0.1290 |
| 7 | control | -0.1269 |
| 8 | synaptic | 0.1250 |
| 9 | theory | 0.1196 |
| 10 | changes | -0.1088 |
| 11 | university | -0.1066 |
| 12 | mathematical | 0.0960 |
| 13 | machine | 0.0908 |
| 14 | november | -0.0890 |
| 15 | november 2025 | -0.0890 |
| 16 | press | -0.0878 |
| 17 | principle | 0.0874 |
| 18 | friston | -0.0842 |
| 19 | free energy | 0.0830 |
| 20 | using | -0.0828 |

#### Interpretation

**Positive contributors** (high loading): fep, systems, brain, learning, synaptic
**Negative contributors** (low loading): 2025, entropy, control, changes, university

---

### Principal Component 3 (PC3)

- **Variance Explained**: 3.37%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | 2025 | 0.3021 |
| 2 | fep | 0.1787 |
| 3 | active | -0.1691 |
| 4 | active inference | -0.1647 |
| 5 | entropy | -0.1542 |
| 6 | estimation | -0.1446 |
| 7 | university | 0.1319 |
| 8 | inference | -0.1306 |
| 9 | noise | -0.1190 |
| 10 | brain | 0.1165 |
| 11 | changes | 0.1147 |
| 12 | synaptic | 0.1122 |
| 13 | article | 0.1121 |
| 14 | information | -0.1119 |
| 15 | press | 0.1056 |
| 16 | states | -0.1046 |
| 17 | november 2025 | 0.1007 |
| 18 | november | 0.1007 |
| 19 | energy | -0.0991 |
| 20 | study | 0.0951 |

#### Interpretation

**Positive contributors** (high loading): 2025, fep, university, brain, changes
**Negative contributors** (low loading): active, active inference, entropy, estimation, inference

---

### Principal Component 4 (PC4)

- **Variance Explained**: 3.25%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | estimation | 0.3268 |
| 2 | control | 0.2802 |
| 3 | state | 0.2137 |
| 4 | noise | 0.1943 |
| 5 | 2025 | -0.1587 |
| 6 | network | 0.1250 |
| 7 | input | 0.1090 |
| 8 | repeated | 0.1077 |
| 9 | states | -0.1037 |
| 10 | colored noise | 0.1019 |
| 11 | inference | -0.1014 |
| 12 | aguilera | 0.0984 |
| 13 | performance | 0.0982 |
| 14 | colored | 0.0978 |
| 15 | estimation control | 0.0959 |
| 16 | active | -0.0949 |
| 17 | self | -0.0902 |
| 18 | agents | 0.0889 |
| 19 | theory | -0.0883 |
| 20 | wind | 0.0864 |

#### Interpretation

**Positive contributors** (high loading): estimation, control, state, noise, network
**Negative contributors** (low loading): 2025, states, inference, active, self

---

### Principal Component 5 (PC5)

- **Variance Explained**: 3.20%

#### Top Contributing Words

| Rank | Word | Loading |
|------|------|---------|
| 1 | entropy | 0.2261 |
| 2 | 2025 | -0.1973 |
| 3 | principles | 0.1958 |
| 4 | local | 0.1918 |
| 5 | estimation | -0.1652 |
| 6 | synaptic | 0.1528 |
| 7 | active inference | -0.1487 |
| 8 | max entropy | 0.1486 |
| 9 | max | 0.1486 |
| 10 | belief | 0.1452 |
| 11 | active | -0.1436 |
| 12 | control | -0.1236 |
| 13 | brain | 0.1218 |
| 14 | kikuchi | 0.1139 |
| 15 | bethe kikuchi | 0.1139 |
| 16 | bethe | 0.1139 |
| 17 | energy | 0.1091 |
| 18 | legendre | 0.1091 |
| 19 | variational principles | 0.1091 |
| 20 | belief propagation | 0.1091 |

#### Interpretation

**Positive contributors** (high loading): entropy, principles, local, synaptic, max entropy
**Negative contributors** (low loading): 2025, estimation, active inference, active, control

---

## Summary

The loadings indicate which words (features) are most strongly associated with each 
principal component. Positive loadings indicate words that increase with the component, 
while negative loadings indicate words that decrease.

### Key Insights

- Components with higher explained variance capture more of the overall variation in the corpus.
- Words with large absolute loadings are the most important for that component.
- Components can be interpreted as themes or topics in the literature.
