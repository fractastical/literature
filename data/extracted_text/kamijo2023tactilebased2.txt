Tactile-based Active Inference for
Force-Controlled Peg-in-Hole Insertions
Tatsuya Kamijo1, Ixchel G. Ramirez-Alpizar 2, Enrique Coronado 2, Gentiane Venture1,3
Abstract— Reinforcement Learning (RL) has shown great
promise for efficiently learning force control policies in peg-
in-hole tasks. However, robots often face difficulties due to
visual occlusions by the gripper and uncertainties in the initial
grasping pose of the peg. These challenges often restrict force-
controlled insertion policies to situations where the peg is rigidly
fixed to the end-effector. While vision-based tactile sensors
offer rich tactile feedback that could potentially address these
issues, utilizing them to learn effective tactile policies is both
computationally intensive and difficult to generalize. In this
paper, we propose a robust tactile insertion policy that can align
the tilted peg with the hole using active inference, without the
need for extensive training on large datasets. Our approach
employs a dual-policy architecture: one policy focuses on
insertion, integrating force control and RL to guide the object
into the hole, while the other policy performs active inference
based on tactile feedback to align the tilted peg with the hole. In
real-world experiments, our dual-policy architecture achieved
90% success rate into a hole with a clearance of less than 0.1
mm, significantly outperforming previous methods that lack
tactile sensory feedback (5%). To assess the generalizability
of our alignment policy, we conducted experiments with five
different pegs, demonstrating its effective adaptation to multiple
objects.
I. I NTRODUCTION
Broadening the application of industrial robots necessitates
the ability to safely execute precise contact-rich manipulation
tasks, such as peg insertion. Yet, the achievement of safe
and robust execution of insertion tasks is challenging due
to grasp uncertainty, visual occlusions by the gripper, and
complex physical interaction between the grasped object and
the environment.
Early work on peg-in-hole tasks leverage mathematical
or geometrical model of the environment [1], [2]. In recent
years, learning-based approaches have shown great success in
various manipulation tasks by learning complex behaviours,
thus avoiding the need to model physical interactions be-
tween the manipulated object and the environment [3].
Reinforcement Learning (RL) methods have especially been
shown to be effective in object insertion tasks. While RL
policies can successfully learn peg-in-hole insertion tasks,
most of the work either consider the peg to be part of the
robot’s end-effector or fix it to the gripper, assuming no in-
hand slippage occurs during the insertion process [4]. This
paper addresses this assumption by using feedback signal
from the vision-based tactile sensors.
1Department of Mechanical Engineering, Faculty of Engineering, The
University of Tokyo, Japan tatsukamijo@g.ecc.u-tokyo.ac.jp
2Automation Research Team, Industrial CPS Research Center, National
Institute of Advanced Industrial Science and Technology (AIST), Japan
3CNRS-AIST JRL (Joint Robotics Laboratory), National Institute of
Advanced Industrial Science and Technology (AIST), Japan
Fig. 1: Proposed dual-policy system for robust insertion. It leverages
deep active inference for tactile pose alignment.
We propose a safe tactile insertion policy that leverages
vision-based tactile sensors for robot pose alignment. Our
method combines the strengths of force control and active
inference, a promising neuroscience theory that unifies per-
ception and action under a single objective of minimizing
free energy. In our system, the agent predicts tactile sensation
from its own internal state, namely the tilt of the peg.
This internal state (i.e. inferred tilt) is updated in a way
that minimizes discrepancies between predicted and current
tactile image. The key insight is that by formulating tactile
perception under free energy minimization problem, the
active inference agent can adapt to diverse objects without
extensive training on vast datasets. Our approach consists of
two policies as depicted in Fig. 1:
• Insertion policy that executes force-controlled policy
learned by RL in simulation to insert the grasped peg.
• Alignment policy that employs active inference based
on tactile feedback to change the robot pose.
The insertion policy handles the main process of inserting
the peg. When the peg slips while in contact with the
environment, the alignment policy takes over. It executes
active inference to adjust the robot’s end effector pose in
a way that aligns the peg with the hole.
This paper presents three main contributions. First, we
propose a novel deep active inference approach to tactile pose
arXiv:2309.15681v1  [cs.RO]  27 Sep 2023
alignment. Building on the free energy principle, this ap-
proach adapts to various objects without a pre-trained model
built on a large dataset or prior knowledge of their shape.
Second, we introduce the self-data augmentation method to
realize deep active inference without collecting extensive
data in the real world. Third, we combine a force-controlled
insertion policy and the active inference-based tactile pose
alignment policy. This dual-policy system is experimentally
validated with the UR5 e-series robotic arm and the Gelsight
Mini [5] tactile sensor.
II. B ACKGROUND AND RELATED WORK
A. Learning Contact-Rich Manipulation Tasks
Learning force control by RL has shown significant
promise for handling complex, contact-rich manipulation
tasks [3]. Beltran-Hernandez et al. [6] proposes a learning-
based force control framework that combines RL techniques
with traditional force control methods. The authors use
transfer-learning techniques (Sim2Real) and domain random-
ization to close the reality gap. Although these methods
have advanced work in object-insertion tasks, they typically
assume that the peg is rigidly fixed to the robot’s end-effector
to prevent in-hand slippage during the insertion process.
However, visual occlusions by the gripper often make it
difficult for a robot to receive feedback about the physical
state around the end-effector.
Recent advances in high-resolution vision-based tactile
sensors [5], [7], [8], [9] have enabled robots to obtain rich
tactile information directly from their grippers. Approaches
leveraging tactile information for manipulation tasks include
tactile mapping [10], pose estimation [11], [12] and super-
vised learning [13], [14]. Learning a tactile insertion policy
through RL is one way to utilize this tactile information.
Dong et al. [15] study different design choices for tactile-
based feedback insertion policies and propose an RL-based
insertion policy that incorporates curriculum training and
tactile flow representation. They also argue that raw tactile
RGB images contain detailed object-specific features, which
can cause a learning-based agent to easily overfit to the
training objects. While tactile flow representation is effective
in dynamical situation where markers on the surface change
position in response to actions, it is not the best option
when you need to obtain the static state of the peg such
as tilt. Contrary to this, our work demonstrates that static
RGB images can also generalize across various objects
when you use active inference in combination with contact
area estimation. We utilize the neural network architecture
proposed in [16] to estimate the contact area. This estimated
shape is then used as input for our active inference controller.
B. Free Energy Principle and Active Inference
The free energy principle is a theoretical framework
from neuroscience that proposes that living systems seek to
minimize a statistical quantity known as free energy [17].
Building upon this theory, body perception can be modeled
as inferring the hidden state z from the sensory observation
o. The objective in perception is to find a hidden state z
that is consistent with Bayes’ rule given an observation o:
p(z|o) = p(o|z)p(z)
p(o) . (1)
Here, p(z|o) is the posterior probability of the internal
state z given a sensory observation o. To avoid calculating
the marginal likelihood p(o) =
R
z p(o|z)p(z)dz, which is
intractable when the dimension of the hidden state is large,
a reference distribution, also referred to as the recognition
density, q(z) is introduced. By minimizing the Kullback-
Leibler divergence DKL between the true posterior and the
recognition density, the hidden state z can be optimized.
DKL (q(z) ∥ p(z|o)) =
Z
q(z) ln q(z)
p(o, z)dz = F + lnp(o)
(2)
Rearranging (2), free energy can be written as
F = DKL (q(z) ∥ p(z|o)) − ln p(o). (3)
The first term is associated with perception, where the agent
performs Bayesian inference to better model its environment.
The second term −ln p(o) represents the sensory surprise
and is related to the action component, where the agent acts
to minimize this sensory surprise and thereby achieve desired
sensory outcomes.
Active inference is a theory that outlines the specific mech-
anism by which a system acts on its world to change sensory
inputs, thereby minimizing free energy. From Equation (3),
minimizing DKL is equivalent to minimizing free energy F
when the observation o is fixed. This is known as perceptual
inference. Perceptual inference can tightly constrain the level
of surprise by approximating the world but cannot lessen
the surprise within the observations themselves −ln p(o).
In active inference, the agent can decrease this sensory
surprise by acting upon the environment to change sensory
observations o, thereby minimizing free energy. Thus, both
perception and action can be done under the single free
energy minimization:
z = arg min
z
F(z, o), (4)
a = arg min
a
F(z, o(a)). (5)
Active inference has been recently applied in the field of
robotics [18]. In applying active inference to robotics, gener-
ative functions are critical. Generative functions are learned
mappings that approximate the internal hidden state dynam-
ics and how sensory observations are generated from this
hidden state, essentially serving as the model’s understanding
of the underlying causal structure of its environment. The
work in [19] presents a deep learning approach to learn the
generative function, proposing PixelAI that deals with high-
dimensional RGB input for body perception and action. This
type of learning-based method called Deep Active Inference
(Deep AIF) in general has extended the active inference
framework to high-dimensional inputs by learning generative
functions [20], [21], [22], [23]. As for the choice of hidden
state, previous work that apply active inference to robotics
often assume the robots’ joint angles as internal state [24],
[25], [26], [27]. This makes sense as joint angles are the
only factors that bring change to visual sensations in the
context of robot body perception and action. Our work sets
apart from these approaches in that we treat external objects
within the framework of active inference. We adopted the
tilt of the grasped object as the internal state and learned the
generative model that predicts tactile sensations from this tilt.
Further details about our approach are presented in Section
IV.
III. P ROBLEM STATEMENT
We tackle the peg-in-hole task with a 6 DoF UR5 e-series
robot arm equipped with vision-based tactile sensors within
its fingers. The objective is to safely insert various objects
into corresponding holes given the initial and the goal
end-effector pose. During the whole insertion process, the
robot has access to its joint angles, force-torque readings
and tactile readings from one of the tactile sensors. No
visual information was given to the robot in this work. In
the experiments we made the following assumptions:
1) The width of the peg to be grasped is small enough
such that a “tilt” can be perceived in the tactile image.
2) The inferred tilt obtained from the iteration of free
energy minimization is accurate enough to be used as
an observation of the robot.
3) The target pose of the end effector is known.
IV. M ETHODOLOGY
A. Overview
To achieve robust and adaptive insertion, we propose a
dual-policy structure, as depicted in Fig. 1. The system
initially employs a learned force control policy to insert the
grasped peg into the hole while avoiding excessive force [6].
When the grasped peg slips and tilts within the gripper due to
physical contact with the environment, the system transitions
to executing active inference. In this phase, the agent infers
the tilt of the peg and uses this inference to decide what pose
to take.
B. Insertion Policy
Our force-controlled insertion policy is based on [6]. We
use a PID-based parallel position-force control scheme with
a selection matrix to determine the degree of control exerted
on position and force along each direction. The control
command given to the robot xc is composed of a PD action
on position, a PI action on force, a selection matrix S, and
a position action from the RL policy ax:
xc = S(Kx
p xe+Kx
d ˙xe)+ax+(I−S)(Kf
p Fe+Kf
i
Z
Fedt),
(6)
where Fe and xe represent the target force and position
error, respectively. Kx
p , Kx
d , Kf
p , and Kf
i are the controller
gain parameters. In this work, we exclude rotational action
from the control command, as the alignment policy handles
that aspect. All the PID and selection matrix parameters are
Fig. 2: The internal state is updated in real-time to minimize free
energy, thereby reducing discrepancies between the predicted and
the actual tactile images of the contact area estimation. Note that
vague contact area estimation is enough for performing µ updates
based on prediction error minimization. The agent calculates the
inverse kinematics based on the inferred tilt µ and adjusts the end-
effector pose to align the peg with the hole.
learned by an RL policy in simulation and transferred to the
real world (Sim2Real). Domain randomization [28] is used
to close the reality gap between simulation physics and the
real-world dynamics. For more details, see [6].
C. Alignment Policy
Fig. 2 outlines the agent’s perception of tactile observa-
tions based on its internal state. In the following sections,
we detail our active inference model and describe how it is
implemented for tactile sensory data.
1) Active Inference Model : We model perception as
the inference of an unobservable internal state µ, which
represents the tilt of the peg relative to the end effector. This
internal state is modeled as a one-dimensional scalar. The
robot’s observations, denoted as o, comprise a preprocessed
tactile image otac and the relative angle θ between the peg
and the hole. Since µ is belief of the tilt angle between the
peg and the end effector, the angle θ may differ from µ
in situations where the peg undergoes multiple tilts. Fig. 3
illustrates the definition of µ and θ. The generative model
g maps this internal state to predicted tactile sensations as
follows:
otac = g(µ) + ϵo, (7)
where ϵo is zero-mean Gaussian noise with variance Σo.
We assume a Gaussian prior for µ with mean zero and
variance σ2
µ. Using these assumptions, the free energy F
can be expressed as:
F = −ln p(otac|µ) − ln p(µ) − ln p(θ) + Const. (8)
Here, p(θ) is also assumed Gaussian with zero mean and
variance σ2
θ. Under the Laplace approximation, we assume a
Gaussian form for the recognition density q(µ), defined by
its mean µ and variance σ2.
Fig. 3: Left: Definition of θ. While µ does not change after the
action, θ becomes close to zero. Right: Depending on the surface
of the peg, the estimated contact area can become noisy (top right
figure), which poses challenges for accurate tilt estimation. Our
proposed deep active inference approach addresses this issue by
updating the internal state µ in a way that minimizes the prediction
error.
Given that the agent’s action of aligning its pose does not
affect the internal state µ, the optimal state that minimizes
free energy can be found through gradient descent. The
update rule is:
d
dtµ = −∂F (µ)
∂µ
= ∂g(µ)
∂µ
T
Σ−1
tac(otac − g(µ)) − σ−2
µ µ. (9)
In this equation, the term otac − g(µ) represents the pre-
diction error, while Σ−1
tac serves as a precision parameter.
The expression ∂g(µ)T /∂µ maps the tactile sensory space
to the internal state space, which can be obtained through
a backward pass of the network when the generative model
is approximated by a deep neural network [25]. The second
term acts as a regularization term that mitigates excessive
updates. Upon updating the internal state to µ′ = µ + ∆t ˙µ,
the agent performs inverse kinematics to correct the tilt by
rotating the end effector around the Tool Center Point (TCP),
which is defined at the center of the two fingers.
Updating µ according to Equation (9) constitutes the
perceptual component of our model, as it aims to minimize
the first and second terms of the free energy in Equation (8).
Conversely, the action performed by the agent targets the
minimization of the third term in the free energy equation,
reflecting its goal to align the peg with the hole.
2) Generative Model: For the generative model g (i.e.
generative function) to predict tactile sensation from the
inferred tilt, we approximate it using a neural network
architecture closely following the design proposed in [25],
which is based on [29]. The network consists of two fully
connected layers followed by alternating transposed con-
volution and standard convolution layers, with a final 1D-
Dropout layer to mitigate overfitting. For a comprehensive
understanding, readers are referred to [25]. Our modification
to the architecture involves reducing the input dimension
from 4 to 1 in order to decode the tactile image from a
Algorithm 1: πalign by Deep Active Inference
Instant Decoder Training
oinit ← ContactArea(tactile image in a straight pose )
Dataset ← DataAugmentation(oinit)
Decoder.train(Dataset)
Active Inference Loop
µ ← 0
while True do
otac ← ContactArea(tactile image)
g(µ) ← Decoder.forward(µ)
∂g ← Decoder.backward(µ)
etac = otac − g(µ) ▷ Prediction error
µ = Update(µ, ∂g, etac) ▷ Perception
if µ >threshold then
InverseKinematics(µ) ▷ Action
end
end
single numerical value, which is the tilt.
3) Instant Decoder Training: Our framework trains a de-
coder between the initial grasp and the insertion stage in just
a few seconds, removing the need for a pre-trained model.
Two key components enable this: contact area estimation and
self-data augmentation.
We use the neural network architecture from [16] to
estimate the peg’s contact area for each frame, as only shape
information is essential for tilt inference. This serves as the
first component.
The second component is self-data augmentation. A no-
table limitation of using vision-based tactile sensors is their
susceptibility to damage. To avoid damaging the sensor
surface by collecting large datasets in a real-world setting,
we developed a self-data augmentation method that creates
a dataset from a single tactile image of the peg in a straight
pose. Assuming that we have access to this tactile image of
a peg in a straight pose (aligned with the hole).
To create a dataset for decoder training, we use computer
vision techniques to rotate this estimated contact area of
the peg in a straight pose oinit by a specified degree to
generate new tactile data. As discussed in [15], raw tactile
RGB images can be complex and contain task-irrelevant
features (see Fig. 3). Our method overcomes this issue
by performing active inference based on prediction error
minimization in conjunction with contact area estimation.
Extracting the contact area of the grasped peg enables the
agent to quickly learn the decoder every time it grasps a new
object.
The core advantage of this rapid training lies in its
efficiency: our agent updates its internal state, denoted as µ,
by minimizing prediction error. This means the decoder does
not need to capture detailed shapes of the contact area for
effective performance, as illustrated in Fig. 2. Consequently,
this allows our system to swiftly adapt to new pegs without
the need for a large, diverse pre-trained model.
Fig. 4: Overview of our experimental setup. In the bottom right
corner, the pegs used in the experiments are displayed, arranged
from left to right as follows: shaft, pulley, cylinder, cuboid, and
elliptical cylinder. For the dual-policy experiments, we utilized two
peg-in-hole tasks: inserting the pulley into the motor and inserting
the cuboid into the peg hole.
4) Algorithm: Algorithm 1 summarizes the flow of the
proposed alignment policy. The agent employs self-data
augmentation to create a dataset. This dataset consists of tilt-
labelled, estimated contact areas derived from tactile images
of a peg in a straight pose oinit. The decoder is trained
subsequently using this dataset. During the force-controlled
insertion process, a perceptual inference loop runs in real-
time, updating µ following Equation (9) at regular intervals.
The agent takes an action only when µ exceeds a specified
threshold, indicating that the peg is tilted. The action is
designed to reduce the relative angle between the peg and
the hole, θ becomes zero by rotating the end effector around
TCP, as calculated through inverse kinematics.
V. E XPERIMENTS AND RESULTS
A. Experimental Setup
We evaluate the proposed method on several peg-in-hole
insertion tasks. We use a 6 DoF UR5 e-series robot arm
with a control frequency of 500 Hz. The robotic arm has a
built-in force/torque sensor at its wrist and a Robotiq 2F-85
Adaptive Gripper. Two GelSight Mini sensors are mounted
on the gripper, where only one of them is used during the
experiments. We use the assembly task (motor, pulley, and
shaft) from the Assembly Challenge of the World Robot
Summit 2020 edition [30]. Additionally, we use other 3D-
printed pegs such as a cuboid, a cylinder, and an elliptical
cylinder. For the peg-in-hole insertion tasks, we use a motor
pulley and a cuboid. We observed that working with the
shaft resulted in significant slippage along the x-axis. Since
translations along the x-axis are not the focus of our study,
we opted for a 3D-printed cuboid peg instead of the shaft.
This cuboid has an industrial-level clearance of 0.08 mm
(measured with a caliper), compared to the shaft’s 0.05 mm.
The motor pulley has a clearance of 0.3 mm. The average
width of the pegs is 8mm. We used Gazebo simulator [31]
version 9 for the simulation environment to train the insertion
policy. To control the robot, the Robot Operating System
(ROS) [32] with the Universal Robot ROS Driver is used.
B. Experimental Procedure
To validate our approach, we conduct two independent
experiments. The first one is the perceptual inference exper-
iment, where we focus on evaluating our alignment policy’s
capability of inferring the tilt of multiple objects. The second
one is the active inference experiment, where the whole dual-
policy system is evaluated.
1) Perceptual Inference Procedure: For this experiment,
we aim to validate our alignment policy’s ability to infer the
tilts of multiple objects accurately. Assuming the availability
of a tactile image from a straightly grasped peg, the agent’s
goal is to infer peg tilts based on tactile images captured by
the GelSight sensor. The initial tactile image is processed
through a pre-trained neural network model to estimate the
contact area [16]. We used the trained model made publicly
available by the authors of [16] for all tactile images in
the experiments. A training dataset ( Dtrain) of 500 tactile
images, along with their corresponding tilts, is then created
by rotating the initial contact area observation by a randomly
sampled value from [-20, 20] degrees. Test sets ( Dtest)
containing 100 samples are created using the tactile image in
a straight pose at a different time step to avoid using the same
exact shape among the train and the test data. The decoder
model was trained over five epochs, taking approximately
one second on average using an Intel Core i9-9900K CPU
and an Nvidia RTX-2080 Ti GPU.
Upon completing the instant decoder training, perceptual
inference is performed for each of the 100 test data Dtest.
The initial value of µ is set to 0.0, with a maximum of
500 inference iterations. The update for µ is based on
Equation (9) and involves two parameters: Σ−1
tac and σ
2
µ. We
empirically set Σ−1
tac = 2 × 104 and σ
2
µ = 1 × 10−2.
2) Dual-policy Procedure: Before deploying the dual-
policy architecture, the force-controlled insertion policy was
trained in Gazebo simulation environment. During the train-
ing, the agent’s task was to insert a cuboid peg fixed to the
end effector into a hole. The goal position, object-surface
stiffness, goal pose uncertainty, and desired insertion force
were randomized for each episode. The agent was trained for
100000 time steps, which takes about an hour to complete.
The active inference experiment follows the same procedure
as perceptual inference for decoder training, except that we
do not create test data Dtest. The robot initially trains the
decoder using a tactile image of the peg in a straight pose.
The agent creates a dataset of 1000 tactile images whose
tilts were drawn randomly from [-10, 10]. We narrowed the
range of degrees since we noticed that in real situations the
TABLE I: Mean absolute error of estimated tilts [deg]
Object Supervised Proposed method
Shaft 4.5 1.0
Pulley 0.3 1.3
Cylinder 2.7 1.5
Cuboid 4.4 1.5
Elliptical Cylinder 1.0 1.2
tilts were mostly within this range. The robot then moves
to an initial position, which is about 1 cm far in x axes
from the hole, and [-1, 1] cm in y and z axes. This initial
position is changed after 10 insertions, a total of 40 insertions
were done. At this initial position, the robot grasps the peg
with a random tilt, assuming that a tilt has occurred due
to the contact with the environment, or initial grasp pose
uncertainty. While grasping the peg, the perceptual inference
runs in real-time with 0.5 Hz, starting from µ = 0 to update
until it reaches the maximum of 1000 iterations. The updated
µ is used as the current belief of the internal state. The
agent first performs the active inference-based policy to align
the tilted peg with the hole and transitions to the insertion
policy. When θ becomes greater than a threshold, the agent
switches to the alignment policy to make the peg straight.
This threshold is empirically set to 0.7.
C. Comparison
To validate the adaptability and accuracy of our alignment
policy on multiple objects, we also tested a baseline method
that employs supervised learning with Convolutional Neural
Networks (CNNs) [33]. This baseline model is designed to
predict the tilt of the peg based on the tactile image of
the estimated contact area. The baseline was trained using
an identical dataset and the same number of epochs as our
proposed method.
For the dual-policy experiments, we employed our inser-
tion policy without tactile feedback [6] as a baseline for
comparison. To make fair comparison under same friction,
we conducted the baseline experiments with the tactile sensor
attached to the finger, although not used.
D. Results
1) Perceptual Inference Result:The results of the percep-
tual inference experiments are summarized in Table I. The
maximum mean absolute error for estimated tilts using the
supervised learning method is 4.5 degrees, while maximum
mean absolute error for our proposed method is 1.5 degrees.
As evidenced by the results for the shaft ( 4.5 deg) and the
cylinder (2.7 deg), the supervised learning method struggles
to extract meaningful features from small datasets, especially
when the peg is round and has an indistinct border in the
tactile image of the contact area. In contrast, our proposed
method is robust against such noise, as the tilt inference is
based on maximizing the pixel overlap between the predicted
(i.e., inferred) contact area g(µ) and the contact area derived
from the actual tactile sensation. This result indicates that
our agent’s inference is generally applicable to multiple pegs
with different geometry. It’s worth noting that the baseline
TABLE II: Success rate of insertions
Object Without tactile feedback Proposed method
Cuboid 1/20 (5%) 36/40 (90%)
Pulley 14/20 (70%) 37/40 (93%)
supervised learning method was only feasible because the
internal state was defined as a single scalar. In contrast, our
proposed method can be applied to internal states with higher
dimensions simply by altering the decoder input dimension.
2) Dual-policy Result: The success rates of insertions
for different objects are summarized in Table. II. For the
cuboid peg with a clearance of 0.08 mm, the baseline method
without tactile feedback achieved a success rate of just 5%,
corresponding to 1 out of 20 trials. Given the stringent
clearance, the baseline method generally failed to insert the
peg with an initial random grasp pose, except in one trial
where it managed to grasp the peg in almost a straight pose
by chance. In contrast, our proposed method significantly
improved the success rate to 90% with the aid of the tactile
alignment policy, succeeding in 36 out of 40 trials. Similarly,
for the pulley, the baseline method achieved a relatively
better but still suboptimal success rate of 70%, or 14 out
of 20 trials. Our proposed method again outperformed the
baseline, with a success rate of 93% based on 37 successful
insertions out of 40 trials. The relatively higher success rate
of motor pulley insertions by baseline method compared
with the cuboid insertions comes not only from the higher
clearance (0.3 mm) but also from the shape and the material
of pulley. As illustrated in bottom right of Fig. 4, the pulley
has a hole in the center, whose position itself does not
change due to slippage, or rotation. We also noticed that
the motor pulley insertion has less friction than 3D printed
cuboid and the hole, guiding the the hole of the pulley
to the motor. However, while this small friction enabled
the baseline method to insert with 70% success rate, it
greatly damaged the gel of the tactile sensors. Due to this
significant damage on the tactile sensor observed during the
experiments, we decided to run only 20 insertions for the
baseline method.
VI. C ONCLUSION
In this paper, we introduced a novel, tactile-based active
inference approach for force-controlled peg-in-hole inser-
tions. Our method achieved a 90% success rate in physical
robot experiments, with a clearance of less than 0.1 mm by
utilizing active inference on tactile data for peg alignment.
Furthermore, we demonstrated that our approach generalizes
to five different objects without the need for a pre-trained
model or the collection of real-world data. This addresses a
significant limitation associated with the fragility of vision-
based tactile sensors. As a pathway for future work, we aim
to integrate vision into the system to enhance its robustness
by accounting for slippage in both the insertion and rotational
directions. Additionally, we see potential in expanding the
internal states of our active inference model to handle more
complex tasks in the tactile space.
REFERENCES
[1] H. Bruyninckx, S. Dutre, and J. De Schutter. Peg-on-hole: a model
based solution to peg and hole alignment. InProceedings of 1995 IEEE
International Conference on Robotics and Automation , volume 2,
pages 1919–1924 vol.2, 1995.
[2] M.E. Caine, T. Lozano-Perez, and W.P. Seering. Assembly strategies
for chamferless parts. In Proceedings, 1989 International Conference
on Robotics and Automation, pages 472–477 vol.1, 1989.
[3] ´I˜nigo Elguea-Aguinaco, Antonio Serrano-Mu ˜noz, Dimitrios Chrysos-
tomou, Ibai Inziarte-Hidalgo, Simon Bøgh, and Nestor Arana-
Arexolaleiba. A review on reinforcement learning for contact-rich
robotic manipulation tasks. Robotics and Computer-Integrated Man-
ufacturing, 81:102517, 2023.
[4] Cristian Camilo Beltran-Hernandez, Damien Petit, Ixchel Georgina
Ramirez-Alpizar, Takayuki Nishi, Shinichi Kikuchi, Takamitsu Mat-
subara, and Kensuke Harada. Learning force control for contact-
rich manipulation tasks with rigid position-controlled robots. IEEE
Robotics and Automation Letters, 5(4):5709–5716, oct 2020.
[5] Wenzhen Yuan, Siyuan Dong, and Edward H. Adelson. Gelsight:
High-resolution robot tactile sensors for estimating geometry and
force. Sensors (Basel, Switzerland), 2017.
[6] Cristian C. Beltran-Hernandez, Damien Petit, Ixchel G. Ramirez-
Alpizar, and Kensuke Harada. Variable compliance control for robotic
peg-in-hole assembly: A deep-reinforcement-learning approach. Ap-
plied Sciences, 10(19), 2020.
[7] Elliott Donlon, Siyuan Dong, Melody Liu, Jianhua Li, Edward Adel-
son, and Alberto Rodriguez. Gelslim: A high-resolution, compact,
robust, and calibrated tactile-sensing finger. In 2018 IEEE/RSJ
International Conference on Intelligent Robots and Systems (IROS),
pages 1927–1934, 2018.
[8] Mike Lambeta, Po-Wei Chou, Stephen Tian, Brian Yang, Benjamin
Maloon, Victoria Rose Most, Dave Stroud, Raymond Santos, Ahmad
Byagowi, Gregg Kammerer, Dinesh Jayaraman, and Roberto Calandra.
Digit: A novel design for a low-cost compact high-resolution tactile
sensor with application to in-hand manipulation. IEEE Robotics and
Automation Letters, 2020.
[9] Akhil Padmanabha, Frederik Ebert, Stephen Tian, Roberto Calandra,
Chelsea Finn, and Sergey Levine. Omnitact: A multi-directional high-
resolution touch sensor. 2020 IEEE International Conference on
Robotics and Automation (ICRA), pages 618–624, 2020.
[10] Maria Bauz ´a, Oleguer Canal, and Alberto Rodriguez. Tactile mapping
and localization from high-resolution tactile imprints. 2019 Interna-
tional Conference on Robotics and Automation (ICRA), pages 3811–
3817, 2019.
[11] Maria Bauz ´a, Eric Valls, Bryan Lim, Theo Sechopoulos, and Alberto
Rodriguez. Tactile object pose estimation from the first touch with
geometric contact rendering. In Conference on Robot Learning, 2020.
[12] Tarik Kelestemur, Robert Platt, and Taskin Padir. Tactile pose estima-
tion and policy learning for unknown object manipulation. In Piotr
Faliszewski, Viviana Mascardi, Catherine Pelachaud, and Matthew E.
Taylor, editors, 21st International Conference on Autonomous Agents
and Multiagent Systems, AAMAS 2022, Auckland, New Zealand, May
9-13, 2022, pages 742–750. International Foundation for Autonomous
Agents and Multiagent Systems (IFAAMAS), 2022.
[13] Siyuan Dong and Alberto Rodriguez. Tactile-based insertion for
dense box-packing. In 2019 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS), pages 7953–7960, 2019.
[14] Letian Fu, Huang Huang, Lars Berscheid, Hui Li, Ken Goldberg, and
Sachin Chitta. Safe self-supervised learning in real of visuo-tactile
feedback policies for industrial insertion. In 2023 IEEE International
Conference on Robotics and Automation (ICRA), pages 10380–10386,
2023.
[15] Siyuan Dong, Devesh Jha, Diego Romeres, Sangwoon Kim, Daniel
Nikovski, and Alberto Rodriguez. Tactile-rl for insertion: General-
ization to objects of unknown geometry. In 2021 IEEE International
Conference on Robotics and Automation (ICRA), 2021.
[16] Niklas Funk, Paul-Otto M ¨uller, Boris Belousov, Anton Savchenko,
Rolf Findeisen, and Jan Peters. Canfnet: High-resolution pixelwise
contact area and normal force estimation for visuotactile sensors using
neural networks. 2023.
[17] Karl Friston. Friston, k.j.: The free-energy principle: a unified brain
theory? nat. rev. neurosci. 11, 127-138. Nature reviews. Neuroscience,
11:127–38, 02 2010.
[18] Pablo Lanillos, Cristian Meo, Corrado Pezzato, Ajith Anil Meera, Mo-
hamed Baioumy, Wataru Ohata, Alexander Tschantz, Beren Millidge,
Martijn Wisse, Christopher L. Buckley, and Jun Tani. Active inference
in robotics and artificial agents: Survey and challenges, 2021.
[19] Cansu Sancaktar, Marcel A. J. van Gerven, and Pablo Lanillos. End-to-
end pixel-based deep active inference for body perception and action.
In 2020 Joint IEEE 10th International Conference on Development
and Learning and Epigenetic Robotics (ICDL-EpiRob), 2020.
[20] Kai Ueltzh ¨offer. Deep active inference. Biological Cybernetics,
112(6):547–573, oct 2018.
[21] Zafeirios Fountas, Noor Sajid, Pedro Mediano, and Karl Friston. Deep
active inference agents using monte-carlo methods. In H. Larochelle,
M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin, editors, Advances
in Neural Information Processing Systems, volume 33, pages 11662–
11675. Curran Associates, Inc., 2020.
[22] Otto van der Himst and Pablo Lanillos. Deep active inference for
partially observable mdps. In International Workshop on Affective
Interactions, 2020.
[23] Beren Millidge. Deep active inference as variational policy gradients.
Journal of Mathematical Psychology, 96:102348, 2020.
[24] Pablo Lanillos and Gordon Cheng. Adaptive robot body learning and
estimation through predictive coding. In 2018 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS). IEEE, oct 2018.
[25] Cansu Sancaktar, Marcel A. J. van Gerven, and Pablo Lanillos. End-to-
end pixel-based deep active inference for body perception and action.
In 2020 Joint IEEE 10th International Conference on Development
and Learning and Epigenetic Robotics (ICDL-EpiRob), 2020.
[26] Corrado Pezzato, Riccardo Ferrari, and Carlos Hern ´andez Corbato.
A novel adaptive controller for robot manipulators based on active
inference. IEEE Robotics and Automation Letters, PP:1–1, 02 2020.
[27] Guillermo Oliver, Pablo Lanillos, and Gordon Cheng. An empirical
study of active inference on a humanoid robot. IEEE Transactions on
Cognitive and Developmental Systems, 14(2):462–471, 2022.
[28] Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech
Zaremba, and Pieter Abbeel. Domain randomization for transferring
deep neural networks from simulation to the real world. In 2017
IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS), pages 23–30, 2017.
[29] Alexey Dosovitskiy, Jost Springenberg, Maxim Tatarchenko, and
Thomas Brox. Learning to generate chairs, tables and cars with
convolutional networks. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 39:1–1, 05 2016.
[30] World Robot Summit. Assembly Challenge 2020, 2020. Accessed:
2023-9-15.
[31] N. Koenig and A. Howard. Design and use paradigms for gazebo, an
open-source multi-robot simulator. In 2004 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS) (IEEE Cat.
No.04CH37566), volume 3, pages 2149–2154 vol.3, 2004.
[32] Morgan Quigley, Ken Conley, Brian Gerkey, Josh Faust, Tully Foote,
Jeremy Leibs, Rob Wheeler, and Andrew Ng. Ros: an open-source
robot operating system. volume 3, 01 2009.
[33] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet
classification with deep convolutional neural networks. In Proceedings
of the 25th International Conference on Neural Information Processing
Systems - Volume 1, NIPS’12, page 1097–1105, Red Hook, NY , USA,
2012. Curran Associates Inc.