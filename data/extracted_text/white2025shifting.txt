ORIGINAL RESEARCH
Synthese          (2025) 205:81 
https://doi.org/10.1007/s11229-025-04924-9
Abstract
This article applies the thesis of the extended mind to ambient smart environments. 
These systems are characterised by an environment, such as a home or classroom, 
infused with multiple, highly networked streams of smart technology working in the 
background, learning about the user and operating without an explicit interface or 
any intentional sensorimotor engagement from the user. We analyse these systems 
in the context of work on the “classical” extended mind, characterised by condi -
tions such as “trust and glue” and phenomenal transparency, and find that these 
conditions are ill-suited to describing our engagement with ambient smart environ -
ments. We then draw from the active inference framework, a theory of brain func -
tion which casts cognition as a process of embodied uncertainty minimisation, to 
develop a version of the extended mind grounded in a process ontology, where the 
boundaries of mind are understood to be multiple and always shifting. Given this 
more fluid account of the extended mind, we argue that ambient smart environments 
should be thought of as extended allostatic control systems, operating more or less 
invisibly to support an agent’s biological capacity for minimising uncertainty over 
multiple, interlocking timescales. Thus, we account for the functionality of ambient 
smart environments as extended systems, and in so doing, utilise a markedly differ -
ent version of the classical thesis of extended mind.
Keywords Extended mind · Active inference · Ambient technology · Allostasis · 
Cognitive niche construction
Received: 28 May 2024 / Accepted: 13 January 2025
© The Author(s) 2025
Shifting boundaries, extended minds: ambient technology 
and extended allostatic control
Ben White1 · Andy Clark1,2 · Avel Guènin-Carlut2 · Axel Constant2 ·  
Laura Desirée Di Paolo2,3
  Laura Desirée Di Paolo
lauradesiree.dipaolo@gmail.com
1 School of Media, Arts and Humanities, University of Sussex, Brighton, UK
2 School of Engineering and Informatics, University of Sussex, Brighton, UK
3 School of Psychology, Children and Technology Lab, University of Sussex, Brighton, UK
1 3

Synthese          (2025) 205:81 
1 Introduction
According to the Thesis of the Extended Mind (TXM), some genuinely cognitive 
operations can be partly constituted by activities involving material tools, artefacts, 
and devices (Clark & Chalmers, 1998). When the fit is right, and certain conditions 
met, such external devices and human biological cognition can form an integrated 
system—an ‘extended mind’ (Clark, 2008, 2010; Clark & Chalmers, 1998). This is a 
strong thesis stating that the substrate of mind can, literally, lie in external material -
ity. In the years since the original (1998) paper was published, spirited debate has 
surrounded what that right fit, and what those conditions are. Thus far, these debates 
have focused almost entirely on devices, tools, and artefacts, like notebooks (Clark 
& Chalmers, 1998), smartphones (Bruineberg, 2023; Bruineberg & Fabry, 2022; 
Chalmers, 2008), laptop computers (Carter & Palermos, 2016), video game inter -
faces (Kirsh, 2019; Kirsh & Maglio, 1994), and navigation systems (Clowes, 2020; 
Wheeler, 2019), as well as science fiction examples like the replacement of neural 
circuitry with silicon circuits (e.g. Clark, 2008; Clark & Chalmers, 1998). New forms 
of technology are emerging though, and this article focuses on the role that ambient 
smart technology could come to play in daily life. Recent work has brought into 
focus ambient smart environments, highlighting the conceptual differences between 
such systems and the technology that has featured in most of the TXM literature. It’s 
argued that ambient smart environments exhibit a radical functionality that sees them 
playing an “upstream” role in attention and action selection (Verbeek, 2009; Aydin et 
al., 2019; White & Miller, 2024; White & Hipólito, 2024; Hipólito & White, 2023). 
In this article, we assess the applicability of TXM to ambient smart environments, 
arguing that they present a challenging case for classical formulations of TXM. We 
introduce the active inference framework, with a two-fold goal: first, demonstrating 
that an active inference reading of TXM supports a more fluid and process-orientated 
form of TXM, that is more able to make sense of emerging cases like ambient tech -
nology. And second, such an account leads to the view that such ambient systems 
can indeed form extended cognitive systems, which we cast as a form of extended 
allostatic control.
In Section One we introduce TXM, highlighting some canonical examples and 
concerns. In Section Two we introduce ambient smart environments, providing 
a vivid example. In Section Three, we ask how ambient smart environments fare 
against the conditions of classical TXM, asking whether ambient smart environments 
should count as extended systems. In the final two sections (Sec. 4 & 5), we introduce 
active inference, seeing how it might change the way we conceptualise TXM, and 
think again about ambient smart environments.
In summary, our view is that ambient smart environments should be viewed as 
extended allostatic control systems, extending an agent’s capacity for optimal plan -
ning and anticipatory action. Moreover, we suggest that ambient smart environments 
highlight the way that it’s likely to become increasingly clumsy to continually draw 
a sharp line exactly where an extended cognitive system stops and the rest of the 
(external) machinery begins. While in many contexts it will still be useful and impor-
tant to use sensible conditions to set down a line of demarcation, we show that active 
inference helps facilitate a different approach that conceptualises our coupling with 
1 3
   81  Page 2 of 28
Synthese          (2025) 205:81 
external technological resources as rolling processes rather than fixed states, where 
humans and technology can form transient shifting “ecosystems of intelligence” 
(Friston et al., 2022). These shifting ecosystems see our biology nested within inter-
locking circles of bio-external machinery with shifting grades of integration, autono-
mous agency, and trust.
2 The extended mind
2.1 Classical TXM
The thesis of the extended mind (TXM) holds that under certain conditions, some 
external, material substrates supporting cognitive processes and mental states can be 
considered as part of the mind. 1 At the heart of TXM sits the often misunderstood 
Parity Principle, which goes like this:
If, as we confront some task, a part of the world functions as a process which, 
were it to be done in the head, we would have no hesitation in recognising as 
part of the cognitive process, then that part of the world is (so we claim) part of 
the cognitive process (Clark & Chalmers, 1998. Pp. 8)
The point of the principle is to undermine the temptation to focus too much on the 
character of biological processing when making assessments about what constitutes 
a cognitive system. The Parity Principle says nothing at all about any fine-grained 
similarities between the processes themselves, though. It is not about identifying neu-
ral or bodily processing and then looking outward to see if something external can 
be found to be doing the same kinds of processing. In other words, the Parity Prin -
ciple speaks to a more coarse-grained parity of opportunity—to what the functional 
assembly allows us to achieve—asking whether, were that to be achieved using only 
bio-internal resources, we would call it cognitive.
The classic example concerns Otto and Inga, who are making their way to the 
Museum of Modern Art in New York (Clark & Chalmers, 1998). Inga thinks and 
recalls (i.e., retrieves from biological memory) that the MOMA is on 53rd Street, 
and so she goes to see the exhibition. This is taken to be an indubitable case of 
a dispositional belief supported by internal bio-memory that can be called upon to 
navigate effectively. Otto is also on his way to see the exhibition at the MOMA, but 
Otto suffers from a mild case of Alzheimer’s disease. Fortunately, Otto is in the habit 
of writing down useful information in his notebook, which he has with him all the 
time, and in the notebook is the address of the MOMA. After consulting his note -
book, Otto quickly forms the intention to travel to 53rd Street, and makes his way 
to the museum. According to TXM, Otto should be counted as holding (even prior 
1 Throughout this paper we will typically refer to cognitive processing, rather than mental states. Although 
the original Clark and Chalmers paper (1998) distinguishes between cognitive processes and “truly men-
tal states”, later work on the extended mind tends to treat “mind” and “cognition” as largely interchange-
able (see, e.g., Wheeler (2019)).
1 3
Page 3 of 28    81 
Synthese          (2025) 205:81 
to consulting the notebook) the correct dispositional belief too. The notebook passes 
the parity test because if something inside the head played the same coarse-grained 
functional role (that of enabling the right kind of occurrent mental state on demand) 
we would have no hesitation in counting the notebook as part of Otto’s cognitive 
machinery.
2.2 Constraining TXM
Despite this being the canonical and very widely cited example case of extended 
mind, some have pushed back, arguing that while extended cognition is in prin -
ciple possible, the case of Otto should not be counted (e.g., Kirsh, 2019). Indeed, 
Ned Block has stated that while TXM was false when the paper was written, it has 
since come true with the widespread use of smartphones (quoted in Chalmers, 2019: 
Pp.12). Questions about what kind of brain-to-technology couplings should count 
as cases of extension have spawned discussion about what conditions might apply. 
Suggested criteria for being part of an extended cognitive system include that the 
resource be reliably invoked, that the retrieved information is more or less auto -
matically endorsed, that it’s easily accessible (the so called “trust and glue” criteria) 
(Clark, 2008, 2010; Clark & Chalmers, 1998), that the coupling be fast and continu-
ous, phenomenologically transparent (Kirsh, 2019; Thompson & Stapleton, 2009), 
and reciprocally bidirectional (Kirsh, 2019), and that a subject be, in some sense, 
epistemically responsible for the contents of a non-neural resource (Roberts, 2012). 
Kim Sterelny ( 2010) describes how a select few resources which are “importantly, 
robustly, reliably or persistently supportive of decision making” could be identified 
as cognitive extension (Sterelny, 2010. Pp. 466).
2.3 Expanding TXM
While some have offered constraints for TXM, others have applied its core principle 
to a wider array of mental phenomena. For instance, it’s been argued that if “purely 
cognitive” phenomena are amenable to extension, then so should our affective and 
emotional states (Columbetti & Roberts, 2015; Krueger & Szanto, 2016), and that 
our autobiographical memories can be materially extended (Heersmink, 2020). Cases 
have been made for extended personhood (Clowes, 2020; Heersmink, 2016), creativ-
ity (Wheeler, 2018), and for extended moral agency (Heersmink, 2017). Others have 
argued that consciousness itself is extended (Kirchhoff & Kiverstein, 2019; V old, 
2020). Joseph Heath and Joel Anderson ( 2010) have argued that “the will” extends, 
based on the observation that reorganising material space can introduce friction or 
smoothness that modulates the difficulty of doing hard things that, on some level, we 
might not want to do.
A detailed exploration of the TXM literature and its wide-ranging impact is beyond 
the scope of this article, but it’s important to see that the limits of the applicability of 
TXM continue to be fought over. Arguments about what should or should not count, 
and by which criteria we are to decide, are ongoing. This is important because, as 
we’ll see, emerging forms of technology might invite us to reconsider these condi -
tions, even where they’re seemingly well established.
1 3
   81  Page 4 of 28
Synthese          (2025) 205:81 
3 Ambient smart environments
3.1 Introducing ambient smart environments
In the near future humans will inhabit environments that are increasingly adaptive to 
their needs. Research in “ubiquitous” or “pervasive” computing has continued and 
developed a vision first introduced by Mark Weiser (1993), of environments infused 
with information processing technology, where the traditional user interface dis -
solves. Weiser’s vision was of environments infused with computing power wherein 
the user does not have to intentionally interact with a computing system. Computing 
technology will be embedded into the material of everyday things, like walls, floors, 
tables, and even the paint on the wall (Heylen, 2012).
These ubiquitous and invisible systems will perform their function without the 
need for intentional user input: “use as a conscious process will not apply to twenty-
first century, ‘smart’, ambient technologies” (Brenner, 2007). In this sense, we can 
say that the pragmatic function of such technology, such as automatically adjusting 
the temperature settings on the thermostat, precedes the user. A low-tech example 
of such pragmatic precedent is the modern car key fob that opens the car when the 
owner walks close. Wherever we describe the functionality of ambient technology as 
“passive”, we are referring to this form of pragmatic precedent.
But new technological developments in machine learning mean that systems will 
not precede the user only pragmatically, but also epistemically. New smart capabili-
ties realised in various kinds of sensors and wearables, for instance, could allow sys-
tems to gather deep reservoirs of data about the user. 2 Ambient smart environments 
(ASEs) are local environments, such as classrooms or homes, permeated with this 
kind of pervasive and invisible technology. A smart bathroom alone could monitor 
gum health through a toothbrush, weight fluctuations through hidden floor scales, 
signs of eye problems like glaucoma using mirror-gazing, the composition of waste 
via a smart toilet. It could track trends in users’ physical activity, the quality of sleep, 
medium to long-term trends in productivity and work, changes in environmental 
organisation, and behavioural changes in the carrying out of everyday tasks that 
might warrant analysis (Cicirelli et al., 2021). Crucially, these systems will be in the 
position to identify important causal dynamics that the users are unlikely to be able 
to identify, due to their obscurity and intrinsic complexity. The aetiology of different 
kinds of health complaints, for instance, that are often difficult (or impossible) to 
track, given the kaleidoscopic array of potential causal factors in the modern world. 
The insight of such systems may well be far deeper than that of even the most per -
ceptive and self-reflective individuals (or, indeed, human experts) (White & Miller, 
2024; White & Hipólito, 2024; Hipólito & White, 2023). Current smart technologies, 
such as apps running on our smartphones, already monitor certain behaviours, learn-
ing what we like and what interests us. To make better predictions and suggestions 
these technologies use algorithms that interact with users in useful and creative ways, 
often by making suggestions or curating content (Lazer et al., 2021).
2 We use smart here in its now largely colloquial usage, to refer to technology that exhibits anticipatory and 
adaptive capability through the use of algorithms and machine learning.
1 3
Page 5 of 28    81 
Synthese          (2025) 205:81 
One important question to ask regarding ASEs is: what are they actually doing? 
One approach for thinking about human-technology interaction is thinking in terms 
of affordances (e.g. Norman, 2013). Affordances here are understood as opportuni-
ties for actions  that emerge from a relation between an agent and the environment 
(Chemero, 2003; Gibson, 1979; Heft, 1989). But when the whole point of the func -
tionality of the system is for the user to not have to do anything, it’s difficult, if not 
impossible, to describe that system in terms of affordances (White & Miller, 2024). 
Arguing that an affordance-based framework is ill-suited when applied to ASEs, 
recent work has claimed that the best way to understand the functionality of ASEs is 
as operating “upstream” of affordances, sculpting the agent’s affordances in real time 
(White & Miller, 2024).
According to this account, we can think of these forces as shaping an agent’s field 
of affordances, which is to say, the affordances that stand out to the agent as soliciting   
(Bruineberg & Rietveld, 2014). For example, while my broader landscape of affor -
dances is broad and mostly static, certain temporary constraints (of many different 
kinds) will mean that some of those stand out as more relevant or inviting than others 
in a way that’s almost constantly changing. For instance, right now my laptop and 
coffee cup seem inviting, but an hour from now the bathroom might exert a strong 
pull. The field of affordances is typically shaped by both the intrinsic dynamics of 
the agent, and by an array of external contextual influences (van Dijk & Rietveld, 
2017). This active shaping of the field of affordances, through a hidden, adaptive, 
and upstream functionality is, we think, an apt description of the function of ASEs.
3.2 Living in an ASE
Here, an example will help: consider Utto, who works from home but finds life quite 
stressful. The anxiety that he experiences is also impacting his sleep and diet; stress 
seems to make effort in other areas impossible and haunt him when he goes to bed. 
A combination of wearable technologies and sensors around the home begin col -
lecting physiological, behavioural, and environmental data. Over time, the system 
starts to build a causal generative model reflecting deep regularities and structures 
that Utto himself could never track. The system then makes some more or less subtle 
interventions. Based on real-time data the system can adaptively manage workflow. 
For example, it will learn when Utto most struggles with stress, when he’s likely 
to procrastinate, monitoring blood glucose levels to predict dips in energy before 
they happen, and then shifting tasks around, modulating complexity to match Utto’s 
state. For example, when Utto is busy and focused, the system could slow down the 
rate of incoming emails, perhaps blocking non-urgent incoming contact altogether 
(Verbeek, 2009). In its text-based feedback and support, the system will make use of 
large language models to present information using figurative language to help shape 
thought patterns and influence mood and behaviour (e.g., Thomley & Safron, 2021; 
Kukkonen, 2020).
More impressively, the system may then monitor for signs of increasing vari -
ability in outward (behavioural) and inward (physiological) markers. Increases in 
variability are linked to prime windows for destabilising patterns of psychologi -
cal ill health and are therefore opportunities for therapeutic intervention (Hanna, 
1 3
   81  Page 6 of 28
Synthese          (2025) 205:81 
1996; Hayes & Andrews, 2020; Hayes & Yasinski, 2015). The system also monitors 
Utto’s overall health, suggesting supplementation where it finds deficiency or neces-
sity (Clark, 2003; Verbeek, 2009). In terms of reducing complexity, the system can 
ease the overall stress in Utto’s life by taking over important tasks that stressed-out 
Utto often neglects, and that would be likely to accumulate. Tasks like budgeting for 
healthy groceries, paying bills, and more of modernity’s grinding minutiae. In terms 
of increasing complexity, the system could make it more difficult for Utto to fall into 
bad habits, introducing friction into things like frivolous online spending. This could 
be achieved in a number of ways, such as ‘locking’ certain apps, slowing scroll speed, 
burying them far from the ‘home screen’, or even introducing strong haptic feedback 
to illicit meta-cogntive monitoring (Manshad & Brannon, 2021).
When the stress is really on, the system gets creative, introducing rhythm into the 
environment through lighting in ways that have been shown to entrain neural oscil -
lations (Charalambous & Djebbara, 2023). Such entrainment results in a resonance 
between brain, physiology, and environment, and is effective in influencing behav -
iour. The deliberate modulation of pattern frequency in environments, for example, 
can modulate the speed of people walking through a space (Djebbara et al., 2022). 
The system can also shift the intensity of light and colour to create atmospheric prim-
ing states, shifting an agent’s emotional experience (Canepa et al., 2023).3 Haptics 
can be deployed in similar ways, using soft textures, temperature, and rhythms to 
entrain breathing patterns effective for anxiety reduction (Shor et al., 2021), or modu-
lating the frequency of vibration in haptic feedback systems to elicit different emo -
tion responses. More speculatively, the system could use lighting, sound, and haptics 
to reflect Utto’s internal states (like heart rhythm), thereby putting him within his 
own body and training interoceptive accuracy, which can potentially ease symptoms 
of multiple psychological health concerns (Garfinkel et al., 2015; Quadt et al., 2021; 
Nord, 2022). Utto may even decide to wear a fairly unobtrusive device capable of 
inducing minor physiological changes, such as frisson, deployed to provoke specific 
interoceptive inferences, thereby inducing positive emotional experiences (Schoellar 
et al., 2019).
Importantly, much of this will be achieved through ASEs’ ability to simplify a 
problem space. However, one less obvious function of an ASE will be to temporarily 
and tactically increase the complexity of a problem space. Recent work has argued 
that the ability to increase complexity could have therapeutic potential, supporting 
well-being by disrupting overly powerful attractor states (which are hypothesised to 
underpin various forms of psychopathology (e.g., White & Hipólito, 2024). To take a 
simple example, consider how an ASE could subtly destabilise the kinds of habitual 
avoidance behaviours that can entrench episodes of depression, such as becoming 
socially withdrawn, and relying on the same repetitive routines of physical and men-
tal inactivity. Interestingly, this places ASEs in line with accounts of the therapeutic 
potential of psychedelic therapies, which have been hypothesised to disrupt rigidly 
entrenched patterns of neural activity (Hipólito et al., 2023).
3 “Atmosphere” here refers to an intuitive notion used by architects to describe “the essence of affective 
qualities” present in the material space, that may be influenced by features such as lighting and colour 
(see Canepa et al., 2023).
1 3
Page 7 of 28    81 
Synthese          (2025) 205:81 
4 Ambient smart environments and “classical” extended mind
In this section, we explore how ASEs fare in regard to classical TXM and its condi -
tions. We see ASEs as one of the “exotic puzzle cases” anticipated in the original 
paper, and think that the exploration of ASEs in relation to classical TXM will tell us 
something interesting not just about ASEs but also about TXM itself.
4.1 Sensorimotor interaction
A good place to start is with a recent, clear formulation of TXM, endorsed (at the 
time) by both Clark (2019), and Chalmers (2019):
A subject’s cognitive processes and mental states can be partly constituted.
By entities that are external to the subject, in virtue of the subject’s sensorimotor.
Interaction with these entities (Chalmers, 2019. Pp. 15).
The whole point of an ASE, however, is that the inhabitant doesn’t have to engage 
in sensorimotor interaction.4 As the above section described, the real functionality of 
the ASEs lies upstream of sensorimotor interaction. Why should we think that sen -
sorimotor engagement is so crucial though? Chalmers (2019) introduces the stipula-
tion to capture what is “strong and interesting” about TXM (pp. 15). The thought is 
this: some proposed (more science fiction) cases of cognitive extension involve parts 
of a person’s brain being replaced with an external silicon circuit, such as in Clark 
(2008). If we were to lose the ability to do mental arithmetic, and received a neural 
implant that restored that ability, it’s argued that accepting that silicon circuit as a 
proper part of our mind means accepting that minds can be extended. But Chalm -
ers (2019), along with Farkas (2012), seems to think that these kinds of cases fail to 
capture what’s controversial about TXM. Chalmers points out that critics of TXM 
happily endorse such cases but want to reject a class of other cases. That class of 
other (rejected) cases are, Chalmers thinks, captured by them involving sensorimotor 
engagement, and so the stipulation is added not because cases that don’t involve sen-
sorimotor engagement shouldn't count as extended, but because they count too easily.
Clark and Chalmers’ current view is that this explicit sensorimotor stipulation is 
too strong.5 We believe that the spirit of the sensorimotor stipulation can be preserved 
whilst also making room for interesting cases of extension in which there is no sen -
sorimotor interaction. We believe that the core claim of TXM regarding sensorimotor 
interaction—the way that stipulation should be interpreted—is that the presence of a 
sensorimotor interaction does not create a barrier such that a cognitive process must 
always stop when a sensorimotor interface is crossed. As Chalmer’s points out, many 
cases that do not cross that line may be uninteresting or uncontroversial, and so not 
typically the subject of arguments favouring TXM. But we think that ASEs are a 
4 Insofar as the ASE’s functionality doesn’t show as an affordance to be intentionally engaged with 
through motor action. There is, of course, a more minimal sense of sensory interaction in that the ASE is 
sensing and monitoring aspects of the agent, or in using sensory flows to entrain behaviour. Thanks to an 
anonymous reviewer for helping us to make this clear.
5 This current view, with its softening of the sensorimotor stipulation, was established during conversa -
tions at the 25th anniversary of the Extended Mind conference held in Boulder, Colorado, August 2023.
1 3
   81  Page 8 of 28
Synthese          (2025) 205:81 
prime class of cases where the extension claim is both very interesting and does not 
involve sensorimotor interaction.
4.2 Trust and glue
“Trust” refers to the automatic endorsing of, in Otto’s case, the information in the 
notebook. It also, arguably, refers to the fact that Otto, at some point in the past, con-
sciously endorsed the entering of the information into the notebook (Clark & Chalm-
ers, 1998. Pp. 17). Trust is taken to be a crucial condition of extension. 6 Firstly, it 
seems wrong to count something as a part of my mind if I don’t trust it. But secondly 
because it’s taken to be a possible point of functional non-parity between internal and 
external resources. For example, Sterelny (2004) made the case that Otto’s notebook 
should not be counted as a part of his mind due to its comparable vulnerability, both 
to accidents (Otto dropping it into a puddle), or by deliberate sabotage (one of Otto’s 
many enemies inserts some false beliefs). The importance of such consideration is 
contested though, with Sterelny himself softening some of these worries about the 
notebook in later work (Sterelny, 2010).
In the case of ASEs, we can ask if the flow of information and affordances sculpted 
by the ASE feel like something that can be automatically endorsed. A wide body 
of work in human–machine interaction has cast trust as a “mutual predictabil -
ity” between a human agent and a machine (Mayer et al., 1995; Lee & See, 2004; 
Montague, 2010; Hoff & Bashir, 2015; Schoeller et al., 2021). According to these 
accounts, although they vary in some details, fundamentally an agent trusts a sys -
tem when that agent can model the consequences of actions involving that system 
with a high degree of accuracy, resulting in interactions with low degrees of opera -
tional uncertainty. As far as ASEs are concerned, their role in shaping our attention in 
ways that reduce the complexity of a task seems like prime candidates for functions 
automatically endorsed by the user. For example, having the ASE draft non-critical 
emails could become something I predict the system will do well.
But what about that other form of functionality, whereby the ASE increases com-
plexity to destabilise rigid patterns. In these cases, the imperative of the system is 
to be, on some level, unpredictable. Imagine if Otto licensed an exciting but well-
meaning friend to occasionally throw some curveballs his way via interventions in 
the notebook. In regard to ASEs, there is a degree to which this worry is only surface 
level referring simply to the degrees of freedom we perceive in the system; while we 
know that our smart kitchen might surprise us with new recipe suggestions, we trust 
that it won't surprise us with an arsenic-laced quiche. However, there is a sense in 
which ASEs could be a more serious threat to trust. While this isn’t quite the same 
notion of trust deployed in Clark and Chalmers (1998), we should consider the capac-
ity of the system to operate in support of fulfilment of genuine preferences, which 
can often be nested, conflicting, or otherwise complex. Systems like ASEs could 
support loftier goals like personal growth and healing, but they could also pander to 
6 It is interesting that a failure of trust is widely agreed to preclude genuine cognitive extension. However, 
failure of trust is consistent with material scaffolding (see forthcoming special issue of Topoi titled “Scaf-
folding Bad: Varieties of Situated Cognitive Harm”, edited by Spurrett, Colombetti, & Sutton (2024).
1 3
Page 9 of 28    81 
Synthese          (2025) 205:81 
our lower-order preferences, thereby undermining a robust sense of personal agency 
(White, 2024). The relationship between highly adaptive personal technology and 
agency is a topic worthy of further work, but for now it’s simply worth recognising 
that even systems that are entirely predictable in their fulfilment of genuine prefer -
ences, could still pose a risk of harm.
One option to address this concern is by recognising that the dominant account 
of trust, based on ‘mutual predictability’ or ‘reliability’ might not be wholly suit -
able. Many philosophers have criticised this conception of trust as anaemic and 
offered more normatively thick conceptions of trust (Baier, 1986; Faulkner, 2017; 
Hollis, 1998; Stern, 2017). Adopting a less mechanistic account of trust will help us 
understand how an agent might trust a system like an ASE, even when it operates 
unpredictably and in ways that, temporarily at least, might make life more uncer -
tain. Briefly, Kiran and Verbeek ( 2010) provide an account of trust in human-tech -
nology relations based on the confidence to “trust oneself to technology”(Kiran & 
Verbeek, 2010. Pp. 411). This account is premised on the idea that technology isn’t 
external to human experience, but rather that technologies constitute human sub -
jectivity, in effect changing what it means to experience the world as human. This 
might mean more or less predictability or automatic endorsement, but is less about 
the performance of the technology in relation to a defined task, and more about how 
accepting we are of the shifts in phenomenology and identity. On this account, the 
notion of trust takes a meaning closer to what we understand the original meaning of 
“automatic endorsement”. One trusts an extended mind if one has no other choices 
than doing so. I trust my arm, not because it doesn't fail me, but rather because it is 
anchored to me and because I cannot conceive how it would be otherwise. It is in that 
sense that one “automatically endorses” an extended mind. The hard question is how 
can one endow an extended mind with such deep trust?
This is where the “glue” aspect becomes important. “Glue” refers to the way in 
which an extended mind such as Otto’s notebook becomes “a constant in Otto’s 
life”, with it being consistently consulted and the information being “directly avail -
able without difficulty” (Clark & Chalmers, 1998. Pp. 17). There are, arguably, two 
ways in which an extended mind comes to be. There are “palliative” cases where the 
extended mind fills a gap in the cognitive abilities of an agent (e.g., Otto’s notebook). 
In palliative cases the extended mind is glued through filling the gap left by the 
lack of a cognitive ability (e.g., Otto’s memory dysfunctions). There are also “pros -
thetic” cases where the extended mind replaces an existing cognitive ability. Pros -
thetic cases, arguably, lead to a higher level of trust than the palliative cases, as their 
adoption and “glueing”– the replacement of the existing ability– is driven by their 
recognised superiority and benefit. In prosthetic cases, the extended mind is glued 
through (i) making obsolete the use of onboard cognitive functions and (ii) making 
habitual/cultural/biological the use of the material, technique or technology that will 
constitute the extended mind. On the developmental time scale, this may look like 
losing the ability to navigate a city after starting to use a GPS. On the evolutionary 
time scale, this could be a niche construction process that makes a trait obsolete 
and replaces it (e.g., the lost ability to digest certain food through the acquisition 
of food processing techniques) (see Constant et al., 2022 for a discussion). ASE, if 
they are to be considered as extended minds, could become glued either as palliative 
1 3
   81  Page 10 of 28
Synthese          (2025) 205:81 
extended minds or prosthetic extended minds. As palliatives, they can become glued 
through handling tasks that may otherwise be too stressful for users suffering from, 
say, anxiety issues. As prosthetics, they may become glued to through losing, say, 
the ability to write proper emails that would be replaced by the customary use of an 
AI email assistant. As a user would be living inside the ASE, it would likely exhibit 
very high degrees of accessibility and reliance. ASEs can’t be left behind somewhere 
or dropped, and when operational they do not need to be accessed in any intentional 
way. But Otto’s notebook, as well as the ubiquitous smartphone, can now be taken 
anywhere, and accessed on demand. ASEs are not like this, in the sense that the 
whole home can't be taken with us to the office or on holiday. This isn’t to say that the 
ASE can’t function while we’re away. For example, the system might monitor and 
adjust humidity levels in the greenhouse while we relax on the beach somewhere. 
Moreover, the functionality of the ASE could be extended in an impoverished fash -
ion by downloading information to a set of smart glasses that can then overlay the 
information in augmented reality. What is clear is that in the case of ASEs, levels of 
“trust and glue” as outlined above, will be different between systems and users, and 
will likely fluctuate over short and long timescales.
4.3 Transparency, bidirectionality, and speed
There are also constraints referring to the coupling between device and user. These 
are articulated in Kirsh ( 2019), as: phenomenological transparency, speed, and syn -
chronous bidirectionality. Bidirectionality must, according to Kirsh, be fast and fluid, 
such that the changes are “synchronous.” For example, as one uses a pen and paper 
to jot down notes to form an idea, they form a “tight interactive loop” with the page 
where thought shapes writing and writing shapes the emergence of thought. Kirsh 
argues that adopting the synchronicity requirement for bidirectionality is an effective 
guard against the feared cognitive bloat (see Sec. 1.2). There’s no reason to think 
that an ASE could not operate in a synchronous, bidirectional manner, especially 
using the biofeedback features outlined earlier. And surely, the learning that ASEs 
undertake will help underpin this fluid bidirectionality; the more the system models a 
user’s preferences and intentions, the faster it will be able to shape affordances, mak-
ing the case for extension (by these lights) increasingly plausible. As Clark ( 2003) 
notes: “The more closely the smart world becomes tailored to an individual’s specific 
needs, habits, and preferences, the harder it will become to tell where the person stops 
and this tailor-made, co-evolving smart world begins” (pp. 30). However, although 
ASEs will be capable of synchronous bidirectional coupling, much of their function-
ality will rely on processes and interactions unfolding diachronically. This potential 
for diachronic coupling will be addressed in later sections.
There is agreement among numerous theorists that cognitive extensions must be 
phenomenologically transparent (see Thompson & Stapleton, 2009; Kirsh, 2019; 
Wheeler, 2019).7 Kirsh ( 2019) argues that prosthetic limbs are “the least problem -
atic of human extenders and therefore offer hints about what to expect of cognitive 
7 Although this agreement is by no means universal, with some making persuasive arguments that phe -
nomenal transparency is neither necessary nor sufficient (See Smart et al., 2022).
1 3
Page 11 of 28    81 
Synthese          (2025) 205:81 
extenders” (pp. 131). This notion of transparency draws on work by Merleau-Ponty 
describing how blind people apprehend the world through the cane, never experienc-
ing the cane as separate from themselves. In the case of cognitive extensions, most 
of us will be familiar with software or operating systems that we hate using, because 
they feel clunky. Here it feels like our cognitive efforts are directed as much at the 
software as the task at hand. Alternatively, when software is well designed, it can 
feel like a clear window we act through. ASEs are, potentially, exemplary transparent 
technology. But this depends on how we interpret ‘transparency’, as in most cases, 
it seems to be taken to apply to tasks involving intentional motor action (i.e., a blind 
person using a cane, or a skilled artist using a sketch pad). ASEs don’t involve these 
kinds of intentional motor interactions, but their functionality is transparent in the 
sense that we don’t act on it, but, in a sense, we do act through that functionality. 
This kind of transparency, coupled with their adaptivity, likens them to systems Clark 
(2003) describes as “pseudo-neural”, in the sense that many of the operations of 
neural circuits are transparent and require no conscious deliberate effort (think about 
the fact that I hardly deliberate over every movement of my fingers in writing this 
sentence) (Clark, 2003. Pp. 45).
On the other hand we might think that this kind of transparency should make us 
suspicious, as it disrupts our ability to individuate cognitive functions that are puta -
tively extended. As mentioned above, Kirsh ( 2019) suggests that cognitive exten -
sions must have a “bodily component” (pp.131). In the case of Otto’s notebook, a 
clearly delineated system manifests through sensorimotor interaction, extending a 
definable function. The ubiquity of the ASE and the range of different applications 
described seem more like a general and constant mediation between user and world 
in a way that makes it difficult to pin down specific functions (See, e.g., Kiran and 
Verbeek, 2010a; b; Aydin et al., 2019).
We think that the picture that emerges when ASEs are examined within the context 
of the constraints of classical TXM is somewhat unclear. Although we don’t view the 
lack of sensorimotor engagement in the case of ASEs as precluding them as cases 
of extension, it’s plausible that the ubiquity and automaticity make it difficult to pin 
down the precise functions being extended. As many authors note, literature on TXM 
has almost always focused on the completion of a specific task, thereby highlighting 
a specific and well-defined cognitive function (Aagaard, 2021; Bruineberg & Fabry, 
2022; Slaby, 2016). Although they are critical of this bias, highlighting and address-
ing the absence of work on non-task related cognition, the role of ASEs as support -
ing such a broad array of functions makes it difficult to apply the above conditions 
clearly.
5 Active inference and the extended mind
5.1 Active inference
Frameworks in theoretical neuroscience have reinvigorated discussions around 
TXM. The active inference framework (AIF) sees agents as embodied uncertainty 
minimisers, instantiating a generative model of self and environment (Friston, 2010; 
1 3
   81  Page 12 of 28
Synthese          (2025) 205:81 
Hohwy, 2013; Clark, 2015; Parr & Friston, 2017; Parr, Pezzulo & Friston, 2022). 
A recognition density encodes sets of expectations (priors), generating predictions 
about the causes of sensory states (e.g., that crash downstairs is just the wind and not 
a burglar), and about the most effective action strategies (e.g., I should probably go 
and check anyway). Under the AIF, an agent’s imperative is to minimise the long-
term uncertainty associated with its own sensory observations (prediction errors), 
which can be done in three ways: first by updating predictions to better match the 
data, second by changing the data that is being perceived through acting on the sen -
sorium (e.g., moving your eyes), and third, indirectly, by acting to bring the world 
in line with expectation– also referred to as cognitive niche construction (Constant 
et al., 2018; Constant et al., 2022; Bruineneber et al., 2018). By occupying the states 
that are ‘expected’ (given the agent’s specific phenotype and history), the agent keeps 
itself healthy and alive.
Prediction errors, however, are not all equal. In a world as noisy, some sets of 
errors are more salient and reliable than others, and agents must be able to separate 
signal from noise. The modulation of salience and reliability is achieved directly, 
downstream using a mechanism of second-order prediction known as ‘precision 
weighting’ (Friston, 2010; Hohwy, 2013; Clark, 2013a, 2013b, 2015), and indirectly, 
upstream through the mechanism of cognitive niche construction whereby irrelevant 
sensory inputs are made unavailable, through environmental modification. Consider 
crossing a busy road in a major city. Our experience is a cacophony: tourists chat -
tering, billboards advertising multi-vitamin pills, flashing lights, and road signs. 
Given our strong expectation of crossing the road safely and our model of the regular 
causal dynamics of busy intersections, we can expect higher precision on certain 
input streams. The system effectively turns down the ‘volume’ on the billboard and 
the tourists, and ups the ‘volume’ on the sound of approaching buses. On a foggy 
day, precision on all visual information can be reduced, entraining exploratory action 
like finding a safer crossing. We could, collectively, also implement upstream niche 
construction strategies, such as deciding to adopt urban planning rules that prohibit 
invasive forms of marketing in certain areas requiring focus. Thus, precision weight-
ing and niche construction instil predictive systems with a high degree of crucial 
contextual flexibility at multiple temporal scales, from low-level neurocognitive to 
high-level social organisation.
5.2 Allostasis
A crucial element here is that agents don’t solely aim toward minimising present 
prediction error; we plan and act to minimise expected uncertainty over the long-term 
(Parr and Friston, 2017; Kiverstein et al., 2020). This focus on expected uncertainty 
speaks to the theoretical unification of actions both pragmatic and epistemic under 
uncertainty minimisation: both pulling out an umbrella and watching the week’s 
weather forecast are folded under actively inferring that we remain dry. In order 
to undertake this complex concert of temporally interlocking action policies, agents 
are hypothesised to be sensitive to changes in the rate of error reduction over time 
relative to expectation, known as ‘error dynamics’ (Joffily & Coricelli, 2013; Van de 
Cruys, 2017; Kiverstein et al., 2020). Error dynamics holds that changes in the rate of 
1 3
Page 13 of 28    81 
Synthese          (2025) 205:81 
reduction are fed back on the subjective level as bodily affect, and this bodily affect 
influences and reflects changes in precision weighting, thereby updating expectations 
in an ongoing way sensitive to how the agent is doing. The totality of this picture is of 
an agent attuned to a range of both epistemic and pragmatic affordances, constantly 
tuning the precision of policies that reflect the best predicted trajectories of expected 
uncertainty unfolding over multiple overlapping timescales, the success and failure 
of which is constantly fed back through affectivity.
An inability to manage uncertainty is linked to stress and illness. The anticipa -
tory actions that underpin our ability to manage expected error reflect allostasis, 
which describes the adaptive changes that respond to external perturbation, main -
taining homeostasis (Sterling & Eyer, 1988; McEwen, 1998; McEwen & Wingfield, 
2003; Barrett, et al. 2016). Being in an unresolved allostatic state demands that the 
body operate beyond its typical physiological setpoints: for example, the changes in 
physiology (like rapid breathing) accompanying a perceived threat. Typically, these 
changes are short-lived responses to external stressors, but in cases where there's a 
breakdown in optimal agent-environment dynamics, these periods may be prolonged, 
resulting in damage to the body's vital underlying processes and systems (Koob & 
Le Moal, 2001). The effects of staying within an unresolved allostatic state have 
been termed allostatic load, and negatively impact many vital systems including the 
immune system, endocrine system, and cardiovascular system (Barrett et al., 2016; 
Guidi et al., 2021; Koob & Le Moal, 2001), and allostatic load is associated with 
severe negative health outcomes (Arnaldo et al., 2022; Rabey & Maloney, 2022).
5.3 Active inference and TXM
Our goal in the remainder of this section is to highlight the contributions AIF research-
ers have made to TXM, and in the next section we then apply this work to ASEs. The 
potential of the AIF to expand classical TXM is articulated in Constant et al. (2022), 
who argue that the AIF provides a “formal apparatus to make progress” in thinking 
about different cases of cognitive extension. The claim is that the formalisms of the 
AIF vindicate the parity principle by describing both the process of surprise mini -
misation for brain-bound processes and processes involving extra-bodily resources. 
In other words, prediction error minimisation describes equally body-bound dynam-
ics and actions involving material environmental features. Constant and colleagues 
(2022) say nothing about the conditions of TXM discussed earlier, but they are 
explicit in their objective to “provide future researchers with a formal apparatus to 
make progress in these debates by showing how the varieties of claims on extended 
cognition may be formally expressed” (pp. 388).
Constant and colleagues’ aim is to show how an AIF formulation of niche con -
struction, one that the authors term ‘extended active inference’ (EAI), casts cogni -
tive niche construction as a form of cognitive “uploading” or “offloading”, of the 
kinds described by the canonical cases of TXM (i.e., the use of artefacts like note -
books and smartphones).8 Although in their view cognitive niche construction goes 
8 Contant et al. ( 2022) define cognitive offloading as the restructuring of material space to minimise the 
internal energy costs associated with a cognitive task, such as rearranging ingredients for a complicated 
1 3
   81  Page 14 of 28
Synthese          (2025) 205:81 
beyond strict cases of TXM, they write that “over developmental time, smartening 
the world through cognitive niche construction operates through processes akin to…
the extended approach to cognition” (pp. 387). Adopting the AIF as a lens through 
which to view these activities (leveraging the niche as an externalised, shared genera-
tive model) allows us to qualify cases typical of TXM as genuine cognition. Under 
EAI, all cases of cognitive offloading or uploading, whether it's treading a desire 
path used by subsequent generations, or the short-term use of a computer, can be for-
malised as prediction error minimisation driven through cognitive niche construction 
(Constant et al., 2022. Pp. 377). Here, uncertainty minimisation, acting as a shared 
computational currency, unites cognitive processes underlying perception and action 
with material-involving practices (Constant et al., pp. 377).
One way of thinking about this EAI picture, and how it shifts our perspective on 
TXM, is to see how expected changes to the rate prediction error reduction can help 
select cognition-action cycles that include external structures and resources. Accord-
ing to Constant and colleagues, internal salience mappings can dictate the use of 
external resources, such as when I check my phone as the quickest way to know the 
time of a flight departure, and cases where those salience mappings themselves can 
be externally cued, such as setting an alarm to remind myself to check the departure 
time (Constant et al., 2022. Pp. 389). In other words, given a certain task, the brain 
has no prejudice in estimating that the best rates of error reduction will rely on exter-
nal tools. This picture is developed to a great extent by Clark ( 2015, 2016, 2017, 
2022). Clark argues that understanding cognition through the AIF casts agents as 
constantly “knowledge budgeting”, wherein the minimising of relevant prediction 
error includes marshalling whatever material resources happen to be readily available 
for efficient use (Clark, 2022. Pp. 4). The recruitment of external tools is a natural 
part of the brain’s core strategy for minimising prediction error.9
5.4 Recruitment puzzles
One way to appreciate the impact of the AIF, is to see that classical TXM lacked 
any specific notion of brain function and relied on coarse-grained functionalism. In 
short, the parity principle entailed that questions around extension be predicated upon 
the potential for a functional isomorphism between biological and non-biological 
vehicles of cognition (Constant et al., 2022). This had the benefit of helping us over-
come our chauvinism toward bio-internal structures, thus broadening the mind both 
literally and figuratively. But it also left open the question of how the brain-body 
system ‘decided’ when, where, and how to recruit bio-external hardware. This was 
known as the “recruitment puzzle” (Clark, 2008). Consider a student attempting to 
solve a difficult maths problem, but having access to multiple tools. Classical TXM 
dish on the kitchen top in the order they are to be used. This is to be contrasted with cognitive “uploading” 
wherein a material device like a smartphone or computer takes on the cognitive labour itself, such as in 
the case of a calculator doing long division.
9 Just how natural a process this is can be seen in studies that show how quickly the brain accommodates 
the uncertainty minimisation value of basic tools in Macaques, with neurons quickly re-representing 
objects as “near” or “far” depending on the reach capabilities of available tools (see: Berti & Frassinetti, 
2000).
1 3
Page 15 of 28    81 
Synthese          (2025) 205:81 
with its coarse-grained functional approach can describe the way that picking up, say, 
a calculator, forms an extended cognitive system based on the parity principle, but 
the recruitment puzzle remains: how can this coarse-grained functionality describe 
how one resource is recruited and not any other, and what cognitive process drives 
the recruitment? In light of active inference, however:
The answer to the recruitment puzzle is now clear. Predictive brains constantly 
estimate.
The extent to which taking an action…will reliably reduce uncertainty in ways 
that help us approach our goals (Clark, 2022. Pp. 6)
A critical part of this answer is that predictive systems improve their models of the 
world not just by updating expectations, but also by reducing the complexity of the 
model, the world, or uncertain generative processes (Hohwy, 2013; FitzGeralds, 
Dolan & Friston, 2014; Clark, 2015; Constant et al., 2018; Constant et al., 2022). In 
the context of recruiting non-bodily cognitive resources, precision weighing allows 
the system to flexibly select transient assemblages that represent the strategies the 
system is most confident deliver the best balance between accuracy and complexity. 
As Clark (2015) argues, cognitively complex agents with temporally thick generative 
models can learn over time strategies that utilise known environmental features that 
are just as apt for precision-based selection as any internal routine (Clark, 2015). By 
understanding these assemblies in this way they increasingly appear less amenable to 
the strict conditions explored above (Sec. 1.2): the best combination of accuracy and 
complexity right now might be ill-suited for a task five minutes from now, and levels 
of trust and transparency can, therefore, shift moment-to-moment.
5.5 Shifting boundaries and process ontology
Regarding how this picture fits with classical TXM, Clark ( 2017) suggests that the 
boundaries of self-evidencing systems like us are constantly shifting to accommo -
date different assemblies of internal and external components that form part of our 
prediction error-minimising machinery.10 As such, he calls for us to adopt a “pro -
cess ontology” (Dupré, 2014) approach to identifying what counts, at any given 
time, as part of a cognitive system (Clark, 2017. Pp. 13). This is opposed to the kind 
of fixed state ontology that characterises the metaphysical conception of material 
objects, and seems implicit in much classical TXM literature. A process ontology 
better captures the nature of a system that “builds and rebuilds” its own boundar -
ies in real-time through temporary precision mappings, characterised by “mutabil -
ity and multiplicity” (Clark, 2017. Pp. 7). An implicitly assumed state ontology is, 
arguably, accountable for some of the worries that dogged the classical version. For 
10 Although we want to avoid a lengthy discussion here, it is worth noting that the AIF has the math -
ematical and conceptual tools to account for systems with shifting boundaries. ‘Markov blankets’ serve 
to delineate and describe the boundaries between the internal states of the system and its external states. 
Markov blankets are not fixed or permanent, and a system can be comprised of multiple nested blankets 
(for discussion see: Friston, 2013; Clark, 2017; Hohwy, 2017; Kirchoff et al., 2018; Van Es and Kirchoff, 
2021; Bruineberg et al., 2022).
1 3
   81  Page 16 of 28
Synthese          (2025) 205:81 
example, arguments about whether external resources were to be understood as con-
stituting part of a cognitive system, or ‘merely’ acting causally on the internal (“truly 
cognitive”) machinery, led to accusations against TXM theorists of committing the 
‘causal-constitutive (C–C)’ fallacy (Adams & Aizawa, 2001, 2009, 2010). The argu-
ment is that proponents of TXM unjustifiably mistake elements which are causally 
relevant to a system to be constitutive of that system. For example, while a piece of 
marble materially constitutes the statue David, it does not cause David. Conversely, 
while the fire alarm causes me to evacuate, the fire alarm does not constitute my 
evacuation (see Kirchoff, 2015).
In response, an alternative account of constitution—diachronic constitution—has 
been proposed (Kirchoff, 2015; Kirchoff & Kiverstein, 2019). Proponents of the dia-
chronic account of constitution argue that the C–C fallacy is based on a mistaken 
assumption that cognitive processes are amenable to the same conception of con -
stitution as material objects. Instead, it is argued that cognitive processes are differ -
ent because they are, first, made up of interlevel dependence relations, and second, 
because they are temporally multifaceted, with constitutive subprocesses (synaptic 
firing) unfolding over different timescales to the higher-level process (recalling the 
location of a museum) (Kirchoff, 2015). These differences are at the core of the dis -
tinction between process and state ontology. Explaining how what we experience as 
water is diachronically constituted by a temporal flow of ongoing multi-level pro -
cesses, Ross and Ladyman (2010), describe how:
It makes no sense to imagine it having its familiar properties synchronically. 
Rather, the water’s wetness, conductivity, and so on all arise because of equi -
libria in the dynamics of processes happening over short but non-negligible 
time scales at the atomic scale. From the point of view of any attempted reduc-
tive explanation, the kind water is not held by physicists to be ‘constituted’ as 
opposed to ‘caused’ because it is not a substance in the classical metaphysical 
sense (Ross and Ladyman 2010, 160)
Thus, when Clark argues for a process ontology of extended cognitive systems, it 
implies a notion of diachronic constitution. In a nutshell, cognition is more like a 
river than it is like a chunk of marble—the interesting characteristics are underpinned 
by ongoing multi-level, temporally extended processes. This shift toward a process 
ontology and diachronic constitution is supported by the AIF, which emphasises 
the multi-layered temporality of our actions and strategies (Kirchhoff & Kiverstein, 
2019). The generative models of active inference are temporally deep and hierarchi-
cal, with upper levels tracking slower timescales and lower levels tracking faster 
causal regularities. The rapidly unfolding predictions at lower levels, pertaining to 
fast perception–action loops, ground and update the more slowly unfolding expecta-
tions at higher levels. The temporal thickness of models is what allows human agents 
to engage in the allostatic control outlined earlier. When viewed through the AIF, we 
see more clearly how cognitive processes necessarily occur across timescales, where 
fast processing at one level partly constitutes processes unfolding more slowly at 
other levels (Kirchhoff & Kiverstein, 2019).
1 3
Page 17 of 28    81 
Synthese          (2025) 205:81 
The goal of the foregoing paragraphs has been to show how the AIF has provided 
motivation and means for reimagining TXM in a different way: first, the formal -
isms of the AIF vindicate the parity principle, moving it from a more coarse-grained 
functionalism, to a finer-grained computationally unified perspective. This provides 
a surer footing for TXM theorists, and removes the “cost of going coarse grained” as 
Sterelny (2010) puts it (pp. 471), which is a reduction in richness of the overall the -
ory. This TXM is one that is more fluid, characterised by a process ontology of roll -
ing assemblies (of biological and material vehicles). This should soften the instinct 
to apply fixed boundaries for the definition of extended cognitive systems. This isn’t 
because boundaries become unimportant in specific circumstances or in regard to 
important questions, but because the application of strict boundaries becomes more 
difficult as these processes unfold over time and across different scales. The temporal 
dynamics essential to understanding the AIF describe a different kind of constitu -
tion for cognitive processes that lends itself to diachronic couplings that assemble 
and dissipate over time. Thus, the AIF provides the theoretical tools for cashing out 
these conceptual shifts, providing a view of brain function that is hierarchical and 
transient, where recognition of salience is achieved through temporary webs of preci-
sion weighting estimates. The view of the cognitive agent that emerges from the AIF, 
then, is one in which boundaries are characterised by a healthy degree of ambiguity 
and inconstancy.
6 Active inference extended minds, and ASEs
6.1 ASEs: extended allostatic control systems
This emerging vision of TXM seems to be more in the spirit of Clark ( 2017), which 
casts human agents qua cognitive systems as fundamentally “meta-morphic.” It also 
seems better poised to capture that diverse, fast functionality of ASEs. While Otto’s 
notebook serves a relatively fixed functionality and requires an intentional engage -
ment, new technologies—if we are inclined to think of them as extensions—will 
necessitate a faster and more fluid picture of cognitive extension. The ubiquity of 
the ASEs functionality and the range of different applications described seem more 
like a general and constant mediation between user and world in a way that makes 
it difficult to pin down specific functions (See, e.g., Kiran and Verbeek, 2010; Aydin 
et al., 2019).
The view of ASEs we present here is one of a general allostatic and epistemic 
support system, the multifacetedness and fluidity of which means that its fulfilment 
of certain conditions and constraints will never be stable. The literature on TXM is 
testament to our proclivity to pick out specific cognitive functions. However, we 
should note that the original extended mind paper was a call to accept a broader mate-
rial base for our mental lives generally, and wasn’t meant to restrict our application 
to well-defined functions (Clark & Chalmers, 1998). Keeping this in mind should 
dampen our instinct to decompose the role of ASEs; we want to capture that com -
bined functionality rather than any one strand. Moreover, the AIF casts all cognitive 
1 3
   81  Page 18 of 28
Synthese          (2025) 205:81 
behaviours, whether that's remembering the location of a museum or writing a novel, 
as a process of prediction error minimisation.
The second difficult aspect of ASEs is their ambience. We might think, for exam-
ple, about the way that many background features of our environments passively sup-
port cognition all the time. Clark (2008), for example, wonders whether the rhythmic 
lashing of rain on an office window, conducive to concentration, should be counted 
as part of my assembled cognitive substrate when writing (pp. 130). Clark concludes 
that no, the rain should not be counted as it isn’t “selected and maintained” as part 
of my system. But the ambience of an ASE is different. Consider again the example 
of Utto, and the ways that ambient lighting in the walls and haptics in the work chair 
use rhythms to entrain responses directly relevant to Utto’s needs in real time, based 
on up to date information about his internal states. Thus, we can distinguish between 
the passivity of general environmental features which, under certain circumstances, 
might support us in whatever task we’re doing, and the kind of adaptive functionality 
of a system like an ASE. The “passive” features of ASEs are stronger candidates for 
extension because they are maintained and selected , and in those moments trusted 
and closely coupled to Utto. But exactly which functions should count at any given 
time as part of an extended system could fluctuate as the user switches between tasks.
An interesting path forward is to think of ASEs as extended allostatic systems. 
The function of the ASE, on this view, is to extend an agent's biological capacity 
for avoiding prolonged allostatic states (i.e., states that demand operation beyond 
the body's physiological homeostatic setpoints), which, under the AIF, includes both 
pragmatic policies and epistemic policies. The ASE serves as an extension to these 
pragmatic and epistemic capacities for anticipation and adaptation. The system’s 
immense capacity for learning extends the epistemic demands of allostasis, while its 
pragmatic functions reduce the energy demands of constant adaptation during times 
of high stress. We chose to conceptualise these systems as extended allostatic control 
for several reasons. Firstly, to be clear, we take allostatic control to be a truly cogni-
tive process in that it is maintained through adaptive planning and action and the 
role that these operations play in the ongoing resolution of uncertainty. 11 Moreover, 
extended allostatic control captures the task diversity of ASEs; from supporting emo-
tion regulation to maintaining a household budget, the diverse functionality of the 
ASE is, ultimately, working in the service of avoiding prolonged states of stress. In the 
philosophical literature, we might strongly associate this with the maintenance of an 
“optimal grip” (Merleau-ponty, 1962/2012; Bruineberg & Rietveld, 2014; Kiverstein 
et al., 2020), but the notion of “grip” is “primarily phenomenological”, describing a 
component of subjective experience rather than an underlying process (Bruineberg & 
Rietveld, 2014). Extended allostatic control also speaks to the anticipatory function 
of ASEs, manifest across multiple interlocking timescales; the upstream functionality 
of an ASE may unfold over more than just the present moment, learning to predict, 
anticipate, and mitigate periods of stress, and sculpt the ongoing affordance field 
accordingly. This functionality overlaps neatly with biological allostatic control.
The role of attention in allostatic control is crucial, and can be brought into sharp 
relief with recent insights from the AIF. Deane et al. (2024) describe a hypothesised 
11 Thanks to one anonymous reviewer for raising this point of clarification.
1 3
Page 19 of 28    81 
Synthese          (2025) 205:81 
system of ‘adaptive narrative control’ based on the flexible and subpersonal deploy -
ment of precision weighting to avoid negatively valenced affective states. The key 
insight here is that in order to maintain good allostatic control, the generative model 
need not deploy precision in a strictly truth-tracking way, but that the generative 
model includes the “pragmatic implications” of specific attentional states (Deane et 
al., 2024. Pp. 8). Such a system is described as a consequence of intelligent agents 
gaining the requisite sophistication to anticipate and model future contingent affec -
tive states (e.g., if I pay attention to x I will feel bad). Think, for example, about a 
person experiencing financial difficulty that, for the time being, they have little or no 
means of remedying. The person may know that it’s a good idea to check their bank 
balance and credit card statements, and yet continue to spend money and fail to track 
the reality of their situation. These kinds of avoidant behaviours and forms of denial 
are accounted for on this view by the adaptive narrative control system allocating 
precision in a way that avoids the allostatic stress response of facing financial reality 
(Deane et al., 2024). Of course, we don’t want ASEs that disconnect us from reality 
in problematic ways, but it’s easy to imagine systems that extend this kind of adaptive 
narrative control, carefully patterning our attention, shaping the field of affordances, 
such that prolonged periods of stress are avoided. We think, therefore, that concep -
tualising the functionality of ASEs as a form of highly adaptive extended allostatic 
control system combining learning, passive adaptation and active intervention, does 
justice both to the potential power of ASEs, and to the flexibility of a process-based 
TXM.
6.2 Concerns and future questions
In this final subsection we address what we think could be a natural worry about the 
account we’ve provided. In advocating for this more fluid approach to TXM, push -
ing for a TXM that can accommodate the great swirl of shifting temporary couplings 
characterised by varying degrees of trust and transparency, might threaten to leave us 
unable to articulate a bounded agent in contexts that are important. In a nutshell, the 
worry here might be that in adopting a process-based TXM with its multiple shifting 
boundaries, we essentially do away with the notion of a bounded agent altogether.
It’s crucial to make clear that this is not the case, and does not follow from the 
account provided above. We aren’t at all advocating for an abandonment of any 
meaningful notion of a self as separate from the environment. Rather than obliterat -
ing boundaries, we take the version of TXM outlined here and applied to ASEs, to 
powerfully demonstrate the view articulated in Clark (2017), namely that the bound-
ary between agent and environment really is constantly in flux; there is “neither a 
unique nor a stationary boundary” (Clark, 2017. Pp 6), but there will always, within a 
specific context, be a boundary relevant to our concerns. Emerging technologies will, 
however, increasingly bring to our attention the way that the persisting agent cannot 
be captured through a single stationary boundary. When the need does arise for ask-
ing where, at a specific moment in time, the boundary of the agent was (in the case 
of an assault, for example), we can fall back on the relevant sensible conditions. The 
specific legal or moral considerations in play should guide our intuitions about the 
most relevant considerations. As Kirsh (2019) puts it: “As cyborg couplings prolifer-
1 3
   81  Page 20 of 28
Synthese          (2025) 205:81 
ate, the voice of justice will have to clarify things…Law is the arbiter, but scientists 
will be the expert witness” (pp. 141). The adoption of multiple shifting boundaries 
also need not re-raise concerns about “cognitive bloat”, as a process-based TXM 
facilitates the drawing and redrawing of boundaries in an ongoing way as specific 
task-relevant resources change. Considering a person entering a library, we aren’t 
forced to think in static terms about where in the library the boundary of the agent’s 
mind really sits. Instead we can consider which resources are being recruited for 
prediction error minimisation which may change over time as the agent consults a 
computer station, pores over one book, and then two together, uses a pencil to make 
notes, and so on. Finally, another consideration for thinking about shifting selfhood 
and TXM would be to consider the broader political and economic contexts in which 
material and technological culture arises. While agents will (hopefully) freely choose 
how their engagements with ASEs happen, this isn’t true for so much of our embed-
ded and scaffolded endeavours, and considering the wider influences that shape our 
engagements, and the interests in play, could help us think about relevant boundaries 
and the forces that shape them (see, e.g. Slaby, 2016).
7 Conclusion
We began in Section One by reviewing the classical version of TXM and exploring 
in detail some of the proposed conditions on extension. In Section Two we outlined 
the unique functionality of ASEs, drawing on work that casts them as a ‘meta-affor -
dance’, acting upstream of our sensorimotor engagements to shape our affordances in 
ways that support general wellbeing. In Section Three we assessed the status of ASEs 
as extension by applying the classical conditions, and found that the picture that 
emerges is somewhat unclear; the peculiar functionality of ASEs seems to evade the 
stringent application of some conditions. In Section Four we introduced the AIF, and 
then explored how it should change the lens through which we think about TXM. We 
first saw how the formalisms of the framework vindicate the parity principle, shift -
ing it from coarse-grained functionalism to a reflection of the shared computational 
imperative of prediction error minimisation. Next, we saw how the AIF necessitates 
a notion of cognitive processing as unfolding across multiple interlocking and nested 
timescales, and that this suggests a form of diachronic constitution and process ontol-
ogy, as opposed to the state ontology and synchronous notion of constitution that 
have often been assumed to apply to TXM. In the final section, we applied this new 
fluid process ontology account of TXM to ASEs, arguing for an accommodation of 
ASE functionality as extended allostatic control.
Ned Block’s assertion that TXM was false in 1998 but true in 2019 reveals some-
thing fundamental about any theory that aims to capture the intimate relationship 
between mind and technology. Technological conception and design is endlessly 
changing, new developments can be surprising and even revolutionary, and the emer-
gence of new technologies might always challenge the assumptions of our estab -
lished frameworks. The running debates between classical TXM and its rivals, often 
with a strong emphasis on strict conditions and fixed boundaries, are ill-suited to 
account for a future in which people are increasingly enveloped by ubiquitous, adap-
1 3
Page 21 of 28    81 
Synthese          (2025) 205:81 
tive, and highly individualised technological environments that support multi-tim -
escale functions. Systems that will impinge on many aspects of a user’s cognitive 
worlds, from sending emails to their long-term mental health, are difficult to capture 
using the tools of classical theories. We’ve argued here that this new approach, made 
possible by the AIF, allows for a principled move away from static boundaries, strict 
conditions, and long-held dichotomies between these different approaches. While the 
scaffolded approach retains a historical emphasis on developmental and intergenera-
tional timescales, learning and evolution, the AIF allows for a deep continuity with 
TXM. As emerging technology spectacularly amplifies human cognitive capacities, 
the approach afforded by the AIF will be increasingly appropriate.
Funding Leverhulme Trust, Sussex be. AI Doctoral Scholarship Program, Ben White, HORIZON 
EUROPE European Research Council, ERC-2020-Syg 951631, Andy Clark.
Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, 
which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long 
as you give appropriate credit to the original author(s) and the source, provide a link to the Creative 
Commons licence, and indicate if changes were made. The images or other third party material in this 
article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line 
to the material. If material is not included in the article’s Creative Commons licence and your intended use 
is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission 
directly from the copyright holder. To view a copy of this licence, visit  h t t p : / / c r e a t i v e c o m m o n s . o r g / l i c e n 
s e s / b y / 4 . 0 /     .  
References
Aagaard, J. (2021). 4E cognition and the dogma of harmony. Philosophical Psychology, 34(2), 165–181.  
h t t p s :  / / d o i  . o r g / 1  0 . 1 0  8 0 / 0 9  5 1 5 0 8  9 . 2 0 2 0  . 1 8 4  5 6 4 0
Adams, F., & Aizawa, K. (2001). The bounds of cognition. Philosophical Psychology, 14(1), 43–64. 
https://doi.org/10.1080/09515080120033571
Adams, F., & Aizawa, K. (2009). Why the mind is still in the head. In P. Robbins & M. Aydede (Eds.), 
Cambridge Handbook of Situated Cognition (pp. 78–95). Cambridge University Press.
Adams, F, and Aizawa, K (2010).'Defending the Bounds of Cognition', in Richard Menary (ed.), The 
Extended Mind.  h t t p s :  / / d o i  . o r g / 1  0 . 7 5  5 1 / m i  t p r e s  s / 9 7 8 0  2 6 2 0  1 4 0 3 8 . 0 0 3 . 0 0 0 4, accessed 5 May 2023.
Albarracin, M., Constant, A., Friston, K. J., & Ramstead, M. J. D. (2021). A variational approach to scripts. 
Frontiers Psychology, 12, 585493.  h t t p s :  / / d o i  . o r g / 1  0 . 3 3  8 9 / f p  s y g . 2  0 2 1 . 5 8  5 4 9 3  . P M I D : 3 4 3 5 4 6 2 1 ; P M 
C I D : P M C 8 3 2 9 0 3 7
Andersen, B., Miller, M., & Vervaeke, J. (2022). Predictive processing and relevance realization: explor-
ing convergent solutions to the frame problem. Phenomenology and the Cognitive Sciences.  h t t p s : / / 
d o i . o r g / 1 0 . 1 0 0 7 / s 1 1 0 9 7 - 0 2 2 - 0 9 8 5 0 - 6       
Arnaldo, I., Corcoran, A. W., Friston, K. J., & Ramstead, M. (2022). Stress and its sequelae: An active 
inference account of the etiological pathway from allostatic overload to depression. Neuroscience 
and Biobehavioral Reviews, 135, 104590.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / j .  n e u b i  o r e v . 2  0 2 2 .  1 0 4 5 9 0
Aydin, C., & González Woge, M. (2019). Technological environmentality: conceptualizing technology 
as a mediating milieu. Philosophical Technology, 32, 321–338.  h t t p s : / / d o i . o r g / 1 0 . 1 0 0 7 / s 1 3 3 4 7 - 0 1 
8 - 0 3 0 9 - 3       
Baier, A. (1986). Trust and antitrust. Ethics, 96(2), 231–260.
Barrett, L. F., Quigley, K. S., & Hamilton, P. (2016). An active inference theory of allostasis and interocep-
tion in depression. Philosophical Transactions of the Royal Society of London, 371(1708), 20160011. 
https://doi.org/10.1098/rstb.2016.0011
Berti, A., & Frassinetti, F. (2000). When far becomes near: remapping of space by tool use. Journal of Cog-
nitive Neuroscience, 12(3), 415–420. https://doi.org/10.1162/089892900562237. PMID: 10931768.
1 3
   81  Page 22 of 28
Synthese          (2025) 205:81 
Brenner, S. (2007). Law in an Era of "Smart" Technology.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  9 3 / a c  p r o f :  o s o / 9 7  8 0 1 9  5 3 3 
3 4 8 0 . 0 0 1 . 0 0 0 1.
Bruineberg, J. (2023). Adversarial inference: predictive minds in the attention economy. Neuroscience 
Consciousness. https://doi.org/10.1093/nc/niad019
Bruineberg, J., & Fabry, R. (2022). Extended mind-wandering. Philosophy and the Mind Sciences,  3, 
1–30.
Bruineberg, J., & Rietveld, E. (2014). Self-organization, free energy minimization, and optimal grip on a 
field of affordances. Frontiers in Human Neuroscience. https://doi.org/10.3389/fnhum.2014.00599
Bruineberg, J., Rietveld, E., Parr, T., van Maanen, L., & Friston, K. J. (2018). Free-energy minimization in 
joint agent-environment systems: a niche construction perspective. Journal of Theoretical Biology, 
455, 161–178. https://doi.org/10.1016/j.jtbi.2018.07.002
Bruineberg, J., Dołęga, K., Dewhurst, J., & Baltieri, M. (2022). The emperor’s new markov blankets. 
Behavioral and Brain Sciences, 45, e183. https://doi.org/10.1017/S0140525X21002351
Canepa, E., Djebbara, Z., Güler, K., Andrighetto, L., Schiavetti, Irene, Jelic, Andrea, Condia, & Bob 
(2023). First Impressions: Conscious and Nonconscious Responses to Atmospheric Primes in Archi-
tectural Space. https://doi.org/10.5281/zenodo.8373552
Carter, J. A & Palermos, S. O (2016). The Ethics of Extended Cognition: Is Having your Computer Com-
promised a Personal Assault? Journal of the American Philosophical Association
Chalmers, D. (2008) ‘Foreword’ in Clark, A. Supersizing the Mind: Embodiment, action, and cognitive 
extension. OUP USA.
Chalmers, D. (2019).'Extended Cognition and Extended Consciousness', in Matteo Colombo, Elizabeth 
Irvine, and Mog Stapleton (eds), Andy Clark and His Critics (2019; online edn, Oxford Academic, 
23 May 2019). https://doi -org.sussex .idm.oclc.o rg/ h  t t p s :  / / d o i .  o r g / 1  0 . 1 0  9 3 / o s  o / 9 7 8 0  1 9 0 6 6  2 8 1 3  . 0 0 3 . 
0 0 0 2, accessed 3 Aug. 2023.
Charalambous, E., & Djebbara, Z. (2023). On Natural Attunement: Shared Rhythms Between the Brain 
and the Environment. Neuroscience & Biobehavioral Reviews, 155(105438).  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 
6 / j .  n e u b i  o r e v . 2  0 2 3 .  1 0 5 4 3 8
Chemero, A. (2003). An out line of a theory of affordances. Ecological Psychology, 15, 181–195.  h t t p s : / / d 
o i . o r g / 1 0 . 1 2 0 7 / S 1 5 3 2 6 9 6 9 E C O 1 5 0 2 _ 5       
Cicirelli, G., Marani, R., Petitti, A., Milella, A., & D’Orazio, T. (2021). Ambient assisted living: a review 
of technologies, methodologies and future perspectives for healthy aging of population. Sensors, 
21(10), 3549. https://doi.org/10.3390/s21103549
Clark, A. (2003). Natural-Born Cyborgs: Minds, Technologies, and the Future of Human Intelligence . 
Oxford University Press.
Clark, A. (2005). Thought in a hostile world: the evolution of human cognition. Mind, New Series,  
114(455), 777–782.
Clark, A. (2010). Memento’s Revenge. In R. Menary (Ed.), The Extended Mind (pp. 43–66). MIT Press.
Clark, A. (2013a). Whatever next? Predictive brains, situated agents, and the future of cognitive science. 
Behavioural and Brain Sciences, 36(3), 181–204. https://doi.org/10.1017/S0140525X12000477
Clark, A. (2013b). The many faces of precision (replies to commentaries on whatever next? Neural predic-
tion, situated agents, and the future of cognitive science). Frontiers in Psychology, 4, 270.  h t t p s : / / d o 
i . o r g / 1 0 . 3 3 8 9 / f p s y g . 2 0 1 3 . 0 0 2 7 0       
Clark, A. (2015). Radical predictive processing. Southern Journal of Philosophy, 53(S1), 3–27.
Clark, A. (2016). Surfing Uncertainty: Prediction, Action, and the Embodied mind . Oxford University 
Press.
Clark, A., & Chalmers, D. (1998). The extended mind. Analysis, 58(1), 7–19.
Clark, A. (2008). Supersizing the mind: Embodiment, action, and cognitive extension. OUP USA.
Clark, A. (2012). How to qualify for a cognitive upgrade: Executive control, glass ceilings and the limits 
of simian success. In: McFarland, D., Stenning, K., & McGonigle, M (Eds). The Complex Mind: An 
Interdisciplinary Approach, Springer: 197–222.
Clark, Andy (2017). How to Knit Your Own Markov Blanket. Philosophy and Predictive Processing.
Clark, A. (2019)'Replies to Critics: In Search of the Embodied, Extended, Enactive, Predictive (EEE-P) 
Mind', in Matteo Colombo, Elizabeth Irvine, and Mog Stapleton (eds), Andy Clark and His Critics. 
https://doi -org.sussex .idm.oclc.o rg/ h  t t p s :  / / d o i .  o r g / 1  0 . 1 0  9 3 / o s  o / 9 7 8 0  1 9 0 6 6  2 8 1 3  . 0 0 3 . 0 0 2 0, accessed 
3 Aug. 2023.
Clark, A. (2022). Extending the Predictive Mind. Australasian Journal of Philosophy, 1–12.
1 3
Page 23 of 28    81 
Synthese          (2025) 205:81 
Clowes, R. W. Smart, P. & Heersmink, R (forthcoming). The ethics of the extended mind: Mental privacy, 
manipulation and agency. In B. Beck, O. Friedrich & J. Heinrichs (eds.), Neuroprosthetics: Ethics of 
applied situated cognition.
Clowes, R. (2020) The internet extended person: exoself or doppelganger? Instituto de Filosofia da NOV A 
(IFILNOV A)
Colombetti, G., & Roberts, T. (2015). Extending the extended mind: the case for extended affectivity. 
Philosophical Studies, 172, 1243–1263. https://doi.org/10.1007/s11098-014-0347-3
Constant, A., Ramstead, M. J. D., Veissière, S. P. L., Campbell, J. O., & Friston, K. J. (2018). A variational 
approach to niche construction. Journal of the Royal Society, Interface / the Royal Society .  h t t p s : / / d 
o i . o r g / 1 0 . 1 0 9 8 / r s i f . 2 0 1 7 . 0 6 8 5       
Constant, A., Clark, A., Kirchhoff, M., & Friston, K. J. (2022). Extended active inference: constructing 
predictive cognition beyond skulls. Mind & Language, 37, 373–394.  h t t p s : / / d o i . o r g / 1 0 . 1 1 1 1 / m i l a . 1 
2 3 3 0       
Van de Cruys, S. (2017). Affective Value in the Predictive Mind. In T. Metzinger, & W. Wiese, Philosophy 
and Predictive Processing.
Deane, G., Mago, J., Fotopoulou, A., Sacchet, M. D., Carhart-Harris, R., & Sandved-Smith, L. (2024). The 
computational unconscious: Adaptive narrative control, psychopathology, and subjective well-being. 
https://doi.org/10.31234/osf.io/x7aew
Djebbara, Z., Jensen, O. B., Parada, F. J., & Gramann, K. (2022). Neuroscience and architecture: modulat-
ing behavior through sensorimotor responses to the built environment. Neuroscience and Biobehav-
ioral Reviews, 138, 104715.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / j .  n e u b i  o r e v . 2  0 2 2 .  1 0 4 7 1 5
Dupré, J. (2014). A process ontology for biology. Physiology News, 100, 33–34.
Engstrom, K. V ., & Van Ginneken, E. F. (2022). Ethical prison architecture: a systematic literature review 
of prison design features related to wellbeing. Space and Culture, 25(3), 479–503.
Facchin, M. (2024). Phenomenal transparency, cognitive extension, and predictive processing. Phenom 
Cogn Sci, 23, 305–327. https://doi.org/10.1007/s11097-022-09831-9
Farkas, K. (2012). Two versions of the extended mind thesis. Philosophia, 40, 435–447.  h t t p s : / / d o i . o r g / 1 
0 . 1 0 0 7 / s 1 1 4 0 6 - 0 1 1 - 9 3 5 5 - 0       
Faulkner, P. (2017)'The Problem of Trust', in Paul Faulkner, and Thomas Simpson (eds), The Philosophy 
of Trust (Oxford, 2017; online edn, Oxford Academic, 23 Mar. 2017).  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  9 3 / a c  p r o f 
:  o s o / 9 7  8 0 1 9  8 7 3 2 5 4 9 . 0 0 3 . 0 0 0 7. accessed 14 Feb. 2024.
FitzGerald, T. H., Dolan, R. J., & Friston, K. J. (2014a). Model averaging, optimal inference, and habit 
formation. Frontiers in Human Neuroscience, 8, 457. https://doi.org/10.3389/fnhum.2014.00457
FitzGerald, T. H., Dolan, R. J., & Friston, K. J. (2014b). Model averaging, optimal inference, and habit 
formation. Frontiers Human Neuroscience, 8, 457. https://doi.org/10.3389/fnhum.2014.00457
Foucault, M. (1977). Discipline and punish: The birth of the prison. Pantheon Books.
Friston, K. (2010). The free-energy principle: a unified brain theory? Nature Reviews Neuroscience, 11(2), 
127–138. https://doi.org/10.1038/nrn2787
Friston, K. (2013). Life as we know it. Journal of the Royal Society Interface, 10(86), 20130475.  h t t p s : / / 
d o i . o r g / 1 0 . 1 0 9 8 / r s i f . 2 0 1 3 . 0 4 7 5       
Friston, K. (2018). Am I self-conscious? (or does self-organization entail self-consciousness? Frontiers 
in Psychology, 24(9), 579.  h t t p s :  / / d o i  . o r g / 1  0 . 3 3  8 9 / f p  s y g . 2  0 1 8 . 0 0  5 7 9 .  P M I D : 2 9 7 4 0 3 6 9 ; P M C I D : P M 
C 5 9 2 8 7 4 9
Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., & Doherty, O. (2016). Active inference and 
learning. Neuroscience Biobehavioral Reviews,  2016(68), 862–879.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / j .  n e u b i  
o r e v . 2  0 1 6 .  0 6 . 0 2 2
Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., & Pezzulo, G. (2017). Active inference: a process 
theory. Neural Computation, 29(1), 1–49. https://doi.org/10.1162/NECO_a_00912
Friston, K.J., Ramstead, M.J., Kiefer, A.B., Tschantz, A., Buckley, C.L., Albarracin, M., Pitliya, R.J., 
Heins, C., Klein, B., Millidge, B., Sakthivadivel, D.A., Smithe, T.S., Koudahl, M.T., Tremblay, S.E., 
Petersen, C., Fung, K., Fox, J.G., Swanson, S., Mapes, D.A., & Ren'e, G. (2022). Designing Ecosys-
tems of Intelligence from First Principles. ArXiv, abs/2212.01354.
Gallager, Shaun (ed.), (2005)'Prenoetic Constraints on Perception and Action', How the Body Shapes the 
Mind https://doi.org/10.1093/0199271941.003.0007. Accessed 12 Feb. 2024.
Garfinkel, S. N., Seth, A. K., Barrett, A. B., Suzuki, K., & Critchley, H. D. (2015). Knowing your own 
heart: distinguishing interoceptive accuracy from interoceptive awareness. Biological Psychology, 
104, 65–74.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / j .  b i o p s  y c h o . 2  0 1 4 .  1 1 . 0 0 4
Gibson, J. (1979). The ecological approach to visual perception. Houghton Mifflin.
1 3
   81  Page 24 of 28
Synthese          (2025) 205:81 
Greenwood, J. (2015). Is mind extended or scaffolded? Ruminations on Sterelney’s (2010) extended stom-
ach. Phenomenology and the Cognitive Sciences, 14, 629–650.
Guenin-Carlut, A., & Albarracin, M. (2023, June 1). On Embedded Normativity - An Active Inference 
account of agency beyond flesh. https://doi.org/10.31219/osf.io/7x8cm
Guenin-Carlut, A. White, B. Sganzerla, L (2023); July 24–28. "The Cognitive Archaeology of Sociocul -
tural Lifeforms." Proceedings of the ALIFE 2023: Ghost in the Machine: Proceedings of the 2023 
Artificial Life Conference. ALIFE 2023: Ghost in the Machine: Proceedings of the 2023 Artificial 
Life Conference. Online. (pp. 142). ASME. https://doi.org/10.1162/isal_a_00670
Guidi, J., Lucente, M., Sonino, N., & Fava, G. A. (2021). Allostatic load and its impact on health: a system-
atic review. Psychotherapy and Psychosomatics, 90(1), 11–27. https://doi.org/10.1159/000510696
Hanna, F. J. (1996). Precursors of change: pivotal points of involvement and resistance in psychotherapy. 
Journal of Psychotherapy Integration, 6(3), 227–264. https://doi.org/10.1037/h0101102
Hayes, A. M., & Andrews, L. A. (2020). A complex systems approach to the study of change in psycho -
therapy. BMC Medicine, 18(1), 1–13.
Hayes, A. M., & Yasinski, C. (2015). Pattern destabilization and emotional processing in cognitive therapy 
for personality disorders. Frontiers in Psychology, 6, 107.
Heath, J., & Anderson, J. (2010). Procrastination and the extended will. In C. Andreou & M. D. White 
(Eds.), The Thief of Time (pp. 233–253). Oxford University Press.
Heersmink, R. (2016). The Internet, cognitive enhancement, and the values of cognition. Minds & 
Machines, 26, 389–407. https://doi.org/10.1007/s11023-016-9404-3
Heersmink, R. (2017). Extended mind and cognitive enhancement: Moral aspects of cognitive artifacts. 
Phenomenology and the Cognitive Sciences, 16(1), 17–32.
Heersmink, R. (2020). Varieties of the extended self. Consciousness and Cognition, 85, 103001.
Heft, H. (1989). Affordances and the body: an intentional analysis of Gibson’s ecological approach to 
visual perception. Journal for the Theory of Social Behaviour, 19(1), 1–30.  h t t p s :  / / d o i  . o r g / 1  0 . 1 1  1 1 / j 
.  1 4 6 8 -  5 9 1 4 . 1  9 8 9 .  t b 0 0 1 3 3 . x
Heylen, D. K. J. (2012). Ambient Utopia. In T. Bosse (Ed.), Agents and Ambient Intelligence (pp. 3–16). 
(Ambient Intelligence and Smart Environments; V ol. 12, No. 12). SISWO.  h t t p s : / / d o i . o r g / 1 0 . 3 2 3 3 / 
9 7 8 - 1 - 6 1 4 9 9 - 0 5 0 - 5 - 3       
Hipólito, I., Mago, J., Rosas, F. E., & Carhart-Harris, R. (2023). (2023) Pattern breaking: a complex sys -
tems approach to psychedelic medicine. Neuroscience of Consciousness, 1, niad017.  h t t p s : / / d o i . o r g 
/ 1 0 . 1 0 9 3 / n c / n i a d 0 1 7       
Hipólito‬, I. & White, B. (2023). Smart Environments for Diverse Cognitive Styles: the Case of Autism. 
https://doi.org/10.31234/osf.io/eb48n‬‬‬
Hoff, K. A., & Bashir, M. (2015). Trust in automation: integrating empirical evidence on factors that influ-
ence trust. Human Factors, 57(3), 407–434. https://doi.org/10.1177/0018720814547570
Hohwy, J. (2013). The Predictive Mind. Oxford University Press.
Hohwy, J. (2016). The Self-Evidencing Brain. Noûs, 50(2), 259–285.
Hohwy, Jakob (2017). How to entrain your evil demon. Philosophy and Predictive Processing.
Hollis, M. (1998). Trust Within Reason. Cambridge University Press.
Ingold, T. (2011). Being Alive: Essays on Movement, Knowledge and Description. Routledge.
Joffily, M., & Coricelli, G. (2013). Emotional valence and the free-energy principle. PLoS Computational 
Biology, 9(6), e1003094.
Kiran, A. H. (2010a). Trusting our selves to technology. Know Technology & Policy, 23, 409–427.  h t t p s : / 
/ d o i . o r g / 1 0 . 1 0 0 7 / s 1 2 1 3 0 - 0 1 0 - 9 1 2 3 - 7       
Kiran, A. H. (2010b). Trusting our selves to technology. Know Technology & Policy, 23, 409–427.  h t t p s : / 
/ d o i . o r g / 1 0 . 1 0 0 7 / s 1 2 1 3 0 - 0 1 0 - 9 1 2 3 - 7       
Kirchhoff, M. D. (2015). Extended cognition & the causal-constitutive fallacy: In search for a diachronic 
and dynamical conception of constitution. Philosophy and Phenomenological Research,  90(2), 
320–360.
Kirchhoff, M. D. (2015). Extended cognition & the causal-constitutive fallacy. In search for a diachronic 
and dynamical conception of constitution. Philosophy and Phenomenological Research,  90, 320–
360. https://doi.org/10.1111/phpr.12039
Kirchhoff, M. D., & Kiverstein, J. (2019). Extended Consciousness and Predictive Processing: A Third 
Wave View. Routledge.
Kirchhoff, M., Parr, T., Palacios, E., Friston, K., & Kiverstein, J. (2018). The Markov blankets of life: 
autonomy, active inference and the free energy principle. Journal of the Royal Society Interface,  
15(138), 20170792.
1 3
Page 25 of 28    81 
Synthese          (2025) 205:81 
Kirsh, D., & Maglio, P. (1994). On distinguishing epistemic from pragmatic action. Cognitive Science, 
18(4), 513–549. https://doi.org/10.1207/s15516709cog1804_1
Kirsh, David. (2004). Metacognition, Distributed Cognition and Visual Design. Cognition, Education, and 
Communication Technology (pp.147–180) Lawrence Erlbaum Associates
Kirsh, D, (2019)'When Is a Mind Extended?', in Matteo Colombo, Elizabeth Irvine, and Mog Stapleton 
(eds), Andy Clark and His Critics (2019; online edn, Oxford Academic, 23 May 2019),  h t t p s :  / / d o i  . o r 
g / 1  0 . 1 0  9 3 / o s  o / 9 7 8  0 1 9 0 6 6  2 8 1 3  . 0 0 3 . 0 0 1 1, accessed 5 May 2023
Kiverstein, J., Miller, M., & Rietveld, E. (2020). (2020) How mood tunes prediction: a neurophenomeno-
logical account of mood and its disturbance in major depression. Neurosci Conscious, 1, niaa003. 
https://doi.org/10.1093/nc/niaa003
Koob, G. F., & Le Moal, M. (2001). Drug addiction, dysregulation of reward, and allostasis. Neuropsycho-
pharmacology: Official Publication of the American College of Neuropsychopharmacology,  24(2), 
97–129.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / S 0 8 9 3 - 1 3 3 X ( 0 0 ) 0 0 1 9 5 - 0
Krueger, J., & Szanto, T. (2016). Extended emotions. Philosophy Compass, 11, 863–878.  h t t p s : / / d o i . o r g / 
1 0 . 1 1 1 1 / p h c 3 . 1 2 3 9 0       
Kukkonen, K (2020). Probability Designs: Literature and Predictive Processing. Oup Usa.
Laland, K. N., & Sterelny, K. (2006). Perspective: Seven reasons (not) to neglect niche construction. 
Evolution, 60(9), 1751–1762.
Laland, K. N., Sterelny, K., Odling-Smee, J., Hoppitt, W., & Uller, T. (2011). Cause and effect in biology 
revisited: Is Mayr’s proximate-ultimate dichotomy still useful? Science, 334(6062), 1512–1516.
Laland, K. N., Uller, T., Feldman, M. W., Sterelny, K., Müller, G. B., Moczek, A., Jablonka, E., & Odling-
Smee, J. (2015). The extended evolutionary synthesis: Its structure, assumptions and predictions. 
Proceedings of the Royal Society b: Biological Sciences, 282(1813), 20151019.
Laland, K., Uller, T., Feldman, M., Sterelny, K., Müller, G. B., Moczek, A., Jablonka, E. et al. (2014). 
"Does evolutionary theory need a rethink?." Nature 514, no. 7521 (2014): 161–164.
Lazer, D., Hargittai, E., Freelon, D., et al. (2021). Meaningful measures of human society in the twenty-
first century. Nature, 595, 189–196. https://doi.org/10.1038/s41586-021-03660-7
Lee JD, See KA. Trust in automation: designing for appropriate reliance. Hum Factors. 2004 Spring; 
46(1):50–80. https://doi.org/10.1518/hfes.46.1.50_30392. PMID: 15151155.
Leong, J. (2023). Using Generative AI to Cultivate Positive Emotions and Mindsets for Self-Development 
and Learning. XRDS 29, 3 (Spring 2023), 52–56. https://doi.org/10.1145/3589659
Levy, Neil,' Neuroethics and the Extended Mind', in Judy Illes, and Barbara J. Sahakian (eds), Oxford 
Handbook of Neuroethics, Oxford Library of Psychology (2011; online edn, Oxford Academic, 21 
Nov. 2012),  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  9 3 / o x  f o r d h  b / 9 7 8 0  1 9 9 5  7 0 7 0 6 . 0 1 3 . 0 0 7 1, accessed 12 Feb. 2024.
Lewontin, R. C. (1983). The Organism as the Subject and Object of Evolution. Scientia, 77(18), 65.
Malafouris, L. (2021). Mark making and human becoming. Journal of Archaeological Method and Theory, 
28(1), 95–119.
Manshad, M. S., & Brannon, D. (2021). Haptic-payment: Exploring vibration feedback as a means of 
reducing overspending in mobile payment. Journal of Business Research, 122, 88–96.  h t t p s :  / / d o i  . o r 
g / 1  0 . 1 0  1 6 / j .  j b u s r  e s . 2 0 2  0 . 0 8  . 0 4 9
Mayer, R. C., Davis, J. H., & Schoorman, F. D. (1995). An Integrative Model of Organizational Trust. The 
Academy of Management Review, 20(3), 709–734. https://doi.org/10.2307/258792
McEwen, B. S. (1998). Stress, adaptation, and disease. Allostasis and allostatic load. Annals of the New 
York Academy of Sciences, 840, 33–44.  h t t p s :  / / d o i  . o r g / 1  0 . 1 1  1 1 / j .  1 7 4 9 -  6 6 3 2 . 1  9 9 8 .  t b 0 9 5 4 6 . x
McEwen, B. S., & Wingfield, J. C. (2003). The concept of allostasis in biology and biomedicine. Hor-
mones and Behavior, 43(1), 2–15.  h t t p s :  / / d o i  . o r g / 1  0 . 1 0  1 6 / S 0 0 1 8 - 5 0 6 X ( 0 2 ) 0 0 0 2 4 - 7
Merleau-Ponty M. The Phenomenology of Perception. (Translated by Smith C.) London: Routledge, 
1962/2012.
Miller, M., Kiverstein, J., & Rietveld, E. (2020). Embodying addiction: A predictive processing account. 
Brain and Cognition, 138, 105495. https://doi.org/10.1016/j.bandc.2019.105495
Miller, M., Kiverstein, J., & Rietveld, E. (2022). The Predictive Dynamics of Happiness and Well-Being. 
Emotion Review, 14(1), 15–30. https://doi.org/10.1177/17540739211063851
Montague, E. (2010). Validation of a trust in medical technology instrument. Applied Ergonomics, 41(6), 
812–821. https://doi.org/10.1016/j.apergo.2010.01.009
Nord, C. L., & Garfinkel, S. N. (2022). Interoceptive pathways to understand and treat mental health 
conditions. Trends in Cognitive Sciences, 26(6), 499–513. https://doi.org/10.1016/j.tics.2022.03.004
Norman, D. A. (2013). The design of everyday things. MIT Press.
1 3
   81  Page 26 of 28
Synthese          (2025) 205:81 
Odling-Smee, F. J. (1988). Niche-constructing phenotypes. In H. C. Plotkin (Ed.), The role of behavior in 
evolution (pp. 73–132). The MIT Press.
Orben, A. (2020). The Sisyphean Cycle of Technology Panics. Perspectives on Psychological Science,  
15(5), 1143–1157. https://doi.org/10.1177/1745691620919372
Parr, T., & Friston, K. J. (2017). Uncertainty, epistemics and active inference. Journal of the Royal Society 
Interface, 14(136), 20170376.
Parr, T., Friston, K. J., & Pezzulo, G. (2022). Active inference: The free energy principle in mind, brain, 
and behaviour. MIT Press.
Quadt, L., Garfinkel, S. N., Mulcahy, J. S., Larsson, D. E., Silva, M., Jones, A. M., Strauss, C., & Critch-
ley, H. D. (2021). Interoceptive training to target anxiety in autistic adults (ADIE): A single-center, 
superiority randomized controlled trial. EClinicalMedicine, 39, 101042.  h t t p s : / / d o i . o r g / 1 0 . 1 0 1 6 / j . e c 
l i n m . 2 0 2 1 . 1 0 1 0 4 2       
Rabey, m., & Moloney, N. (2022) “I Don’t Know Why I’ve Got this Pain!” Allostasis as a Possible Explan-
atory Model, Physical Therapy, V olume 102, Issue 5, May 2022, pzac017.  h t t p s : / / d o i . o r g / 1 0 . 1 0 9 3 / 
p t j / p z a c 0 1 7       
Rietveld, E., & Kiverstein, J. (2014). A Rich Landscape of Affordances. Ecological Psychology, 26, 325–
352. https://doi.org/10.1080/10407413.2014.958035
Roberts, T. (2012). You do the maths: Rules, extension, and cognitive responsibility. Philosophical Explo-
rations, 15(2), 133–145. https://doi.org/10.1080/13869795.2012.670724
Ross, D., & Ladyman, J. (2010). ‘The Alleged Coupling-Constitution Fallacy and the Mature Sciences’, 
in Richard Menary (Ed.), The Extended Mind (Cambridge, MA,; online edn, MIT Press Scholarship 
Online, 22 Aug. 2013).  h t t p s :  / / d o i  . o r g / 1  0 . 7 5  5 1 / m i  t p r e s  s / 9 7 8 0  2 6 2 0  1 4 0 3 8 . 0 0 3 . 0 0 0 7, accessed 14 Feb. 
2024.
Schoeller, F., Haar, A. J. H., Jain, A., & Maes, P. (2019). Enhancing human emotions with interoceptive 
technologies. Physics of Life Reviews, 31, 310–319. https://doi.org/10.1016/j.plrev.2019.10.008
Schoeller, F., Miller, M., Salomon, R., & Friston, K. J. (2021). Trust as Extended Control: Human-Machine 
Interactions as Active Inference. Frontiers in Systems Neuroscience, 15, 669810.  h t t p s : / / d o i . o r g / 1 0 . 
3 3 8 9 / f n s y s . 2 0 2 1 . 6 6 9 8 1 0       
Schwartenbeck, P., FitzGerald, T., Dolan, R. J., & Friston, K. (2013). Exploration, novelty, surprise, and 
free energy minimization. Frontiers in Psychology. https://doi.org/10.3389/fpsyg.2013.00710
Shor, D., Ruitenburg, Y ., Boere, W., Lomas, J. D., Huisman, G., & “The Resonance Pod: Applying Haptics 
in a Multi-Sensory Experience to Promote Relaxation Through Breathing Entrainment,”. (2021). 
IEEE World Haptics Conference (WHC). Montreal, QC, Canada, 2021, 1143–1143.  h t t p s :  / / d o i  . o r g / 
1  0 . 1 1  0 9 / W H  C 4 9 1 3  1 . 2 0 2 1  . 9 5 1  7 1 6 5
Slaby, J. (2016). Mind Invasion: Situated Affectivity and the Corporate Life Hack. Frontiers in Psychol-
ogy, 7, 266.
Smart, P. R., Andrada, G., & Clowes, R. W. (2022). Phenomenal transparency and the extended mind. 
Synthese, 200, 335. https://doi.org/10.1007/s11229-022-03824-6
Sprevak, M. (2009). Extended Cognition and Functionalism. Journal of Philosophy, 106(9), 503–527.
Sprevak, M. (2019). Extended Cognition. In The Routledge Encyclopedia of Philosophy. Taylor and Fran-
cis. Retrieved 5 May. 2023, from  h t t p s :  / / w w w  . r e p . r  o u t l  e d g e .  c o m / a  r t i c l e  s / t h  e m a t i  c / e x t  e n d e d -  c o g n  i t i o 
n / v - 1. https://doi.org/10.4324/9780415249126-V049-1
Sterelny, K. (2003). Thought in a Hostile World. Blackwell.
Sterelny, K. (2007). Social intelligence, human intelligence and niche construction. Philosophical Trans-
actions of the Royal Society b: Biological Sciences, 362(1480), 719–730.
Sterelny, K. (2010). Minds: Extended or scaffolded? Phenomenology and the Cognitive Sciences,  9(4), 
465–481.
Sterelny, K. (2013). Constructing the cooperative niche. Entangled life: Organism and environment in the 
biological and social sciences (pp. 261–279). Springer, Netherlands.
Sterelny, K. (2017). Artifacts, symbols, thoughts. Biological Theory, 12(4), 236–247.
Sterelny, K. (2004). Externalism, epistemic artefacts and the extended mind. The externalist challeng. In: 
Schantz, R. (Ed.). The externalist challenge (V ol. 2). Walter de Gruyter. 239–254
Sterelny, K. (2012). The evolved apprentice. MIT press.
Sterelny, K. (2019). The archaeology of the extended mind. Andy Clark and his critics, 143.
Sterling, P., & Eyer, J. (1988). Allostasis: A new paradigm to explain arousal pathology. In S. Fisher & 
J. Reason (Eds.), Handbook of life stress, cognition and health (pp. 629–649). John Wiley & Sons.
Stern, R. (2017). ‘Trust is Basic’: Løgstrup on the Priority of Trust, Robert Stern. The Philosophy of Trust. 
Edited by Paul Faulkner and Thomas Simpson. Oxford University Press.
1 3
Page 27 of 28    81 
Synthese          (2025) 205:81 
Thomley, Amelia & Safron, Adam. (2021). Strengthening the Foundations: An Introduction to the Role of 
Conceptual Metaphor Theory in Art Therapy. https://doi.org/10.31234/osf.io/vyxze.
Thompson, E., & Stapleton, M. (2009). Making Sense of Sense-Making: Reflections on Enactive and 
Extended Mind Theories. Topoi, 28, 23–30. https://doi.org/10.1007/s11245-008-9043-2
van Dijk, L., & Rietveld, E. (2017). Foregrounding sociomaterial practice in our understanding of affor -
dances: The skilled intentionality framework. Frontiers in Psychology.  h t t p s : / / d o i . o r g / 1 0 . 3 3 8 9 / f p s y 
g . 2 0 1 6 . 0 1 9 6 9       
van Es, T., & Kirchhoff, M. D. (2021). Between pebbles and organisms: Weaving autonomy into the Mar-
kov blanket. Synthese, 199, 6623–6644.
Verbeek, P. P. (2009). Ambient intelligence and persuasive technology: The blurring boundaries between 
human and technology. NanoEthics, 3(3), 231–242.
V old, K. (2018). Overcoming deadlock: Scientific and ethical reasons to embrace the extended mind thesis. 
Filozofija I Društvo, 29(4), 489–504.
V old, K. (2020). Can Consciousness Extend? Philosophical Topics, 48(1), 243–264.
Weiser, M. (1993). Some Computer Science Issues in Ubiquitous Computing. Communications of the 
ACM, 36, 75–84. https://doi.org/10.1145/159544.159617
Wheeler, M. (2019). The reappearing tool: Transparency, smart technology, and the extended mind. AI & 
SOCIETY, 34, 857–866. https://doi.org/10.1007/s00146-018-0824-x
Wheeler M (2018) Talking about more than Heads: the Embodied, Embedded and Extended Creative 
Mind. In: Gaut B & Kieran M (eds.) Creativity and Philosophy. London: Routledge, pp. 230–250.  h t t 
p s :   /  / w w  w . r o u t l e d g   e . c  o  m / C r e a  t i v i  t  y -  a  n d - P h  i l o s o   p h y /  G  a u t -  K i  e  r a n / p  / b o o k / 9 7 8 1 1 3 8 8 2 7 6 8 4
White, B. (2024). Techno-Wantons: Adaptive Technology and the Will of Tomorrow. Topoi.  h t t p s : / / d o i . o r 
g / 1 0 . 1 0 0 7 / s 1 1 2 4 5 - 0 2 4 - 1 0 0 9 5 - y       
White, B., & Hipólito, I. (2024). Preventive Mental Health Care: A Complex Systems Framework for Ambi-
ent Smart Environments. Cognitive Systems Research. https://doi.org/10.1016/j.cogsys.2023.101199
White, B., & Miller, M. (2024). Ambient smart environments: Affordances, allostasis, and wellbeing. Syn-
these, 204, 48. https://doi.org/10.1007/s11229-024-04679-9
Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps 
and institutional affiliations.
1 3
   81  Page 28 of 28