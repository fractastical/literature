Fast and Scalable Signal Inference for Active Robotic Source Seeking
Christopher E. Denniston 1,2 Oriana Peltzer3 Joshua Ott3 Sangwoo Moon1 Sung-Kyun Kim1
Gaurav S. Sukhatme 2 Mykel J. Kochenderfer 3 Mac Schwager3 Ali-akbar Agha-mohammadi1
Abstract— In active source seeking, a robot takes repeated
measurements in order to locate a signal source in a cluttered
and unknown environment. A key component of an active
source seeking robot planner is a model that can produce
estimates of the signal at unknown locations with uncertainty
quantiﬁcation. This model allows the robot to plan for future
measurements in the environment. Traditionally, this model has
been in the form of a Gaussian process, which has difﬁculty
scaling and cannot represent obstacles. We propose a global
and local factor graph model for active source seeking, which
allows the model to scale to a large number of measurements
and represent unknown obstacles in the environment. We
combine this model with extensions to a highly scalable planner
to form a system for large-scale active source seeking. We
demonstrate that our approach outperforms baseline methods
in both simulated and real robot experiments.
I. I NTRODUCTION
Prompt and accurate situational awareness is crucial for
ﬁrst responders to emergencies, such as natural disasters
or accidents. Visual information is often unavailable or
insufﬁcient to detect people needing assistance in disaster-
stricken environments. Wireless signals, such as radio, Wi-
Fi, or Bluetooth from mobile devices, can be important in
search and rescue missions. Autonomous exploration and
signal source seeking by a robotic system can signiﬁcantly
improve the situational awareness of the human response
team operating in hazardous and extreme environments. In
active source seeking, a robot not only attempts to get
closer to the predicted source location but also gathers
more information to actively reduce the source localization
uncertainty.
Signal source seeking in large, unknown, obstacle-rich
environments is an important but challenging task. Source
seeking systems typically consist of two components: a
model of the environment that provides a belief over the
signal strength at unknown locations, and a planner which
generates a policy to improve the model and locate the
source. The model of the environment, as well as the planner,
must scale to a large area and a large number of collected
measurements. Models for signal inference typically do not
scale well to large numbers of measurements, relying on ei-
ther approximation or having exponential growth in the time
1 NASA Jet Propulsion Laboratory, Caltech, 2 University of Southern
California, 3 Stanford University. Corresponding Author: cdennist@usc.edu.
Sukhatme holds concurrent appointments as a Professor at USC and as an
Amazon Scholar. This paper describes work not associated with Amazon.
The work is partially supported by the Jet Propulsion Laboratory,
California Institute of Technology, under a contract with the National
Aeronautics and Space Administration (80NM0018D0004), and Defense
Advanced Research Projects Agency (DARPA). ©2022. All rights reserved.
Real Environment
Traversability Map
Local Traversability
Local Signal Belief
Global Traversability
Global Signal Belief
Robot
Fig. 1: Overview of approach. Both the information
roadmap (which models the traversabilty of the environment)
and the signal inference system maintain global and local
representations of the environment. The signal inference
system topology is built from the information roadmap. The
environment is a paved outdoor walkway which can be seen
in the image as well as the traversability map. The local
signal representation maintains both the mean (shown as
colored spheres) as well as the variance (ﬂat squares), both
are shown from blue (low) to red (high).
required for inference [1]–[3]. In the presence of unknown
obstacles, the robot must continually re-plan at a high rate
and adapt the signal model to account for newly discovered
obstacles. The presence of unknown obstacles has complex
impacts on signal propagation and requires the robot have
the ability to re-visit un-visited corridors which potentially
lead to the signal source.
In this work, we formulate the problem of ﬁnding the
highest signal strength as a problem of ﬁnding the location
with the maximum radios signal to noise ratio (SNR). To
ﬁnd this maximum, the robot takes actions which increase
its understanding of the signal while the planner is creating
the next policy for the robot to execute. We formulate this as
an Bayesian informative path planning problem in which the
robot must balance the exploration-exploitation trade off [4].
In order to ﬁnd the signal source, the robot must explore
to better the model of the signal in the environment, while
being driven to the maxima of the signal strength.
To improve understanding of the signal strength, the robot
must be able to estimate both the strength at unknown spatial
locations, as well as the uncertainty in that estimate. This
probabilistic signal model gives the robot the ability to plan
arXiv:2301.02362v2  [cs.RO]  17 Apr 2023
over future measurements to determine which locations to
measure given the information about the signal strength.
To facilitate large-scale active source seeking both the
planner and model of the environment must be highly
scalable. To this end, we have developed a factor-graph
based signal inference model and extended a large-scale
multi-robot planner to handle these challenges. Both the
planner and model maintain global and local representations
of the environment, which allows for decomposition of the
problem. This problem decomposition can be seen in ﬁg. 1,
which shows that both the information roadmap (which
contains traversibility information) and the signal inference
are split into global and local components.
Our contributions are:
• A novel factor graph based model for belief over the
signal strength which scales well with the number of
measurements taken and models the signal propagation
through obstacles,
• An extension to the PLGRIM planner [5] that allows it
to take advantage of our factor-graph model and perform
active source seeking, and
• Demonstration on challenging simulation and real-robot
experiments with real-world signal strength data.
II. B ACKGROUND / RELATED WORK
Active Source seeking is the process of using a robot
to ﬁnd a signal source in an unknown environment. Active
source seeking has been used in locating radiation sources
by representing the environment as voxels [6]. Active source
seeking has also been used to map plumes of unknown
hazardous agents [7]. Gaussian processes have been used
as the model in active source seeking of radio signals by
developing a control law that allows the robot to move
towards the source, while updating the model in an online
fashion [8]. Active source seeking has been extended to the
multi-robot setting by using a particle ﬁlter based model [9].
Informative path planning (IPP) is a process in which
a robot takes measurements of a concentration to maximize
an information metric. Informative path planning can be used
to minimize the uncertainty in the model, such as through
an entropy metric [10]. Informative path planning can also
be combined with Bayesian acquisition funtions to form
sequential Bayesian optimization [4], in which the goal is
to ﬁnd high concentration areas and can be used for active
source seeking. Previously, this formulation has been used in
ﬁnding high concentrations of chlorophyll for studying algae
blooms [2], [11] or ﬁnding the quantiles of a chlorophyll
distribution [12].
Gaussian Processes are non-parametric models with un-
certainty quantiﬁcation which are widely used for IPP [1],
[4], [8], [12], [13]. They approximate an unknown function
from its known outputs by computing the similarity between
points from a kernel function, k, in our case the squared
exponential kernel [3]. Function values y∗ at any input
location x∗ are approximated by a Gaussian distribution:
Y∗|Y ∼ N
(
K∗K−1y, K∗∗−K∗K−1KT
∗
)
where Y is
training output, Y∗ is test output. The kernel matrices K,
K∗, and K∗∗ are computed by evaluating the kernel on
X, the training input, and X∗, the test input, such that
Ki,j = k(xi,xj), Ki,j
∗ = k(xi,xj
∗), and Ki,j
∗∗ = k(xi
∗,xj
∗).
Gaussian processes typically do not have a way to rep-
resent obstacles as the kernel function only relies only on
the distance between the locations in the model. Gaussian
processes tend to scale cubically in the time required for
inference due to the need to compute K−1, and scale linearly
in the time required when adding new measurements as
the kernel function k needs to be computed with the new
measurement and all previous measurements [3].
Ergodic trajectory generation is rooted in the intuition
that a path should spend time in a region proportional to
the amount of expected information in that region [14],
[15]. Ergodic trajectory design was originally presented in
Mathew and Mezi´c [16] where they introduced a norm on the
statistical distance between a trajectory and a reference dis-
tribution allowing problem to be framed as an optimization
problem with the goal of achieving the lowest ergodic score.
Miller [17] introduced a closed-loop ergodic control algo-
rithm for active search problems and Dressel [18] extended
this work to target source localization. Ergodic trajectory
generation does not explicitly quantify the uncertainty in
the surrounding environment but rather plans a trajectory
assuming an information distribution is given. In this work,
we use the uncertainty in the factor graph model to guide
our exploration.
Factor Graphs are a common way to represent estimation
problems for SLAM and other non-linear estimation prob-
lems. A factor graph is a graphical model involving factor
nodes and variable nodes. The variables, or values, represent
the unknown random variables in the estimation problem,
such as robot poses. The factors are probabilistic information
on the variables and represent measurements, such as of the
signal strength, or constraints between values. Performing
inference in a factor graph is done through optimization,
making it suitable for large scale inference problems [19].
Factor graphs have been used for very large-scale SLAM
problems [20] and for estimation of gas concentrations [21].
Factor Graph based Informative Path planning Factor
graphs have been used as a model of a continuous con-
centration by modeling the problem as a Markov random
ﬁeld. This approach has been used to monitor time varying
gas distributions in spaces with obstacles by deﬁning a
factor graph over the entire space with an unknown value
at each cell [21]. It has also been used to jointly estimate
the concentration of gas and the wind direction [22]. These
approaches suffer from a scaling problem due to their ties to
the geometry of the environment and do not handle unknown
environments.
III. F ORMULATION
In informative path planning for active source seeking,
the robot is tasked to localize the source of a radio signal
without any prior map of the environment and within limited
time constraints. We deﬁne the state as s = (q,Ws,Wr)
where q is the robot state, Ws is the signal state (the signal
location) and Wr is the world traversal risk state. The task
is to ﬁnd a policy that maximizes an objective function S
while minimizing its action cost. Typically, the objective S
corresponds to the expected reduction in uncertainty in the
belief over the signal source location Ws. We deﬁne the
reward for taking action a at state s as
R(s,a) =f(S(q′|Ws),C(q,a |Wr)) s.t. q′= T(q,a |Wr)
(1)
where C(q,a | Wr) is the cost of taking action a from
state s and T is the robot state transition function, and
f is a weighted combination of the two terms deﬁned in
PLGRIM [5].
In order to maximize S, the robot must be able to infer
signal strength at unseen locations, given the history of lo-
cations X0:t and measurements Y0:t, as well as hypothetical
future locations and measurements, predicted by the model.
This multiple step look-ahead allows the robot to plan a
policy which is non-myopic and looks ahead to the reward
for complex, multiple step policies. We denote the belief at
time t as Wt
s = M(X0:t,Y0:t) where M is a model of the
belief over the signal strength in the environment. Under this
model, we wish to ﬁnd an optimal policy
π∗= argmax
π∈Π
T∑
t′=t
E[R(bt′,π(bt′))] (2)
where t is the current planning time, bt′ is the belief over
state s at time t′, and T is the robot’s time budget. As the
robot progresses in the mission and updates its world belief,
we re-solve the problem in a receding horizon fashion over
the remaining time interval [t,T].
IV. A PPROACH
In this section, we introduce novel signal belief compo-
nents Wg
s and Wl
s and propose a hierarchical planner for
solving Eq. (2).We decompose the signal, traversibility, and
planning portions into global and local components to allow
our system to scale easily through decomposition.
A. World Traversability Belief
Hierarchical planning frameworks address both space
complexity (due to the large and increasing environment
size) and model uncertainty challenges by breaking down
the environment representation into components of different
scales and resolutions. In PLGRIM [5], the world belief
representation is composed of a meter-level resolution lat-
tice representation of the robot’s local surroundings, termed
Local Information Roadmap (Local IRM), and a topological
graph representing the explored space, called Global Infor-
mation Roadmap (Global IRM). Together, the Local IRMWl
r
and Global IRM Wg
r compose the world traversability belief
Wr. This can be seen in ﬁg. 1 where the local and global
information roadmaps are shown next to a traversability map
of the environment.
B. Signal Belief
In order to facilitate large scale signal inference the model
is split into global and local representations of the signal
Measurement Factor Global Node Link Factor
(a) Global factor graph
Global Node Posterior FactorLocal Node Link Factor (b) Local factor graph
Fig. 2: The signal belief is represented by two factor
graphs, described in section IV-B. (a) The global factor
graph represents the belief over the signal strength at lo-
cations the robot has received measurements, represented as
the values g1,..,g n. (b) The local factor graph is centered at
the robot using the values l1,...,l n to infer the signal locally
around the robot.
Algorithm 1: Add To Global Graph
Add measurement yi at location xi, Given global graph Gg, Current
Estimate Vg, Distance based signal variance function σ2
dist, Measurement
variance σ2
meas, Minimum new global node distance dmin, Global values
gi,gi−1
if ∥xi −xi−1∥>dmin then
fg
link ←N(gi −gi−1 |0,σ2
dist(xi,xi−1)))
fg
meas ←N(gi |yi,σ2
meas))
Gg ←Gg ∪{fg
link,fg
meas}
Vg ←SOLVE (Gg,V g)
over the environment. The local representation in the planner
and model represent local beliefs and plans about the area
immediately surrounding the robot. The global representation
describes the belief about the signal strength at locations the
robot has received measurements. The posterior distributions
over the global signal representation are used as priors in the
local signal representation.
Global Factor Graph (Gg,V g) is seen in ﬁg. 2a where
each value gn ∈Vg is connected to at least one measurement
factor, fmeas ∈Gg. These measurement factors are unary
factors which represent the real world measurements taken
by the robot at the location xn. Each global value is con-
nected to the previous and next global value through a link
factor, fg
link ∈Gg. The link factor connects the previous and
current global values, based on distance traveled, while the
measurement factor connects the global graph to real world
signal measurements. The global graph does not consider
obstacles as the robot only moves a small distance between
global node generation. This link factor, used in both the
global and local factor graphs to connect values which
have a spatial relationship, serves a similar purpose to the
kernel distance in Gaussian processes. This link factor has
an expected mean of 0, with an uncertainty that grows in
proportion to the distance the location corresponding to the
values are apart σ2
dist(xi,xj) = ϵ+ αdist∥xi −xj∥where
ϵ is a small positive number and αdist is an experimentally
determined constant. In order to add new measurements to
the global factor graph, alg. 1 is used, in which a new global
value is created only when the robot has moved sufﬁciently
from the current location. If the robot has not moved far
Algorithm 2: Create Local Graph
Produces a new local graph Gl and local values Vl, given new local
information roadmap IRMl, global graph Gg, global values Vl, global
k-nearest neighbors function KNNg, number of global nodes to link to
kg, and robot location xt
Vl,Gl ←∅,∅
for xi ∈nodes(IRMl) do
Vl ←Vl ∪{vi}
for xj ∈neighbor(xi,IRM l) do
σ2
occ ←σ2
occ(xi) +σ2
occ(xj)
fl
link ←N(li −lj |0,σ2
dist(xi,xj) +σ2
occ)
Gl ←Gl ∪{flink}
for xg ∈KNNg(xt,kg) do
l←CLOSEST (xg,V l)
µ(xg),σ2(xg) ←Vg(xg)
fl
global ←N(l|µ(xg),σ2(xg) +σ2
dist(l,xg)
Gl ←Gl ∪{fl
global}
enough from the current location, the another measurement
factor is added to the previous value.
Local Factor Graph (Gl,V l) is built from the local
information roadmap over the area centered at the robot. The
local information roadmap is an n×mgrid which describes
the area the robot can traverse in the local policy, described in
section IV-A. The local factor graph (ﬁg. 2b) models the local
IRM topology by adding link factors between values l∈Vl
in the local information roadmap which are connected. The
local link factors, fl
link ∈Gl, are similar to the global link
factors as uncertainty increases with the distance between
the spatial locations, but also has the addition of occupancy
information. We assume that if a location corresponding to
a local value is not traversable for the robot, the model
estimate of the signal will have higher uncertainty in that
area due to potential attenuation or reﬂection in the case of
solid obstacles. To model this we increase the uncertainty
proportional to the occupancy probability of that location,
according to σ2
occ(i) =αoccpocc(i), where αocc is an exper-
imentally chosen constant, set to 0.5 in this work. In order
to incorporate the real world measurements into the local
factor graph, we ﬁnd the closest kg locations corresponding
to values in the global factor graph to the robot location. For
each location that is close to the robot location, we add a
factor, fl
global ∈Gl, to the closest local value which uses
the posterior estimate from the global value as well as the
distance between the local and global locations. We assume
the distance is small and do not consider obstacles between
the global and local nodes. The algorithm for this can be
seen in alg. 2, which describes how both the local graph and
local values are constructed.
Inference In order for the planner to do active source
seeking, the signal belief must be able to efﬁciently infer
a distribution over the signal at unknown spatial locations.
The model must also support the ability to condition the
model on locations and measurements the robot plans to
take, but has not taken yet, termed hypothetical locations
Xh and hypothetical values Yh. This allows the planner to
make non-myopic plans in which the future values take into
Algorithm 3: Inference at locations
Produces a belief over signal at location xq given hypothetical future
locations Xh and measurements Yh, initially empty local value cache C,
local graph Gl and local values Vl.
if Xh ∈C then
return C(Xh,xq)
Gl
h = Gl
for (x,y) ∈(Xh,Yh) do
l←CLOSEST (x,V l)
µ(l),σ2(l) ←Vl(l)
Gl
h ←Gl
h ∪{N(l|y,σ2
i )}
Vl
h ←SOLVE (Gl
h,V l)
C(Xh) =Vl
h
return Vl
h(xq)
account measurements that will be taken in the policy [4]. To
this end, alg. 3 describes the algorithm to infer the posterior
belief at a spatial location xq. Typically, the graph cannot
be re-solved with every query so the algorithm determines
if it has already computed the local values given the current
hypothetical locations Xh by checking if it is in the cache C.
The cache C allows the re-use of previously solved values as
the posterior distribution over xq has already been computed
when computing a different query location. C is emptied
when a new local IRM is received due to the robot moving, or
a new measurement is added to the global graph. If algorithm
cannot use the cached values, the algorithm adds unary
factors representing the conditioning on the hypothetical
measurements, using the previous prior uncertainty for the
unary factor. The algorithm then re-solves the factor graph
for the entire local information roadmap and adds the newly
solved factors to the cache. This cache is emptied each time
a new local factor graph is constructed.
To produce a belief over locations that are not in the local
information roadmap, query locations are added to the global
roadmap with distance based link factors and the resulting
graph is solved.
C. Hierarchical Solver
Our approach is to compute a local planning policy that
solves eq. (2) on Wl
r and Wl
s over a receding horizon tl,
which we refer to as Local Planning, while simultaneously
solving eq. (2) over the full approximate world representation
Wg
r and Wg
s, which we refer to as Global Planning.
Local Policy In Receding Horizon Planning (RHP), the
objective function in Eq. (2) is modiﬁed:
π∗
t:t+T(b) = argmax
π
E
[t+tl∑
t′=t
γt′−tR(bt′,πt′(bt′))
]
(3)
where tl is a ﬁnite planning horizon for a planning episode at
time t. The expected value is taken over future measurements
and the reward is discounted by γ [23].
For the local policy, the reward is based on the current
signal belief and uses the upper conﬁdence bound (UCB)
acquisition function, which is commonly used for informa-
tive path planning for Bayesian optimization [4]. The UCB
equation is Sl(xi) =µ(xi)+ βσ2(xi) where µ(x) and σ2(x)
are the current mean and variance of Ws at location xi and
β is an empirically determined weight. We use this objective
function for local exploration as the robot should investigate
areas that the model is uncertain about, but should still prefer
high concentration areas. In our experiments we set β = 3
to encourage exploration.
Global Policy Boundaries in between explored and unex-
plored space, termed frontiers, are encoded in the topological
graph of the environment (Global IRM) and represent goal
waypoints. By visiting frontiers, the robot takes new signal
measurements and uncovers swaths of the unexplored en-
vironment. The robot must plan a sequence of frontiers p
that it can reach within the time budget that maximizes its
expected reward Sg. Equation (2) becomes
π⋆ = argmax
p
∑
n∈p
F
(
tp(n); Wg
r) ·Sg(
n; Wg
s) (4)
where tp(n) is the time required to reach frontier n
through p, F is the front-loading function proposed in
[24], and where p should verify the time budget constraint.
F
(
tp(n); Wg
r) is a greedy incentive that encourages gath-
ering reward earlier in time in order to trade off long-term
ﬁnite-horizon planning with immediate information gain.
We wish to maximize the expected improvement (EI) for
signal measurement taken at a frontier ni (corresponding to
location xi), given current signal belief Wg
s. EI favors actions
that offer the best improvement over the current maximal
value, with an added exploration term ξto encourage diverse
exploration. The EI objective function is deﬁned according
to Sg(xi) = IΦ(Z) + σ(xi)φ(Z) where Z = I
σ2(xi) ,
I = µ(xi) −max(µ(X0:t)) −ξ, and Φ and φ are the
CDF and PDF of the normal distribution, respectively [25],
[26]. Expected improvement is chosen as the global objective
function because the robot should prefer frontiers which
have a gain in the expected signal strength, while during
local exploration the robot should seek out information rich
locations rather than only seeking the maxima.
Policy Selection The local planning policy πl provides
immediate signal reward, and is computed over the local
space immediately surrounding the robot, while the global
policy πg is computed over a sparse representation of the
entire environment the robot has explored so far. Therefore,
the global policy has the potential to bring the robot to
valuable locations it has not yet explored, but may also
require more travel time. As in [27], we select the planning
policy π according to its utility U(bt; π) computed from
eq. (2) and the probability ˆP(π) that the plan will be
successfully executed:
π⋆
t = arg max
π∈{πg
t:t+T ,πℓ
t:t+tl
}
ˆP(π)U(bt; π). (5)
V. E XPERIMENTS
We demonstrate our system on two simulation environ-
ments as well as a hardware trial. The simulated envi-
ronments were collected in a parking garage with a robot
with an attached radio and a radio placed in the envi-
ronment. In the simulation environments, we ﬁrst run the
robot in a lawnmower path to collect signal strength data
and traversibility data in the environment. We position the
Fig. 3: Maps of the Signal to Noise Ratio collected in
a real parking garage. SNR is colored from blue (low)
to yellow (high). Areas in white are not traversable by the
robot.
0 200 400 600
Time (s)
0
20
40
60Maximum SNR Measured
Radio A
Method
Factor Graph
GP
GP (Limited)
0 200 400 600
Time (s)
0
10000
20000
30000
40000Sum of SNR Measurements
Radio A
0 200 400 600
Time (s)
20
30
40
50Maximum SNR Measured
Radio B
0 200 400 600
Time (s)
0
20000
40000
60000
80000Sum of SNR Measurements
Radio B
Fig. 4: Simulation experiment results over two real-world
environments. Left: the maximal signal reading up until time
t. Right: the sum of the measurements taken until time t.
radio in two different locations (ﬁg. 3). Location A is less
accessible, so that stronger readings are only seen in direct
line of sight, in location B the radio is placed so that it is
within line of sight of more areas of the environment. The
robot starts in the same location in both environments, and
the traversability is the same in both environment.
In the experiments we compare our approach (labeled Fac-
tor graph) with a standard Gaussian process using a squared
exponential kernel. The kernel hyper-parameters are set to
a length scale of 3 and an observation noise of 0.01. This
Gaussian process also only adds new measurements when
the robot has moved a minimum distance ( dmin), which was
set to 0.25min our experiments. We also compare against a
Gaussian process (GP) which is limited during inference to
the same number of measurements ( kg) during inference as
the Factor graph, which we term Gaussian process (limited),
(GP (limited)). This limited Gaussian process is added to
show that the performance of our system is not merely due to
limiting the number of measurements included in the model.
For the factor graph, we set the measurement noise to 0.01,
αocc to 0.5, and αdist to 0.1.
A. Simulation Experiments
We compare our novel Factor graph approach with the two
baseline approaches (Gaussian Process and Gaussian process
(limited)) in both environments (location A and location B).
To compare against the baselines, we show two metrics for
each environment (ﬁg. 4). The ﬁrst shows the maximal SNR
measurement recorded up until time t. It compares how
closely the robot approaches the signal source, and how
quickly it approaches the signal source. The second metric is
the cumulative sum of the SNR measurements the robot has
taken until time t. This metric, inspired by the cumulative
reward metric [4], shows how the robot makes decisions to
ﬁnd maximal areas over time. For each environment, we run
the robot three times and report each trial.
As can be seen in ﬁg. 4, the factor graph model allows
the robot to ﬁnd a much higher signal strength in 2 out of
3 trials, and the performance is more consistent. Limiting
the Gaussian process to only 200 measurements does not
have a big impact on the performance compared to the
regular Gaussian process, but it still does not perform as
well as the factor graph model. In the comparison of the
cumulative signal measurement the factor graph outperforms
the other methods in all 3 trials, with the other two methods
performing about as well. This implies the factor graph
consistently allows the planner to make better decisions
through the entire experiment.
We also present a study of the scalabilty of the approaches,
shown in ﬁg. 5. We ﬁnd that the Gaussian process has
the typical exponential scaling with in the time required
for inference as the number of measurements in the model
grows. We also ﬁnd that even limiting the Gaussian process
to a ﬁxed number of measurements per inference is still is
more expensive than the factor graph on average. The factor
graph has a bimodal distribution in its performance, when
the graph has to be re-solved it is slower than the Gaussian
process methods, but due to its ability to cache the model
posterior, most of the inference is a hash table lookup.
We believe the consistent performance of the factor graph
is due to to two reasons. The ﬁrst is that the factor graph is
generally faster for inference than Gaussian process methods,
allowing the planner to plan at a higher frequency. The
second reason is the ability of the factor graph to represent
uncertainty in the signal due to obstacles. This allows the
factor graph model to infer that signal strengths on the
opposite side of obstacles and around corners are more
interesting as the signal uncertainty increases through the
obstacle.
B. Hardware Experiments
We demonstrate our system on a real robot locating a radio
in an unknown environment. The robot, a Boston Dynamics
Spot [28] equipped with custom sensing and computing
systems [29]–[31], is initially started at one end of a parking
garage. The radio is deployed at another end of the hallway
after two lefthand turns. We use the factor graph model as
with kg equal to 100 due to the fact that the computer payload
on the robot is limited. As can be seen in ﬁg. 6, the robot
explores an open passage before going directly to the source
of the radio. We ﬁnd that our system is able to be easily
tuned to the computational limits of the robot and efﬁciently
0 200 400
Number of Measurements
0.00
0.02
0.04
0.06Solve Time (s)
Binned
Name
Factor Graph
GP
GP (Limited)
Fig. 5: Comparison of time required to perform inference
for the three models over the number of measurements
in the model. Left: the data binned data with the standard
deviation, Right: the raw data.
Fig. 6: Experiment of our system on a real Spot robot. The
robot explores a man made structure to ﬁnd the radio. The
collected measurements, colored from blue (low) to yellow
(high), as well as the robot’s trajectory are shown. Black dots
show the non-traversable areas such as walls.
ﬁnds the signal source. As with ﬁg. 5 we found that the
robot does not increase its planning time drastically when
more measurements are added to the model.
VI. C ONCLUSION
Large scale active source seeking using a robot is a com-
plex and challenging task which requires the ability to scale
the planner and model. In this work we have demonstrated
the ability of our factor graph based model to decompose
the problem into local and global tasks which allows the
model to scale easily with a large number of measurements.
We have also demonstrated the model’s ability to handle
the propagation of signals through unknown obstacles by
modeling the explicit uncertainty due to these obstacles.
Through simulation experiments we have shown that the
ability to plan rapidly due to the inference speed of the
model as well as the ability to represent signal uncertainty
due to obstacles allow our overall system to perform active
source seeking better than the baseline methods. We have
also shown the ability of our model to be scaled to the
computational needs of a real life robot and demonstrated
our system in a real life unknown environment.
Robot Trajectory
Starting Location
Radio Location
15 m
Fig. 7: Experiment of our system on a real Spot robot in
extended ﬁeld conditions. Top: The robot explores a man
made structure to ﬁnd the radio. The collected measurements,
colored from blue (low) to yellow (high), as well as the
robot’s trajectory are shown. Black dots show the non-
traversable areas such as walls and cars. Bottom: Spot robot
platform used in this experiment and the experiment in
section V-B.
VII. A PPENDIX
A. Extended Hardware Experiment
We present an extended study of the performance of our
system in the ﬁeld. The setup is similar to section V-B,
including robot platform. The robotic platform is limited not
only in computational power, but also further limited due
to the multiple other systems which must run in parallel on
the robot to allow for localization, control, and high level
mission objectives. To allow for rapid re-planning, we sub-
sample the local factor graph, discarding every other node.
The environment is a parking garage with the target source
placed outside of the garage.
As can be seen in ﬁg. 7, the robot exits the ﬁrst corridor,
attempts to go down the second corridor but discovers that
it cannot directly go to the source in that corridor. It then
exits the second corridor, attempting to discover an unseen
passage, then goes to the third corridor to go directly to the
source.
This demonstrate the ability of our system to guide the
robot to the signal source in the presence of limited compu-
tation and difﬁcult real-world environments.
REFERENCES
[1] S. Kemna, J. G. Rogers, C. Nieto-Granda, S. Young, and G. S.
Sukhatme, “Multi-robot coordination through dynamic voronoi par-
titioning for informative adaptive sampling in communication-
constrained environments,” in IEEE International Conference on
Robotics and Automation (ICRA) , 2017, pp. 2124–2130.
[2] S. McCammon, G. Marcon dos Santos, M. Frantz, T. P. Welch, G.
Best, R. K. Shearman, J. D. Nash, J. A. Barth, J. A. Adams, and
G. A. Hollinger, “Ocean front detection and tracking using a team of
heterogeneous marine vehicles,” Journal of Field Robotics , vol. 38,
no. 6, pp. 854–881, 2021. eprint: https://onlinelibrary.
wiley.com/doi/pdf/10.1002/rob.22014.
[3] C. E. Rasmussen and C. K. I. Williams, Gaussian Processes for
Machine Learning. MIT press, 2006.
[4] R. Marchant, F. Ramos, and S. Sanner, “Sequential Bayesian op-
timisation for spatial-temporal monitoring,” in Conference on Un-
certainty in Artiﬁcial Intelligence (UAI) , ser. UAI’14, Arlington,
Virginia, USA: AUAI Press, Jul. 2014, pp. 553–562.
[5] S.-K. Kim *, A. Bouman *, G. Salhotra, D. D. Fan, K. Otsu, J.
Burdick, and A.-a. Agha-mohammadi, “PLGRIM: Hierarchical value
learning for large-scale exploration in unknown environments,” in
International Conference on Automated Planning and Scheduling
(ICAPS), vol. 31, 2021, pp. 652–662.
[6] F. Mascarich, T. Wilson, C. Papachristos, and K. Alexis, “Radiation
source localization in gps-denied environments using aerial robots,”
in IEEE International Conference on Robotics and Automation
(ICRA), Brisbane, Australia: IEEE Press, 2018, pp. 6537–6544.
[7] Y . Sung and P. Tokekar, “A competitive algorithm for online multi-
robot exploration of a translating plume,” in 2019 International Con-
ference on Robotics and Automation (ICRA) , 2019, pp. 3391–3397.
[8] J. Fink and V . Kumar, “Online methods for radio signal mapping
with mobile robots,” in IEEE International Conference on Robotics
and Automation (ICRA) , 2010, pp. 1940–1945.
[9] B. Charrow, N. Michael, and V . R. Kumar, “Cooperative multi-robot
estimation and control for radio source localization,” International
Journal of Robotics Research , vol. 33, pp. 569–580, 2012.
[10] C. Guestrin, A. Krause, and A. P. Singh, “Near-Optimal Sensor
Placements in Gaussian Processes,” Tech. Rep., 2005.
[11] T. O. Fossum, J. Eidsvik, I. Ellingsen, M. O. Alver, G. M. Fragoso,
G. Johnsen, R. Mendes, M. Ludvigsen, and K. Rajan, “Information-
driven robotic sampling in the coastal ocean,” Journal of Field
Robotics, vol. 35, no. 7, pp. 1101–1121, 2018. eprint: https :
//onlinelibrary.wiley.com/doi/pdf/10.1002/rob.
21805.
[12] I. M. Rayas Fern ´andez, C. E. Denniston, D. A. Caron, and G. S.
Sukhatme, “Informative path planning to estimate quantiles for
environmental analysis,” IEEE Robotics and Automation Letters ,
vol. 7, no. 4, pp. 10 280–10 287, 2022.
[13] G. Salhotra, C. E. Denniston, D. A. Caron, and G. S. Sukhatme,
“Adaptive sampling using pomdps with domain-speciﬁc considera-
tions,” in IEEE International Conference on Robotics and Automa-
tion (ICRA), 2021, pp. 2385–2391.
[14] L. Dressel and M. J. Kochenderfer, “Efﬁcient decision-theoretic tar-
get localization,” inInternational Conference on Automated Planning
and Scheduling (ICAPS) , 2017.
[15] L. K. Dressel and M. J. Kochenderfer, “On the optimality of ergodic
trajectories for information gathering tasks,” in American Control
Conference (ACC), IEEE, 2018, pp. 1855–1861.
[16] G. Mathew and I. Mezi ´c, “Metrics for ergodicity and design of
ergodic dynamics for multi-agent systems,” Physica D: Nonlinear
Phenomena, vol. 240, no. 4-5, pp. 432–442, 2011.
[17] L. Miller, “Optimal ergodic control for active search and information
acquisition,” Ph.D. dissertation, Northwestern University, 2015.
[18] L. K. Dressel, Efﬁcient and Low-cost Localization of Radio Sources
with an Autonomous Drone . Stanford University, 2018.
[19] F. Dellaert, “Factor Graphs and GTSAM: A Hands-on Introduction,”
Tech. Rep., 2012.
[20] Y . Chang, K. Ebadi, C. E. Denniston, M. F. Ginting, A. Rosinol,
A. Reinke, M. Palieri, J. Shi, A. Chatterjee, B. Morrell, A.-a. Agha-
mohammadi, and L. Carlone, “Lamp 2.0: A robust multi-robot
slam system for operation in challenging large-scale underground
environments,” IEEE Robotics and Automation Letters , vol. 7, no. 4,
pp. 9175–9182, 2022.
[21] J. G. Monroy, J.-L. Blanco, and J. Gonzalez-Jimenez, “Time-variant
gas distribution mapping with obstacle information,” en, Autonomous
Robots, vol. 40, no. 1, pp. 1–16, Jan. 2016.
[22] A. Gongora, J. Monroy, and J. Gonzalez-Jimenez, “Joint estimation
of gas and wind maps for fast-response applications,” Applied
Mathematical Modelling, vol. 87, pp. 655–674, 2020.
[23] A. Bouman, J. Ott, S.-K. Kim, K. Chen, M. J. Kochenderfer, B.
Lopez, A.-a. Agha-mohammadi, and J. Burdick, “Adaptive coverage
path planning for efﬁcient exploration of unknown environments,” in
IROS, 2022.
[24] O. Peltzer, A. Bouman, S.-K. Kim, R. Senanayake, J. Ott, H.
Delecki, M. Sobue, M. Kochenderfer, M. Schwager, J. Burdick, and
A.-a. Agha-mohammadi, “FIG-OP: Exploring Large-Scale Unknown
Environments on a Fixed Time Budget,” in IROS, 2022.
[25] D. R. Jones, M. Schonlau, and W. J. Welch, “Efﬁcient Global
Optimization of Expensive Black-Box Functions,” Journal of Global
Optimization, 1998.
[26] C. Qin, D. Klabjan, and D. Russo, “Improving the expected im-
provement algorithm,” in NeurIPS, Long Beach, California, USA,
2017.
[27] J. Ott, S.-K. Kim, A. Bouman, O. Peltzer, M. Sobue, H. Delecki,
M. J. Kochenderfer, J. Burdick, and A.-a. Agha-mohammadi, Risk-
aware meta-level decision making for exploration under uncertainty ,
2022. arXiv: 2209.05580.
[28] Spot® - The Agile Mobile Robot , en, https : / / www .
bostondynamics.com/products/spot.
[29] A. Agha, K. Otsu, B. Morrell, D. D. Fan, R. Thakker, A. Santamaria-
Navarro, S.-K. Kim, A. Bouman, X. Lei, J. Edlund, M. F. Ginting, K.
Ebadi, M. Anderson, T. Pailevanian, E. Terry, M. Wolf, A. Tagliabue,
T. S. Vaquero, M. Palieri, S. Tepsuporn, Y . Chang, A. Kalantari, F.
Chavez, B. Lopez, N. Funabiki, G. Miles, T. Touma, A. Buscicchio,
J. Tordesillas, N. Alatur, J. Nash, W. Walsh, S. Jung, H. Lee, C.
Kanellakis, J. Mayo, S. Harper, M. Kaufmann, A. Dixit, G. Correa,
C. Lee, J. Gao, G. Merewether, J. Maldonado-Contreras, G. Salhotra,
M. S. Da Silva, B. Ramtoula, Y . Kubo, S. Fakoorian, A. Hatteland,
T. Kim, T. Bartlett, A. Stephens, L. Kim, C. Bergh, E. Heiden, T.
Lew, A. Cauligi, T. Heywood, A. Kramer, H. A. Leopold, C. Choi,
S. Daftry, O. Toupet, I. Wee, A. Thakur, M. Feras, G. Beltrame,
G. Nikolakopoulos, D. Shim, L. Carlone, and J. Burdick, “Nebula:
Quest for robotic autonomy in challenging environments; team costar
at the darpa subterranean challenge,”Journal of Field Robotics, 2021.
[30] K. Otsu, S. Tepsuporn, R. Thakker, T. S. Vaquero, J. A. Edlund, W.
Walsh, G. Miles, T. Heywood, M. T. Wolf, and A. Agha-mohammadi,
“Supervised autonomy for communication-degraded subterranean
exploration by a robot team,” in IEEE Aerospace Conference, 2020.
[31] A. Bouman ∗, M. Ginting ∗, N. Alatur ∗, M. Palieri, D. Fan, T.
Touma, T. Pailevanian, S. Kim, K. Otsu, J. Burdick, and A.
Agha-Mohammadi, “Autonomous Spot: Long-Range Autonomous
Exploration of Extreme Environments with Legged Locomotion,”
in IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS), 2020.