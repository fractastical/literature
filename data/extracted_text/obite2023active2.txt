Active Inference for Sum Rate Maximization in
UA V-Assisted Cognitive NOMA Networks
Felix Obite1,2, Ali Krayani 1, Atm S. Alam 2, Lucio Marcenaro 1, Arumugam Nallanathan 2, Carlo Regazzoni 1
1DITEN, University of Genova, Italy
2EECS, Queen Mary University of London, United Kingdom
emails:felix.obite@edu.unige.it, ali.krayani@ieee.org, {lucio.marcenaro, carlo.regazzoni}@unige.it, {a.alam, a.nallanathan}@qmul.ac.uk
Abstractâ€”Given the surge in wireless data traffic driven by
the emerging Internet of Things (IoT), unmanned aerial vehi-
cles (UA Vs), cognitive radio (CR), and non-orthogonal multiple
access (NOMA) have been recognized as promising techniques
to overcome massive connectivity issues. As a result, there is
an increasing need to intelligently improve the channel capacity
of future wireless networks. Motivated by active inference from
cognitive neuroscience, this paper investigates joint subchannel
and power allocation for an uplink UA V-assisted cognitive NOMA
network. Maximizing the sum rate is often a highly challenging
optimization problem due to dynamic network conditions and
power constraints. To address this challenge, we propose an
active inference-based algorithm. We transform the sum rate
maximization problem into abnormality minimization by utilizing
a generalized state-space model to characterize the time-changing
network environment. The problem is then solved using an Active
Generalized Dynamic Bayesian Network (Active-GDBN). The
proposed framework consists of an offline perception stage, in
which a UA V employs a hierarchical GDBN structure to learn an
optimal generative model of discrete subchannels and continuous
power allocation. In the online active inference stage, the UA V
dynamically selects discrete subchannels and continuous power
to maximize the sum rate of secondary users. By leveraging the
errors in each episode, the UA V can adapt its resource allocation
policies and belief updating to improve its performance over
time. Simulation results demonstrate the effectiveness of our
proposed algorithm in terms of cumulative sum rate compared
to benchmark schemes.
Index Termsâ€”Active Inference, UA V , NOMA, Cognitive Radio.
I. I NTRODUCTION
The present and emerging wireless technologies, such as
6G, are expected to experience an increase in data intensity.
There is a growing expectation to connect a larger number of
self-autonomous devices and Internet of Things (IoT) devices,
putting pressure on the existing wireless network [1]. To
address these demands, future wireless systems need to incor-
porate innovative technologies like unmanned aerial vehicles
(UA Vs), cognitive radio (CR), and non-orthogonal multiple
access (NOMA). The integration of these technologies requires
intelligent resource allocation to improve system performance.
UA Vs have gained significant attention in wireless communi-
cations due to their advantageous line-of-sight (LoS) commu-
nication, cost-effectiveness, miniaturization, and flexibility [2].
CR serves as the main technology that enables secondary users
(SUs) to utilize licensed spectrum when available without
causing interference to primary users (PUs) [3]. Conversely,
there has been a shift towards NOMA as an alternative to
orthogonal multiple access (OMA) to overcome its limitations.
NOMA has demonstrated superior spectrum efficiency, user
fairness, and the ability to accommodate multiple users simul-
taneously in the same sub-channel by employing superposition
coding (SC) at the transmitter and successive interference
cancellation (SIC) at the receiver [4].
However, in order to fully harness the promised benefits of
NOMA, a key challenge lies in jointly optimizing discrete
subchannels and continuous power to maximize the sum
rate in such a dynamic system. Additionally, it has been
established that the problem of maximizing the sum rate in
wireless networks is strongly NP-hard [5]. Hence, numerous
suboptimal or heuristic approaches have been proposed by
researchers. The authors in [6] explore heuristic and iterative
search optimization methods for user pairing and resource
allocation in the uplink NOMA scenario. In [7], the authors
investigate the stochastic successive convex approximation
method to maximize the sum rate of users under imperfect
channel state conditions. In [8], an upper bound is derived
for the optimal weighted sum rate, and the authors propose a
near-optimal approach using Lagrangian duality and dynamic
programming. For a comprehensive review of conventional
optimization approaches, we refer the readers to [9]. It is
important to note that these traditional optimization schemes
lack adaptive online self-awareness and often involve complex
mathematical formulations, making them impractical for real-
time systems that require minimal latency.
In recent years, machine learning techniques have demon-
strated significant potential in addressing complex compu-
tational tasks and have been widely implemented in var-
ious wireless communication systems [10]. However, deep
learning methods require well-labeled datasets for training
in order to achieve accurate results. Obtaining such datasets
can be challenging in complex wireless networks, and the
resulting models may be difficult to interpret [11]. Likewise,
in [9], deep reinforcement learning (Deep RL) is employed
to maximize the sum rate, power allocation, and channel
assignment in a multi-carrier NOMA scheme. Nevertheless,
despite the recent successes of RL, several limitations hinder
its full implementation in dynamic systems [12]. Firstly, RL
algorithms often require numerous iterations to converge to
an optimal solution due to the strong influence of negative
rewards [13], [14]. An RL agent must take several bad actions
arXiv:2309.11263v1  [eess.SP]  20 Sep 2023
in order to learn how to improve its policy. Additionally,
RL agents are typically trained for specific predefined tasks,
which limits their ability to generalize to new experiences.
Generalizing to new experiences necessitates retraining or
modifying the agent, or incorporating meta-learning capabili-
ties [15]. An alternative approach widely studied and rooted
in neurocognitive science, called active inference, provides a
fundamental framework for characterizing adaptive behaviors
in unknown and complex environments [13], [16]. In this
framework, every agent (considered a self-organizing system)
maintains a dynamic equilibrium with its external environment
to minimize prediction errors [17]. Preliminary results suggest
that active inference is more adaptable and resilient in a variety
of settings that are challenging for RL models [18].
We also observe that the majority of active inference
agents are trained to learn generative models with predefined
sections of the state space [13], [19]. While this approach
is suitable for discrete state spaces, it becomes impractical
for complex dynamic systems [20]. In this paper, we explore
active inference using a unique generalized dynamic Bayesian
network (Active-GDBN) to learn the complex, time-changing
network environment. The key contributions of this study are
summarized as follows:
â€¢ We have developed and implemented an active inference-
based algorithm called Active-GDBN to address the sum
rate maximization problem in a UA V-assisted cognitive
NOMA network. In this algorithm, the UA V is equipped
with a generative model that is learned offline, capturing
the dynamic rules that generate preferred observations
(i.e., optimal superimposed signals). This learned knowl-
edge serves as a prior target when the UA V becomes
active during the online deployment process. We describe
how the UA V dynamically learns both discrete subchan-
nels and a continuous power allocation policy online to
minimize prediction errors or abnormalities.
â€¢ We formulate the problem of maximizing the sum rate
as a challenge of minimizing abnormalities, employing
a generalized state-space formulation to capture the tem-
poral dynamics of the radio environment. Unlike most
existing papers, which discretize power allocation, our
proposed framework optimizes continuous power. Dis-
cretizing power allocation introduces quantization errors
and increases computational complexity [21]. Addition-
ally, our algorithm is explainable because it estimates and
represents the dynamic causal structure of the training
environment at both discrete and continuous states.
â€¢ The numerical findings using simulated data provide
evidence of the efficiency of our proposed algorithm
in achieving a higher cumulative sum rate compared to
benchmark schemes.
The remainder of this paper is organized as follows: Section
II describes the system model and problem formulation. The
proposed method for joint sub-channel and power allocation is
described in Section III. The simulation results and discussion
are presented in Section IV. Section V concludes the paper.
II. S YSTEM MODEL AND PROBLEM FORMULATION
As illustrated in Fig. 1, we examine a multi-channel uplink
Cognitive-NOMA system that encompasses a primary network
(PN) and a secondary network (SN), with a UA V positioned
centrally and hovering above randomly moving secondary
users (SUs). In practice, a single and hovering UA V could
be used to provide communication services to emergency
responders in the event of a disaster. This could be used
to coordinate the response, communicate with victims, or
provide medical assistance. The PN consists of a primary
base station (PBS) that serves primary users (PUs) over the
primary channels in a time-slotted manner. The SN consists
of a UA V that assists the PBS and serves a set of SUs. Let
N denote the set of SUs and K represent the number of sub-
channels in the network, expressed as N = {1, 2, Â·Â·Â· , N} and
K = {1, 2, Â·Â·Â· , K}, respectively. We assume non-interference
among the different sub-channels due to the orthogonality
provided by frequency division.
In the uplink, each SU n transmits its signal to the UA V
on subchannel k with assigned transmit power pk
n and channel
gain gk
n. By using QPSK modulation, the system can maintain
a certain level of performance and minimize the impact of in-
terference compared to higher-order modulation schemes. This
is particularly important in scenarios with multiple NOMA
users, where the signals from different users may interfere
with each other. Let Uk â‰œ {n âˆˆ N: pk
n > 0} denote the
set of SUs that are multiplexed on sub-channel k and |Uk|
represents the cardinality of that set. In each transmission
time slot, the channel of a specific SU remains constant but
changes independently in each period or episode. The UA V ,
equipped with Active-GDBN, can continuously update its
policy online based on new observations of the channel state
information (CSI). This adaptability allows the UA V to handle
variations in the wireless channel conditions and adjust its
actions accordingly. For simplicity, we assume a line-of-sight
SIC decoding
UAV
y
PUn
PBS
PU2
PU1
Secondary channel 
Primary channel
â„1
SU2SU1
SUn
â„n
User 1 signal 
decoding
User 2 signal 
decoding
User     signal 
decoding
n
â‹°
â‹®
Fig. 1. System model with uplink NOMA signaling.
(LOS) channel and adopted the free-space path loss (FSPL)
model as defined by [22]. Thus, the distance du,n from the
UA Vu to ground SUs n at a given time instance t is expressed
as: du,n =
p
h2 + âˆ¥qu(t) âˆ’ wnâˆ¥2, where h is the UA Vâ€™s
altitude, the horizontal coordinate of the UA V is represented
by qu(t), and wn=[xn yn]T denotes the horizontal coordinate
for the mobile ground n-th SU. Similarly, the link power gain
from UA V to SUs is given by:
hn(t) = gk
n(t)â„¦n(t), (1)
where gk
n(t) is the large-scale power gain, accounting for path
losses and shadowing, and is calculated as follows:
gk
n(t) = Ï0dâˆ’2
n,u(t) = Ï0
h2 + âˆ¥qu(t) âˆ’ wnâˆ¥2 , (2)
where the link power gain at a reference distance is Ï0.
In (1), â„¦n(t) is the small-scale fading coefficient, which
follows a Rician distribution with a non-central chi-square
probability density function (PDF) [23]. To ensure a minimum
distance âˆ†y between the superimposed SUsâ€™ signal, each SU is
mapped to a unique QPSK constellation at the transmitter. This
minimum distance is well-spaced to minimize interference and
ensure successful SIC decoding at the receiver. By using the
learned generative model, the UA V can make informed predic-
tions about each userâ€™s signal and estimate their contributions
to the observed optimal superimposed signal. The UA V will
perform SIC by actively adapting its actions online to decode
x1 first, which is the SU with the strongest channel gain,
subtract it from the total received signal yt,k, and treat the
other signals ( x2 to xM ) as interference. The UA V performs
subsequent SIC and the next user with a stronger channel gain
is decoded. The uplink SIC is performed in decreasing order
of channel gain. The achievable data rate Rk,n in the uplink
is expressed as:
Rk,n â‰œ bk log2

1 + pk
ngk
n
P|Uk|
j=Ïƒâˆ’1
k (n)+1 pk
Ïƒk(j)gk
Ïƒk(j) + Î·kn

. (3)
Our objective is to ensure a maximum sum-rate subject to
power constraints while assuring the maximum number of
allowable SUs per sub-channel. The maximization problem
can be formulated mathematically as follows:
max
pkn
KX
k=1
NX
n=1
Rk,n (4a)
s.t.
|Uk|X
k=1
pk
n â‰¤ pmax, n âˆˆ N, kâˆˆ K (4b)
pk
n â‰¥ 0, n âˆˆ N, kâˆˆ K (4c)
|Uk| â‰¤M, k âˆˆ K (4d)
pk
n â‰¤ pk,n
max, n âˆˆ N, kâˆˆ K. (4e)
Constraint (4b) defines the maximum allowed total power
budget for each SU, which cannot surpass pmax. (4c) specifies
that the power allocation for each SU on each sub-channel
is non-negative. (4d) restricts the maximum number of SUs
multiplexed on a particular sub-channel to M. (4e) sets power
restrictions for each sub-channel. The optimization task in
(4a) is nonconvex, and solving the global optimal using
heuristic approaches is computationally infeasible. Therefore,
we propose an active inference-based approach that efficiently
learns the optimal subchannel and power allocation policy.
III. P ROPOSED METHOD FOR JOINT SUB -CHANNEL AND
POWER ALLOCATION
We describe active inference as a partially observable
Markov decision process (POMDP) [24]. In a given time
instance t, the actual state of an environment ËœSt âˆˆ Rds changes
according to a random transition process ËœSt âˆ¼ Pr(ËœSt|ËœStâˆ’1, A),
where A âˆˆ Rda represents the actions of an agent (UA V). The
actual environmental state is usually hidden from the agent,
but the agent can only infer them through observations ËœZt âˆˆ
Rdz , given by ËœZt âˆ¼ Pr(ËœZt|ËœSt). As a result, the agent works
with beliefs about the hidden state ËœSt.
Under the active inference framework, the relationship be-
tween the UA V and its environment can be described as a
6-element tuple ( ËœSt, ËœXt, A, Tpu
Ï„ , Î a
Ï„ , ËœZt), where ËœSt and
ËœXt are sets of the environmental hidden states that include
noise, PUs and/or SUs. A = {A[f], A[p]} is the action space
containing all the possible sub-channel decisions and initial
power allocation values. Tpu
Ï„ is the time-varying transition
model for PUs. Î a
Ï„ is the Active Inference-table that encodes
the state-action pair and ËœZt is the set of K sensory signals.
1) Radio Environment Representation: The UA V
can observe K sensory signals expressed as:
ËœZt={ËœZt,1, ËœZt,2, . . . ,ËœZt,K}, which correspond to K sub-
channels. In addition, we describe the radio environment
using a generalized hierarchical state-space model, which
includes the following components:
ËœS(e)
t,k = f(ËœS(e)
tâˆ’1,k) + wt,k, (5)
ËœX(e)
t,k = CËœX(e)
tâˆ’1,k + DUËœS(e)
t,k
+ wt,k, (6)
ËœZt,k = H
 ËœX(1)
t,k + Â·Â·Â· + ËœX(M)
t,k + ËœX(pu)
t,k

+ vt,k. (7)
In (5), the discrete random variables describing the discrete
sate clusters of the physical signal, the sub-channel carrying
the signal and its power level are denoted by ËœS(e)
t,k. Also, f (.)
is a non-linear function that expresses how ËœS(e)
t,k evolve over
time as a function of ËœS(e)
tâˆ’1,k and wt,k is the process noise, such
that wt,kâˆ¼N(0, Î£wt,k ). The dynamic equation defined in (6)
expresses how the Generalized States (GS) ËœX(e)
t,k evolve over
time as a function of ËœX(e)
tâˆ’1,k and ËœS(e)
t,k where e âˆˆ {no, pu, c},
no, pu, and c stands for noise, PU and the M superimposed
signals, respectively. C and D represent the dynamic and
control matrices, respectively, and UËœS(e)
t,k
is the control vector.
The observation model in (7) describes dependence of the
sensory signals on the hidden GS. The hierarchical dynamic
models formulated in terms of stochastic processes in (5), (6),
and (7) are structured in a graphical GDBN as depicted in
Fig. 2. The procedure includes an offline phase (i.e., the UA Vâ€™s
perception of desired observation), and the UA V is equipped
with a hierarchical GDBN at discrete and continuous states
to learn a generative model of the network, as depicted in
Fig. 2(a). Due to the Markov separation between the UA V
à·¨ğ’tâˆ’1,ğ‘˜
à·©ğ—tâˆ’1,ğ‘˜
à·¨ğ’t,ğ‘˜
à·©ğ—t,ğ‘˜
ğœ† à·¨St,ğ‘˜
ğœ† à·©Xt,ğ‘˜
â‹¯
â‹¯â‹¯
â‹¯
â‹¯
â‹¯
Discrete 
level
Continuous 
level
Observation 
level
à·¨ğ™tâˆ’1 à·¨ğ™t
ğœ‹ à·©Xt,ğ‘˜
ğœ‹ à·©Xt,ğ‘˜
Pr à·©Xt,k á‰šà·¨St,ğ‘˜
ğœ‹ à·¨St,ğ‘˜
(a)
à·¨ğ’tâˆ’1,ğ‘˜
à·©ğ—tâˆ’1,ğ‘˜
à·¨ğ’t,ğ‘˜
à·©ğ—t,ğ‘˜
ğœ† à·¨St,ğ‘˜
ğœ† à·©Xt,ğ‘˜
â‹¯
â‹¯â‹¯
â‹¯
â‹¯
â‹¯
Discrete 
level
Continuous 
level
Observation 
level
à·¨ğ™tâˆ’1 à·¨ğ™t
ğœ‹ à·©Xt,ğ‘˜
ğœ‹ à·©Xt,ğ‘˜
Pr à·©Xt,k á‰šà·¨St,ğ‘˜
ğ‘¨ğ’•âˆ’ğŸ
ğŸ , ğ©
ğœ‹ à·¨St,ğ‘˜
Î Ï„a (b)
Fig. 2. Graphical representations of the proposed method: (a) GDBN, (b)
Active-GDBN: As depicted in sub-figure (b), the highest level of the hierarchy
is the active states ( A[f],[p]
tâˆ’1 ), which indicate the joint actions of the UA V .
Representing the joint sub-channel and power allocation variables using
Active-GDBN enables us to describe the dynamic causal structure of the
radio environment at discrete and continuous states, facilitated by constant
message passing and belief updating. The blue arrows denote prior messages,
while the red arrows represent future messages. In essence, the past and future
states are constantly represented over time as new evidence becomes available.
The joint actions ( A[f]
tâˆ’1 for discrete sub-channel selection) and ( A[p]
tâˆ’1 for
continuous power allocation) affect the present states ËœSt,k, ËœXt,k at time t on
sub-channel k and defines the present observation ËœZt which depends on the
previous states ËœStâˆ’1,k, ËœXtâˆ’1,k.
and the external world, the UA V learns an optimal policy
of discrete sub-channels and continuous power by taking
into account network conditions and user position. Fig. 2(b)
denotes the online active inference phase, where the UA V
performs joint actions (i.e., dynamically selects continuous
power A[p]
tâˆ’1 and discrete sub-channels A[f]
tâˆ’1) to reach the
desired observation.
2) Perceptual Learning of Preferred Observations:At the
beginning of the learning stage, the UA V is equipped with an
initial model similar to the Unmotivated Kalman Filter (UKF)
which assumes that the environmental states evolve along
with static rules and relies on (6) to predict the continuous
environmental states where UËœS(e)
t,k
=0 [16]. The UA Vâ€™s memory
produces initial errors known as generalized errors (GEs) [25].
The GEs are further used to learn new models incrementally.
We used the Growing Neural Gas (GNG) unsupervised clus-
tering algorithm to learn the GDBN model that receives the
GEs and generates discrete state clusters. Similarly, the time-
varying transition matrix Î k,Ï„ is learned by estimating the
transition probability Pr(ËœS(e)
t,k|ËœS(e)
tâˆ’1,k, Ï„). The UA V repeats the
previous learning procedure to learn distinct vocabularies that
represent the various entities, such as, noise, PU, SU, and the
combined signals generated from multiple SUs.
3) Active Inference Phase:The UA Vâ€™s decision-making de-
pends on the state-action pair encoded in Î [f]
Ï„ , a time-varying
matrix encoding the probabilistic dependencies between states
and discrete actions, and Î [p]
Ï„ , a time-varying matrix encoding
the probabilistic dependencies between states and continuous
actions.
a) Action selection process: Initially, during the first
iteration, the UA V performs random sampling to select the
discrete actions as every possible discrete action has the
same probability ( 1
K ) of being chosen and selects the initial
continuous action A[p]
tâˆ’1 = A[p]
0 for power allocation. The
selected actions indicate what will be the next discrete and
continuous environmental states ËœSt,k, ËœXt,k which are charac-
terized by Pr(ËœSt,k|ËœStâˆ’1,k, A[f]
tâˆ’1) and Pr(ËœXt,k|ËœXtâˆ’1,k, A[p]
tâˆ’1).
In the successive iterations, the UA V can adjust the action
selection process by predicting implicitly the future activity
of PUs according to Tpu
Ï„ and skipping the resources that are
expected with high probability to be occupied by PUs. By
utilizing a modified Markov Jump Particle Filter (M-MJPF)
[26], the UA V is capable of predicting the outcomes of its
actions. The M-MJPF utilizes a switching model, employing
Particle Filtering (PF) for prediction and updating in the
discrete state, and Kalman Filtering (KF) for prediction and
updating in the continuous state. Through dynamic causal
relationships, a top-down inference can be distinguished from
a bottom-up inference. Additionally, the UA V observes and
senses the unselected sub-channels to determine their state
(occupied or vacant) and detect the activity of primary users
(PUs) in the spectrum. This information is used to enhance
future decision-making processes. Time-based inter-slice top-
down predictive messages Ï€(ËœXt,k) and Ï€(ËœSt,k) is based on
the information acquired in the dynamic model. The intra-
slice bottom-up inference is built on the likelihood function
and consists of backward propagated messages Î»(ËœXt,k) and
Î»(ËœSt,k) towards the discrete level. The prediction at the
continuous level depends on the discrete level. For each
particle propagated at the discrete level, a KF is activated to
predict the equivalent continuous level ËœXt,k. PF propagates
L particles equally weighted based on the proposal density
encoded in transition matrix Î k. After receiving the new
observation, diagnostic messages propagate in a bottom-up
manner to update the belief in hidden variables at the different
hierarchical levels (continuous and discrete states).
b) Abnormality measurements and action evaluation:
The continuous level abnormality indicator calculates the
similarity between the two messages entering the node ËœXt,k,
namely, Ï€(ËœXt,k) and Î»(ËœXt,k) to understand how much the
observation supports the predictions, according to:
Î¥ËœXt,k
= âˆ’ln

BC
 
Ï€(ËœXt,k), Î»(ËœXt,k)

=
Z q
Ï€(ËœXt,k)Î»(ËœXt,k)dËœXt,k,
(8)
where BC is the Bhattacharyya coefficient. The UA V can
decide whether the allocated actions were good or wrong by
comparing the multiple abnormalities.
c) Updating of action selection process: The UA V re-
ceives sensory signals to perceive the radio environment and
modifies the environment through its actions. It then infers the
effects of the executed actions, both discrete and continuous,
through observations. By selecting appropriate actions, the
UA V can adapt its strategy and determine its future behavior
by minimizing the GEs given by:
ËœEAtâˆ’1 =

Atâˆ’1, Ë™EAtâˆ’1

=

Atâˆ’1, Î»(Atâˆ’1) âˆ’ Ï€(Atâˆ’1)

. (9)
IV. S IMULATION RESULTS AND DISCUSSION
In this section, we assess the performance of our proposed
Active-GDBN. We fix the radius of the cell R to 1000 meters.
Within the cell, there is a PBS, and a UA V is positioned in the
middle, serving N SUs. We assumed that three PUs are ac-
tively occupying three sub-channels and the other sub-channels
are vacant. Table I summarizes the network parameters.
TABLE I
SIMULATION PARAMETERS
Cell radius 1000 m
Min. distance from UA V to SUs 100 m
Modulation scheme of PUs BPSK
Modulation scheme of SUs QPSK
Path loss model Free-space-path-loss [22]
Noise power âˆ’174 dBm/Hz
System Bandwidth,Bw 1.4 MHz
Number of sub-channelsK 6
Number of SUsN 20
Power budget of SUsPmax 20 W [27]
Number of SUs multiplexed per sub-channelM M = [1,3,5,7],
Power difference thresholdPth 1
Learning rate of GNG clustering 0.01
Fig. 3 illustrates the convergence performance of the pro-
posed algorithm where the sum rate values are plotted versus
the number of episodes for different numbers of SUs ( M)
multiplexed per sub-channel. When M = 1 , the problem
reduces to orthogonal multiple access (OMA). As revealed,
it takes within zero and fifty episodes to converge for all
possible values of M. Moreover, the sum rate increases with an
increasing number of SUs. The proposed algorithm achieved
a maximum number of 5 SUs multiplexed per sub-channel.
Also, as we increased the number of SUs to 7, the proposed
algorithm shows performance degradation. This is because,
beyond this limit, the symbols of the superimposed SU signals
begin to overlap, making accurate SIC and signal decoding
impossible for the UA V . Thus, the difference between the
superimposed constellation points âˆ†y is kept at a reasonable
distance to avoid inter-symbol interference.
0 50 100 150 200 250 300 350 400
Episodes
100
200
300
400
500
600
700
800Cumulative Sum Rate (bps/Hz)
M=1 (OMA)
M=3 (Active-GDBN)
M=5 (Active-GDBN)
M=7 (Active-GDBN)
Fig. 3. Convergence of Active-GDBN with different numbers of multiplexed
SUs when M = 5, Pth = 1, Pmax = 20Watts.
Fig. 4 shows the cumulative abnormality results of the
proposed algorithm, validating Fig. 3. We transform the sum
rate maximization problem into abnormality minimization. As
a result, Active-GDBN abnormality minimization is equivalent
to Active-GDBN reward (i.e., cumulative sum rate) maximiza-
tion.
Fig. 5 reveals the cumulative abnormality value as a function
of different GNG learning rates during offline training. As
0 50 100 150 200 250 300 350 400
Episodes
0
0.5
1
1.5
2
2.5
3
3.5Cumulative Abnormality
104
M=1 (OMA)
M=2 (Active-GDBN)
M=5 (Active-GDBN)
M=7 (Active-GDBN)
Fig. 4. Cumulative Abnormality of the proposed Active-GDBN with different
numbers of multiplexed SUs when M = 5, Pth = 1, Pmax = 20Watts.
0 20 40 60 80 100 120 140 160 180 200
Episodes
0
500
1000
1500
2000
2500
3000Cumulative Abnormality
GNG Learning rate = 0.01
GNG Learning rate = 0.05
GNG Learning rate = 0.1
Fig. 5. Cumulative abnormality of the proposed Active-GDBN with different
GNG learning rates when M = 5, Pth = 1, Pmax = 20Watts.
is evident, setting the learning rate to 0.01 results in the
fewest episodes required to attain the minimum cumulative
abnormality. Therefore, to achieve faster convergence, we set
the learning rate to 0.01 for all simulation settings.
To compare the performance of the proposed Active-GDBN,
we adopt and modify the Q-learning algorithm from [28] and
the successive convex approximation technique from [7]. As
clearly indicated in Fig. 6, the proposed method surpasses
the Q-learning scheme to reach a better and more stable
sum rate in fewer episodes. This is because, in each time
step, the UA V detects abnormalities, implying a mismatch
between the preferred observations and the predictions due
to the performed actions. As a result, the UA V exploits the
errors in each episode to learn how to take better actions
that minimize future abnormalities. Moreover, the proposed
Active-GDBN performs dynamic continuous power allocation
to SUs. Due to the strong influence of negative rewards on
Q-learning, it requires more training episodes to achieve a
significant improvement in the sum rate. The low sum rate
performance of convex approximation is due to its inability
to learn from experience and adapt its strategies to the time-
varying radio environment.
0 100 200 300 400 500 600 700 800
Episodes
100
200
300
400
500
600
700Cumulative Sum Rate (bps/Hz)
Q-learning
Convex approximation
Active-GDBN
Fig. 6. Cumulative sum rate comparison of the proposed Active-GDBN with
benchmark schemes when M = 5, Pth = 1, Pmax = 20Watts.
0 2 4 6 8 10 12 14 16 18 20
time slots
-15
-10
-5
0
5
10
15
Errors on the In-phase (I) signal
Errors at Episode 1
Errors at Episode10
Errors at Episode 30
Fig. 7. An example of the In-phase prediction errors with varying training
episodes per time slot when M = 5, Pth = 1, Pmax = 20Watts.
Fig. 7 indicates an example of the errors on the in-phase
component of the predicted combined SUsâ€™ signal. The initial
errors are high in the first episode (blue line) because the
UA Vâ€™s initial beliefs about the SUsâ€™ positions and channel
conditions are not accurate. The red line shows that the
errors have decreased significantly after 10 episodes, as the
UA V has learned to adapt its resource allocation policies and
belief updating. The errors decrease to a minimum after 30
episodes (green), as the UA V continues to learn and improve
by exploiting the generalized prediction errors.
V. C ONCLUSION
In this study, we investigate the joint sub-channel and
power allocation problem in an uplink UA V-assisted cogni-
tive NOMA network. We propose an active inference-based
algorithm, called Active-GDBN, to solve the sum rate maxi-
mization problem. Due to network dynamics and practical lim-
itations on the number of users multiplexed per sub-channel,
the problem is usually difficult to solve analytically. As a
result, we use a generalized state space model to characterize
the dynamic network environment and transform the problem
into an abnormality minimization problem. After performing
extensive simulations, the results reveal the effectiveness of
our proposed algorithm over the benchmark schemes in terms
of cumulative sum rate. Future research will examine the effect
of the UA Vâ€™s trajectory in relation to the mobility of SUs and
high-order modulation schemes.
REFERENCES
[1] L. Bonati et al., â€œOpen, programmable, and virtualized 5G networks:
State-of-the-art and the road ahead,â€ Computer Networks, vol. 182, p.
107516, 2020.
[2] P. Luong et al., â€œDeep Reinforcement Learning-Based Resource Allo-
cation in Cooperative UA V-Assisted Wireless Networks,â€ IEEE Trans-
actions on Wireless Communications, vol. 20, no. 11, pp. 7610â€“7625,
2021.
[3] F. Shen, G. Ding, Z. Wang, and Q. Wu, â€œUA V-based 3D spectrum
sensing in spectrum-heterogeneous networks,â€ IEEE Transactions on
Vehicular Technology, vol. 68, no. 6, pp. 5711â€“5722, 2019.
[4] M. F. Sohail, C. Y . Leow, and S. Won, â€œNon-orthogonal multiple access
for unmanned aerial vehicle assisted communication,â€ IEEE Access,
vol. 6, pp. 22 716â€“22 727, 2018.
[5] L. Sala Â¨un et al., â€œOptimal joint subcarrier and power allocation in
NOMA is strongly NP-hard,â€ in 2018 IEEE International Conference
on Communications (ICC). IEEE, 2018, pp. 1â€“7.
[6] S. Chen, K. Peng, and H. Jin, â€œA suboptimal scheme for uplink noma in
5g systems,â€ in 2015 International wireless communications and mobile
computing conference (IWCMC). IEEE, 2015, pp. 1429â€“1434.
[7] H. Guo, Y .-C. Liang, J. Chen, and E. G. Larsson, â€œWeighted sum-
rate maximization for reconfigurable intelligent surface aided wireless
networks,â€ IEEE transactions on wireless communications , vol. 19,
no. 5, pp. 3064â€“3076, 2020.
[8] L. Lei, D. Yuan, C. K. Ho, and S. Sun, â€œPower and channel allocation
for non-orthogonal multiple access in 5g systems: Tractability and
computation,â€ IEEE Transactions on Wireless Communications, vol. 15,
no. 12, pp. 8580â€“8594, 2016.
[9] C. He et al., â€œJoint power allocation and channel assignment for NOMA
with deep reinforcement learning,â€ IEEE Journal on Selected Areas in
Communications, vol. 37, no. 10, pp. 2200â€“2210, 2019.
[10] X. You, C. Zhang, X. Tan, S. Jin, and H. Wu, â€œAI for 5G: research
directions and paradigms,â€ Science China Information Sciences, vol. 62,
no. 2, pp. 1â€“13, 2019.
[11] L. Kohoutov Â´a, J. Heo, S. Cha, S. Lee, T. Moon, T. D. Wager, and C.-W.
Woo, â€œToward a unified framework for interpreting machine-learning
models in neuroimaging,â€ Nature protocols, vol. 15, no. 4, pp. 1399â€“
1435, 2020.
[12] A. Irpan, â€œDeep reinforcement learning doesnâ€™t work yet,â€ 2018.
[13] K. J. Friston, J. Daunizeau, and S. J. Kiebel, â€œReinforcement learning
or active inference?â€ PloS one, vol. 4, no. 7, p. e6421, 2009.
[14] A. Kurenkov, â€œReinforcement learningâ€™s foundational flaw,â€ The Gradi-
ent, 2018.
[15] T. Hospedales, A. Antoniou, P. Micaelli, and A. Storkey, â€œMeta-learning
in neural networks: A survey,â€ IEEE transactions on pattern analysis
and machine intelligence, vol. 44, no. 9, pp. 5149â€“5169, 2021.
[16] A. Krayani et al., â€œA Novel Resource Allocation for Anti-Jamming in
Cognitive-UA Vs: An Active Inference Approach,â€ IEEE Communica-
tions Letters, vol. 26, no. 10, pp. 2272â€“2276, Oct 2022.
[17] K. Friston, J. Kilner, and L. Harrison, â€œA free energy principle for the
brain,â€ Journal of physiology-Paris, vol. 100, no. 1-3, pp. 70â€“87, 2006.
[18] A. Tschantz, B. Millidge, A. K. Seth, and C. L. Buckley, â€œReinforcement
learning through active inference,â€ arXiv preprint arXiv:2002.12636,
2020.
[19] N. Sajid, P. Tigas, and K. Friston, â€œActive inference, preference learning
and adaptive behaviour,â€ in IOP Conference Series: Materials Science
and Engineering, vol. 1261, no. 1. IOP Publishing, 2022, p. 012020.
[20] O. C Â¸ atal, S. Wauthier, C. De Boom, T. Verbelen, and B. Dhoedt,
â€œLearning generative state space models for active inference,â€ Frontiers
in Computational Neuroscience, vol. 14, p. 574372, 2020.
[21] X. Wang et al., â€œDRL-based energy-efficient resource allocation frame-
works for uplink NOMA systems,â€ IEEE Internet of Things Journal,
vol. 7, no. 8, pp. 7279â€“7294, 2020.
[22] Q. Wu, Y . Zeng, and R. Zhang, â€œJoint trajectory and communication
design for multi-UA V enabled wireless networks,â€ IEEE Transactions
on Wireless Communications, vol. 17, no. 3, pp. 2109â€“2121, 2018.
[23] M. M. Azari, F. Rosas, K.-C. Chen, and S. Pollin, â€œOptimal uav
positioning for terrestrial-aerial communication in presence of fading,â€ in
2016 IEEE Global Communications Conference (GLOBECOM). IEEE,
2016, pp. 1â€“7.
[24] K. Friston et al., â€œActive inference and epistemic value,â€ Cognitive
neuroscience, vol. 6, no. 4, pp. 187â€“214, 2015.
[25] A. Krayani, A. S. Alam, L. Marcenaro, A. Nallanathan, and C. Regaz-
zoni, â€œAutomatic Jamming Signal Classification in Cognitive UA V
Radios,â€ IEEE Transactions on Vehicular Technology, vol. 71, no. 12,
pp. 12 972â€“12 988, Dec 2022.
[26] A. Krayani et al., â€œSelf-Learning Bayesian Generative Models for
Jammer Detection in Cognitive-UA V-Radios,â€ in GLOBECOM 2020 -
2020 IEEE Global Communications Conference, Dec 2020, pp. 1â€“7.
[27] S. Wang, S. Cao, and R. Ruby, â€œOptimal power allocation in noma-based
two-path successive af relay systems,â€ EURASIP Journal on Wireless
Communications and Networking, vol. 2018, pp. 1â€“12, 2018.
[28] Y . Huang, X. Mo, J. Xu, L. Qiu, and Y . Zeng, â€œOnline maneuver design
for uav-enabled noma systems via reinforcement learning,â€ in2020 IEEE
Wireless Communications and Networking Conference (WCNC). IEEE,
2020, pp. 1â€“6.