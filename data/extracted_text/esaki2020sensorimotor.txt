Sensorimotor Visual Perception on Embodied System Using Free Energy Principle
Kanako Esaki1, Tadayuki Matsumura1, Kiyoto Ito1 and Hiroyuki Mizuno1
1Center for Exploratory Research, Research & Development Group, Hitachi, Ltd., Tokyo, Japan
kanako.esaki.oa@hitachi.com
Abstract visual perception infers the environmental state, not the sensory
input itself. Therefore, the spatial limitation of the human visual
We propose an embodied system based on the free energy
field is not a â€œlimitationâ€ but is actually a â€œtriggerâ€ for an action
principle (FEP) for sensorimotor visual perception. We
evaluated it in a character-recognition task using the MNIST that moves the gazing position.
dataset. Although the FEP has successfully described a rule that In machine learning, many methods have been proposed that
living things obey mathematically and claims that a biological incorporate various characteristics and phenomena found in
system continues to change its internal models and behaviors to humans. The spatial limitations of the human body, such as that
minimize the difference in predicting sensory input, it is not described above, are treated as constraints called partial
enough to model sensorimotor visual perception. An observation in the context of reinforcement learning (Pineau, J.
embodiment of the system is the key to achieving sensorimotor
et al., 2003; Ji, S. et al., 2007; Silver, D. and Veness, J., 2010).
visual perception. The proposed embodied system is configured
These papers evaluated the degree of performance degradation
by a body and memory. The body has an ocular motor system
by partial observation in classification and regression
controlling the direction of eye gaze, which means that the eye
can only observe a small focused area of the environment. The problems, assuming that not all necessary information can be
memory is not photographic, but is a generative model obtained in most practical cases. In terms of classification and
implemented with a variational autoencoder that contains prior regression performance, the spatial limitations are certainly
knowledge about the environment, and that knowledge is constraints and not treated as â€œtriggersâ€ for actions. Various
classified. By limiting body and memory abilities and operating models and algorithms similar to SMC have also been
according to the FEP, the embodied system repeatedly takes proposed. Auto regressive models (Gregor, K. et al., 2015;
action to obtain the next sensory input based on various
Oord, A. et al., 2016; Salimans, T. et al., 2017) predict the entire
potentials of future sensory inputs. In the evaluation, the
image by repeating the action of obtaining a partial image.
inference of the environment was represented as an approximate
Algorithms that generate exploring actions for reinforcement
posterior distribution of characters (0â€“9). As the number of
learning (Oh, J. et al., 2015; Houthooft, R. et al., 2016)
repetitions increased, the attention area moved continuously,
gradually reducing the uncertainty of characters. Finally, the contribute to finding optimum solutions by covering a wide
probability of the correct character became the highest among range of the action space without bias. These models and
the characters. Changing the initial attention position provides a algorithms generate the actions not on a basis of inference of
different final distribution, suggesting that the proposed system environmental states but on that of sensory inputs such as
has a confirmation bias. partial images and observations in reinforcement learning.
None of the above studies have achieved the inference of
environmental states, which is the essence of human
Introduction
sensorimotor visual perception.
The purpose of this study is to achieve human sensorimotor
The human visual field seems to cover a wide area of the
visual perception using the free energy principle (hereafter
surrounding environment, but the range with high enough
called FEP; Friston, K. et al., 2006; Friston, K. J., 2010;
resolution to identify the shape and color of the target object is
McGregor, S. et al., 2015; Friston, K. et al., 2017; Buckley, C.
limited to only the central visual field of about 5 degrees
L. et al., 2017). The FEP mathematically describes the principle
(Mandelbaum, J. and Sloan, L. L., 1947). Since the human
that living things obey. The free energy in the FEP measures
visual field has this spatial limitation, it is necessary to move
the difference between the probability distribution of
the gazing position to obtain environmental information (see)
environmental states that act on a biological system and an
in a wide area. This leads to a phenomenon called sensorimotor
approximate posterior distribution of environmental states
contingency (hereafter called SMC; Oâ€™Regan, J. K. and NoÃ«,
encoded by the configuration of that system. The biological
A., 2001; Seth, A.K., 2015), which changes the interpretation
system minimizes the free energy by changing its configuration
of â€œseeingâ€ (Land, M. F., 2006; Friston, K. and Kiebel, S.,
to affect the way it samples the environment or by changing the
2009; Seth, A.K. et al., 2012; Adams, R. A. et al., 2013;
approximate posterior distribution it encodes. These two
Bogacz, R., 2017; Lotter, W., 2017). Human sensorimotor
changes correspond to action and perception, respectively, and
visual perception makes â€œseeingâ€ knowing about things to do
lead to â€œactive inferenceâ€ and â€œperceptual inference.â€ The
rather than making an internal representation. In other words,
biological system thus encodes an implicit and probabilistic
experience is not something we feel but something we do
model of the environment.
(Oâ€™Regan, J. K., 2001). This is because human sensorimotor
Although the FEP has successfully described a biological
system of performing active and perceptual inferences Environmental state ğ‘¥ğ‘¡
mathematically, it is not enough to model human sensorimotor
visual perception. An embodiment of this system is the key to
Attention image
achieving human sensorimotor visual perception. The
embodiment provides an interaction between the biological
system and environment, resulting in sensory inputs and T=t-2
Sensory input image ğ‘ ğ‘¡
T=t-1
actions, and the causal relationship between these is stored in Vision sensor T=t
the biological system (Fitzpatrick, P. et al., 2003; Cheng, G. et
Attention position moves (ğ‘ğ‘¡âˆ’1)
al., 2006; Friston, K., 2011; Gallagher, S. and Allen, M., 2018). every time step
In this paper, we propose an embodied system based on FEP
to achieve sensorimotor visual perception. The proposed
embodied system is configured by a body, which partially Figure 1 Overview of problem setting to consider sensorimotor
observes the environment, and memory, which has classified visual perception.
prior knowledge about the environment as a generative model.
Evaluation using the MNIST dataset (LeCun, Y. and Cortes, and expected free energy, which are necessary components to
C., 1998) shows that the proposed system triggers an action that describe the perceptual and active inferences, are expressed as
moves a gazing position and repeatedly performs active and follows. The variational free energy ğ¹(ğœ™ ğ‘¥ğ‘¡ ,ğ‘ ğ‘¡âˆ’1 ) described in
perceptual inferences by following the FEP. Moreover, the the FEP is expressed as
intentionality is reproduced on the proposed system, producing
ğ¹(ğœ™ ,ğ‘ )
an equivalent of human confirmation bias. We discuss how ğ‘¥ğ‘¡ ğ‘¡âˆ’1
important this bias is for taking the action in an unknown
environment.
=ğ¸ [lnğ‘(ğ‘¥ |ğœ™ )âˆ’lnğ‘ (ğ‘¥ ,ğ‘  )]
ğ‘(ğ‘¥ğ‘¡|ğœ™ğ‘¥ğ‘¡ ) ğ‘¡ ğ‘¥ğ‘¡ ğ‘ğ‘¡âˆ’1 ğ‘¡ ğ‘¡
Sensorimotor Visual Perception =ğ· [ğ‘(ğ‘¥ |ğœ™ )||ğ‘ (ğ‘¥ |ğ‘  )]âˆ’lnğ‘ (ğ‘  ), (1)
ğ¾ğ¿ ğ‘¡ ğ‘¥ğ‘¡ ğ‘ğ‘¡âˆ’1 ğ‘¡ ğ‘¡ ğ‘ğ‘¡âˆ’1 ğ‘¡
To list the components necessary for achieving sensorimotor where ğ‘(ğ‘¥ |ğœ™ ) is the approximate posterior distribution of
visual perception, the following problem settings are ğ‘¥ , and ğ‘ ğ‘¡ ğ‘¥ ( ğ‘¡ ğ‘¥ ,ğ‘  ) is a generative model that stores the
considered. Figure 1 shows an overview of our problem setting. ca ğ‘¡ usal relat ğ‘ i ğ‘¡ o âˆ’ n 1 shi ğ‘¡ p o ğ‘¡ f ğ‘¥ and ğ‘  under ğ‘ . The ğ‘(ğ‘¥ |ğœ™ )
Let us consider a situation in which there is an object to be is made to minimize the ğ‘¡ variatio ğ‘¡ nal free en ğ‘¡ e âˆ’ r 1 gy. The exp ğ‘¡ ect ğ‘¥ e ğ‘¡ d
perceived, e.g., the number 5, in the environment and the vision free energy ğº(ğœ™ ,ğ‘ ) described in the FEP is expressed as
sensor is used to perceive it. The situation is called an
ğ‘¥ğ‘¡+1 ğ‘¡
environmental state ğ‘¥ ğ‘¡ . The vision sensor replaces the role of ğº(ğœ™ ğ‘¥ğ‘¡+1 ,ğ‘ ğ‘¡ )
the human eye and has a spatial limitation of the visual field.
The spatial limitation leads to a change in direction of the vision =ğ¸ ğ¹(ğœ™ ,ğ‘ )
sensor to obtain images in the wide area of the environment.
ğ‘(ğ‘ ğ‘¡+1|ğ‘¥ğ‘¡+1,ğœ™ğ‘¥ğ‘¡+1 ) ğ‘¥ğ‘¡+1 ğ‘¡
When the direction of the vision sensor is determined in a =ğ¸ ğ¸
certain direction, an image of a specific region of the
ğ‘(ğ‘ ğ‘¡+1|ğ‘¥ğ‘¡+1,ğœ™ğ‘¥ğ‘¡+1 ) ğ‘(ğ‘¥ğ‘¡+1|ğœ™ğ‘¥ğ‘¡+1 )
environment is obtained. A representative position of the region [lnğ‘(ğ‘¥ |ğœ™ )âˆ’lnğ‘ (ğ‘¥ ,ğ‘  )]
(for example, the position of the upper left corner of the region)
ğ‘¡+1 ğ‘¥ğ‘¡+1 ğ‘ğ‘¡ ğ‘¡+1 ğ‘¡+1
is defined as an attention position, which equals the gazing
=ğ¸ [ğ¸
position of the human eye. The image of the region is defined ğ‘(ğ‘ ğ‘¡+1|ğ‘¥ğ‘¡+1,ğœ™ğ‘¥ğ‘¡+1 ) ğ‘(ğ‘¥ğ‘¡+1|ğœ™ğ‘¥ğ‘¡+1 )
as an attention image. The attention image at each time point
[lnğ‘(ğ‘¥ |ğœ™ )âˆ’lnğ‘(ğ‘¥ )]
(ğ‘‡=ğ‘¡âˆ’2,tâˆ’1,t) is obtained by the previous actions ğ‘¡+1 ğ‘¥ğ‘¡+1 ğ‘¡+1
ğ‘
ğ‘¡âˆ’3
,ğ‘
ğ‘¡âˆ’2
,ğ‘
ğ‘¡âˆ’1
that move the attention position every time
âˆ’ğ¸ lnğ‘ (ğ‘  |ğ‘¥ )]
step. A composition image of the attention images obtained up ğ‘(ğ‘¥ğ‘¡+1|ğœ™ğ‘¥ğ‘¡+1 ) ğ‘ğ‘¡ ğ‘¡+1 ğ‘¡+1
to the current time ğ‘‡=ğ‘¡ is used as a sensory input (hereafter
called sensory input image ğ‘  ğ‘¡ ). As described above, =ğ¸ ğ‘(ğ‘ ğ‘¡+1|ğ‘¥ğ‘¡+1,ğœ™ğ‘¥ğ‘¡+1 ) ğ· ğ¾ğ¿ [ğ‘(ğ‘¥ ğ‘¡+1 |ğœ™ ğ‘¥ğ‘¡+1 )||ğ‘(ğ‘¥ ğ‘¡+1 )]
sensorimotor visual perception is to perceive the object (the
number 5) in the environment by repeating the actions to obtain +ğ¸ [âˆ’ğ¸ lnğ‘ (ğ‘  |ğ‘¥ )]. (2)
ğ‘  . Our goal of this study is to achieve sensorimotor visual
ğ‘(ğ‘ ğ‘¡+1|ğ‘¥ğ‘¡+1,ğœ™ğ‘¥ğ‘¡+1 ) ğ‘(ğ‘¥ğ‘¡+1|ğœ™ğ‘¥ğ‘¡+1 ) ğ‘ğ‘¡ ğ‘¡+1 ğ‘¡+1
ğ‘¡ ğ‘ (ğ‘¥ ,ğ‘  ) is factorized into ğ‘ (ğ‘  |ğ‘¥ )ğ‘(ğ‘¥ )
perception based on FEP. ğ‘ğ‘¡ ğ‘¡+1 ğ‘¡+1 ğ‘ğ‘¡ ğ‘¡+1 ğ‘¡+1 ğ‘¡+1
since ğ‘¥ and ğ‘ are independent. The next action is
ğ‘¡+1 ğ‘¡
selected to minimize the expected free energy.
Free Energy Principle The purpose of perceptual inference is to find ğ‘(ğ‘¥ ğ‘¡ |ğœ™ ğ‘¥ğ‘¡ )
that minimizes ğ¹(ğœ™ ,ğ‘ ) . Since the second term of
ğ‘¥ğ‘¡ ğ‘¡âˆ’1
The FEP mathematically describes the perceptual and active Equation (1) is composed of ğ‘ and the current ğ‘  , which
ğ‘¡âˆ’1 ğ‘¡
inferences. In our problem setting, the sensory input image ğ‘  have already been determined, the purpose is achieved by
ğ‘¡
is determined by the previous action ğ‘ and the current changing ğ‘(ğ‘¥ |ğœ™ ) with ğœ™ to make the first term close to
ğ‘¡âˆ’1 ğ‘¡ ğ‘¥ğ‘¡ ğ‘¥ğ‘¡
environmental state ğ‘¥ . The ğ‘¥ does not change (ğ‘¥ =ğ‘¥ = zero. When the first term is made close to zero,
ğ‘¡ ğ‘¡ ğ‘¡âˆ’1 ğ‘¡
ğ‘¥ ). Under the above assumptions, the variational free energy ğ‘ (ğ‘¥ |ğ‘  )~ğ‘(ğ‘¥ |ğœ™ ). Active inference aims to find action
ğ‘¡+1 ğ‘ğ‘¡âˆ’1 ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¥ğ‘¡
ğ‘ that minimizes ğº(ğœ™ ,ğ‘ ). Since ğ‘ is included only in uncertainty is mapped for each ğ‘  . In generating ğ‘  (the
ğ‘¡ ğ‘¥ğ‘¡+1 ğ‘¡ ğ‘¡ ğ‘¡+1 ğ‘¡
the second term (hereafter called uncertainty), the purpose is first process of perceptual inference), the attention image
achieved by minimizing the uncertainty. obtained from the environment and the past attention images
are composed while maintaining their relative attention
positions to generate ğ‘  . In calculating ğ‘(ğ‘¥ |ğœ™ ) and
Proposed Embodied System ğ‘ (ğ‘¥ |ğœ™ ) (the second ğ‘¡ process of perceptual ğ‘¡ inf ğ‘¥ e ğ‘¡ rence),
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡
for Sensorimotor Visual Perception ğ‘ (ğ‘¥ ,ğ‘  ) is implemented with a combination of a
ğ‘ğ‘¡âˆ’1 ğ‘¡ ğ‘¡
variational autoencoder (VAE) and a fully connected neural
An embodiment is the key to achieving sensorimotor visual network (FNN), which is inspired by the idea of auxiliary loss
perception based on the FEP. The proposed embodied system in GoogleNet (Szegedy, C. et al., 2015). The VAE contains
is configured by a body and memory. The body has an ocular prior knowledge about the environment, and the FNN classifies
motor system for controlling the attention position. In our the prior knowledge in the latent space generated in the VAE.
problem setting shown in Figure 1, the vision sensor is the The combination of the VAE and FNN is pre-trained, which
body. The body has thus limited spatial observation ability, corresponds to human â€œexperience.â€ The pre-training is
which means that it can only observe a small area of the equivalent to changing ğœ™ in Equation (1) to make the first
ğ‘¥ğ‘¡
environment that is focused upon. The memory is not term of that equation closer to zero. Although ğœ™ is updated
ğ‘¥ğ‘¡
photographic but is a generative model that contains prior in the long term, it is fixed in the short term from ğ‘¡âˆ’1 to ğ‘¡.
knowledge about the environment, and that knowledge is The ğ‘(ğ‘¥ |ğœ™ ) and ğ‘ (ğ‘¥ |ğœ™ ) are calculated by inputting
ğ‘¡ ğ‘¥ğ‘¡ ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡
classified. By limiting body and memory abilities and operating the ğ‘  to the combination of the VAE and FNN. Calculation
ğ‘¡
according to the FEP, the proposed embodied system of uncertainty (the first process of active inference) uses
repeatedly performs perceptual and active inference. Figure 2 ğ‘ (ğ‘¥ |ğœ™ ). Uncertainty is the expected information amount
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡
shows the processing flow of sensorimotor visual perception of ğ‘ (ğ‘  |ğ‘¥ ), which is the probability distribution of ğ‘ 
ğ‘ğ‘¡ ğ‘¡+1 ğ‘¡+1 ğ‘¡+1
with the proposed system. In perceptual inference, a current with action ğ‘ as a parameter, which is conditioned by ğ‘¥ .
ğ‘¡ ğ‘¡+1
sensory input image ğ‘  is generated using an attention image Conditioning by ğ‘¥ (=ğ‘¥ ) is interpreted as extracting ğ‘ 
ğ‘¡ ğ‘¡+1 ğ‘¡ ğ‘¡+1
obtained from the environment and the past attention images from ğ‘ (ğ‘¥ |ğœ™ ). The ğ‘  is composed of the current ğ‘ 
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡ ğ‘¡+1 ğ‘¡
obtained up to the current time point. Then, ğ‘  is input to the and the candidate attention images surrounding it.
ğ‘¡
generative model ğ‘ (ğ‘¥ ,ğ‘  ) to calculate an approximate Parameterizing ğ‘ is interpreted as assuming the candidate
ğ‘ğ‘¡âˆ’1 ğ‘¡ ğ‘¡ ğ‘¡
posterior distribution ğ‘(ğ‘¥ |ğœ™ ) and an approximate posterior attention images. Under these interpretations, the information
ğ‘¡ ğ‘¥ğ‘¡
image ğ‘ (ğ‘¥ |ğœ™ ) which is a conversion of ğ‘(ğ‘¥ |ğœ™ ) into amount of ğ‘ (ğ‘  |ğ‘¥ ) is calculated as that of ğ‘  . The
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡ ğ‘¡ ğ‘¥ğ‘¡ ğ‘ğ‘¡ ğ‘¡+1 ğ‘¡+1 ğ‘¡+1
an image format. In active inference, the uncertainty of the information amount of ğ‘  is the entropy of the approximate
ğ‘¡+1
expected sensory input images ğ‘  is calculated using posterior distribution calculated by inputting ğ‘  to
ğ‘¡+1 ğ‘¡+1
ğ‘ (ğ‘¥ |ğœ™ ). After that, an attention position having the ğ‘ (ğ‘¥ ,ğ‘  ). Since ğ‘  is deterministically calculated from
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡ ğ‘ğ‘¡âˆ’1 ğ‘¡ ğ‘¡ ğ‘¡+1
minimum value is selected from an uncertainty map in which one ğ‘ (ğ‘¥ |ğœ™ ), the expected-value calculation is not
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡
System
<Perceptual inference> <Active inference>
Sensory-input- Approximate posterior Uncertainty calculation Attention-position selection
image generation calculation
Sensory input Generative Approximate posterior Approximate posterior
image ğ‘  ğ‘¡
ğ‘ ğ‘ğ‘¡
m
âˆ’1
od
ğ‘¥
e
ğ‘¡
l
,ğ‘  ğ‘¡
image ğ‘
5
ğ‘–ğ‘šğ‘” ğ‘¥ ğ‘¡ |ğœ™ ğ‘¥ğ‘¡ e
ta d id
imag
5
e ğ‘ ğ‘–ğ‘šğ‘” ğ‘¥
ğ‘ 
ğ‘¡
ğ‘¡
|ğœ™ ğ‘¡ A
m
t
in
te
im
nti
i
o
ze
n
s
p
e
o
n
s
t
i
r
ti
o
o
p
n
y
th
is
a t
selected
VAE n
a
c
h
Candidate
c a â€¦ attention
FNN
ro
ire
ts o p
e
tam
ix
o rp p A
n
o
itu
b irtsid
ğœ™
ğ‘
ğ‘¥ |
ğ‘¥
ğ‘¡
ğ‘¡
0123456789
e
ro
f d e ta
ren
e
G
Uncertai
5
nty =
i
O e
s
i
ğ‘ 
n
m
e
ğ‘¡
x
p
n
+
n
a
p
u
e
s
1
g
e
t
o
e
c o
r
t
i
f
y
m
ed
ages
Past attention Set of approximate posterior
images entropies of each expected Uncertainty map
Body Memory sensory input image
Environment
Attention image Attention position
Environmental
state ğ‘¥
ğ‘¡
Figure 2 Processing flow of sensorimotor visual perception with proposed embodied system.
required. Uncertainty is thus the set of the entropies of each 8: calculate approximate posterior distribution
ğ‘  . In selecting the attention position (the second process of ğ‘(ğ‘¥ |ğœ™ ) using ğ‘  [ğ‘–ğ‘›ğ‘‘ğ‘’ğ‘¥] and
ğ‘¡+1 ğ‘¡+1 ğ‘¥ğ‘¡+1 ğ‘¡+1
active inference), an uncertainty map is generated where the ğ‘ (ğ‘  ,ğ‘¥ )
ğ‘ğ‘¡ ğ‘¡ ğ‘¡
entropy of each ğ‘  corresponds to each attention position. An 9: calculate entropy of ğ‘(ğ‘¥ |ğœ™ )
ğ‘¡+1 ğ‘¡+1 ğ‘¥ğ‘¡+1
attention position that minimizes the entropy is selected 10: add entropy to uncertainty map ğ‘€
according to the uncertainty map. 11: end for
Algorithm 1 shows the pseudo code of the processing flow. 12: set attention position using ğ‘€
The ğ‘ (ğ‘  ,ğ‘¥ ) is pre-trained using training data of (ğ‘  ,ğ‘¥ ). 13: end while
ğ‘ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡
All the training data of ğ‘  are pre-processed so that the center
ğ‘¡
of gravity of an image is shifted to the center position. During 14: generate_expected_sensory_input_image
the operation of the proposed embodied system, the process 15: generate approximate posterior image
from the 2nd line to the 12th line is repeated. First, an attention ğ‘ (ğ‘¥ |ğœ™ ) using ğ‘  and ğ‘ (ğ‘  ,ğ‘¥ )
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡ ğ‘¡ ğ‘ğ‘¡ ğ‘¡ ğ‘¡
image ğ‘ â€² is obtained from the vision sensor. The past sensory 16: generate template from ğ‘ 
ğ‘¡ ğ‘¡
input images are composed with the obtained ğ‘ â€² while 17: obtain current sensory input position ğ‘¢
ğ‘¡ ğ‘ğ‘¢ğ‘Ÿ
maintaining each relative attention position. The center of by template matching in ğ‘ (ğ‘¥ |ğœ™ )
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡
gravity of the composed image is calculated, and the composed 18: calculate next candidate attention positions
image is shifted so that the center of gravity is located at the ğ‘¢ using ğ‘¢
ğ‘›ğ‘’ğ‘¥ğ‘¡ ğ‘ğ‘¢ğ‘Ÿ
center position of the image. The shifted composed image is an 19: generate ğ‘  using ğ‘ (ğ‘¥ |ğœ™ ), ğ‘¢ ,
ğ‘¡+1 ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡ ğ‘ğ‘¢ğ‘Ÿ
ğ‘  . Then, ğ‘(ğ‘¥ |ğœ™ ) is calculated by inputting ğ‘  to and ğ‘¢
ğ‘¡ ğ‘¡ ğ‘¥ğ‘¡ ğ‘¡ ğ‘›ğ‘’ğ‘¥ğ‘¡
ğ‘ (ğ‘  ,ğ‘¥ ). After that, the sub function starting from the 14th 20 return with ğ‘ 
ğ‘ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡+1
line is called to generate expected sensory input images ğ‘  .
ğ‘¡+1
In the sub function, an ğ‘ (ğ‘¥ |ğœ™ ) is calculated by inputting
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡
ğ‘  to ğ‘ (ğ‘  ,ğ‘¥ ). A template image is generated by detecting a
b ğ‘¡ oundin ğ‘ g ğ‘¡ r ğ‘¡ ect ğ‘¡ angle area of non-zero pixels in ğ‘  and Evaluation
ğ‘¡
extracting the area from ğ‘  . Template matching is carried out
ğ‘¡
in the ğ‘ (ğ‘¥ |ğœ™ ), and the representative position of the We evaluated the proposed embodied system for achieving
current ğ‘  ğ‘–ğ‘š , ğ‘” ğ‘¢ ğ‘¡ , ğ‘¥ is ğ‘¡ obtained. To calculate the next candidate sensorimotor visual perception in a character-recognition task
ğ‘¡ ğ‘ğ‘¢ğ‘Ÿ
attention positions ğ‘¢ , a candidate region of ğ‘¢ is set. with partial observation constraint. We used the MNIST dataset
ğ‘›ğ‘’ğ‘¥ğ‘¡ ğ‘›ğ‘’ğ‘¥ğ‘¡
The candidate region is a region obtained by adding a fixed as the character dataset. The generative model was
margin pixel to a region of ğ‘  in ğ‘ (ğ‘¥ |ğœ™ ). The region of implemented with a convolutional VAE (Kingma, D.P. and
ğ‘  is defined by ğ‘¢ and th
ğ‘¡
e size
ğ‘–
o
ğ‘š
f
ğ‘”
the
ğ‘¡
tem
ğ‘¥ğ‘¡
plate image. The Welling, M., 2014; Rezende, D. J. et al., 2014) that was robust
ğ‘¡ ğ‘ğ‘¢ğ‘Ÿ
ğ‘¢ are calculated by sliding the window with the fixed stride against displacement and a three-layer FNN (30 units in the
ğ‘›ğ‘’ğ‘¥ğ‘¡
pixel in the candidate region. The window is the size of ğ‘ â€² . hidden layer, 10 units in the output layer, and the activation
ğ‘¡
The representative positions of all the window positions during function of the output layer was the Softmax function).
Training of the generative model involved 60,000 MNIST
sliding are ğ‘¢ . The ğ‘  are generated by extracting the
ğ‘›ğ‘’ğ‘¥ğ‘¡ ğ‘¡+1
region of the ğ‘  ğ‘¡ and the region of the next candidate attention images (28 Ã— 28 pixels). The stochastic variables ğ‘¥ ğ‘¡ of the
i d m ef a i g n e e s d ğ‘  b â€² y ğ‘¡+ 1 ğ‘¢ from a n d ğ‘ ğ‘–ğ‘š th ğ‘” e ( ğ‘¥ s ğ‘¡ i | z ğœ™ e ğ‘¥ ğ‘¡ o ) f . T th h e e t r e e m gi p o l n a te o f im th a e g e ğ‘  , ğ‘¡ a i s s a o p f p th ro e x M im N a I t S e T p o d s a t t e a r s i e o t r . T di h s e tr s ib iz u e t i o o f n b o ğ‘ t ( h ğ‘¥ t ğ‘¡ h |ğœ™ e ğ‘¥ se ğ‘¡ ) n s w or e y r e in l p a u b t e i l m s 0 a â€“ g 9 e
ğ‘ğ‘¢ğ‘Ÿ
mentioned above. The region of the ğ‘ â€² are defined by and approximate posterior image was 28 Ã— 28 pixels, while the
ğ‘¡+1
ğ‘¢ and the size of ğ‘ â€² . The extracted images are clipped size of the attention image was 6 Ã— 6 pixels. The margin pixel
ğ‘›ğ‘’ğ‘¥ğ‘¡ ğ‘¡+1
or applied with zero-padding to have the same size as ğ‘  . Each and stride pixel for generating the next candidate attention
ğ‘¡
approximate posterior distribution ğ‘(ğ‘¥ |ğœ™ ) is images were set to 3 and 1, respectively. The number of
calculated by inputting each image include ğ‘¡ d +1 in ğ‘¥ ğ‘¡+ ğ‘  1 to attention repetitions was set to 20.
ğ‘¡+1
ğ‘ (ğ‘  ,ğ‘¥ ). Note that ğ‘(ğ‘¥ |ğœ™ ) is calculated using the current Perceptual inference was performed during the attention
ğ‘ 
o
ğ‘¡
f
ğ‘ , ğ‘¡ w
e
h
a
ğ‘¡
c
il
h
e ğ‘¡ ğ‘
ğ‘
(
(
ğ‘¥
ğ‘¥
ğ‘¡+1 |
|
ğœ™
ğœ™
ğ‘¥ğ‘¡+1 )
)
i ğ‘¡ s
i
c
s
a ğ‘¥ l ğ‘¡
c
c
a
u
l
l
c
a
u
te
la
d
t e
u
d
si n
a
g
n d
ğ‘  ğ‘¡+
a
1
d
.
d
T
e
h
d
e e
t
n
o
t ro
t
p
h
y
e
r
m
e
a
p
k
e
i
t
n
it
g
io n
a
s
n
. F
a
i
t
g
te
u
n
re
ti o
3
n
sh
a
o
t
w
c
s
h a
th
ra
e
c
t
t
r
e
a
r
n
s
si
â€œ
t
0
io
â€
n
,
o
â€œ
f
2 â€
ğ‘
,
(
â€œ
ğ‘¥
9
ğ‘¡
â€
|ğœ™
,
ğ‘¥
a
ğ‘¡
n
)
d
w
â€œ
h
3
e
â€
n
.
uncertainty ma ğ‘¡ p + 1 ğ‘€. ğ‘¥ ğ‘¡ F + i 1 nally, the attention position having the Symbols A, B, C, and D in Figure 3 (a) are described later. Each
minimum value in ğ‘€ is defined as the next attention position. graph plots the probability distribution for the stochastic
variable (0â€“9). In each subfigure ((a)â€“(d)), the graph on the left
shows the distribution for the 1st to 10th attentions in order
Algorithm 1 Pseudocode of processing flow
from the top, and the graph on the right shows the distribution
1: while system is operating do:
for the 11th to 20th attentions in order from the top. The image
2: obtain attention image ğ‘ â€²
ğ‘¡ on the right side of each graph is the corresponding
3: compose past sensory input images with ğ‘ â€²
ğ‘¡ approximate posterior image ğ‘ (ğ‘¥ |ğœ™ ). Regardless of the
4: generate sensory input image ğ‘ 
ğ‘¡
by shifting
characters, the probability of â€œ1â€
ğ‘–ğ‘š
w
ğ‘”
as
ğ‘¡
max
ğ‘¥ğ‘¡
imum from the 1st to
gravity point to center of composed image
the 2nd attention, and the ğ‘ (ğ‘¥ |ğœ™ ) at that time contained
5: calculate approximate posterior distribution ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡
a shape that was difficult to recognize as a character. After the
ğ‘(ğ‘¥ |ğœ™ ) using ğ‘  and generative model
ğ‘¡ ğ‘¥ğ‘¡ ğ‘¡ 3rd attention, the probability of the characters different from
ğ‘ (ğ‘  ,ğ‘¥ )
ğ‘ğ‘¡ ğ‘¡ ğ‘¡ the correct characters â€œ0â€, â€œ2â€, â€œ9â€, and â€œ3â€ changed to the
6: call generate_expected_sensory_input_image
maximum, and the ğ‘ (ğ‘¥ |ğœ™ ) at that time contained shapes
7: for expected sensory input images ğ‘  ğ‘¡+1 : similar to numbers â€œ5 ğ‘–ğ‘š â€ ğ‘” and ğ‘¡ â€œ7 ğ‘¥ â€ ğ‘¡ . When making an attention at
characters â€œ0â€, â€œ2â€, and â€œ9â€, the probability of correct
1st to 10th attentions 11th to 20th attentions 1st to 10th attentions 11th to 20th attentions
A
C
B
ğœ™
ğ‘¥ğ‘¡
ğœ™
ğ‘¥ğ‘¡
ğ‘¥
|ğ‘¡
ğ‘¥
|ğ‘¡
ğ‘ ğ‘
D
ğ‘¥ ğ‘¡ ğ‘¥ ğ‘¡ ğ‘¥ ğ‘¡ ğ‘¥ ğ‘¡
(a) (b)
1st to 10th attentions 11th to 20th attentions 1st to 10th attentions 11th to 20th attentions
ğ‘¥ğ‘¡ ğ‘¥ğ‘¡
ğœ™ ğœ™
ğ‘¥
|ğ‘¡
ğ‘¥
|ğ‘¡
ğ‘ ğ‘
ğ‘¥ ğ‘¥ ğ‘¥ ğ‘¥
ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡
(c) (d)
Figure 3 Transition of approximate posterior distribution along with attention repetition. Each
subfigure (a), (b), (c), and (d) corresponds to making attention at the characters â€œ0â€, â€œ2â€, â€œ9â€,
and â€œ3â€, respectively.
characters was maximum at the 20th attention, and â€œ0â€, â€œ2â€, at the 20th attention. The ğ‘ (ğ‘¥ |ğœ™ ) contained a part of
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡
and â€œ9â€ appeared in the ğ‘ (ğ‘¥ |ğœ™ ). On the other hand, â€œ3â€, not the entire â€œ3â€.
ğ‘–ğ‘šğ‘” ğ‘¡ ğ‘¥ğ‘¡
when making an attention at character â€œ3â€, the probability of Active inference was performed during attention repetitions.
â€œ7â€ was maximum from the 4th to 13th and from the 15th to Figure 4 shows the uncertainty map at the 1st, 4th, 13th, and
19th attentions, and the probability of â€œ2â€ was maximum even 20th attentions (corresponding to A, B, C, and D in Figure 3
Approximate posterior image
O y A B
(x, y) Candidate attention
image at next time
x
Current sensory input
image
x x
y y
C D
x x
y y
Figure 4 Uncertainty map when making attention at â€œ0â€. Each subfigure A, B, C, and D corresponds to 1st, 4th, 13th, and
20th attentions, respectively.
(a), respectively) when making an attention at â€œ0â€. The vertical
(x) and horizontal (y) axes of the maps indicate the position
coordinates of the upper left corner of the candidate attention Discussion
image. The values of the uncertainty map of the 1st and 20th
In the transition of the approximate posterior distribution, the
attentions were biased toward the minimum value, whereas the
probability of â€œ1â€ was maximun at the 1st attention for all
values of the uncertainty map of the 4th and 13th attentions
characters from â€œ0â€ to â€œ9â€ that were verified. This is because,
were dispersed.
at the 1st attention, the sensory input image only includes the
Sensorimotor visual perception was performed by repeating
1st attention image capturing only points or short lines, and this
perceptual and active inferences. Figure 5 shows attention
is perceived as a part of â€œ1â€. In fact, the approximate posterior
images and sensory input images for each number of attentions
images also looked like â€œ1.â€ This is similar to the situation in
when making attentions from â€œ0â€ to â€œ9â€. Each subset of two
which humans temporarily labeled information (in this case,
rows corresponds to making attentions from â€œ0â€ to â€œ9â€. The
â€œ1â€) so that they could identify the environment based on the
first row shows the attention images (The rectangle area of each
information they had collected and their experience thus far and
image is the attention image). The second row shows the
moved on to the next action.
sensory input images. As the number of attention repetition
In the middle stage of attention repetition for most of the
increased, the visible area of a character became larger, and at
characters, a form that could not be identified as any shape was
the 20th attention, except â€œ3â€, most of the characters were
shown in the approximate posterior image; accordingly, the
visible enough to be recognized by humans as numbers. At the
approximate posterior distribution fluctuated among various
20th attention of â€œ3â€, however, a part of â€3â€ was missing.
shapes during attention repetition. This situation is analogous
To analyze the case of making an attention at â€œ3â€, the initial
to a human making a decision without a specific classification
attention position was changed. Figure 6 shows transition of
label, considering the various possibilities when information is
approximate posterior distribution, attention image, and
uncertain.
sensory input image when the initial attention position was
While most characters fluctuated among various shapes in
changed to a position different from those in Figures 3 and 5 in
the middle stage of the attention, the period in which â€œ7â€ was
the case of making an attention at â€œ3â€. Similar to Figure 3 (d),
higher was maintained in the middle stage of the attention
the probability of â€œ1â€ was maximum from the 1st to 4th
repetition when making the attention of â€œ2â€. This is because the
attentions, and the approximate posterior image at that time
shape of â€œ2â€ includes the shape of â€œ7â€, and â€œ7â€ appears first in
contained shapes that were difficult to recognize as characters.
this attention-position order. In fact, the approximate posterior
Different from Figure 3 (d), the probabilities of â€œ1â€, â€œ3â€, and
image in the middle stage of the attention repetition was â€œ7â€.
â€œ5â€ changed to maximum after the 5th attention, and the
In the early stages of attention repetition, the probability of
probability of correct character â€œ3â€ reached maximum at the
a particular number in the approximate posterior distribution
20th attention. The probability image contained â€œ3â€.
will not increase wherever the next attention is made. The
* Attention image is rectangular area ( ) Number of attention repetitions
Number of attention repetitions extracted from MNIST dataset image. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
1st to 10th attentions 11th to 20th attentions
ğœ™ğ‘¥ğ‘¡
ğ‘¥
|ğ‘¡
ğ‘
ğ‘¥ğ‘¡ ğ‘¥ğ‘¡
Figure 6 Attention images, sensory input images, and transition
of approximate posterior distribution. Changes in initial
attention position when making attention at â€œ3â€ provides
different transition patterns.
again biased toward the minimum-value side. This is a situation
in which the probability of a particular number in the
approximate posterior distribution has already been high, and
the entropy of this distribution is low no matter where the next
attention position is. For this reason, the range was smaller than
that of the uncertainty map in the early stage of attention
repetition in which the distribution was similarly biased.
In the transition of attention images, the attention-position
movement was along the line of the character, but not a
complete â€œone-strokeâ€. This is because the approximate
Figure 5 Transition of attention images and sensory input posterior image is not necessarily the image with the correct
images. Each subset of two rows corresponds to making number. A number different from the correct number is shown
attentions from â€œ0â€ to â€œ9â€. First row shows attention images* in the approximate posterior image from the early to middle
and second row shows sensory input images along with number stages of attention repetition, and the uncertainty is calculated
of attention repetitions. using the approximate posterior image. Even at the final stage
of the attention repetition, due to the randomness of the VAE,
distribution of the uncertainty map is thus biased toward the a random movement can also be seen along the character line.
minimum value of the uncertainty. In this case, the difference When making an attention at â€œ3â€, different initial attention
in the value included in the uncertainty map is mainly due to positions confirmed both cases in which the probability of
the random number included in the VAE calculation and correct characters became the highest and that of different
considered to be in the situation equivalent to random selection characters became the highest after a fixed number of attention
of the next attention position. This is similar to a situation in repetitions. This result suggests that the proposed system has a
which a human takes a random attention action to obtain clues confirmation bias similar to humans that depends on what is
in an unknown environment. obtained from the environment and prior knowledge about the
In the middle stage of the attention repetition, the number environment. The human confirmation bias has a negative
can be specified depending on the next sensory input image impact on decision-making in various fields, from politics to
determined with attention position, so the distribution of the science and education (Kappes, A., 2020). Whereas, the
uncertainty map is more dispersed than that in the early stage confirmation bias has the advantage of adaptability to unknown
of attention repetition. This is equivalent to a human taking environments. General optimization problems require complete
actions to increase the certainty of a certain number when the models of the environment, but lack of environmental
likelihood of that number increases. information and time constraints cannot provide complete
In the final stage of attention repetition, most regions of models in most practical cases. In these cases, humans take the
numbers have already become visible in the approximate next action on the basis of the confirmation bias made of
posterior image; thus, the distribution of the uncertainty map is
previous experiences. Taking the next action (exploring action) Gregor, K., Danihelka, I., Graves, A., Rezende, D. J., and Wierstra, D.
enables making decisions in practical time and obtaining the (2015). DRAW: A Recurrent Neural Network For Image Generation.
Proceedings of the 32nd International Conference on Machine
environmental information. We believe that our results will
Learning, pages 1462â€“1471.
help solve the previously difficult problem of triggering action
Houthooft, R., Chen, X., Chen, X., Duan, Y., Schulman, J., De Turck, F.,
in an unknown environment. and Abbeel, P. (2016). VIME: Variational Information Maximizing
Exploration., Advances in neural information processing systems 29,
pages 1109â€“1117.
Conclusion Ji, S., Parr, R., Li, H., Liao, X., and Carin, L. (2007). Point-based policy
iteration., Proceedings of the 22nd National Conference on Artificial
We proposed an embodied system based on the free energy Intelligence (AAAI), pages 1243â€“1249.
principle (FEP) for sensorimotor visual perception. We Kappes, A., Harvey, A.H., Lohrenz, T., Montague, P.R., and Sharot, T.
(2020). Confirmation bias in the utilization of othersâ€™ opinion
evaluated the proposed system in a character-recognition task
strength. Nature Neuroscience, 23: 130â€“137.
using the MNIST dataset. The proposed embodied system is
Kingma, D.P. and Welling, M. (2014). Auto-Encoding Variational Bayes.,
configured by a body and memory. By limiting body and 2nd International Conference on Learning Representations
memory abilities and operating according to the FEP, the (ICLR2014.)
proposed system triggers an action that moves an attention Land, M. F. (2006). Eye movements and the control of actions in everyday
position and repeatedly performs perceptual and active life. Progress in Retinal and Eye Research, 25(3): 296â€“324.
LeCun, Y. and Cortes, C. (1998). MNIST handwritten digit database.
inferences. In the evaluation, as the number of repetitions
http://yann.lecun.com/exdb/mnist/. Last accessed on 23/04/2020.
increases, the attention area moves continuously, gradually
Lotter, W., Kreiman, G., and Cox, D. (2017). Deep predictive coding
reducing the uncertainty of the characters. Finally, the networks for video prediction and unsupervised learning., 5th
probability of the correct character becomes the highest among International Conference on Learning Representations (ICLR2017.)
the characters. It was thus confirmed that the embodied system Mandelbaum, J. and Sloan, L. L. (1947). Peripheral Visual Acuity*: With
greatly contributes to achieving sensorimotor visual Special Reference to Scotopic Illumination. American Journal of
Ophthalmology, 30(5): 581â€“ 588.
perception. Moreover, changing the initial attention position
McGregor, S., Baltieri, M., and Buckley, C. L. (2015). A minimal active
provides a different final distribution, suggesting that the
inference agent., arXiv preprint arXiv:1503.04187.
proposed system has a confirmation bias similar to humans. We Oh, J., Guo, X., Lee, H., Lewis, R., and Singh, S. (2015). Action-
believe that these results will help solve the difficult problem Conditional Video Prediction Using Deep Networks in Atari Games.,
of triggering action in an unknown environment. Advances in neural information processing systems 28, pages 2863â€“
2871.
Oord, A., Kalchbrenner, N., and Kavukcuoglu, K. (2016). Pixel Recurrent
Neural Networks., Proceedings of the 33rd International Conference
on Machine Learning, pages 1747â€“1756.
References
Oâ€™Regan, J. K. (2001). Experience is not something we feel but something
we do: a principled way of explaining sensory phenomenology, with
Change Blindness and other empirical consequences.
Adams, R. A., Shipp, S., and Friston, K. J. (2013). Predictions not http://nivea.psycho.univ-paris5.fr/ASSChtml/Pacherie4.html. Last
commands: active inference in the motor system. Brain Structure and accessed on 23/04/2020.
Function, 218(3):611â€“643. Oâ€™Regan, J. K. and NoÃ«, A. (2001). A sensorimotor account of vision and
Bogacz, R. (2017). A tutorial on the free-energy framework for modelling visual consciousness. The Behavioral and Brain Sciences, 24(5):939â€“73;
perception and learning. Journal of Mathematical Psychology, discussion 973â€“1031.
76:198â€“211. Pineau, J., Gordon, G., and Thrun, S. (2003). Point-based value iteration:
Buckley, C. L., Kim, C. S., McGregor, S., and Seth, A. K. (2017). The free An anytime algorithm for POMDPs., International Joint Conference
energy principle for action and perception: A mathematical review. on Artificial Intelligence (IJCAI) , pages 1025â€“1032.
Journal of Mathematical Psychology, 14:55â€“79. Rezende, D. J., Mohamed, S., and Wierstra, D. (2014). Stochastic
Cheng, G., Hyon, S., Morimoto, J., Ude, A., Colvin, G., Scroggin, W., and Backpropagation and Approximate Inference in Deep Generative
Jacobsen, S. C. (2006). CB: A Humanoid Research Platform for Models., Proceedings of the 31st International Conference on
Exploring NeuroScience. 2006 6th IEEE-RAS International International Conference on Machine Learning (ICML2014), pages
Conference on Humanoid Robots, pages 182â€“187. 1278â€“1286.
Fitzpatrick, P., Metta, G., Natale, L., Rao, S., and Sandini, G. (2003). Salimans, T., Karpathy, A., Chen, X., and Kingma, D. P. (2017).
Learning about objects through action - initial steps towards artificial PixelCNN++: Improving the PixelCNN with Discretized Logistic
cognition. 2003 IEEE International Conference on Robotics and Mixture Likelihood and Other Modifications., 5th International
Automation, pages 3140â€“3145. Conference on Learning Representations (ICLR2017.)
Friston, K. J. (2010). The free-energy principle: a unified brain theory? Seth, A. K. (2015). The Cybernetic Bayesian Brain: From Interoceptive
Nature Reviews Neuroscience, 11:127â€“138. Inference to Sensorimotor Contingencies. Open MIND, 35.
Friston, K. (2011). Embodied inference: or "I think therefore I am, if I am Seth, A. K., Suzuki, K., and Critchley, H. D. (2012). An interoceptive
what I think". The implications of embodiment: Cognition and predictive coding model of conscious presence. Frontiers in
communication, 89â€“125. psychology, 2:395.
Friston, K., FitzGerald, T., Rigoli, F., Schwar tenbeck, P., and Pezzulo, G. Silver, D. and Veness, J. (2010). Monte-Carlo planning in large POMDPs.,
(2017). Active Inference: A Process Theory. Neural Computation, Advances in neural information processing systems, pages 2164â€“
29(1):1â€“49. 2172.
Friston, K. and Kiebel, S. (2009). Predictive coding under the free-energy Szegedy, C., Liu, W., Jia, Y, Sermanet P., Reed, S., Anguelov, D, Erhan,
principle Philosophical Transactions of the Royal Society B: D., Vanhoucke V., and Rabinovich, A. (2015). Going Deeper With
Biological Sciences, 364(1521):1211â€“1221. Convolutions., The IEEE Conference on Computer Vision and
Friston, K., Kilner, J., and Harrison, L. (2006). A free energy principle for Pattern Recognition (CVPR), pages 1â€“9.
the brain. Journal of Physiology-Paris, 100:70â€“87.
Gallagher, S. and Allen, M. (2018). Active inference, enactivism and the
hermeneutics of social cognition. Synthese, 195: 2627â€“2648.