1 of 15Psychophysiology, 2025; 62:e70113
https://doi.org/10.1111/psyp.70113
Psychophysiology
ORIGINAL ARTICLE OPEN ACCESS
Active Inference in Music Perception: Motor Engagement to 
Syncopation Modulates Rhythmic Prediction Error
Kai Ishida  |  Hiroshi Nittono
Graduate School of Human Sciences, The University of Osaka, Osaka, Japan
Correspondence:  Kai Ishida (ishida@hus.osaka-u.ac.jp )
Received:  8 January 2025 | Revised:  3 June 2025 | Accepted:  11 July 2025
Funding:  This work was supported by Japan Society for the Promotion of Science (Grant JP22KJ2199).
Keywords: active inference | free energy principle | groove | mismatch negativity | predictive coding | rhythm perception | Shannon surprise
ABSTRACT
In active inference, the sensory surprisal (a log-  probability of sensory data) of the prediction error between prediction and sen -
sory input is modulated by action. The urge to move (groove) induced by syncopation, which provides metric uncertainty, can 
be considered a case of active inference in music perception. The present study investigated whether rhythmic prediction error is 
modulated by improving the precision of rhythm perception through tapping in sync with the rhythm. Thirty-  five participants 
listened to a rhythmic sequence while tapping the half-  note beat (tapping condition) or holding a pillow (no- tapping condition), 
and electroencephalography (EEG) was recorded. In both conditions, the onset of the syncopated tone was rarely earlier (tim -
ing deviant: 20%) than the standard (80%). The timing deviant elicited mismatch negativity (MMN) in both the tapping and 
no- tapping conditions, reflecting a prediction error in timing. Moreover, the MMN was larger in the tapping condition than 
in the no-  tapping condition, which may indicate increased precision due to tapping, even when motor-  related potentials were 
controlled for. Neural entrainment was measured by calculating intertrial phase coherence (ITPC), which reflects oscillatory 
activity synchronized to stimulus frequency, and ITPC differed between the two conditions at beat-  related frequencies. These 
results suggest that tapping enhanced meter and beat information and reduced the sensory surprisal of syncopation, resulting in 
a larger precision- weighted prediction error. These effects were not due to physiological arousal differences between conditions, 
as assessed by EEG power and heart rate variability. These results are discussed as evidence that bodily engagement modulates 
sensory prediction error within the active inference framework.
1   |   Introduction
Humans enjoy moving and dancing to music. How does the 
human brain give rise to this complex engagement with music? 
One possible framework for explaining this musical phenom -
enon is active inference via the free energy principle (Vuust 
et al. 2018; Vuust and Witek 2014). The free energy principle ex-
plains perception, learning, and action in terms of free energy 
minimization (Friston  2005, 2010, 2012). The characteristics of 
agents (biological systems) are the maintenance of their states 
and forms in a constantly changing environment. Thus, the rep -
ertoire of agents' physiological and sensory states is limited. This 
means that the probability of sensory states of interoception and 
exteroception must have low entropy, where only a limited num-
ber of states occur with high probability (Friston 2010). Here, en-
tropy is the expected value of the information-  theoretic surprise 
(i.e., Shannon surprise) of the sensory input. Surprise, a log- 
probability of sensory data, is provided by a prediction error be -
tween the sensory input and prediction (Buckley et al.  2017). To 
avoid confusing the term surprise with the everyday language of 
surprise, which has a psychological meaning, the present study 
uses “surprisal” as per Buckley et al. (2017). Because free energy 
is an upper bound on surprisal, minimizing free energy leads 
to the suppression of surprisal (Friston  2010). Therefore, agents 
This is an open access article under the terms of the Creative Commons Attribution-NonCommercial License, which permits use, distribution and reproduction in any 
medium, provided the original work is properly cited and is not used for commercial purposes.
© 2025 The Author(s). Psychophysiology  published by Wiley Periodicals LLC on behalf of Society for Psychophysiological Research.
2 of 15
 Psychophysiology, 2025
perceive, learn, and act to minimize free energy in order to 
suppress surprisal. Free energy can be suppressed by changing 
sensory input through action or by updating the agent's inter -
nal model of the environment (Buckley et al.  2017). The former 
is known as active inference, which involves changing sensory 
input to suppress prediction errors that lead to sensory surprisal.
In music perception, action induced by music can be related to 
active inference. For example, when we listen to jazz and dance 
music, we feel the urge to move or dance. This sensation has 
been defined as groove and is accompanied by pleasure (Etani 
et  al.  2024; Janata et  al.  2012; Stupacher et  al.  2022; Vuust 
et al.  2018). Groove is induced by medium levels of complexity, 
which are often indexed by the degree of syncopation (Sioros 
et al. 2014; Witek et al. 2014). Rhythm is the organized pattern of 
variable note durations. When we hear the rhythmic sequence, 
we feel a sense of beat—a regularly repeating pulse—and the 
meter patterns the beats into strong and weak beats. A synco -
pated rhythm creates a deviation by shifting the tone onset from 
the metrically strong beat to the weak beat (Temperley  1999). 
Therefore, syncopation generates a prediction error between the 
metric prediction and the actual tone onset, resulting in higher 
sensory surprisal and entropy during rhythmic perception. In 
this situation, the urge to move may stem from a desire to reduce 
the surprisal that leads to sensory uncertainty by changing the 
precision of the sensory input through actions that establish beat 
or meter.
Several studies have discussed the origin of the groove sensa -
tion in terms of the link between action and perception (Vuust 
et  al.  2018, 2022; Witek  2017; Witek et  al.  2017; Vuust and 
Witek 2014). Witek et al. ( 2017) proposed that the gap afforded 
by syncopation invites the body to fill in for a phenomenally 
perceived accent without actual sound input. This study ar -
gued that the body becomes the beat, manifesting the beat pulse 
through which the groove is understood and completed. Groove 
sensation has also been explained in terms of predictive pro -
cessing under active inference (Vuust et al.  2018, 2022). Vuust 
et al. (2018) proposed that the prediction error induced by rhyth-
mic incongruence (i.e., syncopation) is weighted by the preci -
sion of the sensory input, which is the inverse of variance. They 
also considered that the repeated syncopation pattern induces a 
feeling of urge to move (groove) to strengthen the metric model, 
which leads to a reduction of surprisal (entropy) in rhythmic 
prediction. Previous studies have also demonstrated that tap -
ping improves timing perception in the detection of timing de -
viation (Manning and Schutz  2013, 2016) and in the extraction 
of subjective pulse or temporal structures (Su and Pöppel  2012). 
Therefore, bodily engagement that enhances meter or beat in -
formation seems to improve precision in rhythmic perception by 
reducing sensory surprisal. The present study investigated em -
pirical evidence for active inference during rhythmic prediction.
Rhythmic prediction can be examined using event-  related po -
tentials (ERPs) in electroencephalography (EEG). Mismatch 
negativity (MMN), which reflects neural prediction error, has 
been regarded as an indicator of predictive processing in the 
auditory modality (Friston  2005; Garrido et  al.  2009; Winkler 
and Czigler 2012). MMN is recorded using an oddball paradigm 
in which tones with different characteristics are presented in 
a sequence with high (standard) and low (deviant) probability. 
The latter tone, which deviates from a regularity formed from 
standard tone characteristics, elicits an MMN, typically in the 
front- central scalp region, for about 100–250 ms (Fishman 2014; 
May and Tiitinen  2010; Näätänen et  al.  2005, 2007; Picton 
et  al. 2000). The MMN is a neural prediction error, reflecting 
surprisal in the sensory input (Friston  2005). Vuust et al. (2009) 
showed that syncopated rhythms elicit MMN, reflecting the 
violated expectations provided by the temporal grid or meter. 
Moreover, Lumaca et  al.  (2019) examined the relationship be -
tween the size of MMN amplitude and Shannon entropy, which 
relates to sensory uncertainty in the rhythmic context. In their 
study, the MMN response elicited by a small deviant that oc -
curred 100 ms earlier than the standard tone was larger when 
the rhythmic context was simple (low entropy) than when the 
rhythmic context was complex (high entropy). Therefore, the 
MMN reflects a precision-  weighted prediction error, and its 
magnitude is influenced by precision, which varies with the en -
tropy or uncertainty of the sensory input (Koelsch et al.  2019; 
Quiroga- Martinez et al. 2019, 2020; Tsogli et al. 2022).
The present study investigated whether prediction error in 
syncopated rhythm is modulated by a tapping action that en -
hances meter information using syncopation. To examine this, 
participants performed tapping and no-  tapping conditions 
while listening to a rhythmic sequence. In the tapping condi -
tion, participants tapped with their index finger on the half note 
beat, corresponding to a strong beat in the meter, while in the 
no- tapping condition, they held a pillow while concentrating on 
the rhythmic sequence. The effect of the action on prediction 
error in rhythmic prediction was measured by recording MMN, 
as its amplitude is modulated by precision or sensory entropy 
(Lumaca et  al.  2019). The rhythmic pattern was occasionally 
violated by one of the syncopated tones presented earlier (tem -
poral deviant) than the original (standard). Because tapping in -
volves motor- related potentials, the ERP during silent tapping 
was subtracted from the standard and deviant ERPs. This motor 
correction is based on methods used in research on omitted 
stimulus potentials. In this research, the ERP associated with 
a button press alone is subtracted from the ERP elicited when 
an expected stimulus is omitted after the button is pressed 
(Dercksen et  al.  2020; Ishida and Nittono 2024b ). Therefore, 
the difference in MMN amplitude between the tapping and no- 
tapping conditions cannot be attributed to differences in motor- 
related potentials. If action that enhances meter information 
modulates prediction error by changing sensory uncertainty, the 
MMN amplitude would be larger in the tapping condition than 
in the no- tapping condition, reflecting prediction error weighted 
by the precision of the sensory input.
In addition to MMN, neural entrainment during rhythmic lis -
tening was measured by intertrial phase coherence (ITPC) to 
examine the enhancement of meter, beat, and rhythm informa -
tion in the brain. ITPC is a measure of the phase consistency 
of brain activity that is time-  locked to stimulus presentation 
(Van Diepen and Mazaheri  2018; Varela et  al.  2001). It has 
been used to investigate the entrainment of neural oscilla -
tions in response to frequent stimuli during rhythm listening 
(Cameron et al.  2019) and statistical learning (Batterink and 
Paller 2017, 2019). Stefanics et al. ( 2010) showed that the more 
predictable the rhythmic stimulus, the more accurately the 
phase of neural oscillations was locked to the expected timing 
3 of 15
of the tone onset. They also found that entrainment was sig -
nificantly correlated with reaction time to the cued tone. 
Therefore, if tapping enhances meter information, the ITPC of 
the beat frequency (ITPC two-  beat) would be greater in the tap -
ping condition than in the no-  tapping condition. We further 
explored the difference in the ITPCs of rhythm (ITPC rhythm ) 
and four-  beat (ITPC four- beat) frequencies.
Groove sensation was measured using questionnaire items based 
on previous studies that examined the degree of syncopation 
and groove sensation (Matthews et al.  2019; Witek et al.  2014). 
Groove was defined as “the sensation of wanting to move some 
part of your body in relation to some aspect of the music,” as per 
Sioros et al. (2014). Three aspects of groove sensation were sub -
jectively measured: the extent to which participants felt the want 
to move, the extent to which this want was satisfied, and the 
degree of pleasure experienced while listening to the rhythm. 
We hypothesized that pleasure would be higher in the tapping 
condition than in the no-  tapping condition because the urge 
to move is satisfied by modulating sensory uncertainty in the 
rhythmic context through tapping.
2   |   Methods
2.1   |   Participants
Power analysis was conducted using G*power (Faul 
et al. 2007 ). Although we were primarily interested in the dif -
ference between tapping and no-  tapping conditions, none of 
the other studies examined this. Therefore, assuming a me -
dium effect size of dz  = 0.5, a sample size of N  = 34 was cal -
culated with power 1 − β = 0.80 and error rate α  = 0.05. Note 
that Vuust et al.'s ( 2012) data on the rhythmic-  deviant MMN 
suggested an effect size of dz  = 1.75 (t(10) = 5.82 in the nonmu -
sician group), resulting in a sample size of N  = 5 with power 
1 − β = 0.80 and error rate α  = 0.05. Considering the data ex -
clusion, 40 participants were sampled and randomly assigned 
to two groups with different orders of tapping and no-  tapping 
conditions to counterbalance the order of conditions: Group 
I was tapping to a no-  tapping order and Group II was no-  
tapping to a tapping order. Finally, data from 35 participants 
(16 women and 19 men, 18–27 years old, M = 21.3 years, equal 
number of participants for each group) were used for hypoth -
esis testing after the exclusion of five participants. These five 
participants were excluded because the number of deviant 
trials in either the tapping or no-  tapping condition fell below 
the predetermined threshold of 70 due to excessive noise. Of 
these, 33 participants were right-  handed, one was left-  handed, 
and one was ambidextrous, as per the FLANDERS handed -
ness questionnaire (Okubo et  al.  2014). None of the partici -
pants had a hearing impairment or a history of neurological 
or cardiovascular disease. The participants' musical ability 
was assessed using the Japanese Gold-  MSI questionnaire 
(Sadakata et al.  2023; the original is Müllensiefen et al.  2014): 
general sophistication ( M = 62.3, SD = 22.3), as well as sub -
scales of active engagement ( M = 30.3, SD = 10.9), perceptual 
abilities ( M = 39.9, SD = 10.9), musical training ( M = 20.3, 
SD = 10.5), emotions (M = 30.3, SD = 5.6), and singing abilities 
(M = 23.0, SD = 9.0). Moreover, according to the Gold-  MSI, 
participants had various experience with formal instruction 
of musical instruments (20 participants had 0 years, two had 
0.5 years, two had 1 year, one had 2 years, seven had 3–5 years, 
two had 6–9 years, and six had 10 or more years of experi -
ence) and music theory (29 participants had 0 years, three had 
0.5 years, two had 1 year, one had 2 years, two had 3 years, 
two had 4–6 years, and one had 7 or more years of experi -
ence). This study's protocol was approved by the Behavioral 
Research Ethics Committee of Osaka University School of 
Human Sciences, Japan (HB024-  015), and written informed 
consent was obtained from all participants. Participants re -
ceived a cash voucher of 4000 Japanese yen as an honorarium.
2.2   |   Stimuli and Procedure
Figure  1 shows an example of the rhythmic sequence. Because 
the complex syncopated rhythm reduced the ability to tap syn -
chronously (Fitch and Rosenfeld  2007 ), a simple syncopated 
rhythm was created. The tones of the rhythmic sequence were 
generated by the cowbell timbre of MuseScore 3 (Version 
3.6.2.548021803, Werner Schweer) and edited using Audacity 
3.4.2 (Audacity Team  2014). The rhythm was played at 200 
BPM, and a sequence consisted of eight bars. In the first bar, 
two half notes were presented as a two-  beat introduction. 
In the second bar, no notes were presented. The syncopated 
rhythm was then presented in the third through eighth bars. 
The second note of the rhythm was rarely presented 50 ms ear-
lier than the standard (shown in blue in Figure  1) as a timing 
deviant (shown in red in Figure  1). This corresponds to an 
8.33% deviation of the interbeat interval (per 600 ms). Since 
the cowbell tone included a decay phase, the deviant shifted 
50 ms earlier could also be interpreted as a duration deviant 
relative to the preceding tone. However, because this deviant 
appeared in both the tapping and no-  tapping conditions, it 
could not explain the difference in MMN amplitudes between 
the two. A 9.6-  s sequence was presented 100 times with no in -
terstimulus interval (0 ms) in both the tapping and no-  tapping 
conditions. The total number of trials for the standard and de -
viant conditions was 600 bars (trials), counting the third to 
eighth bars of a sequence. Of these, 480 trials (i.e., 80% of the 
bars) were standard, and 120 trials (20% of the bars) were devi -
ant. The deviant could occur at any position from the third to 
the eighth bar. Therefore, the timing deviant was expected to 
elicit the MMN reflecting a violation of the syncopated rhyth -
mic pattern.
Participants were administered both the tapping and no-  
tapping conditions. Each condition consisted of four blocks, 
with 25 sequences presented per block (approximately 4 min 
each). In the tapping condition, they were asked to tap on the 
half note beat with the index finger of their dominant hand and 
to not move any other part of their body. No notes were pre -
sented in the second bar of a sequence to facilitate beat predic -
tion by tapping because trying to maintain tapping generates 
predictions. Prior to the experiment, practice was conducted 
by presenting four sequences consisting only of the standard 
rhythms (i.e., 32 bars for approximately 1 min) while visually 
presenting scores of two-  beat notes. Importantly, participants 
wore soundproof earmuffs over their earphones as an addi -
tional measure to prevent the tapping sound from overlapping 
with the rhythm sounds while tapping on pads that absorbed 
4 of 15
 Psychophysiology, 2025
the sound. Thus, the tapping sound did not overlap with the 
rhythmic sequence. In the no-  tapping condition, participants 
were asked to concentrate only on the rhythm and to hold a 
pillow with both hands and to not move any part of their body 
to prevent unconscious tapping while listening to the rhyth -
mic sequence. In both conditions, participants were asked to 
fixate on a point on the screen.
For the rhythm and trigger output, a stereo audio file was cre -
ated with the rhythm sequence in the first channel and the 
trigger sound indicating the onset of the tones in the second 
channel. These channels were output separately via a stereo-  to- 
monoaural splitter cable. The rhythm channel was connected 
to left and right headphones (MDR-  EX650AP; SONY, Tokyo, 
Japan) at 60 dB SPL. The trigger channel was connected to an 
auditory signal detector (StimTrak; Brain Products, Gilching, 
Germany), which immediately (< 1 ms) sent a trigger to an elec -
troencephalography (EEG) amplifier.
Groove sensation was quantified using three questionnaire 
items—using 5-  point scales—answered after the fourth 
block of EEG recordings for both the tapping and no-  tapping 
conditions:
• Q1. To what extent does the rhythm make you want to 
move?
• Q2. To what extent was the feeling of wanting to move 
resolved?
• Q3. How much pleasure do you experience listening to the 
rhythm?
Q1 and Q3 followed previous studies examining groove 
(Matthews et  al.  2019; Witek et  al.  2014). However, unlike 
previous studies where participants only listened passively, this 
study involved active tapping that allowed participants to move. 
Therefore, the extent to which their desire to move was satisfied 
was assessed in Q2. Participants were asked to recall how they 
felt while they were tapping. After completing the groove- related 
questions, participants answered the Emotion and Arousal 
Checklist (EACL; Oda et  al.  2015), consisting of five emotion 
factors (fear, anger, sadness, disgust, and joy) and four arousal 
factors (energy positive, energy negative, tension positive, and 
tension negative). Participants rated how well the adjective for 
each emotion and arousal factor matched their feelings while 
listening to the rhythm on a 4-  point scale ranging from 0, Not 
at all , to 3, Ver y much. Including electrode preparation, EEG 
recording, the questionnaire session, and short breaks between 
blocks, the entire experiment took approximately 2 h.
2.3   |   Data Recording
Physiological data were recorded using QuickAmp (Brain 
Products, Germany) with Ag/AgCl electrodes. For EEG record -
ing, 34 scalp electrodes were placed according to the 10–20 sys -
tem (Fp1/2, F3/4, F7/8, Fz, FC1/2, FC5/6, FT9/10, C3/4, T7/8, 
Cz, CP1/2, CP5/6, TP9/10, P3/4, P7/8, Pz, O1/2, Oz, PO9/10). 
Additional electrodes were placed on the left and right mastoids, 
the left and right outer canthi of the eyes, and above and below 
the right eye. Data were referenced offline to the nose electrode. 
The sampling rate was 1000 Hz, and the online filter was DC–
200 Hz. Electrode impedances were kept below 10 kΩ. The elec -
trocardiography (ECG) was recorded bipolarly with two active 
electrodes at the left lower rib and the right clavicle site. The 
tapping response was recorded using a clip from the CLIPHIT 
drum module (Korg, Tokyo, Japan), which detects a vibration of 
tapping and sends a signal to StimTrack with a delay of < 1 ms.
FIGURE 1     |    Rhythmic sequence and tapping and no-  tapping conditions. The target was the syncopated eighth note. The blue note indicates the 
standard with the correct timing, and the red note indicates the deviant, which had a 50 ms earlier onset than the standard. In the tapping condition, 
participants tapped to the beat of the half note in time with the presented sound. In the no-  tapping condition, participants just concentrated on the 
presented sound while holding a pillow.

5 of 15
2.4   |   Data Reduction
2.4.1   |   ERP Data Reduction
EEG data were analyzed using EEGLAB (Delorme and 
Makeig  2004; version 2024.1). First, a finite-  impulse- response 
filter of 0.5–30 Hz was applied to the data, following the recom -
mendation of Zhang et al. ( 2024). Bad electrodes were removed 
for 12 participants before applying independent component 
analysis (ICA), and these electrodes were corrected by spheri -
cal interpolation after ICA. ICA with the InfoMax algorithm 
was applied to the filtered data to remove ocular, heartbeat, and 
muscle artifacts. The ADJUST algorithm (Mognon et al.  2011) 
was used to automatically detect artifact ICs, which were manu-
ally rejected after visual inspection.
For MMN without motor correction, data were segmented into 
a 400 ms period: 100 ms before and 300 ms after the standard 
and deviant onsets (for a maximum of 120 trials each). This 
epoch was predefined to ensure that successive tones did not 
overlap with it, and a baseline correction was performed by 
subtracting the mean amplitude of the 100 ms pre-  stimulus 
period from each point of the waveform. Finally, epochs with 
voltages exceeding ±80 μV in any channel were removed. 
Valid trials were then averaged for the standard and deviant 
in the tapping and no-  tapping conditions, respectively. The 
mean number of averaged deviant epochs was 117 (Min–
Max = 101–120) for the tapping condition and 119 (114–120) 
for the no-  tapping condition.
For MMN with motor correction, data were segmented into 
a 1800 ms period: 1000 ms before and 800 ms after the onset 
of standard, deviant, and no-  sound tapping (see Figure  1). To 
extract the motor-  related potentials associated with tapping 
at 0 and 600 ms (relative to the start of the bar) and subtract 
them from the ERP waveforms of the standard and deviant 
conditions, it was necessary to obtain ERP waveforms span -
ning from the end of the standard to the beginning of the bar. 
The duration from the beginning of the bar to the end of the 
standard ERP epoch was 750 ms, and to the end of the devi -
ant ERP epoch was 700 ms. Therefore, aligning the onset of 
the standard, deviant, and no-  sound tapping conditions at 
0 ms, setting the baseline to − 1000 to 0 ms, and extending 
the end of the epoch generously to 800 ms ensures that the 
no- sound tapping epoch includes the − 100 to 300 ms window 
of the standard and deviant ERPs. In this way, ERP epochs 
of sufficient length were extracted, and the ERP waveforms 
during silent tapping were subtracted from those of the stan -
dard and deviant trials. Therefore, in the initial stage of motor 
correction, longer epochs were extracted compared to those 
used for the MMN without motor correction. After motor cor -
rection, the length of the epochs was adjusted to match that 
of the MMN without motor correction. In the segmentation, 
epochs with voltages exceeding ±80 μV in any channel were 
removed. The mean number of averaged deviant epochs was 
114 (Min–Max = 95–120) for the tapping condition and 116 
(109–120) for the no-  tapping condition. The epochs were then 
averaged. Subsequently, the average ERP of the no-  sound tap -
ping (motor-  related ERP) was subtracted from the average 
ERP of the standard and deviant after aligning their positions 
with the bar lines. Then, the onset of the standard and deviant 
was aligned to 0 ms, and the data were edited into a 400 ms 
epoch ranging from − 100 to 300 ms. A baseline correction 
was performed using the − 100 to 0 ms pre-  stimulus interval. 
In addition to the subtraction method, another motor correc -
tion was performed to confirm that the MMN amplitude was 
still enhanced in the tapping condition compared to the no-  
tapping condition, with nearly identical peak latencies. This 
check was reported in Supporting Analysis S2 .
The calculation method of the MMN was the same for ERPs 
with and without motor correction. The deviance-  related dif -
ference waveforms were calculated by subtracting the stan -
dard ERP waveforms from the deviant ERP waveforms (i.e., 
deviant—standard) in two conditions. Five frontal electrodes 
(F7, F3, Fz, F4, and F8) were then clustered for statistical eval -
uation, as in previous studies (Ishida and Nittono  2022 , 2024a , 
2024b). The difference grand-  averaged ERP waveforms—av -
eraged in participants' difference waveforms—of the tapping 
and no-  tapping conditions were further averaged. The most 
negative peak was detected in the 100–250 ms time window on 
the final difference grand-  averaged waveform, and the 40 ms 
period centered around the negative peak was defined as the 
MMN interval. Therefore, 174–214 ms (peak was 194 ms) and 
176–216 ms (peak was 196 ms) were used to calculate the mean 
MMN amplitudes without and with motor correction for the 
two conditions.
2.4.2   |   Intertrial Phase Coherence
Neural entrainment to the rhythmic sequences was quan -
tified by calculating the ITPC, whose value ranges from 0 
(non–phase-  locked) to 1 (fully phase-  locked). To calculate 
ITPC values in the two conditions, six of the eight bars were 
used from the second to the eighth bar, in which the synco -
pated rhythm was presented. The maximum epoch of the 
six bars was 100 (sequences) in each tapping condition, and 
this epoch was extracted after ICA-  based artifact correction 
in EEG preprocessing. To capture the phase synchronization 
of the EEG at the frequencies of the rhythm (0.833 Hz) and 
the four-  beat (3.33 Hz), an epoch long enough to encompass 
more than one cycle of the rhythm was needed. This corre -
sponds to one bar. Therefore, ITPC was calculated using ep -
ochs from a single sequence. Since all 100 sequences included 
deviant trials, ITPC was calculated including deviant trials. 
Because ITPC was calculated with deviant trials in both the 
tapping and no-  tapping conditions, the inclusion of deviant 
trials cannot explain the difference in ITPC between the 
two conditions. ITPC was computed using a Morlet wavelet 
transform from 0.5556 to 5 Hz in steps of 0.1389 Hz to extract 
rhythm-  and beat-  related frequencies. The calculation was 
performed using the newtimef function of EEGLAB (Delorme 
and Makeig  2004 ). Finally, the ITPC calculated at each of the 
34 scalp electrodes was averaged. Because averaging ITPCs 
across the whole scalp may include motor-  or tactile-  related 
potentials during tapping, differences in ITPCs were explor -
atorily examined across regions of interest (ROIs) and are re -
ported in Supporting Analysis S3 . The ITPC of 0.8333, 1.6667, 
and 3.333 Hz was extracted for the evaluation of neural en -
trainment to rhythm (ITPC rhythm ), beat (ITPC two-  beat), and 
triplet (ITPC four- beat), respectively.
6 of 15
 Psychophysiology, 2025
2.4.3   |   Power Spectral Density
The power spectral density (PSD) of theta and alpha power in 
EEG was calculated to rule out the possibility that differences in 
MMN and ITPC between conditions were due to differences in 
neurophysiological arousal. EEG data were filtered at 1–60 Hz 
(finite- impulse- response filter) and used to calculate the PSD. 
The full range of each tapping and no-  tapping condition block 
was used for calculation, and blocks were segmented in 2.048 s, 
with an overlap of 1.024 s. The PSD was calculated using the 
fast Fourier transform with a Hanning window with the spec -
topo function of EEGLAB. Electrode clusters were formed for 
theta (4.0–8.0 Hz), alpha (8.0–13.0 Hz), and beta (13.0–30.0 Hz) 
bands (theta band: Fz, Cz, FC1, FC2; alpha and beta bands: P3, 
Pz, P4, O1, O2), and the total power of EEG was calculated and 
square root transformed. These channel clusters did not include 
interpolated channels. One participant with values greater than 
three times the third quartile of the data in the theta and beta 
bands was removed from the analysis as an outlier, resulting in 
N = 34 for the analysis of PSD.
2.4.4   |   ECG Data
ECG was preprocessed using a Python library, Neurokit2 
(Makowski et al.  2021), which can process biological data, in -
cluding ECG data. First, the ECG data were segmented into 
four blocks for each condition. The length of each block of data 
was approximately 4 min. Second, the data from each block 
were cleaned using the ecg_clean  function with the ‘neurokit’ 
method, which applies a 0.1–50 Hz Butterworth filter to the 
data. Third, the cleaned data were submitted to the ecg_peak  
function, which automatically detects R- peaks with artifact cor -
rection based on Lipponen and Tarvainen  ( 2019). Fourth, the 
preprocessed data were submitted to the hrv  function, which 
can calculate various heart rate variability (HRV) indices, in -
cluding root mean square of successive differences of RR inter -
vals (RMSSD), and heart rate (HR) and RMSSD were averaged 
over four blocks for each condition. Due to excessive noise and 
poor peak detection quality, one block from one participant and 
two blocks from another participant were excluded from averag-
ing. To examine the difference in physiological arousal between 
the tapping and no-  tapping conditions, HR and RMSSD were 
compared between the two conditions as indices of autonomic 
nervous system activity.
2.4.5   |   Tapping Performance
Tapping performance was evaluated using two types of 
measures. First, the inert-  tapping interval (ITI), defined 
as the interval (ms) between the previous and current taps, 
was calculated according to the method described by Patel 
et al. (2005). The mean and standard deviation (SD) of the ITI 
were computed as indices of tapping timing and variability, 
respectively. Second, tapping error was assessed by calcu -
lating the absolute difference (in milliseconds) between the 
correct and actual tapping times, averaged across all taps, 
following Tomyta et al. ( 2023). ITIs of ≤  100 ms or ≥ 1200 ms 
were excluded before computing the mean and SD of the ITI 
for each participant, as these values were considered to reflect 
double taps or missed taps. As a result, the average propor -
tion of excluded taps was 20.56% (SD = 28.26%). For the tap -
ping error calculation, taps with an absolute error exceeding 
300 ms were excluded from the average, resulting in a mean 
exclusion rate of 18.33% (SD = 26.68%). Due to technical issues 
such as malfunctioning recording equipment, participants for 
whom data were not completely recorded throughout an entire 
block were excluded from the analysis. Consequently, tapping 
performance was analyzed for the remaining 31 participants. 
Although tapping accuracy was relatively low compared to 
previous studies (e.g., Patel et al.  2005), participants with poor 
tapping accuracy were not excluded from the EEG analysis. 
This decision was based on the current study's aim to inves -
tigate how movement modulates rhythmic prediction, regard -
less of tapping accuracy. The analysis comparing the MMN 
and ITPC between groups divided by high and low tapping 
performance is reported in Supporting Analysis S4 .
2.5   |   Statistical Analysis
Both classical (frequentist) and Bayesian analyses were per -
formed using JASP 0.19.1 (JASP Team  2024). Bayes Factors 
(BF10 for two- tailed) were calculated to assess the absence (null 
hypothesis) or presence (alternative hypothesis) of the differ -
ence. The Cauchy distribution (scale parameter r of 0.707) was 
used as the prior distribution for the effect δ. For statistical eval-
uation, the type I error rate ( α) was set at 0.05. A BF 10 > 3 and a 
BF10 smaller than 0.33 (1/3) were considered moderate evidence 
for the alternative and null hypotheses, respectively, as per 
Schönbrodt and Wagenmakers (2018).
First, tapping performance (i.e., ITI and tapping error) was 
compared between the no-  sound tapping position and the 
rhythm position using classical and Bayesian paired t - 
tests. This comparison evaluated the validity of the motor-  
subtraction approach, which assumes that motor and tactile 
related potentials occur at the same timing due to consis -
tent tapping performance. Moreover, a one-  way repeated-  
measures ANOVA was conducted with the factor block (1–4) 
to examine how tapping performance changed throughout the 
experimental session.
Second, PSD (theta and alpha power), HRV indices, EACL 
scores, MMN amplitudes, and ITPCs were compared between 
conditions using traditional and Bayesian paired t - tests. An ef -
fect size of paired t - tests was calculated as dz = t∕
√
n. For mul-
tiple comparisons of ITPCs, p values were corrected using the 
Bonferroni method. For MMN and ITPC analyses, the group 
effect with different order of conditions was examined using a 
two- way mixed analysis of variance (ANOVA) with condition 
(tapping and no- tapping) and group (Group I and Group II). As 
no group effects were significant, the results of this analysis are 
not reported in the main text but in Supporting Analysis S1 .
Third, EACL scores were calculated as the total score of question 
items for each factor and compared between the two conditions. 
Ratings of the groove- related questions were compared between 
conditions using traditional and Bayesian Wilcoxon signed- rank 
sum tests because a 5-  point scale was used. The rank-  biserial 
correlation rB was reported as an effect size in the Wilcoxon 
7 of 15
signed- rank sum test. In the Bayesian Wilcoxon signed-  rank 
sum test, the sample size of the simulation was set to 1000.
Finally, correlations between MMN, ITPC, and groove-  related 
question ratings were analyzed exploratorily. Because the 
groove- related question ratings were included in the correla -
tion analysis, Spearman's rank correlation coefficient was cal -
culated. A false discovery rate (FDR) correction was applied 
for multiple comparisons in the correlation analysis ( q = 0.05). 
Additionally, the relationship between tapping performance and 
neural responses (MMN and ITPC) was examined exploratorily 
(see Supporting Analysis S5 ). The stimulus materials and data 
necessary to replicate the results are available at https://  osf. io/ 
nej9k/  .
3   |   Results
3.1   |   Tapping Performance
Table 1 shows the ITI and tapping error of each position. The 
grand means of the mean ITIs of all positions were around 616–
636 ms, close to the beat interval of 600 ms. The grand means of 
the SD of ITI were around 78–89 ms. Given the relatively high 
exclusion rate of tapping data (see Section  2.4) and the large SD 
of ITI, it is evident that tapping was difficult for some partici -
pants. The means of tapping error were around 72–86 ms. As 
with the ITI, the relatively large exclusion rate of tapping data 
(see Section 2.4) and the large standard deviation of tapping error 
indicate that not all participants were able to tap accurately.
Tapping performance was compared between the no-  sound and 
rhythm positions. A paired t - test of the mean ITI revealed no 
significant difference between the two positions, t (30) = 1.12, 
p = 0.271, dz = 0.20, BF 01 = 2.94, suggesting the absence of a 
difference in tapping performance. However, the SD of ITI, 
t(30) = −3.06, p = 0.005, dz = −0.55, BF 01 = 0.12, and the tap -
ping error were significantly different between the positions, 
t(30) = −4.91, p < 0.001, dz = −0.88, BF 01 = 0.001, suggesting a 
difference in tapping timing relative to the beat onset between 
the no-  sound tapping and rhythm positions. This difference 
in tapping performance is discussed as a limitation in the 
Discussion section.
The progression of tapping performance over the experimental 
session was examined by comparing the ITI and tapping error 
between blocks. A one-  way ANOVA revealed no significant 
effect for the mean ITI, F (3, 87) = 0.65, p = 0.511, ηp
2 = 0.022, 
Greenhouse–Geisser ε = 0.598, BF incl = 0.09, SD of ITI, F (3, 
87) = 0.58, p = 0.627, ηp
2 = 0.020, BFincl = 0.09, and tapping error, 
F(3, 87) = 0.40, p = 0.687, ηp
2 = 0.014, Greenhouse–Geisser 
ε = 0.721, BF incl = 0.07. These results suggest that tapping 
performance remained constant throughout the experimental 
session.
3.2   |   Physiological and Psychological Arousal
Possible differences in physiological and psychological arousal 
were tested by examining the PSD of EEG, HRV, and EACL 
checklist scores. Summary and test statistics of these measures 
are shown in Table  2. The PSDs of the theta, alpha, and beta 
bands were compared between the two conditions. The PSDs 
were not significantly different, and the absence of the effect 
was supported by the Bayes factor in either band. These results 
suggest that neurophysiological arousal was not different be -
tween the tapping and no- tapping conditions.
HR and RMSSD were compared between the tapping and no- 
tapping conditions using a paired t - test. None of the differences 
were statistically significant, and Bayes factors supported the 
null effects, suggesting that autonomic activity and physiolog -
ical arousal did not differ between conditions.
Psychological valence and arousal were compared between the 
two conditions using a paired t- test. For valence, joy was signifi-
cantly higher in the tapping condition than in the no-  tapping 
condition. For arousal, energy positive, energy negative, and 
tension negative were significantly different between the two 
conditions, indicating that psychological arousal was higher in 
the tapping condition than in the no- tapping condition.
3.3   |   Comparison of the Tapping and No- Tapping 
Conditions
Figure  2 shows the grand average waveforms and scalp to -
pographies of MMN and ITPC. When analyzing ERP with -
out motor correction, MMN responses were observed in the 
tapping condition as − 0.98 μV (SD = 0.81 μV), t (34) = −7.09, 
p < 0.001, dz = −1.20, BF 10 = 399418.24, and in the no-  tapping 
condition as − 0.48 μV, (SD = 0.72 μV), t (34) = −3.94, p < 0.001, 
dz = −0.67, BF 10 = 73.76. MMN amplitudes were significantly 
larger in the tapping condition than in the no- tapping condition, 
t(34) = −3.57, p = 0.001, dz = −0.60, BF 10 = 29.35. The MMN re -
sponse, as an index of precision-  weighted prediction error, was 
enhanced by tapping.
Because the MMN results reported above are contaminated by 
motor- related ERP responses, the MMN response was further 
examined after subtracting the motor-  related ERP response 
obtained during the no-  sound tapping in the second bar of 
the eight- bar sequence (see Figure  1). Again, MMN responses 
were statistically significant in both the tapping ( M = −0.84 μV, 
TABLE 1     |    Mean (SD) of ITI and tapping error at each position.
(ms) Leading sound position Silent position Rhythm position All positions
Mean ITI 616 (44) 636 (42) 626 (80) 625 (69)
SD of ITI 87 (50) 78 (56) 89 (53) 89 (54)
Tapping error 83 (34) 72 (39) 86 (41) 84 (39)
8 of 15
 Psychophysiology, 2025
SD = 1.07 μV), t(34) = −4.64, p < 0.001, dz = −0.78, BF10 = 466.88, 
and no-  tapping ( M = −0.44 μV, SD = 0.72 μV) conditions, 
t(34) = −3.61, p < 0.001, dz = −0.61, BF10 = 32.45. MMN was sig -
nificantly larger in the tapping condition than in the no-  tapping 
condition, even after motor correction, t (34) = −2.13, p = 0.041, 
dz = −0.36, BF10 = 1.34.
The values of ITPC rhythm , ITPC two- beat, and ITPC four- beat were, 
respectively, 0.12, 0.24, and 0.14 in the tapping condition and 
0.11, 0.15, and 0.11 in the no-  tapping condition. ITPC two- beat 
and ITPC four- beat were significantly greater in the tapping con -
dition than in the no-  tapping condition, t (34) = 5.21, corrected 
p < 0.001, dz = 0.88, BF 10 = 2217.26, t(34) = 4.17, corrected 
p = 0.001, dz = 0.70, BF10 = 134.01. However, ITPCrhythm was not 
significantly different between the two conditions, t (34) = 0.84, 
corrected p = 1.000, dz = 0.14, BF10 = 0.25. These results suggest 
that neural entrainment to beat- related frequencies was stronger 
in the tapping condition, but neural entrainment to rhythm did 
not differ between the two conditions.
The ratings of the three questionnaire items were compared 
between the two conditions. The degree of wanting to move 
(Q1) was M = 3.0 (SD = 1.2) in the tapping condition and M = 2.6 
(SD = 1.2) in the no- tapping condition and was not significantly 
different between conditions, W s = 157, p = 0.143, rB = 0.36, 
BF10 = 0.56. Satisfaction with the wanting to move (Q2) was 
M = 2.5 (SD = 1.3) in the tapping condition and M = 2.0 (SD = 1.0) 
in the no-  tapping condition and was not significantly different 
between conditions, W s = 205, p = 0.112, rB = 0.37, BF10 = 0.49. 
The degree of pleasure (Q3) was M = 2.9 (SD = 1.1) in the tapping 
condition and M = 3.0 (SD = 1.0) in the no- tapping condition and 
was not significantly different between conditions, W s = 145, 
p = 0.889, rB = −0.03, BF 10 = 0.18. Finally, groove sensation and 
pleasure were not significantly different between the tapping 
and no- tapping conditions.
3.4   |   Correlation Analysis
Correlations between MMN, ITPCs, and groove-  related ques -
tion ratings were explored. Table  3 shows the Spearman's rank 
coefficient ρ in the tapping and no-  tapping conditions. The 
correlations between the groove-  related questions were ob -
served only in the tapping condition, but not in the no-  tapping 
condition. The degree of wanting to move (Q1) and satisfac -
tion with wanting to move (Q2) were significantly correlated 
only in the tapping condition, ρ (33) = 0.50, corrected p = 0.020. 
Moreover, the sense of groove was significantly correlated 
with pleasure (Q3) only in the tapping condition, ρ (33) = 0.54, 
corrected p = 0.010.
4   |   Discussion
The present study examined whether rhythmic prediction error 
is modulated by tapping. MMN responses were observed in both 
tapping and no-  tapping conditions. Before and after subtract -
ing motor- related ERPs, the MMN response was larger in the 
tapping condition than in the no-  tapping condition, suggesting 
greater precision due to the suppression of sensory surprisal and 
uncertainty in syncopation. Moreover, ITPC, as an indicator 
of neural entrainment, showed greater power at the two-  and 
four- beat frequencies in the tapping condition than in the no- 
tapping condition, reflecting the enhancement of meter and beat 
TABLE 2     |    Indices of physiological and psychological arousal.
Tapping No- tapping t
BF10M (SD) M (SD) (p)
PSD (μV) Theta (4.0–8.0  Hz) 22.6 (5.4) 22.9 (6.0) −0.45 (0.655) 0.20
(N = 34) Alpha (8.0–13.0 Hz) 1.4 (0.4) 1.4 (0.4) 0.46 (0.648) 0.20
Beta (13.0–30.0 Hz) 0.9 (0.4) 0.9 (0.4) −0.43 (0.672) 0.20
HRV HR (bpm) 69.9 (8.6) 69.5 (7.9) 0.86 (0.395) 0.26
(N = 35) RMSSD (ms) 48.3 (33.2) 45.4 (21.4) 0.75 (0.459) 0.24
EACL Fear 0.6 (1.0) 0.7 (1.2) −0.12 (0.909) 0.18
(N = 35) Angry 1.2 (1.6) 1.8 (2.8) −1.10 (0.280) 0.32
Sad 1.1 (1.7) 1.3 (1.8) −0.72 (0.475) 0.23
Disgust 1.7 (2.2) 2.3 (2.9) −1.20 (0.237) 0.35
Joy 5.0 (3.1) 3.7 (3.1) 2.08 (0.045)* 1.22
Energy positive 5.5 (3.4) 3.7 (3.3) 3.23 (0.003)* 13.05
Energy negative 1.4 (1.8) 2.2 (1.9) −2.13 (0.041)* 1.33
Tension positive 2.4 (1.7) 2.3 (2.6) 0.12 (0.903) 0.18
Tension negative 2.8 (2.4) 3.7 (2.8) −2.11 (0.043)* 1.28
Note: Asterisks indicate statistical significance in a paired t - test (p < 0.05).
Abbreviations: EACL, emotion and arousal checklist; HRV, heart rate variability; PSD, power spectral density.
9 of 15
FIGURE 2    |    ERP responses and ITPCs in the tapping and no-  tapping conditions. (a) Grand ERP waveforms of the standard, deviant, and deviant- 
related difference without motor subtraction. ERP waveforms were calculated by averaging the five frontal electrodes (F3, F4, F7, F8, and Fz). The 
gray area indicates the MMN interval (174–214 ms) defined as the peak ±20 ms. The topographic distribution shows the mean ERP amplitude of the 
MMN interval. (b) The motor-  related ERP response was subtracted from the standard and deviant ERPs of the tapping condition. The topographic 
distribution shows the mean ERP amplitude at 176–216 ms. (c) The ITPC of each frequency is shown with arrows indicating the rhythm, two-  beat, 
and four-  beat frequencies. (d) Mean MMN amplitudes with and without motor correction and ITPC values of each frequency are shown as bar 
graphs. Each point represents individual data, and asterisks indicate statistically significant differences. The light-  colored bands on the ERP and 
ITPC waveforms and the error bars in the bar graph indicate a 95% confidence interval.
TABLE 3     |    Spearman's rank correlation coefficient of tapping and no-  tapping conditions.
Wanting 
to move
Satisfaction 
of wanting 
to move
How 
pleasure MMN
Corrected 
MMN ITPCrhythm ITPCtwo-  beat ITPCfour- beat
Wanting to 
move
0.16 0.15 −0.22 −0.18 −0.09 0.04 −0.14
Satisfaction 
of wanting 
to move
0.50* −0.003 0.15 0.14 −0.07 0.14 −0.19
How 
pleasure
0.54* 0.39 0.09 0.06 −0.18 −0.14 −0.19
MMN 0.01 −0.06 −0.20 0.98* 0.08 −0.07 −0.09
Corrected 
MMN
0.05 0.07 −0.08 0.77* 0.15 −0.08 −0.03
ITPCrhythm −0.26 0.002 −0.23 −0.07 −0.15 0.23 0.28
ITPCtwo- beat 0.09 0.16 0.24 −0.13 0.04 −0.03 −0.13
ITPCfour- beat 0.01 0.08 0.06 −0.28 −0.14 0.02 0.26
Note: The left of the diagonal shows Spearman's rank correlation coefficient ( ρ) in the tapping condition, while the right shows that in the no-  tapping condition. 
Asterisks indicate statistical significance after FDR correction.
10 of 15
 Psychophysiology, 2025
information by tapping. ITPC at the rhythm frequency was not 
significantly different between the two conditions. Although 
physiological arousal was not statistically different between the 
two conditions, subjective arousal was higher in the tapping 
condition than in the no-  tapping condition. Additionally, par -
ticipants felt more joyful in the tapping condition than in the 
no- tapping condition. However, ratings of groove-  related ques-
tions were not statistically different between the two conditions. 
These results are discussed within the framework of active in -
ference or the relationship between groove sensation and body 
movement.
The MMN response was larger in the tapping condition than 
in the no-  tapping condition, even after motor correction. The 
present results verified behavioral studies that reported facil -
itation of timing deviance detection by tapping (Manning and 
Schutz  2013, 2016), using the neural MMN response, which 
has been regarded as a neural deviance detection response 
(Fishman  2014; Picton et  al.  2000). In the active inference 
framework, MMN is considered a precision-  weighted predic -
tion error (Friston  2005, 2012; Garrido et  al.  2009; Winkler 
and Czigler  2012). The lower the entropy of the sensory data, 
the larger the MMN amplitude (Lumaca et  al.  2019; Quiroga- 
Martinez et  al.  2019, 2020; SanMiguel et  al.  2021). Consistent 
with this property, the MMN amplitude was larger in the tap -
ping condition than in the no-  tapping condition. Importantly, 
the difference in MMN response cannot be attributed to the 
difference in physiological arousal because differences in EEG 
powers, which relate to arousal (Barry et  al.  2007, 2020), and 
HRV indices were not supported. Instead, the sensory uncer -
tainty of rhythm was regulated by reducing sensory surprisal 
through tapping, which enhanced precision and resulted in a 
greater prediction error (i.e., surprisal) for timing violations of 
rhythm. Therefore, the precision-  weighted prediction error is a 
possible explanation for the current MMN results. This result 
resembles the suggestion made by Vuust et al. ( 2018), who dis -
cussed groove sensation in terms of predictive processing under 
the active inference framework, in which the brain minimizes 
surprisal by prediction error through actions that enhance 
meter and beat information.
The mismatch response elicited by the deviant may have par -
tially overlapped with the N2b component, which reflects at -
tentional allocation and the response to novel stimuli (Folstein 
and van Petten 2008; Krokhine et al. 2020). In the present study, 
participants attended to rhythmic stimuli that included the de -
viant. Under such task conditions, it is plausible that the deviant 
elicited an N2b. Therefore, another interpretation of the differ -
ence in negativity is that the negativity observed around the 
174–214 ms and 176–216 ms intervals reflects differences in N2b 
amplitude due to attentional allocation. Even if the current mis -
match response is an N2b, a larger N2b in the tapping condition 
would also align with predictive coding theory within the ac -
tive inference framework. This is because enhancing precision 
corresponds to increasing the gain of sensory input by attention 
(Feldman and Friston  2010). In the present study, tapping may 
have increased precision, thereby enhancing attentional pro -
cessing of the unexpected deviant. However, this interpretation 
is post hoc and assumes an attentional mechanism underlying 
the N2b component. Importantly, the falsifiability of predictive 
coding is under debate (Bowman et al.  2023). If all phenomena 
are explained retroactively within the predictive coding frame -
work, the theory risks becoming unfalsifiable. Therefore, future 
research should formalize hypotheses about the N2b compo -
nent within the predictive coding model and test whether its 
predictions correspond to measurable improvements in atten -
tional gain.
The enhancement of meter and beat information was supported 
by the ITPC of two types of beat- related frequencies. ITPCtwo- beat 
and ITPC four- beat were greater in the tapping condition than in 
the no- tapping condition. This difference was observed not only 
in the whole-  head average but also in the occipital and fron -
tal regions, where motor-  related potentials are minimal (see 
Supporting Analysis S3 ). The increased neural entrainment to 
the beat frequency may have facilitated rhythmic prediction, 
and this could be a way to modulate sensory uncertainty. Using 
the steady state evoked potential (SSEP), a periodic evoked brain 
response whose frequency remains constant in amplitude and 
phase, Nozaradan et  al.  (2011, 2012) observed the peak of the 
SSEP at the meter frequency, which is based on the interpreta -
tion of the beat. Neural entrainment to the meter and beat was 
also observed in the current ITPC, and it was greater in the 
metrically strong beat position (two-  beat frequency) than in 
the four- beat frequency. ITPC increases with the frequency of 
relevant stimuli. For example, previous studies (Batterink and 
Paller 2017; Moser et al. 2021) reported that ITPC was selectively 
enhanced in the frequency of tone chunks (i.e., word or tone 
triplet) when learned in structured sequences, whereas ITPC in 
tone frequency did not change between structured and random 
sequences. Therefore, it was speculated that enhanced neural 
entrainment to the beat was due to movement, which enhanced 
meter and beat information, thereby regulating sensory surpri -
sal in rhythmic prediction. However, this speculation was not 
supported by the data and was inconclusive, as MMN amplitude 
and ITPC were not significantly correlated. One possible reason 
is that the rhythmic stimulus used in the present study was rel -
atively simple, allowing for strong and consistent phase-  locking 
across participants and reducing individual variability in ITPC. 
This is indicated by the small standard deviations (ITPC two- beat 
is 0.09 and 0.03 for tapping and no-  tapping conditions, respec -
tively). This reduced variance may have limited the statistical 
power to detect significant associations with MMN. Future 
research should examine the relationship between MMN and 
ITPC using rhythms with varying degrees of syncopation.
ITPCrhythm was not significantly different between the two con -
ditions. When perceiving complex rhythms, such as syncopa -
tion, processing the entire rhythmic structure is not the optimal 
way to reduce sensory uncertainty (entropy). Instead, enhanc -
ing meter and beat information is an effective way to reduce the 
entropy of the rhythmic context because it fills the gap of synco -
pation. This may be the reason why ITPC rhythm was not differ -
ent between the two conditions, but beat-  related ITPC showed 
stronger power in the tapping condition than in the no-  tapping 
condition. Large et al. ( 2015) demonstrated that SSEP synchro -
nizes with pulse (meter) frequency in the motor network, even 
though the rhythm itself does not contain an input at the pulse 
frequency, with a simulation using a neural model of dynamic 
attention theory. In the present study, the enhancement of beat- 
related ITPC with and without tapping compared to rhythm- 
related ITPC may reflect a strategy to fill in gaps in the rhythmic 
11 of 15
structure while listening to syncopated music, as suggested by 
Witek et al. (2017).
ITPC has a local peak at 2.5 Hz, which corresponds to three of 
the two-  against- three rhythms. This frequency corresponds 
to a sound presentation interval of 400 ms within a single bar 
(1200 ms). According to the ITI results, participants tapped 
within around 500–700 ms intervals. Thus, the enhancement of 
the ITPC at 2.5 Hz cannot be attributed to the tapping move -
ment. Rather, it may be due to inaccurate rhythm grouping, as 
the syncopated rhythm in the present study had three notes per 
bar. When listening to a rhythmic sequence, listeners perceive 
tones with grouping and chunking (Hestermann et  al.  2023; 
Iversen et  al.  2014). Therefore, it could be chunked as a two- 
against- three rhythm due to an inaccurate perception of synco -
pation. It seems that the ITPC of 2.5 Hz is slightly smaller in the 
tapping condition than in the no-  tapping condition, although 
this difference is not statistically significant. This reduction 
may also be due to the enhancement of meter information, and 
rhythmic perception becomes more accurate with tapping.
The neural responses in the present study were not due to the 
sound produced by finger- tapping because of earmuffs. Instead, 
the interoceptive and proprioceptive sensations produced by 
tapping may have increased the precision of rhythmic predic -
tion. Aschersleben et al. ( 2001) showed that under the tapping 
task, the degree of tapping asynchrony increased when the tac -
tile sense was completely blocked by local anesthesia compared 
to when it was not blocked. Goebl and Palmer ( 2008) suggested 
that temporal accuracy in piano playing was positively related 
to finger-  key surface impact. The action-  induced interoceptive 
or proprioceptive sensation synchronized with the external 
rhythm signal would be used as meter and beat information that 
elaborates rhythmic prediction in such a way that the body be -
comes a beat that fills a gap (Witek  2017). Therefore, the urge 
to move, the groove sensation, may stem from a bodily desire 
to reduce the surprisal and sensory uncertainty of syncopa -
tion. Previous studies have suggested a relationship between 
the accuracy of interoceptive sensation (e.g., cardiac response) 
and rhythm perception (Tanaka et al.  2021; Tomyta et al. 2023). 
Future research could examine whether the modulation of sen -
sory surprisal in rhythmic prediction differs by individual in -
teroceptive accuracy.
The difference in groove sensation was not statistically signifi -
cant between the tapping and no-  tapping conditions. One pos -
sibility is that the level of syncopation was lower and simpler 
compared to stimuli used in previous studies featuring drum 
breaks (Céspedes-  Guevara and Witek  2023; Witek et al.  2014). 
Another possibility is that tapping in sync with the rhythm was 
difficult and diminished the positive groove sensation associ -
ated with movement. Céspedes-  Guevara and Witek ( 2023) also 
reported no difference in groove sensation when foot tapping to 
rhythms versus remaining still. This suggests that the positive 
effect of movement on groove may have been outweighed by the 
difficulty of the synchronization task. Moreover, in the present 
study, the lack of difference in the sense of wanting to move 
and pleasure between conditions may be because the amount 
of syncopation was not manipulated and only one rhythm 
was used. This could have caused the lack of difference in the 
groove between conditions and limited the generalizability of 
the modulation of rhythmic prediction error to other types of 
rhythms. Previous studies have suggested that the degree of 
wanting to move and pleasure is related to the amount of syn -
copation (Matthews et al.  2019; Witek et al.  2014). An inverted 
U- shaped relationship between the degree of syncopation and 
groove sensation or pleasure has been proposed theoretically 
(Koelsch et  al.  2019; Stupacher et  al.  2022; Vuust et  al.  2018, 
2022; Vuust and Witek 2014) and empirically (Sioros et al. 2014; 
Witek et  al.  2014). In this relationship, the urge to move and 
pleasure are stronger at the medium degree of syncopation, and 
groove sensation and pleasure are a function of syncopation de -
gree (Matthews et al. 2019; Witek et al. 2014). Thus, it is not sur-
prising that there were no differences between the conditions in 
the ratings of wanting to move and pleasure, as the syncopation 
pattern was the same across conditions.
Overt movement in sync with the rhythm (e.g., finger-  tapping 
and dancing) is not necessarily required to feel groove or plea -
sure, as previous studies have been able to examine groove 
sensation without overt movement (Madison et  al.  2011; Senn 
et  al.  2018; Sioros et  al.  2014; Witek et  al.  2014). As Witek 
et al. (2017) pointed out, groove- related pleasure may not be the 
result of satisfying the desire to move but the “process pleasure” 
that arises from the process of experiencing the groove itself. 
This may explain the lack of difference in satisfaction with the 
urge to move (Q2) between the tapping conditions. This is be -
cause if the movement itself induces pleasure, the urge to move 
is likely to persist and therefore may never be fully satisfied. 
Another explanation for the null difference in satisfaction is 
that the urge to move may not be fully satisfied by tapping be -
cause the movement is small. Regarding this, Witek et al. (2017) 
showed that torso synchronization was significantly correlated 
with the degree of syncopation, whereas hand synchronization 
was not.
Despite the lack of difference in groove sensation between the 
tapping and no-  tapping conditions, qualitative differences in 
groove ratings were observed in the correlation analysis between 
conditions. In the tapping condition, participants who felt a 
stronger sense of groove also experienced a greater sense of plea-
sure, similar to Witek et al. ( 2014). Using functional magnetic 
resonance imaging, Matthews et al. (2020) reported associations 
between ratings of pleasure and wanting to move, and motor 
and reward-  related regions, such as the nucleus accumbens. 
They concluded that groove sensation is driven by a combina -
tion of motor and reward- related regions in the brain. Moreover, 
Cheung et al. ( 2019) demonstrated that a high-  surprisal chord 
was more pleasurable than a low- surprisal chord in a low uncer-
tainty musical chord context. Syncopation involves prediction 
errors in meter prediction. If beat tapping reduces the entropy 
of meter prediction and syncopation provides an optimal level of 
surprisal (i.e., prediction error), groove sensation may be mod -
ulated. Then, the right level of syncopation offers groove sensa -
tion and pleasure (Vuust et al. 2022).
This study has several limitations. First, the attentional state 
was qualitatively different between the tapping and no-  tapping 
conditions, although participants attended to the rhythmic se -
quence in both conditions, and physiological arousal did not 
differ between conditions. MMN amplitude is sensitive to 
the content of an attentional task (Sussman  2007 ; Sussman 
12 of 15
 Psychophysiology, 2025
et  al.  2014). Using a phonemic sequence in which pho -
nemes and intensity were changed infrequently, Szymanski 
et  al.  (1999) reported that the MMN elicited by an intensity 
change (deviant) was larger when participants detected the 
intensity changes (task relevant) than when they detected 
phoneme changes (task irrelevant). Similarly, tapping may 
have facilitated the interpretation of the rhythmic context 
compared to the no-  tapping condition because of its task rel -
evance. Future research should clarify this by controlling for 
the qualitative difference in attentional state between the tap -
ping and no-  tapping conditions. Regarding the task demands, 
the MMN is often reduced due to task demands associated 
with concurrent tasks during auditory deviant detection (see 
the meta-  analysis by Wiens et al.  2016). Therefore, the differ -
ence in MMN amplitude between the tapping and no-  tapping 
conditions cannot be explained by higher task demands in the 
tapping condition.
Second, the tapping performance differed between the silent 
position (used for motor correction) and the rhythm position 
(used for standard and deviant trials). Therefore, the subtraction 
may contain some bias because the tapping positions were jit -
tered due to the performance differences between the silent and 
rhythm positions. However, another correction method revealed 
that the MMN was still enhanced in the tapping condition com -
pared to the no-  tapping condition (see Supporting Analysis S2 ), 
with the same peak latency of the MMN with and without motor 
correction. Therefore, the difference in MMN amplitude cannot 
be solely attributed to bias from motor subtraction.
In summary, the present study investigated active inference 
in music perception by examining whether prediction error 
in rhythmic prediction is modulated by reducing the sensory 
surprisal and uncertainty of syncopation through tapping, 
which enhances meter information. The MMN response was 
larger in the tapping condition than in the no-  tapping condi -
tion, suggesting an improvement in precision by reducing un -
certainty in the rhythmic context. The enhancement of meter 
information was supported by a larger ITPC of the beat-  related 
frequency in the tapping condition than in the no-  tapping con -
dition. Regarding groove sensation, the degree of wanting to 
move correlated with pleasure only in the tapping condition. 
The present results can be interpreted as evidence for active 
inference in music perception accompanied by bodily engage -
ment with syncopation. Future research should examine the 
relationship between groove and active inference more pre -
cisely by using various types of rhythms with differing degrees 
of syncopation.
Author Contributions
Kai Ishida: conceptualization, methodology, software, data curation, 
investigation, validation, formal analysis, funding acquisition, visu -
alization, project administration, writing – original draft. Hiroshi 
Nittono: conceptualization, methodology, software, formal analysis, 
validation, supervision, resources, writing – review and editing.
Acknowledgments
This work was supported by JSPS KAKENHI JP22KJ2199.
Conflicts of Interest
The authors declare no conflicts of interest.
Data Availability Statement
The sound materials used and datasets analyzed for the present paper 
are available at https:// osf. io/ nej9k/  .
References
Aschersleben, G., J. Gehrke, and W. Prinz. 2001. “Tapping With 
Peripheral Nerve Block: A Role for Tactile Feedback in the Timing of 
Movements.” Experimental Brain Research  136: 331–339. https://  doi. 
org/ 10. 1007/ s0022 10000562.
Audacity Team. 2014. Audacity(R): Free Audio Editor and Recorder 
[Computer Program]. Version 2.0.0 . Accessed April 20, 2014. http://  
audac ity. sourc eforge. net/ .
Barry, R. J., A. R. Clarke, S. J. Johnstone, C. A. Magee, and J. A. Rushby. 
2007. “EEG Differences Between Eyes-  Closed and Eyes-  Open Resting 
Conditions.” Clinical Neurophysiology  118, no. 12: 2765–2773. https://  
doi. org/ 10. 1016/j. clinph. 2007. 07. 028.
Barry, R. J., F. M. De Blasio, J. S. Fogarty, and A. R. Clarke. 2020. 
“Clinical Neurophysiology Natural Alpha Frequency Components in 
Resting EEG and Their Relation to Arousal.” Clinical Neurophysiology  
131, no. 1: 205–212. https:// doi. org/ 10. 1016/j. clinph. 2019. 10. 018.
Batterink, L. J., and K. A. Paller. 2017. “Online Neural Monitoring of 
Statistical Learning.” Cortex  90: 31–45. https://  doi. org/ 10. 1016/j. cortex. 
2017. 02. 004.
Batterink, L. J., and K. A. Paller. 2019. “Statistical Learning of Speech 
Regularities Can Occur Outside the Focus of Attention.” Cortex  115: 
56–71. https:// doi. org/ 10. 1016/j. cortex. 2019. 01. 013.
Bowman, H., D. J. Collins, A. K. Nayak, and D. Cruse. 2023. “Is 
Predictive Coding Falsifiable?” Neuroscience and Biobehavioral Reviews  
154: 105404. https:// doi. org/ 10. 1016/j. neubi orev. 2023. 105404.
Buckley, C. L., C. S. Kim, S. McGregor, and A. K. Seth. 2017. “The Free 
Energy Principle for Action and Perception: A Mathematical Review.” 
Journal of Mathematical Psychology 81: 55–79. https://  doi. org/ 10. 1016/j. 
jmp. 2017. 09. 004.
Cameron, D. J., I. Zioga, J. P. Lindsen, et al. 2019. “Neural Entrainment 
Is Associated With Subjective Groove and Complexity for Performed 
but Not Mechanical Musical Rhythms.” Experimental Brain Research  
237, no. 8: 1981–1991. https:// doi. org/ 10. 1007/ s0022 1-  019-  05557 -  4.
Céspedes-  Guevara, J., and M. A. G. Witek. 2023. “Syncopation Levels, 
but Not Movement, Are Associated With Pleasantness While Listening 
to Rhythmic Music.” Psychology of Music 51, no. 6: 1627–1637. https://  
doi. org/ 10. 1177/ 03057 35623 1153062.
Cheung, V. K., P. M. Harrison, L. Meyer, M. T. Pearce, J. D. Haynes, 
and S. Koelsch. 2019. “Uncertainty and Surprise Jointly Predict Musical 
Pleasure and Amygdala, Hippocampus, and Auditory Cortex Activity.” 
Current Biology  29, no. 23: 4084–4092. https://  doi. org/ 10. 1016/j. cub. 
2019. 09. 067.
Delorme, A., and S. Makeig. 2004. “EEGLAB: An Open Source Toolbox 
for Analysis of Single-  Trial EEG Dynamics Including Independent 
Component Analysis.” Journal of Neuroscience Methods 134, no. 1: 9–21. 
https:// doi. org/ 10. 1016/j. jneum eth. 2003. 10. 009.
Dercksen, T. T., A. Widmann, E. Schröger, and N. Wetzel. 2020. 
“Omission Related Brain Responses Reflect Specific and Unspecific 
Action- Effect Couplings.” Neuroimage 215: 116840. https://  doi. org/ 10. 
1016/j. neuro image. 2020. 116840.
Etani, T., A. Miura, S. Kawase, et al. 2024. “A Review of Psychological 
and Neuroscientific Research on Musical Groove.” Neuroscience and 
13 of 15
Biobehavioral Reviews  158: 105522. https://  doi. org/ 10. 1016/j. neubi orev. 
2023. 105522.
Faul, F., E. Erdfelder, A. G. Lang, and A. Buchner. 2007. “G* Power 3: A 
Flexible Statistical Power Analysis Program for the Social, Behavioral, 
and Biomedical Sciences.” Behavior Research Methods  39, no. 2: 175–
191. https:// doi. org/ 10. 3758/ BF031 93146 .
Feldman, H., and K. J. Friston. 2010. “Attention, Uncertainty, and Free- 
Energy.” Frontiers in Human Neuroscience  4: 215. https:// doi. org/ 10. 
3389/ fnhum. 2010. 00215 .
Fishman, Y. I. 2014. “The Mechanisms and Meaning of the Mismatch 
Negativity.” Brain Topography  27, no. 4: 500–526. https://  doi. org/ 10. 
1007/ s1054 8-  013-  0337-  3.
Fitch, W. T., and A. J. Rosenfeld. 2007. “Perception and Production of 
Syncopated Rhythms.” Music Perception  25, no. 1: 43–58. https://  doi. 
org/ 10. 1525/ mp. 2007. 25.1. 43.
Folstein, J. R., and C. van Petten. 2008. “Influence of Cognitive 
Control and Mismatch on the N2 Component of the ERP: A Review.” 
Psychophysiology  45, no. 1: 152–170. https://  doi. org/ 10. 1111/j. 1469-  
8986. 2007. 00602. x.
Friston, K. 2005. “A Theory of Cortical Responses.” Philosophical 
Transactions of the Royal Society, B: Biological Sciences 360, no. 1456: 
815–836. https:// doi. org/ 10. 1098/ rstb. 2005. 1622.
Friston, K. 2010. “The Free-  Energy Principle: A Unified Brain Theory?” 
Nature Reviews Neuroscience  11, no. 2: 127–138. https:// doi. org/ 10. 1038/ 
nrn2787.
Friston, K. 2012. “Prediction, Perception and Agency.” International 
Journal of Psychophysiology 83, no. 2: 248–252. https:// doi. org/ 10. 1016/j. 
ijpsy cho. 2011. 11. 014.
Garrido, M. I., J. M. Kilner, K. E. Stephan, and K. J. Friston. 2009. “The 
Mismatch Negativity: A Review of Underlying Mechanisms.” Clinical 
Neurophysiology  120, no. 3: 453–463. https://  doi. org/ 10. 1016/j. clinph. 
2008.  11. 029.
Goebl, W., and C. Palmer. 2008. “Tactile Feedback and Timing Accuracy 
in Piano Performance.” Experimental Brain Research  186: 471–479. 
https:// doi. org/ 10. 1007/ s0022 1-  007-  1252-  1.
Hestermann, L. D., J. Wagemans, and R. T. Krampe. 2023. “Perceptual 
Grouping Incomplex Rhythmic Patterns.” Psychological Research  87, 
no. 4: 1293–1305. https:// doi. org/ 10. 1007/ s0042 6-  022-  01717 -  4.
Ishida, K., and H. Nittono. 2022. “Relationship Between Early Neural 
Responses to Syntactic and Acoustic Irregularities in Music.” European 
Journal of Neuroscience 56, no. 12: 6201–6214. https://  doi. org/ 10. 1111/ 
ejn. 15856 .
Ishida, K., and H. Nittono. 2024a. “Relationship Between Schematic 
and Dynamic Expectations of Melodic Patterns in Music Perception.” 
International Journal of Psychophysiology 196: 112292. https:// doi. org/ 
10. 1016/j. ijpsy cho. 2023. 112292.
Ishida, T., and H. Nittono. 2024b. “Effects of Sensory Modality and 
Task Relevance on Omitted Stimulus Potentials.” Experimental 
Brain Research  242, no. 1: 47–57. https://  doi. org/ 10. 1007/ s0022 1-  023-  
06726  -  2.
Iversen, J. R., A. D. Patel, and K. Ohgushi. 2014. “Perception of 
Rhythmic Grouping Depends on Auditory Experience.” Journal of the 
Acoustical Society of America 124, no. 4: 2263–2271. https://  doi. org/ 10. 
1121/1. 2973189.
Janata, P., S. T. Tomic, and J. M. Haberman. 2012. “Sensorimotor 
Coupling in Music and the Psychology of the Groove.” Journal of 
Experimental Psychology: General  141, no. 1: 54–75. https://  doi. org/ 10. 
1037/ a0024208.
JASP Team. 2024. JASP (Version 0.19.0) [Computer Software] . https:// 
jasp-  stats. org/ .
Koelsch, S., P. Vuust, and K. Friston. 2019. “Predictive Processes and the 
Peculiar Case of Music.” Trends in Cognitive Sciences 23, no. 1: 63–77. 
https:// doi. org/ 10. 1016/j. tics. 2018. 10. 006.
Krokhine, S. N., N. P. Ewers, K. I. Mangold, R. Boshra, C. Y. A. Lin, and 
J. F. Connolly. 2020. “N2b Reflects the Cognitive Changes in Executive 
Functioning After Concussion: A Scoping Review.” Frontiers in Human 
Neuroscience  14: 601370. https:// doi. org/ 10. 3389/ fnhum. 2020. 601370.
Large, E. W., J. A. Herrera, and M. J. Velasco. 2015. “Neural Networks for 
Beat Perception in Musical Rhythm.” Frontiers in Systems Neuroscience  
9: 159. https:// doi. org/ 10. 3389/ fnsys. 2015. 00159 .
Lipponen, J. A., and M. P. Tarvainen. 2019. “A Robust Algorithm for 
Heart Rate Variability Time Series Artefact Correction Using Novel 
Beat Classification.” Journal of Medical Engineering & Technology 43, 
no. 3: 173–181. https:// doi. org/ 10. 1080/ 03091 902. 2019. 1640306.
Lumaca, M., N. Trusbak Haumann, E. Brattico, M. Grube, and P. Vuust. 
2019. “Weighting of Neural Prediction Error by Rhythmic Complexity: 
A Predictive Coding Account Using Mismatch Negativity.” European 
Journal of Neuroscience 49, no. 12: 1597–1609. https://  doi. org/ 10. 1111/ 
ejn. 14329 .
Madison, G., F. Gouyon, F. Ullén, and K. Hörnström. 2011. “Modeling the 
Tendency for Music to Induce Movement in Humans: First Correlations 
With Low-  Level Audio Descriptors Across Music Genres.” Journal of 
Experimental Psychology: Human Perception and Performance 37, no. 5: 
1578–1594. https:// doi. org/ 10. 1037/ a0024323.
Makowski, D., T. Pham, Z. J. Lau, et  al. 2021. “NeuroKit2: A Python 
Toolbox for Neurophysiological Signal Processing.” Behavior Research 
Methods 53: 1689–1696. https:// doi. org/ 10. 3758/ s1342 8-  020-  01516 -  y.
Manning, F., and M. Schutz. 2013. ““Moving to the Beat” Improves 
Timing Perception.” Psychonomic Bulletin and Review 20, no. 6: 1133–
1139. https:// doi. org/ 10. 3758/ s1342 3-  013-  0439-  7.
Manning, F. C., and M. Schutz. 2016. “Trained to Keep a Beat: Movement- 
Related Enhancements to Timing Perception in Percussionists and 
Non- Percussionists.” Psychological Research  80, no. 4: 532–542. https://  
doi. org/ 10. 1007/ s0042 6-  015-  0678-  5.
Matthews, T. E., M. A. Witek, O. A. Heggli, V. B. Penhune, and P. 
Vuust. 2019. “The Sensation of Groove is Affected by the Interaction 
of Rhythmic and Harmonic Complexity.” PLoS One  14, no. 1: e0204539. 
https:// doi. org/ 10. 1371/ journ al. pone. 0204539.
Matthews, T. E., M. A. G. Witek, T. Lund, P. Vuust, and V. B. Penhune. 
2020. “The Sensation of Groove Engages Motor and Reward Networks.” 
Neuroimage 214: 116768. https://  doi. org/ 10. 1016/j. neuro image. 2020. 
116768.
May, P. J. C., and H. Tiitinen. 2010. “Mismatch Negativity (MMN), the 
Deviance-  Elicited Auditory Deflection, Explained.” Psychophysiology  
47, no. 1: 66–122. https:// doi. org/ 10. 1111/j. 1469-  8986. 2009. 00856. x.
Mognon, A., J. Jovicich, L. Bruzzone, and M. Buiatti. 2011. “ADJUST: 
An Automatic EEG Artifact Detector Based on the Joint Use of Spatial 
and Temporal Features.” Psychophysiology  48, no. 2: 229–240. https://  
doi. org/ 10. 1111/j. 1469-  8986. 2010. 01061. x.
Moser, J., L. Batterink, Y. Li Hegner, et  al. 2021. “Dynamics of 
Nonlinguistic Statistical Learning: From Neural Entrainment to the 
Emergence of Explicit Knowledge.” Neuroimage  240: 118378. https://  
doi. org/ 10. 1016/j. neuro image. 2021. 118378.
Müllensiefen, D., B. Gingras, J. Musil, and L. Stewart. 2014. “The 
Musicality of Non-  Musicians: An Index for Assessing Musical 
Sophistication in the General Population.” PLoS One  9, no. 2: e89642. 
https:// doi. org/ 10. 1371/ journ al. pone. 0089642.
Näätänen, R., T. Jacobsen, and I. Winkler. 2005. “Memory-  Based or 
Afferent Processes in Mismatch Negativity (MMN): A Review of the 
Evidence.” Psychophysiology  42, no. 1: 25–32. https://  doi. org/ 10. 1111/j. 
1469-  8986. 2005. 00256. x.
14 of 15
 Psychophysiology, 2025
Näätänen, R., P. Paavilainen, T. Rinne, and K. Alho. 2007. “The 
Mismatch Negativity (MMN) in Basic Research of Central Auditory 
Processing: A Review.” Clinical Neurophysiology  118, no. 12: 2544–
2590. https:// doi. org/ 10. 1016/j. clinph. 2007. 04. 026.
Nozaradan, S., I. Peretz, M. Missal, and A. Mouraux. 2011. “Tagging 
the Neuronal Entrainment to Beat and Meter.” Journal of Neuroscience 
31, no. 28: 10234–10240. https://  doi. org/ 10. 1523/ JNEUR OSCI. 0411-  
11. 2011.
Nozaradan, S., I. Peretz, and A. Mouraux. 2012. “Selective Neuronal 
Entrainment to the Beat and Meter Embedded in a Musical Rhythm.” 
Journal of Neuroscience 32, no. 49: 17572–17581. https:// doi. org/ 10. 1523/ 
JNEUR  OSCI. 3203-  12. 2012.
Oda, Y., R. Takano, T. Abe, and K. Kikuchi. 2015. “Development of 
the Emotion and Arousal Checklist (EACL).” Japanese Journal of 
Psychology  85, no. 6: 579–589. https:// doi. org/ 10. 4992/ jjpsy. 85. 13231 .
Okubo, M., H. Suzuki, and M. E. R. Nicholls. 2014. “A Japanese Version 
of the FLANDERS Handedness Questionnaire.” Shinrigaku Kenkyu  85: 
474–481. https:// doi. org/ 10. 4992/ jjpsy. 85. 13235 .
Patel, A. D., J. R. Iversen, Y. Chen, and B. H. Repp. 2005. “The 
Influence of Metricality and Modality on Synchronization With a Beat.” 
Experimental Brain Research  163, no. 2: 226–238. https:// doi. org/ 10. 
1007/ s0022 1-  004-  2159-  8.
Picton, T. W., C. Alain, L. Otten, W. Ritter, and A. Achim. 2000. 
“Mismatch Negativity: Different Water in the Same River.” Audiology 
and Neurotology  5, no. 3–4: 111–139. https://  doi. org/ 10. 1159/ isbn. 978-  
3-  318-  00601 -  8.
Quiroga- Martinez, D. R., C. Hansen, A. Højlund, M. Pearce, E. Brattico, 
and P. Vuust. 2020. “Musical Prediction Error Responses Similarly 
Reduced by Predictive Uncertainty in Musicians and Non-  Musicians.” 
European Journal of Neuroscience  51, no. 11: 2250–2269. https:// doi. org/ 
10. 1111/ ejn. 14667 .
Quiroga- Martinez, D. R., N. C. Hansen, A. Højlund, M. T. Pearce, E. 
Brattico, and P. Vuust. 2019. “Reduced Prediction Error Responses in 
High- As Compared to Low-  Uncertainty Musical Contexts.” Cortex  120: 
181–200. https:// doi. org/ 10. 1016/j. cortex. 2019. 06. 010.
Sadakata, M., Y. Yamaguchi, C. Ohsawa, et  al. 2023. “The Japanese 
Translation of the Gold-  MSI: Adaptation and Validation of the Self- 
Report Questionnaire of Musical Sophistication.” Musicae Scientiae  27, 
no. 3: 798–810. https:// doi. org/ 10. 1177/ 10298 64922 1110089.
SanMiguel, I., J. Costa-  Faidella, Z. R. Lugo, E. Vilella, and C. Escera. 
2021. “Standard Tone Stability as a Manipulation of Precision in the 
Oddball Paradigm: Modulation of Prediction Error Responses to Fixed- 
Probability Deviants.” Frontiers in Human Neuroscience  15: 734200. 
https:// doi. org/ 10. 3389/ fnhum. 2021. 734200.
Schönbrodt, F. D., and E. J. Wagenmakers. 2018. “Bayes Factor Design 
Analysis: Planning for Compelling Evidence.” Psychonomic Bulletin and 
Review  25, no. 1: 128–142. https:// doi. org/ 10. 3758/ s1342 3-  017-  1230-  y.
Senn, O., L. Kilchenmann, T. Bechtold, and F. Hoesl. 2018. “Groove 
in Drum Patterns as a Function of Both Rhythmic Properties and 
Listeners' Attitudes.” PLoS One  13, no. 6: e0199604. https://  doi. org/ 10. 
1371/ journ al. pone. 0199604.
Sioros, G., M. Miron, M. Davies, F. Gouyon, and G. Madison. 2014. 
“Syncopation Creates the Sensation of Groove in Synthesized Music 
Examples.” Frontiers in Psychology 5: 1036. https://  doi. org/ 10. 3389/ 
fpsyg.  2014. 01036 .
Stefanics, G., B. Hangya, I. Hernádi, I. Winkler, P. Lakatos, and I. Ulbert. 
2010. “Phase Entrainment of Human Delta Oscillations Can Mediate 
the Effects of Expectation on Reaction Speed.” Journal of Neuroscience 
30, no. 41: 13578–13585. https:// doi. org/ 10. 1523/ jneur osci. 0703- 10. 2010.
Stupacher, J., T. E. Matthews, V. Pando-  Naude, O. Foster Vander 
Elst, and P. Vuust. 2022. “The Sweet Spot Between Predictability and 
Surprise: Musical Groove in Brain, Body, and Social Interactions.” 
Frontiers in Psychology 13: 906190. https:// doi. org/ 10. 3389/ fpsyg. 2022. 
906190.
Su, Y. H., and E. Pöppel. 2012. “Body Movement Enhances the Extraction 
of Temporal Structures in Auditory Sequences.” Psychological Research  
76, no. 3: 373–382. https:// doi. org/ 10. 1007/ s0042 6-  011-  0346-  3.
Sussman, E. S. 2007. “A New View on the MMN and Attention 
Debate: The Role of Context in Processing Auditory Events.” Journal 
of Psychophysiology 21, no. 3–4: 164–175. https://  doi. org/ 10. 1027/ 0269-  
8803. 21. 34. 164.
Sussman, E. S., S. Chen, J. Sussman-  Fort, and E. Dinces. 2014. “The 
Five Myths of MMN: Redefining How to Use MMN in Basic and Clinical 
Research.” Brain Topography 27, no. 4: 553–564. https:// doi. org/ 10. 1007/ 
s1054 8-  013-  0326-  6.
Szymanski, M. D., E. W. Yund, and D. L. Woods. 1999. “Phonemes, 
Intensity and Attention: Differential Effects on the Mismatch Negativity 
(MMN).” Journal of the Acoustical Society of America 106, no. 6: 3492–
3505. https:// doi. org/ 10. 1121/1. 428202.
Tanaka, Y., Y. Terasawa, and S. Umeda. 2021. “Effects of Interoceptive 
Accuracy in Autonomic Responses to External Stimuli Based on 
Cardiac Rhythm.” PLoS One  16, no. 8: e0256914. https://  doi. org/ 10. 
1371/ journ al. pone. 0256914.
Temperley, D. 1999. “Syncopation in Rock: A Perceptual Perspective.” 
Popular Music  18, no. 1: 19–40. https://  doi. org/ 10. 1017/ s0261 14300 
0008710 .
Tomyta, K., K. Katahira, and H. Ohira. 2023. “Effects of Interoceptive 
Accuracy on Timing Control in the Synchronization Tapping Task.” 
Frontiers in Neuroscience  16: 907836. https:// doi. org/ 10. 3389/ fnins. 
2022. 907836.
Tsogli, V., S. Jentschke, and S. Koelsch. 2022. “Unpredictability of the 
“When” Influences Prediction Error Processing of the “What” and 
“Where”.” PLoS One  17, no. 2: e0263373. https://  doi. org/ 10. 1371/ journ 
al. pone. 0263373.
Van Diepen, R. M., and A. Mazaheri. 2018. “The Caveats of Observing 
Inter- Trial Phase-  Coherence in Cognitive Neuroscience.” Scientific 
Reports 8, no. 1: 2990. https:// doi. org/ 10. 1038/ s4159 8-  018-  20423 -  z.
Varela, F., J. Lachaux, E. Rodriguez, and J. Martinerie. 2001. “The 
Brainweb: Phase Synchronization and Large-  Scale Integration.” 
Nature Reviews Neuroscience  2, no. 4: 229–239. https://  doi. org/ 10. 1038/ 
35067550.
Vuust, P., E. Brattico, M. Seppänen, R. Näätänen, and M. Tervaniemi. 
2012. “The Sound of Music: Differentiating Musicians Using a 
Fast, Musical Multi-  Feature Mismatch Negativity Paradigm.” 
Neuropsychologia  50, no. 7: 1432–1443. https://  doi. org/ 10. 1016/j. neuro 
psych ologia. 2012. 02. 028.
Vuust, P., M. J. Dietz, M. Witek, and M. L. Kringelbach. 2018. “Now 
You Hear It: A Predictive Coding Model for Understanding Rhythmic 
Incongruity.” Annals of the New York Academy of Sciences 1423, no. 1: 
19–29. https:// doi. org/ 10. 1111/ nyas. 13622 .
Vuust, P., O. A. Heggli, K. J. Friston, and M. L. Kringelbach. 2022. 
“Music in the Brain.” Nature Reviews Neuroscience  23, no. 5: 287–305. 
https:// doi. org/ 10. 1038/ s4158 3-  022-  00578 -  5.
Vuust, P., L. Ostergaard, K. J. Pallesen, C. Bailey, and A. Roepstorff. 
2009. “Predictive Coding of Music–Brain Responses to Rhythmic 
Incongruity.” Cortex 45, no. 1: 80–92. https://  doi. org/ 10. 1016/j. cortex. 
2008. 05. 014.
Vuust, P., and M. A. G. Witek. 2014. “Rhythmic Complexity and 
Predictive Coding: A Novel Approach to Modeling Rhythm and Meter 
Perception in Music.” Frontiers in Psychology 5: 1111. https://  doi. org/ 10. 
3389/ fpsyg. 2014. 01111 .
Wiens, S., M. Szychowska, and M. E. Nilsson. 2016. “Visual Task 
Demands and the Auditory Mismatch Negativity: An Empirical Study 
15 of 15
and a Meta- Analysis.” PLoS One  11, no. 1: e0146567. https:// doi. org/ 10. 
1371/ journ al. pone. 0146567.
Winkler, I., and I. Czigler. 2012. “Evidence From Auditory and Visual 
Event- Related Potential (ERP) Studies of Deviance Detection (MMN 
and vMMN) Linking Predictive Coding Theories and Perceptual Object 
Representations.” International Journal of Psychophysiology 83, no. 2: 
132–143. https:// doi. org/ 10. 1016/j. ijpsy cho. 2011. 10. 001.
Witek, M. A. G. 2017. “Filling in: Syncopation, Pleasure and Distributed 
Embodiment in Groove.” Music Analysis  36, no. 1: 138–160. https:// doi. 
org/ 10. 1111/ musa. 12082 .
Witek, M. A. G., E. F. Clarke, M. Wallentin, M. L. Kringelbach, and P. 
Vuust. 2014. “Syncopation, Body-  Movement and Pleasure in Groove 
Music.” PLoS One 9, no. 4: e94446. https:// doi. org/ 10. 1371/ journ al. pone. 
0094446 .
Witek, M. A. G., T. Popescu, E. F. Clarke, et al. 2017. “Syncopation Affects 
Free Body- Movement in Musical Groove.” Experimental Brain Research  
235, no. 4: 995–1005. https:// doi. org/ 10. 1007/ s0022 1-  016-  4855-  6.
Zhang, G., D. R. Garrett, and S. J. Luck. 2024. “Optimal Filters for 
ERP Research II: Recommended Settings for Seven Common ERP 
Components.” Psychophysiology  61: e14530. https://  doi. org/ 10. 1111/ 
psyp. 14530 .
Supporting Information
Additional supporting information can be found online in the 
Supporting Information section.  