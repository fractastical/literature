TYPE Original Research
PUBLISHED /one.tnum/seven.tnum October /two.tnum/zero.tnum/two.tnum/two.tnum
DOI /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
OPEN ACCESS
EDITED BY
Dorota Frydecka,
Wroclaw Medical University, Poland
REVIEWED BY
Zafeirios Fountas,
Huawei, United Kingdom
Karl Friston,
University College London,
United Kingdom
*CORRESPONDENCE
Dimitrije Markovi ´c
dimitrije.markovic@tu-dresden.de
SPECIALTY SECTION
This article was submitted to
Learning and Memory,
a section of the journal
Frontiers in Behavioral Neuroscience
RECEIVED /zero.tnum/six.tnum June /two.tnum/zero.tnum/two.tnum/two.tnum
ACCEPTED /two.tnum/six.tnum September /two.tnum/zero.tnum/two.tnum/two.tnum
PUBLISHED /one.tnum/seven.tnum October /two.tnum/zero.tnum/two.tnum/two.tnum
CITATION
Markovi´c D, Reiter AMF and Kiebel SJ
(/two.tnum/zero.tnum/two.tnum/two.tnum) Revealing human sensitivity to a
latent temporal structure of changes.
Front. Behav. Neurosci./one.tnum/six.tnum:/nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum.
doi: /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
COPYRIGHT
© /two.tnum/zero.tnum/two.tnum/two.tnum Markovi´c, Reiter and Kiebel.
This is an open-access article
distributed under the terms of the
Creative Commons Attribution License
(CC BY)
. The use, distribution or
reproduction in other forums is
permitted, provided the original
author(s) and the copyright owner(s)
are credited and that the original
publication in this journal is cited, in
accordance with accepted academic
practice. No use, distribution or
reproduction is permitted which does
not comply with these terms.
Revealing human sensitivity to a
latent temporal structure of
changes
Dimitrije Markovi´c/one.tnum*, Andrea M. F. Reiter /one.tnum,/two.tnum,/three.tnumand
Stefan J. Kiebel /one.tnum,/four.tnum
/one.tnumDepartment of Psychology, Technische Universität Dresden, Dre sden, Germany, /two.tnumDepartment of
Child and Adolescence Psychiatry, Psychosomatics and Psychoth erapy, Centre of Mental Health,
University Hospital Würzburg, Würzburg, Germany, /three.tnumGerman Center of Prevention Research on
Mental Health, Julius-Maximilians Universität Würzburg, Wür zburg, Germany, /four.tnumCentre for Tactile
Internet with Human-in-the-Loop (CeTI), Technische Universi tät Dresden, Dresden, Germany
Precisely timed behavior and accurate time perception plays a cri tical role
in our everyday lives, as our wellbeing and even survival can depe nd on
well-timed decisions. Although the temporal structure of the wo rld around
us is essential for human decision making, we know surprisingl y little about
how representation of temporal structure of our everyday env ironment
impacts decision making. How does the representation of tempo ral structure
aﬀect our ability to generate well-timed decisions? Here we addre ss this
question by using a well-established dynamic probabilistic l earning task.
Using computational modeling, we found that human subjects’ bel iefs about
temporal structure are reﬂected in their choices to either explo it their current
knowledge or to explore novel options. The model-based analysis illustrates
a large within-group and within-subject heterogeneity. To exp lain these
results, we propose a normative model for how temporal structur e is used in
decision making, based on the semi-Markov formalism in the activ e inference
framework. We discuss potential key applications of the presen ted approach
to the ﬁelds of cognitive phenotyping and computational psychia try.
KEYWORDS
decision making, temporal structure, Bayesian inference, active inference, reversal
learning
/one.tnum. Introduction
The passage of time is a fundamental aspect of human experience. Our behavior is
tightly coupled to our estimate of the elapsed time and the expectations about the t ime
remaining to fulﬁll short or long-term goals. We are highly sensitive to the temporal
structure of our everyday environment and capable of forming precise beliefs a bout
the duration of various events (e.g., a theater play, traﬃc lights, waiting in a que ue).
In practice, temporal structure is typically latent (e.g., not reﬂected in ex ternal clocks)
and we seem to rely on an internalized timing mechanism, such as various implicit
clocking mechanisms (
Buhusi and Meck, 2005 ). This enables us to provide temporal
context and an order to events, and to form beliefs about the underlying tempor al
structure ( Eichenbaum, 2014 ). It has been proposed that these temporal beliefs are
Frontiers in Behavioral Neuroscience /zero.tnum/one.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
used to make predictions and to adapt our behavior successfully
to ever-changing conditions (
Griﬃths and Tenenbaum, 2011 ).
Therefore, understanding how we learn and represent the
temporal structure of our every day environment (
Kiebel et al.,
2008) and use these representations for making decisions
(Markovi´c et al., 2019 ) is essential for understanding human
adaptive behavior ( Purcell and Kiani, 2016 ).
Neuronal and behavioral mechanisms of time perception
have been studied in humans and animals, traditionally using
interval timing tasks (
Meck, 1996 ; Eagleman, 2008 ). The key
insights of these experiments are that humans and animals
integrate the experience of between event duration, in a given
context, to form beliefs about possible future duration they
might experience. They use these beliefs when estimating or
reproducing a newly experienced interval (
Jazayeri and Shadlen,
2010); in line with a Bayesian account of decision-making
(Shi et al., 2013 ). However, it is still an open question how
we integrate time perception and beliefs about durations into
everyday decision making. Recently, distinct but interlinked
research ﬁelds have illustrated the importance of temporal
representations for cognition and decision making in sequential
and dynamic tasks (
McGuire and Kable, 2012 ; Eichenbaum,
2014; Vilà-Balló et al., 2017 ; Nobre and Van Ede, 2018 ). The
sequential neuronal activity in the hippocampus has been
suggested to represent elapsed time (
Friston and Buzsáki, 2016 ;
Buzsáki and Llinás, 2017 ; Eichenbaum, 2017), which have led to
the postulate of time cells in the hippocampus ( Itskov et al., 2011 ;
Eichenbaum, 2014; MacDonald et al., 2014 ) critical for memory
and decision-making. For example, in the research on temporal
aspects of attention it has been demonstrated that temporal
expectations guide allocation of attentional resources in time
(
Nobre and Van Ede, 2018 ). Similarly, inter-temporal choices or
one’s willingness to wait for higher reward is strongly inﬂuenced
by temporal expectations (
McGuire and Kable, 2012 ).
Motivated by the rich literature on temporal representations
in the brain, here we focus on the question of how humans
form complex temporal representation of their environment.
We test how such temporal representations support decisions
about whether to explore or to exploit in anticipation of a
change in the environment. We introduce a novel computational
model of behavior that describes learning of a latent temporal
structure of a dynamic task environment in the context
of sequential decision making. The computational model is
applicable to any task that can be cast as a dynamic multi-
armed bandit problem (
Gupta et al., 2011 ) with semi-Markovian
changes or switches in the underlying latent states ( Janssen
and Limnios, 1999 ). Here we speciﬁcally apply the model to
describe learning in a sequential (probabilistic) reversal learning
task (
Costa et al., 2015 ; Reiter et al., 2016 , 2017; Vilà-Balló
et al., 2017 ). We do so by manipulating temporal contexts in
this task: Subjects encountered semi-regular intervals between
contingency reversals in one environment. Their behavior
was contrasted with behavior in another environment where
intervals between contingency reversals were irregular.
The proposed behavioral model was based on three
components: (i) a set of templates representing possible
latent temporal structure of reversals using an implicit
representation of between reversal duration (
Yu, 2015 ), (ii)
the update of beliefs about states and temporal templates
derived via approximate inference (
Yu and Kobayashi, 2003 ;
Parr et al., 2019 ), and (iii) the action selection, that is the
planning process, cast as active inference ( Friston et al., 2017 ;
Markovic et al., 2021 ). Together these components allow
us to deﬁne an eﬃcient and approximate active learning
and choice algorithm of latent temporal structures based on
variational inference (
Blei et al., 2017 ). Here we extend on
our previous investigation of human behavior in temporally
structured dynamic environments (
Markovi´c et al., 2019 ).
In this work, we demonstrated that a computational model
which infers a between-event duration, can be used to
reveal subjects’ beliefs about the latent temporal structure
in a dynamic learning task. However, a question that has
remained open is how humans acquire temporal structure
in the ﬁrst place. Understanding the learning of temporal
structure is critical for revealing between-individual variability
in temporal expectations and capturing the evolution of
temporal representations within individuals. Critically, with
the extended model we present here, we are indeed able to
capture the learning of temporal representation and address the
non-stationarity of subjects’ temporal representation during the
course of the experiment.
Our aim is to address the following questions: (i) Are
subjects a priori biased toward expecting regular or irregular
temporal structure? (ii) Are subjects able to learn latent
temporal structure without explicit instructions? (iii) How
does the quality of temporal representation impact their
performance? Using simulations we can illustrate the interaction
of accurate representation of temporal structure and behavior,
mainly performance on the task and the engagement with
exploratory behavior. Using model-based analysis, that is,
by estimating the prior beliefs—under a semi-Markovian
generative model—that best explain observed choice behavior,
we demonstrate high diversity between subjects both in their
prior beliefs about temporal structure, and their ability to
adapt their beliefs to diﬀerent latent temporal structure.
Crucially, we link the quality of temporal representation to
subjects’ performance both in terms of group-level performance
and within-subject variability of their performance during
the task.
In what follows we will ﬁrst brieﬂy describe the experimental
task, provide the overall summary of behavioral characteristics,
introduce the behavioral model, and ﬁnally show results of the
model-based analysis of behavior. The formal details of the
approach are described in Section 4.
Frontiers in Behavioral Neuroscience /zero.tnum/two.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
FIGURE /one.tnum
Exemplary trial sequence of the probabilistic reversal lear ning
task. Subjects were instructed that one card always had a higher
probability of a monetary reward. They were instructed to
choose the card that they thought would lead to a monetary
gain with higher probability, or, alternatively, choose to explore
(small yellow rectangle with question mark). The latter would
provide them with a correct information about what option
would have had a higher probability of reward. (A) If participants
had chosen one of the cards, the corresponding card was
highlighted and feedback was displayed. The feedback
consisted of either the visual display of a /one.tnum/zero.tnum Euro cents coin in
the center of the screen for a gain outcome, or a crossed /one.tnum/zero.tnum
Euro cents for a loss outcome. (B) If the participant had chosen
the explore option, the card with the currently highest reward
probability was highlighted (either the left or the right card).
/two.tnum. Results
A typical probabilistic reversal learning task asks subjects
to make a binary choice between two options, e.g., A and B,
where each option is associated with a probability of receiving a
reward or punishment. For example, initially choosing A returns
a reward with a high probability pH = 0.8 and choosing B
returns a reward with low probability pL = 0.2. Importantly,
after several trials the reward contingencies reverse, i.e., switch,
such that choosing B returns the reward with high probability
pH. However, subjects are not informed about the reversal and
they have to infer that a change occurred from the feedback they
receive in order to adapt their behavior. From the point of view
of participants, a reversal can be diﬃcult to detect as outcomes
are probabilistic. This means that if someone observes a loss
after a sequence of gains, e.g., when choosing the option A, this
could be caused either by: (i) a true reversal, where now option
B is rewarded with the probability pH or (ii) by an unlucky
outcome of an otherwise correct choice. To obtain a more direct
information about the subjective uncertainty of participants
about the correct choice (i.e., choosing the option with high
reward probability, pH) on any given trial, we extended the
standard design with an additional third exploratory option.
This new option does not result in monetary gain or loss but
provides information about the correct choice on a current
trial. A high uncertainty about the best choice (current context)
can be easily resolved by selecting the epistemic option. We
will label all choices of the exploratory options as exploratory,
and all other choices as exploitative (note that the outcomes of
exploitative options also provide some information about the
current context). A trial sequence of the experimental task is
shown in
Figure 1.
To investigate subjects’ ability to learn latent temporal
structure we deﬁned two experimental conditions (manipulated
in a between-subject design), one with irregular reversals and
another with regular reversals (see
Figure 2). In the condition
with irregular reversals, the moments of reversals are not
predictable and between-reversal intervals are drawn from
a geometric distribution (
Figure 2A). In the condition with
regular reversals, the moments of reversal are predictable, and
they occur at semi-regular intervals, drawn from a negative
binomial distribution (
Figure 2B). Subject were randomly
assigned to one of the two possible conditions, as illustrated
in
Figure 2. In the ﬁrst condition, subjects experience irregular
reversal statistics for 800 trials, after which the reversals occur a t
semi regular intervals for the last 200. In the second condition,
subjects experience semi-regular reversal statistics for 800 trials,
and then the irregular reversal statistics during the last 200 trials.
Note that when changing the temporal statistics we copied the
time series of reversals from the initial 200 trials of the diﬀerent
condition. The motivation for using parts of the trajectories
from one condition in another condition comes from the
process we use to deﬁne the moments of reversals in both
conditions. We aimed to tailor both experimental conditions in a
way that maximizes the behavioral diﬀerences between subjects
entertaining diﬀerent underlying beliefs about latent statistics of
reversals. Such optimization results in improved model selection
and parameter estimates as distinct latent beliefs result in more
pronounced behavioral diﬀerences.
Therefore, we have generated a large number (10 5) of
trajectories of length T = 800 for each condition and kept the
one for which we found the maximal performance diﬀerence
between agents with a correct representation of latent reversal
statistics and an agent with a representation from the opposite
condition. As we kept only single trajectory of reversals for
each condition, we have ﬁxed the moments of reversal for
each subject group (depending on the condition, reversals occur
always on the same trials). Furthermore, the same choice by
diﬀerent subjects exposed to the same condition leads to the
same outcome on any given trial (the outcome statistics were
Frontiers in Behavioral Neuroscience /zero.tnum/three.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
generated only once for each condition and trial, and then
replayed to all subjects depending on their choices and the
condition they were assigned to). Hence, we removed the noise
in behavioral responses which would be induced by unique
experiences of each subject in the experiment, were we to
generate moments of reversal and response-outcomes on-the-ﬂy
for each subject.
/two.tnum./one.tnum. Analysis of choice data
We will ﬁrst describe the behavioral characteristics of the
two groups of subjects exposed to the two diﬀerent experimental
conditions. The two behavioral measures of interests here are the
performance (odds of being correct, i.e., odds of choosing the
option with the higher reward probability) and probing (odds
of exploring, i.e., odds of choosing the exploratory option). We
describe all the behavioral measures in detail in Section 4.5.
Subjects (N = 74) were pseudo-randomly assigned to one of
the two experimental conditions, where nr = 41 participants
were assigned to the condition with regular reversals, and
ni = 33 to the condition with irregular reversals. Note
that some subjects rarely engaged with exploratory option.
Out of 50 subjects who where exposed to the variant of the
experiment with exploratory option (24 subjects performed a
standard version of the task without exploratory option, see
Section 4.3 for more details), 5 subjects never engaged with
the exploratory option. In
Figure 3, we provide a summary
of average behavioral measures for individual subjects. We
do not ﬁnd any signiﬁcant performance diﬀerences between
the two regularity conditions (see
Figure 3A). However, for
the subset of subjects which interacted with the exploratory
option (45 subjects) we ﬁnd that the performance is positively
correlated with probing (Pearson correlation coeﬃcient for
all data points r = 0.6, with p < 10−4; for the regular
condition r = 0.73, p <0.0001, and for the irregular condition
r = 0.52, p < 0.02; see
Figure 3B). Interestingly, neither
of the two behavioral measures (when plotted as a within
subject average over the course of experiment), reveals obvious
between-condition diﬀerences. However, when comparing the
temporal proﬁle of these measures over the course of experiment
(see
Supplementary Figure 1 ), one notices large variability both
between subjects but also within a subject over the course of
experiment; suggesting ongoing learning of the task structure.
In what follows we will classify the heterogeneity of behavioral
responses using a model-based analysis.
/two.tnum./two.tnum. Behavioral model
The behavioral model will allow us to investigate the
process of learning of the latent temporal structure in diﬀerent
FIGURE /two.tnum
Time series of reward probabilities. (A) Condition with irregular reversals, and (B) condition with (semi-)regular reversals. The reward probabili ty
of the high-probability stimuli at any time step was set to pH = /zero.tnum./eight.tnum and the low-probability stimuli topL = /zero.tnum./two.tnum. Dashed vertical lines shows the
moment of change of the latent temporal structure: (i) from irregul ar to semi-regular statistics in the irregular condition, and (i i) from the
semi-regular to irregular statistics in the regular condition. F igures on the right illustrate the generative distribution of the between-reversal
intervals d for each condition. Note that the mean between reversal duration ⟨d⟩ is identical in both conditions.Frontiers in Behavioral Neuroscience /zero.tnum/four.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
FIGURE /three.tnum
Averages of behavioral summary measures. (A) Distribution of the mean performance of subjects with low and hi gh number of exploratory
choices (see Section /four.tnum).(B) Dependence of the mean performance on the mean probing, where we e xcluded participants without exploratory
choices (count = /zero.tnum). Note that when computing mean performance and mean probing foreach participants, we have excluded the ﬁrst /four.tnum/zero.tnum/zero.tnum
(initial responses during which the subjects might have still been adjusting to the task) and last /two.tnum/zero.tnum/zero.tnum (responses after the change in the reversal
statistics) responses of each participant, see Section /four.tnum./seven.tnum forthe motivation for the cutoﬀ.
experimental conditions, reveal subjects’ preferences to engage
with an exploratory option (collect information), and subjects’
motivation to collect rewards. We achieve this by ﬁtting free
model parameters to behavioral responses of each subject (see
Section 4 for more details). Our aim with the model based
analysis is to quantify beliefs about temporal structure of
reversals and understand how the belief updating inﬂuences
subjects’ behavior.
We conceptualized the behavioral model as an active
inference agent (
Friston et al., 2015 , 2016) with hidden semi-
Markov models ( Yu, 2010 ), which are capable of representing
and inferring latent temporal structure. In active inference,
besides deﬁning perception and learning as a Bayesian inference
process, action selection is also cast as an inference problem
aimed at minimizing the expected surprise about future
outcomes, that is, the expected free energy (
Smith et al.,
2022; see also Equation 18). Through its dependence on the
expected free energy, the action selection has an implicit
dual imperative (see possible factorization of the expected free
energy in Equation 18): The expected free energy combines
intrinsic and extrinsic value of a choice, where intrinsic
value corresponds to the expected information gain, and the
extrinsic value to the expected reward of diﬀerent choices. The
implicit information gain or uncertainty reduction pertains to
beliefs about the task’s dynamical structure and choice-outcome
mappings (e.g.,
Schwartenbeck et al., 2013 ; Kaplan and Friston,
2018). Therefore, selecting actions that minimize the expected
free energy dissolves the exploration-exploitation trade-oﬀ, as
every action is driven both by expected value and the expected
information gain. This is a critical feature of active inference
models which allows us to account for exploratory choices (see
Figure 1).
We express the agent’s generative model of task dynamics
in terms of hidden semi-Markov models (HSMM) ( Yu, 2015 ;
Markovi´c et al., 2019 ). The HSMM framework extends a
standard hidden Markov model with an implicit (or explicit)
representation of durations between consecutive state changes.
HSMM have found numerous applications in the analysis of
non-stationary time series in machine learning (
Duong et al.,
2005; Gales and Young, 2008 ), and in neuroimaging ( Borst and
Anderson, 2015 ; Shappell et al., 2019 ). HSMM have also been
used in decision making for temporal structuring of behavioral
policies (
Bradtke and Duﬀ, 1994 ) or in temporal diﬀerence
learning as a model of dopamine activity when the timing
between action and reward is varied between experimental
trials (
Daw et al., 2002 ).
Here, we use the semi-Markov representation of task
dynamics within the behavioral models to deﬁne an agent that
can learn latent temporal structure, form beliefs about moments
of change, and anticipate state changes. We implemented the
learning of the hidden temporal structure of reversals as a
variational inference scheme, where we assume that the agent
entertains a hierarchical representation of the reversal learning
task, with a ﬁnite set of models of possible temporal structure
of the dynamic environment. In other words, we assume
that human brain entertains a set (possibly a very large set)
of temporal templates. In
Figure 4, we show the graphical
representation of the generative model of behavior, which is
described detail in Section 4.6. Here we will brieﬂy introduce
the relevant parametrization of the behavioral model, which
are critical for understanding the model comparison results
presented in the next subsection.
Each temporal template m corresponds to a pair of
parameters m = (µ , ν) that deﬁne the frequency of reversals
Frontiers in Behavioral Neuroscience /zero.tnum/five.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
FIGURE /four.tnum
Graphical representation of the generative model and model
summary. At the top of the hierarchy is the temporal template
variable m. The total number of temporal templates is ﬁnite, e.g.,
m ∈
{
/one.tnum,... , mmax
}
, and each template m provides an implicit
representation of a prior probability distribution over
between-reversal intervals d, parameterized with a pair
m = (µ , ν), where µ expresses mean between reversal interval,
and νplays a role of a precision parameter, that deﬁnes
regularity of between-reversal intervals. The implicit
representation of temporal structure is encoded with probabili ty
transition matrices LLLm,f of latent phases f. The number of latent
phases depends on precision ν. The reversal can occur only
when the end phase is reached ( f = ν+ /one.tnum). Therefore, the phase
variable f controls the transitions probability BBBs/one.tnum,f between latent
states of the task denoted as random variable s/one.tnum∈
{
/one.tnum, /two.tnum
}
. At
every trial t the subject makes a choice at hence decides on
which option ( s/two.tnum) to select which results in an outcome ot. The
choices are deterministic, meaning that the corresponding
transition probability corresponds to identity matrix, that is ,
p
(
s/one.tnum
t |s/one.tnum
t−/one.tnum, at
)
= p
(
s/one.tnum
t |at
)
= δs/one.tnum
t ,at , hence BBBa = I/three.tnum. Finally, the
choice-outcome contingencies are treated as latent variables
ρρρs/one.tnum,s/two.tnumwhich have to be learned over the course of the
experiment. We use a vague Dirichlet prior over
choice-outcome contingencies. Inverting the generative model
of outcomes using variational inference deﬁnes the inference
and learning component of the behavioral model. In turn,
marginal beliefs about latent states s/one.tnum
t , s/two.tnum
t and parameters ρρρs/one.tnum,s/two.tnum
are used to deﬁne action selection, that is compute the choice
likelihoods using the expected free energy (Equation /one.tnum/eight.tnum).
µ and the regularity of reversals ν (the higher the value the
more regular the changes are). In Figure 12, we illustrate three
of these templates, which diﬀer in their regularity parameter ν,
but all have the same frequency parameter µ . It is important
to note that when ν = 1 (the lowest value) the temporal
templates correspond to the hidden Markov model (HMM)
representation. HMM representation implies that the moments
of reversals are unpredictable, or maximally irregular. Here
we use the HMM representation as a reference point for
determining whether participants were able to learn latent
temporal structure of reversals, and whether they a priori
expected predictable moments of reversal.
When simulating behavior and ﬁtting the model to
participants’ choices, we use a prior probability p (m) over
temporal templates m to restrict otherwise rich set of all possible
temporal templates m =
(
µ , ν
)
, that span all combinations of
µ ∈ {5, ... , 45} and ν ∈ {1, ... , 10}. Hence, template prior
p (m) reﬂects prior expectations of an agent at the beginning
of the experiment about the possible temporal structure of the
task dynamics. Therefore, to capture a wide range of prior beliefs
we require a ﬂexible prior p(m) that can reﬂect subjects with
diﬀerent prior expectations about temporal structure. Posterior
estimates of the most likely parameterizations of the temporal
prior, allows us to infer from the behavioral data if participants’
beliefs are a priori precise and biased toward expecting irregular
reversals, or are imprecise and accommodate a wide range of
possible latent temporal structures. In the model, we use the
following prior over temporal templates:
p
(
m|νmax
)
= p
(
µ , ν|νmax
)
= p(µ )p
(
ν|νmax
)
p(µ ) = 1
40
p
(
ν|νmax
)
=
{ 1
νmax for 1 ≤ ν≤ νmax
0 otherwise
(1)
where νmax ∈ {1, ... , 10}. Note that the prior regularity
parameter νmax reﬂects Bayesian prior expectations about the
maximal precision of between-reversal intervals. In other words,
νmax captures the agent’s expectations about the maximal
regularity of reversals, and hence their predictability. Thus,
with this parameterization we assume that subjects, at the
beginning of the experiment, have uniform beliefs about a
possible mean duration between reversal interval, but might
diﬀer in their propensity to represent high or low regularity
of between-reversal intervals. For example, some subjects could
hold precise beliefs that reversals were not under their control
and were therefore inherently unpredictable (corresponding
to νmax = 1). Such a subject would fail to learn—or
accumulate evidence for—the regularity of reversals in the
regular condition. Conversely, some participants may have
imprecise prior beliefs about regularity ( νmax > 1); enabling
them to learn that reversals were regular, thus predictable, in the
appropriate condition.
The beliefs about temporal templates, inﬂuence the beliefs
about the reversal probability on any given trial (i.e., how likely
is that a reversal occurs in the next trial), and consequently
modulate beliefs about the latent state of the task (i.e., which card
is associated with high reward probability) and corresponding
outcome probabilities. In turn, the beliefs about the latent state
inﬂuence the choices. As mentioned above, choices are deﬁned
as the minimizers of the expected free energy (surprise about
future outcomes), typically denoted by G. Given the expected
free energy Ga [PPPo, νmax, t] of action a on trial t we deﬁne the
choice likelihood as
at ∼ p(a) ∝ eγGa[PPPo,νmax,t]. (2)
Frontiers in Behavioral Neuroscience /zero.tnum/six.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
Here, the parameter γ denotes choice precision, the vector of
probabilities PPPo =
(
p−, p+, 1
2 pc, 1
2 pc
)
denotes prior preferences
over possible outcomes, that is, losses ( −), gains ( +), and cues
(c). In active inference ( Friston et al., 2017 ) prior preference
parameter PPPo deﬁnes a preference of the agent to observe
rewards and collect information (engage with the exploratory
option). This balance is at the core of active inference and rests
upon choosing actions that minimize expected free energy (see
Section 4). In turn, expected free energy can be decomposed
into epistemic value (i.e., expected information gain) and
extrinsic value (i.e., expected preferences or reward). The
relative contribution of epistemic and extrinsic value depends
upon the precision of preferences over outcomes. In other
words, if subjects do not care which of the four outcomes
they encounter, then they will behave in a purely exploratory
fashion. Conversely, if they have precise or strong preferences,
extrinsic value will dominate. In our setup, the precision of
preferences rests on two diﬀerences; namely the diﬀerence
between reward and loss, and the diﬀerence between collecting
rewards or information. Interestingly, a prior preference for
collecting information has, itself, epistemic aﬀordance (or at
least has greater epistemic value than collecting rewards). This
kind of prior preference emerges during the formation of
epistemic habits. In the terminology of reinforcement learning,
the logarithm of prior preferences ln PPPo assigns a subjective value
to possible outcomes, and the expectation of log-preferences
deﬁnes the expected value of diﬀerent actions (see Equation 18).
Importantly, we use Equation (2) in two diﬀerent ways:
(i) as a mapping from beliefs into actions which we used to
simulate behavioral choices, and (ii) as a choice likelihood
which we use for inverting the model when ﬁtting the model to
subjects’ choices to derive the posterior estimates of free model
parameters ( γ, p−, p+, νmax), individually for each subject.
Details of the model inversion procedure are described in
Section 4.7.
/two.tnum./two.tnum./one.tnum. Simulating the behavioral eﬀect of prior
expectations over temporal templates
By simulating the model’s behavior given diﬀerent
values of temporal regularity parameter νmax, we aimed to
demonstrate that the agent can acquire a correct representation
of the latent temporal structure in diﬀerent experimental
conditions, and that νmax inﬂuences the dynamics of both
performance and probing. Importantly, diﬀerent values of
νmax should lead to suﬃciently distinct behavior, if we hope
to accurately associate subjects’ behavior with underlying
model parameterization.
The temporal regularity parameter νmax is the key parameter
in the model to understand how learning about temporal
structure comes about. As νmax constrains the maximal
temporal regularity the agent expects in the task, it is
a measure of subjects’ sensitivity to the latent temporal
structure. Importantly, we ﬁnd that varying νmax results in
simulated behavior with distinct behavioral patterns in our two
experimental conditions as shown in
Figure 5. As we increase
νmax the behavioral performance increases, in both conditions.
In contrast, as we increase νmax the probing decreases, as the
agent is more certain about the moment of reversal and requires
information provided by exploratory option less often. Note
that diﬀerent values of νmax induce stronger diﬀerences in both
performance and probing in the regular condition, compared to
the irregular condition. Practically, this means that we can infer
νmax from behavioral data with higher precision in regular than
in irregular condition. We validate the classiﬁcation accuracy of
νmax based on posterior estimates given simulated data in the
form of confusion matrix as shown in
Supplementary Figure 2 .
Note that even in the ideal case when behavior is generated
exactly from the behavioral model, classiﬁcation accuracy with
regard to νmax is substantially lower in irregular compared
to irregular condition. We will clarify the impact of low
classiﬁcation accuracy in the next subsection when discussing
the results of model-based analysis.
/two.tnum./two.tnum./two.tnum. Demonstrating the learnability of latent
temporal structure
As a next step we will illustrate that the agent with the
highest value of temporal prior ( νmax = 10)—that is, the
agent with the most adaptable beliefs about the latent temporal
structure—is capable of accurately inferring the correct temporal
template m, and that the rate at which agent learns correct
representations of the temporal structure depends on the given
temporal context. Hence, we expect that human subjects, with
similar prior expectations about temporal structure, should also
be capable of learning the correct statistics. In
Figure 6, we show
posterior beliefs over temporal templates in the form of marginal
posterior beliefs about the mean µ and the regularity νat each
time step of the experiment. We see that the agent quickly
learns the correct mean between-reversal duration (already after
200 trials the highest posterior probability is close to µ =
19), but it takes longer (more than 400 trials) to form precise
beliefs about the level of temporal regularity. In contrast, in
the irregular condition, learning the correct mean between-
reversal-interval (ﬁxed to µ = 19 in both conditions) takes
more time and is less precise, but the posterior estimates
over the precision parameter ( ν) converge faster to the correct
values (already after 200 trials). Note that having the correct
representation of both mean and precision parameters is more
important in the regular condition as one can achieve higher
improvements in the performance compared to the irregular
condition, as we demonstrated previously in
Markovi´c et al.
(2019).
Frontiers in Behavioral Neuroscience /zero.tnum/seven.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
FIGURE /five.tnum
Model dependent dynamics of behavioral measures for varying νmax. Each line corresponds to an average over n = /five.tnum/zero.tnum simulated trajectories
with γ = /five.tnum, andPPPo = (/zero.tnum./one.tnum, /zero.tnum./six.tnum, /zero.tnum./one.tnum/five.tnum, /zero.tnum./one.tnum/five.tnum).(A) Performance estimated as odds of generating a correct choice with in a /two.tnum/zero.tnum/zero.tnum trials long time window
centered at trial index. (B) Probing, computed as odds of selecting the exploratory option within the /two.tnum/zero.tnum/zero.tnum trials long time window. The shaded
colored areas around the trajectories correspond to the /nine.tnum/five.tnum% conﬁdence interval.
FIGURE /six.tnum
Posterior beliefs about temporal templates. Posterior beliefs of a s ingle agent in the regular (left) and the irregular condition (right). Posterior
beliefs qt(m) = qt(µ , ν) at each trial t over templates m are marginalized over precision parameter νobtaining qt(µ ) (top) and mean parameter µ
obtaining qt(ν) (bottom). The posterior beliefs are estimates obtained from a single run of th e agent in both experimental conditions where we
ﬁxed the temporal prior parameter to νmax = /one.tnum/zero.tnum, choice precision toγ = /five.tnum, and the preference vector toPPPo = (/zero.tnum./one.tnum, /zero.tnum./six.tnum, /zero.tnum./one.tnum/five.tnum, /zero.tnum./one.tnum/five.tnum). The lighter the
color the higher is the corresponding posterior probability for that p arameter value.
Frontiers in Behavioral Neuroscience /zero.tnum/eight.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
/two.tnum./two.tnum./three.tnum. Simulating the behavioral eﬀect of prior
preferences over outcomes
As mentioned above, the prior preference over outcomes
PPPo parameterize agents’ motivation to collect rewards (generate
correct choices) and collect information (engage with the
exploratory option). Therefore, it is important to understand
how prior preferences interact with performance and probing.
We show that the more an agent engages with the exploratory
options (i.e., the higher its preference for choice cues), the
better its representation of latent temporal structure, and
consequently the higher agent’s performance. This is because
selecting exploratory options maximally reduces the uncertainty
about the latent state (which option has higher reward
probability) which in turn allows an agent to learn a more
accurate representation of the latent task dynamics. We visualize
these dependencies in
Figure 7, where we show what impact
changing p+ and p− have on performance, probing, and
the quality of temporal representation after 800 trials. In the
Supplementary Figure 3 we show the same dependencies but
with respect to changing p+ and pc, hopefully helping the reader
to build an intuition about interactions between prior preference
parameter and behavior. Note that in both ﬁgures we only
consider cases in which p+ ≥ p− as this reﬂects higher prior
preference for gains than for losses in the agent, which we expect
to hold for all subjects.
/two.tnum./three.tnum. Model-based analysis of subjects’
choices
By estimating the prior beliefs—under a semi-Markovian
generative model—that best explain observed choice behavior,
we next ask whether human subjects can learn latent temporal
regularities in the reversal learning tasks? An individual’s
capacity to learn correct temporal regularity corresponds to
their behavior being associated with a less precise prior over
temporal templates (Equation 1), that is, larger νmax. An
agent with imprecise prior over temporal templates is able to
learn an accurate representation of a distribution of between-
reversal-intervals, and to form expectations about the moment
of reversals (see
Figures 6, 7) in both conditions. Thus, we
anticipated that between-subject variability in performance and
probing would be reﬂected in diﬀerent posterior estimates of the
most likely νmax value associated with the behavior of individual
subjects.
Therefore, we ﬁrst classify subjects based on the maximum
a-posteriori estimate over possible values of νmax ∈ {1, ... , 10},
as shown in
Figure 8. For each subject we compute a posterior
probability over νmax and assign the subject the value of the
temporal prior νmax corresponding to the value with the highest
exceedance probability (see Section 4.7). Using this procedure
we ﬁnd that 11 out of 41 subjects in the regular condition, and
1 out of 33 subjects in the irregular condition are assigned to
the group with temporal prior νmax > 1. For the subjects in
the regular condition this result suggests that about a quarter
of subjects learned to anticipate reversals to a certain extent. As
our aim is not to identify precisely participants’ temporal prior,
but simply to distinguish between subjects that learn temporal
regularities ( νmax > 1) from those that do not ( νmax =
1), limiting the analysis to binary classiﬁcation leads to the
following classiﬁcation accuracy in simulated data: (i) in the
regular condition νmax = 1, ACC = 1, and νmax >1, ACC = 1,
(ii) in the irregular condition νmax = 1, ACC = 1.0 and νmax >
1, ACC = 0.9. Note that in regular condition we have around
10% chance of misclassifying a subject that actually has a less
precise prior over temporal templates ( νmax >1).
The posterior estimates of model parameters shown in
Figure 8 show that the majority of participants were assigned
to the model class corresponding to the simplest HMM
representation (νmax = 1) which assumes maximal irregularity.
However, in the regular condition we also ﬁnd a number of
participants (27%) that exhibit more ﬂexible priors, allowing us
to form two subject groups. Importantly, when we plot the time
course of both performance and probing, as shown in
Figure 9,
we ﬁnd a trajectory of behavioral measures over the course of the
experiment similar to what we see in simulated data. Namely,
that the performance is higher and the probing reaches lower
values in the group of participants associated with larger νmax
(compare with
Figure 5—regular condition). We excluded the
irregular condition from the visualization as we did not ﬁnd
suﬃcient number of subjects with associated with numax > 1.
The behavioral trajectories of individual participants are shown
in
Supplementary Figure 1 .
These ﬁndings show a good correspondence between
simulated behavior for diﬀerent parameterizations of the model
(νmax = 1 vs νmax > 1 in
Figure 5), and the participants’
behavior associated with diﬀerent model classes ( Figure 9).
There are two possible explanations for this: (i) the model
inversion accurately captures the participants behavior and
between-participant sensitivity to temporal regularities of the
task, (ii) the group diﬀerences come from other free model
parameters and do not correspond to diﬀerences in sensitivity
to temporal structure. To exclude the second option we show
in
Figure 10 the mean of the posterior estimates of free model
parameters γ, p− and p+. Note that in both experimental
conditions we see a lack of separation between free model
parameters associated with each model class.
There are a couple of interesting observations to be made
from the posterior expectations of the free model parameters.
First, we ﬁnd in most participants rather large posterior
estimates of choice precision γ, close to γ = 5 (see
Figures 10B,D), suggesting that choice stochasticity is rather
low in most participants. Low choice stochasticity means
that choices are well aligned with the choice likelihoods
encoded in terms of expected free energy (Equation 18). In
Frontiers in Behavioral Neuroscience /zero.tnum/nine.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
FIGURE /seven.tnum
Dependence of performance, probing, and the quality of temporal representations on prior preferences over outcomes. Each dot in the plot
corresponds to a single run with ﬁxed prior preferences Po =
(
p−, p+, /one.tnum
/two.tnumpc, /one.tnum
/two.tnumpc
)
, with temporal prior set to νmax = /one.tnum/zero.tnum, and with decision
precision set to γ = /five.tnum. For each possible pair ((p−, p+) ∈
{
/zero.tnum./zero.tnum/five.tnum, /zero.tnum./zero.tnum/six.tnum,... , /zero.tnum./two.tnum/five.tnum
}⨂ {
/zero.tnum./five.tnum, /zero.tnum./five.tnum/five.tnum, /zero.tnum./six.tnum
}
) we have repeated n = /five.tnum/zero.tnum simulations in each
condition. Here RMSEµ ,ν stands for the root mean square error of corresponding parameters µ , νthat deﬁne temporal template. The RMSE is
computed using posterior probabilities qt(µ , ν) obtained at trial t = /eight.tnum/zero.tnum/zero.tnum. The performance and the probing are computed as averages over
responses from trial t = /four.tnum/zero.tnum/zero.tnum until trialt = /eight.tnum/zero.tnum/zero.tnum. Note that probing is increasing as we reducep− and keep p+ ﬁxed (circles of the same color), and
as we reduce p+ and keep p− ﬁxed, as the larger the sum ( p+ + p−) is, the lower is the preference for choice cues pc, and hence the tendency of
the agent to engage with the epistemic option. Higher probing (larger circle size) results in higher performance in both conditions (top row).
Similarly, both RMSEµ and RMSEν are lower for larger exploration odds, with the exception of RMSEν in irregular condition. Note that forming an
accurate temporal representation is especially important in t he regular condition, where forming correct anticipatory beliefs c an substantially
improve behavioral adaptation and simplify the problem of balanc ing between exploratory and exploitative choices. In contrast, i n the irregular
condition, having a precise representation of temporal structu re does not impact performance substantially, and the agent perf orms better
when engaging with the epistemic option more often.
other words, the chosen option is the option that minimizes
expected free energy and the model is rather accurate in
predicting behavioral responses. Second, the posterior estimates
of outcome preference parameters p−, and p+ split subjects in
two distinct groups, which correspond to their preference for
receiving informative cues when selecting exploratory option.
The 29 subjects who never engaged with the exploratory option
have a higher preference for losses than for informative cues,
hence p− ≥ pc. We marked with the dashed gray line
(
Figures 10A,C) the limiting case of p− = pc = 1−p+
2 , which
separates the subjects which did not interact with the exploratory
option (above the dashed line) and subjects that were relying
on exploratory option to reduce their belief uncertainty (below
the dashed line). Similarly, participants who prefer informative
cues over gains would have prior preferences over cues in the
region pc ≥ p+. The dotted gray line (
Figures 10A,C) marks the
limiting case of p+ = pc = 1−p−
2 . Note that only one subject
in the irregular condition, and several subjects in the regular
condition fall along this line.
/three.tnum. Discussion
Sequential activity of neuronal assemblies is one of
principled neuronal operations that support higher level
cognitive functions (
Eichenbaum, 2014 ; Buzsáki and
Llinás, 2017 ) and allow humans to form complex spatio-
temporal representation of our every day environment
(
Frölich et al., 2021 ). Akin to grid cells known to support
representation of both spatial and non-spatial task states
(
Fu et al., 2021 ), time cells have been linked to temporal
representation of state sequences critical for memory
and decision-making (
Eichenbaum, 2014 ). Importantly,
in spite of these fruitful experimental ﬁndings we have
Frontiers in Behavioral Neuroscience /one.tnum/zero.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
FIGURE /eight.tnum
Posterior probability over temporal prior νmax. Posterior probability of possible νmax values for each subject, reﬂecting a subject’s ﬂexibility to
learn latent temporal structure: (A) regular condition, and (B) irregular condition. On the right hand side, we combine posterior es timates into
two classes, one for the limiting case νmax = /one.tnum, and another for all other optionsνmax >/one.tnum. This split diﬀerentiates subjects not sensitive to
temporal regularities from the ones who a priori expected a regular t emporal structure of reversals. Note that lighter colors correspon d to
higher posterior probability.
FIGURE /nine.tnum
Category based mean estimate of behavioral measures. Each line corresponds to a model class average over behavioral trajectories o f subjects
assigned to that model class. Note the similarity of the traject ory proﬁles to the simulated trajectories in
Figure /five.tnumregular condition. The shaded
colored areas around the trajectories correspond to the /nine.tnum/five.tnum% conﬁdence interval.
Frontiers in Behavioral Neuroscience /one.tnum/one.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
FIGURE /one.tnum/zero.tnum
Posterior median of continuous model parameters. Each dot correspon ds to the median of the n = /one.tnum, /zero.tnum/zero.tnum/zero.tnum samples from the posterior
distribution of γ, p−, and p+ for each participant. The dashed gray lines denotes equality be tween preferences for losses and epistemic cues,
that is, when p− = pc
/two.tnumthen p− = (/one.tnum− p+)//two.tnum. In turn, the doted grey line indicates equality between preferences for gains and epistemic cues, that
is, when p+ = pc
/two.tnumthen p− = /one.tnum− /three.tnump+. Note that we use the same color coding as in the previous ﬁgure to den ote classiﬁcation of participants
into diﬀerent model classes.
no clear computational understanding of how humans
learn temporal structure in the service of successfully
behavioral adaptation.
Here we introduced a novel computational model of
behavior capable of learning latent temporal structure of a
probabilistic reversal learning task with multiple reversals
(
Costa et al., 2015 ; Reiter et al., 2016 , 2017; Vilà-Balló et al.,
2017). The computational model combines hidden semi-Markov
framework for representing latent temporal structure ( Yu,
2015) and active inference for resolving exploration-exploitation
trade-oﬀ ( Friston et al., 2015 , 2016). Crucially, the model
can be used for investigating decision making in changing
environments in any behavioral task that can be cast as a
dynamic multi-armed bandit problem (
Gupta et al., 2011 ;
Markovic et al., 2021 ); of which the reversal learning tasks is
a special case corresponding to a speciﬁc type of two-armed
bandit problem.
The probabilistic reversal learning task, which we utilized
to demonstrate ﬂexibility of proposed model, is one of
the most established paradigms for investigating human
behavior in changing environments and quantifying cognitive
disorders. We used model-based analysis of behavioral data
to infer temporal expectations of subjects exposed to one
of the two task variants: (i) with regular intervals between
reversals, (ii) with irregular intervals between reversals.
Notably, being able to form expectations about the moment
of reversal is critical for achieving high performance in the
probabilistic reversal learning task, which we illustrate using
simulations. We demonstrated that participants behavior is
highly heterogeneous reﬂecting the diﬀerences in participants
expectations about temporal regularities. Crucially, the
participants expectations about temporal regularities inﬂuence
their ability to correctly learn latent temporal structure
(especially relevant in the condition with regular between
reversal intervals), and is reﬂected in their performance
throughout the experiment.
We have extended the standard reversal learning
task and incorporated an explicit exploratory option in
addition to the two standard options whose choice results
in monetary gain or loss. This exploratory option informs
the participant about the currently correct choice. The
additional behavioral response provides us with more direct
access to the individual uncertainty about a correct choice
and improves model selection. Interestingly, in addition
to participants’ diversity of temporal representation, we
ﬁnd stark diﬀerences in their preferences to engage with
the exploratory option, suggesting individual diﬀerences
for the value of information (
Niv and Chan, 2011 ) and
utilized strategies for resolving the exploration-exploitation
trade-oﬀ. Critically, their epistemic preferences are not
obviously correlated with the quality of the learned temporal
structure, as in both groups participants show heterogeneous
prior expectations about temporal regularities limiting the
available temporal templates, hence the accuracy of temporal
representations. However, the willingness to engage with the
epistemic options does inﬂuence participants’ performance,
where higher engagement results in better performance.
Therefore, these joint ﬁndings reveal distinct components of the
Frontiers in Behavioral Neuroscience /one.tnum/two.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
computational mechanisms that underlie adaptive behavior in
dynamic environments.
To recapitulate, we have eﬀectively shown that it is
possible to explain a subject’s choice behavior in terms of
their prior beliefs about temporal regularity, that is, a set of
temporal templates they entertain, and other contingencies
that characterize the (generic) paradigm at hand. This is
potentially important because this kind of phenotyping could
be deployed in a neurodevelopmental or psychiatric context
to summarize any subject in terms of a small number of
interpretable priors. Theoretically, this sort of phenotyping
provides a suﬃcient description of a subject via the complete
class theorem. The complete class theorem says that for any
given pair of reward functions and behaviors there exists
some priors that render the behavior Bayes optimal (
Wald,
1947; Brown, 1981 ). To be Bayes optimal is to conform
to the belief updates and action selection described by
active inference. This means that there is always a set of
prior beliefs that provide a suﬃcient account of any subject
speciﬁc behavior.
Having said this, we have only explored a small subset
of possible sets of temporal templates. We could apply the
same technology (i.e., model inversion) to ask more general
questions. For example, if some subjects a priori exclude
from the templates the possibility of irregular reversals. There
are other priors we could have explored that place various
constraints on belief updating or divergences from particular
prior beliefs. These might be interestingly related to notions
of motivation, cognitive eﬀort and resources in cognitive
science (
Pezzulo et al., 2018 ); however, this would require a
speciﬁcation of motivation, resources and eﬀort in terms of
belief updating, which is an outstanding challenge. Overall,
we expected that, as we humans are exposed to predictable
changes in our everyday environment, that there should be
profound evidence that subjects utilize a higher order (semi-
Markovian) model. The fact that we do not see that in the
model selection results (in the regular condition the majority of
subjects’ behavior can be associated with the simplest Markovian
assumption) suggests that a better experimental paradigm than
the currently used reversal learning task is required. This
paradigm should be more engaging and intuitively linked to
distinct latent temporal regularities. A notable limitation of
the current experimental paradigm is that it is not obvious to
subjects that anticipating reversals can improve performance,
or that potential performance improvement is suﬃciently large
to justify added eﬀort required to keep track of higher-
order statistics.
To accurately predict future it is critical not only to
know that change might be coming but also when the
change will occur. To anticipate the changes in our-everyday
environments and adapt our behavior accordingly, it is critical
to accurately estimate and represent elapsed time between
relevant events. Although the presented model abstracts
elapsed time as a hierarchically structured counting process,
it is straightforward to model events duration in physical
time, by using continues representation of the phase-type
distribution. This way the underlying model corresponds to
continues time semi-Markov processes (
Hongler and Salama,
1996) where state transitions follow the master equations,
allowing one to capture decision making in real-time. Notably,
an implicit assumption we make here is that a simple
counting process can represent elapsed time at multiple
time scales. In fact, various experimental ﬁndings suggest
that the brain employs counting mechanisms, represented
over multiple timescales, and integrates those representations
when generating behavior (
Baldassano et al., 2017 ; Fountas
et al., 2022 ). Similarly, a range of experimental ﬁndings has
linked timing of events and hence forecasting the future
to underlying Bayesian inference mechanisms (
Jazayeri and
Shadlen, 2010 ; Griﬃths and Tenenbaum, 2011 ). Most recently,
Maheu et al. (2022) has linked sequence learning and prediction
in human subjects to an underlying hierarchical Bayesian
inference model with distinct hypothesis spaces for statistics
and rules corresponding to a set of deterministic temporal
templates. The authors conclude that the hierarchical Bayesian
inference mechanism underlies human ability to process
sequence, similar to hierarchical semi-Markov framework
proposed here.
Furthermore, in recent years, various neuroimaging studies
have linked diﬀerent neuro-cognitive domains, such as attention
and working memory, to speciﬁc spatio-temporal expectations
about underlying dynamics of the environment (
Nobre and
Van Ede, 2018 ). Interestingly, the human ability to estimate
and reproduce elapsed time was also previously linked to
reward discounting and intertemporal choice behavior (
Ray
and Bossaerts, 2011 ; Retz Lucci, 2013 ; Bermudez and Schultz,
2014). For example, McGuire and Kable (2015) demonstrated
that “impulsivity” (reluctance to wait for a better reward),
depends on the hidden statistics of delays—between an
initial bad oﬀer and a later but more valuable oﬀer—which
human participants experienced. Using a similar “limited oﬀer”
game (with a constant latent temporal statistics) and active
inference representation of behavior (
Schwartenbeck et al.,
2015) have linked the dopaminergic midbrain activity with
expected certainty about desired outcomes. In Mikhael and
Gershman (2019), the authors have linked time perception and
dopaminergic neuronal activity, demonstrating the role of value-
based prediction errors in time representation. Furthermore,
time perception and timed behavior have been linked to
all major neuromodulatory systems (
Meck, 1996 ) either
directly using neuropharmacological manipulations ( Crockett
and Fehr, 2014 ) or indirectly using neurological disorders
(Story et al., 2016 ) and aging research ( Read and Read,
2004).
Together these ﬁndings provide important evidence for
the role of temporal expectations in goal-directed decision
Frontiers in Behavioral Neuroscience /one.tnum/three.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
making and let one speculate whether a range of aberrant
behaviors might be related to an erroneous representation of the
temporal structure of the task. Importantly, the computational
behavioral model that we introduced here can emulate the
learning of temporal structure, hence can become a potent
tool linking aberrant behavior found in cognitive disorders
to erroneous prior beliefs about the rules that govern the
dynamics of the environment, as suggested by the active
inference account of human behavior (
Friston et al., 2015 , 2016,
2017).
To conclude, the results presented here provide novel
insights into computational mechanism underlying the
human ability to learn hidden temporal structure of the
environment and the computational principles they utilize
for making decisions based on temporal representations. The
fact that we ﬁnd behavioral heterogeneity in a population
of healthy young adults suggests a potential use of the
proposed design and behavioral model for cognitive
phenotyping and for revealing causes of aberrant behavior
in clinical populations.
/four.tnum. Methods and materials
/four.tnum./one.tnum. Code availability statement
All code for reproducing the ﬁgures and running
data analysis and simulation algorithms is available at
https://github.com/dimarkov/pybeﬁt.
/four.tnum./two.tnum. Experiment
/four.tnum./two.tnum./one.tnum. Probabilistic reversal learning
In the experimental task subjects were deciding between two
cards shown on a screen, each showing a diﬀerent stimulus (a
geometric shape, e.g., rectangle, triangle, or a question mark) as
shown in
Figure 1. The reward probabilities associated with the
two choice options were anti-correlated on all trials: whenever
reward probability of choice A was high ( pH = 0.8) the reward
probability of choice B was low ( pL = 0.2), and vice versa. Note
that pH = 1 − pL on all trials. The location of each stimulus on
the screen (right or left side) was kept ﬁxed over trials. After each
choice the stimulus was highlighted and depicted for 1.5s minus
the reaction time. The feedback in the form of a gain or a loss
was shown for 0.5s. Similarly, the feedback after an exploratory
choice was also shown for 0.5s. If no response occurred during
the decision window of 3s, the message “too slow” was presented,
and no outcome was delivered.
All subjects underwent a training session during which
they had the opportunity to learn the statistics of the rewards
associated with high pH and low pL reward probability choices.
The set of stimuli used in the training phase diﬀered from the
one used during the testing phase. Subjects were instructed
that they could either win or lose 10 cents on each trial,
and that they will be paid the total amount of money they
gained during the testing phase at the end of the experiment.
Each subject performed 40 training trials with a single reversal
after the 20th trial. Before the start of the testing phase
subjects were told that the reward probabilities might change
at regular intervals (in both conditions) over the course of
the experiment. No other information about reversals or the
correlation of choices and outcomes was provided. Thus, the
subjects had no explicitly instructed knowledge about the anti-
correlated reward probabilities or between-reversal-intervals
before the experiment.
Note that, out of n = 74 participants np = 24 were exposed
to the variant of the reversal learning task without epistemic
option. This group of subjects belongs to an initial pilot study
that used the standard two-choice task design. In the pilot study
14 subjects were assigned to the regular condition and 10 to the
irregular condition. We decided to include the subjects from the
pilot into the analysis, as we noticed that almost 30% of subjects,
in the post pilot group, choose not to interact at all with the
exploratory option, even when that was a possibility. We will
not explore this ﬁnding here in more detail, but we can exclude
their misunderstanding of the task as a potential confound, as
we provided a detailed instructions and training before they
performed the task (see Section 4.3 for more details).
/four.tnum./three.tnum. Behavioral measures
To quantify behavior we have used two summary measures:
(i) performance, deﬁned as odds of making a correct choice, and
(ii) probing, deﬁned as odds of making an exploratory choice.
The process of computing performance is illustrated in
Figure 11. We ﬁrst label subjects’ responses as either correct
or incorrect, depending on whether a card with higher reward
probability was selected or not (see
Figure 11A). Then we
compute a probability of making a correct choice within a
201 trial window, centered at the current trial number t (see
Figure 11B). Finally, for each trial we compute performance as
odds of being correct (see Figure 11C).
The probing is computed in similar manner to performance,
with the only diﬀerence that we label choices as either
exploratory or exploitative depending on whether subjects have
chosen the exploratory option (middle card in
Figure 1), or not.
Probing is deﬁned as the odds of selecting the exploratory option
within a 200 trials time window.
/four.tnum./four.tnum. Behavioral model
To introduce the generative model of task dynamics, and
subsequently derive the behavioral model via model inversion
Frontiers in Behavioral Neuroscience /one.tnum/four.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
FIGURE /one.tnum/one.tnum
Computing behavioral performance. The process of computing performance. (A) We label subjects’ responses as either correct or incorrect,
depending on whether a card with higher reward probability was s elected or not. (B) We compute a probability of making a correct choice
within a /two.tnum/zero.tnum/zero.tnum trial window, centered at the current trial number t. (C) For each trial we compute performance as odds of being correct.
methods, we will consider the following features of the task.
At any trial the task environment is in one of the two possible
states, deﬁned as the conﬁguration of reward contingencies. For
example, state one corresponds to stimulus A being associated
with a high reward probability pH, and state two to stimulus
B being associated with a low reward probability pL. Subjects
do not know in advance how likely rewards and losses are
when making a correct choice compared to making an incorrect
choice, and this is something they have to learn during the
course of experiment. In other words, we also treat reward
probabilities ( pH and pL) as latent variables. Between trials the
state can change, i.e., when a reversal occurs but only after a
certain minimum number of trials has elapsed since the last state
change. Depending on the experimental condition the between
reversal duration will either be semi-regular (occurring every
20 trials with small variability) or irregular (occurring every 20
trials, but with maximal variability)
The explicit representation of state duration d enables us
to associate changes in state transition probabilities with the
current trial and the moment of the last change. The dependence
of state transition probability on the number of trials since
the last change corresponds to the formalism of hidden semi-
Markov models (HSMM;
Murphy, 2002; Yu, 2010), which allows
mapping complex dynamics of non-stationary time series to
a hierarchical, time aware, hidden Markov model. However,
using an explicit representation of context duration is ineﬃcient,
as it requires an enormous state space representation. Here,
we will instead adopt a phase-type representation of duration
distribution (
Varmazyar et al., 2019 ) which substitutes duration
variable d ∈ {1, ... , ∞} with a phase variable f ∈
{
1, ... , fmax
}
,
allowing for a ﬁnite state representation of an inﬁnite duration
state space.
In what follows we will deﬁne the components of the
generative model (observation likelihood, the dynamics of latent
variables, and the parameterization of the dynamics) and derive
the corresponding update rules for latent variables and state,
hence enabling the learning of diﬀerent temporal contexts
during the experiment. The graphical representation of the
generative model is shown in
Figure 4.
Practically we introduce four latent states, to describe the
task on any trial:
• First, the conﬁguration of reward contingencies can be
in one of the two possible states. Hence, s1
t ∈ {1, 2}
which describes which card is associated with high reward
probability and which with low reward probability.
• Second, choosing one of the options on a given trial
corresponds to setting the task in one of the three possible
Frontiers in Behavioral Neuroscience /one.tnum/five.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
choice states s2
t ∈ {1, 2, 3} (chosen left card, chosen
middle card—exploratory option, and chosen right card)
corresponding to the chosen option. The choice of the
option is deterministic and this state is always known with
certainty after the choice is made.
• Third, current phase ft ∈ {1, ... , ν+ 1} of the task
dynamics. The phase latent variable controls transitions of
latent state s1
t , where the change of state is only possible if
the end phase ( ft = ν + 1) is active on the current trial.
Note that the larger the number of phases is (parameter
ν ∈ 1, ...) the more regular is the occurrence of reversals.
We have limited here the number of phases by setting ν =
10, as this is suﬃciently large for accurate representation of
reversal dynamics in regular condition.
• Fourth, temporal template m. Latent temporal template
deﬁnes the frequency of reversals, µ (mean between-
reversal duration) and the number of latent phases ν, that
is the regularity of reversals.
/four.tnum./four.tnum./one.tnum. Observation likelihood
The observation likelihood links latent states ( s1
t , and s2
t )
with probabilities of observing diﬀerent possible outcomes in
those states.
In the temporal reversal learning task there are four possible
outcomes: (1) loss of 10 Eurocents, (2) gain of 10 Eurocents,
(3) the correct card is left card, or (4) the correct card is the
right card. Therefore, we deﬁne the observation likelihood as a
categorical distribution
p
(
ot|ρρρ, s1
t , s2
t
)
=
4∏
i=1
ρδot,i
s1
t ,s2
t ,i (3)
where i denotes the outcome type, ot ∈ {1, ... , 4}. The
probabilities of diﬀerent outcomes are parameterized via
ρs1
t ,s2
t ,i, where each state tuple ( s1
t , s2
t ) corresponds to a unique
probability of observing any of four possible outcomes. We
deﬁne prior beliefs about outcome probabilities in the form of
a product of Dirichlet distributions
p
(
ρρρ
)
=
4∏
s1=1
3∏
s2=1
Dir
(
ρρρs1,s2 |ααα0
s1,s2
)
. (4)
We set the parameters of Dirichlet priors to the following values:
ααα0
s1=1,s2 ≡
ot\s2
1 2 3
1 6 1 32
2 32 1 6
3 1 1000 1
4 1 1 1
, ααα0
s1=2,s2 ≡
ot\s2
1 2 3
1 32 1 6
2 6 1 32
3 1 1 1
4 1 1000 1
(5)
The above conﬁguration for the parameterization of
prior Dirichlet probabilities reﬂects an assumption that the
FIGURE /one.tnum/two.tnum
Negative binomial distribution. We illustrate here the changes in
the negative binomial distribution as a function of shape
parameter νwhich is inversely proportional to the variance of
between reversal durations. Note that for higher values of νthe
distribution peaks around its expected value (dashed line). A s the
variance increases (green) the mode shifts toward zero. The
limiting case of the negative binomial distribution in the form o f
geometric distribution (red) corresponds to ν= /one.tnum. For all three
cases we ﬁxed the mean duration to the same value.
participants have formed during training an initial—vague
beliefs—about reward probabilities associated with diﬀerent
actions in diﬀerent states. We assume that participants are highly
certain that selecting the epistemic option does not return gain
or loss (high value of αααs1,s2=2 for the corresponding outcome
in both states). Furthermore, we assume that participants have
formed good expectations gain/loss probabilities ( ⟨pH⟩ = 32
40 =
0.8, and ⟨pL⟩ = 6
40 = 0.15), but that they are still uncertain
about the exact values. Weak priors about outcome probabilities
allow for ongoing adaptation of beliefs during the course
of experiment.
/four.tnum./four.tnum./two.tnum. Hidden state dynamics
To formalize the presence of sequential reversals, we deﬁne
the phase dependent state transition probability as follows
p
(
s1
t |s1
t−1, ft−1
)
=



I2, if ft−1 = ν+ 1,
J2 − I2, if ft−1 ≤ ν,
(6)
where I2 denotes the 2 × 2 identity matrix and J2 denotes the
2 × 2 all-ones matrix. The above relations describe a simple
deterministic process for which the current state s1
t remains
unchanged as long as the phase variable ft−1 remains below
the end phase, ν+ 1. The transition between states occurs with
certainty (e.g., if s1
t−1 = 1 then s1
t = 2) once the end phase is
reached, that is, when ft−1 = ν+ 1.
Although it is possible to condition state changes on a
duration variable d, as demonstrated in
Markovi´c et al. (2019),
Frontiers in Behavioral Neuroscience /one.tnum/six.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
such an explicit representation is ineﬃcient as it requires large
state spaces (
Vaseghi, 1995; Yu and Kobayashi, 2003 ). Here we
adopt the discrete phase-type (DPH) representation of duration
distribution (
Varmazyar et al., 2019 ). The DPH representation
deﬁnes transitions between phase variables ft and the following
parameterization of phase transition probabilities corresponds
to the DPH representation of the negative binomial distribution
p(ft|ft−1, m) =















δm, if ft−1 ≤ ν, and ft = ft−1 + 1
1 − δm, if ft−1 ≤ ν, and ft = ft−1
πm
ft
, if ft−1 = ν+ 1,
0, otherwise
(7)
where πm
i =
(ν
i−1
)
(1 − δm)ν−i−1 δi−1m for i < ν + 1, and
πm
ν+1 = 1 − ∑ ν
i=1 πm
i .
The corresponding negative binomial distribution of
between-reversal duration can be expressed as follows
pm(d) =
(d + ν− 2
d − 1
)
(1 − δm)d−1 δν
m; d ∈ {1, 2, ...} (8)
where the expected duration corresponds to
Epm
[
d
]
= ν(1 − δm)
δm
+ 1 = µ + 1; δm = ν
µ + ν, (9)
and variance, hence uncertainty about duration regularity, to
Varpm
[
d
]
= µ + µ 2
ν . (10)
Note that the parameter νof the negative binomial distribution,
acts as a precision parameter. We illustrate this in Figure 12.
The choice of prior beliefs about the between-reversal
interval d in the form of a negative binomial distribution
has interesting consequences on the dynamics of the marginal
probability that a reversal will occur at some future point τ
δm [τ] = p(s1
t+τ = 2|s1
t−1 = 2, ft−1 = ν+ 1, m)
=
∑
ft,...,ft+τ
∑
s1
t ,...,s1
t+τ−1
p
(
s1
t , ft|s1
t−1 = 2, ft−1 = ν+ 1, m
)
t+τ∏
k=t+1
p
(
s1
k, fk|s1
k−1, fk−1, m
)
(11)
In
Figure 13, we show the dependence of the future reversal
probability δm [τ] on the precision parameter ν, given a ﬁxed
mean duration Epm
[
d
]
= 20. Note that for ν = 1
we get a constant transition probability, which corresponds
to the expectations of change probabilities found in hidden
Markov models. In contrast, for larger values of ν one obtains
a trial-dependent, eﬀective transition probability with values
alternating between low and high probabilities in a periodic
FIGURE /one.tnum/three.tnum
Expected transition probability at future trial τ. Estimate of the
transition probability δm[τ] (Equation /one.tnum/one.tnum), at a future trialτ
conditioned upon a reversal at t and known initial state s/one.tnum
t . Each
curve corresponds to estimates of the transition probability
obtained from prior beliefs pm(d) shown in
Figure /one.tnum/two.tnum.
manner. This temporal dependence of the transition probability
will aﬀect the inference process. The agent will become
insensitive to subsequent reversals occurring a few trials after
the previous reversal, and highly sensitive to reversals occurring
twenty to thirty trials after the previous reversal.
Finally, the choice states s2
t are fully dependent on the
current choice at ∈ {1, 2, 3}, and we express the state transition
probability as
p
(
s2
t |s2
t−1, at
)
= p
(
s2
t |at
)
= δs2
t ,at . (12)
In practice this means that the agent is always certain about
the choice it made and how that choice impacted the state of
the task. Therefore, the posterior estimate over s2
t can be trivially
expressed as
q(s2
t |at) = δs2
t ,at .
/four.tnum./four.tnum./three.tnum. Active inference
In active inference, agents form posterior beliefs both about
latent states of the environment and about their own actions.
In other words, both perception and action selection are cast
as inference problems (
Attias, 2003 ; Botvinick and Toussaint,
2012). Practically, we will use variational inference for deﬁning
update rules for beliefs ( Blei et al., 2017 ; Friston et al., 2017 ). In
what follows we will ﬁrst introduce perception as minimization
of the variational free energy (upper bound on log-marginal
likelihood) with respect to posterior beliefs over latent states,
and after that introduce action selection as minimization of
the expected free energy (
Smith et al., 2022 ), that is, expected
surprisal about future outcomes.
Frontiers in Behavioral Neuroscience /one.tnum/seven.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
We write the generative model of outcomes ot on trial t as
˜p
(
ot, s1
t , s2
t , ft, m,ρρρ
)
= p
(
ot|s1
t , s2
t ,ρρρ
)
˜pt
(
s1
t |ft
)
p
(
s2
t |at
)
˜pt
(
ft|m
) ˜pt (m)˜pt
(
ρρρ
)
, (13)
where we use ˜pt(·) to denote prior beliefs conditioned on a
sequence of past outcomes, o1 : t−1 =
(
o1, ... , ot−1
)
and choices
a1 : t−1 =
(
a1, ... , at−1
)
. Given a choice a∗
t and an observed
outcome ot at trial t, the approximate posterior belief qt(x) over
latent states x = (s1
t , s2
t , ft,ρρρ, m) is obtained in two steps:
• We ﬁrst compute the marginal likelihood with respect to
˜pt
(
ρρρ
)
, and obtain the exact marginal posterior over discrete
states using the Bayes rule
qt
(
s1
t , s2
t , ft, m
)
=
˜pt
(
ot, s1
t , s2
t , ft, m
)
˜pt (ot) . (14)
• Given the marginal posterior qt
(
s1
t , s2
t
)
=
∑
ft,m qt
(
s1
t , s2
t , ft, m
)
we compute the posterior over
outcome probabilities using the variational message
passing update
qt
(
ρρρ
)
∝ ˜pt
(
ρρρ
)
e
∑
s1
t ,s2
t
q
(
s1
t ,s2
t
)
ln p
(
ot|s1
t ,s2
t ,ρρρ
)
. (15)
As we initially deﬁned the prior over outcome probabilities in
the form of a Dirichlet distribution with parameters α0α0α0, we
can express the posterior estimate on every trial in the same
functional form. Hence,
qt
(
ρρρ
)
=
∏
s1
∏
s2
Dir
(
ρρρs1,s2 |αααt
s1,s2
)
(16)
where
αt
s1,s2=a∗
t ,i = δot,i ·q
(
s1
t = s1
)
+ αt−1
s1,s2=a∗
t ,i
αt
s1,s2̸=a∗
t ,i = αt−1
s1,s2̸=a∗
t ,i
, (17)
and ˜pt
(
ρρρ
)
= qt−1
(
ρρρ
)
. The above belief updating scheme
corresponds to the variational surprise minimization learning
algorithm (
Liakoni et al., 2021 ; Markovic et al., 2021 ) adapted
to the categorical likelihood and the Dirichlet prior.
/four.tnum./four.tnum./four.tnum. Action selection
In active inference, decision strategies (behavioral policies)
are chosen based on a single optimization principle: minimizing
expected surprisal about observed and future outcomes, that is,
the expected free energy (
Schwartenbeck et al., 2019 ; Smith et al.,
2022). Here, we will express the expected free energy of a choice
a on trial t as
Ga = DKL
(˜pt(ot|a)||P(ot)
)
  
Risk
+ E˜pt
(
s1
t
)
˜pt (ρρρ)
[
H
[
ot|ρρρ, s1
t , s2
t = a
] ]

 
Ambiguity
≈ − E˜pt (ot |a)
[
ln P(ot)
]
  
Extrinsic value
− E˜pt (ot |a)
[
DKL
(
qt
(
s1
t , s2
t , ft|ot, a
)
||˜pt
(
s1
t , s2
t , ft|a
) ) ]

 
Epistemic value
− E˜pt (ot |a)
[
DKL
(
qt
(
ρρρ|ot, a
)
||˜pt
(
ρρρ
) )
+ DKL
(
qt
(
m|ot, a
)
||˜pt (m)
) ]
  
Novelty
(18)
where P(ot) denotes prior preferences over outcomes,
H
[
ot|ρρρ, s1
t , s2
t
]
the entropy of outcome likelihood
p
(
ot|ρρρ, s1
t , s2
t
)
, and DKL(p||q), stands for the Kullback-
Leibler divergence between two probability densities : p and q.
Note that action selection based on minimization of expected
free energy would have an implicit dual imperative (see the
diﬀerent factorizations in Equation 18): On one hand, the
expected free energy combines ambiguity and risk. On the other
hand, it consists of information gain (epistemic value + novelty)
and extrinsic value. Therefore, selecting actions that minimize
the expected free energy dissolves the exploration-exploitation
trade-oﬀ, as every action contains both expected value and
information gain. This is a critical feature of action selection
which allows us to account for epistemic choices as used in our
experimental paradigm (see
Figure 1).
At any trial t choice at is sampled from choice beliefs p(at)
(cf. planning as inference Attias, 2003; Botvinick and Toussaint,
2012) deﬁned as
at ∼ p
(
at|γ,PPPo, νmax
)
∝ e−γGa[PPPo,νmax,t], (19)
where parameter γ corresponds to choice precision, which
we will attribute to empirical choice behavior of participants.
Therefore, for describing participants’ behavior we assume that
the action selection process is corrupted by external sources of
noise; e.g., mental processes irrelevant for the task at hand. In
our simulations we will ﬁx γ to a reasonably large value, to
achieve approximate free energy minimization as the following
relation will be satisﬁed
at ≈ argminaGa, when γ ≫ 1. (20)
Notably, here we consider the simplest form of active
inference in which expected free energy is computed from a
one-step-ahead prediction. This is a standard simpliﬁcation for
environments in which actions cannot interfere with the state
transitions, as is the case in typical dynamic multi-armed bandit
problems (
Markovic et al., 2021 ).
To express the expected free energy, G(at), in terms of beliefs
about arm-speciﬁc reward probabilities, we will ﬁrst constrain
Frontiers in Behavioral Neuroscience /one.tnum/eight.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
the prior preference to the following categorical distribution
P(ot) =
∏
ot
[Po]δo,ot , Po =
(
p−, p+, 1
2 pc, 1
2 pc
)
(21)
In active inference, prior preferences determine whether a
particular outcome is attractive, that is, rewarding. Here we
assume that all agents prefer gains ( ot = 2) over losses
(ot = 1). Hence, we constrain parameter values such that
p+ > p− holds always. The ratio p+
pc = λ determines the
balance between epistemic and pragmatic imperatives. When
prior preferences for gains are very precise, corresponding to
large λ, the agent becomes risk sensitive and will tend to forgo
exploration if the risk is high (see Equation
18). Conversely, a
low lambda corresponds to an agent which is less sensitive to
risk and will engage in exploratory, epistemic behavior, until it
has familiarized itself with the environment.
Given the following expressions for the marginal predictive
likelihood,
˜pt
(
ot|a
)
=
∑
s1
t ,s2
t
∫
p
(
ot|ρρρ, s1
t , s2
t
)
˜pt
(
s1
t
)
p
(
s2
t |a
)
˜pt
(
ρρρ
)
dρρρ
˜pt
(
ot|a
)
=
2∑
s=1
˜pt
(
s1
t = s
) 4∏
o=1
[
µ t−1
s,a,o
] δot,o
µ t−1
s1,s2,o =
αt−1
s1,s2,o
∑
i αt−1
s1,s2,i
, ¯µ t−1
s2,o =
∑
s1
˜pt
(
s1
t = s1
)
µ t−1
s1,s2,o
(22)
we get the following expressions for the expected free energy
Gt(a) =
∑
o
¯µ t−1
a,o ln ¯µ t−1a,o
Po
−
∑
s1
˜p
(
s1
t = s1
)
∑
o
µ t−1
s1,a,o



ψ
(
αt−1
s1,a,o + 1
)
− ψ


1 +
∑
j
αt−1
s1,a,j







(23)
Above we have used the following relation
∫
dxxxDir
(
xxx|ααα
)
xi ln xi =
αi
∑
j αj



ψ
(
αi + 1
)
− ψ


1 +
∑
j
αj






, (24)
for computing ambiguity term in Equation (18).
/four.tnum./five.tnum. Model inversion
To estimate subject-speciﬁc priors we eﬀectively identiﬁed
prior beliefs (i.e., νmax, γ, and PPPo) that rendered the observed
choices the most likely under active inference (i.e., under ideal
Bayesian assumptions and the complete class theorem). In
other words, for any given
(
νmax, γ,PPPo
)
, we can simulate belief
updating — given subject speciﬁc outcomes to evaluate the
expected free energy. The expected free energy then speciﬁes the
probability of choices at each trial. These probabilities can be
used to assess the likelihood of any observed choice sequence
of nth subject, conditioned upon a particular set of priors
[p
(
νmax, γ,PPPo
)
]. One can then explore the space of priors (i.e.,
model parameters) to evaluate the marginal likelihood or model
evidence for diﬀerent combinations of priors.
In more detail, given a sequence of subjects’ responses AAAn =(
an
1, ... , an
T
)
, where n denotes subject index and T = 1, 000
denotes the total number of trials, the response likelihood is
deﬁned as
P
(
AAAn|γ,PPPo, νmax
)
=
T∏
t=400
p
(
at = an
t |γn,PPPn
o , νn
max
)
. (25)
Note that for estimating the posterior over model parameters
(γ,PPPo, νmax) we ignore the ﬁrst 400 responses from the
likelihood. We expect that during these ﬁrst trials, subjects are
still getting used to the task, and potentially use additional
strategies for representing the task and making choices. As we do
not model all possible task representations, exclusion of initial
trails reduces the noise in model comparison. Importantly,
we do use the entire set of responses for computing belief
trajectories of the active inference agents, that is, we expose the
agent to the complete sequence of individual responses and the
corresponding outcomes.
We deﬁne the prior over model parameters
(
νnmax, γn,PPPn
o
)
for the nth subject as follows:
p
(
γn,PPPn
o , νn
max
)
= p
(
γn)
p (PPPo)p(νn
max), (26)
where for a prior over choice precision parameter γ we use an
inverse gamma distribution, thus
p
(
γn)
∼ Ŵ−1 (2, 2), (27)
and for the prior over prior preferences PPPo we use a Dirichlet
distribution, such that
pn
i ∼ Dir
(
ppp|βββ
)
, βi = 1, i ∈ {1, 2, 3} ,
PPPn
o =
(
pn
1
2 , pn
1
2 + pn
2, pn
3
2 , pn
3
2
)
.
(28)
With the above parameterization of prior preferences PPPo we
constrain the prior to reﬂect our expectations that all subjects
will have higher preferences for gains than for losses, and that
they will have equivalent preference associated with informative
cues, that is, epistemic choices. Finally, we deﬁne a prior over the
temporal precision parameter νmax as a categorical distribution
νn
max ∼ Cat
(
rrrn)
(29)
Frontiers in Behavioral Neuroscience /one.tnum/nine.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
where rrrn = (rn
1 , ... , rn
10) denotes prior probability over possible
νmax values. Here we adopt the approach known as random
eﬀect Bayesian model selection ( Stephan et al., 2009 ; Rigoux
et al., 2014 ) which treats models (i.e., diﬀerent νmax values) as
random eﬀects that could diﬀer between subjects and conditions,
with an unknown population distribution. Hence, we introduce
a condition speciﬁc hyper-priors over model probabilities in the
form of a Dirichlet distribution
τ ∼ C+(0, 1)
rrr1 ∼ Dir
(
rrr1|ααα0/τ
)
rrr2 ∼ Dir
(
rrr2|ααα0/τ
)
(30)
where rrr1 corresponds to the condition with regular reversals and
rrr2 to the condition with the irregular reversals. Finally, τ plays
a role of a shrinkage parameter, that sets a non-zero probability
to a conﬁguration where all models have equal frequency in the
population (in the limit τ → 0 we get rrr1 = rrr2 = 1
10 ). The
subject speciﬁc prior probability rrrn corresponds to one of the
two priors, based on the condition the subject was exposed to;
hence, rrrn ∈ {rrr1, rrr2}.
To implement the above hierarchical generative model
of subjects responses we used the probabilistic programming
library Numpyro (
Phan et al., 2019 ). Numpyro library provides
an interface to multiple state-of-the-art inference schemes. For
drawing samples from the posterior we have used Numpyro’s
implementation of the No-U-Turn sampler (NUTS) (
Hoﬀman
et al., 2014 ). NUTS is an self-tuning version of the Hamiltonian
Monte Carlo, a popular Markov Chain Monte Carlo algorithm
for avoiding random walks and sensitivity to between-parameter
correlations. The limitation of NUTS is that it can only
draw samples from continues random variables. Therefore, for
implementation purposes we have to marginalize the generative
model with respect to νmax.
The marginalization results in the following marginal
generative model:
τ ∼ C+(0, 1)
rrr1 ∼ Dir
(
rrr1|ααα0/τ
)
, α0,ν = 1, ν∈ {1, ... , 10} ,
rrr2 ∼ Dir
(
rrr2|ααα0/τ
)
, α0,ν = 1, ν∈ {1, ... , 10} ,
rrrn = f (rrr1,rrr2, n)
PPPn
o ∼ p
(
PPPn
o |βββ
)
, βi = 1, i ∈ {1, 2, 3} ,
γn ∼ Ŵ−1 (2, 2),
AAAn ∼
∑
ν
rn
ν
1000∏
t=400
p
(
at|γn,PPPn
o , νmax = ν
)
.
(31)
With the mixture model above we can unify the parameter
estimation with the model comparison (selection). Given a
sample from the posterior
rrrs
1,rrrs
2,PPPn,s
o , γn,s ∼ p
(
rrr1,rrr2,PPP1 : N
o , γ1 : N |AAA1 : N
)
(32)
we can obtain a sample from the marginal posterior
probability over νmax for the nth subject as
ps
(
νn
max = ν|AAA1 : N
)
=
p
(
AAAn|γn,s,PPPn,so , νnmax = ν
)
rn,sν
∑
i p
(
AAAn|γn,s,PPPn,so , νnmax = i
)
rn,s
i
.
(33)
To classify subjects’ behavior in terms of adaptability of
temporal representations we use the exceedance probability
(
Rigoux et al., 2014 ) of the marginal posterior deﬁned as
in,s = argmaxνps
(
νn
max = ν|AAA1 : N
)
,
Xn
i = 1
S
S∑
s=1
δi,in,s ,
(34)
thus, obtaining the probability that the ith model has the highest
marginal posterior probability for the nth subject. The value
Xn
i is plotted in Figure 8. Finally, the most likely precision
parameter νnmax of the nth subject corresponds to νnmax =
argmaxiXn
i which we than used for classiﬁcation as illustrated
in Figures 9, 10.
Data availability statement
The datasets presented in this study can be found in
online repositories. The names of the repository/repositories
and accession number(s) can be found at:
https://osf.io/h526v/.
Ethics statement
The studies involving human participants were reviewed and
approved by the Ethical Board of Technical University Dresden.
The patients/participants provided their written informed
consent to participate in this study.
Author contributions
DM, AR, and SK contributed to conception and design of
the study and wrote the sections of the manuscript. DM and
AR collected the data. DM developed the model, performed the
data analysis, and wrote the ﬁrst draft of the manuscript. All
authors contributed to manuscript revision, read, and approved
the submitted version.
Funding
The study was supported by the German Research
Foundation (DFG, Deutsche Forschungsgemeinschaft), SFB
940/3—Project A09 awarded to SK and SFB 940/3—Project B7
awarded to AR. SK acknowledges further support by DFG TRR
265/1 (Project ID 402170461, B09) and Germany’s Excellence
Frontiers in Behavioral Neuroscience /two.tnum/zero.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
Strategy—EXC 2050/1 (Project ID 390696704)—Cluster of
Excellence Centre for Tactile Internet with Human-in-the-Loop
(CeTI) of Technische Universität Dresden. AR acknowledges
further support by the German Research Foundation (DFG RE
4449/1-1, RTG 2660-B2) and by a 2020 BBRF NAR-SAD Young
Investigator Grant from the Brain and Behavior Research
Foundation. This study was partially funded by funding
opportunities for young scientists (Anschubﬁnanzierung)
from the Department of Psychology of the Technische
Universität Dresden.
Conﬂict of interest
The authors declare that the research was conducted in the
absence of any commercial or ﬁnancial relationships that could
be construed as a potential conﬂict of interest.
Publisher’s note
All claims expressed in this article are solely those
of the authors and do not necessarily represent those
of their aﬃliated organizations, or those of the publisher,
the editors and the reviewers. Any product that may be
evaluated in this article, or claim that may be made by
its manufacturer, is not guaranteed or endorsed by the
publisher.
Supplementary material
The Supplementary Material for this article can be found
online at: https://www.frontiersin.org/articles/10.3389/fnbeh.
2022.962494/full#supplementary-material
References
Attias, H. (2003). “Planning by probabilistic inference, ” in Proceedings of the
Ninth International Workshop on Artiﬁcial Intelligence and Stat istics, eds C. M.
Bishop and J. B. Frey (PMLR), 9–16. Available online at: http://proceedings.mlr.
press/r4/attias03a/attias03a.pdf
Baldassano, C., Chen, J., Zadbood, A., Pillow, J. W., Hasson, U. , and
Norman, K. A. (2017). Discovering event structure in contin uous narrative
perception and memory. Neuron 95, 709–721. doi: 10.1016/j.neuron.2017.
06.041
Bermudez, M. A., and Schultz, W. (2014). Timing in reward and d ecision
processes. Philos. Trans. R. Soc. B Biol. Sci . 369:20120468. doi: 10.1098/rstb.2012.
0468
Blei, D. M., Kucukelbir, A., and McAuliﬀe, J. D. (2017). Variati onal
inference: a review for statisticians. J. Am. Stat. Assoc . 112, 859–877.
doi: 10.1080/01621459.2017.1285773
Borst, J. P., and Anderson, J. R. (2015). The discovery of proc essing stages:
analyzing EEG data with hidden semi-Markov models. NeuroImage 108, 60–73.
doi: 10.1016/j.neuroimage.2014.12.029
Botvinick, M., and Toussaint, M. (2012). Planning as inferen ce. Trends Cogn.
Sci. 16, 485–488. doi: 10.1016/j.tics.2012.08.006
Bradtke, S., and Duﬀ, M. (1994). “Reinforcement learning met hods
for continuous-time Markov decision problems, ” in Advances in Neural
Information Processing Systems , eds G. Tesauro, D. Touretzky, and T. Leen
(MIT Press). Available online at: https://proceedings.neurips.cc/paper/1994/ﬁle/
07871915a8107172b3b5dc15a6574ad3-Paper.pdf
Brown, L. D. (1981). A complete class theorem for statistical pro blems with ﬁnite
sample spaces. Ann. Stat. 9, 1289–1300. doi: 10.1214/aos/1176345645
Buhusi, C. V., and Meck, W. H. (2005). What makes us tick? Func tional
and neural mechanisms of interval timing. Nat. Rev. Neurosci . 6, 755–765.
doi: 10.1038/nrn1764
Buzsáki, G., and Llinás, R. (2017). Space and time in the brain. Science 358,
482–485. doi: 10.1126/science.aan8869
Costa, V. D., Tran, V. L., Turchi, J., and Averbeck, B. B. (201 5). Reversal
learning and dopamine: a Bayesian perspective. J. Neurosci . 35, 2407–2416.
doi: 10.1523/JNEUROSCI.1989-14.2015
Crockett, M. J., and Fehr, E. (2014). “Pharmacology of econom ic
and social decision making, ” in Neuroeconomics, 2 nd Edn, eds P. W.
Glimcher and E. Fehr (San Diego, CA: Academic Press), 259–279.
doi: 10.1016/B978-0-12-416008-8.00014-0
Daw, N., Courville, A. C., and Touretzky, D. (2002). “Timing an d partial
observability in the dopamine system, ” in Advances in Neural Information
Processing Systems , eds S. Becker, S. Thrun, and K. Obermayer (MIT
Press). Available online at:
https://proceedings.neurips.cc/paper/2002/ﬁle/
13111c20aee51aeb480ecbd988cd8cc9-Paper.pdf
Duong, T. V., Bui, H. H., Phung, D. Q., and Venkatesh, S. (2005 ). “Activity
recognition and abnormality detection with the switching hi dden semi-Markov
model, ” in2005 IEEE Computer Society Conference on Computer Vision and Pattern
Recognition (CVPR’05), Vol. 1, 838–845. IEEE. doi: 10.1109/CVPR.2005.61
Eagleman, D. M. (2008). Human time perception and its illusions. Curr. Opin.
Neurobiol. 18, 131–136. doi: 10.1016/j.conb.2008.06.002
Eichenbaum, H. (2014). Time cells in the hippocampus: a new dimens ion for
mapping memories. Nat. Rev. Neurosci . 15, 732–744. doi: 10.1038/nrn3827
Eichenbaum, H. (2017). On the integration of space, time, and memory. Neuron
95, 1007–1018. doi: 10.1016/j.neuron.2017.06.036
Fountas, Z., Sylaidi, A., Nikiforou, K., Seth, A. K., Shanaha n, M., and Roseboom,
W. (2022). A predictive processing model of episodic memory and time perception.
Neural Comput. 34, 1501–1544. doi: 10.1162/neco_a_01514
Friston, K., and Buzsáki, G. (2016). The functional anatomy o f time: what and
when in the brain. Trends Cogn. Sci . 20, 500–511. doi: 10.1016/j.tics.2016.05.001
Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., Pe zzulo, G., et al.
(2016). Active inference and learning. Neurosci. Biobehav. Rev . 68, 862–879.
doi: 10.1016/j.neubiorev.2016.06.022
Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., an d Pezzulo,
G. (2017). Active inference: a process theory. Neural Comput . 29, 1–49.
doi: 10.1162/NECO_a_00912
Friston, K., Rigoli, F., Ognibene, D., Mathys, C., Fitzgerald , T., and Pezzulo,
G. (2015). Active inference and epistemic value. Cogn. Neurosci . 6, 187–214.
doi: 10.1080/17588928.2015.1020053
Frölich, S., Markovi ´c, D., and Kiebel, S. J. (2021). Neuronal sequence models for
Bayesian online inference. Front. Artif. Intell . 4:50. doi: 10.3389/frai.2021.530937
Fu, Z., Beam, D., Chung, J. M., Reed, C. M., Mamelak, A. N., Adolph s, R., et al.
(2021). The geometry of domain-general performance monitor ing in the human
medial frontal cortex. Science 376:6953. doi: 10.1126/science.abm9922
Gales, M., and Young, S. (2008). The application of hidden markov
models in speech recognition. Foundation. Trend. Sign. Process. 1, 195–304.
doi: 10.1561/2000000004
Griﬃths, T. L., and Tenenbaum, J. B. (2011). Predicting the fu ture as Bayesian
inference: people combine prior knowledge with observations whe n estimating
duration and extent. J. Exp. Psychol . 140:725. doi: 10.1037/a0024899
Gupta, N., Granmo, O.-C., and Agrawala, A. (2011). “Thompson
sampling for dynamic multi-armed bandits, ” in 2011 10th International
Conference on Machine Learning and Applications and Workshops. p. 484–489.
doi: 10.1109/ICMLA.2011.144
Hoﬀman, M. D., and Gelman, A. (2014). The No-U-Turn sampler: adapt ively
setting path lengths in hamiltonian Monte Carlo. J. Mach. Learn. Res . 15,
1593–1623. doi: 10.48550/arXiv.1111.4246
Frontiers in Behavioral Neuroscience /two.tnum/one.tnum frontiersin.org
Markovi´c et al. /one.tnum/zero.tnum./three.tnum/three.tnum/eight.tnum/nine.tnum/fnbeh./two.tnum/zero.tnum/two.tnum/two.tnum./nine.tnum/six.tnum/two.tnum/four.tnum/nine.tnum/four.tnum
Hongler, M., and Salama, Y. (1996). Semi-Markov processes with phase-type
waiting times. Zeitsch. Angew. Math. Mech . 76, 461–462.
Itskov, V., Curto, C., Pastalkova, E., and Buzsáki, G. (2011). Cell assembly
sequences arising from spike threshold adaptation keep track of time in the
hippocampus. J. Neurosci. 31, 2828–2834. doi: 10.1523/JNEUROSCI.3773-10.2011
Janssen, J., and Limnios, N. (1999). Semi-Markov Models and Applications . New
York, NY: Springer. p. 404. doi: 10.1007/978-1-4613-3288-6
Jazayeri, M., and Shadlen, M. N. (2010). Temporal context calib rates interval
timing. Nat. Neurosci. 13, 1020–1026. doi: 10.1038/nn.2590
Kaplan, R., and Friston, K. J. (2018). Planning and navigation a s active inference.
Biol. Cybern. 112, 323–343. doi: 10.1007/s00422-018-0753-2
Kiebel, S. J., Daunizeau, J., and Friston, K. J. (2008). A hier archy of time-scales
and the brain. PLoS Comput. Biol . 4:e1000209. doi: 10.1371/journal.pcbi.1000209
Liakoni, V., Modirshanechi, A., Gerstner, W., and Brea, J. (2 021). Learning in
volatile environments with the bayes factor surprise. Neural Comput. 33, 269–340.
doi: 10.1162/neco_a_01352
MacDonald, C. J., Fortin, N. J., Sakata, S., and Meck, W. H. (20 14).
Retrospective and prospective views on the role of the hippocampus i n
interval timing and memory for elapsed time. Timing Time Percept . 2, 51–61.
doi: 10.1163/22134468-00002020
Maheu, M., Meyniel, F., and Dehaene, S. (2022). Rational arbi tration between
statistics and rules in human sequence processing. Nat. Hum. Behav. 6, 1087–1103.
doi: 10.1038/s41562-021-01259-6
Markovi´c, D., Reiter, A. M., and Kiebel, S. J. (2019). Predicting
change: approximate inference under explicit representation of temporal
structure in changing environments. PLoS Comput. Biol . 15:e1006707.
doi: 10.1371/journal.pcbi.1006707
Markovic, D., Stojic, H., Schwoebel, S., and Kiebel, S. J. (202 1). An
empirical evaluation of active inference in multi-armed bandi ts. arXiv preprint
arXiv:2101.08699. doi: 10.1016/j.neunet.2021.08.018
McGuire, J. T., and Kable, J. W. (2012). Decision makers calibra te behavioral
persistence on the basis of time-interval experience. Cognition 124, 216–226.
doi: 10.1016/j.cognition.2012.03.008
McGuire, J. T., and Kable, J. W. (2015). Medial prefrontal corti cal activity reﬂects
dynamic re-evaluation during voluntary persistence. Nat. Neurosci . 18, 760–766.
doi: 10.1038/nn.3994
Meck, W. H. (1996). Neuropharmacology of timing and time percept ion. Cogn.
Brain Res. 3, 227–242. doi: 10.1016/0926-6410(96)00009-2
Mikhael, J. G., and Gershman, S. J. (2019). Adapting the ﬂow of time with
dopamine. J. Neurophysiol. 121, 1748–1760. doi: 10.1152/jn.00817.2018
Murphy, K. P. (2002). Hidden semi-Markov models (HSMMs), vol. 2 . Citeseer.
Available online at: https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.
123.2942&rep=rep1&type=pdf
Niv, Y., and Chan, S. (2011). On the value of information and ot her rewards.
Nat. Neurosci. 14, 1095–1097. doi: 10.1038/nn.2918
Nobre, A. C., and Van Ede, F. (2018). Anticipated moments: tem poral structure
in attention. Nat. Rev. Neurosci . 19:34. doi: 10.1038/nrn.2017.141
Parr, T., Markovic, D., Kiebel, S. J., and Friston, K. J. (2019 ). Neuronal message
passing using mean-ﬁeld, Bethe, and marginal approximations. Sci. Rep . 9, 1–18.
doi: 10.1038/s41598-018-38246-3
Pezzulo, G., Rigoli, F., and Friston, K. J. (2018). Hierarchica l active inference: a
theory of motivated control. Trends Cogn. Sci . 22, 294–306. doi: 10.1016/j.tics.2018.
01.009
Phan, D., Pradhan, N., and Jankowiak, M. (2019). Composable eﬀ ects for
ﬂexible and accelerated probabilistic programming in Numpyro. arXiv preprint
arXiv:1912.11554. doi: 10.48550/arXiv.1912.11554
Purcell, B. A., and Kiani, R. (2016). Hierarchical decision pro cesses that
operate over distinct timescales underlie choice and changes i n strategy.
Proc. Natl. Acad. Sci. U.S.A . 113, E4531–E4540. doi: 10.1073/pnas.152468
5113
Ray, D., and Bossaerts, P. (2011). Positive temporal dependen ce of
the biological clock implies hyperbolic discounting. Front. Neurosci . 5:2.
doi: 10.3389/fnins.2011.00002
Read, D., and Read, N. L. (2004). Time discounting over the lif espan. Organ.
Behav. Hum. Decis. Process . 94, 22–32. doi: 10.1016/j.obhdp.2004.01.002
Reiter, A. M., Deserno, L., Kallert, T., Heinze, H.-J., Heinz, A., and Schlagenhauf,
F. (2016). Behavioral and neural signatures of reduced updat ing of alternative
options in alcohol-dependent patients during ﬂexible decision-ma king. J. Neurosci.
36, 10935–10948. doi: 10.1523/JNEUROSCI.4322-15.2016
Reiter, A. M., Heinze, H.-J., Schlagenhauf, F., and Deserno, L. (2017). Impaired
ﬂexible reward-based decision-making in binge eating disord er: evidence from
computational modeling and functional neuroimaging. Neuropsychopharmacology
42, 628–637. doi: 10.1038/npp.2016.95
Retz Lucci, C. (2013). Time, self, and intertemporal choice. Front. Neurosci. 7:40.
doi: 10.3389/fnins.2013.00040
Rigoux, L., Stephan, K. E., Friston, K. J., and Daunizeau, J. ( 2014).
Bayesian model selection for group studies-revisited. Neuroimage 84, 971–985.
doi: 10.1016/j.neuroimage.2013.08.065
Schwartenbeck, P., FitzGerald, T., Dolan, R., and Friston, K. ( 2013).
Exploration, novelty, surprise, and free energy minimization. Front. Psychol. 4:710.
doi: 10.3389/fpsyg.2013.00710
Schwartenbeck, P., FitzGerald, T. H., Mathys, C., Dolan, R., an d Friston, K.
(2015). The dopaminergic midbrain encodes the expected certa inty about desired
outcomes. Cereb. Cortex 25, 3434–3445. doi: 10.1093/cercor/bhu159
Schwartenbeck, P., Passecker, J., Hauser, T. U., FitzGerald, T. H., Kronbichler,
M., and Friston, K. J. (2019). Computational mechanisms of cu riosity and goal-
directed exploration. Elife 8:e41703. doi: 10.7554/eLife.41703
Shappell, H., Caﬀo, B. S., Pekar, J. J., and Lindquist, M. A. (2019) . Improved state
change estimation in dynamic functional connectivity usin g hidden semi-Markov
models. NeuroImage 191, 243–257. doi: 10.1016/j.neuroimage.2019.02.013
Shi, Z., Church, R. M., and Meck, W. H. (2013). Bayesian optimi zation of time
perception. Trends Cogn. Sci . 17, 556–564. doi: 10.1016/j.tics.2013.09.009
Smith, R., Friston, K. J., and Whyte, C. J. (2022). A step-by-s tep tutorial on
active inference and its application to empirical data. J. Math. Psychol. 107:102632.
doi: 10.1016/j.jmp.2021.102632
Stephan, K. E., Penny, W. D., Daunizeau, J., Moran, R. J., and F riston, K. J.
(2009). Bayesian model selection for group studies. Neuroimage 46, 1004–1017.
doi: 10.1016/j.neuroimage.2009.03.025
Story, G. W., Moutoussis, M., and Dolan, R. J. (2016). A computat ional analysis
of aberrant delay discounting in psychiatric disorders. Front. Psychol . 6:1948.
doi: 10.3389/fpsyg.2015.01948
Varmazyar, M., Akhavan-Tabatabaei, R., Salmasi, N., and Mod arres, M. (2019).
Classiﬁcation and properties of acyclic discrete phase-type dist ributions based on
geometric and shifted geometric distributions. J. Indus. Eng. Int . 15, 651–665.
doi: 10.1007/s40092-018-0299-x
Vaseghi, S. (1995). State duration modelling in hidden Markov models. Signal
Process. 41, 31–41. doi: 10.1016/0165-1684(94)00088-H
Vilà-Balló, A., Mas-Herrero, E., Ripollés, P., Simó, M., Miró, J., Cucurell, D., et al.
(2017). Unraveling the role of the hippocampus in reversal learnin g. J. Neurosci. 37,
6686–6697. doi: 10.1523/JNEUROSCI.3212-16.2017
Wald, A. (1947). An essentially complete class of admissible decisi on functions.
Ann. Math. Stat. 18, 549–555. doi: 10.1214/aoms/1177730345
Yu, S.-Z. (2010). Hidden Semi-Markov models. Artif. Intell . 174, 215–243.
doi: 10.1016/j.artint.2009.11.011
Yu, S.-Z. (2015). Hidden Semi-Markov Models: Theory, Algorithms
and Applications , 1 st Edn. Elsevier Science Publishers B. V.
doi: 10.1016/B978-0-12-802767-7.00002-4
Yu, S.-Z., and Kobayashi, H. (2003). An eﬃcient forward-bac kward algorithm
for an explicit-duration hidden Markov model. IEEE Signal Process. Lett . 10, 11–14.
doi: 10.1109/LSP.2002.806705
Frontiers in Behavioral Neuroscience /two.tnum/two.tnum frontiersin.org