ࢽV ol. 25, No. 3ʢ2018ʣɼ71–85
ղઆ
ͷਪ࿦
࠸
νʔϜ∗
Introduction of the Free-Energy Principle: Perception, Action, and Inference of Another’s
Mind
Takuya Isomura
Laboratory for Neural Computation and Adaptation, RIKEN Center for Brain Science∗
ཁ
͸ Fristonཧʢfree-energy principleʣΛΘ͔Γ΍͘͢ղઆ͢Δ͜ͱ
༝
؆
ೖྗͷ༧ଌ
దԽ͠ଓ͚͍ͯΔʯͱఆΊ͍ͯΔɽ͜
Խʢ
predictive codingܗݱ
ߋ
ཧ͔Βಋग़ՄೳͰ͋
͖
Δʯͱઆ໌Ͱ͖Δɽ͜Ε͸ೳಈతਪ࿦ʢactive inferenceʹɼ֎քͷਪ
࿦͢Δɽ
1. ͸͡Ίʹ
࠷
ͷΑ
ཧ͔Β਺ཧతʹઆ໌Ͱ͖ͳ
ཧ
ʢfree-energy principleʣ1, 2)ཧ
େԽ͢Δ͜
ͱͰ͋ΔʯͱఆΊ͍ͯΔɽ৘ใཧ࿦Ͱ͸༧ଌͷ೉͠͞
ೖྗͷα
͑ΒΕΔɽ
తʹ͸ɼ19ऀvon Helmholtz
తਪ࿦ʢunconscious inferenceʣ3)༝
ʹͳΔɽHelmholtz֮ײ
͍ɼෆ଍ͨ͠৘
ͷຊ
ͩͱͨ͠†1తʹ
ҼΛਪ࿦
∗˟ 351–0198୔ 2–1
https://sites.google.com/site/takuyaisomura/
͢Δ૷ஔͰ͋Δͱ͍͏ओுͰ͋Δɽ
ೖྗΛੜ੒͢
γεςϜʢੜ੒աఔʀgenerative processʣ
ஙɼͭ·Γίϐʔ
͍ͬͯΔͱ͍͏ɼ಺෦Ϟσ
ϧԾઆ
4ʙ6)͘͸ Dayan ͱ Hinton
Β͕ Helmholtz machineػ
దԽʹΑΓਪ
͍ͯ͠Δ4)ɽ͜ͷΑ͏ʹɼ೴ͷ
शϞσϧʹΑΓઆ
͑ΒΕ͍ͯΔɽ
ཧ͸ɼFristonೳΛ
౷Ұత͔ͭ਺ཧతʹઆ໌͢Δ๏ଇͱͯ͠ఏএ͞Εͨ1, 2)ɽ
తਪ࿦Λ৘ใཧ࿦ɾϕΠζਪ࿦ͷ࿮૊Έ
ཧ͸೴ͱ৘ใཧ࿦ʹ
༝Τω
೉͞Λҙຯ͢Δαϓ
†1ͱ͸ɼྫ͑͹ԕ͘ʹ͋ΔϦϯΰͷ
ʹӅΕ͍ͯΔͱ͖ʹɼϦϯΰͷ
ӅΕ͍ͯΔ෦෼ΛΠϝʔδʢਪ࿦ʣͰ͖Δ͜ͱͰ͋Δɽ
72ࢽV ol. 25, No. 3ʢ2018ʣ
༝ΤωϧΪʔʢvariational free
energyཧͰ͸ɼα
ࣦ
ଇͰ͋Δ
๔ɾγφ
ೖྗͷαϓϥΠζΛ
ͬ
ੑ
ʢuncertaintyʀ≈ఆ
খԽ͢Δ͜ͱͰ೴
͑ΒΕ͍ͯΔɽ
ີʹड़΂Α
քͰ
ೖྗͷαϓϥΠζΛখ͘͞
Ͱͳ͚Ε͹ͳΒͳ͍ʯ͜ͱΛཁ੥͢Δɽ͜ͷ
͑ɼ਺
ೖ
ྗͷϕΫτϧΛ
s ≡s(t) ͱ͢ΔɽαϓϥΠζ͸௨ৗɼೖ
ྗͷෛͷର਺໬౓ʢnegative log likelihoodʣ
Surprise S (˜s) ≡−log p(˜s|m)( 1 )
Ͱ༩͑ΒΕΔɽͨͩ͠ ˜s ≡(s,s′,s′′,... ) ͸ s࣌
ඪʢgen-
eralized coordinate of motion͹ΕΔɽʢs′͸଎౓ɼ
s′′͸Ճ଎౓ɼetc.ʣ͜ͷp(˜s|m)཰෼
෍ p(˜s)ϞσϧͰ͋ΓɼmೖྗΛ
଄Ͱ͋Δ†2ɽ
͜ͷϞσϧ͸ӅΕม਺ʢlatent variablesষͰಋೖ͢
ೖྗΛੜ੒͢ΔաఔΛϞσϧԽ͢ΔͷͰ
ੜ੒Ϟσϧʢgenerative model͹ΕΔɽ
ײ
͜Γʹ͍͘ʢ௝
ۭ
ͷͳ
଴஋͕ͱͯ΋খ͍͞ͷͰʣେ͖ͳ S
ͷ஋Λ༩͑Δɽ͔͠͠Կ౓΋ಉ͡ೖྗΛड͚ͯͦΕ͕
श͢Δͱɼಉ͡ೖྗͰ͋ͬͯ΋
S ͷ஋͸খ͘͞ͳΔɽ೴͕௚઀ड͚औΔ͜ͱͷͰ͖Δ
਺͸֎քͷӅΕม
Ή͜ͱ͸Ͱ͖ͳ͍ͨΊʢৄ
͸Markov blanket7, 8)রʣɼ֎քΛਪ࿦͠༧ଌ͢Δ
΋ଥ౰ͳ
†2͸ྫ͑͹ ˜s ͕Ψ΢ε෼෍ʹै͏ͱͯ͠
ೖྗ͸௨ৗɼӅΕม਺͔Βඇ
ࣅۙ
͕๬·͍͠ɽ
਺ͷҰͭͰ͋Δɽ
ݪ
దԽ໰୊
֮
शͷϞσϧ9)श10, 11)श11ʙ13)ɼ
ίϛϡχέʔγϣϯ14, 15)ױ࣬16, 17)૊৫Խ18)ɼ
৅ΛϞσϧԽՄೳͰ͋Δɽͦͷͨ
ཧͱ͢Δ͜ͱ
ຊͱͳΔ໰୊
ʑ
ɼ·ͣ
2 ষͰର৅ͱ͢Δ
͢Δɽଓ͍ͯɼ3 ষ
शʹ͍ͭͯɼ4࠷
దԽʹ͍ͭͯɼ5 ষͰίϛϡχέʔγϣϯͱଞऀਪ࿦
ʹ 6 ষͰ·ͱΊΛड़΂Δɽ
2.ٛ
༝ΤωϧΪʔͷಋ
ೖʹ͍ͭͯड़΂Δɽ
2.1 ໰୊ઃఆɿ֎քͷੜ੒աఔ
ཧ
͞ΕΔɽΠΣϯ
ʢJensen’s inequalityʣΑΓɼαϓϥΠζSظ
ͷʢਅͷʣೖྗͷγϟϊϯΤϯτϩϐʔʢShan-
non entropyʣEp(˜s)[−log p(˜s)] ≡−
∫
d˜sp(˜s)l o gp(˜s) ΑΓ
͸෼෍͕Ұக͢Δͱ͖
ͷ໨త͸ Ep(˜s)[−log p(˜s|m) +
log p(˜s)]͸ 3রʀ
ݙ19)র͞Ε͍ͨʣɽ͜͜ͰEp(˜s)[•] ͸ p(˜s) ʹ͍ͭ
ʣͰ͋ΔɽҰํͰɼӡ
ͷೖྗͷγϟϊϯΤϯ
ͷೖྗ
͖
ʹେผ͞ΕΔ͕ɼ྆ऀΛ·ͱΊͯӡಈͷ໨త΋
͸
4 ষ
রʣɽ
ʹ͸ೖ
ྗΛੜ੒͍ͯ͠ΔӅΕͨμΠφϛΫεɼੜ੒աఔ͕ଘ
దԽ͸͜ͷੜ੒աఔͷϕΠζ
ਪ࿦ʹΑͬͯҝ͞ΕΔ
9, 20)ɽਤ1͢Α͏ʹɼ֎ք
ͷੜ੒աఔ͕ӅΕม਺ͷϕΫτϧuೖྗ˜sɼύϥ
ϝʔλͷηοτ θʹΑ
͞ΕΔͱ͢Δʢද1রʣɽ·ͨɼੜ෺ʢΤʔ
ಈʢaction͏ʣΛa ͱ
͢ΔɽӅΕม਺u =(˜x,˜v) ͕ӅΕঢ়ଶʢhidden statesʣ˜x
Ҽʢhidden causesʣ˜v ͔Β੒Δͱ͖ɼ˜x ͷμΠφϛ
ཧͷղઆ 73
ਤ1ݙ9)ͷ Fig. 5੒ͨ͠ɽ
਺ fͬͯ
D˜x =f (˜x,˜v,θ,a) +˜z (2)
Ͱ༩͑ΒΕΔɽ͜͜Ͱ˜z ͸γεςϜϊΠζͰ͋Δɽ·
ͨ DྻʣͰ͋Γ
D˜x =(x′,x′′,x′′′,... )͸ x ͷӡಈͷҰൠ
ड़͞ΕΔ͕ɼ˜zͨͳ
͸ ˜x =x ͓Αͼ˜z =z ͱ͢Δ
཰෼෍p(˜v|m) ͔Β
ؔ
਺ gͬͯ
˜s =g(˜x,˜v,θ,a) +˜ω (3)
Ͱ༩͑ΒΕΔɽ͜͜Ͱ˜ωͰ
͑Δ͕ɼҰൠʹ
͑Δ͜ͱ
͸2 ૚໨ʢ্૚ʣͷग़ྗ͕1 ૚໨
ҼʹͳΔ˜v(1) =g(2)(˜x(2),˜v(2),θ(2),a) +˜ω(2) ͱ
͢Δ9)ɽ·ͨϊΠζ˜z,˜ωͷେ͖͞Λௐઅ͢ΔϋΠύʔ
ύϥϝʔλͷਪఆ஋ʹ͍ͭͯ΋ύϥϝʔλθͱಉ༷ʹ
शͰ͖Δ9)Ͱ͸লུ͢Δɽ
·ΔͷͰɼ
཰p(˜s,u,θ|m)
཰෼෍ͱͯ͠(2) ͸
p(˜x|˜v,θ,m) ͱɼ(3) ͸ p(˜s|˜x,˜v,θ,m)ड़Ͱ͖ΔͨΊɼ
཰
Generative model
p(˜s,u,θ|m) =p(˜s|˜x,˜v,θ,m)p(˜x|˜v,θ,m)p(˜v|m)p(θ|m)( 4 )
Ҽ˜v ͔ΒӅΕঢ়ଶ˜x֮ײ
ೖྗ˜s ͕ੜ੒͞ΕΔաఔΛද͍ͯ͠Δɽ͜͜Ͱ p(θ|m)
લ෼෍ʢpriorʣͰ͋Δɽ͜͜Ͱ
ఆ͞ΕΔैଐ
ม਺ a ≡a(˜x,˜v,θ)·ͳ͍ɽ
शϞσϧ21, 22)Λྫʹ
࿦͍ͨ͠ʢਤ2తʹଥ౰ͳ
ੜ੒աఔ͸ΧΦεΞτϥΫλͱͯ͠༩͑ΒΕΔ͜ͱ͕
஌ΒΕ͍ͯΔ
23)ɽ͜ͷྫͰ͸ɼ֎ք͸ௗͷՎͷੜ੒ա
଄ͷ
ʹ͋ΔΧΦ
ֶ
ɼ
Ϳ͜ͱʹ͢Δɽ͜ͷྫͰ͸ɼ
͠ͷঢ়ଶͰ͋Δɽ྆
Ͱ͋ΔҰํɼੜ
ెͷํ͸దԠೳྗ͕͋Δ͜ͱͰ͋Δɽ
ਤ
1ཧͰ͸௨ৗɼ
଴஋ u
ࠩޡξΛͦΕͧΕίʔυ͓ͯ͠Γɼγφϓ
଴஋ θ
͑Δ9)ೖྗͷαϓϥ
ಈΛมԽͤ͞Δ͜ͱΛ
ΛมԽͤ͞Δ͜ͱʢi.e.
Ϳɽ
2.2༝ΤωϧΪʔͷಋೖ
খԽ͢Δํ
๏Λղઆ͢Δɽ಺෦ϞσϧԾઆʹΑΔͱɼΤʔδΣϯ
଄ͷϞσϧʢ͜͜Ͱ͸(4)ʣ
͏͜ͱͰɼະ
श͠ӅΕม਺Λਪ࿦͍ͯ͠Δɽ֎
քͷਅͷӅΕม਺u ͱύϥϝʔλθ͸͋Δ஋Λऔͬͯ
͍Δ͕ɼਪఆ͢Δଆ͔Β͢Δͱͦͷਪఆ஋͸Ұൠʹ͸
཰෼෍ͱͯ͠༩
཰ʢ
posteriorࣝ
෼෍ʢrecognition densityͼ q(u,θ) Ͱද͢ɽ
ೖྗ͕(4) ͔Βੜ੒͞ΕΔͱ͢Δͱαϓϥ
Πζ͸ S =−log
(∫
p(˜s,u,θ|m)dudθ
)
Ͱ͖Δ͕ɼ
logࢉܭ
ʹద͞ͳ͍ͨΊɼ୅ཧํ๏ʢproxyʣͱͯ͠ Sݶ
༝ΤωϧΪʔͰ͋ΔɽΠΣ
74ࢽV ol. 25, No. 3ʢ2018ʣ
ද 1ٛ
߸هҙຯ
sೖྗͷϕΫτϧ
x ӅΕঢ়ଶͷϕΫτϧ
vҼͷϕΫτϧ
˜s ≡(s,s′,s′′,... )
˜x ≡(x,x′,x′′,... )ඪʢϕΫτϧʣ
˜v ≡(v,v′,v′′,... )
u ≡(˜x,˜v) ӅΕม਺ͷϕΫτϧ
θ ύϥϝʔλͷϕΫτϧ
aಈͷϕΫτϧ
f (˜x,˜v,θ,a),f ˜x਺
g(˜x,˜v,θ,a),g ˜s਺
˜z,˜ωଌϊΠζ
D ≡
⎛⎜⎜
⎜
⎜
⎜
⎜
⎜⎜⎝
OI O
OI
O
...
...
⎞⎟⎟
⎟
⎟
⎟
⎟
⎟⎟⎠
ྻ
D˜x =(˜x)′=(x′,x′′,x′′′,... )
p(˜s,u,θ|m) ੜ੒Ϟσϧ (4)
m଄
u,θ଴஋
q(u),q(θ)཰
ϵs,ϵx,ξs,ξxࠩޡ
A,B,A,B଴஋
S (˜s),S αϓϥΠζ (1)
F(˜s,q(u,θ)),F༝ΤωϧΪʔ (5)(6)(7)
F(q(θ)),F༻ (11)
Eq[•]཰෼෍ q଴஋
DKL[q||p]཰෼෍ q ͱ p ͷΧϧόοΫɾ
ϥΠϒϥʔμΠόʔδΣϯε
N[u,Cu]ۉuྻ Cu ͷΨ΢ε෼෍
ʭ
˜s ≡(s1,..., sT )ೖྗͷγʔΫΤϯε
˜x ≡(x1,..., xT ) ӅΕঢ়ଶͷγʔΫΤϯε
π,π଴஋
A xτ͔Β sτྻ
Bπ
τࠁ࣌τྻ
P(˜s,˜x,π,θ|m)ͷੜ੒Ϟσϧ (20)
F(τ,π),F(π),F༝ΤωϧΪʔ (22)(26)
G(τ,π),G(π)༝ΤωϧΪʔ (28)
ΑΓEq(u,θ)[−log(p(˜s,u,θ|m)/q(u,θ))] ͸ඞ
ͣ−log Eq(u,θ)[p(˜s,u,θ|m)/q(u,θ)] =−log p(˜s|m) =S Ҏ
্†3༝ΤωϧΪʔ͸
†3 Eq(u,θ)[p(˜s,u,θ|m)/q(u,θ)] ͸ p(˜s,u,θ|m)/q(u,θ) ͱ q(u,θ)
ΛdudθͰੵ෼͢ΔͷͰɼq(u,θ)͍
Variational free energy
F(˜s,q(u,θ)) ≡S +DKL[q(u,θ)||p(u,θ|˜s,m)] (5)
͞ΕΔɽୈ 2͸ΧϧόοΫɾϥΠϒϥʔ
μΠόʔδΣϯεʢ Kullback-Leibler divergence ʣ24)
ͱ͍͏ 2 ͭͷ෼෍ͷҧ͍Λද͢ඇෛͷྔͰ͋
ΓɼDKL[q(u,θ)||p(u,θ|˜s,m)] = Eq(u,θ)[log q(u,θ) −
log p(u,θ|˜s,m)]཰ q(u,θ)
͕ੜ੒Ϟσϧ p(u,θ|˜s,m) ͱͲΕ΄ͲҟͳΔ͔ΛఆྔԽ
͓ͯ͠Γɼ྆෼෍͕ಉҰͰ͋Δͱ͖ͷΈF ͸S ʹҰக
ʹΑΓF֬ޙࣄ
཰ͷγϟϊϯΤϯτϩϐʔʹ෼ղͰ͖Δɿ
F =Eq(u,θ)[−log p(˜s,u,θ|m) +log q(u,θ)] (6)
ୈ 1͸಺෦ΤωϧΪʔʢinternal energyʣU(˜s,u,θ) ≡
−log p(˜s,u,θ|m)͹ΕΔɽ͋Δ͍͸ɼF ͸ෛͷର
ʹ෼ղͰ͖Δɿ
F =Eq(u,θ)[−log p(˜s|u,θ,m)]
+DKL[q(u)||p(u|m)] +DKL[q(θ)||p(θ|m)] (7)
ୈ1ͷෛͷର਺໬౓͸ਫ਼౓ʢaccuracy͹ΕΔ†4ɽ
ୈ 2,3ੑʢcomplexity͹Εɼ௨ৗ͸ӅΕ
शΛ཈੍͢ΔϖφϧςΟ
ͱղऍͰ͖Δ†5ɽ
ه5)(6)(7)ͷղऍ͸ҟͳΔ΋ͷͷಉ͡ίε
਺F Λද͓ͯ͠ΓɼFখԽ͢ΔͨΊʹ͸q(u,θ)
Λ p(u,θ|˜s,m)ʹS Λখ͘͢͞Δඞཁ͕
଄mͮ͘ੜ੒Ϟσϧ(4) ͷΫϥε
͢Δͷʹద੾Ͱ͋Δͱ͖ɼ
Fখ஋Λ༩͑Δq(u,θ)ʹSখ஋Λ༩͑
࠷
਺Ͱ͋Δɽ
3.श
ͷཧ࿦9)దԽ
খԽ͸(i)Ҽͷਪ࿦͓Α
ͼ (ii)Ҽ
తਪ࿦͔ΒདྷΔ΋ͷͰ͋Δ͕ɼϒϥ
Eq(u,θ)[p(˜s,u,θ|m)/q(u,θ)] =
∫
p(˜s,u,θ|m)dudθ = p(˜s|m)
Ͱ͋Δɽ
†4 ରͯ͠αϓϥΠζ S ͸ӅΕม਺ͱύϥϝʔλʹ͍ͭ
ͯपลԽ͍ͯ͠ΔͷͰʢෛͷʣपลԽ໬౓ʢ marginal
likelihood͹ΕΔɽ
†5 ͜͜Ͱɼ(5)(6) ͱ (7)ີʹಉҰͰ͋ΔͨΊʹ͸ɼ(7)
ͷୈ 2͸ q(u|θ) ͱ p(u|m)؆
Ͱ
ड़͍ͯ͠Δɽ
ཧͷղઆ 75
ਤ2ݙ14)ͷ Fig. 2ʹ͠
੒ͨ͠ɽ
෼཭ʢblind source separationʣͱͯ͠΋
஌ΒΕ͍ͯΔ25, 26)Θͬͨ͞ෳ਺ͷೖྗ
ʑͷ৴
ҼʣΛ෼཭ʢਪ࿦ʣ͢Δख๏Ͱ͋ΔɽΧΫς
Ռʢcocktail party eﬀectʀ͏Δ͍͞৔ॴͰ
΋ಛఆͷ࿩ऀͷ੠Λฉ͖෼͚ΒΕΔೳྗʣ27ʙ30)࣮
ࢹ
ผ͢ΔͨΊʹඞ
ཁͳೳྗͰ͋Δ31)༝ΤωϧΪʔ
ʹΑ
Δղઆ32)ײ
ߟ
Խʢpredictive codingʣͱͯ͠஌ΒΕ͍ͯ
Δ33, 34)͍ͬͯΔͱ͍͏
͑͸ϕΠζ೴Ծઆ35)ͱͯ͠΋஌ΒΕ͍ͯΔɽ͜͜Ͱ
਎ͷอ༗͢Δੜ੒
খԽ
Ա͢Δͱ͍͏ΑΓ΋
͑ΒΕ
Δ19)ɽҎԼͰ͸ɼ3.1దԽख๏ʹ͍ͭͯɼ3.2 ͱ
3.3૷ํ๏ʹ͍ͭͯɼ3.4
ʹ͍ͭͯઆ໌͢Δɽͳ͓͜͜Ͱઆ໌͢Δ
৽ଇ͸
Expectation-MaximizationʢEMʣ
͍ͯ͠ΔɽEM ΞϧΰϦζϜ
ͷ
ղઆ36)র͞Ε͍ͨɽ
3.1৽ଇ
దԽ໰୊͸ม෼๏ʢม෼
ϕΠζʀvariational BayesʣʹΑΓղ͘͜ͱ͕Ͱ͖Δɽ
͍ʹಠཱ
q(u,θ) =q(u)q(θ)ۙ
Ͱ͋Δ†6ɽ·ͣ(6) Λq(u)݅
†6͑ͯ΋ྑ͍ɽχϡʔϩϯͷൃՐ
εέʔϧ͕े෼཭Ε͍ͯ
δF =
∫
duδq(u){Eq(θ)[−log p(˜s,u,θ|m)]+log q(u)+1}=0
Λղ͘͜ͱʹΑΓɼF෼෍͸
q(u) ∝e−Eq(θ)[−log p(˜s,u,θ|m)] (8)
Ͱ͋Δ͜ͱ͕Θ͔Δɽ͜͜Ͱq(u)ස஋ʢmodeʣ͸
q(u)଴஋ʢi.e., 1Ϟʔϝϯτʣu ≡Eq(u)[u]
ʹҰக͢ΔͱԾఆ͢Δɽ͢ΔͱFదͳ
u഑๏ʹΑΓ
Inference ˙u −Du ∝− ∂Eq(θ)[−log p(˜s,u,θ|m)]
∂u
⏐⏐⏐⏐⏐⏐u=u
≈− ∂F(˜s,u,θ)
∂u (9)
఺ʢ͢ͳΘͪ˙u =Duʣ
దͳu Λ༩͑Δɽ͜͜Ͱ Du ͸ 1ײ
ΊͨӅΕม਺ͷมԽྔͷਪఆ஋Ͱ͋Δɽ
ҰํͰ ˙uΊͨ໬౓
഑ʹΑΔิਖ਼ʢઁಈʣ͕Ճ͑ΒΕ͍ͯΔɽ͢ͳΘ
ͪ (9)͍
มԽྔਪఆ஋ Du ͔Β৽͍͠มԽྔਪఆ஋ ˙u৽
Λҙຯ͍ͯ͠Δ9, 20)ࣜ9) ͷ 2໨͸1Ϟʔϝϯτ
͍ͯ͠Δɽ
ͭ·Γ 1͢Δͱ
F(˜s,u,θ) ≈−log p(˜s,u,θ|m) +const. (10)
ΛಘΔɽ
༝Τωϧ
࿏ੵ෼ʀpath integral༻
ʢvariational free actionదԽ͞
ΕΔ†7ࣜ7)༻͸
Λਖ਼౰Խ͢Δɽ
†7࿏ʢpathʣͱ͸ӅΕม਺ͷτ=0 ͔Βt ·Ͱ
ظ
ࣅۙ
q(u(0),u(dτ),u(2dτ),..., u(t)) =
q(u(0))q(u(dτ))q(u(2dτ)) ... q(u(t)) ʹΑΓ (11) ΛಘΔɽ
76ࢽV ol. 25, No. 3ʢ2018ʣ
Variational free action
F(q(θ)) ≡
∫ t
0
Eq(u(τ),θ)[−log p(˜s(τ),u(τ)|θ,m)]dτ
+DKL[q(θ)||p(θ|m)] (11)
ੵ෼ͷதͰ͸ ˜s ≡
˜s(τ) ͓Αͼ u ≡ u(τ)ड़Λলུ͢Δɽม
༻Λ q(θ)݅δF =∫
dθδq(θ)
{∫ t
0 Eq(u)[−log p(˜s,u|θ,m)]dτ +log q(θ) −
log p(θ|m) +1
}
=0 Λղ͘͜ͱʹΑΓɼFখԽ͢Δ
෼෍͸
q(θ) ∝e−
{∫ t
0 Eq(u)[−log p(˜s,u|θ,m)]dτ−log p(θ|m)
}
(12)
Ͱ͋Δɽ͞Βʹq(θ)଴஋θ ≡Eq(θ)[θ]
৽ଇ͸
Learning
˙θ∝− ∂
∂θ
{∫ t
0
Eq(u)[−log p(˜s,u|θ,m)]dτ−log p(θ|m)
}⏐⏐⏐
⏐⏐⏐
θ=θ
≈−∂F(θ)
∂θ (13)
ͱ༩͑ΒΕΔɽ2໨͸ 1ྔ
఺Λऔ
ہ
దԽ͞
ΕΔɽ
৽ଇ
(9)ɼ(13)ମతͳϞσϧʹର͠
૷ํ๏Λ
ϞσϧͰ͋ΔҰൠԽΨ΢γΞϯɾ
ϑΟϧλϦϯάʢgeneralized Gaussian ﬁlteringʣ9, 20)ͱ཭
ఆաఔʢMarkov decision
process; MDPʣ12)ʹ͍ͭͯઆ໌͢Δ†8ɽ
3.2૷
ҰൠԽΨ΢γΞϯɾϑΟϧλϦϯά9, 20)༝
୯ʹ͢ΔͨΊ
ʹ Eq(θ)[−log p(˜s,u,θ|m)] ͓Αͼ Eq(u)[−log p(˜s,u|θ,m)]
ස஋ʢ≈଴஋ʣͷपΓͰ 2ͷςʔϥʔల։ʹ
ʣ9, 20)଴஋ʹ͓
ड़͞ΕΔͷͰ(8) ͱ (12) ͸Ψ
ྻ͕े෼౷
཰
Λ q(u) =N[u,Cu] ͓Αͼ q(θ) =N[θ,Cθ]ड़͢Δ
ʢN[u,Cu]཰ม਺uۉuྻCu ͷ
֮ײ
†8ཧͰ͸௨ৗ͜ΕΒ 2 ͭͷϞσ
ཧ͔ΒҰҙʹಋग़͞Ε
૷ํ๏΋ՄೳͰ͋Δɽ
ೖྗΛ஌ͬͨͱ͖ͷu ͱ θ֬
཰Λද͍ͯ͠Δ†9ɽ
ΛਐΊΔͨΊγεςϜϊΠζ˜zଌϊΠ
ζ ˜ω͕Ψ΢ε෼෍ p(˜z|m) ≡N[0,Σz] ͓Αͼ p(˜ω|m) ≡
N[0,Σω]͓
͏ɽ͢Δͱɼ p(˜s|˜x,˜v,θ,m) = N[g(˜x,˜v,θ),Σω] ͓Αͼ
p(˜x|˜v,θ,m) =N[ f (˜x,˜v,θ),Σz]؆
ಈ͸ͳ͍ʢa =0ʣͱ
͢ΔɽҰํp(˜v|m) ͓Αͼp(θ|m) ͸Ұൠʹ͸ͲΜͳ෼෍
ͷςʔϥʔల։ʹ͓
͍ͯ1͠Α͏ɽର਺໬౓ͷςʔϥʔ
ల։ͷ2ɼ(10)ͨ͠Α͏ʹม
଴஋
଴஋͔ΒͷͣΕ
ࠩޡϵs ≡˜s −g(˜x,˜v,θ) ͓Αͼϵx ≡D˜x −f (˜x,˜v,θ)
͠
༻͸ఆ
਺Λআ͖
F(˜s,u,θ) =1
2 ϵT
s Σ−1
s ϵs +1
2 ϵT
x Σ−1
x ϵx −log p(˜v|m)
F(θ) =1
2
∫ t
0
(
ϵT
s Σ−1
s ϵs +ϵT
x Σ−1
x ϵx
)
dτ−log p(θ|m) (14)
ड़Ͱ͖Δ†10ظ
৽ଇ͸ (9) ͱ (13) ΑΓ
˙u −Du ∝∂g
∂u
T
Σ−1
s ϵs +∂f
∂u
T
Σ−1
x ϵx +∂log p(˜v|m)
∂u
˙θ ∝
∫ t
0
(∂g
∂θ
T
Σ−1
s ϵs +∂f
∂θ
T
Σ−1
x ϵx
)
dτ+∂log p(θ|m)
∂θ (15)
ͱ༩͑ΒΕΔɽ·ͨ q(u) ͱ q(θ)ࣅۙ
తʹ F ͓Αͼ F ͷϔογΞϯ
C−1
u =∂2F(˜s,u,θ)
∂u2
C−1
θ =∂2F(θ)
∂θ2 (16)
Ͱ༩͑ΒΕΔɽ
ߟ
†9 ͭ·Γ q(u) ͸ɼu଴஋͸ uࠩޡ
ʢstandard errorʣͷೋ৐͸ Cu͑ͯ
͍Δͱ͍͏ҙຯͰ͋Δɽ
†10ࣜ10) ͔Β (14)͸ɼ·ͣ (4) Λ༻͍
ͯ −log p(˜s,u,θ|m) Λ෼ղ͠ɼΨ΢ε෼෍Ͱ͋Δ͜
ͱ͔Β −log p(˜s|˜x,˜v,θ,m) = 1
2 ϵT
s Σ−1
s ϵs + const. ͱ
−log p(˜x|˜v,θ,m) = 1
2 ϵT
x Σ−1
x ϵx +const.Λ୅ೖͨ͠ɽͳ
͓ (15) ʹ͓͍ͯɼ F(˜s,u,θ) ͸ u Ͱඍ෼͞ΕΔͷͰ
−log p(θ|m) ͸ఆ਺ͱΈͳ͠ɼF(θ) ͸ θ Ͱඍ෼͞ΕΔ
ͷͰ −log p(˜v|m) ͸ఆ਺ͱΈͳͨ͠ɽ
ཧͷղઆ 77
͑Α͏9)ɽύϥϝʔλθ≡{θf ,θg}ྻθf ≡B, θg ≡A
ͱͯ͠༩͑ΒΕ͓ͯΓ f ≡f (Bu), g ≡g(Au)ड़Ͱ
͖Δͱ͢Δɽ͜͜Ͱ f,g਺Ͱ͋
Δɽ௨ৗɼf,g਺37)ʹɼύϥϝʔλ
଴஋ A,Bߟ
Λίʔυ͢Δχϡʔϩϯʢerror coding
neuronಈ͸
ξs ≡Σ−1
s ϵs =Σ−1
s (˜s −g(Au))
ξx ≡Σ−1
x ϵx =Σ−1
x
(D˜x −f (Bu)) (17)
Ͱ༩͑ΒΕΔɽ·ͨ(15)଴஋Λίʔ
υ͢Δχϡʔϩϯʢexpectation coding neuronಈ͸
˙u =Du +α
(
AT g′ξs +BT f ′ξx +∂log p(˜v|m)
∂u
)
(18)
Ͱ༩͑ΒΕΔɽͨͩ͠ α> 0৽཰Ͱ͋Γɼg′≡
g′(Au) ͱ f ′≡ f ′(Bu) ͸ 1ྻ
Ͱ͋Δɽ͜Ε͸ɼ4 छྨͷೖྗ DuɼAT g′ξsɼBT f ′ξxɼ
∂log p(˜v|m)/∂u ʹΑΓൃՐ཰ uΊ
ΔχϡʔϩϯϞσϧͰ͋Δͱղऍ͞ΕΔʢਤ3ʣɽҰํɼ
଴஋ A,B৽ଇ͸ (15) ΑΓ
˙A ∝
∫ t
0
g′ξsuT dτ+∂log p(θ|m)
∂A
˙B ∝
∫ t
0
f ′ξxuT dτ+∂log p(θ|m)
∂B (19)
Ͱ༩͑ΒΕΔ†11ɽୈ 1γφϓεՄ઼ੑ
ʢHebbian plasticityʣ38)Λද͍ͯ͠Δɽͳ͓u ͱ f ′ξxʢ͋
Δ͍͸ g′ξsχϡʔϩ
ϯʹରԠ͢Δɽୈ 2લ෼෍͔Β཭ΕΔ͜ͱʹର
Ͱ͋Δɽ
3.3૷
MDP ͷ࿮૊Έ12)ࣜ2)(3) Λ཭
͠ɼӅΕঢ়ଶ xtೖྗ st஋Λ
औΔͱ͢Δ†12ɽ͜ΕΒ͸͋Δ 1 ͭͷ੒෼͕ 1 Ͱ͋Γɼ
ͦͷଞͷ੒෼͕0Ҽvt
͸ͳ͍΋ͷͱ͢Δɽ·ͨɼ ˜s ≡(s1,s2,..., sT ) ͓Αͼ
˜x ≡(x1,x2,..., xT ) Λ௕͞ TೖྗͱӅΕঢ়ଶͷ
ʹ͓
ड़͞ΕΔɽ͜͜Ͱ
ͷ ˜sɼ˜x͸࿈ଓϞσϧͱҟͳΔ͜ͱʹ஫ҙ͕ඞ
ͨ͠
†11ࣜ13)(15)(16) Ͱ͸ϕΫτϧ θ Ͱඍ෼͍ͯͨ͠ͷʹର
͠ɼ(19)ྻ A,B Ͱඍ෼͍ͯ͠Δ͜ͱʹ஫ҙɽ
†12 ͳ͓ MDP Ͱ͸௨ৗ12)ɼӅΕঢ়ଶΛ stೖྗΛ ot
ه
༻ͨ͠ɽ
ਤ3࣮
ݙ9)ͷ Fig. 8੒ͨ͠ɽͳ͓
ਤதͰ͸(18) Λ˜x ͱ˜v ʹ͍ͭͯ෼͚ͯද͓ͯ͠
Γɼ·ͨ A ≡(Ax,O),B ≡(Bx,Bv) ͱͨ͠ɽ༧ଌ
ೖྗଆʣ͔Βӈʹ఻ΘΔʢϘτϜ
ʹ఻ΘΔ
ʢτοϓμ΢ϯʣɽ
ͷੜ੒աఔ͸ xt ͔
Β stྻ A ͓Αͼ xt−1 ͔Β xt
ྻ Bπ
τड़͞ΕΔʢਤ 4ʣɽ͜
֬
଴
ೖྗ͸ΧςΰϦΧϧ෼
෍
P(sτ|xτ,A,m) =Cat(A)ఆ͞ΕΔɽ͜Ε͸
P(sτ =i|xτ = j,A,m) =Aij ͱ͍͏ҙຯͰ͋ΔɽҰํɼ
ӅΕঢ়ଶͷγʔΫΤϯε͸P(xτ|xτ−1,B,m) =Cat(Bπ
τ−1)
ྻ Bπ
τࠁ࣌τࡦ
ʢpolicyʣͷϕΫτϧπʹΑͬͯมԽ͢Δʢશͯͷπͱ
τʹ͍ͭͯͷ Bπ
τ Λ·ͱΊͨ΋ͷΛ Bߦ
ೖྗ xظ
཰෼෍P(x1|D,m) =Cat(D) ʹΑΓ༩͑ΒΕΔͱ
͢Δɽ
MDP ͷੜ੒Ϟσϧ͸ɼ(4) Λগ͠मਖ਼ͯ͠
Generative model
P(˜s,˜x,π,θ|m) =P(s1|x1,A,m)P(x1|D,m)
·
T∏
τ=2
P(sτ|xτ,A,m)P(xτ|xτ−1,Bπ
τ,m)P(π|m)P(θ|m) (20)
͞ΕΔɽ͜͜Ͱ P(π|m) = Cat(Π)଴஋ Π
78ࢽV ol. 25, No. 3ʢ2018ʣ
લ෼෍Ͱ͋Δɽ·ͨ
P(θ|m) =P(A|m) ∏
τ,πP(Bπ
τ|m)P(D|m)ࣄ
ύϥϝʔλ͸࿈ଓ஋ΛऔΔͨΊ࿈ଓ
෼෍Ͱ͋ΔσΟϦΫϨ෼෍ʢDirichlet distributionʣ͔
ྻAྻ ˆA Λे
ྔͱͨ͠σΟϦΫϨ෼෍ P(A|m) =Dir( ˆA) ͔Β
ੜ੒͞ΕΔͱ͢Δ†13ɽ
খԽ͢ΔӅΕ
খԽ͢
ষ
దԽ͸ະདྷͷαϓϥΠ
ద
͕ t ͷͱ͖ɼੜ
੒Ϟσϧ (20)཰͸ Q(x1,..., xt,θ|π) ≡∏ t
τ=1 Q(xτ|π)Q(θ)ͷ xτޙࣄ
཰͸ಠཱͰ͋ΔͱԾఆ͍ͯ͠Δɽ ʣͨͩ͠ Q(xτ|π)
଴஋ xπ
τྔͱͨ͠ΧςΰϦΧϧ෼෍
Q(xτ|π) =Cat(xπ
τ) Ͱ͋ΓɼQ(θ) ≡Q(A) ∏
τ,πQ(Bπ
τ)Q(D)
ྔ ˆA,ˆBπ
τ,ˆDྔͱͨ͠σΟϦΫϨ
෼෍ Q(A) =Dir( ˆA),Q(Bπ
τ) =Dir( ˆBπ
τ),Q(D) =Dir( ˆD)
ͱಉ༷ʹ
͔Β
͸
log A ≡EQ(A)[log A] =ψ( ˆA) −ψ
⎛⎜⎜
⎜
⎜
⎜
⎝
∑
i
ˆAij
⎞⎟⎟
⎟
⎟
⎟
⎠
log B
π
τ ≡EQ(B)[log Bπ
τ] =ψ( ˆBπ
τ) −ψ
⎛⎜⎜
⎜
⎜
⎜
⎝
∑
i
( ˆBπ
τ)ij
⎞⎟⎟
⎟
⎟
⎟
⎠
log D ≡E
Q(D)[log D] =ψ( ˆD) −ψ
⎛⎜⎜⎜⎜
⎜
⎝
∑
i
ˆDi
⎞⎟⎟⎟⎟
⎟
⎠ (21)Ͱ༩͑ΒΕΔɽ͜͜Ͱ ψ(•) ≡Γ′(•)/Γ(•) ͸σΟΨϯ
਺ʢdigamma function਺ͷର਺ඍ෼ʣ
৽͸͜ΕΒ
log A,log Bπ
τ,log Dతͳύ
౓͕
͑ΒΕ͍ͯΔɽ
༝ΤωϧΪʔ͸ (7) Λগ͠मਖ਼ͯ͠
†13 A཰෼෍Ͱ͋ΔͨΊɼ೚ҙͷྻ j ʹ͓͍ͯ
i ʹ͍ͭͯ࿨ΛऔΔͱৗʹ 1ʢ∑
i Aij = 1ʣʹͳ
Խ͞Ε͍ͯΔɽҰํ ˆAԽલ
͸
P(A|m) =Dir( ˆA) ≡∏
j B( ˆA•j)−1 ∏
i A
ˆAij
ij Ͱ͋ΓɼB( ˆA•j) ≡
∏
i Γ( ˆAij )/Γ(∏
i ˆAij )ࣜ22) Ͱ͸
B( ˆA) ≡∏
j B( ˆA•j)͍ͯ͠Δɽ
ਤ4ݙ13)ͷFig. 2ʹͯ͠
ࠁ࣌τ=1,2,3,... ͷঢ়ଶΛද
ೖྗ sτΑΓ্͸֎քͷੜ੒աఔ
ΛɼԼ͸χϡʔϥϧωοτΛද͍ͯ͠Δɽͨͩ
͠ɼx1,x2,x3,...ʹ͓͚
͍ͯ͠Δͷʹର͠ɼxπ
1,xπ
2,xπ
3,...֤࣌
଴஋Λίʔυ͢Δผʑͷχϡʔϩ
ϯΛද͍ͯ͠Δ఺ʹ஫ҙ͍͖͍ͯͨͩͨ͠ɽ
F(π,τ) =EQ(xτ,θ)[−log P(sτ|xτ,θ,m)]
+DKL[Q(xτ|π)||P(xτ|xτ−1,π,θ, m)]
=−xπ
τ·log A ·sτ+xπ
τ·log xπ
τ−xπ
τ·log Bπ
τ−1xπ
τ−1
F(π) =
t∑
τ=1
F(π,τ) +DKL[Q(θ)||P(θ|m)]
=
t∑
τ=1
F(π,τ) +( ˆA −ˆA) ·log A −log B( ˆA)
+
t∑
τ=2
{
( ˆBπ
τ−ˆBπ
τ) ·log Bπ
τ−log B( ˆBπ
τ)
}
+( ˆD −ˆD) ·log D −log B( ˆD) (22)
͞ΕΔɽ͜͜ͰB(•)ٛ
͸஫ऍ †13ࣜ22) ͷ F(π,τ) ͷୈ 1͸ਫ਼౓ʹ
ରԠ͠ɼୈ2ੑΛද͍ͯ͠
Δɽ·ͨ F(π) ͷୈ 2͸ύϥϝʔλͷ෼෍ͷෳ
ʹ
దԽ͢ΔͷͰɼ
F(π) ͷม෼͕ 0݅δF(π)/δxπ
τ =0 Λղ͘͜ͱ
ʹΑΓɼӅΕঢ়ଶͷਪ࿦͸
xπ
τ =σ(log A ·sτ+log Bπ
τ−1xπ
τ−1 +log Bπ
τ·xπ
τ+1
) (23)
ड़͞ΕΔɽ͜͜Ͱɼσ(•) ≡exp(•)/∑
i exp(•i) ͸ι
਺Ͱ͋ΔɽχϡʔϥϧωοτͷϞσϧ
਺37)ʹରԠ͍ͯ͠
ཧͷղઆ 79
Δɽ·ͨ δF/δA =O,δF(π)/δBπ
τ =O,δF/δD =0 Λղ
͘͜ͱʹΑΓʢFࣜ26)রʣɼύϥϝʔ
श͸
ˆA = ˆA +
T∑
τ=1
sτ⊗xτ
ˆBπ
τ−1 =ˆBπ
τ−1 +(π·π) xπ
τ⊗xπ
τ−1
ˆD = ˆD +x1 (24)
ͱ༩͑ΒΕΔ†14ɽͳ͓ ⊗Λද͠ɼxτ ≡
EQ(π)[xπ
τ]γφϓεՄ઼ੑ38)Λ
ද͍ͯ͠Δͱղऍ͞ΕΔɽྫ͑͹ ˆAͰ͸ xτͱ sτ
χϡʔϩϯʹରԠ͢Δɽ
3.4ڀݚ
ԽϞσϧΛͲͷΑ͏
తಛ௃ͱରԠ͚ͮ
࿦͕ҝ͞Ε͍ͯΔ6)લ
ࠂ39)΋೴͕ϕΠζਪ࿦
͍ͯ͠Δɽ·ͨഓཆ
ճ࿏໢ʹ͓͍ͯ͸ɼχϡʔϩ
෼
ʹɼγφϓεՄ઼ੑʢi.e.͖
গ͢Δ͜ͱ
͞Ε͍ͯΔ40, 41)ɽ
ʹ
ͷੜ੒Ϟσϧ (4)
Ϟσϧʹॖ໿͢Δ͜ͱʹΑΓɼର਺໬౓͕2 ͭ
ྻͷੵͰॻ͚ΔΑ͏ʹͳΔɽ
͸2ີʹ
ਖ਼͍͠ɽʣͦͷͨΊɼύϥϝʔλʹ͍ͭͯඍ෼ͯ͠ಘΒ
৽ଇ͸2 ͭͷঢ়ଶม਺ͷ֎ੵͰ͋ΓҰൠʹ
ͷਅͷੜ੒աఔ͸Ұൠʹ͸࿈ଓͰ
ͷ2͸ಉ
͑Δ͔΋͠Εͳ͍ɽ
शଇͱͯ͠͸ε
ґଘγφϓεՄ઼ੑʢspike-timing dependent
synaptic plasticityʀSTDPʣ42, 43)͕Α͘஌ΒΕ͍ͯΔɽε
ύΠΫൃՐχϡʔϩϯϞσϧͱSTDP ʹΑΔμΠφϛ
ࣗ
†14 ͜ΕΒ͸௕͞ T ͷγʔΫΤϯε͕Ұ౓༩͑ΒΕͨͱ͖
ೖྗΛड͚औͬ
ʹ 1͑Ε
शΛऩଋͤ͞ΔͨΊʹ͸ಉ͡
ੜ੒աఔ͔ΒϥϯμϜʹੜ੒͞ΕͨγʔΫΤϯεΛԿ
৽͢Δඞཁ͕͋Δɽͦͷ
ͱ͖
k ճ໨ͷηογϣϯʹ͓͍ͯ͸ k −1ޙࣄ
લ෼෍ʹͳΔɽ
ʹͳ͍ͬͯΔ44)ɽ͔͠͠Ұൠʹ͸ɼ
ͷχϡʔϩ
఻ୡʹΑͬͯ௨ৗ͸஌Γಘͳ͍৘
౓ͷ஋ʣ
शଇ45)Ͱ͋Δɽ
ҰํͰɼMDP৽ଇ(24) ͸ɼχϡʔϩϯ͕γφ
श͕Մ
शଇ46)Ͱ͋Δͱ͞Ε͍ͯΔɽ͜ͷΑ͏
૷ํ๏͸ϓϩηεཧ࿦ʢprocess
theory͹Ε͍ͯΔ12)ɽ
ਂ૚Խͨ͠ҰൠԽΨ΢γΞϯɾϑΟϧλϦϯά͸ɼੜ੒
ඪʹͭ
ʢvariational autoencoderʣ47)Ͱ
͑ΒΕΔɽ͜ΕΛॖ໿͢Δͱओ੒෼෼ੳ48, 49)ɼ
ಠཱ੒෼෼ੳ50ʙ52)ث53)ɼΧϧϚϯϑΟϧ
ΕΔ 9)ԽϞ
৽ଇ (15)఻೻๏ʢback-
propagationʣͱಉ౳Ͱ͋Δ54)৽ଇͷ
఺Λ༩͑Δu৽ଇʹ୅ೖ͠
৽ଇΛ༩͑ΔͨΊͰ͋Δͱղ
ऍͰ͖Δɽͳ͓ੜ੒Ϟσϧ͔ΒμΠφϛΫεΛআ͘ͱ
(15) ͸εύʔείʔσΟϯάϞσϧ55, 56)ʹॖ໿͞ΕΔɽ
शʢϩʔ
Ͱ͋Γ
Δ
ಠཱ੒
෼෼ੳ
57)͠ਅ
·Δอূ͸ͳ͍͜ͱ͕஌ΒΕͯ
͍Δ58, 59)ɽ
4.దԽ
Λ
΅͞ͳ͔ͬͨɽ
͸ɼ
ಈa਺Ͱ͋Δɽ
ɼ−log p(˜s)਺Ͱ͋
ୈͰະདྷͷ−log p(˜s)ੑΛ
ཧ
దԽͱͯ͠αϓϥΠζ
SͰ͋Δ−log p(˜s)
ߟ
͑Δɽ͜Ε͸ೳಈతਪ࿦ʢactive inference͹Εͯ
͍Δ11, 12)͖Δ 3 ͭͷγφ
ֱ
ͷղઆ60)র͞
Ε͍ͨɽ
80ࢽV ol. 25, No. 3ʢ2018ʣ
4.1దԽ
ܾ
ఆ͞ΕΔɿ
Action ˙a ∝−∂F
∂a (25)
ೳಈతਪ࿦ͷγφϦΦ 1 ͸ɼ೴಺ͷੜ੒Ϟσϧͱ֎ք
ͷੜ੒աఔ͕ҟͳΔͱ͖ʹɼ೴಺ͷੜ੒ϞσϧΛมԽ
ಈΛ֎քʹ༩͑Δ͜ͱͰɼ֎քͷ
దԽ
Ͱ͋Δ11)୯ͳྫ
ͬͯઆ໌͠Α͏ɽ֎ք͔Βฉ͑͜ΔՎ΋ɼ
ೖྗ
˜s ͱͯ͠ड
ಈ͕˙a ∝−Σ−1
s (˜s −g(˜x,˜v,θ)) Ͱ༩͑
ΒΕΔͱ͢Δɽ΋͠ɼ֎ք͔ΒՎ͕ฉ͍͑ͯ͜Δঢ়ଶ
ʹಥવՎ͕ฉ
͑͜ͳ͘ͳͬͨͱ͢ΔͱɼͦͷΤʔδΣϯτʹͱͬͯɼ
͍ɽ
ఆ
෼͕Վ͏͜ͱ
Εͨʣঢ়ଶʹ
มԽͤ͞Δ
†15ɽ͢ͳΘͪ ˜s =a +˜ω≈g(˜x,˜v,θ) +˜ωͰ
ಈ aࣗ
ೖྗg(˜x,˜v,θ)ೖ
ྗ˜s ͱͯ͠ड͚औ͍ͬͯΔ఺ʹ஫ҙ͍͖͍ͯͨͩͨ͠ɽ
খԽͷํ๏͸ɼ೴Λ֎քʹ
ͷ2 छྨ͕
఺͔Β͸2ಈΛ
͍ʹΑΓɼઌ
෼͕Վ
͏Α͏ʹ֎քΛ
·ΔͨΊɼͲ
͜Γ͏Δɽ
4.2దԽ
ಈa΅͢ӡಈͰ͋Δͷʹରͯ͠ɼ
ࡦπ͸ɼকདྷͷӡಈͷϓϥϯΛҙຯ͠ɼ೴಺ʹ
ݴ
ͷ sτ ΍ xτ ͱಉ༷ʹ͋Δ 1
ͭͷ੒෼ͷΈ͕ 1Γ͕ 0 ͷϕΫτϧͰ͋Γɼϕ
ʢϓϥ
ద
తʹ͸αϓϥΠ
ζ
−log p(˜s|m)খԽͰ͋Δʹ΋͔͔ΘΒͣɼѻ͏
͍͸ҟ
†15 ͋Δ͍͸ɼ͜͜Ͱ͸ड़΂ͳ͍͕ɼՎ͕ฉ͑͜Δ৔ॴ·
͜͢͜ͱͰαϓϥΠζΛԼ
͑Δ͜ͱ͕Ͱ͖Δɽ
ͮ
·Ͱͷʣ−log p(˜s|m)
Λ−log p(˜s)ߦ
ੑ −log p(˜s)ܾ
ఆ͞ΕΔɽೳಈతਪ࿦ͷγφϦΦ2 ͸ɼ͜ͷΑ͏ʹক
ద
୯ͷͨΊɼ೴಺
͓ྃͯ͠Γ֎෦ͷੜ੒ա
͍ͯ͠Δʢ
−log p(˜s|m) =−log p(˜s)ʣ
ɼ
ى
͸ɼҰൠԽΨ΢γΞϯɾϑΟ
཰෼෍
ͭ෼
෍Λ༰қʹѻ͑Δ MDP͑Δɽ
ͷੜ੒Ϟσϧ͸(20) Ͱ༩͑
༝ΤωϧΪʔ͸(22)ಈ
Λ௥Ճͯ͠
F =EQ(π)[F(π)] +DKL[Q(π)||P(π|m)]
=π ·(F +log π −log Π) (26)
ͱ༩͑ΒΕΔɽͨͩ͠ F ≡ Vec[F(π)] ͸ͦΕͧΕͷ
ʹ͍ͭͯͷ F(π) ΛϕΫτϧͱͯ͠ฒ΂ͨ
ࡦπࠁ֤࣌τʹ͓͚
ྻ Bπ
τ ͸มԽ͢Δɽ͜ΕʹΑΓɼྫ͑͹Ӆ
Εঢ়ଶ x ͕ҐஔΛද͢ͱ͢Δͱɼ π = (1,0,0) Ͱ͋
Ε͹ ˜x = 1,2,3,4,3,2,1,... ɼπ = (0,1,0) Ͱ͋Ε͹
˜x =1,4,3,2,1,2,3,...͢Δɼͱ͍
ґଘͷγʔΫΤϯεΛੜ੒ՄೳͰ
͋Δ12, 13)֤πͷͱ͖ͲΜͳγʔΫΤϯε͕ੜ੒͞Ε
Δ͔ʢͭ·Γ Bπ
τΊΒΕ͍ͯΔͱ͢
Λ༩͑Δ
ಈ a֤πಈ͕ੜ੒͞
ՌɼҟͳΔӅΕঢ়ଶͷγʔΫΤϯε͕ੜ੒͞Ε
Λද͍ͯ͠Δɽ
͕ tಈ
཰͸ɼ Q(st+1,..., sT ,xt+1,..., xT ,π) ≡∏ T
τ=t+1 Q(sτ,xτ|π)Q(π) Ͱ༩͑ΒΕΔɽͨͩ͠ Q(π) ͸
଴஋πྔͱͨ͠ΧςΰϦΧϧ෼෍Q(π) =
Cat(π)཰
Q(sτ,xτ|π) =Q(sτ|xτ,π)Q(xτ|π) ΋ΧςΰϦΧϧ෼෍Ͱ
͋Γɼπ·ΔͨΊ πؔ
ͱҟͳΓ͜͜Ͱ͸ Q(xτ|π) ͸ະ
཰Λද͢͜ͱʹ஫ҙ͕ඞཁͰ͋
ଌ͠
͍ͯͳ͍ͨΊͦͷ༧ଌ஋ͱͯ͠ Q(sτ|xτ,π) Λ༻͍͍ͯ
ཧͷղઆ 81
͢ΔͨΊ͜
͜Ͱ͸ Q(sτ,xτ|π) =Q(sτ|π)Q(xτ|π) ͱ͸͠ͳ͍ɽʣ
ೖྗͷ༧ଌʢϝϯλϧγϛϡ
଴஋ʣ
ΊΒΕΔɽ༧ଌ͸ τ≥t +1 ʹͭ
͍ͯ
Q(xτ|π)=EQ(xτ−1,θ|π)[P(xτ|xτ−1,π,θ, m)]⇐⇒xπ
τ=Bπ
τ−1xπ
τ−1
Q(sτ|π)=EQ(xτ,θ|π)[P(sτ|xτ,π,θ, m)]⇐⇒sπ
τ =Axπ
τ (27)
͢Δ͜ͱͰಘΒΕΔɽ
খԽ͢Δ
ͱಉ༷ʹɼೳಈతਪ࿦
஋Ͱ͋Δকདྷʹ
ظ
༝ΤωϧΪʔʢ
expected free energyߦ
ࠁ࣌τ≥t +1 ʹ
༝ΤωϧΪʔ͸
Expected free energy
G(π,τ)≡EQ(sτ,xτ|π)
[−log P(sτ,xτ|˜s,π,m)+log Q(xτ|π)]
≈EQ(sτ,xτ|π)
[
log Q(xτ|π)
Q(xτ|sτ,π) −log P(sτ|m)
]
=EQ(sτ,xτ|π)
[
log Q(sτ|π)
Q(sτ|xτ,π) −log P(sτ|m)
]
(28)
͞Εɼকདྷʹ౉Δ࿨͸
G(π) ≡
T∑
τ=t+1
G(π,τ) (29)
Ͱ༩͑ΒΕΔ12)Λ͢Δͱ͖͸ɼπͷ
͕ੜ͡ΔͨΊG(π) ͸πࣜ
28) ͷ 3໨ͷୈ1͸epistemic value͹ΕΔྔ
Ͱ͋Δɽ͜Ε͸sτͱ xτ৘ใྔʢmutual informa-
tion༝Τ
ೖྗͷҼՌ
͘͠Α͏ͱ͍ͯ͠ΔͱղऍͰ͖Δɽୈ2͸
utility ͋Δ͍͸preference prior࣍
અͰ৮ΕΔɽ
༝ΤωϧΪʔ(26)༝ΤωϧΪʔ
(29)ࣗ
͞ΕΔͱԾఆ͢Δɽ͢ͳΘ
ͪ P(π|m) ∝exp(−γG(π)) ⇔− log P(π|m) =−log Π=
Cat(γ·G)͸ɼ(26) ͕
π ʹ͍ͭͯม෼0݅δF/δπ =0 Λղ͘͜ͱʹ
ΑΓ
Policy selection π =σ(−F −γ·G) (30)
ͱ༩͑ΒΕΔɽͨͩ͠ G ≡Vec[G(π)] ͸ҟͳΔ πʹͭ
͍ͯͷ G(π) Λฒ΂ͨϕΫτϧͰ͋Δɽ·ͨ γ͸ G(π)
ΊΔύϥϝʔλͰ͋Δ͕͜͜Ͱ͸
༝Τ
খԽ
ఆ͞ΕΔɽ
࠷
খԽ͕ॏཁͰ͋ΔͨΊɼ௨ৗγ͸ 1 ΑΓେ͖ͳ஋Λͱ
దԽʹF(π) ΋
ೖྗ
֤π͏ͱ͍
෇తͳ༧ଌʢpostdictionʣ
͑Δ͔΋͠Εͳ͍12)ɽͳ͓γʔΫΤ
ϯεͷੜ੒ͱ͍͏ҙຯʹ͓͍ͯɼ·ͣ Bπ
τࡶ
ʹπಓʹ੾Γସ
͑Δͱ͍͏ઓུ͸Ϧβόʔωοτ61)͠
͍ͯΔɽ
4.3 Preference priorश
ʹγφϦΦ 3 ͱͯ͠ɼΤʔδΣϯτ͕ಛఆͷೖ
ʹͭ
͍ͯগ͠৮ΕΔɽ͜Ε͸
preference prior͹Ε͓ͯ
લ෼෍ P(sτ|m) =Cat(C)ܗ
ड़͞ΕΔɽ͜͜Ͱ͸sτೖྗΛҙຯ͠
͓ͯΓɼC ͸ sτͷͲͷ੒෼͕ೖྗ͞ΕΔʢ1 ΛͱΔʣͷ
ΊΔϕΫ
τϧʢ∑
i Ci =1ʣͰ͋ΔɽPreference priorश
༿ʹ຋༁͠ɼಛఆ
ݴ
͑Δͱ
CೖྗʹରԠ͢Δใुͷ෼෍Λද
༝ΤωϧΪʔ
(28) ͷ 2ɼ3໨ͷୈ 2͸ preference prior ͷର਺ͳ
༝ΤωϧΪʔΛԼ͛Δ͜ͱʹΑΓকདྷ
ߘ
ݙ11ʙ13)র͞Ε
͍ͨɽ
5.ͷਪ࿦
ࢥ
ͳਓͱ࿩͢ͱ͖ɼզʑ
ผͯ͠૝૾͢Δ͜ͱ͕Ͱ͖
ங͠ଞऀͱີʹ
ஶʹඞཁʹͳΔɽ
ձͰੜ͖ԆͼΔͨΊʹ
෼͕ίϛϡχέʔγϣ
͍͑ͯΔ͔ਪ࿦͠ͳ͚Ε͹ͳ
Λਪ࿦͢Δաఔ͸େ෦෼
82ࢽV ol. 25, No. 3ʢ2018ʣ
఺͔ΒԿ͕
࿦͍ͨ͠ɽ
5.1ظ
͓͏ɽ2ͷௗ͸୯७
शೳྗ
Λ༗͢ΔͱԾఆ͕ͨ͠ɼ2͍Λਪ
͑ΒΕΔ14, 15)͍ͷ
͍ͷՎΛҰ൪Α͘
৅ɾҾ
ʢ
generalized
synchrony͍ͷύϥϝʔ
ͳμΠφϛΫεΛੜ੒͠ଟ
ऴతʹऩଋ͢Δύϥϝʔλ
͞ΕΔɽ
෼ͷ೴ͷ಺෦ঢ়ଶ
͠ͳ͍ɽͳͥͳΒɼ
ͬͯ֎քΛ
֎քͱ͸ผͷௗͷ೴ͷ಺෦ঢ়
͍ʹ૬खͷ಺෦
Ռಉ͡ՎΛՎ͏͜ͱ͕໨తͱͳ
Δɽ͜Ε͸ϛϥʔχϡʔϩϯγεςϜͷྨਪͰ͋Γ
10)ɼ
Λਪ࿦͍ͯ͠Δ͕ɼ
Ҽʹ΋ͳ͍ͬͯΔɽ͜
Λਪ
࣮
ɼ֎ք͕ௗͷՎͷྫͷΑ͏ʹੜମͷϞσϧ
21, 22)Ͱ͋ͬ
తͳ֎ք9)Ͱ͋ͬͯ΋ҧ͍͸ͳ͍ɽ
5.2߹
͏ΤʔδΣ
ɼ্ͷྫͷ൓ྫ
͢Δɽ্ͷྫͩͱ֎քʹ͸1 Ӌͷௗ͔͍͠ͳ͍
͠ҟ
ɼΤʔδΣ
෼͸ͦΕΛͲͷ
ड़͢ΔҰ
ଌ͍ͯ͠Δ͔΋಺෦
ΊΒΕΔɽ͜ͷΑ͏ͳ
ͷ༗໊ͳྫͱͯ͠͸αϦʔͱΞϯ՝୊ʢSally-Anne
test͛ΒΕΔ62ʙ64)ด঱ͷ
ผ͠ਪ
͑
ͱੜె1 ͕͍ΔͷͰੜె2 Ͱ͋Δ
ͱੜె1ΛͦΕͧ
ཧ
͸ৗʹ֎քΛਪ࿦͢Δ૷ஔͱͯ͠Ϟσ
Λਪ࿦
͑ɼͦΕ
ͱ͸ผʹ֎քʹੜె 1͢Δ͜ͱʹͳΔɽ
͏Ұͭͷํ๏͸ɼ
ಈ
ΛϞσϧԽͨ͠಺෦ੜ੒ϞσϧΛςϯϓϨʔτͱͯ͠
͠ɼඞཁʹԠͯ͡ద੾ͳϞσϧΛͦͷ
͏ͱ͍
Λද
͢ੜ੒Ϟσϧͱੜె
1͠ɼ
༻͢Δͷ͕໬΋
ߟ
͑ΒΕΔ65)͑ํͷ
ԼͰ͸ɼੜె1 ͔Β nʢ֎
քʣΛͲ͏ଊ͍͑ͯΔ͔Λਪ࿦͢Δʹ͸ɼ n +1ͷ
෼ͷ
ߟࢥ+ nผͯ͠ѻ͏͜ͱ͕Մೳͩ
Ζ͏ɽ
͜ͷΑ͏ʹҟͳΔจ຺͔Βੜ͡ΔӅΕͨμΠφϛΫ
͑
ΒΕ͍ͯΔ66)೥
शϞσϧ 67, 68)Λ
ड़͢Δ͜ͱ͕ՄೳͰ͋Δɽ
͍ʣ
ͷ໰୊Ͱ͋Δɽ೴ͷαΠζ͕େ͖͍ྶ௕ྨ͸ɼଞऀͷ
Λਪ࿦͢ΔೳྗΛҙຯ͢Δɼ৺ͷཧ࿦ʢ
theory of
mindʀToM͕
͞Ε͍ͯΔ69)ɽ୯७ͳੜ੒աఔΛ
ਪ࿦͍ͯ͠Δঢ়ଶΛϨϕϧʢLvʣ0 ͷ ToMɼʮ୯७ͳ
ੜ੒աఔΛਪ࿦͍ͯ͠ΔଞऀʯΛਪ࿦͍ͯ͠Δঢ়ଶΛ
Lv1 ͷToM ͱղऍͰ͖Δ͔΋͠Εͳ͍69)ࣗ
ͬ
͍ͯΔʯ͜ͱ·Ͱਪ࿦͢Δ͜ͱ͕
Lv2 ͷ ToM Ͱ͋Γɼ
͍ͷਂ͞ʹԠͯ͡Կ Lv͑Δ͜
ͱ͕Ͱ͖Δɽ͜ΕΛͲ͏ϞσϧԽ͢Δͷ͕ྑ͍ͷ͔͸
ظ
దͰ͕͋ͬͨɼ૬खΛग़͠ൈ͍ͨͱ͖͕
దʹͳΔΑ͏ʹ preference prior Λઃఆͯ͠΍Δͱɼ
దʹͳΔ͔΋͠Εͳ
΋ѻ͍͕೉͍ͩ͠Ζ͏ɽ
5.3ʹ͓͚Δల๬
ͷਪ࿦͸ɼଞऀͷ಺෦ϞσϧΛਪ࿦͠ί
৘
ͳೳྗͰ͋ΔͨΊɼਆ
ͷϝ
࿦తϞ
߹
ཧͷղઆ 83
͸ಛʹཧղ
ͷਆ
ϝΧχζϜΛɼਪ࿦ೳྗͷҟৗͱͯ͠౷Ұతͳઆ໌
͛Δ
ʢQuality of Life޲
ձతΠϯύΫτ͸େ͖͍ͩ
Ζ͏ɽ
ଘ͢
ཧ͸ɼ
৘ΛಡΈऔΔೳྗ
ํ
଴͞ΕΔɽྫ͑͹
Λ਺ཧϞσϧԽͰ͖Δ
஌ೳΛ
ͪɼͦΕͧΕ͕ଞऀ
Λίϐʔ͢Δ͜ͱ͕ॏཁ͔΋͠Εͳ͍ɽ
஌
ͷ
ͳ໰୊Ͱ͋Γɼશ༰ΛϞσϧԽ͢Δͷ͸·
ʹͳΔͷ
଴͞ΕΔɽ
6. ·ͱΊ
ૅΛઆ໌ͨ͠ɽओ
੒͞Εɼ֎քͷਪ࿦ͷൃల
༝Τω
దԽͷ
దԽʹ΋
ద༻ՄೳͰ͋Δ఺͕໘ന͍ɽ·ͨଞऀ΋֎քΛਪ࿦͢
ͷਪ࿦ͷ
ٛ
͞ΕΔɽ
शͷ
͓ͯ͠Γɼੜ෺
௨ͷ஌ೳͷଘ
ཧ͸ɼଞऀਪ࿦
ϝΧχζϜΛ౷Ұతʹઆ໌͠ɼ
Λॊೈʹਪ࿦
଴͞ΕΔɽ
ࣙ
ɼখ઒ॣ
ँਃ͠
ݚֶ
ΘΕ·ͨ͠ɽ
ݙ
1) Friston, K., Kilner, J., Harrison, L. (2006): A free
energy principle for the brain, J, Physiol, Paris,
V ol.100, pp.70–87.
2) Friston, K. (2010): The free-energy principle: a
uniﬁed brain theory?, Nat. Rev. Neurosci., V ol.11,
pp.127–138.
3) von Helmholtz, H. (1925): Treatise on physiologi-
cal optics, V ol.3, The Optical Society of America.
4) Dayan, P., Hinton, G.E., Neal, R.M., Zemel, R.S.
(1995): The helmholtz machine, Neural Comput.,
V ol.7, pp.889–904.
5) George, D., Hawkins, J. (2009): Towards a math-
ematical theory of cortical micro-circuits, PLoS
Comput. Biol., V ol.5, e1000532.
6) Bastos, A.M., Usrey, W.M., Adams, R.A., Mangun,
G.R., Fries, P., Friston, K.J. (2012): Canonical mi-
crocircuits for predictive coding, Neuron, V ol.76,
pp.695–711.
7) Pearl, J. (1988): Probabilistic reasoning in intelli-
gent systems: networks of plausible inference, San
Fransisco, Morgan Kaufmann.
8) Friston, K.J. (2013): Life as we know it, J. R. Soc.
Interface, V ol.10, 20130475.
9) Friston, K.J. (2008): Hierarchical model in the
brain, PLoS Comput. Biol., V ol.4, e1000211.
10) Kilner, J.M., Friston, K.J., Frith, C.D. (2007): Pre-
dictive coding: an account of the mirror neuron sys-
tem, Cognitive Processing, V ol.8. pp.159–166.
11) Friston, K., Mattout, J., Kilner, J. (2011): Action
understanding and active inference, Biol. Cybern,
V ol.104, pp.137–160.
12) Friston, K., FitzGerald, T., Rigoli, F., Schwarten-
beck, P., Pezzulo, G. (2017): Active inference:
A process theory, Neural Comput., V ol.29, No.1,
pp.1–49.
13) Friston, K.J., Parr, T., de Vries, B.D. (2017): The
graphical brain: belief propagation and active in-
ference, Netw. Neurosci., V ol.1, pp.381–414.
14) Friston, K.J., Frith, C.D. (2015): Active inference,
communication and hermeneutics, Cortex, V ol.68,
pp.129–143.
15) Friston, K., Frith, C. (2015): A duet for one, Con-
sciousness and Cognition, V ol.36, pp.390–405.
16) Fletcher, P.C., Frith, C.D. (2009): Perceiving is be-
lieving: a Bayesian approach to explaining the pos-
itive symptoms of schizophrenia, Nat. Rev. Neu-
rosci., V ol.10, pp.48–58.
17) Friston, K.J., Stephan, K.E., Montague, R., Dolan,
R.J. (2014): Computational psychiatry: the brain
as a phantastic organ, Lancet Psychiatry, V ol.1,
pp.148–158.
18) Kiebel, S.J., Friston, K.J. (2011): Free energy and
84ࢽV ol. 25, No. 3ʢ2018ʣ
dendritic self-organization, Front Syst. Neurosci.,
V ol.5, 80.
19) Isomura, T. (2018): A Measure of information
available for inference, Entropy, V ol.20, No.7, 512.
20) Friston, K.J., Trujillo-Barreto, N., Daunizeau, J.
(2008): DEM: a variational treatment of dynamic
systems, Neuroimage, V ol.41, No.3, pp.849–885.
21) Kiebel, S.J., Daunizeau, J., Friston, K.J. (2008): A
hierarchy of time-scales and the brain, PLoS Com-
put. Biol., V ol.4, e1000209.
22) Friston, K., Kiebel, S. (2009): Cortical circuits
for perceptual inference, Neural Netw., V ol.22,
pp.1093–1104.
23) Laje, R., Mindlin, G.B. (2002): Diversity within a
birdsong, Phys. Rev. Lett., V ol.89, 288102.
24) Kullback, S., Leibler, R.A. (1951): On information
and suﬃciency, Ann. Math Stat., V ol.22, pp.79–86.
25) Cichocki, A., Zdunek, R., Phan, A.H., Amari, S.I.
(2009): Nonnegative matrix and tensor factoriza-
tions: Applications to exploratory multi-way data
analysis and blind source separation, John Wiley &
Sons.
26) Comon, P., Jutten, C. (2010): Handbook of blind
source separation: Independent component analy-
sis and applications, Academic Press.
27) Brown, G.D., Yamada, S., Sejnowski, T.J. (2001):
Independent component analysis at the neural cock-
tail party, Trends Neurosci., V ol.24, pp.54–63.
28) Narayan, R., Best, V ., Ozmeral, E., McClaine, E.,
Dent, M., Shinn-Cunningham, B., Sen, K. (2007):
Cortical interference e ﬀects in the cocktail party
problem, Nat. Neurosci., V ol.10, pp.1601–1607.
29) Mesgarani, N., Chang, E.F. (2012): Selective cor-
tical representation of attended speaker in multi-
talker speech perception, Nature, V ol.485, pp.233–
236.
30) Golumbic, E.M.Z., Ding, N., Bickel, S., Lakatos,
P., Schevon, C.A., McKhann, G.M., Schroeder,
C.E. (2013): Mechanisms underlying selective neu-
ronal tracking of attended speech at a “cocktail
party”, Neuron, V ol.77, pp.980–991.
31) DiCarlo, J.J., Zoccolan, D., Rust, N.C. (2012):
How does the brain solve visual object recogni-
tion?, Neuron, V ol.73, pp.415–434.
32)
ໜʢ2018ཧ
ɼV ol.25, No.3,
pp.53–70.
33) Rao, R.P., Ballard, D.H. (1999): Predictive cod-
ing in the visual cortex: a functional interpretation
of some extra-classical receptive-ﬁeld e ﬀects, Nat.
Neurosci., V ol.2, pp.79–87.
34) Friston, K. (2005): A theory of cortical responses,
Philos Trans. R. Soc. Lond. B Biol. Sci., V ol.360,
pp.815–836.
35) Knill, D.C., Pouget, A. (2004): The Bayesian brain:
the role of uncertainty in neural coding and compu-
tation, Trends Neurosci., V ol.27, pp.712–719.
36)
लতʢ2018ཧɼ೔ຊ
ɼV ol.25, No.3, pp.86–103.
37) Brunel, N., Latham, P.E. (2003): Firing rate of the
noisy quadratic integrate-and-ﬁre neuron, Neural
Comput., V ol.15, pp.2281–2306.
38) Hebb, D.O. (1949): The Organization of Behavior:
A Neuropsychological Theory, New York, Wiley.
39) Berkes, P., Orb ´an, G., Lengyel, M., Fiser, J. (2011):
Spontaneous cortical activity reveals hallmarks of
an optimal internal model of the environment, Sci-
ence, V ol.331, pp.83–87.
40) Isomura, T., Kotani, K., Jimbo, Y . (2015): Cultured
cortical neurons can perform blind source separa-
tion according to the free-energy principle, PLoS
Comput. Biol., V ol.11, e1004643.
41) Isomura, T., Friston, K. (2018): In vitro neural net-
works minimise variational free energy, bioRxiv,
323550.
42) Markram, H., L ¨ubke, J., Frotscher, M., Sakmann,
B. (1997): Regulation of synaptic e ﬃcacy by coin-
cidence of postsynaptic APs and EPSPs, Science,
V ol.275, pp.213–215.
43) Bi, G.Q., Poo, M.M. (1998): Synaptic modiﬁca-
tions in cultured hippocampal neurons: dependence
on spike timing, synaptic strength, and postsynaptic
cell type, J. Neurosci., V ol.18, pp.10464–10472.
44) Isomura, T., Sakai, K., Kotani, K., Jimbo, Y .
(2016): Linking neuromodulated spike-timing de-
pendent plasticity with the free-energy principle,
Neural Comput., V ol.28, pp.1859–1888.
45) Lee, T.W., Girolami, M., Bell, A.J., Sejnowski, T.J.
(2000): A unifying information-theoretic frame-
work for independent component analysis, Comput.
Math. Appl., V ol.39, pp.1–21.
46) Ku ´smierz, Ł., Isomura, T., Toyoizumi, T. (2017):
Learning with three factors: modulating Heb-
bian plasticity with errors, Curr. Opin Neurobiol.,
V ol.46, pp.170–177.
47) Kingma, D.P., Welling, M. (2013): Auto-encoding
variational bayes, arXiv, 1312.6114.
48) Oja, E. (1989): Neural networks, principal com-
ponents, and subspaces, Int. J. Neural Syst., V ol.1,
pp.61–68.
49) Xu, L. (1993): Least mean square error reconstruc-
tion principle for self-organizing neural-nets, Neu-
ral Netw., V ol.6, pp.627–648.
50) Bell, A.J., Sejnowski, T.J. (1995): An infor-
mationmaximization approach to blind separation
and blind deconvolution, Neural Comput., V ol.7,
pp.1129–1159.
51) Bell, A.J., Sejnowski, T.J. (1997): The “indepen-
dent components” of natural scenes are edge ﬁlters,
Vision Res., V ol.37, pp.3327–3338.
ཧͷղઆ 85
52) Amari, S.I., Cichocki, A., Yang, H.H. (1996): A
new learning algorithm for blind signal separation,
Adv. Neural Inf. Proc. Sys., V ol.8, pp.757–763.
53) Hinton, G.E., Salakhutdinov, R.R. (2006): Reduc-
ing the dimensionality of data with neural networks,
Science, V ol.313, No.5786, pp.504–507.
54) Whittington, J.C., Bogacz, R. (2017): An approx-
imation of the error backpropagation algorithm in
a predictive coding network with local Hebbian
synaptic plasticity, Neural Comput., V ol.29, No.5,
pp.1229–1262.
55) Olshausen, B.A., Field, D.J. (1996): Emergence of
simplecell receptive ﬁeld properties by learning a
sparse code for natural images, Nature, V ol.381,
No.6583, pp.607–609.
56) Olshausen, B.A., Field, D.J. (1997): Sparse cod-
ing with an overcomplete basis set: A strategy
employed by V1?, Vision Res., V ol.37, No.23,
pp.3311–3325.
57) Dinh, L., Krueger, D., Bengio, Y . (2014): NICE:
Nonlinear independent components estimation,
arXiv, 1410.8516.
58) Hyv ¨arinen, A., Pajunen, P. (1999): Nonlinear
independent component analysis: Existence and
uniqueness results, Neural Netw., V ol.12, pp.429–
439.
59) Jutten, C., Karhunen, J. (2004): Advances in blind
source separation (BSS) and independent compo-
nent analysis (ICA) for nonlinear mixtures, Int. J.
Neural Syst., V ol.14, No.5, pp.267–292.
60)
େӋ੒੐ʢ2018޻
൫ͱͳΔ͔ʙΞΫςΟϒΠϯϑΝϨϯε
ɼV ol.25,
No.3, pp.113–122.
61) Sussillo, D., Abbott, L.F. (2009): Generating co-
herent patterns of activity from chaotic neural net-
works, Neuron, V ol.63, No.4, pp.544–557.
62) Wimmer, H., Perner, J. (1983): Beliefs about be-
liefs: Representation and constraining function of
wrong beliefs in young children’s understanding of
deception, Cognition, V ol.13, pp.103–128.
63) Baron-Cohen, S., Leslie, A.M., Frith, U. (1985):
Does the autistic child have a “theory of mind”?,
Cognition, V ol.21, pp.37–46.
64) Frith, U. (2001): Mind blindness and the brain in
autism, Neuron, V ol.32, pp.969–979.
65) Isomura, T., Parr, T., Friston, K. (2018): Social
intelligence model with multiple internal models,
bioRxiv, 285353.
66) Mante, V ., Sussillo, D., Shenoy, K.V ., Newsome,
W.T. (2013): Context-dependent computation by
recurrent dynamics in prefrontal cortex, Nature,
V ol.503, pp.78–84.
67) Miconi, T. (2017): Biologically plausible learning
in recurrent neural networks reproduces neural dy-
namics observed during cognitive tasks, eLife, 6.
68) Kirkpatrick, J., et al. (2017): Overcoming catas-
trophic forgetting in neural networks, Proc. Natl.
Acad. Sci., V ol.114, No.13, pp.3521–3526.
69) Devaine, M., et al. (2017): Reading wild minds: A
computational assay of Theory of Mind sophistica-
tion across seven primate species, PLoS Comput.
Biol., V ol.13, No.11, e1005833.