Vol.:(0123456789)
European Journal of Applied Physiology (2025) 125:2643–2677 
https://doi.org/10.1007/s00421-025-05855-6
INVITED REVIEW
The myth of the Bayesian brain
Madhur Mangalam1 
Received: 24 April 2025 / Accepted: 31 May 2025 / Published online: 26 June 2025 
© The Author(s) 2025
Abstract
The Bayesian brain hypothesis—the idea that neural systems implement or approximate Bayesian inference—has become a 
dominant framework in cognitive neuroscience over the past two decades. While mathematically elegant and conceptually 
unifying, this paper argues that the hypothesis occupies an ambiguous territory between useful metaphor and testable, biologi-
cally plausible mechanistic explanation. We critically examine the key claims of the Bayesian brain hypothesis, highlighting 
issues of unfalsifiability, biological implausibility, and inconsistent empirical support. The framework’s remarkable flexibility 
in accommodating diverse findings raises concerns about its explanatory power, as models can often be adjusted post hoc to 
fit virtually any data pattern. We contrast the Bayesian approach with alternative frameworks, including dynamic systems 
theory, ecological psychology, and embodied cognition, which conceptualize prediction and adaptive behavior without 
recourse to probabilistic inference. Despite its limitations, the Bayesian brain hypothesis persists—driven less by empirical 
grounding than by its mathematical elegance, metaphorical power, and institutional momentum.
Keywords Bayesian brain hypothesis · Predictive coding · Free energy principle · Cognitive neuroscience · Theoretical 
neuroscience · Embodied cognition · Philosophy of neuroscience · Dynamic systems theory · Unfalsifiability
The Bayesian boom
Every scientific revolution begins with elegant equa-
tions promising certainty, continues with increasingly 
baroque modifications to account for anomalies, and 
ends with a crowded citation list defending mathemati-
cal fictions that never quite mapped to biological real-
ity.
The Bayesian brain hypothesis represents one of the most 
influential frameworks in contemporary cognitive science 
and neuroscience, having emerged as a dominant paradigm 
that has fundamentally reshaped how we conceptualize neu-
ral function (Doya 2007; Friston 2010; Knill and Pouget 
2004). At its core lies a deceptively simple yet profound 
premise: the brain functions primarily as a sophisticated pre-
diction machine that uses Bayesian inference to interpret 
sensory information and continuously update internal mod-
els of the world (Friston 2005; Lee and Mumford 2003; Rao 
and Ballard 1999). According to this perspective, neural 
processing is fundamentally concerned with minimizing 
prediction errors through probabilistic inference—essen-
tially implementing something akin to Bayes’ theorem at 
various levels of neural organization, from individual cells to 
large-scale networks (Bogacz 2017; Friston 2010; Ma et al. 
2006). This view constitutes a radical departure from tradi-
tional stimulus–response models by positioning the brain 
as an active, hypothesis-testing organ rather than a passive 
receiver of sensory information (Clark 2015; Friston 2010; 
Gregory 1980). This paradigm shift has sparked widespread 
enthusiasm and growing controversy, raising questions about 
whether the Bayesian brain is a genuine mechanistic account 
or merely a compelling metaphor (Bowers and Davis 2012; 
Colombo and Seriès 2012; Jones and Love 2011).
The intellectual lineage of this approach can be traced 
back to Helmholtz’s notion of perception as unconscious 
inference, but its modern formulation and meteoric rise 
to prominence occurred primarily during the early 2000 
s. Building on earlier computational approaches to cogni-
tion, researchers like Karl Friston, Geoffrey Hinton, and 
Andy Clark have developed increasingly sophisticated 
Communicated by Michalis G Nikolaidis.
 * Madhur Mangalam 
 mmangalam@unomaha.edu
1 Division of Biomechanics and Research Development, 
Department of Biomechanics, Center for Research in Human 
Movement Variability, Omaha, NE 68182, USA
2644 European Journal of Applied Physiology (2025) 125:2643–2677
mathematical models that describe perception, action, and 
learning in Bayesian terms. Friston’s Free Energy Principle 
(FEP) and its corollary, active inference, represents perhaps 
the most ambitious extension of this approach, aiming to 
derive principles of neural organization from thermodynam-
ics and information theory. Meanwhile, Clark’s influential 
“whatever next” paper positioned predictive processing as a 
potential “grand unified theory of the brain,” while Hinton’s 
work on generative models established crucial connections 
between Bayesian frameworks and neural network imple -
mentations. Together, these researchers and many others 
have transformed what began as a specialized approach in 
vision research into an expansive paradigm that now encom-
passes virtually all domains of cognition.
The explanatory scope of the Bayesian brain hypothesis 
has expanded at a remarkable pace, extending beyond per -
ception to encompass action, attention, learning, decision-
making, and even psychiatric disorders. What makes this 
framework particularly appealing is its mathematical ele-
gance and apparent unifying power—it promises to provide 
a common language and set of computational principles that 
bridge traditionally separate domains of neurobiology, psy-
chology, and psychiatry under a single coherent framework. 
For example, conditions like schizophrenia have been rein-
terpreted as disorders of precision-weighting in hierarchi-
cal predictive coding networks, while phenomena like the 
placebo effect have been reconceptualized as manifestations 
of strong perceptual priors influencing bodily states. This 
expansive reach has elevated the Bayesian brain from merely 
another theory of neural function to a paradigm-defining 
framework that shapes research questions, experimental 
designs, and interpretations across multiple fields. Yet, this 
very expansiveness—its capacity to explain nearly every -
thing—has led some to question whether the Bayesian brain 
risks becoming a theory of everything that, paradoxically, 
explains nothing in a scientifically constraining way.
These concerns are not unprecedented. A growing body 
of critical scholarship has questioned the empirical, mecha-
nistic, and conceptual foundations of Bayesian frameworks 
in cognitive science and neuroscience. For example, Bowers 
and Davis (2012) warned that many Bayesian models are too 
flexible to be falsifiable and often rely on post hoc parameter 
fitting rather than making risky predictions. Jones and Love 
(2011) argued that rational Bayesian models are typically 
underconstrained, often neglect mechanistic specificity, and 
risk functioning as metaphors rather than scientific theories. 
Colombo and Seriès (2012) further noted that many such 
models serve primarily as descriptive tools and lack cor -
respondence with identifiable neural mechanisms, making 
the inference from Bayesian behavior to Bayesian brains 
highly tenuous. Other critiques have highlighted the diffi-
culty of empirically constraining priors and loss functions 
in perceptual models (Colombo 2018), and the problematic 
metaphysical overreach of the Free Energy Principle in its 
attempts to explain life, cognition, and action through a sin-
gle variational formalism (Colombo and Wright 2021). Most 
directly aligned with our critique, Williams ( 2018); Wil -
liams and Colling (2018); Williams (2020) argued that the 
FEP’s universal scope and mathematical generality render 
it effectively unfalsifiable. His work has specifically shown 
that FEP avoids empirical refutation by shifting interpre -
tive ground across levels of analysis. Our work builds on 
these critiques by systematically analyzing how rhetorical 
strategies, metaphor–mechanism slippage, and institutional 
incentives have jointly reinforced the persistence of an unfal-
sifiable and biologically implausible framework.
The mathematical sophistication of Bayesian approaches 
has lent them considerable prestige within the increasingly 
computational landscape of neuroscience. Complex behav -
iors and neural responses can be formalized in terms of 
probability distributions, likelihood functions, and prior 
beliefs—bringing a satisfying rigor to domains previously 
characterized by descriptive or phenomenological accounts. 
This quantitative precision allows researchers to derive 
specific, testable predictions and to fit complex models to 
behavioral and neural data. The approach’s success in mod-
eling certain perceptual phenomena—such as visual illu -
sions, multisensory integration, and context effects—has 
bolstered confidence in its broader applicability, leading to 
what might fairly be called a “Bayesian boom” in neuro-
scientific research. However, this surge in popularity also 
raises important questions about whether the mathematical 
elegance of Bayesian models is being mistaken for empirical 
adequacy or mechanistic insight.
Despite its undeniable popularity and apparent 
explanatory power, this paper argues that the Bayesian 
brain hypothesis occupies an ambiguous conceptual territory 
between useful metaphor and legitimate mechanistic 
explanation. While it has undoubtedly generated productive 
research programs and compelling interpretations of 
neural function, its status as an explanatory theory remains 
deeply problematic when subjected to critical scrutiny. 
The challenge is not merely technical but conceptual—
concerning the very nature of scientific explanation in 
neuroscience and what constitutes a satisfactory account of 
neural function. The following sections will demonstrate that 
when pressed on its mechanistic claims, proponents of the 
Bayesian brain often retreat to metaphor or abstraction; when 
challenged on its metaphorical looseness, they reassert its 
mechanistic aspirations and point to implementation details. 
This conceptual slippage, I argue, threatens the scientific 
integrity of the approach and requires critical examination 
to assess whether it genuinely explains brain function or 
merely sustains the appearance of explanation—whether it 
remains a viable model or has already crossed the line into 
scientific myth.
2645European Journal of Applied Physiology (2025) 125:2643–2677 
The Bayesian perspective has also transformed how we 
understand the relationship between brain, body, and envi-
ronment (Allen and Friston 2018 ; Clark 2015 ; Kirchhoff  
and Kiverstein 2019). By framing perception as inference 
and action as a means of testing perceptual hypotheses, it 
challenges traditional boundaries between sensing and doing 
(Clark 2013; Hohwy 2013; Seth 2014). This has profound 
implications for how we conceptualize embodied cognition 
and the extended mind—suggesting that the brain’s primary 
purpose is not to represent the world accurately but to facili-
tate successful interaction with it through prediction (Clark 
2015; Gallagher and Allen 2018; Kirchhoff 2018). Yet this 
reformulation, however compelling, raises profound ques-
tions about implementation: how could neural tissue actually 
encode probability distributions, perform Bayesian updates, 
or represent precision estimates (Fiser et al. 2010; Pouget 
et al. 2013; Sanborn and Chater 2016)? These questions of 
biological plausibility stand in tension with the framework’s 
mathematical elegance, creating a gap between theoretical 
aspiration and mechanistic reality that remains inadequately 
addressed in much of the literature (Bowers and Davis 2012; 
Nelson et al. 2018; Williams and Colling 2018).
Moreover, the social dynamics of scientific research have 
contributed to the framework’s rapid ascendancy (Kuhn 
1962; Latour 1987; Smaldino and McElreath 2016). The 
Bayesian approach offers researchers powerful mathematical 
formalisms, computational models, and a common vocabu-
lary that facilitates collaboration across disciplines (Clark 
2013; Griffiths et al. 2010; Hohwy 2013). Career incen-
tives reward those working within influential paradigms, 
and funding agencies often prioritize research that builds 
on established frameworks rather than those that challenge 
them fundamentally (Nelson et al. 2018; Romero 2017; 
Smaldino and McElreath 2016). These sociological factors, 
while external to the scientific content of the theory itself, 
nevertheless, shape how the Bayesian brain hypothesis has 
been developed, evaluated, and institutionalized within neu-
roscience (Kuhn 1962; Latour 1987; Longino 2020). Under-
standing these dynamics is crucial for assessing not just 
the theory’s truth but its persistence and influence despite 
significant conceptual and empirical challenges (Ioannidis 
2005; Smaldino and McElreath 2016).
These considerations raise deep concerns about the 
explanatory coherence and empirical viability of the 
Bayesian brain hypothesis. Despite its widespread adoption 
and mathematical sophistication, the framework often 
oscillates between metaphor and mechanism, adapting 
flexibly to accommodate contradictory findings without clear 
constraints. Its ability to unify diverse domains has become 
both its greatest strength and its most serious vulnerability. 
What appears at first as theoretical elegance may, on closer 
inspection, reflect a troubling looseness of formulation—one 
that undermines the framework’s explanatory coherence and 
opens the door to uncritical adoption. To assess its actual 
scientific value, we must rigorously investigate its conceptual 
commitments, empirical support, and biological plausibility.
While this paper aims to provide a rigorous philosophical 
and scientific critique of the Bayesian brain hypothesis and the 
FEP, we acknowledge that some of the language may strike 
readers as unusually direct. This is intentional. The rhetorical 
tone—at times pointed or sharply critical—is meant to reflect 
the seriousness of the epistemological and institutional issues 
at stake. Specifically, we aim to highlight how certain theoreti-
cal frameworks can achieve disproportionate influence despite 
persistent conceptual and empirical shortcomings. This style 
follows a long tradition in philosophy of science, where direct 
critique is often necessary to expose unfalsifiable or over -
extended explanatory systems that resist correction through 
standard empirical means. Rather than targeting individuals 
or communities, the tone is directed at systemic tendencies in 
contemporary neuroscience to conflate metaphor with mecha-
nism, and mathematical elegance with biological plausibility. 
We have nonetheless taken care to revise language where it 
may have been overly dismissive or needlessly inflammatory, 
and we hope readers will interpret the critique as a principled 
intervention, not a polemic.
The paper proceeds as follows to clarify the stakes of this 
critique and provide readers with a clear guide through the 
argument. First, we unpack the core theoretical claims of the 
Bayesian brain hypothesis and its associated frameworks, 
including predictive coding and the Free Energy Principle. 
Next, we examine the ambiguity between metaphor and 
mechanism that characterizes many Bayesian models, fol-
lowed by an in-depth analysis of their unfalsifiability and 
over-flexibility. We then turn to the biological and neuro-
physiological limitations of the hypothesis, including prob-
lems of computational and metabolic feasibility, implemen-
tation challenges, and mismatches with empirical data. After 
outlining the non-Gaussian statistical properties of neural 
dynamics as a fundamental challenge to Bayesian assump-
tions, we introduce alternative frameworks—dynamic sys-
tems theory, ecological psychology, and embodied cogni-
tion—that offer more biologically plausible accounts of 
perception and action. The manuscript concludes with a 
fictional dialogue that crystallizes the core conceptual ten-
sions and reflects on why the Bayesian metaphor persists 
despite its empirical and mechanistic shortcomings. We thus 
draw a clear boundary between scientific explanation and 
seductive abstraction.
What is the Bayesian brain claiming?
The danger of a good idea is not that it fails to explain 
anything, but that it can be twisted to explain eve -
rything. When a theory grows flexible enough to 
2646 European Journal of Applied Physiology (2025) 125:2643–2677
encompass candle flames and cortical columns under 
the same mathematical umbrella, perhaps we should 
question not its scope but its substance.
Before we can fully assess these concerns, we must first 
clarify what the Bayesian brain hypothesis actually claims. 
While variations exist across different research programs, 
the core commitments generally include:
Perception as probabilistic inference
The Bayesian brain frames perception not as a passive recep-
tion of sensory data, but as an active process of probabil-
istic inference (Knill and Pouget 2004; Friston 2005; Rao 
and Ballard 1999). Sensory inputs are viewed as evidence 
that the brain uses to test and update its internal models of 
the world. What we perceive is not the world directly, but 
the brain’s best prediction about the causes of its sensory 
inputs, constrained by prior expectations and the likelihood 
of specific sensory data given different possible causes 
(this process is often illustrated schematically in models of 
predictive coding, where prior beliefs are combined with 
incoming sensory input to generate perceptual estimates and 
error signals, as shown in Fig. 1).
Action as prediction‑error minimization
Under this framework, motor actions are seen as attempts 
to minimize prediction errors by altering sensory inputs to 
align with predictions, rather than adjusting predictions to 
match inputs as in perception (Adams et al. 2013; Brown 
et al. 2013; Friston 2011). This perspective reframes motor 
control as a process analogous to perception, with both 
understood as forms of Bayesian inference. The key dis-
tinction lies in the direction of inference: perception updates 
predictions based on inputs, while action modifies inputs to 
fulfill predictions.
Learning as Bayesian belief updating
In the Bayesian framework, learning is the ongoing pro-
cess of updating internal models in response to mismatches 
between predicted and actual sensory input—that is, predic-
tion errors. This updating is presumed to follow Bayes’ rule, 
which combines prior beliefs with likelihood functions to 
Fig. 1  A schematic representation of the Bayesian brain hypothesis, 
illustrating how the brain integrates prior beliefs (hypotheses) with 
incoming sensory inputs to generate predictions and update internal 
models. Sensory inputs (blue arrows) from the environment—includ-
ing visual, auditory, and proprioceptive signals—are compared 
against internally generated sensory predictions (purple arrows) 
derived from prior beliefs about the world. Prediction errors (PE), 
calculated as the discrepancy between expected and actual input, 
are used to update beliefs (green arrows) and expected value (EV), 
adjusting the brain’s internal model through processes such as error-
based learning and reinforcement learning. The brain minimizes pre-
diction error, refining its model to interpret better and anticipate sen-
sory information. This framework is foundational to predictive coding 
theories and active inference in neuroscience. Figure reproduced from 
Keysers et  al. (2024). Creative Commons Attribution 4.0 Interna-
tional (CC BY 4.0)
2647European Journal of Applied Physiology (2025) 125:2643–2677 
generate posterior beliefs (Behrens et al. 2007; Mathys et al. 
2011; Tenenbaum et al. 2006). Over time, this inferential 
mechanism is thought to refine the brain’s generative mod-
els, enabling progressively more accurate predictions about 
the structure and dynamics of the external world.
These core claims have been elaborated and extended in sev-
eral related frameworks, most notably:
Predictive coding models describe how prediction errors 
might be computed and propagated through hierarchical 
neural systems, with higher levels providing predictions to 
lower levels and receiving error signals in return (Bastos 
et al. 2012; Clark 2013; Rao and Ballard 1999).
The Free Energy Principle (FEP) attempts to unify percep-
tion, action, and learning under a single imperative: mini-
mizing variational free energy, which is claimed to approxi-
mate prediction error or surprise over time (Friston et al. 
2006; Friston 2010; Parr and Friston 2019).
Active inference extends these ideas to account for decision-
making and planning, suggesting that agents select actions 
that minimize expected free energy or maximize expected 
information gain (Friston et al. 2011, 2017; Parr et al. 2020).
While these frameworks vary in mathematical details 
and scope, they share the fundamental assumption that 
Bayesian inference, or something functionally equivalent, 
constitutes the basic operating principle of neural systems. 
To clarify the rhetorical and conceptual slippage across 
different implementations of the Bayesian brain hypoth-
esis, Table 1 summarizes core terms and how their mean-
ings vary by context, model level, and narrative intent. 
Table 2 extends this point by showing how these same 
terms often shift meaning entirely depending on con-
text—serving simultaneously technical, rhetorical, and 
metaphorical functions.
Notably, “Bayesian brain” theories vary widely in their 
claims, from literal implementations of Bayes’ rule at the 
neural circuit level (strong mechanistic models), to compu-
tational-level descriptions that treat Bayesian inference more 
as an “as-if” convenience. Some researchers adopt approxi-
mate sampling approaches (e.g., Monte Carlo sampling in 
neural populations), others discuss Bayesian integration only 
at the behavioral level, and still others envision a purely met-
aphorical role. This heterogeneity makes it crucial to specify 
which “Bayesian flavor” is under discussion.
While the core claims of the Bayesian brain hypothesis 
are relatively clear, their status as actual mechanistic expla-
nations remains deeply contested and persistently unre-
solved. This ambiguity reflects a broader and longstanding 
issue in theoretical neuroscience: the potential conflation 
of metaphorical descriptions with genuine, biologically 
grounded accounts of neural function. To address this issue 
meaningfully, we must carefully and explicitly distinguish 
between these different modes of explanation—not only in 
Table 1  Glossary of core terms in the Bayesian brain literature. These 
terms are widely used across predictive coding and active inference 
models, often with flexible or contradictory meanings depending on 
the context. Readers are encouraged to examine how each term is 
operationalized—or left undefined—in specific studies
Term Stated meaning Operational usage Convenient flexibility
Prior Belief about a hidden cause or state Often fitted post hoc from data; rarely 
observable directly
Can be adjusted arbitrarily to explain 
behavioral variance
Likelihood Probability of data given a state Used in model-fitting to simulate 
expected input
Rarely derived from actual sensory noise 
or measurement properties
Posterior Updated belief after observing data Equated with perceptual content or 
motor intent
Sometimes collapses back into the prior 
depending on results
Prediction error Difference between predicted and 
observed input
Inferred from fMRI or EEG correlates Broad enough to explain nearly any 
neural response
Precision Confidence (inverse variance) on a 
prediction error
Said to modulate neural gain or synap-
tic weights
Alternately interpreted as attention, sali-
ence, or relevance
Generative model Internal model that simulates sensory 
input
Invoked to explain perception, action, 
and imagination
Often remains a black box between equa-
tions and neurons
Free energy Bound on surprise or model evidence Optimization target for Bayesian agents Used metaphorically, mathematically, 
and metaphysically
Active inference Acting to minimize expected free 
energy
Justifies perception, action, planning, 
and emotion
May explain everything while predicting 
nothing
Surprise Improbability of an observation Linked to learning, novelty, or model 
update
Sometimes psychological, sometimes 
mathematical, always fuzzy
Markov blanket Statistical boundary between system 
and environment
Applied to neurons, organs, and even 
candle flames
Becomes metaphysical when stretched 
too far
2648 European Journal of Applied Physiology (2025) 125:2643–2677
language, but in empirical commitments and evidentiary 
standards.
From metaphor to mechanism—or myth
A metaphor is a promise. A mechanism is its fulfill-
ment. A myth is what remains when the promise is 
never kept.
The Bayesian brain hypothesis did not begin as a mecha -
nism. Like many influential scientific ideas, it began as a 
metaphor—a conceptual lens through which to reinterpret 
core cognitive processes such as perception, action, and 
learning. Rather than presenting a fully articulated model of 
neural function grounded in biological detail, the hypothesis 
offered a broad, unifying framework that cast the brain as 
an inference engine, continuously generating and updating 
probabilistic models of the world. This framing provided a 
flexible alternative to classical stimulus–response models, 
allowing for the reimagination of brain function as predic-
tion, uncertainty, and statistical optimization. As a heuristic, 
the idea of the brain as a “Bayesian inference engine” proved 
powerful: it offered a narrative capable of organizing diverse 
phenomena across levels of analysis. Yet metaphors in sci-
ence carry an implicit contract—they must eventually be 
translated into mechanistic explanations that are biologically 
plausible and empirically testable (Craver 2007). When they 
are not—when they continue to shape theory and research 
despite lacking clear implementation or falsifiability—they 
cross a threshold and become self-sealing narratives: rhetori-
cally compelling, yet empirically ungrounded.
To make this distinction precise, we briefly define three 
conceptual categories: 
1. Metaphor: A metaphor is an analogical device that 
maps one domain of understanding onto another (Lakoff 
and Johnson 1980). In science, metaphors are often 
indispensable for theory development, serving as scaf-
folding for the construction of models or hypotheses 
(Hesse 1970). Yet a metaphor is not an explanation: it is 
a guide, not a ground.
2. Mechanism: A mechanism, by contrast, is a causally 
specific, empirically tractable process embedded in 
physical systems. A mechanistic explanation identifies 
components, operations, and their organization in pro-
ducing a phenomenon. It is the standard by which claims 
about brain function must ultimately be judged (Bechtel 
2011; Craver 2007; Machamer et al. 2000).
3. Myth: A myth is what remains when a metaphor per -
sists without becoming a mechanism. It is a narrative 
that resists empirical challenge, flexibly absorbs contra-
dictory findings, and sustains belief through rhetorical 
appeal rather than evidential support. Myths in science 
are not necessarily false—but they are unfalsifiable, and 
thus epistemically inert.
This taxonomy clarifies what is at stake in the ongoing 
debate over the Bayesian brain hypothesis by distin-
guishing between metaphor, mechanism, and myth. The 
predictive coding framework, and later the Free Energy 
Principle, did not begin as mechanistic models but as 
evocative metaphors—mathematical formalisms that 
invited reinterpretation of neural function in probabil-
istic terms (Clark 2013; Knill and Pouget 2004; Friston 
et al. 2006; Friston 2010; Hohwy 2013). These metaphors 
proved highly generative: they inspired theoretical innova-
tion, computational simulations, and reinterpretations of 
empirical findings across diverse cognitive domains. Yet 
generativity alone is not sufficient for scientific legitimacy. 
In many cases, these constructs have failed to evolve into 
biologically grounded mechanisms. The internal genera-
tive model, precision-weighted prediction error, and the 
Markov blanket remain metaphorical placeholders unless 
and until they are tied to specific, testable neural substrates 
and causal processes—as some approximation-based mod-
els attempt, though often without sufficient constraint or 
empirical validation. Until then, they function less as 
mechanistic explanations and more as durable narrative 
devices—mathematically fluent, rhetorically compelling, 
and empirically ambiguous.
Table 2  Polysemy as a feature: How core terms shift shape across contexts. Terms commonly used in Bayesian frameworks often take on differ -
ent meanings depending on rhetorical or theoretical need
Term Context A Context B
Precision Neural gain modulation (e.g., V1 BOLD signal) Subjective confidence or attentional weighting
Free energy Surprise minimization (in theory) Surprise rebranding (in practice)
Surprise Kullback–Leibler (KL) divergence between model and 
input
Phenomenological “Whoa!” moments in psychology
Priors Built-in generative model constraints Flexible narrative device to explain deviant data
Prediction error Signal mismatch at sensory cortex Any unexpected effect in behavior or physiology
2649European Journal of Applied Physiology (2025) 125:2643–2677 
Moreover, when these metaphors are challenged, pro-
ponents often retreat to abstraction rather than mechanism. 
When neural data fails to support prediction error coding, 
the theory shifts to another level of analysis. When behav -
ior contradicts Bayesian optimality, the priors are redefined. 
This flexibility is not a sign of robustness; it is a sign of 
rhetorical insulation. As Popper (2014) warned, a theory that 
cannot be falsified—because it can explain any outcome—
ceases to be scientific.
The problem is not that the Bayesian brain began as a 
metaphor; all scientific theories do. The problem is that 
it has remained one—while being defended as if it were a 
mechanism. It is this unresolved status that turns the meta-
phor into a myth.
In the following sections, we explore how this process 
of mythologization unfolds across several key domains of 
cognitive neuroscience, including perception, motor con-
trol, psychiatric modeling, and artificial intelligence. Each 
of these domains has been reshaped by the Bayesian frame-
work’s rhetorical and mathematical appeal, yet often with-
out corresponding empirical or mechanistic specificity. We 
argue that unless proponents can rigorously demonstrate 
how their constructs map onto identifiable neural mecha -
nisms, the Bayesian brain hypothesis must be reclassified not 
as a genuine explanation of brain function, but as a durable, 
aesthetically appealing, and ultimately empirically hollow 
metaphor.
The “as‑if” problem
To say the brain behaves “as if” it were a Bayesian 
inference engine is not an explanation—it is an abdica-
tion. It is the polite fiction we tell ourselves when the 
equations look good but the biology refuses to coop-
erate. It is a way to sound mechanistic while saying 
nothing mechanistic at all.
The Bayesian brain hypothesis frequently operates in an 
“as-if” mode of explanation: the brain acts as if  it were 
performing Bayesian inference, without claiming that actual 
Bayesian computations are implemented in neural tissue 
(Colombo and Seriès 2012; Danks 2014). This linguistic 
framing is not merely stylistic but reveals a fundamental 
ambiguity in the theory’s explanatory status (cf. Ramsey 
2007). It allows theorists to borrow the authority of 
mathematics while avoiding commitment to the messiness 
of biological implementation.
The “as-if” problem manifests in several ways. First, 
descriptions of neural processes invariably slip into inten-
tional language—neurons “expect,” “predict,” or “rep-
resent” probability distributions—suggesting cognitive 
operations that the theory simultaneously disavows at the 
implementation level (Brette 2019). Second, the very math-
ematics of Bayesian inference requires computation over 
explicit probability distributions, yet proponents often claim 
that the brain need not explicitly represent these distribu-
tions (Sprevak and Smith 2023). This leads to an unstable 
oscillation between literal and metaphorical interpretations 
depending on the empirical context. What begins as a theo-
retical convenience quickly becomes a rhetorical strategy.
Most problematically, the “as-if” framing allows the the-
ory to preserve its narrative appeal and scientific prestige 
while systematically evading clear mechanistic commit-
ments, except in a limited number of computational neuro-
science implementations that warrant separate evaluation. 
When neural data fails to align with Bayesian predictions, 
the retreat to “as-if” terminology preserves the framework’s 
rhetorical force despite remaining detached from biological 
reality (Bowers and Davis 2012; Jones and Love 2011). This 
linguistic slippage becomes particularly acute in expressions 
like “the brain minimizes prediction error” or “neurons 
encode precision weights”—phrases implying mechanistic 
claims while remaining shielded from falsification by their 
metaphorical status (Litwin and Miłkowski 2020).
The “as-if” problem thus reveals a deeper issue: without 
a clear commitment to implementational specificity, Bayes-
ian brain models risk becoming what Dennett (1987) calls 
“free-floating rationales”—explanations that identify com-
putational functions without constraining how those func-
tions are realized in physical systems. To move beyond this 
impasse requires abandoning the comfort of “as-if” termi-
nology and specifying exactly what neural operations would 
constitute—not merely simulate or approximate—Bayesian 
inference (Zednik and Jäkel 2016).
This reliance on “as-if” reasoning thus functions not 
merely as a linguistic shortcut but as a conceptual buffer—
protecting the framework from empirical scrutiny while 
preserving its rhetorical coherence. But what begins as 
a metaphorical convenience gradually metastasizes into 
explanatory ambiguity. As we will see in the next section, 
this ambiguity is not an isolated issue but symptomatic of a 
deeper theoretical tendency: the conflation of metaphor with 
mechanism, which threatens to transform a once-generative 
idea into a self-insulating scientific myth.
Metaphor, mechanism, or myth: The 
conceptual drift of the Bayesian brain
A metaphor becomes a myth the moment we stop 
interrogating its limitations and start defending its uni-
versality. The Bayesian brain was born as an analogy, 
matured into a paradigm, and calcified into dogma—
2650 European Journal of Applied Physiology (2025) 125:2643–2677
all without ever demonstrating its biological plausibil-
ity.
This section draws on Marr’s well-known framework, distin-
guishing computational, algorithmic, and implementational 
levels of explanation (Marr 1982). We do not argue against 
the utility of Bayesian models at the computational level, 
where they often serve as useful abstractions for describing 
task structure or statistical inference. Rather, our critique 
focuses on the conceptual slippage between levels: meta-
phorical or computational claims are often implicitly treated 
as if they entailed mechanistic commitments, without suf-
ficient constraint at the algorithmic or implementational 
level. It is this rhetorical and explanatory ambiguity—not 
probabilistic modeling per se—that we identify as the central 
problem. Clarifying this distinction is essential for evaluat-
ing the scientific status of the framework.
Whether due to deliberate flexibility or a lack of con-
ceptual clarity, the explanatory status of the Bayesian 
brain hypothesis remains surprisingly ambiguous—even as 
it is often presented with the mathematical formalism of 
a fully developed scientific theory. Its apparent precision 
can sometimes mask a lack of mechanistic clarity, allowing 
the framework to shift fluidly between levels of description 
without clear empirical constraint. When closely examined, 
many “Bayesian brain” models function not as process mod-
els—particularly in cognitive neuroscience and psychia -
try—describing actual neural mechanisms, but as statistical 
descriptions that characterize behavioral or neural data in 
Bayesian terms, often retrospectively (Bowers and Davis 
2012; Jones and Love 2011).
As noted above, Bayesian accounts span a wide spec-
trum of interpretations, ranging from purely metaphorical 
frameworks that offer broad conceptual guidance to com-
putational-level approximations that describe the functional 
goals of perception and cognition and, finally, to strong 
mechanistic claims that purport to specify the actual neural 
implementations of inference in the brain. This ambiguity is 
particularly evident in the interpretation of neural activity. 
Consider studies that identify neural signals as representing 
“prediction errors” or “prior expectations.” These interpre-
tations frequently rest on correlational evidence (O’Reilly 
et al. 2012; Poldrack 2011). The inference from correlation 
to representation is not always substantiated, yet it is often 
rhetorically framed as evidence of implementation. If neu-
ral activity correlates with values derived from a Bayesian 
model fitted to behavioral data, it is claimed that this region 
“represents” or “encodes” the corresponding Bayesian con-
struct. This reflects a broader issue of reverse inference: the 
fact that a Bayesian model fits observed data does not imply 
that the brain necessarily implements Bayes’ rule or explic-
itly represents Bayesian quantities.
A central concern here is reification—treating math-
ematical constructs as physical entities or neurobiological 
processes (Krakauer et al. 2017). Priors, likelihoods, and 
posteriors are mathematical terms that help us describe 
probabilistic relationships, but it is unclear whether the brain 
carves itself at these particular joints or manipulates such 
quantities in any explicit form. Neural activity that corre-
lates with prediction errors might emerge from underlying 
dynamics or structural constraints that may not correspond 
directly to explicit Bayesian calculations.
When challenged on these points, proponents of the 
Bayesian brain often pivot between two positions. On one 
hand, they may retreat to a weaker claim: Bayesian models 
provide a useful “as if” description, without committing to 
specific implementation details. On the other hand, they may 
assert stronger mechanistic claims when presenting evidence 
that seems to align with Bayesian predictions. This concep-
tual ambiguity—between abstraction and implementation, 
metaphor and mechanism—allows the framework to absorb 
contradictory findings without penalty, insulating it from 
empirical falsification while maintaining explanatory appeal. 
This conceptual flexibility makes it difficult to pin down 
exactly what the hypothesis is claiming about actual brain 
function.
The metaphor-mechanism distinction matters deeply. If 
the Bayesian brain is primarily a metaphor or high-level 
description, it should not be evaluated on its mechanistic 
accuracy but on its heuristic value in generating testable 
predictions. However, if it makes mechanistic claims, it 
must specify how abstract Bayesian computations map onto 
biological processes and neural architectures. Appeals to 
Marr ’s (1982) computational level does not absolve the 
framework from empirical accountability. If the computa-
tional-level theory is too flexible to be falsified, or if it lacks 
algorithmic and implementational constraints, then its sci -
entific utility diminishes. A coherent theory must connect its 
computational goals to biologically plausible processes and 
allow for empirical disconfirmation at each level. Without 
this clarity, the hypothesis risks becoming what philosopher 
Karl Popper would call a “metaphysical research program” 
(Popper 2014)—influential but ultimately unfalsifiable.
Falsifiability criteria for the Bayesian brain 
hypothesis
To evaluate the Bayesian brain hypothesis as a scientific 
theory, it must generate predictions that are specific enough 
to be disproven by empirical evidence. The following condi-
tions would, in principle, falsify core claims of the hypoth-
esis or its associated frameworks (e.g., predictive coding, 
active inference): 
2651European Journal of Applied Physiology (2025) 125:2643–2677 
1. Absence of prediction error signatures: Neural popu-
lations hypothesized to encode prediction errors (e.g., 
mismatch responses in sensory cortices) should system-
atically differ under conditions of violated expectations 
(Egner and Summerfield 2013). If no such differences 
are observed—even when priors are explicitly manipu-
lated—this challenges the predictive coding framework.
2. Failure to detect prior-driven modulation: The theory 
predicts that prior expectations modulate neural activ -
ity and behavioral outcomes. Experiments designed 
to isolate prior influence (e.g., cue-based probabilistic 
expectations) that show no such modulation undermine 
Bayesian assumptions (Teufel and Fletcher 2020).
3. Non-hierarchical neural responses: Predictive coding 
models assume hierarchical processing. If top-down pre-
dictions and bottom-up errors do not interact as pre-
dicted—e.g., if perturbations to higher-order areas do 
not affect lower-level error responses—this violates core 
architectural assumptions (Clark 2013).
4. Lack of precision weighting evidence: A key claim is 
that the brain dynamically adjusts the weight of predic-
tion errors based on uncertainty. Empirical evidence that 
uncertainty manipulation does not modulate neural gain 
or connectivity (e.g., through fMRI or electrophysiologi-
cal signatures) would contradict this mechanism.
5. Violation of behavioral Bayesian optimality: In tightly 
controlled tasks where prior probabilities and likeli-
hoods are explicitly defined, persistent deviations from 
Bayesian-optimal behavior—unexplainable by noise, 
heuristics, or approximation—would falsify normative 
claims (Rahnev and Denison 2018).
6. Disconfirmation of neural implementations: Proposed 
neural implementations (e.g., probabilistic population 
coding, sampling-based approximations) must be empir-
ically verified. If studies fail to identify populations or 
dynamics consistent with these computational roles, the 
mechanistic plausibility of the framework is weakened.
7. Predictive failure in clinical models: If Bayesian-based 
explanations of psychiatric disorders (e.g., schizophrenia 
as altered precision weighting) fail to predict symptom 
patterns, treatment outcomes, or neural correlates in out-
of-sample datasets, the theory’s applied value dimin-
ishes (Fletcher and Frith 2009).
Together, these criteria illustrate that Bayesian brain models 
must be held to the same standards of empirical testability 
as any scientific theory. Absent clear predictions and 
falsifiability conditions, the framework risks functioning as 
a flexible narrative rather than a mechanistic explanation. 
Table 3 illustrates how common responses to disconfirming 
data—though rhetorically effective—gradually dissolve the 
framework’s empirical bite.
These criteria are not intended to specify detailed experi-
mental paradigms, but rather to highlight the theoretical 
commitments that must be clarified for the Bayesian brain 
hypothesis to function as a testable scientific theory. They 
serve to delineate the boundaries of falsifiability, without 
presupposing that such boundaries have yet been meaning-
fully enforced in current empirical practice. Clarifying these 
boundaries is a necessary step before meaningful experimen-
tal testing can even begin.
Concrete examples. The abstract concerns raised above 
are not merely theoretical; they are reflected in the empiri-
cal literature where predictive processing and FEP-based 
models are frequently invoked. For example, in the clinical 
domain, Bayesian models of schizophrenia posit that posi-
tive symptoms emerge from the altered precision weighting 
of prediction errors (Adams et al. 2013; Fletcher and Frith 
2009; Friston et al. 2014). While conceptually appealing, 
such models are often underconstrained and rarely generate 
falsifiable predictions about symptom specificity or treat-
ment outcomes. In perceptual neuroscience, auditory mis-
match negativity (MMN) is frequently interpreted within a 
predictive coding framework (Garrido et al. 2009 ; Teufel 
et al. 2013; Teufel and Fletcher 2020). Yet, similar neural 
responses can be explained by simpler mechanisms such 
as adaptation or dynamic filtering, making the inference 
to hierarchical prediction error computation questionable. 
Each example concretely illustrates the theoretical concerns 
raised above. Finally, in cue integration paradigms, such as 
the classic visual–haptic study by Ernst and Banks (2002), 
Table 3  Adapt or die? How flexibility undermines falsifiability 
(Danks 2014). A sample of common responses to disconfirming data 
and why each reduces the empirical bite of the theory. Note:  These 
criteria apply most strongly to generalized or flexible Bayesian frame-
works; some tightly constrained Bayesian models may offer stronger 
empirical grounding
Response to contradiction How it preserves the theory Why it undermines science
Adjust priors to fit data Retains Bayesian framing Priors become unfalsifiable parameters
Invoke suboptimal inference Absorbs errors into theory Prevents theory from being proven wrong
Retreat to “as-if” model Evades mechanistic commitment Confuses metaphor for mechanism
Shift levels of analysis Reframes failure at one level as success at another Eliminates clear prediction accountability
2652 European Journal of Applied Physiology (2025) 125:2643–2677
retrospective model-fitting often justifies Bayesian optimal-
ity post hoc, as priors and likelihoods are typically inferred 
from the behavioral data they purport to explain, rather than 
derived independently. These cases illustrate how flexible 
interpretation and post hoc adjustment—hallmarks of con-
ceptual slippage—play out in practical modeling scenarios.
A note on descriptive utility. While this paper strongly 
critiques the mechanistic and empirical claims of the Bayes-
ian brain hypothesis, it is important to acknowledge that 
Bayesian models can still serve a useful descriptive function 
in certain contexts (Jones and Love 2011). Their ability to 
fit data and formalize uncertainty has made them valuable 
formalisms for summarizing behavioral trends or design-
ing experimental paradigms. However, such uses should be 
clearly delineated from claims about neural implementation. 
A Bayesian model that captures behavior is not necessarily 
evidence for Bayesian computation in the brain. Conflating 
descriptive adequacy with mechanistic validity remains one 
of the central confusions this paper seeks to clarify.
Unfalsifiability and flexibility
A theory that adapts to all outcomes predicts none. 
When priors can be adjusted post-hoc to accommodate 
any observation, and precision parameters can explain 
away any deviation, we are no longer doing science—
we risk falling into an overly flexible interpretative 
framework.
Perhaps the most troubling aspect of the Bayesian brain 
hypothesis is its extraordinary flexibility in accommodat-
ing a wide range of empirical findings, including those that 
appear contradictory. By adjusting free parameters—such as 
priors, likelihood functions, noise distributions, or assumed 
processing levels—Bayesian models—particularly in their 
loosely specified, post hoc applications—an often be tailored 
to fit virtually any observed data pattern (Bowers and Davis 
2012; Jones and Love 2011 ). This flexibility manifests in 
several ways:
First, when behavioral data fail to conform to the predic-
tions of Bayesian optimality, researchers frequently appeal 
to auxiliary assumptions—such as “suboptimal” priors, 
cognitive capacity limitations, or the use of approxima-
tion algorithms—to account for these deviations (Rahnev 
and Denison 2018; Sanborn and Chater 2016). While such 
adjustments may be reasonable and necessary within a par -
ticular experimental contexts, their cumulative effect renders 
the framework remarkably elastic and resistant to empirical 
challenge. As a result, almost any observed behavior—no 
matter how inconsistent with normative expectations—can 
be retroactively interpreted as “Bayesian” in some qualified, 
metaphorical, or indirect sense, thereby blurring the bound-
ary between explanation and rationalization.
Second, when neural data fail to align with predicted 
Bayesian patterns, proponents can readily shift the theoreti-
cal focus between different levels of analysis. Proponents 
might even argue that individual neurons are not performing 
Bayesian computations, but that such computations emerge 
at the level of neural populations. Alternatively, the Bayes-
ian framework may be invoked at a more abstract, compu-
tational level, where its validity does not depend on direct 
neural implementation (Colombo and Seriès 2012; Kiefer 
and Hohwy 2018). Particularly telling is how predictive 
coding advocates responded when single-unit recordings 
in macaque IT cortex by Kaliukhovich and Vogels ( 2014) 
failed to show the expected repetition suppression effects. 
Rather than interpreting this as a challenge to the theory, 
they argued that Bayesian processes might operate at dif-
ferent spatial or temporal scales, or that such effects only 
emerge under specific task conditions (Walsh et al. 2020).
Third, the hypothesis spans multiple timescales, ranging 
from moment-to-moment perceptual processes to long-term 
evolutionary dynamics. This expansive scope allows propo-
nents to shift the explanatory emphasis when challenged. 
For instance, if current neural activity does not appear 
explicitly Bayesian, it may be reinterpreted as approximat-
ing Bayesian solutions that emerged through evolutionary 
or developmental processes (Griffiths and Tenenbaum 2006; 
Perfors et al. 2011).
These issues connect to broader and longstanding cri-
tiques of unfalsifiability in cognitive neuroscience, particu-
larly regarding using highly abstract, mathematically dense 
frameworks. The FEP, which incorporates and extends the 
Bayesian brain hypothesis, has been especially subject to 
such criticism. As Williams (2020) and Colombo and Wright 
(2021) have persuasively argued, the FEP’s sweeping math-
ematical formalism and conceptual elasticity enable it to 
accommodate virtually any empirical outcome, rendering it 
difficult—if not impossible—to falsify (Fig. 2).
The risk here is the unchecked proliferation of “just-so 
stories”—post hoc narratives crafted to explain observed 
phenomena without generating risky, testable predictions 
that could potentially disconfirm the theory (Gigerenzer 
1998; Marcus and Davis 2013). While narrative explana-
tions have their place in science, they become problematic 
when they create an illusion of understanding without genu-
ine explanatory power or empirical constraint. Proponents 
might argue that such theoretical flexibility merely reflects 
the genuine complexity and adaptability of neural systems, 
rather than indicating any weakness in the theory itself—but 
this very defense illustrates the core concern: a theory that 
is never at risk of being wrong ultimately forfeits its status 
as a scientifically informative framework (Lakatos 2014).
2653European Journal of Applied Physiology (2025) 125:2643–2677 
This theoretical looseness threatens the very foundations 
of the scientific discipline. A framework that can explain 
everything, after all, explains nothing in particular (Lakatos 
2014; Popper 2002). For the Bayesian brain hypothesis to 
progress beyond a compelling interpretive lens and estab-
lish itself as a genuinely scientific theory, it must articulate 
clear, testable conditions under which specific Bayesian 
mechanisms would be falsified—for example, by identify -
ing neural circuits that ought to encode prediction errors and 
showing that their absence would undermine the theory, or 
by specifying experimental contexts in which non-Bayes-
ian mechanisms demonstrably fail to approximate Bayes-
ian inference. Many of these post hoc moves function less 
as genuine scientific revisions aimed at refining theoretical 
accuracy and more as rhetorical defense—strategic maneu-
vers designed to preserve the framework’s coherence and 
authority in the face of contradictory evidence. Box 1 out-
lines some of the most common—and how to respond.
Box 1: Twelve common defenses of the Bayesian brain And how to 
respond
1.“You’re misusing Marr’s levels of analysis.”
Defense: “Marr distinguished between computational and imple-
mentational levels.”
Response: But even computational theories need implementational 
constraints. Otherwise, they become metaphysical abstractions.
Fig. 2  The unfalsifiability problem in Bayesian brain models. This 
flowchart illustrates the methodological circularity that renders the 
Bayesian brain hypothesis effectively unfalsifiable. When experimen-
tal evidence contradicts Bayesian predictions (e.g., “brain minimizes 
prediction error”), researchers rarely reject the framework. Instead, 
they systematically protect the Bayesian paradigm through post-hoc 
adjustments—either by adding auxiliary hypotheses (“subject to com-
putational constraints”) or redefining Bayesian parameters (“adjusted 
priors/precision weights”). These adjustments create a self-reinforc-
ing cycle that transforms empirical failures into theoretical successes, 
immunizing the framework against genuine falsification. This circu-
lar reasoning pattern reveals why Bayesian approaches persist despite 
repeated predictive failures: the theory automatically accommodates 
contradictory evidence through an endless proliferation of auxiliary 
hypotheses. As argued throughout this manuscript, this methodo-
logical structure violates Popperian standards of scientific testabil-
ity, functioning more as mathematical rhetoric than as an empirically 
accountable mechanistic model of neural function
2654 European Journal of Applied Physiology (2025) 125:2643–2677
Box 1: Twelve common defenses of the Bayesian brain And how to 
respond
2. “Of course, the brain isn’t doing exact Bayesian updates.”
Defense: “The brain uses approximations—sampling, probabilistic 
population codes, etc.”
Response: Approximate how? Vague gestures toward sampling 
aren’t mechanisms. Show us the circuitry or concede it’s just a 
metaphor.
3. “You’re ignoring all the empirical successes.”
Defense: “Bayesian models have explained multisensory integra-
tion, illusions, and behavior.”
Response: Most of those are post hoc curve-fitting exercises. Where 
are the risky predictions and independent validations?
4. “This theory spans all of cognition.”
Defense: “Predictive coding unifies perception, action, learning, and 
psychiatry.”
Response: Theories that explain everything without constraint often 
explain nothing. Breadth without falsifiability is rhetorical sprawl.
5. “It’s evolutionarily plausible.”
Defense: “Natural selection would favor near-optimal inference 
strategies.”
Response: Evolution favors robustness and speed, not statistical 
optimality. Metabolic efficiency beats elegance every time.
6. “There’s neural evidence for prediction error coding.”
Defense: “BOLD signals, EEG responses, and repetition suppres-
sion all support predictive coding.”
Response: Correlation is not implementation. These signals are 
inconsistent, context-dependent, and theoretically overfitted.
7. “We’re still refining the model.”
Defense: “Science progresses by refining theories in light of new 
data.”
Response: If every contradiction leads to a new auxiliary clause, 
you’re not refining—you’re shielding the theory from genuine 
falsification.
8. “You’re attacking a straw man.”
Defense: “Nobody really believes the strong version of the Bayesian 
brain.”
Response: Then stop writing papers claiming the brain encodes 
priors, computes posteriors, and minimizes free energy.
9. “It’s the best model we have.”
Defense: “Bayesian models outperform alternatives in many tasks.”
Response: Dominance in the literature may reflect institutional 
momentum, not epistemic superiority. Utility isn’t legitimacy.
10. “You’re confusing levels of explanation.”
Defense: “Computational theories don’t need neural mechanisms.”
Response: Theories that stay permanently at the computational level 
become theology. At some point, they must cash out biologically.
11. “We never said the brain explicitly computes probabilities.”
Defense: “The brain implements functionally equivalent strategies.”
Response: Then define what counts as equivalence—and show it 
with data, not wishful mappings.
12. “Predictive coding already includes embodiment.”
Defense: “Active inference unites brain, body, and environment.”
Response: Only on paper. In practice, embodiment is often a bolt-on 
module to an inference engine, not a core architectural principle.
Empirical and biological Shortcomings
The brain may whisper in mathematics, but it speaks 
in flesh. No amount of probabilistic elegance can over-
come the stubborn facts of neural tissue: its metabolic 
constraints, its non-Gaussian dynamics, and its embod-
ied evolutionary history that prioritized survival over 
statistical optimality.
Beyond conceptual concerns, the Bayesian brain hypothesis 
faces substantial empirical and biological challenges that are 
often underappreciated in theoretical discussions.
Neurobiological implementation challenges
First is the question of how (and whether) the brain could 
encode full probability distributions. Bayesian models typi-
cally operate on probability distributions over possible world 
states, often involving high-dimensional, continuous spaces. 
Representing such distributions poses significant challenges 
for neural systems constrained by finite resources. Research-
ers have proposed potential mechanisms, including popula-
tion coding, sampling-based representations, and distributed 
encoding schemes. However, these proposals remain largely 
speculative and face substantial implementation challenges 
(Fiser et al. 2010; Pouget et al. 2013).
Second is the computational implausibility of explicit 
Bayesian updating in real-time. Exact Bayesian inference 
is computationally intensive even for simple problems and 
becomes intractable for complex ones. While approximate 
inference methods exist (variational inference, Monte Carlo 
sampling, etc.)—and have been proposed as biologically 
plausible strategies, these still require sophisticated compu-
tations that strain biological plausibility, especially for real-
time decision-making under pressure (Griffiths et al. 2015; 
Sanborn and Chater 2016).
The temporal dynamics of neural processing present 
another challenge. Bayesian updating is typically formulated 
as a sequential process, but real neural systems operate with 
parallel, recurrent dynamics across multiple timescales. 
Reconciling these temporal patterns with idealized Bayes -
ian updating remains problematic (Pouget et al. 2013).
Empirical mismatches
Beyond implementation concerns, empirical evidence for 
Bayesian processing in the brain remains, at best, mixed and 
inconsistent. While some studies report behavioral patterns 
that align with Bayesian predictions, an equally substantial 
number reveal systematic deviations that question the frame-
work’s generality. Human perception and decision-making 
routinely exhibit robust cognitive biases and heuristics that 
2655European Journal of Applied Physiology (2025) 125:2643–2677 
appear distinctly non-Bayesian, including base-rate neglect, 
availability bias, and anchoring effects (Kahneman and Tver-
sky 2013; Tversky and Kahneman 1974). These deviations 
are not merely incidental or reducible to noise; rather, they 
reflect stable, reproducible patterns observed across a wide 
range of tasks, populations, and experimental contexts. 
Such findings raise important questions about whether the 
brain genuinely performs probabilistic inference or whether 
Bayesian models are retrospectively fitted to behaviors that 
emerge from fundamentally different, and perhaps more heu-
ristic, cognitive mechanisms.
At the neural level, the evidence for Bayesian process-
ing is similarly equivocal and uneven. While some studies 
identify neural signatures that appear to correlate with pre-
dictions derived from Bayesian models, these findings are 
frequently inconsistent across experimental tasks, stimulus 
conditions, and individual participants. Moreover, alter -
native non-Bayesian models—grounded in heuristics, 
dynamical systems, or adaptation mechanisms—can often 
account for the same neural patterns with equal or even 
greater parsimony and explanatory clarity (Rahnev and 
Denison 2018).
Perhaps most problematically, the Bayesian framing has 
difficulty accounting for the context-sensitivity and task-
dependence of neural responses. The same neural circuits 
may perform different functions depending on behavioral 
context, attentional state, or motivational factors—a flex-
ibility that sits uncomfortably with strict Bayesian formu -
lations (Gilbert and Li 2013). These shortcomings suggest 
that while Bayesian principles may successfully capture 
certain aspects of neural processing under narrowly 
defined or experimentally controlled conditions, they fall 
short as a comprehensive or generalizable account of how 
the brain actually operates across the full spectrum of con-
texts, environments, and real-world challenges (Gigerenzer 
and Gaissmaier 2011; Summerfield and Tsetsos 2015).
Revisiting the “successes:” What do Bayesian models 
actually explain?
Proponents of the Bayesian brain hypothesis often point to a 
set of well-known empirical findings—such as optimal mul-
tisensory integration, visual illusions, and motor control—as 
evidence of Bayesian computation in the brain. These case 
studies are frequently cited as successes that validate the 
framework and demonstrate its predictive and explanatory 
power (Ernst and Banks 2002; Körding and Wolpert 2004; 
Weiss et al. 2002). However, a closer examination reveals 
that these findings are often consistent with multiple theoret-
ical interpretations. This is especially true when priors and 
likelihoods are fitted retroactively, require strong post hoc 
assumptions to align with the data, or fail to establish any 
clear neural implementation of Bayesian principles (Bow -
ers and Davis 2012; Jones and Love 2011). What appears 
to support the hypothesis may instead reflect the descriptive 
flexibility of the models rather than evidence of mechanistic 
reality (Marcus and Davis 2013; Rasmussen and Eliasmith 
2013).
Multisensory cue integration. A classic example comes 
from studies on visual-haptic integration, which report that 
humans combine sensory cues in a statistically optimal way, 
as predicted by Bayesian models (Ernst and Banks 2002). 
These findings are often interpreted as evidence that the 
brain computes a weighted average of sensory inputs based 
on their relative reliabilities. Yet such behavior can also 
emerge from experience—driven calibration or embodied 
strategies that do not require explicit probabilistic infer -
ence. Moreover, deviations from optimal integration have 
been observed in tasks with time constraints or novel stimuli 
(Arnold et al. 2019; Stanford et al. 2005), suggesting that 
the Bayesian fit may reflect task-specific tuning rather than 
a general cognitive strategy.
Visual illusions. Bayesian models have also been used 
to explain classic perceptual illusions, such as Adelson’s 
checker shadow illusion or motion illusions under ambigu-
ous input (Knill and Richards 1996). These interpretations 
often posit that the brain uses prior knowledge to “explain 
away” unexpected sensory inputs. However, the priors in 
such models are typically inferred from the illusion itself—
raising concerns about circular explanation. In many cases, 
non-Bayesian accounts based on ecological constraints or 
perceptual heuristics offer equally plausible, and often more 
parsimonious, explanations (Purves et al. 2011).
Sensorimotor control. In motor behavior, optimal feed-
back control models grounded in Bayesian inference have 
been widely proposed to explain how humans plan and cor-
rect movement trajectories under conditions of uncertainty 
(Todorov and Jordan 2002). These models have been notably 
successful in capturing certain features of motor behavior, 
such as movement efficiency, variability scaling, and adap-
tive responses to perturbations. However, they rely on ide-
alized assumptions about cost functions, internal forward 
models, and noise distributions—assumptions that are often 
abstract and difficult to validate empirically. Crucially, these 
internal quantities are not directly measurable in biological 
systems and are frequently tuned post hoc to fit the observed 
data, rather than being specified as a priori. While this flex-
ibility enables the models to accommodate a wide range of 
behavioral patterns, it substantially weakens their capacity to 
generate novel, falsifiable predictions about the actual neural 
mechanisms involved (Wolpert et al. 2011).
2656 European Journal of Applied Physiology (2025) 125:2643–2677
Pathophysiology.  Another prominent “success story” 
of the Bayesian brain framework is its application to psy -
chiatric conditions, particularly schizophrenia. Predictive 
coding accounts propose that symptoms such as hallucina-
tions and delusions arise from aberrant precision-weighting 
of prediction errors—either attributing too much weight to 
low-level sensory signals or too little to top-down priors 
(Adams et al. 2013; Corlett et al. 2019; Friston 2016). While 
compelling in its post hoc coherence, this interpretation 
suffers from the same problems discussed throughout this 
paper. The models typically explain observed symptoms by 
adjusting the relative weight of priors or sensory inputs, but 
rarely predict which patients will exhibit which symptoms 
under specific conditions (Sterzer et al. 2018). Moreover, 
non-Bayesian alternatives—such as models based on disor-
dered neuromodulation (Hu et al. 2015), disrupted synaptic 
pruning (Sekar et al. 2016), or abnormal cortical dynamics 
(Uhlhaas et al. 2009)—can also account for similar symp -
tom profiles without invoking probabilistic inference. The 
Bayesian explanation, while mathematically elegant, risks 
functioning more as a narrative scaffold than a mechanistic 
theory of pathophysiology (Williams 2018). Without direct 
empirical markers of prediction error precision or falsifi-
able predictions about symptom onset or treatment response, 
such models offer little more than descriptive reinterpreta-
tion (Bowers and Davis 2012; Colombo 2018).
These case studies reveal a common pattern: empirical 
phenomena interpreted as Bayesian successes often rely 
on fitting data to flexible models that are agnostic about 
implementation. While these models may provide useful 
descriptive tools, but they do not necessarily demonstrate 
that the brain performs Bayesian inference or confirm the 
mechanistic claims often associated with the Bayesian brain 
hypothesis. A prominent example is the modeling of audi-
tory mismatch negativity (MMN) using predictive coding 
frameworks. While Bayesian models can simulate MMN 
waveforms, they typically require finely tuned priors and 
assume hierarchical precision-weighting mechanisms with-
out identifying specific neural circuits that implement them. 
Non-Bayesian alternatives—such as models based on local 
adaptation, Hebbian plasticity, or dynamic resonance—have 
reproduced similar MMN features without invoking hierar-
chical inference, raising questions about the unique explana-
tory value of Bayesian accounts.
Neurobiological constraints 
and the implausibility of Bayesian 
implementation
Even the most elegant computation becomes meaning-
less noise when it outpaces biological possibility. The 
gap between theoretical Bayesian inference and actual 
neurophysiology is not merely a matter of approxima-
tion—it is a fundamental category error, like trying to 
run quantum algorithms on an abacus.
Core assumptions of the Bayesian brain hypothesis
The Bayesian brain hypothesis rests on at least five key 
assumptions that warrant careful scrutiny: 
1. Representation of full probability distributions: The 
framework assumes neural systems can encode and 
manipulate complete probability distributions over pos-
sible world states, including prior beliefs, likelihoods, 
and posteriors (Ma et al. 2006; Pouget et al. 2013).
2. Real-time Bayesian updating: It presupposes that neu-
ral circuits can perform or approximate Bayesian infer -
ence rapidly enough to support real-time perception and 
decision-making (Knill and Pouget 2004; Friston 2010).
3. Hierarchical error propagation: The predictive cod-
ing variant assumes a specific hierarchical organization 
where higher levels send predictions to lower levels and 
receive precision-weighted prediction errors in return 
(Rao and Ballard 1999; Friston 2005).
4. Precision weighting: The model assumes neural sys-
tems can dynamically adjust the “precision” (inverse 
variance) of prediction errors based on contextual fac-
tors and uncertainty (Feldman and Friston 2010; Hohwy 
2012).
5. Generative models: Perhaps most fundamentally, it 
assumes the brain maintains internal generative models 
of the world that can simulate expected sensory inputs 
(Hinton 2007; Clark 2013).
Non‑Gaussian nature of neural fluctuations
A critical yet frequently overlooked constraint on the Bayes-
ian brain hypothesis involves the statistical properties of 
neural fluctuations. Most Bayesian models implicitly or 
explicitly assume that neural noise conforms to Gaussian 
(normal) distributions—a choice made more for mathemati-
cal tractability than for biological realism. However, a grow-
ing body of empirical evidence indicates that neural activity 
consistently exhibits distinctly non-Gaussian statistical prop-
erties across multiple temporal and spatial scales of brain 
organization: 
2657European Journal of Applied Physiology (2025) 125:2643–2677 
1. Heavy-tailed distributions: Neural fluctuations fre-
quently follow heavy-tailed distributions, including 
power-law, log-normal, and Lévy-stable distributions 
rather than Gaussian profiles (Beggs and Plenz 2003; 
Chialvo 2010; Freyer et al. 2009; Metzler and Klafter 
2000; Touboul and Destexhe 2010). Such distributions 
imply that large-amplitude events occur much more fre-
quently than would be expected under Gaussian assump-
tions, fundamentally altering the statistical landscape 
within which neural computation must operate.
2. Scale-free dynamics: The power spectra of neural sig-
nals typically follow a power-law form ( 1∕f /u1D6FD ), indicating 
temporal correlations that persist across multiple time-
scales (He et al. 2010; Miller et al. 2009; Linkenkaer-
Hansen et al. 2001; Touboul and Destexhe 2010). This 
scale-free property contradicts the assumption of tem-
porally uncorrelated noise that underlies many Bayesian 
formulations.
3. Bistability and multistability: Neural activity often 
exhibits multimodal distributions, reflecting transitions 
between distinct dynamical states rather than continu-
ous fluctuations around a single equilibrium (Deco et al. 
2011; Freyer et al. 2009; Kinouchi and Copelli 2006). 
Such bistable or multistable dynamics cannot be ade-
quately captured by conventional Bayesian frameworks 
that presume unimodal posterior distributions.
4. Multiplicative noise processes: Evidence suggests that 
neural fluctuations involve multiplicative rather than 
merely additive noise components, where the variance 
of the noise depends on the system’s state (Buice et al. 
2010; Roberts et al. 2019). These multiplicative interac-
tions create fundamentally different statistical properties 
than the additive noise typically assumed in Bayesian 
models.
These non-Gaussian characteristics of neural fluctuations 
present severe challenges to the Bayesian brain hypothesis, 
suggesting that the simplifying assumptions underlying 
many Bayesian models may systematically misrepresent the 
true nature of brain function. Conventional Bayesian infer -
ence becomes analytically intractable under non-Gaussian 
noise conditions, and approximation methods often fail to 
capture the rich statistical structure of real neural activity. 
While proponents might argue that the brain could imple-
ment specialized algorithms to perform Bayesian inference 
under non-Gaussian conditions, such implementations 
would require vastly more computational resources than 
standard Bayesian methods and would introduce additional 
layers of complexity that strain biological plausibility.
At the same time, the widespread presence of non-Gauss-
ian statistics in neural systems suggests that the brain may 
rely on fundamentally different computational principles 
than those assumed by standard Bayesian theory. Dynamic 
systems approaches, which naturally account for non-Gauss-
ian fluctuations, criticality, and multistability, offer a com-
pelling alternative. These frameworks may provide more 
biologically realistic accounts of neural computation than 
the idealized models of probabilistic inference central to the 
Bayesian brain hypothesis.
Neuroanatomical inconsistencies: brain structures 
and circuit properties incompatible with Bayesian 
processing
The Bayesian brain hypothesis faces not only abstract com-
putational challenges but also concrete neuroanatomical 
inconsistencies that fundamentally undermine its biologi-
cal plausibility. These structural and functional properties 
of real neural tissue present obstacles that no amount of 
mathematical elegance can overcome:
• Dendritic integration dynamics:  Contrary to the pre-
cise weighted summation required by Bayesian models, 
dendritic integration in actual neurons exhibits highly 
nonlinear, context-dependent properties. Dendrites 
contain voltage-gated ion channels that create complex 
integration zones with supralinear and sublinear summa-
tion depending on the spatiotemporal pattern of inputs 
(Branco and Häusser 2010; London and Häusser 2005; 
Polsky et al. 2004). These dynamics create input–output 
functions that cannot be mapped onto the linear weighted 
averaging required for combining likelihoods and pri -
ors in Bayesian calculations. Moreover, single neurons 
often exhibit branch-specific plasticity rather than global 
weighting adjustments (Losonczy et al. 2008), contra-
dicting the assumption that synaptic weights represent 
statistical parameters in a coherent probabilistic model.
• Neuromodulatory effects on circuit dynamics: Bayes-
ian frameworks typically assume stable computational 
mechanisms with adjustable parameters (e.g., preci-
sion weighting). However, neuromodulators like dopa-
mine, acetylcholine, and norepinephrine fundamentally 
reconfigure circuit properties—not merely adjusting 
weights but qualitatively changing input–output func-
tions, intrinsic excitability, and even the direction of 
plasticity (Dayan 2012; Marder et al. 2014). This creates 
context-dependent processing modes that cannot be char-
acterized as mere parameter adjustments within a stable 
Bayesian architecture. The pervasive influence of these 
neuromodulatory systems means that neural circuits are 
constantly switching between fundamentally different 
computational regimes—an observation incompatible 
with the consistent application of Bayesian principles.
• Recurrent connectivity patterns and attractor dynam-
ics: Cortical and subcortical circuits exhibit dense recur-
rent connectivity that generates attractor dynamics, oscil-
2658 European Journal of Applied Physiology (2025) 125:2643–2677
latory patterns, and metastable states (Brinkman et al. 
2022; Deco and Hugues 2012). These dynamics create 
temporal dependencies that violate the Markov assump-
tions underlying sequential Bayesian updating. Further -
more, the prevalence of inhibitory interneurons creates 
winner-take-all dynamics and competitive inhibition 
that force categorical rather than probabilistic represen-
tations—a pattern seen in the sharp tuning curves and 
bistable activity patterns observed across cortical regions 
(Buzsáki 2006; Isaacson and Scanziani 2011). These pat-
terns indicate that neural circuits are organized around 
attractor dynamics rather than the continuous probability 
distributions required for Bayesian processing.
• Sparse, synchronous coding schemes: Bayesian models 
typically rely on distributed representations to encode full 
probability distributions across high-dimensional spaces. 
In contrast, empirical evidence suggests that actual neu-
ral activity is highly sparse and temporally structured. 
Many brain regions exhibit population activity where 
only < 10% of neurons are active simultaneously, with 
spike timing locked to ongoing oscillatory rhythms (Fries 
2015; Olshausen and Field 2004). While sparse coding is 
metabolically efficient and well-suited for feature extrac-
tion, it poses challenges for implementations that require 
continuous probabilistic sampling or integration across 
neural populations. The temporal and anatomical con -
straints that give rise to sparse, synchronous activity are 
not just computational limitations—they reflect architec-
tural principles that may be fundamentally incompatible 
with the assumptions of Bayesian inference. Encoding 
and maintaining full posterior distributions in such sys-
tems would require coordination and representational 
bandwidth not supported by current neurophysiological 
data (Olshausen and Field 2004). Thus, the mismatch is 
not merely one of degree, but of representational format 
and underlying biophysical feasibility.
• Anatomical specialization versus domain-general 
Bayesian processing: The brain exhibits extreme ana-
tomical specialization with distinct cell types, circuit 
motifs, and processing principles across regions—from 
the unique neuronal types of the cerebellum to the colum-
nar organization of sensory cortices to the distinct micro-
circuits of the basal ganglia (Harris and Shepherd 2015; 
Nelken 2004). This neuroanatomical diversity contradicts 
the assumption of a uniform Bayesian processing prin-
ciple operating throughout the brain. If Bayesian infer -
ence were a core organizing principle, we would expect 
greater uniformity in computational architecture; instead, 
we observe region-specific wiring patterns optimized for 
particular transformations rather than general-purpose 
probabilistic inference.
• Developmental constraints on precision-based hier -
archies: Predictive coding models within the Bayes-
ian brain framework assume hierarchically organized 
precision-weighting mechanisms. However, examining 
the developmental trajectory of neural circuits reveals 
that these supposedly precision-weighted connections 
develop according to genetically guided principles and 
activity-dependent pruning mechanisms that do not 
incorporate statistical precision information (Katz and 
Shatz 1996; Wong and Ghosh 2002). The laminar con-
nections that supposedly implement hierarchical mes-
sage-passing develop through molecular guidance cues 
and critical period mechanisms that are insensitive to the 
statistical properties predictive coding requires. These 
developmental constraints produce circuit architectures 
determined more by embryological and molecular factors 
than by the statistical requirements of Bayesian inference.
• Non-parametric plasticity mechanisms: Synaptic 
plasticity mechanisms—the presumed basis for learn -
ing statistical relationships in Bayesian models—oper -
ate according to principles incompatible with Bayesian 
updating. Long-term potentiation and depression depend 
on coincidence detection, postsynaptic calcium levels, 
retrograde messengers, and structural reorganization 
rather than error-based updating of statistical param-
eters (Feldman 2012 ; Malenka and Bear 2004 ). These 
mechanisms produce binary-like, threshold-dependent 
changes rather than the continuous parameter adjust-
ments required for proper Bayesian updating. Further -
more, homeostatic plasticity operates to maintain overall 
activity levels rather than statistical accuracy (Turrigi -
ano and Nelson 2004), often pushing synaptic weights 
in directions opposite to what Bayesian learning would 
predict.
These neuroanatomical inconsistencies collectively present 
insurmountable challenges to any literal interpretation of 
the Bayesian brain hypothesis. The fundamental organizing 
principles of neural tissue—from dendritic integration to 
circuit motifs to plasticity mechanisms—reflect evolutionary 
pressures favoring robustness and energy efficiency under 
biological constraints, rather than the implementation of 
probabilistic inference. While mathematical models might 
abstract away these biological details, a truly scientific the-
ory of brain function cannot ignore the actual properties of 
the substrate it purports to explain. The mismatch between 
Bayesian computational requirements and neuroanatomical 
reality suggests that the brain employs fundamentally dif-
ferent organizational principles than those proposed by the 
Bayesian framework. If the theory demands mechanisms that 
biology cannot provide, then the elegance of its math is no 
substitute for empirical viability.
2659European Journal of Applied Physiology (2025) 125:2643–2677 
Neurophysiological implausibility
These assumptions face significant challenges when con-
fronted with known properties of neural systems: 
1. Metabolic and computational constraints: Exact 
Bayesian inference is computationally intensive. While 
approximate methods exist, even these impose substan-
tial burdens that appear incompatible with the brain’s 
energy budget. Neural tissue is metabolically expensive, 
consuming approximately 20% of the body’s energy 
despite comprising only 2% of body mass (Attwell and 
Laughlin 2001; Magistretti and Allaman 2015). The 
computational resources required for full Bayesian infer-
ence across multiple sensory modalities would impose 
prohibitive energy costs (Harris et al. 2012).
2. Temporal dynamics mismatch: Neural processing 
occurs through complex parallel and recurrent dynam-
ics across multiple timescales. These dynamics do not 
align well with the sequential, iterative nature of Bayes-
ian updating. The brain must respond to environmental 
challenges within milliseconds, while proper Bayesian 
inference in complex state spaces would require exten-
sive computation time, creating a fundamental temporal 
mismatch (Csicsvari et al. 1999; Hari and Parkkonen 
2015).
3. Representational capacity limitations: Representing 
full probability distributions over high-dimensional 
state spaces would require vast neural resources. Sim-
ple laboratory tasks might involve only a few variables, 
but real-world perception involves thousands of interact-
ing dimensions. The representational capacity required 
exceeds what could plausibly be implemented in neural 
tissue, particularly for continuous variables with theo-
retically infinite possible states (Beck et al. 2012; Fiser 
et al. 2010).
4. Noise and variability: Neural systems exhibit substan-
tial intrinsic noise and variability at all levels, from ion 
channel fluctuations to large-scale network dynamics 
(Renart et al. 2010). While Bayesian models elegantly 
incorporate uncertainty, they typically assume well-
behaved noise distributions that may not match the 
complex, state-dependent noise characteristics of real 
neural systems. This intrinsic neural variability would 
systematically undermine the precision of any attempted 
Bayesian computations.
5. Context-dependent processing: Neural responses show 
remarkable context-sensitivity, with the same circuits 
serving different roles in processing different behavioral 
states, neuromodulatory influences, and task demands 
(Bargmann 2012; Gilbert and Li 2013). This flexible, 
adaptive processing conflicts with the relatively rigid 
computational structure implied by hierarchical Bayes-
ian models. Furthermore, neuromodulatory systems 
dynamically reconfigure circuit properties in ways that 
do not map cleanly onto Bayesian parameters like pre -
cision-weighting.
6. Implementation gap: Proponents have suggested vari-
ous neural implementations of Bayesian computations, 
including population coding, probabilistic population 
codes, and sampling-based approaches (Pouget et al. 
2013). However, these proposals remain largely theoreti-
cal and lack direct empirical confirmation. The neural 
mechanisms that could perform the necessary computa-
tions—encoding priors, computing likelihoods, and inte-
grating these according to Bayes’ rule—have not been 
convincingly shown in biological neural circuits.
7. Developmental implausibility: The Bayesian frame-
work struggles to explain how appropriate priors and 
generative models could be established during develop-
ment. While some priors might be genetically encoded, 
many must be learned through experience. This creates 
a bootstrapping problem: how could a developing brain 
learn appropriate probabilistic models without sufficient 
models to interpret its experiences? (Smith and Gasser 
2005; Zhao et al. 2024)
8. Evolutionary considerations: From an evolutionary 
perspective, organisms require fast, efficient, and reliable 
mechanisms that are sufficiently effective for survival 
in complex and often unpredictable environments—not 
mechanisms that necessarily deliver statistically optimal 
inference. Natural selection tends to favor strategies that 
work well enough under real-world constraints, includ-
ing limited time, energy, and computational capac-
ity. The high computational complexity and resource 
demands of full Bayesian inference make it an implau-
sible candidate for biological implementation, especially 
when simpler, more robust heuristic strategies can yield 
adaptive behavior with far less cost. These heuristics, 
shaped by evolutionary pressures, often perform remark-
ably well in natural settings despite their departure from 
statistical optimality (Cosmides and Tooby 1996; Gig-
erenzer and Goldstein 1996; Gigerenzer and Brighton 
2009; Gigerenzer 2020; Marewski and Schooler 2011). 
As such, the brain is more likely to implement these 
satisficing solutions than to engage in the exhaustive 
computations required by normative Bayesian models.
These neurobiological constraints collectively suggest that 
the Bayesian brain hypothesis, while mathematically ele-
gant, faces serious limitations as a literal account of neural 
function. Although certain behaviors may resemble Bayesian 
inference in controlled settings, the underlying neural mech-
anisms likely rely on non-Bayesian, heuristic processes that 
are more consistent with the biological realities of the brain. 
Neural systems operate under severe constraints—metabolic, 
2660 European Journal of Applied Physiology (2025) 125:2643–2677
temporal, and structural—that often preclude the kind of 
optimal computation the hypothesis assumes. Despite these 
challenges, the Bayesian framework continues to shape theo-
retical models, sometimes more for its conceptual appeal 
than its empirical plausibility. This enduring influence 
underscores the need for deeper scrutiny of its assumptions 
and a greater willingness to engage with alternative models 
better suited to the messy, adaptive nature of living systems.
The limitations of the Bayesian brain hypothesis become 
particularly apparent when compared to alternative theo-
retical frameworks that conceptualize cognition in funda-
mentally different terms. These alternatives offer not just 
competing explanations but challenge the basic assumptions 
upon which the Bayesian approach rests.
Alternative views of cognition
To know a mind, you must first acknowledge that it 
evolved not in the pristine realm of probability distri-
butions, but in the messy, constraint-laden world of 
bodies navigating environments. Cognition emerges 
not from internal models but from the dynamic dance 
between organism and world.
The limitations of the Bayesian brain hypothesis become 
clearer when contrasted with alternative frameworks that 
conceptualize cognition in fundamentally different terms. 
These alternatives do not merely offer competing accounts 
within the same basic paradigm but challenge the founda-
tional assumptions on which Bayesian models rest. Where 
Bayesian models begin with inference, representation, and 
error minimization, these alternatives begin with embodi-
ment, interaction, and dynamic constraint—treating cogni-
tion not as a computational problem solved by internal mod-
els but as an emergent phenomenon of systems embedded in 
material, temporal, and relational contexts, shaped continu-
ously by bodily dynamics, environmental affordances, and 
the irreversible flow of lived experience.
Dynamic systems approaches
Dynamic systems theory considers cognition emerging from 
complex, nonlinear interactions among neural, bodily, and 
environmental components (Kelso 1995; Thelen and Smith 
1994; Van Orden et al. 2003). Rather than focusing on infor-
mation processing or probabilistic inference, this approach 
emphasizes how cognitive functions self-organize through 
the continuous coordination of processes unfolding across 
multiple timescales (Beer 2000; Sporns and Edelman 1993). 
Prediction, in this framework, is not the outcome of inter -
nal model selection but a natural consequence of tempo-
rally structured dynamics—where the system’s history and 
current state constrain its future evolution, without requiring 
explicit Bayesian updating (Schmidt and Richardson 2008; 
Richardson et al. 2014).
Ecological psychology
The ecological approach rejects the assumption that percep-
tion requires inference, reconstruction, or internal models 
of the world (Gibson 1966, 1979). Instead, it proposes that 
organisms directly perceive affordances—possibilities for 
action—by detecting invariant structures in ambient sensory 
arrays (Chemero 2009; Turvey 1992). Perception, then, is 
not a problem of interpretation under uncertainty but a con-
tinuous process of attunement to ecological information. It 
is fundamentally action-oriented, relational, and environ-
ment-coupled, grounded in real-time interaction rather than 
mediated by internal representations or probabilistic infer -
ence (Michaels and Carello 1981; Warren 2021). This ori-
entation stands in direct contrast to Bayesian frameworks, 
which assume that perception involves constructing internal 
hypotheses about hidden causes of sensory input; the eco-
logical view holds that no such detour through representa-
tion is necessary when information is already available in 
the structure of the environment.
Embodied and enactive cognition
Embodied cognition emphasizes how cognitive processes 
are shaped by the physical body and its sensorimotor inter -
actions with the world (Clark 1999; Shapiro 2019; Varela 
et al. 1991). Related enactive approaches view cognition as 
constituted by the dynamic coupling between organism and 
environment, rather than as computation occurring within 
the brain (Di Paolo et al. 2017; Thompson and Varela 2001). 
These perspectives shift the explanatory focus from internal 
models to the organism-environment system as the proper 
unit of analysis (Gallagher 2017 ; Noë 2004). What unites 
these alternatives is their treatment of cognition as emer -
gent, context-sensitive, and fundamentally non-inferential. 
They suggest that prediction and adaptive behavior can arise 
from rich dynamical coupling with the environment, with-
out necessarily involving probabilistic inference or Bayesian 
computation (Anderson 2014; Chemero 2009).
Importantly, these frameworks offer empirically distinct 
predictions from Bayesian models. For instance, they predict 
that cognitive performance will be highly sensitive to bod-
ily states and environmental contexts in ways that purely 
brain-based inferential models might not anticipate (Barsa-
lou 2008; Spivey 2007). They also suggest that the temporal 
dynamics of neural activity may reflect ongoing engagement 
with the environment rather than sequential updating of 
internal models (Kiverstein and Rietveld 2018; Raja 2019).
2661European Journal of Applied Physiology (2025) 125:2643–2677 
By taking these alternatives seriously, we gain a broader 
and more grounded perspective on the limitations of the 
Bayesian brain hypothesis. What appears from one theo-
retical vantage point as probabilistic inference may, from 
another, be more coherently understood as dynamic cou-
pling, direct perception, or embodied action unfolding in 
real time. These frameworks do not merely shift explanatory 
emphasis; they pose a conceptual alternative, though their 
ability to generate tightly constrained predictions remains 
an open challenge. This pluralistic approach reminds us 
that mathematical descriptions, however elegant or inter -
nally consistent, represent only one possible way of carving 
nature at its joints—and that the joints themselves may not 
always lie where the equations suggest (Dale et al. 2013; 
Richardson et al. 2008). By loosening the grip of inference 
and embracing interaction, these alternatives invite a neuro-
science more attuned to the realities of living systems than 
to the ideals of formal logic.
A full comparative evaluation of these alternative frame-
works is beyond the scope of this critique, which is focused 
on exposing the limitations of the Bayesian paradigm. How-
ever, we acknowledge the importance of more thoroughly 
articulating the empirical and mechanistic commitments of 
these approaches, and we view that effort as a necessary 
complement to the present work. Such work will require not 
only detailing their successes but also clarifying the domains 
in which they outperform—or meaningfully diverge from—
Bayesian accounts.
A fictional dialogue: Critic vs. Bayesian 
theorist
The more universal a theory claims to be, the more 
invisible its assumptions become. What appears as 
mathematical insight may simply be metaphysical 
sleight-of-hand—turning epistemic flexibility into 
evidence, and unfalsifiability into strength.
To illustrate the core conceptual tension at the heart of the 
Bayesian brain and Free Energy Principle frameworks, we 
present a fictional but representative exchange between a 
critical interlocutor and a proponent (though this dialogue 
does not reproduce actual statements). This constructed dia-
logue serves as a heuristic device to clarify where the theo-
ry’s strengths intersect with its vulnerabilities—particularly 
in terms of scope, testability, and mechanistic specificity. It 
is not intended as a verbatim transcript but as a distillation 
of recurring arguments on both sides.
Critic: Dr. Bayesian theorist, you’ve argued that the 
Free Energy Principle (FEP) underlies all self-organizing 
systems, from bacteria to candle flames, and that the brain 
operates in a fundamentally Bayesian way—constantly 
minimizing “surprise.” Critics worry this makes your the-
ory unfalsifiable. They say, “If everything is doing Bayes -
ian inference, the idea loses empirical bite.” How do you 
respond?
Bayesian theorist:  The principle is universal: any system 
maintaining its integrity—bacterium, cell, brain—can be 
cast as minimizing free energy. I don’t see that as a draw -
back. Universality reflects the fundamental nature of self-
organization, not a lack of empirical content.
Critic: But critics point to your own examples: a can-
dle flame or a bacterium apparently also “minimizes free 
energy.” Yet no one claims a flame is actually computing  
Bayesian posteriors. Doesn’t that ring of absurdity?
Bayesian theorist: To call it “absurd” is to miss the point. 
The candle-flame example shows a physical system evolving 
in a way that can be described using the same mathematics 
we apply to living systems. That doesn’t mean the flame has 
internal generative models. It means the underlying dynam-
ics—entropy flows, thermodynamics—are expressible in 
free-energy terms. The same math can describe everything 
from quantum phenomena to adaptive brains.
Critic: That’s exactly the problem: a flame is obviously not 
thinking or updating priors. If both nonthinking flames and 
sophisticated brains are described by “Bayesian” or “free-
energy” equations, it looks like you’re labeling any  self-
organizing process “Bayesian.”
Bayesian theorist: You could call it Bayesian in a formal 
sense, but I see it as evidence of a unifying principle. The 
brain’s internal dynamics instantiate more complex versions 
of the same fundamental process. Don’t conflate “Bayes -
ian explanation” with “deliberate calculation.” My point 
has always been that living systems must reduce surprise to 
persist, and those dynamics can be cast in Bayesian terms.
Critic: But if you can cast anything in Bayesian terms, how 
can we show it’s wrong? Couldn’t you just rewrite the mod-
el’s “priors” every time something unexpected happens, so 
you can say, “Look, it was always Bayesian!”
Bayesian theorist: The principle is not a matter of rewriting 
at whim. It constrains how you adjust priors or likelihoods. 
If a system consistently defies Bayesian predictions—for 
instance, if hierarchical error-correction utterly fails—we’d 
need a different explanation. The fact we can keep refining 
a Bayesian model doesn’t mean we can’t fail; it just means 
the FEP is broad enough to generate models for diverse 
scenarios.
2662 European Journal of Applied Physiology (2025) 125:2643–2677
Critic: In everyday neuroscience, illusions, multisensory 
integration, and motor control are called “Bayesian success 
stories.” Skeptics say those models have so many parameters 
that even odd results can be fitted retroactively. Where’s the 
big falsification? Couldn’t a sufficiently flexible Bayesian 
model also explain me walking into a lamppost?
Bayesian theorist: (Laughs) Overfitting can happen in any 
modeling framework. But we focus on mechanistic detail—
which neural populations encode priors, how synapses 
implement error-correction, and so on. If we cannot locate 
or measure these processes in actual neural data, then the 
model remains purely formal. But real Bayesian neurosci-
ence tries to ground the math in genuine physiology.
Critic: Yet your own candle-flame or bacterial examples 
seem to trivialize that. They also show up in discussions of 
the Free Energy Principle: a flame or a microbe doesn’t have 
neurons, so how is it Bayesian? Some observers see that as 
a reductio ad absurdum.
Bayesian theorist:  I never claimed a flame literally  per-
forms Bayesian updates. It’s about self-organization—the 
math is universal, but the specific mechanistic implementa-
tion differs vastly. A candle flame has only a transient bound-
ary, while an organism has a stable Markov blanket that sup-
ports hierarchical processes akin to Bayesian inference.
Critic: Still, you give an impression that everything fits 
under free-energy minimization, so critics wonder if it’s 
truly a testable  theory. Doesn’t its sweeping scope risk 
nonfalsifiability?
Bayesian theorist: People conflate broad applicability with 
an absence of testability. The principle is broad, but actual 
models of neural systems are specific. Take predictive cod-
ing in vision, for example: if certain error signals or top-
down predictions aren’t found where the theory says they 
should be, that challenges the model. Some of these con-
cerns are valid—especially when Bayesian models are used 
metaphorically or post hoc. But well-specified models can 
and do make falsifiable predictions.
Critic: And if the data don’t match, you can just posit new 
priors or updated likelihoods. That’s what makes it feel slip-
pery. Maybe the candle flame is a comedic extreme, but to 
many, it exemplifies how you can “explain” anything by 
shoehorning it into a Bayesian or free-energy story.
Bayesian theorist: I accept that critics see it that way. My 
stance is that the theory’s generality shows how universal 
processes, like thermodynamic minimization, continue into 
biological and cognitive realms. If you want to call that 
“slippery,” so be it. I view it as a deep unification of physics 
and biology. Whether one finds that profound or suspicious 
might depend on one’s philosophical commitments.
Critic (turning to the audience): So there you have 
it. Dr. Bayesian theorist maintains the view that the Free 
Energy Principle and Bayesian frameworks are universal, 
and that this universality doesn’t negate testability. Many of 
us remain skeptical, especially when a candle flame can be 
dubbed a free-energy minimizer. But Dr. Bayesian theorist 
stands firm: the math unifies how living systems arise from 
physical processes, and our criticisms do not bring down 
his core claim.
Why the myth persists
Ideas do not spread by truth alone, but by prestige, 
mathematical fluency, and the comforting promise 
of order amid chaos. The Bayesian brain persists not 
because it accurately describes neural function, but 
because it satisfies our desire for elegant theories that 
render the world comprehensible through equations.
Despite its conceptual and empirical shortcomings, the 
Bayesian brain hypothesis continues to exert enormous 
influence on cognitive neuroscience. Understanding this 
persistence requires examining both intellectual and socio-
logical factors that sustain the approach despite its problems. 
The resilience of this framework in the face of substantial 
criticism represents a fascinating case study in the sociol-
ogy of scientific knowledge and the dynamics of theoretical 
entrenchment in contemporary neuroscience.
The appeal of mathematical elegance
Bayesian models offer something precious in science: 
mathematical precision and formal elegance. The ability to 
express complex cognitive phenomena in the language of 
probability theory creates a satisfying sense of clarity and 
rigor. This mathematical tractability facilitates modeling, 
hypothesis testing, and theoretical integration in ways that 
less formalized approaches cannot match. As Kuhn (1962) 
noted in his analysis of scientific paradigms, the aesthetic 
appeal of theories—their simplicity, coherence, and math-
ematical beauty—often plays a crucial role in their accept-
ance and persistence. The Bayesian framework exemplifies 
this phenomenon, offering researchers a clean, formalized 
language that promises to bring order to the messy complex-
ity of neural systems. This aesthetic allure is not merely a 
philosophical curiosity; it has real consequences for how 
theories gain traction and guide empirical investigations in 
contemporary neuroscience.
2663European Journal of Applied Physiology (2025) 125:2643–2677 
The mathematical formalism of Bayesian approaches 
has particular appeal in an era when neuroscience increas-
ingly values computational sophistication (Kriegeskorte 
and Douglas 2018). Complex statistical techniques, com-
putational models, and mathematical abstractions carry 
significant prestige in contemporary science, often serv -
ing as markers of theoretical rigor and sophistication. This 
“mathematization” of neuroscience reflects broader trends 
across the sciences, where quantitative approaches tend to 
displace qualitative ones, regardless of their explanatory 
adequacy (Gigerenzer and Brighton 2009; Gigerenzer 2020). 
As a result, theories are often judged more by their formal 
consistency and technical elegance than by their capacity to 
generate novel, testable insights about biological systems. 
The Bayesian brain hypothesis benefits from this cultural 
privileging of mathematical formalism, gaining credibility 
partly through its quantitative sophistication rather than its 
empirical or mechanistic plausibility.
Moreover, the Bayesian framework connects to a ven-
erable tradition of understanding cognition as rational or 
optimal within constraints (Anderson 2013; Chater and 
Oaksford 1999). It offers a comforting vision of the brain 
as fundamentally rational, implementing statistically opti-
mal solutions to cognitive problems. This aligns with long-
standing philosophical and scientific aspirations to discover 
underlying rationality in human thought, a project that 
extends back through the history of cognitive science to the 
Enlightenment ideal of human rationality (Gigerenzer and 
Goldstein 1996). By echoing these deep-rooted ideals, the 
Bayesian approach inherits not just intellectual appeal but 
also a kind of cultural legitimacy that can make it resist-
ant to empirical challenge. The Bayesian view thus appeals 
not only to technical considerations but to deeper cultural 
narratives about the nature of mind and its relationship to 
mathematical order.
The technical advantages of Bayesian methods further 
reinforce their appeal. Their capacity to handle uncertainty, 
incorporate prior knowledge, and update beliefs based 
on evidence makes them effective for modeling complex 
systems (Gelman et al. 1995; MacKay 2003). This utility 
incentivizes researchers to adopt the Bayesian framework, 
independent of its deeper theoretical claims about neural 
function. However, technical utility alone can foster a kind 
of theoretical complacency, where successful applications 
are mistaken for confirmation of foundational assumptions. 
As researchers invest time and resources in developing 
Bayesian models and methods, this momentum creates a 
path dependency that sustains the framework even when its 
foundational assumptions remain questionable.
The power of metaphor
As a metaphor, the Bayesian brain has undeniable power. 
The image of the brain as a prediction machine, constantly 
testing hypotheses against incoming evidence, provides an 
intuitive and generative way of thinking about neural func-
tion (Clark 2013; Hohwy 2013). Even if the implementation 
details remain murky, the metaphor helps organize diverse 
findings and suggests new research directions. Cognitive sci-
entists have long recognized the importance of metaphors 
in scientific theorizing—from computer models of mind to 
neural networks to dynamical systems (Gentner and Grudin 
1985; Lakoff and Johnson 1980). These metaphors function 
not merely as pedagogical devices but as conceptual scaf-
folds that structure research programs and shape theoretical 
intuitions.
The predictive processing metaphor inherits the cultural 
authority of Bayesian statistics while connecting to intui-
tive notions of prediction and error-correction that resonate 
across multiple levels of description (Clark 2015). Its con-
ceptual versatility allows it to be deployed across domains—
from low-level sensory processing to high-level cognition, 
from individual neurons to large-scale networks. This cross-
domain applicability creates a sense of theoretical unifica-
tion that is deeply appealing in a field often characterized by 
fragmentation and specialization (Friston 2010).
The very ambiguity discussed earlier—the slippage 
between metaphor and mechanism—may paradoxically 
contribute to the framework’s appeal. This conceptual flex-
ibility allows researchers to engage with the framework at 
different levels of commitment, from loose inspiration to 
strong mechanistic claims, depending on their goals and dis-
ciplinary backgrounds (Jones and Love 2011). Philosophers 
can explore its epistemological implications; computational 
neuroscientists can develop formal models; experimental 
neuroscientists can interpret neural data within its concep-
tual framework—all without necessarily agreeing on the 
precise status or scope of the claims being made. This inter-
pretive flexibility functions as a form of “boundary object” 
in science studies terms—a conceptual entity that is plastic 
enough to adapt to local needs while robust enough to main-
tain a common identity across contexts (Star and Griesemer 
1989). But while this flexibility facilitates interdisciplinary 
dialogue and theoretical innovation, it also blurs the lines 
between scientific theory and rhetorical scaffold, making 
it increasingly difficult to discern where genuine empirical 
content ends and metaphorical or programmatic resonance 
begins.
Furthermore, the predictive processing narrative offers 
an appealing synthesis of seemingly opposing traditions in 
cognitive science—bringing together representationalist 
and embodied approaches, computational and dynamical 
perspectives, and internalist and externalist views of mind 
2664 European Journal of Applied Physiology (2025) 125:2643–2677
(Allen and Friston 2018; Clark 2015). This synthetic qual-
ity positions the framework as a potential bridge across 
entrenched theoretical divides, enhancing its attractiveness 
to researchers from various disciplinary and philosophical 
backgrounds. Proponents frequently underscore this poten-
tial, suggesting that predictive processing can reconcile con-
flicting paradigms and move the field beyond dichotomous 
thinking, resolving longstanding debates rather than merely 
choosing sides in them (Kirchhoff 2018).
The Bayesian brain metaphor, while powerful, carries 
potential epistemological risks. As Kuhn (1962) noted, 
dominant metaphors can hinder scientific progress when 
they obscure observations that challenge the prevailing 
framework. When a metaphor transitions from productive 
heuristic to unquestioned background assumption, it risks 
becoming what Bachelard (2002) called an “epistemologi-
cal obstacle”—a conceptual barrier that hinders rather than 
facilitates discovery. In the case of the Bayesian brain, the 
predictive metaphor’s very success may lead researchers to 
overlook or reinterpret evidence inconsistent with its basic 
premises, potentially obscuring alternative conceptualiza-
tions of neural function that might better account for certain 
aspects of cognition and behavior (Anderson 2017). This 
concern invites a critical question for cognitive neurosci -
ence: not merely whether the metaphor is useful, but under 
what conditions should be refined, limited, or even replaced 
by more empirically grounded frameworks.
Institutional and sociological factors
Scientific practices are shaped by evidence and social and 
institutional factors that influence research funding, pub-
lication, and recognition (Latour 1987; Longino 2020). 
The Bayesian brain hypothesis emerged during a period of 
increasing mathematization in neuroscience and psychology, 
when computational approaches gained prestige and insti-
tutional support (Dupré 1993; Piccinini and Craver 2011). 
This timing positioned it to benefit from broader trends in 
funding and publication, where mathematically sophisticated 
approaches often receive preferential treatment.
The framework has been championed by influential 
researchers at prestigious institutions, whose intellectual 
authority lends credibility and accelerates its diffusion 
through influential scientific networks (Whitley 2000). High-
profile publications in elite journals have further reinforced 
its position as a dominant, mainstream approach, creating 
a self-reinforcing cycle in which early prominence leads to 
increased visibility, higher citation counts, and sustained 
influence across disciplines. This well-documented Matthew 
effect in scientific recognition—where initial advantages 
accumulate and intensify over time—helps explain how 
certain theoretical frameworks can rise to prominence and 
maintain dominance, even when their empirical adequacy 
remains contested or incomplete (Merton 1968).
Once established as a dominant paradigm, such frame -
works tend to perpetuate through various mechanisms: fund-
ing agencies prioritize research within established frame-
works; graduate students are trained in these approaches; 
journals favor papers that extend or apply the dominant 
paradigm. Kuhn (1962) described this phenomenon decades 
ago as the self-reinforcing nature of scientific paradigms, 
where normal science operates within established concep-
tual frameworks rather than challenging their foundations. 
The Bayesian brain has achieved paradigmatic status in cer-
tain areas of cognitive neuroscience, with researchers more 
likely to work within its assumptions than to question them 
fundamentally.
Career incentives further reinforce this pattern. Young 
researchers face strong pressures to publish in high-impact 
journals and secure competitive grants—goals more easily 
achieved by working within established frameworks than 
by challenging them (Smaldino and McElreath 2016). The 
safer career path involves extending or applying the Bayes-
ian framework rather than developing alternatives or expos-
ing its limitations, thereby creating a selection pressure in 
the academic ecosystem that favors theoretical conformity 
over innovation or critique (Akerlof and Michaillat 2018). 
Furthermore, the publishing landscape in contemporary sci-
ence rewards novel, positive findings over replications or 
negative results (Ioannidis 2005; Romero 2017).
This creates pressure to adapt research to fit popular 
frameworks, even when the evidence is ambiguous. The 
flexibility of Bayesian models makes them particularly sus-
ceptible to this dynamic, as priors, precision-weighting, and 
hierarchical depth can be adjusted to accommodate almost 
any finding. Researchers have strong incentives to interpret 
their results as supporting or extending the Bayesian frame-
work, rather than challenging it—leading to a literature that 
systematically over-represents supportive evidence (Ioan-
nidis 2008; Nosek et al. 2012).
The interdisciplinary nature of the Bayesian brain hypoth-
esis also contributes to its resilience. Criticisms about non-
Gaussian neural dynamics from neurophysiologists can 
be deflected by computational theorists highlighting the 
framework’s mathematical elegance, while concerns about 
mechanistic implementation from cellular neuroscientists 
can be dismissed by philosophers emphasizing its unifying 
conceptual power (Longino 2020). These factors combine 
to create a situation in which the explanatory limitations 
of the Bayesian brain hypothesis are systematically under -
explored or downplayed, while its perceived successes are 
prominently highlighted and widely celebrated. The result 
is acquiring the status of an entrenched but under-specified 
paradigm—a compelling narrative that endures not only 
because of selective empirical support, but also because 
2665European Journal of Applied Physiology (2025) 125:2643–2677 
of its mathematical elegance, metaphorical resonance, and 
accumulated sociological momentum (Smaldino and McEl-
reath 2016). Gaining a clear understanding of these extra-
empirical influences is essential for critically evaluating the 
Bayesian brain hypothesis’s current status and advancing 
more epistemically rigorous and scientifically accountable 
approaches to theoretical neuroscience.
As the philosopher of science Lakatos (2014) argued, 
research programs that continually accommodate counter -
evidence by adjusting auxiliary assumptions may become 
degenerative rather than progressive. The Bayesian brain 
hypothesis risks following this trajectory when confronted 
with mechanistic challenges—by retreating to increasingly 
abstract formulations of “approximated” inference, “hier -
archical” cortical implementations, or “implicit” Bayesian 
operations that become progressively detached from testable 
neural mechanisms (Bowers and Davis 2012). The frame-
work’s persistence despite substantial criticism illustrates 
broader patterns in scientific theorizing—how aesthetic, 
practical, and social factors shape theory choice alongside 
empirical considerations.
This does not mean that the Bayesian brain hypothesis 
lacks scientific value, but rather that its dominance cannot 
be explained by its empirical or explanatory successes alone. 
A full understanding of its place in contemporary neurosci-
ence requires attention to both its intellectual content and its 
sociological context (Firestein 2012; Longino 2020). One 
key to its resilience lies in traversing different explanatory 
levels, often without explicitly committing to any of them. 
This strategic slippage is often hidden behind invocations 
of Marr’s framework, which, rather than clarifying explana-
tory levels, has become a rhetorical escape hatch. As shown 
in Table 4, this strategic slippage between Marr ’s ( 1982) 
levels of analysis allows proponents to evade empirical 
accountability without relinquishing theoretical authority.
Post‑Bayesian neuroscience: Dynamics, 
constraints, and interaction
The future of neuroscience lies not in decoding inter -
nal maps, but in understanding the terrain of interac-
tions that shape them.
If the Bayesian brain hypothesis falters in its promise to 
mechanistically account for cognition, it is not for lack of 
mathematical elegance but for its failure to capture the situ-
ated, dynamical, and interaction-dominated nature of biolog-
ical systems. Moving beyond this paradigm does not mean 
abandoning rigor or predictive power; it means shifting the 
center of gravity from inference to interaction, from static 
priors to evolving constraints, and from internal representa-
tions to systemic dynamics. The alternative is not chaos but a 
more grounded, empirically generative science of constraint-
driven dynamics. To move beyond critique, Table 5 provides 
side-by-side examples of how constraint-based, dynamical 
approaches reframe core empirical domains traditionally 
modeled under Bayesian assumptions. These reorientations 
invite new modeling strategies, hypotheses, and empirical 
questions.
From representations to real‑time dynamics
Biological systems are not abstract inference engines. They 
are embodied, energy-consuming, open systems operating 
far from equilibrium. Their behavior emerges from richly 
structured, multi-timescale interactions among neural, 
physiological, and environmental processes. This shift—
from inference over symbolic content to constraint-driven 
coordination—requires models that treat cognition not as 
the manipulation of probability distributions, but as the sta-
bilization of activity within and across nested dynamical 
regimes.
In such a framework, the core unit of analysis is not the 
isolated variable or the internal model, but the evolving tra-
jectory of the system within a space of possibilities shaped 
by constraints: mechanical, metabolic, informational, con-
textual. Constraints here are not merely boundary condi-
tions or limitations; they are the generative architecture of 
Table 4  Levels of analysis or levels of evasion? A comparison of how Marr’s levels are invoked in ideal theory versus how they function rhetori-
cally within Bayesian brain literature
Level (Marr, 1982) Original purpose Bayesian brain rhetorical use
Computational Define the problem the system solves and why Used to justify abstract probabilistic goals (e.g., inference, minimization) 
without committing to implementational details
Algorithmic Specify the process and representations used Often skipped or loosely sketched; Bayesian updating is assumed rather 
than demonstrated in neural architecture
Implementational Describe the physical realization in the brain Invoked in post hoc fashion (e.g., population codes, cortical hierarchies), 
but lacking falsifiable mappings or physiological specificity
2666 European Journal of Applied Physiology (2025) 125:2643–2677
Table 5  How post-Bayesian frameworks rethink classic cognitive domains. This table contrasts the explanatory focus, assumptions, failure modes, and modeling strategies of Bayesian brain 
models versus interaction-dominant, constraint-based approaches. Examples are drawn from domains frequently used to support the Bayesian brain hypothesis
Domain Bayesian explanation Constraint-based alternative Implications for modeling and methodology
Multisensory integration The brain weights sensory cues based on prior 
reliability to form an optimal estimate
Cue weighting reflects bodily state, task 
demands, or environmental instability. 
Weighting adapts through time under meta-
bolic or attentional constraints
Bayesian fits collapse variability into priors; 
dynamical models treat variability as a 
function of state-dependent coupling. Study 
trial-to-trial dynamics instead of average 
performance
Perceptual illusions Deviations from veridical perception reflect 
strong priors overriding sensory input
Illusions emerge from ecological statistics or 
structural constraints of sensory surfaces. No 
inference is necessary
Bayesian accounts often fit priors post hoc; 
ecological/dynamical models study invariant 
detection and affordances. Test robustness 
across contexts
Motor control and trajectory planning Optimal control under uncertainty: movement 
trajectories minimize expected cost
Movement emerges from real-time coordina-
tion of mechanical, energetic, and sensory 
constraints. Control is distributed, not 
centralized
Shift from inverse models to real-time feedback 
loops. Use coupled oscillators or tensegrity 
models instead of optimal feedback control
Visual mismatch negativity (MMN) MMN reflects a neural prediction error in 
response to unexpected stimuli under a 
generative model
MMN arises from neural habituation, reso-
nance, or phase resetting—not from hierar-
chical prediction
Instead of inferring priors, test for critical 
slowing, entrainment, or adaptation dynamics. 
Predict responses to repetition or variability, 
not “surprise.”
Psychiatric symptoms (e.g., schizophrenia) Symptoms reflect misweighting of priors or 
prediction errors (e.g., hallucinations = over-
weighted priors)
Symptoms result from destabilized inter-sys-
tem coordination (e.g., disrupted brain-body-
environment coupling, neuromodulatory 
breakdown)
Bayesian models are post hoc and descriptive; 
constraint-based models identify attractor 
breakdowns and loss of resilience. Use phase 
transition markers and whole-system indica-
tors
Emotion and interoception Affective states result from probabilistic infer-
ence over interoceptive signals. Valence = 
prediction error
Emotion emerges from dynamic regulation of 
constraints (e.g., thermoregulation, meta-
bolic cost, proprioception). Affect = global 
coordination state
Rather than modeling internal inference, analyze 
physiological-environmental coupling. Use 
dynamical systems tools to track transitions 
between regulatory regimes
2667European Journal of Applied Physiology (2025) 125:2643–2677 
behavior. Stability, flexibility, and adaptability emerge not 
from optimal inference, but from the real-time modulation 
of dynamics under shifting constraints.
Modeling noise as signal: Complexity 
beyond Gaussian assumptions
Where Bayesian frameworks often rely on additive, station-
ary Gaussian noise for tractability, empirical observations 
consistently point toward noise that is multiplicative, state-
dependent, heavy-tailed, and temporally correlated. These 
fluctuations are not nuisances to be averaged away; they are 
deeply intertwined with the system’s capacity for respon-
siveness and adaptation. Rather than modeling cognition as 
the minimization of prediction error within a narrow band of 
assumptions, post-Bayesian frameworks embrace noise as a 
source of exploration, variability, and emergent organization.
This perspective invites the use of simulation tools that do 
not impose a preordained structure on noise, but that allow 
interactions among nested constraints to shape complex 
behavior. State-space modeling, noise-driven dynamical sys-
tems, agent-environment coupling, and stochastic resonance 
models are promising pathways. Importantly, such tools do 
not seek to reproduce behavior through optimization, but 
to reproduce the conditions under which coherent, adaptive 
patterns emerge.
Empirical commitments: from controlled inputs 
to naturalistic interaction
The research agenda for post-Bayesian neuroscience begins 
by shifting experimental emphasis. Rather than crafting ever 
more precise internal priors, we must develop methods to 
quantify how bodily states, environmental conditions, and 
temporal dependencies shape neural dynamics and behav -
ioral outcomes. This includes:
• Measuring constraint modulation across timescales 
(e.g., metabolic fatigue, task-switching, proprioceptive 
reweighting)
• Analyzing coordination and entrainment across systems 
(e.g., brain-heart, posture-vision, movement-breath)
• Modeling behavior as the product of interacting dynami-
cal systems with endogenous and exogenous inputs
• Designing tasks that probe adaptation under instability, 
uncertainty, or emergent constraint conflict
These approaches demand new methodological 
commitments:
• Longitudinal, high-dimensional recordings across neural 
and bodily systems
• Data analysis techniques sensitive to phase transitions, 
bifurcations, and nonstationarity
• Experimental designs that allow interaction, learning, 
and breakdown—not just well-constrained choice under 
fixed probabilities
Toward a science of coordination, not computation
A post-Bayesian neuroscience must ask different questions. 
Instead of asking what internal model best explains observed 
behavior, we should ask what interactive processes give rise 
to coordination and breakdown. Instead of modeling per -
ception as posterior estimation, we should investigate how 
perceptual systems stabilize amidst competing constraints. 
Instead of using priors to constrain likelihoods, we should 
examine how history, development, fatigue, and context 
modulate the attractor landscape of behavior.
This is a science of constraints and co-regulation, not rep-
resentation and error correction. It privileges fluidity over 
optimality, adaptability over accuracy, and coordination over 
computation. And crucially, it returns neuroscience to the 
task of understanding real organisms acting in real environ-
ments—not in the language of ideal observers, but in the 
dynamics of lived interaction.
This shift will not be easy. It requires new tools, new met-
aphors, and new standards for theoretical rigor. But it prom-
ises a neuroscience that is empirically anchored, biologically 
plausible, and better equipped to confront the complexity of 
embodied cognition. A neuroscience not of Bayesian brains, 
but of living, learning, and dynamically constrained bodies 
in motion. Where Marr’s computational level invites abstract 
formulations, the algorithmic and implementational levels 
demand specificity. Post-Bayesian models must engage these 
levels directly, grounding dynamics in biologically plausible 
mechanisms rather than idealized probabilistic reasoning.
Beyond Bayesianism
A science that fears contradiction is not a science 
that seeks truth but one that preserves dogma. The 
path forward requires not more flexible Bayesian 
models, but the courage to abandon mathematical 
convenience for biological reality.
This critical examination of the Bayesian brain hypothesis is 
not intended to dismiss its contributions or deny its insights. 
Rather, it aims to clarify its proper status and limitations in 
the scientific study of mind and brain. To conclude, I offer 
specific recommendations on how cognitive neuroscience 
might move forward in light of these critiques.
2668 European Journal of Applied Physiology (2025) 125:2643–2677
First, we must recognize that the Bayesian brain, while 
influential and mathematically sophisticated, risks becoming 
pseudoscientific when it sheds the two most important scien-
tific requirements: falsifiability and mechanistic grounding. 
Proponents must specify concrete neural implementations 
and falsifiable predictions to maintain scientific integrity. 
For example, falsification would require identifying condi-
tions under which a system’s behavior consistently violates 
Bayesian predictions—such as when neural populations fail 
to signal prediction error in response to surprising stimuli, or 
when behavior ignores prior probabilities in controlled deci-
sion tasks where such information is available and relevant. 
While some predictive coding and active inference models 
have been used to simulate observed neural responses, such 
simulations typically rely on adjusted priors and free param-
eters post hoc, rather than offering risky, a priori predictions 
that could be decisively falsified. For example, rather than 
merely claiming that perception follows Bayesian principles, 
researchers should identify specific neuronal populations 
that encode probability distributions and specify how these 
distributions are updated through synaptic mechanisms. Karl 
Friston’s Free Energy Principle, in particular, needs clearer 
operational definitions and greater specificity about what 
would constitute disconfirming evidence. Although terms 
like “Markov blanket” (Fig. 3) and “generative model” are 
often presented as mechanistic constructs, they frequently 
function as abstract formalisms without directly mapping 
specific neurophysiological structures or processes.
Second, we should embrace theoretical pluralism not as 
a weak compromise but as a principled alternative to the 
hegemony of Bayesian approaches. Visual neuroscience 
provides a case in point: while predictive coding models 
have gained prominence, robust empirical research contin-
ues to emerge from alternative frameworks—such as reso-
nance theories, neural synchrony models, and dynamic field 
approaches—that make no reference to Bayesian inference. 
These models often emphasize dynamical coordination, 
oscillatory coupling, or stability through feedback rather 
than probabilistic computation. Embodied approaches like 
those of Thelen and Smith, the ecological psychology of 
Gibson, and dynamical systems models developed by Kelso 
offer explanatory frameworks that directly challenge, rather 
than complement, Bayesian formulations. These approaches 
proceed from fundamentally different premises about the 
nature of cognition—emphasizing direct perception, self-
organization, and emergent dynamics rather than internal 
models and inference—and have generated productive 
research programs without the conceptual baggage of Bayes-
ian metaphysics.
Third, it is not sufficient to defend the Bayesian brain 
hypothesis by appealing to a misunderstood scope. This 
paper does not critique a caricature, but rather the dominant 
rhetorical and modeling practices associated with Bayesian 
brain theories. If the theory continually shifts between meta-
phor and mechanism, between universal law and specific 
model, then its boundaries must be clearly defined before its 
scientific status can be responsibly assessed. Future theories 
of mind and brain should prioritize biological plausibility, 
empirical testability, and theoretical humility. Sampling-
based approximations proposed by researchers like Fiser, 
Berkes, and Orbán represent promising steps toward bio-
logically realistic implementations of probabilistic infer -
ence. Yet even in approximation mode, these models often 
leave unclear what exactly is being approximated, how such 
Fig. 3  Illustrative examples of 
the conceptual overextension of 
the “Markov blanket” construct 
across ontologically disparate 
systems. While originally 
formalized as a boundary 
condition in graphical models 
of statistical dependency, the 
term has increasingly been 
applied to biological, cognitive, 
and even sociocultural enti-
ties—from neurons and cells to 
flames, microbes, nation-states, 
and human collectives. This 
proliferation raises concerns 
about the dilution of mechanis-
tic specificity and the erosion 
of explanatory constraint within 
theoretical neuroscience

2669European Journal of Applied Physiology (2025) 125:2643–2677 
approximations are implemented neurally, and under what 
conditions the brain diverges from or conforms to Bayesian 
logic. Proponents often respond that approximate inference 
mitigates concerns about biological plausibility. However, 
invoking approximation does not clarify the underlying pro-
cess—unless the approximations themselves are mechanisti-
cally specified and empirically constrained, the theory risks 
being shielded from disconfirmation. This ambiguity allows 
Bayesian claims to persist in the absence of direct empiri-
cal support. Without such specificity, the models remain 
computationally elegant but biologically opaque. Greater 
scrutiny is especially warranted for frameworks like active 
inference: while Adams, Shipp, and Friston have proposed 
that neuromodulators encode precision, these claims remain 
largely post hoc and have not yielded novel, specific, and 
empirically validated predictions. This exemplifies the core 
problem critiqued throughout this paper—the tendency to 
retrofit existing findings into Bayesian language without 
offering falsifiable hypotheses. Going forward, cognitive 
neuroscience must prioritize approaches that genuinely 
connect abstract computational principles to concrete neural 
mechanisms and produce truly testable experimental predic-
tions—something the Bayesian brain literature has largely 
failed to deliver.
Finally, we should embrace the messiness and complexity 
of embodied, context-sensitive cognition without forcing it 
into ill-fitting probabilistic frameworks. While Cisek and 
Kalaska’s work on affordance competition offers valuable 
insights into how the brain represents action possibilities, 
attempts to subsume such approaches under predictive 
processing frameworks (as in Clark’s work) or to reframe 
emotion in terms of Bayesian inference (as in Barrett’s con-
structed emotion theory) often exemplify precisely the prob-
lem this paper critiques: retrofitting non-Bayesian insights 
into Bayesian language without adding explanatory value. 
The brain has evolved not to implement Bayes’ theorem but 
to coordinate adaptive behavior in complex, uncertain envi-
ronments, typically through simpler, more robust mecha-
nisms. The heuristic strategies documented by Gigerenzer 
and colleagues demonstrate how effective decision-making 
can emerge without the computational burden of full proba-
bilistic processing. It challenges the core premises of the 
Bayesian brain hypothesis rather than complementing it.
The path forward requires moving decisively beyond the 
Bayesian paradigm rather than continuing to grant it special 
status. Clark’s predictive processing framework, despite its 
claims of integrating action and embodiment, ultimately sub-
ordinates these elements to probabilistic inference, maintain-
ing the very problems of biological implausibility and unfal-
sifiability that this paper critiques. Similarly, Tenenbaum’s 
probabilistic graphical models in cognitive development 
research exemplify the post-hoc modeling approach that fits 
parameters to existing data without generating truly novel 
predictions—merely redescribing phenomena in Bayesian 
terminology without advancing mechanistic understanding. 
This shift demands not just methodological adjustment, but 
a fundamental reorientation of explanatory priorities—from 
abstract, probabilistic constructs toward models grounded 
in the material, dynamical, and context-sensitive nature of 
real brains in real bodies. Rather than attempting to salvage 
Bayesian approaches, cognitive neuroscience would benefit 
from fresh theoretical frameworks that start from biological 
realities and embodied cognition, rather than from math -
ematical formalisms that must be awkwardly retrofitted to 
neural systems.
Cognitive neuroscience can develop more nuanced, 
integrative, and pluralistic approaches to understanding 
the mind–brain relationship by acknowledging the funda-
mental limitations of the Bayesian approach and actively 
embracing a wider range of theoretical alternatives. As Marr 
emphasized in his influential levels-of-analysis framework, 
a central and enduring challenge is to bridge computational 
theory, algorithmic description, and biological implementa-
tion in a mechanistically specific and empirically testable 
way. Meeting this challenge requires navigating carefully 
between metaphor and mechanism, as well as between math-
ematical elegance and biological plausibility. Scientific pro-
gress depends on building theories that are both explanatory 
and empirically grounded. In the end, the Bayesian brain 
hypothesis may have served as a useful metaphor—but the 
future of neuroscience lies in the dynamic, constraint-bound 
interplay of bodies, brains, and worlds.
Final recommendations: A summary in five points
To close, we distill the main critiques and suggestions of 
this paper into five concise, actionable points for theoreti-
cal neuroscience: 
1. Demand falsifiability and mechanistic grounding.  
Theories of brain function must make risky predictions 
and specify biologically plausible mechanisms. Abstract 
elegance is not enough.
2. Embrace theoretical pluralism. Competing frame-
works—such as dynamic systems theory, ecologi-
cal psychology, and embodied cognition—offer rich, 
empirically grounded alternatives to the Bayesian brain 
hypothesis.
3. Clarify scope and level of explanation. The Bayesian 
brain often blurs metaphor and mechanism, oscillating 
between universal principles and specific implementa-
tions. Clear theoretical boundaries are essential.
4. Avoid post hoc rationalization. Approximate infer -
ence, flexible priors, and retrospective model fitting can 
immunize the theory from refutation. Scientific pro-
2670 European Journal of Applied Physiology (2025) 125:2643–2677
gress requires vulnerability to being wrong. This cri -
tique applies most directly to generalized or unfalsifiable 
uses of Bayesian modeling, rather than to all Bayesian 
models.
5. Center biology, not formalism. Theories must begin 
with the physical and dynamical constraints of real neu-
ral systems—not with formalisms that require biology 
to conform after the fact.
These recommendations aim to realign cognitive psy -
chology and neuroscience with the principles of empiri-
cal accountability, biological plausibility, and conceptual 
clarity. By following these recommendations, cognitive 
neuroscience can develop more rigorous, biologically 
grounded, and empirically accountable theories of brain 
function. The future of our field depends not on the elegant 
mathematics of inference machines but on understanding 
the messy reality of embodied cognition.
The final blow: A crucial experiment 
and the limits of the Bayesian metaphor
A framework that accounts for everything, regardless 
of outcome, is less a scientific theory than a meta-
physical comfort blanket.
Concrete neural predictions, not post hoc fits
To deliver the definitive challenge to the Bayesian brain 
hypothesis, we propose a single, tightly controlled empirical 
test that targets the hypothesis in its strongest, most mecha-
nistic form. This “crucial experiment” aims to show whether 
the brain really implements Bayesian-style computations—
or whether such claims persist only by post hoc reinter -
pretation and parameter-tweaking. If the Bayesian brain 
hypothesis is to remain viable as a mechanistic explanation, 
it must pass a decisive empirical test—one that makes clear, 
pre-registered predictions about neural dynamics under well-
defined conditions.
Setup: Identify a particular cortical or subcortical cir -
cuit that Bayesian/predictive-coding accounts explicitly 
claim encodes priors, likelihoods, or precision weights dur-
ing a well-studied perceptual task. The key is to specify, in 
advance: 
1. Which neuronal population (layer, area, microcircuit) 
encodes the “prior belief,”
2. Which population encodes “prediction errors,”
3. How “precision” modulates firing rates or synaptic 
gains,
4. Precisely how these populations will respond if they 
implement Bayes’ rule under varying prior probabilities 
and likelihood manipulations.
Crucial test:  Employ real-time neural recordings (e.g., 
multi-electrode arrays, two-photon calcium imaging) while 
systematically manipulating both the prior probability and 
the reliability (likelihood) of the sensory cue. For instance, 
a strong prior via a predictive cue can be introduced, and 
then the actual likelihood or degraded sensory signal can be 
abruptly altered.
In practical terms, researchers could train animals in a 
visual-cue task with explicit priors (e.g., 80% of trials have 
a bright stimulus, 20% a dim one). We would measure multi-
electrode activity in cortical region X, hypothesized to rep-
resent the prior. We would also record from cortical region 
Y, hypothesized to encode precision-weighted prediction 
errors, using real-time decoding. The Bayesian model must 
specify, a priori, how spike rates and local field potentials 
in regions X and Y should systematically shift in response 
to manipulations of likelihood. If we fail to see the predicted 
parametric shift in neural activity in real time—and cannot 
salvage it with post hoc parameter tweaks—this would fal-
sify the strong Bayesian claim.
• If the Bayesian brain is literally correct: We should 
observe immediate, lawful shifts in the prior-encoding  
population that precisely match the updated posterior dis-
tribution, with no new free parameters introduced post 
hoc.
• The “prediction error” populations must show systematic, 
monotonic changes that reflect the mismatch between the 
experimenter-manipulated priors and the newly intro-
duced likelihoods.
• These changes in firing or synaptic gain must match the 
timescale and hierarchy predicted a priori by the Bayes-
ian model.
Any major divergence between the pre-registered predic-
tions and actual neural data would be fatal to the hypothesis, 
unless proponents resort to the usual escapes (e.g., “the pri-
ors were really something else”). But such reparameteriza-
tion would only confirm that the theory remains “safe” by 
becoming unfalsifiable. Unless proponents can answer the 
empirical and mechanistic challenges summarized in Box 2, 
the Bayesian brain should be reclassified not as a scientific 
theory, but as a durable metaphor—valuable in pedagogy, 
but inert in biology.
2671European Journal of Applied Physiology (2025) 125:2643–2677 
Box 2: Questions the Bayesian brain hypothesis must answer—
but can’t
1. Where in the brain are priors stored, and how are they repre-
sented at the circuit level?
The framework often refers to priors, but never specifies where or 
how they exist biologically.
2.Which neural mechanisms encode the full probability distri-
butions required for Bayesian updating?
Models assume distributions, but neurons fire spikes—not functions 
over state spaces.
3.How does the brain compute likelihood functions in real-time 
under metabolic constraints?
There’s no evidence of likelihood computation in real circuits under 
ecological conditions.
4.What, exactly, is the generative model in a given task, and how 
is it implemented?
“Generative model” is often invoked as a black box—never mapped 
onto structure or process.
5.How do we distinguish neural evidence of prediction error 
from adaptation or surprise?
EEG/fMRI correlates are too coarse to adjudicate between Bayesian 
and non-Bayesian accounts.
6.When does the Bayesian brain make a wrong prediction—and 
how is that measured biologically?
Without a theory of “Bayesian failure,” the framework is immune to 
error and thus unscientific.
7.How would we know if the brain is not Bayesian?
If no empirical result could falsify the framework, then the frame-
work is no longer science.
Escaping the “Heads I Win, Tails You Lose” trap
A persistent problem is that whenever data fail to match 
Bayesian predictions, proponents retreat to: 
1. New “approximation” claims,
2. Suboptimal inference or “algorithmic constraints,”
3. Ad hoc changes to priors,
4. Shifting the explanation to some other hierarchical level.
A truly decisive experiment would forbid these infinite get-
out-of-jail-free cards by demanding:
• A single form of approximate inference specified in 
advance,
• A fixed prior for each condition,
• No indefinite hierarchical recourse.
Only if the pre-registered predictions align with the meas-
ured neural data can we claim real Bayesian updating in the 
literal sense.
When a theory becomes myth
A theory that deflects every mismatch by revising priors 
or recasting “precision parameters” is no longer empirical 
science but a metaphor—or at worst, a scientific myth. The 
final blow to the Bayesian brain emerges precisely when the 
hypothesis shows it can “explain away” any neural or behav-
ioral result by retroactive tuning. Such boundless flexibility 
ensures it “survives” but only by sacrificing actual predictive 
power—a framework that cannot be wrong also cannot tell 
us anything new about how the brain really works.
Accepting the consequences
If the Bayesian brain hypothesis is genuinely falsifiable, then 
its proponents should eagerly welcome and design a cru-
cial, pre-registered experiment that explicitly ties each core 
theoretical quantity—such as priors, likelihoods, prediction 
errors, and precision weights—to well-defined, identifiable 
neural populations and circuits in specific, testable ways. 
Should that experiment fail to confirm the predicted com-
putations, the strong Bayesian claim collapses. Declining to 
propose or run such a decisive test, or retreating to indefi-
nite “as-if” language, would itself be the final, tacit conces-
sion: the Bayesian brain is not an implementational model 
of cognition but a rhetorical flourish—valuable as metaphor, 
but scientifically inert as a mechanistic account—an idea 
immune to failure, and thus unfit for science.
Epilogue: The map and the terrain
The brain is not a statistician calculating posterior 
probabilities in a vacuum. It is a body in the world, 
learning to move well enough to stay alive—a project 
for which Bayes’ theorem is neither necessary nor suf-
ficient.
The Bayesian brain may have offered a seductive map—
clean, coherent, and mathematically elegant. That elegance, 
however, often conceals the unruly, dynamic complexity it 
claims to summarize. But as every cartographer knows, 
maps are not the territory. The brain’s terrain is rugged, 
adaptive, and radically embodied. It pulses with histories, 
constraints, and interactions that no prior or posterior can 
quite capture. To understand minds, we must walk the 
ground—muddy, nonlinear, and alive.
2672 European Journal of Applied Physiology (2025) 125:2643–2677
Appendix: Historical glossary of Bayesian 
expansion
This appendix traces the conceptual drift of the Bayesian 
brain hypothesis from its origins in sensory processing to 
its current status as a purportedly universal principle. The 
timeline reveals not just historical development but rhetori-
cal expansion—a pattern of widening scope accompanied 
by weakening constraints. Each new domain added to the 
Bayesian framework brings mathematical elegance but raises 
empirical concerns about overextension and unfalsifiability.
This appendix offers a chronological overview of how 
the Bayesian brain hypothesis has expanded across domains 
(Table 6). What follows is not merely a timeline, but a rhe-
torical map of a framework growing too fast to be critically 
metabolized. The timeline may serve as both a historical 
reference and a cautionary tale.
As the scope of Bayesian rhetoric has widened, its 
empirical constraints have thinned. This drift raises urgent 
questions about whether theoretical breadth has outpaced 
scientific utility. The result is a theory that increasingly func-
tions as a universal metaphor rather than a testable scientific 
model.
Author Contributions Madhur Mangalam: Conceptualization, Writing 
– Original draft, Writing – Review & Editing, Visualization.
Availability of data and materials Data sharing does not apply to this 
article as no new data were created or analyzed in this study.
Declarations 
Conflict of interest The authors declare that they have no known com-
peting financial interests or personal relationships that could have ap-
peared to influence the work reported in this paper.
Open Access This article is licensed under a Creative Commons Attri-
bution 4.0 International License, which permits use, sharing, adapta-
tion, distribution and reproduction in any medium or format, as long 
as you give appropriate credit to the original author(s) and the source, 
provide a link to the Creative Commons licence, and indicate if changes 
were made. The images or other third party material in this article are 
included in the article’s Creative Commons licence, unless indicated 
otherwise in a credit line to the material. If material is not included in 
the article’s Creative Commons licence and your intended use is not 
permitted by statutory regulation or exceeds the permitted use, you will 
need to obtain permission directly from the copyright holder. To view a 
copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.
References
Adams RA, Shipp S, Friston KJ (2013) Predictions not commands: 
Active inference in the motor system. Brain Struct Funct 
218:611–643. https:// doi. org/ 10. 1007/ s00429- 012- 0475-5
Adams RA, Stephan KE, Brown HR, Frith CD, Friston KJ (2013) The 
computational anatomy of psychosis. Front Psych 4:47. https://  
doi. org/ 10. 3389/ fpsyt. 2013. 00047
Akerlof GA, Michaillat P (2018) Persistence of false paradigms in 
low-power sciences. Proc Natl Acad Sci 115(52):13228–13233. 
https:// doi. org/ 10. 1073/ pnas. 18164 54115
Allen M, Friston KJ (2018) From cognitivism to autopoiesis: Towards 
a computational framework for the embodied mind. Synthese 
195:2459–2482. https:// doi. org/ 10. 1007/ s11229- 016- 1288-5
Anderson JR (2013) The Adaptive Character of Thought. Psychology 
Press, New York, NY
Anderson ML (2014) After Phrenology: Neural Reuse and the Interac-
tive Brain. MIT Press, Cambridge, MA
Anderson ML (2017) Of Bayes and bullets: An embodied, situated, 
targeting-based account of predictive processing. In: Metzinger 
T, Wiese W (eds) Philosophy and Predictive Processing. MIND 
Group, Frankfurt am Main, Germany
Arnold DH, Petrie K, Murray C, Johnston A (2019) Suboptimal human 
multisensory cue combination. Sci Rep 9:5155. https:// doi. org/ 
10. 1038/ s41598- 018- 37888-7
Table 6  History of Bayesian expansion. This timeline highlights 
how the Bayesian brain hypothesis has drifted across domains over 
the past two decades. Each entry marks a turning point in the scope, 
ambition, or rhetorical framing of Bayesian models, illustrating how 
an initially targeted theory of sensory processing became a universal 
template
Period Domain Key works Conceptual shift
1999–2003 Early vision (Ernst and Banks 2002; Lee and Mumford 
2003; Rao and Ballard 1999)
Perception as hierarchical prediction. Initial formulation 
of predictive coding
2004–2007 Sensorimotor integration (Knill and Pouget 2004; Friston 2005) Multisensory cue integration framed as Bayesian weight-
ing. Optimally fused estimates
2007–2010 General cognition (Friston 2010; Doya 2007) Free Energy Principle introduced. “Bayesian brain” 
extended to decision, emotion, action
2010–2015 Psychiatry & emotion (Adams et al. 2013; Hohwy 2013) Predictive processing applied to psychosis, anxiety, 
autism. Uncertainty reframed as affect
2015–2018 Artificial intelligence (Friston et al. 2016; Buckley et al. 2017) Active inference linked to AI/robotics. Bayesian control 
and generative models fused
2018–2023 Evolution & cell biology (Hipólito et al. 2021; Ramstead et al. 2023) Markov blankets reinterpreted as boundaries of all living 
systems. Bayesian selfhood
2023–Present Everything (Numerous) Bayesian framing applied to candle flames, phototaxis, 
immune cells, and cosmology. Universality normalized
2673European Journal of Applied Physiology (2025) 125:2643–2677 
Attwell D, Laughlin SB (2001) An energy budget for signaling in 
the grey matter of the brain. Journal of Cerebral Blood Flow & 
Metabolism 21(10):1133–1145. https:// doi. org/ 10. 1097/ 00004 
647- 20011 0000- 00001
Bachelard G (2002) The formation of the scientific mind: A contribu-
tion to a psychoanalysis of objective knowledge. Clinamen Press, 
Manchester, UK
Bargmann CI (2012) Beyond the connectome: How neuromodulators 
shape neural circuits. BioEssays 34(6):458–465. https:// doi. org/ 
10. 1002/ bies. 20110 0185
Barsalou LW (2008) Grounded cognition. Annuual. Rev Psychol 
59(1):617–645. https:// doi. org/ 10. 1146/ annur ev. psych. 59. 
103006. 093639
Bastos AM, Usrey WM, Adams RA, Mangun GR, Fries P, Friston KJ 
(2012) Canonical microcircuits for predictive coding. Neuron 
76(4):695–711. https:// doi. org/ 10. 1016/j. neuron. 2012. 10. 038
Bechtel W (2011) Mechanism and biological explanation. Philosophy 
of Science 78(4):533–557. https:// doi. org/ 10. 1086/ 661513
Beck JM, Ma WJ, Pitkow X, Latham PE, Pouget A (2012) Not noisy, 
just wrong: The role of suboptimal inference in behavioral vari-
ability. Neuron 74(1):30–39. https:// doi. org/ 10. 1016/j. neuron. 
2012. 03. 016
Beer RD (2000) Dynamical approaches to cognitive science. Trends 
Cogn Sci 4(3):91–99. https:// doi. org/ 10. 1016/ S1364- 6613(99) 
01440-0
Beggs JM, Plenz D (2003) Neuronal avalanches in neocortical circuits. 
J Neurosci 23(35):11167–11177. https:// doi. org/ 10. 1523/ JNEUR 
OSCI. 23- 35- 11167. 2003
Behrens TE, Woolrich MW, Walton ME, Rushworth MF (2007) Learn-
ing the value of information in an uncertain world. Nat Neurosci 
10:1214–1221. https:// doi. org/ 10. 1038/ nn1954
Bogacz R (2017) A tutorial on the free-energy framework for model-
ling perception and learning. J Math Psychol 76:198–211. https:// 
doi. org/ 10. 1016/j. jmp. 2015. 11. 003
Bowers JS, Davis CJ (2012) Bayesian just-so stories in psychology and 
neuroscience. Psychol Bull 138(3):389–414. https:// doi. org/ 10. 
1037/ a0026 450
Branco T, Häusser M (2010) The single dendritic branch as a funda-
mental functional unit in the nervous system. Curr Opin Neuro-
biol 20(4):494–502. https:// doi. org/ 10. 1016/j. conb. 2010. 07. 009
Brette R (2019) Is coding a relevant metaphor for the brain? Behavio-
ral and Brain Sciences 42:e215. https:// doi. org/ 10. 1017/ S0140 
525X1 90000 49
Brinkman BA, Yan H, Maffei A, Park IM, Fontanini A, Wang J, La 
Camera G (2022) Metastable dynamics of neural circuits and 
networks. Appl Phys Rev 9:011313. https:// doi. org/ 10. 1063/5. 
00626 03
Brown H, Adams RA, Parees I, Edwards M, Friston K (2013) Active 
inference, sensory attenuation and illusions. Cogn Process 
14:411–427. https:// doi. org/ 10. 1007/ s10339- 013- 0571-3
Buckley CL, Kim CS, McGregor S, Seth AK (2017) The free energy 
principle for action and perception: A mathematical review. J 
Math Psychol 81:55–79. https:// doi. org/ 10. 1016/j. jmp. 2017. 09. 
004
Buice MA, Cowan JD, Chow CC (2010) Systematic fluctuation 
expansion for neural network activity equations. Neural Comput 
22(2):377–426. https:// doi. org/ 10. 1162/ neco. 2009. 02- 09- 960
Buzsáki G (2006). Rhythms of the Brain. Oxford University Press, 
oxford, UK
Chater N, Oaksford M (1999) The probability heuristics model of syl-
logistic reasoning. Cogn Psychol 38(2):191–258. https:// doi. org/ 
10. 1006/ cogp. 1998. 0696
Chemero A (2009) Radical Embodied Cognitive Science. MIT Press, 
Cambridge, MA
Chialvo DR (2010) Emergent complex neural dynamics. Nat Phys 
6:744–750. https:// doi. org/ 10. 1038/ nphys 1803
Clark A (1999) An embodied cognitive science? Trends Cogn Sci 
3(9):345–351. https:// doi. org/ 10. 1016/ S1364- 6613(99) 01361-3
Clark A (2013) Whatever next? Predictive brains, situated agents, and 
the future of cognitive science. Behavioral and Brain Sciences 
36(3):181–204. https:// doi. org/ 10. 1017/ S0140 525X1 20004 77
Clark A (2015) Surfing Uncertainty: Prediction, Action, and the 
Embodied Mind. Oxford University Press, Oxford, UK
Colombo M (2018) Bayesian cognitive science, predictive brains, and 
the nativism debate. Synthese 195:4817–4838. https:// doi. org/ 
10. 1007/ s11229- 017- 1427-7
Colombo M, Seriès P (2012) Bayes in the brain–on Bayesian modelling 
in neuroscience. British Journal for the Philosophy of Science. 
https:// doi. org/ 10. 1093/ bjps/ axr043
Colombo M, Wright C (2021) First principles in the life sciences: The 
free-energy principle, organicism, and mechanism. Synthese 
198:3463–3488. https:// doi. org/ 10. 1007/ s11229- 018- 01932-w
Corlett PR, Horga G, Fletcher PC, Alderson-Day B, Schmack K, Pow-
ers AR (2019) Hallucinations and strong priors. Trends Cogn 
Sci 23(2):114–127. https:// doi. org/ 10. 1016/j. tics. 2018. 12. 001
Cosmides L, Tooby J (1996) Are humans good intuitive statisticians 
after all? Rethinking some conclusions from the literature on 
judgment under uncertainty. Cognition 58(1):1–73. https:// doi. 
org/ 10. 1016/ 0010- 0277(95) 00664-8
Craver CF (2007) Explaining the Brain: Mechanisms and the Mosaic 
Unity of Nneuroscience. Clarendon Press, Oxford, OK
Csicsvari J, Hirase H, Czurkó A, Mamiya A, Buzsáki G (1999) Oscil-
latory coupling of hippocampal pyramidal cells and interneurons 
in the behaving rat. J Neurosci 19(1):274–287. https:// doi. org/ 10. 
1523/ JNEUR OSCI. 19- 01- 00274. 1999
Dale R, Fusaroli R, Duran ND, Richardson DC (2013) The self-organ-
ization of human interaction. Psychol Learn Motiv 59:43–95. 
https:// doi. org/ 10. 1016/ B978-0- 12- 407187- 2. 00002-2
Danks D (2014) Unifying the Mind: Cognitive Representations as 
Graphical Models. MIT Press, Cambridge, MA
Dayan P (2012) Twenty-five lessons from computational neuromodu-
lation. Neuron 76(1):240–256. https:// doi. org/ 10. 1016/j. neuron. 
2012. 09. 027
Deco G, Hugues E (2012) Neural network mechanisms underly -
ing stimulus driven variability reduction. PLoS Comput Biol 
8(3):e1002395. https:// doi. org/ 10. 1371/ journ al. pcbi. 10023 95
Deco G, Jirsa VK, McIntosh AR (2011) Emerging concepts for the 
dynamical organization of resting-state activity in the brain. Nat 
Rev Neurosci 12:43–56. https:// doi. org/ 10. 1038/ nrn29 61
Dennett D (1987) The Intentional Stance. MIT Press, Cambridge, MA
Di Paolo EA, Buhrmann T, Barandiaran XE (2017) Sensorimotor Life: 
An Enactive Proposal. Oxford University Press, Oxford, UK
Doya K (2007) Bayesian Brain: Probabilistic Approaches to Neural 
Coding. MIT Press, Cambridge, MA
Dupré J (1993) The Disorder of Things: Metaphysical Foundations of 
the Disunity of Science. Harvard University Press, Cambridge, 
MA
Egner T, Summerfield C (2013) Grounding predictive coding models in 
empirical neuroscience research. Behavioral and Brain Sciences 
36(3):210–211. https:// doi. org/ 10. 1017/ s0140 525x1 20021 8x
Ernst MO, Banks MS (2002) Humans integrate visual and haptic infor-
mation in a statistically optimal fashion. Nature 415:429–433. 
https:// doi. org/ 10. 1038/ 41542 9a
Feldman DE (2012) The spike-timing dependence of plasticity. Neuron 
75(4):556–571. https:// doi. org/ 10. 1016/j. neuron. 2012. 08. 001]
Feldman H, Friston KJ (2010) Attention, uncertainty, and free-energy. 
Front Hum Neurosci 4:215. https:// doi. org/ 10. 3389/ fnhum. 2010. 
00215
2674 European Journal of Applied Physiology (2025) 125:2643–2677
Firestein S (2012) Ignorance: How It Drives Science. Oxford Univer -
sity Press, New York, NY
Fiser J, Berkes P, Orbán G, Lengyel M (2010) Statistically optimal 
perception and learning: From behavior to neural representations. 
Trends Cogn Sci 14(3):119–130. https:// doi. org/ 10. 1016/j. tics. 
2010. 01. 003
Fletcher PC, Frith CD (2009) Perceiving is believing: A Bayesian 
approach to explaining the positive symptoms of schizophrenia. 
Nat Rev Neurosci 10:48–58. https:// doi. org/ 10. 1038/ nrn25 36
Freyer F, Aquino K, Robinson PA, Ritter P, Breakspear M (2009) 
Bistability and non-Gaussian fluctuations in spontaneous cortical 
activity. J Neurosci 29(26):8512–8524. https:// doi. org/ 10. 1523/ 
JNEUR OSCI. 0754- 09. 2009
Fries P (2015) Rhythms for cognition: Communication through coher-
ence. Neuron 88(1):220–235. https:// doi. org/ 10. 1016/j. neuron. 
2015. 09. 034
Friston K (2005) A theory of cortical responses. Philosophical 
Transactions of the Royal Society B: Biological Sciences 
360(1456):815–836. https:// doi. org/ 10. 1098/ rstb. 2005. 1622
Friston K (2010) The free-energy principle: A unified brain theory? 
Nat Rev Neurosci 11:127–138. https:// doi. org/ 10. 1038/ nrn27 87
Friston K (2011) What is optimal about motor control? Neuron 
72(3):488–498. https:// doi. org/ 10. 1016/j. neuron. 2011. 10. 018
Friston K (2016) The Bayesian savant. Biol Psychiat 80(2):87–89. 
https:// doi. org/ 10. 1016/j. biops ych. 2016. 05. 006
Friston K, Kilner J, Harrison L (2006) A free energy principle for the 
brain. Journal of Physiology-Paris 100(1–3):70–87. https:// doi.  
org/ 10. 1016/j. jphys paris. 2006. 10. 001
Friston K, Mattout J, Kilner J (2011) Action understanding and active 
inference. Biol Cybern 104:137–160. https:// doi. org/ 10. 1007/ 
s00422- 011- 0424-z
Friston KJ, Stephan KE, Montague R, Dolan RJ (2014) Computational 
psychiatry: The brain as a phantastic organ. The Lancet Psy -
chiatry 1(2):148–158. https:// doi. org/ 10. 1016/ s2215- 0366(14) 
70275-5
Friston K, FitzGerald T, Rigoli F, Schwartenbeck P, Pezzulo G et al 
(2016) Active inference and learning. Neuroscience & Biobe-
havioral Reviews 68:862–879. https:// doi. org/ 10. 1016/j. neubi 
orev. 2016. 06. 022
Friston K, FitzGerald T, Rigoli F, Schwartenbeck P, Pezzulo G (2017) 
Active inference: A process theory. Neural Comput 29(1):1–49. 
https:// doi. org/ 10. 1162/ NECO_a_ 00912
Gallagher S (2017) Enactivist Interventions: Rethinking the Mind. 
Oxford University Press, Oxford, UK
Gallagher S, Allen M (2018) Active inference, enactivism and the her-
meneutics of social cognition. Synthese 195:2627–2648. https:// 
doi. org/ 10. 1007/ s11229- 016- 1269-8
Garrido MI, Kilner JM, Stephan KE, Friston KJ (2009) The mismatch 
negativity: A review of underlying mechanisms. Clin Neurophys-
iol 120(3):453–463. https:// doi. org/ 10. 1016/j. clinph. 2008. 11. 029
Gelman A, Carlin JB, Stern HS, Rubin DB (1995) Bayesian Data 
Analysis. Chapman and Hall/CRC, Boca Raton, FL
Gentner D, Grudin J (1985) The evolution of mental metaphors in psy-
chology: A 90-year retrospective. Am Psychol 40(2):181–192. 
https:// doi. org/ 10. 1037/ 0003- 066X. 40.2. 181
Gibson JJ (1966) The Senses Considered as Perceptual Systems. 
Houghton Mifflin, Boston, MA
Gibson JJ (1979) The Ecological Approach to Visual Perception. 
Houghton Mifflin, Boston, MA
Gigerenzer G (1998) Surrogates for theories. Theory & Psychology 
8(2):195–204. https:// doi. org/ 10. 1177/ 09593 54398 082006
Gigerenzer G (2020) How to explain behavior? Top Cogn Sci 
12(4):1363–1381. https:// doi. org/ 10. 1111/ tops. 12480
Gigerenzer G, Brighton H (2009) Homo heuristicus: Why biased minds 
make better inferences. Top Cogn Sci 1(1):107–143. https:// doi. 
org/ 10. 1111/j. 1756- 8765. 2008. 01006.x
Gigerenzer G, Gaissmaier W (2011) Heuristic decision making. Annu 
Rev Psychol 62(2011):451–482. https:// doi. org/ 10. 1146/ annur 
ev- psych- 120709- 145346
Gigerenzer G, Goldstein DG (1996) Reasoning the fast and frugal way: 
Models of bounded rationality. Psychol Rev 103(4):650–669. 
https:// doi. org/ 10. 1037/ 0033- 295x. 103.4. 650
Gilbert CD, Li W (2013) Top-down influences on visual processing. 
Nat Rev Neurosci 14:350–363. https:// doi. org/ 10. 1038/ nrn34 76
Gregory RL (1980) Perceptions as hypotheses. Philosophical 
Transactions of the Royal Society B: Biological Sciences 
290(1038):181–197. https:// doi. org/ 10. 1098/ rstb. 1980. 0090
Griffiths TL, Tenenbaum JB (2006) Optimal predictions in everyday 
cognition. Psychol Sci 17(9):767–773. https:// doi. org/ 10. 1111/j. 
1467- 9280. 2006. 01780.x
Griffiths TL, Chater N, Kemp C, Perfors A, Tenenbaum JB (2010) 
Probabilistic models of cognition: Exploring representations and 
inductive biases. Trends Cogn Sci 14(8):357–364. https:// doi. org/ 
10. 1016/j. tics. 2010. 05. 004
Griffiths TL, Lieder F, Goodman ND (2015) Rational use of cogni-
tive resources: Levels of analysis between the computational and 
the algorithmic. Top Cogn Sci 7(2):217–229. https:// doi. org/ 10. 
1111/ tops. 12142
Hari R, Parkkonen L (2015) The brain timewise: How timing shapes 
and supports brain function. Philosophical Transactions of the 
Royal Society B: Biological Sciences 370(1668):20140170. 
https:// doi. org/ 10. 1098/ rstb. 2014. 0170
Harris KD, Shepherd GM (2015) The neocortical circuit: Themes and 
variations. Nat Neurosci 18:170–181. https:// doi. org/ 10. 1038/ 
nn. 3917
Harris JJ, Jolivet R, Attwell D (2012) Synaptic energy use and supply. 
Neuron 75(5):762–777. https:// doi. org/ 10. 1016/j. neuron. 2012. 
08. 019
He BJ, Zempel JM, Snyder AZ, Raichle ME (2010) The temporal struc-
tures and functional significance of scale-free brain activity. Neu-
ron 66(3):353–369. https:// doi. org/ 10. 1016/j. neuron. 2010. 04. 020
Hesse M (1970) Models and Analogies in Science. University of Norte 
Dame Press, Notre Dame, IN
Hinton GE (2007) Learning multiple layers of representation. Trends 
Cogn Sci 11(10):428–434. https:// doi. org/ 10. 1016/j. tics. 2007. 
09. 004
Hipólito I, Ramstead MJ, Convertino L, Bhat A, Friston K, Parr T 
(2021) Markov blankets in the brain. Neuroscience & Biobe-
havioral Reviews 125:88–97. https:// doi. org/ 10. 1016/j. neubi orev. 
2021. 02. 003
Hohwy J (2012) Attention and conscious perception in the hypothesis 
testing brain. Front Psychol 3:96. https:// doi. org/ 10. 3389/ fpsyg. 
2012. 00096
Hohwy J (2013) The Predictive Mind. Oxford University Press, Oxford, 
UK
Hu W, MacDonald ML, Elswick DE, Sweet RA (2015) The glutamate 
hypothesis of schizophrenia: Evidence from human brain tissue 
studies. Ann N Y Acad Sci 1338(1):38–57. https:// doi. org/ 10. 
1111/ nyas. 12547
Ioannidis JP (2005) Why most published research findings are false. 
PLoS Med 2(8):e124. https:// doi. org/ 10. 1371/ journ al. pmed. 
00201 24
Ioannidis JP (2008) Why most discovered true associations are inflated. 
Epidemiology 19(5):640–648. https://  doi. org/ 10. 1097/ EDE. 
0b013 e3181 8131e7
Isaacson JS, Scanziani M (2011) How inhibition shapes cortical activ-
ity. Neuron 72(2):231–243. https:// doi. org/ 10. 1016/j. neuron. 
2011. 09. 027
Jones M, Love BC (2011) Bayesian fundamentalism or enlighten-
ment? On the explanatory status and theoretical contributions of 
Bayesian models of cognition. Behavioral and Brain Sciences 
34(4):169–188. https:// doi. org/ 10. 1017/ S0140 525X1 00031 34
2675European Journal of Applied Physiology (2025) 125:2643–2677 
Kahneman D, Tversky A (2013) Prospect theory: An analysis of deci-
sion under risk. In: MacLean LC, Ziemba WT (eds) Handbook 
of the Fundamentals of Financial Decision Making: Part I. World 
Scientific, Singapore, pp 99–127
Kaliukhovich DA, Vogels R (2014) Neurons in macaque inferior tem-
poral cortex show no surprise response to deviants in visual odd-
ball sequences. J Neurosci 34(38):12801–12815. https:// doi. org/ 
10. 1523/ JNEUR OSCI. 2154- 14. 2014
Katz LC, Shatz CJ (1996) Synaptic activity and the construction of 
cortical circuits. Science 274(5290):1133–1138. https:// doi. org/ 
10. 1126/ scien ce. 274. 5290. 1133
Kelso JS (1995) Dynamic Patterns: The Self-organization of Brain and 
Behavior. MIT Press, Cambridge, MA
Keysers C, Silani G, Gazzola V (2024) Predictive coding for the actions 
and emotions of others and its deficits in autism spectrum dis-
orders. Neuroscience & Biobehavioral Reviews 167:105877. 
https:// doi. org/ 10. 1016/j. neubi orev. 2024. 105877
Kiefer A, Hohwy J (2018) Content and misrepresentation in hierarchi-
cal generative models. Synthese 195:2387–2415. https:// doi. org/ 
10. 1007/ s11229- 017- 1435-7
Kinouchi O, Copelli M (2006) Optimal dynamical range of excitable 
networks at criticality. Nat Phys 2:348–351. https://  doi. org/ 10. 
1038/ nphys 289
Kirchhoff MD (2018) Predictive processing, perceiving and imagin-
ing: Is to perceive to imagine, or something close to it? Philos 
Stud 175:751–767. https:// doi. org/ 10. 1007/ s11098- 017- 0891-8
Kirchhoff MD, Kiverstein J (2019) Extended Consciousness and Pre-
dictive Processing: A Third Wave View. Routledge, New York, 
NY
Kiverstein JD, Rietveld E (2018) Reconceiving representation-hun-
gry cognition: An ecological-enactive proposal. Adapt Behav 
26(4):147–163. https:// doi. org/ 10. 1177/ 10597 12318 772778
Knill DC, Pouget A (2004) The Bayesian brain: The role of uncertainty 
in neural coding and computation. Trends Neurosci 27(12):712–
719. https:// doi. org/ 10. 1016/j. tins. 2004. 10. 007
Knill DC, Richards W (1996) Perception as Bayesian Inference. Cam-
bridge University Press, Cambridge, UK
Körding KP, Wolpert DM (2004) Bayesian integration in sensorimo-
tor learning. Nature 427:244–247. https:// doi. org/ 10. 1038/ natur 
e02169
Krakauer JW, Ghazanfar AA, Gomez-Marin A, MacIver MA, Poeppel 
D (2017) Neuroscience needs behavior: Correcting a reduction-
ist bias. Neuron 93(3):480–490. https:// doi. org/ 10. 1016/j. neuron. 
2016. 12. 041
Kriegeskorte N, Douglas PK (2018) Cognitive computational neuro-
science. Nat Neurosci 21:1148–1160. https:// doi. org/ 10. 1038/ 
s41593- 018- 0210-5
Kuhn TS (1962) The Structure of Scientific Revolutions. University of 
Chicago Press, Chicago, IL
Lakatos I (2014) Falsification and the methodology of scientific 
research programmes. In: Lydia P (ed) Philosophy, Science, and 
History. Routledge, New York, pp 89–94
Lakoff G, Johnson M (1980) Metaphors We Live By. University of 
Chicago Press, Chicago, IL
Latour B (1987) Science in Action: How to Follow Scientists and Engi-
neers Through Society. Harvard University Press, Cambridge, 
MA
Lee TS, Mumford D (2003) Hierarchical Bayesian inference in the 
visual cortex. J Opt Soc Am A 20(7):1434–1448. https:// doi. org/ 
10. 1364/ JOSAA. 20. 001434
Linkenkaer-Hansen K, Nikouline VV, Palva JM, Ilmoniemi RJ (2001) 
Long-range temporal correlations and scaling behavior in human 
brain oscillations. J Neurosci 21(4):1370–1377. https:// doi. org/ 
10. 1523/ JNEUR OSCI. 21- 04- 01370. 2001
Litwin P, Miłkowski M (2020) Unification by fiat: Arrested develop-
ment of predictive processing. Cogn Sci 44(7):e12867. https://  
doi. org/ 10. 1111/ cogs. 12867
London M, Häusser M (2005) Dendritic computation. Annuual Review 
of. Neuroscience 28(1):503–532. https:// doi. org/ 10. 1146/ annur 
ev. neuro. 28. 061604. 135703
Longino HE (2020) Science as Social Knowledge: Values and Objec-
tivity in Scientific Inquiry. Princeton University Press, Princeton, 
NJ
Losonczy A, Makara JK, Magee JC (2008) Compartmentalized den -
dritic plasticity and input feature storage in neurons. Nature 
452:436–441. https:// doi. org/ 10. 1038/ natur e06725
Ma WJ, Beck JM, Latham PE, Pouget A (2006) Bayesian inference 
with probabilistic population codes. Nat Neurosci 9:1432–1438. 
https:// doi. org/ 10. 1038/ nn1790
Machamer P, Darden L, Craver CF (2000) Thinking about mecha -
nisms. Philosophy of Science 67(1):1–25. https:// doi. org/ 10. 
1086/ 392759
MacKay DJ (2003) Information Theory. Cambridge University Press, 
Cambridge, UK, Inference and Learning Algorithms
Magistretti PJ, Allaman I (2015) A cellular perspective on brain energy 
metabolism and functional imaging. Neuron 86(4):883–901. 
https:// doi. org/ 10. 1016/j. neuron. 2015. 03. 035
Malenka RC, Bear MF (2004) LTP and LTD: An embarrassment of 
riches. Neuron 44(1):5–21. https:// doi. org/ 10. 1016/j. neuron.  
2004. 09. 012
Marcus GF, Davis E (2013) How robust are probabilistic models of 
higher-level cognition? Psychol Sci 24(12):2351–2360. https://  
doi. org/ 10. 1177/ 09567 97613 495418
Marder E, O’Leary T, Shruti S (2014) Neuromodulation of circuits 
with variable parameters: Single neurons and small circuits 
reveal principles of state-dependent and robust neuromodula-
tion. Annu Rev Neurosci 37(1):329–346. https:// doi. org/ 10. 1146/ 
annur ev- neuro- 071013- 013958
Marewski JN, Schooler LJ (2011) Cognitive niches: An ecological 
model of strategy selection. Psychol Rev 118(3):393–437. https:// 
doi. org/ 10. 1037/ a0024 143
Marr D (1982) Vision: A Computational Investigation Into the Human 
Representation and Processing of Visual Information. MIT Press, 
Cambridge, MA
Mathys C, Daunizeau J, Friston KJ, Stephan KE (2011) A Bayesian 
foundation for individual learning under uncertainty. Front Hum 
Neurosci 5:39. https:// doi. org/ 10. 3389/ fnhum. 2011. 00039
Merton RK (1968) The Matthew effect in science: The reward and 
communication systems of science are considered. Science 
159(3810):56–63. https:// doi. org/ 10. 1126/ scien ce. 159. 3810. 56
Metzler R, Klafter J (2000) The random walk’s guide to anomalous dif-
fusion: A fractional dynamics approach. Phys Rep 339(1):1–77. 
https:// doi. org/ 10. 1016/ S0370- 1573(00) 00070-3
Michaels CF, Carello C (1981) Direct Perception. Prentice-Hall, Engle-
wood Cliffs, NJ
Miller KJ, Sorensen LB, Ojemann JG, Den Nijs M (2009) Power-law 
scaling in the brain surface electric potential. PLoS Comput Biol 
5(12):e1000609. https:// doi. org/ 10. 1371/ journ al. pcbi. 10006 09
Nelken I (2004) Processing of complex stimuli and natural scenes in 
the auditory cortex. Curr Opin Neurobiol 14(4):474–480. https:// 
doi. org/ 10. 1016/j. conb. 2004. 06. 005
Nelson LD, Simmons J, Simonsohn U (2018) Psychology’s renais-
sance. Annu Rev Psychol 69(1):511–534. https:// doi. org/ 10. 
1146/ annur ev- psych- 122216- 011836
Noë A (2004) Action in Perception. MIT Press, Cambridge, MA
Nosek BA, Spies JR, Motyl M (2012). Scientific utopia: II. Restructur-
ing incentives and practices to promote truth over publishability. 
Perspectives on Psychological Science, 7(6):615–631. https:// doi. 
org/ 10. 1177/ 17456 91612 459058
2676 European Journal of Applied Physiology (2025) 125:2643–2677
Olshausen BA, Field DJ (2004) Sparse coding of sensory inputs. Curr 
Opin Neurobiol 14(4):481–487. https:// doi. org/ 10. 1016/j. conb. 
2004. 07. 007
O’Reilly JX, Jbabdi S, Behrens TE (2012) How can a Bayesian 
approach inform neuroscience? Eur J Neurosci 35(7):1169–1179. 
https:// doi. org/ 10. 1111/j. 1460- 9568. 2012. 08010.x
Parr T, Friston KJ (2019) Generalised free energy and active infer -
ence. Biol Cybern 113:495–513. https:// doi. org/ 10. 1007/  
s00422- 019- 00805-w
Parr T, Rikhye RV, Halassa MM, Friston KJ (2020) Prefrontal compu-
tation as active inference. Cereb Cortex 30(2):682–695. https://  
doi. org/ 10. 1093/ cercor/ bhz118
Perfors A, Tenenbaum JB, Griffiths TL, Xu F (2011) A tutorial intro-
duction to Bayesian models of cognitive development. Cognition 
120(3):302–321. https:// doi. org/ 10. 1016/j. cogni tion. 2010. 11. 015
Piccinini G, Craver C (2011) Integrating psychology and neuroscience: 
Functional analyses as mechanism sketches. Synthese 183:283–
311. https:// doi. org/ 10. 1007/ s11229- 011- 9898-4
Poldrack RA (2011) Inferring mental states from neuroimaging 
data: From reverse inference to large-scale decoding. Neuron 
72(5):692–697. https:// doi. org/ 10. 1016/j. neuron. 2011. 11. 001
Polsky A, Mel BW, Schiller J (2004) Computational subunits in thin 
dendrites of pyramidal cells. Nat Neurosci 7:621–627. https://  
doi. org/ 10. 1038/ nn1253
Popper K (2002) The Logic of Scientific Discovery, 2nd edn. Rout-
ledge, New York, NY
Popper K (2014) Conjectures and Refutations: The Growth of Scien-
tific Knowledge. Routledge, New York, NY
Pouget A, Beck JM, Ma WJ, Latham PE (2013) Probabilistic brains: 
Knowns and unknowns. Nat Neurosci 16:1170–1178. https:// doi. 
org/ 10. 1038/ nn. 3495
Purves D, Wojtach WT, and Lotto RB (2011). Understanding vision in 
wholly empirical terms. Proceedings of the National Academy 
of Sciences, 108(supplement_3):15588–15595. https:// doi. org/  
10. 1073/ pnas. 10121 78108
Rahnev D, Denison RN (2018) Suboptimality in perceptual decision 
making. Behavioral and Brain Sciences 41:e223. https:// doi. org/ 
10. 1017/ S0140 525X1 80009 36
Raja V (2019) From metaphor to theory: The role of resonance in 
perceptual learning. Adapt Behav 27(6):405–421. https:// doi. org/ 
10. 1177/ 10597 12319 854350
Ramsey WM (2007) Representation Reconsidered. Cambridge Univer-
sity Press, Cambridge, UK
Ramstead MJ, Sakthivadivel DA, Heins C, Koudahl M, Millidge B, 
Da Costa L, Klein B, Friston KJ (2023) On Bayesian mechanics: 
A physics of and by beliefs. Interface Focus 13(3):20220029. 
https:// doi. org/ 10. 1098/ rsfs. 2022. 0029
Rao RP, Ballard DH (1999) Predictive coding in the visual cortex: A 
functional interpretation of some extra-classical receptive-field 
effects. Nat Neurosci 2:79–87. https:// doi. org/ 10. 1038/ 4580
Rasmussen D, Eliasmith C (2013) God, the devil, and the details: 
Fleshing out the predictive processing framework. Behavioral 
& Brain Sciences 36(3):223–224. https:// doi. org/ 10. 1017/ S0140 
525X1 20021 54
Renart A, De La Rocha J, Bartho P, Hollender L, Parga N, Reyes A, 
Harris KD (2010) The asynchronous state in cortical circuits. 
Science 327(5965):587–590. https:// doi. org/ 10. 1126/ scien ce. 
11798 50
Richardson MJ, Shockley K, Fajen BR, Riley MA, Turvey MT (2008) 
Ecological psychology: Six principles for an embodied-embed-
ded approach to behavior. In: Calvo P, Gomila A (eds) Hand-
book of Cognitive Science. Elsevier, Amsterdam, Netherlands, 
pp 159–187
Richardson MJ, Dale R, Marsh KL (2014) Complex dynamical sys-
tems in social and personality psychology. In: Reis HT, Judd CM 
(eds) Handbook of Research Methods in Social and Personality 
Psychology. Cambridge University Press, Cambridge, UK, pp 
253–282
Roberts JA, Gollo LL, Abeysuriya RG, Roberts G, Mitchell PB, Wool-
rich MW, Breakspear M (2019) Metastable brain waves. Nat 
Commun 10:1056. https:// doi. org/ 10. 1038/ s41467- 019- 08999-0
Romero F (2017) Novelty versus replicability: Virtues and vices in the 
reward system of science. Philosophy of Science 84(5):1031–
1043. https:// doi. org/ 10. 1086/ 694005
Sanborn AN, Chater N (2016) Bayesian brains without probabilities. 
Trends Cogn Sci 20(12):883–893. https:// doi. org/ 10. 1016/j. tics. 
2016. 10. 003
Schmidt RC, Richardson MJ (2008) Dynamics of interpersonal coor -
dination. In: Fuchs A, Jirsa VK (eds) Coordination: Neural, 
Behavioral and Social Dynamics. Springer, Berlin, Heidelberg, 
Germany, pp 281–308
Sekar A, Bialas AR, De Rivera H, Davis A, Hammond TR, Kamitaki 
N, Tooley K, Presumey J, Baum M, Van Doren V et al (2016) 
Schizophrenia risk from complex variation of complement com-
ponent 4. Nature 530:177–183. https:// doi. org/ 10. 1038/ natur 
e16549
Seth AK (2014) A predictive processing theory of sensorimotor con-
tingencies: Explaining the puzzle of perceptual presence and its 
absence in synesthesia. Cogn Neurosci 5(2):97–118. https:// doi. 
org/ 10. 1080/ 17588 928. 2013. 877880
Shapiro L (2019) Embodied Cognition. Routledge, New York, NY
Smaldino PE, McElreath R (2016) The natural selection of bad sci-
ence. Royal Society Open Science 3(9):160384. https:// doi. org/ 
10. 1098/ rsos. 160384
Smith L, Gasser M (2005) The development of embodied cognition: 
Six lessons from babies. Artif Life 11(1–2):13–29. https:// doi.  
org/ 10. 1162/ 10645 46053 278973
Spivey J (2007) The Continuity of Mind. Oxford University Press, 
New York, NY
Sporns O, Edelman GM (1993) Solving Bernstein’s problem: A pro-
posal for the development of coordinated movement by selection. 
Child Dev 64(4):960–981. https:// doi. org/ 10. 1111/j. 1467- 8624. 
1993. tb041 82.x
Sprevak M, Smith R (2023) An introduction to predictive process-
ing models of perception and decision-making. Top Cogn Sci. 
https:// doi. org/ 10. 1111/ tops. 12704
Stanford TR, Quessy S, Stein BE (2005) Evaluating the operations 
underlying multisensory integration in the cat superior colliculus. 
J Neurosci 25(28):6499–6508. https:// doi. org/ 10. 1523/ JNEUR 
OSCI. 5095- 04. 2005
Star SL, Griesemer JR (1989) Institutional ecology, ‘translations’ 
and boundary objects: Amateurs and professionals in Berke-
ley’s Museum of Vertebrate Zoology, 1907–39. Soc Stud Sci 
19(3):387–420. https:// doi. org/ 10. 1177/ 03063 12890 19003 001
Sterzer P, Adams RA, Fletcher P, Frith C, Lawrie SM, Muckli L, Petro-
vic P, Uhlhaas P, Voss M, Corlett PR (2018) The predictive cod-
ing account of psychosis. Biol Psychiat 84(9):634–643. https:// 
doi. org/ 10. 1016/j. biops ych. 2018. 05. 015
Summerfield C, Tsetsos K (2015) Do humans make good decisions? 
Trends Cogn Sci 19(1):27–34. https:// doi. org/ 10. 1016/j. tics.  
2014. 11. 005
Tenenbaum JB, Griffiths TL, Kemp C (2006) Theory-based Bayesian 
models of inductive learning and reasoning. Trends Cogn Sci 
10(7):309–318. https:// doi. org/ 10. 1016/j. tics. 2006. 05. 009
Teufel C, Fletcher PC (2020) Forms of prediction in the nervous sys-
tem. Nat Rev Neurosci 21:231–242. https:// doi. org/ 10. 1038/  
s41583- 020- 0275-5
Teufel C, Subramaniam N, Fletcher PC (2013) The role of priors in 
Bayesian models of perception. Front Comput Neurosci 7:25. 
https:// doi. org/ 10. 3389/ fncom. 2013. 00025
2677European Journal of Applied Physiology (2025) 125:2643–2677 
Thelen E, Smith LB (1994) A Dynamic Systems Approach to the 
Development of Cognition and Action. MIT Press, Cambridge, 
MA
Thompson E, Varela FJ (2001) Radical embodiment: Neural dynamics 
and consciousness. Trends Cogn Sci 5(10):418–425. https:// doi. 
org/ 10. 1016/ S1364- 6613(00) 01750-2
Todorov E, Jordan MI (2002) Optimal feedback control as a theory of 
motor coordination. Nat Neurosci 5:1226–1235. https:// doi. org/ 
10. 1038/ nn963
Touboul J, Destexhe A (2010) Can power-law scaling and neuronal ava-
lanches arise from stochastic dynamics? PLoS ONE 5(2):e8982. 
https:// doi. org/ 10. 1371/ journ al. pone. 00089 82
Turrigiano GG, Nelson SB (2004) Homeostatic plasticity in the devel-
oping nervous system. Nat Rev Neurosci 5:97–107. https:// doi.  
org/ 10. 1038/ nrn13 27
Turvey MT (1992) Affordances and prospective control: An outline 
of the ontology. Ecol Psychol 4(3):173–187. https://  doi. org/ 10. 
1207/ s1532 6969e co0403_3
Tversky A, Kahneman D (1974) Judgment under uncertainty: Heu-
ristics and biases: Biases in judgments reveal some heuristics 
of thinking under uncertainty. Science 185(4157):1124–1131. 
https:// doi. org/ 10. 1126/ scien ce. 185. 4157. 1124
Uhlhaas P, Pipa G, Lima B, Melloni L, Neuenschwander S, Nikolić D, 
Singer W (2009) Neural synchrony in cortical networks: History, 
concept and current status. Front Integr Neurosci 3:543. https://  
doi. org/ 10. 3389/ neuro. 07. 017. 2009
Van Orden GC, Holden JG, Turvey MT (2003) Self-organization of 
cognitive performance. J Exp Psychol Gen 132(3):331–350. 
https:// doi. org/ 10. 1037/ 0096- 3445. 132.3. 331
Varela FJ, Thompson E, Rosch E (1991) The Embodied Mind: Cogni-
tive Science and Human Experience. MIT Press, Cambridge, MA
Walsh KS, McGovern DP, Clark A, O’Connell RG (2020) Evaluat-
ing the neurophysiological evidence for predictive processing 
as a model of perception. Ann N Y Acad Sci 1464(1):242–268. 
https:// doi. org/ 10. 1111/ nyas. 14321
Warren WH (2021). Information is where you find it: Percep-
tion as an ecologically well-posed problem. i-Perception, 
12(2):20416695211000366. https:// doi. org/ 10. 1177/ 20416 69521 
10003 66
Weiss Y, Simoncelli EP, Adelson EH (2002) Motion illusions as opti-
mal percepts. Nat Neurosci 5:598–604. https:// doi. org/ 10. 1038/ 
nn0602- 858
Whitley R (2000) The Intellectual and Social Organization of the Sci-
ences. Oxford University Press, New York, NY
Williams D (2018) Predictive processing and the representa-
tion wars. Mind Mach 28:141–172. https:// doi. org/ 10. 1007/  
s11023- 017- 9441-6
Williams D (2020) Predictive coding and thought. Synthese 197:1749–
1775. https:// doi. org/ 10. 1007/ s11229- 018- 1768-x
Williams D, Colling L (2018) From symbols to icons: The return of 
resemblance in the cognitive neuroscience revolution. Synthese 
195:1941–1967. https:// doi. org/ 10. 1007/ s11229- 017- 1578-6
Wolpert DM, Diedrichsen J, Flanagan JR (2011) Principles of senso-
rimotor learning. Nat Rev Neurosci 12:739–751. https:// doi. org/ 
10. 1038/ nrn31 12
Wong RO, Ghosh A (2002) Activity-dependent regulation of dendritic 
growth and patterning. Nat Rev Neurosci 3:803–812. https:// doi. 
org/ 10. 1038/ nrn941
Zednik C, Jäkel F (2016) Bayesian reverse-engineering considered as a 
research strategy for cognitive science. Synthese 193:3951–3985. 
https:// doi. org/ 10. 1007/ s11229- 016- 1180-3
Zhao B, Lucas CG, Bramley NR (2024) A model of conceptual boot-
strapping in human cognition. Nat Hum Behav 8:125–136. 
https:// doi. org/ 10. 1038/ s41562- 023- 01719-1
Publisher's Note Springer Nature remains neutral with regard to 
jurisdictional claims in published maps and institutional affiliations.