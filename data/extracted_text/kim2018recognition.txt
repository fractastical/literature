ARTICLE Communicated by Karl Friston
Recognition Dynamics in the Brain under the
Free Energy Principle
Chang Sub Kim
cskim@jnu.ac.kr
DepartmentofPhysics,ChonnamNationalUniversity,Gwangju61186,
RepublicofKorea
We formulate the computational processes of perception in the frame-
work of the principle of least action by postulatingthe theoretical action
asatimeintegralofthevariationalfreeenergyintheneurosciences.The
freeenergyprincipleisaccordinglyrephrased,onautopoeticgrounds,as
follows: all viable organisms attempt to minimize their sensory uncer-
tainty about an unpredictable environment over a temporal horizon. By
taking the variation of informational action, we derive neural recogni-
tion dynamics (RD), which by construction reduces to the Bayesian fil-
tering of external states from noisy sensory inputs. Consequently, we ef-
fectivelycastthegradient-descentschemeofminimizingthefreeenergy
into Hamiltonian mechanics by addressing only the positions and mo-
menta of the organisms’ representations of the causal environment. To
demonstratetheutilityofourtheory,weshowhowtheRDmaybeimple-
mentedinaneuronallybasedbiophysicalmodelatasingle-cellleveland
subsequently in a coarse-grained, hierarchical architecture of the brain.
We also present numerical solutions to the RD for a model brain and an-
alyze the perceptual trajectories around attractors in neural state space.
1 Introduction
The quest for a universal principle that may explain the cognitive and be-
havioral operation of the brain is of great scientific interest. The apparent
difficulty in this quest is the gap between information processing and the
biophysics that governs neurophysiology in the brain. However, it is evi-
dent that the base material for brain functions comprises neurons obeying
the laws of physics. Thus, any biological principles that attempt to explain
the brain’s large-scale functioning must be consistent with our accepted
physical reality (Schrödinger, 1967). It appears that among the current ap-
proaches, the one that prevails is the classical, effective epistemology of re-
garding perceptions as the construction of hypotheses that may represent
the truth by producing symbolic structures matching physical reality (von
Helmholtz, 1962; Gregory, 1980; Dayan, Hinton, Neal, & Zemel, 1995).
NeuralComputation 30, 2616–2659(2018) © 2018 Massachusetts Institute of Technology.
Published under a Creative Commons
Attribution4.0International(CCBY4.0)license.
doi:10.1162/neco_a_01115
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2617
One influential candidate at present for such a rubric in neuroscience
is the free energy principle (FEP; Friston, 2009, 2010, 2013). For a technical
appraisal of the FEP, we refer to (Buckley, Kim, McGregor, & Seth, 2017)
where the theoretical assumptions and mathematical structure involved in
the FEP are reviewed in great detail. A recent study (Ramstead, Badcock,
& Friston, 2017) suggested variational neuroethology, which integrates the
FEPwithevolutionarysystemstheorytoexplainhowlivingsystemspersist
asbounded,self-organizingsystemsovertime.Tostatecompactly,theFEP
suggeststhatallviableorganismsperceiveandactontheexternalworldby
instantiatingaprobabilisticcausalmodelembodiedintheirbraininaman-
ner that ensures their adaptive fitness or autopoiesis (Maturana & Varela,
1980). The biological mechanism that endows the organism’s brain with
theoperationistheoreticallyframedintoaninformation-theoreticmeasure,
which is termedvariational or informational free energy(IFE). According to
the FEP, a living system attempts to minimize sensory surprisal (i.e., self-
information) when exposed to environmental perturbations by calling on
activeinference.However,thebraindoesnotpresideoverin-streamingsen-
sory distribution; accordingly, the brain cannot directly minimize the sen-
sorysurprisal;instead,itminimizesitsupperbound,whichistheIFE.This
is the same quantity used in machine learning, namely, the evidence lower
bound, when using a negative IFE. The probabilistic rationale of the FEP
argues that the brain’s representations of the uncertain environment are
the sufficient statistics of a probability density encoded in the brain—for
example, means and variances for gaussian densities. The variational pa-
rametersaresupposedtobeencodedasphysicalvariablesinthebrain.The
brain statistically infers the external causes of sensory input by Bayesian
filteringthroughitsinternaltop-downmodelforpredicting,orgenerating,
sensory data. Filtering is a probabilistic approach to determining external
states from noisy measurements of sensory data (Jazwinski, 1970). There is
growingexperimentalsupportforthebrain’smaintenanceofinternalmod-
elsoftheenvironmenttopredictsensoryinputsandtoprepareactions(see
Berkes, Orban, Lengyel, & Fiser, 2011, for instance). The computational op-
erationoftheabductive(Bayesian)inferenceissubservedbythebrainvari-
ables,andtheresultingperceptualmechanicsistermed recognitiondynamics
(RD).
AlthoughtheFEPispromisingintermsofaccountingforinferenceinthe
brain(andactiveinference),severaltechnicalissuesarisewhenitisapplied
tocontinuousstate-spacemodelsoftheworld.First,theFEPminimizesthe
IFEateachpointintimeforsuccessivesensoryinputs(Friston,Stephan,Li,
&Daunizeau,2010).However,theobjectivefunctiontobeminimizedispre-
ciselytheIFEcontinuouslyaccumulatedoverafinitetime. 1 Theminimiza-
tion must be performed considering trajectories over a temporal horizon
1
According to the FEP, the updating or learning of the generative model occurs in the
brain on a longer timescale than that associated with perceptual inference. To derive the
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2618 C. S. Kim
across which an organism encounters atypical events in its natural habitat
and biology.
Second,theFEPemploysthegradient-descentmethodforpracticallyex-
ecuting the minimization of the IFE (Friston et al., 2010), which is widely
used in data analysis (e.g., dynamic causal modeling) and offers a solution
toengineeringoptimizationproblems.Theschemeenablesonetofindopti-
malsolutionsontheFElandscape,buttheunderlyingvariationalprinciples
(of least action) are not explicit.
Third, the FEP introduces the notion of generalized coordinates of mo-
tion, which comprise an infinite number of high-order derivatives that can
accountforanalytic(i.e.,smooth)randomfluctuations(Friston,2008a).The
ensuingtheoreticalconstructisageneralizationofstandardNewtonianme-
chanics.2 However, there is no principled approach to specify the order of
generalized motion. In practice, the generalized motion is truncated at a
finite embedding order by assuming that the precision of random fluctua-
tions on higher orders of motion disappears very quickly.
Fourth,theFEPintroducesthehydrodynamics-likeconceptsofthepath
of a mode (motion of expectation) and the mode of a path (expected mo-
tion) by distinguishing the dynamic update from the temporal update of a
time-dependentstate(Friston,2008b).Becausethedistinctionisessentialto
ensure an equilibrium solution to the RD when employing the dynamical
generative models, further theoretical exploration seems worthwhile.
Fifth, the FEP considers the states of the environment as “hidden”
because what the brain faces is only a probabilistic sensory mapping.
Subsequently, a distinction is made between the hidden-state representa-
tions responsible for intralevel dynamics and causal-state representations
responsibleforinterleveldynamicsinthehierarchicalbrain(Friston,2006).
Suchadistinctionisbasedonahierarchicalgenerativemodelwithdynam-
ics on different timescales. Accordingly, a biophysically grounded formu-
lation that enables this separation of timescales is required.
In this article, we present a mechanical formulation of the RD in the
brain in the framework of Hamilton’s principle of least action (Landau
RD of the slow variables for synaptic efficacy and gain, the time integral of the IFE is
taken as an objective function; however, the gradient descent method is again executed
in a pointwise manner in time (Friston & Stephan, 2007).
2
In standard Newtonian mechanics, the mechanical state of a particle is specified by
position and velocity, which is the first-order time derivative of position. The velocity
changes in the presence of an applied force, and the resulting rate of change is termed
acceleration,whichisthesecond-orderderivativeofposition.Nophysicalobservablesare
assigned to the dynamical orders beyond the second order. In some literature (see Schot,
1978,forinstance),theconceptof“jerk”isassignedtothethird-orderderivativeasaphys-
icalmeaning.Fromthemathematicalperspective,suchageneralizationisnotforbidden.
However, higher orders are difficult to measure (Visser, 2004). More seriously, the third
orderraisesthequestionofwhatcausesjerk,likehowforcecausesaccelerationaccording
to Newton’s second law. The same impasse occurs for all higher orders.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2619
& Lifshitz, 1976). Motivated by the aforementioned theoretical observa-
tions, we attempt to resolve some of the technical complexities in the FEP
framework.Specifically,thegoalistorecastthegradient-descentstrategyof
minimizing the IFE, which has thus far eluded an undergirding formal
description, into a mathematical framework that is consistent with the
normative physics principles. We do this by hypothesizing the IFE as a La-
grangianofthebrainthatentersatheoreticalaction,beingthefundamental
objective function to be minimized in continuous time under the principle
of least action (see Sengupta, Tozzi, Cooray, Douglas, & Friston, 2016, for a
technicalessaysketchingamodel-independentLagrangianformalismrele-
vanttoouridea).Consequently,wereformulatetheRDbyconsideringonly
thecanonical,physicalrealitiestoeschewthegeneralizedcoordinatesofin-
finitelyrecursivetimederivativesofthecontinuousstatesofanorganism’s
environment and brain. In the ensuing description, the dynamical state of
a system is specified only by positions and their first-order derivatives.
In this work, supported by recent evidence (Markov et al., 2014;
Michalareas,Vezoli,vanPelt,Schoffelen,&Kennedy,2016),weadmitthebi
directionalfacetininformationalflowinthebrain.Theenvironmentbegets
sensory data at the brain-environment interface through structures such as
sensory receptors or interoceptors within an organism. The incited electro-
opto-chemical interaction in sensory neurons must transduce forward in
the anatomical structure of the brain. While complying with the idea of
perception as the construction of hypotheses, there must be a backward
pathway as well in information processing in the functional hierarchy of
the brain. To understand how such a bidirectional functional architecture
emerges from the electrophysiology of biophysics and anatomical organi-
zation of the brain is a primary research interest (see Markov & Kennedy,
2013, for instance). We shall consider a simple model that effectively incor-
porates the functional hierarchy while focusing on the brain’s perceptual
mechanics for inferring the external world, given sensory data. The prob-
lem of learning of the environment via updating the internal model of the
worldandofactiveinference—changingsensationsviaactionontheexter-
nal world (see Friston, Daunizeau, & Kiebel, 2009; Buckley & Toyoizumi,
2018, for instance)—is deferred for an upcoming paper. Instead, we pro-
vide a broad discussion in section 5 on how the learning may work in our
formulation.
Here, we outline how in this work we cast Bayesian filtering in the
FEP by using a variational principle of least action and how we articulate
the minimization of the sensory uncertainty in terms of the associated La-
grangianandHamiltonian.Furthermore,givenaparticularformofthedif-
ferential equations, afforded by computational neuroscience, one can see
relativelyeasilyhowneuronaldynamicscouldimplementtheBayesianfil-
tering. First, according to the FEP, the brain represents the environmen-
tal features statistically efficiently by using the sufficient statisticsμ.W e
assume thatμ represents the state of the basic computational unit of the
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2620 C. S. Kim
neural attributes of perception in the brain. Such a constituent is consid-
ered a “perceptual particle,” which may be a single neuron or physically
coarse-grained population of neurons forming a small particle. Second, we
postulate that the Laplace-encoded IFE in the FEP, denoted asF (see sec-
tion 2.1), serves as an effective informational Lagrangian (IL) of the brain,
which is denoted asL. Accordingly, the informational action (IA),3 which
we denote byS, is defined as the time integral of the approximate IFE (see
section3.1).Third,conformingtotheHamiltonianprincipleofleastaction,
the equations of motion of the perceptual particles are derived mathemat-
ically by varying the IA with respect to bothμ and ˙μ. The resulting La-
grangeequationsconstitutetheperceptualmechanics,thatis,theRDofthe
brain’s inference of the external causes of sensory stimuli (see section 3.1).
Fourth, we obtain the brain’s informational Hamiltonian (IH)H from the
LagrangianviaaLegendretransformation.Consequently,wederiveasetof
coupled,first-orderdifferentialequationsfor μ anditsconjugate pμ,which
are equivalent to the perceptual mechanics derived from the Lagrange for-
malism.TheresultingperceptualmechanicsisourderivedRDinthebrain.
Accordingly, the brain performs the RD in the state space spanned by the
position μ and momentumpμ of the constituting neural particles (see sec-
tion 3.2).
Fifth,weadopttheHodgkin-Huxley(H-H)neuronsasbiophysicalneu-
ralcorrelatesthatformthebasicperceptualunitsinthebrain.Wefirstderive
the RD of sensory perception at a single-neuron level at which the mem-
branepotential,ionictransport,andsynapticgatingaretherelevantphysi-
calattributes.Subsequently,wescaleupthecellularformulationtofurnish
a functional hierarchical architecture of the brain. On this coarse-grained
scale,theperceptualstatesaretheaveragedproperties ofmanyinteracting
neurons. We simplify the hierarchical picture with two classes of averaged
variables for activation and connection, mediating the intra- and interlevel
dynamics,respectively.AccordingtoourformulationofthehierarchicalRD
inthebrain,assensoryperturbationoccupiesthelowestlevel(i.e.,thesen-
sory interface), the brain carries out the RD in its functional network and
finds an optimal trajectory that minimizes the IA.
Tosummarize,wehaveadoptedtheIFEasaninformationalLagrangian
ofthebrainandsubsequentlyemployedtheprincipleofleastactiontocon-
struct the Hamiltonian mechanics of cognition. In doing so, only positions
and momenta of the neural particles have been addressed as dynamical
variables.Wedonotdistinguishthecausalandhiddenstates,bothofwhich
mustemergeasbiophysicalneuronalactivitiesondifferenttimescales.The
resulting RD is statistically deterministic, arising from unpredictable mo-
tionsoftheenvironmentalstatesandnoisysensorymapping.Furthermore,
3
Note that one must not confuse “informational action” with the “physical action” of
an organism.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2621
the derived RD describes not only the dynamics of the brain’s representa-
tion of hidden states of the world but also the prediction errors. We will
see later that the latter corresponds to momenta in the setting of Hamilto-
nian mechanics. Note that the dynamics of prediction errors is not part of
theconventionalformulationofgeneralizedfilteringundertheFEP;rather
it emerges naturally in the current variational formulation. The successful
solutions of the RD are stable equilibrium trajectories in the neural state
space, which specify the tightest upper bound of the sensory uncertainty
by conforming to the rephrased FEP. Our formulation allows solutions in
ananalyticalforminlinearregimesnearfixedpoints,expandedintermsof
theeigenvectorsoftheJacobian;thus,itprovidesatractablereal-timeanal-
ysis. We hope that our theory will motivate further investigations of some
model brains with numerical simulations as well as of active inference and
learning problems.
The remainder of this article is organized as follows. We first recapitu-
late the FEP in section 2 to support our motivation for casting the gradi-
ent descent scheme into the standard mechanical formulation. In section 3,
we present the RD reformulated in the Lagrangian and Hamiltonian for-
malisms. In section 4, biophysical implementations of our theory at the
cellular level and in the scaled-up hierarchical brain are formulated, and
nonlinear as well as linear dynamical analyses are carried out. Finally, a
discussion is presented in section 5.
2 The Free Energy Principle
To present our motivation for this article, we briefly discuss the IFE and
FEP, which are currently used in the brain sciences to derive the RD. The
RDisanorganism’scomputationalframeworkforexecutingtheminimiza-
tion of the IFE in the brain under the FEP. In practice, there are various
IFE-minimizing schemes, such as variational message passing and belief
propagation, that do not invoke treatment using generalized coordinates
ofmotion.Ourtreatmenthere,whichaccommodatesthenotionofgeneral-
ized motion, is more relevant to the Bayesian filtering and predictive cod-
ing schemes that have become a popular analogy for message passing in
thebrain.Filteringistheproblemofdeterminingthestateofasystemfrom
noisymeasurements(Jazwinski,1970).Foradetailedtechnicalappraisalof
the FEP, we refer to Buckley et al., (2017) from which we borrow the math-
ematical notations.
2.1 Informationalfreeenergy. Alivingorganismoccupiesafinitespace
andtimeintheunbounded,changingworldwhileinteractingwiththerest
oftheworld,comprisingitsenvironment.Thestatesoftheenvironmentare
collectivelydenotedas ϑ,whichare“hidden”fromtheorganism’sperspec-
tive. The signals from the environment are registered biophysically at the
organism’s sensory interface as sensory dataϕ.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2622 C. S. Kim
The organism’s brain faces uncertainty when it attempts to predict the
sensory inputs, the amount of which is quantified assensoryuncertaintyH .
The sensory uncertainty is defined as an average of the self-information,
−lnp(ϕ), over the probability densityp(ϕ) encoded at the interface:
H ≡
∫
dϕ
{
−lnp(ϕ)
}
p(ϕ). (2.1)
The self-information, which is also termed the sensorysurpriseor surprisal
in information theory, quantifies the survival tendency of living organisms
in an unpredictable environment; it is the logarithm of the inverse of the
probability that they will be found in a particular sensory state over time.
Assuming that the sensory density describes an ergodic ensemble of sen-
sory streaming,4 one mayconvert thesensory uncertaintyinto atimeaver-
age as
∫
dϕ
{
−lnp(ϕ)
}
p(ϕ) = 1
T
∫ T
0
dt
{
−lnp(ϕ(t))
}
,
where T is the temporal window over which exchange with the envi-
ronment occurs (i.e., a temporal horizon). Here, one may manipulate the
right-hand side of the preceding equation by adding a nonnegative,
Kullback-Leibler divergence to the integrand to obtain
−lnp(ϕ)+
∫
dϑq(ϑ)ln q(ϑ)
p(ϑ|ϕ) →
∫
dϑq(ϑ)ln q(ϑ)
p(ϑ,ϕ ).
The outcome brings about the mathematical definition of the IFE,
F[q(ϑ), p(ϑ,ϕ )] ≡
∫
dϑq(ϑ)ln q(ϑ)
p(ϑ,ϕ ), (2.2)
whichisexpressedasafunctionalofthetwoprobabilitydensities, q(ϑ)and
p(ϑ,ϕ ),termedtherecognitiondensity(R-density)andthegenerativeden-
sity (G-density), respectively. The R-density is the organism’s probabilistic
representationoftheexternalworld,whichtheorganism’sbrainusesinap-
proximately inferring the causesϑ of inputsϕ. The G-density, a joint prob-
ability betweenϑ and ϕ, underlies a generative model of how the sensory
data are biophysically produced by interaction between the brain and the
environment. By construction, the surprisal is smaller than the IFE by the
4
This ergodicity assumption is an essential ingredient of the FEP, which hypothesizes
that the ensemble average of the surprisal is equal to its time average, considering the
surprisal to be a statistical, dynamical quantity.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2623
added positive amount; accordingly, the sensory uncertainty is bounded
from above in accordance with
∫
dt
[
−lnp(ϕ)
]
≤
∫
dtF[q(ϑ), p(ϑ,ϕ )]. (2.3)
Notethatthesensoryuncertaintyontheleft-handsideofequation2.3spec-
ifies the accumulated surprisal over a temporal horizon involved in an en-
vironmental event.
Equation2.3constitutesamathematicalstatementoftheFEP:“Allviable
organismsattempttoavoidbeingplacedinanatypicalsituationintheiren-
vironmental habitats for existence by minimizing the sensory uncertainty.
However, organisms do not possess direct control over the sensory distri-
bution p(ϕ);instead,theyminimizetheupperboundofequation2.3,
∫
dtF,
as a proxy for the sensory uncertainty.” The brain conducts the minimiza-
tion probabilistically by updating the R-density to approximate the poste-
rior densityp(ϑ|ϕ), namely, by carrying out the Bayesian inference of the
causes ϑ of the sensory dataϕ. In the conventional application of the FEP,
the following approximate inequality is usually employed (see Friston &
Kiebel, 2009; Friston, Adams Perrinet & Breakspear, 2012, for instance):
−lnp(ϕ) ≤ F. (2.4)
However,notethattheinequality,equation2.4,isnotequivalenttoequation
2.3 in general. It is only a point approximation piecewise in time.
Note that the negative-evidence bound in equation 2.4 does not specify
the form of the R-density. This means that one is at liberty to use a conve-
nient form that renders the minimization of variational IFE tractable. Usu-
ally what one invokes is a gaussian fixed form for the R-density, called the
Laplaceapproximation:
q(ϑ) = 1√2πζ exp
{
−(ϑ − μ)2/(2ζ )
}
≡ N(ϑ;μ, ζ), (2.5)
whichisfullycharacterizedsimplybyitsmeans μ andvariances ζ,namely ,
first-andsecond-ordersufficientstatistics,respectively.Then,bysubstitut-
ing equation 2.5 into equation 2.2 and after some technical approximations
(seeBuckleyetal.,2017,fordetails),onecanconverttheIFEfunctionalinto
a function of only the meansμ, given the sensory inputϕ,
F[q(ϑ), p(ϑ,ϕ )] →− lnp(μ, ϕ) ≡ F(μ, ϕ), (2.6)
where the dependence on the conditional variances disappears because
theyareastraightforwardanalyticfunctionofthemeans.TheresultingIFE
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2624 C. S. Kim
functionFinequation2.6istermedthe Laplace-encodedIFEinwhichthepa-
rameters μ, specifying the organism’s belief or expectation of the environ-
mentalstates,aretheorganism’sprobabilisticrepresentationoftheexternal
world.Inturn,itisarguedthatthevariationalparameters μ areencodedin
the brain as biophysical variables.
To proceed with minimization of the IFE in the filtering scheme, a gen-
erative model for noisy-data measurement and the equations of motion
of the states must be supplied. The FEP assumes a formal homology be-
tween the external dynamics and the organism’s top-down belief. The for-
mer describes, according to the laws of physics, the equations of motion of
environmental states and the sensory-data registering process. The latter
prescribes the internal dynamics of the representations of environmental
states and the generative model of sensory data in the organism’s brain
(Friston, Daunizeau, Kilner, & Kiebel, 2010). Following this idea, one hy-
pothesizes that sensory dataϕ are predicted on the basis of the expected
hiddenstate,whichisdenotedbythemean μ oftheR-density,accordingto
a linear or nonlinear mapping,
ϕ = g(μ)+ z, (2.7)
where g(μ)i sam a pf r o mμ onto ϕ and z is the involved random fluctua-
tion. Furthermore, the brain’s representationsμ of the causes are assumed
to obey the stochastic equation of motion,
dμ
dt = f(μ)+ w, (2.8)
where f(μ) is a linear or nonlinear function of the organism’s expectation
of environmental dynamics andw is the associated random fluctuation.
Assuming mutually uncorrelated gaussian fluctuations,w and z,o ft h e
organism’s beliefs, one may furnish the models for the likelihoodp(ϕ|μ)
and the empirical priorp(μ), which jointly enter the Laplace-encoded IFE
in equation 2.6 in the factorized form:
p(ϕ,μ ) = p(ϕ|μ)p(μ). (2.9)
Using the notation introduced in equation 2.5, they are given explicitly as
p(ϕ|μ) = N(ϕ − g(μ);0,σz), (2.10)
p(μ) = N(˙μ − f(μ);0,σ w), (2.11)
where we have set ˙μ = dμ/dt, and the normal densities are assumed to
possess zero means with variancesσz and σw, respectively. When the fluc-
tuations are statistically stationary, the variances are handled as constant;
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2625
however, nonstationary fluctuation can also be taken into account by
assuminganexplicittimedependenceinthevariances.Finally,bysubstitut-
ing equations 2.10 and 2.11 into equation 2.6, one can convert the Laplace-
encoded IFE, up to a constant, into
F(μ, ϕ) = 1
2σ−1
z ε2
z + 1
2σ−1
w ε2
w + 1
2 ln(σzσw), (2.12)
where the new variables have been defined as
εz ≡ ϕ − g(μ)a n d εw ≡ ˙μ − f(μ).
Theauxiliaryvariable εz specifiesthediscrepancybetweenthesensorydata
ϕ andthebrain’sprediction g(μ).Similarly, εw specifiesthediscrepancybe-
tweenthechangeofexpectations ˙ μ andtheorganism’sbelief f(μ).Wewill
seethattheequivalencebetweenthechangeofexpectationsandtheexpec-
tation of the change of external states follows from a minimization formu-
lation in generalized coordinates of motion.
It is straightforward to extend the formulation to the multiple corre-
lated noisy inputs. However, for simplicity, we shall continue to work in
the single-variable picture and extend it to a general situation later.
2.2 Gradient Descent Scheme of the RD.With the Laplace-encoded
IFE as an instrumental tool, the organism’s brain searches for the tightest
bound for the surprisal, conforming to equation 2.4, by varying its internal
states μ. The critical question here is what machinery the brain employs
for the minimization procedure. Typically the gradient descent method in
machine learning theory is employed in the conventional approach.
To give an idea of the gradient-descent scheme, we set up a simple
gradient-descent equation here, in the usual manner, by regarding the IFE
functionF as an objective function:
˙μ =− κ∇μF. (2.13)
In this equation, ˙μ denotes a temporal or sequential update of the brain
variableμ,∇μ isthegradientoperatorwithrespectto μ,and κ isthelearn-
ingratethatcontrolsthespeedofoptimization.Inthesteadystate,defined
by ˙μ ≡ 0, the solutionμ(0) to the relaxation equation, equation 2.13, must
satisfy ∇μF = 0. Subsequently, it may be interpreted that such a solution
corresponds to an equilibrium (or fixed) point of the IFE functionF, speci-
fying a local minimum in the IFE landscape.
By inspection, however, we find that the gradient-descent construct in
the above approach causes ambiguity when applied to dynamic causal
models such as equation 2.8 because imposing the condition ˙μ ≡ 0o nt h e
left-hand side of equation 2.13 does not guarantee a desired equilibrium
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2626 C. S. Kim
point in the state space spanned byμ. The reason is that ˙μ also appears on
the right-hand side of equation 2.13 viaF. The gradient operation on the
right-handsideofequation2.13canbeperformedexplicitlyfor F,givenby
equation 2.12, to obtain
ˆμ ·∇ μF =− σ−1
z (ϕ − g)∂g
∂μ − σ−1
w ( ˙μ − f) ∂ f
∂μ .
This subtlety does not appear in the formulation using generalized coor-
dinates of motion, which incorporates the aspect of continually changing
external or hidden states via the mathematical construct of unbounded,
higher-order motion of the generalized coordinates.5
Forcompleteness,wenowdescribetheformulationingeneralizedcoor-
dinatesofmotion.Itisanattempttoallowamoreprecisespecificationofa
system’s dynamical state. This formulation is useful when random fluctu-
ations on higher-order motion are to be considered. Effectively, this allows
one to eschew Wiener assumptions and deal with smooth random pertur-
bations (Friston, 2008a). The generalized coordinates are defined as a row
vector in the state space spanned by all orders of time derivatives of a bare
state μ,
˜μ = (μ, μ′,μ′′,... ) ≡ (μ[0],μ[1],μ[2],... ), (2.14)
where vector components are defined, with the understanding thatμ[0] ≡
μ,a s
μ[n+1] = μ′
[n] ≡ Dμ[n].
Note that the notationDμ[n] ≡ μ′
[n] has been introduced to denote the dy-
namical update of the componentμ[n], which is in contrast to the notation
˙μ[n] for the sequential update. Furthermore, two components of a vector
at different dynamical orders in the generalized coordinates are mutually
independent variables. Similarly, the sensory data ˜ϕ are expressed in the
generalized coordinates as a row vector:
˜ϕ = (ϕ,ϕ ′,ϕ ′′,... ) ≡ (ϕ[0],ϕ[1],ϕ[2],... ). (2.15)
5
The terminology of the generalized coordinates in generalized filtering is dissimi-
lar from its common usage in physics. In classical mechanics, the generalized coordi-
natesrefertotheindependentcoordinatevariablesthatarerequiredtocompletelyspecify
the configuration of a system with a holonomic constraint, not including their temporal
derivatives. The number of generalized coordinates determines the degree of freedom in
the system (Landau & Lifshitz, 1976). Therefore, the termgeneralized statesseems more
suitable thangeneralizedcoordinates in generalized filtering.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2627
Eachcomponentinthevectors ˜μ and ˜ϕ istobeconsideredasadynamically
independent variable. Moreover, assuming that the random fluctuations,z
andw,areanalytic,theyhavebeenexpressedinthegeneralizedcoordinates
as ˜z and ˜w, respectively. Then the generalization of equations 2.7 and 2.8
followsaftersometechnicalapproximationsas(seeBuckleyetal.,2017,for
details)
˜ϕ = ˜g+ ˜z, (2.16)
D˜μ = ˜f + ˜w, (2.17)
where D˜μ = (μ′,μ′′,μ′′′,... ). For reference, we explicitly spell out equa-
tions 2.16 and 2.17 at dynamical ordernas
ϕ[n] = ∂g
∂μ μ[n] + z[n],
Dμ[n] = ∂ f
∂μ μ[n] + w[n].
Notethatdifferentdynamicalordersofthenoiseterms ˜zand ˜w maybecon-
sidered to be statistically correlated in general. Then the Laplace-encoded
IFE can be mathematically constructed from multivariate correlated gaus-
siannoiseswithzeromeansandcovariancematrices /Sigma1w and/Sigma1z asfollows:
F(˜μ, ˜ϕ) = 1
2{ ˙˜μ − ˜f}/Sigma1−1
w { ˙˜μ − ˜f}T + 1
2 ln|/Sigma1w|
+1
2{ ˜ϕ − ˜g}/Sigma1−1
z { ˜ϕ − ˜g}T + 1
2 ln|/Sigma1z|, (2.18)
where { ˙˜μ − ˜f}T is the transpose of row vector{ ˙˜μ − ˜f},a n d|/Sigma1w| and /Sigma1−1
w
are the determinant and inverse of the covariance matrix/Sigma1w, respectively.
Inmanypracticalexercises,however,conditionalindependenceamongdif-
ferentdynamicalordersisusuallyimposed.Consequently,thenoisedistri-
bution at each dynamical order is assumed to be an uncorrelated gaussian
density about zero means. This simplification corresponds to the Wiener
processorMarkovianapproximation(Jazwinski,1970).Here,werecallthat
the generalized states ˜μ are the means of the brain’s probabilistic model of
thedynamicalworld,whichistheR-densityinequation2.5,afterrewriting
in the generalized coordinates. Note that equation 2.18 is a direct general-
ization of equation 2.12.
Furnished with the extratheoretical constructs, the IFE becomes a func-
tion of the generalized coordinates ˜μ, given sensory data ˜ϕ: F = F(˜μ, ˜ϕ).
Accordingly, the gradient-descent scheme must be extended to incorpo-
rate the generalized motions in its formulation. This is achieved by the
theoretical prescription that the dynamical updateD˜μ is distinctive from
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2628 C. S. Kim
the sequential update˙˜μ. Consequently, one recasts equation 2.13 into the
form
˙˜μ − D˜μ =− κ∇˜μF(˜μ, ˜ϕ). (2.19)
This formis effectivelyagradientdescentequippedwith asolenoidalflow
(or in a moving frame of reference). It is argued that the solution to this
equation(whenthegradientwithrespecttotheIFEiszero)rendersthemo-
tion of the expectation the same as the expected motion (see Friston et al.,
2010).Thislicensestheequalityinequation2.19,whichstatesthatatamin-
imumof F,thetworates ˙˜μ andD˜μ becomecoincident—thatis ˙μ[n] = Dμ[n]
at every dynamic ordern. The entire minimization procedure is compactly
expressed in the literature as
˜μ∗ = argmin
˜μ
F(˜μ, ˜ϕ|m),
where we have insertedmin F to indicate explicitly that the minimization
is conditioned on the generative model of an organism.
In brief, equation 2.19 furnishes the RD from the gradient-descent for-
mulation in the FEP. The brain performs the RD of perceptual inference by
biophysically implementing equation 2.19 in the gray matter. Aline attrac-
torsolution ˜μ∗ specifiestheminimumvalueoftheIFE,say, Fmin = F(˜μ∗, ˜ϕ),
yielding the tightest bound of the surprisal (see equation 2.4), associated
with a given sensory experience ˜ϕ.
3 The Informational Action Principle
TheRDcondensedinsection2.2isbasedonthemathematicalstatementof
the FEP given by equation 2.4, which is a point approximation of equation
2.3. Here we reformulate the RD by complying with the full mathematical
statement of the FEPgiven in equation 2.3. Accordingly, we need a formal-
ism that allows minimization of the time integral of the IFE rather than the
IFE at each point in time. We have assimilated that the theoretical action
in the principle of least action neatly serves the goal (Landau & Lifshitz,
1976). This formalism allows us to eschew the introduction of the general-
izedcoordinatesofadynamicalstatecomprisinganinfinitenumberoftime
derivatives of the brain stateμ. Consequently, the distinctive classification
of the time derivative of the parametric update ( ˙μ) and dynamical update
(Dμ) of the state variable is not required. In what follows, we consistently
use the dot symbol to denote the time derivative of a dynamical variable.
We will frame the variational principle of least action for the RD under
theFEP.OurformulationoftheRDrevealssomeveryinterestinginterpreta-
tionsoffactorssuchasthepredictionerroranditsinversevariance(i.e.,pre-
cision). For example, prediction error becomes the momentum of a neural
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2629
particle, while precision becomes its inertial mass. In section 4, we unpack
them in the context of neuronal dynamics (as described by the Hodgkin-
Huxley equation) and consider hierarchical architectures under the infor-
mational action principle.
3.1 Lagrangian Formalism. To formulate the RD from the principle of
least action, the Lagrangian of the system must be supplied. We define the
ILof the brain, denoted byL, as the Laplace-encoded IFE function
L(μ, ˙μ;ϕ) ≡ F(μ, ˙μ;ϕ),
wherewehaveplacedthesemicolonintheargumentof Ltoindicatethat μ
and ˙μ arethetwodynamicalvariablesofthebrain,givenasensoryinput ϕ.
Thesensoryinputsarestochasticandtimedependent;ingeneral, ϕ = ϕ(t),
reflecting the changing external states, the generative processes of which
areto besuppliedbythelawsof physics.Theproposed ILisnot aphysical
quantitybutratheraninformation-theoreticobject.Whenwetakeequation
2.12 as an explicit expression forF, the ILis expressed as
L(μ, ˙μ;ϕ) = 1
2σ−1
w (˙μ − f(μ))2 + 1
2σ−1
z (ϕ − g(μ))2. (3.1)
Note that we have dropped the term1
2 ln(σzσw) in writing equation 3.1 by
assumingitasaconstant,whichthendoesnotaffectthedynamicsof μ and
˙μ. This assumption of statistical stationarity may be lifted by introducing
time dependence in the variances (MacDonald, 2006),
σw = σw(t)a n d σz = σz(t).
Still, however, the dropped term does not affect the dynamics because a
term that can be expressed as a total time derivative in the Lagrangian will
not affect the resulting equations of motion (Landau & Lifshitz, 1976).
Next, we postulate that the perceptual dynamics of the neural particles
conforms to the principle of least action (Landau & Lifshitz, 1976). Accord-
ingly, we suppose that the brain’s perceptual operation corresponds to the
search for an optimal dynamical path that minimizes the informational ac-
tion (IA), denoted byS,
S ≡
∫ tf
ti
dtL(μ, ˙μ;ϕ), (3.2)
wheretf − ti isthetemporalhorizonoverwhichalivingorganismengages
with the environment. When the functional derivative ofS is taken with
respect toμ and ˙μ, we obtain
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2630 C. S. Kim
δS =
[ ∂L
∂μ δμ
] tf
ti
−
∫ tf
ti
dt
( d
dt
∂L
∂ ˙μ − ∂L
∂μ
)
δμ.
Byimposing δS≡ 0undertheconditionthatinitialandfinalstatesarefixed,
δμ(ti) = 0 = δμ(tf),
we derive the Lagrangian equation as
d
dt
∂L
∂ ˙μ − ∂L
∂μ = 0. (3.3)
Using the specified Lagrangian, equation 3.1, in equation 3.3, we obtain a
Newtonian equation of motion for the brain variableμ,
σ−1
w ˙v = ¯/Lambda11 + ¯/Lambda12, (3.4)
where we have defined the kinematic velocity as
v ≡ ˙μ
and the additional notations on the right-hand side as
¯/Lambda11 ≡ σ−1
w f ∂ f
∂μ and ¯/Lambda12 ≡− σ−1
z (ϕ − g)∂g
∂μ . (3.5)
Equation 3.4 entails the RD of the brain in the Lagrangian formulation. As
ananalogy,weinterpretthattheinverseofthevariance σ−1
w playstheroleof
inertialmass oftheneuralparticles.Accordingly,theleft-handsideofequa-
tion 3.4 represents aninertial force—the product of inertial mass and accel-
eration ¨μ. Note that the inverse of variance is interpreted as precision in
the Friston formulation (Buckley et al., 2017), which gives a measure for
theaccuracyofthebrain’sexpectationorpredictionofsensorydata.There-
fore,theprecisionismetaphoricallythe“informationalmass”oftheneural
particle, which we shall denote throughout as
mα ≡ σ−1
α and α = w,z.
Furthermore,theterms ¯/Lambda1i,i= 1,2,ontheright-handsideareinterpretedas
the“forces”thatdrivetheinternal( ¯/Lambda11)aswellassensory( ¯/Lambda12)excitationsin
the brain. The acceleration can be evaluated from ¨μ = ∑ ¯/Lambda1i/mw when the
net force is known.
While the organism’s brain integrates the RD for an incoming sensory
input, an optimal trajectoryμ∗(t) is continuously achieved in the neural
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2631
configuration space. Moreover, the steady-state condition in the long-time
limitt →∞ is given by
˙μ∗ = v∗ = const, (3.6)
where the net force vanishes. Note that equation 3.6, which defines an at-
tractor, μeq = μ∗(∞), is more general than the simple solution, ˙μ∗ = 0. In
otherwords,weallowforanoptimaltrajectoryasopposedtoafixedpoint.
The optimal trajectoryμ∗(t) minimizes the IA, which in turn provides the
organismwiththetightestestimateofthesensoryuncertainty(seeequation
2.3).
3.2 HamiltonianFormalism. Themechanicalformulationcanbemade
moremodishintermsofHamiltonianlanguage,whichadmitspositionand
momentumasindependentbrainvariablesinsteadofpositionandvelocity
intheLagrangianformulation.Thepositionsandmomentaspanthephase
space of a physical system, which defines the neural state space of the or-
ganism’s brain.
The “canonical” momentump, which is conjugate to the positionμ,i s
defined via the LagrangianL as (Landau & Lifshitz, 1976)
p≡ ∂L
∂ ˙μ = mw ( ˙μ − f), (3.7)
which evidently differs from the “kinematic” momentum mwv = mw ˙μ
wheremw istheinertialmass σ−1
w .ThentheinformationalHamiltonian(IH),
denotedby H,maybeconstructedfromtheLagrangianthroughaLegendre
transformation:
H(μ, p;ϕ) =
∑ ∂L
∂ ˙μ ˙μ − L(μ, ˙μ;ϕ). (3.8)
The first term on the right-hand side of equation 3.8 can be further manip-
ulated to yield
∑ ∂L
∂ ˙μ ˙μ = mw ˙μ2 − mw ˙μ f.
By plugging the outcome and the LagrangianL given in equation 3.1 into
equation 3.8, we obtain the IH as a function ofμ and p,g i v e nϕ, as follows:
H(μ, p;ϕ) = T (p)+ V(μ, p;ϕ), (3.9)
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2632 C. S. Kim
Figure1: Thepotentialenergygiveninequation3.12, inarbitraryunits,where
the dashed and solid curves are for the variancesσz = 100 and 30, respectively.
Both cases exhibit a stable minimum in the central well and two unstable max-
ima on the side hills, which contribute to determining the IFE landscape.
where equation 3.7 has been used to replace ˙μ with p. The first term on the
right-handsideofequation3.9isthe“kineticenergy,”whichdependsonly
on momentum:
T (p) = p2
2mw
. (3.10)
Moreover,thesecondtermontheright-handsideofequation3.9isthe“po-
tential energy,” which depends on both position and momentum:
V(μ, p;ϕ) = V(μ;ϕ)+ pf (μ), (3.11)
where we have defined the momentum-independent term separately as
V(μ;ϕ) =− 1
2mz(ϕ − g)2. (3.12)
We remark that the sensory stimuliϕ enter the Hamiltonian only through
thepotential-energypart V,whichbecomes“conservative”when ϕ isstatic.
Here, we assume that the variances associated with the noisy data are
constant. For time-varying sensory inputs, in general, the Hamiltonian is
nonautonomous. In Figure 1, we depict the conservative potential energy
by using three-term approximations for the generative function,
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2633
g(μ) ≈ b1 + b2μ + b2μ2.
For convenience, we have assumed a constant sensory input,ϕ = 15, and
set parameters as (b1,b2,b3) = (0,1,0.01). We have observed numerically
that the static sensory signalϕ changes the distance between two unstable
fixed points but does not affect the location of the stable equilibrium point.
Furthermore, the depth of the stable equilibrium valley increases with the
magnitude ofϕ.
Next, we take the total derivative of the Hamiltonian given in equation
3.8 with respect toμ and ˙μ to obtain
dH(μ, p;ϕ) =
∑
d(p˙μ)− dL(μ, ˙μ;ϕ)
= ˙μdp + pd˙μ −
( ∂L
∂μ dμ + ∂L
∂ ˙μd˙μ
)
=− ˙pμdμ + ˙μdp.
By comparing the above expression with the formal expansion,
dH = ∂H
∂μ dμ + ∂H
∂pdp,
we identify the Hamilton equations of motion for independent variablesμ
and pof a neural particle:
˙μ = ∂H
∂p, (3.13)
˙p =− ∂H
∂μ . (3.14)
For a givenH in equation 3.9, we spell out the right-hand side of equation
3.13 as
˙μ = 1
mw
p+ f, (3.15)
which is identical to equation 3.7. Similarly, equation 3.14 is spelled out as
˙p=− ∂V
∂μ − ∂ f
∂μ p. (3.16)
The first term on the right-hand side of equation 3.16 specifies the conser-
vative force,
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2634 C. S. Kim
−∂V
∂μ →− σ−1
z (ϕ − g)∂g
∂μ .
Onthe otherhand,thesecondtermon theright-handsideof equation3.16
specifies the dissipative force, where∂ f/∂μ plays the role of a damping
coefficient.
Thederivedsetofcoupledequationsforthevariables μ and pfurnishes
theRDofthebraininphasespacespannedby μ and p,whichinvolveonly
first-order time derivatives. When the time derivative is taken once more
for both sides of equation 3.15, followed by the substitution of equation
3.16 for ˙p, the outcome is identical to the Lagrangian equation of motion,
equation 3.4. This observation confirms that the two mechanical formula-
tions, one from the Lagrangian and the other from the Hamiltonian, are in
fact equivalent.
IntheHamiltonianformulation,thebrain’sfulfillingoftheRDisequiv-
alent to finding an optimal trajectory (μ∗(t), p∗(t)) in phase space. For a
static sensory input, the dynamics governed by equations 3.15 and 3.16 is
autonomous, and for a time-dependent sensory input, it becomes nonau-
tonomous. The RD can be integrated by providing appropriate models for
the generative functionsf and g. The attractor (μ∗(∞), p∗(∞))wouldbea
focus or center in phase space, which can be calculated by simultaneously
imposing the following conditions on the left-hand sides of equations 3.15
and 3.16:
˙μ∗ = 0a n d ˙p∗ = 0. (3.17)
One can readily confirm that these fixed-point conditions match the New-
tonianequilibriumcondition, ∑
i ¯/Lambda1i = 0intheLagrangianformulation(see
section 3.1). The situation corresponds to the brain’s resting state at a local
minimum on the energy landscape defined by the Hamiltonian function.
3.3 MultivariateFormulation. HavingestablishedtheHamiltoniandy-
namics for a single brain variableμ, we now extend our formulation to the
general case of the multivariate brain. We denote{μ} as a row vector ofN
brain states as in section 2.1:
{μ}= (μ1,μ2,...,μ N).
The brain states respond to multiple sensory inputs in a general manner:
{ϕ}= (ϕ1,ϕ2,...,ϕ N).
For simplicity, we neglect the statistical correlation of the fluctuations
associated with environmental variables and sensory inputs. Then, within
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2635
the independent-particle approximation of uncorrelated brain variables,
the Laplace-encoded IFE given by equation 2.18 furnishes the multivariate
Lagrangian:
L({μ},{ ˙μ}; {ϕ}) = 1
2
N∑
α=1
[
mwα ( ˙μα − fα({μ}))2 + mzα (ϕα − gα({μ}))2
]
,
(3.18)
where we have dropped the terms that contain only the variances,σzα =
m−1
zα and σwα = m−1
wα. One may extend equation 3.18 to interacting neural
nodes in terms of the covariance matrix formulation, which is not our con-
cernhereeither.Subsequently,theconjugatemomentumtothegeneralized
coordinateμα is determined by an explicit evaluation of
pα = ∂L
∂ ˙μα
= mwα ( ˙μα − fα ). (3.19)
Note that the momentumpα gives a measure of the discrepancy, weighted
by mwα, between the change of the probabilistic representation of the envi-
ronment ˙μα and the organism’s belief of itfα. The weighting factormwα is
the inertial mass, which is the precision in statistics. In turn, the Hamilto-
nian of the multivariate brain can be constructed from equation 3.9 as
H({μ},{p}; {ϕ}) = T ({μ},{p}; {ϕ})+ V({μ},{p}; {ϕ}) (3.20)
where first term on the right-hand side is the kinetic energy,
T ({p}; {ϕ}) ≡
N∑
α=1
pα2
2mwα
, (3.21)
and the potential energyV is identified as
V({μ},{p}; {ϕ}) ≡
N∑
α=1
[
−1
2mzα(ϕα − gα )2 + pα fα
]
. (3.22)
ThenitisstraightforwardtoderivetheRDofthevariables μα and pα,given
sensory dataϕα,a s
˙μα = ∂H
∂pα
= 1
mwα
pα + fα, (3.23)
and for their conjugate momenta,
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2636 C. S. Kim
Figure 2: The perceptual circuitry at neural nodeα in which sensory dataϕα
stream, where it is depicted that the computational unitsμα and pα are posi-
tively activated by arrows and negatively by lines ending with filled dots. The
conjugatemomenta pα,definedinequation3.19,tothebrainvariables μα mimic
the precision-weighted prediction errors in the language of predictive coding
(Rao & Ballard, 1999).
˙pα =− ∂H
∂μα
=− ∂gα
∂μα
pϕα − ∂ fα
∂μα
pα. (3.24)
In equation 3.24, for notational convenience we have introduced an auxil-
iary quantitypϕα:
pϕα ≡ mzα(ϕα − gα ).
Equations 3.23 and 3.24 are a coupled set of equations for the computa-
tional units,μα and pα, describing a specific brain variable and its conju-
gate momentum, respectively, given the sensory discrepancypϕα between
theobserveddata ϕα anditsprediction gα(μα ).Accordingtotheneuralim-
plementationofthepredictive-codingtheory(Summerfield&Egner,2009),
μα and pα correspond to the representational and error neurons, respec-
tively. With some working models forfα and gα, they shape the RD in the
brain’smultidimensionalphasespaceintheHamiltonianprescription.Fig-
ure 2 shows a schematic of the perceptual circuitry implied by the RD at a
neural node. The classification of excitatory (positive) and inhibitory (neg-
ative)activationofthecomputationalunitsisonlyforconveniencebecause
the sign of each term on the right-hand side of equations 3.23 and 3.24 de-
pends on the generative functionfα and mapgα, which are not specified.
Itisadmissibletoassumethatthebrainisinarestingstateattheoutset.
As the sensory inputsϕα arrive, the organism’s brain performs the RD on-
linebyintegratingequations3.23and3.24toattainanoptimaltrajectoryin
neural phase space,
μα = μ∗
α(t)a n d pα = p∗
α(t),
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2637
which minimize the IA (see equation 3.2). The entire minimization proce-
dure may be stated abstractly as
(μ∗
α, p∗
α ) = argmin
μα,pα
S(μα, pα;ϕ), (3.25)
whereS is the IA. We emphasize here that minimization is conditioned on
the organism as a model of the world.
NotethatourrevisedRD involvesnotonlytheorganism’spredictionof
the environmental change via its representationμα but also the dynamics
of its prediction errorpα.
4 Biophysical Implementation
We know that the anatomy and entire function of an organism’s brain de-
velop from single cells. In order to provide empirical Bayesian filtering in
the FEPwith a solid biophysical basis, we must start with known biophys-
ical substrates and then introduce probabilities to describe a neuron, neu-
rons, and a network. Thus far, however, most work has taken the reverse
direction: theory prescribes first a conjectural model and then attempts to
allocatepossibleneuralcorrelates.Atpresent,ourknowledgeremainslim-
ited on how biophysical mechanisms of neurons implicate predictions and
model aspects of the environment. From this perspective, a neurocentric
approachtotheinferenceproblemseemssuggestivetobridgethegap(Fio-
rillo, 2008; Fiorillo, Kim, & Hong, 2014).
Here, we regard coarse-grained Hodgkin-Huxley (H-H) neurons as the
generic, basic building blocks of encoding and transmitting a perceptual
message in the brain. The famous H-H model continues to be used to this
dayincomputationalneurosciencestudiesofneuronaldynamics(Hodgkin
& Huxley, 1952; Hille, 2001). In extracellular electrical recordings, the local
fieldpotentialandmultiunitactivityresultincombinedsignalsfromapop-
ulationofneurons(Einevoll,Kayser,Logothetis,&Panzeri,2013).Suchav-
eragedneuronalvariablesmustsubservetheperceptualstatesandconduct
the cognitive computation in the brain. We shall call them “small” neural
particles and envisage that a small neural particle functions as a node that
collectively forms the whole neural network on a large scale. Before pro-
ceeding, we note that there have been many biophysical efforts to describe
such averaged neuronal properties, such as the neural mass models and
neural field theories (Jansen, Zouridakis, & Brandt, 1993; Jirsa & Haken,
1996; Robinson, Rennie, & Wright, 1997; David & Friston, 2003; Deco, Jirsa,
Robinson, Breakspear, & Friston, 2008). Furthermore, we note the bottom-
up effort of attempting to understand the large-scale brain function at the
corticalmicrocircuitlevelbasedontheaveragedspikesandsynapticinputs
over a coarse-grained time interval (Potjans & Diesmann, 2014; Steyn-Ross
& Steyn-Ross, 2016).
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2638 C. S. Kim
4.1 SingleCellDescription. Wefirstpresenthowourformulationmay
beimplementedatasingle-celllevelbyhypothesizingthateachneuronre-
flectsthefundamentalsoftheperceptualcomputationofthewholesystem.
Atypical neuron receives current information about its surroundings from
the sensory periphery via glutamate, which excites or inhibits the mem-
branepotential V whileregulatingthegatingvariables γl andionicconcen-
trations nl, wherel is the ion channel index. We assume that (V,{nl},{γl})
represents the neural states of a neuron as a neural observer in the neural
configurationalspace(Fiorilloetal.,2014).Weencapsulatetheneuralstates
as components in a multidimensional row vector:
{μ}= (V,{nl},{γl}) = (μ1,μ2,μ3,... ).
TheH-Hequationforexcitationofthemembranevoltage Vinaspatially
homogeneous cell is given by
CdV
dt =
∑
l
γlGl(El − V)+ Iex(t), (4.1)
whereCisthemembranecapacitance; Gl isthemaximalconductanceofion
channell;γl istheprobabilityfactorassociatedwiththeopeningorclosing
channel l, which in general is a product of activation and inactivation gat-
ing variables; andIex is the external driving current. For simplicity, contri-
butions from leakage current as well as synaptic input are assumed to be
included in the external currents. In general, the reverse potentialEl of the
lth ion channel is given, allowing its time dependence via nonequilibrium
ion concentrations to be expressed as
El(t) = kBT
ql
ln nli(t)
nlo(t), (4.2)
where kB is the Boltzmann constant,T is the metabolic temperature of an
organism,ql is the ionic charge of channell,a n dnli(t)a n dnlo(t) are the in-
stantaneous ion concentrations inside and outside the membrane, respec-
tively.Inthesteadystatewithoutexternalcurrent, Iex = 0,and Vtendstothe
resting(Nernst)potential V(t →∞ )whileretainingionicconcentrationsin
electrochemical equilibrium. The gating variableγl of ion channels is as-
sumed to obey the following chemical kinetics,
dγl
dt =− 1
τl
(γl − γleq)+ ηl, (4.3)
whereηl istheinvolvednoise.Therelaxationtime τl andsteady-stategating
variable γleq in equation 4.3 depend on the membrane potential in general:
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2639
τl = τl(V)a n d γleq = γleq(V).
For ionic concentration dynamics, we suppose that ion concentrations
{nl} vary slowly compared to the membrane potential and gating-channel
kinetics,andweconsequentlytreatthemasstaticinourwork.Thisrestric-
tion can be lifted when a more detailed description is required for ion con-
centration dynamics. Accordingly, the reverse potentialsEl are also treated
as static below.
Then the state equations for the multivariate neural variable{μ} neatly
map onto the standard form suggested in the FEP,
dμα
dt = fα(V,{γl},{nl})+ wα(t), (4.4)
whereα takes the values 1,2,... with μ1 = V, μ2 = γ1, μ3 = γ2, and so on.
The driving functionsfα are specified as
fV(V,{γl}; {nl}) = 1
C
∑
l
γlGl(El − V)+ 1
CIex, (4.5)
fγl (V,{γl}; {nl}) =− 1
τl
(γl − γleq). (4.6)
The termswα in equation 4.4 describe the noisy synaptic and/or leakage
current wV flowing into the neural cell rather than the deterministic con-
tribution Iex included in fV and the noisewγl = ηl associated with the acti-
vation and inactivation of ion channels, respectively. For both noise terms,
weassumethegaussiandistributions N(˙μα − fα;0,σ wα )withvariances σwα
about zero means.
For neuronal response to the sensory stimulusϕα,w ea d o p tt h eu s u a l
generative map in the FEP(see equation 2.7) as follows:
ϕα = gα(V,{γl},{nl})+ zα, (4.7)
where gα is the generative map that is unknown but must be supplied for
practical application andzα characterizes the stochastic nature of the sen-
sory reading, which we assume to have the normal distributionN(ϕα −
gα;0,σ zα ).Withthemodel,theneuralobserverrespondstothesensorydata
instantly by means of the neuronal states. Currently, we do not possess a
firm ground on the biophysical processes of the sensory prediction.
As a working example, we consider here the H-H neuron, which al-
lows fast relaxation (i.e.,τl ≪ 1) of gating variables to their steady states,
γl(t) → γl(∞) = γleq(V). In this case, our neural particle is fully character-
izedbyasingledynamicalvariable V.Notethatthetimedependenceofthe
gating variables occurs only implicitly through the long-time membrane
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2640 C. S. Kim
voltages in equation 4.5. Then the RD of our neural particle is fulfilled in a
two-dimensional state space spanned by{μ}= (V, pV) ≡ (μ, p), prescribed
by the Hamiltonian function, given by equation 3.9,
H(μ, p) = p2
2mw
− 1
2mz(ϕ − g)2 + pf,
wheremw = σ−1
w andmz = σ−1
w .Whilethe“dissipative”function f isexplic-
itly given in the H-H model as
f(μ) = 1
C
∑
l
γleq(μ)Gl(El − μ)+ Iex/C, (4.8)
the“conservative”function gmustbeadditionallysupplied.Moreover,one
needstomakethevoltagedependenceof γleq availableinpractice.Notethat
theHamiltonianisnonautonomousingeneralbecauseitexplicitlydepends
on time through both the sensory inputϕ(t) and the driving currentIex in
f,a sw e l la st h r o u g hσw(t)a n dσz(t) when the noisy data are statistically
nonstationary.
Figure 3 presents the energy landscape described by the Hamiltonian
function, assuming static sensory data, constant driving currents, and sta-
tisticalstationarity.Sinceourknowledgeislimitedtothefunctionalformof
g(μ)a n df(μ), we have taken the algebraic polynomial approximations by
replacing transcendental nonlinearities in the H-H model (Wilson, 1999):
g(μ) ≈ a0 + a1μ + a2μ2,
f(μ) ≈ b0 + b1μ + b2μ2 + b3μ3.
For numerical purposes, we have specified ( a0,a1,a2) = (0,1,1) and
(b0,b1,b2,b3) = (0,0.1,1,1) and assumed a static sensory input with equal
masses(precisions)onthebrain’sinternalmodelandbeliefofsensorypre-
diction as
ϕ = 1.0a n d mw = mz = 0.1.
Moreover, for simplicity, we have assumed that the input current is con-
stant.
The Hamilton equations of motion, equations 3.23 and 3.24, yield the
nonlinear RD as
˙μ = /Lambda11(μ, p;t), (4.9)
˙p = /Lambda12(μ, p;t), (4.10)
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2641
Figure 3: Hamiltonian functionH(μ, p) in arbitrary units for the chosen set of
parameters given in the main text, where the black curve on the energy land-
scape is the trajectory calculated by solving the Hamilton equations of motion
for an initial condition at (μ, p) = (2.5, −5.0). (For interpretation of the color in
this figure, see the web version of this article.)
where the “force” functions/Lambda11 and/Lambda12 are expressed as
/Lambda11 = f(μ)+ 1
mw
p, (4.11)
/Lambda12 =− mz(ϕ − g)∂g
∂μ − ∂ f
∂μ p. (4.12)
Wehavechosenaninitialstateandsolvedtheequationsofmotiontoobtain
theresultingtrajectory.Theoutcomeisdrawnonthespecifiedenergyland-
scapeinFigure3.Accordingtothemodel,theneuralobserverperformsthe
RD,giventhesensoryinput ϕ,andconsequentlyobtainstheoptimaltrajec-
tory (μ∗, p∗) conforming to equation 3.25. In the long-time limit, the brain
will reach a fixed (equilibrium) point (μ∗
eq, p∗
eq) in the state space, which is
specified by intersections of twoisoclines,
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2642 C. S. Kim
Figure4: Optimaltrajectoriesinphasespace,whichareobtainedbyintegrating
the RD, given by equations 4.9 and 4.10, from the initial conditions arbitrarily
chosen on the red circle. Here the blue dots are fixed points among which only
the middle dot, at (−0.50, −0.01), is a stable fixed point; the other two points
aresaddlepoints.Thestablefixedpointturnsouttobeacenter,whichwehave
confirmednumericallyandbylinearstabilityanalysis.(Forinterpretationofthe
color in this figure, see the web version of this article.)
/Lambda1i(μ, p;∞ ) = 0, i= 1,2.
We determined the fixed points numerically and found that there ex-
ist three real solutions for the specified system parameters, (−1.23,0.05),
(−0.50,−0.01), and (0.07,−0.04), which are depicted as blue dots in Fig-
ure 4. Through further analysis, we have found that only the middle point
is a stable equilibrium solution, while the other two are saddle points. Fig-
ure 4 shows a flow of trajectories obtained from arbitrary initial points on
the red-colored circle of radiusμ2 + p2 = 1.6 in phase space.
Togaininsightintohowthesystemapproachesasteadystate,weinspect
the optimal trajectories near an equilibrium point:
μ∗ ≈ μ∗
eq + δμ∗ and p∗ ≈ p∗
eq + δp∗.
We expand equations 4.9 and 4.10 to the linear order in the deviationsδμ∗
and δp∗ and, after rearrangement, obtain the normal form,
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2643
d
dt
(
δμ∗
δp∗
)
+
(
R11 R12
R21 R22
)(
δμ∗
δp∗
)
= 0. (4.13)
In equation 4.13, the elements of the relaxation (Jacobian) matrixR are ex-
pressed as
R11 =−
[ ∂ f
∂μ
]
eq
, R12 =− 1
mw
R21 = σ−1
z
[
−
( ∂g
∂μ
) 2
+ (ϕ − g)∂2g
∂μ2 − ∂2 f
∂μ2 p
]
eq
,
R22 =
[ ∂ f
∂μ
]
eq
,
where the partial derivatives are to be evaluated at the equilibrium points.
Here, for notational convenience, we denote the column vector as
δψ ≡
( δμ∗
δp∗
)
.
Then, the formal solution to equation 4.13 is expressed as
δψ(t) = e−Rtδψ(0).
One may expand the initial stateψ(0) in terms of the eigenvectors ofR as
δψ(0) =
∑
cαφα,
wheretheeigenvalues λα andeigenvectors φα aredeterminedbythesecular
equation,
Rφα = λαφα.
Consequently, the solution to the linear RD at a single node level is com-
pleted as
δψ(t) =
2∑
α=1
cαe−λαtφα, (4.14)
where the expansion coefficientscα are fixed by the initial condition.
In the linear regime, a geometrical interpretation of the equilibrium so-
lutions is possible by inspecting the eigenvalues of the Jacobian matrixR.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2644 C. S. Kim
Considering that the matrixR is not symmetric, we anticipate that the
eigenvalues are not real. Furthermore, because the trace of the relaxation
matrix equals zero, the sum of the two eigenvalues must be zero. Thus,
whenthedeterminantof Rispositive,thetwoeigenvalues λ1 andλ2 would
be purely imaginary with opposite signs. Consequently, in our particular
model,theresultingequilibriumpointislikelytobeacenter.Wehavecon-
firmed numerically that the eigenvalues of the Jacobian corresponding to
the stable equilibrium point in Figure 4 are±1.6i, specifying a center.
4.2 The Hierarchical Neural Network.Here, we suppose that a finite
number of levels exist in the perceptual hierarchy of the whole system and
that for simplicity, each level is characterized efficiently as a single neural
node. Further, we assume that the neural node at hierarchical leveliis de-
scribedbythecoarse-grainedactivationandconnectionvariables,denoted
asV(i) andS(i),respectively.Theactivationvariabledescribestheactionpo-
tential at a node, and the connection variable describes interlevel synaptic
inputandoutputvariables.Bothvariablesarederivedfromapopulationof
neurons and thus vary on a coarse-grained space and timescale. The tech-
nical details of how one may derive such a coarse-grained description are
outofourscope(seeDecoetal.,2008,forareference).Thesevariablesform
the coordinates in the brain’s configurational space,
μ(i) = (V(i),S(i)),
where the superscripti= 1,2,..., M, withMdenoting the highest level.
Weassumethattheactivationvariables V(i) obeytheeffectivedynamics
with noisew(i) within each hierarchical leveli,
dV(i)
dt = f(i)(V(i),S(i))+ w(i), (4.15)
which is a direct generalization of equation 4.4 with the incorporation of
the hierarchical dependence viaS(i). For interlevel dynamics, we propose
thattheconnectionvariablesareupdatedbyaone-level-higherconnection
as well as activation variables, subjected to the stochastic equations
dS(i)
dt = g(i+1)(V(i+1),S(i+1))+ z(i), (4.16)
wherez(i) representsthe noiseassociatedwith theprocess. Thebrain’stop-
downpredictionfunctions f(i) andg(i) mustbesuppliedinpracticalimple-
mentation.Notethatonlyspontaneousfluctuationoccursatthetopcortical
level, i= M; accordingly,
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2645
g(M+1) = 0. (4.17)
Furthermore, we enforce the constraint that the sensory dataϕ enter the
interface of (or boundary between) the brain and environment, which is
specified as the lowest hierarchical level,i= 1. Subsequently we assume
that the brain’s prediction of the sensory inputs is performed by way of an
instantaneous mapping,
S(0) = g(1)(V(1),S(1))+ z(0), (4.18)
where, for notational convenience, we have set
S(0) ≡ ϕ(t).
Weremarkthatthehierarchicalequationswepropose,equation4.16,are
dissimilar to the conventional formulation, which assumes a static nonlin-
earity in the entire hierarchy like the one in equation 4.18 at the sensory
interface (see Buckley et al., 2017). One may ensure that the time constants
of equation 4.16 are sufficiently fast to approximate a static nonlinearity.
Here, we treat the connection variables dynamically, rather than statically,
totreatlateralandhierarchicaldynamicssymmetrically.Theratesoftheac-
tivation and connection variables may be subjected to different timescales
thatcanbeincorporated,forinstance,byintroducingdistinctiverelaxation
times in their generative functions. It turns out that our equations suit the
formalism of the Hamilton action principle neatly.
Having specified our hierarchical model, we express the informational
Lagrangian for the constructed neural network by generalizing equation
3.18 with a single sensory input for now as
L(V, ˙V;S, ˙S;ϕ) = 1
2
M∑
i=1
m(i)
w
(
ε(i)
w
) 2
+ 1
2
M∑
i=0
m(i)
z
(
ε(i)
z
) 2
, (4.19)
where m(i)
w and m(i)
z are the inertial masses (precisions) associated with the
gaussian noises,w(i) andz(i), respectively, and are defined as
m(i)
w ≡ 1/σ(i)
w and m(i)
z ≡ 1/σ(i)
z . (4.20)
The auxiliary variables in the Lagrangian are defined as (i≥ 1)
ε(i)
w ≡ ˙V(i) − f(i)
(
V(i),S(i)
)
, (4.21)
ε(i)
z ≡ ˙S(i) − g(i+1)
(
V(i+1),S(i+1)
)
. (4.22)
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2646 C. S. Kim
We interpret thatε(i)
w specifies the discrepancy between the change in the
present lateral state and the brain’s on-level prediction, which may be con-
sidered as the lateral prediction error. On the other hand,ε(i)
z measures the
prediction error between the change in the present hierarchical state and
its prediction from one higher level via the generative mapg, which may
be viewed as the hierarchical prediction error. Note thatε(0)
z in the second
term on the right-hand side of equation 4.19 is defined separately as
ε(0)
z ≡ S(0) − g(1)
(
V(1),S(1)
)
,
whichspecifiesanerrorestimationinsensorypredictionatthelowesthier-
archical level.
The canonical momenta, conjugate toV(i) andS(i), are readily calculated
for i≥ 1, respectively, as
p(i)
V ≡ ∂L
∂ ˙V(i) = m(i)
w ε(i)
w , (4.23)
p(i)
S ≡ ∂L
∂ ˙S(i)
= m(i)
z ε(i)
z . (4.24)
Note that the informational massesm(i)
w and m(i)
z are the precisions (see the
discussion below equation 3.5). The role of the inertial masses is to modu-
late the discrepancy between the change of the perceptual states and their
prediction. Thus, in our theory, the momentump(i)
V i sam e a s u r eo fl a t e r a l
prediction error modulated by inertial massm(i)
w , and the momentump(i)
S is
a measure of hierarchical prediction error modulated by inertial massm(i)
z .
The precision is higher for a greater mass. In predictive coding formula-
tionsoftheFEP,thismodulatedpredictionerrorisknownastheprecision-
weighted prediction error.
Given the Lagrangian in equation 4.16, we can formulate the informa-
tional Hamiltonian by performing a Legendre transformation:
H =
∑
i
(
˙V(i)p(i)
V + ˙S(i)p(i)
S
)
− L.
After some manipulation, we obtain
H(V, pV;S, pS;ϕ) =
M∑
i=1
(
T (i) + V(i)
)
, (4.25)
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2647
where the informational kinetic energy is defined as (i≥ 1)
T (i)(pV, pS) = 1
2m(i)
w
(
p(i)
V
) 2
+ 1
2m(i)
z
(
p(i)
S
) 2
(4.26)
and the potential energy as (i≥ 2)
V(i)(V, pV;S, pS;ϕ) ≡ p(i)
V f(i) + p(i)
S g(i+1). (4.27)
Note that the potential energy at the lowest level is specified separately as
V(1) = p(1)
V f(1) − 1
2m(0)
z
(
p(0)
S
) 2
, (4.28)
where, for notational convenience, we have expressed the precision-
weighted prediction error associated with the sensory measurement as
p(0)
S ≡ m(0)
z ε(0)
z = m(0)
z (ϕ − g(1)),
which,unlike p(i)
S fori≥ 1,isnotacanonicalmomentum.Consequently,the
multilevel Hamiltonian in equation 4.25 has been prescribed via the per-
ceptual states in the hierarchical chain,i= 1,2,..., M, denoted as a four-
dimensional column vectorψ(i) at each level,
ψ(i) = (V(i), p(i)
V ,S(i), p(i)
S )T ≡ (ψ(i)
1 ,ψ (i)
2 ,ψ (i)
3 ,ψ (i)
4 )T,
where T indicates the transpose operation.
Next,itisstraightforwardtogeneratetheHamiltonianequationsofmo-
tionforthebrain’sperceptualstates ψ(i).Theresultsarethecoupleddiffer-
entialequationsforthefourcomputationalcomponentsateachlevel( i≥ 1),
which are, in turn, hierarchically connected among adjacent levels:
˙V(i) = ∂H
∂p(i)
V
= 1
m(i)
w
p(i)
V + f(i), (4.29)
˙S(i) = ∂H
∂p(i)
S
= 1
m(i)
z
p(i)
S + g(i+1), (4.30)
˙p(i)
V =− ∂H
∂V(i) =− ∂ f(i)
∂V(i) p(i)
V − ∂g(i)
∂V(i) p(i−1)
S , (4.31)
˙p(i)
S =− ∂H
∂S(i) =− ∂ f(i)
∂S(i) p(i)
V − ∂g(i)
∂S(i) p(i−1)
S . (4.32)
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2648 C. S. Kim
According to the derived RD, the sensory inputsϕ enter the brain-
environment interface at the levelj = 1, and are instantly predicted by the
organism’s lowest-level generative modelg(1)(V(1),S(1)). Subsequently, the
resultingpredictionerror p(0)
S actsasasourcetoupdatethepredictionerrors
p(1)
V and p(1)
S . The changes of on-level perceptual statesV(1) andS(1) are pre-
dicted by the generative modelsf(1) and g(2) with additional modulations
from the perceptual momentap(1)
V and p(1)
S , which are the lateral and hier-
archicalpredictionerrors,respectively.Athigherlevels i≥ 2,theintralevel
dynamicsoftheactivationstate V(i) isupdatedthroughequation4.29bythe
on-level generative functionf(i) and prediction errorp(i)
V , while the change
of the current hierarchical stateS(i) is determined through equation 4.30 by
the interlevel predictiong(i+1) and the on-level prediction errorp(i)
S . The or-
ganism’s top-down message flow is mediated by the connection stateS(i)
via equation 4.30 as (S(i+1),V(i+1)) → S(i). Furthermore, equations 4.31 and
4.32 govern the coupled, bottom-up propagation of the prediction errors,
mediated byp(i)
S , p(i)
S → (p(i+1)
S , p(i+1)
V ). Figure 5 schematically illustrates the
perceptualarchitectureofthehierarchicalnetworkatthelowesttwolevels,
implied by equation 4.29 to 4.32. It shows the top-down prediction of the
sensory inputsϕ at the lowest level and the bottom-up propagation of the
prediction errorsp(0)
S .
Here,weemphasizethatthedynamicsofprecision-weightedprediction
errors, encapsulated in canonical momenta in which mass takes over the
role of precision, are taken into account in our Hamiltonian formulation
on an equal footing with the dynamics of prediction of the state variables.
This aspect is also in contrast to the conventional minimization algorithm,
which entails differential equations only for the update of the brain states
without carrying parallel ones for the prediction errors. Consequently, the
message passing in our model shows different features compared with the
neuralcircuitryfromtheconventionalRD(Bastosetal.,2012).However,the
general message flow, in terms of the computational units, of feedforward,
feedback,andlateralconnectionsremainsthesameinthehierarchicalbrain
network. An attempt to incorporate the brain’s computation of prediction
errors in the FEPcan be found in a recent tutorial model (Bogacz, 2017).
Here, for mathematical compactness, we rewrite the filtering algorithm,
equations 4.29 to 4.32, as
dψ(i)
α
dt = /Lambda1(i)
α ({ψ(i)
α }), (4.33)
where the hierarchical indexiruns from 1 toM,α runs from 1 to 4, and the
forcefunction /Lambda1(i)
α isthecorrespondingright-handsidetoeachvectorcom-
ponent ψ(i)
α at cortical leveli. The obtained hierarchical equations are the
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2649
Figure 5: A schematic of the neural circuitry that conducts the RD given by
equations 4.29 to 4.32 in the hierarchical network of the brain, where the com-
putational units (S(i),V(i), p(i)
S , p(i)
V ), i= 1, 2,..., M, are connected by arrows for
excitatory (positive) inputs and by lines ended with filled dots for inhibitory
(negative) inputs. Note that the prediction errorp(0)
S of incoming sensory data
ϕ, at the lowest level, induces an inhibitory change in the perceptual momenta
(p(1)
S , p(1)
V ). Subsequently, the prediction error propagates up in the hierarchy,
p(1)
S → (p(2)
S , p(2)
V ), and so on. The top-down message passing is mediated by
means of the connection statesS(i). For instance, the connection stateS(1) istop-
down predicted by both units (S(2),V(2)) from one level higher.
highlight of our theory, prescribing the RD of the brain’s sensory inference
under the FEPframework.
To apply our formulation to an empirical brain, one needs to supply the
generatingfunctionoflateraldynamics f(i) andthehierarchicalconnecting
functiong(i), which enter the force functions/Lambda1(i)
α in the perceptual mechan-
ics given by equation 4.33. For the generating function, we again use the
H-H model in equation 4.5 to write
f(i)(V(i),S(i)) =
∑
l
γleq ˜Gl
(
El − V(i)
)
+ ˜GSS(i)
(
ES − V(i)
)
, (4.34)
where ˜Gl are the channel conductances normalized by the capacitanceC.
Moreover, the second term on the right-hand side accounts for other deter-
ministic driving sources such as leakage or lateral synaptic currents, with
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2650 C. S. Kim
˜GS beingthenormalizedsynapticconductance.Thehierarchicalconnection
function, for which we have limited biophysical knowledge, shall be taken
in a simple form here as
g(i)(V(i),S(i)) = /Gamma1(V(i))S(i), (4.35)
where the function/Gamma1denotes the voltage-dependent synaptic plasticity
fromhierarchicallevel itolevel i− 1.Inaddition,asinthesingle-nodecase,
one must supply approximate models for the voltage dependence of the
gating variablesγleq and the connection strength/Gamma1. For instance, one may
take the quadratic approximations (Wilson, 1999)
γleq(V(i)) ≈ bl0 + bl1V(i) + bl2V(i)V(i),
/Gamma1(V(i)) ≈ a0 + a1V(i) + a2V(i)V(i).
Havinglaiddownthelateralandhierarchicalgenerativemodels,theor-
ganism’s brain can now perform the RD given a stream of noisy inputs.
Whileconductingthefiltering,anoptimaltrajectoryisobtainedinmultidi-
mensional phase space,
ψ∗(i)
α = ψ∗(i)
α (t),
which, in the end, tends to a fixed point,ψ(i)
α,eq = ψ∗(i)
α (t →∞ ). The neces-
sary equilibrium condition for equation 4.33 is
/Lambda1(i)
α ({ψ(i)
α }) = 0. (4.36)
Although the full time-dependent solutions must be invoked numeri-
cally,onemayinspecttheperceptualtrajectoriesnearafixedpointbylinear
analysis. To this end, we consider a small deviation of theαth component
oftheperceptualstatevector ψ∗(i)
α atthecorticallevel i,δψ(i)
α ,fromthefixed
point ψ(i)
α,eq:
ψ∗(i)
α ≈ ψ(i)
α,eq + δψ(i)
α .
Then, we expand equation 4.33 about the fixed point to the linear order in
the small deviation, and after some manipulation, we obtain the hierarchi-
cal equations forδψ(i)
α ,
dδψ(i)
α
dt +
4∑
β=1
R(i)
αβ δψ(i)
β =
4∑
β=1
M∑
j̸=i
/Phi1(ij)
αβ δψ(j)
β , (4.37)
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2651
where theαβ component of the 4× 4 Jacobian matrix at cortical leveli is
given by
R(i)
αβ =
[
∂/Lambda1(i)
α
∂ψ (i)
β
]
eq
.
Theinterlevelconnectionbetweenlevels iand jinthehierarchicalpathway
is given by
/Phi1(ij)
αβ =
[
∂/Lambda1(i)
α
∂ψ (j)
β
]
eq
,
where the subscripteq indicates that the matrix elements are to be evalu-
atedattheequilibriumpoints.Tocasttheinhomogeneoustermintoamore
suggestive form, we further inspect it in detail within the models speci-
fied. We observe first that the matrix elements/Phi1(ij)
αβ do not vanish only for
α = 3 because only the force function/Lambda1(i)
3 possesses ψ(j)
β for j ̸= i as vari-
ables viag(i+1) (see equation 4.30). Second, becauseg(i+1) depends solely on
the hierarchical-level indexi+ 1, only matrix elements with the hierarchi-
cal indexj = i+ 1 survive. Combining these two observations, the source
term on the right-hand side of equation 4.37 is converted into a vector at
level i+ 1 with only a single nonvanishingα = 3 component,
4∑
β=1
M∑
j̸=i
/Phi1(ij)
αβ δψ(j)
β ≡ δζ (i+1)
α ,
which, for completeness, we spell out explicitly as
δζ (i+1)
α = δα3
⎧
⎨
⎩
[
∂g(i+1)
∂ψ (i+1)
1
]
eq
δψ(i+1)
1 +
[
∂g(i+1)
∂ψ (i+1)
3
]
eq
δψ(i+1)
3
⎫
⎬
⎭, (4.38)
whereδα3 is the Kronecker delta.
Finally, we present a formal solution to the linearized perceptual me-
chanics given by equation 4.37, which can be obtained by a direct integra-
tion with respect to time. The result takes the form
δψ(i)(t) = e−R(i)tδψ(i)(0) +
∫ t
0
dt′e−R(i)(t−t′)δζ (i+1)(t′). (4.39)
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2652 C. S. Kim
We next solve the eigenvalue problem at each hierarchical level, which is
defined as
R(i)φ(i)
α = λ(i)
α φ(i)
α , (4.40)
where λ(i)
α and φ(i)
α are the eigenvalues and corresponding eigenvectors at
leveli,respectively.Thenweexpandtheinitialstate δψ(i)(0)intermsofthe
complete eigenvectors:
δψ(i)(0) =
∑
a(i)
α φ(i)
α . (4.41)
Similarly, we may expand the inhomogeneous vectorδζ (i+1) as
δζ (i+1)(t′) =
∑
b(i+1)
α (t′)φ(i)
α , (4.42)
where the expansion coefficientsb(i+1)
α are time dependent. By substituting
the expansions equations 4.41 and 4.42 into equation 4.39, we obtain the
desired formal solution near equilibrium points:
δψ(i)(t) =
4∑
α=1
aαe−λ(i)
α tφ(i)
α +
4∑
α=1
φ(i)
α
∫ t
0
dt′e−λ(i)
α (t−t′)b(i+1)
α (t′). (4.43)
Thegeometricalapproachtoafixedpointisagaindeterminedbytheeigen-
values λ(i)
α ; however, the details are driven by the time-dependent genera-
tivesources b(i+1)
α (t)fromonelevelhigherinthehierarchy.Anapplicationof
equation 4.43 would be to determine the natural frequencies of predictions
and prediction errors. As the solution approaches an attractor, these corre-
spond to the imaginary parts of the principal eigenvalues above. This ap-
plication is potentially very interesting because there are characteristic fre-
quencies associated with message passing in the brain (Bastos et al., 2015).
The precise relevance of this formulation to the asymmetric frequency de-
pendence must be further explored.
To summarize, responding to a sensory streamϕ = S(0), at the lowest
hierarchical level (i= 1), the brain, which is initially in a resting state, per-
forms the hierarchical RD by integrating equation 4.33 to infer the external
causes. The ensuing brain’s computation corresponds to the minimization
of the IA, which is an upper bound of the sensory uncertainty. Its mathe-
matical statement, equation 2.3, is repeated compactly as
H[p(ϕ)] ≤ S[F;ϕ],
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2653
where the sensory uncertaintyH was defined in equation 2.1 and the IA
on the right-hand side is expressed here in terms of the hierarchical states
asS[F;ϕ] =
∫
dtF({ψ(i)
α };ϕ).ConformingtotheFEP,theminimumvalueof
IA specifies the tightest bound of the sensory uncertainty over a relevant
biological timescale, which preserves the organism’s current model of the
environment.
5 Discussion
We have recast the FEP following the principles of mechanics, which state
that all living organisms are evolutionally self-organized to tend to mini-
mizethesensoryuncertaintyaboutenvironmentalencounters.Thesensory
uncertaintyisanaverageofthesurprisaloverthesensorydensityregistered
onthebrain-environmentinterface,whichistheself-informationcontained
inthesensoryprobabilitydensity.TheFEPsuggeststhattheorganismsim-
plement the minimization by calling forth the IFE in the brain. The time
integral of the IFE gives an estimate of the upper bound of the sensory un-
certainty.WehaveenunciatedthattheminimizationoftheIFEmustcontin-
uallyoccuroverafinitetemporalhorizonofanorganism’sunfoldingenvi-
ronmentalevent.Ourschemeisageneralizationoftheconventionaltheory,
whichapproximatestheminimizationoftheIFEateachpointintimewhen
it performs the gradient descent. Note that the sensory uncertainty is an
information-theoreticalShannonentropy(Shannon,1948);however,inthis
work,weavoidedusingtheterm entropybecause“minimizationofthesen-
soryentropy”is reminiscentof ErwinSchrödinger’sthermodynamicterm,
negative entropy, which carries a disputable connotation implying how the
living organism avoids decay (Schrödinger, 1967). The nerve cell and the
brain are open systems, the physical entropy of which can increase or de-
creasedependingonthedirectionofheatflow.Accordingtofluctuationthe-
orems (see Crooks, 1999; Evans & Searles, 2002; Seifert, 2005, for instance),
under nonequilibrium conditions, it is reasonable to anticipate a statistical
deviation from the second law of thermodynamics even in finite systems
forafinitetime.ThebiologicalFEPpostulatesthattheorganism’sadaptive
fitness corresponds to the minimization of the sensory uncertainty, which
is the average surprisal. The average is required because the sensory or-
gans are not small or mesoscopic systems, and the perceptual and active
inferences are phenomena occurring in the macroscopic brain. Therefore,
from the perspective of the second law, the sensory-uncertainty minimiza-
tion must contribute to the total entropy of the brain and its environment
as a whole. Note, however, that the IFE we work with is an information-
theoretic construct rather than a physical quantity. Currently, we do not
have a theory to formulate the physical FE for the brain.
WehaveadoptedtheLaplace-encodedIFEasanILinimplementingthe
FEPunderthevariationalHamiltonprinciple.Further,bysubscribingtothe
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2654 C. S. Kim
standard Newtonian dynamics, we have considered the IFE to be a func-
tionofpositionandvelocityasmetaphorsfortheorganism’sbrainvariable
and their first-order time derivative, respectively. According to Newton’s
second law, the brain’s perceptual state, specified by the position and ve-
locity of the brain variables, changes by an applied force; for example, an
exogenous sensory perturbation is the cause of the rate of change of veloc-
ity or acceleration, which is the second-order time derivative of position.
The brain variable maps onto the first-order sufficient statistics of the R-
density engaged in the organism’s brain to perform the RD, which is the
Bayesian filtering of the noisy sensory data. In the ensuing Hamiltonian
formulation, the RD prescribes momentum, conjugate to position, as a me-
chanical measure of prediction error weighted by inertial mass, which is
the precision. We have eschewedthe use of generalizedcoordinates of mo-
tion, which is introduced in the prevailing theory to specify the extended
states of higher orders of motion. Consequently, the conceptual subtlety of
assigningthecausestohigher-ordermotionsbeyondaccelerationhasbeen
dismissed.Furthermore,thearbitrarinessinvolvedindecidingthenumber
ofgeneralizedcoordinatesforacompletedescriptionandtheambiguityin
specifyingunknowableinitialconditionshavebeenaverted.Consequently,
the RD tenably underpins the causality: for specified initial conditions for
the perceptual positions and corresponding momenta, the RD can be inte-
grated continuously online in response to sensory inputs.
Thefeaturesofthechangingworldenterourtheoryviatime-dependent
sensory inputs, which affect the brain states in continuous time. The tem-
poral correlation of the dynamical states may be incorporated as time-
dependent covariances; however, these are not explored in this work.
Moreover, in our theory, all the parameters in the RD are specified in
the Hamiltonian; thus, no extra parameters such as learning rates in the
gradient-descent scheme are required to control the speed of convergence
toasteadystate.Ineffect,thelearningrateisformallyidenticaltotheinfor-
mationalmassorprecision.Inotherwords,thelearningratesareimplicitin
the FEP, which is already optimal in the sense of approximate Bayesian in-
ference.Accordingtoourformulation,thebrain’sHelmholtzianperception
corresponds to finding an optimal trajectory in the hierarchical functional
networkbyminimizingtheIA.WhenthebraincompletestheRDbyreach-
ingadesiredfixedpointoranattractor,itremainsresting(i.e.,spontaneous)
until another sensory stimulus enters.
We have admitted the top-down rationale of sensory prediction in our
formalism, an essential facet of the FEP. As usual, the sensory inputs at the
interface, which is the lowest hierarchical level, were assumed to be in-
stantaneously mapped to the organism’s belief with associated noises. In
contrast, however, at higher levels, we have generalized that the interlevel
filtering in the brain’s functional hierarchy obeys the stochastic dynam-
ics, supplied with the organism’s dynamical generative model of environ-
mental states. The resulting RD notably incorporates the dynamics of both
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2655
predictionsandpredictionerrorsoftheuncertainsensorydataonthesame
footing in the computational architecture. Consequently, the details of the
ensuing neural circuitry from our formulation differ from that supported
bythegradient-descentscheme,whichgeneratesonlythedynamicsofpre-
dictionofthecausalandhiddenstates,nottheirpredictionerrors.Ourfor-
mulationprovidesanaturalaccountofthegeneralstructureofasymmetric
messagepassing,namely,descendingpredictionsandascendingprediction
errors, in the brain’s hierarchical architecture.
To show how our formulation may be implemented in the biophysi-
cal brain, we have employed the H-H-type neuronal dynamics at a single-
celllevelandsubsequentlyconstructedthelarge-scaleperceptualcircuitry.
We have chosen the conductance-based model, which is complex but ex-
perimentally grounded (Koch, 1999; Hille, 2001), instead of more efficient
spiking models such as integrate-and-fire or firing-rate models (Dayan &
Abbott, 2001; Izhikevich, 2003; Burkitt, 2006). The reason was that while
theH-Hdynamicsdeliversanautonomoustrajectory,theintegrate-and-fire
modelsbearanabruptdynamicalinterruptioninvolvedinsettingspikefir-
ing at a threshold and resetting voltage to a resting value; in other words,
thespikegenerationitselfisnotpartofthedynamicaldevelopment.More-
over, the firing-rate models describe average dynamics over many trials
rather than single-neuron dynamics; therefore, they neglect the detailed
time course of the action potential. To derive the RD within the framework
of the FEP, the IA must be minimized continuously with respect to trajec-
tories, which requires an implicit (autonomous) time dependence of the
IFE through its arguments, that is, the dynamical variables. Furthermore,
the spike-sorting problem from raw extracellular recordings is still a chal-
lengingproblem(Einevoll,Franke,Hagen,Pouzat,&Harris,2012).Forthe
working example in this article, we have assumed that the gating kinetics
relaxed quickly to a steady state and the ion concentrations stayed in elec-
trochemical equilibrium. Consequently, we considered the state equation
for single neurons on a timescale in which only the change in the mem-
branepotentialmattered,andthedetailsoffiringrate,axonalpropagation,
and dendritic time lags were ignored in the computational description.
Finally,theunderlyingmechanismforlearninginthebrainwasnotcon-
sidered explicitly in our biophysical implementation, unlike the common
firing-rate models of network neurons. In the latter, the coupling mecha-
nism between the presynaptic and postsynaptic rates, via phenomenolog-
ical synaptic weights, facilitates Hebbian plasticity for learning (Abbott,
1994; Martin, Grimwood, & Morris, 2000). In our formulation, the synaptic
efficacy at a neuronal level can be incorporated by considering a synaptic
input current in the driving function (see equation 4.8), which would in-
fluencethepostsynapticoutput,equations4.9and4.10.Similarly,toimple-
ment the synaptic plasticity at the network level, one can add the synaptic
driving terms in the intra- and interlevel generative functions in equations
4.15and4.16andminimizetheIAtoobtaintheRD.Thegeneralstructureof
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2656 C. S. Kim
the outcome will appear the same as the neural circuitry presented in Fig-
ure5.Thepositions—activationandconnectionvariables—andtheircorre-
spondingmomentainthebraincircuitrymaymapontotherepresentational
and error units, respectively, among functional populations of neurons in
thecortex(Summerfield&Egner,2009).Itturnsoutthatthetwofunctional
populations in Figure 5 do not follow Dale’s law, because they have neural
units with both excitatory and inhibitory outputs (Dayan & Abbott, 2001;
Okun&Lampl,2008).Intheconventionalspikingmodels,thenetworkdy-
namics is put in place by writing down coupled equations obeying Dale’s
law for the two biophysically distinct classes of neurons (see Aitchison &
Lengyel,2016,forinstance).Thisleavesachallengeintheframeworkofthe
FEP for rendering the RD, which operates on the functional neural units,
to reconcile with Dale’s law for the biophysical neurons. Furthermore, the
synapticgainmaybeformulatedeffectivelyinthepresenttheorybytaking
into account the statistical nonstationarity of the fluctuations (MacDonald,
2006)involvedinthestateequations.Thestatisticalnonstationaritysetsup
anextratimescaleoverwhichtheprecisionsaretransient(seeequation4.20)
and slower than that associated with the change of the state variables. Ac-
cordingly, one may treat the time-dependent precision as an independent
dynamicvariableintheLagrangian,prescribinggain,andgenerateHamil-
ton’sequationofmotionforthegainvariables,therebygeneralizingtheRD.
Consequently, the generalized RD can deliver the gain control over model
learningintheextendedstatespacecomprisingnotonlybrainvariablesand
momenta but also gain variables and their partner momenta. The work is
in progress and will be reported elsewhere.
In short, we are still a long way from understanding how the Bayesian
FEP in neurosciences may be made congruous with the biophysical reality
of the brain. It is far from clear how the organism embodies the generative
model of the environment in the physical brain. Our theory delivers only a
hybridmodelofthebiologicallyplausibleinformation-theoreticframework
oftheFEPandthemechanicalformulationoftheRDundertheprincipleof
least action. To quote Hopfield (1999), “It lies somewhere between a model
ofneurobiologyandametaphorforhowthebraincomputes.”Wehopethat
our effort will guide a step forward for solving the challenging problem.
Acknowledgments
Ithankanonymousreviewersforprovidinginvaluablecommentsandsug-
gestions to improve this article.
References
Abbott,L.F.(1994).Decodingneuralfiringandmodelingneuralnetworks. Quarterly
ReviewofBiophysics ,27, 291–331.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2657
Aitchison, L., & Lengyel, M. (2016). The Hamiltonian brain: Efficient probabilistic
inference with excitatory-inhibitory neural circuit dynamics.PLoSComputational
Biology,12(12), e1005186.
B a s t o s ,A .M . ,U s r e y ,W .M . ,A d a m s ,R .A . ,M a n g u n ,G .R . ,F r i e sP . ,&F r i s t o n ,K .J .
(2012). Canonical microcircuits for predictive coding.Neuron,76, 695–711.
Bastos, A. M., Vezoli, J., Bosman, C. A., Schoffelen, J.-M., Oostenveld, R., Dowdall,
J .R . ,...F r i e s ,P .(2015). Visual areas exert feedforward and feedback influences
through distinct frequency channels.Neuron,85, 390–401.
Berkes, P., Orban, G., Lengyel, M., & Fiser, J. (2011). Spontaneous cortical activity
reveals hallmarks of an optimal internal model of the environment.Science, 331,
83–87.
Bogacz,R.(2017).Atutorialonthefree-energyframeworkformodellingperception
and learning.JournalofMathematicalPsychology , 76(B), 198–211.
Buckley, C. L., Kim, C. S., McGregor, S., & Seth, A. K. (2017). The free energy prin-
ciple for action and perception: A mathematical review.Journal of Mathematical
Psychology, 81, 55–79.
Buckley, C. L., & Toyoizumi, T. (2018). A theory of how active behavior stabilises
neuralactivity:Neuralgainmodulationbyclosed-loopenvironmentalfeedback.
PLoSComputationalBiology ,14(1), e1005296.
Burkitt, A. N. (2006). A review of the integrate-and-fire neuron model: I. Homoge-
neous synaptic input.BiologicalCybernetics,95, 1–19.
Crooks, G. E. (1999). Entropy production fluctuation theorem and the nonequilib-
rium work relation for free energy difference.PhysicalReviewE ,60, 2721–2726.
David,O.,&Friston,K.J.(2003).AneuralmassmodelforMEG/EEG:Couplingand
neuronal dynamics.NeuroImage, 20, 1743–1755.
Dayan,P.,&Abbott,L.F.(2001). Theoreticalneuroscience. Cambridge,MA:MITPress.
Dayan,P.,Hinton,G.E.,Neal,R.M.,&Zemel,R.S.(1995).TheHelmholtzmachine.
NeuralComputation, 7, 889–904.
Deco, G., Jirsa, V. K., Robinson, P. A., Breakspear, M., & Friston, K. (2008). The dy-
namic brain: From spiking neurons to neural masses and cortical fields.PLoS
ComputationalBiology,4, e1000092.
Einevoll, G. T., Franke, F., Hagen, E., Pouzat, C., & Harris, K. I. (2012). Towards reli-
ablespike-trainrecordingsfromthousandsofneuronswithmultielectrodes. Cur-
rentOpinioninNeurobiology ,22, 11–17.
Einevoll,G.T.,Kayser,C.,Logothetis,N.K.,&Panzeri,S.(2013).Modellingandanal-
ysis of local field potentials for studying the function of cortical circuits.Nature
ReviewsNeuroscience,14, 770–785.
Evans, D. J., & Searles, D. J. (2002). The fluctuation theorem.AdvancesinPhysics , 51,
1529–1585.
Fiorillo,C.D.(2008).Towardsageneraltheoryofneuralcomputationbasedonpre-
diction by single neurons.PLoSOne, 3(10), e3298.
Fiorillo, C. D., Kim, J. K., & Hong, S. Z. (2014). The meaning of spikes from the neu-
ron’spointofview:Predictivehomeostasisgeneratestheappearanceofrandom-
ness. FrontiersinComputationalNeuroscience ,8, 49.
Friston, K. (2006). A free energy principle for the brain,Journal of Physiology-Paris,
100, 70–87.
Friston, K. J. (2008a). Variational filtering.NeuroImage, 41, 747–766.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

2658 C. S. Kim
Friston, K. (2008b). Hierarchical models in the brain.PLoS Computational Biology,
4(11), e1000211.
Friston, K. (2009). The free-energy principle: A rough guide to the brain?Trends in
CognitiveScience,13, 293–301.
Friston, K. (2010). The free-energy principle: Aunified brain theory?NatureReviews
Neuroscience,11, 127–138.
Friston,K.(2013).Lifeasweknowit. JournaloftheRoyalSocietyInterface ,10,20130475.
Friston, K., Adams R. A., Perrinet L., & Breakspear, M. (2012). Perceptions as hy-
potheses: Saccades as experiments.FrontiersinPsychology , 3, 151.
Friston, K. J., Daunizeau, J., & Kiebel, S. J. (2009). Reinforcement learning or active
inference?PLoSOne, 4(7), e6421.
Friston, K. J., Daunizeau, J., Kilner, J., & Kiebel, S. J. (2010). Action and behavior: A
free energy formulation.BiologicalCybernetics, 102(3), 227–260.
Friston, K., & Kiebel, S. (2009). Cortical circuits for perceptual inference.NeuralNet-
works,22, 1093–1104.
Friston, K. J., & Stephan, K. E. (2007). Free-energy and the brain.Synthese, 159, 417–
458.
Friston, K., Stephan, K., Li, B., & Daunizeau, J. (2010). Generalized filtering.Mathe-
maticalProblemsinEngineering , 261670.
Gregory,R.L.(1980).Perceptionsashypotheses. PhilosophicalTransactionsoftheRoyal
SocietyofLondonB , 290, 181–197.
Hille,B.(2001). Ionchannelsofexcitablemembranes (3rded.).Sunderland,MA:Sinauer
Associates.
Hodgkin, A., & Huxley, A. (1952). Aquantitative description of membrane current
and its application to conduction and excitation in nerve.Journal of Physiology,
117, 500–544.
Hopfield, J. J. (1999). Brain, neural network, and computation.Review of Modern
Physics, 71, S431–S437.
Izhikevich,E.M.(2003).Simplemodelofspikingneurons. IEEETransactionsonNeu-
ralNetworks, 14(6), 1569–1572.
Jansen, B. H., Zouridakis, G., & Brandt, E. (1993). A neurophysiologically-based
mathematical model of flash visual potentials.Biological Cybernetics, 68, 275–
283.
Jazwinski, A. H. (1970).Stochastic process and filtering theory.New York: Academic
Press.
Jirsa,V.K.,&Haken,H.(1996).Fieldtheoryofelectromagneticbrainactivity. Physical
ReviewLetter, 77, 960–963.
Koch,C.(1999). Biophysicsofcomputation:Informationprocessinginsingleneurons. New
York: Oxford University Press.
Landau, L. P., & Lifshitz, E. M. (1976).Classical mechanics(3rd ed.). Amsterdam: El-
sevier.
MacDonald, D. K. C. (2006).Noiseandfluctuations . Mineola, NY: Dover.
Markov, N. T., & Kennedy, H. (2013). The importance of being hierarchical.Current
OpinioninNeurobiology ,23, 187–194.
Markov, N. T., Vezoli, J., Chameau, P., Falchier, A., Quilodran, R., Huissoud, C., . . .
Kennedy,H.(2014).Anatomyofhierarchy:Feedforwardandfeedbackpathways
in macaque visual cortex.JournalofComparativeNeurology , 522, 225–259.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025

Recognition Dynamics in the Brain under the Free Energy Principle 2659
Martin, S. J., Grimwood, P. D., & Morris, R. G. M. (2000). Synaptic plasticity and
memory:Anevaluationofthehypothesis. AnnualReviewofNeuroscience ,23,649–
711.
Maturana,H.,&Varela,F.(1980). Autopoiesisandcognition:Therealizationoftheliving.
Boston: Reidel.
Michalareas, G., Vezoli, J., van Pelt, S., Schoffelen, J.-M., & Kennedy, H. (2016).
Alpha-beta and gamma rhythms subserve feedback and feedforward influences
among human visual cortical areas.Neuron,89, 384–397.
Okun, M., & Lampl, I. (2008). Instantaneous correlation of excitation and inhibition
during ongoing and sensory-evoked activities.NatureNeuroscience,11, 535–537.
Potjans,T.C.,&Diesmann,M.(2014).Thecell-typespecificcorticalmicrocircuit:Re-
latingstructureandactivityinafull-scalespikingnetworkmodel. CerebralCortex,
24(3), 785–806.
Ramstead, M. J. D., Badcock, P. B., & Friston, K. J. (2017). Answering Schödinger’s
question: Afree-energy formulation.PhysicsofLifeReviews , 24, 1–16.
Rao, R. P. N., & Ballard, D. H. (1999). Predictive coding in the visual cortex: Afunc-
tional interpretation of some extra-classical receptive-field effects.NatureNeuro-
science, 2(1), 79–87.
Robinson,P.A.,Rennie,C.J.,&Wright,J.J.(1997).Propagationandstabilityofwaves
of electrical activity in the cerebral cortex.PhysicalReviewE , 56, 826–840.
Schot, S. H. (1978). Jerk: The time rate of change of acceleration.AmericanJournal of
Physics, 46, 1090–1094.
Schrödinger,E.(1967). Whatislife?Mindandmatter. Cambridge:CambridgeUniver-
sity Press.
Seifert, U. (2005). Entropy production along a stochastic trajectory and an integral
fluctuation theorem.PhysicalReviewLetters , 95, 040602.
Sengupta,B,Tozzi,A.,Cooray,G.K.,Douglas,P.K.,&Friston,K.J.(2016).Towards
a neuronal gauge theory.PLoSBiology,14(3), e1002400.
Shannon,C.E.(1948).Amathematicaltheoryofcommunication. BellSystemTechnical
Journal, 27, 379–423, 623–656.
Steyn-Ross, M. L., & Steyn-Ross, D. A. (2016). From individual spiking neurons to
populationbehavior:Systematiceliminationofshort-wavelengthspatialmodels.
PhysicalReviewE93 , 022402.
Summerfield, C., & Egner, T. (2009). Expectation (and attention) in visual cognition.
TrendsinCognitiveSciences ,13(9), 403–409.
Visser, M. (2004). Jerk, snap and the cosmological equation of state.Classical and
QuantumGravity, 21, 2603–2615.
von Helmholtz, H. (1962).Treatiseonphysiologicaloptics. Mineola, NY: Dover.
Wilson, H. R. (1999). Simplified dynamics of human and mammalian neocortical
neurons.JournalofTheoreticalBiology ,200, 375–388.
Received January 21, 2018; accepted May 9, 2018.
Downloaded from http://direct.mit.edu/neco/article-pdf/30/10/2616/2015054/neco_a_01115.pdf by guest on 13 December 2025
