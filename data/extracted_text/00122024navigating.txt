 1 
Abstractâ€” This paper presents a novel approach to improving 
autonomous vehicle control in environments lacking clear road 
markings by integrating a diffusion -based motion predictor within 
an Active Inference Framework (AIF). Using a simulated parking 
lot environment as a parallel to unmarked roads, we develop and 
test our model to predict and guide vehicle movements effectively. 
The diffusion -based motion predictor forecasts vehicle actions by 
leveraging probabilistic dynamics, while AIF aids in decision -
making under uncertainty. Unlike traditional methods such as 
Model Predictive Con trol (MPC) and Reinforcement Learning 
(RL), our approach reduces computational demands and requires 
less extensive training, enhancing navigation safety and efficiency. 
Our results demonstrate the model's capability to navigate 
complex scenarios, marking s ignificant progress in autonomous 
driving technology . 
 
Index Terms â€” Diffusion-Based Motion Prediction , Active 
Inference Framework (AIF) , Autonomous Control Systems  
  
I. INTRODUCTION 
n tackling the challenge of autonomous navigation  under 
uncertain  and opposing circumstances, our research adopts a 
novel approach by utilizing new advances in Generative AI, 
namely Probabilistic Diffusion (PD), and Active Inference 
(AIF). PD reverse engineers a motion predictor and AIF safel y 
guides vehicles to their intended destinations. We conjecture 
that the proposed approach can be generically applied to many 
engineering applications involving predictions and control . In 
this article, however, we demonstrate the main ideas for vehi cl e 
navigation in a parking lot setting, where vehicles are expected 
to park at some designated spots. Lacking clear navigati onal 
cues and  given random interactions between vehicles, parki ng 
lots can serve as a building block for mirroring some of  the 
complexities of autonomous navigation in more compl ex 
settings, such as unmarked roadways. We propose basic i deas 
for extending our parking lot model to the unmarked roadway 
scenario s but leave the details to a future  manuscript. Our 
approach is pioneering, particularly in the utilization of PD for 
its novel application in the realm of autonomous navigati on, 
beyond its traditional use in image processing where it excel s 
in generative AI tasks and reverse engineering complex systems 
[1]. Notably, this research marks one of the first instances of 
PD being adapted for reverse engineering  applications, a 
testament to its versatility and robust generative capabilities [2]. 
Similarly, AIF is employed not just as a control strategy but as 
a cognitive model that mimics the Predictive Mind, enhanci ng 
 
Y. Huang, Y. Li, and M. Jafari are with the Department of Industrial and  
Systems Engineering, Rutgers University â€“ New Brunswick, Piscataway, NJ 
08854, USA (e-mails: yh639@scarletmail.rutgers.edu; yl959@soe.rutgers.edu ; 
jafari@soe.rutgers.edu). 
decision-making under uncertainty through predicti ve 
reasoning [3]. 
Uncertainties, such as missing roadway markings and mi xed 
traffic , set a higher demand for a robust perception model i n 
autonomous navigation.  Human drivers utilize their inner 
predictive mind  [4] capability t o predict and minimi ze 
consequential errors by properly acting according to thei r 
perception of the roadway conditions. By anticipating and 
predictive reasoning, human drivers can handle poor road 
conditions and avoid random moving traffic and parked 
vehicles. 
Navigating through traffic safely and efficiently remai ns a 
paramount concern for autonomous navigation, especially i n 
environments where traditional road markings are not clear. 
This challenge becomes even more pronounced in mixed fl ow 
traffic environments, where autonomous vehicles must coexi st 
with human -driven vehicles, all navigating without the 
guidan ce of clear lane markings. Traditional navigation systems, 
which rely heavily on well-defined road infrastructures, often 
fall short under these conditions. The problem at hand focuses 
on enabling autonomous vehicles to find safe and efficient paths 
to their destinations in such unmarked road segments, hence, an 
ability to adapt to less structured environments.  
Our approach sets itself apart from traditional methods such 
as Model Predictive Control (MPC) and Reinforcement 
Learning (RL), by leveraging the strengths of diffusion model s 
and the AIF. MPC relies heavily on precise vehicle model i ng 
and the resolution of complex optimization challenges. Unli ke 
RL, which necessitates extensive training, our model offers a 
direct, structured method for predicting vehicle trajectori es, 
incorporating safety considerations through its handling of 
predictive uncertainty. This unique combination of diffusi on 
models and AIF, with its ability to make informed decisi ons 
under uncertain conditions, positions our model as a pioneeri ng 
(the first of its kind) solution in the realm of autonomous 
navigation . 
This paper is structured as follows: Section II reviews rel ated 
works in the field; Section III details the methodology behi nd 
our diffusion -based motion predictor and the AIF controll er; 
Section IV presents the results from our simulation studies, and 
Section V concludes the paper with a discussion on the 
implications of our findings and directions for future research. 
II. RELATED WORKS 
A. Matta is with the Department of Mechanical Engineering of Politecnico 
di Milano  â€“ Via La Masa 1 20156, Milano, ITALY  (e-mail:  
andrea.matta@polimi.it). 
Navigating Uncertainties with Probabilistic Diffusion-
Based Motion Prediction and Active Inference  
Yufei Huang, Yulin Li, Andrea Matta and Mohsen Jafari 
I 
 2 
Navigating unmarked road environments poses uni que 
challenges for autonomous vehicles, as traditional cues used for 
lane following and distance keeping are not available. Model 
Predictive Control (MPC) has been extensively applied in 
autonomous vehicle nav igation due to its ability to handl e 
dynamic constraints and predict future vehicle states [5]. For 
instance, [6] demonstrated MPC's efficacy in lane-keepi ng and 
obstacle avoidance by incorporating real-time traffic data i nto 
the control strategy. However, MPC's performance heavi l y 
relies on the accuracy of the vehicle model and the 
computational complexity of solving optimization problems i n 
real-time [7]. In scenarios with undefined road markings, the 
absence of structured environmental data can limit MPC's 
predictive accuracy, making it less adaptable to unforeseen 
changes in traffic flow or road conditions.  Recent studi es 
primarily focus on the development of robust machine learni ng 
models that can interpret complex environments where 
traditional sensor -based systems falter. Reinforcement 
Learning (RL) has been praised for its adaptability and abil i ty 
to improve over time, as highlighted by [8], who successful l y 
applied deep reinforcement learning for trajectory planning i n 
automated parking systems. But RL requires extensive traini ng 
data and significant computational resources , especially in 
complex and dynamic environments.  
Diffusion models have been predominantly utilized in image 
processing and generation fields, as detailed by  [9]. Our work 
extends the application of diffusion models to the domai n of 
reverse engineering; The diffusion model is used as a generati ve 
model for next state prediction in AIF. AIF integrates 
perception, action, and cognition into a cohesive framework, 
emphasizing the role of uncertainty and the agent's internal 
model in guiding its behavior. The AIF has been used in 
robotics and cognitive science to model decision -maki ng 
processes under uncertainty  [10]. Unlike Reinforcement 
Learning, which aims to maximize a numerical reward signal 
through actions, AIF takes actions as a means to minimi ze the 
expected free energy. This fundamental difference shifts the 
focus from seeking rewards to reducing uncertainty and 
achieving a state of least surprise  [11]. In RL, decisions are 
driven by the potential for reward maximization, often defi ned 
in terms of explicit rewards linked to specific outcomes. 
However, AIF embeds a preference-based approach where no 
explicit reward signal is necessary; instead, it operates under a 
model where rewards are integrated as preferences over sensory 
states , known as free energy. By minimizing free energy, AIF 
inherently balances exploration and exploitation [12], adapti ng 
its strategy based on both current understanding and new 
observations. This holistic approach allows agents to not onl y 
respond to their environment but also anticipate changes, 
making decisions that are informed by both past experi ences 
and pot ential future states.  
While AIF's application to autonomous vehicles is nascent, 
preliminary studies, such as those by [13] [14], indicate its 
promise for enhancing adaptive decision -making in dynami c 
environments. Our research contributes to this emerging fi el d 
by integrating AIF with a diffusion-based motion predictor for 
improved navigation in mixed flow traffic environments. Whi l e 
existing literature provides a foundation for autonomous 
vehicle navigation, there is a distinct lack of research focused 
on mixed flow environments with unclear or no road markings. 
Furthermore, the potential of diffusion models and AIF in thi s 
context has not been fully explored, underscoring the novel ty 
and significance of our approach.  
III. VEHICLE CONTROL IN UNMARKED PARKING AREAS 
The goal of the control framework is to replicate a road 
segment devoid of lane markings. To mimic the scenario, we 
break down the control system to aid vehicle navigati on i n a 
simulated parking lot environment, where vehicles need to 
drive in unmarked cor ridors and avoid collision with other 
parked and moving vehicles. The explanation is split into three 
main parts. To begin with, we elaborate on the transformati on 
of a conventional road structure into a parking lot configurati on. 
This step is crucial in s imulating a scenario where vehicles, 
starting from random positions, velocities, and directions, need 
to navigate towards their designated parking spots. Thi s 
scenario represents a transition from a state of chaos to one of 
order, which requires skillful maneuvering by the vehicl es to 
avoid stationary and mobile obstacles. Next, we introduce an 
innovative diffusion-based motion predictor. This predictor i s 
engineered to calculate the probability distribution of a vehicl e's 
imminent actions that will lead to  its successful parking. The 
model is developed using diffusion model methodologi es, 
which include a forward training process and a reverse 
application process. This dual-phase approach ensures a robust 
predictive framework capable of accurately forecasti n g 
vehicular movement within the parking lot. Lastly, we eluci date 
the application of the diffusion model within an active inference 
framework. Here, the diffusion model's generative capabiliti es 
are used to help vehicles choose the most optimal acti on at each 
junction based on the principle of expected free energy. 
Additionally, the model is continuously refined via variati onal 
free energy adjustments, enhancing navigational effi cacy. 
Finally, the detailed workflow of the diffusion -based acti ve 
inference fr amework for autonomous vehicle navigation is 
illustrated. 
A. Adapting Parking Lot Dynamics to Simulate Unmarked 
Road Navigation  
Within the context of  autonomous navigation each vehi cl e 
must not only determine a path that avoids collisions but al so 
progress toward its destination amongst a dynami c and 
unpredictable setting. To tackle this, the concept of 
discretization becomes valuable. If we imagine breaking down 
the continuo us road into smaller, manageable pieces, aki n to 
segments on a game board, the problem becomes less daunti ng. 
As is shown in Fig.1 (a) and (b), within each of these discrete 
segments, the vehicle's immediate task is to determine a safe 
and viable route to the edge of the segment. This step-by-step 
approach, where the road is segmented into pieces, lays the 
groundwork for drawing parallels with a parking lot scenari o. 
In a parking lot, vehicles navigate through aisles to reach a 
specific parking spot without the guidance of painted lines. 
Each aisle can be thought of as a segment of the road. The 
 3 
vehicles must maneuver with care, negotiating their way around 
other cars and obstacles, all while making progress toward thei r 
allocated parking space. Both scenarios share fundamental 
similarities: they require the vehicles to create order from 
disorder, forming structured outcomesâ€”whether it be a neatl y 
parked car or a vehicle successfully reaching the end of a road 
segment â€”out of initially unstructured situations.  
 
B. Path prediction: the diffusion -based motion predict or 
 
The stable probabilistic diffusion [15] for image processi ng 
commonly contains two phases as is shown in Fig.3. The 
forward process begins with an original image, labeled as ğ‘‹0, 
that is fully observable. Through a sequence of transformati ons, 
random perturbation (noise) is incrementally introduced to thi s 
image, leading to a progression of states where the original 
image becomes less recognizable, reaching a point of maxi mum 
randomness at ğ‘‹ğ‘‡. Denote ğ›½ğ‘¡ as the variance of the Gaussi an 
noise to be added at timestep ğ‘¡, which is increasing over ti me, 
and the mean is defined as a scaled version of the previous state 
ğ‘¥ğ‘¡âˆ’1, which is âˆš1âˆ’ğ›½ğ‘¡ğ‘¥ğ‘¡âˆ’1. The probability distribution of the 
image at time ğ‘¡ can be represented as:  
 ğ‘(ğ‘¥ğ‘¡|ğ‘¥ğ‘¡âˆ’1)=ğ’©(ğ‘¥ğ‘¡;âˆš1âˆ’ğ›½ğ‘¡ğ‘¥ğ‘¡âˆ’1,ğ›½ğ‘¡ğ‘°) (1) 
In the subsequent reverse phase, the process methodi cal l y 
retracts the randomness, incrementally reinstating structure and 
clarity. While the graph concludes with an image that is 
partially clarified at ğ‘‹ğ‘¡âˆ’1, the aim is to recover a clear i mage, 
closely resembling the initial state ğ‘‹0 . This process 
demonstrates the potential to reconstruct the original image 
from a state of maximal entropy through a systematic removal 
of the introduced noises. In practice, a neural network can be 
introduced to learn the probability distribution to iterativel y 
denoise the image during the generative phase, with ğœ‘ 
representing the learned parameters of the model. The model 
for the reverse process can be represented as:  
 ğ‘ğœ‘(ğ‘¥ğ‘¡âˆ’1|ğ‘¥ğ‘¡)=ğ’©(ğ‘¥ğ‘¡âˆ’1;ğœ‡ğœ‘(ğ‘¥ğ‘¡,ğ‘¡),ğœğœ‘
2(ğ‘¥ğ‘¡,ğ‘¡)ğ‘°) (2) 
Drawing on this established framework, the development of 
the motion diffusion predictor adapts these principles to the 
realm of vehicular movement. Instead of transitioning between 
visual pixels, the motion diffusion predictor applies a simil ar 
iterative process to the kinematic variables of a vehicle duri ng 
navigation.  
a. Forward process of the diffusion-based motion predictor 
In contrast to the image generation approach, where clarity i s 
progressively diminished by overlaying Gaussian noise, the 
motion diffusion predictor simulates the real-world conditi ons 
that a vehicle starts from its parking spot, note the state as ğ‘†0, 
and take random actions to drive away from the initial positi on 
The final state ğ‘†ğ‘‡ is determined when a collision happens, 
whether the vehicle hit the boundary of the parking area, or a 
collision happen with other vehicles.  
 
 
Illustrated in Fig.3 (a), the path of two actively movi ng 
vehicles is traced (indicated in green). Initially positioned i n 
designated spots alongside four stationary vehicles, these two 
green vehicles perform random throttle and steering 
adjustments. Meanwhile, the yellow and  red vehicles remai n 
stationary. The depicted sequence concludes with one green 
vehicle making contact with the red vehicle. Fig.3 (b) provi des 
an alternative depiction, where the roles are assumed by two 
yellow stationary cars and two green mobile cars. The green 
cars persist in random movements until an eventual collisi on 
with the parking area's boundary, represented by a red wall. 
This forward process effectively emulates the journey from a 
state of complete organization to one of disorder, analogous to 
the method by which noise is added in image processing.  
Assuming that every aspect of the setting is visibl e and 
trackable, the model processes time in fixed, uniform segments. 
Within these segments, the system monitors all vehicles' 
conditions. Each vehicle's condition is characterized by its 
location, marked by coordinates (ğ‘¥,ğ‘¦), its speed in the directi on 
of both coordinates (ğ‘£ğ‘¥,ğ‘£ğ‘¦), and the direction it's facing, noted 
as â„. The state of each vehicle at a certain timestamp ğ‘¡ can be 
represented as a vector of 5 elements ğ‘†ğ‘¡=
[ğ‘¥ğ‘¡ ğ‘¦ğ‘¡ ğ‘£ğ‘¥
ğ‘¡ ğ‘£ğ‘¦
ğ‘¡ ğ‘¡ğ‘¡]. To aid in navigation, two extra pi eces 
of information are provided for each vehicle at time ğ‘¡: ğœƒğ‘¡ shows 
 
Fig.1 (a) - Road segment for the controlled green car at timestep ğ‘› 
    
 Fig. 1 (b) - Road segment for the controlled green car at timestep ğ‘›+1. 
  
 
Fig. 2.  Diffusion process for image generation. 
  
  
(a) (b) 
Fig. 3.  Forward process for automated parking. 
 

 4 
the direction to the vehicle's starting parking spot, and  ğ‘™ğ‘¡ 
measures how far the vehicle is from this spot.  
During each discrete interval of time in the simulation, the 
vehicles under control undergo random changes in speed and 
direction. This is analogous to how, in the image diffusi on 
process, the amount of Gaussian noise is increased over ti me to 
gradually obscure the image. In a similar vein, the range withi n 
which these random driving decisions are made becomes wi der 
as time progresses. The sequence of random driving decisi ons 
made throughout this process is represented by ğ‘1,â‹¯,ğ‘ğ‘‡âˆ’1. 
Each action ğ‘ğ‘–, where ğ‘– ranges from 1 to ğ‘‡âˆ’1, is drawn from 
a Gaussian distribution that is truncated. To avoid dramati c 
movement change, the previous action is the mean of the 
current action, the actions are chosen based on the previ ous 
action ğ‘ğ‘–âˆ’1  but with added variability defined by ğœğ‘–
2 . 
Mathematically, this is written as:  
 ğ‘ğ‘–~ğ’©(ğ‘ğ‘–âˆ’1,ğœğ‘–
2ğœ¤) (3) 
 ğ‘ğ‘–=ğ‘ğ‘™ğ‘–ğ‘(ğ‘ğ‘–, ğ‘™ğ‘, ğ‘¢ğ‘) (4) 
The clip function applied here ensures that each action ğ‘ğ‘– 
stays within a specific range, denoted by the lower and upper 
bounds (ğ‘™ğ‘ and ğ‘¢ğ‘). This range reflects the real-world physi cal 
constraints on how much a vehicle can accelerate or decel erate 
(throttle) and turn (steering) at any given moment.  
To manage the growing variability in the actions over ti me, 
a straightforward method increases ğœğ‘– linearly from a starti ng 
low point to a peak. This increment allows the range of potenti al 
actions to widen as the simulation progresses, facilitati ng a 
gradual intensification of action diversity. The formula to 
calculate ğœğ‘– reflects this linear growth, ensuring that with each 
step from the first to the last, the variance expands smoothl y 
from its minimum to its maximum value:  
 ğœğ‘– =ğœğ‘šğ‘–ğ‘›+(ğœğ‘šğ‘ğ‘¥âˆ’ğœğ‘šğ‘–ğ‘›)Ã— ğ‘–
ğ‘‡âˆ’1 (5) 
In Equation (5), ğœğ‘šğ‘–ğ‘›  and ğœğ‘šğ‘ğ‘¥  define the bounds of 
variance, while ğ‘– represents the current step, and ğ‘‡âˆ’1 
signifies the total number of steps. This approach guarantees a 
controlled and predictable escalation in action variabili ty, 
mirroring the real-world scenario where decision-making mi ght 
become increasingly bold or cautious as conditions evolve.  
 
b. Reverse process of the diffusion-based motion predictor 
In the reverse process, akin to the denoising steps i n 
traditional diffusion models, a vehicle starts at random positi ons 
inside the parking area with an initial speed and direction. The 
motion diffusion predictor employs learned parameters to infer 
the mo st probable previous action distribution of a vehicle - 
essentially 'denoising' the vehicleâ€™s trajectory to yiel d a 
predicted path back to its parking state. The predictor is trai ned 
on reversed state -action sequences:  
 ğ‘†ğ‘¡
â€²ğ‘ğ‘¡âˆ’1â€²
â†’  ğ‘†ğ‘¡âˆ’1
â€² ğ‘ğ‘¡âˆ’2â€²
â†’  â‹¯
ğ‘1â€²
â†’ğ‘†1
â€²ğ‘0â€²
â†’ğ‘†0
â€² (6) 
where ğ‘†ğ‘¡
â€² is the reverse of ğ‘†ğ‘¡ defined as:  
 ğ‘†ğ‘¡
â€²=[ğ‘¥ğ‘¡ ğ‘¦ğ‘¡ âˆ’ğ‘£ğ‘¡
ğ‘¥ âˆ’ğ‘£ğ‘¡
ğ‘¦ ğœ‹âˆ’â„ğ‘¡] (7) 
Due to the dynamics of a vehicle's axles, the sequence of 
actions taken during the forward phase may differ from those i n 
the reverse phase, implying that the reversed action ğ‘ğ‘¡
â€² â‰ ğ‘ğ‘¡. In 
the reverse process, the goal is to uncover the range of possi bl e 
actions that would logically return the vehicle to its prior state 
ğ‘†ğ‘¡âˆ’1
â€²  based on the current state and navigational aids ğœƒğ‘¡ and ğ‘™ğ‘¡. 
The aim here is mathematically modeled by seeking a 
distribution for actions that reconcile with the earlier state, 
given the existing conditions and guidance parameters. Thi s 
approach endeavors to map out a backward trajectory, 
identifying actions that could have preceded the current 
vehicular state, hence facilitating a methodical backtracki ng to 
the initial position. The objective function, Kullback-Leibl er 
(KL) Divergence [16], quantifies how one probabil i ty 
distribution diverges from a second, expected probabil i ty 
distribution. In this context, minimizing KL divergence hel ps i n 
adjusting the parameters of the predictive model ğ‘„ so that i t 
closely approximates the true distribution ğ‘ƒ, leading to more 
accurate predictions of the previous actions based on the gi ven 
state and guidance features.  
 min
ğ‘ğ‘¡âˆ’1â€² KL(ğ‘ƒ(ğ‘ğ‘¡âˆ’1
â€² |ğ‘†ğ‘¡
â€²,ğœƒğ‘¡
â€²,ğ‘™ğ‘¡
â€²)||ğ‘„(ğ‘ğ‘¡âˆ’1
â€² |ğ‘†ğ‘¡
â€²,ğœƒğ‘¡
â€²,ğ‘™ğ‘¡
â€²)) (8) 
To effectively reduce the difference between what our model 
predicts and what actually happens, the goal is to closel y match 
the state that our model predicts for the next step in the reverse 
process,  ğ‘†ğ‘¡âˆ’1
â€²  (which corresponds to the state just before the 
current state ğ‘†ğ‘¡
â€² in the forward process), with the actual previ ous 
state from the forward process. By doing so, we aim to refi ne 
our model's ability to accurately forecast the results of its 
suggested actions, ensuring the transitions it predicts align wel l 
with real-world transitions.  
 
Given the current state ğ‘†ğ‘¡
â€² and predicted action ğ‘ğ‘¡âˆ’1
â€² , the next 
state ğ‘†ğ‘¡âˆ’1
â€²  can be estimated using the kinematic bicycl e model 
[17] as shown in Fig.4. Define the vehicleâ€™s position as (ğ‘¥,ğ‘¦), 
vehicleâ€™s forward speed as ğ‘£, vehicle's heading as ğœ“, the 
vehicle's acceleration as ğ‘, vehicle's slip angle at the center of 
gravity ğ›½, and ğ›¿ as the front wheel angle used as a steering 
command. The traditional bicycle model does not account for 
uncertainties in state transitions that occur due to factors such 
as slippery roads and tires . To address this, the model is 
enhanced by incorporating stochastic elements into its dynami c 
equations. Specifically, noise terms are introduced, assumed to 
follow a normal distribution, ğœ–~ğ’©(0,Î£), where Î£ represents a 
diagonal covariance matrix. The variances  ğœğ‘¥
2, ğœğ‘¦
2, ğœğ‘£ğ‘¥
2 , ğœğ‘£ğ‘¦
2 , 
and ğœğ›¿
2 correspond to the respective state variables in ğ‘†ğ‘¡
â€². These 
modifications enable the model to generate the next state by 
integrating the impact of environmental and vehicul ar 
variabilities more realistically.  The extended dynami c 
equation s to get the next state can be written as : 
 ğ‘¥ğ‘¡+1=ğ‘¥ğ‘¡+ğ‘£ğ‘¥ğ‘¡ âˆ™ğ‘ğ‘œğ‘ (ğ›¿ğ‘¡+ğ›½ğ‘¡)âˆ™âˆ†ğ‘¡+ğœ–ğ‘¥ (9) 
 ğ‘¦ğ‘¡+1=ğ‘¦ğ‘¡ +ğ‘£ğ‘¦ğ‘¡ âˆ™ğ‘ ğ‘–ğ‘›(ğ›¿ğ‘¡+ğ›½ğ‘¡)âˆ™âˆ†ğ‘¡+ğœ–ğ‘¦ (10) 
 ğ›¿ğ‘¡+1=ğ›¿ğ‘¡+ğ‘£ğ‘¡ âˆ™ğ‘ ğ‘–ğ‘›â¡(ğ›½ğ‘¡)
ğ¿/2 âˆ™âˆ†ğ‘¡+ğœ–ğ›¿ (11) 
 
Fig. 4.  Kinematic bicycle model. 
  

 5 
 ğ‘£ğ‘¡+1
ğ‘¥ =ğ‘£ğ‘¡ âˆ™ğ‘ğ‘œğ‘ (ğ›¿ğ‘¡+1)+ğœ–ğ‘£ğ‘¥ (12) 
 ğ‘£ğ‘¡+1
ğ‘¦ =ğ‘£ğ‘¡ âˆ™ğ‘ ğ‘–ğ‘›(ğ›¿ğ‘¡+1)+ğœ–ğ‘£ğ‘¦ (13) 
where âˆ†ğ‘¡ is the time step, ğ¿ is the length of the vehicle, ğ›½ğ‘¡ =
arctanâ¡(
1
2âˆ™tanâ¡(ğ›¿ğ‘¡)) is the steering angle at the mass center, 
ğ‘£ğ‘¡ =âˆšğ‘£ğ‘¥ğ‘¡2 +ğ‘£ğ‘¦ğ‘¡2  is the speed of the vehicle.  ğœ–ğ‘¥, ğœ–ğ‘¦, ğœ–ğ‘£ğ‘¥, ğœ–ğ‘£ğ‘¦, 
and ğœ–ğ›¿ represents the noise on each state variable . 
In the context of autonomous vehicle navigation using 
probabilistic methods, the application of Probabilistic Diffusi on 
(PD) through score matching [18] offers an innovati ve way to 
handle the inherent randomness in vehicle dynamics. Thi s 
approach utilizes a stochastic differential equation framework 
to model the dynamics of vehicle states, which is particul arl y 
useful in environments where precise control and prediction of 
vehicle behavior are critical due to unpredictable road 
conditions. The probabilistic state transition dynamics of a 
vehicle, represented by the bicycle model ğ‘†ğ‘¡=ğ¹(ğ‘†ğ‘¡âˆ’1,ğ´ğ‘¡âˆ’1) 
 ğ‘†(ğ‘¡+âˆ†ğ‘¡)â‰…ğ‘†ğ‘¡+ğ‘“(ğ‘†ğ‘¡,ğ´ğ‘¡)âˆ™ğ‘‘ğ‘¡+ğœ(ğ´(ğ‘¡),ğ‘¡)
âˆ™âˆšâˆ†ğ‘¡ğ’©(ğ´ğ‘¡âˆ’1,ğœğ‘¡
2ğ¼,ğ‘™ğ‘,ğ‘¢ğ‘) 
(14) 
 ğ‘‘ğ‘†ğ‘¡=ğ‘“(ğ‘†ğ‘¡,ğ´ğ‘¡)âˆ™ğ‘‘ğ‘¡+ğ‘”(ğ´ğ‘¡,ğ‘¡)ğ‘‘ğœ”Ì‚ğ‘¡ (15) 
Here, ğ‘“(ğ‘†ğ‘¡,ğ´ğ‘¡) denotes the deterministic evolution of the 
state, reflecting predictable changes based on the current state 
ğ‘†ğ‘¡, action ğ´ğ‘¡, and the bicycle model ğ‘“(âˆ™). The functi on ğ‘”(ğ´ğ‘¡,ğ‘¡) 
represents the diffusion term, introducing randomness into the 
process to account for environmental uncertainties and the 
inherent variability in vehicle responses. The term ğ‘‘ğœ”Ì‚ğ‘¡ denotes 
the increment of a Wiener process, encapsulating the random 
fluctuations that affect the vehicle's trajectory. To address the 
challenge of modeling the reverse process, where one ai ms to 
infer past states from current observations, a score matchi ng 
technique is integrated into the dynamics:  
 ğ‘‘ğ‘†ğ‘¡
=[ğ‘“(ğ‘†ğ‘¡,ğ´ğ‘¡)âˆ’ğ‘”(ğ´ğ‘¡,ğ‘¡)2ğ›»ğ‘†ğ‘¡ğ‘™ğ‘œğ‘”ğ‘ğ‘¡(ğ‘†ğ‘¡|ğ‘†0)]ğ‘‘ğ‘¡
+ğ‘”(ğ´ğ‘¡,ğ‘¡)ğ‘‘ğœ”Ì‚ğ‘¡ 
(16) 
In this setup, ğ´ğ‘¡ adheres to a truncated Gaussian distributi on, 
ğ´ğ‘¡~ğ’©(ğ´ğ‘¡âˆ’1,ğœğ‘¡
2ğ¼,ğ‘™ğ‘,ğ‘¢ğ‘), ensuring that the actions remai n 
within plausible limits defined by physical and operati onal 
constraints of the vehicle. The term ğ›»ğ‘†ğ‘¡ğ‘™ğ‘œğ‘”ğ‘ğ‘¡(ğ‘†ğ‘¡|ğ‘†0) 
represents the score function, crucial for the score matchi ng 
approach. This gradient, which needs to be estimated vi a a 
neural network ğ‘ ğœ‘(ğ‘¥ğ‘¡,ğ‘¡), guides the correction of the forward 
model by quantifying how the probability density function of 
the state transitions should be adjusted to better fit the observed 
data.  
This refined modeling through score matching not onl y 
enhances the accuracy of state prediction in backward ti me but 
also improves the robustness and adaptability of the navigati on 
system under diverse and challenging driving conditions. The 
objective func tion can be written as:  
ğ‘šğ‘–ğ‘›
ğœƒ
ğ”¼ğ‘¡~ ğ“Š(0,ğ‘‡)ğ”¼ğ‘¥0~ğ‘0(ğ‘¥0)ğ”¼ğ´ğ‘¡~ğ’©(ğ´ğ‘¡âˆ’1,ğœğ‘¡2ğ¼,ğ‘™ğ‘,ğ‘¢ğ‘) â€–ğ‘ ğœ‘(ğ‘¥ğ‘¡,ğ‘¡)
âˆ’ğ›»ğ‘†ğ‘¡ğ‘™ğ‘œğ‘”ğ‘ğ‘¡(ğ‘†ğ‘¡)â€–2
2
 
(17) 
where 
 ğ‘†ğ‘¡=ğ›¾ğ‘¡ğ‘†0+ğœğ‘¡ğ‘¨ (18) 
Since ğ´ğ‘¡ follows truncated normal distribution, the followi ng 
equation holds when ğ´ğ‘¡ is within the boundaries:  
 ğ›»ğ‘†ğ‘¡logğ‘ğ‘¡(ğ‘†ğ‘¡|ğ‘†0)=âˆ’ğ›»ğ‘†ğ‘¡
(ğ‘†ğ‘¡âˆ’ğ›¾ğ‘¡ğ‘†0)2
2ğœğ‘¡2
=âˆ’ğ‘†ğ‘¡âˆ’ğ›¾ğ‘¡ğ‘†0
ğœğ‘¡2
=âˆ’ğ›¾ğ‘¡ğ‘†0+ğœğ‘¡ğ‘¨ âˆ’ğ›¾ğ‘¡ğ‘†0
ğœğ‘¡2
=âˆ’ğ‘¨
ğœğ‘¡
 
(19) 
Therefore  
 ğ‘ ğœ‘(ğ‘¥ğ‘¡,ğ‘¡)â‰”âˆ’ğ´ğœƒ(ğ‘¥ğ‘¡,ğ‘¡),
ğœğ‘¡
 (20) 
For the timestep ğ‘¡ approaching a large number, we can use 
the reparameterization trick because ğ‘ ğœ‘(ğ‘¥ğ‘¡,ğ‘¡) would al so 
follow Gaussian distribution based on the central limit theory. 
The objective of estimating the score function can be simplifi ed 
as: 
ğ‘šğ‘–ğ‘›
ğœƒ
ğ”¼ğ‘¡~ ğ“Š(0,ğ‘‡)ğ”¼ğ‘¥0~ğ‘0(ğ‘¥0)ğ”¼ğ´ğ‘¡~ğ’©(ğ´ğ‘¡âˆ’1,ğœğ‘¡2ğ¼,ğ‘™ğ‘,ğ‘¢ğ‘) â€–ğ´ğ‘¡
âˆ’ğ´ğœ‘(ğ‘¥ğ‘¡,ğ‘¡)â€–2
2
 
(21) 
However, the total timestep in the proposed forward process 
would have a limited length and the reparameterization trick i s 
not applicable. In this case, a rolling back method is introduced 
to learn ğ›»ğ‘†ğ‘¡logğ‘ğ‘¡(ğ‘†ğ‘¡|ğ‘†ğ‘¡+ğ‘‘ğ‘¡). 
As illustrated in Fig. 5, the process demonstrates how a 
specific segment of state-action transitions from ğ‘†ğ‘¡âˆ’1
ğ‘ğ‘¡âˆ’1
â†’  ğ‘†ğ‘¡  i n 
the forward phase is mirrored. In this reversal, the current state 
ğ‘†ğ‘¡ becomes ğ‘†ğ‘¡
â€², following the method outlined in Equation (7). 
A neural network model then predicts the probabil i ty 
ğ‘ƒ(ğ‘ğ‘¡âˆ’1
â€² |ğ‘†ğ‘¡
â€²,ğœƒğ‘¡
â€²,ğ‘™ğ‘¡
â€²) using the reversed state ğ‘†ğ‘¡
â€² in stage â‘  as is 
illustrated in Fig. 5 . By employing the mean and vari ance 
derived from ğ‘ƒ(ğ‘ğ‘¡âˆ’1
â€² |ğ‘†ğ‘¡
â€²,ğœƒğ‘¡
â€²,ğ‘™ğ‘¡
â€²), a reparametrized action ğ‘§ğ‘¡âˆ’1
â€²  i s 
selected. Subsequently, a physical model, referred to as the 
bicycle model, is used to estimate the preceding state ğ‘†ğ‘¡âˆ’1
â€²  from 
ğ‘†ğ‘¡
â€² and ğ‘§ğ‘¡âˆ’1
â€²  in stage â‘¡ as is shown in Fig. 5. The discrepancy 
between this estimated state ğ‘†ğ‘¡âˆ’1
â€²  and the actual prior state, once 
reversed to ğ‘†ğ‘¡âˆ’1, is quantified using the mean squared error 
(MSE). This rollback technique is pivotal in ensuring that the 
actions predicted by the model effectively guide the vehicl e 
closer to its initial parking spot, thereby reversing its trajectory 
in a manner that approximates the original state transitions.  
 
This neural network model architecture, rooted in the 
principles of physics, utilizes a physics-informed variati onal 
autoencoder (VAE) approach to carry out two key stages of 
prediction, as is shown in Fig. 6. At its core, the model inputs 
 
Fig. 5.  Rolling back process. 
  

 6 
the current reversed state ğ‘†ğ‘¡
â€². The initial phase invol ves an 
encoder, structured as a fully connected neural network, whi ch 
predicts the likelihood of the previous action, ğ‘ğ‘¡âˆ’1
â€²  based on ğ‘†ğ‘¡
â€². 
This previous action is modeled to follow a Gaussi an 
distribution, with the neural network providing the mean 
ğœ‡ğ‘ğ‘¡âˆ’1â€² |ğ‘¥ğ‘¡ and variance ğœğ‘ğ‘¡âˆ’1â€² |ğ‘¥ğ‘¡
2  as outputs. Next, an action ğ‘§ğ‘¡âˆ’1
â€²  
is chosen using a technique known as reparameterization, whi ch 
aids in drawing a sample from the predicted distribution. The 
next part of the model, which acts as a decoder, incorporates a 
physics-based framework to estimate the earlier state, ğ‘†ğ‘¡âˆ’1
â€² . 
informed by the chosen action ğ‘§ğ‘¡âˆ’1
â€²  and the current modifi ed 
state ğ‘†ğ‘¡
â€². The process culminates with a comparison between the 
estimated previous state ğ‘†ğ‘¡âˆ’1
â€²  and the actual previous state 
known from the data, referred to as ğ‘†ğ‘¡âˆ’1
âˆ—â€² . This final step verifi es 
the accuracy of the model's predictions, ensuring that the 
chosen actions are effectively guiding the vehicle back toward 
a state that aligns with the known trajectory leading up to the 
original parking position. 
 
The loss function designed for the physics-informed VAE i s 
threefold: Firstly, it accounts for the state prediction error, 
quantifying the difference between predicted states and true 
states. Secondly, it incorporates a regularization component for 
the variance ğœğ‘ğ‘¡âˆ’1â€² |ğ‘¥ğ‘¡
2 . This regularization ensures that the model 
does not overly concentrate on minimizing the prediction error 
linked to the mean ğœ‡ğ‘ğ‘¡âˆ’1â€² |ğ‘¥ğ‘¡, but also accurately gauges the level 
of uncertainty in the variance. The third term accounts for 
model uncertainty in predictions of the next state. It regul ates 
the variance of state transition noise ğœ–~ğ’©(0,Î£). The structure 
of this loss function is intended to maintain a balance between 
precise state estimation and a reliable measure of predicti on 
confidence.  
â„’=ğ‘€ğ‘†ğ¸(ğ‘†ğ‘¡âˆ’1
â€² ,ğ‘†ğ‘¡âˆ’1
âˆ—â€² )+ğœ†1ğ‘…ğ‘(ğœğ‘ğ‘¡âˆ’1â€² |ğ‘¥ğ‘¡
2 )+ğœ†2ğ‘…ğœ–(Î£) (22) 
where ğœ†1 and ğœ†2 serve as scaling factor s that dictate the 
relative weight of the regularization term and the noise term i n 
the overall loss function. By adjusting ğœ†1 and ğœ†2 , one can 
control how much emphasis is placed on the regularizati on 
aspect, which governs the precision of the uncertainty captured 
by ğ‘…ğ‘(ğœğ‘ğ‘¡âˆ’1â€² |ğ‘¥ğ‘¡
2 ) and ğ‘…ğœ–(Î£), compared to the emphasi s on 
minimizing the mean squared error (MSE) between the 
predicted state ğ‘†ğ‘¡âˆ’1
â€²  and the true previous state ğ‘†ğ‘¡âˆ’1
âˆ—â€² . The val ue 
of ğœ†1 and ğœ†2 are chosen to balance the trade -off between 
accuracy of state prediction and reliability of the model 's 
confidence in its predictions.  
The function ğ‘…ğ‘(ğœğ‘ğ‘¡âˆ’1â€² |ğ‘¥ğ‘¡
2 ) defined in Equation (23) is a 
regularization term designed to refine the model's estimate of 
action variance at each timestep. It is expressed as the negati ve 
average over all timesteps ğ‘‡ of the logarithm of the variance ğœğ‘– 
adjusted by a small constant ğœ– to maintain numerical stabili ty. 
Specifically, ğœ€ prevents the logarithm from diverging to 
negative infinity in cases where the variance ğœğ‘– approaches zero. 
 
ğ‘…ğ‘(ğœğ‘ğ‘¡âˆ’1â€² |ğ‘¥ğ‘¡
2 )=âˆ’1
ğ‘‡âˆ‘[ğ‘™ğ‘œğ‘”(ğœğ‘–+ğœ€)
ğ‘‡
ğ‘¡=1
+ğ‘™ğ‘œğ‘”(1âˆ’ğœğ‘–âˆ’ğœ€)] 
(23) 
This regularization term comprises two components: the l og 
of ğœğ‘– plus ğœ€, and the log of 1âˆ’ğœğ‘–âˆ’ğœ€, which together 
encourage the model not to be overly confident (by avoidi ng 
too small variance) or overly uncertain (by avoiding too large 
variance) about its action predictions. The balance achieved by 
this term is crucial for a model that needs to have a reasonabl e 
level of uncertainty to be robust yet confident enough to make 
accurate predictions.  The noise loss term ğ‘…ğœ–(Î£) defined i n 
Equation (24) measures how likely the true next state is, given 
the model's predictions, scaled by the model's own uncertai nty 
about its predictions (expressed through Î£). 
 ğ‘…ğœ–(Î£)=ğ‘€ğ‘†ğ¸(ğ‘†ğ‘¡âˆ’1
â€² ,ğ‘†ğ‘¡âˆ’1
âˆ—â€² )
2âˆ™Î£2  (24) 
The function is fundamentally derived from the log-
likelihood of a Gaussian distribution, which is a common 
approach in statistical modeling to handle errors or noise that 
follows a normal distribution. the log-likelihood of observi ng 
the next state ğ‘†ğ‘¡âˆ’1
â€²  from a Gaussian distribution with the mean 
(true next state) ğ‘†ğ‘¡âˆ’1
âˆ—â€²  and variance Î£2 is given by Equation (25): 
log(ğ‘(ğ‘†ğ‘¡âˆ’1
â€² |ğ‘†ğ‘¡âˆ’1
âˆ—â€² ,Î£2))=âˆ’
(ğ‘†ğ‘¡âˆ’1â€² âˆ’ğ‘†ğ‘¡âˆ’1âˆ—â€² )
2
2âˆ™Î£2 âˆ’
log(Î£âˆš2ğœ‹)  
(25) 
We can drop the constant term logâ¡(Î£âˆš2ğœ‹) for optimizati on 
since it does not affect the relative evaluations of the model 
parameters. This formulation leverages the properties of the 
Gaussian distribution to model uncertainty in state transiti ons 
and incorporate it into the loss function . 
C. Decisions on the move: Active Inference with the diffusion 
model 
Active Inference (AIF) offers a framework for understandi ng 
and predicting the behavior of autonomous agents in dynami c 
and uncertain environments. This approach uses the princi pl e 
of minimizing expected free energy and variational free energy 
to guide decision -making [19]. Variational free energy deal s 
with the present (how well the agent's model predicts what i t 
currently observes), while expected free energy is concerned 
with the future (choosing actions that minimize future surpri se 
and maximize goal fulfillment) [20]. Together, these concepts 
help an agent continuously adapt and make informed decisi ons 
in a changing world, aiming for a coherent and accurate 
understanding of its environment and effective interaction wi th 
it. 
Variational free energy is a concept derived from statisti cal 
physics but adapted in the realm of cognitive science to measure 
how well an agent's internal model predicts sensory inputs i t 
observes. It is a discrepancy measure between what the agent 
 
Fig. 6.  Physics-informed VAE. 
  

 7 
expects to see and what it observes. Minimizing variational free 
energy means the agent is improving its model of the worl d to 
better predict incoming sensory data. In simpler terms, itâ€™s like 
an error signal that tells the agent how wrong its predicti ons 
were; by reducing this error, the agentâ€™s model becomes more 
accurate. Expected free energy, on the other hand, is more 
forward -looking. It measures not just the "fit" or accuracy of the 
agent's model against current observations but also consi ders 
the fut ure states the agent might experience. Expected free 
energy considers the uncertainty or surprise that those future 
states could hold and how valuable they might be in terms of 
the agent's goals. By minimizing expected free energy, the 
agent doesnâ€™t just seek to reduce surprise in the present but al so 
acts in ways that are expected to reduce surprise in the future 
while maximizing its goals [21].  
Here, A IF is an approach that conceptualizes the way 
autonomous vehicles navigate and interact with the world. The 
automated parking is modeled as a finite horizon Markov 
decision process (MDP) [22]. The key to applying AIF is the 
balance between being true to vehicleâ€™s model of the parki ng 
environment while taking actions that are most likely to resul t 
in preferred outcomes, which are states that lead the vehi cl e 
back to its desired parking spot. Th e diffusion-based moti on 
predictor operates as a generative model for a vehicle's 
interactions within its environment. This model, parameteri zed 
by ğœ‘ , projects the likelihood of potential acti ons ğ‘(ğ‘ğ‘›|ğ‘†ğ‘›;ğœ‘), 
each action being one that could revert the vehicle to a positi on 
progressively nearer to its designated parking locati on. 
Complementing this predictive layer is the physi cal 
probabilistic bicycle model, symbolized as ğ‘“(âˆ™), which serves 
to estimate the vehicle's subsequent state as a consequence of 
the selected actions. This physical model follows the dynami cs 
encapsulated in the predefined Equations (9) â€“ (13), providi ng 
the trajectory that a vehicle would trace given a set of 
maneuvers. The interplay between the generative model and the 
physical model creates a cohesive framework for understandi ng 
and guiding a vehicle's movements towards its goal state.  
 ğ‘†ğ‘›+1
â€² =ğ‘“(ğ‘†ğ‘›,ğ‘ğ‘›) (26) 
Incorporating the realities of dynamic environments into the 
predictive model, the likelihood of future states and acti ons can 
now be represented with a probability distribution that all ows 
for environmental uncertainties such as slippery road conditi ons. 
This predictive distribution  is described by: 
 ğ‘„(ğ‘†â€²âƒ—âƒ—âƒ— ,ğ‘ |ğ‘†ğ‘›)â‰” 
âˆ ğ’©(ğ‘†ğœ+1;ğ‘“(ğ‘†ğœ,ğ‘ğœ),Î£)ğ‘(ğ‘ğœ|ğ‘†ğœ;ğœ‘)
ğ‘âˆ’1
ğœ=ğ‘›
 
(27) 
In Equation (27), ğ‘„(ğ‘†â€²âƒ—âƒ—âƒ— ,ğ‘ |ğ‘†ğ‘›) denotes the estimated future 
states and actions, assuming the agent is in state ğ‘†ğ‘›. Instead of 
asserting that actions lead to a single specific state, the Gaussi an 
distribution ğ’© introduces a scope of possible next states ğ‘†ğœ+1, 
with ğ‘“(ğ‘†ğœ,ğ‘ğœ) providing the mean or most likely next state and 
Î£ encapsulating the uncertainty in this transition. The term 
ğ‘(ğ‘ğœ|ğ‘†ğœ;ğœ‘) captures the conditional probability of an acti on ğ‘ğœ, 
given the current state ğ‘†ğœ, and influenced by the model 's 
parameters ğœ‘. 
a. Refining the Predictive Model via Variational Free Energy 
In the AIF framework, Variational Free Energy (VFE) serves 
as a measure of the divergence between the predicted and actual 
future states. In this work, VFE is used to quantify the 
discrepancy between the outcomes predicted by the diffusi on 
model (DP model) and the observed true states. The VFE is 
formally represented by the equation:  
 ğ‘‰ğ¹ğ¸=ğ·ğ¾ğ¿[ğ‘(ğœ‘|ğ‘†ğ‘›,ğ‘)||ğ‘(ğœ‘)]
âˆ’ğ¸ğ‘[ğ‘™ğ‘œğ‘”ğ‘(ğ‘†â€²âƒ—âƒ—âƒ— |ğ‘†ğ‘›,ğ‘,ğœ‘)] 
(28) 
In equation (28), the first term is the KL divergence, whi ch 
calculates the difference between the current belief about the 
model parameters ğ‘(ğœ‘|ğ‘†ğ‘›,ğ‘) and the prior beliefs ğ‘(ğœ‘). The 
second term is the expected log probability of the observed 
states given the current state, actions, and model parameters, 
which serves to anchor the model's predictions to the actual 
observations. To optimize the diffusion model, VFE is 
minimized by continuously adjusting the model parameters, 
denoted as ğœ‘ using the data collected during operation. Thi s 
optimization is typically performed using gradient descent on 
the physics-informed VAE, as is discussed in section III part b, 
where ğœ‘ğ‘›ğ‘’ğ‘¤=ğœ‘ğ‘œğ‘™ğ‘‘âˆ’ğœ‚ğ›»ğœ‘ğ‘‰ğ¹ğ¸, with ğœ‚ is the learning rate. 
b. Navigating Towards Goals with the Free Energy of the 
Future 
In the exploration of preferred states within the AIF 
framework, a preference distribution ğ¶ğ›½ is defined over the 
state space ğ•Š. This distribution is weighted by a pa rameter ğ›½, 
which is greater than zero, to prioritize states that the agent fi nds 
rewarding. Mathematically, preferred states are derived from 
the Boltzmann distribution expressed as in logarithmic form by: 
 âˆ’ğ‘™ğ‘œğ‘”ğ¶ğ›½(ğ‘†)=âˆ’âˆ’ğ›½ğ‘…(ğ‘†)âˆ’ğ‘(ğ›½),âˆ€ğ‘†
âˆˆğ•Š,for some ğ‘(ğ›½)
âˆˆâ„ constant w.r.t s. 
(29) 
The parameter ğ›½, known as the inverse temperature, 
quantifies the agentâ€™s motivation level: a higher ğ›½ corresponds 
to a stronger preference for states yielding higher rewards. 
Agents are therefore inclined to select states that maximize the 
reward function ğ‘…(ğ‘†), thus maximizing ğ¶ğ›½(ğ‘†) and minimizi ng 
âˆ’ğ‘™ğ‘œğ‘”ğ¶ğ›½(ğ‘†) for any given ğ›½  greater than zero. Thi s 
foundational preference structure underpins the agent's 
decision-making process, steering it toward states that it deems 
preferable or beneficial in the context of its environment and 
objectives. The reward function ğ‘…(ğ‘†) captures the criteri a for 
these desired states, integrating goals such as reaching a parki ng 
spot ğ‘†ğ‘”ğ‘œğ‘ğ‘™, maintaining safety by avoiding collisions with 
surrounding vehicles ğ‘†ğ‘›+1
ğ‘£âˆ’  at time step ğ‘›+1, and ensuri ng 
smoothness in the control actions. Mathematically, the reward 
function is characterized by:  
 ğ‘…(ğ‘†)=âˆ’ğœ†ğ‘”ğ‘œğ‘ğ‘™âˆ™â€–ğ‘†ğ‘›+1
â€² âˆ’ğ‘†ğ‘”ğ‘œğ‘ğ‘™â€–+ğœ†ğ‘ ğ‘ğ‘“ğ‘’ğ‘¡ğ‘¦
âˆ™âˆ‘â€–ğ‘†ğ‘›+1
â€² âˆ’ğ‘†ğ‘›+1
ğ‘£âˆ’ â€–
âˆ’ğœ†ğ‘ ğ‘šğ‘œğ‘œğ‘¡â„âˆ™â€–ğ‘ğ‘›
â€² âˆ’ğ‘ğ‘›âˆ’1â€– 
(30) 
where ğœ†ğ‘”ğ‘œğ‘ğ‘™ , ğœ†ğ‘ ğ‘ğ‘“ğ‘’ğ‘¡ğ‘¦, and ğœ†ğ‘ ğ‘šğ‘œğ‘œğ‘¡â„ are the weighting 
parameters that balance the importance of each aspect in the 
reward function. Extending the preference distribution ğ¶ğ›½ over 
trajectories ğ‘† â‰”(ğ‘†1,ğ‘†2,â‹¯,ğ‘†ğ‘)âˆˆğ•Šğ‘, we apply the additi ve 
property of the reward function to evaluate entire paths : 
 8 
 
âˆ’ğ‘™ğ‘œğ‘”ğ¶ğ›½(ğ‘† )=âˆ’ğ›½ğ‘…(ğ‘† )âˆ’ğ‘â€²(ğ›½)
=âˆ’âˆ‘ ğ›½ğ‘…(ğ‘†ğœ)
ğ‘
ğœ=1
âˆ’ğ‘â€²(ğ›½),âˆ€ğ‘† 
âˆˆğ‘†ğ‘ 
(31) 
The inverse temperature parameter ğ›½ remains a measure of 
how strongly the agent prefers certain trajectories, favori ng 
those that accumulate greater rewards. Through this framework, 
the active inference process not only seeks individual states but 
also entire trajectories that are aligned w ith the agent's 
preferences and the dynamics of the vehicle's environment.  
Vehicles aim to minimize a quantity known as Expected Free 
Energy (EFE) in the framework of active inference, whi ch 
guides them in making decisions that align with thei r 
preferences. This aims at balancing the exploration-exploitati on 
trade -off by minimizing surprise (or uncertainty) and 
maximizing the likelihood of achieving preferred outcomes  
[20]. The general formula for EFE is:  
 ğº(ğ‘ ,ğ‘)=ğ”¼ğ‘„(ğ‘ â€²|ğ‘ ,ğ‘)[logğ‘„(ğ‘ â€²|ğ‘ ,ğ‘)
âˆ’logğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘)] 
(32) 
whereâ¡â¡ğ‘  represents the current state, ğ‘ represents the acti on 
taken by the agent, ğ‘ â€² represents the subsequent state resulti ng 
from action ğ‘, and ğ‘œ is the observation or outcome associ ated 
with state ğ‘ â€². ğ‘„(ğ‘ â€²|ğ‘ ,ğ‘) is the approximate posterior or the 
agentâ€™s belief about the next state given the current state and 
action.  ğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘) is the generative model that links states and 
observations, providing the likelihood of observing ğ‘œ in state ğ‘ â€² 
after taking action ğ‘. The term logğ‘„(ğ‘ â€²|ğ‘ ,ğ‘) refers to the 
entropy of the agent's beliefs, which measures uncertainty or 
surprise about the next state. The term logğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘) captures 
the accuracy of the predictions under the model, quantifyi ng 
how probable the outcomes are given the agentâ€™s model of the 
world. In practice, this formula guides agents to choose acti ons 
that are expected to provide the most informative (reduci ng 
uncertainty) and rewarding outcomes according to their internal 
model of the world.  
Equation (33) can be approximated and split into an energy 
and an entropy or an accuracy and complexity term [20], whi ch 
corresponds to the extrinsic and epistemic action terms i n the 
EFE: 
ğº(ğ‘ ,ğ‘)
â‰ˆâˆ’ğ”¼ğ‘„(ğ‘ â€²|ğ‘ ,ğ‘)[logğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘)]
+ğ”¼ğ‘„(ğ‘ â€²|ğ‘ ,ğ‘)ğ·ğ¾ğ¿[ğ‘„(ğ‘†â€²âƒ—âƒ—âƒ—âƒ—âƒ— |ğ‘ ,ğ‘†ğ‘›)|ğ¶ğ›½(ğ‘† )] 
(33) 
where the first term ğ”¼ğ‘„(ğ‘ â€²|ğ‘ ,ğ‘)[logğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘)] is the 
extrinsic value.  It quantifies the surprise or improbability of 
observing ğ‘œ and the next state ğ‘ â€² given the current state ğ‘ â¡and 
the current action ğ‘, thereby estimating how unexpected or 
unlikely these observations and transitions are under the current 
policy. The second term ğ”¼ğ‘„(ğ‘ â€²|ğ‘ ,ğ‘)ğ·ğ¾ğ¿[ğ‘„(ğ‘†â€²âƒ—âƒ—âƒ—âƒ—âƒ— |ğ‘ ,ğ‘†ğ‘›)|ğ¶ğ›½(ğ‘† )] i s 
the intrinsic value, which incorporates the cost function ğ¶ğ›½(ğ‘† ) 
and quantifies how the distribution of predicted future states 
ğ‘„(ğ‘†â€²âƒ—âƒ—âƒ—âƒ—âƒ— |ğ‘ ,ğ‘†ğ‘›) diverges from a desired or preferred state 
distribution as encoded by ğ¶ğ›½(ğ‘† ). This divergence ai ms to 
penalize decisions leading to future states that are less preferred 
according to the cost function. Essentially, it encourages the 
selection of actions that not only minimize surprise but al so 
align future states closely with those that are considered 
preferable or beneficial . 
Given a MDP process , the EFE for a sequence of acti ons, 
denoted as ğº(ğ‘ |ğ‘ ğ‘¡), can be expressed as an aggregate of 
individual free energies at each time step : 
 
ğº(ğ‘ |ğ‘ ğ‘¡)â‰ˆ âˆ‘ ğº(ğ‘ğœ|ğ‘ ğœ) 
ğ‘
ğœ=ğ‘›+1
 
(34) 
This simplification allows the agent to plan by eval uati ng 
each future time point separately, significantly streamlini ng the 
planning process without the need for an exhaustive evaluati on 
of all possible future trajectories. It is an efficient method to 
guide the agent toward preferred states while considering the 
inherent uncertainties and computational constraints.  
D. Comprehensive Workflow of the Diffusion-Based Active 
Inference Framework  
The following algorithm outlines the entire workflow of the 
Diffusion-Based Active Inference Framework (AIF) . It  is 
structured into three interlinked phases: Forward Diffusi on 
Process, Reversed Diffusion Process, and Active Inference 
Control. Using simulation for training, vehicles exit parki ng 
spots under a variety of initial conditions, performing random 
maneuvers such as steering and throttle adjustments. The 
process continues until the vehicle either collides or reaches the 
boundary of the parking area. The reversed Diffusion process 
utilizes the data generated in the forward Diffusion process and 
employs a physics informed Variational Autoencoder (VAE) 
model to reverse the sequence of the collected data. The model 
predicts previous states and actions from current states, 
enabling the vehicle to reverse -engineer its movements. The 
reverse model is refined through VFE when it fails to properl y 
predict. The refined reverse model and AIF  then decide the 
most probable action(s) that minimize expected free energy. the 
vehicle toward its intended destination, dynamically adapti ng 
to new data and making necessary course c orrections. 
Algorithm 1: Algorithm for Diffusion -Based Active 
Inference Framework  
 DP-Forward:  Data Collection  
  Input: Number of trials, vehicle dynamics.  
  Output: Vehicle trajectory dataset.  
1  For each trial:  
2   Initialize parking lot with vehicles at random 
spots. 
3   Simulate vehicle movement until a collision or 
boundary is reached : 
4    Apply random actions (throttle, steering) 
and introduce Gaussian noise to model 
uncertainty.  
5    Record state transitions and actions until 
the end condition is met.  
 DP-Reverse: Model Training  
  Input: Collected vehicle trajector ies. 
  Output: Trained physics-informed VAE model for 
 9 
motion prediction . 
6  Reverse the state -action sequences from the 
trajectory dataset.  
7  Initialize the VAE model. 
8  For each training epoch:  
9   Predict action distributions to reverse states.  
10   Sample actions using reparameterization.  
11   Predict previous states using the probabilistic 
bicycle model.  
12   Compute loss and update model parameters. 
 Active Inference Control:  Implementation and 
Execution  
  Input: Pretrained VAE model, vehicleâ€™s current 
state, and destination.  
  Output: Vehicle actions (throttle, steering).  
13  Continuously predict and apply actions that 
minimize EFE until the vehicle reaches the desired 
spot. 
14  Monitor state prediction error:  
15   If error exceeds a threshold, fine-tune the model 
with recent state -action data.  
The algorithm is inherently cyclic and adaptive, featuri ng 
feedback mechanisms within the Active Inference Control 
phase that can trigger additional data collection and model 
retraining as needed. This adap tive cycle ensures that the 
navigation system continuously evolves, enhancing its capaci ty 
to handle increasingly complex environments and improvi ng 
accuracy over time.  
IV. SIMULATION AND VALIDATION RESULTS 
In this section, we delve into the validation results from 
simulations conducted within a custom -designed parki ng 
environment created using the â€˜highway-envâ€™ simulati on 
package. The purpose of these simulations is to assess the real-
world applicability and robustness of the proposed Framework. 
The validation is divided into three segments. The initial part 
describes the simulation environment set up within 'highway-
env'. This setup provides the foundational context for 
subsequent testing and analysis. In th e second segment, a 
detailed analysis of the diffusion model's performance is 
presented. Finally, we examine the simulation outcomes where 
the model's practical efficacy is showcased through its 
application in controlling vehicles. These simulati ons 
underscore the model's potential contributions to  autonomous 
navigation under uncertainty.  
A. Simulation Setup  
a. Setup for training the diffusion motion predicto r 
For the motion prediction model, the highway -env 
simulation package was tailored to create two specific parki ng 
scenarios, shown in figure 7, with the aim of training and 
validating a diffusion-based motion predictor. In the simul ati on 
setup, green vehicles are designated for autonomous control , 
whereas the yellow vehicles remain stationary. The parki ng 
area is outlined by yellow lines, denoti ng its boundaries. The 
first scenario is structured with six parking spots and four cars 
within the simulated environment shown in figure 7(a). Two of 
these vehicles are designated as controllable, while the 
remaining pair are static and parked. In the second, more 
complex scenario, the environment is expanded to include ten 
parking spots and six cars, with half of the vehicles being under 
our control, as is shown in figure 7(b). 
 
For training phase, the starting positions of the vehicles are 
randomized in different parking spots in each trial, ensuri ng a 
diverse range of initial conditions for model training.  
b. Customizing the Simulation for AIF -Controlled Driving 
 
For the application phase, the parking environment is agai n 
customized for scenarios with four and six cars as is shown i n 
Fig. 8.  Parked cars are placed in predetermined spots, whil e the 
controllable vehicles are placed at random locations withi n the 
parking area, each with an assigned destination spot. The 
controllable cars, equipped with initial velocities and 
orientations, utilize AIF for navigation, driving towards thei r 
designated parking spots while avoiding collisions. This two-
tiered simulation approach serves a dual purpose: traini ng the 
model to understand vehicle dynamics and control strategies i n 
a constrained environment and validating the model's capabil i ty 
to navigate complex scenarios with multiple agents. The resul ts 
from these simulations are expected to provide insightful data 
on the potential of AIF in the field of autonomous vehi cl e 
navigation, particularly in unstructured environments where 
traditional driving guidelines may be absent.  
B. Assessing the performance of the diffusion motion 
predictor  
Fig. 9 illustrates the loss plot of the diffusion moti on 
predictor throughout its training and validation phases. Initial l y, 
a precipitous decline in the training loss is observed, indicati ve 
of the model's rapid acclimatization to the structure withi n the 
training data. Concurrently, the validation loss mirrors the 
downward trend of the training loss, suggesting a consistent 
learning pattern that generalizes beyond the training set. As the 
epochs advance, both losses stabilize and exhibit mini mal 
variance, which implies that the model has potentially reached 
its learning capacity given the current architecture and dataset. 
The absence of a significant gap between the training and 
validation losses towards the end of the training suggests that 
the model is not ove rfitting and is well -calibrated to the 
complexity of the data it aims to model.  
  
(a) (b) 
Fig. 7.  Randomly generated starting points for the forward process. 
 
  
(a) (b) 
Fig. 8.  Randomly generated starting points for the reverse process. 
 

 10 
 
Table I presents some prediction examples that illustrates the 
diffusion-based motion predictor's performance. The tabl e 
compares the positions of the controlled vehicles after applyi ng 
the reparametrized action selected from the predicted acti on 
distribution aga inst their actual positions. These exampl es 
indicate the model's adeptness in tracking and predicti ng 
vehicle motion with a high degree of accuracy, as reflected by 
the minor discrepancies between predicted and true states.   
 
Table II  enumerates more key metrics used to eval uate the 
diffusion-based motion predictor. The Mean Squared Error 
(MSE) for the model's predictions, which evaluates the average 
squared difference across all elements in the vehicle state 
(ğ‘¥,ğ‘¦,ğ‘£ğ‘¥,ğ‘£ğ‘¦,â¡andâ¡â„), is 0.2296.  indicating the average squared 
difference between the predicted and actual next states. 
Furthermore, the model demonstrates a probabilisti c 
confidence in its predictions, with the true next state falli ng 
within one standard deviation (1 sigma) of the pred icted 
distribution 43.05% of the time, within two standard devi ati ons 
(2 sigma) 68.22% of the time, and within three standard 
deviations (3 sigma) 86.27% of the time. These statistics not 
only affirm the model's predictive strength but also su ggest a 
well-calibrated understanding of the uncertainty inherent i n 
vehicle movements.  
 
C. Active Inference Framework: Guiding Autonomous 
Vehicles to Precision Parking  
The trajectory plots shown in Fig. 10 illustrates the behavi ors 
of the vehicles under the guidance of AIF. Fig. 10 (a) and (b) 
shows the trajectories for two controlled vehicles, (c) and (d) 
shows the cases with three controlled vehicles. They depi ct the 
routes taken from the vehiclesâ€™ starting points to their parki ng 
spots, highlighting the adaptive maneuvers made to avoi d 
obstacles and achieve their parking goals. Through these pl ots, 
we can demonstrate AIF's capacity for spatial reasoning and i ts 
application in complex navigation tasks, validating its use in 
autonomous parking systems.  
 
V. CONCLUSION AND FUTURE WORK 
In this paper , we have explored a novel approach to guidi ng 
autonomous vehicles in scenarios where the usual road 
markings are absent. This exploration was grounded in the 
development of a diffusion -based motion predictor, 
implemented within an Active Inference Framework (AIF), and 
tested within a specially designed parking lot simulation. Our 
goal was to closely mimic the challenges vehicles face on 
unmarked roads, using the parking lot as a stand -in for such 
environments. We started by transforming a traditional road 
scenario into a parking lot setup, a crucial step in creati ng a 
realistic yet controlled environment for our simulations. Thi s 
environment, characterized by its lack of lane markings, 
required vehicl es to navigate from their starting points to 
designated parking spots while avoiding collisions. Thi s 
scenario was meticulously designed to transition vehicles from 
a disordered state, where their positions and velocities were 
randomized, to an orderly sta te, mirroring the structured 
outcome of successful parking. The introduction of the 
diffusion-based motion predictor was a pivotal part of our 
exploration. This tool, developed through a nuanced 
understanding of diffusion model methodologies, was adept at 
forecasting the future movements of vehicles within the parki ng 
lot. By predicting a range of possible actions for each vehi cl e 
and selecting the optimal path based on expected free energy, 
the model demonstrated its ability to effectively navi gate 
vehicles to their intended destinations.  
Our simulations offered concrete evidence of the model 's 
effectiveness. Through a series of tests in environments wi th 
varying degrees of complexity, from four to six cars navigati ng 
towards six to ten parking spots, we showcased the model 's 
robust capability to ensure safe and efficient vehicle parki ng. 
These tests not only affirmed the model's practical applicabil i ty 
but also its potential to significantly improve traffic safety and 
 
Fig. 9.  Loss plot for training the reverse process. 
  
TABLE I 
PREDICTION EXAMPLES OF THE DIFFUSION -BASED MOTION PREDICTOR  
#  Next State ğ’™ ğ’š ğ’—ğ’™ ğ’—ğ’š ğ’‰ 
1 True next state 3.96 -19.46 -0.86 1.59 -1.08 
 Predicted next state 3.92 -19.55 -0.73 1.65 -1.15 
2 True next state -11.36 -8.30 9.80 9.73 -2.36 
 Predicted next state -11.61 -7.58 8.67 10.76 -2.25 
3 True next state 6.16 14.55 -0.08 -1.41 1.51 
 Predicted next state 6.32 14.47 -0.11 -1.78 1.51 
 
TABLE II 
PERFORMANCE METRICS FOR THE DIFFUSION -BASED MOTION PREDICTOR  
Metric Description Value 
MSE between reparametrized next state and true next state  0.2296 
True next state within 1 ğœ¹ of predicted next state distribution 43.05% 
True next state within 2 ğœ¹ of predicted next state distribution 68.22% 
True next state within 3 ğœ¹ of predicted next state distribution 86.27% 
 
  
(a) (b) 
  
(c) (d) 
Fig. 10. Vehicle trajectories controlled by diffusion-based AIF. 
 

 11 
vehicle navigation in real -world scenarios devoid of lane 
markings. Looking forward, we aim to extend the scope of our 
research to encompass larger and more complex driving 
environments. The next steps involve refining the model to 
enhance its predictive a ccuracy and adaptability to the 
unpredictability inherent in real-world driving conditions. The 
scalability of the proposed system will also be tested in urban 
driving environments, pushing the boundaries of whatâ€™s 
currently achievable in autonomous vehicl e naviga tion. 
 
REFERENCES 
 
[1]  H. Cao, C. Tan, Z. Gao, Y. Xu, G. Chen, P.-A. Heng 
and S. Z. Li, "A Survey on Generative Diffusion 
Models," IEEE Transactions on Knowledge and Data 
Engineering, pp. 1-20, 2024.  
[2]  Z. Zhong, D. Rempe, D. Xu, Y. Chen, S. Veer, T. 
Che, B. Ray and M. Pavone, "Guided Conditional 
Diffusion for Controllable Traffic Simulation," in 
IEEE International Conference on Robotics and 
Automation (ICRA) , London, 2023.  
[3]  G. Pezzulo, F. Rigoli and K. Friston, "Active 
Inference, homeostatic regulation and adaptive 
behavioural control," Progress in Neurobiology, vol. 
134, pp. 17 -35, 2015.  
[4]  K. Friston and S. Kiebel, "Predictive coding under the 
free-energy principle," Philosophical transactions of 
the Royal Society of London Series B Biological 
sciences, vol. 364, no. 1521, pp. 1211 -1221, 2009.  
[5]  F. Mohseni, E. Frisk and L. Nielsen, "Distributed 
Cooperative MPC for Autonomous Driving in 
Different Traffic Scenarios," IEEE Transactions on 
Intelligent Vehicles, vol. 6, no. 2, pp. 299-309, 2021.  
[6]  W. Y. Choi, S.-H. Lee and C. C. Chung, "Horizonwi se 
Model-Predictive Control With Application to 
Autonomous Driving Vehicle," IEEE Transactions on 
Industrial Informatics, vol. 18, no. 10, pp. 6940-6949, 
2021.  
[7]  A. Muraleedharan, H. Okuda and T. Suzuki, "Real -
Time Implementation of Randomized Model 
Predictive Control for Autonomous Driving," IEEE 
Transactions on Intelligent Vehicles, vol. 7, no. 1, pp. 
11-20, 2022.  
[8]  Z. Du, Q. Miao and C. Zong, "Trajectory Planning for 
Automated Parking Systems Using Deep 
Reinforcement Learning," International Journal of 
Automotive Technology, vol. 21, pp. 881 -887, 2020.  
[9]  R. Rombach, A. Blattmann, D. Lorenz, P. Esser and 
B. Ommer, "High-Resolution Image Synthesis with 
Latent Diffusion Models," in arXiv, 2021.  
[10]  O. Ã‡atal, T. Verbelen, T. V. d. Maele, B. Dhoedt and 
A. Safron, "Robot navigation as hierarchical active 
inference," Neural Networks, vol. 142, pp. 192 -204, 
2021.  
[11]  R. Ghugare, H. Bharadhwaj, B. Eysenbach, S. Levine 
and R. Salakhutdinov, "Simplifying Model-based RL: 
Learning Representations, Latent-space Models, and 
Policies with One Objective," in ICLR, Kigali, 2023.  
[12]  N. Sajid, P. J. Ball, T. Parr and K. J. Friston, "Active 
inference: demystified and compared," The Wellcome 
Centre for Human Neuroimaging, UCLQueen Square 
Institute of Neurology, London, 2020.  
[13]  C. Pezzato, C. H. Corbato, S. Bonhof and M. Wisse, 
"Active Inference and Behavior Trees for Reactive 
Action Planning and Execution in Robotics," IEEE 
Transactions on Robotics, vol. 39, no. 2, pp. 1050 -
1069, 2023.  
[14]  C. Pezzato, R. Ferrari and H. C. Corbato, "A Novel 
Adaptive Controller for Robot Manipulators Based on 
Active Inference," IEEE Robotics and Automation 
Letters, vol. 5, no. 2, pp. 2973 -2980, 2020.  
[15]  R. Rombach, A. Blattmann, D. Lorenz, P. Esser and 
B. Ommer, "High-Resolution Image Synthesis with 
Latent Diffusion Models," arXiv, 2022.  
[16]  S. Kullback and R. A. Leibler, "On Information and 
Sufficiency," The Annals of mathematical statistics, 
vol. 22, no. 1, pp. 79 -86, 1951.  
[17]  P. Polack, F. AltchÃ© , B. d'AndrÃ© a-Novel and A. d. L. 
Fortelle, "The kinematic bicycle model: A consistent 
model for planning feasible trajectories for 
autonomous vehicles?," in IEEE Intelligent Vehicles 
Symposium (IV), Redondo Beach, California, US, 
2017.  
[18]  Y. Song, C. Durkan, I. Murray and S. Ermon, 
"Maximum Likelihood Training of Score -Based 
Diffusion Models," in Conference on Neural 
Information Processing Systems (NeurIPS) , Online, 
2021.  
[19]  J. Kulveit and R. Hadshar, "Why Simulator AIs want 
to be Active Inference AIs," 10 April 2023. [Online]. 
Available: 
https://www.lesswrong.com/posts/YEioD8YLgxih3yd
xP/why-simulator-ais-want-to-be-active-inference-ais. 
[20]  T. Parr, G. Pezzulo and K. J. Friston, Active Inference 
The Free Energy Principe in Mind, Brain, and 
Behavior, MIT Press, 2022.  
[21]  K. Friston, "The free-energy principle: a unified brain 
theory?," Nature Reviews Neuroscience, vol. 11, pp. 
127-138, 2010.  
[22]  O. V. D. Himst and P. Lanillos, "Deep Active 
Inference for Partially Observable MDPs," in IWAI 
2020 : International Workshop on Active Inference , 
Ghent, 2020.  
 
 
 12 
Yufei Huang received a B.Eng. degree i n 
Automation from Xi â€™an Jiaotong 
University in 2016. Also, he received an 
M.S. degree in Systems Engineering from 
the University of Maryland, College Park 
in 2018. He is currently a Ph.D. student at 
Rutgers, the State University of New Jersey, 
studying Industrial and Systems 
Engineering, and a Research Assistant at 
the Center for Advanced Infrastructure and Transportati on 
(CAIT). His research interests are in multi -agent systems, 
autonomous systems , robotics, and  reinforcement learning.  
 
 
Yulin Li  received his B.S. degree in 
industrial and systems engineering from 
Rutgers University in 2019 and an M.S. 
degree in systems engineering from Cornel l 
University in 2021. He is currently worki ng 
towards a Ph.D. degree in industri al 
engineering at Rutgers Un iversity. His 
research interests include generati ve 
models and the use of active inference for 
decision-making in dynamic environments.  
 
 
Andrea Matta  is Full Professor at 
Politecnico di Milano, where he currentl y 
teaches integrated manufacturing systems 
and manufacturing processes. His 
research area includes analysis, design, 
and management of manufacturing and 
healthcare systems. He is Editor in Chi ef 
of the Flexible Services and 
Man ufacturing Journal.  
 
 
Mohsen Jafari  (Mâ€™97) received a Ph.D. 
degree from Syracuse University in 1985. 
He has directed or co -directed a total of 
over 23 million U.S. dollars in fundi ng 
from various government agenci es, 
including the National Science Foundati on, 
the Department of Energy, the Office of 
Naval Res earch, the Defense Logistics 
Agency, the NJ Department of Transportation, FHWA, and 
industry in automation, system optimization, data modeling, 
information systems, and cyber risk analysis. He activel y 
collaborates with universities and research institutes abroad. He 
has also been a Consultant to several Fortune 500 compani es as 
well as local and state government agencies. He is currentl y a 
Professor and the Chair of Industrial & Systems Engineeri ng at 
Rutgers University-New Brunswick. His research applicati ons 
extend to manufacturing, transportation, healthcare, and energy 
systems. He is a member of the IIE. He received the IEEE 
Excellence Award in service and research.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
