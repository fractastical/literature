arXiv:2406.07577v1  [cs.AI]  7 Jun 2024
Structured Active Inference
T oby St Clere Smithe r0000´ 0002´ 8317´ 8722s
VERSES Research Lab
toby.smithe@verses.ai
Abstract. We introduce structured active inference, a large generaliza-
tion and formalization of active inference using the tools o f categorical
systems theory. We cast generative models formally as syste ms “on
an interface”, with the latter being a compositional abstra ction of the
usual notion of Markov blanket; agents are then ‘controller s’ for their
generative models, formally dual to them. This opens the act ive inference
landscape to new horizons, such as: agents with structured i nterfaces
(e.g. with ‘mode-dependence’, or that interact with computer API s);
agents that can manage other agents; and ‘meta-agents’, tha t use active
inference to change their (internal or external) structure . With structured
interfaces, we also gain structured (‘typed’) policies, wh ich are amenable
to formal veriﬁcation, an important step towards safe artiﬁ cial agents.
Moreover, we can make use of categorical logic to describe ex press agents’
goals as formal predicates, whose satisfaction may be depen dent on the
interaction context. This points towards powerful composi tional tools to
constrain and control self-organizing ensembles of agents .
Keywords: Active inference · Categorical systems theory · Cybernetic s
· Multi-agent · F ormal methods · Safe AI.
As active inference develops beyond toy models and early exp lorations, and
becomes a fully-ﬂedged account of the form and function of co mplex living
systems at all scales, the necessity of a compositional orga nizing framework
becomes apparent: without this, the complexity of veridica l multi-agent systems
in realistic environments is impossible to handle. T o see th is necessity , one need
only ponder the question, how would you model an agent as it ge ts on a bicycle,
or starts to drive a car? Even in cases as mundane as these, cur rent presentations
of active inference do not yield a canonical answer. More gen erally , it is not at
all clear how to describe, in general, an agent that can chang e its ‘interface’.
This is an argument that we must move beyond the current parad igm
of partially observable Markov decision problems (and thei r continuous-time
cousins), which are most suitable for the description of ind ividual agents with
unchanging Markov blankets and static environments, and ad opt a new paradigm
with change at its heart, and that makes the most of the compos itional structure
of our world. It is such a paradigm that we propose here: structured active
inference, in which every agent’s generative model has an explicit int erface, vastly
generalizing the existing notion of Markov blanket. This ne w paradigm exploits
2 T. St Clere Smithe
the new mathematics of categorical systems theory (CST) [
1], which organizes
interacting dynamical systems into a coherent composition al framework.
Being based on category theory , change and composition are a t the heart of
structured active inference: patterns of interaction amon g systems constitute
morphisms of interfaces, as do changes-of-interface; and c hanges-of-structure
are morphisms of systems (over interfaces). Category theor y is moreover the
mathematics of structure, meaning that agents’ interfaces may exhibit substan-
tially richer structures than merely a ﬁxed pair of sets (of p ossible actions
and observations). In particular, agents may now exhibit mo de-dependence: the
available actions may depend on contextual data (encoded in their current state).
Being a mathematical lingua franca , category theory allows us to import ideas
from computer science, yielding agents that correctly inte ract with computer
APIs, or whose policies may be interpreted as programs and th us type-checked
(a step towards formal veriﬁcation), or that (recursively) manage other agents,
or (‘corecursively’) use active inference to change their o wn structure.
Additionally , categorical systems theory is itself amenab le to categorical logic
[2], which explains the structural fundaments of logic and typ e theory and which
may be instantiated in any suﬃciently structured context. I n this way , structured
active inference permits not only typed policies, but also a rigorous analysis of
agents’ goals as formal predicates (possibly in a fuzzy , qua ntitative, temporal
logic), whose satisfaction may be judged in relation to thei r interaction contexts:
thanks to its compositionality , the logic of systems is itse lf ‘covariant’ with
their patterns of interaction. This promises a further impo rtant step towards
safe artiﬁcial agents, as agents’ goals may be gated behind t he certiﬁcation
(within bounds) of their safety [ 3, 4], and their policies judged accordingly . In
combination with structurally nested (‘manager’) agents, it becomes possible
to pass formal speciﬁcations of high-level goals down to low -level agents which
actually implement them.
This extended abstract is an announcement of work in progres s. A full
expository paper will follow soon. Meanwhile, we supply app endices below which
sketch the key structures and exemplify the corresponding p ossibilities.
Acknowledgments. The author thanks VERSES for ﬁnancial support during the
development of this work.
Disclosure of Interests. The author has no competing interests to declare that are
relevant to the content of this article.
References
[1] David Jaz Myers. Categorical Systems Theory (Draft) . 2022. url:
http://davidjaz.com/Papers/DynamicalBook.pdf.
[2] Bart Jacobs. Categorical Logic and Type Theory . V ol. 141. Studies in
Logic and the F oundations of Mathematics. North-Holland Pu blishing
Co., Amsterdam, 1999, pp. xviii+760. isbn: 0-444-50170-3.
Structured Active Inference 3
[3] David "davidad" Dalrymple. Safeguarded AI: Constructing Guaranteed
Safety. T ech. rep. Advanced Research and Innovation Agency, 2024. url:
https://www.aria.org.uk/wp-content/uploads/2024/01/ARIA-Safeguarded-AI-Programme-Thes 
[4] David "davidad" Dalrymple et al. Towards Guaranteed Safe AI: A
Framework for Ensuring Robust and Reliable AI Systems . 05/17/2024.
arXiv: 2405.06624 [cs]. url: http://arxiv.org/abs/2405.06624
(visited on 06/07/2024). preprint.
[5] Nelson Niu and David I. Spivak. Polynomial Functors: A Mathematical
Theory of Interaction . arXiv, 12/01/2023. arXiv: 2312.00990 [math].
url: http://arxiv.org/abs/2312.00990 (visited on 04/05/2024).
[6] Bart Jacobs. “ A Recipe for State-and-Eﬀect T riangles”. In: Logical
Methods in Computer Science 13.2 (2017-05-17, 2017), pp. 1860–5974.
doi: 10.23638/LMCS-13(2:6)2017. arXiv: 1703.09034 [cs.LO].
[7] Dylan Braithwaite, Jules Hedges, and T oby St Clere Smith e. The
Compositional Structure of Bayesian Inference . 05/10/2023. arXiv:
2305.06112 [cs, math]. url: http://arxiv.org/abs/2305.06112
(visited on 05/11/2023). preprint.
[8] Karl J. F riston et al. “ Deep T emporal Models and Active In ference”.
In: Neuroscience & Biobehavioral Reviews 77 (06/2017), pp. 388–402.
issn: 01497634. doi: 10 . 1016 / j . neubiorev . 2017 . 04 . 009. url:
https://linkinghub.elsevier.com/retrieve/pii/S0149763416307096
(visited on 05/31/2024).
[9] T oby St Clere Smithe. Animating Categories . 11/16/2023. url:
https://tsmithe.net/p/animating-cats.html.
[10] Joachim Kock. “ Polynomial F unctors and T rees”. In: Int. Math. Res. No-
tices 2011 (2011), 609-673 (07/17/2008). arXiv: 0807.2874 [math.CT].
[11] Nathanael Arkor and Marcelo Fiore. “ Algebraic Models o f Simple
Type Theories: A Polynomial Approach”. In: Proceedings of the
35th Annual ACM/IEEE Symposium on Logic in Computer Science .
LICS ’20: 35th Annual ACM/IEEE Symposium on Logic in Com-
puter Science. Saarbrücken Germany: ACM, 07/08/2020, pp. 8 8–101.
isbn: 978-1-4503-7104-9. doi:
10 . 1145 / 3373718 . 3394771. url:
https://dl.acm.org/doi/10.1145/3373718.3394771 (visited on
04/05/2024).
[12] Matteo Capucci et al. “ T owards F oundations of Categori cal Cybernet-
ics”. In: Electronic Proceedings in Theoretical Computer Science . Ap-
4 T. St Clere Smithe
plied Category Theory 2021. V ol. 372. Cambridge, UK: Open Pu blishing
Association, 11/03/2022, pp. 235–248. doi: 10.4204/EPTCS.372.17 .
url: http://arxiv.org/abs/2105.06332v2 (visited on 09/29/2023).
[13] Matteo Capucci. “ Diegetic Representation of F eedback in Open Games”.
In: Electronic Proceedings in Theoretical Computer Science . Applied
Category Theory 2022. V ol. 380. Glasgow, UK: Open Publishin g
Association, 08/07/2023, pp. 145–158. doi: 10 . 4204 / EPTCS . 380 . 9.
url: http://arxiv.org/abs/2206.12338v3 (visited on 09/29/2023).
[14] T oby St Clere Smithe. “ Cyber Kittens, or Some First Step s T owards
Categorical Cybernetics”. In: Electronic Proceedings in Theoretical
Computer Science . Applied Category Theory 2020. V ol. 333. Cambridge,
MA: Open Publishing Association, 02/08/2021, pp. 108–124. doi:
10.4204/EPTCS.333.8 . url: http://arxiv.org/abs/2101.10483v1
(visited on 09/29/2023).
[15] David I Spivak. “ The Steady States of Coupled Dynamical Sys-
tems Compose According to Matrix Arithmetic”. 12/02/2015. arXiv:
1512.00802 [math.DS].
Structured Active Inference 5
A Categorical systems theory for active inference
A.1 Systems indexed by interfaces
A systems theory is a family of categories of systems, covariantly indexed by a
category of interfaces. More formally , this is a (pseudo) fu nctor Sys : Int Ñ Cat,
where Cat is the 2-category of categories, functors and natural trans formations.
The category Int is usually understood to have ‘interfaces’ (of some type) fo r
objects, and “patterns of interaction” or “wiring diagrams ” for morphisms. Thus,
if p and q are two interfaces (objects in Int), then a morphism p Ñ q encodes
“how to wire a p-shaped system into a q-shaped system”.
A standard example category of interfaces is the category LenspSetq of
‘lenses’ in Set (the latter being the category of sets and functions between
them). In this case, the objects of LenspSetq are pairs pO,I q of sets; we think
of O as representing the output type of some system, and I as representing its
input type. and a morphism (a so-called ‘lens’) ϕ : pO,I q Ñ p P,J q is a pair
of functions
`
ϕ1 : O Ñ P,ϕ 7 : Oˆ J Ñ I
˘
. W e typically understand the map
ϕ1 as representing how an O ‘output’ is mapped to a P output, and the map
ϕ7 as representing how an I ‘input’ may be obtained from an O output and a
J input. That is, ϕ encodes how an inner system with output-input interface
pO,I q may be ‘nested’ inside an outer system with interface pP,J q: the outer
outputs are obtained as a transformation of the inner output s, and the inner
inputs are obtained as a transformation of the inner outputs and outer inputs,
thereby enabling feedback.
A simple example of a systems theory over LenspSetq is that of deterministic
automata, or Moore machines , Moore : LenspSetq Ñ Cat. A Moore machine
with interface pO,I q is a triple pS,ϑ o,ϑ uq of a state space S : Set, an output map
ϑo : S Ñ O, and an update map ϑu : Sˆ I Ñ S. A morphism f : pS,ϑ q Ñ p S1 ,ϑ 1 q
of Moore machines over pO,I q is a function f : S Ñ S1 that “commutes with the
dynamics”: i.e., satisfying f ˝ ϑu “ ϑ1 u ˝ p f ˆ idIq. The category MoorepO,I q is
thus constituted by Moore machines with interface pO,I q and their morphisms,
which compose simply as functions.
Given a lens ϕ : pO,I q Ñ p P,J q, Moore must deﬁne a functor Moorepϕq :
MoorepO,I q Ñ MoorepP,J q which ‘rewires’ machines over pO,I q so that they
become machines over pP,J q. Note that a Moore machine pS,ϑ q over pO,I q may
equivalently be presented as a lens pϑo,ϑ uq : pS,S q Ñ p O,I q, and so Moorepϕq
may be deﬁned simply by composing ϕ after ϑ, thus mapping pS,ϑ q to pS,ϕ ˝ ϑq.
It is easy to check that this maps morphisms of Moore machines over pO,I q to
morphisms of Moore machines over pP,J q (and does so functorially); and since
composition is functorial, this deﬁnition yields a valid ps eudo functor.
A.2 Placing systems side-by-side
In order to understand morphisms of interfaces as wiring sys tems together, we
need to be able to place systems side-by-side, so that we can m ake sense of
the plural ‘systems’. This demands that we can ﬁrst compose i nterfaces “in
6 T. St Clere Smithe
parallel”, and second that our systems theories are such tha t we can take a
system over one interface and a system over another, and form a system over
the corresponding parallel composite interface. F ormally , this means we require
Int to be a monoidal category pInt,y, bq with parallel composition (‘tensor’) b
and unit (trivial) interface y, and that our systems theories are (lax) monoidal
with respect to this parallel composition. The latter requi rement means that we
need a natural transformation Sysppq ˆ Syspqq Ñ Sysppb qq (satisfying some
standard coherence conditions). The laxness of this struct ure means that this
transformation is not invertible: that is, not every system over a composite
interface pb qmay be decomposable into systems over the component interfa ces
p,q .
LenspSetq is monoidal, with tensor pO,I q b p A,B q “ p Oˆ A,I ˆ Bq and
unit p1, 1q. Moore is similarly lax monoidal, with the laxator MoorepO,I q ˆ
MoorepA,B q Ñ Moore
`
pO,I q b p A,B q
˘
deﬁned by mapping pS,ϑ q, pT,ψ q to
pSˆ T,ϑ b ψq.
A.3 Dynamic wiring
W e will see below that it can be useful to deﬁne systems with “d ynamic wiring”.
Recalling that ‘wiring’ corresponds to a morphism in a categ ory of interfaces
Int, a system that can change some wiring would need an interface type that
encapsulates morphisms of interfaces; that is, given inter faces q,r to be wired
together, we need an object in Int that ‘internalizes’ the set of morphisms
Intpq,r q. Such an object is called an internal hom , and we will denote it by
rq,r s.
F or rq,r s to behave like an internalization of Intpq,r q, it needs to exhibit a
‘currying’
1 relationship with b. That is, morphisms pbqÑ rmust be in bijection
with morphisms p Ñ r q,r s. In other words, we need a natural isomorphism
Intppb q,r q – Intpp, rq,r sq. (This makes rq, ´s right adjoint to ´ b q.) F rom
this natural isomorphism we can obtain 2 ‘evaluation’ morphisms rq,r s b q Ñ r
which say that, given a rq,r s-system and a q-system, we can wire the former into
the latter to obtain an r-system. Thus rq,r s-systems dynamically wire q-systems
into r-systems.
W e will use this structure to describe agents that manage oth er agents,
generalizing hierarchical (‘deep’) active inference.
A.4 Polynomial interfaces
A lens interface is a ﬁxed pair of sets, much as in classical ac tive inference. T o
capture systems whose interfaces may be mode- or context-de pendent
3, we need
1 The currying of a function f : A ˆ B Ñ C is the function f7 : A Ñ r B, Cs deﬁned
by the mapping a ÞÑ fpa,´q .
2 Set p “ r q, rs and then transport the identity morphism idrq,rs : rq, rs Ñ r q, rs from
the right-hand side to the left-hand side.
3 F or example, when I close my eyes, the sense-data that I recei ve (my ‘inputs’) are
diﬀerent from when I open them.
Structured Active Inference 7
the possible inputs to a system to be able to depend on the syst em’s state,
as revealed by its output. T o encode such dependence, we may u se polynomial
functors, whose morphisms are sometimes known as dependent lenses .
A polynomial p in one variable, denoted y, is an expression of the formř
i:I ypris . W e call I the indexing set and, for each i: I, pris is the exponent at
i. In high-school algebra, the variable y takes numerical values, the exponents
pris are all numbers, and the whole expression may be evaluated in to a number,
thus deﬁning a function. Here, we allow the variable y and exponents pris to
be valued in sets, noting that each natural number n may be understood as a
ﬁnite set rns with n-many elements. An exponential BA of sets is understood to
denote the set SetpA,B q of functions A Ñ B, so that each term ypris denotes
the ‘hom’ functor X ÞÑ Xpris , and the sum denotes the disjoint union of sets.
In this way , each polynomial p does indeed denote a functor Set Ñ Set. If we
evaluate this functor at the singleton set 1, we ﬁnd
pp1q “
ÿ
i:I
1pris –
ÿ
i:I
1 – I .
F or this reason, we will often write a polynomial p as ř
i:pp1q ypris .
Each polynomial p also corresponds to a (discrete) bundle of sets, given by
projecting from the disjoint union of the exponents 4 back to the indexing set.
That is, each p corresponds to a function
ÿ
i:pp1q
pris Ñ pp1q
pi,x q ÞÑ i.
Note that, if the exponents do not vary with the index, e.g. q “ ř
j:J yQ, then
the bundle corresponds to a product projection ř
j:J Q – J ˆ Q Ñ J. Such
‘non-dependent’ polynomials are called monomials and can be written as JyQ.
A morphism ϕ : p Ñ q of polynomial functors is a natural transformation.
One can show (using the Y oneda Lemma) that these natural tran sformations
correspond to pairs of functions pϕ1,ϕ 7 q as in the following commutative diagram,
where the square on the right is a pullback square:
ř
i:pp1q pris ř
i:pp1q qrϕ1piqs ř
j:qp1q qrjs
pp1q qp1q
p
ϕ7
ϕ˚
1 q
{
q
ϕ1
Alternatively , ϕ7 may be understood as a pp1q-indexed family of functions
tϕ7
i : qrϕ1piqs Ñ prisui:pp1q. Thus we have a ‘forwards’ function ϕ1 and a pp1q-
dependent ‘backwards’ function ϕ7 .
4 The elements of ř
i:pp1q pris are pairs pi, xq of i P pp1q and x P pris.
8 T. St Clere Smithe
Polynomial functors and their morphisms constitute a categ ory Poly. The
composition of ϕ : pÑ q and ψ : qÑ r is given by pψ1 ˝ ϕ1,ϕ 7 ˝ ϕ˚
1 ψ7 q. W ritten
in indexed form, the backwards components are
rrψ1pϕ1piqqs
ψ7
ϕ 1piq
Ý Ý Ý Ý Ñqrϕ1piqs
ϕ7
i
Ý Ñpris .
W e mentioned above that morphisms between polynomial funct ors may
be understood as ‘dependent’ lenses. T o make this perspecti ve clearer, we
observe that LenspSetq embeds into Poly. Each lens object pO,I q corresponds
(bijectively) to a monomial OyI. Each lens pO,I q Ñ p P,J q is then exactly a
morphism OyI Ñ PyJ. W e can therefore think of the exponents of a polynomial
as ‘mode-dependent’ input types, and the indexing sets as po ssible outputs.
Alternatively , we may understand pp1q as the set of “possible conﬁgurations”
that a p-shaped system may adopt; and each pris is the set of possible incoming
signals in conﬁguration i, or the “ i-context-dependent sensorium”.
A.5 T ensor and internal hom of polynomials
Poly has a ‘parallel’ tensor product b with unit y. p b q is deﬁned as the
polynomial ř
pi,j q:pp1qˆ qp1q yprisˆ qrjs ; likewise, one takes products on morphisms.
It is easy to verify that yb p– p– pb y, and that this product is symmetric,
pb q– qb p.
This tensor structure py, bq has a corresponding internal hom r´ , “s . On
objects, the internal hom may be deﬁned by
rp,q s “
ÿ
ϕ:pÑq
y
ř
i:pp1q qrϕ1piqs .
(Given morphisms ϕ : p1 Ñ p and ψ : q Ñ q1 , we leave the deﬁnition of rϕ,ψ s :
rp,q s Ñ r p1 ,q 1 s as an exercise for the reader.)
W e therefore think of the conﬁgurations of rp,q s as encoding wirings from
p to q; and, for each such conﬁguration ϕ, the inputs rp,q srϕs are the inputs
demanded by ϕ7 — thus, the data required to pass inputs to any p-system wired
by ϕ into q.
F or much more on polynomial functors, we refer the reader to t he wonderful
book by Niu and Spivak [
5].
A.6 Generative models as stochastic Moore machines
Above (§ A.1), we introduced the theory of Moore machines over LenspSetq,
where we saw that a Moore machine on pO,I q is a choice of state space Sand lens
pS,S q Ñ p O,I q. W e have just seen that LenspSetq is the monomial subcategory
of Poly, so a (non-dependent) Moore machine over pO,I q may alternatively be
deﬁned as a Poly morphism SyS Ñ OyI for some set S. This yields a ﬁrst
generalization: a dependent Moore machine with polynomial interface pis a pair
Structured Active Inference 9
pS,ϑ q where S is a set and ϑ a morphism SyS Ñ pin Poly. By similar reasoning
to that in § A.1, this yields a systems theory DMoore : Poly Ñ Cat.
The reader may have noticed a similarity between the data of a Moore
machine ϑ : SyS Ñ OyA — consisting of an output map (or ‘likelihood’)
ϑo : S Ñ O and an update map (or “transition function”) ϑu : S ˆ A Ñ S
— and a (discrete-time) generative model with state space S, observations O,
and actions A. There are two key diﬀerences: a generative model is a stochastic
transition system; and it is usually understood as being equ ipped with a ‘prior’
distribution (a stochastic initial condition) on the state space S.
Let us address the ﬁrst diﬀerence ﬁrst, deﬁning a systems the ory Gen :
Poly Ñ Cat of stochastic dependent Moore machines, which we take as a mo de-
dependent generalization of classical generative models. T o keep the exposition
simple, we will restrict ourselves to discrete probability distributions, which may
be deﬁned over any set. If X is any set, we will write DX to denote the set of
such distributions over X. That is,
DX “
#
p: X Ñ r 0, 1s
ˇ
ˇ
ˇ
ˇ
ˇ
ÿ
x:X
ppxq “ 1
+
.
F or the sum over X to be well-deﬁned, p P DX may only be supported on a
countable subset of X.
Given any function f : X Ñ Y, we have a function Df : DX Ñ DY deﬁned
by ‘pushforward’: if p P DX, then Dpfqppq is the distribution mapping y P
Y to ř
xPf´ 1tyu ppxq. (The pushforward distribution Dpfqppq is sometimes also
denoted by f˚ p.) This makes D into a functor Set Ñ Set.
A conditional probability distribution qpy|xq then corresponds to a function
X Ñ DY; note that, by currying, this is equivalent to a stochastic m atrix
X ˆ Y Ñ r 0, 1s. If q : X Ñ DY and r : Y Ñ DZ are two stochastic matrices,
then they may be composed by matrix multiplication to yield a conditional
distribution r‚ q : X Ñ DZ deﬁned by pr‚ qqpz|xq “ ř
y:Y rpz|yq qpy|zq. Thus
conditional distributions form the morphisms of a category , FinStoch. These
morphisms are also known as stochastic maps or channels. W e will denote a
channel X Ñ DY by X ù Y The identity channel X ù X is deﬁned by
mapping x to the Dirac delta distribution at x; this mapping is sometimes
denoted ηX. Every function f : X Ñ Y yields a channel δf : X ù Y deﬁned
by X
f
Ý ÑY
ηY
Ý Ý ÑDY.
A (discrete-time, discrete-space) Markov chain thus corre sponds to a channel
X ù X, for some state space X. W e will use this correspondence to deﬁne the
systems theory Gen.
Given a polynomial p, we deﬁne the objects of Genppq to be triples pS,ϑ o,ϑ uq
where S is a set, ϑo is a function S Ñ pp1q and ϑu is a channel ř
s:Sprϑopsqs ù
S. W e will call these generative models or stochastic dependent Moore machines
with interface p. A morphism f : pS,ϑ q Ñ p S1 ,ϑ 1 q in Genppq is a channel f :
S ù S1 such that f ‚ ϑu “ ϑ1 u ‚ p f ˆ idq. Morphisms of generative models
compose by channel composition.
10 T. St Clere Smithe
Given a dependent lens ϕ : p Ñ q, we obtain a functor Genpϕq : Genppq Ñ
Genpqq by post-composition, almost exactly as for Moore machines. Thus, Genpϕq
maps a model pS,ϑ o,ϑ uq over p to the model pS,ϕ 1 ˝ ϑo,ϑ u ‚ δϑ˚
o ϕ7 q. More
explicitly , the update channel is here given by the composit e
ÿ
s:S
qrϕ1pϑopsqqs
δϑ ˚
o ϕ 7
ù
ÿ
s:S
prϑopsqs ϑu
ù S
whose ﬁrst component is the deterministic channel induced b y the function ϑ˚
oϕ7 .
It is easy to check that this deﬁnition preserves morphisms o f models and thus
yields a valid pseudo functor Gen : Poly Ñ Cat.
It will be important in the sequel that Gen is monoidal, so that we can
place generative models in parallel. Thus, we need a family o f functors λp,q :
Genppq ˆ Genpqq Ñ Genppb qq natural in the polynomials p,q . These are deﬁned
as follows.
First, note that there is a family of functions DX ˆ DY Ñ DpX ˆ Yq,
natural in the sets X and Y, given by mapping α P DX and β P DY to the joint
distribution α b β whose independent marginals are α and β. That is, α b β is
deﬁned by mapping px,y q P Xˆ Y to the probability αpxq βpyq. (Note that this
b is not the same as the tensor on Poly; it is rather the tensor on FinStoch.)
Next, we deﬁne λp,q using these functions. If ϑ “ p S,ϑ o,ϑ uq is a model
over p and χ “ p T,χ o,χ uq is a model over q, then λp,q pϑ,χ q is deﬁned by
pSˆ T,ϑ o ˆ χo,ϑ u b χuq. In turn, ϑu b χu is deﬁned by the function
ÿ
ps,tq:Sˆ T
prϑopsqs ˆ qrχoptqs
ϑuˆ χu
Ý Ý Ý Ý ÑDSˆ DT bÝ ÑDpSˆ Tq .
If f : pS,ϑ o,ϑ uq Ñ p S1 ,ϑ 1
o,ϑ 1 uq and g: pT,χ o,χ uq Ñ p T1 ,χ 1
o,χ 1 uq are morphisms
in Genppq and Genpqq respectively , then λp,q pf,g q is the morphism λp,q pϑ,χ q Ñ
λp,q pϑ1 ,χ 1 q deﬁned by the function
Sˆ T
fˆ g
Ý Ý Ý ÑDS1 ˆ DT1 bÝ ÑDpS1 ˆ T1 q .
One may then check that this makes λp,q into a functor, and that this deﬁnition
is natural in p and q (i.e., that it respects morphisms on both interfaces).
Remark. T o check that Gen really does correspond to classical (discrete time
and space) generative models means checking how it behaves o ver monomials
OyA. The objects of GenpOyAq are triples pS : Set,ϑ o : S Ñ O,ϑ u : Sˆ Aù Sq.
Thus they are almost, but not quite, exactly classical generative models: the
output maps are still deterministic by this deﬁnition.
The reason for this is technical: in general, it is so that the pullback setř
s:Sprϑopsqs is well deﬁned. In the monomial case, there is no problem havi ng
stochasticity in ϑo, because the deﬁning expression should evaluate to Sˆ A in
any case. But it is less simple to make sense of the expression ř
s:Sprϑopsqs when
ϑo is a stochastic map (although there are ways to do so).
Structured Active Inference 11
Nonetheless, this is not in the end a problem, because if we wa nt a stochastic
‘likelihood’, we can fold it into the update channel. That is , we can let the state
space be S ˆ pp1q, the output map be the projection S ˆ pp1q Ñ pp1q, and
the update channel be deﬁned by ř
ps,iq:Sˆ pp1q pris
pϑu,ϑ lq
ù S ˆ pp1q, where ϑu
is a ‘transition’ channel ř
ps,iq:Sˆ pp1q pris ù S and ϑl is a ‘likelihood’ channel
S ù pp1q, so that pϑu,ϑ lq maps ps,i,x q to ϑups,i,x q b ϑlpsq.
Alternatively , we could make an alternative deﬁnition of Gen so that a model
over p consists of a quintuple pS,O,ϑ l,ϑ o,ϑ uq where S and O are sets, ϑl is a
likelihood channel S ù O, ϑo is an output function O Ñ pp1q, and ϑu is an
update channel ř
o:Oprϑopoqs ù S. W e made the deﬁnition we did because it
keeps the amount of data to a minimum and maintains a close ana logy with
deterministic Moore machines.
W e end this section by noting that priors over states are simp ly additional
data attached to a generative model. Thus we can deﬁne a varia nt of Gen, denoted
Gen˚ , where the objects of each Gen˚ ppq are be tuples pS,ϑ,π q where pS,ϑ q is
an object of Genppq and π : 1 ù S is a distribution over S. W e may similarly
extend the deﬁnition of morphism so that a morphism f : pS,ϑ,π q Ñ p S1 ,ϑ 1 ,π 1 q
in Gen˚ ppq is a morphism f : pS,ϑ q Ñ p S1 ,ϑ 1 q in Genppq satisfying the additional
condition that π1 “ δf ‚ π. With this deﬁnition, there is a canonical indexed
functor Gen˚ ñ Gen that simply forgets the data of the priors. W e will see
below (§ B.5) that this is a basic example of a logical structure over Gen.
A.7 Agents’ control systems are dual to their generative mod els
The preceding section introduced structured generative mo dels, but an active
inference agent is more than just a generative model: it is a m odel along with
a system for ‘controlling’ the model, supplying inputs (act ions) that minimize
expected free energy , in an attempt to minimize the divergen ce between how the
world is inferred to be (from the observations) and how the wo rld is expected to
be (from the transition model).
In active inference, an important distinction is made betwe en the generative
model, which forms part of an agent, and the generative process, which may be
quite diﬀerent from the generative model, but which is under stood as the “ground
truth” generator of the agent’s observations (and which is t he ‘true’ recipient of
the agent’s actions). The generative model is used by the age nt to predict how
the generative process ( i.e., how the ‘environment’) will respond to its actions.
In order to make such a prediction — in order to ‘unroll’ the ge nerative model
in time — the agent must supply it with actions, which are chos en by the agent’s
control system. F ormally , this means that the generative mo del along with the
control system must form a closed system (a system on the triv ial interface y),
because closed systems are those that can be evolved autonom ously , without
external input.
If the generative model has interface p, then this means that the control
system should have interface rp,y s, because (as we saw in § A.3) there is a
12 T. St Clere Smithe
canonical morphism rp,y s b pÑ y. Thus any p-system (any p-generative model)
may be canonically coupled to a rp,y s-system (a p-controller) to produce a closed
system (with interface y), which may be unrolled.
Let us verify that this abstract reasoning captures the stru cture of a classical
active inference agent with interface OyA. W e have already seen that its
generative model comprises a state space S, a stochastic transition function
Sˆ Aù S, and a ‘likelihood’ S Ñ O. The dual
5 of OyA is rOyA,y s “ AOyO.
A Moore machine on this interface comprises a state space T, an output map
T Ñ AO, and an update map T ˆ O Ñ T. By currying, we can equivalently
write the output map as Tˆ OÑ A. If we let the state space T be DS, then our
two maps ﬁnally have the types DSˆ OÑ Aand DSˆ OÑ DS. The latter is
the type signature of Bayesian inversion [ 7], so this map may be understood as
performing state inference (‘perception’). The former may then be understood
as performing action selection, and we may call it the policy; in active inference,
this is achieved by the minimization of expected free energy .
By inspection, we can therefore see that the pair of a generat ive model over
OyA and a Moore machine over rOyA,y s captures all the data of a classsical
active inference agent. This licenses the following import ant deﬁnition.
Deﬁnition A1. An agent with polynomial interface pand state space Sconsists
of a generative model over p with state space S, along with a controller for the
generative model: a Moore machine over rp,y s with state space DS. The output
map of the controller is the agent’s policy, performing action selection; the update
map of the controller performs inference.
W e emphasize again that the agent’s interface p generalizes the classical
notion of the Markov blanket of its generative model.
A.8 Animated categories: generative Poly
The preceding exposition has discussed individual agents, and justiﬁed the
constructions using ‘shallow’ generative models with inte rface OyA. But active
inference purports to model agents in complex contexts, int eracting with other
agents; and even a single agent is often supposed to have some ‘deep’ or
hierarchical structure [
8].
W e can incorporate such situations easily into the structur ed active inference
framework, by noticing that p – r y,p s. Thus, we can equivalently deﬁne a
‘simple’ agent with interface p as a model over ry,p s coupled to a controller
over rp,y s. If an agent is embedded into a more complex context, we can mo del
this by replacing the trivial interface y with an interface q describing the “outer
boundary” of the interaction context. Thus a ‘complex’ agen t with interface p
in context q may be deﬁned as a model over rq,p s along with a controller over
rp,q s.
5 Mathematically, many dualities are obtained by “homming in to a unit object” [ 6],
which is precisely the situation we have here.
Structured Active Inference 13
This situation may be rendered fully compositional using th e monoidal
structure of Gen and Moore, formalized in the framework of animated categories
[9]. The key observation here is that the internal hom structur e r´ , “s induces
an “internal composition” operation in the category of inte rfaces Poly: there are
morphisms rp,q s b r q,r s Ñ r p,r s which act to “compose along q”, and these are
natural in p,q,r . This is to say that Poly is enriched in itself.
In general, whenever we have a category C enriched in a category V, and
a monoidal functor F : V Ñ V1 , we can “change the enrichment of C along
F”, to produce a category F˚ C enriched in V1 . Here, we have a category Poly
enriched in Poly, and a (pseudo) functor Gen : Poly Ñ Cat. Thus we can
produce a category Gen˚ Poly enriched in Cat — that is, a bicategory. W e call
Gen˚ Poly generative Poly. (This is animation: change of enrichment along a
systems theory .)
The objects of Gen˚ Poly are polynomials, and the hom-category from p
to q is Genprp,q sq. Thus a 1-morphism p Ñ q is a generative model on rp,q s
and a 2-morphism is a corresponding morphism of systems. If w e have a model
pÑ q and a model qÑ r, we can compose them using the internal composition
structure. W e will see below (§ B.3) that this is a precise generalization of what
happens in deep/hierarchical active inference that allows for richer situations
like “agents that manage agents”.
B Exempliﬁcation
B.1 APIs as polynomial interfaces
Polynomial functors are closely related to trees [
10] and tree-structured data,
like typed syntax [ 11]: the allowed inputs to a formal operation depend on the
operation in question, and its output may be passed as an inpu t to a subsequent
operation, so long as the types match. Thus, a formal grammar corresponds to
a polynomial functor p, and the set of p-terms with inputs in a set X is the
set ppXq; an interpretation of the syntax in a set Y is then given by a function
ppXq Ñ Y.
In this way , if we have a computer application programming in terface (API)
or domain-speciﬁc language (DSL), we can encode its interac tion pattern as
a polynomial functor p; and if we wish to construct an artiﬁcial agent that
interacts with the corresponding computer system, we can eq uip it with an
interface derived from p.
As a simple example, we might consider a ‘calculator’ langua ge with two
binary operations t` , ˆu , one unary operation t´u , and R-many constants. This
would correspond to the polynomial functor p“ t` , ˆu y2 ` t´u y` R. A machine
that takes an expression with inputs in X and outputs a real number could then
have the interface RypX; and a model of such a machine with
W e note that this interface is, in the end, monomial. But if we had a more
complex language with diﬀerent possible output types, we co uld encode these
as a family of polynomials tpju, yielding a machine with interface ř
jOjypj Xj ,
where Oj is the output type for pj.
14 T. St Clere Smithe
Finally , let us note that this short section only scratches t he surface of the
the connection between polynomial interfaces and typed lan guages.
B.2 Typed policies, structured spaces: actions as morphism s
In classical active inference, a policy is a sequence of acti ons. Because all actions
are valid in all states (as necessitated by the monomial form alism), any sequence
of actions is a valid policy . In structured active inference , only certain actions are
valid at each state, so only certain sequences constitute va lid policies. F ollowing
the link between polynomial functors and typed languages sk etched in the
preceding section, one could say that, in structured active inference, policies
are typed: they are sequences of composable actions.
In some situations, this result can be strengthened: every c ategory C yields a
polynomial c “ ř
x:C0 y
ř
y:C0 Cpx,y q whose conﬁgurations are the objects of C and
whose actions at each object x are the morphisms out of x. W e can think of a
category as an abstract structured space: morphisms out of xcorrespond to paths
away from x. Alternatively , we can think of a category as a (non-determi nistic6)
automaton, whose states are the objects, and whose transiti ons out of each state
x are the morphisms out of x. In such a setting, a policy really is a composable
sequence of morphisms.
W e emphasize that this is a powerful strengthening of the cla ssical notion of
policy .
On the practical side, this strengthening allows us to apply active inference to
manipulate structured contexts in a principled way . Any suc h structured context
may usually be expressed in a categorical way , and using this homoiconicity ,
we may attach a structured active inference agent to it. In th is way , structured
agents may manipulate their own (or other agents’) structur e, thereby answering
the question posed at the opening of this extended abstract. W e will consider
this ability in more detail below (§ B.4).
On the ethical side, the strengthened notion of policy const itutes a step
towards safer artiﬁcial agents, ﬁrst because policies may b e type-checked,
and second because categories often come with an “internal l ogic”, in which
propositions may be formulated, and against which policies may be veriﬁed. W e
will sketch more in this area below (§ B.5).
B.3 Hierarchical agents: systems that manage systems
In §
A.8, we indicated that structured active inference extends nat urally to
‘nested’ systems of agents, including to the special case of individual agents
with a ‘deep’ or hierarchical structure, by extending the in terface of a generative
model from p– r y,p s to rq,p s for some polynomial q. Here, we sketch how this
plays out.
6 If we work with categories enriched in weighted sets, meanin g each morphism is
equipped with a weight, then we can think of such a category as representing a
stochastic automaton; or as having paths equipped with a len gth.
Structured Active Inference 15
The basic idea is to see q as encoding the interface(s) of systems that may
be nested within p, just as a dependent lens qÑ p encodes the wiring of q into
p. The polynomial q might itself be composed as the tensor of a number of other
polynomials, such as q“ q1 b q2 b q3. Then a system in Gen˚ Polypq1 b q2 b q3,p q
could be understood as one that builds a high-level agent out of three lower-level
ones. W e could think of such a system as a ‘manager’ for the tqiu systems,
bringing them together to form a ‘collective’ with interfac e p. Then, if we had
three lower-level systems tyÑ qiu, we could tensor them together and compose
them with the manager q1 b q2 b q3 Ñ p to instantiate the collective yÑ p.
Of course, an active inference agent is composed of a system a nd its dual
(§ A.7), so to achieve a compositional description of nested agent s, we need to
incorporate both parts of the structure. This is easily done .
Deﬁnition B1. Let the bicategory Agent be the ‘diagonal’ sub-bicategory of
Gen˚ Poly ˆ p DMoore˚ Polyq op whose objects are pairs pp,p q of two copies of a
polynomial p; we will write these objects simply as p. Additionally , restrict the
state spaces of the 1-cells to be pairs pS, DSq where Sis a set. Thus a 1-morphism
q Ñ p is a pair of a model in Gen˚ Polypq,p q and a corresponding controller in
DMoore˚ Polypp,q q.
Let us consider then a ‘manager’ agent ByC b DyE Ñ OyA; recall that
ByC b DyE – p Bˆ DqyCˆ E. Such an agent consists of:
(a) a state space S;
(b) three output maps (‘ likelihoods’):
(i) Sˆ Bˆ D Ñ O, predicting a high-level observation in O, on the basis
of the state and the low-level predictions/observations in B and D;
(ii) S ˆ B ˆ D ˆ A Ñ C, returning a low-level action in C (for the left
low-level agent), on the basis of the state, the low-level ob servations,
and the high-level action in A;
(iii) S ˆ B ˆ Dˆ A Ñ E, returning a low-level action in E (for the right
low-level agent), on the basis of the state, the low-level ob servations, and
the high-level action in A;
(c) a transition channel Sˆ Bˆ Dˆ Aù S, updating the state, given low-level
observations and high-level action;
(d) generative processes for both low-level agents’ observations, on the basis of
the state and the high-level observation;
(i) DSˆ OÑ B, for the left low-level agent;
(ii) DSˆ OÑ D, for the right low-level agent;
(e) a high-level policy, DSˆ Oˆ Cˆ E Ñ A, possibly depending on all of: the
state, the high-level observation, and the low-level actio ns;
(f) an inference process, DS ˆ Oˆ C ˆ E Ñ DS, inferring the current state
given a prior, a high-level observation, and low-level acti ons (which we take
to be observed).
As we have seen above (§ A.7), an agent with interface ByC is constituted by
(a) a state space T,
16 T. St Clere Smithe
(b) an output map T Ñ B (yielding the low-level agent’s prediction of the
high-level agent’s generative process),
(c) a transition channel T ˆ C ù T,
(d) a policy DT ˆ B ù C, and
(e) an inference process DT ˆ B ù DT.
A similar structure is of course obtained for the other low-l evel agent (on CyE).
Then the composition of the low-level agents to the manager a gent proceeds by
passing:
(a) the manager’s low-level action outputs to the low-level agents’ transition
models;
(b) the low-level agents’ predicted observations to the man ager’s transition
model;
(c) the manager’s generated observations to the low-level a gent’s policies and
inference processes; and
(d) the low-level agents’ actions (selected by their polici es) to the high-level
agent’s policy and inference process.
Put together, this composite agent has the interface OyA; the internal composi-
tion is hidden within this “generalized Markov blanket”.
W e emphasize that all of this compositional structure is obt ained from the
rules of the Agent construction; in principle, it is fully automatable. Moreo ver, it
extends gracefully to arbitrary levels of nesting, with com plex internal structure.
Deep active inference is a special case. W e end this section by sketching
how the Agent construction captures deep active inference, in the sense o f
F riston et al. [ 8].
A deep active inference agent has a hierarchy of generative m odels: the
outputs (the ‘predictions’) at one level act on the level bel ow, where they are
taken as a ‘control’ or ‘policy’ input. (It may also be the cas e that each level also
produces predictions of other observations, but these are e ﬀectively extraneous,
in that they have no direct eﬀect on the evolution of the model .)
This pattern is easily captured by a sequence of 1-cells
yÑ yA1 ¨ ¨ ¨ Ñ yAi Ñ yAi` 1 ¨ ¨ ¨
in Agent, where the increasing index i corresponds to increasingly high levels
in the hierarchy . W e leave it to the reader to write out the det ails and check
the correspondence. (One may simply recapitulate the examp le above, taking
B “ D “ E “ O “ 1 and letting C,E correspond to two levels Ai,A i` 1 of the
action hierarchy .)
B.4 Meta-agents: changing internal and external structure
In §
B.2, we explained that categorical structures can be encoded in polynomial
interfaces. Because structured active inference collects agents, and their struc-
ture, into categories, this makes it able to act on itself.
Structured Active Inference 17
Crucially , the models Genppq over each interface p form a category , whose
morphisms represent changes of internal structure. And the morphisms between
interfaces (of course) represent changes of interface.
These two types of change can be bundled together by applying the
Grothendieck construction to Gen. This yields a category
ş
Gen whose objects
are triples pp,S,ϑ q where p is an interface in Poly and pS,ϑ q is a model in
Genppq. A morphism pp,S,ϑ q Ñ p p1 ,S 1 ,ϑ 1 q in
ş
Gen is then a pair of a dependent
lens ϕ : p Ñ p1 and a morphism of systems GenpϕqpS,ϑ q Ñ p S1 ,ϑ 1 q. Thus
the morphisms of
ş
Gen are morphisms of interfaces along with compatible
morphisms of systems.
One could then consider an agent whose interface combines th e polynomial
induced by
ş
Gen with observations on “the current interface”, as in
ÿ
pp,S,ϑ q:
ş
Gen
pp1q y
ř
pp1 ,S 1 ,ϑ 1 q
ş
Gen
`
pp,S,ϑ q,pp1 ,S 1 ,ϑ 1 q
˘
.
Such an agent would predict both a structure for an agent alon g with the
observations that that agent should expect, and its policy w ould be a sequence
of changes-of-structure (which include standard operatio ns like model expansion
and model reduction). By minimizing free energy , one might i magine that such
an agent would seek a structure that best explains its observ ations: it would be a
structure-learning agent. Planning (policy search) for such an agent would involve
exploring diﬀerent potential structures, which we can inte rpret as explanations
for the observed data.
This approach can be extended to hierarchical agents, turni ng Agent into a
double category 7. But we will not expand on this here, except to note that
this brings structured active inference even closer to othe r developments in
categorical cybernetics [ 12– 14]. W e leave this conﬂuence to future work.
B.5 The logic of systems: goals, constraints, and safety
Let us end this tour of structured active inference with a not e on the logic of
systems. W e indicated in §
A.6 that agents’ state priors can be understood as
a basic example of a logical structure. This is due to the (ind exed) forgetful
functor U : Gen˚ Ñ Gen. All that is required to bring logic into a categorical
situation is the ability to deﬁne a notion of ﬁbration in that setting; and indeed
the setting of categorical systems theory is suﬃciently ric h to do so (because
systems theories collect into a 2-category).
The forgetful functor U is a simple instance of a ﬁbration of systems theories.
In a logical context, one thinks of the ﬁbre Uϑ over an object ϑ as a category
of ‘predicates’ over ϑ. The reindexing operation entailed by the ﬁbration may
be interpreted as substitution of terms inside the formal ex pressions of these
7 The horizontal morphisms would be agents; the vertical morp hisms would be changes-
of-interface; and the squares would be changes-of-structu re compatible with the
corresponding changes-of-interface.
18 T. St Clere Smithe
predicates. When the situation is suﬃciently rich, these su bstitution functors
have left and right adjoints which correspond to existentia l and universal
quantiﬁcation in these predicates.
W e will not elaborate the details of the categorical logic of systems further
here, referring the interested or intrepid reader instead t o Jacobs [
2] (and the
task of translating that work to the systems-theoretic sett ing). But we will note
that it is of course possible to produce more interesting ﬁbr ations of predicates
than U, with more expressive capability; and we will be able to use t hese to
specify not only goals for systems, but also constraints on t heir behaviour (their
policies). Moreover, because these logics are indexed by th e systems’ patterns
of interaction, we will be able to judge the extent to which su ch constraints are
satisﬁed in diﬀerent interaction contexts 8. W e expect that these abilities will be
useful for distributing shared goals amongst collectives o f agents, and crucial in
the development of veriﬁably safe (‘safeguarded’ [ 3]) AI systems.
8 This is formally much like the situation with ﬁxed points: th e ﬁxed points of a
composite dynamical system may be computed from the ﬁxed poi nts of the composite
systems, plus knowledge of their pattern of interaction [ 15]