A New Approach for Knowledge Generation Using Active
Inference
Jamshid Ghasimia∗ Nazanin Movarraeib†
a Prof. Hessaby foundation, Tehran, Iran
b School of Mathematics, Institute for Research in Fundamental Sciences
(IPM), P.O. Box: 19395-5746, Tehran, Iran
Abstract
There are various models proposed on how knowledge is generated in the human brain
including the semantic networks model. Although this model has been widely studied and
even computational models are presented, but, due to various limits and ineﬃciencies in the
generation of diﬀerent types of knowledge, its application is limited to semantic knowledge
because of has been formed according to semantic memory and declarative knowledge and
has many limits in explaining various procedural and conditional knowledge. Given the im-
portance of providing an appropriate model for knowledge generation, especially in the areas
of improving human cognitive functions or building intelligent machines, improving existing
models in knowledge generation or providing more comprehensive models is of great impor-
tance. In the current study, based on the free energy principle of the brain, is the researchers
proposed a model for generating three types of declarative, procedural, and conditional knowl-
edge. While explaining diﬀerent types of knowledge, this model is capable to compute and
generate concepts from stimuli based on probabilistic mathematics and the action-perception
process (active inference). The proposed model is unsupervised learning that can update itself
using a combination of diﬀerent stimuli as a generative model can generate new concepts of
unsupervised received stimuli. In this model, the active inference process is used in the gener-
ation of procedural and conditional knowledge and the perception process is used to generate
declarative knowledge.
Keywords: semantic network, knowledge generation, free energy principle, active inference
1 Introduction
How knowledge is generated in the human brain is very important because of its eﬀect on the
study of cognitive features and functions such as problem-solving, judgment, or decision making
[38, 30, 26]. At the same time, ﬁnding appropriate models for knowledge generation by the brain can
pave the way for the realization of intelligent machines that, unsupervised, can generate knowledge
and use it in processes related to their cognitive features and functional goals.
Human knowledge is formed based on the contents of its memory, therefore, given the function
∗Email: jgh1001@yahoo.com
†Email: nazanin.movarraei@gmail.com
1
of memory and diﬀerent features of knowledge, human knowledge can be classiﬁed into three
categories: declarative knowledge, procedural knowledge, and conditional knowledge. Declarative
knowledge is about what a phenomenon or object is, and procedural knowledge is about how
things are done. Conditional knowledge leads to guiding a person in applying both declarative and
procedural knowledge [1, 22, 32, 51].
Various models for knowledge generation are mostly focused on one or at most two categories
of knowledge. In addition, the process of knowledge generation in the existing proposed models
is more descriptive and lacks computational steps or process analysis that can be converted into
computational algorithms. At the same time, no model can address all three types of knowledge
in an integrated manner. One of the most important and widely used models is the semantic
networks model, which provides a model for generating semantic knowledge using the relationship
between concepts. This model refers only to the generation of declarative knowledge and there is
very limited information on procedural or conditional knowledge generation and expression. The
model of semantic networks is based on semantic memory and despite the advances that have been
made to compute it; it has many limitations in providing a computational model for generating
procedural or conditional knowledge.
The current paper presents a model for the generation of declarative knowledge that simultaneously
supports, analyzes, and generates procedural and conditional knowledge computationally. The
proposed model takes into account concepts, the relationship between concepts, and the features
or stimuli of concepts generators. Concepts or objects are the smallest unit of declarative knowledge
formation in a semantic network structure or knowledge generation. This model is based on the
free energy principle (FEP) in the brain, which shows the process of generating concepts from
stimuli [5, 22]. For this purpose, while reviewing the FEP model and examining its variables, the
model has been adapted in a way that can show how to generate diﬀerent types of knowledge.
Finally, a model is presented that, while being able to compute diﬀerent types of knowledge, can
also show the process of knowledge generation. This model shows the process of learning and
updating knowledge and generating concepts under diﬀerent conditions such as meaning-making
using stimuli, executive and procedural functions, as well as the acquisition of executive skills [19].
In terms of computation or modeling, this model uses the inference attribute of the human mind
to generate concepts by receiving sensory stimuli [23].
2 Semantic memory and the formation of semantic
Declarative knowledge is the result of the data in semantic memory processed by the brain [11, 43].
Perception of concepts, and their stimuli and the relationship between diﬀerent concepts based on
the commonalities in their stimuli form declarative knowledge. Stimuli, because of the features
of concepts, generate new concepts that are then stored in memory. It should be noted that in
semantic memory, the meaning of a concept is preserved and not the word itself or the grammatical
features of a conceptual sentence. Concepts are generated through their stimuli. In other words,
concepts are hidden variables in the environment that can be discovered or inferred through stim-
uli.
In addition, declarative knowledge can be presented orally (linguistically) and in writing. In this
case, declarative knowledge is generated by information that is constructed as a hierarchy in the
semantic memory and the form of a network consisting of concepts and their relationships (seman-
tic networks) [31].
Each concept could have several stimuli. The stimuli of each concept can be varied and abundant,
which depending on the observer may diﬀer in quality and number, however, most concepts and
2
objects in the environment create stimuli that aﬀect the observer factors equally. Networks of
interconnected concepts are constructed about the semantic networks, which may diﬀer depending
on the type of culture, or the capabilities of agents (observers).
Thus, semantic knowledge is the result of input perceptions and inference of these perceptions,
which is stored in semantic memory as a communication network. This network creates semantic
organization, which allows the agent to retrieve information. This type of semantic network is in
a hierarchical manner and a combination of concepts in the form of nodes and relationships be-
tween concepts. A graphical representation of a semantic network is shown in Figure 1 [4] relation
between concepts is represented by arrows. In Figure 1 semantic network, Is A means a direct
link between two concepts, for example, ”stork is a bird” or Capable of means the ability of one
concept to perform another.
Semantic networks are presented in diﬀerent forms or models with similarities and diﬀerences
[33, 29, 47, 50] but the common feature of all is the on concepts and the stimuli of concepts to
separate or categorize concepts. These models include [12, 40]:
- Feature comparison model: Concepts are categorized by matching their stimuli, and according
to the stimuli of the target group.
- Hierarchical network model: Concepts are organized by using hierarchical relationships in the
semantic network.
- Spreading activation model: This model emphasizes interconnected concepts. Concepts once ac-
tivated in the mind, expand along network paths and activate other concepts, however, the farther
away from the original concept, the less active the subsequent concepts become. This model shows
a clear picture of the semantic relationships between concepts that decrease over time.
Semantic network models, despite their many strengths in explaining the memory functions that
lead to knowledge generation, also have weaknesses. For some concepts, the hierarchical model may
not ﬁnd a feature that puts it at one of the levels of the hierarchy, or it may even have some kind
of contradiction in predicting the levels of the hierarchy for some concepts. In addition, this model
neglects the typical eﬀect. The identiﬁer eﬀect states that members who are more identiﬁable at
one level are easier to categorize than less representative members are. The success of the scalable
activation model also signiﬁcantly depends on the proper explanation of the test results; other-
wise, it is considered an ineﬃcient model, although it well demonstrates the ability of semantics
preparation. Semantic network models are so ﬂexible that sometimes this ﬂexibility makes them
impossible to predict. The process of knowledge generation in semantic networks is the result of
stimuli generation and the relationship of received concepts with stimuli. This feature of semantic
networks represents a Markovian model [52, 2] that has the following two basic features:
- Concepts are not fully known, understanding or inferring each does not mean inferring all existing
concepts, and they are known as hidden variables that must be inferred through stimuli. So that
in terms of the agent, some concepts can be understood through inference, and some are hidden
in the environment.
- Each concept is deduced under a probabilistic process through its stimuli generated by that con-
cept. Given the models of semantic networks, the way of generating semantic knowledge is the
result of converting continuous perceptual signals into discrete concepts using the Markovian model.
3 The relationship between concepts and stimuli
In an interaction between man and the environment and the connection between the two, each
concept is shaped by its stimuli. Depending on whether the concepts are sensory or associative,
3
their properties are perceived by the agent through sensory perceptions or other data such as ver-
bal or written data. As soon as the environmental stimuli are received by the brain, either the
previous concepts are activated and primed, or a new concept will be generated. For example,
when an agent hears a dog barking while simultaneously observes the shape of a dog, the concept
of a dog comes to mind. In this case, sound and image, which are received through the two sen-
sory modalities of phonology and vision, will be formed as stimuli and the dog itself as a concept
[15, 14]. Each concept is perceived as a combination of stimuli. Several sensory or abstract stimuli
can be considered that are located in the brain and memory for priming several concepts. Dogs,
for example, have an objective meaning derived from sensory stimuli, while the word justice has
an abstract meaning [14]. Of course, concepts can have both objective and abstract properties,
such as the word home.
If n is several concepts, then m stimuli can be considered for all of them. Some of these stim-
uli may be common to diﬀerent concepts; synonyms are formed if several concepts share all of
their stimuli. The concepts and the stimuli sets have been shown as follows:
Concepts set : S = {s1,...,s n}
Stimuli set : R = {r1,...,r m}
Where n is the number of concepts and m is the number of stimuli. The relationship between
concepts and stimuli can be considered as a matrix with m ×n dimensions (A matrix), which
is also called the matrix or model for generating concepts from stimuli. The rows of this matrix
are the number of stimuli and the columns are the number of concepts. In the simplest case, the
components of the A matrix (aij) will be binary. In this case, if a particular stimulus, like stimulus
j, does not exist in a particular concept, like i, the component aij is zero, otherwise, it is equal
to one. In a communication system consisting of a transmitter (could be the environment or a
human agent or a computer) and a receiver (could be a computer or a human agent), the amount
of energy required to transmit information is obtained from Equation 1 [14]:
Ω(λ) = −λI(S,R) + (1−λ)H(S) (1)
Where, Ω(λ) ,I(S,R) and H(S) are the energy function, the information transfer between stimulus
and the concepts, and the entropy of the concepts, respectively. λ is a parameter of controlling
the balance between information transfer maximization and cost minimization of communication
(entropy of concepts), that is in the range λ∈[0,1].
The stimulus ( R set) is the information that is sent by the environment or person to another
person or machine to convey concepts. Here, we consider the recipient to be a human being who
must be able to deduce concepts in the environment by receiving environmental stimuli. Of course,
if the sender is a human being who wants to transfer information to the recipient (human agent)
through speech or writing, according to Zipf’s Law [45, 52], the information transfer energy is
minimized.
In this case, both the transmitter and the receiver (speaker and listener) act to minimize free en-
4
ergy, which according to the principle of least eﬀort try to maximize information and minimize the
entropy of concepts (cost). According to the equation of information transfer energy, this process
should be done to minimize Ω( λ) energy , in which case the two terms of information and entropy
are eﬀective. If the entropy increases, in practice, the amount of energy also increases, while the
amount of information must be maximized. It means that to minimize the energy, the information
I(S,R) , and the entropy H(S) must work in two opposite directions. Hence, we need to ﬁnd an
optimal point concerning λ to achieve energy minimization concerning information maximization
of both concepts and stimuli and minimization of entropy. For λ ≈0.41 [14, 53], the system is
very close to this condition. So that, the conﬂict between the minimum entropy of concepts and
the maximum of information is resolved for the appropriate value λ . In this case, the choice λ
can be considered as a policy choice to predict energy consumption. A Matrix, which shows the
relationship between concepts and stimuli, is a concept generative matrix of stimuli that works
under the policy of λ choice to minimize the energy of information transmission, according to the
received stimuli. Thus, we will have a generative model of concepts based on stimuli.
If there was a smart machine on the transmitter side instead of the human agent, it can be assumed
that the entropy of the transmitted information would be zero [14]. That is, the transmission en-
ergy is as follows:
Ωo = I(S,R) (2)
In this case, the minimizing eﬀort will be only on the receiver side. In addition, if instead of
the transmitter, there is an environment in which the human agent is located, then we will have a
one-sided minimum eﬀort on the side of the receiver (human agent) to receive concepts from the
environment. According to Zipfs law, if the sender is a human, most entropy changes result from
the use of synonymous words or concepts that give rise to similar stimuli, as well as the use of
words with high frequency and low variation and words with low frequency but a high variation.
If only a small number of synonyms are more frequent, there will be a high cognitive cost. Also,
if all the concepts in the text sent by the sender have an equal probability of sending, the entropy
value H(S) will be maximized, and if only one concept is submitted, this entropy will be zero. The
amount of combined information is shown in Equation 3 [16]:
I(S,R) =
n∑
i=1
m∑
j=1
p(si,rj) log p(si,rj)
p(si)p(rj) (3)
p(si) , p(rj) and p(si,rj) are the distribution density of concepts, the distribution density of
stimuli, and the distribution density of concepts-stimuli respectively. Equation 3 shows that the
combined information of concepts-stimuli is equal to the amount of divergence between the possible
distributions of concepts-stimuli with multiplied by the distributions of concepts and stimuli or
the KullbackLeibler divergence [15] and we have:
I(S,R) = DKL(p(si,rj)∥p(si)p(rj)) (4)
Therefore, the information transfer energy function can be as Equation 5:
5



Ω(λ)/λ= −DKL(p(si,rj)∥p(si)p(rj)) + aΩ(H(S))
aΩ = 1
λ −1 ,0 ≤λ≤1, 0 ≤aΩ ≤∞
(5)
The relationship between concepts and stimuli is a many-to-many relationship, meaning that each
concept (or each word) may have diﬀerent stimuli, and on the other hand, there might be several
concepts for each stimulus. In this case, if stimuli jointly refer to diﬀerent concepts, those concepts
form a synset.
The p(si,rj) matrix, as a generative model and for each possibility of si,rj , will be a method
to generate concepts through stimuli. In such a model, with the introduction of new stimuli or a
combination of existing stimuli that cannot refer to any of the concepts, one can expect the gener-
ation of new concepts and thus the expansion of the generative model matrix ( p(si,rj) matrix or
A). The introduction of new concepts means an increase in the entropy of H(S) that the receiver
(human agent) can update his model by reducing this entropy and thus minimizing the information
transmission energy.
This matrix model is another representation of semantic networks that allows the generation of
semantic or declarative knowledge (receiving and expanding concepts and their relationship with
each other). This model of semantic networks has the computational ability as well as present
the process of generation and introduction of new concepts into the semantic network compared
to the hierarchical models or the model of expanding activation or dendrogram of concepts with
separation of sensory modalities or applied eﬀects of concepts. Also, how the concepts are related
and their similarity [49] can be shown in the form of a concept overlap matrix. This matrix is the
result of the generation A matrix. Each of the si concepts can be represented as a combination of
rj stimuli [7] such as Equation 6:
si = (ai1,ai2,...,a im) (6)
aij is the component of the A matrix, and si , is the i-th concept represented by the vector
of the components related to the stimuli in the A matrix.
To calculate the similarity of concepts si and sj , one has:
cos θij =
m∑
k=1
aikajk
||si||.||sj || (7)
Where, cos θij shows the degree of similarity between the si, sj concepts. Given that this value
is in the range [0,1], the degree of similarity of the two concepts can be shown as probabilistic or
as a percentage. So the similarity matrix will be a n×n matrix with components between zero
and one. The process of generating a concept from stimuli is a Markov process in which hidden
variables (concepts) are inferred by stimuli.
4 Free energy principle in the brain
According to the FEP, the brain is the existence of hypothesis tested [13]. It is continuously updat-
ing its hypotheses based on the concepts it acquires from perceptions received from the environment
6
so that these concepts can be inferred by generating diﬀerent sensory stimuli and inﬂuencing sen-
sory perceptions [22] based on Bayesian inference and in a process as Markov process [46, 52]. The
brain will be disturbed if it is unable to ﬁnd out the truth and make predictions for the stimuli
received through sensory inputs such as visionary or aural. This property of the brain is explained
based on entropy properties and analogy to the principle of thermodynamic free energy [21].
The entropy of the brain increases as the agent receives new sensory inputs. If this increase remains
the same or increases over time, it can lead to cognitive impairment by the brain. To prevent such
a situation, it is necessary to reduce the generated entropy rapidly. In a thermodynamic system,
entropy reduction occurs through the consumption of free energy [17]. Thermodynamically, the
brain acts as an open system, so it can receive energy from the outside. Also, due to its self-
organization nature [3] the brain can use its free energy to reduce entropy.
Receiving sensory data and increasing entropy causes a surprise, because of inconsistency of the
received data with the hypothesis in the brain, which should be eliminated immediately through
the consumption of free energy [18]. Accordingly, the FEP states that any adaptive change in
the brain will minimize free energy. This principle is a logical analogy of the thermodynamic free
energy model based on complex implications and an attempt to describe the structure and func-
tion of the brain. In this case, with the receipt of sensory data and the increase of surprisal, the
synaptic connections of the brain are updated through coding [17].
If the variable is as sensory inputs, the entropy of these inputs is obtained from Equation 8:
H(ϕ) = −
∫
p(ϕ|m)lnp(ϕ|m)dϕ
= lim
T→∞
1
T
∫ T
0
−lnp(ϕ|m)dt (8)
Where, H(ϕ) is the entropy of sensory stimuli, m is the generative model that generates concepts
from sensory stimuli, and t is a time variable. p(ϕ|m) is the probability of sensory stimuli and
the amount of surprisal (or the amount of self-information) is negative of lnp(ϕ|m) . Studies show
that the brain uses Bayesian inference to induce sensory stimuli, i.e. environmental concepts to
prevent the eﬀect of surprise [27]. Equation 8 shows that entropy minimization is associated with
surprisal compression over time. In this way, the brain, based on the structure of its hypothesis
tested, is constantly engaged in minimizing its predictions errors based on these hypotheses. In
other words, free energy is the same as prediction error.
In the FEP of the brain, two terms of surprise and the divergence between the estimated inferential
posterior probability, q(θ) and the real probability model, p(θ|ϕ) , determine the amount of free
energy, in which θ the same concepts, or environmental states, generate sensory stimuli [18, 28].
Given the amount of surprisal and their eﬀect on free energy, the surprisal bound is determined
with the -log p(ϕ) term, which after the update; one will have a model of how surprisal is generated
in exchange for sensory perceptions. Given that any adaptive change in the brain minimizes free
energy, this minimization takes place through two processes of perception and action [17, 18]:
- Perception means changing expectations to reduce entropy and prediction error,
- Action means changing the conﬁguration by aﬀecting the biological agent on the environment to
change sensory stimuli and to avoid surprisal.
By combining perception and action, it is possible to adapt to new sensory stimuli. This pro-
7
cess is called active inference.
The equations of free energy in the two processes of perception and action will be in the form of
equations 9.
Perception to optimize the bound



F = Divergence + Surprise = DKL[q(θ|µ)∥p(θ|ϕ)] −lnp(ϕ)
µ= arg minDivergence
µ
(9)
Action to minimize the bound on surprise



F = Complexity −Accuracy = DKL(q∥p(θ))−<lnp(ϕ(a)|θ,m) >
q
a= arg maxAccuracy
a
In these equations, also µis the internal and coded concepts of the model in the brain and a is
the actions required to inﬂuence sensory stimuli in order to reduce free energy.
The µ will change as the model is updated. Hidden environmental concepts are parametrized
by the internal states of the brain. It is necessary to adopt policies, π (action choice), to select
appropriate actions, to minimize free energy [36, 39]. According to new sensory perceptions, these
actions can change discontinuously in time steps.
It means actions will be a function of the policies in question at each time step( τ). The set of
active inference process variables based on selected policies and actions at diﬀerent stages is given
in Table 1 [22, 24]
Figure 2 shows that the agent, instead of inferring the causes of new sensory stimuli, must per-
form an action that best adapts the stimulus to its generative concepts (the same mechanism of
active inference). A very important assumption in this process is that the hidden concepts in the
environment may not be received directly, but are inferred as a Bayesian process by receiving the
sensory stimuli they create. If there is no action to receive stimuli and inﬂuence the environment,
the prediction made about the concepts is the same as Bayesian inference, otherwise, inference will
be active inference.
The actions selected under diﬀerent policies can compress the error of predicting sensory stimuli,
in which case the brain encodes a probabilistic relationship among internal states, sensory stimuli,
behavioral responses, and outputs of these behaviors. This model shows that the brain not only es-
timates the closest similarities, but also the distribution of variables related to stimuli and concepts.
The minimization of free energy is done according to the two functions of recognition probabil-
ity density, namely q(θ) and generative density p(θ,ϕ) [6, 8].The joint density function p(θ,ϕ)
represents how concepts are generated concerning sensory stimuli [25]. This function is usually
obtained by using the Bayesian formula and the density function of similarity and p(ϕ|θ)marginal
distribution (θ) shown in Equation 10.
8
p(θ,ϕ) = p(θ|ϕ)p(ϕ) = p(ϕ|θ)p(θ) (10)
Given that the agent needs hypotheses that represent the generation of concepts concerning sen-
sory stimuli, the presence of recognition density and generative density functions will be necessary
to minimize free energy. With the new sensory stimuli, the generative model (generative density)
is updated and can generate new hidden variables (environmental states or concepts) according
to these sensory stimuli. In other words, we will have a generative model that, unsupervised, can
generate new and credible hidden states based on previous distributions and new data (sensory
stimuli). In this case, the brain, under the mechanism of active inference, selects sensory stimuli
according to its previous beliefs and minimizes the complexity of their representation, and by min-
imizing free energy, reaches a steady state of imbalance [8]. To minimize free energy, the prediction
error is minimized, while at the same time the conditional density entropy,H[q(ϕ|µ)] is maximized.
This is the same conﬂict in the stimulus-concept model of semantic networks. In this case, if the
entropy of the sensory stimuli H(ϕ|µ) is minimized by minimizing the free energy over time, the
conditional entropyH[q(ϕ|µ)] must be maximized.
At any given time, this phenomenon is due to the need for a balance between complexity and
accuracy. Perception, action, and policy will regulate the free energy minimization mechanism
[25, 44].
According to Equation 9, the operations that are selected according to diﬀerent policies are nec-
essary to minimize the divergence between the two functions of recognition density q(θ) and the
function of the true posterior conditional probability p(θ|ϕ) [6]. On the environmental side, one
will have the correct and deﬁnite concepts ( θ∗) the density of stimulus generation, i.e. , p(ϕ) and
the inferential generation model p(θ|ϕ). θ∗ are real concepts without considering the inference of
the agent, while, θ are concepts that are inferred by the agent and through observations (sensory
stimuli). In this case, the conditional probability of producing sensory stimuli p(ϕ|θ) is due to
the agent’s previous beliefs about environmental concepts or states [31]. Active inference and free
energy minimization evolve the model of generating concepts over time, maximizing the evidence
for observations (stimuli). Introduces a model of free energy of the brain, which, like semantic
networks, can generate semantic knowledge, and at the same time can also generate procedural
knowledge by performing actions on the environment. This free energy model of the brain is called
the FEP knowledge generation model.
5 Knowledge generation based on the FEP
The brain FEP model shown in Figure 2 introduces how concepts are generated concerning re-
ceiving new sensory stimuli. This process can be extended to the model of knowledge generation.
In addition to declarative knowledge, it also includes procedural and conditional knowledge. This
model is shown in Figure 3.
Figure 3 shows two diﬀerent loops I and II. Loop I includes prediction, perception, and brain error.
If the inference is passive (environment is not aﬀected by agent), loop I is the brain’s only func-
tional process on sensory stimuli. The prediction error changes the predictions through perception,
resulting in a change in the brain’s internal coding and updating. Thus, if there is no action to
change the sensory inputs, Bayesian-type learning and inference is done by updating previous prob-
abilities (previous beliefs) concerning receiving new sensory stimuli. This process is similar to the
computational model of updating semantic networks in the generation of declarative knowledge.
The learning in the FEP of the brain means detecting and reducing the prediction error in loop I
[19, 48]. Otherwise and in case of the need to inﬂuence sensory stimuli that have faced surprisal
9
and to minimize free energy and avoid surprisal in the future, loop II is enabled which includes a
predictive error, policy selection, and appropriate action and impact on the environment (sensory
stimuli). In this case, Bayesian probabilistic inferences become Bayesian variational inferences, due
to the need to use diﬀerent policies [34] and eventually the inference will be activated. This feature
of the model, which uses predicted actions to minimize the free energy [1, 6] means learning the
concepts that under diﬀerent actions, by receiving sensory stimuli, generate procedural knowledge.
For this case, it is necessary to learn and update the parameters of the brain, in combination with
the loop I. Thus, if the process of learning and updating the brain causes the agent to automatically
learn a series of actions that minimize free energy, this type of learning leads to the generation of
procedural knowledge.
After the generation of procedural knowledge, loop I will be inactive (without aﬀecting the updat-
ing and coding) and to use loop II the agent performs its automatic activities by using memory
and brain coding after updating and generating procedural knowledge. If both loops are active the
agent can perform the desired actions on the environment (usually automatically) simultaneously
with the extraction and application of concepts from semantic memory that are already under the
process of active inference, perceived and updated them in their brain, it means the generation of
conditional knowledge. Accordingly, the knowledge generation process for three examples is given
in Table 2.
The brain function in a FEP based knowledge generation will be as follows:
- According to previous stimuli and hypotheses, the brain infers a set of concepts and considers a
model of the inferential generation that predicts the future by receiving sensory stimuli.
- By receiving new sensory stimuli, if these stimuli are not able to infer previous concepts, the
brain generates new concepts in return for these stimuli. In other words, if a stimulus or a set
of several stimuli does not engage with any of the concepts, it is necessary to add a new hidden
concept to the model [48].
- It is possible to reduce the surprisal of receiving stimuli by inﬂuencing the factor on sensory
stimuli. In this way, the process of active inference is performed based on perception and action,
and the brain updates the model of generating concepts from stimuli by changing and correcting
future predictions.
In this case, the brain re-encodes a kind of probabilistic relationship between stimuli and concepts,
which is a mapping of the generation model in the brain. Thus, using the principle of free en-
ergy and the processes of perception, action, and learning (updating the internal parameters of
the brain), inferences and the construction of a hypothesis or model are integrated to generate
diﬀerent knowledge. In all these stages, concepts as environmental states are hidden variables that
are inferred indirectly through sensory stimuli.
- The proposed knowledge generation model is a discontinuous model of concepts and sensory
perceptions that due to the abstraction of concepts in a related set, one will have a discontinuous
model of concepts. By learning or inferring concepts, the connected spaces of sensory stimuli are
mapped into discrete entities called concepts. Abstraction of concepts provides the power to easily
generalize and transfer knowledge among agents.
Given that the distribution of stimuli or concepts is not clear from the beginning, the Bayesian
nonparametric (BNP) method is used for the learning process [2]. In an unsupervised manner,
this method helps to upgrade and update the model, by increasing the number of observations
(stimuli), over time, with high ﬂexibility. Categorical distribution ( Cat) is used to demonstrate
the distribution of concepts, stimuli, and the possible distribution of policies ( q(π)) because of the
abstraction of these variables. Given that the Dirichlet distribution ( Dir) is a conjugate prior of
polynomial distribution, it can be appropriately used in Bayesian inference. The polynomial dis-
10
tributions and the Dirichlet process are commonly used in nonparametric statistics and the use of
discontinuous variables such as concepts. Accordingly, the variables and functions of the concept
generation model are given in Table 3 [9, 10].
In Table 3, G is the expected free energy (EFE) based on the selected policy. represents the
softmax function, which transmits the EFE values to the probability range [0,1] to determine the
probability of selective policies ( p(π)) per policy. The process of generating concepts and showing
the impact of variables on the generative model can be seen in Figure 4 [37, 35].
Given the relationships and equations in Table 3 and Figure 4, one has a Bayesian decision-making
process in which the EFE, G, determines the policies needed to understand the concepts in the
future (to minimize free energy). There are also concepts based on the previous initial distribution
function and the D matrix, for the agent to be believable that as the process continues, and as new
sensory stimuli are received, the concepts are updated in a Bayesian inference under the conversion
B matrix. At the same time, Figure 4 shows how to generate concepts through sensory stimuli by
A matrix.
The probabilistic generation model is represented in Equation 11 [51, 50].
p( ˜ϕ,˜θ,π) = p(θ1)p(π)
∏
τ
p(θτ+1|θτ,π)p(ϕτ|θτ) (11)
According to the process of learning and updating the generative model, the equations of per-
ception, planning and action are shown in Table 4.
6 Comparison of knowledge generation models through se-
mantic networks and the principle FEP of the brain
Learning and knowledge generation in both of semantic networks model and FEP of the brain is
done by minimizing free energy. In semantic networks and the process of data transfer through
stimuli to humans, the generation of concepts (meaning) is done by energy minimizing (Equation
1), and in the FEP of the brain, it is done by minimizing variable free energy which is depen-
dent on human perception and action ( Equations 9). The comparison of these two approaches in
knowledge generation is as follows:
- In the semantic network model, the inference is based on Bayesian probabilities and inferences,
while in the FEP model, the inferences are based on the Bayesian variability and happen in the
perception-action process.
- In the semantic network model, only the declarative knowledge is generated, but in the FEP
model, all three types of declarative, procedural, and conditional knowledge are generated.
- Both models act as generative model to generate concepts of stimuli.
- Updating it over time is possible in both models.
- In the model of semantic networks, to separate concepts, the combination of stimuli is used to
generate concepts, while the FEP uses the diﬀerence between prediction and sensory perceptions
and the eﬀect of the factor on sensory stimuli.
- Both models correspond to the characteristics of a Markov model in the process of learning and
inference.
- Elimination of loop II in the FEP (Figure 3) eliminates the generation of procedural knowledge
and active inference and turns it into a declarative knowledge generation model similar to the
semantic network model.
11
- Perception is an important part of the FEP model in such a way that, while the semantic networks
and free energy of information transmission models does not have such possibility, a computational
model can be presented for human perception when receiving sensory stimuli.
- The semantic relationship between concepts in the model of semantic networks is determined
based on the matrix of similarity or Euclidean distance of concepts [11, 41]
7 Conclusion
This article examined how knowledge is generated in the brain and proposed a model for it. The
model of semantic networks is widely considered in the generation of declarative knowledge, but
it is not possible to explain in detail the process of procedural and conditional knowledge genera-
tion. By classifying it into two loops of declarative knowledge generator and procedural knowledge
generator, a model was proposed for generating diﬀerent types of knowledge using the FEP model
of the brain, which shows the ability to learn concepts in the human brain. This model, while
calculating the method of generating diﬀerent types of knowledge in the brain, can be very ﬂexible
in updating the model and generating concepts of sensory stimuli in a perceptual-action process. In
the continuation of this research, while addressing sensory stimuli that are involved in the process
of generating concepts, semantic or abstract stimuli can also be considered in the brain, which can
generate new concepts without sensory stimuli. The application of this model can be examined
in speciﬁc examples, such as knowledge generation in intelligent machines. Also, in the case of
cognitive diseases, especially Alzheimer’s, probability it is possible to control the disease based on
the process of producing semantic or procedural knowledge.
8 Acknowledgment
The authors would like to express sincere gratitude to Prof. Karl Friston for his invaluable inputs.
The authors are thankful to Dr. Adel Maghsoudpour and Dr. Reza Jafari Jam for valuable dis-
cussions.
9 Tables and Figures
12
Table 1: Active Inference model variables
Table 2: The process of knowledge generation according to the free energy framework of the brain
for three diﬀerent examples.
Table 3: Variables and distribution functions of the generation model.
13
Table 4: Perception, planning, and action in a process of generating concepts by minimizing free
energy in the brain [37]
.
Figure 1: An example of a semantic network with 9 concepts (in the circles or ovals) and 12
relation links (arrows)
Figure 2: The process of learning concepts and updating the brain based on minimizing free
energy and action-perception process. Prediction error can be reduced by changing predictions
(perception) and sensations (action). Photo is recreated from [20] with permission.
14
Figure 3: FEP brain model and knowledge generation
Loop I: generation of declarative knowledge (without active inference and independent of Loop II)
Loop II: generation of procedural knowledge (with active inference and connect to Loop I)
Combining two loops: generation of conditional knowledge
Figure 4: Generation of concepts in a Bayesian network according to the Markov decision-making
process based on the principle of free energy. In this process, hidden concepts cannot be directly
observed. The circles represent random variables, the comprise stimuli concepts and policies .
Arrows indicate conditional probabilities. G, Expected Free Energy; D, initial concept prior; B,
transition probabilities between hidden concepts; A, likelihood mapping from hidden concepts to
stimuli.
15
References
[1] J. R. Anderson, The architecture of cognition, Cambridge: Harvard university press, (1983).
[2] C. E. Antonic, Mixture of Dirichlet Process with Application to Bayesian Nonparametric
Problem, The Annals of Statistics, 2(6), 1152-1174, (1974), doi:10.1214/aos/1176342871.
[3] W. R. Ashby, Principle of the self-organization dynamic system, Journal of General Psychol-
ogy, 37(2), 125-128, (1947), https://doi.org/10.1080/00221309.1947.9918144.
[4] A. G. Baydin, L. R. deMontares, S. Ontanon, A semantic network-based evolution-
ary algorithm for computational creativity, Evolutionary Intelligence, 8, 3-21, (2015),
https://doi.org/10.1007/s12065-014-0119-1 .
[5] M. Berck Mirza, R. A. Adams, K. Friston, T. Parr, Introducing a Bayesian model of
selecive attention based on active inference, Nature, Scientiﬁc Reports, 9, 13915 (2019),
https://doi.org/10.1038/s41598-019-50138-8.
[6] R. Bogacz, A tutorial on free energy framework for modelling perception and
learning, Journal of Mathematical Psychology, 76, Part B, 198-211 (2017),
https://doi.org/10.1016/j.jmp.2015.11.003 .
[7] J. Borge-Holthoefer, A. Arena, Entropy, Semantic Networks: Structure and Dynamics, 12(5),
1264-1302, (2010), https://doi.org/10.3390/e12051264.
[8] C. L. Buckley, C. Kim, S. McGregor, A. Seth, The free energy for action and percep-
tion: A mathematical review, Journal of Mathematical Psychology, 81, 55-79, (2017),
https://doi.org/10.1016/j.jmp.2017.09.004
[9] O. Catal, J. Nauta, T. Verbelen, P. Simoens, B. Dhoeht, Bayesian policy selection using active
inference, The proceedings of ” Workshop on Structure Priors in Reinforcement Learning”
at ICLR (2019).
[10] O. Catal, T. Verbelen, J. Nauta, C. De Boom, B. Dhoeht, Learning Perception and Plan-
ning with Deep Active Inference, CASSP 2020, IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP), Barcelona, Spain, 2020, pp. 3952-3956, doi:
10.1109/ICASSP40776.2020.9054364.
[11] A. M. Coleman, A Dictionary of Psychology, Oxford University Press, (2008), DOI:
10.1093/acref/9780199534067.001.0001.
[12] A. M. Collins, M. Quillian, Retrieval time from semantic network memory, Journal of Verbal
Learning and Verbal Behavior 8(2), 240-248, (1969).
[13] P. Dayan, G. E. Hinton, R. Neal, The Helmholtz machine, Neural Computation, 7, 889-904,
(1995), doi:101162/neco.1995.7.5.889 .
[14] R. Ferrer i Cancho, When language breaks into pieces A conﬂict between commu-
nication through isolated signals and language, Biosystems 84, 3, 242-253, (2006),
https://doi.org/10.1016/j.biosystems.2005.12.001.
[15] R. Ferrer i Cancho, Optimization Model of Natural Communication, Journal of Quantitative
Linguistics 25(3), 207237, (2008), doi:10.1080/09296174.2017.1366095 .
16
[16] R. Ferrer i Cancho, R. Sole, Least eﬀort and the origin of scaling in human language, Proc.
Natl. Acad. Sci. (PNAS), 100 (3), 788-791, (2003), https://doi.org/10.1073/pnas.0335980100.
[17] K. Friston, The free-energy principle: A rough guid to the brain? Opinion, Trends in Cognitive
Science, 13, 7, 293-301, (2009), https://doi.org/10.1016/j.tics.2009.04.005.
[18] K. Friston, The free-energy principle: A uniﬁed brain theory?, Nature Reviews Neuroscience,
11(2), 127138, (2010), https://doi.org/10.1038/nrn2787
[19] K. Friston, A Free Energy Principle for Biological Systems. MDP, Entropy, 14(11), 7, 2100-
2121, (2012), doi:10.3390/e1412100 .
[20] K. Friston, Conference presentation, 3rd IMPRS NeuroCom Summer School, Leipzig, Ger-
many. Retrieved from https://www.ﬁl.ion.ucl.ac.uk/ karl/Free, (2013).
[21] K. Friston, A free energy principle for a particular physics,
https://doi.org/10.48550/arXiv.1906.10184, (2019).
[22] K. Friston, J. Kilner, L. Harison, A free energy principle for the brain, Journal of Physiology-
Paris, 100, Issues 13, Pages 70-87, (2006), https://doi.org/10.1016/j.jphysparis.2006.10.001.
[23] K. Friston, R. A. Adams, L. Perrit, M. Breakspear, Perception as hypotheses: sac-
cades as experiments, Front in Psychology, Sec. Perception Science, 3, 151, 1-20, (2012),
https://doi.org/10.3389/fpsyg.2012.00151.
[24] K. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbech, J. O’Doherty, G. Pezzulo, Ac-
tive inference and learning, Neuroscience and Behavioral Review, 68, 862-879, (2016),
https://doi.org/10.1016/j.neubiorev.2016.06.022.
[25] K. Friston, T. FitzGerald, F. Rigoli, G. Pezzulo , Active inference and epistemic value, Cog-
nitive Neuroscience, 6(4), 187-214, (2015), https://doi.org/10.1080/17588928.2015.1020053.
[26] F. Gobet, H. A. Simon, F. Rigoli, G. Pezzulo, Roles of recognition processes and look-ahead
search in time-constrained expert problem solving: Evidence from grand-master-level, Psy-
chological Science, 7(1), 52-55, (1996), http://www.jstor.org/stable/40062907.
[27] S. J. Greshman, What does the free energy principle tell us about the brain?, Cognitive
Neuroscience 6(4), 187-214, (2019), http://dx.doi.org/10.1080/17588928.2015.1020053.
[28] D. C. Knill, A. Pouget The Bayesian brain: the role of uncertainty in neu-
ral coding and computation, Trends in Neurosciences, 27, 12, 2004, 712-719,
https://doi.org/10.1016/j.tins.2004.10.007.
[29] L. K. Komatsu, Recent views on conceptual structure, Psychological Bulletin, 112(3), 500-526,
(1992), https://doi.org/10.1037/0033-2909.112.3.500.
[30] J. H. Larkin, J. McDermonth, D. P. Simon, H. A. Simon, Expert and novice perfor-
mance in solving physics problems, Science, 208, 4450, 1335-1342, (1980), Doi: 10.1126/sci-
ence.208.4450.1335.
[31] F. Lehmann, Semantic Networks, Computers and mathematics with applications, 23(2-5),
1-50, (1992), https://doi.org/10.1016/0898-1221(92)90135-5.
17
[32] B. Love, Encyclopedia of Cognition Science, London: Nature Publishing Group, 2, (2003).
[33] D. L. Madin, J. B. Proﬁtt, H. C. Schwartz, Concepts: an overview, Washington, DC: American
Psychology Association, (2000).
[34] D. Ostwald, E. Kirilina, L. Strake, F. Blankengurg, A tutorial on variational Bayes for
latent linear stochastic time-series models, Journal of Mathematical Psychology, 60, 1-19,
(2014), https://doi.org/10.1016/j.jmp.2014.04.003 .
[35] T. Parr, K. Friston, The Anatomy of Inference: Generative Models and Brain Structure,
Frontiers in Computational Neuroscience, 12(90), (2018),
https://doi.org/10.3389/fncom.2018.00090.
[36] T. Parr, K. Friston, Uncertainty, epistemic and active inference, Journal of Royal Society
Interface, 14(136), 1-10, (2017), doi:10.1098/rsif.2017.0367.
[37] T. Parr, R. V. Ricky, M. M. Halassa, K. Friston, Prefrontal computation as active inference,
Oxford, Cerebral Cortex, 30, 2, 682695, (2020), doi:10.1093/cercor/bhz118 .
[38] J. Payne, Task complexity and cotingent processing in decision making: An information
search and protocol analysis, Organizational Behavior and Human Performance, 16(2), 366-
387, (1976), https://doi.org/10.1016/0030-5073(76)90022-2.
[39] J. Pearl, Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference,
Morgan Kaufmann Publishers Inc, San Francisco: CA, (1988).
[40] R. Ratcliﬀ, G. Mckoon, A retrieval theory of priming in memory, Psychological Review,
95(3), 385-408, (1988), doi:10.1037/0037-295x.95.3.385 .
[41] T. Rogers, M. A. Lombon Ralph Mckoon, Structure and Detection of Semantic Network: A
Neurophysiological and Computational Investigation, Psychological Review, 111(1), 205-235,
(2004), doi: 10.1037/0033-295X.111.1.205.
[42] N. Sajid, P. J. Ball, K. Friston, Active inference: demystiﬁed and compred, Neural Com-
putation, 33(3), 674-712, (2021), https://doi.org/10.1162/neco-a-01357.
[43] G. Schraw, Promoting general metacognitive awareness, Instructional Science, 26, 113-125,
(1998), http://doi.org/10.1033/A:1003044231033.
[44] B. Sengupta, M. Stemller, K. Friston, Information and Eﬃciency in the Nervous Systems,
PLos Comutational Biology, 9(7), (2013), doi:10.137/journal.pcbi.1003157 .
[45] L. F. Seone, R. Sole, The morphospace of language networks, Scientiﬁc Reports, 8, 10465,
(2018), https://doi.org/10.1038/s41598-018-28820-0.
[46] Y. Shen, C. Archambeau, D. Cornford, M. Opper, J. Shawe-Taylor, R. Barillec, A
comparision of variational and Markov chain monte carlo methods for inference in partially
observed stochastic dynamic systems, Journal of Signal Processing Systems, 61(1), 51-59,
(2010), doi:10.1007/s11265-008-0299-y .
[47] E. E. Smith, E. J. Shoben, L. J. Rips, Structure and process in semantic mem-
ory: A featural model for semantic decision, Psychology Review, 81, 3, 214-241, (1974),
https://doi.org/10.1037/h0036351.
18
[48] R. Smith, P. Schwartenbeck, T. Parr, K. Friston, An Active Inference Approach to mod-
elling structure learning: concept learning as an example case, Frontier in Computational
Neuroscience, 14(41), (2020), https://doi.org/10.3389/fncom.2020.00041.
[49] M. Steyvers, M. R. Shiﬀrin, D. L. Nelson, Word association spaces for predicting semantic
similarity eﬀects in episodic memory, Experimental cognitive psychology and its applications,
237-249, (2005), doi:10.1037/10897-018.
[50] R. Strenberg, Cognitive Psychology, Australia, Belmont: CA: Thomson, Wadsworth, (2006).
[51] B. Sugiharto, A. D. Corebima, H. Suilo, I. Ibrohim, A comparision types of knowledge of
cognition of preservice biology teacher, Asia-Paciﬁc Forum on Science Learning and Teaching,
19(1), (2018).
[52] E. Todorov, Linearly-solvable Markov decision problems, In Advances in Neural Information
Processing Systems, 1369-1376, MIT Press, (2006).
[53] G. Zipf, Human behavior and the Principle of Least Eﬀort: An Introduction to Human
Ecology, ,New York: Addisson Wesley, (1949).
19