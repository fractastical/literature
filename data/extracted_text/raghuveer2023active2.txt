UC Merced
Proceedings of the Annual Meeting of the Cognitive Science 
Society
Title
Active Inference and Psychology of Goals: A study in Substance and Process Metaphysics
Permalink
https://escholarship.org/uc/item/69d0s6jq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 45(45)
Authors
Raghuveer, Dhanaraaj
Endres, Dominik M
Publication Date
2023
Copyright Information
This work is made available under the terms of a Creative Commons Attribution License, 
available at https://creativecommons.org/licenses/by/4.0/
 
Peer reviewed
eScholarship.org Powered by the California Digital Library
University of California
Active Inference and Psychology of Goals: A study in Substance and Process
Metaphysics
Dhanaraaj Raghuveer (dhanaraaj.raghuveer@uni-marburg.de)
Theoretical Cognitive Science Lab, Department of Psychology,
Philipps-Universit¨at Marburg, Marburg 35037 Germany.
Dominik Endres (dominik.endres@staff.uni-marburg.de)
Theoretical Cognitive Science Lab, Department of Psychology,
Philipps-Universit¨at Marburg, Marburg 35037 Germany.
Abstract
Active Inference and its accompanying Bayesian Mechanics
(BM) are important psychological and cognitive science theo-
ries. While there is a strong interaction between the theories
and the philosophical realm, it needs to be clarified what its
metaphysical commitments are. We tease out these commit-
ments while looking from the perspective of the psychology
of goals. We find that Active Inference cannot account for the
dynamic growth of goals, primarily because of its closed gen-
erative model. We trace the reason for this through the extrin-
sic ‘ontological constraint’ of BM, characteristic of all mech-
anistic models which follow the ‘logic of machines.’ Finally,
we ground our arguments in the necessity of external relations
in substance metaphysics and its incompatibility with internal
relations and impredicativity. Thus we argue that Active Infer-
ence implicitly presupposes a Substance metaphysics, yielding
the theory no resource to model novelty, growth, and develop-
ment observed in human psychology. We briefly sketch a pow-
erful alternative grounded in process metaphysics to model bi-
ological and cognitive systems.
Keywords: Active Inference; Goals; Generative Models;
Metaphysics; Impredicativity; Internal Relations
Introduction
Friedrich von Weizs ¨acker famously said, ‘Every scientist
works with metaphysical assumptions, and those who deny
this most usually work with the poorest ones.’ As a disci-
pline, Cognitive Science is one of the few sciences explicitly
acknowledging philosophy as a core part of itself. However,
even in Cognitive Science, facets of philosophy other than the
philosophy of mind are seldom considered – like ontology
and metaphysics. We intend to undertake a study that points
to the value of metaphysics – especially process metaphysics
– and analyze implicit assumptions in one of psychology’s
core theories, Active Inference.
Active Inference has been central in cognitive science and
psychology for almost two decades. It is also one of the few
psychological theories that engage critically with the philos-
ophy of mind (mental representations) and philosophy of sci-
ence (realist and instrumentalist reading of Active Inference).
However, to date, it has yet to be clear what the metaphysi-
cal commitments of the theory are, and not much elaboration
has been offered. We make one such attempt in this study.
Notably, we focus on the goal-oriented aspect of human psy-
chology to highlight and illuminate these commitments.
By psychology of goals, we do not mean anything fancy
other than the activities of everyday life - like the goal to
finish a paper, which suddenly changes to cooking a meal,
switching to paying utility bills, or maybe transitioning to
completely disparate goals. Our focus is on this dynamic-
ity, flexibility, and fluidity with which goals change, emerge,
and develop over ontogenetic time. More importantly, change
and emergence from within the system, i.e., internal & intrin-
sic goals, and not imposed by an external experimenter - as in
the case of laboratory bandit tasks. Our primary thesis is that
Active Inference, as it is currently formulated, cannot account
for this dynamicity of goal-oriented activities.
Active Inference is the idea that humans perceive and act
on the world through Bayesian Inference (perception as infer-
ence, planning as inference) via variational free energy min-
imization (VFEM) (Parr, Pezzulo, & Friston, 2022). While
the perception as inference is a crucial part of the story, we
will focus here on the action part and the associated goals
it achieves. The system’s goals are baked into the priors of
the generative model that the system embodies (Ramstead,
Friston, & Hip ´olito, 2020). Thus, goals are instantiated
through priors on observations (in discrete-time Active In-
ference, called C-matrix) that the system wants to observe.
This goal-informed prior forces the system to infer actions
that yield the said goals.
In many ways, this is a generalized form of model-based
reinforcement learning. Instead of a separate reward function,
goals are cast as a probabilistic belief on sensory observations
yielding one inference scheme for both action and perception
(Millidge, Tschantz, & Buckley, 2021). There are other prop-
erties like learning and uncertainty handling, but these are not
of concern for our inquiry.
The crucial point to note here is that irrespective of which
time-setting (discrete or continuous) one is working with Ac-
tive Inference, the generative model and its associated goals
are always ‘closed.’ By ‘closed,’ we mean the inability to
change, grow, and evolve by itself. In short, a closed set
of goals is embodied through priors on a fixed set of obser-
vations. A fixed, a-priori-specified set of actions is used to
achieve these goals.
This closed-ness of Active Inference comes from the ‘high
road to Active Inference,’ (Parr et al., 2022) or what is re-
cently called Bayesian Mechanics (Ramstead et al., 2022).
We want to draw attention to the critical assumption in this
‘high road’: if a ‘thing’ exists, then there is a stipulated defi-
nition of ‘the kind of thing that it is’ (Ramstead et al., 2022).
763
In M. Goldwater, F. K. Anggoro, B. K. Hayes, & D. C. Ong (Eds.),Proceedings of the 45th Annual Conference of the Cognitive Science
Society. ©2023 The Author(s). This work is licensed under a Creative Commons Attribution 4.0 International License (CC BY).
This ‘thingness’ is also called the ‘ontological potential or
constraint’ of the thing.
‘Ontological potentials or constraints provide a mathe-
matical definition of what it means for a particular sys-
tem to be the kind of system that it is: they allow us
to specify the equations of motion of particular systems,
based on description of what sorts of states or paths are
typical of that kind of system’ (Ramstead et al. (2022),
emphasis ours).
These ‘typical states’ are also called phenotypic states (in
the case of biological systems) of the ‘thing’ (Ramstead,
Kirchhoff, & Friston, 2020). The question then becomes
where these phenotypic states come from and what is its na-
ture. The acknowledged answer in Active Inference litera-
ture is that they are evolution-endowed innate characteristics
(Friston, Kilner, & Harrison, 2006).
The critical point here is that these ‘ontological constraints’
are not intrinsic to the system’s dynamics but are rather ex-
trinsic. I.e., they influence the system’s dynamics but are
not themselves influenced by the dynamics. This inability
to model intrinsic constraints is traced to a logical necessity
inherent in Bayesian Mechanics (and all mechanics), which
Koutroufinis (2017) calls ‘logic of machines.’ We further ar-
gue that this logic is a natural outcome of substance meta-
physical assumptions, thereby showing us where Active In-
ference is metaphysically grounded.
Several authors have raised issues about other aspects of
Bayesian Mechanics and Active Inference, like lack of his-
toricity (Paolo, Thompson, & Beer, 2022), fixed state-space
(Colombo & Wright, 2021), and inability to capture consti-
tutive relations (Raja, Valluri, Baggs, Chemero, & Anderson,
2021). These problems’ root is an implicit substance meta-
physical assumption in Bayesian mechanics. This assump-
tion gets cashed out in Active Inference as a closed genera-
tive model with a fixed set of priors – ‘priors that correspond
to innate value and are part of the (generative) model per se’
(Friston et al., 2006).
In what follows, we elaborate on why we think Active In-
ference, as it is currently formalized, cannot account for nov-
elty and development in the psychology of goals. The fun-
damental thesis is that it presupposes a substance ontology
through its ‘logic of machines’ in Bayesian mechanics - An
ontology that makes any form of internal relations and im-
predicative causality impossible and thus any real change,
growth & development.
Furthermore, we elaborate on the necessity of process
metaphysics to account for impredicativity & internal rela-
tions within our scientific models. We briefly sketch Robert
Rosen’s relational modeling and argue how its tools to model
complex systems are a strong candidate to explain the dynam-
icity of biological and cognitive systems. We end the study
with some concluding remarks.
Active Inference and Substance Metaphysics
The theory of Active Inference has two routes of entry, the
low road and the high road to Active Inference (Parr et al.,
2022). For psychological modeling, most Active Inference
researchers use the tools of the low road to model percep-
tion, action, and learning. The high road justifies those tools
from ontological first principles – like free energy minimiza-
tion rather than MCMC sampling for Bayesian inference. To
that extent, we will introduce the basic concepts of the low
road before making contact with the high road, also called
Bayesian Mechanics (BM) (Costa, Friston, Heins, & Pavlio-
tis, 2021; Ramstead et al., 2022).
The low road starts with the assumption that human per-
ception is a kind of inference, continuing in the Helmholtzian
idea of ‘unconscious inference’ (Buckley, Kim, McGregor, &
Seth, 2017). Why inference? Well, the argument is that sen-
sory data hitting the retina is substantially reduced compared
to the rich three-dimensional world that we perceive.1 So, the
brain has to infer the outside world (hidden state, s) by com-
bining the sensory data (observation,o) with prior knowledge
(generative model, p(o, s)) to re-present the world in our per-
ception (p(s|o)).
The standard cognitivist theory in psychology posits that
this re-presentation undergoes further mental processing to
plan optimal actions based on a separate utility/reward func-
tion. This view is the case in most decision-making the-
ories like model-based Reinforcement learning. However,
the major innovation in Active Inference is unifying percep-
tion and action under one inference scheme by instituting a
perception-action loop (Millidge et al., 2021).
The idea is that the agent expects to observe certain sen-
sory data and acts to bring about those observations – ‘given
the assumption that I will achieve my preferred outcomes,
what course of action am I most likely to pursue?’ (Smith,
Friston, & Whyte, 2022; Millidge et al., 2021). Thus, given
certain preferred future observations (goals, called C-matrix
in discrete Active Inference), the system infers which plan
(sequence/course of action) would bring those observations.
This inference is called ‘planning as inference’ (Smith et al.,
2022). Once a particular observation is generated, the system
compares it with its expected observation to perceptually in-
fer the world. This ‘perception as inference’ then feeds into
changing the course of action (if needed), thus completing the
perception-action loop.
One optimal way to do all this is through Bayesian in-
ference. Since Bayesian inference is intractable for most
real-world complexity, variational free energy minimization
(VFEM) is introduced as an approximate Bayes-optimal so-
lution2. The key player in this inference scheme is the gener-
ative model, instantiating the prior knowledge of the system.
1For a rejection of this ‘poverty of the stimulus’ argument, see
(Bickhard & Richie, 1983)
2See Kwisthout and van Rooij (2020); Kwisthout, Wareham, and
Rooij (2011) for a rebuttal to tractability of approximation algo-
rithms
764
Figure 1: An agent-environment system particularly partitioned by its Markov Blanket. The Active and Internal states constitute
the Autonomous states of the system while adding Sensory states to them constitutes the particle - also called Particular states.
(Figure from Friston et al. (2021); used under CREATIVE COMMON ATTRIBUTION LICENSE)
The generative model specifies which observations the sys-
tem prefers (goals), how actions change the outside world
(state transition, B-matrix), which hidden state yields which
observations (likelihood function, A-matrix), etc. It is fair to
say that almost everything (except VFEM) in Active Infer-
ence comes down to the prior knowledge and prior prefer-
ences instantiated in the generative model.
Given this introduction, we are now in an excellent posi-
tion to ask whether the theory of Active Inference can explain
dynamic, emergent goals. One way of viewing the question
in light of previous paragraphs is, can the generative model
dynamically grow w.r.t its goals? Unfortunately, we do not
think it can. The generative models are closed, allowing only
a finite and fixed set of goals embodied as a prior on a finite
set of observations.
Several authors have previously noted this shortcoming of
closed generative models in Active Inference. For example,
in the context of learning, ‘we would be missing a means
of representing all the new categories that are constantly be-
ing developed’ like ‘neutrino, blockchain, tweet, and bitcoin’
(Rutar, de Wolff, van Rooij, & Kwisthout, 2022) and in the
context of expectations, ‘This introduction of a novel cate-
gory/concept was a puzzle ... and realized that the fixed state
space of a dynamical POMDP (like the one used here) cur-
rently lacks the flexibility to model such emergent expecta-
tions’ (Raghuveer & Endres, 2023) - highlighting the limi-
tations of closed models. In the upcoming sections, we will
identify and point out the root of such limitations.
Bayesian Mechanics
To analyze the finite and closed characteristics of generative
models and goals, we must turn to Bayesian Mechanics – the
high road to Active Inference (Parr et al., 2022; Ramstead et
al., 2022). As noted earlier, Bayesian Mechanics (BM from
here on) furnishes justification for using tools like VFEM,
action-perception loop, and prior expectations from ontolog-
ical first principles.
Notably, it starts with the question of what it means for a
thing to exist. Quoting Friston et al. (2022):
• ‘If something exists, in the sense of possessing character-
istic states or dynamics, what properties must it possess?
To answer this question, it is necessary to define a thing or
particle.’
• ‘A particle is constituted by internal and blanket states. The
blanket states constitute the boundary between the states
internal and external to the particle.’
We do not have to concern ourselves with the boundary or
‘particular partition’ for now, but let us focus on the first step.
The foundational assumption in BM is that every system that
exists is described by a stochastic dynamical system of the
form:
˙x(t) = f (xt ) +ω(t) (1)
Where f (xt ) is the deterministic flow and ω(t) is the
stochastic noise. Once this is assumed, the next move is parti-
tioning the system into internal, sensory, active, and external
states (Figure 1). This partition is formalized by partitioning
the dynamical system into four components - fµ, fs, fa, fη and
their corresponding noise terms. As quoted in Friston et al.
(2022) above, the ‘thing’ is then constituted by internal and
blanket states.
Since BM is affirmed as a theory of self-organizing
systems, it assumes that there is a set of ‘characteristic’
states/dynamics that the system self-organizes into. These
states/paths define the ‘thing’ as ‘the kind of thing it is’
(Ramstead et al., 2022). They are called ‘ontological con-
straints’ of the ‘thing.’
Given this set of characteristic states, one can describe the
system’s dynamics as a random dynamical system with a pull-
back attractor. These dynamics could be given a probabilis-
tic description using the Fokker-Planck equation, yielding the
765
generative model ( p(x)) with its attractor states as prior ex-
pectations of the system. That is a probability distribution on
states that encodes a high probability for attractor states than
other states.
The innovation in BM is the particular assumption on the
nature of ‘partition’ (Markov Blanket) within the system. The
conditional independence following this assumption leads to
interesting results - like autonomous states lookas ifthey are
minimizing surprisal w.r.t external states - yielding the VFEM
scheme and perception-action loop. However, our focus is
not that per se, but rather on the nature and origin of the goals
instantiated as prior expectations of the ‘thing.’ Let us first
start with the origin.
Given the above elucidation, it is easy to see that the goals
of a system are intricately linked to its ‘characteristic states’
– the states a system expects to be in. In fact, Ramstead et
al. (2022) explicitly states that ‘we can think of this [attrac-
tor] solution to the dynamics as a naturalised account of the
teleology of cognitive systems’ (emphasis ours). For a bio-
logical system, the characteristic states are also called pheno-
typic states of the system –
‘organisms expect to be in their characteristic pheno-
typic states; surprising deviations from these expecta-
tions must be avoided to maintain the system within vi-
able (i.e., phenotypic) states’ (Ramstead, Kirchhoff, and
Friston (2020), emphasis ours).
So where do phenotypic states come from? The well-
acknowledged answer to this question in the literature is that
they are innate, originating from evolution (Friston, Samoth-
rakis, & Montague, 2012; Friston et al., 2006; Friston, 2010;
Badcock, Friston, Ramstead, Ploeger, & Hohwy, 2019). This
is the crucial part. The characteristic phenotypic states are
imposed through evolution and are not produced through the
dynamics or current activity of the system itself.
To reiterate, the ‘characteristic states’ of the system, ac-
quired through ancestral evolution, determine the ‘ontologi-
cal constraint,’ which directs the system’s deterministic flow,
f (x). The influence flow is one-way, i.e., the characteris-
tic states and ontological constraints influence the system’s
dynamics but not vice versa. The asymmetry between the
system’s dynamics and ‘ontological constraints’ makes those
constraints external (in origin) and extrinsic (in nature). With
these answers to our question of the origin and nature of
goals, we will now move on to their implications.
Intrinsic and Extrinsic Constraints
The next question is, why can’t the ‘ontological constraints’
be influenced back by the system’s dynamics? If the sys-
tem can change its constraints autonomously, it could create
new ones too. If that happens, we have a model of auton-
omy and dynamically emergent goals. We argue that intrin-
sic and dynamically emergent constraints are necessary (but
insufficient) to have a realistic model of human psychology.
However, as it is currently formulated, Active Inference and
Bayesian Mechanics cannot accommodate such dynamicity
and intrinsic constraints.
To answer why this is so, we need to trace back to the
fundamental assumption of BM - that every existing system
is a form of stochastic dynamical system with characteristic
states/paths. On top of that, we also need to introduce some
terminology of dynamical systems theory and Aristotelian
causes from Koutroufinis (2017) and Rosen (1985). Every
dynamical system comprises two kinds of causal factors - in-
trinsic and extrinsic. Intrinsic factors are those the system’s
dynamics can influence, while extrinsic factors are fixed and
cannot be influenced.
Going back to Eq 1, our intrinsic factors are the state vari-
ables (x; when partitioned µ, s, a, η); extrinsic factors are the
independent variables and parameters. However, these are
only first-order factors. The second-order extrinsic factors
are those that operate on the first-order factors, in our case,
the deterministic flow f . To introduce Aristotelian causes,
we turn to a mathematically equivalent way of writing Eq 1,
x(t) =
Z t
t0
f (xτ)dτ+C(x(t0)) (2)
where, initial state x(t0) is the material cause, and op-
erator
Rt
t0 f (xτ)dτ is the efficient cause of the effect x(t)
(Rosen, 1985). Given these terminologies, we will return to
Koutroufinis (2017).
In all dynamical systems, Koutroufinis (2017) argues that
second-order operators/efficient causation have to be extrin-
sic - in the sense of not being influenced by the system’s
dynamics. The necessary reason is that dynamical systems
theory falls under the ‘logic of machines,’ i.e., the logic of
state-determined systems with no intrinsic constraints and in-
ternally relatedefficient causation. As we will see later, this
necessity is a direct outgrowth of classical physics’ substance
ontology and its accompanying view of efficient causation as
an external force acting on an inertial matter that is epistemo-
logically inherited in state-determined systems.
Moreover, this extrinsic nature between the dynamics and
second-order function prevents any new generation of intrin-
sic factors at the first-order level. These two essential proper-
ties of dynamical systems are argued to be incompatible with
empirical, biological facts of living systems (Koutroufinis,
2017). For example, during their growth (and other activi-
ties), cellular organisms synthesize a vast array of proteins
resulting in novel functions (second-order factors) and rela-
tions between first-order factors. Also, these new relations
produce varying types of molecules (first-order factors) that
were not already present.
The extrinsic nature of the ‘ontological constraint’ and its
inability to generate new first-order intrinsic factors make
the underlying state variables fixed without any change or
growth. Thus, while Active Inference can model the apparent
change in position within a state-space, it cannot model the
real change of the state-space itself, as observed in biological
and cognitive systems. This fixed state space is what leads to
766
A g
f3) B
A B
f1)
A BA
f C
g
4)
A B
f
C
g2)
Figure 2: Rosen’s category theoretic mappings depicting
Simple (1 & 2) and Complex Systems (3 & 4). Red and Blue
arrows indicate Aristotle’s efficient and material causes, re-
spectively. All simple state-determined systems are Turing
computable, owing to their ‘logic of machines’ that always
have extrinsic higher-order factors.
closed generative models.
However3, one could postulate a higher-level function
space (like evolution) that could make the state-space and
generative models change dynamically. Nevertheless, the
question becomes whether that higher-level space is fixed or
changing. If the latter, we get into an infinite regress (by
positing an even higher-level space); if the former, we are
back to a closed ontology. The rejection of such postulations
could be summarized as,
‘Both [Whitehead and Peirce] reject physical necessity,
and both philosophers were aware that the challenge of
defending such a [process] realism is to find a way to
model change such that natural laws themselves change’
(Auxier & Herstein, 2019).
Thus, modeling change without getting into an infinite
regress, nor positing an unchanging, privileged level, is pre-
cisely what a process ontology yields and is what we argue to
be impossible in substance ontological state-determined mod-
els.
Substance and External Relations
As stated earlier, all models of dynamical systems fall under
the ‘logic of machines’ category - to the extent that they can-
not model intrinsic constraints. At the same time, as long as
BM assumes that it completely explains life and mind purely
in terms of dynamical systems theory, it presupposes a mech-
anistic ontology. To put it in Koutroufinis (2017)’s words:
3We thank one of our reviewers for pointing this out.
‘an ontology can be described as a ‘mechanistic sys-
tems ontology’ or simply a ‘mechanistic ontology’ if it
implicitly or explicitly assumes that the term ‘system’
refers to real entities the inner causality of which can, in
principle, be explained by models obeying the logic of
the Turing or non-trivial machine.’
The key term here isinner causalityand its nature in mech-
anisms. Before investigating causality, we need to expli-
cate the link between mechanistic and substance ontology.
Classical mechanics and its variants borrow from substance
metaphysics the assumption of physical/material substance
as ontologically primary 4. This assumption, in turn, leads
to the view of nature as ‘all the things that exist are physi-
cal things—either basic bits of matter or made up of bits of
matter’ (Campbell, 2009).
Crucially, such particles/substances ‘are supposed to ex-
ist independently of anything else: there are no relations in-
trinsic to [it]’ (Bickhard, 2019) and are fundamentally un-
changing. Given this nature of substances, the only relation
predicable of them is external relations.5 On top of these
immutable particles, Newton posited external forces which
cause changes to its position in space through accelerations.
The mathematical image of such a substance-mechanistic
ontology was the R3 space occupied by an unchanging parti-
cle with its instantaneous position (state variable) determined
by dynamical laws independent of it and its motion. While
significant developments were made from this particle me-
chanics, Rosen (1985) argues that explicit separation of dy-
namical laws and system dynamics were still the epistemo-
logical presupposition of state-determined models like ana-
lytical, statistical, and quantum mechanics.
Thus, at the root of extrinsic efficient causes in all state-
determined systems is the substance ontological assumption
of externally related matter with external forces as the effi-
cient cause of position change. Given this background, it is
clear why in mechanisms, ‘efficient causes have to be extrin-
sic’ (see above and Fig 2.1-2.2). Owing to their substance
metaphysical presupposition, any form of mechanics (includ-
ing Bayesian Mechanics) has to follow a logic of causality
that necessarily grounds in an extrinsic factor, which makes
it impossible to model our intrinsic constraints - a form of
impredicative causality.
In the next section, we will look at an alternative to sub-
stance metaphysics, which takes relations, change, and ac-
tivity seriously. This, in turn, yields powerful resources to
model biological and cognitive agents.
Process and Internal Relations
Unlike substance metaphysics, process metaphysics views
processes as fundamental and ‘matter or bits of matter’ as
organized actualization of processes. This shifts our view of
4There are other critical assumptions like the elimination of po-
tentiality, absolute space, and time which we will not get into here.
5For a definition and concrete example of internal, external rela-
tion, and impredicativity, see next section.
767
nature to ‘all things have to be conceived fundamentally as
processes of various scales and complexity, having causal ef-
ficacy in themselves’ (Campbell, 2009).
Thus, if the default condition for substance metaphysics
was inertness and isolation, then it is the opposite - activ-
ity and relations for process metaphysics. Crucially, self-
determining activity and internal relations, capable of han-
dling intrinsic constraints and internally related efficient
causes. We are now in the correct position to elaborate on
internal and external relations.
In logic, two terms are internally related if one or both
the term’s existence depends on having that relation between
them (Campbell, 2011). In other words, it is an essential re-
lation for the constitution of the term/s. Externally-related
terms do not have constitutive or essential relations between
them. Let us visit some examples.
A classic instance of internal relation is the relation be-
tween the arc of a circle and its center (Bickhard, 2003). An
arc cannot exist as ‘that’ arc without its relation to the cen-
ter. Another crucial example is Robert Rosen’s impredicative
cycle (Fig 2.3). Note that the efficient causes f and g mutu-
ally cause each other in an impredicative cycle. Without f, g
would not exist, and without g, f would not exist - A form
of internally related efficient causation.6 Thus, the very exis-
tence and constitution of the term/s depend on such relations.
Contrast this with the external relation between ‘...’ of
Morse code and its content ‘S.’ There is nothing intrinsic in
‘...’ that depends on ‘S.’ ‘...’ could exist perfectly fine as
‘...’7 without that Morse code relation. In fact, all such infor-
mational encodings are external relations (Bickhard, 2003).
While substance metaphysics can only offer external rela-
tions, both internal and external relations play a crucial role
in process metaphysics.8
The purpose of these elaborations is to emphasize that in
‘a process metaphysics there are no particulars’ (Seibt, 2010),
i.e., there are no inert, externally-related substances but rather
internally organized actualization of processes. Within this
framework, there is a continual mutual influence (both in-
ternal and external) among processes, with those influences
embodying causal powers.
Furthermore, because of the relational character of pro-
cesses, their causal powers too are relational. Also, since at
least some of these relations are internal, constitutive change
and thus emergence/emergent causalityis legitimate in pro-
cess metaphysics. Thus, process metaphysics provides pow-
erful resources to model both external & predicative forms of
causality and impredicative forms.
To sum up, the two essential aspects of process meta-
physics are activity (with its inherent causal power) and rela-
tions (including internal relations). Combining these two as-
6Rosen calls this closure to efficient causation.
7For example, it could be used perfectly well inside a python
function, without meaning ‘S’ wherever it is used.
8We are skipping technical complications in process philosophy
like past being externally related to present and present being inter-
nally related to past due to space constraints.
pects, one could heuristically think of a process as an organi-
zation of causes, with novel organizations yielding emergent
processes. These aspects of process metaphysics are what
Rosen’s Relational Biology is about.
While explaining the details of Rosen’s brilliant insights is
beyond the scope of this paper, we would merely like to high-
light two classes of systems that he identified - simple and
complex systems (Fig 2). Simple systems exhibit only pred-
icative forms of causality, while complex systems can exhibit
both predicative and impredicative forms.
The critical difference between these systems is the extrin-
sic and intrinsic higher-order causal factors (efficient causes
f and g). In Rosen’s complex systems, the system’s activity
influences (in fact produces) the higher-order factors, while
in simple systems, the highest level is always extrinsic. Thus,
by adopting process-relational metaphysics, we are endowed
with a powerful logic to scientifically model the complexity
of biological and cognitive systems.
Conclusion
We started our study with the goal of analyzing the im-
plicit metaphysical assumptions present in Cognitive Sci-
ence’s core theories - Active Inference and Bayesian Me-
chanics (BM). Furthermore, we focused on the goal-oriented
aspects of human psychology and its dynamic properties to
cast light upon those metaphysical commitments. Through
this analysis, we find that Active Inference is based on sub-
stance metaphysics, preventing it from capturing the novelty
and growth of goals associated with biological and cognitive
systems.
Specifically, the closed nature of generative models used
to explain human cognition is derived from the ‘ontological
constraints’ of BM’s ‘things.’ The fixed nature of these ‘onto-
logical constraints’ was traced back to the ‘logic of machines’
and its extrinsic higher-order factors. Furthermore, we found
that this logic was a natural outgrowth of substance meta-
physical assumptions and its apparent incompatibility with
internal relations and impredicative causality.
We also describe some key features of process metaphysics
and the powerful resources it yields to model predicative and
impredicative process organizations. We end with a brief out-
line of Rosen’s Relational modeling as a suitable framework
for biological and cognitive systems. Recent advances in Ac-
tive Inference toward a more relational, category-theoretic ap-
proach are encouraging (Smithe, 2022). However, category
theory in and of itself is not a silver bullet for conceptual and
theoretical problems. It remains to be seen whether the re-
cent formulations avoid the pitfalls of substance metaphysics
described here.
Acknowledgments
This work was supported by the DFG GRK-RTG 2271
‘Breaking Expectations’ project number 290878970.
768
References
Auxier, R., & Herstein, G. E. (2019).Quantum of explanation
: Whitehead’s radical empiricism.ROUTLEDGE.
Badcock, P. B., Friston, K. J., Ramstead, M. J., Ploeger, A.,
& Hohwy, J. (2019, 12). The hierarchically mechanistic
mind: an evolutionary systems theory of the human brain,
cognition, and behavior. Cognitive, Affective & Behavioral
Neuroscience, 19, 1319. doi: 10.3758/S13415-019-00721-
3
Bickhard, M. H. (2003, 11). Some notes on internal and ex-
ternal relations and representation. Consciousness & Emo-
tion, 4, 101-110. doi: 10.1075/CE.4.1.08BIC
Bickhard, M. H. (2019, 1). Dynamics is not enough: An
interactivist perspective. Human Development, 63, 227-
244. doi: 10.1159/000503826
Bickhard, M. H., & Richie, D. M. (1983). On the
nature of representation: A case study of james
gibson’s theory of perception . Retrieved from
https://philpapers.org/rec/BICOTN
Buckley, C. L., Kim, C. S., McGregor, S., & Seth, A. K.
(2017, 12). The free energy principle for action and per-
ception: A mathematical review. Journal of Mathematical
Psychology, 81, 55-79. doi: 10.1016/J.JMP.2017.09.004
Campbell, R. (2009, 2). A process-based model for
an interactive ontology. Synthese, 166, 453-477. doi:
10.1007/S11229-008-9372-0/METRICS
Campbell, R. (2011). The concept of truth. Palgrave Macmil-
lan UK. doi: 10.1057/9780230307803
Colombo, M., & Wright, C. (2021, 6). First principles
in the life sciences: the free-energy principle, organi-
cism, and mechanism. Synthese, 198, 3463-3488. doi:
10.1007/S11229-018-01932-W/METRICS
Costa, L. D., Friston, K., Heins, C., & Pavliotis, G. A.
(2021, 12). Bayesian mechanics for stationary pro-
cesses. Proceedings of the Royal Society A, 477. doi:
10.1098/RSPA.2021.0518
Friston, K. (2010, 1). The free-energy principle: a unified
brain theory? Nature Reviews Neuroscience 2010 11:2, 11,
127-138. doi: 10.1038/nrn2787
Friston, K., Costa, L. D., & Parr, T. (2021, 8). Some
interesting observations on the free energy principle.
Entropy 2021, Vol. 23, Page 1076 , 23, 1076. doi:
10.3390/E23081076
Friston, K., Costa, L. D., Sakthivadivel, D. A. R., Heins, C.,
Pavliotis, G. A., Ramstead, M., & Parr, T. (2022, 10). Path
integrals, particular kinds, and strange things.
doi: 10.48550/arxiv.2210.12761
Friston, K., Kilner, J., & Harrison, L. (2006, 7). A free energy
principle for the brain. Journal of Physiology-Paris, 100,
70-87. doi: 10.1016/J.JPHYSPARIS.2006.10.001
Friston, K., Samothrakis, S., & Montague, R. (2012, 10).
Active inference and agency: Optimal control without cost
functions. Biological Cybernetics, 106, 523-541. doi:
10.1007/S00422-012-0512-8/METRICS
Koutroufinis, S. A. (2017, 4). Organism, machine, process.
towards a process ontology for organismic dynamics. Or-
ganisms. Journal of Biological Sciences, 1, 23-44. doi:
10.13133/2532-5876/13878
Kwisthout, J., & van Rooij, I. (2020, 6). Computa-
tional resource demands of a predictive bayesian brain.
Computational Brain and Behavior, 3, 174-188. doi:
10.1007/S42113-019-00032-3/FIGURES/4
Kwisthout, J., Wareham, T., & Rooij, I. V . (2011, 7).
Bayesian intractability is not an ailment that approxima-
tion can cure. Cognitive Science, 35, 779-784. doi:
10.1111/J.1551-6709.2011.01182.X
Millidge, B., Tschantz, A., & Buckley, C. L. (2021, 2).
Whence the expected free energy? Neural Computation,
33, 447-482. doi: 10.1162/NECO A 01354
Paolo, E. A. D., Thompson, E., & Beer, R. D. (2022, 1).
Laying down a forking path: Tensions between enaction
and the free energy principle. Philosophy and the Mind
Sciences, 3. doi: 10.33735/PHIMISCI.2022.9187
Parr, T., Pezzulo, G., & Friston, K. J. (2022). Ac-
tive inference. The MIT Press. doi: 10.7551/MIT-
PRESS/12441.001.0001
Raghuveer, D., & Endres, D. (2023). Active inference
and psychology of expectations: A study of formalizing
violex. Communications in Computer and Information
Science, 1721 CCIS, 235-250. doi: 10.1007/978-3-031-
28719-0 17
Raja, V ., Valluri, D., Baggs, E., Chemero, A., & Ander-
son, M. L. (2021, 12). The markov blanket trick:
On the scope of the free energy principle and active
inference. Physics of Life Reviews, 39, 49-72. doi:
10.1016/J.PLREV .2021.09.001
Ramstead, M. J., Friston, K. J., & Hip ´olito, I. (2020, 8).
Is the free-energy principle a formal theory of semantics?
from variational density dynamics to neural and phenotypic
representations. Entropy 2020, Vol. 22, Page 889, 22, 889.
doi: 10.3390/E22080889
Ramstead, M. J., Kirchhoff, M. D., & Friston, K. J. (2020,
8). A tale of two densities: active inference is enac-
tive inference. Adaptive Behavior, 28, 225-239. doi:
10.1177/1059712319862774
Ramstead, M. J., Sakthivadivel, D. A. R., Heins, C., Koudahl,
M., Millidge, B., Costa, L. D., . . . Friston, K. J. (2022,
5). On bayesian mechanics: A physics of and by beliefs.
Retrieved from http://arxiv.org/abs/2205.11543
Rosen, R. (1985, 1). Organisms as causal systems which
are not mechanisms: An essay into the nature of complex-
ity. Theoretical Biology and Complexity, 165-203. doi:
10.1016/B978-0-12-597280-2.50008-8
Rutar, D., de Wolff, E., van Rooij, I., & Kwisthout, J. (2022,
6). Structure learning in predictive processing needs revi-
sion. Computational Brain and Behavior, 5, 234-243. doi:
10.1007/S42113-022-00131-8/FIGURES/3
Seibt, J. (2010). Particulars. Roberto Poli & Johanna Seibt
(eds.), Theories and Applications of Ontology., 23-55.
Smith, R., Friston, K. J., & Whyte, C. J. (2022, 4). A step-
769
by-step tutorial on active inference and its application to
empirical data. Journal of mathematical psychology, 107.
doi: 10.1016/J.JMP.2021.102632
Smithe, T. S. C. (2022, 12). Mathematical foundations for a
compositional account of the bayesian brain. arXiv.
770