npj |complexity Article
https://doi.org/10.1038/s44260-024-00026-8
Characterizing the sense of agency in
human–robot interaction based on the free
energy principle
Check for updates
Wataru Ohata & Jun Tani
Social interaction takes various forms, ranging from cooperation to conﬂict. The current study focused
on competition between top-down and bottom-up information processes in perception and action
generation in social interaction, based on the free energy principle. In particular, it attempted to
account for the sense of agency. We built a computational model for multimodal social interaction with
a variational Bayes recurrent neural network, based on the free energy principle, and we evaluated the
model in imitative interaction between a human and a robot. Ourﬁndings demonstrate that when
prioritization of the top-down process is enhanced, the robot behaves egocentrically, leading the
human more and manifesting a stronger sense of agency. Conversely, when this prioritization is
reduced, the robot tends to modify its intention so that it aligns with that of its human counterpart,
suggesting a weaker sense of agency. We also proposed a computational model for a multifactorial
account of the sense of agency and examined the correspondence between the experimental results
and the model. The study reveals the underlying mechanism of social interaction dynamics and the
resultant sense of agency by conducting a rigorous analysis of the neural internal representation, as
well as the behaviors of the human and the robot.
Even though humans engage in various forms of social interaction, ranging
from cooperation to conﬂict, underlying mechanisms shaping these
dynamics remain unknown. By focusing speciﬁcally on the sense of agency,
this study sought to discover its possiblerelationship with social interaction
dynamics. We employed the free energy principle1–4, a prominent theory in
neuroscience, as the theoretical underpinning of this study. Based on the free
energy principle (FEP), we proposea computational model for social
interaction using a variational Bayes recurrent neural network and evaluate
the model in a human–robot interaction (HRI) experiment.
Sense of agency (SoA)
5–10 refers to one’s action authorship, a subjective
feeling that“I am the one who is generating this action,”and is thought to
contribute to minimal self, the fundamental aspect of sense of self, which is
pre-reﬂective and does not extend in time
5. The SoA is thought to be
registered by congruence between prediction of action-outcome and actual
observation11,12.T y p i c a l l y ,s t u d i e so fS o Ar e l yon either implicit or explicit
measurement of SoA13. On the one hand, implicit measurement assesses the
SoA with behavioral or neurophysiological correlates of voluntary action,
without inquiring about the subjective experience of agency. The intentional
binding effect14, an experience of compression of time between a voluntary
action and its sensory feedback, is often employed as an indicator of SoA.
While methodologies using intentional binding are widely accepted, recent
studies have challenged the current conceptualization of intentional binding
and its relationship with SoA15–18. On the other hand, explicit measurement
asks human subjects about their sense of agency, usually through ques-
tionnaires, but results commonly manifest substantial variation among
individuals that confounds attempts to draw clear conclusions. While stu-
dies using these methodologies have provided substantial insight into the
nature of SoA, approaches using computational models
19,20 should be able to
compensate for the aforementionedshortcomings in order to enhance
understanding of SoA, as such studies enable direct and objective evaluation
of the SoA.
In situations involving social interactions in which multiple agents
interact, it becomes laborious for them to maintain their SoAs because when
an agent acts on others, they may not behave as predicted, which leads to a
mismatch between the prediction of action outcome and observation,
hindering registration of the SoA. For instance, in the case of dyadic
interaction, leader–follower relationships can emerge through the interac-
tion, and it is assumed that the leader and follower perceive different degrees
of their SoA based on the prediction error of their action outcome. Con-
sidering a conﬂict situation, e.g., two people start talking at the same time in
a conversation. One of them leads the interaction, e.g., continuing to talk,
and is considered to reinforce his (or her) SoA because he can execute
Cognitive Neurorobotics Research Unit, Okinawa Institute of Science and Technology Graduate University, Okinawa, Japan.e-mail: jun.tani@oist.jp
npj Complexity|            (2025) 2:12 1
1234567890():,;
1234567890():,;
actions as he intends. In contrast, the other one has to adjust his original
i n t e n t i o na n dm o d i f yh i sa c t i o no nt h es pot, e.g., stopping talking, to follow
the leader, which is deemed to diminish his SoA due to a discrepancy
between his original prediction andobservation. As such, context and
situation inﬂuence how each agent behaves in social interaction, and
emergent interaction dynamics alter the SoA that each agent perceives.
To formulate the problem of the relationship between the SoA and
social interaction dynamics, we introduce the FEP
1–4 as the theoretical basis
of the study. The FEP is a theory originating in theﬁeld of neuroscience that
has attracted considerable attention recently. The FEP posits that biological
agents execute various functions to maximize their chances of survival, such
as learning, perception, and action generation, to minimize surprises they
encounter in the environment. According to the FEP, these functions are
achieved by optimizing generative models for predicting the sensation,
whereby a common statistical quantity called free energy is minimized. In
the case of perception, free energy is deﬁned as the upper bound of surprise
or negative marginal log-likelihood, and it can be decomposed into two
terms: complexity and accuracy.
/C0 log pðXÞ|ﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄ}
surprise
≤
Z
qðzjXÞlog qðzjXÞ
pðX; zÞdz
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
free energy
ð1Þ
¼DKL½qðzjXÞkpðzÞ/C138|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
complexity
/C0 EqðzjXÞ½log pðXjzÞ/C138
|ﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ{zﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄﬄ}
accuracy
ð2Þ
where X and z are observation and latent state, respectively;p(z)a n dq(z∣X)
are the prior and variational approximate posterior density, respectively.
The complexity term is the Kullback-Leibler (KL) divergence between the
variational posterior and prior density, estimating dissimilarity between
them. The accuracy term is the expectation of log-likelihood with respect to
the approximate posterior, quantifying how the current recognition
matches the observation. In minimizing the free energy, minimization of
the complexity term and maximization of the accuracy term occur
simultaneously. While the former enforces the prior on the posterior
approximation, contributing to a top-down process based on prior
experience, the latter modiﬁes the posterior to enhance a bottom-up
process adapting to the observation. Thus, free energy minimization
involves a competition between top-down and bottom-up information
processing, and the balance between them is essential for learning and
adaptation.
Previous research on the FEP using artiﬁcial neural networks has
explored the complexity–accuracy balance during supervised training
21,
where it is demonstrated that alternating the balance develops different
traits of networks, such as generating prediction more deterministically or
randomly, through learning. The study has been extended to examine social
cognition, showing that the change in the complexity–accuracy balance
during training leads to different behaviors in social interaction22–24.H o w -
ever, these characteristics are rather permanent. An agent learning to lead
the interaction always tries to lead, and one learning to follow tries to follow
all the time. Given individual propensities to exhibit varying behaviors in
different contexts, we speculate that there should be a mechanism to
modulate behavior in social interaction, depending on the context. Based on
this notion, our previous study hypothesized that a change in the balance
between complexity and accuracy terms during the interaction should
modify behavior, thereby modulating the strength of the SoA in social
interaction
20.T h i ss t u d ye v a l u a t e dt h i sh y p o t h e s i si nas i m u l a t i o ne x p e r i -
ment of pseudo-imitative interaction between a human and a robot, in
which the robot imitated a human’s pre-recorded movements and pre-
sented supportive results.
The current study extends the previous simulation study to actual HRI
experiments to test the hypothesis further. We built a computational model
for multimodal imitative interaction grounded in the FEP by extending our
previous model
20 using a variational Bayesrecurrent neural network21.T o
verify the model, we recruited human subjects and conducted HRI
experiments. We collected data from twenty participants and analyzed them
from various perspectives to reveal the complexity–accuracy balance in the
interaction, interaction dynamics, and resultant modulation of the strength
of the SoA. These analyses include those based on behavioral data of the
human and the robot, the network’s prediction error, an estimation of
information-theoretic quantity in the interaction, and the network’s internal
representation. Our ﬁndings are consistent with the aforementioned
hypothesis and demonstrate that modifying the complexity–accuracy bal-
ance during interaction inﬂuences interaction dynamics, resulting in
modulation of the strength of the SoA in HRI. Particularly, when prior-
itization of minimizing the complexity term is enhanced, the robot exhibits
more egocentric behavior, exerting greater inﬂuence on the human, and
indicating a stronger SoA. Conversely, when this prioritization is reduced,
the robot displays a tendency to adjust its intentions to align them with those
of humans, suggesting a weaker SoA.
Results
Computational model
To study social interaction dynamics, we introduce a computational model
for multimodal interaction by extending a model from our previous study
20
that utilizes a variational Bayes recurrent neural network, called PV-RNN21
(Fig. 1c). We employed a model based on the PV-RNN as the PV-RNN is
the only neural network model groundedi nt h eF E P ,t oo u rk n o w l e d g e ,t h a t
allows the control of the balance between top-down and bottom-up
Fig. 1 | Movement patterns and network architecture. aPictures of two movement patterns and a transition between them.b A probabilisticﬁnite state machine underlying
the movement pattern transition.c A schematic of the network architecture.
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 2
information processes and is desirable to investigate the problem of interest.
This model comprises associative, proprioception, and vision modules. It
has a hierarchical structure, in which the associative module at the top
conditions the peripheral proprioception and vision modules. The pro-
prioception module generates predictions of the robot’sj o i n ta n g l e s ,w h i c h
model its proprioception and are used for robot control. The vision module
generates predictions of human body movements during the interaction.
Importantly, the links between the visual and proprioceptive modules,
and predictions of both from the same associative module, mean that it is as
if the robot believes the visual and proprioceptive data are both measures of
the same hand position. In other words, it is as if the robot sees the human
hand as its own, reﬂected in a mirror. Crucially, this means inferences drawn
from the visual modality can be used to predict the proprioceptive data
expected if the robot hand were in the same position as the human hand, and
to use these predictions to drive the controller. It is this that allows the robot
to synchronize with human movements-much as a “mirror-neuron”
system
25 is sometimes thought to underwritebiological imitation. However,
it will only do so when it is permitted to deviate from its prior belief about its
own motor patterns.
One of the characteristics of the model is that visual sensation is based
on a virtual reality device that directly measures human posture. During the
experiment, the human holds a VR controller in his hand, the position of
which becomes the target for the prediction of the vision module of the
network. We employ the VR controller only to measure the human’sh a n d
position efﬁciently and to facilitate data analyses. Other VR devices, such as
a head-mount display, were not used in this study. Details of the compu-
tational model refer to“Network computation”. Dataset preparation and
network training prior to the experiment are described in“Dataset pre-
paration”and “Network training”, respectively.
Experimental design
We used a humanoid robot (Torobo, developed by Tokyo Robotics, a dis-
continued model) for the experiment (Fig.1a). Torobo is a torso-type
humanoid robot invented for research use and is as large as an adult person
when ﬁxed on its base (see also Fig.2). The robot has six joints in each arm
and seven in its torso and head. As explained below, we only used its left arm
for the experiment.
In these experiments, the human and the robot performed mutual
imitation using pre-designed movement patterns following certain transi-
tion rules. There are three movement patterns: pattern A, pattern B, and the
transition pattern (Fig.1a). One repetition of pattern A moves the left arm
horizontally from right to left, fromthe perspective of the human standing
in front of the robot, and returns to the starting position at shoulder height
(Fig. 1a). Similarly, one cycle of pattern B moves the left arm from left to
right and returns to the starting position at waist height. Patterns A and B are
smoothly connected through the transition pattern, which moves the left
a r me i t h e rf r o mt o pr i g h tt ob o t t o ml e f to rf r o mb o t t o ml e f tt ot o pr i g h t .
These movement patterns switch according to the probabilisticﬁnite state
machine (PFSM) (Fig.1b). After performing pattern A, the robot either
switches to the transition pattern with a 50% chance or repeats pattern A
once again with a 50% chance, and following pattern B, the robot ether
switches to the transition pattern orcontinues pattern B with a 50% chance.
The transition pattern is not implemented twice in a row, which is why states
S
0
1 and S0
2 are included in the PFSM, in order to decrease the number of
possible random transitions during the interaction.
As the PFSM includes random transitions, the human and the robot
may encounter conﬂicting situations during the interaction. For instance,
after pattern A, while the human tries toswitch to the transition pattern, the
robot tries to repeat pattern A. One of the focus points of the study is how the
human and the robot behave in such conﬂicting situations. If the robot leads
the interaction and continues pattern A, and the human changes his
movement pattern from the transitionpattern to pattern A, the robot would
perceive a stronger sense of agency as a result of congruence between the
robot’s prediction and observation. In contrast, if the robot follows the
interaction and switches to the transition pattern, and the human continues
the transition pattern, the robot would acquire a weaker sense of agency due
to the violation of prediction.
Human– robot interaction experiment
We recruited 20 healthy adults from the institute to participate in the
experiment. Prior to the experiment, participants watched an instruc-
tional video describing the task and movement patterns that the robot
performs. The task description asked participants tokeep the movement of
the human and the robot as synchronized and smooth as possible. It did not
ask the participants to lead or follow the robot during trials, so the
interaction between the participants and the robot was emergent and
spontaneous. Figure2 shows the appearance of the experiment. When
participants started a trial, they were asked to stand in front of the robot
and to raise their right arms at shoulder height with their right hand
holding a VR controller. The robot raised its left arm at the same height
(Fig. 2a). During the trial, the participant and the robot tried to imitate
each other such that their movements were synchronized and smooth, as
if facing a mirror (Fig.2b)
26.
In the experiment, two conditionsw1 and wlarge (Table 1)w e r ep r e -
pared, in which a hyperparameter called the meta-prior21, denoted asw,w a s
varied. The meta-prior weights the complexity term in the free energy
(“Online posterior inference”). While models with a larger meta-prior,w
large
condition, prioritize minimizationof the complexity term more, modeling
agents driven by top-down intention, with smaller meta-priors,w1 condi-
tion, do so less. Such modeling agentsare propelled by bottom-up sensation.
Thus, this experiment examines how altering the complexity–accuracy
balance affects interaction dynamics and the resultant SoA by comparingw1
and wlarge conditions.
Fig. 2 | Experimental procedure.The participant is
holding a VR controller in his right hand.a Starting
position of the experiment.b A snapshot of the
experiment. The human and the robot were per-
forming the movement pattern A in Fig.1.
Table 1 | Meta-prior values used in the human– robot
interaction experiment
w1 wlarge
Associative modulewa
er 0.1 40.0
Proprioception modulewp
er 5.0 5.0
Vision modulewv
er 10.0 10.0
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 3
Figure 3 exempliﬁes how different meta-prior values affect the pos-
terior inference and subsequent robot’sa c t i o ns e l e c t i o n .C o n s i d e ras i t u a -
tion in which the robot was predicting the movement pattern A before
observation, but observing the human performing the transition pattern,
denoted as“T”in Fig.3 (Fig. 3 l e f t ) .T h ea s s o c i a t i v em o d u l eo ft h en e t w o r k
predicts the movement pattern A with prior belief, which conditions the
vision module predicting to observe the human counterpart performing
pattern A and the proprioception module generating pattern A. Then,
observing the human performing thetransition pattern T gives rise to a
mismatch in visual prediction, decreasing the accuracy term in the free
energy. After posterior inference, in the case of a small meta-prior (Fig.3 top
right), the approximate posterior in thea s s o c i a t i v em o d u l ec a nd e v i a t ef r o m
the prior to maximize the accuracy term owing to relaxation of the com-
plexity term minimization. As a result, the vision module recognizes the
human’s transition pattern T, resolving the mismatch, and the proprio-
ception module switches to generate the transition pattern T accordingly. In
contrast, a large meta-prior prevents the approximate posterior from
diverging from the prior due to the prioritization of the complexity term
minimization (Fig.3 bottom right). In this case, the visual recognition
remains consistent with the prediction before the posterior inference
without reconciling the mismatch, and the proprioception module keeps
generating pattern A.
Table 1 summarizes the meta-prior values for each module in the
network inw
1 and wlarge conditions. Calculation of meta-prior values and
computation of the free energy with the meta-prior during the interaction
are detailed in“Methods”in “Online posterior inference”and “Meta-prior
values in human–robot interaction”, respectively.
Each participant was asked to complete 10 trials, each of which took
1m i n . T h eﬁrst four trials were considered warm-up sessions, and the
remaining six were used for analysis. During these ten trials, participants
interacted with the robot inw
1 and wlarge conditions, which were unknown
to participants. Trials were performed twice each in the two conditions in
the warm-up trials and three times each in the test trials, so the number of
trials for each condition was equal. The order of the conditions was ran-
domly selected. During the interaction, the joint angle of the robot’sl e f ta r m ,
the coordinates of the human’s VR controller, and the internal activities of
the network model were recorded. A recorded video of preliminary
experiments with animation of network internal representation is available
in Supplementary Information S.1.
Analysis of behavioral data
We ﬁrst examined the behavioral data to ascertain the relationship between
the meta-prior conditions and the movement patterns that the human and
the robot performed during the interaction. Recorded data were labeled
based on the three predeﬁned movement patterns, A, B, and the transition
between them (“Movement pattern labeling”). Fig. 4a–c summarize the
analysis based on labeled movement trajectories of the human and robot.
Fig. 4a shows the mismatch rate between human and robot movement
patterns: how much the human and robot movement patterns were asyn-
chronous in terms of movement labels (Algorithm 2). Each data point
represents the mean of trials in either thew
1 or wlarge condition for each
participant. A paired T-test (n = 20) did not show statistical signiﬁcance
(p = 0.184), suggesting that the human and robot movement patterns were
synchronized, or not synchronized, to the same degree in both conditions.
Fig. 4b visualizes the re-match rate: how much the human and robot
movement patterns aligned one time-step after a mismatch occurred
(Algorithm 2). A paired T-test (n = 20) did not show statistical signiﬁcance
(p = 0.600), indicating that the human and robot movement patterns
aligned after the mismatch to a similar degree in both conditions. Fig.4c
illustrates the rate of re-matching by the human changing the movement
patterns: how frequently the human changed his movement patterns to
those of the robot when a mismatch occurred (Algorithm 2). A paired T-test
Fig. 3 |An example of how different meta-prior values affect the posterior inference and the subsequent action selection during the interaction.
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 4
(n = 20) suggested that humans changed their movement patterns more
frequently inwlarge c o n d i t i o nt h a ni nt h ew1 condition (p =1 . 6 7×1 0−3). On
the other hand, Fig.4d compares the rate of alignment by the robot changing
its movement patterns: how frequently the robot changed its movement
patterns to those of the human after a mismatch (Algorithm2). A paired
T-test (n = 20) showed a tendency for the robot to change its movement
patterns more frequently in thew
1 c o n d i t i o nt h a ni nt h ewlarge condition
after a mismatch (p =8 . 7 9×1 0−5).
These results indicate that while human and robot movement patterns
were synchronized and re-matched after a mismatch to a similar degree
both inw
1 and wlarge conditions, which agent changed its movement pat-
terns to resolve a mismatch differed. Speciﬁcally, humans changed their
movement patterns more frequently in thewlarge than in thew1 condition,
and the robot changed its movement patterns more often in thew1 than in
the wlarge condition. These imply that, in a conﬂicting situation in which the
movement patterns of the human and the robot did not match, they took
different roles in order to coordinate the interaction, depending on pressure
on the complexity term minimization. In thew
1 condition, the robot seemed
to adapt to the human with ease, inducing the human to exert his intention.
Consequently, the leader–follower relationship seemed to be formed
through interaction: the human becoming a leader and the robot becoming
a follower. In contrast, in thew
large condition, the robot seemed to persist in
its intention, prompting the human toadapt to the robot. As a result, the
human and the robot seemed to play the opposite roles as in thew1 con-
dition. Therefore, it is suggested that modifying the complexity–accuracy
balance gave rise to different interaction dynamics for cooperation between
the human and the robot.
Analysis of prediction error
We then investigate the prediction error that the robot encountered during
the interaction in relation to the meta-prior conditions. Fig.4e and f provide
an analysis based on the robot’s prediction error. Computation of the pre-
d i c t i o ne r r o ri sp r o v i d e di n“C o m p u t a t i o no fp r e d i c t i o ne r r o ri nF i g .4”.
Figure 4e compares the prediction error in proprioception inw1 and wlarge
conditions, which estimates how much the robot generated its action as it
intended. A paired T-test (n = 20) revealed that the prediction error in
proprioception tended to be smaller in thewlarge c o n d i t i o nt h a ni nt h ew1
condition (p =3 . 8 0×1 0−3). Similarly, Fig.4f shows the prediction error in
vision, which quantiﬁes how much the human behaved as the robot pre-
dicted. A paired T-test (n = 20) indicated that the prediction error in vision
also tended to be smaller in thewlarge c o n d i t i o nt h a ni nt h ew1 condition
(p =1 . 8 9×1 0−3).
These results show that the prediction error both in proprioception and
vision was smaller in thewlargecondition, in which the robot moved as it had
predicted and the human interacting with the robot also moved as the robot
had predicted. Moreover, assuming thata small prediction error contributes
to a strong sense of agency, these results suggest that the robot perceived a
stronger sense of agency in thew
large c o n d i t i o nt h a ni nt h ew1 condition.
Analysis of transfer entropy
Obtained data were further analyzed from an information-theoretic per-
spective to investigate a different aspect of the interaction. Particularly, we
utilized transfer entropy27 to estimate how much each agent’s behavior
affected the other’s. The transfer entropy quantiﬁes a non-parametric
directed informationﬂow between two coupled random processes, and its
application to analyses of social interaction is often reported as it provides a
ﬂexible framework for analysis and requires less assumption in studies
28–30.
We estimated the transfer entropy from the human to the robot as well as
from the robot to the human during the interaction and evaluated which
agent affected the other more in different conditions (“Estimation of transfer
entropy in Fig.5”).
Figure 5a, b shows the estimated transfer entropy from the human to
the robot and from the robot to the human inw
1 and wlarge conditions,
respectively. Paired T-tests (n = 20) suggest that the transfer entropy from
the human to the robot was larger in thew1 condition (p =1 . 4 3×1 0−3)a n d
that from the robot to the human is larger in the wlarge condition
(p =1 . 6 7×1 0−3).
These results indicate that the predictability of the human’s movement
from the previous history of the robotmovement increased, and that of the
robot’s from the human’s decreased, as the meta-prior value increased. In
Fig. 4 | Analysis based on movement patterns and prediction error.Analysis based
on observed movement patterns (a–d) and prediction error evaluated by negative
log-likelihood (NLL) (e, f). Two dots linked by a gray line indicate the same subjects
in w1 and wlarge conditions. n.s., *, and** indicate p > 0.05,p ≤ 0.05, andp ≤ 0.001 in
paired T-test (n = 20), respectively.a Mismatch rate throughout the interaction.
b The re-match rate after a mismatch.c The rate of re-matching by the human
changing the movement patterns.d The rate of alignment by the robot changing the
movement patterns.e Prediction error in the proprioception module.f Prediction
error in the vision module.
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 5
other words, the causal relationship from the robot’s movement to the
human’s was enhanced, suggesting that the robot took more of a leading role
in the interaction. While the results in Fig. 4c, d indicate the the
leader–follower relationship based on the labeled movement patterns, these
results support it using the information-theoretic framework.
Analysis of network internal representation
As we employed a variational Bayes recurrent neural network to model social
interaction, analyses of the network internal representation, especially how
the prior and inferred posterior density changed during the interaction, also
provided insight into the relationship between meta-prior conditions and
the robot’s recognition (“Computation of KL divergence in Fig.5”). Fig.5c, d,
e shows the dissimilarity evaluated by the KL divergence between the prior
before the observation and the approximate posterior after the inference in
the associative, proprioception, andvision modules, respectively. Paired
T-tests (n = 20) indicated that the KL divergence was smaller in thew
large
condition (p =3 . 8 2×1 0−6 for the associative module;p =1 . 0 3×1 0−5 for the
proprioception module;p =2 . 2 8×1 0−5 for the vision module).
These results suggest that prediction before the observation and the
recognition after observation are better aligned whenw is large. In other
words, the robot perceived less conﬂict at the latent state label. Considering
that a small conﬂict at the latent state also reinforces the SoA, the robot was
suggested to receive a greater and lesser SoA inwlarge and w1 conditions,
respectively. Whereas the results in Fig.4e, f indicate different degrees of
SoA based on the prediction error at sensory level, these results support it in
terms of the conﬂict at latent, intentional level.
Model for multifactorial account of the sense of agency
Recent studies have proposed that the sense of agency emerges as a result
of a multifactorial process7,31,32. According to these studies, two steps of
agency underpin the registration of the sense of agency: the feeling of
agency (FoA) and the judgment of agency (JoA). The FoA is registered
through a low-level, implicit, pre-re ﬂective process. This process
involves a comparison between prediction of action outcome and actual
observation (the comparator model)
11,12. In contrast, the JoA is formed
through a high-level, reﬂective, inferential process, which considers
other factors, such as thoughts and contextual cues33.W h i l et h eF o A
usually remains intact when there is no mismatch between prediction
and observation, the process of registering the JoA is triggered when the
prediction is violated, in which the JoA is manifested if the cause of the
unexpected observation is attributed to the agent. Here we attempt to
interpret experimental results from the viewpoint of the multifactorial
account of agency.
The FoA is primarily registered by the match between prediction of
action outcome and actual observation. Therefore, we consider the match
between the prediction (generated before the observation) and the actual
observation an indicator of the FoA (“Computation of prediction error in
Fig. 6d, e”). The JoA, on the other hand, appears through the process of
making sense of the observation that originally did not match the prediction.
Thus, we regard the online posterior inference process to minimize the
prediction error as the registration of the JoA. If the inferred posterior aligns
with the prior, which represents habituated environmental dynamics
learned through the association of proprioception and vision
34,t h ec a u s eo f
the unexpected observation is ascribed to the agent, yielding the JoA. If the
inferred posterior deviates from the prior, the prediction error is attributed
to external factors, rejecting registration of the JoA. Therefore, we postulate
that upon encountering an unexpectedobservation, minimizing both pre-
diction error and the difference between the prior and inferred posterior is
an essential component for establishing the JoA (“Computation of predic-
t i o ne r r o ri nF i g .6d, e”).
Fig. 5 | Analysis based on transfer entropy and KL divergence.Analysis based on
transfer entropy (a, b) and KL divergence (c–e). * and ** indicate p ≤ 0.05 and
p ≤ 0.001 in paired T-tests (n = 20), respectively. A gray line connects mean values in
the two conditions from the same participant.a The estimated transfer entropy from
the human to the robot inw1 and wlarge conditions. b The estimated transfer entropy
from the robot to the human.c KL divergence in the associative module.d KL
divergence in the proprioception module.e KL divergence in the vision module.
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 6
Figure 6a presents the correspondence between the proposed model
and the multifactorial account of the sense of agency. The blue arrows
describe a process to register the FoA. The prior belief, conditioned by
observations up to the previous time step, generates the prediction of action
outcome. If the prediction error between prediction and observation is
small, the FoA is registered. The red arrows show a process to attribute the
JoA. After an observation, if the prediction error is substantial, the
approximate posterior is modiﬁed under constraint by the prior, by which
the prediction for the observation isupdated through the forward model to
minimize the prediction error. This process of modifying the posterior and
updating the prediction is repeated under a certain time constraint. Once the
p r e d i c t i o ne r r o ri ss u fﬁciently minimized, indicating that the posterior
managed to make sense of the unpredicted observation, and the modiﬁed
posterior is consistent with the prior, denoting that the model recognizes the
observation as a familiar one, the JoA is marked.
Our analysis of the experimental resul t si nt e r m so ft h em u l t i f a c t o r i a l
account of the sense of agency is summarized in Fig.6b–e. Figure6bs h o w s
the relationship between the predictione r r o ri nv i s i o na n dK Ld i v e r g e n c ei n
the associative module before and after the posterior inference. Computa-
t i o no ft h ep r e d i c t i o ne r r o ri sp r o v i d e di nt h e“Computation of prediction
e r r o ri nF i g .6d, e”. KL divergence values before the inference are always zero
because parameters of the approximate posterior are initialized with those
for the corresponding prior (“Online posterior inference”). The prediction
e r r o rb e f o r et h ei n f e r e n c ei ss m a l l e ri nt h ew
large c o n d i t i o nt h a ni nt h ew1
condition (Fig.6c, p =4 . 4 4×1 0−3 in paired T-test (n = 20)), indicating that
the robot maintained the FoA more in thewlarge condition. While the
prediction error after the inference is minimized to the same degree in both
conditions (Fig.6d, p =8 . 7 9×1 0−2 in paired T-test (n = 20)), KL divergence
values after the inference are smaller in thewlarge condition (Fig. 6e,
p =2 . 8 7×1 0−6 in paired T-tests (n = 20)), suggesting that the model attri-
butes the cause of the observation to itself more in thewlarge condition. On
the other hand, the model imputed the source of the prediction error to the
interacting human more in thew
1 condition. In summary, the robot tended
to lead the human in thewlargecondition, in which the robot detected smaller
prediction errors and preserved the FoA. The robot was apt to follow the
h u m a ni nt h ew
1 condition, in which the prediction error before the pos-
terior inference disturbed the FoA ofthe robot, and the subsequent infer-
ential process ascribed the cause of the prediction error to the human
counterpart, attenuating the JoA of the robot.
Our computational model provides an explanation for the continuous
change in the FoA and the JoA in the multifactorial account of the SoA based
on the prediction error and the difference between the prior and the inferred
posterior. The current experiment did not explore a situation in which the
FoA is reduced, but the JoA is registered. However, in other experimental
scenarios, this model could be employed to examine such situations, which
would improve our understanding of multifactorial characteristics of the
SoA. We discussed such a scenario in Supplementary Information S. 2.
Discussion
This study explored the balance between top-down and bottom-up pro-
cesses in perception and action generation under the FEP, social interaction
dynamics, and the resultant SoA. We modeled multimodal perception and
action generation with a variational Bayes recurrent neural network as an
implementation of the FEP and evaluated it in a human–robot imitative
interaction experiment. Particularly, we modiﬁed the complexity–accuracy
balance in the free energy during the interaction, by altering the value of
meta-prior, to model two different agential conditions: thew
1 condition for
an agent driven by bottom-up process and thewlarge condition for an agent
driven by top-down process. The experiment participants interacted with
the robot under these two conditions, and the interaction was analyzed from
various perspectives.
We ﬁrst characterized the interaction by categorizing the movement
trajectories of both the human and the robot into distinct movement pat-
terns. We then quantiﬁed the relative roles of the agents— who led and who
followed— when their movement patterns did not align. Our analysis
revealed that as the top-down process became more dominant, the robot
shifted from following the human to leading the human. Next, we measured
the prediction error perceived by the robot during the interaction as an
indicator of its SoA. Our results showed that the prediction error decreased
as the prioritization of the top-down process increased, suggesting that the
robot’sp e r c e p t i o no fi t sS o Aw a se n h a n c ed. We also estimated the transfer
entropy between the human’s and robot’s movements to infer the causal
relationship between them. As the top-down process gained dominance, we
observed a decrease in the transfer entropy from the human to the robot and
an increase in the transfer entropy from the robot to the human. This shift
suggests that the robot’s movement increasingly inﬂuenced the human’s
movement, which aligns with the results from our analysis of the categorized
movement patterns. Focusing on the network model performing variational
inference, we computed the dissimilarity between the prior and the inferred
posterior as a measure of the incongruity between the robot’s prediction and
recognition at the latent state level. The dissimilarity also decreased as the
top-down process became more inﬂuential, further indicating a reinforce-
ment of the robot’s SoA. While the earlier analysis based on prediction error
related sensory-level congruence to the SoA, this analysis, based on the
prior–posterior dissimilarity, related the alignment at the latetnt state level
to SoA. Finally, integrating these two levels of contributors to the SoA, we
Fig. 6 | Analysis based on multifactorial account of sense of agency. aA model of
the multifactorial account of the sense of agency. The blue arrows are a model to
register the feeling of agency. The blue arrows are a model to form the judgment of
agency via an inferential process.b–e The prediction error in vision and KL diver-
gence before and after the posterior inference in the associative module.n.s., *, and**
indicate p > 0.05,p ≤ 0.05, andp ≤ 0.001 in paired T-tests (n = 20), respectively.b The
relationship between the prediction error in vision measured by negative log-like-
lihood(NLL) and the KL divergence between the prior and approximate posterior in
the associative module before and after the error regression (ER). A pair of symbols
linked by a line indicates the mean of trials for a participant before and after posterior
inference in eitherw
1l or wlarge condition. c The prediction error in vision before the
posterior inference. Each dot represents the mean of trials for a participant in either
w1 or wlarge condition. A gray line links the mean values in the two conditions from the
same participant.d The prediction error in vision after the posterior inference.e The
KL divergence between the prior and approximate posterior in the associative module
after the posterior inference inw1 and wlarge condition.
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 7
proposed a novel model for the multifactorial account of the SoA, in which
both the FoA and the JoA are framed within the context of variational
inference. We demonstrated how the proposed model corresponds with our
experimental results and highlighted the continuous changes in FoA and
JoA in response to shifts in the balance between top-down and bottom-up
processes. Our study demonstrates a novel approach to the study of the SoA
of an artiﬁcial agent
35,36, which directly assesses the SoA based on an
objective metric, in contrast to studies that use indirect or subjective metrics,
and it offers insights into mechanisms underlying diverse social interaction
dynamics from the perspective of the SoA.
In this study, we used meta-prior tocontrol the interplay between top-
down and bottom-up information processing for the perception and action
generation of the robot, and examinedhow the meta-prior values affected
the robot’s sense of agency. Considering the robot as a simpliﬁed model of a
human, it is speculated that humans may also have an implicit equivalence
to the meta-prior, and we could infer the sense of agency of the human by
estimating the human’s meta-prior. In this respect, the current experiment
setup could be extended to do so. In theimitative interaction experiment in
this study, if the meta-prior value is titrated until the leader–follower rela-
tionship between the human and the robot switches, it should estimate that
of the human, indicating the strength of the sense of agency. This direction
of research may pave the way not only for measuring the sense of agency of a
human but also for computationally phenotyping each individual’sp s y -
chiatric traits
37.
In the experiment presented in this study, the values of the meta-prior
were ﬁx e di ne a c ht r i a l .T h i si sas i t u a t i o ni nw h i c ht h ec h a r a c t e r i s t i c so ft h e
robot are rather constant during interaction with humans, so the robot tends
to maintain a leading or following role throughout the trial. Looking at
human social interaction, however, humans do not always lead or follow
others. Instead, the roles of leader and follower can change, depending on
context and situation. Such turn-taking between leader and follower occurs
in various situations, such as conversation
38, pre-verbal communication
between infant and mother39, and imitating behavior40. As an extension of
the current study, mechanisms underlying turn-taking should be con-
sidered for a better understanding of the dynamics of social interaction.
Prior studies have proposed a possible explanation for turn-taking in
modeling studies
41–43, in which turn-taking emerges as a result of interaction
in an unstable coupled dynamical systems. Turn-taking behavior has also
been studied using robots44–46.N o t a b l y ,W i r k u t t i se ta l .46 employed a similar
framework based on the free energy principle and demonstrated that turn-
taking behavior developed in robot–robot interaction when the balance
between the complexity and accuracy terms in free energy took particular
settings in two robots. While this study successfully explained turn-taking
behavior, the experimenter must provide meta-prior values for the two
interacting robots. Thus, we consider an alternative model for turn-taking
behavior. The value of the meta-prior changes dynamically during the
interaction. This model expects that values of the meta-prior in dyadic
agents compromise each other such that the agent with a larger meta-prior
leads the other, and these roles switch autonomously during the interaction
in response to the change in values of the meta-prior.
Since the computational model in this study rests on the free energy
principle, the scope of which encompasses neural computation in the bio-
logical brain, it is worthwhile to consider some implications of the study to
neuroscience. First, the results of this study may provide new insight into the
role of the mirror-neuron system
20. In the imitative interaction, the asso-
ciative module of the network model serves to both recognize and generate
the same action of the human and the robot, respectively, which can be
considered a model for mirror-neuron system
25. When the bottom-up
process of the robot is enhanced with a small meta-prior, the robot infers the
posterior so as to recognize the human’s movement pattern, and it generates
the recognized movement pattern. In contrast, when the top-down process
is prioritized with a large meta-prior, the robot infers the posterior to be
consistent with the prior and generates its movement without considering
the human’s. This suggests that the mirror-neuron system may play a dual
role, adaptive and persistent behavior, in social interaction, based on the
balance between top-down and bottom-up information processing. Second,
such a change in the balance may be attributed to neuromodulators in the
brain. How the top-down and bottom-up signals interact boils down to the
precision of prediction in variational inference. In this regard, the literature
on active inference has suggested that dopamine plays a key role in con-
trolling precision
47. Furthermore, previous studies have reported other
neuromodulators, such as acetylcholine and noradrenaline, are involved in
the modulation of the transmissionof top-down and bottom-up signals48.
These indicate that different social interaction dynamics, such as the
emergence of leader–follower relationships shown in this study, might be
accounted for by the effect of one or more neuromodulators on information
processing in the brain.
Methods
Network computation
Figure7 shows variable dependencies in the proposed network model. As in
ref. 20, each module comprises two types of hidden variables,d and z,i n
whichd follows a delta distribution andz follows a normal distribution. The
superscripts ofa, p,a n dv in those represent the associative, proprioception,
and vision modules, respectively. The subscriptt denotes the time step./C22Xp
t
and /C22Xv
t are the prediction for proprioceptive and visual observationsXp
t and
Xv
t , respectively. One of the important modiﬁcations of the previous network
model is that the network output follows a normal distribution. Whereas the
previous network model used in ref.20 only had a deterministic repre-
sentation of the network output, the current model has a probabilistic
representation and predicts observation noise through learning. With this
probabilistic representation of thenetwork output, the network not only
becomes more robust to observation noise, but is also able to weight the
prediction error based on its precision
49,50, making the model more con-
sistent with formulation of the FEP. While the network model used in ref.20
did not have a direct connection between the proprioception module and the
vision module, such connections are introduced in the current model to
enhance the association between the proprioception and vision modules
(Fig. 1c). Each of the modules consists of a one-layer PV-RNN. The fol-
lowing describes the computation scheme of the generative model for the
visuo-proprioceptive prediction, followed by that of the inference model.
Computation of the generative model. Computation of the generative
model is described for each module. In the associative module, compu-
tation of the prior density is based on the idea of a conditional prior
51,i n
which parameters for the prior density are mapped from a deterministic
latent state in the previous time step:
pðz
p;a
t Þ¼ Nðzp
1; μp;a
1 ; diag ðσp;a
1 ÞÞ if t ¼1
pðzp;a
t jda
t/C01Þ¼ Nðzp;a
t ; μp;a
t ; diag ðσp;a
t ÞÞ otherwise
(
ð3Þ
where
μp;a
t ¼sigmoidðWa
μdda
t þba
μÞ ð4Þ
σp;a
t ¼sigmoidðWa
σdda
t þba
σ Þ ð5Þ
μa;p
t and σa;p
t are the mean and standard deviation of the prior density
following a multivariate normal distribution with a diagonal covariant
matrix.Wa
μd and Wa
σd,a n dba
μ and ba
σ are weight matrices and biases to map
da
t in the associative module, respectively. Activation functions have been
changed from hyperbolic tangent functions to sigmoid (logistic) functions
forμ, and from exponential to sigmoid (logistic) functions forσ, respectively,
to stabilize network training.μp;a
t and σp;a
t are self-organized through
learning, except t =1 , μp;a
1 and σp;a
1 , which are determined by the
experimenter and ﬁxed throughout the experiment. In the current
experiments, μp;a
1 and σp;a
1 are empirically given as μp;a
1 ¼0:5 /C3 1
and σp;a
1 ¼0:1 /C3 1.
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 8
The recurrent computation part follows the same computation in20,
which is based on the Multiple Timescale Recurrent Neural Network
(MTRNN)
52. The MTRNN is a recurrent neural network consisting of
multiple layers of continuous-time recurrent neural networks53 with dif-
ferent time constants, which enable the network to extract a functional
hierarchy based on different time scales through learning52,54,55.I nt h ec u r -
rent model, a larger time constant is allocated to the associative module, and
smaller time constants are allocated to the proprioception and vision
modules (Table2), to allow the network to represent higher-level functions,
such as predicting movement patterns, in the associative module, and lower-
level functions, such as predicting details of each movement pattern, in the
proprioception and vision module, separately in the network. Its compu-
tation in the associative module is as follows:
h
a
t ¼ 1 /C0 1
τa
/C18/C19
ha
t/C01 þ1
τa Wa
hdda
t/C01 þWa
hzza
t
þba
h
/C0/C1
ð6Þ
da
t ¼tanhðha
t Þð 7Þ
where ha
t is a latent state before applying anactivation function to compute
da
t ; τa is a time constant;Wa
hd andWa
hz are weight matrices to mapda
t andza
t ,
respectively;ba
h is a bias term for the recurrent computation.da
0 and ha
0 are
ﬁxed asda
0 ¼0 and ha
0 ¼0 to prevent the network from developing an
initial sensitivity and to encourage the network to utilizez to learn the target
sequences56.
z is sampled from the prior density through reparametrization57:
za
t ¼μa;p
t þσa;p
t /C3 ϵt ð8Þ
where ϵt is noise sampled from a standard normal distributionNð0; 1Þ.
In the proprioception module, computation of the prior density is
similar to that in the associative module:
pðzp;p
t Þ¼ Nðzp
1; μp;p
1 ; diagðσp;p
1 ÞÞ if t ¼1
pðzp;p
t jdp
t/C01Þ¼Nðzp;p
t ; μp;p
t ; diagðσp;p
t ÞÞ otherwise
(
ð9Þ
where
μp;p
t ¼sigmoidðWp
μddp
t þbp
μÞ ð10Þ
σp;p
t ¼sigmoidðWp
σddp
t þbp
σ Þ ð11Þ
and μp;p
1 ¼0:5 /C3 1 and σp;p
1 ¼0:1 /C3 1. The recurrent computation part
differs from that in the associative module in that it receives input from the
a s s o c i a t i v em o d u l ea n dt h ev i s i o nm o d u l e( F i g .7).
hp
t ¼ 1 /C0 1
τp
/C18/C19
hp
t/C01 þ1
τp Wp
hddp
t/C01 þWp
hzzp
t þWpa
hddp
t þWpv
hddv
t/C01 þbp
h
/C0/C1
ð12Þ
dp
t ¼tanhðhp
t Þ ð13Þ
where
zp
t ¼μp;p
t þσp;p
t /C3 ϵt ð14Þ
Table 2 | The model conﬁguration used in training
Rd Rz τ w β
Associative module 20 2 16 2.0 1.0
Proprioception module 10 1 2 0.5 1.0
Vision module 10 1 2 1.0 1.0
Rd and Rz are the dimensions ofd and z, respectively.τ is the time constant in the recurrent
computation in each module.
Fig. 7 |A graphical model for the proposed
generative model.
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 9
and dp
0 ¼0 and hp
0 ¼0. Input from the vision module, which did not exist
in the previous model, has been introduced to enhance the association
between the proprioception module and the vision module, and the input
f r o mt h ev i s i o nm o d u l ei sd e l a y e db yo n et i m e - s t e p( F i g .7).
The predictive distribution of proprioceptive output is assumed to
follow a normal distribution with a diagonal covariant matrix, and para-
meters of the distribution are mapped from the latent stated
p of the PV-
RNN layer in the proprioception module:
pðXp
t jdp
t Þ¼NðXp
t ; μout;p
t ; diagðσout;p
t ÞÞ ð15Þ
where
μout;p
t ¼sigmoidðWop
μddp
t þbop
μ Þ ð16Þ
σout;p
t ¼sigmoidðWop
σddp
t þbop
σ Þ ð17Þ
In the current experiment,pðXp
t jdp
t Þis the predictive distribution of the
robot’sj o i n ta n g l ec o nﬁguration. When controlling the robot with the
network,μout,p is fed to the robot controller as the target position.
Similarly, computations of the vision module are as follows. Compu-
tation of the prior density is
pðzp;v
t Þ¼ Nðzp
1; μp;v
1 ; diagðσp;v
1 ÞÞ if t¼1
pðzp;v
t jdv
t/C01Þ¼Nðzp;v
t ; μp;v
t ; diagðσp;v
t ÞÞ otherwise
(
ð18Þ
where
μp;v
t ¼sigmoidðWv
μddv
t þbv
μÞ ð19Þ
σp;v
t ¼sigmoidðWv
σddv
t þbv
σ Þ ð20Þ
and μp;v
1 ¼0:5 /C3 1 and σp;v
1 ¼0:1 /C3 1. Similar to computation in the pro-
prioception module, the vision module also receives input from the asso-
ciative module and the proprioception module in the recurrent
computation (Fig.7):
hv
t ¼ 1 /C0 1
τv
/C18/C19
hv
t/C01 þ1
τv Wv
hddv
t/C01 þWv
hzzv
t
þWva
hddv
t þWvp
hddp
t/C01 þbv
h
/C0/C1
ð21Þ
dv
t ¼tanhðhv
t Þð 22Þ
where
zv
t ¼μp;v
t þσp;v
t /C3 ϵt ð23Þ
T h ep r e d i c t i v ed i s t r i b u t i o no ft h ev ision output also follows a normal dis-
tribution with a diagonal covariant matrix, and its mean and standard
distribution are mapped from the latent stated
v of the PV-RNN layer in the
vision module:
pðXv
t jdv
t Þ¼NðXv
t ; μout;v
t ; diagðσout;v
t ÞÞ ð24Þ
where
μout;v
t ¼sigmoidðWov
μddv
t þbov
μ Þ ð25Þ
σout;v
t ¼sigmoidðWov
σddv
t þbov
σ Þ ð26Þ
In the current experimental setup,pðXv
t jdv
t Þcorresponds to the predictive
distribution of the coordinate of the VR controller.
Computation of the inference model. The proposed model computes
the approximate posterior as follows. In the associative module, the
approximate posterior density function is computed as
qðz
a
t jXp
t:T ; Xv
t:T Þ¼ Nðza
t ; μq;a
t ; diag ðσq;a
t ÞÞ ð27Þ
μq;a
t ¼sigmoid ðAa
μ;tÞ ð28Þ
σq;a
t ¼sigmoid ðAa
σ;tÞ ð29Þ
T h es y m b o lf o rt h ea d a p t i v ev a r i a b l et oc o m p u t eμa
t and σa
t has been
changed froma used in20 to A to avoid confusion about variable notations.
Also, while computation ofμq;a
t and σq;a
t consider the input from the latent
variableda
t/C01 in the previous model, they depend solely onA in the current
model. This is intended to make the approximate posterior conditioned only
by the observation. In the previous computation scheme, sampling from the
posterior density affects computationof parameters of the posterior density
at the next time step; thus, it needs to be considered as an expectation with
respect to the posterior densities in previous time steps. In contrast, the
current computation scheme does not rely on the previous time step, which
allows computation of the exact form of the posterior density.
As in the associative module, the approximate posterior density in the
proprioception module is computed as
qðz
p
t jXp
t:T ; Xv
tþ1:T Þ¼Nðzp
t ; μq;p
t ; diagðσq;p
t ÞÞ ð30Þ
μq;p
t ¼sigmoidðAp
μ;t Þ ð31Þ
σq;p
t ¼sigmoidðAp
σ;tÞ ð32Þ
Because of the network architecture, the approximate posterior of the
proprioception module at time stept is not conditioned by visual obser-
vations from time stept to T,b u tf r o mt +1t oT.
T h ev i s i o nm o d u l ea l s oe m p l o y st h es a m ec o m p u t a t i o ns c h e m e :
qðzv
t jXp
tþ1:T ; Xv
t:T Þ¼Nðzv
t ; μq;v
t ; diagðσq;v
t ÞÞ ð33Þ
μq;v
t ¼sigmoidðAv
μ;tÞ ð34Þ
σq;v
t ¼sigmoidðAv
σ;tÞ ð35Þ
where the proprioceptive observation for conditioning the approximate
posterior in the vision module is from time stept +1t oT,n o tf r o mt to T.
Dataset preparation
A dataset of synchronized trajectories of the robot’s left arm joint angles and
the VR controller position was prepared for network training, according to
the following procedure. First, an experimenter put on a motion-capture
suit (MTw Awinda (hardware) and MVN Animate (software) manu-
factured by Movella) and held a VR controller (the controller for VIVE Pro 2
manufactured by HTC) in his right hand. A set of sensors for the VR system
was placed in the experimental room so that the position of the VR con-
troller was measured using three-dimensional coordinates. Although the
controller coordinates are representedin six dimensions, including position
and orientation, the current experimentonly used positional information, as
orientation information does not contribute to predicting the prepared
movement patterns (Fig.1a). While the experimenter was moving, the
motion-capture system estimated the experimenter’s posture, which was
then mapped onto the humanoid robot joint angle conﬁguration such that
the experimenter and the robot adopted the same upper body posture. The
experimenter stood in front of the robot, moved his right arm according to
the PFSM (Fig.1b), and recorded the robot joint angle trajectory and the VR
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 10
controller position trajectory simultaneously. Trajectories were recorded at
10 Hz, and a dataset of 10 sequences, each with 612 time steps, both for the
joint angle and the VR controller position, was prepared. Fig.8 shows an
example of the obtained trajectories. The top row shows the joint-angle
trajectory, in which the blue line corresponds to the left shoulder joint in
charge of the robot’s left arm height and indicates when movement patterns
switch through transitional movement. Similarly, the bottom row depicts a
VR controller position trajectory, and the orange line shows the z coordinate
(height) of the controller position,indicating the change of movement
patterns.
Network training
As the proposed network is designed based on the free energy principle,
training of the network is to optimize network parameters by minimizing
the free energy of the network. The free energy of the network generating aT
time-step visuo-proprioceptive sequence is derived as
F :¼βaDKL½qðza
1Þkpðza
1Þ/C138þ βpDKL½qðzp
1Þkpðzp
1Þ/C138þ βvDKL½qðzv
1Þkpðzv
1Þ/C138
þPT
t¼2
waEqðza
1:t/C01Þ DKL½qðza
t Þkpðza
t jda
t/C01Þ/C138
/C2/C3h
þwpEqðza
1:t/C01ÞEqðzp
1:t/C01ÞEqðzv
1:t/C02Þ DKL½qðzp
t Þkpðzp
t jdp
t/C01Þ/C138
/C2/C3
þwvEqðza
1:t/C01ÞEqðzp
1:t/C02ÞEqðzv
1:t/C01Þ DKL½qðzv
t Þkpðzv
t jdv
t/C01Þ/C138
/C2/C3 i
/C0 PT
t¼1
Eqðza
1:t/C01ÞEqðzp
1:t/C01ÞEqðzv
1:t/C01Þ Eqðzp
t Þ log pðXp
t jdp
t Þ
/C2/C3
þEqðzv
t Þ log pðXv
t jdv
t Þ
/C2/C3hi
ð36Þ
The detailed derivation in a single modality case can be found in ref.58.
The ﬁrst three terms represent the KL divergence between the prior and
approximate posterior at time step 1, which is weighted by a hyper-
parameter β controlling the initial sensitivity for the autoregressive
process of the network, for the associative module, proprioception
module, and vision module, respectively. The fourth to sixth terms are
the expectation of KL divergence for the rest of the time steps with
respect to the approximate posterior, weighted by the meta-prior,w, for
each modality. The last two terms are the expectation of the log-
likelihood with respect to the approximate posterior for the proprio-
ceptive and visual observations. While the hyperparameter for weighting
the KL divergence at time step 1 is denoted asw
1 in ref.20,i ti si n s t e a d
represented asβ here for clarity. While variational densities in Eq. (36)
are conditioned by observations, they are omitted here for brevity. Since
sequence generation includes sampling from the approximate posterior
over time steps, Eq. (36) contains nested conditional expectations, which
are difﬁcult to compute analytically. Therefore, the free energy of the
network during training is approximated with iterative sampling.
Removing expectations from Eq. (36), the free energy based on sampling
is deﬁned as
^F :¼βaDKL½qðza
1Þk pðza
1Þ/C138þ βpDKL½qðzp
1Þk pðzp
1Þ/C138þ βvDKL½qðzv
1Þk pðzv
1Þ/C138
þPT
t¼2
waDKL½qðza
t Þk pðza
t jda
t/C01Þ/C138þ wpDKL½qðzp
t Þk pðzp
t jdp
t/C01Þ/C138þ wvDKL½qðzv
t Þk pðzv
t jdv
t/C01Þ/C138
/C2 /C3
/C0 PT
t¼1
log pðXp
t jdp
t Þþlog pðXv
t jdv
t Þ
/C2/C3
ð37Þ
Since both the prior and approximate densities are assumed to follow a
multivariate normal distribution with a diagonal covariant matrix, the
Kullback-Leibler (KL) divergence between them is computed.
κðm; tÞ:¼
1
nzm DKL qðzm
1 Þkpðzm
1 Þ
/C2/C3
if t¼1
1
nzm DKL qðzm
t Þkpðzm
t jdm
t/C01Þ
/C2/C3
otherwise
(
ð38Þ
¼ 1
nzm
Xnzm
i¼1
log σp;m
t;i
σq;m
t;i
þðμq;m
t;i /C0 μp;m
t;i Þ
2
þðσq;m
t;i Þ
2
2ðσp;m
t;i Þ
2 /C0 1
2
"#
ð39Þ
where m ∈ {a, p, v} represents the associative, proprioception, and vision
module in the network, respectively, andnzm indicates the dimension ofzm,
which is introduced to normalize the KL divergence with respect to the
dimension ofz
m to facilitate interpretation of the effect ofβ and w for
different network conﬁgurations.i represents theith entry of each vector.
In the proposed model, predictive distributions of proprioceptive and
visual observations are assumed to follow multivariate normal distributions
with a diagonal covariant matrix. Thus, the log-likelihood terms in Eq. (37)
take an analytical form. That is,
λðm; tÞ:¼ 1
nXm
log pðXm
t jdm
t Þ ð40Þ
¼ 1
nXm
XnXm
i¼1
log 1ﬃﬃﬃﬃﬃ
2π
p
σout;m
t;i
exp 1
2
Xm
t;i /C0 μout;m
t;i
σout;m
t;i
 ! 2"#"#
ð41Þ
¼ 1
nXm
XnXm
i¼1
1
2
Xm
t;i /C0 μout;m
t;i
σout;m
t;i
 ! 2
/C0 log σout;m
t;i /C0 1
2 log 2π
"#
ð42Þ
where m ∈ {p, v} represents the proprioception and vision modules,
respectively, andnXm is the dimension ofXm introduced to normalize the
log-likelihood with respect to the data dimension to maintain the balance
between the complexity and accuracy terms in the free energy for different
modalities.
Fig. 8 | An example of dataset sequences.The ﬁrst two hundred time steps are
shown for brevity. The top row is a trajectory of the joint angle of the robot’s left arm
(six degrees of freedom), and the bottom row is a trajectory of the VR controller
position (three dimensions). Characters above the top row indicate corresponding
movement patterns: A for pattern A, B for pattern B, and T for the transition pattern
(Fig. 1a).
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 11
Combiningκ(m, t)a n dλ(m, t), the free energy used to train the net-
work is deﬁned as
F :¼βaκða; 1Þþβpκðp; 1Þþβvκðv; 1ÞþPT
t¼2
waκða; tÞþwpκðp; tÞþwvκðv; tÞ
/C2/C3
þPT
t¼1
λðp; tÞþλðv; tÞ
/C2/C3
ð43Þ
Let θ and ϕ be learnable parameters of the generative and inference models,
respectively. Given a dataset to train the network,θ andϕ are optimized such
that
ðθ/C3 ; ϕ/C3 Þ¼argmin
θ;ϕ
F ð44Þ
An alternative interpretation of this meta-prior is that it plays the role of a
modiﬁer for the prior precision. This is most obvious in the combination of
Eqs. (43)a n d(39) where the meta-prior weights of Eq. (43) can be absorbed
into the inverse prior variances of Equation 39 in terms that vary with the
difference in expectations. Thisﬁts well with the idea that the meta-prior
prohibits deviations from prior beliefs. It does so because it renders those
prior beliefs more or less conﬁdent. Table2 provides a conﬁguration of the
network for the study. Values of meta-priorw are speciﬁc to training, and
different values were used in the interaction experiment (Table1). The
network was trained for 200,000 epochs using Adam optimizer
59 with
learning rate 0.01 before the interaction experiments.
Online posterior inference
The online posterior inference during the human–robot interaction
experiment is performed based on the scheme of error regression (ER) with
a shifting window
20,21. While the posterior for all time steps of a sequence is
inferred in training, the posterior forﬁxed time steps representing the
immediate past is inferred during the experiment. Similar to the free energy
for training the network, the free energy at time stept to infer the posterior
for the pastt
w time steps during the experiment is deﬁned as
F er
t :¼ Pt
t0¼t/C0tw
wa
er Eqðza
t/C0tw:t0/C01Þ DKLqðza
t0Þkpðza
t0jda
t0/C01Þ
/C2/C3
þwp
er Eqðza
t/C0tw:t0/C01ÞEqðzp
t0/C0tw:t0/C01ÞEqðzv
t0/C0tw :t0/C02Þ DKL qðzp
t0Þkpðzp
t0jdp
t0/C01Þ
/C2/C3/C2/C3
þwv
er Eqðza
t/C0tw:t0/C01ÞEqðzp
t0/C0tw:t0/C02ÞEqðzv
t0/C0tw :t0/C01Þ DKL qðzv
t0Þkpðzv
t0jdv
t0/C01Þ
/C2/C3/C2/C3
/C0Eqðza
t/C0tw:t0ÞEqðzp
t0/C0tw :t0ÞEqðzv
t0/C0tw:t0/C01Þ log pðXp
t0jdp
t0Þ
/C2/C3
/C0Eqðza
t/C0tw:t0ÞEqðzp
t0/C0tw :t0/C01ÞEqðzv
t0/C0tw :t0Þ log pðXv
t0jdv
t0Þ
/C2/C3
ð45Þ
where wer d e n o t e st h em e t a - p r i o rf o rt h eE Ri ne a c hm o d u l e .A si nt h ef r e e
energy for training, Eq. (45) contains conditional expectations that are not
computable. Thus, it is approximated through iterative sampling. One of the
differences from the training procedure is that this posterior inference is
performed under some constraints. As the experiment involves an
interaction between a human and a robot, the posterior inference at each
time step has to beﬁnished so fast that the robot can naturally interact with
the human. In the ER scheme, the posterior inside the inference window is
optimized by repeating the forward computation and back-propagation
through time, which is computationally intense. Therefore, optimization
tends to be performed with a small number of optimization steps and a high
learning rate. However, this settingcan perturb optimization when the
stochastic variable sampled from the approximate posterior density takes an
extreme value by chance and creates a large gradient for error propagation.
Due to the high learning rate, such a large gradient can disturb the posterior
optimization, and the subsequent inference and prediction process can
become unstable. To mitigate this problem, the current model estimates the
free energy at each time step by averaging multiple samples. Namely, using
the notation ofκ(m, t)a n dλ(m, t)i nE q .(43), the estimated free energy at
time stept is deﬁned as
F
er
t :¼ 1
nspl
Xnspl
i¼1
Fer
t;i ð46Þ
where
F er
t;i :¼
Xt
t0¼t/C0tw
wa
erκða; t0Þþwp
erκðp; t0Þþwv
er κðv; t0Þþλðp; t0Þþλðv; t0Þ
ð47Þ
F er
t;i represents theith sampling of the free energy;F er
t is the estimated free
energy as an average over the sampled free energy;Nspl is the number of
samplings per optimization step. Given observations for the ER window,
online optimization of the learnable parameters of the inference model at
each time step during the interaction is performed by:
ϕ/C3 ¼argmin
ϕ
Fer
t ð48Þ
Algorithm 1 provides a pseudo-codefor the online inference process by
means of ER. When the time step advances, the time window for inferring
the posterior shifts, such that the approximate posterior for the incoming
time step is prepared. In the currentstudy, adaptive variables for the
parameters of posterior density,A
μ and Aσ, are initialized such that the
approximate posterior becomes the same as the corresponding prior:
μm;p
t ¼μm:q
t and σm;q
t ¼σm;p
t .A sμm;q
t and σm;q
t are mapped fromAm
μ;t and
Am
σ;t with logistic function (“Computation of the generative model”), Am
μ;t
and Am
σ;t are initialized as:
Am
μ;t  logitðμp;m
t Þ ð49Þ
Am
σ;t  logitðσp;m
t Þ ð50Þ
In human–robot interaction experiments, the size of the ER window is set to
tw = 50. The system is designed such that one time step takes 0.1 s, 50 time
steps correspond to 5 s; therefore, online posterior inference is performed
for the last 5 s at every 0.1 s. The number of times that the free energy is
sampled per optimization step is set toNspl = 30. The number of optimi-
zation steps per time step is set toNitr = 30. Optimization utilized the Adam
optimizer59 with learning rate 0.1.
Algorithm 1. Error-regression with a growing and shifting window
T: number of time steps to perform error-regression
tw: size of error-regression window
Nitr: number of optimization steps per time step
Fer
t : estimated free energy
1: d0 ← 0, h0 ← 0
2: for t =1 ,… , T do
3: initialize Aμ
t and Aσ
t
4: observe new targetsXp
t and Xv
t
5: for i =1 ,… , Nitr do
6: compute Fer
t
7: update Atstart:t
8: end for
9: end for
Meta-prior values in human– robot interaction
Meta-prior values for w1 and wlarge conditions used in human–robot
interaction experiments (Table1) were determined as follows. Although
each module of the model is equipped with its own meta-prior, meta-prior
values in the proprioception and vision modules were kept constant, and the
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 12
o n ef o rt h ea s s o c i a t i v em o d u l ew a so n l yc h a n g e di nw1 andwlargeconditions.
This conﬁguration is based on the assumption that the change in agential
characteristics should be attributed to a modiﬁcation in a higher-level
cognitive function, modeled with the associative module, rather than lower-
level functions, modeled with the proprioception and vision modules. We
conducted some preliminary experiments to examine the range of the meta-
prior value for the associative module, with which humans and the robot can
smoothly interact. Then, linearly increasing or decreasing the meta-prior
v a l u ef o rt h ea s s o c i a t i v em o d u l ei nt r a i n i n g( T a b l e2) within the range, we
obtained the meta-prior values inw
1 and wlarge conditions. Values for
proprioception and vision modules were also modiﬁed from those in
training to stabilize interaction but shared in two conditions.
Movement pattern labeling
Robot and human movement patterns during the interaction were cate-
gorized based on the arm height of the human and robot, because the
predeﬁned three movement patterns, A, B, and the transition between them,
do not overlap with respect to arm height, as shown Fig.1.I nt h ec a s eo f
human movement, arm height is represented byz coordinates of the VR
controller position. Since thez coordinates above the initialized position are
represented as negative values and below it are represented as positive values
in VIVE sensor system (see the orange line in the bottom row of Fig.8),
respectively, human movement at time stept, L
h
t , is labeled by
Lh
t ¼
A if Xv
t;3<m i nðX
v
1:T;3
Þþ1
3 maxðX
v
1:T;3
Þ/C0 minðX
v
1:T;3
Þ
/C18/C19/C20/C21
B if Xv
t;3>m a xðX
v
1:T;3
Þ/C0 1
3 maxðX
v
1:T;3
Þ/C0 minðX
v
1:T;3
Þ
/C18/C19/C20/C21
T otherwise
8
>>
>
>
>
<
>>
>
>
>
:
ð51Þ
where A, B, and T indicate movement pattern names, pattern A, pattern B,
and the transition between them, andX
v
1:T;3 ¼fXv
1;3; /C1/C1/C1 ; Xv
T;3grepresents
at i m es e r i e so ft h ez coordinate, the third dimension, of the VR position for
each T time-steps trial.
Similarly, the robot’s shoulder joint angle, theﬁrst coordinate of the
joint angle trajectory (see the blue line in the top row of Fig.8), indicates the
height of the robot’s left arm. The joint angle value is expressed in degrees;
larger values correspond to higher positions, and smaller values correspond
to lower ones. Therefore, the robot movement at time stept, Lr
t , is labeled by
Lr
t ¼
A if Xp
t;1>m a xðX
p
1:T;1
Þ/C0 1
1 maxðX
p
1:T;1
Þ/C0 minðX
p
1:T;1
Þ
/C18/C19/C20/C21
B if Xp
t;1<m i nðX
p
1:T;1
Þþ1
3 maxðX
p
1:T;1
Þ/C0 minðX
p
1:T;1
Þ
/C18/C19/C20/C21
T otherwise
8
>>
>
>
>
<
>>
>
>
>
:
ð52Þ
Dividing the height into three equal segments in Eqs. (51)a n d(52)m a yn o t
seem sufﬁciently accurate to label movement patterns, but this is to negate
the human’s large movement variations during a trial.
Calculation of match and re-match rates in Fig.4
In “Analysis of behavioral data”, the mismatch rate in Fig.4a, the re-match
rate in Fig.4b, the human’s change rate in Fig.4c, and the robot’sc h a n g er a t e
in Fig.4d were calculated based on Algorithm 2 below.
Algorithm 2. Calculating mismatch and re-match rate
T: number of time steps in a trial
rmis: mismatch rate
rre:r e - m a t c hr a t e
rhc:h u m a n’sc h a n g er a t e
rrc: robot’sc h a n g er a t e
1: rmis ← 0, rre ← 0, rhc ← 0, rrc ← 0
2: for t =1 ,… , T − 1 do
3: ifLh
t ≠Lr
t then
4: rmis ← rmis + 1
5: if Lh
tþ1 ¼Lr
t then
6: rre ← rre + 1
7: rhc ← rhc + 1
8: end if
9: if Lh
t ¼Lr
tþ1 then
10: rre ← rre + 1
11: rrc ← rrc + 1
12: end if
13: end if
14: end for
15 rhc ← rhc/rmis
16: rrc ← rrc/rmis
17: rali ← rali/rmis
18 rmis ← rmis/(T −1)
Computation of prediction error in Fig.4
In the process of posterior inference during human–robot interaction,
the visuo-proprioceptive prediction corresponding to the observation
keeps changing through post-dictive process
60 to minimize the free
energy. Therefore, the comparison between the observation and the
prediction generated by sampling from the inferred posterior does not
account for the congruence between the observation and the prediction
generated before the observation. To compare the observation and the
prediction generated before the observation, the following metric is
introduced:
λ
F ðm; t; tF Þ:¼/C0 1
tF
XtþtF þ1
t0¼tþ1
log p Xm
t0jμout;m/C0
ðt; t0Þ; σout;mðt; t0Þ
/C0/C1
: ð53Þ
where m ∈ {p, v} represents proprioception and vision,μout;mðt; t0Þand
σout;mðt; t0Þare the mean and standard deviation for the predictive dis-
tribution at time stept0when the model has acquired observations up to
time stept, meaning that the present time step ist,a n dtF represents the
number of time steps to consider for the prediction error. In other words,
λ
F(p, t, tF) estimates how much the robot moved relative to what it predicted
before moving, andλF(v, t, tF)q u a n t iﬁes how much the human interacting
with the robot moved relative to what therobot predicted before observing it
by negative log-likelihood. Using Eq. (53) ,t h ep r e d i c t i o ne r r o rf o re a c ht r i a l
is deﬁned by
/C22λ
F
ðm; tF Þ:¼ 1
T /C0 tF
XT/C0tF
t¼1
λF ðm; t; tF Þ ð54Þ
In this analysis,tF was set to 10 so that the prediction error concerns up to
1.0 s ahead as the system runs at 10 Hz and one time step takes 0.1 s.
Estimation of transfer entropy in Fig.5
Transfer entropy is a non-parametricmeasurement of directed information
ﬂow between two coupled random processes. Given two random processes
X ={ X1, X2, ⋯ }a n dY ={ Y1, Y2, ⋯ }, the transfer entropy from processX to
Y at time stept is deﬁned as follows27:
TX!Y ðtÞ¼
X
pðYt ; YðjÞ
t/C01; XðiÞ
t/C01Þlog pðYt jYðjÞ
t/C01; XðiÞ
t/C01Þ
pðYt jYðjÞ
t/C01Þ
ð55Þ
where XðiÞ
t/C01 ¼ðXt/C01/C0i;/C1/C1/C1 ;t/C01Þand YðjÞ
t/C01 ¼ðYt/C01/C0j; /C1/C1/C1 ; Yt/C01Þdenoting i
and j time steps of the previous history of the random processesX and Y,
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 13
respectively, following the notation in ref.27.E q .(55) can also be written as
TX!Y ðtÞ¼HðYt jYðjÞ
t/C01Þ/C0 HðYt jYðjÞ
t/C01; XðiÞ
t/C01Þ ð56Þ
¼IðYt ; XðiÞ
t/C01jYðjÞ
t/C01Þ ð57Þ
whereH( ⋅∣⋅ )a n dI( ⋅ ; ⋅∣⋅ ) represent conditional entropy61 and conditional
mutual information62, respectively. As Eq. (57) designates, the transfer
entropy fromX to Y quantiﬁes, how much aboutYt can be predicted fromi
time steps of the history ofX,g i v e nt h ep r e v i o u sj time steps history ofY.
While mutual information is often used to analyze the interaction between
two random processes, it is symmetrical for the processes. In contrast, the
transfer entropy is asymmetrical and can be used to estimate the directed
informationﬂow.
The transfer entropy between the humans and the robot during the
i n t e r a c t i o nw a se s t i m a t e da sf o l l o w s .I ti sa s s u m e dt h a th u m a n sg a i n e d
information about the robot’s movement through the trajectory of the end-
effector position of the robot’s left arm, and the robot obtained information
about the human’s movement through the trajectory of the VR controller.
Therefore, the transfer entropy from the human to the robot and from the
robot to the human are deﬁned, respectively, as
T
H!RðtÞ:¼IðXe
t ; Xv;ðlv Þ
t/C01 jXe;ðleÞ
t/C01 Þ ð58Þ
TR!H ðtÞ:¼IðXv
t ; Xe;ðleÞ
t/C01 jXv;ðlv Þ
t/C01 Þ ð59Þ
whereXe
t is the end-effector position of the robot’s left arm computed by the
robot’s forward model and Xe;ðleÞ
t/C01 ¼ðXe
t/C01/C0le
; /C1/C1/C1 ; Xe
t/C01Þand Xv;ðlv Þ
t/C01 ¼
ðXv
t/C01/C0lv
; /C1/C1/C1 ; Xv
t/C01Þconsiderle and lv time steps of the previous history of
the end-effector and VR controller position trajectory, respectively.
While computation of the transfer entropy for discrete random vari-
ables is relatively straightforward, estimating it for continuous random
variables is more challenging. Among previously proposed algorithms to
estimate probability densities from a limited amount of data, such as the
Gaussian estimator
61 and the box-kernel estimator27, the algorithm pro-
posed in ref.63 was employed in this analysis. While the box-kernel esti-
m a t o ra p p l i e saﬁxed-size box to estimate thedensity, the algorithm in63
applies boxes with dynamic widths based on nearest-neighbor counting,
yielding a more reliable estimation of transfer entropy63.W eu s e dJ I D T64,a
library for estimating information-theoretic quantities, for implementation
of the algorithm.
Based on the transfer entropy at one time step in Eqs. (58)a n d(59), the
transfer entropy for one experiment trial was computed by
/C22TH!R ¼1
T
XT
t¼1
TH!RðtÞ ð60Þ
/C22TR!H ¼1
T
XT
t¼1
TR!H ðtÞ ð61Þ
where T is the length of each trial. In the current analysis, the length of
history considered to estimate transfer entropy in Eqs. (58)a n d(59)w a s
ﬁxed asle = lv = 15.
Computation of KL divergence in Fig.5
Due to characteristics of the conditional prior51, the prior for a given time
step keeps changing based on the context up to the previous time step during
the posterior inference. That is, when the current time step ist,t h ep r i o ra f t e r
t −t
w can change as a result of updating the approximate posterior between
t −tw and t. Therefore, after the posterior inference, the prior does not
represent the prediction before the observation. Similar to the idea in Eq.
(53), the consistency between the prior belief before the observation and the
posterior belief after the posterior inference is measured by:
κF ðm; tÞ:¼DKL N ztþ1; μp;mðt; t þ1Þ; diagðσp;mðt; t þ1ÞÞ
/C0/C1
k
/C2
N ztþ1; μq;mðt þtw þ1; t þ1Þ; diagðσq;mðt þtw þ1; t þ1ÞÞ
/C0/C1 /C3
ð62Þ
where m ∈ {a, p, v} represents each network module;μp;mðt; t0Þand
σp;mðt; t0Þrepresent the mean and standard deviation of the prior density at
time step t0when the network has the observation up to time stept,
respectively;μm;qðt; t0Þand σm;qðt; t0Þrepresent those for the approximate
posterior. In other words, Eq. (62) measures the dissimilarity between the
prior one time-step ahead of the current time step and the corresponding
posterior after inference by the KL divergence. The KL divergence is used to
simplify computation. The inferred posterior does not change after the
inference window passes: μ
q,m(t +tw +1, t +1) =μq,m(t +tw +2,
t +1) =⋯ and σq,m(t +tw +1, t +1) =σq,m(t +tw +2, t +1) =⋯ . Using
Eq. (62), the congruence between the prior before observation and the
approximate posterior after inference for a trial is measured by
/C22κF ðmÞ:¼ 1
T /C0 tw /C0 1
XT/C0tw/C01
t¼1
κF ðm; tÞ ð63Þ
Computation of prediction error in Fig.6d, e
The prediction error between the prediction generated before the obser-
vation and the actual observation in Fig.6d was computed by focusing on
the visual prediction and using Eq. (53), /C22λ
F
ðv; tF ¼1Þ,i nw h i c hs m a l l e r
values result in a stronger FoA. The prediction error between the prediction
after the posterior inference and thecorresponding observation in Fig.6e
was computed as follows. As in Eqs. (53)a n d(54), the following metric was
introduced to quantify it:
λ
Eðm; tÞ:¼/C0 log p Xm
t jμout;m/C0
ðt; t þtwÞ; σout;mðt; t þtwÞ
/C0/C1
: ð64Þ
/C22λ
E
ðmÞ:¼ 1
T /C0 tw
XT/C0tw
t¼1
λEðm; tÞ ð65Þ
As above, focusing on the visual prediction,/C22λ
E
ðvÞis used in Fig.6e, where
the smaller the value, the greater JoAappears when the agent detects the
prediction error.
Data availability
The dataset used for training the network model, and the collected data in
the experiments in the current study are available from the corresponding
author upon reasonable request.
Code availability
The code for the computational model for this study was primarily written
in C++with Python front end and is available online [under preparation].
Received: 10 May 2024; Accepted: 2 December 2024;
References
1. Friston, K. J., Daunizeau, J., Kilner, J. & Kiebel, S. J. Action and
behavior: a free-energy formulation.Biol. Cybern.102, 227–260
(2010).
2. Friston, K. The free-energy principle: a uniﬁed brain theory?Nat. Rev.
Neurosci. 11, 127–138 (2010).
3. Friston, K. et al. The free energy principle made simpler but not too
simple. Phys. Rep.1024,1 –29 (2023).
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 14
4. Parr, T., Pezzulo, G. & Friston, K. J.Active Inference: The Free Energy
Principle in Mind, Brain, and Behavior(MIT Press, 2022).
5. Gallagher, S. Philosophical conceptions of the self: implications for
cognitive science.Trends Cogn. Sci.4,1 4–21 (2000).
6. Moore, J. W., Wegner, D. M. & Haggard, P. Modulating the sense
of agency with external cues.Conscious. Cogn. 18,1 0 5 6–1064
(2009).
7. Synofzik, M., Vosgerau, G. & Newen, A. Beyond the comparator
model: a multifactorial two-step account of agency.Conscious. Cogn.
17, 219–239 (2008).
8. Braun, N. et al. The senses of agency and ownership: a review.Front.
Psychol. 9, 535 (2018).
9. Eitam, B. & Haggard, P.The Sense of Agency(Oxford University Press
Oxford, 2015).
10. Balconi, M. et al.Neuropsychology of the Sense of Agency(Springer,
2010).
11. Frith, C. D., Blakemore, S.-J. & Wolpert, D. M. Abnormalities in the
awareness and control of action.Philos. Trans. R. Soc. Lond. Ser. B
Biol. Sci.355, 1771–1788 (2000).
12. Blakemore, S.-J., Wolpert, D. M. & Frith, C. D. Abnormalities in the
awareness of action.Trends Cogn. Sci.6, 237–242 (2002).
13. Moore, J. W. What is the sense of agency and why does it matter?
Front. Psychol.7, 209433 (2016).
14. Moore, J. W. & Obhi, S. S. Intentional binding and the sense of agency:
a review.Conscious. Cogn.21, 546–561 (2012).
15. Wohlschläger, A., Engbert, K. & Haggard, P. Intentionality as a
constituting condition for the own self— and other selves.Conscious.
Cogn. 12, 708–716 (2003).
16. Wohlschläger, A., Haggard, P., Gesierich, B. & Prinz, W. The perceived
onset time of self-and other-generated actions.Psychol. Sci.14,
586–591 (2003).
17. Braun, N., Thorne, J. D., Hildebrandt, H. & Debener, S. Interplay of
agency and ownership: the intentional binding and rubber hand
illusion paradigm combined.PloS ONE9, e111967 (2014).
18. Buehner, M. J. & Humphreys, G. R. Causal binding of actions to their
effects. Psychol. Sci.20, 1221–1228 (2009).
19. Legaspi, R. & Toyoizumi, T. A Bayesian psychophysics model of
sense of agency.Nat. Commun.10,1 –
11 (2019).
20. Ohata, W. & Tani, J. Investigation of the sense of agency in social
cognition, based on frameworks of predictive coding and active
inference: a simulation study on multimodal imitative interaction.
Front. Neurorobotics14, 61 (2020).
21. Ahmadi, A. & Tani, J. A novel predictive-coding-inspired variational
RNN model for online prediction and recognition.Neural Comput.31,
2025–2074 (2019).
22. Chame, H. F. & Tani, J. Cognitive and motor compliance in intentional
human-robot interaction. InProc. 2020 IEEE International Conference
on Robotics and Automation (ICRA)11291–11297 (IEEE, 2020).
23. Wirkuttis, N. & Tani, J. Leading or following? dyadic robot imitative
interaction using the active inference framework.IEEE Robot. Autom.
Lett. 6, 6024–6031 (2021).
24. Sawada, H., Ohata, W. & Tani, J. Human-robot kinaesthetic
interaction based on free energy principle.IEEE Trans. Syst. Man.
Cybern.: Syst.55, 366–379 (2025).
25. Rizzolatti, G. & Craighero, L. The mirror-neuron system.Annu. Rev.
Neurosci. 27, 169–192 (2004).
26. Prepin, K. & Gaussier, P. How an agent can detect and use synchrony
parameter of its own interaction with a human?Development of
Multimodal Interfaces: Active Listening and Synchrony: Second
COST 2102 International Training School, Dublin, Ireland, March
23–27, 2009, Revised Selected Papers50–65 (Springer Berlin
Heidelberg, 2010).
27. Schreiber, T. Measuring information transfer.Phys. Rev. Lett.85, 461
(2000).
28. Kojima, H., Froese, T., Oka, M., Iizuka, H. & Ikegami, T. A sensorimotor
signature of the transition to conscious social perception: co-
regulation of active and passive touch.Front. Psychol.8, 1778 (2017).
29. Takamizawa, K. & Kawasaki, M. Transfer entropy for synchronized
behavior estimation of interpersonal relationships in human
communication: identifying leaders or followers.Sci. Rep.9, 10960
(2019).
30. Masumori, A., Maruyama, N. & Ikegami, T. Personogenesis through
imitating human behavior in a humanoid robot“alter3”. Front. Robot.
AI 7, 532375 (2021).
31. Synofzik, M., Vosgerau, G. & Lindner, A. Me or not me–an optimal
integration of agency cues?Conscious. Cogn.18, 1065–1068 (2009).
32. Vosgerau, G. & Synofzik, M. Weighting models and weighting factors.
Conscious. Cogn.21,5 5–58 (2012).
33. Wegner, D. M. & Wheatley, T. Apparent mental causation: sources of
the experience of will.Am. Psychol.54, 480 (1999).
34. López, F. M., Shi, B. E. & Triesch, J. Eye-hand coordination develops
from active multimodal compression. InProc. 2023 IEEE International
Conference on Development and Learning (ICDL)437–442 (IEEE,
2023).
35. Legaspi, R., He, Z. & Toyoizumi, T. Synthetic agency: sense of agency
in artiﬁcial intelligence.Curr. Opin. Behav. Sci.29,8 4–90 (2019).
36. Legaspi, R. et al. The sense of agency in human-AI interactions.
Knowl. Based Syst.286, 111298 (2024).
37. Schwartenbeck, P. & Friston, K. Computational phenotyping in
psychiatry: a worked example.eNeuro 3, ENEURO.0049-16.2016
(2016).
38. Sacks, H., Schegloff, E. A. & Jefferson, G. A simplest systematics for
the organization of turn taking for conversation. InStudies in the
Organization of Conversational Interaction7–55 (Elsevier, 1978).
39. Trevarthen, C. Communication and cooperation in early infancy: a
description of primary intersubjectivity.Speech. Begin. Interpers.
Commun. 1, 530–571 (1979).
40. Nadel, J. Imitation and imitation recognition: functional use in
preverbal infants and nonverbal children with autism.The imitative
mind: Development, Evolution, and Brain Bases42–62 (Cambridge
University Press, 2002).
41. Ito, M. & Tani, J. On-line imitative interaction with a humanoid robot
using a dynamic neural network model of a mirror system.Adapt.
Behav. 12,9 3–115 (2004).
42. Ikegami, T. & Iizuka, H. Turn-taking interaction as a cooperative and
co-creative process.Infant Behav. Dev.30, 278–288 (2007).
43. Mwaffo, V., Keshavan, J., L. Hedrick, T. & Humbert, S. Detecting
intermittent switching leadership in coupled dynamical systems.Sci.
Rep. 8, 10338 (2018).
44. Kose-Bagci, H., Dautenhahn, K. & Nehaniv, C. L. Emergent dynamics
of turn-taking interaction in drumming games with a humanoid robot.
RO-MAN 2008-The 17th IEEE International Symposium on Robot and
Human Interactive Communication346–353 (IEEE, 2008).
45. Thomaz, A. L. & Chao, C. Turn-taking based on informationﬂow for
ﬂuent human-robot interaction.AI Mag.32,5 3–63 (2011).
46. Wirkuttis, N., Ohata, W. & Tani, J. Turn-taking mechanisms in imitative
interaction: robotic social interaction based on the free energy
principle. Entropy 25, 263 (2023).
47. Friston, K. J. et al. Dopamine, affordance and active inference.PLoS
Comput. Biol.8, e1002327 (2012).
48. Avery, M. C. & Krichmar, J. L. Neuromodulatory systems and their
interactions: a review of models, theories, and experiments.Front.
Neural Circuits
11, 108 (2017).
49. Feldman, H. & Friston, K. J. Attention, uncertainty, and free-energy.
Front. Hum. Neurosci.4, 215 (2010).
50. Haarsma, J. et al. Precision weighting of cortical unsigned prediction
error signals beneﬁts learning, is mediated by dopamine, and is
impaired in psychosis.Mol. Psychiatry26, 5320–5333 (2021).
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 15
51. Chung, J. et al. A recurrent latent variable model for sequential data.
Advances in Neural Information Processing Systems2980–2988, Vol.
28 (eds. Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., & Garnett,
R.) (Curran Associates Inc., 2015).
52. Yamashita, Y. & Tani, J. Emergence of functional hierarchy in a
multiple timescale neural network model: a humanoid robot
experiment. PLoS Comput. Biol.4, e1000220 (2008).
53. Beer, R. D. On the dynamics of small continuous-time recurrent neural
networks. Adapt. Behav.3, 469–509 (1995).
54. Nishimoto, R. & Tani, J. Development of hierarchical structures for
actions and motor imagery: a constructivist view from synthetic
neuro-robotics study.Psychol. Res. PRPF73, 545–558 (2009).
55. Hwang, J., Kim, J., Ahmadi, A., Choi, M. & Tani, J. Dealing with large-
scale spatio-temporal patterns in imitative interaction between a
robot and a human by using the predictive coding framework.IEEE
Trans. Syst. Man Cybern. Syst.50, 1918–1931 (2020).
56. Goyal, A., Sordoni, A., Côté, M., Ke, N. & Bengio, Y. Z-forcing: training
stochastic recurrent networks. InProc. of the 31st International
Conference on Neural Informatio Processing Systems6716-6726
(Curran Associates Inc., Long Beach, California, USA, 2017).
57. Kingma, D. P. & Welling, M. Auto-encoding variational bayes.arXiv
preprint arXiv:1312.6114(2013).
58. Idei, H., Ohata, W., Yamashita, Y., Ogata, T. & Tani, J. Emergence of
sensory attenuation based upon the free-energy principle.Sci. Rep.
12, 14542 (2022).
59. Kingma, D. P. & Ba, J. Adam: A method for stochastic optimization.
arXiv preprint arXiv:1412.6980(2014).
60. Shimojo, S. Postdiction: its implications on visual awareness,
hindsight, and sense of agency.Front. Psychol.5, 196 (2014).
61. Cover, T. M.Elements of Information Theory(John Wiley & Sons, 1999).
62. Wyner, A. D. A deﬁnition of conditional mutual information for arbitrary
ensembles. Inf. Control38,5 1–59 (1978).
63. Kraskov, A., Stögbauer, H. & Grassberger, P. Estimating mutual
information. Phys. Rev. E69, 066138 (2004).
64. Lizier, J. T. Jidt: An information-theoretic toolkit for studying the
dynamics of complex systems.Front. Robot. AI1, 11 (2014).
Acknowledgements
We are grateful for the help and support provided by the Scientiﬁc
Computing and Data Analysis section of Research Support Division at OIST.
We also thank Steven D. Aird for editing the manuscript. This study was
funded by the Japan Society for the Promotion of Science (JSPS) KAKENHI,
Transformative Research Area (A): uniﬁed theory of prediction and action
[24H02175]. The funder played no role in study design, data collection,
analysis, and interpretation of data, or the writing of this manuscript.
Author contributions
W.O. and J.T. conceived the study, built the computational models,
designed the experiments, and analyzed the data. W.O. conducted the
experiments, visualized the data, and was a major contributor to writing the
manuscript. J.T. reviewed and edited the manuscript.
Competing interests
The authors declare no competing interests.
Ethics
The experiment protocol was reviewed and approved by the institution’s
ethics committee [HSR-2022-022], and written informed consent was
obtained from each participant.
Additional information
Supplementary informationThe online version contains supplementary
material available at
https://doi.org/10.1038/s44260-024-00026-8
.
Correspondenceand requests for materials should be addressed to
Jun Tani.
Reprints and permissions informationis available at
http://www.nature.com/reprints
Publisher’s noteSpringer Nature remains neutral with regard to
jurisdictional claims in published maps and institutional afﬁliations.
Open AccessThis article is licensed under a Creative Commons
Attribution-NonCommercial-NoDerivatives 4.0 International License,
which permits any non-commercial use, sharing, distribution and
reproduction in any medium or format, as long as you give appropriate
credit to the original author(s) and the source, provide a link to the Creative
Commons licence, and indicate if you modiﬁed the licensed material. You
do not have permission under this licence to share adapted material
derived from this article or parts of it. The images or other third party
material in this article are included in the article’s Creative Commons
licence, unless indicated otherwise in a credit line to the material. If material
is not included in the article’s Creative Commons licence and your intended
use is not permitted by statutory regulation or exceeds the permitted use,
you will need to obtain permission directly from the copyright holder. To
view a copy of this licence, visithttp://creativecommons.org/licenses/by-
nc-nd/4.0/
.
© The Author(s) 2025
https://doi.org/10.1038/s44260-024-00026-8 Article
npj Complexity|            (2025) 2:12 16