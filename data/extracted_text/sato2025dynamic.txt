Dynamic Balancing Free Energy in Non-
Equilibrium:Dual J–F Mapping, Diagonal Policy, and
S-drift
Toshio SATO 
Independent Scholar
Research Article
Keywords:
Posted Date: October 22nd, 2025
DOI: https://doi.org/10.21203/rs.3.rs-7686818/v1
License:   This work is licensed under a Creative Commons Attribution 4.0 International License.  
Read Full License
Additional Declarations: No competing interests reported.
Dynamic Balancing Free Energy in Non-Equilibrium:
Dual J–F Mapping, Diagonal Policy, and S-drift
Toshio Sato∗
Abstract
We revisit the free-energy based formulation from a dynamic-balanci ng perspective and make explicit
a dual mapping between J = VFE − λ EFE and F = U − T S that yields a simple diagonal policy
on the correspondence plane. We analyze overshoot across the dia gonal and show that an S-direction
drift induces a steady oﬀset D∞ = ( u∗ − vS )/(2k) parallel to the diagonal. Robustness to noise and
a practical identiﬁcation scheme are also provided. This situa tes the VFE–EFE decomposition in
active inference and non -equilibrium thermodynamics [ 1, 2, 3, 4], and anticipates neuromodulatory/ANS
implementations (LC–NE, DA, sympatho -vagal balance) [ 5, 6, 7, 8, 9, 10]. We provide testable predictions
(OU variance/ACF scalings, fastest settling at slight underda mping, and a linear steady oﬀset law) and
an interpretive mapping to LC–NA/DA and autonomic balance.
1 Introduction
The Free Energy Principle (FEP) proposes that adaptive systems min imize a free-energy functional that
bounds surprise. In practice this is implemented via minimizat ion of variational free energy (VFE), aligning
internal states with observed data. While successful, VFE-only form ulations face the “dark-room problem”:
convergence to trivial, non-exploratory states. Expected free ener gy (EFE) was introduced to quantify
uncertainty about future outcomes and to encourage exploratory actions. How ever, within conventional
FEP it remained unclear how to balance VFE and EFE. We address this by t he Dynamic Balancing FEP
(DBFEP), which uniﬁes present alignment and future openness und er
J = VFE − λ EFE,
where λ plays the role of an exploration temperature. This form is structurall y dual to the thermodynamic
identity
F = U − T S,
and supplies a principled dual potential balancing stability and exp loration.
2 Related work
The present dual form complements motivated control and hierarchical ac tive inference [ 11, 12], recasting
the balance in standard linear-systems and stochastic-process tool s; we avoid committing to thermodynamic
identities [13, 14] and prioritise structural analyzability.
Related work. Our formulation connects to active inference and generalised free en ergy [ 1, 15, 2], links
accuracy–complexity trade -oﬀs to non -equilibrium thermodynamics [ 3, 4], and complements neuromodulatory
control theories for exploration/exploitation and learning rates [ 5, 6, 8, 9, 16, 7, 17]. From a control perspective,
our diagonal policy resonates with value -of-control accounts [ 18] while remaining grounded in free -energy
minimisation. Classical FEP accounts minimize VFE to align internal st ates with current data [ 1, 1]. EFE
augments this with epistemic value, but the balance between VFE and E FE has remained model– and
∗Email: toshioandfep@gmail.com
1
task–dependent. Our contribution is to make this balance explicit v ia J = VFE−λ EFE (structurally mapped
to F = U − T S), together with a diagonal policy on ( ˆU, ˆS) that admits stability and transient analyses and a
closed-form steady oﬀset under S-drift. For reviews see, e.g., [19, 20].
3 Preliminaries and Notation
We work on the correspondence plane ( ˆU, ˆS) with discrepancy D = ˆU − ˆS measuring deviation from the
diagonal policy ˆU = ˆS. Symbols: ˆU ≈ VFE (present-ﬁt), ˆS ≈ EFE (future-openness), λ (exploration
temperature), k > 0 (diagonal restoring), vS (S-drift), u∗ (drive on ˆU), D∞ = ( u∗ − vS )/(2k).
Remark (Agency parameter c (brief note)) . We use c as a lumped self-monitoring gain that rescales the
eﬀective feedback seen by D (e.g., keﬀ = c k). Reduced agency ( c ↓) weakens diagonal restoring, enlarging
oﬀset variability and slowing ACF decay, while the vS -driven mean shift remains conceptually separate. A
full treatment is beyond the scope of this paper.
Table 1: Notation summary (correspondence plane).
Symbol Meaning
ˆU ≈ VFE Present-ﬁt component (alignment with data)
ˆS ≈ EFE Future-openness (uncertainty/epistemic value)
λ Exploration temperature (analog of T )
D = ˆU − ˆS Discrepancy from the diagonal policy
k > 0 Diagonal-restoring gain
vS S-direction drift (future-attitude bias)
u∗ Constant drive on ˆU (e.g., rumination)
D∞ = ( u∗ − vS )/(2k) Steady oﬀset under (2) (deterministic)
4 Formulation
4.1 Duality between DBFEP and thermodynamic free energy
Accuracy–complexity decomposition of VFE. The variational free energy F [q] admits the decomposi-
tion
F [q] = Eq[ln q(s)] − Eq[ln p(s, o)] = DKL(q(s) ∥ p(s))  
complexity
− Eq[ln p(o | s)]  
accuracy
,
which recovers ELBO = accuracy − complexity. Here, ˆU ≈ VFE denotes the total; increasing accuracy
(expected log-likelihood) decreases ˆU. Therefore,
J = VFE − λ EFE = (complexity − accuracy) − λ EFE ,
and the diagonal policy makes explicit the dual objective: raise accuracy (VFE↓) while regulating future
uncertainty (EFE) via λ to maintain openness.
Proposition 1 (Duality). The DBFEP functional J = VFE−λ EFE is structurally dual to the thermodynamic
free energy F = U − T S, under the correspondence ( ˆU, ˆS, λ) ↔ (VFE, EFE, T ).
Sketch. Both J and F balance two antagonistic terms: present alignment ( U or VFE) and future openness
(S or EFE). The mapping is structural (not numerical), licensing the rmodynamic-style reasoning for adaptive
inference.
4.2 Diagonal policy
Deﬁnition 1 (Diagonal policy) . The control law that drives trajectories toward the diagonal ˆU = ˆS, i.e.,
alignment between present and future models.
2
4.3 Stability in linear Gaussian systems
Theorem 1 (Stability). Let D = ˆU − ˆS. Under the diagonal policy, a linear Gaussian system is locally
asymptotically stable: D(t) → 0 as t → ∞ for small perturbations.
Sketch. Linearization around D = 0 yields a Lyapunov function that decreases monotonically; Gaussian
assumptions give bounded variance and convergence.
4.4 Numerical demonstration
We numerically integrate the planar dynamics under the diagonal policy f rom multiple initial conditions.
Across runs, trajectories contract toward the correspondence diagonal ˆU = ˆS and remain there thereafter,
illustrating stability of the policy and disappearance of steady mismat ch in the no-drift case ( vS = 0).
Figure 1: Simulated trajectories under the diagonal policy. All trajectori es converge to ˆU = ˆS.
Legend (parameters used):overdamped ζ = 1 .4, critical ζ = 1 .0, underdamped ζ = 0 .8.
5 Overshoot and trajectory typology
Linearization and identiﬁcation of the damping ratio. Near the diagonal, for the mismatch state
x = [ D, ˙D]⊤, take the standard realization ˙x = Ax with A =
[ 0 1
− ω2
n − 2ζωn
]
, with characteristic polynomial
s2+2ζωns+ω2
n = 0. Comparing with the ﬁrst-order-plus-lag implementation ¨D+2ζωn ˙D+ω2
nD = β ω 2
n(u∗−vS )
shows ( ζ, ωn) is uniquely determined by ( k, τ, β ), and a small overshoot obtains when ζ < 1, critical damping
at ζ = 1, and monotone return for ζ > 1.
3
5.1 Linearization to a canonical second-order form
We write the discrepancy dynamics near the diagonal as a 2 × 2 linear system on the augmented state
x = ( D, ˙D)⊤:
˙x = Alin x, A lin =
[ 0 1
−ω2
n −2ζωn
]
.
Given a linearization matrix A, identify ω2
n = det(A) and 2 ζωn = − tr(A) so that s2 + 2 ζωns + ω2
n = 0
matches the characteristic polynomial.
One canonical realization (with actuator/update lag). Let u be the corrective drive generated from
D with time constant τ > 0: ˙D = −2k D + u, ˙ u = − 1
τ u − β D. Eliminating u gives
¨D +
(
2k + 1
τ
)
˙D +
( 2k
τ + β
)
D = 0 , (1)
hence ω2
n = 2k
τ + β and ζ = 2k + 1/τ
2
√
2k/τ + β
.
5.2 Regimes and demonstration
Standard regimes: overdamped ( ζ > 1), critically damped ( ζ = 1), underdamped (0 < ζ < 1), with maximum
overshoot Mp ≈ exp
(
− πζ/
√
1 − ζ2)
.
Figure 2: Overshoot regimes. Overdamped (monotone), critical (fastest non-oscillatory), a nd underdamped
(overshoot) behaviors. Dashed lines indicate the diagonal ˆU = ˆS.
Legend (parameters used):overdamped ζ = 1 .4, critical ζ = 1 .0, underdamped ζ = 0 .8.
6 S-direction drift and steady oﬀset
Let D = ˆU − ˆS. Under linear restoring with gain k > 0, a constant drive u∗ on ˆU, and an S-direction drift
vS , the minimal ﬁrst-order dynamics are
˙D = −2k D + u∗ − vS + η(t). (2)
4
In the deterministic case ( η ≡ 0), the unique equilibrium is
D∞ = u∗ − vS
2k , (3)
so with u∗ = 0 one has D∞ = − vS /(2k). Intuition: vS controls the position (parallel shift), while k controls
the approach speed and dispersion.
6.1 Noise robustness and early-warning statistics
With white noise of variance σ2, D follows an OU process dDt = ( −2k Dt +u∗ −vS ) dt+σ dWt with stationary
E[D] = D∞, Var[D] = σ2/(4k), and ACF(τ) = e−2kτ . Increasing k shrinks dispersion and correlation time;
changing vS shifts the mean without altering OU variance.
Figure 3: vS sweep and steady oﬀset. With u∗ = 0 and ﬁxed k, increasing vS shifts the steady line parallel to
ˆU = ˆS as predicted by D∞ = −vS /(2k).
7 Parameter identiﬁcation from trajectories
From the AR(1) coeﬃcient ˆϕ, reconstruct k = − 1
2∆t ln ˆϕ (from the stationary OU ρ∆t = e−2k∆t); a scatter
plot in Supplementary Fig. S2 validates the identiﬁcation.
We estimate ( k, vS , u∗, σ) from ( ˆUt, ˆSt) time-series by state-space regression on Dt = ˆUt − ˆSt. A practical
scheme is (i) de-mean around the empirical diagonal, (ii) ﬁt the OU dri ft a D + b by least-squares on ˙D
(or AR(1) in discrete time), and (iii) recover k = −a/2, u∗ − vS = b, and σ2 from residual variance. When
overshoot is present, ﬁt the second-order canonical parameters ( ζ, ωn) via the linearization relations above,
yielding ( k, τ, β ) under the actuator-lag realization.
7.1 Discrete-time OU identiﬁcation (ﬁrst-order case)
Let ∆ t be the sampling interval and Dt = ˆUt − ˆSt. Discretizing (2) gives the AR(1) model
Dt+1 = ϕ Dt + β + εt, ε t ∼ N (0, σ2
ε ). (4)
With ϕ ≈ 1 − 2k ∆t and β ≈ (u∗ − vS ) ∆t, the back-transform is
ˆk = 1 − ˆϕ
2 ∆t , ˆ(u∗ − vS ) =
ˆβ
∆t.
5
The innovation variance maps to the continuous-time noise scale via σ2 ≈ σ2
ε
2k
1−ϕ2 for small ∆ t.
7.2 Second-order identiﬁcation (overshoot present)
When transients overshoot, ﬁt the AR(2)
Dt = φ1Dt−1 + φ2Dt−2 + et, e t ∼ N (0, σ2
e ). (5)
Let the characteristic roots be λ1,2 = r e±iθ (valid when φ2 < 0). Then r = √− φ2 and θ = arccos
(
φ1/(2r)
)
.
With sampling step ∆ t,
r = e−ζωn∆t, ω d = θ
∆t = ωn
√
1 − ζ2.
Hence
ζωn = −ln r
∆t , ω n =
√
(ζωn)2 + ω2
d, ζ = ζωn
ωn
.
Under the actuator-lag realization, identify ( k, τ, β ) from ω2
n = 2 k/τ + β and 2 ζωn = 2 k + 1/τ.
7.3 Uncertainty and diagnostics
We report 95% CIs from either (i) OLS sandwich covariance of ( ˆϕ, ˆβ) or ( ˆφ1, ˆφ2), propagated to ( k, vS , u∗, ζ, ω n)
by the delta method, or (ii) block bootstrap over contiguous window s. Diagnostics include: residual whiteness
(Ljung–Box), stability ( |ϕ| < 1 for AR(1), roots inside unit circle for AR(2)), and consistency with O U
variance Var[D] ≈ σ2/(4k) when applicable.
8 Discussion
We analyzed adaptive dynamics on the correspondence plane ( ˆU, ˆS) and showed how a simple diagonal policy
recovers the work core (Sec. 4) while enabling transient typology (Fi g. 2) and a closed-form steady oﬀset
under S-drift (Sec. 6). The dual form J = VFE − λ EFE clariﬁes how present-ﬁt and future-openness are
jointly regulated by a single temperature-like parameter λ, in structural analogy to F = U − T S.
Interpretation. On the correspondence plane, k controls approach speed and dispersion, whereas vS sets
the steady position relative to the diagonal via D∞ = ( u∗ − vS )/(2k). Overshoot arises when corrective
updates contain an eﬀective second-order lag; its magnitude is set by ( ζ, ωn) and maps back to ( k, τ, β )
through a canonical realization.
Relation to prior work. Classical FEP accounts emphasize VFE minimization; EFE introduces e pistemic
value but leaves the balance model-dependent. Our results make t hat balance explicit and analyzable with
standard tools from linear systems and stochastic processes, withou t appealing to physical entropy production
or thermodynamic identities beyond the structural mapping.
Testable predictions. (1) Var[D] = σ2
4k , ρ∆t ≈ e−2k∆t(larger k reduces both variance and lag-1
autocorrelation).
(2) ζ ≲ 1 yields the fastest (almost) monotone settling with a small oversho ot.
(3) D∞ = − vS /(2k)(varying vS shifts the bias linearly without changing dispersion or damping).
The framework makes falsiﬁable predictions and links control gains to ne uromodulatory and autonomic
mechanisms, suggesting straightforward experimental handles (pupi l, HRV/vagal tone, noradrenergic and
dopaminergic pharmacology).
8.1 Limitations
(i) The duality between J and F is structural rather than numerical; no thermodynamic claims are mad e.
(ii) Linearization is local; strong nonlinearities may alter oversho ot boundaries. (iii) Identiﬁcation in Sec. 7
assumes stationarity over the ﬁtting window; regime changes requir e segmentation or switching models. (iv)
The agency gain c is summarized as keﬀ = c k; a full treatment is deferred to future work.
6
Related work (brief). Connections to motivated control and hierarchical active inference app ear in [ 21, 22],
and PID/control perspectives compatible with our identiﬁcation are di scussed in [ 23]. For thermodynamic
structure at a descriptive level, see [20].
These implications are consistent with neuromodulatory and autonomic ac counts of exploration–exploitation
balance and arousal/precision control [5, 8, 7, 10].
8.2 Biological grounding (minimal hypothesis)
See also Sec. 9 for strengths and outlook.
We interpret the diagonal-policy gains as complementary neuromodulatory controls. The uncertainty gain
λ(t) is plausibly gated by locus-coeruleus noradrenaline (NE), adjusti ng openness to future evidence [ 24].
Dopamine (DA) acts on two knobs: (i) eﬀective precision via the mean-reversion gain k in cortico–basal-
ganglia–thalamic loops (policy sharpness/vigor), and (ii) the set-point th rough drift vS that tracks average
reward rate, yielding D∞ = − vS /(2k) [ 25, 26, 27, 28]. Thus, NE tunes openness ( λ) while DA sets precision
(k) and baseline ( D∞).
Autonomic grounding (hypothesis). Pupil dilation is a practical proxy for the uncertainty gain
λ [29, 30, 31, 32]. Sympathetic (LC–NA) drive up-regulates λ(t) and tends to reduce eﬀective damping ζ,
yielding larger excursions with small overshoot, whereas parasympat hetic/vagal tone stabilizes by increasing
ζ and suppressing process noise σ. Dopamine primarily sets precision/agency and baseline via the struc tural
mapping of k and D∞ [33, 34].
Links to manipulability. Beta–blockade (e.g., propranolol) corresponds to λ ↓; dopaminergic agonists
correspond to k ↑ and D∞ ↑ at ﬁxed vS . These qualitative links motivate the diagonal policy with λ as an
arousal/openness gain and k as a precision/settling parameter.
Dopamine-speciﬁc predictions. (i) DA upregulation (e.g., L-DOPA / D1 bias) increases k, therefore
Var[D] = σ2/(4k) decreases and ρ1 ≃ e−2k∆t shortens; DA downregulation shows the opposite. (ii) Blockwise
increases in average reward rate shift D∞ in parallel via vS ∝ρ without changing dispersion. (iii) Trial-by-trial
phasic DA (RPE) updates the future-openness drive (reﬂected in vS ), predicting correlated shifts of D(t)
after positive vs. negative RPE.
Autonomic predictions. (i) Acute SNS up (cold pressor / startle / isometric grip) ⇒ λ ↑, ζ ↓: larger
|D(t)|, small overshoot Mp = exp(−πζ/
√
1 − ζ2), slower return. (ii) Vagal breathing / HRV-biofeedback
(PNS up) ⇒ ζ ↑, σ ↓: Var[D] and ACF shrink with unchanged D∞. (iii) Clonidine ( α2; LC-NE down) ⇒
λ ↓; propranolol ( β-block) blunts SNS vigor, reducing overshoot without changing k. These eﬀects sit on top
of DA-speciﬁc manipulations (DA ↑⇒ k ↑, Var/ACF ↓; average reward ρ shifts D∞ = −vS /(2k)).
9 Conclusion
This paper introduced a diagonal policy on the correspondence plane ( ˆU, ˆS) that recovers the work core
while admitting transient typology and a closed-form steady oﬀset unde r S-drift. The dual objective
J = VFE − λ EFE makes explicit the trade-oﬀ between present-ﬁt and future-openn ess, in structural analogy
to F = U − T S. Together with the OU identiﬁcation scheme, the framework yields t estable signatures in
variance, autocorrelation, and overshoot.
Strengths and outlook. Our account moves the free-energy framework from a descriptive sch eme toward
a testable theory. The diagonal policy aﬀords biological grounding via minim al hypotheses linking neuro-
modulatory and autonomic control, and the derived signatures enable dire ct evaluation against physiological
readouts (e.g., pupil dynamics). Future work will extend the line ar analysis to hierarchical and nonlinear
regimes and assess the predictions in task datasets.
See Sec. 8.2 for biological grounding.
7
Data and code availability
All simulation code and ﬁgure scripts used in this paper will be rele ased in a public repository (e.g.,
OSF/Zenodo) upon acceptance and are available to reviewers on request. Parameter ﬁles and random seeds
will be included for full reproducibility.
Acknowledgments
The author thanks colleagues and readers for helpful comments on earlier v ersions of this work.
Author contributions
TS conceived the study, performed the analysis, generated the ﬁgure s, and wrote the manuscript.
Competing interests
The author declares no competing interests.
Supplementary Information
We report auxiliary OU results used in the main text.
S1. OU variance vs. k (related to Sec. 5)
Figure S1: OU variance vs k: empirical variance follows Var[ D] = σ2/(4k).
8
S2. OU lag-1 autocorrelation vs. k (related to Sec. 5)
Figure S2: OU lag-1 autocorrelation vs k: matches e−2k∆t.
9
Supplementary: Toy bandit agent (evidence that λ modulates ex-
ploration)
We simulated a two-armed Bernoulli bandit ( p⋆ = (0 .7, 0.5)) with a Beta–Bernoulli posterior. Action selection
used a simple UCB-like proxy for J = VFE − λ EFE: scorea = µa + β σa, where µa, σa are posterior mean/SD
for arm a, and β ∝ λ. Larger β accelerates discovery of the better arm while reducing cumulativ e regret.
S3. Two-armed bandit: choice accuracy
Figure S3: Probability of choosing the best arm over time for β = 0 .0, 0.5, 1.0.
10
S4. Two-armed bandit: cumulative regret
Figure S4: Cumulative regret. Larger β reduces regret via faster identiﬁcation.
Supplementary: Additional demonstrations
(i) 1D continuous control. Larger k tightens dispersion and shortens correlation time; shown by realist ic
time-series traces.
S5. One-dimensional target tracking: sample trajectories
Figure S5: OU-like tracking error D(t) for k ∈ { 0.5, 1.0, 2.0}. Larger k yields tighter, faster ﬂuctuations.
11
S6. OU metrics vs. k
Figure S6: Empirical variance and correlation time versus k from the traces above. Both decrease with k.
(ii) OU identiﬁcation from pseudo prediction-error. AR(1) slope ϕ yields ˆk = − ln ϕ/(2∆t).
12
S7. OU identiﬁcation: (Dt−1, Dt) scatter and AR(1) slope
Figure S7: Scatter of ( Dt−1, Dt) with ﬁtted AR(1) slope; recovered k matches ground truth.
(iii) Light motor reach. Slight underdamping ( ζ ≲ 1) gives fastest convergence with small overshoot.
S8. Motor reach: slight underdamping ( ζ ≈ 0.8)
Figure S8: Reach error D(t) under ζ ≈ 0.8 shows minimal overshoot and rapid settling, consistent with Fig. 2.
13
0.0 0.5 1.0 1.5 2.0 2.5 3.0
Lag  (s)
0.2
0.4
0.6
0.8
1.0ACF
OU ACF check (k = 0.5)
Empirical ACF
Theory e 2k
Figure S9: OU ACF check. Empirical autocorrelation of Dt vs the theoretical curve e−2kτ (here k = 0 .5).
Data and Code Availability
Data and code supporting this study are available at Zenodo: DOI 10.5281/zeno do.17177681. The archive
includes the minimal script to reproduce OU signatures, the dum my real-like series used in Fig. S11–S12, and
validation ﬁgures. The record is public and versioned.
14
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4
Lag  (s)
1.2
1.0
0.8
0.6
0.4
0.2
0.0
log  ACF
OU log ACF (slope  2 k)
log ACF
Linear fit (slope -0.83)
Figure S10: OU log-ACF linearity. log(ACF) is approximately linear in τ with slope ≈ − 2k.
0.0 0.5 1.0 1.5 2.0 2.5 3.0
Lag  (s)
0.2
0.4
0.6
0.8
1.0ACF
Real-data ACF (dummy)
Empirical ACF
Theory with k= 0.40
Figure S11: Real-data ACF (dummy). Empirical ACF with ﬁtted OU curve using ˆk.
15
0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00
Lag  (s)
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0
log  ACF
Real-data log-ACF (dummy)
log ACF
Linear fit (slope -0.80, R2 1.00)
Figure S12: Real-data log-ACF (dummy). Linear ﬁt to log(ACF); slope ≈ − 2ˆk.
16
0 2 4 6 8 10
Time (s)
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00Response
Transient responses: under/critical/over-damped
= 0.6
= 1.0
= 1.5
Figure S13: Transient responses. Step responses for ζ ∈ { 0.6, 1.0, 1.5} illustrate fastest settling near critical
damping and overshoot in the underdamped regime.
17
0.8 0.6 0.4 0.2 0.0 0.2 0.4 0.6 0.8
vS
0.2
0.0
0.2
0.4
0.6
D  (mean discrepancy)
Offset law: D (u * vS)/(2k)
Observed mean [ D]
Fit: slope -0.59, intercept 0.25
Figure S14: Oﬀset law under S-drift. The steady discrepancy follows D∞ ≈ (u∗ −vS )/(2k); points show synthetic
estimates and line a least-squares ﬁt.
18
A OU Identiﬁcation on Real Data (Minimal Script)
We provide a short script to reproduce the OU signatures on any univ ariate time series (e.g., pupil diameter,
HRV, joystick tracking). Save your data as data/real_series.csv and run:
python OU_ident_realdata.py --in data/real_series.csv --dt 0.01 --col 0
This prints ˆk (from the log-ACF slope) and saves two ﬁgures for ACF and log-ACF. The core is fewer than
60 lines for ease of reuse.
Code (excerpt).
# compute_acf, z-score, and linear fit to log-ACF to estimate k
acf = compute_acf(x, M); taus = np.arange(M)*dt
mask = (taus > 3*dt) & (taus < 0.7*args.maxlag) & (acf > 1e-6)
xfit = taus[mask]; yfit = np.log(acf[mask] + 1e-12)
A = np.vstack([xfit, np.ones_like(xfit)]).T
slope, intercept = np.linalg.lstsq(A, yfit, rcond=None)[0]
\hat k = -0.5 * slope
Figure insertion (real data). After running the script, include:
0.0 0.5 1.0 1.5 2.0 2.5 3.0
Lag  (s)
0.2
0.4
0.6
0.8
1.0ACF
Real-data ACF (dummy)
Empirical ACF
Theory with k= 0.40
Figure S15: Real-data ACF. The empirical ACF with the ﬁtted OU curve using ˆk.
19
0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00
Lag  (s)
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0
log  ACF
Real-data log-ACF (dummy)
log ACF
Linear fit (slope -0.80, R2 1.00)
Figure S16: Real-data log-ACF. Linear ﬁt to log(ACF); slope ≈ − 2ˆk.
References
[1] Karl Friston. The free-energy principle: a uniﬁed brain theory? Nature Reviews Neuroscience , 11:127–138,
2010.
[2] Thomas Parr and Karl Friston. Generalised free energy and active infere nce. Biological Cybernetics,
113(5):495–513, 2019.
[3] Massimiliano Esposito and Christian Van den Broeck. Second law and lan dauer principle far from
equilibrium. EPL (Europhysics Letters) , 95:40004, 2011.
[4] Christian Maes. On the origin and the use of ﬂuctuation relations for the e ntropy. S´ eminaire Poincar´ e,
2:29–62, 2003.
[5] Gary Aston-Jones and Jonathan D. Cohen. An integrative theory of locus coer uleus–norepinephrine
function: adaptive gain and optimal performance. Annual Review of Neuroscience , 28:403–450, 2005.
[6] Susan J. Sara. The locus coeruleus and noradrenergic modulation of cognit ion. Nature Reviews
Neuroscience, 10:211–223, 2009.
[7] Wolfram Schultz, Peter Dayan, and P. Read Montague. A neural substrate of prediction and reward.
Science, 275(5306):1593–1599, 1997.
[8] Matthew R. Nassar, Raphael S. Malika, Joseph W. Gold, Joshua I. Cohen, et al. Rational regulation of
learning dynamics by pupil-linked arousal systems. Nature Neuroscience, 15:1040–1046, 2012.
[9] M. Jepma and S. Nieuwenhuis. Pupil diameter predicts changes in th e exploration–exploitation trade-oﬀ:
evidence for the adaptive gain theory. Journal of Cognitive Neuroscience , 23(7):1587–1596, 2011.
[10] Peter J. Schwartz et al. Sympatho-vagal balance and cardiac risk. Annals of the New York Academy of
Sciences, 1148:322–335, 2008.
20
[11] Karl J. Friston. Active inference: A process theory. Neural Computation , 29(1):1–49, 2017.
[12] Thomas Parr, Giovanni Pezzulo, and Karl J. Friston. Active Inference: The Free Energy Principle in
Mind, Brain, and Behavior . MIT Press, 2022.
[13] Udo Seifert. Stochastic thermodynamics, ﬂuctuation theorems and m olecular machines. Reports on
Progress in Physics , 75(12):126001, 2012.
[14] Massimiliano Esposito and Christian Van den Broeck. Three detailed ﬂuctuation theorems. Physical
Review Letters , 104(9):090601, 2010.
[15] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwarte nbeck, and Giovanni Pezzulo. Active
inference: A process theory. Neural Computation , 29(1):1–49, 2017.
[16] Kenji Doya. Metalearning and neuromodulation. Neural Networks , 15(4-6):495–506, 2002.
[17] Mark W. Howe and David A. Dombeck. Rapid signaling in distinct dopaminer gic axons during locomotion
and reward. Nature, 500:575–579, 2013.
[18] Amitai Shenhav, Matthew M. Botvinick, and Jonathan D. Cohen. The expec ted value of control: an
integrative theory of anterior cingulate cortex function. Neuron, 79(2):217–240, 2013.
[19] Udo Seifert. Stochastic thermodynamics, ﬂuctuation theorems and m olecular machines. Reports on
Progress in Physics , 75(12):126001, 2012.
[20] Christian Maes. Frenesy: Time-symmetric dynamical activity in n onequilibria. Physics Reports, 850:1–33,
2020.
[21] Giovanni Pezzulo, Francesco Rigoli, and Karl Friston. Hierarchical acti ve inference: a theory of motivated
control. Trends in Cognitive Sciences , 22(4):294–306, 2018.
[22] Thomas Parr and Karl J. Friston. Active Inference. MIT Press, 2022.
[23] Manuel Baltieri and Christopher L. Buckley. Pid control as active infe rence. arXiv preprint
arXiv:1811.07061, 2018.
[24] Gary Aston-Jones and Jonathan D. Cohen. An integrative theory of locus coer uleus–norepinephrine
function: adaptive gain and optimal performance. Annual Review of Neuroscience , 28:403–450, 2005.
[25] Wolfram Schultz, Peter Dayan, and P. Read Montague. A neural substrate of prediction and reward.
Science, 275(5306):1593–1599, 1997.
[26] Yael Niv, Nathaniel D. Daw, and Peter Dayan. Tonic dopamine: opportunity c osts and the control of
response vigor. Journal of Neuroscience , 27(21):6473–6479, 2007.
[27] Rafal Bogacz and Kevin Gurney. The basal ganglia and cortex implement optimal decision making
between alternative actions. Neural Computation , 19(2):442–477, 2007.
[28] Michael J. Frank et al. By carrot or by stick: cognitive reinforcement l earning in parkinsonism. Science,
306:1940–1943, 2004.
[29] Susan J. Sara. The locus coeruleus and noradrenergic modulation of cognit ion. Nature Reviews
Neuroscience, 10:211–223, 2009.
[30] Gary Aston-Jones and Jonathan D. Cohen. An integrative theory of locus coer uleus–norepinephrine
function: adaptive gain and optimal performance. Annual Review of Neuroscience , 28:403–450, 2005.
[31] Marlieke Jepma and Sander Nieuwenhuis. Pupil diameter predicts c hanges in the exploration–exploitation
trade-oﬀ: evidence for the adaptive gain theory. Journal of Cognitive Neuroscience , 23(7):1587–1596,
2011.
21
[32] Matthew R. Nassar, Raphael G. Wilson, Joseph W. Gold, Joshua I. Heitz, et al . Rational regulation of
learning dynamics by pupil-linked arousal systems. Nature Neuroscience, 15:1040–1046, 2012.
[33] Wolfram Schultz, Peter Dayan, and P. Read Montague. A neural substrate of prediction and reward.
Science, 275(5306):1593–1599, 1997.
[34] Mark W. Howe and Daniel A. Dombeck. Functional organization of dopamine signalin g during locomotion
and reward. Current Opinion in Neurobiology , 33:63–70, 2016.
22