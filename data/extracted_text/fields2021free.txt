A free energy principle for generic quantum
systems
Chris Fieldsa∗ , Karl Fristonb, James F. Glazebrookc,d and Michael Levine
a 23 Rue des Lavandi`eres, 11160 Caunes Minervois, FRANCE
b Wellcome Centre for Human Neuroimaging, University College London,
London, WC1N 3AR, UK
c Department of Mathematics and Computer Science,
Eastern Illinois University, Charleston, IL 61920 USA
d Adjunct Faculty, Department of Mathematics,
University of Illinois at Urbana-Champaign, Urbana, IL 61801 USA
e Allen Discovery Center at Tufts University, Medford, MA 02155 USA
January 3, 2022
Abstract
The Free Energy Principle (FEP) states that under suitable conditions of weak coupling,
random dynamical systems with sufficient degrees of freedom will behave so as to min-
imize an upper bound, formalized as a variational free energy, on surprisal (a.k.a., self-
information). This upper bound can be read as a Bayesian prediction error. Equivalently,
its negative is a lower bound on Bayesian model evidence (a.k.a., marginal likelihood). In
short, certain random dynamical systems evince a kind of self-evidencing. Here, we re-
formulate the FEP in the formal setting of spacetime-background free, scale-free quantum
information theory. We show how generic quantum systems can be regarded as observers,
which with the standard freedom of choice assumption become agents capable of assigning
semantics to observational outcomes. We show how such agents minimize Bayesian predic-
tion error in environments characterized by uncertainty, insufficient learning, and quantum
contextuality. We show that in its quantum-theoretic formulation, the FEP is asymptot-
ically equivalent to the Principle of Unitarity. Based on these results, we suggest that
biological systems employ quantum coherence as a computational resource and – implicitly
– as a communication resource. We summarize a number of problems for future research,
∗Correspondingauthorat: 23RuedesLavandi`eres,11160CaunesMinervois,FRANCE;E-mailaddress:
fieldsres@gmail.com
1
1202
ceD
03
]hp-tnauq[
1v24251.2112:viXra
particularly involving the resources required for classical communication and for detecting
and responding to quantum context switches.
Contents
1 Introduction 3
2 Physical interaction as information exchange 5
2.1 What is “quantum”? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
2.2 Unitarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2.3 Separability and holographic encoding . . . . . . . . . . . . . . . . . . . . . 7
2.4 Reference frames . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2.5 Symmetry breaking, decoherence, and agency . . . . . . . . . . . . . . . . . 12
2.6 Channel theory of QRFs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
3 Repeated measurements and system identification 20
3.1 Memory, time, and coarse-graining . . . . . . . . . . . . . . . . . . . . . . . 20
3.2 Learning and generative models . . . . . . . . . . . . . . . . . . . . . . . . . 24
3.3 Identifying and measuring systems embedded in E . . . . . . . . . . . . . . . 25
3.4 Noncommutativity and context-switching . . . . . . . . . . . . . . . . . . . . 28
4 FEP for generic quantum systems 30
4.1 Defining VFE for quantum systems . . . . . . . . . . . . . . . . . . . . . . . 30
4.2 Sources of VFE for quantum systems . . . . . . . . . . . . . . . . . . . . . . 31
4.3 Asymptotic behavior of the FEP . . . . . . . . . . . . . . . . . . . . . . . . 34
5 Discussion 37
5.1 High-level overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
5.2 Summary of results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
5.3 Applications to biological cognition . . . . . . . . . . . . . . . . . . . . . . . 40
5.4 Predictions and open questions . . . . . . . . . . . . . . . . . . . . . . . . . 42
2
1 Introduction
Since its introduction as a theory of brain function [1, 2, 3, 4], the variational Free Energy
Principle (FEP) has been extended into an explanatory framework for living systems at all
scales [5, 6, 7, 8, 9], and shown to characterize, in its most general form, all random dy-
namical systems that remain measurable, and hence identifiable as persistent and separable
entities, over macroscopic times [10]. To summarize, it is shown in [10] that any system that
has a non-equilibrium steady state (NESS) solution to its density dynamics i) possesses an
internaldynamics thatis conditionally independent of thedynamics ofits environment, and
ii) will continuously “self-evidence” by returning its state to (the vicinity of) its NESS. The
FEP is the statement that any measurable, i.e. bounded and macroscopically persistent,
system will behave so as to satisfy these requirements. Self-organization, the FEP tells
us, is not a rare, special case, but a ubiquitous feature of physical systems with sufficient
dynamical stability to be called “things.” All “things,” in particular, self-organize Markov
blankets (MBs; see [11] for an informal review) comprising “sensory” states that encode
incoming information and thus mediate the influence of external states on internal states,
and “active” states that encode outgoing information and thus mediate the influence of
internal states on external states. This partitioning of “things” into internal and MB states
means that every “thing” can be construed as a certain kind of “particle” – a particle that
is in open exchange with external states via its MB. In short, the MB of any such “particle”
underwrites conditional independence between its internal states and the external states of
its environment by localizing and thereby restricting information exchange; hence, the MB
can be viewed as separating internal from external states, while mediating their exchange.
As noted in [10], generalizing the FEP to characterize the behavior of all “things” substan-
tialyweakensthetraditionaldistinctionbetween“cognition”andmerely“physical”dynam-
ics, andhenceweakenstheevendeeper, pretheoretical[12]distinctionbetween“agents”and
mere “objects” [13]. Treating physical interaction as information exchange – “observation”
of the environment followed by “action” upon it – redescribes the “mechanical” process
of returning to the NESS – as a random global (a.k.a., pullback) attractor – in terms of
inference. This can be read as “active inference” [4, 5, 6, 10] in which the existential in-
tegrity of the MB, and hence of the “self” – “world” distinction [14], can be maintained
in the face of environmental fluctuations by changing internal states (via sensory states:
c.f., perception) or changing external states (via active states: c.f., action). It refocuses the
discussion, in other words, from abstract trajectories (or flows) in state space to the MB
itself as a concrete locus of “identity” in the form of persistent measurability, and hence of
“self-evidencing” via active inference to maintain that identity.
The idea that all physical systems, including the environment at large, can be considered
“observers” that also act on their surroundings to “prepare” them for subsequent obser-
vations has become commonplace in quantum theory, largely replacing the “wave-function
collapse” postulate of traditional quantum mechanics [15] with interaction-induced deco-
herence (i.e., dissipation of quantum coherence) as the generator of classical information
3
[16, 17, 18, 19, 20].1 Indeed while quantum theory was originally developed – and is still
widely regarded – as a theory specifically applicable at the atomic scale and below, since
the pioneering work of Wheeler [24], Feynman [25], and Deutsch [26], it has, over the past
few decades, been reformulated as a scale-free information theory [27, 28, 29, 30, 31, 32] and
is increasingly viewed as a theory of the process of observation itself [33, 34, 35, 36, 37, 38].
This newer understanding of quantum theory fits comfortably with the generalization of
the FEP, and hence of self-evidencing and active inference, to all “things” as outlined in
[10], and with the general view of observation under uncertainty as inference.
In what follows, we take the natural next step from [10], formulating the FEP as a generic
principle of quantum information theory. We show, in particular, that the FEP emerges
naturally in any setting in which an “agent” or “particle” deploys quantum reference frames
(QRFs), namely, physical systems that give observational outcomes an operational seman-
tics [39, 40], to identify and characterize the states of other systems in its environment.
This reformulation removes two central assumptions of the formulation in terms of random
dynamical systems employed in [10]: the assumption of a spacetime embedding (or “back-
ground” in quantum-theoretic language) and the assumption of “objective” or observer-
independent randomness. It further reveals a deep relationship between the ideas of local
ergodicity and system identifiability, and hence the idea of “thingness” highlighted in [10],
and the quantum-theoretic idea of separability, i.e., the absence of quantum entanglement,
between physical systems.
Any quantum system that can be distinguished from its environment over time can, there-
fore, be regarded as self-organizing and self-evidencing as described in [10]. We then show
that when the FEP is taken to an asymptotic limit, it drives systems away from separabil-
ity towards entanglement, and hence towards a supraclassical statistical coupling between
each “thing” and its environment – between the observer and the observed. In this, the
FEP reproduces the Principle of Unitary, i.e. the Principle of Conservation of Information,
which similarly drives all interacting systems asymptotically toward entanglement. Hence
the FEP is, in an important sense, an alternative statement of the Principle of Unitarity,
the most fundamental principle of quantum theory. It therefore applies to a much broader
array of systems than would fall under an intuitive idea of “thingness,” e.g. to quantum
fields, and applies in principle from the Planck scale to cosmological scales. Formulating
the FEP as a generic principle of quantum information theory thus substantially expands
the range of systems to which “cognitive” or information-processing concepts reasonably
apply.
We begin by reviewing in §2 the basic principles of quantum theory from an information-
1Variants of quantum theory that postulate a physical collapse mechanism also invoke interaction, e.g.
with gravity or a “noise” field, to generate classicality; see [21] for review. We will not discuss here the
question of “interpretations” of quantum theory; see [22] for a thorough review and [23] for a more recent
taxonomy highlighting fundamental assumptions. Both decoherence and entanglement, in particular, have
different physical meanings in different interpretations, although their mathematical representations and
observable effects are interpretation-independent. Our general approach can be viewed as replacing the
“measurement problem” – that such interpretations are designed to solve – with an explicit, quantum-
informational theory of measurement. This theory is, we show, just the theory of the FEP.
4
theoretic perspective, limiting the formalism to focus on the physical meaning of the theory.
Using the category-theoretic [41, 42] formalism of Channel Theory – developed by Barwise
and Seligman [43] to formalize the operational semantics of natural languages – we develop
a generic formal representation of QRFs and show how the noncommutativity of QRFs
induces quantum contextuality [44, 45], a nonclassical effect demonstrating the presence of
entanglement between distinct physical degrees of freedom. We develop in §3 a generic,
formal description of how one quantum system identifies another quantum system as a
persistent entity – a “thing” – and measures, records, and compares its states by deploying
specific sequences of QRFs. This identification and measurement process depends critically
on breaking thermodynamic symmetries, and therefore on system-specific flows of energy.
These sections together provide a representation of generic quantum systems as observers,
or in the language of Gell-Mann and Hartle [46] “information gathering and using systems”
(IGUSs), that is free of scale and spacetime embedding (i.e. “background”) dependent as-
sumptions. It also treats all probabilities as observer-relative. We then show in §4 how the
FEP emerges in this setting and analyze its asymptotic behavior; in particular, we consider
how the FEP addresses the fundamental problem posed by quantum context switches. We
conclude in §5 by discussing the relevance of these results to a scale-independent under-
standing of biological systems as “particles” that interact with other “particles,” whether
these are other organisms, “objects,” or an undifferentiated environment. We consider in
particular the circumstances in which this “particle” nature can break down, and suggest
that well-designed experiments may be expected to detect quantum context switches or vio-
lationsoftheBell[47]orLeggett-Garg[48]inequalities, anyofwhichindicateentanglement,
by macroscopic biological systems under ordinary conditions.
2 Physical interaction as information exchange
2.1 What is “quantum”?
When physical interaction is viewed as information exchange, why it is “quantum” becomes
obvious: the fundamental quantum of information is one bit, one unit of entropy, that
one system exchanges with another. One bit, one quantum of information, is the answer
to one yes/no question. Planck’s quantum of action (cid:126) is then naturally regarded as the
action (energy · time) required to obtain one bit via any physical interaction. The energy
requiredtoirreversiblyobtainonebit, i.e., toreceiveandirreversiblyrecordonebit, isgiven
by Landauer’s Principle as ln2 k T, with k Boltzmann’s constant and T temperature
B B
[49, 50, 51]. The (minimum) time to irreversibly obtain one bit is then (cid:126)/ln2 k T, roughly
B
30 fs at 310 K. For comparison, the thermal dissipation time (in 3d space) due to time-
energy uncertainty is π(cid:126)/2ln2 k T [52], roughly 50 fs at 310 K. These values define a
B
minimal timescale for biologically-relevant, irreversible information processing, roughly the
timescale of molecular-bond vibrational modes [53] and an order of magnitude shorter than
photon-capture timescales [54].
5
Viewing all physical interaction as information exchange – and the bit as the fundamental
“quantum” of information – has the immediate consequence that interaction discretizes
the state spaces of all observable degrees of freedom. Given a set of mutually-commuting,
binary-valued observables, i.e., quantum operators implementing yes/no questions as de-
scribed below, a discrete state space for any observed system is constructed by assigning
a basis vector to each possible outcome (yes or no, +1 or -1) for each observable. These
are finite-dimensional Hilbert spaces. While Hilbert spaces with either finite or infinite
dimension are introduced ad hoc in traditional quantum mechanics [15], finite-dimensional
Hilbert spaces emerge naturally from the process of observation in the information theory.
As Fuchs puts it, infinite dimensional Hilbert spaces are, from an information perspective,
merely a “useful artifice” permitting computation with differential equations [55]. Hence
in what follows, all Hilbert space dimensions will be finite dimensional.
2.2 Unitarity
The fundamental axiom of quantum theory is unitarity, again introduced ad hoc in tradi-
tional treatments. If U is an isolated system, its time propagator is a unitary operator:
P =
e−(ı/(cid:126))HUt,
(1)
U
where H is the “internal” Hamiltonian (i.e. energy) operator satisfying the Schr¨odinger
U
equation:
ı(cid:126)(∂/∂t)|U(t)(cid:105) = H |U(t)(cid:105), (2)
U
where |U(t)(cid:105) is the time-dependent state of U. When H and hence P are time-invariant,
U U
solutions have the form:
|U(t)(cid:105) = e−ıϕt|U(0)(cid:105), (3)
where |U(0)(cid:105) is an initial (t = 0) state. This Eq. (3) describes a phase rotation by ϕ
per unit time t in the Hilbert space H ; the initial state |U(0)(cid:105) is preserved “up to” this
U
phase rotation. The dimension d = dim(H ) is the number of basis vectors of H and is, by
U U
definition, the quantity (in bits) of observable information encoded by the state |U(0)(cid:105). The
number d is clearly invariant under the phase rotation given by Eq. (3); hence the phase
rotation is not an observable. Unitary evolution as defined by Eq. (1) is, therefore, simply
evolution over time that conserves observable information. Hence, the fundamental axiom
of quantum theory is not ad hoc at all: it is the Principle that observable information, like
energy, is neither created nor destroyed by physical processes.
The appearance of the “imaginary” unit ı in Eq. (1) - (3) and the use of Hilbert spaces
over the complex field C are standard in quantum theory but are often considered a mere
convenience; compelling arguments for their necessity have only been developed recently
[56, 57]. They can, however, be given a straightforward interpretation: they emphasize
6
that the phase rotation implemented by P is not an observable dynamics and that the
U
“external” time t in these equations is not an observable, clock-referenced time.2 Indeed,
no classical information – no observational outcome – has yet been obtained in the setting
defined by Eq. (1) - (3). Characterizing observation as a process generating classical
outcomes as a result requires an additional assumption of separability as outlined below.
2.3 Separability and holographic encoding
Let U be an isolated system as above, and let U = AB be a bipartite decomposition of U,
i.e. the Hilbert space H = H ⊗H . At a fixed time t, any such bipartite decomposition
U A B
can be characterized by an entanglement entropy:
(cid:88)
S(|AB(cid:105)) = − |α |2log (|α |2), (4)
i 2 i
i
where the coefficients α are the Schmidt coefficients given by:
i
m
(cid:88)
|AB(cid:105) = α |u (cid:105) |v (cid:105) , (5)
i i A i B
i
where the label B is assigned so that m = dim(H ) ≤ dim(H ) and the |u (cid:105) and |v (cid:105) are
B A i A i B
orthonormalstatesofAandB respectively. TheentanglemententropyS(|AB(cid:105))isamutual
information measure that detects quantum correlation or “coherence” between A and B.
If S(|AB(cid:105)) = 0, the joint state factors as |AB(cid:105) = |A(cid:105)|B(cid:105) and hence is separable; otherwise
the joint state is entangled. Separable states are also called decoherent; entangled states are
coherent. Heuristically, a joint state |AB(cid:105) is separable if the individual states |A(cid:105) and |B(cid:105)
can be determined by independent measurements. If |AB(cid:105) is entangled, interactions with A
and B, including measurements, are no longer independent; this lack of independence can
be detected [47] and is the empirical basis for demonstrating entanglement [60] as discussed
in §5.4 below.
Extending Eq. (4) to all times and all bipartite decompositions of U gives a representation
of the time-dependent entanglement structure of U. As t → ∞ the unitary dynamics of
Eq. (1) will drive U toward maximal entanglement, i.e. S(|AB(cid:105)) → dim(H ) for every
B
bipartite decomposition U = AB; where, here again, B is taken to be the smaller of the two
systems. At maximum entanglement, the joint-state evolution can be considered a simple
rotation as in Eq. (3).
Given a decomposition U = AB, the Hamiltonian can be decomposed as H = H +
U A
H +H , where H represents the A-B interaction. Provided H is weak compared to
B AB AB AB
2Imagine, for an example, listening to a constant tone that has no beginning or end. Writing time as
ıt with t real allows Minkowski spacetime to be given a Galilean (++++) metric. See [58] for a discussion
of ı as a shorthand for converting classical to quantum observables, and [59] for a more intuitive view of
“rotation by ı” as a formal operation.
7
the internal interactions H and H and the time period of interest is short compared to
A B
timescale in which P drives the joint system to maximal entanglement, A and B can be
U
considered at least approximately separable, i.e. S(|AB(cid:105)) ≈ 0 so |AB(cid:105) ≈ |A(cid:105)|B(cid:105). In this
case, |A(cid:105) and |B(cid:105) can be considered individually well-defined, and bases can be chosen for
A and B so that:
N
(cid:88)
H = βkk Tk αkMk, (6)
AB B i i
i
where k = A or B, the Mk are N Hermitian operators with eigenvalues in {−1,1},
i
the αk ∈ [0,1] are such that (cid:80)N αk = 1, and βk ≥ ln2 is an inverse measure of k’s
i i i
thermodynamic efficiency that depends on the internal dynamics H [37, 38, 61, 62]. For
k
fixed k, the operators Mk clearly must commute, i.e. [Mk,Mk] = MkMk − MkMk = 0
i i j i j j i
for all i,j; hence H is swap-symmetric under the permutation group S for each k. The
AB N
thermodynamic factor βkk Tk in Eq. (6) assures compliance with Landauer’s Principle,
B
i.e., assures that the per-bit free-energy cost of classical bit erasure is paid on each cycle
(see [37, 38] for discussion). As U = AB is by assumption isolated, conservation of energy
requires βATA = βBTB. As discussed in [13], Eq. (6) can be written in ordinary narrative
form as:
Physical Interaction = (Thermodynamics)·(Yes/No questions).
This formulation emphasizes what quantum theory is about: the process of obtaining in-
formation. Obtaining information from B requires, in particular, that A acts on B by
asking questions. As Wheeler [63] puts it, “No question? No Answer!” All inference in this
framework is active inference; Eq. (6) does not allow “passive perception” to be a physical
process.
In contrast to classical theories of information transfer, in which physical tokens encoding
bits are transmitted between observers at different locations, Eq. (6) involves no assump-
tions about spacetime, objects, or motions. It is strictly topological: given separability, it
identifies a boundary B between A and B at which H is defined. This boundary is the
AB
“channel” via which A and B exchange strings of bits, ordered by the order of the operators
Mk in Eq. (6). Each of these bit strings encodes one eigenvalue of H ; as H has units
i AB AB
of energy, these eigenvalues are measures of the energy βkk Tk exchanged between A and
B
B during each cycle of interaction. Any time variation of H is, therefore, time variation
AB
of the energy exchanged and can be written:
N
(cid:88)
H (t) = βk(t)k Tk αk(t)Mk, (7)
AB B i i
i
where αk(t) and βk(t) are subject to the conditions on αk and βk given above. As noted for
i i
Eq. (1) - (3) above, the time t in Eq. (7) is not an observable, clock-referenced time. We
8
willforsimplicityconsiderH tobet-invariant; thisiseffectivelyanadiabaticassumption.
AB
An observer-specific, measurable time will be introduced in §3.1 below.
Boundaries such as B that function as information channels are, when embedded in space-
time and constrained by general covariance,3 holographic screens that limit communication
between the regions they separate to the bits that they encode [64, 65, 66, 67]. Interactions
between separable systems, i.e. interactions of the form given by Eq. (6) or (7) can, with-
out loss of generality, be regarded as defined at such holographic screens [38, 62, 68]. The
operators Mk can, in this case, be regarded as “preparation” and “measurement” operators
i
that alternately write and read bit values encoded on B. The S swap symmetry of the
N
Mk for each k means that the bits can be prepared, and then measured, in any order and
i
hence independently, provided preparation precedes measurement for each bit (such swaps
change the “zero point” of the energy scale and are undetectable). The screen B is, as
is any holographic screen, an ancillary construct, not “part of” either A or B. It can be
physically realized as an ancillary array of noninteracting qubits (quantum bits) with which
A and B interact as illustrated in Fig. 1.
3Effectively, this is a requirement for consistency with both Special and General Relativity.
9
Figure 1: A holographic screen B separating systems A and B with an interaction H
AB
given by Eq. (6) can be realized by an ancillary array of noninteracting qubits that are
alternately prepared by A (B) and then measured by B (A). Qubits are depicted as Bloch
spheres [27]. There is no requirement that A and B share preparation and measurement
bases, i.e. QRFs. Adapted from [38] Fig. 1, CC-BY license.
The holographic screen B has an obvious interpretation in the language of the FEP and
active inference: it implements the MB separating A from B [69]. “Active” and “sensory”
states of the MB correspond to preparation and measurement implemented by the Mk; as
i
the interaction H is perfectly symmetrical, A’s actions are B’s sensations and vice-versa.
AB
As bit strings on B encode energy eigenvalues, what either A or B “senses” is energy.
The assumption of separability plays, in this setting, the role played by the assumption
of measurability in [10]: it guarantees that systems A and B have well-defined individual
states. These states are at informational equilibrium; A and B exchange bits one-for-one.
They are not, however, at thermal equilibrium, TA = TB unless their thermodynamic
efficiencies βA = βB. Hence, when sampled and averaged over macroscopic times, the pure
states |A(cid:105) and |B(cid:105) become (mixed) NESS densities ρ and ρ .
A B
2.4 Reference frames
TheisolationofU = AB assuresthattheA−B channelisfreeofclassical, environmentally-
induced noise. The preparation and measurement operations MA and MB that A and B
i i
10
use to communicate, however, are defined with respect to and hence depend on the bases
|u (cid:105) and |v (cid:105) of the Hilbert spaces H and H respectively. In the qubit realization shown in
i i A B
Fig. 1, theMA andMB arez-spinoperatorsandsodependonthe“choices”ofz axisz and
i i A
z . Provided A and B are separable, and assuming that there are no “superdeterminist” a
B
priori correlations, z and z are uncorrelated; this is the “free choice” assumption. Free
A B
choice is often claimed to be essential to science as a practice [70, 71]; if it characterizes any
bounded system, consistency with quantum theory and special relativity together requires
that it must characterize all such systems [72]. Free choice of a basis introduces quantum
“noise” that is indistinguishable, observationally, from classical noise. Suppose B encodes
| ↑(cid:105) on qubit q, using z to define the “up” direction. If z = z , A’s measured state
B A B
|q(cid:105) = | ↑(cid:105), i.e. A’s probability P (| ↑(cid:105)) = 1. If, however, z is chosen perpendicular to z ,
A √ A A B
|q(cid:105) = (| ↑(cid:105)−| ↓(cid:105))/ 2 and P (| ↑(cid:105)) = P (| ↓(cid:105)) = 0.5.
A A A
The z axis in Fig. 1 is a reference frame; free choice of the z axis generalizes to free choice
of the reference frame for encoding each qubit on B. While in classical physics, reference
framesaretypicallythoughtofasfully-specifiableabstractions, inquantumtheoryreference
frames must be considered physical systems – QRFs – that encode unmeasurable quantum
phase information. A QRF cannot, therefore, be fully specified by any finite bit string; it
is “nonfungible” in the terminology of [40]. In the setting of Fig. 1, the z axis deployed
by a A (B) determines how A (B) prepares and then measures the states of the qubits
composing B. We can, in particular, consider A to be isolated from B during the time
interval “between” preparation and measurement steps, an interval shorter than the natural
timescale of the interaction H . During such a short interval, we abuse the notation only
AB
slightly by writing:
P : |B(cid:105) (cid:55)→ |B(cid:105) (8)
k meas prep
where k = A or B, i.e. by thinking of the internal propagators P and P , and hence
A B
the dynamics H and H , as computing the next preparation of the qubits on B from
A B
their most recent measured state. The idea of “computation” – or more properly, of the
physical system A (B) implementing a computation – is the standard notion, reviewed in
[73]: in brief, we can say a system A implements a computation of a function F if an
“interpretation” map I exists such that the diagram:
F
(cid:104)bits(cid:105) F (cid:47)(cid:47) (cid:104)bits(cid:105)
(cid:79)(cid:79) i (cid:79)(cid:79) i+1
IF IF (9)
|B(cid:105) (cid:47)(cid:47) |B(cid:105)
i i+1
PA
commutes, i.e. F I = I P for every “step” i → i + 1, where here (cid:104)bits(cid:105) is a finite bit
F F A
string and i → i+1 generalizes meas → prep in Eq. (8). A QRF, e.g. a z axis as in Fig.
1, implemented by P effectively “chooses” the computational basis that renders the string
A
(cid:104)bits(cid:105) well-defined. This is the same choice of basis that renders the MA well-defined in
i
Eq. (6). Hence, we can identify the interpretation map I with the QRF that renders the
F
11
function F well-defined; to simplify the notation, we will use boldface F to label the QRF
itself. The choice of QRF F and hence of computational basis is functional or semantic, not
physical; both H and H are invariant under changes of basis for H . It is worth noting
A AB A
explicitly that the choice of F is not encoded on B and is not observationally accessible to
B. Indeed, the general question of whether an arbitrary system A implements a QRF F is
Turing undecidable by Rice’s theorem [74]; see [38] for discussion.
As illustrated by the z axes in Fig. 1, the role of any QRF in a measurement setting is to
assure that measured values of some degree of freedom can be compared with each other
and hence given an operational meaning [75]. Meter sticks, clocks, gyroscopes, and the
Earth with its gravitational and magnetic fields serve this function, and are commonplace
laboratory QRFs. As described in detail in §3.3 below, recognizing an external object, such
as a meter stick, as a QRF and using it as such requires that the observer in question
already implements a QRF for the relevant degree of freedom: an observer with no “inter-
nal” ability to measure and compare lengths, for example, would find a meter stick useless.
All QRFs can, therefore, be considered internal functional components of, or computations
implemented by, larger systems that allow measurements of, and assign operational seman-
tics to, one or more degrees of freedom external to the implementing system [61]. Shared
operational semantics across observers requires shared QRFs. The nonfungibility of QRFs
rendersthequestionofQRFsharingingeneralTuringundecidable, againbyRice’stheorem
[38], a result consistent with the general undecidability of language sharing [76].
2.5 Symmetry breaking, decoherence, and agency
We will be interested in what follows in quantum systems, considered to be observers, that
deploy one or more distinct QRFs to measure particular subsets of the bits encoded on
their boundaries/MBs, and that record the values of these bits to a memory that persists
for at least one measurement cycle and hence allows comparisons of the values obtained in
at least two sequential measurements. Such systems effectively decompose the holographic
screen B into three disjoint sectors that we will label E the observed environment, F
the unobserved environment, and Y the memory sector, respectively. Equivalently, they
effectively decompose the set Mk of operators into three disjoint subsets (dropping the
i
redundant index k) ME, MF, and MY, respectively, with:
i j l
X = dom({MX}) (10)
def i
for each sector X. Assuming free choice of basis as above, this decomposition into sectors
can be regarded as freely chosen. Note that as B is the only locus of classical information in
the current formalism, any persistent classical memory must be a sector on B as discussed
in [13].
The assignment of operators to specific sectors breaks the S swap symmetry of B [38].
N
As with choice of QRF, this is a functional or semantic symmetry breaking, not a physical
symmetry breaking; the assignment of bits on B to distinct sectors by H has no effect
A
12
on the definition of H given by Eq. (6). Holding H fixed, we can vary the internal
AB AB
interaction H , and hence the implementation of QRFs as computations, so as to either
A
satisfy S symmetry or break it. Note that varying H in this way is equivalent to varying
N A
H − H ; such variation is undetectable at the boundary B. This insensitivity of B to
U B
variation in the internal or joint dynamics of A and B is the core physical meaning of the
holographic principle [64, 65, 66, 67].
Breaking the S swap symmetry on B renders the sector states |E(cid:105), |F(cid:105), and |Y(cid:105), each of
N
which corresponds to an encoded bit string, separable and hence mutually decoherent [38].
As emphasized in [77, 78, 79, 80, 81, 82] among others, decoherence is always observer-
relative, even when the “observer” is an ambient environment. Hence decoherence due to
swap-symmetrybreakingisdecoherencerelative toA; thechange-of-basisinvarianceofH
AB
renders A’s sector boundaries undetectable by B. Given free choice of QRFs, moreover,
B’s sector boundaries, if any, may be different from A’s. Mismatched sector boundaries
between A and B generate apparent “hidden variables” and hence variational free energy
[4, 5, 6, 10] as discussed in §4.2 below. For the present purposes, what is important is that
deploying a QRF sensitive to only some degrees of freedom of B (i.e. sensitive to only some
bit values encoded on B) breaks the swap symmetry on B and creates a decoherent sector
as defined by Eq. (10).
Breaking the swap symmetry on B allows different sectors to have different thermodynamic
efficiences, i.e. breaking swap symmetry allows breaking thermodynamic symmetry. This
can be made evident by rewriting Eq. (6) for A in terms of sectors X as:
(cid:88) (cid:88)
H = βXk TA αAMA, (11)
AB B i i
X i∈iX
where i is the set of indices of operators MA assigned to sector X. Note that this sym-
X i
metry breaking does not change the total energy exchanged (i.e. the eigenvalue of H ),
AB
it only allocates the energy differently to different sectors. This allows sectors to perform
different thermodynamic roles; in particular, it allows the unobserved environment sector
F to serve as a source of free energy to – and a sink of waste heat from – the observed
environment sector E and the memory sector Y [37, 38]. The bits encoded on F are,
therefore, noninformative to A and are traced (effectively, marginalised and averaged) over
when defining information-bearing states of A. Mathematically, this trace operation can
be viewed as implementing decoherence as discussed in [16, 17, 18, 19, 20], i.e., as imple-
menting the sector boundary of F. Assigning this thermodynamic function to F enables
thermodynamically-expensive classical information processing of bits encoded on E and Y,
including maintaining the stability of bit values written to Y as discussed in §3.1 below. It
therefore allows E and Y to have distinct semantics.
Free choice of a decomposition of B into sectors with different QRF-induced semantics is
indicative of agency. Hence, we can define:
Definition 1. A (nontrivial) agent is a system A with an internal dynamics H that breaks
A
the S swap symmetry of its boundary/MB B.
N
13
We can consider a system with a swap-symmetric boundary as shown in Fig. 1 a trivial
agent. Trivial agents correspond to “inert” systems with functionally-insignificant internal
states, and hence no internal information-processing capacity, as discussed in [10]. All
nontrivial agents are “cognitive” systems that engage in active inference.
Before proceeding to further characterize these sectors or to consider the imposition of ad-
ditional structure on E by further QRFs, we briefly review below the specification of QRFs
using the generic formalism of Channel Theory [43]. This formalism will enable characteri-
zation of the asymptotic behavior of the FEP and of context-switching as a mechanism for
minimizing FEP as discussed below in §4.3 below.
2.6 Channel theory of QRFs
Channel Theory [43] is an application of the category theory of Chu spaces, spaces of
semantic relations exemplified by object – attribute tables [83, 84, 85]. Indeed Channel
Theory can be regarded as defining a category Chan that is isomorphic to the category
Chu(Set,K) (for short, Chu) of Chu spaces. While conceptually simple, Channel Theory
is surprisingly rich, providing both a natural representation of conditional probabilities
and formal criteria for operator commutativity and quantum contextuality [86, 87] (for a
logico-philosophical perspective on the properties of semantic coherence in Chan, see e.g.
[88]). Furthermore, it provides an implementation-independent formal language for writing
functional specifications of QRFs as computations.
The central idea of Channel Theory is that of a “classifier” that relates tokens in some
language to types in that language. We can define a classifier as an object in Chan as
follows:
Definition 2. A classifier A is a triple (cid:104)Tok(A),Typ(A),|= (cid:105) where Tok(A) is a set of
A
“tokens”, Typ(A) is a set of “types”, and |= is a “classification” relating tokens to types.
A
The classification |= can, in general, be valued in any set K without assumed structure
A
(as is the case for Chu spaces); for simplicity, we will consider only binary classifications.
Morphisms in Chan, called “infomorphisms” between these objects are then given by the
following:
Definition3. GiventwoclassifiersA = (cid:104)Tok(A),Typ(A),|= (cid:105)andB = (cid:104)Tok(B),Typ(B),|=
A B
→− ←−
(cid:105), an infomorphism f : A → B is a pair of maps f : Tok(B) → Tok(A) and f : Typ(A) →
→− ←−
Typ(B) such that ∀b ∈ Tok(B) and ∀a ∈ Typ(A), f (b) |= a if and only if b |= f (a).
A B
This last definition can be represented schematically as the requirement that the following
diagram commutes:
−→
f (cid:47)(cid:47)
Typ(A) Typ(B)
(12)
|=A |=B
←−
(cid:111)(cid:111) f
Tok(A) Tok(B)
14
An infomorphism f : A → B is, effectively, a map relating the semantic constraints imposed
by the classification |= to those imposed by |= .
A B
We are, in practice, interested in collections of infomorphisms than construct complex
semantic constraints out of simple ones; these will allow us to specify QRFs as hierarchies
of semantic constraints. Given a finite collection A of classifiers, we can represent this
i
construction process as a finite, commuting cocone diagram (CCD) depicting a flow of
infomorphisms sending inputs to a core C(cid:48) that is the category-theoretic colimit of the
underlying classifiers, i.e., is the apex of the maximally general diagram of this form over
the A , if a unique such maximum exists:
i
(cid:56)(cid:56)C(cid:79)(cid:79) (cid:48) (cid:103)(cid:103)
f1
f2
f
k (13)
(cid:47)(cid:47) (cid:47)(cid:47)
A A ... A
1 g12 2 g23 k
The cocone core C(cid:48) is itself a classifier that encodes, via the incoming infomorphisms f ,
i
the conjunction of the semantic constraints imposed by the A .
i
There is a dual construction to this CCD, namely a commuting finite cone diagram (CD)
of infomorphisms on the same classifiers, where all arrows are reversed. In this case the
core of the (dual) channel is the category-theoretic limit of all possible downward-going
structure-preserving maps to the classifiers A . Hence, we can define the central idea of a
i
finite, commuting cone-cocone diagram (CCCD) as consisting of both a cone and a cocone
on a single finite set of classifiers A linked by infomorphisms as depicted below:
i
(cid:54)(cid:54)C(cid:79)(cid:79) (cid:48) (cid:105)(cid:105)
f1 f
k
f2
A (cid:104)(cid:104) (cid:111)(cid:111) g21 (cid:47)(cid:47) A (cid:111)(cid:111) g32 (cid:47)(cid:47) ... A (14)
1 g12 (cid:79)(cid:79)2 g23 (cid:53)(cid:53) k
h2
h1 h
k
D(cid:48)
If the cores C(cid:48) = D(cid:48), we can also represent the CCCD as:
A (cid:104)(cid:104)
(cid:111)(cid:111) g21 (cid:47)(cid:47)
A
(cid:111)(cid:111) g32 (cid:47)(cid:47)
... A
1 g12 (cid:79)(cid:79)2 g23 (cid:53)(cid:53) k
h2
h1 h
k
(cid:54)(cid:54)C(cid:79)(cid:79) (cid:48) (cid:105)(cid:105) (15)
f1 f
k
f2
A
(cid:111)(cid:111) g21 (cid:47)(cid:47)
A
(cid:111)(cid:111) g32 (cid:47)(cid:47)
... A
1 g12 2 g23 k
This diagram is naturally interpreted as reconstructing the semantics of the A via the
i
“combined” representation C(cid:48). Generalizing Diagram (15) by letting C(cid:48) be the limit of a
15
smaller set of classifiers A(cid:48),...A(cid:48), j < k, we can write:
1 j
A(cid:48) (cid:104)(cid:104) (cid:111)(cid:111) g 2 (cid:48) 1 (cid:47)(cid:47) A(cid:48) (cid:111)(cid:111) g 3 (cid:48) 2 (cid:47)(cid:47) ... A(cid:48)
1 g(cid:48) (cid:79)(cid:79)2 g(cid:48) (cid:53)(cid:53) j
12 23
h(cid:48)
h(cid:48) 2 h(cid:48)
1 j
(cid:54)(cid:54)C(cid:79)(cid:79) (cid:48) (cid:105)(cid:105) (16)
f1 f
k
f2
A
(cid:111)(cid:111) g21 (cid:47)(cid:47)
A
(cid:111)(cid:111) g32 (cid:47)(cid:47)
... A
1 g12 2 g23 k
Diagram (16) provides a natural representation of coarse-graining the semantics of A via
i
C(cid:48) into a compressed representation A(cid:48). We will employ this generalization in §3.1 below
i
to specify the writing of coarse-grained records of observational outcomes to the memory
sector Y.
Diagrams such as (13) – (16) can be generalized into hierarchical networks by adding
intermediate layers of classifiers and appropriate maps; when this is done, they clearly
resemble artificial neural networks (ANNs), and in the “bowtie” form of Diagrams (15)
and (16), variational autoencoders (VAEs) [86]. The core C(cid:48) in (15) and (16) can be
viewed as both an “answer” computed by the f from inputs to the A and, dually, as an
i i
“instruction” propagated by the h (or in Diagram (16), the h(cid:48)), to drive outputs from the
i i
A (or in Diagram (16), the A(cid:48)). Such dual input/output behavior is exactly the behavior
i i
of a QRF. We can, therefore, represent any QRF as a CCCD “attached” to a subset of
measurement operators MA,...MA by maps that identify the binary eigenvalues of the
k n
MA with binary inputs to the A as illustrated in Fig. 2.
i i
16
Figure 2: Attaching a CCCD to a subset of measurement operators MA,...MA by iden-
k n
tifying the binary eigenvalues of the MA with binary inputs to the A . Only the CCD
i i
direction arrows are shown for simplicity; adding equivalent but reversed arrows completes
the CCCD. The CCCD specifies a function computed by the internal dynamics P , i.e. a
A
QRF deployed by A. Adapted from [38] Fig. 3; CC-BY license.
Thus far we have considered binary CCCDs, corresponding to Boolean ANNs or VAEs or to
QRFs imposing Boolean constraints. Mapping a CCCD to an arbitrary ANN or VAE that
computes some function of interest F just requires assigning probabilities, i.e. “weights”
to the infomorphisms in a way that respects the Kolmogorov axioms [86, 87]. We can then
treat the computed function F from network inputs to network outputs as an arbitrary
probabilistic QRF, or as suggested by Diagram (16), a pair of coupled QRFs that process
some “sensory” signal received by the A and write the result to a lower-dimensional and
i
17
hence coarse-grained “memory” via the A(cid:48). A QRF so defined is naturally interpreted as
i
performing hierarchical Bayesian inference [86, 87]; see [89, 90] for applications to human
cognition.
To assign probabilities to infomorphisms, it is convenient to add the structure of a “local
logic” L(A) relating subsets of tokens and types to each classifier A [43]. To do this, we
define an “implication” relation between subsets of types:
Definition 4. Two subsets M,N ⊆ Typ(A) are related by a sequent M |= N if ∀x ∈
A
Tok(A),x |= M ⇒ x |= N.
A A
Via the sequent relation, the local logic L(A) effectively arranges the types of A into a
hierarchy; any classifier can be extended to a local logic in this way by adding types as
needed. Considering all classifiers to be extended to local logics, Diagrams (13) – (16) can
be considered diagrams of local logics by requiring each of the infomorphisms to be a “logic
infomorphism” that preserves the sequent structure. In general, given an information flow
channel:
−→ A −→ A −→ A −→ ··· (17)
α−1 α α+1
the semantic content can be extended by postulating local logics L = L(A ) generated by
α α
the corresponding classifiers A (assumed, in principle, to be in relationship to a (regular)
α
theory associated to the individual A , as specified in [43, Ch 9] (cf. [91]) and reviewed in
α
[87, Appendix A]), so to obtain a flow of logic infomorphisms:
··· −→ L −→ L −→ L −→ ··· (18)
α−1 α α+1
which we can take to comprise comprise a CCD as in Eq. (13). Logic infomorphisms are,
effectively, embeddings of type hierarchies; Diagrams (15) and (16) can be viewed as em-
beddings into a “top-level” type hierarchy C(cid:48) that assigns an overall semantics to its inputs,
followed by encodings of this top-level hierarchy into some componential representation.
The local logic L(A) defined above is Boolean. To extend the type hierarchy defined
by L(A) to a hierarchical Bayesian inference, we extend L(A) to a probabilistic logic by
relaxing the sequent relation to require only that if x |= M, there is some probability
A
P(N|M) that x |= N. We can then write:
A
M |=P N = P(M|N) (19)
A def
and construct (extended, probabilistic) logic infomorphisms as above, requiring that they
preserve the conditional probabilities P(M|N) for all subsets M, N at each level of the
hierarchy.4 Traversing upwards in the hierarchy then imposes multiple conditioning on
each “low-level” probability distribution; traversing downwards sequentially unpacks this
conditioning. In fundamental Bayesian terms, M above can be regarded as a previous
event, whether observed or conjectured, and N as a currently observed datum, in which
4As pointed out in [93], it is instructive to see that Eq. (19) reveals how a conditional probability can
be used for interpreting the logical implication “⇒” as discussed in [96].
18
case P(M) becomes the prior, and P(N) the evidence, that together generate a prediction.
Given the likelihood P(N|M) as the conditional obtained from weakening the sequent via
Eq. (19), Bayes’ theorem specifies this conditional as the posterior:
P(N|M)P(M)
P(M|N) = . (20)
P(N)
Abriefexampleillustratestheseprinciplesasfollows: considerarbitraryclassifiersA(a),...,A(e)
1 5
in some part of an information channel where (as in [87]) the classifiers correspond to events
a,b,c,d,e, respectively, together with logic infomorphisms f ,...,f between them, in
13 45
which the sequents are relaxed to conditional probabilities via Eq. (19):
A(a) A(b)
1 2
f13 f14 f24
(cid:125)(cid:125) (cid:33)(cid:33) (cid:125)(cid:125)
A(c) A(d) (21)
3 4
(cid:15)(cid:15)
f45
A(e)
5
Following e.g. [92], this particular channel then generates a joint probability distribution
given by:
p(abcde) = p(a)p(b)p(c|a)p(d|ab)p(e|d). (22)
Putting these details within the framework of the above diagrams, a portion of a typical
CCD computing a hierarchical Bayesian inference from a set of (posterior) observations A
i
to an outcome C(cid:48) has the form:
(cid:56)(cid:56)C(cid:79)(cid:79) (cid:48) (cid:103)(cid:103)
p10(·|·) p
k0
(·|·)
p20(·|·) (23)
(cid:47)(cid:47) (cid:47)(cid:47)
A A ... A
1 2 k
p12(·|·) p23(·|·)
Inthisformalsetting,thediagramcommutativityofDiagrams(13)–(16),withprobabilities
added as in Diagram (23) above, enforces Bayesian coherence: the probability associated
with any arrow U → V must equal the product of the probabilities associated with the
arrows on any other directed path from U to V.5 Any pair of subsets of the A have,
i
therefore, a well-defined joint probability distribution. As shown in [87], the converse is
also true. Letting A ,A ...B and B,C ,...C be finite sets of classifiers, we can state the
1 2 1 k
following [87, Thm. 7.1]:
5ProbabilityspacesandconditionaldistributionscanalsobedefineddirectlyforChuspacesasexhibited
in [87, Exs. 2.4, 2.5]. See [94] for an alternative representation of Bayesian inference and derivation of the
FEPusingmonodialcategoriesandanoperationalformalismcloselyrelatedtothoseemployedincategorical
quantum theory [95].
19
Theorem 1. A well-defined joint probability distribution exists over subsets A ,A ...B
1 2
and B,C ,...C of classifiers if and only if the following diagram commutes:
1 k
(cid:55)(cid:55)C(cid:103)(cid:103)
φ ψ
(cid:56)(cid:56)C (cid:79)(cid:79)1 (cid:103)(cid:103) (cid:55)(cid:55)C (cid:79)(cid:79)2 (cid:103)(cid:103) (24)
f1
f2
fB gB
g2
g
k
(cid:47)(cid:47) (cid:47)(cid:47) (cid:47)(cid:47) (cid:47)(cid:47)
A A ... B C ... C
1 2 1 k
that is, if and only if there exist logic infomorphisms φ, ψ and a classifier C such that the
above diagram is a CCD.
Proof. See [87]. The key observation is that φ and/or ψ can only fail to exist if the joint
probability distribution fails to exist.
The use of overlapping subsets of classifiers in Theorem 1 mirrors the use of mutually-
noncommuting subsets of mutually-commuting observables in the canonical definition of
quantum contextuality [44, 45] and its extension to a purely statistical criterion of incom-
patibility between measurement contexts [97, 98]. How the deployment of overlapping but
mutually-noncommuting subsets of QRFs implements context-switching between pairs of
complementary observables – such as position and momentum – is discussed in §3.4 be-
low. How the FEP can drive context-switching as a component of active inference is then
discussed in §4.3 below.
Viewing commutativity – and hence Bayesian coherence – as fundamental to the definition
ofmeasurement,andhencealsotothedefinitionofpreparationoractionontheenvironment
generally, suggests that the Born rule, i.e. that if a state:
(cid:88)
|X(cid:105) = α |x (cid:105), (25)
i i
i
the probability of obtaining |x (cid:105) as an observational outcome is:
i
P(|x (cid:105) = |α |2, (26)
i i
is a prescription for coherently assigning amplitudes α to components |x (cid:105), consistent with
i i
the position advocated in [33, 35].
3 Repeated measurements and system identification
3.1 Memory, time, and coarse-graining
The idea that a system must possess a (quasi-) NESS solution to its density dynamics – and
hence be restricted to trajectories in its classical configuration space that do not diverge
20
exponentially over time – in order to be observable as a “thing”, immediately raises the
issues of time as measurable duration and of memory as persistent over measurable time.
As the simplest case, consider the NESS density ρ of the observed environment sector E
E
of some agent A. The agent A can only detect changes in ρ and employ them as bases
E
for inferences and actions if A can write time-ordered records [ρ (t )] to, and subsequently
E A
read them from, the memory sector Y. Here t is an A-specific time coordinate that must
A
be constructed. Persistence of the memory record [ρ (t )] between writing and reading
E A
requires that it be “protected” from environmental noise, i.e. from ongoing events in E;
henceif|Y(cid:105)isthestateencoding[ρ (t )], |Y(cid:105)mustvaryonlyslowlyundertheactionofH .
E A B
In the notation of Eq. (6), “protection” occurs if the coefficients αB of operators MB acting
i i
on qubits within Y all have small magnitudes. We can, therefore, distinguish two classes
of actions by A on its boundary/MB B. Actions on E are “questions” in Wheeler’s [63]
sense; they provoke informative responses from B that can be used to develop a generative
model of H as discussed below. Actions on Y are recordings that must remain relatively
B
stable to be useful. Stability of the memory sector Y against H is a critical resource for
B
any system A capable of responding to environmental state changes, and hence of any A
capable of active inference. Heuristically, this is clearly evinced in active vision, where we
actively palpate the world, every 250 ms or so, to update our working memory Y; i.e.,
update our (Bayesian) beliefs about the observed environment E.
The Second Law tells us that protecting any state against noise requires the expenditure
of free energy. Hence, any agent A is faced with a fundamental thermodynamic tradeoff:
maintainingthestabilityofY requiresfreeenergysourcedfromtheunobserved(tracedover)
environmental sector F. For fixed H , and hence fixed B, expanding F to obtain more
AB
freeenergyforY requiresshrinkingE, i.e. “seeing”lessoftheenvironment. Thealternative
is to coarse-grain Y either in time or in space, i.e. in bit-string length. Which horn of this
thermodynamic trilemma a given system takes is determined by the QRFs it implements.
Classical manifestation of this trade-off are seen in many guises. For example, the intimate
relationship between the efficiency of information transfer afforded by compression – as
seen in minimum message length formulations of variational free energy [99, 100] – through
to the minimisation of statistical complexity afforded by coarse-graining and quantisation
[101].
The simplest memory-write process is illustrated in cartoon form in Fig. 3. A state |E(cid:105), a
bit string of length dim(E), is constructed from one-bit operators ME by a QRF E. It is
i
then written to the memory Y by a QRF Y, with free energy sourced from the remainder
of B, i.e. from the unobserved sector F. In the simplest case, the memory capacity
dim(Y) = ndim(E)+log n where n is the number of distinguishable records. The log n
2 2
labels that allow records to be distinguished can, without loss of generality, be considered
to be an integer sequence of clock ticks i → i+1, starting from i = 1. Hence, any memory
with more than one-record capacity defines a clock G , which we will see below must, in
ij
general, be a groupoid operator [37].6 This clock is an internal time QRF that defines the
6Recallthatagroupoidisacategoryinwhichtheobjectsandarrowseachcompriseaset(asfora‘small’
category), and every arrow is invertible [102, 103]. A groupoid generalizes the group concept in so far that
21
time coordinate t .
A
Figure 3: Cartoon illustration of QRFs required to write a readable memory of an observed
environmental state |E(cid:105). The QRFs E and Y read the state from E and write it to Y
respectively. The clock G is a time QRF that defines the time coordinate t .
ij A
The thermodynamic trade-off faced by A is between dim(E), dim(Y), and the sampling
time of states |E(cid:105), which determines the length of one clock tick and hence of one unit of t .
A
As mentioned earlier, the minimum timescale for biological systems is set by the thermal
dissipation time to roughly 50 fs. Practical biological clocks run much more slowly; a clock
based on Gamma-band neural activity in mammalian cortex, for example, has a sampling
time of 10 – 20 ms. The recorded record, in this case, is a sample from or average over
a time ensemble < |E(cid:105) > of measured states, i.e., is a record [ρ ] of a coarse-grained
E
density. This record can be further compressed to achieve dim([ρ ]) < dim(E) and hence
E
dim(Y) < n·dim(E)+log n.
2
With these QRFs, the memory read-compare-write cycle can be represented as in Fig. 4.
The classical record [ρ (i)] written in the previous cycle is read by Y at “external” (i.e. Eq.
E
(1) or (7)) time t. It is compared to the current measured state |E(t)(cid:105) and a new record
[ρ (j)] is written by Y at t+∆t. This read-compare-write cycle advances the internal clock
E
G by one tick i → j. All QRFs together with the comparison function are implemented by
ij
the former can admit “multiple identities” (the objects).
22
the internal dynamics P . Formally, we can think of P as a weighted sum of “all possible
A A
paths” from the boundary state |B(t)(cid:105) to the boundary state |B(t + ∆t)(cid:105) as in Eq. (8)
[104]; see [105] for discussion.
Figure 4: Cartoon illustration of one memory read-compare-write cycle defining one tick
i → j of the internal clock G and requiring an interval ∆t of “external” time t. All QRFs
ij
and the comparison function are implemented by the quantum dynamics P (block arrow).
A
Fig. 4 explicitly illustrates an important distinction between classical and quantum repre-
sentations of dynamics and hence between classical and quantum formulations of the FEP.
Classical physics assumes a spacetime embedding; hence the MB of any topologically-
connected system can be associated with a spatial boundary that follows a smooth space-
time trajectory. “Internal” states of the system and the “internal” dynamics that operates
on those states to maintain a NESS are spatially localized inside this boundary, and are,
in particular, not exposed on the boundary. The current, quantum setting makes, in con-
trast, no assumptions about spacetime embedding as emphasized earlier. The boundary
B represents a Hilbert-space decomposition, not a “physical” spacetime decomposition.
As B is the only locus of classical information, “internal” classical states, including all
classical memory records, are exposed on B. The assumption that these exposed states
are “protected” from H corresponds to the classical assumption of “self-evidencing”: that
B
maintaining the integrity of the MB as a spatial boundary enables the maintenance of the
NESS and vice-versa [10].
23
The true internal state of a quantum system A is the state |A(cid:105) that remains independently
well-defined provided the joint state |AB(cid:105) remains separable, i.e. provided the interaction
H can be written as Eq. (6). This internal state is “protected” from H by defini-
AB B
tion. Hence for quantum systems, “self-evidencing” is logically equivalent to separability.
Classical memories are at risk of environmental perturbation, unless sufficient free energy
is devoted to maintaining them. Quantum “memories” are encoded by the dynamics P
A
and are at risk of environmental perturbation only if separability breaks down, i.e. if |AB(cid:105)
becomes entangled.
With this non-spatial understanding of the “internal” states of a quantum system A with a
classicalmemory, boththequantum|A(t)(cid:105) → |A(t+∆t)(cid:105)andtheclassical[ρ (i)] → [ρ (j)]
E E
loops are internal to A. Hence, the (classical) integrated information Φ(A) > 0 as defined in
Integrated Information Theory (IIT) [106], rendering A “conscious” and hence an “agent”
in the framework of IIT. Hence the notion of agency in IIT is consistent with that of
Definition 1.
3.2 Learning and generative models
Learning a generative model allowing predictions of the future behavior of E is straightfor-
ward in this setting. The prediction problem can be represented as follows:
[ρ (1)],[ρ (2)],...[ρ (k −1)],[ρ (k)] → [ρ (k +1)], (27)
E E E E E
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Prior Posterior Prediction
where [ρ (1)],[ρ (2)],...[ρ (k − 1)] are previous memory records, [ρ (k)] is the current
E E E E
record, and [ρ (k + 1)] is the not-yet-obtained next record. The prior data can be re-
E
represented in three progressively more sophisticated ways:
1. As a probability distribution over the set of possible records, a discrete set of no more
than 2dim(E) elements.
2. As a probability distribution over the set of pairs ([ρ (i)],[ρ (i+1)]) and hence as a
E E
discrete Markov process.
3. As a map from probability distributions on records 1,2,...i to probability distribu-
tions on records 1,2,...i+1 and hence as a discrete Markov kernel.
Representing the prior data by a discrete Markov kernel provides the greatest data com-
pression, at the cost of more sophisticated processing by P .
A
The process of updating a Markov kernel MA(i) representing A’s prior data for E can be
E
formalized as:
L : (MA(i), [ρ (i)]) (cid:55)→ MA(i+1), (28)
E E E
24
where L is an operator of the form (function,data) → function(cid:48), i.e. a learning operator.
HenceanysystemAthatstorespriorinformationusingadatastructuremorespace-efficient
than an explicit linked list can be considered to be learning.
As the records [ρ (i)] are just bit strings and Bayesian coherence is guaranteed by the com-
E
mutativity of the operators composing the QRF Y, the sequence [ρ (1)],[ρ (2)],...[ρ (k)]
E E E
canberepresentedbya“true”MarkovkernelM (k)satisfyingthefollowingcommutativity
E
constraint:
ρ (i) M E (cid:47)(cid:47) ρ (i+1)
E(cid:79)(cid:79) E (cid:79)(cid:79)
(29)
E E
|B(t)(cid:105) PU(cid:47)(cid:47) |B(t+∆t)(cid:105)
whereasbeforeone“tick”oft correspondsto∆texternallyandthenotation|B(cid:105)indicates
A
the state of the qubit array encoded on B. At step k in A’s acquisition of state information
about E, therefore, A’s prediction error Er for E is:
E
Er (k) = d(MA(k),M (k)), (30)
E E E
where the d is the metric distance on Markov kernels. This definition is independent of L
and hence of the sources of A’s prediction errors.
3.3 Identifying and measuring systems embedded in E
We have so far considered only observers A that measure the states of their observed en-
vironments E without decomposing E into “systems” that have their own specific states.
Such undifferentiated measurements of E plausibly characterize all biological systems that
interact with their environments primarily biochemically, instead of mechanically [107].
A bacterium measuring an ambient salt concentration, for example, does not assign the
concentration value to a specific object within the environment [13]. Animals as diverse
as arthropods, cephalopods, and vertebrates, however, detect and track the states of spe-
cific external “particles” or objects, often other animals. In terms of theoretical biology,
this ability is either ancient, arising at least by the Cambrian explosion, or results from
convergent evolution in multiple distinct lineages.
˜
The question of how an observer A distinguishes a system S from the environment E, in
which S is embedded, is central to classical cybernetics [108, 109] and, under the rubric of
˜
object persistence, to cognitive and developmental psychology [110, 111]. Here, E indicates
˜
the remainder of E when S is removed, i.e. E = SE. While the question of how an
observer distinguishes an external system from its surrounding environment, prior to – and
as a precondition for – measuring some state of interest, is often neglected by physicists, it
imposes significant thermodynamic and computational requirements on observers [112].
25
Distinguishing a system from its environment requires measurement, so it is naturally
formulated in the language of QRFs.
To set up some notation, we will consider any distinct, identified system S to comprise two
components, S = PR, where P is the “pointer” component that indicates some state |P(cid:105)
(ordensityρ oftime-averagedsamplesof|P(cid:105))ofinterestandR isa“reference”component
P
that by maintaining a constant state |R(cid:105) (or constant density ρ of time-averaged samples
R
of |R(cid:105)) allows S to be re-identified while |P(cid:105) varies. Identifying a laboratory apparatus by
monitoring a time-invariant reference state provides an example; see Fig. 5.
Figure 5: Identifying a system S requires identifying some proper component R that main-
tains a constant state |R(cid:105) (or density of time-averaged samples ρ ) as the “pointer” state
R
|P(cid:105) (or density of time-averaged samples ρ ) of interest varies. Adapted from [37] Fig. 2,
P
CC-BY license.
˜
Following the reasoning above, decomposing E into disjoint components E = PRE is
defining subsets of operators {ME} = {MP} (cid:116) {MR} (cid:116) {ME˜ } where (cid:116) indicates disjoint
i j k l
union. We can then define several QRFs:
26
P : P = dom({MP}) → |P(cid:105),
j
R : R = dom({MR}) → |R(cid:105), (31)
k
E˜ : E ˜ = dom({ME˜ }) → |E ˜ (cid:105),
l
with corresponding memory records [ρ (i)], [ρ (i)], and [ρ (i)]. As QRFs that prepare as
P R E˜
well as measure their assigned sectors of B, these QRFs P, R, and E˜ can be represented as
CCCDs with the symmetric form of Diagram (15). The processing pathway from a given
sector X to its associated memory record [ρ ] can, assuming a coarse-grained memory,
X
be represented as a CCCD with the asymmetric form of Diagram (16); the memory-read
to preparation of X pathway has the opposite asymmetry. Note that identifiability of S
requires [ρ (i)] = [ρ (j)] for all i,j. Forgetting what someone looks like, for example, can
R R
lead to re-identification failure.
˜
Measurements of P, R, and E are of no use unless they are recorded. As above, Markov
kernels provide the most efficient data structure. The kernel MA must be constant to enable
R
system identification. By analogy with Eq. (28), these kernels can be associated with a
learning operators L , L , and L ; where there is no requirement that these employ the
P R E˜
same learning algorithm. The “true” Markov kernel M (i) can similarly be decomposed
E
into components, each of which must satisfy the commutativity constraint expressed by
Diagram (29):
ρ M P(i)(cid:47)(cid:47) ρ (i+1) ρ (i) M R (cid:47)(cid:47) ρ (i+1) ρ (i) M E (cid:47)(cid:47) ρ (i+1)
P(cid:79)(cid:79) P (cid:79)(cid:79) R(cid:79)(cid:79) R (cid:79)(cid:79) E˜(cid:79)(cid:79) E˜ (cid:79)(cid:79)
P P R R E˜ E˜
|B(t)(cid:105) PU(cid:47)(cid:47) |B(t+∆t)(cid:105) |B(t)(cid:105) PU(cid:47)(cid:47) |B(t+∆t)(cid:105) |B(t)(cid:105) PU(cid:47)(cid:47) |B(t+∆t)(cid:105)
(32)
˜
Hence prediction errors for P, R, and E can be defined as in Eq. (30). Failing to correctly
predict ρ results in system-identification failure and renders concurrent observations of ρ
R P
meaningless.
˜
The “systems” P, R, and E are, clearly, just subsets of outcomes obtained by measuring
the qubits on A’s boundary/MB B; their states are, therefore, determined by the actions
of B’s encoding operators MB. As [MB,MB] = 0 for all i,j by definition, R, P, and E ˜
i i j
must all be mutually separable and hence mutually decoherent; equivalently, R, P, and E˜
˜
must all mutually commute. Hence, A can regard R, P, and E as “things” with distinct
identities and states as required by [10]. It bears emphasis, however, that no spacetime
background has been assumed in writing Eq. (6), in defining B, or in defining any of the
˜ ˜
sectors R, P, or E. The “things” R, P, and E are not, therefore, observer-independent
in any sense, although observers deploying similar QRFs and able to communicate (i.e.
deploying QRFs that enable mutual recognition and communication) may agree as to their
27
states [35, 36]. The present formalism is, therefore, “system-free” in the sense of [34]
and hence represents measurements using external apparatus as fully device-independent.
While device independence is implied whenever an MB is invoked [11], classical formula-
tions of measurement interactions – indeed, of perception generally – tend nonetheless to
assume differentiated external objects a priori, as Einstein’s famous insistence that the
Moon is there when no one is looking exemplifies [113]; see [114, 115, 116] for examples
from perceptual psychophysics. Evolutionary considerations argue against any assumption
of a priori objects or even Galilean invariances of motion [117, 118], consistent with the
background-independent approach taken here.
3.4 Noncommutativity and context-switching
As emphasized by Bohr almost 100 years ago [119], a finite quantum of action (cid:126) partitions
the set of all possible quantum measurement operators into a set of “complementary” non-
commutingpairs, themostwell-knownbeingpositionxˆ andmomentumpˆ. Theseoperators,
as well as all other operators acting on “systems” with associated spacetime coordinates,
correspond in the current background-free framework to QRFs acting on sectors of B, i.e.,
on subsets of qubits as described above. Hence, noncommuting operators correspond to
noncommuting QRFs, as formalized by Theorem 1.
Two QRFs U and V can fail to commute only if the underlying measurement operators fail
to commute. However, as noted previously, any set of operators Mk appearing in Eq. (6)
i
must all mutually commute. Switching between noncommuting QRFs U and V, therefore,
entails switching between a mutually-commuting operator set MA, of which the MU are a
i j
subset, and a complementary mutually-commuting operator set OA, of which the OV are a
i j
subset, where for at least some i,j, [MU,OV] (cid:54)= 0. This switch implements a basis rotation
i j
on H , leaving its dimension N and its eigenvalues, the binary representations of which
AB
are the bit strings encodable on B, both unchanged while replacing the amplitudes αA with
i
amplitudes λA so that Eq. (6) now reads, for A:
i
N
(cid:88)
H = βAk TA λAOA. (33)
AB B i i
i
In practice, we will be primarily interested in partial basis rotations in which the MA and
i
the OA substantially overlap, e.g. maintaining fixed sectors F, E ˜ and R while switching
i
between complementary pointer sectors as discussed below. Note that such basis rotations
have no effect on B or its operators, so are undetectable, in principle, by B.
An observer A capable of switching between noncommuting QRFs must, to maintain an
operable memory, implement a clock that is invariant under basis rotations on H . If
AB
measurements made at clock ticks i and j do not commute, however, the corresponding
clock operations will not commute; in particular G ◦ G (cid:54)= G ◦ G where ◦ is operator
ij ji ji ij
composition. It is for this reason that the G form a groupoid, and not a group [37]. From
ij
a more practical perspective, noncommutativity forces t to be unidirectional, and hence
A
28
memoryrecordstobeencodedirreversiblywithanaccompanyingexpenditureoffreeenergy.
The internal clock G thus defines t as an entropic time, consistent with the analysis in
ij A
[120]. Any observer A, therefore, observes a unidirectional flow of information from B and
of dissipated heat to B; hence any observer A confirms the Second Law with respect to
its internal time t . As A and B are completely symmetric by Eq. (6), B also confirms
A
the Second Law with respect to t , showing that the Second Law is observer-relative and
B
independent of the “external” time t, consistent with the analysis in [121].
Switching between noncommuting QRFs while holding other QRFs constant, e.g., switch-
ing between interference (position) and which-path (momentum) measurements on an
interferometer identified by a fixed reference sector R, is switching between mutually-
noncommuting but overlapping sets of mutually-commuting operators as described in The-
orem 1 and is a canonical quantum context switch [44, 45]. Pointer-state observables are,
in particular, observables in context as defined in [87]: the state |P(cid:105) of any pointer sector P
˜
is measured in the context of the separable joint state |R(cid:105)|E(cid:105)|F(cid:105), where the component |F(cid:105)
is unobserved by definition. By Theorem 1, two sets of pointer operators MU and OV as
j j
above, thatdefinealternativepointersectorsU andV byEq. (10), aremutually-commuting
and hence co-deployable if and only if maps φ and ψ exist such that the diagram:
(cid:55)(cid:55)C(cid:103)(cid:103)
φ ψ
C (cid:79)(cid:79)1 (cid:102)(cid:102) (cid:56)(cid:56)C (cid:79)(cid:79)2 (34)
f1
g1 g2
f2
(cid:47)(cid:47) ˜ (cid:47)(cid:47)
U REF V
commutes. Here, we have replaced the explicit operators in Diagram (24) by their corre-
sponding sectors to simplify the notation. We can equally well interpret UF and VF as
˜
contexts for the observation of sectors R and E: in this case switching between U and
V—with the unobserved sector F held fixed yields consistent probability distributions if
and only if Diagram (34) commutes.
If Diagram (34) fails to commute, then pointer-state observables are said to be non-co-
deployable. Non-commutativity of the CCD in (34) had been specified in [87, Th. 7.1] in
terms of non-existence of a consistently definable joint probability distribution of condi-
tionals, such as for Diagram (23). This non-co-deployability of observables thus amounts
to occurrence of intrinsic (quantum) contextuality in relationship to (34).7
We will see in §4.2 below that context switching increases variational free energy (VFE)
by generating Bayesian“prediction errors”; hence context-switching makes minimizing VFE
7Asrecalledine.g. [122,§3],‘non-commutativity’isattheveryheartofcontextuality,asfirstformulated
by von Neumann in terms of non-commutativity of self-adjoint operators representing measurement, with
the impossibility of simultaneously measuring the eigenvalues corresponding to non-commuting operators.
In summarizing the principal results of ensuing hidden variables theory, Mermin [123] demonstrated the
impossibility of finding a joint probability distribution for all possible observables.
29
and hence complying with the FEP more difficult. Deploying noncommuting QRFs against
a fixed background can, however, lead to radically better generative models, as the history
of technological applications of quantum theory attests. Hence, context-switching poses
a fundamental challenge to any classical formulation of the FEP, and a fundamental ex-
planadum for a quantum formulation.
4 FEP for generic quantum systems
4.1 Defining VFE for quantum systems
TheFEPisavariationalorleast-actionprinciple: itstatesthatasystemenclosedbyanMB,
and therefore having internal states that are conditionally independent of its environment,
will evolve in a way that tends to minimize a VFE that is an upper bound on surprisal.
Formally, the VFE F(π), where π is a “particular” state π = (b,µ) comprising MB (b) and
internal (µ) components, can be written [10, Eq. 8.4],
F(π) (cid:44) I(π) +D [Q (η) (cid:107) P(η|b)] ≥ I(π). (35)
KL µ
(cid:124)(cid:123)(cid:122)(cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Surprisal Divergence
This functional as an upper bound on surprisal I(π) = −logP(π) because the Kullback-
Leibler divergence (D ) term is always non-negative. This KL divergence is between the
KL
density over external states η, given the MB state b, and a variational density Q (η) over
µ
external states parameterised by the internal state µ. If we view the internal state µ as
encoding a posterior over the external state η, minimizing VFE is, effectively, minimizing a
prediction error, under a generative model supplied by the NESS density. In this treatment,
the NESS density becomes a probabilistic specification of the relationship between external
or environmental states and particular (i.e. “self”) states.
In the notation developed in §2 and 3 above, we can write the surprisal for a quantum
system A in its most general form as:
IA(t) = −P(|B(t)(cid:105) | |A(t)(cid:105)) (36)
and the corresponding evidence bound as:
D [Q (|B(t)(cid:105)) (cid:107) P(|B(t)(cid:105) | |B(t)(cid:105)]. (37)
KL |B(t)(cid:105)
In the current setting, however, these expressions have little direct utility, as our effec-
tive starting point, Eq. (6), constrains neither |A(t)(cid:105) nor |B(t)(cid:105). Indeed, from a strict
formal perspective, neither Eq. (36) nor Eq. (37) is well-defined in the current setting.
The full boundary/MB state |B(t)(cid:105) is, moreover, not an observable for A (or B), as the
thermodynamic-resource sector F remains unobservable by definition. We have, however,
30
already derived in §3.2 a representation of A’s prediction error, Eq. (30), which we repro-
duce here for reference:
Er (k) = d(MA(k),M (k)). (38)
E E E
In this expression, the timestep k counts A’s internal clock time t and the kernels MA
A E
and M are derived from observables and therefore constrained by the theory. The kernel
E
M (k) represents the observable behavior of B, as localized to the sector E, up to t = k.
E A
The kernel MA(k) is A’s generative model of the action of the unknown dynamics PB(t) on
E
B, also as localized to E. Hence Er (k) represents A’s total reducible uncertainty about
E
B at t = k. It is, therefore, an upper bound on surprisal analogous, in the current setting,
A
to F(π).
The operators ME referenced by Eq. (30), i.e. (38) must, clearly, all be co-deployable. In
i
˜
practice, however, E is as discussed above subject to context switches of the form URE →
˜
VRE whenever A switches between noncommuting pointer QRFs U and V and hence non-
co-deployable operators MU and MV. Hence Er is only well-defined in the absence of
i i E
context switches; in the presence of context switches the generalized uncertainty relation:
∆u∆v ≥ (cid:126)/2 (39)
for pointer outcomes u and v can generate divergent uncertainties. Hence in practice, any
system A is faced with separately minimizing:
Er (k) = d(MA(k),M (k)). (40)
X X X
for each sector X defined by a QRF X. We can, therefore, formulate the FEP for generic
quantum systems, taking context-switching into account, as:
FEP: A generic quantum system A will act so as to minimize Er for each
X
deployable QRF X.
A trivial agent can be viewed as executing a trivial QRF, i.e. as only exercising choice of
basis for writing to and reading from B as a whole, and so satisfies the FEP trivially.
4.2 Sources of VFE for quantum systems
As noted in the Introduction, there is no source of objective randomness in the current
˜
formalism. Indeed, an observer A can be regarded as certain of the states |E(cid:105), |R(cid:105), |P(cid:105),
and|Y(cid:105)oftheobservablesectorsofB atevery(external)timet. Uncertaintyandprediction
error–andhence, VFE–isgeneratedinthecurrentformalismbyA’sin-principleignorance
of both the state |B(cid:105) and the dynamics P of its interaction partner B. As the bits A reads
B
from B are written by P , A’s ability to predict the future states of its observable sectors,
B
31
and hence to minimize Er for each sector X via Eq. (40), depends on its ability to predict
X
the behavior of P locally on each observable sector. As the thermodynamic sector F is
B
not observed, direct predictions on F are not possible; the local behavior of P on F can at
B
best be predicted from its local behavior elsewhere. An animal, for example, must employ
its available senses – hence its observable sectors – to predict the nutritional value of food.
The option space governing A’s ability to locally predict P is summarized in Fig. 6. What
B
is important for A is not the dynamic complexity or even the dimension of P , both of
B
which are unobservable in principle, but rather the dynamic complexity of the action of
P on B (the dimension of this action is, clearly, just the dimension of B). Here, the
B
weak-interaction limit that allows separability between A and B is significant: H (and
AB
hence B) must have significantly lower dimension that H (and hence P ) if the weak
B B
interaction limit to is hold. The simplest case is shown in Fig. 6, Panel a), in which the
system B is a trivial agent deploying no QRFs other that the choice of basis for interactions
with B. The action of P is, in this case, limited to choice of basis, e.g., to rotating the z
B
axis z in Fig. 1. As discussed in §2.4, basis rotation by B generates quantum noise in the
B
communication channel defined by H that is indistinguishable by A from classical noise.
AB
Hence, the trivial agent B in Fig. 6, Panel a) “looks like” a noise source to A. Emission
of Hawking radiation from a black hole (BH) provides perhaps the most pure example of
such a noise source; while the dimension “inside” the BH can be arbitrarily large (see e.g.
[67, Fig. 19]), the internal dynamics are uncoupled from the classical information encoded
on the horizon and hence have no classical computational power. As will be discussed in
§4.3 below, a “small” trivial agent will be driven by the FEP toward entanglement with
the larger system A.
32
Figure 6: Four options for A’s ability to predict the local behavior of P on an observable
B
sector X . a) A trivial agent deploying no QRFs beyond choice of basis for interacting with
A
B appears as a noise source to A. b) B encodes a sector X that contains X ; the bits on
B A
X but outside X encode “nonlocal hidden variables” for A. c) The sectors X and X
B A A B
overlap; the areas of non-overlap become noise sources. d) If X = X , VFE is generated
A B
by insufficient learning.
The more interesting parts of A’s option space for prediction are shown in Fig. 6, Panel
b), c), and d), in which B is nontrivial. If B is nontrivial, it deploys at least one QRF X
B
acting on a sector X . As discussed in §2.5, B’s sectors must be mutually decoherent, so
B
the action of P on X is independent of its action elsewhere; it is this independence that
B B
makes prediction possible. If X does not overlap any observable sector for A, however, B
B
will appear trivial, i.e. as a noise source, to A. Hence, the interesting cases are the ones in
which A’s and B’s observable sectors overlap; this is the case, intuitively, in which A and
B can “see each other” and hence interact in the ordinary, nontechnical sense of that term.
InFig. 6, Panelb), B’ssectorX fullycontainsX . AsnotedaboveinconnectionwithEq.
B A
(31), all measure – prepare QRFs X are symmetric, i.e codom(X) = dom(X). Preparation
33
by B of the bits in X will, therefore, in general depend on bits outside of X but within
A A
X , i.e. on bits with the remainder X \X . The values of these bits are “nonlocal hidden
B B A
variables” [45] from A’s perspective; they affect what is observed on sector X without
A
being local to, i.e., contained within, X . Indeed, such bits may be within F and hence
A
unobservable in principle by A. Changes in the values of these nonlocal hidden variables
are, effectively, context changes as defined in [97, 98]; probability distributions P(X |ζ)
A
and P(X |ξ) for distinct hidden-variable states ζ and ξ may be different. The “context-
A
blind” distribution P(X ) can, in this case, fail to be well-defined over time. Such failures
A
manifest as violations of Leggett-Garg inequalities [48], i.e. as “quantum hysteresis” effects
due to nonlocal (i.e. outside of X ) and possibly unobservable causes. In the language of
A
artificial intelligence or robotics, they appear as failures to solve the Frame Problem [87],
the problem of predicting what will not change as the result of an action [124]. If X is
A
a reference sector for A, Frame Problem solution failures on X can result in failures of
A
object re-identification [125].
AsituationinwhichX fullycontainsX presentssimilarissuestothatinFig. 6, Panelb),
A B
except here the “hidden variables” are in X \X and hence are accessible to A. The bits
A B
in X \X nonetheless contribute VFE – effectively, noise – to X that is unconstrained
A B A
by X . If X and X overlap with remainders, as in Fig. 6, Panel c), a similar noise
B A B
contribution to X (or on B’s side, to X ) results. The final possibility is, clearly, that
A B
in which X = X as shown in Fig. 6, Panel d). Here, the source of VFE is not noise,
A B
but rather differences in the computations implemented by the QRFs X and X . Such
A B
differences correspond, in the notation of §2.6, to differences in the structures of the CCCDs
implementing X and X , e.g. differences in the “connection weights” if these are thought
A B
of as ANNs or VAEs. They correspond, in other words, to learning failures, e.g. due to
insufficient training-set representativeness, as Eq. (28) renders obvious. We can, therefore,
represent the overall situation for any observer A as:
VFE = Noise + Insufficient Learning (41)
consistently with Eq. (35) above. Here “noise” includes VFE generated by unobserved
context changes (Leggett-Garg violations or Frame Problem solution failures) as well as
“classical” noise.
4.3 Asymptotic behavior of the FEP
Having seen how VFE is generated, we can now ask how it is minimized: how, in other
words, anagentactsinaccordancewiththeFEP.AsdiscussedintheIntroduction, theFEP
in its classical form is effectively the statement that any system with sufficient stability to
be a “thing” – i.e. a system with a [quasi-] NESS density – will act so as to preserve its
“thingness” by maintaining the integrity of its MB and hence the integrity of its “self” as
distinct from its surroundings. Comparing Eq. (35) and (41), it becomes clear what this
amounts to: a system “self evidences” by behaving in a way that minimizes noise while
improving learning. This, as is well known, induces a trade-off: learning requires seeking
34
uncertainty in order to minimize it. As emphasized in [126], successful learning requires
a focus on learnable tasks and avoidance of unlearnable tasks. Hence, minimizing VFE
is removing all removable noise. It does not, in practice, lead to perfect predictability of
future MB states, but to best feasible predictability of future MB states. In classical FEP
formulations, this becomes clearly evident in the form of a functional called expected free
energy (EFE); namely, VFE expected under a posterior predictive density that is condi-
tioned on action. In this setting, the most probable actions are those that minimise EFE
and thereby resolve uncertainty or maximise information gain (a.k.a., intrinsic motivation
or epistemic affordance). In short, novelty-seeking is an emergent property of any“thing”,
under the FEP.
We can, however, ask in the current framework how the FEP behaves asymptotically, i.e.,
what are the consequences for A as, in the notation of Eq. (40), Er (k) → 0 as k → ∞
X
for all observable sectors X. This clearly involves implementing a learning operator L
X
for each sector X that is capable of asymptotically-perfect learning: let us assume this is
the case. What remains given Eq. (41) is noise, including noise due to observed context
switches. Only one mechanism for removing noise is available: that shown in Fig. 6, Panel
d). Hence we can conclude:
The FEP asymptotically drives alignment of QRFs across B.
It drives any observer A, in particular, to match any context switches by its interaction
partner B in order to maintain QRF alignment. Let us now consider, therefore, a situation
in which all QRFs deployed by A and B are aligned as in Fig. 6 d), and in which all of A’s
QRFs have learned the local behavior of P on their sectors perfectly. The local behavior
B
of P on some shared sector X is determined by B’s QRF X . This QRF X is, however,
B B B
a quantum computation; as such, it encodes nonfungible – not finitely classically encodable
– information as shown in [40]. The future behavior of X can, therefore, only be perfectly
B
predicted by X itself, that is:
B
Er → 0 ⇒ X = X (42)
X A B
If A and B are separable, the consequent in Eq. (42) violates the no-cloning theorem [127]:
it demands that the internal quantum state |B| (t)(cid:105), the time (external t) evolution of
X
which implements X , be replicated exactly in A. Hence, if Eq. (42) holds, A and B
B
cannot be separable. Therefore we have:
If AB is isolated, the FEP asymptotically drives the joint state |AB(cid:105) to entan-
glement.
The claim that isolated systems are driven to entanglement is familiar from our initial
discussion of bipartite interactions in §2.3: all isolated systems are driven to entanglement
by unitary evolution. Separability is a special case, an approximation that holds only
under conditions of weak interactions and short observation times. Hence, we can, finally,
conclude:
35
The FEP is, asymptotically, the Principle of Unitarity.
The FEP is, in other words, asymptotically equivalent to the first axiom of quantum theory.
Any quantum system, therefore, must behave in accord with the FEP; doing so is simply
approaching entanglement with its environment as required by the Principle of Unitarity.
The FEP is therefore, consistent with the results obtained in [10], a fundamental, generic
physical principle. Conversely, the Principle of Unitarity – the principle that observable
information is conserved – can now be seen as a fundamental principle of cognitive science.
As an example of the FEP in action, let us return to the situation in which a “small” trivial
system B interacts with a larger, nontrivial system A considered above. The only freedom
B has in this case is freedom of basis choice for reading and writing from B. From B’s
perspective, any basis choice that is misaligned with A’s basis choice generates noise. The
FEP will, therefore, drive B to align its choice of basis – z axis in Fig. 1 – with that of A.
This basis alignment, however, leaves B entangled with A. This is not surprising. When a
photon, for example, interacts with an atom, it is completely absorbed and loses its identity
as a “thing”; its state becomes irreversibly entangled with that of the atom with which it
interacts.
We can develop this result more formally as follows, noticing that a preparation operation
by B followed by a measurement operation by A can be described by a CCCD in the
X X
form of Diagram (14), with the classifiers A identified with the bits comprising sector X
i
that are prepared and then measured. The question of asymptotic behavior is then the
question of whether this CCCD is symmetric, i.e. whether the cores C(cid:48) = D(cid:48) in Diagram
(14). We approach this by considering the Markov kernels MA and M , the difference
X X
between which defines the error Er (via Eq. (40)) that the FEP asymptotically sends to
X
zero.
As shown in [128, p.17], following [129, §4], every category C whose arrows form a set
K embeds fully as a subcategory into Chu. There is, therefore, an induced mapping
F : C −→ Chu realizing F(C) as an embedded subcategory of Chu that consists of some
objects of the latter, together with all of the arrows between them (for background on such
embeddings, see e.g. [41, 42]).
Now we recall the direct association between Markov kernels and conditional probabilities,
and apply the above embedding to the category P of conditional probabilities, following
mainly [130, 131] (cf. [132, 133]). Objects of P consist of countably generated measurable
spaces (X,Σ ), and arrows of P between two such objects, having the form:
X
M : (X,Σ ) −→ (Y,Σ ). (43)
X Y
These arrows are Markov kernels assigning to each x ∈ X, and each measurable set Q ∈ Σ ,
Y
the probability of Q given x, denoted here by M(Q|x), whenever defined. We can also write
this as p (Q,|x), the (regular) conditional probability determined by the arrow M, ‘regular’
M
in so far that M is conditioned on points rather than on measurable sets in Σ . As arrows
X
given by Eq. (43) specify a Markov process, they comprise a semigroup, and therefore a
36
set. Hence, we obtain a full embedding P −→ Chu, where the (arrow) set K is identified
with a set of conditional probabilities K = {p (S,|x)} ⊆ [0,1].8 Using the fact that Chu
M
and the Channel Theory category Chan are isomorphic categories with respect to their
respective objects and arrows, we can summarize as follows:
Proposition 1. The category P embeds fully into Chan with classification (cid:13) realized by
A
the conditional probability p (·|·) (the Chu space valuation/satisfaction relation) whenever
M
this is defined.
Without loss of generality, we can assume the CCD in Diagram (23) to be a diagram in this
embedded subcategory (for a survey of probability spaces and Bayesian belief networks in
terms of the categories Chu and Chan, see [87, §2]).
We can now proceed to consider the asymptotic behavior of the FEP, in particular the
conditions under which |M − MA| → 0 for an arbitrary system A and sector X (with
X X
QRF X), in the setting where A interacts with some B and the joint system AB is iso-
lated. To make sense of the formal difference M − M , that is, to make sense of the
A B
difference between two arrows in P, we can use the metric distance on Markov kernels
as in Eq. (30). This distance is then manifestly the difference between the conditional
probabilities p (·|·) − p (·|·), in the way the corresponding Markov kernels determine
M M
A B
these as described above. As discussed previously, this is a difference in the (conditional)
probabilities of observable behavior in sectors. Thus, |M −M | → 0 is interpreted as the
A B
metric distance d(M ,M ) → 0 in the asymptotic limit.
A B
With the labeling by A,B, let us return to (23) which we adopt to provide two separate
CCDs as specified by (23) denoted by CCD and CCD . The asymptotic limit → 0 of the
A B
metric distance of the kernels determining the difference of the conditionals (hence → 0 in
the asymptotic limit) provides the sense in which the diagrams CCD and CCD , along
A B
with their respective colimits colim(C(cid:48) ) and colim(C(cid:48) ), can be identified in this limit (or
A B
in the notation of Diagram (14), the cores C(cid:48) and D(cid:48) as required above become identical).
5 Discussion
5.1 High-level overview
While much of the foregoing has been technical, it is conceptually straightforward. To
briefly review, the classical FEP as developed in [10] considers the joint environment-
agent system as a random dynamical system that possesses an attracting set. By placing
particular constraints on the coupling among systemic states (e.g., with sparse coupling
in flow operators or stochastic differential equations), one can partition the joint state
space into external, internal and blanket (MB) states. In turn, the blanket states are
8In a similar way, Abramsky in [134] shows that the Dirac-von Neumann formulation of quantum
mechanics can be conveniently represented in the category Chu.
37
partitioned into sensory states that mediate the influence of external states on internal
states and active states that mediate the influence of internal states on external states.
Crucially, this particular partition imposes conditional independence between internal and
external states, given the blanket states. The final move in the classical FEP is to induce a
variational density Q (η) over external states that is parameterised by internal states. It is
µ
then fairly straightforward to showthat the expected flow of internal (and active) states can
be expressed as a gradient flow on a variational free energy. This free energy is effectively
the divergence between the variational density encoded by internal states and the density
over external states conditioned on the blanket states. This licences an interpretation of
internal and active states in terms of active inference, or a Bayesian mechanics, in which
theirexpectedflowcanbereadasperceptionandaction,respectively. Inotherwords,active
inference is a process of Bayesian belief updating that incorporates active exploration of
the environment.
Reformulating the FEP within quantum information theory allows us to drop the assump-
tionofanobserver-independentspacetimebackgroundcharacterizedby(continuous)frames
of reference that can be specified to infinite precision, and also to drop the assumption of
randomness. In the quantum formulation, the blanket states are implemented by a holo-
graphic screen separating the interacting systems A and B. The screen is the (topological)
locus of the interaction H ; “sensory” and “active” states of the classical MB become
AB
incoming and outgoing encodings of bits on the screen. The interaction is symmetrical
across the screen: the reciprocal exchange between “internal” A and “external” B systems
takes the form of answers and questions (formulated as Hermitian operators Mk), where
i
questions correspond to classical action (mediated by active states) and answers correspond
to classical perception (mediated by sensory states). There is, crucially, no assumption that
A and B share preparation and measurement bases; basis mismatches between A and B
generate quantum noise that is “perceived” as classical noise.
An “agent” in the quantum formalism is a system that deploys quantum reference frames
– effectively, concepts that identify persistent objects and their time-varying states – when
interacting with its environment. Deploying distinct QRFs breaks the thermodynamic
symmetry of the screen for each agent, redirecting energy flows within each agent to fund
processing and recording memory records of some bits while others – those in the “thermo-
dynamic”sectorF –remainnecessarilyunobserved. Thusthequantumformalismexplicitly
enforces a distinction that the classical formalism leaves implicit: that between observed
and unobserved parts of the environment. Mismatches between QRFs deployed by two
interacting agents generate noise and prediction errors, including incorrect Frame Problem
solutions and failures to correctly re-identify objects.
In the classical setting, agents “self-evidence” by maintaining their nonequilibrium steady-
states or, equivalently, the integrity of their MBs. From a mathematical point of view, this
is maintaining their identities (in the sense of being independently well-defined) as systems.
In the quantum setting, being independently well-defined is being separable from – not
entangled with – the environment; hence “self-evidencing” is maintaining separability. The
FEP identifies self-evidencing with the minimization of Bayesian prediction error: to“be”
38
is to be capable of successful predictions; sometimes described as “predicting yourself into
existence”. Minimizingpredictionerroris,inthequantumsetting,minimizingthedifference
between two Markov kernels. As in the classical setting, noise and errors due to insufficient
learning must both be minimized, a process that requires trade-offs between the two.
The classical and quantum formulations of the FEP differ in their asymptotic behavior,
i.e., as total prediction error is driven toward zero. A classical “perfect predictor” achieves
maximal classical correlation and hence maximal behavioral synchrony with its environ-
ment; it becomes a “perfect regulator” in the sense of the good regulator theorem [135].
In a quantum setting, perfect prediction entails shared QRFs between interaction partners
and hence entanglement; a quantum “perfect regulator” becomes indistinguishable from
the environment it is predicting. While this difference in asymptotic behaviors is a formal,
mathematical outcome, it can be traced to a difference in fundamental assumptions. The
classical formalism assumes a spacetime background, and hence can rely on separation in
space to distinguish between systems. The quantum formalism is background free: space
is simply an observable, represented by a QRF that a system may or may not deploy. It
can, therefore, play no “ontic” role in maintaining distinctions between systems. This re-
flects the general role of (“physical” 3d) space in quantum field theories: space is there to
enforce separability (see [68] for a general discussion of this point from a gauge-theoretic
perspective).
Both classical and quantum formulations of the FEP engender a fundamental form of
epistemic solipsism, in the sense that the coupling between internal and external systems
precludes the states of one from ever “knowing” the states of the other. While this seems
counter-intuitive, it is a straightforward consequence of the use of vector spaces to rep-
resent physical states. Vector-space product operators – the classical Cartesian product
or the Hilbert-space tensor product – are by definition associative (equivalently, dynamic
operators such as Hamiltonians are additive); product decompositions are, therefore, un-
detectable across decompositional boundaries in any vector space [136]. This sense of epis-
temicsolipsismdoesnot, asFuchsemphasizes[55], inanywaysuggestonticormetaphysical
solipsism. Both classical and quantum formulations of the FEP – indeed, any theory of
measurement or observation – requires two interacting systems, observer and observed. The
idea of a metaphysically solipsist theory of observation is self-contradictory.
5.2 Summary of results
We have obtained three results in this paper:
1. Given the standard free-choice assumption, the intuitive idea of an “agent” or IGUS
can be fully formulated within background-independent, scale-free quantum informa-
tion theory.
2. The FEP can be given a quantum-theoretic formulation that renders it applicable to
generic quantum systems.
39
3. When formulated as a generic principle of quantum information theory, the FEP is
asymptotically equivalent to the Principle of Unitarity.
Result 1) places the long-standing practice of treating generic quantum systems as “ob-
servers” on a firm theoretical foundation. It allows a formal specification, in the language
of QRFs, of exactly what systems a given observer is capable of recognizing and what states
of those systems it is capable of measuring. Such specifications require no “ontic” assump-
tions of observer-independent systems; hence they are compliant with a device-independent
theoretical strategy. Result 1) also provides a formal definition of an “agent” in the con-
text of the free-choice assumption, and provides a generic language – the category-theoretic
language of Channel Theory – for specifying the semantics assigned by an agent to an
observational outcome. Finally, Result 1) shows how semantics arise from thermodynamic
symmetry breaking on a holographic screen, and provides a formal mechanism for quanti-
fying energy flows that enable classical computation and classical memory encoding.
Result 2) extends the range of applicability of the FEP to generic quantum systems inde-
pendently of spacetime background or scale-dependent assumptions. Quantum fields, black
holes, and other spatially-distributed or topologically-defined systems can, therefore, be
regarded as Bayesian observers and, if free choice is assumed, as Bayesian agents. Result
2) therefore makes clear the sense in which generic quantum systems can be regarded as
“users” of quantum information theory, as proposed under the rubric of QBism [33, 35, 55].
Indeed Result 2) renders QBism a consequence of quantum information theory, not an
interpretation.
Result 3) shows that the FEP is compliant with the Principle of Unitarity and, conversely,
that unitary evolution is compliant with the FEP. It allows us, in particular, to understand
quantum context-switching as both a source of prediction errors and a strategy for reducing
prediction errors. Result 3) also allows us to view separability as a resource for classical
communication and computation that is analogous to entanglement as a resource for quan-
tum communication and computation. Hence, it allows us to consider trade-offs between
these resources by systems that maintain approximate separability while also employing
shared entanglement. Such systems have been studied in the abstract, and can potentially
exceed the computational power of Turing machines (e.g. can solve the Halting problem as
shown in [137]). Result 3) suggests that (some) biological systems may have this capability,
as discussed further in §5.4 below.
5.3 Applications to biological cognition
In addition to the results listed above, the current framework has a variety of more specifi-
callybiologicalconsequences, someofwhichhavebeendiscussedalreadyin[13]. Itpredicts,
for example, that moving in ordinary 3d space does not require a QRF for Euclidean space
and hence, does not require an experience of space. From a classical perspective, this is
certainly true; as evidenced e.g. by place and grid cells in mammalian brains [138, 139, 140]
that appear to encode a coarse-grained representation of location, head-direction etc., in
40
various frames of reference. This coarse graining endorses another prediction; namely, that
actionable classical encodings are coarse-grained. Any system that encodes information
irreversibly is, therefore, faced with a choice that its computational architecture must re-
solve: the trade-off between preserving information in memory and losing information due
to coarse graining. On a classical FEP account, this coarse graining is mandated by the
minimization of VFE, which can be expressed as complexity minus accuracy. Classically,
complexity corresponds to the KL divergence between posterior and prior beliefs as in Eq.
(35). This relative entropy clearly depends upon the degree of discretisation or coarse
graining afforded by the dimensionality of internal states. Effectively, this KL divergence
scores the computational and thermodynamic cost of belief updating that is mitigated by
coarse graining or, in quantum terms, devoting memory resources to the results computed
by only some QRFs, possibly in a context-sensitive fashion [141].
The ubiquity of context-dependent effects leads to another prediction: living systems in
complex environments will evolve context and attention switching systems. On a classical
view, this entails the identification of context (cf. the role of pointers) in a hierarchical
generative model, where high level states contextualise the processing of lower level states.
This immediately introduces the notion of MBs or holographic screens in the joint space of
an agent’s internal states, i.e. a notion of modularity supported by shared memory. This
is gracefully accommodated by the channel theory of QRFs as developed in §2.6.9 Indeed,
much work in the classical field of active inference rests upon optimising the hierarchical
structure of deep generative models, via various free energy minimizing processes [143,
144, 145, 146]. This is especially true for generative models of navigation and language
[147, 148, 149] that are almost universally based upon quantisation or discretisation of state
spaces. The attendant Boolean logic that arises from the imposition of Boolean constraints
by QRFs may have important practical applications, as demonstrated by recent work in
active vision and scene construction [150] that rests upon a generative model of the sensory
(visual) consequences of visually foraging a scene with multiple objects. Active inference
in this context can be seen as an inversion of a generative model that maps from causes
(external objects), to consequences (sensory states) (cf. [116]).
Theinversionofgenerativemodelsforactivevisionisextremelydifficultandill-poseddueto
its computational complexity. These models have to accommodate all the natural physical
laws of motion and optics (e.g., occlusion). The inversion of these models corresponds to
the measurement operators that mediate belief updating. In a classical setting, this can
be massively finessed by coarse graining the problem and applying Boolean operators. For
example, if one object is near and another object is far, an agent will see the near object.
Quantising or coarse graining the internal (i.e. generative) model along these lines reduces
the likelihood mapping to a set of relatively simple Boolean operators that could be cast as
measurement operators in a quantum-theoretic context. At present, when these operators
areencodedonstandardclassicalcomputersforsimulation,theyareeffectivelyimplemented
with enormous tensors. Reading and writing these tensors into working memory dwarfs
9See[90]foranexplicitapplicationtoglobal-workspacetheoryand[142]foramoreambitioussynthesis
of active inference, a global workspace, and IIT.
41
the actual compute time and renders active vision schemes of this sort computationally
and thermodynamically inefficient. One might imagine that a combination of quantum
computing [25, 27] and neuromorphic engineering [151, 152] may be able to parallel the
efficiency of human vision.
There are, in addition, certain technical problems that are resolved in moving from a
classical to a quantum FEP formulation of active inference that go beyond a commitment
to unitary processes and binary measurement operators. These include problems entailed
by assuming reference frames that can be specified to infinite precision. In formalising
the asymptotic behaviour of belief updating in the absence of random fluctuations in the
classical formalism, for example, one has to deal with differential entropies that are ill-
defined for very precise conditional densities, e.g. Dirac Delta functions. One workaround
is to use Jaynes’ limiting density of discrete points (LDDP) [153], which brings us back to
where we started, namely finite dimensional Hilbert spaces and discrete state spaces.
Finally, from a more philosophical perspective, the framework presented here is consistent
with [13, 14, 154] in supporting a panpsychist perspective on questions of agency, sentience,
and cognition. As our Definition 1 of agency illustrates, traditional binary categorizations
of entities into those having agency, sentience, and cognition and those lacking them are
replaced here by continua of “interestingness” along these dimensions. Definition 1 assumes
free choice, in particular of measurement basis. The Conway-Kochen theorem [72] states
that if any physical system is assumed to have free choice, then all physical systems must
be assumed to have free choice. “Free choice” in this case means behavior that is not
determined by (cannot be fully predicted given) the events in the system’s past lightcone.
Determination of behavior by events in the past lightcone is local determinism; such local
determinismisfundamentallyinconsistentwiththeglobaldeterminismimpliedbyunitarity
[155]. Hence what is interesting is the extent of choice. As emphasized in [10], interesting
choices are implemented by internal processes. An electron, for example, has internal
states – its charge and mass are not states of its MB – but they are invariant, and so
do not implement choices. The internal states of rocks are not invariants – changes in
water content or radioactive decay can occur – but they do not, in general, implement
interesting choices from our human perspective. Interesting choices require interesting
sensations and actions, and hence significant internal energy flows as discussed above. They
require differential use of thermodynamic resources to deploy multiple QRFs that probe the
observable environment in different ways. Systems, including organisms, clearly do this to
different extents; even among humans, the extent of variation is striking. Consonant with
a broadly-construed enactivism [156, 157, 158, 159], we view such active exploration of the
environment – hence, active inference – as indicating cognition and intelligence.
5.4 Predictions and open questions
The results obtained here suggest that the field of quantum biology is far larger than has so
far been explored; indeed they suggest that all biological systems are properly considered
quantum systems and can be expected to employ quantum coherence as an information
42
processing resource. This suggestion is of course not novel, having been explored by many
authors from philosophical, theoretical, and increasingly over the past two decades, empiri-
calperspectives[160,161,162,163,164,165,166,167,168,169,170,171,172,173,174]. We
have, however, shown here that it follows from general principles: quantum systems with
sufficiently complex internal information flows can be expected to exhibit active inference,
and hence to behave like organisms. Indeed, quantum systems that do not display evident
intelligence – quantum systems that are trivial agents – become an unusual special case.
Conversely, the results obtained here suggest that the concepts of active inference, agency,
Bayesian satisficing, and cognition are applicable to generic quantum systems, and hence
to physical systems across the board. This turns the traditional question of the emergence
of intentionality [175, 176, 177] on its head: by making agency a generic expectation, it
makes the “merely physical” the special case demanding explanation. It thus suggests that
the traditional division between agency and mechanism is a hindrance, not a help, in the
task of understanding the natural world.
We make, in particular, the following predictions:
1. The internal, molecular-scale dynamics of both prokaryotic and eukaryotic cells im-
plement quantum information processing, i.e., make essential use of quantum coher-
ence as a computational and memory resource. This is consistent with recent results
showingthatthefreeenergybudgetsofbiologicalsystemsacrossknownphylogenyare
orders of magnitude short of the resources required for purely classical computation
at the molecular scale [178].
2. Interacting biological systems trade off separability against entanglement and hence
classical against quantum communication. Interactions between biological systems
from the molecular scale upwards can be expected to display quantum contextuality
and violations of the Bell and Leggett-Garg inequalities.
These predictions remain largely untested, both for reasons of technical difficulty and due
to a still-pervasive traditional view of macroscopic systems as ontically classical. The mech-
anistic role of entanglement – even in relatively well-established systems such as light har-
vesting – remains subject to considerable debate [172, 173, 174]. Quantum context switch-
ing has been detected in human subjects [179, 180], but whether it is properly considered
“quantum” or merely “quantum-like” remains open to question [181].10 Neither Bell nor
Leggett-Garg inequality violations have been conclusively demonstrated with biological sys-
tems.
Setting technical difficulties aside, we suggest that coherence effects in biological settings
may be systematically overlooked due to being dismissed as “noise” or “random coinci-
dence.” Thermal noise in biological settings is well characterized; general environmental
variation, including effects of signaling by other cells or organisms, is less straightforwardly
10Such “quantum-like” contextuality is claimed for a certain case of gene expression in [182] where
conflictingprobabilities(quantumvs. classical)donotgiverisetoaconsistentlydefinablejointdistribution,
so suggesting a variant of Kolmogorov contextuality.
43
modeled or controlled. Experimental designs that explicitly test for coherence effects will,
we expect, be required to test the above predictions. Focused theoretical support for such
designs is therefore necessary.
Interactions involving multiple agents remain an open theoretical as well as experimental-
design problem. In the bipartite setting employed for the technical analysis above, every
agent interacts with its entire surrounding, whether the bits transferred by this interaction
are observed and processed or not (i.e. whether they are included in sector E or F). This
does not change in a multi-party setting; each agent still interacts with its entire surround,
identifying other agents (or not) via specific QRFs. The ubiquitous assumption that inter-
agent communication is classical, made in domains as disparate as cell-cell interaction and
human natural language use, becomes problematic in this setting. As discussed in §4.3,
shared QRFs are required for fully-shared, counterfactual-supporting semantics, but they
induce entanglement (see also the discussion of this point in [38]). The extent of shared
semantics is not readily observable in living systems. In a fully classical setting, generalised
synchronisation (a.k.a., synchronisation of chaos) emerges when two free energy minimising
‘partners’ observe each other [183]. “Perfect prediction” of the partner’s behavior may
result, driven by classical learning of a shared generative model, implicitly resolving the
hermeneutics problem in the communication context [184, 185]. Recognizing a particular
communication partner, in this case, requires invoking a particular generative model, the
correct model to predict that partner’s behavior [186]. Such classical synchronization is not,
however, robust against perturbation; altering one agent’s model does not “automatically”
alter the other, as would be expected if the models, i.e. the QRFs implemented by the two
agentswereentangled. BoththeoreticalandexperimentalcharacterizationofrelevantQRFs
will be required to assess the extent to which classical communication can be considered
purely classical, and detemine where and how quantum coherence contributes to in-practice
successful shared semantics.
Darwinian evolution can be viewed as a process of variation and selection of QRFs, and
hence as an instance of the multiple-agents problem in which semantics is only partially
shared. Evolution can be given a natural description in the framework of the classical FEP
[5, 187, 188, 189]. Variation and selection have been advanced as a model of decoherence
under the rubric of quantum Darwinism [18, 190]; see [191] for a discussion from the per-
spective of universal Darwinism. The selection mechanism invoked by quantum Darwinism,
however, assumes QRF sharing by multiple agents [192]; see [38, 62] for discussion. While
the present results allow any evolutionary system coupled to a larger environment to be
viewed as a Bayesian agent implementing active inference, a fully-satisfactory account of
variation and selection within a quantum framework remains to be developed.
Additional theoretical work is also needed to understand the relationships among the many
distinct models of quantum contextuality that have been put forward, often with the use
of quite different formal tools (e.g. [193, 194, 195, 196]). The question of “context” is
deeply tied up with that of what is to be regarded as the “environment” or “surrounding”
of any given system. This is a particularly critical question at the cellular level, where
multiple signaling modalities with different spatial ranges and temporal characteristics are
44
present. Models that explicitly characterize the “spaces” in which cells and multicellular
systems operate – e.g. the space of potential morphologies, or that of potential messages
from interaction partners – and that consider constraining effects of one space on another
both within and between scales will be needed to understand the roles of context, and of
context switching, in biological systems.
In closing, we hope that we have shown to readers familiar with the FEP and the active
inference framework that quantum effects are worth considering both theoretically and in
experimentaldesign. ForreadersnotfamiliarwiththeclassicalFEPbutliterateinquantum
theory (or vice versa), we hope this paper has gone some way to contextualizing your QRFs
in sense-making via Markov blankets and their underlying holographic screens.
Conflict of Interest Statement
The authors declare that the research was conducted in the absence of any commercial or
financial relationships that could be construed as a potential conflict of interest.
Funding
The work of C.F. is supported in part by the Emerald Gate Foundation. K.J.F. is sup-
portedbyfundingfortheWellcomeCentreforHumanNeuroimaging(Ref: 205103/Z/16/Z)
and the Canada-UK Artificial Intelligence Initiative (Ref: ES/T01279X/1). M.L. gratefully
acknowledges support by the Guy Foundation Family Trust (103733-00001), the John Tem-
pleton Foundation (62212), and the Elisabeth Giauque Trust.
References
[1] Friston KJ. A theory of cortical responses. Philos Trans R Soc Lond B, Biol Sci
2005;360:815–36.
[2] Friston KJ, Kilner J, Harrison L. A free energy principle for the brain. J Physiol Paris
2006;100:70–87.
[3] Friston KJ, Stephan KE. Free-energy and the brain. Synthese 2007;159:417–58.
[4] Friston KJ. The free-energy principle: a unified brain theory? Nat Rev Neurosci
2010;11:127–38.
[5] Friston KJ. Life as we know it. J R Soc Interface 2013;10:20130475.
[6] Friston KJ, FitzGerald T, Rigoli F, Schwartenbeck P, Pezzulo G. Active inference: a
process theory. Neural Comput 2017;29:1–49.
45
[7] Ramstead MJ, Badcock PB, Friston KJ. Answering Schro¨dinger’s question: a free-
energy formulation. Phys Life Rev 2018;24:1–16.
[8] RamsteadMJ,ConstantA,BadcockPB,FristonKJ.Variationalecologyandthephysics
of sentient systems. Phys Life Rev 2019;31:188–205.
[9] Kuchling F, Friston K, Georgiev G, Levin M. Morphogenesis as Bayesian inference:
A variational approach to pattern formation and control in complex biological systems.
Phys Life Rev 2020;33:88–108
[10] Friston K. A free-energy principle for a particular physics. Preprint arXiv:1906.10184
(2019).
[11] Clark A. How to knit your own Markov blanket: Resisting the Second Law with meta-
morphic minds. In: Metzinger T, Wiese W (eds), Philosophy and Predictive Processing:
3. Frankfurt am Main: MIND Group, 2017.
[12] Scholl BJ, Tremoulet PD. Perceptual causality and animacy. Trends Cogn Sci
2000;4:299–309.
[13] Fields C, Glazebrook JF, Levin M. Minimal physicalism as a scale-free substrate for
cognition and consciousness. Neurosci Cons 2021;7:niab013.
[14] Levin M. Life, death, and self: fundamental questions of primitive cognition viewed
throughthelensofbodyplasticityandsyntheticorganisms.BiochemBiophysResComm
2020;564:114–133.
[15] Von Neumann J. The Mathematical Foundations of Quantum Mechanics. Princeton,
NJ: Princeton University Press, 1955.
[16] Omn`es R. Consistent interpretations of quantum mechanics. Rev Mod Phys
1992;64:339–382.
[17] Zurek WH. Decoherence, einselection and the existential interpretation (the rough
guide). Phil Trans R Soc A 1998;356:1793–1821.
[18] Zurek WH. Decoherence, einselection, and the quantum origins of the classical. Rev
Mod Phys 2003;75;715–775.
[19] Schlosshauer M. Decoherence, the measurement problem, and interpretations of quan-
tum mechanics. Rev Mod Phys 2003;76:1267–1305.
[20] Schlosshauer M. Decohenece and the Quantum to Classical Transition. Springer,
Berlin, 2007.
[21] Bassi A, Lochan K, Satin S, Singh TJ, Ulbricht H. Models of wave-function collapse,
underlying theories, and experimental tests. Rev Mod Phys 2013;85:471–527.
46
[22] Landsman NP. Between classical and quantum. In: Butterfield J, Earman J. (eds.),
HandBook of the Philosophy of Science: Philosophy of Physics. Elsevier, Amsterdam,
Netherlands, 2007, pp. 417–553.
[23] Cabello A. Interpretations of quantum theory: A map of madness. Preprint
arXiv:1509.04711v1, 2015.
[24] Wheeler JA. Law without law. In: Wheeler JA, Zurek W (eds), Quantum Theory and
Measurement. Princeton, NJ: Princeton University Press, 1983, pp. 182–213.
[25] Feynman RP. Simulating physics with computers. Int J Theor Phys 1982;21:467–488.
[26] Deutsch D. Quantum theory, the Church-Turing principle and the universal quantum
computer. Proc R Soc A 1985;400: 97–117.
[27] NielsenMA,ChuangIL.QuantumComputationandQuantumInformation.NewYork:
Cambridge University Press, 2000.
[28] Hardy L. Quantum theory from five reasonable axioms. Preprint arxiv:quant-
ph/0101012v4 (2001).
[29] Fuchs CA. Quantum mechanics as quantum information, mostly. J Mod Opt
2003;50:987–1023.
[30] Brassard G. Is information the key? Nat Phys 2005;1:2–4.
[31] Chiribella G, D’Ariano GM, Perinotti P. Informational derivation of quantum theory.
Phys Rev A 2011;84:012311.
[32] Masanes L, Mu¨ller MP. A derivation of quantum theory from physical requirements.
New J Phys 2011:13;063001.
[33] Fuchs C, Schack R. Quantum Bayesian coherence. Rev Mod Phys 2013;85:1693–1715.
[34] Grinbaum A. How device-independent approaches change the meaning of physical the-
ory. Stud Hist Phil Mod Phys 2017;58:22–30.
[35] Mermin ND. Making better sense of quantum mechanics. Rep Prog Phys
2018;82:012002.
[36] Mu¨ller MP. Law without law: from observer states to physics via algorithmic informa-
tion theory. Quantum 2020;4:301.
[37] Fields C, Glazebrook JF. Representing measurement as a thermodynamic symmetry
breaking. Symmetry 2020;12:810.
[38] Fields C, Glazebrook JF, Marciano` A. Reference frame induced symmetry breaking on
holographic screens. Symmetry 2021;13:408.
47
[39] Aharonov Y, Kaufherr T. Quantum frames of reference. Phys Rev D 1984;30:368–385.
[40] Bartlett SD, Rudolph T, Spekkens RW. Reference frames, super-selection rules, and
quantum information. Rev Mod Phys 2007;79:555–609.
[41] Ad´amek J, Herrlich H, Strecker GE. Abstract and Concrete Categories: The Joy of
Cats. New York: Wiley, 2004. Available at http://katmat.math.uni-bremen.de/acc (Ac-
cessed May 26, 2019)
[42] Awodey S. Category Theory. (Oxford Logic Guides, 62). Oxford, UK: Oxford Univer-
sity Press, 2010.
[43] Barwise J, Seligman J, Information Flow: The Logic of Distributed Systems (Cam-
bridge Tracts in Theoretical Computer Science, 44). Cambridge, UK: Cambridge Univer-
sity Press, 1997.
[44] KochenS,SpeckerEP.Theproblemofhiddenvariablesinquantummechanics.JMath
Mech 1967;17:59–87.
[45] Mermin D. Hidden variables and the two theorems of John Bell. Rev Mod Phys
1993;65:803–815.
[46] Gell-Mann M, Hartle JB. Quantum mechanics in the light of quantum cosmology. In
Zurek W (ed) Complexity, Entropy, and the Physics of Information. Boca Raton, FL:
CRC Press, 1989; pp. 425–458.
[47] Bell JS. On the Einstein-Podolsky-Rosen paradox. Physics 1964;1:195–200
[48] Emary C, Lambert N, Nori F. Leggett-Garg inequalities. Rep Prog Phys
2013;77:016001.
[49] Landauer R. Irreversibility and heat generation in the computing process. IBM J Res
Devel 1961;5:183–195.
[50] Landauer R. Information is a physical entity. Physica A 1999;263:63–67.
[51] Bennett CH. The thermodynamics of computation. Int J Theor Phys 1982;21:905–940.
[52] Lloyd S. Ultimate physical limits to computation. Nature 2000;406:1047–1054.
[53] ZweirMC,ChongLT.Reachingbiologicaltimescaleswithall-atommoleculardynamics
simulations. Curr Opin Pharmacol 2010;10:745–752.
[54] Wang Q, Schoenlein RW, Peteanu LA, Mathies RA, Shank CV. Vibrationally coherent
photochemistry in the femtosecond primary event of vision. Science 1994;266:422–424.
[55] Fuchs C. QBism, the Perimeter of quantum Bayesianism. Preprint arXiv:1003.5209,
2010.
48
[56] Moretti V, Oppio M. Quantum theory in real Hilbert space: How the complex Hilbert
space structure emerges from Poincar´e symmetry. Rev Math Phys 2017;29:17500021.
[57] Renou M-O, Trillo D, Weilenmann M, Thinh LP, Tavakoli A, Gisin N, Ac´ın A,
Navascu´es M. Quantum physics needs complex numbers. Preprint arXiv:2101.10873,
2021.
[58] Baez JC. Getting to the bottom of Noether’s theorem. Preprint arXiv:2006.14741,
2020.
[59] Kauffman LH. Eigenforms and quantum physics. Cybernet Human Knowing
2011;18:111–121.
[60] Aspect A, Grangier P, Roger G. Experimental realization of the Einstein-Posolsky-
Rosen gedankenexperiment: A new violation of Bell’s inequalities. Phys Rev Lett
1982;49:91–94.
[61] Fields C, Marciano` A. Sharing nonfungible information requires shared nonfungible
information. Quant Rep 2019;1: 252–259.
[62] Fields C, Marciano` A. Holographic screens are classical information channels. Quant
Rep 2019;2;326–336.
[63] Wheeler JA. Information, physics, quantum: The search for links. In Zurek W (ed)
Complexity, Entropy, and the Physics of Information. Boca Raton, FL: CRC Press, 1989;
pp. 3–28.
[64] ’t Hooft G. Dimensional reduction in quantum gravity. In Ali A, Ellis J, Randjbar-
Daemi S. (eds) Salamfestschrift. Singapore: World Scientific, 1993, pp. 284–296.
[65] Susskind L. The world as a hologram. J Math Phys 1995;36:6377–6396.
[66] Bousso R. The holographic principle. Rev Mod Phys 2002;74:825–874.
[67] Almheiri A, Hartman T, Maldacena J, Shaghoulian E, Tajdini A. The entropy of
Hawking radiation. Rev Mod Phys 2021;93:035002.
[68] Addazi A, Chen P, Fabrocini F, Fields C, Greco E, Lulli M, Marcian`o A, Pasechnik
R. Generalized holographic principle, gauge invariance and the emergence of gravity a` la
Wilczek. Front Astron Space Sci 2021;8:563450.
[69] Fields C, Marciano` A. Markov blankets are general physical interaction surfaces. Phys
Life Rev 2020;33:109–111.
[70] Bohr N. Atomic Physics and Human Knowledge. New York: Wiley, 1958.
[71] Gisin N. Non-realism: Deep thought or a soft option? Found Phys 2012;42:80–85.
[72] Conway JH, Kochen S. The strong free will theorem. Notices AMS 2009;56(2):226–232.
49
[73] HorsmanC,StepneyS,WagnerRC,KendonV.Whendoesaphysicalsystemcompute?
Proc R Soc A 2014;470:20140182.
[74] Rice HG. Classes of recursively enumerable sets and their decision problems. Trans
Am Math Soc 1953;74:358–366.
[75] Fields C, Levin M. How do living systems create meaning? Philosophies 2020;5:36.
[76] Quive WVO. Word and Object. Cambridge, MA: MIT Press, 1960.
[77] Zanardi, P. Virtual quantum subsystems. Phys Rev Lett 2001;87:077901.
[78] Zanardi P, Lidar DA, Lloyd S. Quantum tensor product structures are observable-
induced. Phys Rev Lett 2004;92:060402.
[79] Dugi´c M, Jekni´c J. What is “system”: Some decoherence-theory arguments. Int J
Theor Phys 2006;45:2249–2259.
[80] Dugi´c M, Jekni´c-Dugi´c J. What is “system”: The information-theoretic arguments.
Int J Theor Phys 2008;47:805–813.
[81] De la Torre AC, Goyeneche D, Leitao L. Entanglement for all quantum states. Eur J
Phys 2010;31:325–332.
[82] Harshman NL, Ranade KS. Observables can be tailored to change the entanglement
of any pure state. Phys Rev A 2011;84:012303.
[83] Barr M. *-Autonomous Categories, with an Appendix by Po Hsiang Chu (Lecture
Notes in Mathematics 752). Springer: Berlin, Germany, 1979.
[84] Pratt V. Chu spaces. In School on Category Theory and Applications (Coimbra 1999);
Volume 21 of Textos Math. S´er. B. University of Coimbra: Coimbra, Portugal, 1999, pp.
39–100.
[85] Pratt V. Chu spaces from the representational viewpoint. Ann Pure Appl Logic
1999;96:319–333.
[86] Fields C, Glazebrook JF. A mosaic of Chu spaces and Channel Theory I: Category-
theoretic concepts and tools. J Expt Theor Artif Intell 2019;31:177–213.
[87] Fields C, Glazebrook JF. Information flow in context-dependent hierarchical Bayesian
inference.JExptTheorArtifIntell2021; inpress(doi: 10.1080/0952813X.2020.1836034).
[88] Collier J. Information, causation and computation. In G. D. Crnkovic and M. Burgin
(eds.) Information and Computation: Essays on Scientific and Philosophical Foundations
of Information and Computation (World Scientific Series in Information Studies Vol 2).
World Scientific Press. Hackensack, NJ, 2011, pp. 89-105.
50
[89] Fields C, Glazebrook JF. A mosaic of Chu spaces and Channel Theory II: Appli-
cations to object identification and mereological complexity. J Expt Theor Artif Intell
2019;31:237–265.
[90] Fields C, Glazebrook JF. Do Process-1 simulations generate the epistemic feelings that
drive Process-2 decision making? Cogn Proc 2020;21:533–553.
[91] Barwise J. Information and impossibilities. Notre Dame J Formal Logic
1997;38(4):488–515.
[92] Cherniak E. Bayesian networks without tears. AI Mag 1991;12(4):50–63.
[93] Allwein, G. A qualititative framework for Shannon Information theories. In NSPW
’04: Proceedings of 2004 Workshop on New Security Paradigms (Nova Scotia, Canada,
September 20-23, 2004). New York: ACM, 2004, pp. 23–31.
[94] St.ClereSmitheT.CompositionalactiveinferenceI:Bayesianlenses, statisticalgames.
Preprint arXiv:2109.04461 [math.ST], 2021.
[95] Coecke B. Quantum picturalism. Contemp Phys 2010;51:59–83.
[96] Adams EW. A Primer of Probabilistic Logic. Chicago: University of Chicago Press,
1998.
[97] Dzhafarov EN, Cervantes VH, Kujala JV. Contextuality in canonical systems of ran-
dom variables. Phil Trans R Soc A 2017;375:20160389.
[98] Dzharfarov EN, Kon M. On universality of classical probability with contextually la-
beled random variables. J Math Psych 2018;85:17–24.
[99] MacKay DJC, Peto LCB. A hierarchical Dirichlet language model. Nat Lang Engin
1995;1,289–308.
[100] Wallace CS, Dowe, DL. Minimum message length and Kolmogorov complexity. Com-
puter J 1999;42:270–283.
[101] Smith R, Schwartenbeck P, Parr T, Friston KJ. An active inference approach to mod-
eling structure learning: Concept learning as an example case. Front Comput Neurosci
2020;14:41.
[102] Weinstein A. Groupoids: Unifying internal and external symmetry. Notices Am Math
Soc 1996;43:744–752.
[103] Brown R. Topology and Groupoids. www.groupoids.org.uk, Deganwy, UK, 2006.
[104] Deutsch D. The structure of the multiverse. Proc R Soc A 2002;458:2911–2923.
51
[105] Marcian`o, A.; Chen, D.; Fabrocini, F.; Fields, C.; Greco, E.; Gresnigt, N.; Jinklub,
K.; Lulli, M., Terzidis, K.; Zappala, E. Deep neural networks as the semi-classical limit
of quantum neural networks. Preprint arXiv:2007.00142v2 [cond-mat.diss-nn].
[106] Oizumi M, Albantakis L, Tononi G. From the phenomenology to the mechanisms of
consciousness: Integrated Information Theory 3.0. PLoS Comp Biol 2014;10:e1003588.
[107] Robbins RJ, Krishtalka L, Wooley JC. Advances in biodiversity: Metagenomics and
the unveiling of biological dark matter. Stand Genom Sci 2016:11:69.
[108] Ashby WR. Introduction to Cybernetics. Chapman and Hall, London, UK, 1956.
[109] MooreEF.Gedankenexperimentsonsequentialmachines.InShannonCW,McCarthy
J (eds) Autonoma Studies. Princeton University Press, Princeton, NJ, USA, 1956, pp.
129–155.
[110] Scholl BJ. Object persistence in philosophy and psychology. Mind Lang 2007;22:563–
591.
[111] Fields C. The very same thing: Extending the object token concept to incorporate
causal constraints on individual identity. Adv Cognit Psychol 2012;8:234–247.
[112] Fields C. Some consequences of the thermodynamic cost of system identification.
Entropy 2018;20:797.
[113] Pais A. Einstein and the quantum theory. Rev Mod Phys 1979;51:863–914.
[114] Marr D. Vision. Freeman, San Francisco, CA, 1982.
[115] Palmer S. Vision Science: Photons to Phenomenology. MIT Press, Cambridge, MA,
1999.
[116] Pizlo Z. Perception viewed as an inverse problem. Vis Res 2001;41:3145–3161.
[117] Prakash C, Fields C, Hoffman DD, Prentner R, Singh M. Fact, fiction, and fitness.
Entropy 2020;22:514.
[118] Prakash C, Stephens KD, Hoffman DD, Prentner R, Singh M, Fields C. Fitness beats
truth in the evolution of perception. Acta Biotheor 2021;69: 319–341.
[119] Bohr N. The quantum postulate and the recent development of atomic theory. Nature
1928;121:580–590.
[120] Di Biagio A, Don`a P, Rovelli C. The arrow of time in operational formulations of
quantum theory. Quantum 2021;5;520.
[121] Tegmark M. How unitary cosmology generalizes thermodynamics and solves the in-
flationary entropy problem. Phys Rev D 2012;85:123517.
52
[122] Sulis W. Contextuality in neurobehavioural and collective intelligence systems. Quan-
tum Reports 2021;3: 592–614.
[123] Mermin D. Simplified unified form for the major no-hidden variables theorem. Phys
Rev Lett 1990; 65: 3373–3376.
[124] McCarthy J, Hayes PJ. Some philosophical problems from the standpoint of artificial
intelligence. In Michie D, Meltzer, B. (eds.) Machine intelligence, Vol. 4). Edinburgh
University Press, Edinburgh, 1969, pp. 463–502.
[125] FieldsC.Howhumanssolvetheframeproblem.JExptTheorArtifIntell2013;25:441–
456.
[126] Gottlieb J, Lopes M, Oudeyer P-Y. Motivated cognition: Neural and computational
mechanisms of curiosity, attention, and intrinsic motivation. In: Kim S-Y, Reeve J,
Bong M. (Eds) Recent Developments in Neuroscience Research on Human Motivation
(Advances in Motivation and Achievement, Vol. 19), Emerald Group Publishing Limited,
Bingley, UK, 2016, pp. 149–172.
[127] Wooters WK, Zurek WH. A single quantum cannot be cloned. Nature 1982;299:802–
803.
[128] PrattV.TypesasProcesses, viaChuspaces.ElectNotesTheorCompSci1997;7:227–
247.
[129] Pratt V. Broadening the denotational semantics of linear logic. Elect Notes Theor
Comp Sci 1996;3: 155–166.
[130] Culbertson J, Sturtz K. Bayesian machine learning via category theory. Preprint
arXiv:1312.1445v1[math.CT], 2013.
[131] Culbertson J, Sturtz K. A categorical foundation for Bayesian probability. Appl Cat-
egor Struct 2014;22(4): 647–662.
[132] Giry M. A categorical approach to probability theory. In: Banaschewski B. (ed)
Categorical Aspects of Topology and Analysis. (Lecture Notes in Mathematics, vol 915).
Springer, Berlin, 1982, pp. 68–85.
[133] Lawvere WF. The category of probabilistic mappings. Unpublished seminar notes,
(1962) available at https://ncatlab.org/nlab/files/lawvereprobability196.pdf (Accessed
10 Dec 2021).
[134] Abramsky S. Big toy models: Representing physical systems as Chu spaces. Synthese
2012;186:697–718.
[135] Conant RC, Ashby WR. Every good regulator of a system must be a model of that
system. Int J Syst Sci 1970;1(2):89–97.
53
[136] Fields C. Building the observer into the system: Toward a realistic description of
human interaction with the world. Systems 2016;4:32.
[137] Ji Z, Natarajan A, Vidick T, Wright J, Yuen H. MIP* = RE. Comms ACM
2021;64(11):131–138.
[138] Moser MB., Rowland DC, Moser EI. Place cells, grid cells, and memory. Cold Spring
Harbor Perspect Biol 2015;7:a021808.
[139] StachenfeldKL,BotvinickMM,GershmanSJ.Thehippocampusasapredictivemap.
Nat Neurosci 2017;20:1643–1653.
[140] Whittington JC, Muller TH, Mark S, Chen G, Barry C, Burgess N, Behrens TE. The
Tolman-Eichenbaum Machine: Unifying space and relational memory through generali-
sation in the hippocampal formation. Preprint bioRxiv:770495, 2019.
[141] Lloyd K, Leslie DS. Context-dependent decision-making: A simple Bayesian model.
J R Soc Interface 2013;10:20130069.
[142] Safron A. An Integrated World Modeling Theory (IWMT) of consciousness: Combin-
ing integrated information and global neuronal workspace theories with the Free Energy
Principle and active inference framework; Toward solving the Hard Problem and charac-
terizing agentic causation. Front Artif Intell 2020;3:30.
[143] Davis MH, Johnsrude IS. Hierarchical processing in spoken language comprehension.
J Neurosci 2003;23:3423–3431.
[144] GeorgeD, HawkinsJ.Towardsa mathematicaltheoryofcorticalmicro-circuits.PLoS
Comput Biol 2009;5:e1000532.
[145] Friston KJ, Lin M, Frith CD, Pezzulo G, Hobson JA, Ondobaka S. Active inference,
curiosity and insight. Neural Comput 2017;29:2633–2683.
[146] Friston KJ., Rosch, R, Parr T, Price C, Bowman H. Deep temporal models and active
inference. Neurosci Biobehav Rev 2017;77:388–402.
[147] MacKay DJ. Free-energy minimisation algorithm for decoding and cryptoanalysis.
Electron Lett 1995;31:445–447.
[148] TehYW,JordanMI,BealMJ,BleiDM.HierarchicalDirichletprocesses.JAmStatist
Assoc2006;101:1566–1581.
[149] Friston KJ, Parr T, Yufik Y, Sajid N, Price CJ, Holmes E. Generative models, lin-
guistic communication and active inference. Neurosci Biobehav Rev 2020;118:42–64.
[150] Parr T, Friston KJ. The active construction of the visual world. Neuropsychologia
2017;104:92–101.
54
[151] Mead C. Neuromorphic electronic systems. Proc IEEE 1990;78:1629–1636.
[152] Tang J, Yuan F, Shen X, Wang Z, Rao M, He Y, Sun Y, Li X, Zhang W, Li Y,
Gao B, Qian H, Bi G, Song S, Yang J, Wu H. Bridging biological and artificial neural
networks with emerging neuromorphic devices: Fundamentals, progress, and challenges.
Adv Mater 2019;31:1902761.
[153] Jaynes ET. Information Theory and Statistical Mechanics. Phys Rev (Series II)
1957;106:620–630.
[154] Friston KJ, Wiese W, Hobson JA. Sentience and the origins of consciousness: From
Cartesian duality to Markovian monism. Entropy 2020;22:516.
[155] Fields C. A whole box of Pandoras: Systems, boundaries and free will in quantum
theory. J Expt Theor Artif Intell 2013;25:291–302.
[156] Maturana H, Varela FJ. Autopoiesis and Cognition: The Realization of the Living.
Boston Stud Phil Sci 42. D. Reidel, Dordrecht, 1980.
[157] VarelaF,ThompsonE,Rosch,E.TheEmbodiedMind: CognitiveScienceandHuman
Experience. MIT Press, Cambridsge, MA, 1991.
[158] Anderson ML. Embodied cognition: A field guide. Artif Intell 2003;149:91–130.
[159] Froese T, Ziemke T. Enactive artificial intelligence: Investigating the systemic orga-
nization of life and mind. Artif Intell 2009;173:466–500.
[160] Schr¨odinger E. What Is Life?. Cambridge University Press, Cambridge, UK, 1944.
[161] Wigner EP. Remarks on the mind-body question. In: Good IJ (ed.), The Scientist
Speculates. London: Heinemann, 1961, pp. 284–302.
[162] Penrose R. The Emperor’s New Mind. Oxford University Press, Oxford, 1989.
[163] Hameroff S, Penrose R. Orchestrated reduction of quantum coherence in brain mi-
crotubules: A model for consciousness. Math. Comput. Simul. 1996;40:453–480.
[164] Tegmark M. Importance of quantum decoherence in brain processes. Phys. Rev. E
2000;61:4194–4206.
[165] Davies PCW. Does quantum mechanics play a non-trivial role in life? BioSystems
2004;78:69–79.
[166] Hameroff S, Tuszynski, J. Quantum states in proteins and protein assemblies: The
essence of life? In: Abbott D, Bezrukov SM, Der A, Sa´nchez A. (eds) Fluctuations
and Noise in Biological, Biophysical, and Biomedical Systems II SPIE, Bellingham, WA,
2004, pp. 27–41.
55
[167] ArndtM,JuffmannT,VedralV,Quantumphysicsmeetsbiology.HFSPJ2009;3:386–
400.
[168] Lambert N, Chen Y-N, Cheng Y-C, Li C-M, Chen G-Y, Nori F. Quantum biology.
Nat. Phys. 2012;9:10–18.
[169] Melkikh AV, Khrennikov A. Nontrivial quantum and quantum-like effects in biosys-
tems: Unsolved questions and paradoxes. Prog. Biophys. Mol. Biol. 2015;119:137–161.
[170] Brookes JC. Quantum effects in biology: Golden rule in enzymes, olfaction, photo-
synthesis and magnetodetection. Proc. R. Soc. A 2017;473:20160822.
[171] McFadden J, Al-Khalili J. The origins of quantum biology. Proc. R. Soc. A
2018;474:20180674.
[172] Marais A, Adams B, Ringsmuth AK, Ferretti M, Gruber MJ, Hendrikx R, et al. The
future of quantum biology. J. R. Soc. Interface 2018;15:20180640.
[173] Cao J, Cogdell RJ, Coker DF, Duan H-G, Kleinekath¨ofer U, Jansen TLC, et al.
Quantum biology revisited. Sci. Adv. 2020;6:eaaz4888.
[174] Kim Y, Bertagna F, D’Souza EM, Heyes DJ, Johannissen LO, Nery ET. Quantum
biology: An update and perspective. Quant Rep 2021;3:1–48.
[175] Polanyi M. Life’s irreducible structure. Science 1968;160:1308–1312.
[176] Rosen R. On information and complexity. In Casti JL, Karlqvist A. (eds) Complexity,
Language, and Life: Mathematical Approaches. Springer, Berlin, 1986; pp. 174–196.
[177] Ellis GFR. Physics, complexity, and causality. Nature 2005;435:743.
[178] Fields C, Levin M. Metabolic limits on classical information processing by biological
cells. BioSystems 2021;209:104513.
[179] Cervantes VH, Dzhafarov EN. Snow Queen is evil and beautiful: Experimental evi-
dence for probabilistic contextuality in human choices. Decision 2018;5(3):193–204.
[180] Basieva I, Cervantes VH, Dzhafarov EN, Khrennikov A. True contextuality beats
directs influences in human decision making. J Expt Psychol General 2019;148:1925–
1937.
[181] Khrennikov A. Quantum-like modeling of cognition. Front Phys 2015;3:77.
[182] Basieva I, Khrennikov A, Ohya M, Yamato O. Quantum-like interference effect in
gene expression: glucose-lactose destructive interference. Syst Synth Biol 2011;5:59–68.
[183] Friston K, Frith C. A Duet for one. Conscious Cogn 2015;36:390–405.
56
[184] Frith C, Wentzer T. Neural Hermeneutics. In Kaldis B. (ed) Encyclopedia of Phi-
losophy and the Social Sciences. SAGE Publications, Thousand Oaks, CA, 2013, pp.
657–659.
[185] Friston KJ, Frith CD. Active inference, communication and hermeneutics. Cortex
2015;68:129–143.
[186] Isomura T, Parr T, Friston K. Bayesian filtering with multiple internal models: To-
ward a theory of social intelligence. Neural Comput 2019;31:2390–2431.
[187] Campbell JO. Universal Darwinism as a process of Bayesian inference. Front Syst
Neurosci 2016;10:49.
[188] Fields C, Levin M. Integrating evolutionary and developmental thinking into a scale-
free biology. BioEssays 2020;42:1900228.
[189] Fields C, Levin M. Does evolution have a target morphology? Organisms 2020;4:57–
76.
[190] Zurek WH. Quantum Darwinism. Nature Physics 2009;5:181–188.
[191] CampbellJO.QuantumDarwinismasaDarwinianprocess.PreprintarXiv:1001.0745
[physics.gen-ph], 2010.
[192] Fields C. Quantum Darwinism requires an extra-theoretical assumption of encoding
redundancy. Int J Theor Phys 2010;49:2523–2527.
[193] Abramsky S, Brandenburger, A. The sheaf-theoretic structure of non-locality and
contextuality. New J Phys 2011;13:113036.
[194] Abramsky S, Hardy L. Logical Bell inequalities. Phys Rev A 2012; 85(6):062114.
[195] Popescu S. Non-locality beyond quantum mechanics. Nat Phys 2014;10:264–270.
[196] Adlam E. Contextuality, fine-tuning and teleological explanation. Preprint
arXiv:2110.15898v1[quant-ph], 2021.
57