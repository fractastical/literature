Probabilistic Principles for
Biophysics and Neuroscience
Entropy production,
Bayesian mechanics
&
the free-energy principle.
A thesis presented for the degree of
Doctor of Philosophy of Imperial College London
by,
Lancelot Da Costa
Department of Mathematics
Imperial College London
180 Queen’s Gate, London SW7 2AZ
October 2023
4202
tcO
51
]hp-htam[
1v53711.0142:viXra
Abstract
Thisthesisfocusesonthreefundamentalaspectsofbiologicalsystems;namely,entropyproduction,Bayesian
mechanics, and the free-energy principle. The contributions are threefold: 1) We compute the entropy
productionforagreaterclassofsystemsthanbefore,includingalmostanystationarydiffusionprocess,such
as degenerate diffusions where the driving noise does not act on all coordinates of the system. Importantly,
this class of systems encompasses Markovian approximations of stochastic differential equations driven by
colorednoise,whichissignificantsincebiologicalsystemsatthemacro-andmeso-scalearegenerallysubject
tocoloredfluctuations. 2)WedevelopaBayesianmechanicsforbiologicalandphysicalentitiesthatinteract
withtheirenvironmentinwhichwegivesufficientandnecessaryconditionsfortheinternalstatesofsomething
to infer its external states, consistently with variational Bayesian inference in statistics and theoretical
neuroscience. 3) We refine the constraints on Bayesian mechanics to obtain a description that is more
specific to biological systems, called the free-energy principle. This says that active and internal states of
biological systems unfold as minimising a quantity known as free energy. The mathematical foundation to
the free-energy principle, presented here, unlocks a first principles approach to modeling and simulating
behavior in neurobiology and artificial intelligence, by minimising free energy given a generative model of
external and sensory states.
1
Acknowledgements
I dedicate this thesis to my loving partner Pauline Chatellard who continuously and restlessly supports me
through highs and lows, and so for the past many years. I could not have done this without you.
My heartfelt gratitude goes to my awesome team of supervisors, Grigorios A. Pavliotis and Karl Friston,
who have been incredibly supportive, helpful, and insightful throughout my research journey. Through your
mentorshipyouhavebothgivenmearichandcomplementaryperspective,andauniquetechnicalexpertise.
It is in large part to you that I owe my present and future academic success.
I thank my family for their support; especially my brother for inspiring me to be dedicated, resilient, and
never give up, my father for encouraging me to pursue mathematics and neuroscience, and stimulating my
curiositysincechildhood,mymotherforsupportingmewhateverhappened,andteachingmetobekindand
generous in all areas of life, and my aunt for being there in the most difficult moments. I am grateful to my
longtime friends, particularly Nicolas Ward, Mathieu Binder, Arnaud Pedrazzani, Baptiste Pesanti, Ritwick
Sundar, Stéphane Nordin, and Wojtek Reise.
Thank you to my amazing colleagues and collaborators. Your perspectives have been mind expanding, and
many of you have become dear friends over the years. You are the reason why the PhD has been such a
fun, interesting and rewarding experience. At the risk of omitting many, I particularly thank Conor Heins,
Maxwell Ramstead, Thomas Parr, Kai Ueltzhöffer, Noor Sajid, Alessandro Barp, Victorita Neacsu, Laura
Convertino,AnjaliBhat,RyanSmith,BiswaSengupta,PabloLanillos,TimVerbelen,DaltonSakthivadivel,
Théophile Champion, Guillermo B. Morales, Guilherme França, Aswin Paul, Magnus T. Koudahl, Beren
Millidge, PeterZeidman, AnilSeth, ChristopherBuckley, ZafeiriosFountas, AlexeyZakharov, UmaisZahid,
SergioRubin,CyrusMostajeran,ComeAnnicchiarico,JeremieMattout,LarsSandved-Smith,AntoineLutz,
Danijar Hafner, Mahault Albarracin, Riddhi Pitliya Jain and Jonas Mago. Not least, I am deeply grateful
to Michael I. Jordan, Joshua B. Tenenbaum, Philipp Hennig, and Samuel Gershman for invaluable career
advice. Lastly, I thank my friends and classmates from the Centre for Doctoral Training in Mathematics
of Random Systems, and particularly Rémy Messadene, Felix Prenzel, Alain Rossier, Victoria Klein, Julian
Sieber, Benedikt Petko, Jonathan Tam, and Alessandro Micheli.
I thank the staff of the Centre for Doctoral Training in Mathematics of Random Systems, particularly our
centre manager Lydia Noa, for always being available, incredibly helpful, and supportive; and the directors,
who took a chance on me in spite of my atypical academic background.
Last but not least, I will always be grateful too the Fonds National de la Recherche of Luxembourg (Project
code: 13568875) for funding my PhD research. Your generous funding has allowed me to pursue my PhD
free of many administrative burdens, with unparalleled intellectual freedom, and with the ability to attend
and contribute to many scientific events.
2
Integrity
I certify that this thesis, and the research to which it refers, are the product of my own work, and that
any ideas or quotations from the work of other people, published or otherwise, are fully acknowledged in
accordancewiththestandardreferencingpracticesofthediscipline. Inaddition,IcertifythatIhaveobtained
the necessary copyright allowances for reproducing some of my own academic papers in this thesis.
Copyright
Thecopyrightofthisthesisrestswiththeauthor. Unlessotherwiseindicated,itscontentsarelicensedunder
a Creative Commons Attribution-Non Commercial 4.0 International Licence (CC BY-NC).
Under this licence, you may copy and redistribute the material in any medium or format. You may also
createanddistributemodifiedversionsofthework. Thisisontheconditionthat: youcredittheauthorand
do not use it, or any derivative works, for a commercial purpose.
When reusing or sharing this work, ensure you make the licence terms clear to others by naming the licence
andlinkingtothelicencetext. Whereaworkhasbeenadapted, youshouldindicatethattheworkhasbeen
changed and describe those changes.
Please seek permission from the copyright holder for uses of this work that are not included in this licence
or permitted under UK Copyright Law.
3
Contents
Abstract 1
Acknowledgements 2
Integrity 3
Copyright 3
1 Introduction 9
1.1 Background and motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
1.2 Overview of thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
1.3 Limitations of thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.4 A note on notations and terminologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
1.5 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
1.6 Awards for PhD work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
2 Entropy production 17
2.1 Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
2.3 The e of stationary Markov processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
p
2.4 Time reversal of stationary diffusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.5 The e of stationary diffusions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
p
2.6 Examples and e of numerical simulations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
p
2.7 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
4
2.8 Addendum: Proofs for Chapter 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
3 Bayesian mechanics 62
3.1 Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
3.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
3.3 Markov blankets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
3.4 Bayesian mechanics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
3.5 Active inference and stochastic control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
3.6 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
3.7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
3.8 Addendum: Proofs for Chapter 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
4 The free-energy principle 83
4.1 Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
4.3 Systems, states and fluctuations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
4.4 Solutions, steady-states and nonequilibria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
4.5 Particles, partitions and things . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
4.6 From self-organisation to self-evidencing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
4.7 Lagrangians, generalised states and Bayesian filtering. . . . . . . . . . . . . . . . . . . . . . . 97
4.8 From statistical to classical particles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
4.9 Path integrals, planning and curious particles . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
4.10 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
5 Conclusion 115
5.1 Summary of thesis achievements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
5.2 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
5.3 Future work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
Data availability 117
5
Author contributions 117
Bibliography 117
6
List of Figures
2.1 Helmholtz decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
2.2 Entropy production as a function of time-irreversible drift . . . . . . . . . . . . . . . . . . . . 33
2.3 Exact simulation of linear diffusion process with b (x)∈Rangeσ . . . . . . . . . . . . . . . 38
irr
2.4 Exact simulation of linear diffusion process with b (x)̸∈Rangeσ . . . . . . . . . . . . . . . 39
irr
2.5 Exact simulation of underdamped Langevin dynamics . . . . . . . . . . . . . . . . . . . . . . 41
2.6 Euler-Maruyama simulation of underdamped Langevin dynamics . . . . . . . . . . . . . . . . 42
2.7 BBK simulation of underdamped Langevin dynamics . . . . . . . . . . . . . . . . . . . . . . . 43
3.1 Markov blanket . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
3.2 Synchronisation map: example and non-example . . . . . . . . . . . . . . . . . . . . . . . . . 69
3.3 Markov blanket evolving in time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
3.4 Processes at a Gaussian steady-state . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
3.5 Variational inference and predictive processing, averaging internal variables for any blanket
state . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
3.6 Variational inference and predictive processing . . . . . . . . . . . . . . . . . . . . . . . . . . 74
3.7 Markov blanket evolving in time comprising sensory and active states . . . . . . . . . . . . . 76
3.8 Active inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
3.9 Stochastic control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
3.10 Continuous-time Hidden Markov model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
4.1 Markov blankets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
4.2 Autonomous flows and Bayesian filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
4.3 Markov blankets and self-evidencing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
7
4.4 Generic and precise particles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
4.5 Bayesian mechanics and active inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
4.6 Sentient behaviour and action observation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
4.7 Expected free energy and active inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
4.8 Bayesian mechanics and active inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
4.9 Epistemic foraging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
8
Chapter 1
Introduction
1.1 Background and motivation
The ambition for this thesis started many years ago as I was finishing Part III of the Mathematical Tripos
at Cambridge. I already knew that I wanted to work in neuroscience – deriving a fundamental theory of
brain function that could also be used for principled artificial intelligence. A friend of the time, Sebastiano
Cultrera,toldmeaboutthefree-energyprinciple. ThisisaprinciplepostulatedbytheBritishneuroscientist
Karl Friston promising a powerful and unifying account of brain function in terms of minimising one single
objective–variationalfree-energy[1]. IdidnotunderstandthetheoryatthetimebutIthoughtit–givenmy
idealisticpuremathematician’s background–extremelyexcitingandapromisingstartingpoint towardsthe
endgoalofacompletemathematicaltheoryofthebrain. Followingmymastersinmathematics,Iundertooka
mastersinbrainscienceatUCLwhereIwasveryfortunatetoworkwithKarlFristonhimselfonapplications
of the free-energy principle for modelling neural dynamics in the brain. During that year, I realised that the
free-energy principle was a physicist’s intuition that did not yet admit rigorous mathematical and physical
underpinnings – although attempts led by Karl Friston over the last decade had made considerable progress
towards this. I realised that there was a significant opportunity for a mathematician like me to develop
thisfundamentaltheory. Tothisend, Iorganisedaninter-universityco-supervisionwithProfessorPavliotis,
a world-renowned expert in stochastic differential equations – the type of mathematics that seemed to be
needed to formalise the principle – and Karl Friston.
This collaboration and co-supervision has exceeded my expectations for learning and contributing to math-
ematical neuroscience and various related fields. For instance, I learned that the free-energy principle had
been postulated to hold in biological systems and some physical systems, and a burgeoning line of work –
which started at about the same time as I started my PhD – applies the free-energy principle to generate
intelligent agents for artificial intelligence.
My PhD work has been devoted to developing the mathematical foundation of the free-energy principle
for neuroscience and biophysics more broadly, as a description of human and biological cognition, and
establishingprincipledandrigorousmethodologiesforitsapplicationinartificialintelligence. Ialsoexplored
its potential for generating intelligent agents that are robust, whose decisions are explainable, and that are
9
safe to interact with, which are current main challenges in artificial intelligence [2]. The overarching goal
was to obtain an unbroken narrative from mathematical physics, to cognitive neuroscience, and finally to
artificial intelligence – and a coherent framework to think about these fields.
This thesis focuses on three highlights from my PhD’s work which pertain to fundamental principles in
biophysics and neuroscience, and practically ignores all of the applications to artificial intelligence. The
reason for this is twofold: to keep the length of this thesis within reasonable bounds, and to focus on some
of the most mathematically significant aspects of my PhD project.
1.2 Overview of thesis
Thisthesisstartswiththefundamentalassumptionanyfundamentaltheoryforbiophysicsandneuroscience
has to be consistent with the rest of physics. Its starting point must therefore be a stochastic differential
equation (a.k.a. a Langevin equation)
x˙ =f(x )+w . (1.1)
t t t
This equation decomposes the motion of a system into a deterministic part f(x ) governed by a vector field
t
f , which summarises what we know about the system (this part is usually called the drift or the flow), and
a stochastic part w which summarises what we don’t know about the system (this part is usually called the
t
noise orthe random fluctuations). Sowhy starthere? Because thisdescription isconsistentwiththe restof
physics. Forinstance,stochasticdifferentialequationsformthebasisofstatisticalmechanics[3]. Inparticular
classical mechanics is the limit of statistical mechanics as particles become large and random fluctuations
on the motion become infinitesimally small. Note that we did not commit to any specific interpretation of
the stochastic differential equation at this stage – e.g. Stratonovich or Ito – and we did not commit to any
specific assumptions about the functional form of the random fluctuations. This will come in later.
This thesis is the collection of three papers from my PhD’s work which study three fundamental aspects of
biological systems; namely, entropy production, Bayesian mechanics, and the free-energy principle.
1.2.1 Chapter 2: Entropy production1
One of the fundamental traits of living systems is time-reversibility and entropy production. Entropy pro-
duction measures the amount of time-irreversibility present in a system, that is to what extent the process
astimegoesforwarddiffersfromtheprocessastimegoesbackwards. Theentropyproductionalsomeasures
the minimum amount of energy consumed by the system for the period of time over which it is measured,
or equivalently the minimal amount of heat dissipated by the system during that period of time.
In this chapter we develop a comprehensive and general theory for the entropy production of systems de-
scribed by stochastic differential equations, and contextualise it within the broader literatures of probability
and statistical physics.
1Adapted from: L Da Costa, GA Pavliotis. The entropy production of stationary diffusions. Journal
of Physics A: Mathematical and Theoretical. 2023.
10
From a mathematical perspective we are able to give a computable expression for the entropy production in
a wider range of equations than was previously available, allowing for so-called degenerate diffusions which
are SDEs where the noise process need not act on all coordinates. Although we focus on diffusion processes,
that is SDEs driven by white noise, the fact that we allow degenerate diffusions means that the results
apply to Markovian approximations of systems driven by coloured noise. This is fundamentally important
because any biological system that is not modelled at a molecular level will plausibly be subject to coloured
fluctuations. Although we focus on Euclidean state spaces, our results can easily be generalised to manifold
state spaces.
Technically, we show that any stationary diffusion can be decomposed into a time reversible part and a
time irreversible part, which generalises the classical Helmholtz-Hodge decomposition from vector calculus.
We show that this decomposition is equivalent to writing the Fokker-Planck equation of the system in pre-
GENERICform,whereGENERICstandsforGeneralEquationsforNon-EquilibriumReversible-Irreversible
Coupling – a prominent framework for analysing Dynamics in non-equilibrium statistical physics pioneered
by Ottinger [4]. This is also equivalent to a decomposition of the backward Kolmogorov equation of the
system considered in hypocoercivity theory, a theory developed by C. Villani for quantifying the rate of
convergence of dynamics to their non-equilibrium steady state [5].
All in all, this paper reviews essential concepts related to entropy production and time irreversibility and
provides a wide range of tools for statistical physicists and biological physicists to study non-equilibrium
phenomena.
1.2.2 Chapter 3: Bayesian mechanics2
Themainideathatunderwritesthischapter,isthatifa’thing’(e.g. acell)anditssurroundingenvironment,
together defining a ’system’ x , have an attracting stationary state, then the thing can be interpreted as
t
being adaptive in the sense that its interactions on the environment look as if the thing is bringing itself –
andtheenvironment–towardsapreferredsetofstates(i.e. homeostatic)followinganykindofperturbation.
The implications of this simple observation are quite rich. For instance, the existence of a thing and what is
not the thing entails the existence of boundary states b between the internal states of the thing µ and the
t t
states of every thing else η . We formalise the idea of a boundary between a thing and its environment as a
t
Markov blanket of the stationary density p (i.e. conditional independence given the blanket states)
µ ⊥η |b , where x =(µ ,b ,η )∼p. (1.2)
t t t t t t t
that exists over the period of time that the thing exists.
The existence of a Markov blanket means that internal states synchronise with external states via vicarious
interactions through the blanket. We can go beyond this and show that internal states encode probabilistic
beliefsaboutexternalstatesandupdatethiscontinuouslyinthefaceofnewblanketstates(e.g. newsensory
information) consistently with variational Bayesian inference in theoretical neuroscience and statistics.
2Adapted from: L Da Costa, K Friston, C Heins, GA Pavliotis. Bayesian mechanics for stationary
processes. Proceedings of the Royal Society A. 2021.
11
If we further decompose blanket states into sensory and active states, then we can show that active states
controlthesystembacktoitsstationarystatedefiningitsrangeofpreferredstatesfollowinganyperturbation,
consistently with active inference in theoretical neuroscience and generalized forms of PID (Proportional-
Integral-Derivative) control in engineering.
Since the publication of this article, it has become clear that the proper way to define a boundary between
a thing and everything else is through a Markov blanket over trajectories, that is the fulfilment of (1.2)
where states are replaced by paths over some period of time, as explored in the next Chapter of this thesis.
Indeed, although articulated in a different language, this coincides with the notion of a multipartite process
in statistical physics [6,7]. Fortunately for this paper, a Markov blanket over paths often entails a Markov
blanket over states. This was first realized empirically in simulations of a primordial soup [8], and then in
further simulations involving sparsely coupled stochastic Lorenz systems [9]. The sparse coupling conjecture
claimsthatforsufficientlyhighdimensionalandnonlinearrandomdynamicalsystems,aMarkovblanketover
paths implies the existence of a Markov blanket over states (partial demonstrations are given in [10,11]). In
particular,thisconjecturealwaysholdsinSDEsdrivenbycolourednoisethatcanbeexpandedingeneralized
coordinates [12,13].
1.2.3 Chapter 4: the free-energy principle3
Chapter 3 goes one step further in defining the type of constraints that a biological organism must comply
with, and derives stronger conclusions. In this chapter, the boundary between an organism and its environ-
ment is defined as a Markov blanket over paths. As before, the boundary is composed of sensory and active
states. Further, sensory states are permitted to influence internal states directly but internal states may
not directly influence sensory states. Similarly for active states: they may influence external states directly,
however external states may not directly influence active states. These influences are summarised by sparse
coupling in the flow/drift vector field in the stochastic differential equation defining the whole system.
With this special set up, the conclusions of chapter 2 still hold and then some. We can show that the
internal and active parts of the organism have paths of least action (i.e. most likely path) that minimise
a quantity known as variational free-energy – the objective that used in variational Bayesian inference and
theoretical neuroscience to describe the purpose of brain function. When we consider stochastic differential
equationsdrivenbycolourednoise,wecanshowthatinternaldynamicscorrespondtogeneralized(Bayesian)
filtering [14] – perhaps the most generic filtering algorithm in the literature.
When we consider organisms at a sufficiently high-level of coarse-graining such that the dynamics of the
organismitself(andnotnecessarilyitsenvironment)aregovernedbyclassicalmechanics,wecanseethatthe
mostlikelypathofinternalandactivestatessatisfyaprincipleofleastactionbyminimizingquantityknown
asexpectedfree-energy. Theexpectedfree-energyistheanalogofthevariationalfree-energyfortrajectories.
Whatisinterestingisthatbyexaminingtheexpectedfree-energycarefullywerecoverasspecialcasesseveral
objective functions that are used to describe optimal behavior in various fields of science and engineering,
e.g. economics, machine learning, and psychology. This suggests that several of these theories that have
been arrived at independently may be unified and contextualized within a generic free-energy framework.
3Adapted from: K Friston, L Da Costa, N Sajid, C Heins, K Ueltzhoeffer, GA Pavliotis, T Parr. The
free energy principle made simpler but not too simple. Physics Reports. 2023
12
Pragmatically, the free-energy principle on offer gives us equations of motion, in terms of minimizing varia-
tional and expected free-energy, for describing and simulating intelligent biological behavior. This is shown
by rehearsing some simulations from the literature such as a simulation of handwriting and a simulation of
saccadic eye movements.
Muchremainstobedoneintermsofanalyzingthepreciserelationshipbetweenthefree-energyprincipleand
other theories of purposeful biological behavior that exist in the literature. Much also remains in refining
the principle to obtain a description that is exclusive to the human brain, with more specific implications
forneuroscienceandartificialintelligence. However,thevastbodyofworkutilizingthefree-energyprinciple
for modeling and generating intelligent biological behavior both in neuroscience and artificial intelligence,
and its mathematical foundation – in terms of statistical physics – presented in this thesis suggests that the
free-energy principle provides a solid foundation for a physics of sentient and cognitive beings.
1.3 Limitations of thesis
Perhaps the main limitation of this thesis is the reliance on white noise assumptions for the fluctuations
in the SDE (1.1) in chapter 1 (Entropy production) and chapter 3 (the free-energy principle). Clearly
white noise may be a good model for the random fluctuations driving systems at the molecular level (e.g.
molecular biology) but is not fit for purpose for describing complex biological systems at a higher level of
coarsegraining,becauseinthatcaserandomfluctuationsareusuallytheoutputofotherdynamicalsystems,
and thus have a nontrivial autocorrelation structure. In these two chapters the only place where coloured
noise is treated explicitly is in chapter 3. (Note that there exists a refinement of chapter 3 that is specific to
the case of coloured noise [13], however it is less mathematically rigorous than the current state of chapter
3).
Practically all of my fourth year of PhD has been devoted developing rigorous analysis, numerical simulation
and filtering techniques for SDEs driven by coloured noise. My original plan was to include this in the thesis
as an additional chapter placed between current chapters 1 and 2. However, the administration of Imperial
College has been very inflexible in refusing to grant me an unpaid two month extension to the submission
deadline, the time I need to complete this work. As a result I am not including this in my thesis submission,
butwouldbehappytoadditduringrevisionstageas,crucially,it1)nicelycomplementschapter1,addressing
its main limitations, 2) underpins chapters 2 and 3, and 3) offers a systematic treatment of a fundamentally
important topic in the modelling and simulation of biological and neural systems.
1.4 A note on notations and terminologies
While I have done my best to keep notation and terminology consistent across papers, i.e. chapters, there
remain discrepancies which reflect the fact that each of the papers was originally written with a different
audienceinmind. Forinstance, probabilistsusetheletterbforthedriftofastochasticdifferentialequation,
while physicists use the letter f and call it the flow. Here I mostly chose to maintain the notation and
terminology of the community that each paper was originally addressed to. This highlights the parallels
13
between different and converging fields of research, which is perhaps the main implicit thread linking the
various chapters.
1.5 Publications
My privileged position as one of the only mathematicians working on the free-energy principle, a topic that
isbecomingwidelyadoptedinneuroscienceandotherapplicationdomains,meansthatIhavebeenableand
fortunate to collaborate on a wide range of projects, with collaborators of many different disciplines, which
has been an incredibly mind expanding and enthralling experience.
1.5.1 List of papers (32)
∗ Corresponding author, † Equal contribution, ⋆ Highlighted work, ⋄ Cover article.
Manuscripts Under Review (6)
NDaCosta,MPförtner,LDaCosta,PHennig. SamplePathRegularityofGaussianProcessesfromtheCovariance
Kernel. Under review in JMLR. arXiv:2312.14886. 2023.
KFriston,LDaCosta,etal. Supervisedstructurelearning. UnderreviewinNeuralComputation. arXiv:2311.10300
2023.
CHeins,BMillidge,L Da Costa,RPMann,KFriston,IDCouzin. Collectivebehaviorfromsurpriseminimization.
Under review in PNAS. 2023.
A Paul, N Sajid, L Da Costa, A Razi. On efficient computation in active inference. Under review in IEEE
Transactions on Neural Networks and Learning Systems. arXiv:2307.00504. 2023.
S Rubin, C Heins, T Mitsui, L Da Costa, K Friston. Climate homeostasis by and for active inference in the
biosphere. Under review in Nature Communications. 2023.
NSajid,EHolmes,L Da Costa,CPrice,KFriston. Amixedgenerativemodelofauditorywordrepetition. Under
review in Frontiers in Neuroscience. BioRxiv. 2022.
Book Chapters (2)
⋆ A Barp†, L Da Costa†, G Franca†, K Friston, M Girolami, MI Jordan, GA Pavliotis. Geometric Methods for
Sampling, Optimisation, Inference and Adaptive Agents. Geometry and Statistics, Handbook of Statistics Series vol
46 (Eds. F Nielsen, AS Rao, CR Rao). 2022.
NSajid,L Da Costa,TParr,KFriston. Activeinference,Bayesianoptimaldesign,andexpectedutility. TheDrive
for Knowledge (Eds. IC Dezza, E Schulz, CM Wu). 2022.
14
Workshop Papers (2)
NSajid,PTigas,ZFountas,QGuo,AZakharov,L Da Costa. Modellingnon-reinforcedpreferencesusingselective
attention. First Conference on Lifelong Learning Agents: Workshop Track. arXiv:2207.13699. 2022.
L Da Costa∗, N Sajid, D Zhao, S Tenka. Active inference as a model of agency. RLDM 2022 Workshop on
Reinforcement Learning as a Model of Agency. 2022.
Journal Articles (22)
L Da Costa,LSandved-Smith. TowardsaBayesianmechanicsofmetacognitiveparticles: Acommentaryon"Path
integrals,particularkinds,andstrangethings"byFriston,DaCosta,Sakthivadivel,Heins,Pavliotis,Ramstead,and
Parr. Physics of Life Reviews. 2023.
K Friston, L Da Costa∗, DAR Sakthivadivel, C Heins, GA Pavliotis, MJD Ramstead, T Parr. Path integrals,
particular kinds, and strange things. Physics of Life Reviews. arXiv:2210.12761. 2023.
⋆ K Friston, L Da Costa∗, N Sajid, C Heins, K Ueltzhoeffer, GA Pavliotis, T Parr. The free-energy principle made
simpler but not too simple. Physics Reports. 2023.
⋆ L Da Costa∗, GA Pavliotis. The entropy production of stationary diffusions. Journal of Physics A: Mathematical
and Theoretical. 2023.
⋆LDaCosta∗,NSajid,TParr,KFriston,RSmith. RewardMaximisationthroughDiscreteActiveinference. Neural
Computation. 2023.
MJDRamstead,DARSakthivadivel,CHeins,MKoudahl,BMillidge,LDaCosta,BKlein,KFriston. OnBayesian
Mechanics: A Physics of and by Beliefs. Journal of the Royal Society Interface. 2023.
C Heins, L Da Costa. Sparse coupling and Markov blankets: A comment on "How particular is the physics of the
free-energy Principle?" by Aguilera, Millidge, Tschantz and Buckley. Physics of Life Reviews. 2022.
T Champion, L Da Costa, H Bowman, M Grzes. Branching Time Active Inference: the theory and its generality.
Neural Networks. 2022.
N Sajid, F Faccio, L Da Costa, T Parr, J Schmidhuber, K Friston. Bayesian brains and the Rényi divergence.
Neural Computation. 2022.
⋄ L Da Costa†∗, P Lanillos†, N Sajid, K Friston, S Khan. How active inference could help revolutionise robotics.
Entropy. 2022.
⋆ L Da Costa∗, K Friston, C Heins, GA Pavliotis. Bayesian mechanics for stationary processes. Proceedings of the
Royal Society A. 2021.
K Friston, C Heins, K Ueltzhoeffer, L Da Costa, T Parr. Stochastic Chaos and Markov Blankets. Entropy. 2021.
K Ueltzhoeffer, L Da Costa, D Cialfi, K Friston. A Drive towards Thermodynamic Efficiency for Dissipative
Structures in Chemical Reaction Networks. Entropy. 2021.
T Parr, L Da Costa, C Heins, MJD Ramstead, K Friston. Memory and Markov Blankets. Entropy. 2021.
K Friston, L Da Costa, T Parr. Some interesting observations on the free-energy principle. Entropy. 2021.
15
K Ueltzhoeffer, L Da Costa, K Friston. Variational free-energy, individual fitness, and population dynamics under
acute stress. Comment on "Dynamic and thermodynamic models of adaptation" by Alexander N. Gorban et al.
Physics of Life Reviews. 2021.
T Parr, N Sajid, L Da Costa, MB Mirza, K Friston. Generative models for active vision. Frontiers in Neurobotics.
2021.
⋆L Da Costa∗,TParr,BSengupta,KFriston. Neuraldynamicsunderactiveinference: plausibilityandefficiencyof
information processing. Entropy. 2021.
K Friston, L Da Costa, D Hafner, C Hesp, T Parr. Sophisticated inference. Neural Computation. 2021.
⋆LDaCosta∗,TParr,NSajid,SVeselic,VNeacsu,KFriston. Activeinferenceondiscretestate-spaces: asynthesis.
Journal of Mathematical Psychology. 2020.
S Rubin, T Parr, L Da Costa, K Friston. Future climates: Markov blankets and active inference in the biosphere.
Journal of the Royal Society Interface. 2020.
T Parr, L Da Costa, K Friston. Markov blankets, information geometry and stochastic thermodynamics. Philo-
sophical Transactions of the Royal Society A. 2020.
1.6 Awards for PhD work
My PhD’s work has been honoured by several awards including a Doris Chen Award by Imperial College London
(2023), a Best Paper Award by the journal Entropy (2023), an Excellence Grant by G-Research (2022), and a
DistinguishedStudentAwardbytheAmericanPhysicalSocietyattheAPSMarchmeetingheldinChicago,IL,USA
(2022).
16
Chapter 2
Entropy production
The entropy production of stationary diffusions
By Lancelot Da Costa and Grigorios A. Pavliotis
Adapted from: L Da Costa, GA Pavliotis. The entropy production of stationary diffusions. Journal
of Physics A: Mathematical and Theoretical. 2023
17
2.1 Abstract
The entropy production rate is a central quantity in non-equilibrium statistical physics, scoring how far a stochastic
process is from being time-reversible. In this chapter, we compute the entropy production of diffusion processes at
non-equilibriumsteady-stateundertheconditionthatthetime-reversalofthediffusionremainsadiffusion. Westart
bycharacterisingtheentropyproductionofbothdiscreteandcontinuous-timeMarkovprocesses. Weinvestigatethe
time-reversal of time-homogeneous stationary diffusions and recall the most general conditions for the reversibility
of the diffusion property, which includes hypoelliptic and degenerate diffusions, and locally Lipschitz vector fields.
We decompose the drift into its time-reversible and irreversible parts, or equivalently, the generator into symmetric
and antisymmetric operators. Weshow theequivalence with adecomposition ofthe backward Kolmogorov equation
consideredinhypocoercivitytheory,andadecompositionoftheFokker-PlanckequationinGENERICform. Themain
resultshowsthatwhenthetime-irreversiblepartofthedriftisintherangeofthevolatilitymatrix(almosteverywhere)
theforwardandtime-reversedpathspacemeasuresoftheprocessaremutuallyequivalent,andevaluatestheentropy
production. Whenthisdoesnothold,themeasuresaremutuallysingularandtheentropyproductionisinfinite. We
verify these results using exact numerical simulations of linear diffusions. We illustrate the discrepancy between the
entropy production of non-linear diffusions and their numerical simulations in several examples and illustrate how
the entropy production can be used for accurate numerical simulation. Finally, we discuss the relationship between
time-irreversibilityandsamplingefficiency,andhowwecanmodifythedefinitionofentropyproductiontoscorehow
far a process is from being generalised reversible.
Keywords: measuring irreversibility; time-reversal; hypoelliptic; degenerate diffusion; Helmholtz decomposition;
numerical simulation; Langevin equation; stochastic differential equation; entropy production rate.
2.2 Introduction
The entropy production rate e is a central concept in statistical physics. In a nutshell, it is a measure of the time-
p
irreversibility of a stochastic process, that is how much random motion differs statistically speaking as one plays it
forward, or backward, in time.
At non-equilibrium steady-state, the e is quantified by the relative entropy H (a.k.a Kullback-Leibler divergence)
p
1
e = H[P |P¯ ]
p T [0,T] [0,T]
between the path-wise distributions of the forward and time-reversed processes in some time interval [0,T], denoted
by P ,P¯ , respectively.
[0,T] [0,T]
Physically, the e measures the minimal amount of energy needed, per unit of time, to maintain a system at non-
p
equilibrium steady-state. Equivalently, it quantifies the heat dissipated by a physical system at non-equilibrium
steady-state per unit of time [15, p. 86]. The second law of thermodynamics for open systems is the non-negativity
of the entropy production.
Thee playsacrucialroleinstochasticthermodynamics. Itisthecentralquantityintheso-calledGallavotti-Cohen
p
fluctuation theorem, which quantifies the probability of entropy decrease along stochastic trajectories [16–18]. More
recently, entropy production is at the heart of the so-called thermodynamic uncertainty relations, which provide
estimates of e from observations of the system [19]. The e is also an important tool in biophysics, as a measure
p p
of the metabolic cost of molecular processes, such as molecular motors [16], and it was shown empirically that brain
states associated with effortful activity correlated with a higher entropy production from neural activity [20].
18
In this chapter, we will be primarily concerned with the entropy production of diffusion processes, that is, solutions
of stochastic differential equations. Consider an Itô stochastic differential equation (SDE)
dx =b(x )dt+σ(x )dw
t t t t
with drift b : Rd → Rd and volatility σ : Rd → Rd×m, and w a standard Brownian motion on Rm, whose solution
t
is stationary at a probability measure µ with density ρ. A result known as the Helmholtz decomposition, which is
central in non-equilibrium statistical physics [3,21–23] but also in statistical sampling [24–27], tells us that we can
decomposethedriftintotime-reversibleandtime-irreversibleparts: b=b +b . Inparticular,b ρisthestationary
rev irr irr
probability current, as considered by Nelson [28]. Jiang and colleagues derived the entropy production rate for such
systems under the constraint that the coefficients of the SDE b,σ are globally Lipschitz, and the solution uniformly
elliptic (i.e., the diffusion matrix field D= 1σσ⊤ is uniformly positive definite). This takes the form of [15, Chapter
2
4]:
(cid:90)
e = b⊤D−1b ρ(x)dx.
p irr irr
Rd
Inthischapter,weextendtheirworkbycomputingtheentropyproductionforagreaterrangeofdiffusionprocesses,
which includes non-elliptic, hypoelliptic and degenerate diffusions, and SDEs driven by locally Lipschitz coefficients.
Non-ellipticdiffusionsaresolutionstoSDEswhosediffusionmatrixfieldD= 1σσ⊤isnotpositivedefiniteeverywhere;
2
thismeansthatthereareregionsofspaceinwhichtherandomfluctuationscannotdrivetheprocessineverypossible
direction. Depending on how the volatility interacts with the drift (i.e., Hörmander’s theorem [29, Theorem 1.3]),
solutionsinitialisedatapointmaystillhaveadensity—thehypoellipticcase—ornot—thedegeneratecase;prominent
examples are underdamped Langevin dynamics and deterministic dynamics, respectively. In our treatment, we only
assumethatthetime-reversalofadiffusionisadiffusion(thenecessaryandsufficientconditionsforwhichwerefirst
established by Millet, Nualart and Sanz [30]) and sufficient regularity to apply Girsanov’s theorem or the Stroock-
Varadhan support theorem.
This extension has become important since many processes that are commonplace in non-equilibrium statistical
physics or statistical machine learning are hypoelliptic. For instance, the underdamped and generalised Langevin
equations in phase space [3], which model the motion of a particle interacting with a heat bath, and which form
thebasisofefficientsamplingschemessuchasHamiltonianMonte-Carlo[26],or,stochasticgradientdescentindeep
neural networks [27], or, the linear diffusion process with the fastest convergence to stationary state [31], which
informs us of the properties of efficient samplers. Much research in statistical sampling has drawn the connection
betweentime-irreversibilityandsamplingefficiency[26,32–34],soitisinformativetounderstandtheamountoftime-
irreversibilityassociatedwiththemostefficientsamplers. Lastly,itisknownthatnumericallyintegratingadiffusion
processescanmodifytheamountofirreversibilitypresentintheoriginaldynamic[35]. Theentropyproductionrateis
thusanimportantindicatorofthefidelityofanumericalsimulation,andcanserveasaguidetodevelopingsampling
schemes that preserve the statistical properties of efficient (hypoelliptic) samplers.
The outline of the chapter and our contribution are detailed below.
2.2.1 Chapter outline and contribution
Section 2.3: Wegivevariouscharacterisationsandformulasforthee ofstationaryMarkovprocessesindiscrete
p
and continuous-time, and recall a crude but general recipe for numerical estimation.
Section 2.4: We investigate the time-reversal of time-homogeneous diffusions. We give the general conditions
under which the time-reversal of a time-homogeneous diffusion remains a diffusion, based on the results of Millet,
19
NualartandSanz[30]. WethenrecallhowthedriftvectorfieldofanSDEcanbedecomposedintotime-reversibleand
irreversible parts. We show that this decomposition is equivalent to a decomposition of the generator of the process
into symmetric and antisymmetric operators on a suitable function space. Then we show that this decomposition is
equivalenttotwootherfundamentaldecompositionsinthestudyoffarfromequilibriumsystems: thedecomposition
of the backward Kolmogorov equation considered in hypocoercivity theory [5,36] and the decomposition of the
Fokker-Planck equation considered in the GENERIC formalism [4,36].
Section 2.5: We compute the e of stationary diffusion processes under the condition that the time-reversal of
p
the diffusion remains a diffusion. We show that:
• Section 2.5.1: Ifb (x)∈Rangeσ(x),forµ-almosteveryx∈Rd1 (inparticularforellipticortime-reversible
irr
diffusions). Then the forward and backward path-space measures are mutually equivalent, in other words, the
sets of possible trajectories by forward and backward processes are equal—and the entropy production equals
e = (cid:82) b⊤D−b dµ,where·− denotestheMoore-Penrosematrixpseudo-inverse. SeeTheorems2.5.1,2.5.2for
p irr irr
details.
• Section 2.5.2: When the above does not hold, the forward and backward path-space measures are mutually
singular, in other words, there are trajectories that are taken by the forward process that cannot be taken by
the backward process—and vice-versa2. In particular, the entropy production rate is infinite e = +∞. See
p
Theorem 2.5.4 for details.
Section 2.6: We compute the e of various models such as the multivariate Ornstein-Uhlenbeck and the under-
p
damped Langevin process. We numerically simulate and verify the value of e when the coefficients are linear. We
p
then discuss how numerical discretisation can influence the value of e . As examples, we compute and compare the
p
e of Euler-Maruyama and BBK [37,38] discretisations of the underdamped Langevin process. We summarise the
p
usefulness of e as a measure of the accuracy of numerical schemes in preserving the time-irreversibility properties
p
of the underlying process, and give guidelines, in terms of e , for developing accurate simulations of underdamped
p
Langevin dynamics.
Section 2.7: We give a geometric interpretation of our main results and discuss future perspectives: what this
suggestsabouttherelationshipbetweentime-irreversibilityandmixinginthecontextofsamplingandoptimisation,
and how we could modify the definition—and computation—of e to quantify how a process is far from being time-
p
reversible up to a one-to-one transformation of its phase-space.
2.3 The e of stationary Markov processes
p
Inthissection,(x ) ,T >0isatime-homogeneousMarkovprocessonaPolishspaceX withalmostsurely(a.s.)
t t∈[0,T]
continuous trajectories.
Definition 2.3.1 (Time reversed process). The time reversed process (x¯ ) is defined as x¯ =x .
t t∈[0,T] t T−t
Notethatsincethefinalstateoftheforwardprocessistheinitialstateofthebackwardprocessthisdefinitionmakes
sense only on finite time intervals.
1µ-almost everywhere: This means that the statement holds with probability 1 when x is distributed according to the
probabilitymeasureµ.
2Precisely,twomeasuresaremutualsingularifandonlyiftheyarenotmutuallyequivalent.
20
We define (C([0,T],X),d ) as the space of X-valued continuous paths endowed with the supremum distance d ,
∞ ∞
defined as d (f,g)=sup d(f(t),g(t)), where d is a choice of distance on the Polish space X. Naturally, when
∞ t∈[0,T]
we later specialise to X =Rd, the supremum distance will be given by the L∞-norm ∥·∥ .
∞
Definition 2.3.2 (Path space measure). Each Markov process (x ) with a.s. continuous trajectories defines
t 0≤t≤T
probability measure P on the canonical path space (C([0,T],X),B), where B is the Borel sigma-algebra asso-
[0,T]
ciated with the supremum distance. This probability measure determines the probability of the process to take any
(Borel set of) paths.
Remark 2.3.3 (Cadlag Markov processes). All definitions and results in this section hold more generally for Markov
processes with cadlag paths (i.e., right continuous with left limits), simply replacing the canonical path-space
(C([0,T],X),d )withtheSkorokhodspace. Werestrictourselvestoprocesseswithcontinuouspathsforsimplicity.
∞
Definition 2.3.4 (Restrictiontoasub-intervaloftime). GivenapathspacemeasureP andtimesa<b∈[0,T],
[0,T]
we define P to be the path space measure describing (x ) . This is the restriction of P to the sub
[a,b] t t∈[a,b] [0,T]
(cid:110) (cid:111)
sigma-algebra B := A∈B: A| ∈Borel sigma-algebra on(C([a,b],X),d ) .
[a,b] [a,b] ∞
Let P be the path space measure of the Markov process x and P¯ be that of its time-reversal x¯ , respectively. We
t t
can measure the statistical difference between the forward and time-reversed processes at time τ ∈ [0,T] with the
entropy production rate
lim 1 H (cid:2) P ,P¯ (cid:3) , (2.1)
ε↓0 ε [τ,τ+ε] [τ,τ+ε]
where H is the relative entropy (a.k.a. Kullback-Leibler divergence). This measures the rate at which the forward
and backward path space measures differ in the relative entropy sense at time τ.
The following result [15, Theorem 2.2.4] (see also [39, Theorem 10.4]) shows that the limit exists in stationary and
time-homogeneous Markov processes. Obviously, the limit is independent of τ in this case.
Theorem 2.3.5. Supposethat(x ) isastationarytime-homogeneousMarkovprocessonaPolishspaceX with
t t∈[0,T]
continuous sample paths. Stationarity implies that we can set the time-horizon T > 0 of the process to arbitrarily
large values. Then the quantity
1 H (cid:2) P |P¯ (cid:3) for all τ ∈[0,+∞),t∈(0,+∞)
t [τ,τ+t] [τ,τ+t]
is a constant ∈[0,+∞].
This yields the following general definition of entropy production rate for stationary Markov processes:
Definition 2.3.6 (Entropy production rate of a stationary Markov process). Let (x ) be a stationary time-
t t∈[0,T]
homogeneous Markov process. Stationarity implies that we can set the time-horizon T > 0 to be arbitrarily large.
For such processes, the entropy production rate is a constant e ∈[0,+∞] defined as
p
e := 1 H (cid:2) P |P¯ (cid:3) (2.2)
p t [0,t] [0,t]
for any t∈(0,+∞). e scores the amount to which the forward and time-reversed processes differ per unit of time.
p
In particular, Te is the total entropy production in a time interval of length T. Note that, in the literature, the e
p p
is often defined as e =lim 1H (cid:2) P |P¯ (cid:3), e.g., [15, Definition 4.1.1]; this is just (2.2) in the limit of large
p t→+∞ t [0,t] [0,t]
t. However,Theorem2.3.5showedusthat(2.2)isconstantw.r.t. t∈(0,+∞)sowedonotneedtorestrictourselves
to defining the e as (2.2) in the limit of large t. This added generality will be very helpful to compute e later, by
p p
exploiting the fact that (2.2) is often more easily analysed in the regime of finite or small t.
21
Remark 2.3.7 (Physical relevance of Definition 2.3.6). In some stationary processes (e.g., Hamiltonian systems),
physicistsdefineentropyproductionasDefinition2.3.6withanadditionaloperatorappliedtothepathspacemeasure
of the time-reversed process; that is,
egen,θ :=lim 1 H (cid:2) P ,θ P¯ (cid:3) , (2.3)
p ε↓0 ε [0,ε] # [0,ε]
whereθ isthepushforwardoperatorassociatedtoaninvolutionofphase-spaceθ (e.g.,themomentumflip[40–42])
#
that leaves the stationary distribution invariant3. In this article, we will refer to (2.2) as entropy production and
to (2.3) as generalised entropy production, and proceed to derive general results for (2.2). The results we derive are
informative of the process and applicable independently of whether (2.2) is the physically meaningful definition of
entropy production; yet, physicists looking to interpret these results should bear in mind that they are physically
informativeaboutentropyproductioninsofarasDefinition2.3.6isphysicallymeaningfulforthesystemathand. We
will briefly revisit generalised entropy production in the discussion (Section 2.7.2).
Proposition 2.3.8. Let (x ) be a time-homogeneous Markov process on a Polish space X, stationary at the
t t∈[0,T]
probability measure µ. Then the entropy production rate equals
e = 1 E (cid:2) H (cid:2) Px |P¯x (cid:3)(cid:3)
p t x∼µ [0,t] [0,t]
for any t∈(0,+∞).
A proof is provided in Section 2.8.1.
Notation 2.3.9. By Px we mean the path space measure of the process initialised (possibly out of stationarity) at a
deterministic initial condition x =x∈X.
0
Proposition 2.3.10 (e in terms of transition kernels). Let (x ) be a time-homogeneous Markov process on
p t t∈[0,T]
a Polish space X, stationary at the probability measure µ. Denote by p (dy,x) the transition kernels of the Markov
t
semigroup, and by p¯(dy,x) those of the time-reversed process. Then the entropy production rate equals
t
1
e =lim E [H[p (·,x)|p¯ (·,x)]].
p ε↓0 ε x∼µ ε ε
Thefactthatthetime-reversedprocesspossessestransitionkernelsholdsasitisalsoastationaryMarkovprocess[15,
p. 113]. A proof of Proposition 2.3.10 is provided in Section 2.8.1.
2.3.1 The e of numerical simulations
p
Proposition 2.3.10 entails a formula for the e of Markov processes in discrete time:
p
Definition 2.3.11. The entropy production rate of a discrete-time Markov process with time-step ε equals
1 (cid:90) p (y,x)
eNS(ε)= E p (y,x)log ε dy, (2.4)
p ε x∼µ˜ ε p (x,y)
ε
where µ˜ is the invariant measure of the process.
This definition is useful, for example, to quantify the entropy production of numerical simulations of a stochastic
process[35]. Inparticular,itsuggestsasimplenumericalestimatoroftheentropyproductionratefornumericalsim-
ulations(atstationarity). Considerasmallδ (e.g.,δ isthetime-stepofthenumericaldiscretisation). Givensamples
3Thisgeneraliseddefinitionofentropyproductionistakenasalimitofε↓0analogouslyto(2.1)tocapturethefactthat
we are modelling a rate. We cannot, a priori state that the expression is constant for any ε∈(0,+∞), as in Definition 2.3.6,
sincewedonotknowwhetheraresultanalogoustoTheorem2.3.5holdsinthiscase.
22
from the process at δ time intervals, discretise the state-space into a finite partition U ,...,U , and approximate
1 n
P and P¯ by the empirical transition probabilities p between U ,U from time 0 to δ.
[0,δ] [0,δ] i→j i j
eNS = lim 1 H (cid:2) P |P¯ (cid:3) ≈ 1 H (cid:2) P |P¯ (cid:3) ≈ 1(cid:88) p log p i→j.
p ε→0ε [0,ε] [0,ε] δ [0,δ] [0,δ] δ i→j p
j→i
i,j
Note that this method measures the entropy production rate of the numerical discretisation as opposed to that of
the continuous process. This typically produces results close to e , but does not necessarily converge to e in the
p p
continuum limit δ →0 of the numerical discretisation. Indeed [35] showed that numerical discretisations can break
detailedbalance,sothatthecontinuumlimitofthenumericaldiscretisationcandifferfromtheinitialprocess. Thus
oneshouldchoosenumericalschemescarefullywhenpreservingtheentropyproductionrateofaprocessisimportant.
We will return to this in Section 2.6.
2.4 Time reversal of stationary diffusions
We now specialise to diffusion processes in Rd. These are Markov processes with an infinitessimal generator that
is a second order linear operator without a constant part [43, Definition 1.11.1], which entails almost surely (a.s.)
continuoussamplepaths. Conveniently,diffusionprocessesareusuallyexpressibleassolutionstostochasticdifferential
equations. From now on, we consider an Itô stochastic differential equation
dx =b(x )dt+σ(x )dw (2.5)
t t t t
with drift b:Rd →Rd and volatility σ:Rd →Rd×m, and w a standard Brownian motion on Rm.
t
Notation 2.4.1. Let D = σσ⊤/2 ∈ Rd×d be the diffusion tensor. Denote by ∥·∥ the Euclidean distance, and, for
matrices
d n
∥σ∥2 := (cid:88)(cid:88) |σ |2.
ij
i=1j=1
Throughout, ∇ and ∇· are the gradient and the divergence in the distributional sense. We operationally define the
divergence of a matrix field Q : Rd → Rd×d by (∇·Q) := (cid:80)d ∂ Q for 0 ≤ i ≤ d. We will denote by µ the
i j=1 j ij
stationary probability measure of the process x and by ρ its density with respect to the Lebesgue measure, i.e.,
t
µ(dx)=ρ(x)dx (assuming they exist).
2.4.1 On the time-reversibility of the diffusion property
There is a substantial literature studying the time-reversal of diffusion processes. In general, the time-reversal of a
diffusion need not be a diffusion [30], but Haussman and Pardoux showed that the diffusion property is preserved
under some mild regularity conditions on the diffusion process [44]. A few years later Millet, Nualart, Sanz derived
necessaryandsufficientconditionsforthetime-reversalofadiffusiontobeadiffusion[30,Theorem2.2&p. 220]. We
providetheseconditionshere,withaproofofadifferentnaturethatexploitstheexistenceofastationarydistribution.
Lemma 2.4.2 (Conditionsforthereversibilityofthediffusionproperty). LetanItôSDE (2.5)withlocallybounded,
Lebesgue measurable coefficients b:Rd →Rd,σ :Rd →Rd×m. Consider a strong solution (x ) , i.e., a process
t t∈[0,T]
23
satisfying
(cid:90) t (cid:90) t
x =x + b(x )ds+ σ(x )dw ,
t 0 s s s
0 0
and assume that it is stationary with respect to a probability measure µ with density ρ. Consider the time-reversed
stationary process (x¯ ) . Then, the following are equivalent:
t t∈[0,T]
• (x¯ ) is a Markov diffusion process.
t t∈[0,T]
• The distributional derivative ∇·(Dρ) is a function, which is then necessarily in L1 (Rd,Rd).
loc
A proof is provided in Section 2.8.2.
2.4.2 Setup for the time-reversal of diffusions
From now on, we will work under the assumption that the time-reversal of the diffusion is a diffusion. We assume
that:
Assumption 2.4.3. 1. The coefficients of the SDE (2.5) b,σ are locally Lipschitz continuous. In other words,
∀x∈Rd,∃r>0,k>0 s.t. ∀y∈Rd :
∥x−y∥<r⇒∥b(x)−b(y)∥+∥σ(x)−σ(y)∥≤k∥x−y∥,
2. The solution x to (2.5) is defined globally up to time T > 0. Sufficient conditions in terms of the drift and
t
volatility for Itô SDEs are given in Theorem [45, Theorem 3.1.1].
Assumption2.4.3.1ensurestheexistenceanduniquenessofstrongsolutionslocallyintime[46,ChapterIVTheorem
3.1], while Assumption 2.4.3.2 ensures that this solution exists globally in time (i.e., non-explosiveness). Altogether,
Assumption 2.4.3 ensures that the SDE (2.5) unambiguously defines a diffusion process.
Furthermore, we assume some regularity on the stationary distribution of the process.
Assumption 2.4.4. 1. (x ) is stationary at a probability distribution µ, with density ρ with respect to the
t t∈[0,T]
Lebesgue measure, i.e., µ(dx)=ρ(x)dx.
Then,ρ∈L1(Rd)and,underlocalboundednessofthediffusiontensor(e.g.,Assumption2.4.3),Dρ∈L1 (Rd,Rd×d).
loc
Thus, we can define the distributional derivative ∇·(Dρ). We assume that:
2. ∇·(Dρ)∈L1 (Rd,Rd), i.e., the distributional derivative ∇·(Dρ) is a function.
loc
Assumption2.4.4ensuresthatthetime-reversalofthediffusionprocessremainsadiffusionprocess,asdemonstrated
in Lemma 2.4.2.
2.4.3 The time reversed diffusion
Nowthatweknowsufficientandnecessaryconditionsforthetime-reversibilityofthediffusionproperty,weproceedto
identifythedriftandvolatilityofthetime-reverseddiffusion. ThiswasoriginallydonebyHausmannandPardoux[44,
Theorem2.1],andthenbyMillet,Nualart,Sanzunderslightlydifferentconditions[30,Theorems2.3or3.3]. Inspired
by these, we provide a different proof, which applies to stationary diffusions with locally Lipschitz coefficients.
24
Theorem 2.4.5 (Characterisation of time-reversal of diffusion). Let an Itô SDE (2.5) with coefficients satisfying
Assumption2.4.3. Assumethatthesolution(x ) isstationarywithrespecttoadensityρsatisfyingAssumption
t t∈[0,T]
2.4.4. Then, the time-reversed process (x¯ ) is a Markov diffusion process, stationary at the density ρ, with drift
t t∈[0,T]

−b(x)+2ρ−1∇·(Dρ)(x) when ρ(x)>0,
¯b(x)= (2.6)
−b(x) when ρ(x)=0.
and diffusion D¯ = D. Furthermore, any such stationary diffusion process induces the path space measure of the
time-reversed process P¯ .
[0,T]
A proof is provided in Section 2.8.2. Similar time-reversal theorems exist in various settings: for more singular
coefficients on the torus [47], under (entropic) regularity conditions on the forward path space measure [48,49], for
infinite-dimensional diffusions [50–52], for diffusions on open time-intervals [53], or with boundary conditions [54].
Furthermore, we did not specify the Brownian motion driving the time-reversed diffusion but this one was identified
in [55, Remark 2.5].
We illustrate the time-reversal of diffusions with a well-known example:
Example 2.4.6 (Time reversal of underdamped Langevin dynamics). Underdamped Langevin dynamics is an im-
portant model in statistical physics and sampling [3,38,56]. Consider a Hamiltonian H(q,p) function of positions
q∈Rn and momenta p∈Rn. We assume that the Hamiltonian has the form
1
H(q,p)=V(q)+ p⊤M−1p,
2
for some smooth potential function V :Rd →R and diagonal mass matrix M ∈Rd×d. The underdamped Langevin
process is given by the solution to the SDE [38, eq 2.41]

dq
t
=M−1p
t
dt
(2.7)
dp =−∇V (q )dt−γM−1p dt+ (cid:112) 2γβ−1dw
t t t t
for some friction, and inverse temperature coefficients γ,β > 0. The stationary density, assuming it exists, is the
canonical density [38, Section 2.2.3.1]
ρ(q,p)∝e−βH(q,p) =e−βV(q)−β
2
p⊤M−1p. (2.8)
Thus, the time-reversal of the stationary process (Theorem 2.4.5) is a weak solution to the SDE

dq¯
t
=−M−1p¯
t
dt
dp¯ =∇V (q¯)dt−γM−1p¯dt+ (cid:112) 2γβ−1dw .
t t t t
Letting pˆ =−p¯, the tuple (q¯,pˆ) solves the same SDE as (q ,p ) but with a different Brownian motion wˆ
t t t t t t t

dq¯
t
=M−1pˆ
t
dt
dpˆ =−∇V (q¯)dt−γM−1pˆdt+ (cid:112) 2γβ−1dwˆ .
t t t t
Since path space measures are agnostic to changes in the Brownian motion, this leads to the statement that time-
reversal equals momentum reversal in underdamped Langevin dynamics (with equality in law, i.e., in the sense of
path space measures)
(q¯,p¯) =(q¯,−pˆ) =ℓ (q ,−p ) .
t t t∈[0,T] t t t∈[0,T] t t t∈[0,T]
25
In other words, we have P = θ P¯ where θ(q,p) = (q,−p) is the momentum flip transformation in phase
[0,T] # [0,T]
space.
2.4.4 The Helmholtz decomposition
Armed with the time-reversal of diffusions we proceed to decompose the SDE into its time-reversible and time-
irreversible components. This decomposition is called the Helmholtz decomposition because it can be obtained
geometricallybydecomposingthedriftvectorfieldbintohorizontalb (time-irreversible,conservative)andvertical
irr
b (time-reversible, non-conservative) components with respect to the stationary density [24]. These vector fields
rev
are called horizontal and vertical, respectively, because the first flows along the contours of the stationary density,
whilethesecondascendsthelandscapeofthestationarydensity(seetheschematicintheupper-leftpanelofFigure
2.1). For our purposes, we provide a self-contained, non-geometric proof of the Helmholtz decomposition in Section
2.8.2.
Proposition2.4.7(Helmholtzdecomposition). Considerthesolution(x ) oftheItôSDE (2.5)withcoefficients
t t∈[0,T]
satisfying Assumption 2.4.3. Let a probability density ρ satisfying ∇·(Dρ) ∈ L1 (Rd,Rd). Then, the following are
loc
equivalent:
1. The density ρ is stationary for (x ) .
t t∈[0,T]
2. We can write the drift as
b=b +b
rev irr

D∇logρ+∇·D if ρ(x)>0
b = (2.9)
rev
0 if ρ(x)=0
∇·(b ρ)=0.
irr
Furthermore, b is time-reversible, while b is time-irreversible, i.e.,
rev irr
b=b +b , ¯b=b −b .
rev irr rev irr
The fundamental importance of the Helmholtz decomposition was originally recognised in the context of non-
equilibrium thermodynamics by Graham in 1977 [21], but its inception in this field dates from much earlier: for
instance, the divergence free vector field b ρ is precisely the stationary probability current or flux introduced by
irr
Nelsonin1967[28]. Morerecently,thedecompositionhasrecurrentlybeenusedinnon-equilibriumstatisticalphysics
[3,9,22,23,57–59], and in statistical machine learning as the basis of Monte-Carlo sampling schemes [3,24,25,60].
Remark 2.4.8 (Probabilistic reversibility). Here, time-reversible means reversibility in a probabilistic sense; that is,
invarianceundertimereversal,alsoknownasdetailedbalance[15,Proposition3.3.4]. Probabilisticreversibilityoften
leads to the non-conversation of quantities like the potential −logρ(x). For example, the identity ∇·(b ρ) = 0
irr
implies that the time-irreversible drift b flows along the contours of the probability density; in other words, the
irr
probabilitydensityandthepotentialareconservedalongthetime-irreversiblevectorfield. Incontrast,noneofthem
are conserved when flowing along the time-reversible vector field b . See Figure 2.1 for an illustration.
rev
Remark 2.4.9 (Stratonovich formulation of Helmholtz decomposition). There exists an equivalent decomposition of
the drift of Stratonovich SDEs into time-reversible and irreversible parts. Assuming that σ is differentiable, we can
rewrite the Itô SDE (2.5) into its equivalent Stratonovich SDE
dx =bs(x )dt+σ(x )◦dw .
t t t t
26
Figure2.1: Helmholtz decomposition. TheupperleftpanelillustratestheHelmholtzdecompositionofthedriftintotime-
reversible and time-irreversible parts: the time-reversible part of the drift flows towards the peak of the stationary density,
whilethetime-irreversiblepartflowsalongitscontours. Theupperrightpanelshowsasampletrajectoryofatwo-dimensional
diffusion process stationary at a Gaussian distribution. The lower panels plot sample paths of the time-reversible (lower left)
and time-irreversible (lower right) parts of the dynamic. Purely conservative dynamics (lower right) are reminiscent of the
trajectories of massive bodies (e.g., planets) whose random fluctuations are negligible, as in Newtonian mechanics. Together,
thelowerpanelsillustratetime-irreversibility: Ifweweretoreversetime, thetrajectoriesofthetime-reversibleprocesswould
bestatisticallyidentical,whilethetrajectoriesofthetime-irreversibleprocessbedistinguishablebyflow,say,clockwiseinstead
of counterclockwise. The full process (upper right) is a combination of both time-reversible and time-irreversible dynamics.
Thetime-irreversiblepartdefinesanon-equilibriumsteady-stateandinducesitscharacteristicwandering,cyclicbehaviour.
where bs =b−ι and ι is the Itô to Stratonovich correction [3, eq. 3.31]. Note that the correction is time-reversible.
It follows that
bs =b , (2.10)
irr irr
and for x s.t. ρ(x)>0,
1
bs (x)=(b −ι)(x)=D∇logρ(x)+ σ∇·σ⊤(x).
rev rev 2
In particular, for x s.t. ρ(x)>0,
bs(x)∈Rangeσ(x) ⇐⇒ bs (x)∈Rangeσ(x) (2.11)
irr
as bs (x) ∈ Rangeσ(x). For diffusions driven by additive noise, Itô and Stratonovich formulations coincide bs = b.
rev
27
Thus, we conclude

σ is constant⇒b(x)=
D∇logρ(x)+b
irr
(x) if ρ(x)>0
b (x) if ρ(x)=0
irr
⇒(b(x)∈Rangeσ(x) ⇐⇒ b (x)∈Rangeσ(x)) (2.12)
irr
These identities will be useful to compute the entropy production rate later on.
The time-irreversible part of the drift often takes a simple form:
Proposition 2.4.10 (Characterisation of time-irreversible drift). Consider a smooth, strictly positive probability
density ρ and an arbitrary smooth vector field b . Then
irr
∇·(b ρ)=0 ⇐⇒ b =Q∇logρ+∇·Q
irr irr
where Q=−Q⊤ is a smooth antisymmetric matrix field.
A proof is provided in Section 2.8.2. We conclude this section by unpacking the Helmholtz decomposition of under-
damped Langevin dynamics.
Example 2.4.11 (Helmholtz decomposition of underdamped Langevin). Following Example 2.4.6, it is straightfor-
ward to decompose underdamped Langevin dynamics into its time-irreversible and time-reversible parts. Indeed we
just need to identify the parts of the drift whose sign changes, and remains invariant, under time reversal:
(cid:34) (cid:35) (cid:34) (cid:35)
0 M−1p
b (q,p)= , b (q,p)= .
rev −γM−1p irr −∇V (q)
We can rewrite these in canonical form recalling the gradient of the stationary density (2.8)
b (q,p)=D∇logρ(q,p), b (q,p)=Q∇logρ(q,p)
rev irr
(cid:34) (cid:35) (cid:34) (cid:35) (cid:34) (cid:35)
∇V(q) 0 0 0 −Id
∇logρ(q,p)=−β , D= , Q=β−1 n .
M−1p 0 γβ−1Id Id 0
n n
Clearly, the time-irreversible part of the process d[q ,p ]=b (q ,p )dt is a Hamiltonian dynamic that preserves the
t t irr t t
energy (i.e., the Hamiltonian), while the time-reversible part is a reversible Ornstein-Uhlenbeck process. Example
trajectories of the time-irreversible trajectory are exemplified in Figure 2.1 (bottom right).
2.4.5 Multiple perspectives on the Helmholtz decomposition
The Helmholtz decomposition is a cornerstone of the theory of diffusion processes. In addition to being a geometric
decompositionofthedrift[24],itis,equivalently,atime-reversibleandirreversibledecompositionoftheSDE(2.13),
of the generator and the (backward and forward) Kolmogorov PDEs describing the process. Briefly, the Helmholtz
decompositionisequivalenttoafunctionalanalyticdecompositionofthegeneratorintosymmetricandantisymmetric
operatorsinasuitablefunctionspace. ThiscorrespondstoadecompositionofthebackwardKolmogorovequation—
whichdeterminestheevolutionof(macroscopic)observablesundertheprocess—intoaconservativeandadissipative
flow. This decomposition can be used as a starting point to quantify the speed of convergence of the process to its
stationarystatefromarbitraryinitialconditionsusinghypocoercivitytheory[5]. ThesamegoesfortheFokker-Planck
28
equation,whichcanbedecomposedintoadissipativegradientflow,andaflowthatisconservativeinvirtueofbeing
orthogonal to the gradient flow in a suitable function space. This casts the Fokker-Planck equation in GENERIC
form (General Equations for Non-Equilibrium Reversible-Irreversible Coupling), a general framework for analysing
dynamical systems arising in non-equilibrium statistical physics [4,36].
Below we outline these different equivalent perspectives. This section is provided for independent interest but will
not be used to derive our main results on entropy production; you may conveniently skip it on a first reading.
Helmholtz decomposition of the SDE
Proposition2.4.7isequivalenttoaHelmholtzdecompositionoftheSDEintoitstime-reversibleandtime-irreversible
parts, noting that the volatility is invariant under time-reversal (Theorem 2.4.5)
dx = b (x )dt +b (x )dt+σ(x )dw . (2.13)
t irr t rev t t t
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Time-irreversible Time-reversible
Figure 2.1 illustrates this decomposition with simulations.
Helmholtz decomposition of the infinitesimal generator
Followingthedifferentialgeometricviewpoint,adeterministicflow—namely,avectorfieldb—isgivenbyafirstorder
differential operator b·∇. Similarly, a stochastic flow given by a diffusion—namely, a vector field b and a diffusion
tensor D—is characterised by a second order differential operator
L=b·∇+D∇·∇, (2.14)
known as the generator. Note that the first order part is the deterministic flow given by the drift while the second
order part is the stochastic flow determined by the diffusion. More precisely, the generator of a diffusion process
solving the SDE (2.5) under Assumptions 2.4.3 and 2.4.4 is a linear, unbounded operator defined as
1
L:C∞(Rd)⊂DomL⊂Lp(Rd)→Lp(Rd),1≤p≤∞, Lf(y):=lim E[f(x )−f(y)|x =y], (2.15)
c µ µ t↓0 t t 0
(cid:26) (cid:27)
f ∈DomL= f ∈Lp(Rd)|∃g∈Lp(Rd) s.t. 1 E[f(x )−f(y)|x =y]− t − ↓ → 0 g(y) in Lp(Rd)
µ µ t t 0 µ
DiffusionsareamongthesimplestandmostcanonicalMarkovprocessesbecausetheyarecharacterisedbygenerators
thataresecondorderdifferentialoperators(withnoconstantpart). Indeed,startingfrom(2.15),aquickcomputation
using Itô’s formula yields (2.14).
Recallthatwehaveadualitypairing⟨·,·⟩ :Lp′ (Rd)⊗Lp(Rd)→Rdefinedby⟨f,g⟩ = (cid:82) fgdµ,where 1 +1 =1.
µ µ µ µ Rd p′ p
A well-known fact is that the generator L¯ of the time-reversed diffusion is the adjoint of the generator under the
above duality pairing [61,62], [15, Thm 4.3.2]. The adjoint L¯ is implicitly defined by the relation
⟨f,Lg⟩ =⟨L¯f,g⟩ ,∀f ∈DomL¯,g∈DomL,
µ µ
DomL¯ ={f ∈L1(Rd)|∃h∈L1(Rd),∀g∈DomL:⟨f,Lg⟩ =⟨h,g⟩ }.
µ µ µ µ
(Theconceptofadjointgeneralisesthetransposeofamatrixinlinearalgebratooperatorsonfunctionspaces). The
proof of Lemma 2.4.2 explicitly computes the adjoint and shows that it is a linear operator L¯ : L1(Rd) → L1(Rd)
µ µ
29
which equals
L¯f =−b·∇f +2ρ−1∇·(Dρ)·∇f +D∇·∇f.
Notice how the first order part of the adjoint generator is the drift of the time-reversed diffusion, while the second
order part is its diffusion, as expected (cf. Theorem 2.4.5).
Much like we derived the Helmholtz decomposition of the drift by identifying the time-reversible and irreversible
parts (see the proof of Proposition 2.4.7), we proceed analogously at the level of the generator. Indeed, just as any
matrix can be decomposed into a sum of antisymmetric and symmetric matrices, we may decompose the generator
into a sum of antisymmetric and symmetric operators
L=A+S, A:= (cid:0) L−L¯(cid:1) /2, S:= (cid:0) L+L¯(cid:1) /2, DomA=DomS=DomL∩DomL¯. (2.16)
By its analogous construction, this decomposition coincides with the Helmholtz decomposition; indeed, the sym-
metric operator recovers the time-reversible part of the dynamic while the antisymmetric operator recovers the
time-irreversible part. In a nutshell, the Helmholtz decomposition of the generator is as follows
L=A+S, A=b ·∇ S=b ·∇+D∇·∇,
irr rev
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Time-irreversible Time-reversible
wherethesummandsaresymmetricandantisymmetricoperatorsbecausetheybehaveaccordinglyundertheduality
pairing:
⟨Af,g⟩ =−⟨f,Ag⟩ , ∀f,g∈DomA, ⟨Sf,g⟩ =⟨f,Sg⟩ , ∀f,g∈DomS.
µ µ µ µ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Antisymmetric Symmetric
Notingthat−Sisapositivesemi-definiteoperator,wecangoslightlyfurtheranddecomposeitintoitssquareroots.
To summarise:
Proposition 2.4.12. We can rewrite the generator of the diffusion process as L = A−Σ∗Σ where A is the an-
tisymmetric part of the generator, and −Σ∗Σ is the symmetric part, as defined in (2.16). Here ·∗ denotes the
adjoint with respect to the duality pairing ⟨·,·⟩ . The operators have the following functional forms: Af =b ·∇f,
√ √ µ irr
2Σf =σ⊤∇f, 2Σ∗g=−∇logρ·σg−∇·(σg).
A proof is provided in Section 2.8.2.
Helmholtz decomposition of the backward Kolmogorov equation
We say that a real-valued function over the state-space of the process f :Rd →R is an observable. Intuitively, this
isamacroscopicquantitythatcanbemeasuredorobservedinaphysicalprocess(e.g.,energyorpressure)whenthe
(microscopic) process is not easily accessible. The evolution of an observable f given that the process is prepared at
a deterministic initial condition is given by f (x)=E[f(x )|x =x].
t t 0
Thebackward Kolmogorov equation isafundamentalequationdescribingaMarkovprocess,asitencodesthemotion
of observables
∂ f =Lf , f =f ∈DomL.
t t t 0
In other words, f =E[f(x )|x =x] solves the equation. This highlights the central importance of the generator as
t t 0
providing a concise summary of the process.
30
The Helmholtz decomposition entails a decomposition of the backward Kolmogorov equation
∂ u =Af +Sf =(A−Σ∗Σ)f , f =f ∈DomL. (2.17)
t t t t t 0
This decomposition is appealing, as it allows us to further characterise the contributions of the time-reversible and
irreversiblepartsofthedynamic. Alongthetime-irreversiblepartofthebackwardKolmogorovequation∂ f =Af ,
t t t
theL2(Rd)-norm∥·∥ isconserved. Indeed,sinceAisantisymmetric,⟨Af,f⟩ =0foreveryf ∈DomA,andhence
µ µ µ
∂ ∥f ∥2 =2⟨Af ,f ⟩ =0.
t t µ t t µ
On the other hand, along the time-reversible part of the backward Kolmogorov equation generated by −Σ∗Σ, the
L2(Rd)-norm is dissipated:
µ
∂ ∥f ∥2 =−2⟨Σ∗Σf ,f ⟩ =−2∥Σf ∥2 ≤0.
t t µ t t µ t µ
This offers another perspective on the fact that the time-irreversible part of the dynamic is conservative, while the
time-reversible part is dissipative—of the L2(Rd)-norm.
µ
Beyond this, hypocoercivity theory allows us to analyse the backward Kolmogorov equation, once one has written
itsHelmholtzdecomposition. Hypocoercivityisafunctionalanalytictheorydevelopedtoanalyseabstractevolution
equationsoftheform(2.17),originallydevisedtosystematicallystudythespeedofconvergencetostationarystateof
kinetic diffusion processes like the underdamped Langevin dynamics and the Boltzmann equation. As an important
result, the theory provides sufficient conditions on the operators A,Σ to ensure an exponentially fast convergence of
thebackwardKolmogorovequationtoafixedpoint[5,Theorems18&24]. Dually,theseconvergenceratesquantify
the speed of convergence of the process to its stationary density from a given initial condition.
GENERIC decomposition of the Fokker-Planck equation
This perspective can also be examined directly from the Fokker-Planck equation. The Fokker-Planck equation is
another fundamental equation describing a diffusion process: it encodes the evolution of the density of the process
overtime(whenitexists). TheFokker-PlanckequationistheL2(Rd)-dualtothebackwardKolmogorovequation. It
reads
∂ ρ =L′ρ =∇·(−bρ +∇·(Dρ )),
t t t t t
where L′ is the adjoint of the generator with respect to the standard duality pairing ⟨·,·⟩; in other words ⟨L′f,g⟩=
⟨f,Lg⟩ where ⟨f,g⟩= (cid:82) fg(x)dx.
Rd
The Helmholtz decomposition implies a decomposition of the Fokker-Planck equation into two terms: assuming for
now that ρ ,ρ>0 (e.g., if the diffusion is elliptic)
t
∂ ρ =∇·(−b ρ )+∇·(−b ρ +∇·(Dρ ))
t t irr t rev t t
=∇·(−b irr ρ t )+∇·(−ρ t ρ−1∇·(Dρ)+∇·(Dρ t )) (2.18)
(cid:18) (cid:19)
ρ
=∇·(−b ρ )+∇· ρ D∇log t .
irr t t ρ
We will see that this decomposition casts the Fokker-Planck equation in pre-GENERIC form.
GENERIC (General Equations for Non-Equilibrium Reversible-Irreversible Coupling) is an important theory for
analysing dynamical systems arising in non-equilibrium statistical physics like the Fokker-Planck equation. The
framework rose to prominence through the seminal work of Ottinger [4] and was later developed by the applied
31
physics and engineering communities. Only recently, the framework developed into a rigorous mathematical theory.
We refer to [36] for mathematical details. The following Proposition shows how we can rewrite the Fokker-Planck
equation in pre-GENERIC form:
∂ ρ = W(ρ ) −M (dH[ρ |ρ]), (2.19)
t t t ρt t
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
time-irreversible time-reversible
Proposition 2.4.13 (GENERICdecompositionoftheFokker-Planckequation). The Fokker-Planck equation (2.18)
is in pre-GENERIC form (2.19), with
(cid:18) (cid:19)
ρ
W(ρ )=∇·(−b ρ ), −M (dH[ρ |ρ])=∇· ρ D∇log t ,
t irr t ρt t t ρ
ρ
M (ξ)=Σ′(ρ Σξ)=−∇·(ρ D∇ξ), dH[ρ |ρ]=log t +1,
ρt t t t ρ
where H[· | ·] is the relative entropy, ·′ denotes the adjoint under the standard duality pairing ⟨·,·⟩, d is the Fréchet
derivative in L2(Rd), and W,M satisfy the following relations:
ρt
• Orthogonality: ⟨W(ρ ),dH[ρ |ρ]⟩=0,
t t
• Semi-positive definiteness: ⟨M (h),g⟩=⟨h,M (g)⟩, and ⟨M (g),g⟩≥0.
ρt ρt ρt
A proof is provided in Section 2.8.2.
Writing the Fokker-Planck equation in pre-GENERIC form (2.19) explicits the contributions of the time-reversible
and time-irreversible parts at the level of density dynamics. Indeed, the relative entropy functional H[ρ | ρ] is
t
conserved along the time-irreversible part of the Fokker-Planck equation ∂ ρ =W(ρ )
t t t
dH[ρ |ρ]
t =⟨∂ ρ ,dH[ρ |ρ]⟩=⟨W(ρ ),dH[ρ |ρ]⟩=0.
dt t t t t t
Contrariwise, the relative entropy is dissipated along the time-reversible part of the equation
dH[ρ |ρ]
t =⟨∂ ρ ,dH[ρ |ρ]⟩=−⟨M (dH[ρ |ρ]),dH[ρ |ρ]⟩≤0.
dt t t t ρt t t
Aggregating these results, we obtain the well-known fact that the relative entropy with respect to the stationary
density is a Lyapunov function of the Fokker-Planck equation; a result sometimes known as de Bruijn’s identity or
Boltzmann’s H-theorem [63, Proposition 1.1].
2.5 The e of stationary diffusions
p
We are now ready to investigate the entropy production of stationary diffusions. First, we give sufficient conditions
guaranteeingthemutualabsolutecontinuityoftheforwardandtime-reversedpathspacemeasuresandcomputethe
entropy production rate. Second, we demonstrate that when these conditions fail the entropy production is infinite.
2.5.1 Regular case
Theorem 2.5.1. Let an Itô SDE (2.5) with coefficients satisfying Assumption 2.4.3. Assume that the solution
(x ) is stationary with respect to a density ρ satisfying Assumption 2.4.4. Denote by b the time-irreversible
t t∈[0,T] irr
32
Figure2.2: Entropy production as a function of time-irreversible drift. Thisfigureillustratesthebehaviourofsample
paths and the entropy production rate as one scales the irreversible drift birr by a parameter θ. The underlying process is a
two-dimensionalOrnstein-Uhlenbeckprocess,forwhichexactsamplepathsandentropyproductionrateareavailable(Section
2.6.1). TheheatmaprepresentsthedensityoftheassociatedGaussiansteady-state. Oneseesthatanon-zeroirreversibledrift
inducescircular,wanderingbehaviouraroundthecontoursofthesteady-state,characteristicofanon-equilibriumsteady-state
(toprightandbottomleft). Thisisaccentuatedbyincreasingthestrengthoftheirreversibledrift. Theentropyproductionrate
measurestheamountofirreversibilityofthestationaryprocess. Itgrowsquadraticallyasafunctionoftheirreversiblescaling
factorθ(bottomright). Whenthereisnoirreversibility(topleft),wewitnessanequilibriumsteady-state. Thisischaracterised
byavanishingentropyproduction(bottomright).
part of the drift (Proposition 2.4.7), and by ·− the Moore-Penrose matrix pseudo-inverse. Suppose that:
1. For ρ-almost every x∈Rd, b (x)∈Rangeσ(x), and
irr
2. The product σ−b :Rd →Rm is Borel measurable (e.g., if σ−b is continuous), and
irr irr
3. (cid:82) b⊤D−b ρ(x)dx<+∞.
Rd irr irr
DenotebyP ,P¯ thepathspacemeasuresoftheforwardandtime-reverseddiffusions,respectively,onC([0,T],Rd)
[0,T] [0,T]
(Definition 2.3.2). Then,
1. The path-space measures are equivalent P ∼P¯ , and
[0,T] [0,T]
2. e = (cid:82) b⊤D−b ρ(x)dx.
p Rd irr irr
Under the assumptions of Theorem 2.5.1, the e is a quadratic form of the time-irreversible drift, see Figure 2.2.
p
A proof of Theorem 2.5.1 is provided in Section 2.8.3. The idea of the proof is simple: in the elliptic case, the
approachfollows[15,Chapter4]withsomegeneralisations. Inthenon-ellipticcase,theconditionb (x)∈Rangeσ(x)
irr
33
intuitively ensures that the solution to the SDE, when initialised at any point, evolves on a sub-manifold of Rd and
is elliptic on this manifold (e.g., Figure 2.3). The pseudo-inverse of the diffusion tensor is essentially the inverse on
this sub-manifold. Thus, a proof analogous to the elliptic case, but on the sub-manifold (essentially replacing all
matrix inverses by pseudo-inverses and making sure everything still holds), shows that the path space measures of
theforwardandbackwardprocessesinitialisedatagivenpointareequivalent—andGirsanov’stheoremgivesustheir
Radon-Nykodymderivative. Finally,Proposition2.3.8givesustheusualformulafortheentropyproductionratebut
with the matrix inverse replaced by the pseudo-inverse. Please see Section 2.7.3 for a geometric discussion of this
proof.
Suppose either of assumptions 2, 3 of Theorem 2.5.1 do not hold. Then we have the following more general (and
technical) result:
Theorem 2.5.2. Let (Ω,F,P) be a probability space and (w ) a standard Wiener process on Rm, with respect to
t t⩾0
thefiltration(F ) [45,Definition2.1.12]. ConsidertheItôSDE (2.5)withcoefficientssatisfyingAssumption2.4.3.
t t≥0
Consider its unique strong solution (x ) with respect to the given Brownian motion on the filtered probability
t t∈[0,T]
space (Ω,F,(F ) ,P). Assume that the solution is stationary with respect to a density ρ satisfying Assumption
t t≥0
2.4.4. Denote by b the time-irreversible part of the drift (Proposition 2.4.7), and by ·− the Moore-Penrose matrix
irr
pseudo-inverse. Suppose that:
1. For ρ-almost every x∈Rd, b (x)∈Rangeσ(x), and
irr
2. σ−b (x ) is an F -adapted process (e.g., σ−b :Rd →Rm is Borel measurable), and
irr t t irr
3. The following holds
(cid:18) (cid:90) T (cid:19)
E [Z ]=1,Z :=exp −2 ⟨σ−b (x ),dw ⟩+|σ−b (x )|2dt . (2.20)
P T T irr t t irr t
0
Denote by P ,P¯ the path space measures on C([0,T],Rd) of the forward and time-reversed diffusions, respec-
[0,T] [0,T]
tively (Definition 2.3.2). Then,
1. The path-space measures are equivalent P ∼P¯ , and
[0,T] [0,T]
2. e = (cid:82) b⊤D−b ρ(x)dx.
p Rd irr irr
A proof is provided in Section 2.8.3. The proof is similar to that of Theorem 2.5.1, but much shorter, since (2.20)
allows one to apply Girsanov’s theorem directly; in contrast, a large part of the proof of Theorem 2.5.1 is dedicated
to showing that indeed, a version of Girsanov’s theorem can be applied.
In relation to assumption 2 of Theorem 2.5.2, note that if a matrix field σ : Rd → Rd×m is Borel measurable, then
its pseudo-inverse σ− :Rd →Rm×d is also Borel measurable. We now give sufficient conditions for the exponential
condition (2.20).
Proposition 2.5.3. Consider a stochastic process (x ) on the probability space (Ω,F,(F ) ,P), which is
t t∈[0,T] t t≥0
stationary at the density ρ. Assume that σ−b (x ) is F -adapted. Then, either of the following conditions implies
irr t t
(2.20):
1. Z =exp (cid:16) −2 (cid:82)t⟨σ−b (x ),dw ⟩+|σ−b (x )|2ds (cid:17) ,t∈[0,T]isamartingaleontheprobabilityspace(Ω,F,{F } ,P).
t 0 irr s s irr s t t≥0
2. E P (cid:16) e2(cid:82) 0 T|σ−birr(xt)|2dt (cid:17) <+∞ (Novikov’s condition).
(cid:16) (cid:17)
3. There exists δ>0 such that E
ρ
eδ|σ−birr(x)|2 <+∞.
4. sup E (cid:104) exp (cid:16) − (cid:82)t⟨σ−b (x ),dw ⟩ (cid:17)(cid:105) <+∞ (Kazamaki’s criterion).
t∈[0,T] P 0 irr s s
34
5. There exists K <1 s.t. for all t∈[0,T]
(cid:20) (cid:90) T (cid:12) (cid:21)
E P 2 (cid:12) (cid:12)σ−b irr (x t ) (cid:12) (cid:12) 2 ds (cid:12) (cid:12) F t ≤K.
(cid:12)
t
6. Thetailof|σ−b (x)|2,x∼ρdecaysexponentiallyfast,i.e.,thereexistspositiveconstantsc,C,R>0suchthat
irr
for all r>R
P(|σ−b (x)|2 >r)≤Ce−cr. (2.21)
irr
Furthermore, (2 or 4) ⇒ 1; 5 ⇒ 2; and 6 ⇒ 3.
A proof is provided in Section 2.8.3.
2.5.2 Singular case
Whenthetime-irreversiblepartofthedriftisnotalwaysintherangeofthevolatilitymatrixfield,wehaveadifferent
result.
Theorem 2.5.4. Suppose that the Itô SDE (2.5) satisfies Assumption 2.4.3 and that the volatility is twice contin-
uously differentiable σ ∈ C2(Rd,Rd×m). Furthermore suppose that the solution (x ) is stationary with respect
t t∈[0,T]
to a density ρ satisfying Assumption 2.4.4. Denote by P ,P¯ the path space measures on C([0,T],Rd) of the
[0,T] [0,T]
forward and time-reversed processes, respectively (Definition 2.3.2). If b (x) ∈ Rangeσ(x) does not hold for ρ-a.e.
irr
x∈Rd, then
P ⊥P¯ and e =+∞.
[0,T] [0,T] p
A proof is provided in Section 2.8.3. The proof uses a version of the Stroock-Varadhan support theorem to show
that there are paths that can be taken by the forward diffusion process that cannot be taken by the backward
diffusionprocess—andvice-versa. Specifically,whenconsideringthetwoprocessesinitialisedatapointx∈Rd where
b (x)∈/ Rangeσ(x),wecanseethatthederivativesoftheirrespectivepossiblepathsattime0spandifferenttangent
irr
sub-spacesatx. ThusthepathspacemeasuresPx ,P¯x aremutuallysingular. Sincesuchxoccurwithpositive
[0,T] [0,T]
probability under the stationary density, it follows that the path space measures of the forward and time-reversed
stationary processes Px ,P¯x are also mutually singular. Finally, the relative entropy between two mutually
[0,T] [0,T]
singular measures is infinity, hence the e must be infinite.
p
By Theorem 2.5.4 and (2.12) we can readily see that the underdamped (2.7) and generalised Langevin [3, eq. 8.33]
processes in phase-space have infinite entropy production. Expert statistical physicists will note that this contrasts
with previous results in the literature stating that these diffusions have finite entropy production. There is no
contradiction as physicists usually add an additional operator to the definition of the entropy production in these
systems(Remark2.3.7). Whileobviouslyinformativeoftheunderlyingprocess,statisticalphysicistsshouldtakethe
results of Theorems 2.5.1, 2.5.2 and 2.5.4 to be physically relevant to entropy production insofar as the definition of
entropyproductionweadopted(Definition2.3.6)isphysicallymeaningfulforthesystemathand. Whatifitisnot?
We will return to this in the discussion (Section 2.7.2).
In contrast to the underdamped and generalised Langevin equations, there exist hypoelliptic, non-elliptic diffusions
35
with finite entropy production. For example, consider the following volatility matrix field
 
x 1
σ(x,y,z)=1 1.
 
0 1
By Hörmander’s theorem [29, Theorem 1.3], for any smooth, confining (e.g., quadratic) potential V : R3 → R, the
process solving the SDE
dx =−D∇V(x )dt+∇·D(x )dt+σ(x )dw
t t t t t
is hypoelliptic and non-elliptic. Furthermore, it is stationary and time-reversible at the Gibbs density ρ(x) ∝
exp(−V(x)).
2.6 Examples and e of numerical simulations
p
Weillustratetheseresultsforlineardiffusionprocesses,underdampedLangevindynamicsandtheirnumericalsimu-
lations.
2.6.1 Linear diffusion processes
GivenmatricesB ∈Rd×d,σ∈Rd×m,andastandardBrownianmotion(w ) onRm,consideralineardiffusion
t t∈[0,+∞)
process (i.e., a multivariate Ornstein-Uhlenbeck process)
dx =b(x )dt+σ(x )dw , b(x)=−Bx, σ(x)≡σ. (2.22)
t t t t
This process arises, for example, in statistical physics as a model of the velocity of a massive Brownian particle
subjecttofriction[64];itcoversthecaseofinteractingparticlesystemswhentheinteractionsarelinearinthestates
(e.g., the one dimensional ferromagnetic Gaussian spin model [65]); or when one linearises the equations of generic
diffusion processes near the stationary density.
By solving the linear diffusion process (e.g., [65, Section 2.2]) one sees that the solution can be expressed as a linear
operation on Brownian motion—a Gaussian process—thus the process must itself be Gaussian, and its stationary
density as well (when it exists). Consider a Gaussian density ρ
1
ρ(x)=N(x;0,Π−1), −logρ(x)= x⊤Πx,
2
where Π∈Rd×d is the symmetric positive definite precision matrix. By the Helmholtz decomposition (Propositions
2.4.7 & 2.4.10), ρ is a stationary density if and only if we can decompose the drift as follows:
b=b +b , b (x)=−DΠx, b (x)=−QΠx,
rev irr rev irr
whereQ=−Q⊤ ∈Rd×d isanarbitraryantisymmetricmatrix,and,recallD=σσ⊤/2∈Rd×d isthediffusiontensor.
In particular, the drift of the forward and the time-reversed dynamic, are, respectively,
b(x)=−Bx, B =(D+Q)Π, ¯b(x)=−Cx, C :=(D−Q)Π.
Suppose that b (x) ∈ Rangeσ for any x ∈ Rd. By definiteness of Π this is equivalent to RangeQ ⊆ Rangeσ. By
irr
36
Theorem 2.5.1, and applying the trace trick to compute the Gaussian expectations of a bilinear form, we obtain4
(cid:90) (cid:90)
e = b⊤D−b ρ(x)dx=− x⊤ΠQD−QΠxρ(x)dx
p irr irr
Rd Rd
=−Tr(ΠQD−QΠΠ−1)=−Tr(D−QΠQ) (2.23)
=−Tr(D−BQ)+Tr(D−DΠQ)=−Tr(D−BQ).
(cid:124) (cid:123)(cid:122) (cid:125)
=0
This expression for the entropy production is nice as it generalises the usual formula to linear diffusion processes to
degenerate noise, simply by replacing inverses with pseudo-inverses, cf. [65, eqs. 2.28-2.29] and [66,67].
Contrariwise, suppose that RangeQ̸⊆Rangeσ. Then by Theorem 2.5.4,
e =+∞. (2.24)
p
Exact numerical simulation and entropy production rate
Linear diffusion processes can be simulated exactly as their transition kernels are known. Indeed, by solving the
process, one obtains the transition kernels of the Markov semigroup as a function of the drift and volatility [68,
Theorem 9.1.1]. The forward and time-reserved transition kernels are the following:
(cid:90) ε
p (·,x)=N(e−εBx,S ), S := e−tBσσ⊤e−tB⊤ dt,
ε ε ε
0 (2.25)
(cid:90) ε
p¯ (·,x)=N(e−εCx,S¯ ), S¯ := e−tCσσ⊤e−tC⊤ dt.
ε ε ε
0
Sampling from the transition kernels allows one to simulate the process exactly, and offers an alternative way to
express the entropy production rate. Recall from Proposition 2.3.10 that the e is the infinitesimal limit of the
p
entropy production rate of an exact numerical simulation e (ε) with time-step ε
p
1
e =lime (ε), e (ε)= E [H[p (·,x)|p¯ (·,x)]].
p ε↓0 p p ε x∼ρ ε ε
We can leverage the Gaussianity of the transition kernels to compute the relative entropy and obtain an alternative
formula for the entropy production rate:
Lemma 2.6.1. The entropy production rate of the stationary linear diffusion process can also be expressed as
e =lime (ε),
p p
ε↓0
1 (cid:20) det∗(S¯ )
e (ε)= Tr(S¯−S )−rankσ+log ε (2.26)
p 2ε ε ε det∗(S )
ε
(cid:16) (cid:17)(cid:105)
+Tr Π−1(e−εC−e−εB)⊤S¯−(e−εC−e−εB) ,
ε
where ·− is the Moore-Penrose pseudo-inverse and det∗ is the pseudo-determinant.
A proof is provided in Section 2.8.4. Computing the limit (2.26) analytically, gives us back (2.23), (2.24), however,
we will omit those details here. For our purposes, this gives us a way to numerically verify the value of e that was
p
obtained from theory. See Figures 2.3 and 2.4 for illustrations.
4To obtain the last equality we used Tr(D−DΠQ) = Tr(ΠQD−D) = −Tr(DD−QΠ). By standard properties of the
pseudo-inverse DD− is the orthogonal projector onto RangeD = Rangeσ. Thus, RangeQ ⊆ Rangeσ implies DD−Q = Q.
Finally,thetraceofasymmetricmatrixΠtimesanantisymmetricmatrixQvanishes.
37
Figure 2.3: Exact simulation of linear diffusion process with birr(x) ∈ Rangeσ. This figure considers an OU process
in 3d space driven by degenerate noise, i.e., rankσ < 3. The coefficients are such that σ = Q are of rank 2. In particular,
birr(x)∈Rangeσ holdsforeveryx. Theprocessisnotellipticnorhypoelliptic,butitisellipticoverthesubspaceinwhichit
evolves. Theupper-leftpanelshowsasampletrajectorystartingfromx0=(1,1,1). Theupper-rightpanelshowssamplesfrom
differenttrajectoriesafteratime-stepε. Thereareonlytwoprincipalcomponentstothispointcloudastheprocessevolveson
a two dimensional subspace. In the bottom panel, we verify the theoretically predicted value of ep by evaluating the entropy
productionofanexactsimulationep(ε)withtime-stepε. Aspredicted,werecoverthetrueep intheinfinitesimallimitasthe
time-step of the exact simulation tends to zero ε → 0. Furthermore, since the process is elliptic in its subspace, the entropy
productionisfinite.
2.6.2 Underdamped Langevin dynamics
In this sub-section, we consider the entropy production rate of underdamped Langevin dynamics and its numerical
simulations. Recall that the e we compute here is defined without an additional momentum flip operator on the
p
path space measure of the time-reversed process (i.e., (2.2) and not (2.3)), and may be a distinct quantity from the
entropy production that physicists usually consider in such systems (see the discussion in Section 2.7.2).
Consider a Hamiltonian H(q,p) function of positions q∈Rn and momenta p∈Rn of the form
1
H(q,p)=V(q)+ p⊤M−1p (2.27)
2
for some smooth potential function V :Rn →R and diagonal mass matrix M ∈Rn×n.
38
Figure2.4: Exactsimulationoflineardiffusionprocesswithbirr(x)̸∈Rangeσ. ThisfigureconsidersanOUprocessin3d
spacedrivenbydegeneratenoise. ThecoefficientsaresuchthatRangebirristwo-dimensionalwhileRangeσisone-dimensional,
andsuchthattheprocessdoesnotsatisfyHörmander’shypoellipticitycondition. Assuchtheprocessishypoellipticonatwo-
dimensional subspace; see a sample trajectory in the upper-left panel. By hypoellipticity its transition kernels are equivalent
in the sense of measures, although far removed: On the upper right panel we show samples from different trajectories after a
time-stepε. Thereareonlytwoprincipalcomponentstothisdata-cloudastheprocessevolvesonatwodimensionalsubspace.
Inthebottompanel,weverifythetheoreticallypredictedep byevaluatingtheentropyproductionofanexactsimulationep(ε)
with time-step ε. As predicted, we recover ep =+∞ in the infinitessimal limit as the time-step of the exact simulation tends
tozeroε↓0. Thisturnsouttobeasthetransitionkernelsoftheforwardandtime-reversedprocessesbecomemoreandmore
mutuallysingularasthetime-stepdecreases.
The underdamped Langevin process is the solution to the SDE [38, eq 2.41]

dq
t
=M−1p
t
dt
(2.28)
dp =−∇V (q )dt−γM−1p dt+ (cid:112) 2γβ−1dw
t t t t
for some friction coefficient γ > 0. This process arises in statistical physics, as a model of a particle coupled to a
heat bath [69], [3, Chapter 8]; in Markov chain Monte-Carlo as an accelerated sampling scheme [26,56]; and also as
a model of interacting kinetic particles.
The invariant density, assuming it exists, is [38, Section 2.2.3.1]
ρ(q,p)= 1 e−βH(q,p) = 1 e−βV(q)e−β 2 p⊤M−1p.
Z Z
Since the noise is additive the Itô interpretation of the SDE coincides with the Stratonovich interpretation, thus the
39
irreversibledriftisintherangeofthevolatilityifandonlyifthedriftisintherangeofthevolatility(2.12). Observe
that when the momentum is non-zero p̸=0 the drift is not in the image of the volatility: in the q components the
drift is non-zero while the volatility vanishes. Since p ̸= 0 has full measure under the stationary density ρ(q,p) we
obtain, from Theorem 2.5.4,
e =+∞. (2.29)
p
Note that the entropy production of an exact numerical simulation with time-step ε>0 is usually finite by hypoel-
lipticity5
e (ε)<+∞. (2.30)
p
Figure 2.5 illustrates this with an exact simulation of underdamped Langevin dynamics in a quadratic potential.
When the potential is non-quadratic, the underdamped process is a non-linear diffusion and one is usually unable
to simulate it exactly. Instead, one resolves to numerical approximations to the solution of the process. We now
turn to two common numerical discretisations of underdamped: the Euler-Maruyama and BBK discretisations. We
will examine whether these discretisations are good approximations to the true process by computing their entropy
production rate.
Euler-Maruyama discretisation
In this section, we show that an Euler-Maruyama (E-M) discretisation of underdamped Langevin dynamics at any
time-step ε>0 has infinite entropy production
eE-M(ε)=+∞. (2.31)
p
To see this, we take a step back and consider an arbitrary Itô SDE in Rd
dx =b(x )dt+σ(x )dw
t t t t
The Euler-Maruyama discretisation for some time-step ε>0 is
x =x +b(x )ε+σ(x )ω , ω ∼N(0,εId ).
i+1 i i i i i d
This is a Markov chain with the following transition kernels
pE-M(x ,x )=N(x ;x +εb(x ),2εD(x )),
ε i+1 i i+1 i i i (2.32)
p¯E-M(x ,x ):=pE-M(x ,x ),
ε i+1 i ε i i+1
where p¯E-M denotes the transition kernel of the backward chain6.
ε
It turns out that when the SDE is not elliptic the transition kernels pE-M(·,x),p¯E-M(·,x) tend to have different
ε ε
supports:
5(2.30) always holds in a quadratic potential, whence the process is a linear diffusion and the results from Section 2.6.1
apply. We conjecture this to hold in the non-linear case as well, as hypoellipticity guarantees that the transition kernels are
mutuallyequivalentinthesenseofmeasures.
6Caution: thisisdifferentfromtheE-Mdiscretisationofthetime-reversedprocess.
40
Figure2.5: Exact simulation of underdamped Langevin dynamics. ThisfigureplotsunderdampedLangevindynamics
inaquadraticpotential. Here,theprocessistwodimensional,i.e.,positionsandmomentaevolveontherealline. Weexploitthe
fact that underdamped Langevin in a quadratic potential is an Ornstein-Uhlenbeck process to simulate sample paths exactly.
Thechoiceofparameterswas: V(q)=q2/2,M =γ=1. Theupperleftpanelplotsasampletrajectory. Oneobservesthatthe
processishypoelliptic: itisnotconfinedtoaprespecifiedregionofspace,cf. Figures2.3,2.4,eventhoughrandomfluctuations
affectthemomentaonly. Theupperrightpanelplotssamplesoftheforwardandtime-reversedprocessesafteratime-stepofε.
Inthebottompanel,weverifythetheoreticallypredictedep byevaluatingtheentropyproductionofanexactsimulationep(ε)
with time-step ε. As predicted, we recover ep =+∞ in the infinitessimal limit as the time-step of the exact simulation tends
tozeroε↓0. Thisturnsouttobebecausethetransitionkernelsoftheforwardandtime-reversedprocessesbecomemoreand
moremutuallysingularasthetime-stepdecreases.
Lemma 2.6.2. For any x∈Rd
supppE-M(·,x)={y:y∈x+εb(x)+RangeD(x)}
ε
suppp¯E-M(·,x)={y:x∈y+εb(y)+RangeD(y)}
ε
Lemma2.6.2isimmediatefrom(2.32)bynotingthatthesupportofp¯E-M(·,x)istheclosureofthoseelementswhose
ε
successor by the forward process can be x.
Unpacking the result of Lemma 2.6.2 in the case of underdamped Langevin dynamics yields
supppE-M(·,x)={y:y =x +εx }, suppp¯E-M(·,x)={y:y +εy =x },
ε q q p ε q p q
where x := (x ,x ) respectively denote position and momenta. One can see that pE-M(·,x) ⊥ p¯E-M(·,x),∀x ∈ Rd.
q p ε ε
From Definition 2.3.11, we deduce that the entropy production rate of E-M applied to the underdamped process is
41
infinite for any time-step ε>0.
Figure 2.6: Euler-Maruyama simulation of underdamped Langevin dynamics. This figure compares the Euler-
Maruyama simulation of underdamped Langevin dynamics with the exact simulation available in Figure 2.5. The choice
ofparameterswasthesame: V(q)=q2/2,M =γ=1. Theupperleftpanelplotsasampletrajectoryofthenumericalscheme.
Oneobservesthatthenumericalschemeisnotconfinedtoaprespecifiedregionofspacelikethetrueprocess. Theupperright
panelplotssamplesofthenumericalschemeafteratime-stepofε(inorange)givenaninitialconditionatx0 (inred). Thisis
superimposedontoaheatmapofthetruetransitionkernel(inblack). Weseethatsamplesfromthenumericalschemearein
therightregionofspace, butareconfinedtoasubspacewhichisnotalignedwiththeheatmapofthetruetransitionkernel.
Thesupportofthetransitionkernelofthetime-reversedschemeisshowninblue. Oneseesthatthesupportsofforwardand
reverse transition kernels are mutually singular, thus the entropy production of the numerical discretisation is infinite for any
time-step,whichdiffersfromthetrueprocesswhichhasfiniteentropyproductionforanypositivetime-step.
BBK discretisation
ContrariwisetoEuler,theBBKintegrator[37,38]isasplittingschemethatwhenappliedtounderdampedLangevin
yields absolutely continuous transition kernels. The numerical scheme consists of three intermediate steps
p =p −∇V (q ) ε −γM−1p ε + (cid:112) 2γβ−1ω
i+1 2 i i 2 i2 i
q =q +M−1p ε
i+1 i i+1
2
p =p −∇V (q ) ε −γM−1p ε + (cid:112) 2γβ−1ω
i+1 i+1 2 i+1 2 i+1 22 i+ 2 1
withω ,ω ∼N (cid:0) 0,εId (cid:1). Itsstabilityandconvergencepropertieswerestudiedin[37,38]anditsergodicproperties
i i+ 2 1 2
in [70–72].
It was shown in [35, Theorem 4.3] that the BBK discretisation of the underdamped Langevin process is quasi time-
reversible, so that
eBBK ≤O(ε). (2.33)
p
One sees (cf. Figures 2.6 and 2.7 vs Figure 2.5) that the BBK integrator better approximates the transition kernels
than E-M does, however BBK still islargely inaccurate from the point ofview of the entropy production rate as the
simulation becomes reversible when the time-step tends to zero.
42
Figure 2.7: BBK simulation of underdamped Langevin dynamics. This figure compares the BBK simulation of un-
derdamped Langevin dynamics with the exact simulation available in Figure 2.5. The choice of parameters was the same:
V(q) = q2/2,M = γ = 1. The upper left panel plots a sample trajectory of the numerical scheme. One observes that the
numericalschemeisnotconfinedtoaprespecifiedregionofspacelikethetrueprocess. Theupperrightpanelplotssamplesof
the numerical scheme after a time-step of ε (in orange) given an initial condition at x0 (in red). This is superimposed onto a
heatmapofthetruetransitionkernel(inblack). Weseethatsamplesfromthenumericalschemefitthetruetransitionkernel
relatively well, but have a higher variance. The bottom panel estimates the entropy production rate of the numerical scheme
forseveralchoicesoftime-stepε. Thisisdonebydiscretisingthestate-spaceintoanumberofbinsandnumericallyevaluating
the entropy production of the resulting Markov chain using samples, see Section 2.3.1 for details. The numerical values are
consistentwiththetheoreticalresult(2.33).
Summary
In summary, the underdamped Langevin process has infinite entropy production rate in phase space7, but finite
entropyproductionrateforanyexactsimulationwithapositivetime-step. Whenthepotentialisnon-quadratic,the
process is a non-linear diffusion that one usually cannot simulate exactly. To simulate it as accurately as possible,
oneshouldseekanapproximatingnumericalschemethathasfiniteentropyproductionforanytime-step,andwhose
entropy production tends to infinity for infinitesimally small time-steps.
Two well-known choices of numerical discretisation are the Euler-Maruyama and BBK schemes. By comparing their
transitionkernelswithanexactsimulation,wesawthattheBBKschemeisamuchbetterapproximationtothetrue
processthanEuler-Maruyama. Analysisoftheentropyproductionrateshowshowthesediscretisationsstillfarshort
incapturingimportantstatisticalpropertiesoftheprocess: theE-Mdiscretisationhasinfiniteentropyproductionfor
7Recallthattheep wecomputedhereisdefinedwithout anadditionalmomentumflipoperatoronthepathspacemeasure
ofthetime-reversedprocess,i.e.,(2.2)andnot(2.3). SeealsothediscussioninSection2.7.2,
43
any time-step; while the BBK discretisation has finite entropy production for any time-step, and vanishing entropy
productionforinfinitesimallysmalltime-steps. Wheneverpossible,agoodwaytochooseatime-stepsizefortheBBK
integrator might be matching its entropy production rate with that of an exact simulation. These results indicate
that employing a BBK scheme with very small time-steps might be inadequate. Luckily, large step-sizes are usually
preferred in practice.
In conclusion, the entropy production rate is a useful statistic of stochastic processes that can be used as a tool to
devise accurate numerical schemes, particularly in a non-equilibrium statistical physics or sampling context where
preserving the amount of time-irreversibility is important. Future development of numerical schemes should take
entropy production into account; for example, in developing numerical schemes for underdamped Langevin, one
should seek a finite entropy production rate for any positive time-step, which tends to infinity when time-steps
become infinitesimally small. Other numerical schemes should be analysed in future work, such as those based on
the lexicon for the approximation of the underdamped process developed by Leimkühler and Matthews [73, p. 269
& 271].
2.7 Discussion
Briefly, we unpack a couple of observations and possible extensions of this work.
2.7.1 e and sampling efficiency
p
Awell-knowncriterionforefficientsamplingistime-irreversibility[26,33,34,74]. Intuitively,non-reversibleprocesses
backtrack less often and thus furnish more diverse samples [75]. Furthermore, the time-irreversible part of the drift
flows along the contours of the stationary probability density which yields mixing and accelerates convergence to
the target measure. It is well known that removing non-reversibility worsens the spectral gap and the asymptotic
varianceoftheMCMCestimator[33,34,74],whicharetwomainindicatorsofthespeedofconvergencetostationary
state [26]. Thus efficient samplers at non-equilibrium steady-state have positive entropy production.
In elliptic linear diffusions, one can construct the optimal time-irreversible drift to optimise the spectral gap [60,76]
or the asymptotic variance [74]. This indicates that one cannot optimise elliptic samplers by simply increasing their
entropyproductionatsteady-statewithoutanyotherconstraints,as,werecall,e isaquadraticformofthestrength
p
of the time-irreversible drift (Figure 2.2).
Beyond this, the entropy production rate of general diffusions (Theorems 2.5.1, 2.5.2) bears a formal resemblance
to the Donsker-Varadhan functional [33, Theorem 2.2], from which the asymptotic variance of MCMC estimators is
derived[33]. Itisentirelypossiblethatonemightbeabletorelatethenon-stationaryentropyproductionrate((2.1)
or [15, eq. 3.19]) to the Donsker-Varadhan functional, and thus give a more complete characterisation of sampling
efficiency in terms of entropy production.
Manydiffusionmodelsofefficientsampling(theunderdamped(2.7)andgeneralised[3,eq. 8.33]Langevindynamics,
the fastest converging linear diffusion [31]), and stochastic optimisation (stochastic gradient descent in deep neural
networks [27]) are not elliptic; that is, they are driven by less Brownian drivers than there are dimensions to their
phasespace. Inparticular,theseprocesseshavetheirforwardandbackwardpathspacemeasureswhicharemutually
singular, and infinite entropy production8. In light of this, we conjecture that mutual singularity of the forward
8 [27, Section 5] shows that stochastic gradient descent is out of equilibrium. Furthermore, it shows empirically that the
rankofthediffusionmatrixisabout1%ofitsdimensionindeepneuralnetworks. Thesparsityofthenoisewithrespecttothe
highlyout-of-equilibriumbehaviourtheyobserveconjecturesbirr(x)̸∈Rangeσ(x)andthus,mutualsingularityofforwardand
44
and backward path space measures is an important facet of sampling efficiency (provided the process is ergodic).
Mutual singularity apparently exacerbates the mixing effect that time-irreversibility introduces in the elliptic case.
Heuristically, ifsomepathscan be taken by theforwardprocessand notbythe backwardprocess, thesetrajectories
cannotbereversed,thustheprocessisconstantlyforcedtovisitnewregionsofphasespace,whichcontributestothe
(non-reversible) convergence to steady-state.
If the above intuition holds, a useful statistic of sampling efficiency might be the probability that the forward
process takes paths that cannot be taken by the backward process. By the Lebesgue decomposition theorem we can
decompose the forward path space measure P into P +P such that P ≪P¯ and P ⊥P¯. This statistic is
reg sing reg sing
the non-negative real number
(cid:16) (cid:17)
P({γ ∈C([0,T],Rd):dP/dP¯(γ)=+∞})=P C([0,T],Rd) ,
sing
where dP/dP¯ is the Lebesgue derivative between forward and backward path space measures. Note that the linear
diffusion that converges fastest to steady-state maximises the latter (under the constraint that the process remains
ergodic)sinceithasonlyoneBrowniandriver[31]. However,thisstatisticdoesnottellusallsincethedirectionofthe
Brownian driver with respect to the drift and the stationary density is important to determine sampling efficiency.
Yet, these observations indicate that employing diffusions with less Brownian drivers might be an advantage for
sampling and optimisation (provided ergodicity is maintained). A careful investigation of these relationships is left
to future work.
2.7.2 Generalised non-reversibility and entropy production rate
Many diffusions studied in statistical physics are not time-reversible but they are generalised reversible; that is,
they are time-reversible up to a one-to-one transformation θ of phase-space which leaves the stationary measure
invariant[36,Section5.1],[38,eq. 2.32]. Forexample,theunderdampedlangevinequationisgeneralisedreversible—
it is reversible up to momentum reversal (Example 2.4.6); the generalised Langevin equation is also generalised
reversible.
The entropy production, as defined in Definition 2.3.6, measures time-irreversibility as opposed to generalised non-
reversibility. However, as pointed out in Remark 2.3.7, the physically meaningful definition of entropy production
rate sometimes comprises additional operators applied to the path-space measure of the time-reversed process. This
modified notion of e , which we refer to as generalised entropy production, usually takes the form of
p
egen,θ :=lim 1 H (cid:2) P ,θ P¯ (cid:3) , (2.34)
p ε↓0 ε [0,ε] # [0,ε]
whereθ isthepushforwardoperatorassociatedtoaninvolutionofphase-spaceθthatleavesthestationarydistribu-
#
tioninvariant. Thegeneralisedentropyproductionratemeasuresthegeneralisednon-reversibilityoftheprocess;that
is, the extent to which the process is time-irreversible up to the one-to-one transformation θ. Of course, generalised
entropy production reduces to entropy production, as defined in Definition 2.3.6, when θ≡Id.
Sincegeneralisedentropyproductioncansometimesbemorephysicallymeaningful,wespendtherestofthissection
computing it in a couple of examples.
Itseemstobeageneralconsensusinstatisticalphysicsthatthephysicallyrelevantnotionofentropyproductionforthe
underdamped Langevin process is the generalised entropy production when θ is the momentum reversal [40–42,77].
It is then a by-product of Example (2.4.6) that underdamped Langevin dynamics has zero (generalised) entropy
backwardpathspacemeasures.
45
production egen,θ = 0, which contrasts with the infinite entropy production one obtains in the non-generalised case
p
(Section 2.5.2) when one sets θ≡Id.
Beyond this, generalised entropy production could be a useful construct to quantify how far certain diffusion pro-
cesses are from being generalised reversible. For example we can quantify to what extent certain time-irreversible
perturbationsofunderdampedLangevindynamicsarefarfrombeinggeneralisedreversibleuptomomentumreversal.
Example 2.7.1 (egen,θ of perturbed underdamped Langevin dynamics). Consider the following perturbations of
p
underdamped Langevin dynamics [78, eq. 8]

dq
t
=M−1p
t
dt−Q
1
∇V (q
t
)dt
(2.35)
dp =−∇V (q )dt−Q M−1p dt−γM−1p dt+ (cid:112) 2γβ−1dw ,
t t 2 t t t
whereQ ,Q ∈Rd×d areconstantantisymmetricmatrices. ByinspectionthisequationhasaHelmholtzdecomposi-
1 2
tion that is similar to underdamped Langevin dynamics (cf. Example 2.4.11)
b (q,p)=D∇logρ(q,p), b (q,p)=Q∇logρ(q,p)
rev irr
(cid:34) (cid:35) (cid:34) (cid:35) (cid:34) (cid:35)
∇V(q) 0 0 Q −Id
∇logρ(q,p)=−β , D= , Q=β−1 1 n .
M−1p 0 γβ−1Id Id Q
n n 2
The time-reversed process solves the following SDE (Section 2.4.4)

dq¯
t
=−M−1p¯
t
dt+Q
1
∇V (q¯
t
)dt
dp¯ =∇V (q¯)dt+Q M−1p¯ dt−γM−1p¯dt+ (cid:112) 2γβ−1dw .
t t 2 t t t
Define θ(q,p) = (q,−p) to be the momentum reversal transformation of phase space (that leaves underdamped
Langevin dynamics invariant as shown in Example 2.4.6). Letting pˆ = −p¯, the time-reversed momentum-flipped
t t
equation looks like

dq¯
t
=M−1pˆ
t
dt+Q
1
∇V (q¯
t
)dt
(2.36)
dpˆ =−∇V (q¯)dt+Q M−1pˆ dt−γM−1pˆdt+ (cid:112) 2γβ−1dwˆ .
t t 2 t t t
Denote by bgen,θ the vector field whose sign changes after successively applying these two transformations:
irr
(cid:34) (cid:35)
−Q ∇V (q)
bgen,θ(q,p)= 1 .
irr −Q M−1p
2
It follows that the time-reversed, momentum-flipped equation (2.36) does not induce the same path space measure
as the initial equation (2.35) unless Q = Q = 0. To see this, we follow the proofs of Theorems 2.5.4 and 2.5.1 to
1 2
compute the generalised entropy production rate
Q ̸=0⇒P⊥θ P¯ ⇒egen,θ =+∞,
1 # p
(cid:90)(cid:90)
Q =0⇒P∼θ P¯ ⇒egen,θ = bgen,θ·D−bgen,θρ(q,p)dpdq
1 # p irr irr
Rn
(cid:90)
=γ−1β (Q M−1p)2ρ(p)dp
2
Rn
=−γ−1βTr (cid:0) Q M−1Q (cid:1) <+∞.
2 2
ThelastlineequalityfollowsfromastandardresultaboutexpectationsofbilinearformsunderGaussiandistributions,
since ρ(p) is Gaussian with covariance matrix M. As usual, the generalised entropy production rate is a quadratic
46
form of the (generalised) irreversible drift.
2.7.3 Geometric interpretation of results
Our main results concerning the value of entropy production have a straightforward geometric interpretation. The
Stratonovich interpretation of the SDE
dx =bs(x )+σ(x )◦dw
t t t t
is the natural one to consider in a geometric context, when looking at the directions of the drift bs and volatility
vector fields σ ,i=1,...,m (i.e., the columns of the volatility matrix field).
·i
Recall from Remark 2.4.9 that the Stratonovich SDE also admits a Helmholtz decomposition bs = bs +bs with
rev irr
bs =b , so that
irr irr
bs(x)∈Rangeσ(x) ⇐⇒ bs (x)∈Rangeσ(x) ⇐⇒ ¯bs(x)∈Rangeσ(x) for any x∈suppµ, (2.37)
irr
where¯bsisthedriftofthetime-reversedStratonovichSDE.Inparticular,time-reversalisatransformationthatsends
bs to¯bs, bs to −bs , or, equivalently, adds −2bs to the drift.
irr irr irr
Our main results can be summarised in a nutshell:
(cid:16)(cid:110) (cid:111)(cid:17) (cid:90)
µ x∈Rd :bs(x)∈Rangeσ(x) =1⇒e = bs ·D−bs dµ (see Theorem 2.5.1 or 2.5.2 for details),
p irr irr
Rd (2.38)
(cid:16)(cid:110) (cid:111)(cid:17)
µ x∈Rd :bs(x)∈Rangeσ(x) <1⇒e =+∞ (see Theorem 2.5.4 for details).
p
We derived our main results using the Itô interpretation of an SDE because this allowed us to make more general
statements, notably in the context of the general existence and uniqueness theorem of strong solutions to Itô SDEs;
it turns out, however, that these results are more naturally interpreted in the Stratonovich context.
Consider the case where there is noise in the direction of the vector field bs, (almost every-) where the process is; in
other words, assume that µ (cid:0)(cid:8) x∈Rd :bs(x)∈Rangeσ(x) (cid:9)(cid:1) =1. Consider the process at any point x∈suppµ. In
virtueof(2.37),thedriftsoftheforwardandtimereversedprocessesbothliveinRangeσ(x),thesubsetofthetangent
space that is spanned by the volatility vector fields. Since the driving fluctuations are Gaussian on Rangeσ(x), the
time-reversaltransformationwillbereversedbytherandomfluctuationswithpositiveprobability. Thus,theforward
andtime-reversedMarkovtransitionkernels(foraninfinitesimallysmalltime-step)havethesamesupport—theyare
mutually equivalent. Under sufficient regularity, made explicit in Theorems 2.5.1 or 2.5.2, their relative entropy is
finite. Thee istherelativeentropybetweensuchMarkovkernelsonaninfinitesimallysmalltime-step(Proposition
p
2.3.10), so it too will be finite.
On the other hand, if there exists x∈suppµ such that there is no noise in the direction of the vector field bs, that
is bs(x)̸∈Rangeσ(x), then the direction of the forward and time-reversed dynamics in an infinitesimal time-step lie
on different tangent spaces, bs(x)+Rangeσ(x) and ¯bs(x)+Rangeσ(x), respectively. This means that the forward
and time-reversed transition kernels (for an infinitesimally small time-step) are mutually singular and their relative
entropy is infinite; thus, the e is also infinite.
p
In particular, it should be straightforward to extend these observations and calculations to diffusions on manifolds.
47
2.8 Addendum: Proofs for Chapter 1
Here we provide proofs supporting Chapter 1.
2.8.1 The e of stationary Markov processes
p
e in terms of path space measures with deterministic initial condition
p
We prove Proposition 2.3.8:
Proof. The proof is straightforward
e = 1 H (cid:2) P |P¯ (cid:3) = 1 E (cid:20) log dP [0,t](x ) (cid:21)
p t [0,t] [0,t] t x•∼P dP¯ •
[0,t]
1 (cid:20) (cid:20) dP (cid:21)(cid:21)
= t E x∼µ E x•∼Px [0,t] log dP¯ [0,t](x • )
[0,t]
(cid:34) (cid:34) (cid:35)(cid:35)
= 1 t E x∼µ E x•∼Px [0,t] log d d P P¯ x [ x 0,t](x • ) = 1 t E x∼µ (cid:2) H (cid:2) Px [0,t] |P¯x [0,t] (cid:3)(cid:3) .
[0,t]
e in terms of transition kernels
p
We prove Proposition 2.3.10:
Proof. By Proposition 2.3.8,
(cid:34) (cid:34) (cid:35)(cid:35)
1 dPx
e p =l ε i ↓ m 0 ε E x∼µ E x•∼Px [0,ε] log dP¯x [0,ε](x • )
[0,ε]
(cid:20) (cid:20) (cid:21)(cid:21)
1 dp (·,x)
=lim E E log ε (y)
ε↓0 ε x∼µ y∼pε(·,x) dp¯ ε (·,x)
1
=lim E [H[p (·,x)|p¯ (·,x)]].
ε↓0 ε x∼µ ε ε
2.8.2 Time-reversal of stationary diffusions
Conditions for the reversibility of the diffusion property
We prove Lemma 2.4.2:
Proof. Recall the following facts:
• (x ) is a Markov diffusion process. Its generator is an unbounded, linear operator given by
t t∈[0,T]
L:C∞(Rd)⊂DomL⊂Lp(Rd)→Lp(Rd), 1≤p≤∞, Lf =b·∇f +D∇·∇f. (2.39)
c µ µ
48
• The time-reversal of a Markov process is also a Markov process. Let L¯ be the generator of the time-reversed
process (x¯ ) . It is known that L¯ is the adjoint of L. In other words, we have the identity
t t∈[0,T]
(cid:90) (cid:90)
fLgdµ= gL¯f dµ, ∀f ∈DomL¯,g∈DomL, (2.40)
Rd Rd
where DomL¯ = (cid:8) f ∈L1(Rd)|∃h∈L1(Rd),∀g∈DomL: (cid:82) fLgdµ= (cid:82) hgdµ (cid:9). This followsfrom the fact
µ µ Rd Rd
that the Markov semigroup of the time-reversed process is the adjoint semigroup [15, p. 113], and thus the
infinitesimal generator is the adjoint generator [61,62], [15, Thm 4.3.2].
• L1 -functions define distributions, and hence admit distributional derivatives (which need not be functions).
loc
Weidentifythegeneratorofthetime-reversedprocessbycomputingtheadjointofthegenerator. Inthefollowing,all
integralsarewithrespecttothed-dimensionalLebesguemeasure. Letf,g∈C∞(Rd). Notingthatfρb·∇g,fρD∇·
c
∇g∈L1(Rd), we have
(cid:90) (cid:90) (cid:90)
fLgρ= fρb·∇g+ fρD∇·∇g.
Rd Rd Rd
On the one hand, noting that fρb,ρb∈L1 (Rd,Rd), we have
loc
(cid:90) (cid:90) (cid:90)
fρb·∇g=− g∇·(fρb)=− g(ρb·∇f +f∇·(ρb))
Rd Rd Rd
(cid:90)
=− g(ρb·∇f +f∇·∇·(ρD)),
Rd
wherethelastequalityfollowsfromthestationaryFokker-Planckequation. (Recallthatlocalboundednessofcoeffi-
cientsb,σ,andItô’sformulaimplythatthestationarydensityρsatisfies∇·(−bρ+∇·(Dρ))=0wheretheequality
is in a distributional sense).
On the other hand, noting that fρD,ρD∈L1 (Rd,Rd×d), we have
loc
(cid:90) (cid:90) (cid:90)
fρD∇·∇g= fρD·∇·∇g= g∇·∇·(fρD)
Rd Rd Rd
(cid:90)
= g∇·(ρD∇f +f∇·(ρD))
Rd
(cid:90)
= g(2∇·(ρD)·∇f +ρD∇·∇f +f∇·∇·(ρD)).
Rd
Finally, summing the previous two equations yields:
(cid:90) (cid:90) (cid:90)
fLgρ= g(−ρb·∇f +2∇·(Dρ)·∇f +ρD∇·∇f)= gL¯fρ.
Rd Rd Rd
And thus, the generator of the time-reversed process satisfies ρL¯f = −ρb·∇f +2∇·(Dρ)·∇f +ρD∇·∇f for all
f ∈ C∞(Rd). The time-reversed process is a diffusion if its generator is a second order differential operator with
c
no constant part. This is the case here, except for the fact that the generator outputs distributions as opposed to
functions. Forthegeneratortobeadiffusionoperatorweneedtoassumethatthedistributionalderivative∇·(Dρ)
is indeed a function (which is then necessarily in L1 (Rd,Rd)). Thus, the following are equivalent:
loc
• ∇·(Dρ)∈L1 (Rd,Rd),
loc
• L¯f ∈L1(Rd) for any f ∈C∞(Rd), where L¯f =−b·∇f +2ρ−1∇·(Dρ)·∇f +D∇·∇f,
µ c
• (x¯ ) is a Markov diffusion process.
t t∈[0,T]
49
The time-reversed diffusion
We prove Theorem 2.4.5.
Proof. Since(x¯ ) isaMarkovdiffusionprocesswithgeneratorL¯,wehaveshownthatitsdriftanddiffusionare
t t∈[0,T]
indeed¯b,D, in the proof of Lemma 2.4.2.
To show that any such diffusion process induces the path space measure of the time-reversed process, it suffices to
show that the martingale problem associated to (L¯,ρ) is well-posed. First note that, by Assumption 2.4.3, the Itô
SDE (2.5) has a unique strong solution. Therefore it also has a unique weak solution. Therefore, (x ) is the
t t∈[0,T]
unique solution to the martingale problem associated to the generator L = b·∇+D∇·∇ [79, Theorem 1.1]. In
other words, themartingale problem associated to (L,ρ) is well-posed. It remains toshow thatthere is a one-to-one
correspondence between stationary solutions to the martingale problem associated to L and L¯.
Consider Markov processes (y ) , (y¯) , y¯ = y stationary at the density ρ. We show that (y¯)
t t∈[0,T] t t∈[0,T] t T−t t t∈[0,T]
solves the martingale problem wrt L¯ if and only if (y ) solves the martingale problem wrt L.
t t∈[0,T]
• (y¯) solves the martingale problem wrt L¯ if and only if for arbitrary 0≤s≤t≤T, f,g∈C∞(Rd)
t t∈[0,T] c
(cid:20) (cid:90) t (cid:21) (cid:90) s
E f(y¯)− L¯f(y¯ )dr|y¯ ,0≤θ≤s =f(y¯ )− L¯f(x )dr
t r θ s r
0 0
(cid:20) (cid:90) t (cid:21) (cid:90) s
M⇐ar⇒kovE f(y¯)− L¯f(y¯ )dr|y¯ =f(y¯ )− L¯f(x )dr
t r s s r
0 0 (2.41)
(cid:20) (cid:90) t (cid:21)
⇐⇒E f(y¯)−f(y¯ )− L¯f(y¯ )dr|y¯ =0
t s r s
s
(cid:20)(cid:18) (cid:90) t (cid:19) (cid:21)
⇐⇒E f(y¯)−f(y¯ )− L¯f(y¯ )dr g(y¯ ) =0.
t s r s
s
If we make the change of variable t←T −s,s←T −t, so that 0≤s≤t≤T, this is equivalent to:
(cid:20)(cid:18) (cid:90) T−s (cid:19) (cid:21)
⇐⇒E f(y )−f(y )− L¯f(y )dr g(y ) =0
s t T−r t
T−t
(cid:20)(cid:18) (cid:90) t (cid:19) (cid:21)
⇐⇒E f(y )−f(y )− L¯f(y )dr g(y ) =0
s t r t
s
• Repeatingtheequivalencesin(2.41),(y ) solvesthemartingaleproblemwrtLifandonlyifforarbitrary
t t∈[0,T]
0≤s≤t≤T, f,g∈C∞(Rd)
c
(cid:20)(cid:18) (cid:90) t (cid:19) (cid:21)
E g(y )−g(y )− Lg(y )dr f(y ) =0.
t s r s
s
• Thus, it suffices to show that the two last expressions are equal, i.e.,
(cid:20)(cid:18) (cid:90) t (cid:19) (cid:21) (cid:20)(cid:18) (cid:90) t (cid:19) (cid:21)
E f(y )−f(y )− L¯f(y )dr g(y ) =E g(y )−g(y )− Lg(y )dr f(y )
s t r t t s r s
s s
By stationarity, we have
E[(f(y )−f(y ))g(y )]=E[f(y )g(y )−f(y )g(y )]
s t t s t t t
=E[f(y )g(y )−f(y )g(y )]=E[(g(y )−g(y ))f(y )].
s t s s t s s
50
Thus, it remains to show that
(cid:20)(cid:90) t (cid:21) (cid:20)(cid:90) t (cid:21)
E g(y )L¯f(y )dr =E f(y )Lg(y )dr
t r s r
s s
We proceed to do this. On the one hand:
(cid:20)(cid:90) t (cid:21) (cid:90) t
E f(y )Lg(y )dr = E[f(y )Lg(y )]dr
s r s r
s s
(cid:90) t
= E[E[f(y )Lg(y )|y ]]dr
s r s
s
(cid:90) t
= E[f(y )E[Lg(y )|y ]]dr
s r s
s
(cid:90) t
= E[f(y )P Lg(y )]dr
s r−s s
s
(cid:90) t(cid:90)
= f(y)P Lg(y)ρ(y)dydr (stationarity)
r−s
s Rd
(cid:90) (cid:90) t
= f(y) P Lg(y)drρ(y)dy
r−s
Rd s
(cid:90)
= f(y)(P −P )g(y)ρ(y)dy (∂ P =P L)
t−s 0 t t t
Rd
(cid:90)
= g(y) (cid:0) P¯ −P¯ (cid:1) f(y)ρ(y)dy
t−s 0
Rd
On the other hand:
(cid:20)(cid:90) t (cid:21) (cid:90) t
E g(y )L¯f(y )dr = E(cid:2) g(y )L¯g(y ) (cid:3) dr
t r t r
s s
(cid:90) t
= E(cid:2)E(cid:2) g(y )L¯f(y )|y (cid:3)(cid:3) dr
t r t
s
(cid:90) t
= E(cid:2) g(y )E(cid:2) L¯f(y )|y (cid:3)(cid:3) dr
t r t
s
(cid:90) t
= E(cid:2) g(y )P¯ L¯f(y ) (cid:3) dr
t t−r t
s
(cid:90) t(cid:90)
= g(y)P¯ L¯f(y)ρ(y)dydr (stationarity)
t−r
s Rd
(cid:90) (cid:90) t
= g(y) P¯ L¯f(y)drρ(y)dy
t−r
Rd s
(cid:90)
= g(y) (cid:0) P¯ −P¯ (cid:1) f(y)ρ(y)dy (∂ P¯ =P¯ L¯)
t−s 0 t t t
Rd
This shows the one-to-one correspondence and completes the proof.
The Helmholtz decomposition
We prove Proposition 2.4.7.
Proof. "⇒" We define the time-reversible and time-irreversible parts of the drift
b+¯b b−¯b
b := , b := .
rev 2 irr 2
51
Wenowshowthatthehavethepredictedfunctionalform. Forxsuchthatρ(x)=0,b = (cid:0) b+¯b (cid:1) /2=0. For
rev
x such that ρ(x)>0
b+¯b
b = =ρ−1∇·(Dρ)=ρ−1D∇ρ+ρ−1ρ∇·D=D∇logρ+∇·D. (2.42)
rev 2
For the time-irreversible drift, first note that the stationary density ρ solves the stationary Fokker-Planck
equation [3,80]
∇·(−bρ+∇·(Dρ))=0.
Decomposing the drift into time-reversible and time-irreversible parts, from (2.42)
−bρ+∇·(Dρ)=−b ρ−b ρ+∇·(Dρ)=−b ρ,
rev irr irr
weobtainthatthetime-irreversiblepartproducesdivergence-free(i.e.,conservative)floww.r.t. thesteady-state
density
∇·(b ρ)=0.
irr
"⇐" From (2.42) the time-reversible part of the drift satisfies the following identity
b ρ=∇·(Dρ). (2.43)
rev
It follows that the density ρ solves the stationary Fokker-Planck equation
∇·(−bρ+∇·(Dρ))=∇·(−b ρ−b ρ+∇·(Dρ))=∇·(−b ρ)=0.
rev irr irr
We prove Proposition 2.4.10:
Proof. "⇒" Recallthatanysmoothdivergence-freevectorfieldisthedivergenceofasmoothantisymmetricmatrix
field A=−A⊤ [21,22,81,82]
b ρ=∇·A.
irr
This resultholds mostgenerally aconsequenceof Poincaré duality inde Rhamcohomology [82,AppendixD].
WedefineanewantisymmetricmatrixfieldQ:=ρ−1A. Fromtheproductrulefordivergenceswecanrewrite
the time-irreversible drift as required
b =Q∇logρ+∇·Q.
irr
"⇐" Conversely,wedefinetheauxiliaryantisymmetricmatrixfieldA:=ρQ. Usingtheproductrulefordivergences
it follows that
b =ρ−1∇·A.
irr
Finally,
∇·(b ρ)=∇·(∇·A)=0
irr
as the matrix field A is smooth and antisymmetric.
Multiple perspectives on the Helmholtz decomposition
We prove Proposition 2.4.12:
52
Proof of Proposition 2.4.12. The proof is analogous to [5, Proposition 3]. In view of Section 2.4.5, we only need to
√ √
check that: 1) if 2Σf = σ⊤∇f, then 2Σ∗g = −∇·(σg)−∇logρ·σg; 2) the symmetric part of the generator
factorises as S=−Σ∗Σ.
1) For any f,g∈C∞(Rd):
c
√ √ (cid:90)
⟨f, 2Σ∗g⟩ =⟨ 2Σf,g⟩ = gσ⊤∇fρ(x)dx
L2 µ(Rd) L2 µ(Rd)
(cid:90) (cid:90)
= σgρ·∇f(x)dx=− f∇·(σgρ)(x)dx
(cid:90)
= −f∇logρ·σgρ(x)−f∇·(σg)ρ(x)dx
=⟨f,−∇logρ·σg−∇·(σg)⟩
L2 µ(Rd)
√
This implies 2Σ∗g=−∇logρ·σg−∇·(σg).
2) For any f ∈C∞(Rd):
c
−Σ∗Σf =∇logρ·D∇f +∇·(D∇f)
=∇logρ·D∇f +(∇·D)·∇f +D∇·∇f
=b ·∇f +D∇·∇f =Sf
rev
where the penultimate equality follows since b =D∇logρ+∇·D, µ-a.e.
rev
We now prove Proposition 2.4.13:
Proof of Proposition 2.4.13. • WecomputetheFréchetderivativeofH[·|ρ]. Firstofall,wecomputeitsGâteaux
derivative in the direction of η.
d d (cid:90) ρ +εη (cid:90) ρ +εη (cid:90) (cid:18) ρ +εη (cid:19)
H[ρ +εη|ρ]= (ρ +εη)log t dx= ηlog t +ηdx= η log t +1 dx.
dε t dε t ρ ρ ρ
Rd Rd Rd
By definition of the Fréchet derivative, we have d H[ρ +εη|ρ]| = ⟨dH[ρ | ρ],η⟩. This implies dH[ρ |
dε t ε=0 t t
ρ]=logρt +1 by the Riesz representation theorem.
ρ
√
• Recall, from Proposition 2.4.12, that 2Σ=σ⊤∇. We identify Σ′. For any f,g∈C∞(Rd)
c
√ (cid:90) (cid:90) (cid:90)
⟨g, 2Σf⟩= gσ⊤∇fdx= σg·∇fdx=− f∇·(σg)dx.
Rd Rd Rd
√
This yields 2Σ′g=−∇·(σg). And in particular, Σ′(ρ Σξ)=−∇·(ρ D∇ξ).
t t
• We define M (ξ) := Σ′(ρ Σξ) = −∇·(ρ D∇ξ) and verify that this is a symmetric semi-positive definite
ρt t t
operator. For any g,h∈C∞(Rd):
c
⟨M h,g⟩=⟨Σh,Σg⟩=⟨h,M g⟩, ⟨M g,g⟩=⟨Σg,Σg⟩ ≥0.
ρt ρt ρt ρt
Also, −M (dH[ρ |ρ])=∇·(ρ D∇logρt) is immediate.
ρt t t ρ
53
• We define W(ρ )=∇·(−b ρ ) and verify the orthogonality relation:
t irr t
(cid:90) (cid:18) ρ (cid:19) (cid:90) (cid:18) ρ (cid:19)
⟨W(ρ ),dH[ρ |ρ]⟩= log t +1 ∇·(−b ρ )dx= b ρ ∇ log t +1 dx
t t ρ irr t irr t ρ
Rd Rd
(cid:90) ρ (cid:18) ρ (cid:19) (cid:90) ρ
= b ρ ∇ t dx=− ∇·(b ρ) tdx=0,
irr tρ ρ irr ρ
Rd t Rd
where the last equality holds by Proposition 2.4.7.
2.8.3 The e of stationary diffusions
p
Regular case
We prove Theorem 2.5.1:
Proof. By Assumption 2.4.3 the Itô SDE (2.5) has a unique non-explosive strong solution (x ) with respect to
t t≥0
the given Brownian motion (w ) on a filtered probability space (Ω,F,{F } ,P). (Even though Assumption
t t≥0 t t≥0
2.4.3ensuresnon-explosivenessofthesolutiononafinitetime-interval,stationarityimpliesthatwemayprolongthe
solution up to arbitrary large times).
By Theorem 2.4.5 we know that a solution to the following SDE
dx¯ =¯b(x¯ )dt+σ(x¯ )dw , x¯ =x , (2.44)
t t t t 0 0
induces the path space measure of the time-reversed process. By Proposition 2.4.7, we can rewrite the (forward and
time-reversed) drifts as b=b +b and¯b=b −b .
rev irr rev irr
We define the localised coefficients

(cid:18)(cid:18) n (cid:19) (cid:19) b(x) if |x|≤n
b(n)(x):=b 1∧ x = (cid:16) (cid:17)
|x| b n x if |x|>n,
|x|
and analogously for¯b(n),σ(n),b(n),b(n). Note that the assignment ·(n) respects sums and products, in particular
rev irr
b(n) =(b +b )(n) =b(n)+b(n),
rev irr rev irr (2.45)
¯b(n) =(b −b )(n) =b(n)−b(n).
rev irr rev irr
It is easy to see that the localised SDE
dx(n) =b(n)(x(n))dt+σ(n)(x(n))dw , x(n) =x
t t t t 0 0
alsohasauniquestrongsolutionx(n) =(x(n)) withrespecttothegivenBrownianmotion(w ) ontheprobability
t t≥0 t t≥0
space (Ω,F,{F } ,P). This follows from the fact that the localised SDE has locally Lipschitz continuous and
t t≥0
bounded coefficients that satisfy the assumptions of Theorem [45, Theorem 3.1.1].
54
From assumption 1, we obtain that for ρ-a.e. x∈Rd
b (x)∈Rangeσ(x)⇒b (x)=σσ−b (x)
irr irr irr
(2.46)
b(n)(x)∈Rangeσ(n)(x)⇒b(n)(x)=σ(n)σ(n)− b(n)(x).
irr irr irr
Then, (2.45) and (2.46) imply that we can rewrite the localised SDE as
dx(n) =b(n)(x(n))dt+σ(n)(x(n)) (cid:104) σ(n)− b(n) (cid:16) x(n) (cid:17) dt+dw (cid:105) , x(n) =x .
t rev t t irr t t 0 0
By the definition of Itô’s stochastic calculus, x(n) is an F -adapted process. By assumption 2, σ−b is Borel
t t irr (cid:16) (cid:17)
measurable and thus it follows that the localised map σ(n)− b(n) is Borel measurable. Thus −2σ(n)− b(n) x(n) is
irr irr t
also an F -adapted process. In addition, by continuity and localisation, σ(n)− b(n) is bounded. Therefore, by [83,
t (cid:16) (cid:17) irr
Proposition 10.17 (i)] applied to −2σ(n)− b(n) x(n) ,
irr s
Z(n) =exp (cid:20) −2 (cid:90) t(cid:68) σ(n)− b(n) (cid:16) x(n) (cid:17) ,dw (cid:69) + (cid:12) (cid:12)σ(n)− b(n) (cid:16) x(n) (cid:17)(cid:12) (cid:12) 2 ds (cid:21) ,t≥0,
t irr s s (cid:12) irr s (cid:12)
0
(cid:16) (cid:17)
isamartingaleontheprobabilityspace Ω,F,{F } ,P . WedefineanewprobabilitymeasureP¯ onthesample
t t≥0 n
space Ω through
dP¯
n
(cid:12)
(cid:12) (cid:12) =Z(n), ∀t≥0. (2.47)
dP (cid:12) t
Ft
By Girsanov’s theorem [83, Theorem 10.14], x(n) solves the SDE
t
dx(n) =b(n)(x(n))dt−σ(n)(x(n)) (cid:104) σ(n)− b(n) (cid:16) x(n) (cid:17) dt+dw (cid:105) , x(n) =x .
t rev t t irr t t 0 0
(cid:16) (cid:17)
on the probability space Ω,F,{F } ,P¯ . Using (2.46), x(n) solves
t t≥0 n t
dx(n) =¯b(n)(x(n))dt+σ(n)(x(n))dw , x(n) =x
t t t t 0 0
on said probability space.
Wedefineasequenceofstoppingtimesτ =0andτ =inf{t≥0:|x |>n}forn>0. Since(x ) isnon-explosive,
0 n t t t≥0
P-a.s. lim τ =+∞. As x =x(n) when t≤τ , we have P-a.s.
n→∞ n t t n
Z t ( ∧ n τ ) n =exp
(cid:20)
−2
(cid:90) t∧τn(cid:10)
σ−b irr (x s ),dw s (cid:11) + (cid:12) (cid:12)σ−b irr (x s ) (cid:12) (cid:12) 2 ds
(cid:21)
.
0
As Z(n+1)1 =Z(n)1 , we define the limit as n→+∞
t {t<τn} t {t<τn}
+∞
Z ≡ (cid:88) Z(n)1 = lim Z(n)1 = lim Z(n) .
t t {τn−1≤t<τn }
n→+∞
t {t<τn}
n→+∞
t∧τn
n=1
(cid:16) (cid:17)
By definition, Z is a continuous local martingale on Ω,F,{F } ,P .
t t t≥0
We compute Z . Let’s write −logZ(n) =M(n)+Y(n), where
t t∧τn t t
M t (n) =2
(cid:90) t∧τn(cid:10)
σ−b irr (x s ),dw s (cid:11) , and, Y t (n) =2
(cid:90) t∧τn(cid:12)
(cid:12)σ−b irr (x s ) (cid:12) (cid:12) 2 ds.
0 0
We also define M t =2 (cid:82) 0 t(cid:10) σ−b irr (x s ),dw s (cid:11) and Y t =2 (cid:82) 0 t(cid:12) (cid:12)σ−b irr (x s ) (cid:12) (cid:12) 2ds.
55
From assumption 3, we have
(cid:90)
(cid:12) (cid:12)σ−b irr (x) (cid:12) (cid:12) 2 ρ(x)dx= 2
1(cid:90)
b⊤ irr D−b irr ρ(x)dx<+∞.
Rd Rd
Thus, we obtain that
E P (cid:12) (cid:12) (cid:12) M t (n)−M t (cid:12) (cid:12) (cid:12) 2 =4E P (cid:12) (cid:12) (cid:12) (cid:12) (cid:90) t (cid:10) σ−b irr (x s )1 {s>τn} ,dw s (cid:11) (cid:12) (cid:12) (cid:12) (cid:12) 2
0
(cid:90) t
=4E P (cid:12) (cid:12)σ−b irr (x s ) (cid:12) (cid:12) 21 {s>τn} ds (Itô’s isometry)
0
−n−→−−+−∞→0,
E P (cid:12) (cid:12) (cid:12) Y t (n)−Y t (cid:12) (cid:12) (cid:12) =2E P (cid:90) t (cid:12) (cid:12)σ−b irr (x s ) (cid:12) (cid:12) 21 {s>τn} ds−n−→−−+−∞→0.
0
(cid:16) (cid:17)
Thus, −logZ =M +Y . By Itô calculus, M is a martingale on the probability space Ω,F,{F } ,P , and in
t t t t t t≥0
particular E [M ]=0.
P t
Let T >0. Let (cid:0) C([0,T],Rd),B(cid:1) denote the path space, where B is the Borel sigma-algebra generated by the sup
norm∥·∥ . Denotetrajectoriesoftheprocessbyx :=(x ) :Ω→C([0,T],Rd). BydefinitionofItôcalculus,
∞ • t t∈[0,T]
Z is measurable with respect to ⟨x : 0 ≤ t ≤ T⟩, so there exists a positive measurable function ZC on the path
T s T
space, such that P-a.s. ZC(x (ω))=Z (ω) for ω∈Ω, i.e., the following diagram commutes
T • T
C([0,T],Rd)
x• ZT C
Ω R .
ZT >0
Note that the path space (cid:0) C([0,T],Rd),B(cid:1) admits a canonical filtration (B ) , where
t t∈[0,T]
(cid:110) (cid:16) (cid:17)(cid:111)
B = A⊂C([0,T],Rd): A| ∈Borel sigma-algebra on C([0,t],Rd),∥·∥ .
t [0,t] ∞
For any path γ ∈C([0,T],Rd) and n∈N, we define the hitting time t (γ)=inf{t≥0:|γ |>n}.
n t
Claim: Thesehittingtimesarestoppingtimeswrttothecanonicalfiltration,i.e.,{γ ∈C([0,T],Rd):t (γ)≤t}∈B
n t
for any t∈[0,T].
Proof of claim. Let A:={γ ∈C([0,T],Rd):t (γ)≤t}. Then,
n
A| ={γ ∈C([0,t],Rd):t (γ)≤t}
[0,t] n
(cid:110) (cid:111)
= γ ∈C([0,t],Rd):min{s≥0:|γ |>n}≤t (continuity of γ)
s
(cid:110) (cid:111)
= γ ∈C([0,t],Rd):∥γ∥ >n ,
∞
which is clearly a Borel set in (cid:0) C([0,t],Rd),∥·∥ (cid:1). ■
∞
Thus we can define stopping time sigma-algebras in the usual way
(cid:110) (cid:111)
B = A∈B :A∩{γ ∈C([0,T],Rd):T ∧t (γ)≤t}∈B ,∀t∈[0,T] .
T∧tn T n t
We showed above that, under P,P¯ , the distributions of x restricted to (C([0,T],Rd),B ) are P :=
n T∧tn [0,T∧tn]
P [0,T] (cid:12) (cid:12) B
T∧tn
and P¯ [0,T∧tn] := P¯ [0,T] (cid:12) (cid:12) B
T∧tn
, respectively.
56
By inspection, we have, for any t≥0,

{T <τ
n
}∈F
T
⊂F
t
if T ≤t
{T <τ }∩{T ∧τ ≤t}=
n n
∅⊂F if T >t.
t
Settingt=T∧τ ,wehave{T <τ }∈F ,whichalsoyields{T ≥τ }∈F and{τ ≤T <τ }∈F .
n n T∧τn n T∧τn n−1 n T∧τn
Fixi≥0andA∈B . Thenx−1A∈F asx ismeasurable. Thusx−1A∩{T <τ }⊂F andx−1A∩{τ ≤
T∧ti • • • i T∧τi • n−1
T <τ }⊂F for any n>i. Finally,
n T∧τn
(cid:104) (cid:105) (cid:104) (cid:105)
E ZC1 =E Z 1
P T A P T x−
•
1A
=E (cid:104) Z(i)1 (cid:105) + (cid:88) +∞ E (cid:104) Z(n)1 (cid:105)
P T x− • 1A∩{T<τi} P T x− • 1A∩{τn−1≤T<τn }
n=i+1
(cid:104) (cid:105) (cid:88) +∞ (cid:104) (cid:105)
=E P¯ i 1 x− • 1A∩{T<τi} + E P¯ n 1 x− • 1A∩{τn−1≤T<τn }
n=i+1
=E P¯ (cid:2)1 A∩{T<ti} (cid:3) + (cid:88) +∞ E P¯ (cid:104) 1 A∩{tn−1≤T<tn } (cid:105) =E P¯ [1 A ].
n=i+1
From the arbitrariness of i and that lim τ =+∞ P-a.s., it follows that
n→∞ n
dP¯
[0,T] =ZC.
dP T
[0,T]
Finally, we compute the relative entropy between the forward and backward path-space measures
H (cid:2) P ,P¯ (cid:3) =E (cid:20) log dP [0,T](γ) (cid:21)
[0,T] [0,T] P dP¯
[0,T]
(cid:20) dP (cid:21)
=E log [0,T](x(ω))
P dP¯
[0,T]
=0
(cid:104) (cid:105) (cid:122) (cid:125)(cid:124) (cid:123)
=E −logZC(x(ω)) =E [−logZ ]=E [M ]+E [Y ]
P T P T P T P T
(cid:20) (cid:90) T (cid:21) (cid:90)
=E P 2 (cid:12) (cid:12)σ−b irr (x s ) (cid:12) (cid:12) 2 ds =2T (cid:12) (cid:12)σ−b irr (x) (cid:12) (cid:12) 2 ρ(x)dx
0 Rd
(cid:90)
=T b⊤D−b ρ(x)dx,
irr irr
Rd
where we used Tonelli’s theorem and stationarity for the penultimate equality. By Theorem 2.3.5, we obtain the
entropy production rate
e = 1 H (cid:2) P ,P¯ (cid:3) = (cid:90) b⊤D−b ρ(x)dx.
p T [0,T] [0,T] irr irr
Rd
We now prove Theorem 2.5.2:
Proof. By assumption 1, for ρ-a.e. x∈Rd
b (x)∈Rangeσ(x)⇒b (x)=σσ−b (x). (2.48)
irr irr irr
57
Then, (2.48) implies that we can rewrite the SDE (2.5) as
dx =b (x )dt+σ(x ) (cid:2) σ−b (x )dt+dw (cid:3) , x ∼ρ.
t rev t t irr t t 0
By assumptions 2, 3, we may define a new probability measure P¯ on the sample space Ω through the relation
d d P
P¯(cid:12)
(cid:12) (cid:12) (cid:12) =Z T , (2.49)
F
T
anditfollowsbyGirsanov’stheorem[83,Theorem10.14]appliedtotheprocess−2σ−b (x ),that(x ) solves
irr t t t∈[0,T]
the SDE
dx =b (x )dt−σ(x ) (cid:2) σ−b (x )dt+dw (cid:3) , x ∼ρ.
t rev t t irr t t 0
on the probability space (Ω,F,{F } ,P¯). Using (2.48), (x ) solves
t t≥0 t t∈[0,T]
dx =¯b(x )dt+σ(x )dw , x ∼ρ
t t t t 0
on said probability space. By Theorem 2.4.5 we know that under P¯, (x ) induces the path space measure of
t t∈[0,T]
the time-reversed process.
Let (cid:0) C([0,T],Rd),B(cid:1) denote the path space, where B is the Borel sigma-algebra generated by the sup norm ∥·∥ .
∞
Denote trajectories of the process by x :=(x ) :Ω→C([0,T],Rd). In summary, we showed that, under P,P¯,
• t t∈[0,T]
the distribution of x on (C([0,T],Rd),B) are P and P¯ , respectively.
• [0,T] [0,T]
BydefinitionofItôcalculus,Z ismeasurablewithrespectto⟨x :0≤t≤T⟩,sothereexistsapositivemeasurable
T s
functionZC onthepathspace,suchthatP-a.s. ZC(x (ω))=Z (ω)forω∈Ω,i.e.,thefollowingdiagramcommutes
T T • T
C([0,T],Rd)
x• ZT C
Ω R .
ZT >0
Fix A∈B. Then x−1A∈F as x is measurable. Obviously,
• •
(cid:104) (cid:105) (cid:104) (cid:105) (cid:104) (cid:105)
E P Z T C1 A =E P Z T 1 x−
•
1A =E P¯ 1 x−
•
1A =E P¯ [1 A ].
It follows that
dP¯
[0,T] =ZC.
dP T
[0,T]
58
Through this, we obtain the relative entropy between the forward and backward path-space measures
H (cid:2) P ,P¯ (cid:3) =E (cid:20) log dP [0,T](γ) (cid:21)
[0,T] [0,T] P dP¯
[0,T]
(cid:20) dP (cid:21)
=E log [0,T](x(ω))
P dP¯
[0,T]
(cid:104) (cid:105)
=E −logZC(x(ω)) =E [−logZ ]
P T P T
(cid:20) (cid:90) T (cid:21) (cid:20) (cid:90) T (cid:21)
=E 2 ⟨σ−b (x ),dw ⟩ +E 2 |σ−b (x )|2dt
P irr t t P irr t
0 0
(cid:90)
=2T (cid:12) (cid:12)σ−b irr (x) (cid:12) (cid:12) 2 ρ(x)dx
Rd
(cid:90)
=T b⊤D−b ρ(x)dx.
irr irr
Rd
The penultimate equality follows from the fact that Itô stochastic integrals are martingales (and hence vanish in
expectation), Tonelli’s theorem and stationarity. Finally, by Theorem 2.3.5, we obtain the entropy production rate
e = 1 H (cid:2) P ,P¯ (cid:3) = (cid:90) b⊤D−b ρ(x)dx.
p T [0,T] [0,T] irr irr
Rd
We prove Proposition 2.5.3:
Proof. 1. Follows as Z =1 and by definition of a martingale.
0
We define the F -adapted process ψ =−2σ−b (x ).
t t irr t
2 ⇒ 1. This follows from [84, Theorem 1].
(cid:16) (cid:17)
3. By[83,Proposition10.17(ii)],asufficientconditionfor(2.20)istheexistenceofaδ>0suchthatsup
t∈[0,T]
E
P
eδ|ψt|2 <
(cid:16) (cid:17) (cid:16) (cid:17)
+∞. By stationarity of x
t
at ρ, E
P
eδ|ψt|2 =E
ρ
e4δ|σ−birr(x)|2 , and so the result follows.
4 ⇒ 1. Follows from [84, Theorem 1].
5 ⇒ 2. A t := 2 1(cid:82) 0 t|ψ s |2ds=2 (cid:82) 0 t(cid:12) (cid:12)σ−b irr (x s ) (cid:12) (cid:12) 2dsisanon-decreasing,F t -adaptedprocess. Byassumption,E P [A T −A t |F t ]≤
K for all t∈[0,T]. By [85, Theorem 105 (b)] E [exp(A )]<+∞.
P T
6 ⇒ 3. Let δ∈(0,c). The first equality follows a standard fact about non-negative random variables:
E (cid:104) eδ|σ−birr(x)|2(cid:105) = (cid:90) ∞ P (cid:16) eδ|σ−birr(x)|2 >r (cid:17) dr
ρ
0
≤1+
(cid:90) ∞
P
(cid:16) eδ|σ−birr(x)|2
>r
(cid:17)
dr
ecR
(cid:90) ∞
=1+ P (cid:0) |σ−b (x)|2 >δ−1logr (cid:1) dr
irr
ecR
(cid:90) ∞
≤1+C r−cδ−1 dr (by 6 as δ−1logr>R)
ecR
<+∞.
59
Singularity
We prove Theorem 2.5.4:
Proof. Under the assumption that b (x)∈Rangeσ(x) does not hold for ρ-a.e. x∈Rd, we will show that there are
irr
paths taken by the forward process that are not taken by the backward process—and vice-versa—resulting in the
mutual singularity of forward and backward path space measures.
Recall from Theorem 2.4.5 that any solution to the following SDE
dx¯ =¯b(x¯ )dt+σ(x¯ )dw , x¯ ∼ρ, (2.50)
t t t t 0
induces the path space measure of the time-reversed process.
We rewrite the forward and backward SDEs into their equivalent Stratonovich SDEs [3, eq. 3.31]
dx =bs(x )dt+σ(x )◦dw , x ∼ρ,
t t t t 0
dx¯ =¯bs(x¯ )dt+σ(x¯ )◦dw , x¯ ∼ρ,
t t t t 0
ByRemark2.4.9,time-reversalandthetransformationfromItôtoStratonovichcommuteso¯bs isunambiguous,and
b =bs(x)−¯bs(x). The volatility and Stratonovich drifts are locally Lipschitz as σ∈C2.
irr
Consider an initial condition x=x =x¯ to the trajectories, with ρ(x)>0. Consider trajectories in the Cameron-
0 0
Martin space
γ ∈C :={γ ∈AC([0,T];Rm) | γ(0)=0 and γ˙ ∈L2([0,T];Rm)}
Given such a trajectory, the approximating ODEs
dx =bs(x )dt+σ(x )dγ , x =x,
t t t t 0
dx¯ =¯bs(x¯ )dt+σ(x¯ )dγ , x¯ =x,
t t t t 0
have a unique solution in [0,T], with T >0 uniform in γ.
We can thus apply the Stroock-Varadhan support theorem [86, Theorem 3.10] to state the possible paths under the
forward and backward protocols. These are as follows
(cid:26) (cid:90) t (cid:90) t (cid:27)
suppPx = xγ =x+ bs(xγ)ds+ σ(xγ)γ′(s)ds,t∈[0,T]|γ ∈C ,
[0,T] t s s
0 0
(cid:26) (cid:90) t (cid:90) t (cid:27)
suppP¯x = x¯γ =x+ ¯bs(x¯γ)ds+ σ(x¯γ)γ′(s)ds,t∈[0,T]|γ ∈C .
[0,T] t s s
0 0
where the closure is with respect to the supremum norm on C (cid:0) [0,T];Rd(cid:1). The time derivatives of these paths at
t=0 are
∂ suppPx | ={∂ xγ| ∈Rd |γ ∈C}={bs(x)+σ(x)v|v∈Rd},
t [0,T] t=0 t t t=0
∂ suppP¯x | ={∂ x¯γ| ∈Rd |γ ∈C}={¯bs(x)+σ(x)v|v∈Rd}.
t [0,T] t=0 t t t=0
where the closure is with respect to the sup norm on Rd.
60
Consider an initial condition x with b (x) ̸∈ Rangeσ(x). This implies that the forward and backward path space
irr
measures are mutually singular because the time derivatives of the possible paths differ at the origin
2b (x)=bs(x)−¯bs(x)̸∈Rangeσ(x)
irr
⇐⇒bs(x)+Rangeσ(x)̸=¯bs(x)+Rangeσ(x)
⇐⇒∂ suppPx | ̸⊂∂ suppP¯x | and vice-versa
t [0,T] t=0 t [0,T] t=0
⇒suppPx ̸⊂suppP¯x and vice-versa
[0,T] [0,T]
⇒Px ⊥P¯x
[0,T] [0,T]
Finally, from Proposition 2.3.8
e =E (cid:2) H (cid:2) Px |P¯x (cid:3)(cid:3)
p x∼ρ [0,T] [0,T]
(cid:16) (cid:17)
≥ρ {x∈Rd |Px ⊥P¯x } ·∞
[0,T] [0,T]
(cid:16) (cid:17)
≥ρ {x∈Rd :b (x)̸∈Rangeσ(x)} ·∞
irr
(cid:124) (cid:123)(cid:122) (cid:125)
>0
=+∞.
2.8.4 Entropy production rate of the linear diffusion process
We require the following Lemma, which can be proved by adjusting the derivation of the relative entropy between
non-degenerate Gaussian distributions, cf. [87, Section 9].
Lemma 2.8.1. On Rd
2H[N(µ ,Σ )|N(µ ,Σ )]=tr (cid:0) Σ−Σ (cid:1) −rankΣ +log
(cid:18) det∗Σ
1
(cid:19)
0 0 1 1 1 0 0 det∗Σ
0
+(µ −µ )⊤Σ−(µ −µ ).
1 0 1 1 0
where ·− is the Moore-Penrose pseudo-inverse and det∗ is the pseudo-determinant.
Proof of Lemma 2.6.1. We insert the definitions of the transition kernels (2.25) into Lemma 2.8.1.
E [2H[p (·,x)|p¯ (·,x)]]
x∼ρ ε ε
det∗(S¯ )
=Tr(S¯−S )−rankσ+log ε
ε ε det∗(S )
ε
(cid:104) (cid:105)
+E x⊤(e−εC−e−εB)⊤S¯−(e−εC−e−εB)x
x∼ρ ε
det∗(S¯ )
=Tr(S¯−S )−rankσ+log ε
ε ε det∗(S )
ε
+Tr(Π−1(e−εC−e−εB)⊤S¯−(e−εC−e−εB))
ε
Toobtainthelastline,weusedthetracetrickforcomputingGaussianintegralsofbilinearforms. Theprooffollows
by Proposition 2.3.10.
61
Chapter 3
Bayesian mechanics
Bayesian mechanics for stationary processes
By Lancelot Da Costa, Karl Friston, Conor Heins, Grigorios A. Pavliotis
Adapted from: L Da Costa, K Friston, C Heins, GA Pavliotis. Bayesian mechanics for stationary
processes. Proceedings of the Royal Society A. 2021.
62
3.1 Abstract
This chapter develops a Bayesian mechanics for adaptive systems.
Firstly,wemodeltheinterfacebetweenasystemanditsenvironmentwithaMarkovblanket. Thisaffordsconditions
under which states internal to the blanket encode information about external states.
Second, we introduce dynamics and represent adaptive systems as Markov blankets at steady-state. This allows us
to identify a wide class of systems whose internal states appear to infer external states, consistent with variational
inference in Bayesian statistics and theoretical neuroscience.
Finally,wepartitiontheblanketintosensoryandactivestates. Itfollowsthatactivestatescanbeseenasperforming
activeinferenceandwell-knownformsofstochasticcontrol(suchasPIDcontrol), whichareprominentformulations
of adaptive behaviour in theoretical biology and engineering.
Keywords: Markovblanket,variationalBayesianinference,activeinference,non-equilibriumsteady-state,predictive
processing, free-energy principle
3.2 Introduction
Any object of study must be, implicitly or explicitly, separated from its environment. This implies a boundary that
separates it from its surroundings, and which persists for at least as long as the system exists.
Inthisarticle,weexploretheconsequencesofaboundarymediatinginteractionsbetweenstatesinternalandexternal
to a system. This provides a useful metaphor to think about biological systems, which comprise spatially bounded,
interactingcomponents,nestedatseveralspatialscales[88,89]: forexample,themembraneofacellactsasaboundary
through which the cell communicates with its environment, and the same can be said of the sensory receptors and
muscles that bound the nervous system.
By examining the dynamics of persistent, bounded systems, we identify a wide class of systems wherein the states
internaltoaboundaryappeartoinferthosestatesoutsidetheboundary—adescriptionwhichwerefertoasBayesian
mechanics. Moreover, if we assume that the boundary comprises sensory and active states, we can identify the
dynamicsofactivestateswithwell-knowndescriptionsofadaptivebehaviourfromtheoreticalbiologyandstochastic
control.
In what follows, we link a purely mathematical formulation of interfaces and dynamics with descriptions of belief
updating and behaviour found in the biological sciences and engineering. Altogether, this can be seen as a model of
adaptiveagents,astheseinterfacewiththeirenvironmentthroughsensoryandactivestatesandfurthermorebehave
so as to preserve a target steady-state.
3.2.1 Outline of chapter
This chapter has three parts, each of which introduces a simple, but fundamental, move.
1. ThefirstistopartitiontheworldintointernalandexternalstateswhoseboundaryismodelledwithaMarkov
blanket [90,91]. This allows us to identify conditions under which internal states encode information about
external states.
63
2. Thesecondmoveistoequipthispartitionwithstochasticdynamics. Thekeyconsequenceofthisisthatinternal
states can be seen as continuously inferring external states, consistent with variational inference in Bayesian
statistics and with predictive processing accounts of biological neural networks in theoretical neuroscience.
3. The third move is to partition the boundary into sensory and active states. It follows that active states can
be seen as performing active inference and stochastic control, which are prominent descriptions of adaptive
behaviour in biological agents, machine learning and robotics.
3.2.2 Related work
Theemergenceandsustainingofcomplex(dissipative)structureshavebeensubjectsoflong-standingresearchstarting
from the work of Prigogine [92,93], followed notably by Haken’s synergetics [94], and in recent years, the statistical
physics of adaptation [95]. A central theme of these works is that complex systems can only emerge and sustain
themselves far from equilibrium [96–98].
Information processing has long been recognised as a hallmark of cognition in biological systems. In light of this,
theoretical physicists have identified basic instances of information processing in systems far from equilibrium using
tools from information theory, such as how a drive for metabolic efficiency can lead a system to become predictive
[99–102].
Afundamentalaspectofbiologicalsystemsisaself-organisationofvariousinteractingcomponentsatseveralspatial
scales [88,89]. Much research currently focuses on multipartite processes—modelling interactions between various
sub-componentsthatformbiologicalsystems—andhowtheirinteractionsconstrainthethermodynamicsofthewhole
[6,103–106].
Attheconfluenceoftheseefforts,researchershavesoughttoexplaincognitioninbiologicalsystems. Sincetheadvent
ofthe20thcentury,Bayesianinferencehasbeenusedtodescribevariouscognitiveprocessesinthebrain[1,107–110].
Inparticular,thefreeenergyprinciple[1],aprominenttheoryofself-organisationfromtheneurosciences,postulates
thatBayesianinferencecanbeusedtodescribethedynamicsofmultipartite,persistentsystemsmodelledasMarkov
blankets at non-equilibrium steady-state [8,9,111–113].
This chapter connects and develops some of the key themes from this literature. Starting from fundamental con-
siderations about adaptive systems, we develop a physics of things that hold beliefs about other things–consistently
with Bayesian inference–and explore how it relates to known descriptions of action and behaviour from the neuro-
sciencesandengineering. Ourcontributionistheoretical: fromabiophysicist’sperspective,thischapterdescribeshow
Bayesian descriptions of biological cognition and behaviour can emerge from standard accounts of physics. From an
engineer’sperspectivethischaptercontextualisessomeofthemostcommonstochasticcontrolmethodsandreminds
us how these can be extended to suit more sophisticated control problems.
3.2.3 Notation
Let Π∈Rd×d be a square matrix with real coefficients. Let η,b,µ denote a partition of the states [[1,d]], so that
 
Π Π Π
η ηb ηµ
Π=Π Π Π .
 bη b bµ
Π Π Π
µη µb µ
Wedenoteprincipalsubmatriceswithoneindexonly(i.e.,weuseΠ insteadofΠ ). Similarly,principalsubmatrices
η ηη
involving various indices are denoted with a colon
64
(cid:34) (cid:35)
Π Π
Π := η ηb .
η:b
Π Π
bη b
WhenasquarematrixΠissymmetricpositive-definitewewriteΠ≻0. ker,Imand·− respectivelydenotethekernel,
image and Moore-Penrose pseudo-inverse of a linear map or matrix, e.g., a non-necessarily square matrix such as
Π . In our notation, indexing takes precedence over (pseudo) inversion, for example,
µb
Π− :=(Π )− ̸=(Π−) .
µb µb µb
3.3 Markov blankets
The section formalises the notion of boundary between a system and its environment as a Markov blanket [90,91],
depicted graphically in Figure 3.1. Intuitive examples of a Markov blanket are that of a cell membrane, mediating
all interactions between the inside and the outside of the cell, or that of sensory receptors and muscles that bound
the nervous system.
Figure 3.1: Markov blanket depicted graphically as an undirected graphical model, also known as a Markov random field
[91,114]. (AMarkovrandomfieldisaBayesiannetworkwhosedirectedarrowsarereplacedbyundirectedarrows). Thecircles
represent random variables. The lines represent conditional dependencies between random variables. The Markov blanket
condition means that there is no line between µ and η. This means that, µ and η are conditionally independent given b. In
otherwords,knowingtheinternalstateµ,doesnotaffordadditionalinformationabouttheexternalstateη whentheblanket
statebisknown. Thusblanketstatesactasaninformationalboundarybetweeninternalandexternalstates.
To formalise this intuition, we model the world’s state as a random variable x with corresponding probability distri-
bution p over a state-space X =Rd. We partition the state-space of x into external, blanket and internal states:
x=(η,b,µ)
X =E×B×I.
External, blanket and internal state-spaces (E,B,I) are taken to be Euclidean spaces for simplicity.
A Markov blanket is a statement of conditional independence between internal and external states given blanket
states.
Definition 3.3.1 (Markov blanket). A Markov blanket is defined as
η⊥µ|b (M.B.)
That is, blanket states are a Markov blanket separating µ,η [90,91].
65
The existence of a Markov blanket can be expressed in several equivalent ways
(M.B.) ⇐⇒ p(η,µ|b)=p(η|b)p(µ|b) ⇐⇒ p(η|b,µ)=p(η|b) ⇐⇒ p(µ|b,η)=p(µ|b). (3.1)
Fornow,wewillconsidera(non-degenerate)Gaussiandistributionpencodingthedistributionofstatesoftheworld
p(x):=N(x;0,Π−1), Π≻0,
with associated precision (i.e., inverse covariance) matrix Π. Throughout, we will denote the (positive definite)
covariancebyΣ:=Π−1. Unpacking(3.1)intermsofGaussiandensities,wefindthataMarkovblanketisequivalent
to a sparsity in the precision matrix
(M.B.) ⇐⇒ Π =Π =0. (3.2)
ηµ µη
Example 3.3.2. For example,
 
2 1 0 (cid:34) (cid:35) (cid:34) (cid:35)
2 1 1.5 1
Π=1 2 1⇒Σ−1 = ,Σ−1 =
  η:b 1 1.5 b:µ 1 2
0 1 2
Then,
(cid:18) (cid:19)
1
p(η,µ|b)∝p(η,µ,b)∝exp − x·Πx
2
(cid:32) (cid:34) (cid:35) (cid:34) (cid:35)(cid:33)
1(cid:104) (cid:105) η 1(cid:104) (cid:105) b
∝exp − η,b Σ−1 − b,µ Σ−1 ∝p(η,b)p(b,µ)∝p(η|b)p(µ|b).
2 η:b b 2 b:µ µ
Thus, the Markov blanket condition (3.1) holds.
3.3.1 Expected internal and external states
Blanket states act as an information boundary between external and internal states. Given a blanket state, we can
express the conditional probability densities over external and internal states (using (3.1) and [115, Prop. 3.13])1
p(η|b)=N(η;Σ Σ−1b, Π−1),
ηb b η (3.3)
p(µ|b)=N(µ;Σ Σ−1b, Π−1).
µb b µ
This enables us to associate to any blanket state its corresponding expected external and expected internal states:
η(b)=E[η|b]=E [η]=Σ Σ−1b∈E
p(η|b) ηb b
µ(b)=E[µ|b]=E [µ]=Σ Σ−1b∈I.
p(µ|b) µb b
1NotethatΠη,Πµ areinvertibleasprincipalsubmatricesofapositivedefinitematrix.
66
Pursuing the example of the nervous system, each sensory impression on the retina and oculomotor orientation
(blanket state) is associated with an expected scene that caused sensory input (expected external state) and an
expected pattern of neural activity in the visual cortex (expected internal state) [116].
3.3.2 Synchronisation map
A central question is whether and how expected internal states encode information about expected external states.
For this, we need to characterise a synchronisation function σ, mapping the expected internal state to the expected
external state, given a blanket state σ(µ(b))=η(b). This is summarised in the following commutative diagram:
b∈B
η µ
Image(η) Image(µ)
σ
Theexistenceofσisguaranteed,forinstance,iftheexpectedinternalstatecompletelydeterminestheblanketstate—
that is, when no information is lost in the mapping b (cid:55)→ µ(b) in virtue of it being one-to-one. In general, however,
many blanket states may correspond to an unique expected internal state. Intuitively, consider the various neural
pathwaysthatcompressthesignalarrivingfromretinalphotoreceptors[117],thusmanydifferent(hopefullysimilar)
retinal impressions lead to the same signal arriving in the visual cortex.
Existence
Thekeyfortheexistenceofafunctionσ mappingexpectedinternalstatestoexpectedexternalstatesgivenblanket
states, is that for any two blanket states associated with the same expected internal state, these be associated with
the same expected external state. This non-degeneracy means that the internal states (e.g., patterns of activity in
the visual cortex) have enough capacity to represent all possible expected external states (e.g., 3D scenes of the
environment). We formalise this in the following Lemma:
Lemma 3.3.3. The following are equivalent:
1. There exists a function σ:Image(µ)→Image(η) such that for any blanket state b∈B
σ(µ(b))=η(b).
2. For any two blanket states b ,b ∈B
1 2
µ(b )=µ(b )⇒η(b )=η(b ).
1 2 1 2
3. kerΣ ⊂kerΣ .
µb ηb
4. kerΠ ⊂kerΠ .
µb ηb
See Section 3.8.1 for a proof of Lemma 3.3.3.
Example 3.3.4. • When external, blanket and internal states are one-dimensional, the existence of a synchro-
nisation map is equivalent to Π ̸=0 or Π =Π =0.
µb µb ηb
67
• If Π is chosen at random–its entries sampled from a non-degenerate Gaussian or uniform distribution–then
µb
Π hasfullrankwithprobability1. Iffurthermoretheblanketstate-spaceBhaslowerorequaldimensionality
µb
than the internal state-space I, we obtain that Π is one-to-one (i.e., kerΠ =0) with probability 1. Thus,
µb µb
in this case, the conditions of Lemma 3.3.3 are fulfilled with probability 1.
Construction
Thekeyideatomapanexpectedinternalstateµ(b)toanexpectedexternalstateη(b)isto: 1)findablanketstate
thatmapstothisexpectedinternalstate(i.e.,byinvertingµ)and2)fromthisblanketstate,findthecorresponding
expected external state (i.e., by applying η):
b∈B
η µ
µ−
Image(η) Image(µ)
σ=η◦µ−
We now proceed to solving this problem. Given an internal state µ, we study the set of blanket states b such that
µ(b)=µ
µ(b)=Σ Σ−1b=µ ⇐⇒ b∈µ−1(µ)=Σ Σ−1µ. (3.4)
µb b b µb
Here the inverse on the right hand side of (3.4) is understood as the preimage of a linear map. We know that this
system of linear equations has a vector space of solutions given by [118]
µ−1(µ)= (cid:8) Σ Σ−µ+ (cid:0) Id−Σ Σ−Σ Σ−1(cid:1) b:b∈B (cid:9) . (3.5)
b µb b µb µb b
Among these, we choose
µ−(µ)=Σ Σ−µ.
b µb
Definition 3.3.5 (Synchronisation map). We define a synchronisation function that maps to an internal state a
corresponding most likely internal state23
σ:Imµ→Imη
µ(cid:55)→η(µ−(µ))=Σ Σ−µ=Π−1Π Π−Π µ.
ηb µb η ηb µb µ
The expression in terms of the precision matrix is a byproduct of Section 3.8.1.
Note that we can always define such σ, however, it is only when the conditions of Lemma 3.3.3 are fulfilled that σ
maps expected internal states to expected external states σ(µ(b)) = η(b). When this is not the case, the internal
states do not fully represent external states, which leads to a partly degenerate type of representation, see Figure
3.2 for a numerical illustration obtained by sampling from a Gaussian distribution, in the non-degenerate (left) and
degenerate cases (right), respectively.
2Thismappingwasderivedindependentlyofourworkin[119,Section3.2].
3Replacingµ−(µ)byanyotherelementof (3.5)wouldleadtothesamesynchronisationmapprovidedthattheconditions
ofLemma3.3.3aresatisfied.
68
Figure 3.2: Synchronisation map: example and non-example. This figure plots expected external states given blanket
statesη(b)(inorange),andthecorrespondingpredictionencodedbyinternalstatesσ(µ(b))(inblue). Inthisexample,external,
blanketandinternalstate-spacesaretakentobeonedimensional. WeshowthecorrespondenceundertheconditionsofLemma
3.3.3(leftpanel)andwhenthesearenotsatisfied(rightpanel). Togeneratethesedata,1)wedrew106samplesfromaGaussian
distribution with a Markov blanket, 2) we partitioned the blanket state-space into several bins, 3) we obtained the expected
externalandinternalstatesgivenblanketstatesempiricallybyaveragingsamplesfromeachbin,andfinally,4)weappliedthe
synchronisationmaptothe(empirical)expectedinternalstatesgivenblanketstates.
3.4 Bayesian mechanics
In order to study the time-evolution of systems with a Markov blanket, we introduce dynamics into the external,
blanket and internal states. Henceforth, we assume a synchronisation map under the conditions of Lemma 3.3.3.
3.4.1 Processes at a Gaussian steady-state
We consider stochastic processes at a Gaussian steady-state p with a Markov blanket. The steady-state assumption
meansthatthesystem’soverallconfigurationpersistsovertime(e.g.,itdoesnotdissipate). Inotherwords,wehave
a Gaussian density p = N(0,Π−1) with a Markov blanket (3.2) and a stochastic process distributed according to p
at every point in time
x ∼p=N(0,Π−1) for any t.
t
Recalling our partition into external, blanket and internal states, this affords a Markov blanket that persists over
time, see Figure 3.3
x =(η ,b ,µ )∼p⇒η ⊥µ |b . (3.6)
t t t t t t t
Note that we do not require x to be independent samples from the steady-state distribution p. On the contrary, x
t t
maybegeneratedbyextremelycomplex,non-linear,andpossiblystochasticequationsofmotion. SeeExample3.4.1
and Figure 3.4 for details.
Example3.4.1. Thedynamicsofx aredescribedbyastochasticprocessataGaussiansteady-statep=N(0,Π−1).
t
There is a large class of such processes, for example:
• Stationarydiffusionprocesses,withinitialconditionx ∼p. Theirtime-evolutionisgivenbyanItôstochastic
0
69
Figure3.3: Markov blanket evolving in time. Weuse abacillustodepictanintuitiveexampleofaMarkovblanketthat
persistsovertime. Here,theblanketstatesrepresentthemembraneandactinfilamentsofthecytoskeleton,whichmediateall
interactionsbetweeninternalstatesandtheexternalmedium(externalstates).
Figure3.4: Processes at a Gaussian steady-state. Thisfigureillustratesthesynchronisationmapandtransitionprobabil-
ities of processes at a Gaussian steady-state. Left: We plot the synchronisation map as in Figure 3.2, only, here, the samples
are drawn from trajectories of a diffusion process (3.7) with a Markov blanket. Although this is not the case here, one might
obtainaslightlynoisiercorrespondencebetweenpredictionsσ(µ(bt))andexpectedexternalstatesη(bt)—comparedtoFigure
3.2—in numerical discretisations of a diffusion process. This is because the steady-state of a numerical discretisation usually
differsslightlyfromthesteady-stateofthecontinuous-timeprocess[70]. Right: Thispanelplotsthetransitionprobabilitiesof
thesamediffusionprocess(3.7),fortheblanketstateattwodifferenttimes. Thejointdistribution(depictedasaheatmap)is
not Gaussian but its marginals—the steady-state density—are Gaussian. This shows that in general, processes at a Gaussian
steady-statearenotGaussianprocesses. Infact,theOrnstein-Uhlenbeckprocessistheonlystationarydiffusionprocess(3.7)
thatisaGaussianprocess,sothetransitionprobabilitiesofnon-lineardiffusionprocesses(3.7)arenevermultivariateGaussians.
70
differential equation (see Section 2.4.4):
dx =(Γ+Q)(x )∇logp(x )dt+∇·(Γ+Q)(x )dt+ς(x )dW ,
t t t t t t
=−(Γ+Q)(x )Πx dt+∇·(Γ+Q)(x )dt+ς(x )dW (3.7)
t t t t t
Γ:=ςς⊤/2, Q=−Q⊤.
Here,W isastandardBrownianmotion(a.k.a.,Wienerprocess)[3,120]andς,Γ,Qaresufficientlywell-behaved
t
matrixfields(seeSection2.4.4). Namely,Γisthediffusiontensor(halfthecovarianceofrandomfluctuations),
which drives dissipative flow; Q is an arbitrary antisymmetric matrix field which drives conservative (i.e.,
solenoidal)flow. Weemphasisethattherearenonon-degeneracyconditionsonthematrixfieldς—inparticular,
the process is allowed to be non-ergodic or even completely deterministic (i.e., ς ≡ 0). Also, ∇· denotes the
divergence of a matrix field defined as (∇·(Γ+Q)) := (cid:80) ∂ (Γ+Q) .
i j ∂xj ij
• More generally, x could be generated by any Markov process at steady-state p, such as the zig-zag process or
t
the bouncy particle sampler [121–123], by any mean-zero Gaussian process at steady-state p [124] or by any
random dynamical system at steady-state p [125].
Remark 3.4.2. WhenthedynamicsaregivenbyanItôstochasticdifferentialequation(3.7),aMarkovblanketofthe
steady-statedensity (3.2)doesnotprecludereciprocalinfluencesbetweeninternalandexternalstates[126,127]. For
example,
   
2 1 0 0 0 1
Π=  1 2 1  , Q≡  0 0 0  , ς ≡Id 3
0 1 2 −1 0 0
    
η 1 1.5 2 η
t t
⇒d  b t   =−  0.5 1 0.5    b t   dt+ςdW t .
µ −2 −0.5 1 µ
t t
Conversely, the absence of reciprocal coupling between two states in the drift in some instances, though not always,
leads to conditional independence [9,119,126].
3.4.2 Maximum a posteriori estimation
The Markov blanket (3.6) allows us to harness the construction of Section 3.3 to determine expected external and
internal states given blanket states
η :=η(b ) µ :=µ(b ).
t t t t
Note that η,µ are linear functions of blanket states; since b generally exhibits rough sample paths, η ,µ will also
t t t
exhibit very rough sample paths.
Wecanviewthesteady-statedensitypasspecifyingtherelationshipbetweenexternalstates(η,causes)andparticular
states (b,µ, consequences). In statistics, this corresponds to a generative model, a probabilistic specification of how
(external) causes generate (particular) consequences.
By construction, the expected internal states encode expected external states via the synchronisation map
σ(µ )=η ,
t t
whichmanifestsaformofgeneralisedsynchronyacrosstheMarkovblanket[128–130]. Moreover,theexpectedinternal
71
state µ effectively follows the most likely cause of its sensations
t
σ(µ )=argmaxp(η |b ) for any t.
t t t
This has an interesting statistical interpretation as expected internal states perform maximum a posteriori (MAP)
inference over external states.
3.4.3 Predictive processing
We can go further and associate to each internal state µ a probability distribution over external states, such that
each internal state encodes beliefs about external states
q (η):=N(η;σ(µ),Π−1). (3.8)
µ η
Wewillcallq theapproximateposteriorbeliefassociatedwiththeinternalstateµduetotheforecomingconnection
µ
to inference. Under this specification, the mean of the approximate posterior depends upon the internal state, while
its covariance equals that of the true posterior w.r.t. external states (3.3). It follows that the approximate posterior
equals the true posterior when the internal state µ equals the expected internal state µ(b) (given blanket states):
q (η)=p(η|b) ⇐⇒ µ=µ(b). (3.9)
µ
Note a potential connection with epistemic accounts of quantum mechanics; namely, a world governed by classical
mechanics (σ ≡ 0 in (3.7)) in which each agent encodes Gaussian beliefs about external states could appear to the
agents as reproducing many features of quantum mechanics [131].
Underthisspecification(3.9),expectedinternalstatesaretheuniqueminimiserofaKullback-Leiblerdivergence[132]
µ =argminD [q (η)∥p(η|b)]
t KL µ
µ
that measures the discrepancy between beliefs about the external world q (η) and the posterior distribution over
µ
external variables. Computing the KL divergence (see Section 3.8.2), we obtain
µ =argmin(σ(µ)−η )Π (σ(µ)−η ) (3.10)
t t η t
µ
In the neurosciences, the right hand side of (3.10) is commonly known as a (squared) precision-weighted prediction
error: thediscrepancybetweenthepredictionandthe(expected)stateoftheenvironmentisweightedwithaprecision
matrix [109,133,134] that derives from the steady-state density. This equation is formally similar to that found in
predictivecodingformulationsofbiologicalfunction[109,135–137],whichstipulatethatorganismsminimiseprediction
errors, and in doing so optimise their beliefs to match the distribution of external states.
3.4.4 Variational Bayesian inference
Wecangofurtherandassociateexpectedinternalstatestothesolutiontotheclassicalvariationalinferenceproblem
fromstatisticalmachinelearning[138]andtheoreticalneurobiology[133,139]. Expectedinternalstatesaretheunique
72
Figure 3.5: Variational inference and predictive processing, averaging internal variables for any blanket state.
This figure illustrates a system’s behaviour after experiencing a surprising blanket state, averaging internal variables for any
blanket state. This is a multidimensional Ornstein-Uhlenbeck process, with two external, blanket and internal variables,
initialised at the steady-state density conditioned upon an improbable blanket state p(x0|b0). Upper left: we plot a sample
trajectoryoftheblanketstatesastheserelaxtosteady-stateoveracontourplotofthefreeenergy(uptoaconstant). Upper
right: this plots the free energy (up to a constant) over time, averaged over multiple trajectories. In this example, the rare
fluctuations that climb the free energy landscape vanish on average, so that the average free energy decreases monotonically.
This need not always be the case: conservative systems (i.e., ς ≡0 in (3.7)) are deterministic flows along the contours of the
steady-statedensity(seeSection2.4.4). SincethesecontoursdonotgenerallycoincidewiththoseofF(b,µ)itfollowsthatthe
free energy oscillates between its maximum and minimum value over the system’s periodic trajectory. Luckily, conservative
systems are not representative of dissipative, living systems. Yet, it follows that the average free energy of expected internal
variables may increase, albeit only momentarily, in dissipative systems (3.7) whose solenoidal flow dominates dissipative flow.
Lower left: we illustrate the accuracy of predictions over external states of the sample path from the upper left panel. At
steady-state(fromtimestep∼100),thepredictionsbecomeaccurate. Thepredictionofthesecondcomponentisoffsetbyfour
units for greater visibility, as can be seen from the longtime behaviour converging to four instead of zero. Lower right: We
showtheevolutionofprecision-weightedpredictionerrorsξt:=Πη(ηt−σ(µt))overtime. Thesearenormallydistributedwith
zeromeanatsteady-state.
73
Figure3.6: Variationalinferenceandpredictiveprocessing. Thisfigureillustratesasystem’sbehaviourafterexperiencing
a surprising blanket state. This is a multidimensional Ornstein-Uhlenbeck process, with one external, blanket and internal
variable,initialisedatthesteady-statedensityconditioneduponanimprobableblanketstatep(x0|b0). Upperleft: thisplotsa
sampletrajectoryofparticularstatesastheserelaxtosteady-stateoveracontourplotofthefreeenergy. Thewhitelineshows
theexpectedinternalstategivenblanketstates,atwhichpointinferenceisexact. Afterstartingclosetothisline,theprocess
is driven by solenoidal flow to regions where inference is inaccurate. Yet, solenoidal flow makes the system converge faster to
steady-state[32,33]atwhichpointinferencebecomesaccurateagain. Upperright: thisplotsthefreeenergy(uptoaconstant)
overtime,averagedovermultipletrajectories. Lower left: weillustratetheaccuracyofpredictionsoverexternalstatesofthe
sample path from the upper left panel. These predictions are accurate at steady-state (from timestep ∼ 100). Lower right:
we illustrate the (precision weighted) prediction errors over time. In orange we plot the prediction error corresponding to the
samplepathintheupperleftpanel;theothersamplepathsaresummarisedasaheatmapinblue.
74
minimiser of a free energy functional (i.e., an evidence bound [138,140])
F(b ,µ )≥F(b ,µ )
t t t t
F(b,µ)=D [q (η)∥p(η|b)]−logp(b,µ)
KL µ (3.11)
=E [−logp(x)]− H[q ] .
qµ(η) µ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124)(cid:123)(cid:122)(cid:125)
Energy Entropy
The last line expresses the free energy as a difference between energy and entropy: energy or accuracy measures to
what extent predicted external states are close to the true external states, while entropy penalises beliefs that are
overly precise.
Atfirstsight,variationalinferenceandpredictiveprocessingaresolelyusefultocharacterisetheaverageinternalstate
givenblanketstatesatsteady-state. Itisthensurprisingtoseethatthefreeenergysaysagreatdealaboutasystem’s
expected trajectories as it relaxes to steady-state. Figure 3.5 and 3.6 illustrate the time-evolution of the free energy
and prediction errors after exposure to a surprising stimulus. In particular, Figure 3.5 averages internal variables
for any blanket state: In the neurosciences, perhaps the closest analogy is the event-triggered averaging protocol,
whereneurophysiologicalresponsesareaveragedfollowingafixedperturbation,suchapredictableneuralinputoran
experimentally-controlled sensory stimulus (e.g., spike-triggered averaging, event-related potentials) [141–143].
Themoststrikingobservationisthenearlymonotonicdecreaseofthefreeenergyasthesystemrelaxestosteady-state.
This simply follows from the fact that regions of high density under the steady-state distribution have a low free
energy. Thisoveralldecreaseinfreeenergyistheessenceofthefree-energyprinciple,whichdescribesself-organisation
at non-equilibrium steady-state [1,112,113]. Note that the free energy, even after averaging internal variables, may
decrease non-monotonically. See the explanation in Figure 3.5.
3.5 Active inference and stochastic control
Inordertomodelagentsthatinteractwiththeirenvironment,wenowpartitionblanketstatesintosensoryandactive
states
b =(s ,a )
t t t
x =(η ,s ,a ,µ ).
t t t t t
Intuitively, sensory states are the sensory receptors of the system (e.g., olfactory or visual receptors) while active
states correspond to actuators through which the system influences the environment (e.g., muscles). See Figure 3.7.
The goal of this section is to explain how autonomous states (i.e., active and internal states) respond adaptively to
sensory perturbations in order to maintain the steady-state, which we interpret as the agent’s preferences or goal.
This allows us to relate the dynamics of autonomous states to active inference and stochastic control, which are
well-known formulations of adaptive behaviour in theoretical biology and engineering.
75
Figure3.7: Markovblanketevolvingintimecomprisingsensoryandactivestates. Wecontinuetheintuitiveexample
fromFigure3.3ofthebacillusasrepresentingaMarkovblanketthatpersistsovertime. Theonlydifferenceisthatwepartition
blanketstatesintosensoryandactivestates. Inthisexample,thesensorystatescanbeseenasthebacillus’membrane,while
theactivestatescorrespondtotheactinfilamentsofthecytoskeleton.
3.5.1 Active inference
We now proceed to characterise autonomous states, given sensory states, using the free energy. Unpacking blanket
states, the free energy (3.11) reads
F(s,a,µ)=D [q (η)∥p(η|s,a)]−logp(µ|s,a)−logp(a|s)−logp(s).
KL µ
Crucially, it follows that the expected autonomous states minimise free energy
F(s ,a ,µ )≥F(s ,a ,µ ),
t t t t t t
a :=a(s ):=E [a ]=Σ Σ−1s ,
t t p(at|st) t as s t
where a denotes the expected active states given sensory states, which is the mean of p(a |s ). This result forms
t t t
the basis of active inference, a well-known framework to describe and generate adaptive behaviour in neuroscience,
machine learning and robotics [110,139,144–151]. See Figure 3.8.
3.5.2 Multivariate control
Active inference is used in various domains to simulate control [144,148,150–155], thus, it is natural that we can
relate the dynamics of active states to well-known forms of stochastic control.
By computing the free energy explicitly (see Section 3.8.2), we obtain that
 
s
t
(cid:104) (cid:105)
(a t ,µ t ) minimises (a,µ)(cid:55)→ s t ,a,µ K  a  (3.12)
µ
K :=Σ−1
b:µ
wherewedenotedbyK theconcentration(i.e.,precision)matrixofp(s,a,µ). Wemayinterpret(a,µ)ascontrolling
howfarparticularstates[s,a,µ]arefromtheirtargetset-pointof[0,0,0],wheretheerrorisweightedbytheprecision
matrix K. See Figure 3.9. (Note that we could choose any other set-point by translating the frame of reference or
76
Figure 3.8: Active inference. This figure illustrates a system’s behaviour after experiencing a surprising sensory state,
averaginginternalvariablesforanyblanketstate. WesimulatedanOrnstein-Uhlenbeckprocesswithtwoexternal,onesensory,
one active and two internal variables, initialised at the steady-state density conditioned upon an improbable sensory state
p(x0|s0). Left: The white line shows the expected active state given sensory states: this is the action that performs active
inference and optimal stochastic control. As the process experiences a surprising sensory state, it initially relaxes to steady-
stateinawindingmannerduetothepresenceofsolenoidalflow. Eventhoughsolenoidalflowdrivestheactionsawayfromthe
optimalactioninitially,itallowstheprocesstoconvergefastertosteady-state[32,33,60]wheretheactionsareagaincloseto
theoptimalactionfromoptimalcontrol. Right: Weplotthefreeenergyoftheexpectedinternalstate,averagedovermultiple
trajectories. Inthisexample,theaveragefreeenergydoesnotdecreasemonotonically—seeFigure3.5foranexplanation.
equivalently choosing a Gaussian steady-state centred away from zero). In other words, there is a cost associated
to how far away s,a,µ are from the origin and this cost is weighed by the precision matrix, which derives from
the stationary covariance of the steady-state. In summary, the expected internal and active states can be seen as
performingmultivariatestochasticcontrol,wherethematrixK encodescontrolgains. Fromabiologist’sperspective,
this corresponds to a simple instance of homeostatic regulation: maintaining physiological variables within their
preferred range.
3.5.3 Stochastic control in an extended state-space
Moresophisticatedcontrolmethods,suchasPID(Proportional-Integral-Derivative)control[155,158],involvecontrol-
lingaprocessanditshigherordersofmotion(e.g.,integralorderivativeterms). Sohowcanwerelatethedynamics
of autonomous states to these more sophisticated control methods? The basic idea involves extending the sensory
(cid:16) (cid:17)
state-space to replace the sensory process s by its various orders of motion s˜ = s(0),...,s(n) (integral, position,
t t t t
velocity, jerk etc, up to order n). To find these orders of motion, one must solve the stochastic realisation problem.
The stochastic realisation problem
Recall that the sensory process s is a stationary stochastic process (with a Gaussian steady-state). The following is
t
a central problem in stochastic systems theory: Given a stationary stochastic process s , find a Markov process s˜,
t t
called the state process, and a function f such that
s =f(s˜) for all t. (3.13)
t t
Moreover, find an Itô stochastic differential equation whose unique solution is the state process s˜. The problem of
t
characterising the family of all such representations is known as the stochastic realisation problem [159].
77
Figure3.9: Stochasticcontrol. Thisfigureplotsasamplepathofthesystem’sparticularstatesafteritexperiencesasurprising
sensorystate. ThisisthesamesamplepathasshowninFigure3.8(leftpanel),however,herethelinkwithstochasticcontrol
iseasiertosee. Indeed,itlooksasifactivestates(inred)areactivelycompensatingforsensorystates(ingreen): risesinthe
activestate-spaceleadtoplungesinthesensorystate-spaceandvice-versa. Noticetheinitialriseinactivestatestocompensate
fortheperturbationinthesensorystates. Activestatesfollowasimilartrajectoryassensorystates,withaslightdelay,which
canbeinterpretedasareactiontime[156]. Infact, thecorrespondencebetweensensoryandactivestatesisaconsequenceof
thesolenoidalflow–seeFigure3.8(leftpanel). Thedampedoscillationsastheparticularstatesapproachtheirtargetvalueof
0(ingrey)isanalogoustothatfoundinbasicimplementationsofstochasticcontrol,e.g.,[157,Figure4.9].
What kind of processes s can be expressed as a function of a Markov process (3.13)?
t
There is a rather comprehensive theory of stochastic realisation for the case where s is a Gaussian process (which
t
occurs, for example, when x is a Gaussian process). This theory expresses s as a linear map of an Ornstein-
t t
Uhlenbeckprocess[3,160,161]. Theideaisasfollows: asamean-zeroGaussianprocess,s iscompletelydetermined
t
by its autocovariance function C(t−r) = E[s ⊗s ], which by stationarity only depends on |t−r|. It is well
t r
known that any mean-zero stationary Gaussian process with exponentially decaying autocovariance function is an
Ornstein-Uhlenbeckprocess(aresultsometimesknownasDoob’stheorem)[3,69,162,163]. ThusifC equalsafinite
sumofexponentiallydecayingfunctions,wecanexpresss asalinearfunctionofseveralnestedOrnstein-Uhlenbeck
t
processes, i.e., as an integrator chain from control theory [164,165]
s =f(s(0))
t t
ds(0) =f (s(0),s(1))dt+ς dW(0)
t 0 t t 0 t
ds(1) =f (s(1),s(2))dt+ς dW(1)
t 1 t t 1 t
(3.14)
. . .
. . .
. . .
ds(n−1) =f (s(n−1),s(n))dt+ς dW(n−1)
t n−1 t t n−1 t
ds(n) =f (s(n))dt+ς dW(n).
t n t n t
In this example, f,f are suitably chosen linear functions, ς are matrices and W(i) are standard Brownian motions.
i i
Thus, we can see s as the output of a continuous-time hidden Markov model, whose (hidden) states s(i) encode its
t t
various orders of motion: position, velocity, jerk etc. These are known as generalised coordinates of motion in the
Bayesian filtering literature [14,166,167]. See Figure 3.10.
More generally, the state process s˜ and the function f need not be linear, which enables to realise non-linear,
t
non-Gaussian processes s [166,168,169]. Technically, this follows as Ornstein-Uhlenbeck processes are the only
t
78
Figure 3.10: Continuous-time Hidden Markov model. This figure depicts (3.14) in a graphical format, as a Bayesian
network[90,114]. Theencircledvariablesarerandomvariables—theprocessesindexedatanarbitrarysequenceofsubsequent
times t1 < t2 < ... < t9. The arrows represent relationships of causality. In this hidden Markov model, the (hidden) state
process s˜t is given by an integrator chain—i.e., nested stochastic differential equations s(
t
0),s(
t
1),...,s(
t
n). These processes
s(
t
i),i≥0,canrespectivelybeseenasencodingtheposition,velocity,jerketc,oftheprocessst.
stationaryGaussianMarkovprocesses. Notethatstochasticrealisationtheoryisnotaswelldevelopedinthisgeneral
case [159,166,169–171].
Stochastic control of integrator chains
Henceforth,weassumethatwecanexpresss asafunctionofaMarkovprocesss˜ (3.13). Inserting(3.13)into(3.12),
t t
we now see that the expected autonomous states minimise how far themselves and f(s˜) are from their target value
t
of zero
 
f(s˜)
t
(cid:104) (cid:105)
(a t ,µ t ) minimises (a,µ)(cid:55)→ f(s˜ t ),a,µ K  a   . (3.15)
µ
Furthermore, if the state process s˜ can be expressed as an integrator chain, as in (3.14), then we can interpret
t
expectedactiveandinternalstatesascontrollingeachorderofmotions(i). Forexample,iff islinear,theseprocesses
t
control each order of motion s(i) towards its target value of zero.
t
PID-like control
Proportional-integral-derivative (PID) control is a well-known control method in engineering [155,158]. More than
90%ofcontrollersinengineeredsystemsimplementeitherPIDorPI(noderivative)control. ThegoalofPIDcontrol
is to control a signal s(1), its integral s(0), and its derivative s(2) close to a pre-specified target value [155].
t t t
Thisturnsouttobeexactlywhathappensherewhenweconsiderthestochasticcontrolofanintegratorchain(3.15)
with three orders of motion (n = 2). When f is linear, expected autonomous states control integral, proportional
79
and derivative processes s(0),s(1),s(2) towards their target value of zero. Furthermore, from f and K one can derive
t t t
integral, proportional and derivative gains, which penalise deviations of s(0),s(1),s(2), respectively, from their target
t t t
value of zero. Crucially, these control gains are simple by-products of the steady-state density and the stochastic
realisation problem.
Why restrict ourselves to PID control when stochastic control of integrator chains is available? It turns out that
when sensory states s are expressed as a function of an integrator chain (3.14), one may get away by controlling an
t
approximation of the true (sensory) process, obtained by truncating high orders of motion as these have less effect
on the dynamics, though knowing when this is warranted is a problem in approximation theory. This may explain
why integral feedback control (n=0), PI control (n=1) and PID control (n=2) are the most ubiquitous control
methods in engineering applications. However, when simulating biological control—usually with highly non-linear
dynamics—it is not uncommon to consider generalised motion to fourth (n=4) or sixth (n=6) order [168,172].
It is worth mentioning that PID control has been shown to be implemented in simple molecular systems and is
becoming a popular mechanistic explanation of behaviours such as bacterial chemotaxis and robust homeostatic
algorithms in biochemical networks [155,173,174]. We suggest that this kind of behaviour emerges in Markov
blankets at non-equilibrium steady-state. Indeed, stationarity means that autonomous states will look as if they
respond adaptively to external perturbations to preserve the steady-state, and we can identify these dynamics as
implementations of various forms of stochastic control (including PID-like control).
3.6 Discussion
In this chapter, we considered the consequences of a boundary mediating interactions between states internal and
externaltoasystem. Onunpackingthisnotion,wefoundthatthestatesinternaltoaMarkovblanketlookasifthey
perform variational Bayesian inference, optimising beliefs about their external counterparts. When subdividing the
blanket into sensory and active states, we found that autonomous states perform active inference and various forms
of stochastic control (i.e., generalisations of PID control).
Interacting Markov blankets: The sort of inference we have described could be nuanced by partitioning the
external state-space into several systems that are themselves Markov blankets (such as Markov blankets nested at
severaldifferentscales[88]). Fromtheperspectiveofinternalstates,thisleadstoamoreinterestinginferenceproblem,
with a more complex generative model. It may be that the distinction between the sorts of systems we generally
think of as engaging in cognitive, inferential, dynamics [175] and simpler systems rest upon the level of structure of
the generative models (i.e., steady-state densities) that describe their inferential dynamics.
Temporally deep inference: This distinction may speak to a straightforward extension of the treatment on offer,
from simply inferring an external state to inferring the trajectories of external states. This may be achieved by
representingtheexternalprocessintermsofitshigherordersofmotionbysolvingthestochasticrealisationproblem.
Byrepeatingtheanalysisabove,internalstatesmaybeseenasinferringtheposition,velocity,jerk,etcoftheexternal
process, consistently with temporally deep inference in the sense of a Bayesian filter [14] (a special case of which is
an extended Kalman–Bucy filter [176]).
Bayesian mechanics in non-Gaussian steady-states: The treatment from this chapter extends easily to non-
Gaussian steady-states, in which internal states appear to perform approximate Bayesian inference over external
states. Indeed, any arbitrary (smooth) steady-state density may be approximated by a Gaussian density at one of
itsmodesusingaso-calledLaplaceapproximation. ThisGaussiandensityaffordsonewithasynchronisationmapin
closedform4 thatmapstheexpectedinternalstatetoanapproximationoftheexpectedexternalstate. Itfollowsthat
4Anotheroptionistoempiricallyfitasynchronisationmaptodata[8].
80
the system can be seen as performing approximate Bayesian inference over external states—precisely, an inferential
scheme known as variational Laplace [177]. We refer the interested reader to a worked-out example involving two
sparsely coupled Lorenz systems [9]. Note that variational Laplace has been proposed as an implementation of
variouscognitiveprocessesinbiologicalsystems[110,133,139]accountingforseveralfeaturesofthebrain’sfunctional
anatomy and neural message passing [134,149,175,178,179].
Modelling real systems: The simulations presented here are as simple as possible and are intended to illustrate
general principles that apply to all stationary processes with a Markov blanket (3.6). These principles have been
used to account for synthetic data arising in more refined (and more specific) simulations of an interacting particle
system [8] and synchronisation between two sparsely coupled stochastic Lorenz systems [9]. Clearly, an outstanding
challenge is to account for empirical data arising from more interesting and complex structures. To do this, one
would have to collect time-series from an organism’s internal states (e.g., neural activity), its surrounding external
states,anditsinterface,includingsensoryreceptorsandactuators. Then,onecouldtestforconditionalindependence
between internal, external and blanket states (3.6) [180]. One might then test for the existence of a synchronisation
map (using Lemma 3.3.3). This speaks to modelling systemic dynamics using stochastic processes with a Markov
blanket. Forexample,onecouldlearnthevolatility,solenoidalflowandsteady-statedensityinastochasticdifferential
equation (3.7) from data, using supervised learning [181].
3.7 Conclusion
This chapter outlines some of the key relationships between stationary processes, inference and control. These
relationshipsrestuponpartitioningtheworldintothosethingsthatareinternalorexternaltoa(statistical)boundary,
known as a Markov blanket. When equipped with dynamics, the expected internal states appear to engage in
variational inference, while the expected active states appear to be performing active inference and various forms of
stochastic control.
The rationale behind these findings is rather simple: if a Markov blanket derives from a steady-state density, the
states of the system will look as if they are responding adaptively to external perturbations in order to recover the
steady-state. Conversely,well-knownmethodsusedtobuildadaptivesystemsimplementthesamekindofdynamics,
implicitly so that the system maintains a steady-state with its environment.
3.8 Addendum: Proofs for Chapter 3
3.8.1 Existence of synchronisation map: proof
We prove Lemma 3.3.3.
Proof. (i) ⇐⇒ (ii) follows by definition of a function.
(ii) ⇐⇒ (iii) is as follows
∀b ,b ∈B:µ(b )=µ(b )⇒η(b )=η(b )
1 2 1 2 1 2
⇐⇒ (cid:0) ∀b ,b ∈B:Σ Σ−1b =Σ Σ−1b ⇒Σ Σ−1b =Σ Σ−1b (cid:1)
1 2 µb b 1 µb b 2 ηb b 1 ηb b 2
⇐⇒ (cid:0) ∀b∈B:Σ Σ−1b=0⇒Σ Σ−1b=0 (cid:1)
µb b ηb b
⇐⇒ kerΣ ⊂kerΣ
µb ηb
81
(iii) ⇐⇒ (iv) From [182, Section 0.7.3], using the Markov blanket condition (3.2), we can verify that
Π Σ =−Π Σ
µ µb µb b
Π Σ =−Π Σ .
η ηb ηb b
Since Π ,Π ,Σ are invertible, we deduce
µ η b
kerΣ ⊂kerΣ
µb ηb
⇐⇒ kerΠ Σ ⊂kerΠ Σ
µ µb η ηb
⇐⇒ ker−Π Σ ⊂ker−Π Σ
µb b ηb b
⇐⇒ kerΠ ⊂kerΠ .
µb ηb
3.8.2 Free energy computations
The free energy reads (3.11)
F(b,µ)=D [q (η)∥p(η|b)]−logp(b,µ).
KL µ
Recalling from (3.3), (3.8) that q (η) and p(η|b) are Gaussian, the KL divergence between multivariate Gaussians is
µ
well-known
q (η)=N(η;σ(µ),Π−1), p(η|b)=N(η;η(b),Π−1),
µ η η
1
⇒D [q (η)∥p(η|b)]= (σ(µ)−η(b))Π (σ(µ)−η(b)).
KL µ 2 η
Furthermore, we can compute the log partition
(cid:34) (cid:35)
1(cid:104) (cid:105) b
−logp(b,µ)= b,µ Σ−1 (up to a constant).
2 b:µ µ
Note that Σ−1 is the inverse of a principal submatrix of Σ, which in general differs from Π , a principal submatrix
b:µ b:µ
of Π. Finally,
(cid:34) (cid:35)
1 1(cid:104) (cid:105) b
F(b,µ)= 2 (σ(µ)−η(b))Π η (σ(µ)−η(b))+ 2 b,µ Σ− b:µ 1 µ (up to a constant).
82
Chapter 4
The free-energy principle
The free-energy principle made simpler but not too
simple
By Karl Friston, Lancelot Da Costa, Noor Sajid, Conor Heins, Kai
Ueltzhoeffer, Grigorios A. Pavliotis, Thomas Parr
Adapted from: K Friston, L Da Costa, N Sajid, C Heins, K Ueltzhoeffer, GA Pavliotis, T Parr. The
free energy principle made simpler but not too simple. Physics Reports. 2023
83
4.1 Abstract
This chapter provides a concise description of the free energy principle, starting from a formulation of random
dynamical systems in terms of a Langevin equation and ending with a Bayesian mechanics that can be read as a
physicsofsentience.1 Itrehearsesthekeystepsusingstandardresultsfromstatisticalphysics. Thesestepsentail(i)
establishingaparticularpartitionofstatesbaseduponconditionalindependenciesthatinheritfromsparselycoupled
dynamics, (ii) unpacking the implications of this partition in terms of Bayesian inference and (iii) describing the
paths of particular states with a variational principle of least action. Teleologically, the free energy principle offers
a normative account of self-organisation in terms of optimal Bayesian design and decision-making, in the sense of
maximisingmarginallikelihoodorBayesianmodelevidence. Insummary,startingfromadescriptionoftheworldin
termsofrandomdynamicalsystems,weendupwithadescriptionofself-organisationassentientbehaviourthatcan
be interpreted as self-evidencing; namely, self-assembly, autopoiesis or active inference.
Keywords: self-organisation, nonequilibrium, variational inference, Bayesian, Markov blanket.
4.2 Introduction
Itissaidthatthefreeenergyprincipleisdifficulttounderstand. Thisisironiconthreecounts. First,thefreeenergy
principle(FEP)issosimplethatitis(almost)tautological. Indeed,philosophicalaccountscompareitsexplanandum
to a desert landscape, in the sense of Quine [183]. Second, a tenet of the FEP is that everything must provide an
accurate account of things that is as simple as possible—including itself. Finally, the FEP rests on straightforward
resultsfromstatisticalphysics. Thisreviewtriestopresentthefreeenergyprincipleassimplyaspossiblebutwithout
sacrificingtoomuchtechnicaldetail. Itstepsthroughtheformalargumentsthatleadfromadescriptionoftheworld
as a random dynamical system [125,184] to a description of self-organisation in terms of active inference and self-
evidencing [185]. The evidence in question is Bayesian model evidence, which speaks to the Bayesian mechanics on
offer[113]. Thesemechanicshavethesamestartingpointas=statisticalandclassicalmechanics. Theonlydifference
is that careful attention is paid to the way that the internal states of something couple to its external states.
Tomakethefollowingaccountaccessible,weuseaconversationalstyle,explainingthemeaningofkeymathematical
expressions intuitively. Accordingly, simplifying notation and assumptions are used to foreground the basic ideas.
Before starting, it might help to clarify what the free energy principle is—and why it is useful. Many theories in
the biological sciences are answers to the question: “what must things do, in order to exist?” The FEP turns this
questiononitsheadandasks: “ifthingsexist,whatmusttheydo?” Moreformally,ifwecandefinewhatitmeansto
besomething,canweidentifythephysicsordynamicsthatathingmustpossess? Toanswerthisquestion,theFEP
calls on some mathematical truisms that follow from each other. Much like Hamilton’s principle of least action2, it
is not a falsifiable theory about the way ‘things’ behave—it is a general description of ‘things’ that are defined in a
particular way. As such, the FEP is not falsifiable as a mathematical statement, but it may as well be falsifiable to
the extent that its postulates refer to a specific class of empirical phenomena that the principle aims to describe.
Is such a description useful? In itself, the answer is probably no—in the sense that the principle of least action does
not tell you how to throw a ball. However, the principle of least action furnishes everything we need to know to
simulate the trajectory of a ball in a particular instance. In the same sense, the FEP allows one to simulate and
predict the sentient behaviour of a particle, person, artefact or agent (i.e., some ‘thing’). This allows one to build
sentient artefacts or use simulations as observation models of particles (or people). These simulations rest upon
1Sentiencehereismeantforathingashavingsensorystatesthroughwhichitiscoupledwithitsexternalstates,andbeing
describedasbehavingadaptivelyinaccordancetothesensorystates.
2PerhapsabetteranalogywouldbeNoether’stheorem(BerenMillidge–personalcommunication)[186].
84
specifyingagenerative model thatisapttodescribethebehaviouroftheparticle(orperson)athand. Atthispoint,
committingtoaspecificgenerativemodelcanbetakenasacommitmenttoaspecific—andfalsifiable—theory. Later,
we will see some examples of these simulations.
The remaining sections describe the FEP. Each section focuses on an equation—or set of equations—used in subse-
quentsections. Theensuingnarrativeismeanttobeconcise,takingusfromthebeginningtotheendassuccinctlyas
possible. To avoid disrupting the narrative, we use footnotes to address questions that are commonly asked at each
step. Wealsousefigurelegendstosupplementthenarrativewithexamplesfromneurobiology. Mostofthefollowing
can be found in the literature [9,58,113]; however, there are a few simplifications that replace earlier accounts.
4.3 Systems, states and fluctuations
Westartbydescribingtheworldwithastochasticdifferentialequation[3]. Sowhystarthere? Theprincipalreason
isthatwewantadescriptionthatisconsistentwithphysics. Thisfollowsbecausethingslikethefluctuationtheorems
in statistical mechanics and the Lagrangian formulation of classical mechanics can all be derived from this starting
point [16]. In short, if one wants a physics of sentience, this is a good place to start.
We are interested in systems that have characteristic states. Technically, this means the system has a pullback
attractor; namely,asetofstatesasystemwillcometooccupyfromanyinitialstate[184,187]. Suchsystemscanbe
describedwithstochasticdifferentialequations,suchastheLangevinequationdescribingtherateofchangeofsome
states x(τ), in terms of theirflow f(x), and random fluctuations ω(τ). The fluctuations are usuallyassumed to bea
normally distributed (white noise) process, with a covariance of 2Γ:
x˙(τ)=f(x)+ω(τ)
p(ω|x)=N(ω;0,2Γ)⇒p(x˙ |x)=N(x˙;f,2Γ) (4.1)
p(x)=?
The dot notation denotes a derivative with respect to time3. This means that time and causality are baked into
everythingthatfollows,inthesensethatstatescausetheirmotion. TheLangevinequationisitselfanapproximation
to a simpler mapping from some variables to changes in those variables with time. This follows from the separation
intostatesandrandomfluctuationsimplicitin(4.1),wherestateschangeslowlyinrelationtofastfluctuations. This
(adiabatic)approximationisubiquitousinphysics[94,189,190]. Inbrief,itmeanswecanignoretemporalcorrelations
inthefastfluctuationsandassume—bythecentrallimittheorem—thattheyhaveaGaussiandistribution. Thisequips
thefluctuationswithaprobabilitydensity,whichmeansweknowtheirstatisticalbehaviourbutnottheirtrajectory
or path, which itself is a random variable [3,125,184].
The next step, shared by all physics, is to ask whether anything can be said about the probability density over the
states—the‘?’ in(4.1). Alotcanbesaidaboutthisprobabilitydensity,whichcanbeexpressedintwocomplementary
ways;namely,asdensity dynamics usingtheFokker-Planckequation(a.k.a. theforwardKolmogorovequation)orin
termsoftheprobabilityofapaththroughstate-spaceusingthepath-integralformulation. TheFokker-Planckequation
describes the change in the density due to random fluctuations and the flow of states through state-space [3,80]:
p˙(x,τ)=∇·(Γ∇−f(x))p(x,τ) (4.2)
3Question: why is the flow in (4.1) not a function of time? Many treatments of stochastic thermodynamics allow for
time-dependentflowswhencouplingonesystem(e.g.,anidealisedgas)toanother(e.g.,aheatreservoir),whereitisassumed
thattheothersystemchangesveryslowly,e.g.,[16,188]. However,theambitionoftheFEPistodescribethiscouplingunder
a partition of states. In this setting, separation of temporal scales is an emergent property, where (4.1) holds at any given
temporalscale. See[113]foratreatmentusingtheapparatusoftherenormalisationgroup.
85
The Fokker-Planck equation describes our stochastic process in terms of deterministic density dynamics—instead of
specificrealisations—wherethedensityinquestionisoverstates x(τ)=x . Conversely,thepath-integralformulation
τ
considers the probability of a trajectory or path x[τ]≜[x(t):0≤t≤τ] in terms of its action A (omitting additive
constants here and throughout)4:
A(x[τ])=−lnp(x[τ]|x )
0
τ (cid:90) τ
= ln|(4π)nΓ|+ dtL(x,x˙) (4.3)
2
0
(cid:20) (cid:21)
1 1
L(x,x˙)= (x˙ −f)· (x˙ −f)+∇·f
2 2Γ
Both the Fokker-Planck and path-integral formulations inherit their functional form from assumptions about the
statistics of random fluctuations in (4.1). For example, the most likely path—or path of least action—is the path
taken when the fluctuations take their most likely value of zero. This means that variations away from this path
always increase the action. This is expressed mathematically by saying that its variation is zero when the action is
minimised.5
x[τ]=argminA(x[τ])
x[τ]
(4.4)
⇔δ A(x[τ])=0
x
⇔x˙(τ)=f(x)
In short, the motion on the path of least action is just the flow without random fluctuations. Paths of least action
will figure prominently below; especially, when considering systems that behave in a precise or predictable way. We
will denote the most likely states and paths with a bold typeface.
Although equivalent, the Fokker-Planck and path-integral formalisms provide complementary perspectives on dy-
namics. The former deals with time-dependent probability densities over states, while the latter considers time-
independentdensitiesoverpaths. Thedensityovernstatesatanyparticulartimeisthetime-marginalofthedensity
over trajectories. These probabilities can be conveniently quantified in terms of their negative logarithms (or poten-
tials)leadingtosurprisalandaction,respectively(omittingthedivergenceoftheflowinthelastlineforsimplicity):
ℑ(x,τ)≜−lnp(x,τ)
A(x[τ])≜−lnp(x[τ]|x )
0
H[p(x,τ)]=E[ℑ(x,τ)]
(4.5)
H[p(x[τ]|x )]=E[A(x[τ])]
0
τ (cid:90) τ 1 (cid:20) 1 (cid:21) τ
= ln[(4π)n|Γ|]+ dt E ω(t)· ω(t) = ln[(4πe)n|Γ|]
2 2 p(ω) 2Γ 2
0
The second set of equalities shows that the uncertainty (or entropy) about states and their paths is the expected
surprisalandaction,respectively. Perhapscounterintuitively,theentropyofpathsiseasiertospecifythantheentropy
4Question: where does the divergence in the third equality come from? This term arises from the implicit use of
Stratonovichpathintegrals[16]. Notethatwehaveassumedthattheamplitudeofrandomfluctuationsisstate—andtherefore
path—independentin(4.1),whichmeanswecanplaceitoutsidetheintegralinthesecondequality.
5Omitting the contribution of the divergence term in the Lagrangian to obtain the expression for the path of least action
forsimplicity,cf.[191]. Takingthissimplificationatfacevaluemeansthatweareeither: 1)consideringadescriptiononashort
time-scale as the flow can be approximated by a linear function with impunity (e.g., linear response theory, see [3]); or 2) we
are considering the limit where random fluctuations have vanishingly small amplitude (e.g., precise particles, see Sections 4.8
and4.9).
86
of states. This follows because the only source of uncertainty about paths—given an initial state—are the random
fluctuations [3,16], whose probability density does not change with time. The last pair of equalities in (4.5) show
that the amplitude of random fluctuations determines the entropy of paths. Intuitively, if the fluctuations are large,
then many distinct paths become equally plausible, and the entropy of paths increases6.
4.4 Solutions, steady-states and nonequilibria
So far, we have equations that describe the relationship between the dynamics of a system and probability densities
overfluctuations,statesandtheirpaths. Thisissufficienttoelaboratemuchofphysics. Forexample,wecouldfocuson
systemsthatcomprisestatisticalensemblesofsimilarstatestoderivestochasticandstatisticalmechanicsintermsof
fluctuationtheorems[16]. Finally,wecouldconsiderlargesystems—inwhichthefluctuationsareaveragedaway—to
derive classical mechanics such as electromagnetism.All of these mechanics require some boundary conditions: for
example,aheatbathorreservoirinstatisticalmechanicsandaclassicalpotentialforLagrangianmechanics. Atthis
point, the FEP steps back and asks, where do these boundary conditions come from? Indeed, this was implicit in
Schrodinger’s question:
“How can the events in space and time which take place within the spatial boundary of a living organism be accounted
for by physics and chemistry?” [192].
We read a boundary in a statistical sense as a Markov boundary [90]7. Why? Because the only thing we have
at hand is a probabilistic description of the system. And the only way to separate the states of something from
its boundary states is in terms of probabilistic independencies—in this instance, conditional independencies8. This
means we need to identify a partition of states that assigns a subset to a ‘thing’ or particle and another subset to
the boundary that separates the thing from some ‘thing’ else. In short, one has to define ‘thingness’ in terms of
conditional independencies.
However, if things are defined in terms of conditional independencies and conditional independencies are attributes
ofaprobabilitydensity,wheredoesthedensitycomefrom? TheFokker-Planckequationshowsthatthedensityover
states depends upon time, even if the flow does not. This means that if we predicate ‘thingness’ on a probability
density, it may only exist for a vanishingly small amount of time. This simple observation compels us to consider
probabilitydensitiesthatdonotchangewithtime, namely: (i)steady-statesolutionstotheFokker-Planckequation
or (ii) the density over paths. We will start with the (slightly more delicate) treatment of steady-state solutions
andthenshowthatthe(slightlymorestraightforward)treatmentofdensitiesoverpathsleadstothesamenotionof
‘thingness’.
The existence of things over a particular timescale implies the density in (4.2) does not change over that timescale.
This is what is meant by a steady-state solution to the Fokker-Planck equation. The ensuing density is known as a
steady-state density and, in random dynamical systems, implies the existence of a pullback attractor [125,184]. The
notionofanattractorishelpfulhere,inthesensethatitcomprisesasetofcharacteristicstates,towhichthesystem
is attracted over time9. In short, to talk about ‘things’, we are implicitly talking about a partition of states in a
random dynamical system that has an attracting set—i.e., a steady-state solution to the Fokker-Planck equation.
6From a thermodynamic perspective, uncertainty about paths increases with temperature. For example, the Einstein-
SmoluchowskirelationrelatestheamplitudeofrandomfluctuationstoamobilitycoefficienttimesthetemperatureΓ=µmkBT.
7A Markov boundary is a subset of states of the system that renders the states of a ‘thing’ or particle conditionally
independentfromallotherstates[193].
8Notingthatiftwosubsetsofstateswereindependent,asopposedtobeingconditionallyindependent,wewouldbedescribing
twoseparatesystems.
9More precisely, the time-dependent solutions to the Fokker-Planck equation will tend towards the stationary solution, or
steady-state. Inotherwords,thesteady-statedensitybecomesapointattractorinthespaceofprobabilitydensities.
87
In short, we consider systems that self-organise towards a steady-state density10. This solution is also known as a
nonequilibriumsteady-state(NESS)density,wherethe‘nonequilibrium’aspectrestsuponsolenoidalflow,aswewill
see next.
The existence of a solution to the Fokker-Planck equation—i.e., the existence of something—means that we can
express the flow of states in terms of the steady-state density (or corresponding surprisal) using a generalisation of
theHelmholtzdecomposition. Thisdecomposestheflowintoconservative(rotational,divergence-free)anddissipative
(irrotational,curl-free)components—withrespecttothesteady-statedensity—referredtoassolenoidal andgradient
flows, respectively [3,21,22,24,25,194,195]:
p˙(x)=0⇔f(x)=Ω(x)∇ℑ(x)−Λ(x)= Q(x)∇ℑ(x) − Γ∇ℑ(x) −Λ(x)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Solenoidalflow Gradientflow (4.6)
ℑ(x)=−lnp(x), Q=−QT, Λ ≜
(cid:88)∂Ω
ij =
(cid:88)∂Q
ij.
i ∂x ∂x
j j
j j
This can be understood intuitively as a decomposition of the flow into two parts. The first (conservative) part of
the flow is a solenoidal circulation on the isocontours of the steady-state density (or surprisal). This component
breaks detailed balance and renders the steady-state density a nonequilibrium steady-state density [23,196]. The
second (dissipative) part performs a (natural) gradient descent on the steady-state surprisal and depends upon the
amplitudeofrandomfluctuations[197,198]. Thefinalterm,Λ,canberegardedasacorrectionterm,whichisneither
curl-free nor divergence-free, and which ensures that the probability density remains constant over time [195].
Summary
We now have a probabilistic description of a system in terms of a (NESS) density that admits conditional inde-
pendencies among states. These conditional independencies are necessary to separate the states of things from
their boundaries. In the next step, we will see how conditional independencies inherit from sparse coupling among
states—and how they are used to establish a particular partition of states.
4.5 Particles, partitions and things
In associating some (stochastic differential) equations of motion with a unique (NESS) density, we have a somewhat
special setup, in which the influences entailed by the equations of motion place constraints on the conditional inde-
pendencies of the NESS density. These conditional independencies can be used to identify a particular partition of
states into external, sensory, active and internal states as summarised below. This is an important move because it
separates the states of a particle (i.e., internal states and their sensory and active states) from the remaining (i.e.,
external) states. However, to do this we have to establish how the causal dynamics in (4.1) underwrite conditional
independencies. This can be done simply by using the curvature (Hessian) of surprisal as follows:
(x ⊥x )|b⇔p(x)=p(x |b)p(x |b)p(b)
u v u v
(4.7)
∂2ℑ
⇔ℑ(x)=ℑ(x |b)+ℑ(x |b)+ℑ(b)⇔ =H =H =0.
u v ∂x ∂x uv vu
u v
10At this point, the formalism applies equally to steady-states with a high or low entropy, as we have not committed to a
particularformofthesteady-statedensity. Later,wewillspecialisetosteady-stateswithalowentropytocharacterisethesort
ofself-organisationthatdescribesbiologicalsystems,e.g.,swarmingorflocking[92,94]
88
This says that if the u-th state is conditionally independent of the v-th state, given the remaining states b, then the
corresponding element of the curvature—or Hessian matrix—of surprisal must be zero. Conversely, a zero entry in
the Hessian implies conditional independence. In sum, any two states are conditionally independent if, and only if,
the change of surprisal with one state does not depend on the other. We can now use the Helmholtz decomposition
(4.6)toexpresstheJacobian—i.e.,the(linear)coupling—oftheflowintermsoftheHessian—thatentailsconditional
independencies (with a slight abuse of the dot product notation):
f(x)=Ω∇ℑ−Λ
⇒J=ΩH+∇Ω·∇ℑ−∇Λ
(4.8)
⇒J = ∂f u = (cid:88) Ω H + (cid:88)∂Ω ui ∂ℑ − (cid:88) ∂2Ω ui .
uv ∂x ui iv ∂x ∂x ∂x ∂x
v v i i v
i i i
We can now define sparse coupling as a solution to this equation, in which all the terms are identically zero11:

Q H
ui iv 
Γ u H uv =0:∀i⇒J(x) uv =0. (4.9)
∂Ω /∂x

ui v
SparsecouplingmeansthattheJacobiancouplingstatesuandviszero,i.e.,anabsenceofcouplingfromonestateto
another. Thisdefinitionprecludessolenoidalcouplingwithuthatdependsonv. BecauseH(x) andΓ arepositive
vv u
definite,sparsecouplingrequiresassociatedelementsofthesolenoidaloperatorandHessiantovanishateverypoint
in state-space, which in turn, implies conditional independence:
Q H =0⇒Q =−Q =0
uv vv uv vu (4.10)
Γ H =0⇒H =H =0⇔(x ⊥x )|b.
u uv uv vu u v
In short, sparse coupling means that any two states are conditionally independent if one state does not influence
the other. This is an important observation; namely, that sparse coupling implies a NESS density with conditional
independencies. In turn, this means any dynamical influence graph with absent or directed edges admits a Markov
blanket (the states b above). These independencies can now be used to build a particular partition as follows:
• TheMarkovboundarya⊂xofasetofinternalstatesµ⊂xistheminimalsetofstatesforwhichthereexists
a nonzero Hessian submatrix: H ̸=0. In other words, the internal states are independent of the remaining
aµ
states, when conditioned upon their Markov boundary, called active states. The combination of active and
internal states will be referred to as autonomous states: α=(a,µ).
• TheMarkovboundarys⊂xofautonomousstatesistheminimalsetofstatesforwhichthereexistsanonzero
Hessian submatrix: H ̸=0. In other words, the autonomous states are independent of the remaining states,
sα
when conditioned upon their Markov boundary, called sensory states. The combination of active and sensory
(i.e., boundary) states constitute blanket states: b=(s,a). The internal and blanket states will be referred to
as particular states: π=(s,α)=(b,µ).
• The remaining states constitute external states: x=(η,π).
The names of active and sensory (i.e., blanket) states inherit from the literature, where they are often associated
withbioticsystemsthatacton—andsense—theirexternalmilieu12. Inthissetting,onecanregardexternalstatesas
11Thisimplicitlyprecludesedgecases,inwhichsomenon-zerotermscancel.
12Question: whydoesaparticularpartitioncomprisesfoursetsofstates? Inotherwords,whydoesaparticularpartition
consider two Markov boundaries; namely, sensory and active states? The reason is that this is the minimal partition that
allows for directed coupling with blanket states. For example, sensory states can influence internal states—and active states
can influence external states—without destroying the conditional independencies of the particular partition (these directed
influencesareillustratedintheupperpanelofFigure4.1asdottedarrows).
89
influencinginternalstatesviasensorystates(directlyorthroughactivestates). Andinternalstatesinfluenceexternal
states via active states (directly or through sensory states13). We will see later how this implies a synchronisation
between internal and external states, in the sense that internal states can be seen as actively inferring external
states[9,58]. Theensuingconditionalindependenciesimpliedbyaparticularpartitioncanbesummarisedasfollows:
J =0⇒H =0⇔(µ⊥η)|b
µη µη
J =0⇒H =0⇔(a⊥η)|s,µ (4.11)
aη aη
J =0⇒H =0⇔(s⊥µ)|a,η
sµ sµ
AnormalformfortheflowandJacobianofaparticularpartition—withsparsecoupling—canbeexpressedasfollows,
where α=(a,µ) and β =(η,s):
f(x)=Ω∇ℑ−Λ
    
f (η,b) Q −Γ Q ∇ ℑ(η|b)
η ηη η ηs η
   f s (η,b)   =    −QT ηs Q ss −Γ s       ∇ s ℑ(b|η)   −Λ
 f (b,µ)   Q −Γ Q  ∇ ℑ(b|µ) 
 a   aa a aµ  a 
f (b,µ) −QT Q −Γ ∇ ℑ(µ|b)
µ aµ µµ µ µ
J(x)=ΩH+∇Ω·∇ℑ−∇Λ
    
J J J Q −Γ Q H H
ηηη ηs ηa ηη η ηs ηη ηs
   J sη J ss J sa   =    −QT ηs Q ss −Γ s       HT ηs H ss H sa   
 J J J   Q −Γ Q  HT H H 
 as aa aµ   aa a aµ  sa aa aµ 
J J J −QT Q −Γ HT H
µs µa µµ aµ µµ µ aµ µµ
+∇Ω·∇ℑ−∇Λ
∇ Ω =0, ∇ Ω =0, ∇ Λ =0, ∇ Λ =0
η αα µ ββ η α µ β
(4.12)
This normal form means that particular partitions can be defined in terms of sparse coupling. Perhaps the simplest
definition—that guarantees a Markov blanket14—is as follows: external states only influence sensory states and
internal states only influence active states. This means that sensory states are not influenced by internal states and
active states are not influenced by external states,
   
η˙(τ) f (η,s,a)+ω (τ)
η η
   
  s˙(τ)  =   f s (η,s,a)+ω s (τ)   (4.13)
 a˙(τ)   f (s,a,µ)+ω (τ) 
   a a 
µ˙(τ) f (s,a,µ)+ω (τ)
µ µ
and the noise processes ω (τ),i∈{η,s,a,µ} are independent. Under this sparse coupling, it is simple to show that
i
not only are internal and external states conditionally independent, but their paths are conditionally independent,
given initial states, using the path integral formulation.
The uncertainty (i.e., entropy) over paths derives from random fluctuations. This means that if we knew all the
13Question: doesthismeanthatIcanactonmyworldthroughmysenseorgans? Yes: muchofbioticactionismediated
by (active) motile cytoskeletal filaments, muscles and secretory organs that lie beneath (sensory) epithelia, such as receptors
ontheskinoracellsurface.
14In the absence of solenoidal coupling between autonomous and non-autonomous states, and constraints on the partial
derivatives of the solenoidal coupling in (4.12); i.e., solenoidal coupling among autonomous states does not depend upon
externalstates. Similarly,fornon-autonomousandinternalstates.
90
influences on the flow at every point in time, we can evaluate the entropy of external and internal paths from (4.5):
τ
H[p(η[τ]|b[τ],x )]= ln[(4πe)nη|Γ |]
0 2 η
τ
H[p(µ[τ]|b[τ],x )]= ln[(4πe)nµ|Γ |]
0 2 µ
(4.14)
⇒
H[p(η[τ]|b[τ],x )]=H[p(η[τ]|µ[τ],b[τ],x )]⇒(µ[τ]⊥η[τ])|b[τ],x
0 0 0
H[p(µ[τ]|b[τ],x )]=H[p(µ[τ]|η[τ],b[τ],x )]⇒(µ[τ]⊥η[τ])|b[τ],x
0 0 0
Thefinalequalitiessaythattheuncertaintyaboutexternal(resp.,internal)pathsdoesnotchangewhenweknowthe
internal(resp.,external)pathbecauseexternal(resp.,internal)statesdonotinfluenceinternal(resp.,external)flow.
Thismeanstheexternalandinternalpathsdonotshareanymutualinformationandarethereforeindependentwhen
conditionedonblanketpaths(andinitialstates). From(4.11),theinitialexternalandinternalstatesarethemselves
independent, when conditioned on blanket states.
Note that the conditional independence of paths inherits directly from the sparse coupling, without any reference to
the NESS density or Helmholtz decomposition. This can be seen clearly by replacing the partial derivatives in (4.7)
withfunctionalderivativesandnoting,from(4.12),thattherearenoflowsthatdependonbothinternalandexternal
states:
∂2f ∂2L ∂2L ∂2L ∂2L
=0⇒ = = = =0
∂η∂µ ∂η∂µ ∂η∂µ˙ ∂η˙∂µ ∂η˙∂µ˙
δ2A(x[τ])
⇒ =0⇔(µ[τ]⊥η[τ])|b[τ],x
δη[t]δµ[t] 0
(4.15)
δA(x[τ]) (cid:90) (cid:18) ∂L δµ[t′] ∂L d δµ[t′] (cid:19)
= dt′ + +...
δµ[t] ∂µ[t′] δµ[t] ∂µ˙[t′]dt′ δµ[t]
δ2A(x[τ]) (cid:90) (cid:18) δη[t′′] ∂2L δµ[t′] δη[t′′] ∂2L d δµ[t′] (cid:19)
= dt′dt′′ + +...
δη[t]δµ[t] δη[t] ∂η∂µ δµ[t] δη[t] ∂η∂µ˙ dt′ δµ[t]
These expressions mean that the probability of an internal path, given a blanket path (and initial states), does not
depend on the external path and vice versa.
Summary
Insummary,theinternaldynamics(i.e.,paths)ofsome‘thing’areconditionallyindependentofexternalpathsif,and
onlyif,theflowofinternalstatesdoesnotdependonexternalstatesandviceversa (giveninitialstates). Wetakethis
asanecessaryandsufficientconditionforsomethingtoexist,inthesensethatitcanbedistinguishedfromeverything
else. WhentheinitialstatesaresampledfromtheNESSdensity,theinternalstatesareconditionallyindependentof
externalstates(givenblanketstates), undercertainconstraintsonsolenoidalflow. Figure4.1illustratestheensuing
particular partition. Note that the edges in this graph represent the influence of one state on another, as opposed
to conditional dependencies. This is important because directed influences admit conditional independence. These
conditionalindependenciesaremanifestaszeroentriesintheHessianmatrices,whichinheritfromthesparse,directed
coupling of the dynamics.
4.6 From self-organisation to self-evidencing
Equipped with a particular partition, we can now talk about things in terms of their internal states and Markov
boundary; namely autonomous states. And we can talk about autonomous states and their Markov boundary;
91
Figure 4.1: Markov blankets. This influence diagram illustrates a particular partition of states into internal states (blue)
and external states (cyan) that are separated by a Markov blanket comprising sensory (green) and active states (red). The
edgesinthisgraphrepresenttheinfluenceofonestateonanother,asopposedtoconditionaldependencies. Thediagramshows
thispartitionasitwouldbeappliedtoasingle-cellorganism,whereinternalstatesareassociatedwithintracellularstates,the
sensorystatesbecomethesurfacestatesorcellmembraneoverlyingactivestates(e.g.,theactinfilamentsofthecytoskeleton).
Thedottedlinesindicateallowabledirectedinfluencesfromsensory(resp.,active)tointernal(resp.,external)states. Particular
statesconstituteaparticle;namely,autonomousandsensorystates—orblanketandinternalstates.
namely,particularstates—thestatesofaparticle. Thenextstepistocharacterisetheflowoftheautonomousstates
(of a particle, plant or person) in relation to external states. In other words, we consider the nature of the coupling
between the outside and inside of a particle, across its Markov blanket. It is at this point that we move towards a
(Bayesian) mechanics that is the special provenance of systems with particular partitions.
Theexistenceofaparticularpartitionmeansthat—givensensorystates—onecanstipulativelydefinetheconditional
density over external states as being parameterised by the most likely internal state [58]15. We will call this a
variational density parameterised by the internal mode µ(τ)16:
q (η)≜p(η|s)
µ
α(τ)=(a(τ),µ(τ))
α(τ)=argminℑ(α(τ)|s(τ))⇒ (4.16)
α
α[τ]=argminA(α[τ]|s[τ])⇒
α
α˙(τ)=f (s,α)
α
Aswiththepathsofleastaction,wewilluseboldtypefacetodenoteamodeormostlikelystate,givenallthestates
necessarytospecifyitslikelihood. Forautonomousstates, weonlyneedthesensorystates, becausetheautonomous
states are conditionally independent of external states.
Inducingthevariationaldensityisanimportantmove. Itmeansthatforeverysensorystatethereisacorresponding
active mode and an internal mode (or an autonomous mode in the joint space of active and internal states). The
active a(τ), internal µ(τ) and autonomous α(τ) modes evolve on active, internal and autonomous manifolds17,
15Inotherwords,theinternalmodesuppliesthesufficientstatisticsoftheconditionaldensityoverexternalstates.
16Question: what if the conditional densities are not well-behaved, e.g., what if there are no unique modes? The answer
is that well-behaved densities are generally guaranteed when increasing the dimensionality of state-spaces using generalised
coordinatesofmotion[13,14,199]. Inotherwords,insteadofjustdealingwithstates,weconsiderstatesandtheirgeneralised
motiontoarbitrarilyhighorder. Wewillseeexamplesofthislater.
17Amanifoldisatopological(state-)spacewhereeachstatehasaneighbourhoodthatishomeomorphictoaportionofan
Euclideanspaceofthesamedimension[200]. Intuitively,itisacurvedspace,suchasasmoothsurface,inapossiblylargebut
92
respectively,whosedimensionalityisthesameasthesensorystates18. Wewillseelaterthatthesemanifoldsplaythe
role of centre manifolds; namely, manifolds on which dynamics do not diverge(or converge) exponentially fast [189].
Crucially,theinternalmanifoldisalsoastatisticalmanifold becauseitsstatesaresufficientstatisticsforthevariational
density. Inturn,thismeansthatitisequippedwithametricandimplicitinformationgeometry[112,201,202]. Indeed,
theFisherinformationmetrictensor,whichmeasureschangesintheKullback-Leibler(KL)divergenceresultingfrom
infinitesimalchangesintheinternalmode,isaRiemannianmetricthatyieldsaninformationdistance[203,Appendix
B]. ThismeanswecaninterpretdynamicsontheinternalmanifoldasupdatingBayesianbeliefsabout externalstates.
This interpretation can be unpacked in terms of Bayesian inference as follows.
Equation(4.16)meansthatforeverysensorystatethereisaconditionaldensityoverexternalstatesandacorrespond-
inginternalmodewiththesmallestsurprisal. Thismodespecifiesthevariationaldensity,where—bydefinition—the
KLdivergencebetweenthevariationaldensityandtheconditionaldensityoverexternalstatesiszero19. Thismeans
wecanexpresstheautonomousflowasagradientflowonafreeenergyfunctionalofthevariationaldensity20. From
(4.12)
   
f (x) ∇ ℑ(x)
η η
   
  f s (x)  =Ω   ∇ s ℑ(x)  −Λ, (4.17)
 f (π)   ∇ F(π) 
 a   a 
f (π) ∇ F(π)
µ µ
where the free energy in question is (an upper bound on) the surprisal of particular states:
F(π(τ))=E [lnq(η(τ))−lnp(η(τ))−lnp(π(τ)|η(τ))]=ℑ(π(τ))
q
=E [ℑ(η(τ),π(τ))]−H[q(η(τ))]
q
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Expectedenergy Entropy
=E [ℑ(π(τ)|η(τ))]+D[q(η(τ))∥p(η(τ))]
q
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (4.18)
-veAccuracy Complexity
=D[q(η(τ))∥p(η(τ)|π(τ))]+ℑ(π(τ))
(cid:124) (cid:123)(cid:122) (cid:125)
=0
q=q (η)=p(η|s)=p(η|π)
µ
E[F(π)]=E[ℑ(π)]=H[p(π)]
Thisvariationalfreeenergy21 canberearrangedinseveralways. First,itcanbeexpressedasexpectedenergy minus
finitenumberofdimensions. Inthisinstance,thestatesareconditionalmodes.
18The dimensionality of the active, internal and autonomous manifolds corresponds to the number of sensory states. This
meansthatboththenumberofactiveandinternalstatesmustbegreaterthanthenumberofsensorystates. Inturn,thislimits
thestraightforwardapplicationofthefreeenergyprincipletoparticularpartitionswherethenumberofactivestates—andthe
number of internal states—exceeds the number of sensory states. In other words, the FEP applies to large particles with a
nontrivialinternaldynamics.
19Since the variational and conditional densities over external states are equal, any divergence between them will vanish,
see[204,Section3.2].
20A functional is a function of a function, here, the free energy is a function of a conditional density parameterised by the
internalmode.
21Question: whyisthisfunctionalcalledvariational freeenergy? Moregenerally(forinstanceinengineeringapplications
wherethefreeenergyinquestionisalsocalledanevidencelowerbound[91])thefreeenergyisafunctionalofanapproximate
posteriordensityq thatisanapproximationtotheBayesianposterior,asfollows:
qµ(η)≈p(η|π)⇒F[q]=D[q(η(τ))∥p(η(τ)|π(τ))]+ℑ(π(τ))
(cid:124) (cid:123)(cid:122) (cid:125) (4.19)
≥0
The variational density considered in this article is the minimiser of (4.19), and the free energy evaluated at the variational
density is the variational free energy. The term ’variational’ inherits from the use of the calculus of variations in variational
Bayes(a.k.a.,approximateBayesianinference),appliedinthecontextofameanfieldapproximationorfactorisedformofthe
variationaldensity. Theterm’freeenergy’inheritsfromRichardFeynman’spathintegralformulation,inthesettingofquantum
electrodynamics.
93
the entropy of the variational density, which licences the name free energy22. In this decomposition, minimising
variationalfreeenergycorrespondstothemaximumentropyprinciple,undertheconstraintthattheexpectedenergy
is minimised [206,207]. The expected energy is a functional of the NESS density that plays the role of a generative
model; namely, a joint distribution over causes (external states) and their consequences (particular states)23.
Second,variationalfreeenergycanbedecomposedintothe(negative)loglikelihoodofparticularstates(i.e.,negative
accuracy)andtheKLdivergencebetweenposteriorandpriordensities(i.e.,complexity). Finally,itcanbewrittenas
theself-informationassociatedwithparticularstates(i.e.,surprisal)plustheKLdivergencebetweenthevariational
and conditional (i.e., posterior) density, which—by construction—is zero. In variational Bayesian inference [140],
negative surprisal is read as a log marginal likelihood or model evidence, having marginalised over external states.
In this setting, negative free energy is an evidence lower bound or ELBO [91,208].
So,inwhatsensecanweinterpret(4.17)intermsofinference? Letusstartbyconsideringtheresponseofautonomous
statestosomesensoryperturbation: thatis,thepathofautonomousstatesconditioneduponsensorystates. Ifsensory
stateschangeslowly,thentheautonomousstateswillflowtowardstheirmostlikelyvalue(i.e.,theirconditionalmode)
andstaythere24. However,ifsensorystatesarechanging,theautonomousstateswilllookasiftheyaretryingtohit
a moving target. One can formulate this along the lines of the centre manifold theorem [189,209], where we have a
(fast) flow off the centre manifold and a (slow) flow of the autonomous mode on the manifold.
α(τ)= ε(τ) + α(τ)
(cid:124)(cid:123)(cid:122)(cid:125) (cid:124)(cid:123)(cid:122)(cid:125) (4.20)
Offmanifold Onmanifold
ε(τ)≜α(τ)−α(τ)
In effect, this is a decomposition in a frame of reference that moves with the autonomous mode, whose path lies on
the centre manifold. We further describe the off manifold flow using a Taylor expansion around the (time-varying)
autonomous mode25
∂f ∂f
ε˙(τ)=α˙(τ)−α˙(τ)=f (0)+ ε ·ε+...= α ·ε+...
ε ∂ε ∂α
⇒
α˙(τ)−α˙(τ) =J ·(α−α)+... (4.21)
α
(cid:124) (cid:123)(cid:122) (cid:125)
Offmanifoldflow
=−(Γ ∇ F)·(α−α)+ (Q ∇ F)·(α−α) +...
α αα αα αα
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Flowtocentremanifold Flowparalleltothemanifold
This means that the flow at the expansion point is zero, leaving the second term of the expansion as the first non-
vanishingterm. ThisistheJacobianoftheautonomousflowtimesthedisplacementofthecurrentautonomousstate
22Question: is variational free energy the same kind of free energy found in statistical mechanics? The answer is no: the
entropy term in the variational free energy is the entropy of a variational density—over external states—parameterised by
internal states. This entropy is distinct from the entropy of internal states. Minimising variational free energy increases the
entropyofthevariationaldensityand,usually,reducestheentropyofinternalstates(see[205]foranexample). Mathematically,
wecanexpressthedifferentkindofentropiesasH[q(η(τ))]̸=H[p(µ(τ))].
23Question: in practical applications, variational free energy is usually a function of data or observed (sensory) states.
So, why is variational free energy a function of particular states? Later, we will see that practical applications correspond to
Bayesian filtering, under the assumption that particular dynamics are very precise. This means that there is no uncertainty
aboutautonomouspathsgivensensorypaths,andtheactionofaparticularpathistheactionofasensorypath. Ingeneralised
coordinates of motion—used in Bayesian filtering—the action of a path becomes the surprisal of a state. In this setting, the
variationalfreeenergyofparticularstatesisthesameasthevariationalfreeenergyofsensorystates.
24Or,atleastinthevicinity,iftherearerandomfluctuationsonitsmotion.
25NotethatweareperformingaTaylorexpansionofa(generallyrough)stochasticprocessε,see[210,Chapter5]. Alterna-
tively, it may be possible to instead consider motion in generalised coordinates to introduce smooth random fluctuations (see
nextSection),sothatεbecomessmoothandtheusualTaylorexpansionapplies.
94
Figure4.2: Autonomous flows and Bayesian filters. Thisfigureshowstwocomponentsoftheautonomousflow; namely,
a (fast) flow α˙(τ)−α˙(τ) off the (centre) manifold, and a (slow) flow α˙(τ) on the manifold. The manifold here is the set of
autonomousmodesα(τ)givensensorystatess(τ)foralltimeτ,see(4.16). Thedecompositionintofastandslowflowsmeans
thatthemanifoldcanbethoughtofasacentremanifold. Theleftpanelshowstwocomponentsofthefastflowoffthemanifold;
namely, a flow towards the centre manifold and a flow parallel to the manifold, see (4.21). This decomposition rests upon a
first-orderTaylorexpansionoftheoffmanifoldflow. Therightpanelplotstheexternalmodeasafunctionoftheautonomous
mode—what is known as a synchronisation manifold—as a black curvilinear line. The Gaussian (blue and red) distributions
show possible variations in (external and autonomous) conditional modes due to variations in the sensory states. The arrows
represent the centre manifold flow α˙(τ) in the context of this synchronisation manifold, where the tangent vectors represent
possibledirectionsoftheflow.
from its corresponding mode. The second-order derivatives of the free energy arise from the Jacobian of the flow,
i.e., substituting (4.17) into (4.8). Therefore, the off manifold flow has a component that flows towards the centre
manifold,26 affordedbythegradientflow,andacomponentthatisparallel tothemanifold,affordedbythesolenoidal
flow, cf. (4.6). Taken together, this means that the autonomous states flow in ever-decreasing circles towards the
centre manifold, as illustrated in Figure 4.2.
But what about the flow on the centre manifold? We know from (4.17) that the flow of the autonomous mode can
be expressed in terms of free energy gradients:
α˙(τ)=(Q −Γ )∇ F(s,α)+...
αα α α
=(Q −Γ )∇ E [ℑ(s,α|η)]+(Q −Γ )∇ D[q (η)∥p(η)]+... (4.22)
αα α α q αα α α µ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
-veAccuracy Complexity
This expression unpacks the centre manifold flow in terms of the accuracy and complexity parts of free energy,
where the accuracy part depends upon the sensory states, while the complexity part is a function of, and only of,
autonomous states. In short, the flow on the centre manifold will look as if it is trying to maximise the accuracy of
its predictions, while complying with prior (Bayesian) beliefs.27 Here, predictions are read as the expected sensory
states, under posterior (Bayesian) beliefs about their causes afforded by the variational density over external states.
26We know that the flow must be towards the centre manifold because the covariance of random fluctuations is positive
definite,andthecurvatureofthefreeenergyispositivedefiniteatitsminima: i.e.,aroundtheexpansionpoint.
27The covariance of random fluctuations Γα is positive definite and the solenoidal matrix field Qαα is skew-symmetric,
thereforetheflowin(4.22)willseektominimisecomplexityminusaccuracy.
95
Summary
In summary, a particular partition of a nonequilibrium steady-state density implies that autonomous dynamics can
be interpreted as performing a particular kind of inference. This entails a fast flow towards an autonomous centre
manifold and a slow flow on the centre manifold. The centre manifold flow can be interpreted as Bayesian belief
updating, where posterior (Bayesian) beliefs are encoded by points on an internal (statistical) manifold. In other
words,foreverypointonthestatisticalmanifold,thereisacorrespondingvariationaldensityorBayesianbeliefover
external states. We are now in a position to express this belief updating as a variational principle of least action:
α[τ]=argminA(α[τ]|s[τ])
α[τ]
⇔δ A(α[τ]|s[τ])=0
α
(4.23)
⇔
a˙(τ)=f (s,α)=(Q −Γ )∇ F(s,α)+...
a aa a a
µ˙(τ)=f (s,α)=(Q −Γ )∇ F(s,α)+...
µ µµ µ µ
This is a basis of the free energy principle. Put simply, it means that the internal states of a particular partition
canbecastasencodingconditionalorposteriorBayesianbeliefsabout externalstates. Equivalently,theautonomous
pathofleastactioncanbeexpressedasagradientflowonavariationalfreeenergythatcanbereadaslogevidence.
Thislicencesasomewhatpoeticdescriptionofself-organisationasself-evidencing[185],inthesensethatthesurprisal
or self-information is known as log model evidence or marginal likelihood in Bayesian statistics28.
Interestingly,becauseofthesymmetricsetupoftheMarkovblanket,itwouldbepossibletorepeateverythingabove
but switch the labels of internal and external states—and active and sensory states—and tell the same story about
externalstatestrackinginternalstates. Thisevincesaformofgeneralisedsynchrony[58,128,212,213],whereinternal
andexternalstatestrackeachother. Technically,ifweconsiderthe(internalandexternal)manifoldsinthejointspace
of internal and external states, we have something called a synchronisation manifold that offers another perspective
on the coupling between the inside and outside [58,112,214].
These teleological interpretations cast particular paths of least action as an optimisation process, where different
readings of free energy link nicely to various normative (i.e., optimisation) theories of sentient behaviour. Some
cardinalexamplesaresummarisedinFigure4.3;see[1,113,139,215]forsomeformalaccountsoftheserelationships.
Because internal states do not influence sensory (or external) states, they will look as if they are concerned purely
withinference,inthesensethattheyparameterisethevariationaldensityoverexternalstates. However,activestates
influence sensory (and external) states and will look as if they play an active role in configuring (and causing) the
sensory states that underwrite inference. In the neurosciences, this is known as active inference [110,144,152].
The link between optimisation and inference is simply that inference is belief optimisation. However, it is worth
unpacking the gradients that ‘drive’ this optimisation. In statistics, variational free energy is used to score the
divergencebetweenavariationaldensityandtheconditionaldensityoverexternal(i.e.,hidden)states,givenblanket
states [208]. Unlike the definition in (4.18), these densities are not assumed to be equivalent. Variational inference
proceeds by optimising the variational density such that it minimises free energy—often using the gradient flows in
(4.17). However,thereisasubtledifferencebetweenthedynamicsof (4.17)andvariationalinference. Intheformer,
28Question: this Bayesian mechanics seems apt for inference but what about learning over time? We have been dealing
withstatesinagenericsense. However,onecanhavestatesthatchangeoverdifferenttimescales. Onecanreadslowlychanging
states as special states that play the role of parameters; either parameters of the flow or, implicitly, the generative model. In
mathematicalandnumericalanalyses,statesandparametersareusuallytreatedidentically;i.e.,asminimisingvariationalfree
energy. Indeed,inpracticalapplicationsofBayesianfilteringschemesthatlearn,theparametersaretreatedasslowlychanging
states. See[14,211]forworkedexamples.
96
there is no contribution from the KL-divergence as it is stipulated to be zero. In the latter, it is only the divergence
term that contributes to free energy gradients. So, is it tenable to interpret gradient flows on variational free energy
asvariationalinference,oristhisjustteleologicalwindow-dressing? Thenextsectionaddressesthisquestionthrough
thelensofBayesianfiltering. Inbrief,wewillseethattheautonomouspathsofleastaction—impliedbyaparticular
partition—arethepathsofleastactionofaBayesianfilter. Thistakesusbeyond‘asif’argumentsbyestablishinga
formal connection between particular dynamics and variational inference.
4.7 Lagrangians, generalised states and Bayesian filtering
Now,saywewantedtoemulateorsimulateactiveinference. Givensomeequationsofmotionandstatisticsofrandom
fluctuations, we could find the stationary solution to the Fokker Planck equation and accompanying Helmholtz
decomposition. We could then solve (4.23) for the autonomous paths of least action that characterise the expected
behaviour of this kind of particle, and obtain realisations of synchronisation and inference. See [9] for a worked
example using a system of coupled Lorentz attractors.
Inthissection,wetakeasomewhatpragmaticexcursiontosuggestasimplerwaytorecoverthepathsofleastaction;
namely, as the solution to a generic (Bayesian) filtering scheme that is widely used in the engineering literature.
4.7.1 Dynamics in generalised coordinates of motion
Let us go back to the Langevin equation governing our system
x˙(τ)=f(x)+ω(τ). (4.24)
In this section, we assume that the random fluctuations driving the motion have smooth (analytic) sample paths;
thus,theLangevinequationconsideredintherestofthearticlecanbeseenasthelimitof (4.24)asthefluctuations
become rough [234]. This setup speaks nicely to the fact that, in biology, fluctuations are often smooth up to a
certainorder—contrariwisetothermal(whitenoise)fluctuations—astheyaretheoutputofotherrandomdynamical
systems. As before, we assume that the fluctuations are state-independent, and a stationary Gaussian process, e.g.,
the smoothing of white noise fluctuations with a Gaussian kernel. Just like in the case of white noise, Gaussianity
can be motivated by the central limit theorem—fluctuations should be normally distributed at each point in time.
We denote the autocovariance of fluctuations by Γ = 1E[ω(τ)⊗ω(τ +h)]. The underlying dynamical systems
h 2
givingrisetothisgenerictypeofsmoothnoisecanberecoveredthroughaprocedureknownasstochasticrealisation
[58,159,161]. ThesolutiontotheLangevinequation(4.24)canbeapproximated,onasuitablysmallintervaloftime,
by a linear Langevin equation in generalised coordinates of motion⃗x=(x,x′,x′′,...) [235, Section 4]:2930
29Theexpansion(4.25)isalinearapproximationof (4.24)[236],obtainedbyrecursivelydifferentiating (4.24)andignoring
thecontributionofthederivativesoftheflowoforderhigherthanone. Inotherwords,theexpansionisexactwhentheflowis
linear,anditisaccurateonashorttime-scalewhentheflowisnon-linear.
30The curvature (i.e., second derivative) of the autocovariance Γ′′ is a ubiquitous measure of roughness of a stochastic
0
process[237]. Notethatinthelimitwherethefluctuationsω areuncorrelated(e.g.,whitenoisefluctuations),Γ′′ (andhigher
0
derivatives)becomeinfinitelylarge.
97
Figure4.3: Markov blankets and self-evidencing. Thisschematicillustratesvariouspointsofcontactbetweenminimising
variationalfreeenergyandothernormativetheoriesofoptimalbehaviour. TheexistenceofaMarkovblanketentailsacertain
lackofinfluencesamonginternal,blanketandexternalstates. Thesehaveanimportantconsequence—internalandactivestates
arenotinfluencedbyexternalstates, whichmeanstheirdynamics(i.e., perceptionandaction)areafunctionof, andonlyof,
particular states, given by a variational (free energy) bound on surprisal. This has a number of interesting interpretations.
Given surprisal is the negative log probability of finding a particle or creature in a particular state, minimising surprise
corresponds to maximising the value of that state. This interpretation is licensed by the fact that the states with a high
probability are, by definition, characteristic of the particle in question. On this view, one could relate this to dynamics in
reinforcementlearning[216],optimalcontroltheory[217]and,ineconomics,expectedutilitytheory[218,219]. Gradientflows
thatminimisesurprisal(i.e.,self-information)leadtoaseriesofinfluentialaccountsofneuronaldynamics;includingtheprinciple
ofmaximummutualinformation[220,221],theprinciplesofminimumredundancyandmaximumefficiency[222]andthefree
energy principle [223]. Crucially, the average or expected surprise (over time of particular states) corresponds to entropy.
This means that action and perception look as if they are bounding the entropy of particular states. This links nicely with
theories of self-organisation, such as synergetics in physics [92,94,224] or homoeostasis in physiology [225–227]. Finally, the
probability of a particular state, is, on a statistical view, model evidence or marginal likelihood [228,229], marginalising over
thecausesofparticularstates(i.e.,externalstates). Thismeansthatalltheaboveformulationsareinternallyconsistentwith
thingsliketheBayesianbrainhypothesis,evidenceaccumulationandpredictivecoding[1,133,139]. Mostoftheseformulations
inherit from Helmholtz’s motion of unconscious inference [230], later unpacked in terms of perception as hypothesis testing
in psychology [231] and machine learning [232]. Although not depicted here, the minimisation of complexity—inherent in the
minimisationoffreeenergy—enablesthermodynamicandmetabolicefficiencyviaLandauer’sprinciple[233].
98

x˙
x
′
˙
=
=
x
x
′′
′
=
=
∇
∇
f
f
·
·
x
x
′
+
+
ω
ω′

⃗x˙ =f(⃗x)+ω⃗
x˙′′ =x′′′ =∇f ·x′′+ω′′ ⇔ D⃗x=J⃗x+ω⃗
.
.
.

p(ω⃗(τ))=N(ω⃗(τ);0,2Γ)
(4.25)
 0 1   ∇f   Γ Γ′′ 
0 0
D=        0 1 0 . . . . . .        , J=       ∇f ∇f ...       , Γ=       Γ′ 0 ′ − − Γ Γ ′′ ′ 0 ′ ′ ′ Γ′ 0 ′′′ − . Γ . ′ 0 . ′′′      
0
(cid:16) (cid:17)
Here, the different variables⃗x= x,x′,x′′,...,x(n),... can be seen as the position, velocity, acceleration, jerk, and
higher orders of motion of the process, which are treated as separate (generalised) states that are coupled through
theJacobianJ. Thesearedrivenbysmoothfluctuationsω⃗ (i.e.,theserialderivativesofω)whosecovariance2Γcan
be expressed in terms of the serial derivatives of the autocovariance [238, Appendix A.5.3].
ThegeneralisedstatesarethecoefficientsofaTaylorseriesexpansionofthesolutiontotheLangevinequation(4.24):
x′′(0) x(n)(0)
x(τ)=x(0)+x′(0)τ + τ2+...+ τn+..., (4.26)
2 n!
where (4.26) holds, typically, only on a small time-interval to which we restrict ourselves henceforth. In other
words, thegeneralisedstatesatanytime-pointdeterminethesystem’strajectory, andviceversa; thatis,thereisan
isomorphism between generalised states and paths.
This line of reasoning has two advantages. First, it means one can let go of white noise assumptions on the random
fluctuations and deal with smooth or analytic fluctuations. Second, the linear expansion in generalised coordinates
of motion (4.25) means that the distribution of generalised states has a simple Gaussian form
1
L(⃗x(τ))≜−lnp(⃗x(τ))= ⃗x(τ)·M⃗x(τ)
2 (4.27)
1
M=(D−J)· (D−J).
2Γ
Here,Mcanbereadasamassmatrix. Thissuggeststhatpreciseparticles,withlowamplituderandomfluctuations,
behave like massive bodies. Furthermore, (4.27) is seen as the Lagrangian in generalised coordinates of motion, due
to its formal similarity with (4.3). Under the isomorphism between points and paths in generalised coordinates, the
Lagrangianisequivalenttotheaction; itscoresthelikelihoodofpathsof (4.24),asapathcorrespondstoapointin
generalisedcoordinatesofmotion31. WewillreasonaboutthetrajectoriesofthesystembyanalysingtheLagrangian
of generalised states henceforth.
The path of least action corresponds to the minimiser of the Lagrangian, which can be expressed as follows:
−→
x(τ)=argminL(⃗x(τ))
⃗x(τ) (4.28)
−→
⇔∇L(x(τ))=0 ∀τ.
31Question: how can a point be a path? The generalised states (i.e., temporal derivatives) approximate the path of the
solution to (4.24) on a suitably small time interval because they are the coefficients of a Taylor expansion of the path as a
functionoftime(4.26).
99
We can recover the path of least action by solving the following equation of motion
⃗x˙(τ)=D⃗x−∇L(⃗x)
(4.29)
∇·D⃗x=0.
Indeed, this motion can be interpreted as a gradient descent on the Lagrangian, in a frame of reference that moves
with the mode of the distribution of generalised states [14]. Thus, the convexity of the Lagrangian means that any
solutionto(4.29)convergestothepathofleastaction. Inthissetting,thedivergence-freeflow(i.e.,thefirstterm)is
known as aprediction of thegeneralised statebased upon generalisedmotion, whilethe curl-free, gradient flow (i.e.,
the second term) is called an update.
4.7.2 Particular partitions in generalised coordinates of motion
We now reintroduce the distinction between internal, external, sensory and active states x = (η,s,a,µ). Briefly, as
before,weassumethattheLangevinequation(4.24)issparselycoupledasin(4.13). Thisimpliesthatthetrajectories
internal and external to the particle are conditionally independent given the trajectories of the blanket (4.15). The
samesparsecouplingstructurecarriesthroughtheexpansioningeneralisedcoordinates(4.25)sothatthemotionof
generalisedstatesentailstrajectorieswiththesameconditionalindependencies. Sincepathscorrespondtogeneralised
states, this yields conditional independence between generalised states, as follows:
(µ⃗ ⊥⃗η)|⃗b ⇐⇒ L(⃗x)=L(⃗η|⃗b)+L(µ⃗ |⃗b)+L(⃗b). (4.30)
We can now recover paths of least action of the particle by equating the Lagrangian with the variational free energy
ofgeneralisedstates. Thisallowsustoexpresstheinternalpathofleastactionasagradientflowonvariationalfree
energy, which can itself be expressed in terms of generalised prediction errors. From (4.29), we have
µ⃗˙(τ)=Dµ⃗−∇ L(⃗x)=Dµ⃗−∇ L(µ⃗ |⃗b)
µ⃗ µ⃗ (4.31)
=Dµ⃗−∇ L(⃗π)=Dµ⃗−∇ F(⃗π),
µ⃗ µ⃗
where the free energy of generalised states is analogous to (4.18)
F(⃗s,⃗a,µ⃗)= E [L(⃗η,⃗π)] −H[q(⃗η)]
q
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Expectedenergy Entropy
=E [L(⃗π|⃗η)]+D[q(⃗η)∥p(⃗η)]
q
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Accuracy Complexity
=D[q(⃗η)∥p(⃗η|⃗π)]+L(⃗π)
(4.32)
q (⃗η)=N(⃗η; −→ µ,Σ( −→ µ))=p(⃗η|⃗π)=p(⃗η|⃗b)
µ⃗
1 1
L(⃗η,⃗π)=ε · ε +ε · ε +...
η⃗ 4Γ η⃗ ⃗s 4Γ ⃗s
η s
ε ≜D⃗η−f (⃗η,⃗s)
η⃗ η⃗
ε ≜D⃗s−f (⃗η,⃗s).
⃗s ⃗s
The variational free energy of generalised states is easy to evaluate, given a generative model in the form of a
state-space model [14]; that is, the generalised flow of external and sensory states f ,f , and the covariance of their
η⃗ ⃗s
generalisedfluctuationsΓ ,Γ . Notethattheparameterisationofthevariationaldensityisverysimple: theinternal
η s
statesparameterisetheexpectedexternalstates. Furthermore,thequadraticformoftheLagrangianmeansthatthe
100
variationaldensityoverthegeneralisedmotionofexternalstatesisGaussian32. Thislicensesaubiquitousassumption
in variational Bayes called the Laplace assumption. Please see [177] for a discussion of the simplifications afforded
by the Laplace assumption.
Crucially,intheabsenceofactivestates,thedynamicin(4.31)coincideswithageneralisedBayesianfilter. Generalised
filteringisagenericBayesianfilteringschemefornonlinearstate-spacemodelsformulatedingeneralisedcoordinates
of motion [14]; special cases include variational filtering [166], dynamic expectation maximisation [167], extended
Kalman filtering [239], and generalised predictive coding.
Furthermore,iftheautonomouspathsareconditionallyindependentfromexternalpaths,givensensorypaths33,the
autonomous paths of least action can be recovered from a generalised gradient descent on variational free energy:
α⃗˙(τ)=Dα⃗ −∇ L(⃗x)=Dα⃗ −∇ L(α⃗ |⃗s)
α⃗ α⃗ (4.33)
=Dα⃗ −∇ L(⃗π)=Dα⃗ −∇ F(⃗π).
α⃗ α⃗
In this case, the most likely paths of both internal and active states can be recovered by a gradient descent on
variational free energy, and one can simulate active inference using generalisations of linear quadratic control or
model predictive control [240,241]:
 ⃗η˙(τ)   f (⃗η,⃗s,⃗a)+ω⃗ (τ) 
η⃗ η
   ⃗s˙(τ)   =    f ⃗s (⃗η,⃗s,⃗a)+ω⃗ s (τ)    (4.34)
 ⃗a˙(τ)   D⃗a−∇ F(⃗s,⃗a,µ⃗) 
   ⃗a 
µ⃗˙(τ) Dµ⃗−∇ F(⃗s,⃗a,µ⃗)
µ⃗
This is effectively a (generalised) version of the particular dynamics in (4.23).
Summary
This section has taken a somewhat pragmatic excursion from the FEP narrative to consider generalised coordinates
ofmotion. Thisexcursionisimportantbecauseitsuggeststhatthegradientflowsinsystemswithattractingsetsare
thepathsofleastactioninBayesianfiltersusedtoassimilatedatainstatistics[239]and,indeed,controltheory[242].
Working in generalised coordinates of motion is effectively working with paths and the path integral formulation.
Practically, this is useful because one can use the density over paths directly to evaluate the requisite free energy
gradients, as opposed to solving the Fokker-Planck equation to find the NESS density. Effectively, the generative
model becomes a state-space model, specified with flows and the statistics of random fluctuations: see (4.32). These
are the sufficient statistics of the joint density over external and sensory paths.
Hitherto, we have largely ignored random fluctuations in the motion of particular states to focus on the underlying
flows. Are these flows ever realised or does the principle of least action in (4.23) only apply to the most likely
autonomous paths? In what follows, we will consider a special class of systems, where we suppress particular
fluctuations to recover the behaviour of particles that show a precise or predictable response to external states. For
this kind of particle, the particular paths are always the paths of least action.
32Question: why is the covariance of the variational density only a function of the internal mode? This follows from the
quadraticLagrangianthatfurnishesananalyticsolutiontothefreeenergyminimum. Pleasesee[177]fordetails.
33This is the case for precise particles, which are defined by particular fluctuations of infinitesimally small amplitude—see
nextSectionand[13].
101
4.8 From statistical to classical particles
Sofar,wehaveaBayesianmechanicsthatwouldbeapttodescribeaparticleorpersonwithapullbackattractor. But
whatisthedifferencebetweenaparticleandaperson? Thisquestionspeakstodistinctclassesofthingstowhichthe
freeenergyprinciplecouldapply;e.g.,molecularversusbiological. Here,weassociatebioticself-organisationwiththe
precise and predictable dynamics of large particles. Thanks to the Helmholtz decomposition (4.6), it is known that
when random fluctuations are large, dissipative flow dominates conservative flow, and we have ensembles described
bystatisticalmechanics(i.e.,smallparticles). Conversely,whenrandomfluctuationshavealowamplitude,solenoidal
flow34 dominates and we have classical mechanics and deterministic chaos (i.e., of heavenly and n-body problems).
Here, we consider the distinction between statistical and classical mechanics in the setting of a particular partition.
It is often said that the free energy principle explains why biological systems resist the second law and a natural
tendency to dissipation and disorder [8]. However, this is disingenuous on two counts. First, the second law only
appliestoclosedsystems,whilethefreeenergyprincipledescribesopensystemsinwhichinternalstatesareexposed
to—and exchange with—external states through blanket states. Second, there is nothing, so far, to suggest that the
entropy of particular states or paths is small. Everything we have done would apply equally to particles with high
andlowentropydensities. So,whatdistinguishesbetweenhighandlowentropysystems(e.g.,betweencandleflames
and concierges), respectively?
One answer can be found in the path-integral formulation: from (4.5), we can associate the entropy of a path (i.e.,
history or trajectory of particular states) with the amplitude of random fluctuations. This licences the notion of
precise particles that are characterised by low or vanishing random fluctuations35. In essence, precise particles are
simply ‘things’ that are subject to the classical laws of nature; i.e., Lagrangian mechanics. In the case of vanishing
fluctuations on particular states, every autonomous trajectory is a path of least action. From (4.5) and (4.23) this
can be expressed as follows:
Γ ≡0
π
⇒
α˙(τ)=f (π(τ))⇔δ A(α[τ]|s[τ])=0⇔α[τ]=α[τ]
α α (4.35)
⇒
a˙(τ)=a˙(τ)=(Q −Γ )∇ F(π)+...
aa a a
µ˙(τ)=µ˙(τ)=(Q −Γ )∇ F(π)+...
µµ µ µ
This suggests that precise particles—such as you and me—will respond to environmental flows and fluctuations in a
precise and predictable fashion. Figure 4.4 illustrates the difference between generic and precise particles using an
informationdiagram. Notethatforpreciseparticles,thereisnouncertaintyaboutautonomousstates,givensensory
states. This follows because the flow of autonomous states depends only on sensory states and themselves. Is the
behaviour of precise particles a sufficient description of sentient behaviour?
Ononereading,perhaps: onecanreproducebiologicalbehaviourbynumericallyintegrating (4.23)or(4.34)undera
suitable generative (state-space) model specifying the motion of external and sensory states36. Figure 4.5 illustrates
34AnditsaccompanyingcorrectiontermΛ,see(4.6).
35Question: butsurelymyneuronsarenoisy? Thereisasubstantialliteraturethatreferstoneuronalandsynapticnoise:
e.g., [243]. However, the population dynamics of neuronal ensembles or assemblies are virtually noiseless by the central limit
theorem(becausetheycomprisethousandsofneurons),whenaveragedoversuitablespatialandtemporalscales. Forexample,
inelectrophysiology,averagingseveralfluctuatingsingletrialresponsesyieldssurprisinglystableandreproducibleevent-related
potentials. FromtheperspectiveoftheFEP,studyingsingleneurons(ortrials)islikestudyingsinglemoleculestocharacterise
fluiddynamics.
36A generative model can be specified through the flow of external or sensory states, and the random fluctuations of their
102
Figure 4.4: Generic and precise particles. These information diagrams depict the entropy of external, sensory and au-
tonomous paths, where intersections correspond to shared or mutual information. A conditional entropy corresponds to an
area that is outside the variable upon which the entropy is conditioned. The diagram on the left shows the generic case, in
whichuncertaintyaboutpathsinheritsfromrandomfluctuationsthatdeterminetheconditionalentropiesofpaths. Whenthe
amplitudeofrandomfluctuationsonthemotionofparticularstatesisverysmall,wehavepreciseparticlesinwhichthereisno
uncertainty about autonomous paths, given sensory paths (the right information diagram). Similarly, there is no uncertainty
about sensory paths given external and autonomous paths. Note that because we are dealing with continuous states, we are
implicitlyinterpretingtheentropiesasthelimitingdensityofdiscretepoints(LDDP),whichhavealowerboundofzero[206].
(LDDPisanadjustmenttodifferentialentropywhichensuresthatentropyislowerboundedbyzero. LDDPequalsthenegative
KL-divergencebetweenthedensityinquestionandauniformdensity). Tworelativeentropies(informationgainandrisk)are
highlighted as areas of intersection. These will play an important role later, when decomposing the action (i.e., expected free
energy)ofautonomouspaths.
the implicit computational architecture used to simulate sentient behaviour by integrating (4.23). This scheme
allowsonetosimulatetheinternalandactivestatesthroughsensorystatescausedbyexternaldynamics. Figure4.6
showcasesanexamplefromtheactiveinferenceliterature,thatintegrates(4.34)underasuitablyspecifiedgenerative
model, to simulate sentient behaviour that looks like handwriting. The details of the simulation and the details of
the generative model are not relevant here but are summarised in the figure legend; what is important is to get a
sense of the kind of behaviour that can be reproduced by integrating (4.34).
TheexampleinFigure4.6illustratesanapplicationofthefreeenergyprinciple. Here,insteadofdescribingasystem
by deriving its NESS density, we have specified some equations of motion (and covariance of random fluctuations)
to realise particular dynamics using (4.34) and (4.32). In effect, we have simulated self-evidencing, starting from a
definition (i.e., state-space generative model) of paths that characterise this kind of particle37.
These simulations speak to a key aspect in the applications of the FEP. Hitherto, we have simply defined the
variational density as the conditional density over external states given a sensory state. However, when simulating
precise particles through a gradient flow on variational free energy, as in (4.23) or (4.34), the requisite gradients
have to be evaluated. In turn, this requires the functional form of the variational density or posterior distribution,
motion; that is, the first two lines of (4.34). Observing that the free energy (4.31) is only a function of these flows and the
covarianceoffluctuations,itissufficienttospecifythosecovariances,ratherthanthewholestructureofthefluctuations.
37The example in Figure 4.6 used (4.34) with generalised coordinates of motion up to fourth order. Numerical analyses
suggestthatsimulatinggeneralisedmotionuptoordersix(i.e.,ignoringallsubsequentordersofmotions)issufficientinmost
circumstances[167].
103
Figure 4.5: Bayesian mechanics and active inference. This graphic summarises the belief updating implicit in gradient
flowsonvariationalfreeenergy. Thesearethepathstakenbyapreciseparticleorthepathsofleastactionofagenericparticle.
It illustrates a simple form of (active) inference that has been used in a variety of applications and simulations; ranging from
handwriting and action observation [244], through to birdsong and generalised synchrony in communication [214]. In brief,
sensory states furnish free energy gradients (often expressed as prediction errors), under some generative model. Neuronal
dynamicsaresimulatedasaflowontheresultinggradientstoproduceinternalstatesthatparameteriseposteriorbeliefsabout
externalstates. Similarly,activestatesaresimulatedasaflowonfreeenergygradientsthatgenerallyplaytheroleofprediction
errors. Inotherwords,activestatesmediatemotororautonomicreflexes[245,246]. Anexampleofthiskindofactiveinference
isprovidedinthenextfigure.
which may be difficult to compute exactly38. In this case, we take a variational density that approximates the true
posterior,whencethevariationalfreeenergybecomesanupperboundonsurprisal: see(4.19). Fromtheperspective
ofBayesianinference,thistakesusfrom(computationallycostly)exact Bayesianinferenceto(computationallycheap)
approximate Bayesianinference[140,208,250]. Ononereadingofitsinception,thisiswhyvariationalfreeenergywas
introduced [251]; namely, to convert a computationally expensive marginalisation problem into a computationally
manageableoptimisationproblem. Notethatwhenusinggeneralisedcoordinatestorealiseactiveinference;i.e.,(4.34),
we are generally employing approximate Bayesian inference: the functional form of the variational density inherits
directlyfromGaussianassumptionsaboutrandomfluctuations,howevertheexpansioningeneralisedcoordinateson
which it is based upon (4.29) is generally an approximation to the underlying dynamic (cf. 29).
38InBayesianinference,itiswell-knownthatcomputingtheposteriordistributiongivendataandagenerativemodelp(η|
(cid:82)
π)=p(η,π)/p(π)iscomputationallycostlyasitinvolvescomputinga(typically)high-dimensionalintegralp(π)= p(η,π)dη
(i.e.,apartitionfunction).
104
Figure 4.6: Sentient behaviour and action observation. This figure illustrates a simulation of active inference (here,
writing) evinced by a precise particle, in terms of inferences about external states of the world, consequent predictions about
sensory input, and ensuing action. The autonomous dynamics that underwrite this behaviour rest upon a generative model
of sensory states in the form of Lotka-Volterra dynamics; see sample sensory trajectories as (arbitrarily) coloured lines in the
upperleftinset. Thegenerativemodeldefinesthejointdensityunderwhichinternaltrajectoriescanbeseenasparameterising
external states. This model is not a description of the true external states (which here are simply the positions of the joints
in the simulated arm—with dynamics given by simple Newtonian rules). In this generative model, external trajectories are
assumed to follow predator-prey like dynamics such that a succession of peaks are generated for a subset of external states
(orcoordinates)inturn. EachcoordinateisassociatedwithalocationinEuclideanspacethatattractstheagent’sfinger(the
activestates);i.e.,withatrajectorytowardsthatattractingpoint. Theresultingattractingpointisthusaweightedsumofeach
possibleattractingpointweightedbythecoordinatesfollowingtheLotka-Volterratrajectory. Inturn,theinternalstatessupply
predictionsofwhatsensorystatesshouldregisteriftheagent’sbeliefsweretrue. Activestates(i.e.,theforcesdrivingchanges
intheangularvelocitiesofthelimbjoints)trytosuppresstheensuingpredictionerrorbyadjustingexpectedchangesinsensed
angular velocity, through exerting forces on the agent’s joints (not shown). The subsequent movement of the arm is traced
out in the lower-left panel. This trajectory has been plotted in a moving frame of reference so that it looks like handwriting
(e.g.,asuccessionof‘j’and‘a’letters). Thelowerrightpanelsshowtheactivityofoneinternalstateduringdistinctphasesof
‘action’, and‘action-observation’. Duringtheactionphase, sensorystatesregisterthevisualandproprioceptiveconsequences
ofmovement,whileunderactionobservation,onlyvisualsensationsareavailable—asiftheagentwaswatchinganotheragent.
Thereddotscorrespondtothetimesduringwhichthisinternalstateexceededanarbitrarythreshold. Thekeythingtonote
hereisthatthisinternalstaterespondspreferentiallywhen,andonlywhen,themotortrajectoryproducesadown-stroke,but
not an up-stroke—evincing a cardinal feature of neuronal responses, namely, their functional selectivity. Furthermore, with a
slightdelay,thisinternalstaterespondsduringactionandactionobservation. Fromabiologicalperspective,thisisinteresting
becauseitspeakstoanempiricalphenomenonknownasmirrorneuronactivity[247–249]. Pleasesee[244]forfurtherdetails.
105
Summary
Preciseparticles,immersedinanimpreciseworld,respond(almost)deterministicallytoexternalfluctuations39. This
means, given a generative model (i.e., NESS density), one can solve the equations of motion in (4.34) to predict
how autonomous states evolve as they pursue their path of least action. So, why might this limiting behaviour be
characteristically biological?
Precise particles may be the kind of particles that show lifelike or biotic behaviour, in the sense they respond
predictably, given their initial states and the history of external influences. The distinction between imprecise (e.g.,
statistical)andprecise(e.g.,classical)particlesrestsontherelativecontributionofdissipativeandconservativeflow
to their path through state-space, where solenoidal flow predominates in the precise setting. This means precise
particles exhibit solenoidal behaviour such as oscillatory and (quasi) periodic orbits—and an accompanying loss of
detailed balance, i.e., turbulent and time-irreversible dynamics [195,252,253]. On this view, one might associate
precise particles with living systems with characteristic biorhythms [254–257]; ranging from gamma oscillations in
neuronal populations, through slower respiratory and diurnal cycles to, perhaps, lifecycles per se. Turning this on
its head, one can argue that living systems are a certain kind of particle that, in virtue of being precise, evince
conservative dynamics, biorhythms and time irreversibility.
Onemightaskifsolenoidalflowconfoundsthegradientflowsthatunderwriteself-evidencing. Infact,solenoidalflow
generally augments gradient flows—or at least this is what it looks like. In brief, the mixing afforded by solenoidal
flowcanrendergradientdescentmoreefficient[34,60,258–260]. Anintuitiveexampleisstirringsugarintocoffee. The
mixing afforded by the solenoidal stirring facilitates the dispersion of the sugar molecules down their concentration
gradients. On this view, the solenoidal flow can be regarded as circumnavigating the contours of the steady-state
density to find a path of steepest descent.
Theemergingpicturehereisthatbioticsystemsfeaturesolenoidalflow,invirtueofbeingsufficientlylargetoaverage
away random fluctuations, when coarse-graining their dynamics [113]. From the perspective of the information
geometry induced by the FEP, this means biological behaviour may be characterised by internal solenoidal flows
that do not change variational free energy—or surprisal—and yet move on the internal (statistical) manifold to
continually update Bayesian beliefs about external states. Biologically, this may be a description of central pattern
generators[256,261]thatunderwriterhythmicalactivity(e.g.,walkingandtalking)thatischaracteristicofbiological
systems [262]. The example in Figure 4.6 was chosen to showcase the role of solenoidal flows in Bayesian mechanics
that—in this example—arise from the use of Lotka-Volterra dynamics in the generative model. In psychology, this
kind of conservative active inference may be the homologue of being in a ‘flow state’ [263].
In short, precise particles may be the kind of particles we associate with living systems. And precise particles have
low entropy paths. If so, the question now becomes: what long-term behaviour does this class of particle show? In
other words, instead of asking which behaviours lead to low entropy dynamics, we can now ask which behaviours
follow from low entropy dynamics? We will see next that precise particles appear to plan their actions and, perhaps
more interestingly, show information and goal-seeking behaviour.
4.9 Path integrals, planning and curious particles
While the handwriting example in Figure 4.6 offers a compelling simulation of self-evidencing—in the sense of an
artefact creating its own sensorium—there is something missing as a complete account of sentient behaviour. This
39Question: does the absence of random fluctuations preclude dissipative gradient flows? No, because the gradients can
increase with the precision of random fluctuations. In the limit of no random fluctuations, the steady-state density tends
towardsadeltafunction(i.e.,afixed-pointattractor)andthedissipativegradientstendtowardsinfinity.
106
isbecausewehaveonlyconsideredtheresponseofautonomousstatestosensorystatesoverlimitedperiodsoftime.
TodiscloseadeeperBayesianmechanics,weneedtoconsiderthepathsofautonomousstatesoverextendedperiods.
This takes us to the final step and back to the path-integral formulation.
In the previous section, we focused on linking dynamics to densities over (generalised) states. In brief, we saw that
internal states can be construed as parameterising (Bayesian) beliefs about external states at any point in time. In
what follows, we move from densities over states to densities over paths—to characterise the behaviour of particles
in terms of their trajectories.
Inwhatfollows,wewillbedealingwithpredictiveposteriordensitiesoverexternalandparticularpaths,given(initial)
particular states, which can be expressed in terms of the variational density parameterised by the current (initial)
internal state:40
q(η[τ],π[τ]|π )≜E [p(η[τ],π[τ]|η ,π )]=p(η[τ],π[τ]|π )
0 qµ 0 0 0 (4.36)
q (η )=p(η |π ).
µ 0 0 0
All this equation says is that, given the initial particular states, we can evaluate the joint density over external and
particular paths, because we know the density over the initial external states, which is parameterised by the initial
internal state.
We are interested in characterising autonomous responses to initial particular states. This is given by the action of
autonomous paths as a function of particular states. In other words, we seek an expression for the probability of an
autonomous path that (i) furnishes a teleological description of self-organisation and (ii) allows us to simulate the
sentienttrajectoriesofparticles,giventheirsensorystreams. Gettingfromtheactionofparticularpathstotheaction
of autonomous paths requires a marginalisation over sensory paths. This is where the precise particle assumption
comes in: it allows us to eschew this (computationally costly) marginalisation by expressing the action of particular
paths as an expected free energy.
Recall that when random fluctuations on the motion of particular states vanish, there is no uncertainty about
autonomouspaths,givenexternalandsensorypaths. Andthereisnouncertaintyaboutsensorypathsgivenexternal
and autonomous paths. If we interpret entropies as the limiting density of discrete points (see Figure 4.4), then the
uncertainty about particular, autonomous and sensory paths, given external paths, become interchangeable:
Γ ≡0
π
⇒
H[p(π[τ]|η[τ],π )]=H[p(α[τ]|η[τ],s[τ],π )]+H[p(s[τ]|η[τ],π )]
0 0 0
(cid:124) (cid:123)(cid:122) (cid:125)
=0 (4.37)
=H[p(s[τ]|η[τ],α[τ],π )]+H[p(α[τ]|η[τ],π )]
0 0
(cid:124) (cid:123)(cid:122) (cid:125)
=0
⇒
E [lnp(π[τ]|η[τ],π )]=E [lnp(s[τ]|η[τ],π )]=E [lnp(α[τ]|η[τ],π )]
q 0 q 0 q 0
We canleverage thisexchangeabilityto expresstheaction ofautonomouspaths intermsof anexpected freeenergy.
40Question: Whyisthevariationaldensityparameterisedbytheinitialinternalstateratherthantheinitialinternalmode?
Theansweristhatinpreciseparticles,theabsenceoffluctuationsonparticulardynamicsmeansthattheinternalstatesalways
coincideswiththeinternalmode.
107
From (4.36) and (4.37), we have (dropping the conditioning on initial states for clarity):
(cid:20) (cid:21) (cid:20) (cid:21)
p(η[τ],α[τ]) p(α[τ]|η[τ])p(η[τ])
0=E ln =E ln
q q(η[τ],α[τ]) q q(η[τ]|α[τ])q(α[τ])
(cid:20) (cid:21)
p(s[τ]|η[τ])p(η[τ])
=E ln −lnq(α[τ]) =E [A(α[τ])−G(α[τ])]
q q(η[τ]|α[τ]) q(α[τ])
(cid:104) (cid:105) (4.38)
=D q(α[τ])∥e−G ⇒G(α[τ])=A(α[τ])
Risk Ambiguity
(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)
G(α[τ])=E [lnq(η[τ]|α[τ])−lnp(η[τ])− lnp(s[τ]|η[τ])]
q(η[τ],s[τ]α[τ])
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Expectedcomplexity Expectedaccuracy
All we have done here is to exchange the density over autonomous paths, conditioned on external paths, with the
correspondingdensityoversensorypaths(inthesecondline)thankstothepreciseparticleassumption. Bygathering
terms into a functional of autonomous paths, we recover autonomous action as an expected free energy.
By analogy with the expression for variational free energy (4.18), the expressions for the expected free energy in
(4.38) suggest that accuracy becomes ambiguity, while complexity becomes risk. So why have we called these terms
ambiguity and risk? Ambiguity is just the expected precision or conditional uncertainty about sensory states given
externalstates. Aheuristicexampleofanimpreciselikelihoodmapping—betweenexternalandsensorypaths—would
be a dark room, where there is no precise information at hand. Indeed, according to (4.38), sensory paths into dark
rooms should be highly unlikely. However, this is not the complete story, in the sense that the risk puts certain
constraints on any manifest tendency to minimise ambiguity.
Here,riskissimplythedivergencebetweenexternalpathsgivenanautonomouspath(i.e.,policyorplan),relativeto
external states of affairs. The marginal density over external paths is often referred to in terms of prior preferences,
because they constitute the priors of the generative model characterising the particle’s behaviour [289]. In short,
the expression for expected free energy, suggests that particles will look as if they are (i) minimising the risk of
incurring external trajectories that diverge from prior preferences, while (ii) resolving ambiguity in response to
external events. In this formulation, autonomous paths play the dual role of registering the influences of external
events (via ambiguity), while also causing those events (via risk).
The autonomous path with the least expected free energy is the most likely path taken by the autonomous states.
G(α[τ])=A(α[τ])
⇒α[τ]=argminG(α[τ])
α[τ] (4.39)
⇒δ G(α[τ])=0
α
E[G(α[τ])]=E[A(α[τ])]=H[p(α[τ])]
Inshort,expectedfreeenergyscorestheautonomousactionofparticlesthatdonotadmitnoisydynamics. Expected
free energy has a specific form that inherits from the assumption that the amplitude of particular fluctuations is
small,whichisthecaseforprecisearticlesbydefinition. Althoughvariationalandexpectedfreeenergyareformally
similar,theyarefundamentallydifferentkindsoffunctionals: variationalfreeenergyisafunctionalofadensityover
states,whileexpectedfreeenergyisafunctionalofadensityoverpaths. Variationalfreeenergycanalsobereadasa
functionofparticularstates,whileexpectedfreeenergyisafunctionofanautonomouspath. Finally,variationalfree
energyisaboundonsurprisal,whileexpectedfreeenergyisnotabound—itistheactionofautonomoustrajectories.
Expectedfreeenergyplaysadefinitiveroleinactiveinference,whereitcanberegardedasafairlyuniversalobjective
function for selecting autonomous paths of least action. Figure 4.7 shows that the expected free energy contains
termsthatariseinvariousformulationsofoptimalbehaviour;rangingfromoptimalBayesiandesign[277]throughto
108
Figure4.7: Expectedfreeenergyandactiveinference. Thisfigureillustratesactiveinference,andhighlightsvariouspoints
ofcontactwithotheraccountsofsentient,purposefulorintelligentbehaviour. Theupperpanelcastsactionandperceptionas
theminimisationofexpectedandvariationalfreeenergy,respectively. Crucially,thepathintegralformulationofactiveinference
introduces posterior beliefs over autonomous paths (i.e., policies) that entail a description of planning as inference [264–266].
Whensimulatingactiveinference, posteriorbeliefsaboutexternalpaths, underplausiblepolicies, areoptimisedbyagradient
flowonthevariational(freeenergy)boundonlogevidence—asinFigure4.3. Thesebeliefsarethenusedtoevaluatetheexpected
freeenergyofallowablepolicies,fromwhichactionscanbeselected[267–269]. Crucially,expectedfreeenergycontainstermsthat
ariseinvariousformulationsofoptimalbehaviourthatpredominateincognitivescience,engineeringandeconomics. Theseterms
aredisclosedwhenoneremovescertainsourcesofuncertainty. Forexample,ifweremoveambiguity,decision-makingminimises
risk,whichcorrespondstoaligningpredictionswithpreferencesabouttheexternalcourseofevents. Thisunderwritesprospect
theoryofhumanchoicebehaviourineconomics[270]andmodernapproachestocontrolasinference[271–273],variouslyknownas
Kalmanduality[176,241],KLcontrol[274]andmaximumentropyreinforcementlearning[275]. Ifwefurtherremovepreferences,
decision-makingmaximisestheentropyofexternaltrajectories. Thismaximumentropyprinciple[206,207]canbeinterpreted
asleastcommittingtoapresupposedexternaltrajectoryandthereforekeepingoptionsopen[276]. Ifwereintroduceambiguity,
butignorepreferences,decision-makingmaximisesintrinsicvalueorexpectedinformationgain[229]. ThisunderwritesBayesian
experimentaldesign[277]andactivelearninginstatistics[278],intrinsicmotivationandartificialcuriosityinmachinelearning
and robotics [279–283]. This is mathematically equivalent to optimising expected Bayesian surprise and mutual information,
whichunderwritesvisualsearch[284,285]andtheorganisationofourvisualapparatus[220–222]. Lastly,ifweremoveintrinsic
value, we are left with maximising extrinsic value or expected utility, which underwrites expected utility theory [219], game
theory,optimalcontrol[286,287]andreinforcementlearning[216]. Bayesianformulationsofmaximisingexpectedutilityunder
uncertainty are also known as Bayesian decision theory [288]. The expressions for variational and expected free energy are
arrangedtoillustratetherelationshipbetweencomplexity andaccuracy,whichbecomerisk andambiguity inthepathintegral
formulation. Thissuggeststhatrisk-aversepoliciesminimiseexpectedcomplexityorcomputationalcost[280].
109
controlasinference[271,275]. Wereferthereaderto [290–294]forformalinvestigationsoftherelationshipbetween
these formulations.
Equippedwithaspecificationofthemostlikelyautonomouspath—intermsofexpectedfreeenergy—wecansimulate
fairly lifelike behaviour, given a suitable generative model. An example is provided in Figure 4.9—relying upon the
computational architecture in Figure 4.8—which illustrates the ambiguity resolving part of the expected free energy
in a simulation of visual epistemic foraging.
Thisepistemicaspectofexpectedfreeenergycanbeseenmoreclearlyifwereplacetheconditionaluncertaintyabout
sensory paths with conditional uncertainty about particular paths, noting that they are the same by (4.37). After
rearrangement,wecanexpressexpectedfreeenergyintermsofexpectedvalueandexpectedinformationgain[269,292]:
G(α[τ])=E [lnq(η[τ]|α[τ])−lnp(η[τ])−lnp(π[τ]|η[τ])]
q(η[τ],s[τ]|α[τ])
Expectedvalue Expectedinformationgain
(4.40)
(cid:122) (cid:125)(cid:124) (cid:123) (cid:122) (cid:125)(cid:124) (cid:123)
= E [A(π[τ])]−E [D[p(η[τ]|s[τ],α[τ])∥p(η[τ]|α[τ])]
q(s[τ]|α[τ] q(s[τ]|α[τ])
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Bayesoptimaldecisions Bayesoptimaldesign
This provides a complementary interpretation of expected free energy. The first term can be construed as expected
cost in the sense it is the expected action of particular paths. This marginal likelihood scores the plausibility of a
particlepursuingthiskindofpathandisusuallyinterpretedintermsofexpectedloss(i.e.,negativeexpectedreward
or utility) [216,219], and pragmatic affordance [267,296]. The second term corresponds to the expected divergence
between posterior beliefs about external paths, given autonomous paths, with and without sensory paths. In other
words, it scores the resolution of uncertainty or expected information gain afforded by sensory trajectories arising
from a commitment to an autonomous path. In this sense, it is sometimes referred to as epistemic affordance [172].
When simulating the kind of planning and active inference afforded by the path integral formulation, one usually
works with discrete state-spaces and belief updating over discrete epochs of time [267,268]. One can see this as a
coarse-graining of continuous space-time into discrete space and time bins, where trajectories of continuous states
become sequences of discrete states x[τ] = (x ,...,x ). In discrete state-spaces, the generative model is usually
1 τ
formulated as a partially observed Markov decision process [238,268,290,301], in which the paths of autonomous
states constitute policies, which determine transitions among external states. Plausible policies can then be scored
with their expected free energy and the next action is selected from the most likely policy α=(α ,...,α )41
0 τ
a=argminG(a,µ)
a
G=E [lnQ (η ,...,η |η ,a)−lnP(η ,...,η |η )−lnP(s ,...,s |η ,...,η )]
Q µ 1 τ 0 1 τ 0 1 τ 1 τ
(cid:88)
≈ E [lnQ (η |a)−lnP(η |η )]−E [lnP(s |η )]
Q µ t t 0 Q t t
t>0(cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125) (4.41)
Risk Ambiguity
µ=argminF(s,a,µ)
µ
(cid:88) (cid:88)
F = E [lnQ (η |a)−lnP(η |η ,a)−lnP(η |η ,a)]− E [lnP(s |η )].
Q µ t t+1 t t t−1 Q t t
t<τ(cid:124) (cid:123)(cid:122) (cid:125)
t≤0
(cid:124) (cid:123)(cid:122) (cid:125)
Complexity Accuracy
TheconditionalindependenciesamongstatesimplicitinpartiallyobservedMarkovdecisionprocessesentailtheabove
functionalformsforvariationalandexpectedfreeenergies[267,268]. Crucially,theposterioroverexternalstatesuses
a mean-field approximation, in which the joint distribution over current and future states factorises into marginal
distributions at each point in time [this approximation can be finessed by conditioning on previous states, leading
to a different (Bethe) variational free energy [302,303]]. Note that the discrete version of variational free energy is a
41See[238,268]foraderivationofthesefunctionalformsinpartiallyobservableMarkovdecisionprocesses.
110
Figure 4.8: Bayesian mechanics and active inference. This graphic summarises the belief updating implicit in the
minimisationofvariationalandexpectedfreeenergy. Itdescribesactiveinferencebaseduponautonomouspathsorpoliciesand
hasbeenusedinavarietyofapplicationsandsimulations;rangingfromgamesinbehaviouraleconomics[295]andreinforcement
learning [296,297] through to language understanding [298] and scene construction [299]. In this setup, actions solicit a
sensoryoutcomethatinformsapproximateposteriorbeliefsabouthiddenorexternalstatesoftheworld—viaminimisationof
variationalfreeenergyunderasetofplausiblepolicies(i.e.,perceptualinference). Theapproximateposteriorbeliefsarethen
used to evaluate expected free energy and subsequent action (i.e., active inference). A key insight from simulations is that
the form of the generative model can be quite different from the process by which external states generate sensory states. In
effect, this enables agents (i.e., particles) to author their own sensorium in a fashion that has close connections with econiche
construction[300]. Pleasesee[172,268]fortechnicaldetailsandforaheuristicdiscussionofhowthebeliefupdatingcouldbe
implementedinthebrain.
functionalofadistributionoverasequenceofstatesandcanberegardedasthediscretehomologueofthevariational
free energy of generalised states in (4.32).
The ensuing minimisation of free energy can be formulated as gradient flows following (4.17)—between the discrete
arrival of new sensory input—in a way that relates comfortably to neuronal dynamics [203,267,268]. In some
simulations, one can mix discrete and continuous state-space models by placing the former on top of the latter,
to produce deep generative models that, through active inference, can be used to simulate many known aspects of
computational anatomy and physiology in the brain [172].
Summary
In summary, we now have at hand a way of identifying the most likely autonomous trajectory from any initial
particularstatethatcanbeusedtosimulatethesentientbehaviourofpreciseparticlesthatwehaveassociatedwith
biotic systems. The expected free energy absorbs two aspects of Bayes optimal behaviour into the same (objective)
111
Figure 4.9: Epistemic foraging. This figure shows the results of a numerical simulation where a face was presented to an
agent,whoseresponseswereobtainedbyselectingactivestatesthatminimisedexpectedfreeenergyfollowinganeyemovement.
Theagenthadthreeinternalimagesorhypotheses(i.e.,internalstates)abouttheexternalstateshemightsample(anupright
face (blue), an inverted face (magenta) and a rotated face (green)—shown at the bottom). The agent was presented with
sensorysamplesofanuprightfaceandhervariationalposteriorovertheexternalstatewasobtainedbydescendingvariational
free energy over a 12ms time bin until the next saccade (i.e., action) was emitted. This perception-action cycle was repeated
eighttimes. Theagent’seyemovementsareshownasreddotsattheendofeachsaccadeintheupperrow. Thecorresponding
sequenceofeyemovementsisshownintheupper-leftinset, wheretheredcirclescorrespondroughlytotheproportionofthe
visual image sampled. These saccades are driven by the salience maps in the second row, which correspond to the expected
freeenergyasafunctionofthepolicies;namely,thenextsaccadeorwheretolooknext. Asexpectedfreeenergiesaredefined
in terms of trajectories, it is best to see the locations of on these salience maps as expressing the expected free energy of a
trajectory that ends in that location. Note that these maps change with successive saccades as variational posterior beliefs
becomeprogressivelymoreconfidentabouttheexternalstate. Notealsothatsalienceisdepletedinlocationsthatwerefoveated
intheprevioussaccadebecausetheselocationsnolongerhaveepistemicaffordanceorexpectedinformationgain(i.e.,theability
toreduceuncertaintyintheexpectedfreeenergy). Inneuroscience,thisempiricalphenomenonisknownasinhibitionofreturn.
Oculomotorresponsesareshowninthethirdrowintermsofthetwooculomotorstatescorrespondingtoverticalandhorizontal
eyemovements. Theassociatedportionsoftheimagesampled(attheendofeachsaccade)areshowninthefourthrow. The
fifthrowshowstheevolutionofvariationalposteriorbeliefsaboutexternal(a.k.a. hidden)intermsofthelogprobabilitythey
assigntoeachpossibleexternalstate(colourcoded)and90%confidenceintervals. Thekeythingtonoteisthatthecredence
aboutthetrueexternalstatesupervenesoveralternativeexpectationsand,asaresult,confidenceaboutthecategoryincreases
(andconfidenceintervalsshrinktothemode). Thisillustratesthenatureofevidenceaccumulationwhenselectingahypothesis
orperceptthatbestexplainssensorystates. Pleasesee[304]forfurtherdetails.
112
functional[292]. OnaBayesianreading,theexpectedinformationgainisexactlythesamequantitythatunderwrites
the principles of optimal Bayesian design [229,277,305]. In other words, the principles that prescribe the best
way to solicit evidence that reduces uncertainty about various hypotheses. The second imperative comes from
Bayesiandecisiontheory,wheretheobjectiveistominimisesomeexpectedcostfunctionexpectedunderachoiceor
decision [288,306,307].
Teleologically, it is worth reflecting upon the differences between the generative models that underwrite state-wise
andpath-wisedescriptionsofBayesianmechanics,respectively. Forthestate-wiseformulation(4.23),thegenerative
model is just a joint density over external and particular states, supplied by—or supplying—the NESS density. For
the path-wise formulation (4.34), (4.41), the generative model is a joint distribution over the paths of external and
sensorystates. Inotherwords,thereisanimplicitstate-spacemodelofdynamicsthatcanbesummarisedheuristically
as modelling the consequences of an action on external and sensory dynamics. Because consequences follow causes,
the generative model acquires a temporal depth [298,308]. This depth required to describe any given particle may,
ofcourse,beanothercharacteristicthatdistinguishesdifferentkindsofparticles. Inshort,thepath-wiseformulation
describes particles that plan, under a proximal or distal horizon.
4.10 Conclusion
There are many points of contact between the variational formulation above and other normative theories of self-
organisationandpurposefulbehaviour. However,tofocusthenarrativewehavedeliberatelysuppresseddemonstrat-
ingprecedents,variantsandspecialcases. Figure4.3highlightsafewrelationshipsbetweenthefreeenergyprinciple
and various formulations of self-organisation and sentient behaviour. In brief, this casts things like reinforcement
learning and optimal control theory as optimising the marginal likelihood of particular states, conditioned upon a
generative model supplied by a nonequilibrium steady-state density. It could be argued that the link between the
free energy principle and established formulations is most direct for synergetics [94,309] and related treatments of
dissipativestructures[310]. ThereisalsoaformalanddirectlinktoinformationtheoreticformulationsandBayesian
statistics. Furthermore,thefreeenergyprinciplecanberegardedasdualtotheconstrainedmaximumentropyprin-
ciple[311],wheretheconstraintsaresuppliedbythegenerativemodel. Pleasesee[291,293]foratreatmentofthings
like empowerment [312], information bottleneck [313] and predictive information [101,314].
Inasimilarvein,thereareseveralaccountsofoptimalbehaviour—inbothitsepistemicandpragmaticaspects—that
arecloselyrelatedtothepathintegralformulationofactiveinference. SomekeyrelationshipsarehighlightedinFigure
4.7,suchasintrinsicmotivation,artificialcuriosity[279–281]andoptimalcontrol[240,242,274]. Theinterestingthing
about these other theories is that they are predicated on optimising some objective function that can be recovered
from expected free energy by taking various sources of uncertainty off the table. This discloses things like the
objective optimised in reinforcement learning and expected utility theory in behavioural psychology and economics,
respectively [218,315].
Thischapterhasfocusedonasingleparticleandhaslargelyignoredthe(external)contextthatleadstogeneralised
synchronyamonginternalandexternalstates. Thissynchronisationgoeshand-in-handwithexistenceperse andthe
Bayesianmechanicssuppliedbythefreeenergyprinciple. Theveryfactthatthismechanicsrestsuponsynchronisation
may speak to the emergence of synchronisation among formally similar particles; namely, populations or ensembles.
In other words, an individual member of an ensemble or ecosystem owes its existence to the ensemble of which it
is a member—at the level of multicellular organisation or indeed its conspecifics in evolutionary biology [316]. In
a similar vein, the context established by supra- and subordinate scales plays an existential role. In brief, particles
at one scale can only exist if there is a nonequilibrium steady-state density at a higher scale that entails Markov
blanketsofMarkovblankets[317]. Duetoaseparationoftemporalscales,muchoftheself-evidencingatonescaleis
113
absorbedintothefast,randomfluctuationsatthescaleabove. Forexample,thefastelectrophysiologicalfluctuations
ofaneuronbecome,randomfluctuationsfromthepointofviewofneuronalpopulationdynamicsandsensorymotor
coordination in the brain [318–320]. This follows in a straightforward way from applying the apparatus of the
renormalisation group. Please see [113] for further discussion.
Forbrevityandfocus,wehavenotconsideredapplicationsofthefreeenergyprincipleandactiveinferenceindetail. A
briefreviewoftheliteratureinthisareawillshowthatthatthemajorityofapplicationsareintheneurosciences[268]
with some exceptions: e.g., [321,322]. Recently, there has been an increasing focus on active inference in the setting
ofmachinelearningandartificialintelligence[26,144,290,293,323–325]. Muchofthisliteraturedealswithsimulation
and modelling and, specifically, scaling active inference to real-world problems. These developments speak to the
shift in focus from the foundational issues addressed in this article to their applications. It is quite possible that
thefoundationalaspectsofthefreeenergyprinciplemayalsoshiftassimplerinterpretationsandperspectivesreveal
themselves.
114
Chapter 5
Conclusion
5.1 Summary of thesis achievements
This thesis has focused on three fundamental aspects of biological entities; namely, entropy production, Bayesian
mechanics,andthefree-energyprinciple. Itsmaincontributionsarethreefold: 1)Providingacomprehensivemathe-
maticaltheoryofentropyproductionforstochasticdifferentialequationsthatdescribesagreaternumberofsystems
than before, in particular Markovian approximations of stochastic differential equations driven by colored noise. 2)
DevelopingatheoryofBayesianmechanics,withsufficientandnecessaryconditionsfortheinternalstatesofaparti-
cleorbiologicalentitytosynchronizeandinfertheexternalstatesconsistentlywithvariationalBayesianinferencein
statistics and theoretical neuroscience. 3) Refining these conditions to obtain a description that is more exclusive to
biologicalentities—asopposedtomerelyphysicalones—calledthefree-energyprinciple. Perhapsthemainpractical
outcome here are equations of motions that biological entities must satisfy in virtue of processing a boundary that
separatesthemfromtheirenvironment. Theseequationsofmotion,intermsofminimizingfreeenergyandexpected
free energy can be used for producing simulations of biotic behavior — and in artificial intelligence.
5.2 Applications
The main applications of this thesis is providing tools and formulas for computing entropy production in stochastic
models of biological systems, and affording equations — via the free-energy principle — to simulate practically any
kind of biological behavior. More broadly, the mathematical foundation to the free-energy principle presented here
unlocksacoherentnarrativefromstochasticprocessandstatisticalphysics,tocognitiveneuroscienceandbiophysics,
and to artificial intelligence. Indeed the equations provided by the free-energy principle form the basis of a generic
frameworkforgeneratingsentientbehaviorcalledactive inference,whichhasbeenusedinaplethoraofapplications
that include computational psychiatry, psychology and neurology, all the way to artificial intelligence, robotics and
machine learning, passing by simulations of biological populations and ecosystems [268,326]. The mathematical
foundationofthefree-energyprincipleenablesafirstprinciplesapproachtosimulatingbehaviorinallofthesefields,
which has been taken up by a multitude of research groups worldwide.
115
5.3 Future work
Perhaps the main strength of the free-energy principle – its genericity – is also its main weakness. By deriving a
formaldescriptionofbiologicalsystemswithasfewassumptionsaspossible,weobtainadescriptionofcognitionand
behaviorthatmayapplytovirusesandthehumanbrainalike. Aswemoveforwardwiththisresearchprogram,one
important goal is to refine the class of biological systems that we are willing to study, by singling out constraints
and properties that are fundamental to the human brain and other organisms possessing higher forms of cognition,
to derive refined forms of the principle that are more informative about these sentient beings. Another important
challengeistomapthelocalcomputationsdonebyneuronsandneuralpopulationsinthebrainwiththeoverarching
description provided by the free-energy principle, thereby bridging the detailed and coarse-grained descriptions of
braindynamics[203,327]. Afinalchallengeistoscalethemethodologiesofactiveinferencetotacklehighdimensional
complexproblemsinroboticsandartificialintelligence[324,328]. Thischallengewillnecessitatesignificantexpertise
in scalable Bayesian statistics and computer science.
116
Data availability
Chapter 2: All data and numerical simulations can be reproduced with code freely available at https:
//github.com/lancelotdacosta/entropy_production_stationary_diffusions.
Chapter 3: All data and numerical simulations can be reproduced with code freely available at https:
//github.com/conorheins/bayesian-mechanics-sdes.
Chapter 4: All data is contained within the chapter.
Author contributions
Chapter 2: I conceptualized the paper (together with G.A. Pavliotis); I wrote the initial draft; I did the
mathematical analysis and the proofs in their entirety; I wrote the accompanying software, performed the
simulations and produced the graphics; I reviewed the draft (together with G.A. Pavliotis) and edited for
journal submission; I handled journal correspondence and revised the paper for publication.
Chapter 3: I conceptualized the paper (together with co-authors); I wrote the initial draft; I did the
mathematical analysis and the proofs in their entirety; I wrote the accompanying software, performed the
simulations and produced the graphics (all with C. Heins); I reviewed the draft and edited for journal
submission (all with co-authors); I handled journal correspondence and revised the paper for publication.
Chapter 4: I wrote parts of the draft; I did parts of the mathematical analysis and proofs; I reviewed the
draft and edited for journal submission (all with co-authors); I handled journal correspondence and revised
the paper for publication.
117
Bibliography
[1] KarlFriston. The free-energy principle: A unified brain theory? Nature Reviews Neuroscience, 11(2):127–138,
February 2010. (p. 9, 64, 75, 96, and 98.)
[2] Lancelot Da Costa, Pablo Lanillos, Noor Sajid, Karl Friston, and Shujhat Khan. How Active Inference Could
Help Revolutionise Robotics. Entropy, 24(3):361, March 2022. (p. 10.)
[3] Grigorios A. Pavliotis. Stochastic Processes and Applications: Diffusion Processes, the Fokker-Planck and
Langevin Equations. Number volume 60 in Texts in Applied Mathematics. Springer, New York, 2014. (p. 10,
19, 25, 26, 27, 35, 39, 44, 52, 60, 71, 78, 85, 86, 87, and 88.)
[4] HansChristianÖttinger. Beyond Equilibrium Thermodynamics. Wiley-Interscience,Hoboken,N.J,1stedition
edition, February 2005. (p. 11, 20, 29, and 31.)
[5] Cédric Villani. Hypocoercivity, volume 202 of Memoirs of the American Mathematical Society. American
Mathematical Society, November 2009. (p. 11, 20, 28, 31, and 53.)
[6] Gülce Kardeş and David H. Wolpert. Thermodynamic Uncertainty Relations for Multipartite Processes.
arXiv:2101.01610 [cond-mat], March 2021. (p. 12 and 64.)
[7] DavidH.Wolpert. Minimalentropyproductionduetoconstraintsonratematrixdependenciesinmultipartite
processes, May 2020. (p. 12.)
[8] Karl Friston. Life as we know it. Journal of The Royal Society Interface, 10(86):20130475, September 2013.
(p. 12, 64, 80, 81, and 102.)
[9] Karl Friston, Conor Heins, Kai Ueltzhöffer, Lancelot Da Costa, and Thomas Parr. Stochastic Chaos and
Markov Blankets. Entropy, 23(9):1220, September 2021. (p. 12, 26, 64, 71, 81, 85, 90, and 97.)
[10] Conor Heins and Lancelot Da Costa. Sparse coupling and Markov blankets: A comment on "How particular
is the physics of the Free Energy Principle?" by Aguilera, Millidge, Tschantz and Buckley. arXiv:2205.10190
[cond-mat, physics:nlin], May 2022. (p. 12.)
[11] DaltonA.R.Sakthivadivel.WeakMarkovBlanketsinHigh-Dimensional,Sparsely-CoupledRandomDynamical
Systems, August 2022. (p. 12.)
[12] KarlFriston,LancelotDaCosta,NoorSajid,ConorHeins,KaiUeltzhöffer,GrigoriosA.Pavliotis,andThomas
Parr.Thefreeenergyprinciplemadesimplerbutnottoosimple.PhysicsReports,1024:1–29,June2023.(p.12.)
[13] Karl Friston, Lancelot Da Costa, Dalton A. R. Sakthivadivel, Conor Heins, Grigorios A. Pavliotis, Maxwell
Ramstead, and Thomas Parr. Path integrals, particular kinds, and strange things. Physics of Life Reviews,
August 2023. (p. 12, 13, 92, and 101.)
[14] Karl Friston, Klaas Stephan, Baojuan Li, and Jean Daunizeau. Generalised Filtering. Mathematical Problems
in Engineering, 2010:1–34, 2010. (p. 12, 78, 80, 92, 96, 100, and 101.)
[15] Da-Quan Jiang, Min Qian, and Ming-Ping Qian. Mathematical Theory of Nonequilibrium Steady States: On
the Frontier of Probability and Dynamical Systems. Lecture Notes in Mathematics. Springer-Verlag, Berlin
Heidelberg, 2004. (p. 18, 19, 21, 22, 26, 29, 33, 44, and 49.)
118
[16] Udo Seifert. Stochastic thermodynamics, fluctuation theorems and molecular machines. Reports on Progress
in Physics, 75(12):126001, November 2012. (p. 18, 85, 86, and 87.)
[17] G. Gallavotti and E. G. D. Cohen. Dynamical Ensembles in Nonequilibrium Statistical Mechanics. Physical
Review Letters, 74(14):2694–2697, April 1995. (p. 18.)
[18] Joel L. Lebowitz and Herbert Spohn. A Gallavotti-Cohen Type Symmetry in the Large Deviation Functional
for Stochastic Dynamics. Journal of Statistical Physics, 95(1/2):333–365, 1999. (p. 18.)
[19] AndreasDechant. Multidimensionalthermodynamicuncertaintyrelations. JournalofPhysicsA:Mathematical
and Theoretical, 52(3):035001, December 2018. (p. 18.)
[20] ChristopherW.Lynn,EliJ.Cornblath,LiaPapadopoulos,MaxwellA.Bertolero,andDanielleS.Bassett. Bro-
kendetailedbalanceandentropyproductioninthehumanbrain. arXiv:2005.02526[cond-mat,physics:physics,
q-bio], March 2021. (p. 18.)
[21] Robert Graham. Covariant formulation of non-equilibrium statistical thermodynamics. Zeitschrift für Physik
B Condensed Matter, 26(4):397–405, December 1977. (p. 19, 26, 52, and 88.)
[22] Gregory L. Eyink, Joel L. Lebowitz, and Herbert Spohn. Hydrodynamics and fluctuations outside of local
equilibrium: Driven diffusive systems. Journal of Statistical Physics, 83(3):385–472, May 1996. (p. 19, 26, 52,
and 88.)
[23] P. Ao. Potential in stochastic differential equations: Novel construction. Journal of Physics A: Mathematical
and General, 37(3):L25–L30, January 2004. (p. 19, 26, and 88.)
[24] Alessandro Barp, So Takao, Michael Betancourt, Alexis Arnaudon, and Mark Girolami. A Unifying and
Canonical Description of Measure-Preserving Diffusions. arXiv:2105.02845 [math, stat], May 2021. (p. 19, 26,
28, and 88.)
[25] Yi-An Ma, Tianqi Chen, and Emily B. Fox. A Complete Recipe for Stochastic Gradient MCMC.
arXiv:1506.04696 [math, stat], October 2015. (p. 19, 26, and 88.)
[26] Alessandro Barp, Lancelot Da Costa, Guilherme França, Karl Friston, Mark Girolami, Michael I. Jordan, and
Grigorios A. Pavliotis. Geometric Methods for Sampling, Optimisation, Inference and Adaptive Agents. In
Geometry and Statistics, number 46 in Handbook of Statistics, pages 21–78. Academic Press, 2022. (p. 19, 39,
44, and 114.)
[27] PratikChaudhariandStefanoSoatto. Stochasticgradientdescentperformsvariationalinference,convergesto
limitcyclesfordeepnetworks. InInternationalConferenceonLearningRepresentations,February2018. (p.19
and 44.)
[28] Edward Nelson. Dynamical Theories of Brownian Motion. Princeton University Press, 1967. (p. 19 and 26.)
[29] Martin Hairer. On Malliavin’s proof of H\"ormander’s theorem. arXiv:1103.1998 [math], March 2011. (p. 19
and 36.)
[30] A. Millet, D. Nualart, and M. Sanz. Integration by Parts and Time Reversal for Diffusion Processes. The
Annals of Probability, 17(1):208–238, January 1989. (p. 19, 20, 23, and 24.)
[31] Arnaud Guillin and Pierre Monmarché. Optimal linear drift for the speed of convergence of an hypoelliptic
diffusion. arXiv:1604.07295 [math], October 2021. (p. 19, 44, and 45.)
[32] MichelaOttobre. MarkovChainMonteCarloandIrreversibility. ReportsonMathematicalPhysics,77:267–292,
June 2016. (p. 19, 74, and 77.)
[33] Luc Rey-Bellet and Kostantinos Spiliopoulos. Irreversible Langevin samplers and variance reduction: A large
deviation approach. Nonlinearity, 28(7):2081–2103, July 2015. (p. 19, 44, 74, and 77.)
[34] Chii-Ruey Hwang, Shu-Yin Hwang-Ma, and Shuenn-Jyi Sheu. Accelerating diffusions. The Annals of Applied
Probability, 15(2):1433–1444, May 2005. (p. 19, 44, and 106.)
119
[35] MarkosKatsoulakis,YannisPantazis,andLucRey-Bellet. MeasuringtheIrreversibilityofNumericalSchemes
for Reversible Stochastic Differential Equations. ESAIM: Mathematical Modelling and Numerical Analysis -
Modélisation Mathématique et Analyse Numérique, 48(5):1351–1379, 2014. (p. 19, 22, 23, and 42.)
[36] Manh Hong Duong and Michela Ottobre. Non-reversible processes: GENERIC, Hypocoercivity and fluctua-
tions, October 2021. (p. 20, 29, 32, and 45.)
[37] AxelBrünger,CharlesL.Brooks,andMartinKarplus. Stochasticboundaryconditionsformoleculardynamics
simulations of ST2 water. Chemical Physics Letters, 105(5):495–500, March 1984. (p. 20 and 42.)
[38] Mathias Rousset, Gabriel Stoltz, and Tony Lelievre. Free Energy Computations: A Mathematical Perspective.
World Scientific, June 2010. (p. 20, 25, 39, 42, and 45.)
[39] S.R.S.Varadhan.Largedeviationsandapplications.InPersiDiaconis,DavidElworthy,HansFöllmer,Edward
Nelson, George Papanicolaou, Srinivasa R. S. Varadhan, and Paul-Louis Hennequin, editors, École d’Été de
Probabilités de Saint-Flour XV–XVII, 1985–87,LectureNotesinMathematics,pages1–49,Berlin,Heidelberg,
1988. Springer. (p. 21.)
[40] Tan Van Vu and Yoshihiko Hasegawa. Uncertainty relations for underdamped Langevin dynamics. Physical
Review E, 100(3):032130, September 2019. (p. 22 and 45.)
[41] Jean-Pierre Eckmann, Claude-Alain Pillet, and Luc Rey-Bellet. Entropy Production in Nonlinear, Thermally
Driven Hamiltonian Systems. Journal of Statistical Physics, 95(1):305–331, April 1999. (p. 22 and 45.)
[42] Richard E. Spinney and Ian J. Ford. Nonequilibrium Thermodynamics of Stochastic Systems with Odd and
Even Variables. Physical Review Letters, 108(17):170603, April 2012. (p. 22 and 45.)
[43] Dominique Bakry, Ivan Gentil, and Michel Ledoux. Analysis and Geometry of Markov Diffusion Operators.
Grundlehren Der Mathematischen Wissenschaften. Springer International Publishing, 2014. (p. 23.)
[44] U.G.HaussmannandE.Pardoux.TimeReversalofDiffusions.AnnalsofProbability,14(4):1188–1205,October
1986. (p. 23 and 24.)
[45] ClaudiaPrévôtandMichaelRockner. AConciseCourseonStochasticPartialDifferentialEquations. Springer
Berlin Heidelberg, Berlin, 2007th edition edition, October 2008. (p. 24, 34, and 54.)
[46] S.WatanabeandN.Ikeda. Stochastic Differential Equations and Diffusion Processes. NorthHolland,Amster-
dam ; New York : Tokyo : New York, NY, 0 edition edition, February 1981. (p. 24.)
[47] Jeremy Quastel. Time Reversal of Degenerate Diffusions. In Vladas Sidoravicius, editor, In and Out of Equi-
librium: Probability with a Physics Flavor, Progress in Probability, pages 249–257. Birkhäuser, Boston, MA,
2002. (p. 25.)
[48] H. Föllmer. Time reversal on Wiener space. In Sergio A. Albeverio, Philippe Blanchard, and Ludwig Streit,
editors,StochasticProcesses—MathematicsandPhysics,LectureNotesinMathematics,pages119–129,Berlin,
Heidelberg, 1986. Springer. (p. 25.)
[49] Patrick Cattiaux, Giovanni Conforti, Ivan Gentil, and Christian Léonard. Time reversal of diffusion processes
under a finite entropy condition, April 2021. (p. 25.)
[50] Ya. Belopolskaya. Time Reversal of Diffusion Processes in Hilbert Spaces and Manifolds. In N. Balakrishnan,
I.A.Ibragimov,andV.B.Nevzorov,editors,AsymptoticMethodsinProbabilityandStatisticswithApplications,
Statistics for Industry and Technology, pages 65–79. Birkhäuser, Boston, MA, 2001. (p. 25.)
[51] Annie Millet, David Nualart, and Marta Sanz. Time reversal for infinite-dimensional diffusions. Probability
Theory and Related Fields, 82(3):315–347, August 1989. (p. 25.)
[52] H.FöllmerandA.Wakolbinger. Timereversalofinfinite-dimensionaldiffusions. StochasticProcessesandtheir
Applications, 22(1):59–77, May 1986. (p. 25.)
120
[53] Masao Nagasawa and Thomas Domenig. Diffusion processes on an open time interval and their time reversal.
In Nobuyuki Ikeda, Shinzo Watanabe, Masatoshi Fukushima, and Hiroshi Kunita, editors, Itô’s Stochastic
Calculus and Probability Theory, pages 261–280. Springer Japan, Tokyo, 1996. (p. 25.)
[54] Patrick Cattiaux. Time reversal of diffusion processes with a boundary condition. Stochastic Processes and
their Applications, 28(2):275–292, June 1988. (p. 25.)
[55] E. Pardoux. Time-reversal of diffusion processes and non-linear smoothing. In Arunabha Bagchi and Huber-
tusTheodorusJongen,editors,Systems and Optimization,LectureNotesinControlandInformationSciences,
pages 171–181, Berlin, Heidelberg, 1985. Springer. (p. 25.)
[56] Yi-An Ma, Niladri S. Chatterji, Xiang Cheng, Nicolas Flammarion, Peter L. Bartlett, and Michael I. Jordan.
Is there an analog of Nesterov acceleration for gradient-based MCMC? Bernoulli, 27(3):1942–1992, May 2021.
(p. 25 and 39.)
[57] Hong Qian. A decomposition of irreversible diffusion processes without detailed balance. Journal of Mathe-
matical Physics, 54(5):053302, May 2013. (p. 26.)
[58] Lancelot Da Costa, Karl Friston, Conor Heins, and Grigorios A. Pavliotis. Bayesian mechanics for sta-
tionary processes. Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences,
477(2256):20210518, December 2021. (p. 26, 85, 90, 92, 96, and 97.)
[59] Ying-Jen Yang and Yu-Chen Cheng. Potentials of continuous Markov processes and random perturbations.
Journal of Physics A: Mathematical and Theoretical, 54(19):195001, April 2021. (p. 26.)
[60] TonyLelièvre,FrancisNier,andGrigoriosA.Pavliotis. Optimalnon-reversiblelineardriftfortheconvergence
toequilibriumofadiffusion. JournalofStatisticalPhysics,152(2):237–274,July2013. (p.26,44,77,and106.)
[61] Kösaku Yosida. Functional Analysis. Classics in Mathematics. Springer-Verlag, Berlin Heidelberg, 6 edition,
1995. (p. 29 and 49.)
[62] Pazy. Semigroups of Linear Operators and Applications to Partial Differential Equations. Springer-VerlagNew
York Inc., softcover reprint of the original 1st ed. 1983 edition, October 2011. (p. 29 and 49.)
[63] Djalil Chafaï. Entropies, convexity, and functional inequalities, On $\Phi $-entropies and $\Phi $-Sobolev
inequalities. Journal of Mathematics of Kyoto University, 44(2):325–363, January 2004. (p. 32.)
[64] G.E.UhlenbeckandL.S.Ornstein. OntheTheoryoftheBrownianMotion. Physical Review,36(5):823–841,
September 1930. (p. 36.)
[65] Claude Godrèche and Jean-Marc Luck. Characterising the nonequilibrium stationary states of Ornstein-
Uhlenbeck processes. Journal of Physics A: Mathematical and Theoretical, 52(3):035002, January 2019. (p. 36
and 37.)
[66] Alain Mazzolo and Cécile Monthus. Nonequilibrium diffusion processes via non-Hermitian electromagnetic
quantum mechanics with application to the statistics of entropy production in the Brownian gyrator. Physical
Review E, 107(1):014101, January 2023. (p. 37.)
[67] JohanduBuissonandHugoTouchette. Dynamicallargedeviationsoflineardiffusions,December2022. (p.37.)
[68] LucaLorenzi,MarcelloBertoldi,andMarcelloBertoldi. Analytical Methods for Markov Semigroups. Chapman
and Hall/CRC, July 2006. (p. 37.)
[69] LucRey-Bellet. OpenClassicalSystems. InStéphaneAttal,AlainJoye,andClaude-AlainPillet,editors,Open
Quantum Systems II: The Markovian Approach, LectureNotesinMathematics, pages41–78.Springer, Berlin,
Heidelberg, 2006. (p. 39 and 78.)
[70] Jonathan C. Mattingly, Andrew M. Stuart, and M. V. Tretyakov. Convergence of Numerical Time-Averaging
andStationaryMeasuresviaPoissonEquations. SIAMJournalonNumericalAnalysis,48(2):552–577,January
2010. (p. 42 and 70.)
121
[71] J. C. Mattingly, A. M. Stuart, and D. J. Higham. Ergodicity for SDEs and approximations: Locally Lipschitz
vector fields and degenerate noise. Stochastic Processes and their Applications, 101(2):185–232, October 2002.
(p. 42.)
[72] Denis Talay. Stochastic Hamiltonian Systems: Exponential Convergence to the Invariant Measure, and Dis-
cretization by the Implicit Euler Scheme. Markov Processes and Related Fields, (8):1–36, 2002. (p. 42.)
[73] Ben Leimkuhler and Charles Matthews. Molecular Dynamics: With Deterministic and Stochastic Numerical
Methods. Springer, Cham, 2015th edition edition, June 2015. (p. 44.)
[74] A. B. Duncan, T. Lelièvre, and G. A. Pavliotis. Variance Reduction Using Nonreversible Langevin Samplers.
Journal of Statistical Physics, 163(3):457–491, May 2016. (p. 44.)
[75] Radford M. Neal. Improving Asymptotic Variance of MCMC Estimators: Non-reversible Chains are Better.
arXiv:math/0407281, July 2004. (p. 44.)
[76] Sheng-JhihWu,Chii-RueyHwang,andMoodyT.Chu.AttainingtheOptimalGaussianDiffusionAcceleration.
Journal of Statistical Physics, 155:571–590, May 2014. (p. 44.)
[77] DavidLuposchainskyandHayeHinrichsen. EntropyProductioninContinuousPhaseSpaceSystems. Journal
of Statistical Physics, 153(5):828–841, December 2013. (p. 45.)
[78] A. B. Duncan, N. Nüsken, and G. A. Pavliotis. Using Perturbed Underdamped Langevin Dynamics to Ef-
ficiently Sample from Probability Distributions. Journal of Statistical Physics, 169(6):1098–1131, December
2017. (p. 46.)
[79] Thomas G. Kurtz. Equivalence of Stochastic Equations and Martingale Problems. In Dan Crisan, editor,
Stochastic Analysis 2010, pages 113–130. Springer, Berlin, Heidelberg, 2011. (p. 50.)
[80] Hannes Risken and Till Frank. The Fokker-Planck Equation: Methods of Solution and Applications. Springer
Series in Synergetics. Springer-Verlag, Berlin Heidelberg, 2 edition, 1996. (p. 52 and 85.)
[81] Real analysis - Every divergence-free vector field generated from skew-symmetric matrix.
https://math.stackexchange.com/questions/578898/every-divergence-free-vector-field-generated-from-skew-
symmetric-matrix. (p. 52.)
[82] Ying-JenYangandHongQian. BivectorialNonequilibriumThermodynamics: CycleAffinity,VorticityPoten-
tial, and Onsager’s Principle. Journal of Statistical Physics, 182(3):46, February 2021. (p. 52.)
[83] Giuseppe Da Prato and Jerzy Zabczyk. Stochastic Equations in Infinite Dimensions. Cambridge University
Press, April 2014. (p. 55, 58, and 59.)
[84] Johannes Ruf. A new proof for the conditions of Novikov and Kazamaki. Stochastic Processes and their
Applications, 123(2):404–421, February 2013. (p. 59.)
[85] Claude Dellacherie and Paul-Andre Meyer. Probabilities and Potential: Theory of Martingales Pt. B. Elsevier
Science Ltd, Amsterdam, December 1982. (p. 59.)
[86] Simon Prokop. Topological Support of Solutions to Stochastic Differential Equations. Master’s thesis, Charles
University in Prague, Prague, 2016. (p. 60.)
[87] John Duchi. Derivations for Linear Algebra and Optimization. (p. 61.)
[88] CasperHesp,MaxwellRamstead,AxelConstant,PaulBadcock,MichaelKirchhoff,andKarlFriston. AMulti-
scaleViewoftheEmergentComplexityofLife: AFree-EnergyProposal.InGeorgiYordanovGeorgiev,JohnM.
Smart, Claudio L. Flores Martinez, and Michael E. Price, editors, Evolution, Development and Complexity,
Springer Proceedings in Complexity, pages 195–227, Cham, 2019. Springer International Publishing. (p. 63,
64, and 80.)
[89] Michael Kirchhoff, Thomas Parr, Ensor Palacios, Karl Friston, and Julian Kiverstein. The Markov blankets
of life: Autonomy, active inference and the free energy principle. Journal of The Royal Society Interface,
15(138):20170792, January 2018. (p. 63 and 64.)
122
[90] Judea Pearl. Graphical Models for Probabilistic and Causal Reasoning. In Philippe Smets, editor, Quantified
Representation of Uncertainty and Imprecision, Handbook of Defeasible Reasoning and Uncertainty Manage-
ment Systems, pages 367–389. Springer Netherlands, Dordrecht, 1998. (p. 63, 65, 79, and 87.)
[91] Christopher M. Bishop. Pattern Recognition and Machine Learning. Information Science and Statistics.
Springer, New York, 2006. (p. 63, 65, 93, and 94.)
[92] G.NicolisandI.Prigogine. Self-OrganizationinNonequilibriumSystems: FromDissipativeStructurestoOrder
Through Fluctuations. Wiley-Blackwell, New York, June 1977. (p. 64, 88, and 98.)
[93] Albert Goldbeter. Dissipative structures in biological systems: Bistability, oscillations, spatial patterns and
waves. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences,
376(2124):20170376, July 2018. (p. 64.)
[94] Hermann Haken. Synergetics: An Introduction Nonequilibrium Phase Transitions and Self-Organization in
Physics, Chemistry and Biology. Springer Series in Synergetics. Springer-Verlag, Berlin Heidelberg, 2 edition,
1978. (p. 64, 85, 88, 98, and 113.)
[95] Nikolay Perunov, Robert A. Marsland, and Jeremy L. England. Statistical Physics of Adaptation. Physical
Review X, 6(2):021036, June 2016. (p. 64.)
[96] Kate Jeffery, Robert Pollack, and Carlo Rovelli. On the statistical mechanics of life: Schr\"odinger revisited.
arXiv:1908.08374 [physics], August 2019. (p. 64.)
[97] Jeremy L. England. Statistical physics of self-replication. The Journal of Chemical Physics, 139(12):121923,
August 2013. (p. 64.)
[98] Dominic J. Skinner and Jörn Dunkel. Improved bounds on entropy production in living systems. Proceedings
of the National Academy of Sciences, 118(18), May 2021. (p. 64.)
[99] BenjaminDunnandYasserRoudi. LearningandinferenceinanonequilibriumIsingmodelwithhiddennodes.
Physical Review E, 87(2):022127, February 2013. (p. 64.)
[100] SusanneStill. ThermodynamicCostandBenefitofMemory. Physical Review Letters,124(5):050601,February
2020. (p. 64.)
[101] SusanneStill,DavidA.Sivak,AnthonyJ.Bell,andGavinE.Crooks. ThermodynamicsofPrediction. Physical
Review Letters, 109(12):120604, September 2012. (p. 64 and 113.)
[102] Kai Ueltzhöffer. On the thermodynamics of prediction under dissipative adaptation. arXiv:2009.04006 [cond-
mat, q-bio], September 2020. (p. 64.)
[103] David H. Wolpert. Minimal entropy production rate of interacting systems. New Journal of Physics,
22(11):113013, November 2020. (p. 64.)
[104] David H. Wolpert. Uncertainty Relations and Fluctuation Theorems for Bayes Nets. Physical Review Letters,
125(20):200602, November 2020. (p. 64.)
[105] GavinE.CrooksandSusanneStill.Marginalandconditionalsecondlawsofthermodynamics.EPL(Europhysics
Letters), 125(4):40005, March 2019. (p. 64.)
[106] JordanM.HorowitzandMassimilianoEsposito. ThermodynamicswithContinuousInformationFlow. Physical
Review X, 4(3):031015, July 2014. (p. 64.)
[107] Alexandre Pouget, Peter Dayan, and Richard S. Zemel. Inference and computation with population codes.
Annual Review of Neuroscience, 26(1):381–410, March 2003. (p. 64.)
[108] David C. Knill and Alexandre Pouget. The Bayesian brain: The role of uncertainty in neural coding and
computation. Trends in Neurosciences, 27(12):712–719, December 2004. (p. 64.)
[109] Rajesh P. N. Rao and Dana H. Ballard. Predictive coding in the visual cortex: A functional interpretation of
some extra-classical receptive-field effects. Nature Neuroscience, 2(1):79–87, January 1999. (p. 64 and 72.)
123
[110] Karl J. Friston, Jean Daunizeau, James Kilner, and Stefan J. Kiebel. Action and behavior: A free-energy
formulation. Biological Cybernetics, 102(3):227–260, March 2010. (p. 64, 76, 81, and 96.)
[111] KarlJ.Friston,ErikD.Fagerholm,TaherehS.Zarghami,ThomasParr,InêsHipólito,LoïcMagrou,andAdeel
Razi. Parcels and particles: Markov blankets in the brain. arXiv:2007.09704 [q-bio], July 2020. (p. 64.)
[112] Thomas Parr, Lancelot Da Costa, and Karl Friston. Markov blankets, information geometry and stochastic
thermodynamics. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering
Sciences, 378(2164):20190159, February 2020. (p. 64, 75, 93, and 96.)
[113] Karl Friston. A free energy principle for a particular physics. arXiv:1906.10184 [q-bio], June 2019. (p. 64, 75,
84, 85, 96, 106, and 114.)
[114] Martin J. Wainwright and Michael I. Jordan. Graphical Models, Exponential Families, and Variational Infer-
ence. Foundations and Trends® in Machine Learning, 1(1–2):1–305, 2007. (p. 65 and 79.)
[115] MorrisLEaton. Multivariate Statistics: A Vector Space Approach. Instituteofmathematicalstatistics,Beach-
wood, Ohio, 2007. (p. 66.)
[116] ThomasParr. TheComputationalNeurologyofActiveVision. PhDthesis,UniversityCollegeLondon,London,
2019. (p. 67.)
[117] Markus Meister and Michael J. Berry. The Neural Code of the Retina. Neuron, 22(3):435–450, March 1999.
(p. 67.)
[118] M. James. The generalised inverse. The Mathematical Gazette, 62(420):109–114, June 1978. (p. 68.)
[119] MiguelAguilera,BerenMillidge,AlexanderTschantz,andChristopherL.Buckley.Howparticularisthephysics
of the free energy principle? Physics of Life Reviews, 40:24–50, March 2022. (p. 68 and 71.)
[120] L.C.G.RogersandDavidWilliams. Diffusions, Markov Processes, and Martingales: Volume 1: Foundations,
volume1ofCambridgeMathematicalLibrary. CambridgeUniversityPress,Cambridge,2edition,2000. (p.71.)
[121] Joris Bierkens, Paul Fearnhead, and Gareth Roberts. The Zig-Zag process and super-efficient sampling for
Bayesian analysis of big data. The Annals of Statistics, 47(3):1288–1320, June 2019. (p. 71.)
[122] JorisBierkensandGarethRoberts. ApiecewisedeterministicscalinglimitofliftedMetropolis–Hastingsinthe
Curie–Weiss model. The Annals of Applied Probability, 27(2):846–882, April 2017. (p. 71.)
[123] Alexandre Bouchard-Côté, Sebastian J. Vollmer, and Arnaud Doucet. The Bouncy Particle Sampler: A Non-
reversibleRejection-FreeMarkovChainMonteCarloMethod. Journal of the American Statistical Association,
113(522):855–867, April 2018. (p. 71.)
[124] Carl Edward Rasmussen. Gaussian Processes in Machine Learning. In Olivier Bousquet, Ulrike von Luxburg,
and Gunnar Rätsch, editors, Advanced Lectures on Machine Learning: ML Summer Schools 2003, Canberra,
Australia, February 2 - 14, 2003, Tübingen, Germany, August 4 - 16, 2003, Revised Lectures,LectureNotesin
Computer Science, pages 63–71. Springer, Berlin, Heidelberg, 2004. (p. 71.)
[125] Ludwig Arnold. Random Dynamical Systems. Springer Monographs in Mathematics. Springer-Verlag, Berlin
Heidelberg, 1998. (p. 71, 84, 85, and 87.)
[126] Martin Biehl, Felix A. Pollock, and Ryota Kanai. A Technical Critique of Some Parts of the Free Energy
Principle. Entropy, 23(3):293, March 2021. (p. 71.)
[127] Karl J. Friston, Lancelot Da Costa, and Thomas Parr. Some Interesting Observations on the Free Energy
Principle. Entropy, 23(8):1076, August 2021. (p. 71.)
[128] Haider Hasan Jafri, R. K. Brojen Singh, and Ramakrishna Ramaswamy. Generalized synchrony of coupled
stochasticprocesseswithmultiplicativenoise. PhysicalReviewE,94(5):052216,November2016. (p.71and96.)
[129] D.CuminandC.P.Unsworth. GeneralisingtheKuramotomodelforthestudyofneuronalsynchronisationin
the brain. Physica D: Nonlinear Phenomena, 226(2):181–196, February 2007. (p. 71.)
124
[130] Ensor Rafael Palacios, Takuya Isomura, Thomas Parr, and Karl Friston. The emergence of synchrony in
networks of mutually inferring neurons. Scientific Reports, 9(1):6412, April 2019. (p. 71.)
[131] StephenD.Bartlett,TerryRudolph,andRobertW.Spekkens. ReconstructionofGaussianquantummechanics
from Liouville mechanics with an epistemic restriction. Physical Review A, 86(1):012103, July 2012. (p. 72.)
[132] S. Kullback and R. A. Leibler. On Information and Sufficiency. The Annals of Mathematical Statistics,
22(1):79–86, March 1951. (p. 72.)
[133] Rafal Bogacz. A tutorial on the free-energy framework for modelling perception and learning. Journal of
Mathematical Psychology, 76:198–211, February 2017. (p. 72, 81, and 98.)
[134] Karl Friston and Stefan Kiebel. Predictive coding under the free-energy principle. Philosophical Transactions
of the Royal Society B: Biological Sciences, 364(1521):1211–1221, May 2009. (p. 72 and 81.)
[135] Zenas C. Chao, Kana Takaura, Liping Wang, Naotaka Fujii, and Stanislas Dehaene. Large-Scale Cortical
NetworksforHierarchicalPredictionandPredictionErrorinthePrimateBrain. Neuron,100(5):1252–1266.e3,
May 2018. (p. 72.)
[136] SandraIglesias,ChristophMathys,KayH.Brodersen,LarsKasper,MarcoPiccirelli,HannekeE.M.denOuden,
andKlaasE.Stephan.HierarchicalPredictionErrorsinMidbrainandBasalForebrainduringSensoryLearning.
Neuron, 80(2):519–530, October 2013. (p. 72.)
[137] Nathaniel D. Daw, Samuel J. Gershman, Ben Seymour, Peter Dayan, and Raymond J. Dolan. Model-Based
Influences on Humans’ Choices and Striatal Prediction Errors. Neuron, 69(6):1204–1215, March 2011. (p. 72.)
[138] David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational Inference: A Review for Statisticians.
Journal of the American Statistical Association, 112(518):859–877, April 2017. (p. 72 and 75.)
[139] Christopher L. Buckley, Chang Sub Kim, Simon McGregor, and Anil K. Seth. The free energy principle for
actionandperception: Amathematicalreview. JournalofMathematicalPsychology,81:55–79,December2017.
(p. 72, 76, 81, 96, and 98.)
[140] Matthew James Beal. Variational Algorithms for Approximate Bayesian Inference. PhD thesis, University of
London, 2003. (p. 75, 94, and 104.)
[141] Odelia Schwartz, Jonathan W. Pillow, Nicole C. Rust, and Eero P. Simoncelli. Spike-triggered neural charac-
terization. Journal of Vision, 6(4):484–507, July 2006. (p. 75.)
[142] R.J.Sayer,M.J.Friedlander,andS.J.Redman. ThetimecourseandamplitudeofEPSPsevokedatsynapses
between pairs of CA3/CA1 neurons in the hippocampal slice. The Journal of Neuroscience: The Official
Journal of the Society for Neuroscience, 10(3):826–836, March 1990. (p. 75.)
[143] StevenJ.Luck. An Introduction to the Event-Related Potential Technique. ABradfordBook,Cambridge,MA,
USA, 2 edition, May 2014. (p. 75.)
[144] Kai Ueltzhöffer. Deep Active Inference. Biological Cybernetics, 112(6):547–573, December 2018. (p. 76, 96,
and 114.)
[145] Beren Millidge. Deep active inference as variational policy gradients. Journal of Mathematical Psychology,
96:102348, June 2020. (p. 76.)
[146] R.ConorHeins,M.BerkMirza,ThomasParr,KarlFriston,IgorKagan,andArezooPooresmaeili. DeepActive
Inference and Scene Construction. Frontiers in Artificial Intelligence, 3:81, 2020. (p. 76.)
[147] Pablo Lanillos, Jordi Pages, and Gordon Cheng. Robot self/other distinction: Active inference meets neural
networkslearninginamirror. InEuropeanConferenceonArtificialIntelligence.IOSpress,April2020. (p.76.)
[148] Tim Verbelen, Pablo Lanillos, Christopher Buckley, and Cedric De Boom, editors. Active Inference: First
International Workshop, IWAI 2020, Co-located with ECML/PKDD 2020, Ghent, Belgium, September 14,
2020, Proceedings. Communications in Computer and Information Science. Springer International Publishing,
2020. (p. 76.)
125
[149] RickA.Adams,StewartShipp,andKarlJ.Friston. Predictionsnotcommands: Activeinferenceinthemotor
system. Brain Structure & Function, 218(3):611–643, May 2013. (p. 76 and 81.)
[150] Corrado Pezzato, Riccardo Ferrari, and Carlos Hernández Corbato. A Novel Adaptive Controller for Robot
Manipulators Based on Active Inference. IEEE Robotics and Automation Letters, 5(2):2973–2980, April 2020.
(p. 76.)
[151] Guillermo Oliver, Pablo Lanillos, and Gordon Cheng. An empirical study of active inference on a humanoid
robot. IEEE Transactions on Cognitive and Developmental Systems, pages 1–1, 2021. (p. 76.)
[152] Magnus T. Koudahl and Bert de Vries. A Worked Example of Fokker-Planck-Based Active Inference. In Tim
Verbelen, Pablo Lanillos, Christopher L. Buckley, and Cedric De Boom, editors, Active Inference, Communi-
cations in Computer and Information Science, pages 28–34, Cham, 2020. Springer International Publishing.
(p. 76 and 96.)
[153] Karl Friston. What Is Optimal about Motor Control? Neuron, 72(3):488–498, November 2011. (p. 76.)
[154] Cansu Sancaktar, Marcel van Gerven, and Pablo Lanillos. End-to-End Pixel-Based Deep Active Inference for
Body Perception and Action. arXiv:2001.05847 [cs, q-bio], May 2020. (p. 76.)
[155] Manuel Baltieri and Christopher L. Buckley. PID Control as a Process of Active Inference with Linear Gener-
ative Models. Entropy, 21(3):257, March 2019. (p. 76, 77, 79, and 80.)
[156] R. Kosinski. A Literature Review on Reaction Time Kinds of Reaction Time Experiments. 2012. (p. 78.)
[157] Tony Roskilly and Dr Rikard Mikalsen. Marine Systems Identification, Modeling and Control. Butterworth-
Heinemann, Amsterdam ; Boston, illustrated edition edition, March 2015. (p. 78.)
[158] KarlJohanÅström. PidControllers. InternationalSocietyforMeasurementandControl,January1995. (p.77
and 79.)
[159] Sanjoy Mitter, Giorgio Picci, and Anders Lindquist. Toward a theory of nonlinear stochastic realization. In
Feedback and Synthesis of Linear and Nonlinear Systems, 1981. (p. 77, 79, and 97.)
[160] AndersLindquistandGiorgioPicci.LinearStochasticSystems: AGeometricApproachtoModeling,Estimation
and Identification. Series in Contemporary Mathematics. Springer-Verlag, Berlin Heidelberg, 2015. (p. 78.)
[161] AndersLindquistandGiorgioPicci. RealizationTheoryforMultivariateStationaryGaussianProcesses. SIAM
Journal on Control and Optimization, 23(6):809–857, November 1985. (p. 78 and 97.)
[162] J.L.Doob. TheBrownianMovementandStochasticEquations. Annals of Mathematics, 43(2):351–369, 1942.
(p. 78.)
[163] MingChenWangandG.E.Uhlenbeck. OntheTheoryoftheBrownianMotionII. InSelectedPapersonNoise
and Stochastic Processes. Dover, 2014. (p. 78.)
[164] MikhailKryachkov,AndreyPolyakov,andVadimStrygin. Finite-timestabilizationofanintegratorchainusing
only signs of the state variables. In 2010 11th International Workshop on Variable Structure Systems (VSS),
pages 510–515, June 2010. (p. 78.)
[165] Konstantin Zimenko, Andrey Polyakov, Denis Efimo, and Wilfrid Perruquetti. Finite-time and fixed-time
stabilization for integrator chain of arbitrary order*. In 2018 European Control Conference (ECC), pages
1631–1635, June 2018. (p. 78.)
[166] K. J. Friston. Variational filtering. NeuroImage, 41(3):747–766, July 2008. (p. 78, 79, and 101.)
[167] K. J. Friston, N. Trujillo-Barreto, and J. Daunizeau. DEM: A variational treatment of dynamic systems.
NeuroImage, 41(3):849–885, July 2008. (p. 78, 101, and 103.)
[168] Thomas Parr, Jakub Limanowski, Vishal Rawji, and Karl Friston. The computational neurology of movement
under active inference. Brain, 144(6):1799–1818, June 2021. (p. 78 and 80.)
126
[169] S. N. Gomes, G. A. Pavliotis, and U. Vaes. Mean Field Limits for Interacting Diffusions with Colored Noise:
Phase Transitions and SpectralNumerical Methods. Multiscale Modeling & Simulation, 18(3):1343–1370, Jan-
uary 2020. (p. 78 and 79.)
[170] T. J. S. Tayor and M. Pavon. On the nonlinear stochastic realization problem. Stochastics and Stochastic
Reports, 26(2):65–79, February 1989. (p. 79.)
[171] A. E. Frazho. On stochastic realization theory. Stochastics, 7(1-2):1–27, January 1982. (p. 79.)
[172] KarlJ.Friston,ThomasParr,andBertdeVries. Thegraphicalbrain: Beliefpropagationandactiveinference.
Network Neuroscience, 1(4):381–414, December 2017. (p. 80, 110, and 111.)
[173] Michael Chevalier, Mariana Gómez-Schiavon, Andrew H. Ng, and Hana El-Samad. Design and Analysis of a
Proportional-Integral-DerivativeControllerwithBiologicalMolecules. CellSystems,9(4):338–353.e10,October
2019. (p. 80.)
[174] Tau-Mu Yi, Yun Huang, Melvin I. Simon, and John Doyle. Robust perfect adaptation in bacterial chemotaxis
through integral feedback control. Proceedings of the National Academy of Sciences, 97(9):4649–4653, April
2000. (p. 80.)
[175] KarlFriston. HierarchicalModelsintheBrain. PLoS Computational Biology,4(11):e1000211,November2008.
(p. 80 and 81.)
[176] R. E. Kalman. A New Approach to Linear Filtering and Prediction Problems. Journal of Basic Engineering,
82(1):35–45, March 1960. (p. 80 and 109.)
[177] Karl Friston, Jérémie Mattout, Nelson Trujillo-Barreto, John Ashburner, and Will Penny. Variational free
energy and the Laplace approximation. NeuroImage, 34(1):220–234, January 2007. (p. 81 and 101.)
[178] Karl Friston. A theory of cortical responses. Philosophical Transactions of the Royal Society B: Biological
Sciences, 360(1456):815–836, April 2005. (p. 81.)
[179] Giovanni Pezzulo. An Active Inference view of cognitive control. Frontiers in Psychology, 3, 2012. (p. 81.)
[180] Jean-Philippe Pellet and André Elisseeff. Using Markov Blankets for Causal Structure Learning. Journal of
Machine Learning Research, 9(43):1295–1342, 2008. (p. 81.)
[181] BelindaTzenandM.Raginsky. NeuralStochasticDifferentialEquations: DeepLatentGaussianModelsinthe
Diffusion Limit. ArXiv, 2019. (p. 81.)
[182] Roger A. Horn. Matrix Analysis: Second Edition. Cambridge University Press, New York, NY, 2nd edition
edition, December 2012. (p. 82.)
[183] Andy Clark. Whatever next? Predictive brains, situated agents, and the future of cognitive science. The
Behavioral and Brain Sciences, 36(3):181–204, June 2013. (p. 84.)
[184] Hans Crauel and Franco Flandoli. Attractors for random dynamical systems. Probability Theory and Related
Fields, 100(3):365–393, September 1994. (p. 84, 85, and 87.)
[185] Jakob Hohwy. The Self-Evidencing Brain. Noûs, 50(2):259–285, June 2016. (p. 84 and 96.)
[186] E.Noether. InvariantenbeliebigerDifferentialausdrücke. Nachrichten von der Gesellschaft der Wissenschaften
zu Göttingen, Mathematisch-Physikalische Klasse, 1918:37–44, 1918. (p. 84.)
[187] Hans Crauel. Global random attractors are uniquely determined by attracting deterministic compact sets.
Annali di Matematica Pura ed Applicata, 176(1):57–72, December 1999. (p. 85.)
[188] C.Jarzynski. NonequilibriumEqualityforFreeEnergyDifferences. PhysicalReviewLetters,78(14):2690–2693,
April 1997. (p. 85.)
[189] Jack Carr. Applications of Centre Manifold Theory. 1982. (p. 85, 93, and 94.)
127
[190] T. Koide. Perturbative expansion of irreversible work in Fokker–Planck equation$\less$i$\greater$à
la$\less$/i$\greater$quantum mechanics. Journal of Physics A: Mathematical and Theoretical, 50(32):325001,
July 2017. (p. 85.)
[191] DetlefDürrandAlexanderBach. TheOnsager-MachlupfunctionasLagrangianforthemostprobablepathof
a diffusion process. Communications in Mathematical Physics, 60(2):153–170, June 1978. (p. 86.)
[192] ErwinSchrodinger.WhatIsLife?: WithMindandMatterandAutobiographicalSketches.CambridgeUniversity
Press, Cambridge ; New York, reprint edition edition, March 2012. (p. 87.)
[193] Judea Pearl. Causality. Cambridge University Press, Cambridge, U.K. ; New York, 2nd edition edition,
September 2009. (p. 87.)
[194] Jianghong Shi, Tianqi Chen, Ruoshi Yuan, Bo Yuan, and Ping Ao. Relation of a New Interpretation of
Stochastic Differential Equations to Ito Process. Journal of Statistical Physics, 148(3):579–590, August 2012.
(p. 88.)
[195] Lancelot Da Costa and Grigorios A. Pavliotis. The entropy production of stationary diffusions, 2022. (p. 88
and 106.)
[196] Ruoshi Yuan, Yian Ma, Bo Yuan, and Ping Ao. Potential function in dynamical systems and the relation
with Lyapunov function. In Proceedings of the 30th Chinese Control Conference, pages 6573–6580, July 2011.
(p. 88.)
[197] Mark Girolami and Ben Calderhead. Riemann manifold Langevin and Hamiltonian Monte Carlo methods.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73(2):123–214, 2011. (p. 88.)
[198] Shun-ichi Amari. Natural Gradient Works Efficiently in Learning. page 36, 1998. (p. 88.)
[199] W.C. Kerr and A.J. Graham. Generalized phase space version of Langevin equations and associated Fokker-
Planckequations. TheEuropeanPhysicalJournalB-CondensedMatterandComplexSystems,15(2):305–311,
May 2000. (p. 92.)
[200] J. M. Lee. Introduction to Topological Manifolds. Springer, New York, NY, 2011. (p. 92.)
[201] NihatAy,JürgenJost,HôngVânLê,andLorenzSchwachhöfer.InformationGeometry,volume64ofErgebnisse
Der Mathematik Und Ihrer Grenzgebiete 34. Springer International Publishing, Cham, 2017. (p. 93.)
[202] S. Amari. Information Geometry and Its Applications. Springer, 2016. (p. 93.)
[203] LancelotDaCosta,ThomasParr,BiswaSengupta,andKarlFriston. NeuralDynamicsunderActiveInference:
Plausibility and Efficiency of Information Processing. Entropy, 23(4):454, April 2021. (p. 93, 111, and 116.)
[204] Shun-ichi Amari and Hiroshi Nagaoka. Methods of Information Geometry, volume 191 of Translations of
Mathematical Monographs. American Mathematical Society, April 2007. (p. 93.)
[205] Kai Ueltzhöffer, Lancelot Da Costa, and Karl J. Friston. Variational free energy, individual fitness, and pop-
ulation dynamics under acute stress: Comment on “Dynamic and thermodynamic models of adaptation” by
Alexander N. Gorban et al. Physics of Life Reviews, 37:111–115, July 2021. (p. 94.)
[206] E. T. Jaynes. Information Theory and Statistical Mechanics. Physical Review, 106(4):620–630, May 1957.
(p. 94, 103, and 109.)
[207] AndrzejLasotaandMichaelC.MacKey.Chaos,Fractals,andNoise: StochasticAspectsofDynamics.Springer-
Verlag, 1994. (p. 94 and 109.)
[208] John Winn and Christopher M Bishop. Variational Message Passing. Journal of Machine Learning Research,
page 34, 2005. (p. 94, 96, and 104.)
[209] Christoph J. G. Lang, O. Kneidl, M. Hielscher-Fastabend, and J. G. Heckmann. Voice recognition in aphasic
and non-aphasic stroke patients. Journal of Neurology, 256(8):1303–1306, August 2009. (p. 94.)
128
[210] Peter E. Kloeden and Eckhard Platen. Numerical Solution of Stochastic Differential Equations. Stochastic
Modelling and Applied Probability. Springer-Verlag, Berlin Heidelberg, 1992. (p. 94.)
[211] StevenJ.SchiffandTimSauer. Kalmanfiltercontrolofamodelofspatiotemporalcorticaldynamics. Journal
of Neural Engineering, 5(1):1–8, March 2008. (p. 96.)
[212] BrianR.Hunt,EdwardOtt,andJamesA.Yorke. Differentiablegeneralizedsynchronizationofchaos. Physical
Review E, 55(4):4029–4034, April 1997. (p. 96.)
[213] Victor Buendía, Pablo Villegas, Raffaella Burioni, and Miguel A. Muñoz. The broad edge of synchronization:
Griffiths effects and collective phenomena in brain networks. Philosophical Transactions of the Royal Society
A: Mathematical, Physical and Engineering Sciences, 380(2227):20200424, July 2022. (p. 96.)
[214] KarlJ.FristonandChristopherD.Frith. Activeinference,communicationandhermeneutics. Cortex;aJournal
Devoted to the Study of the Nervous System and Behavior, 68:129–143, July 2015. (p. 96 and 104.)
[215] Karl J. Friston, Jean Daunizeau, and Stefan J. Kiebel. Reinforcement Learning or Active Inference? PLoS
ONE, 4(7):e6421, July 2009. (p. 96.)
[216] Andrew Barto and Richard Sutton. Reinforcement Learning: An Introduction. 1992. (p. 98, 109, and 110.)
[217] Emanuel Todorov and Michael I. Jordan. Optimal feedback control as a theory of motor coordination. Nature
Neuroscience, 5(11):1226–1235, November 2002. (p. 98.)
[218] Peter Bossaerts and Carsten Murawski. From behavioural economics to neuroeconomics to decision neuro-
science: Theascentofbiologyinresearchonhumandecisionmaking. Current Opinion in Behavioral Sciences,
5:37–42, October 2015. (p. 98 and 113.)
[219] J. Von Neumann and O. Morgenstern. Theory of Games and Economic Behavior. Theory of Games and
Economic Behavior. Princeton University Press, Princeton, NJ, US, 1944. (p. 98, 109, and 110.)
[220] L.M.OpticanandB.J.Richmond. Temporalencodingoftwo-dimensionalpatternsbysingleunitsinprimate
inferiortemporalcortex.III.Informationtheoreticanalysis.JournalofNeurophysiology,57(1):162–178,January
1987. (p. 98 and 109.)
[221] R Linsker. Perceptual Neural Organization: Some Approaches Based on Network Models and Information
Theory. Annual Review of Neuroscience, 13(1):257–281, 1990. (p. 98 and 109.)
[222] H.B.Barlow. Possible Principles Underlying the Transformations of Sensory Messages. TheMITPress,1961.
(p. 98 and 109.)
[223] KarlFriston,JamesKilner,andLeeHarrison.Afreeenergyprincipleforthebrain.JournalofPhysiology-Paris,
100(1-3):70–87, July 2006. (p. 98.)
[224] Stuart A. Kauffman. The Origins of Order: Self-organization and Selection in Evolution. Oxford University
Press, 1993. (p. 98.)
[225] W.R.Ashby.PrinciplesoftheSelf-OrganizingDynamicSystem.TheJournalofGeneralPsychology,37(2):125–
128, October 1947. (p. 98.)
[226] Roger C Conant and W. R. Ashby. Every good regulator of a system must be a model of that system. Int. J.
Systems Sci., 1(2):89–97, 1970. (p. 98.)
[227] Claude Bernard. Lectures on the Phenomena of Life Common to Animals and Plants. Thomas, 1974. (p. 98.)
[228] D. J. C. MacKay. Free energy minimisation algorithm for decoding and cryptanalysis. Electronics Letters,
31(6):446–447, March 1995. (p. 98.)
[229] David J. C. MacKay. Information Theory, Inference and Learning Algorithms. Cambridge University Press,
Cambridge, UK ; New York, sixth printing 2007 edition edition, September 2003. (p. 98, 109, and 113.)
129
[230] Hermann von Helmholtz and James P. C Southall. Helmholtz’s Treatise on Physiological Optics. Dover Publi-
cations, New York, 1962. (p. 98.)
[231] R. L. Gregory. Perceptions as hypotheses. Philosophical Transactions of the Royal Society of London. Series
B, Biological Sciences, 290(1038):181–197, July 1980. (p. 98.)
[232] Peter Dayan, Geoffrey E. Hinton, Radford M. Neal, and Richard S. Zemel. The Helmholtz Machine. Neural
Computation, 7(5):889–904, September 1995. (p. 98.)
[233] R. Landauer. Irreversibility and Heat Generation in the Computing Process. IBM Journal of Research and
Development, 5(3):183–191, July 1961. (p. 98.)
[234] EugeneWongandMosheZakai. Ontherelationbetweenordinaryandstochasticdifferentialequations. Inter-
national Journal of Engineering Science, 3(2):213–229, July 1965. (p. 97.)
[235] Bhashyam Balaji and Karl Friston. Bayesian state estimation using generalized coordinates. In Ivan Kadar,
editor,SPIEDefense,Security,andSensing,page80501Y,Orlando,Florida,UnitedStates,May2011. (p.97.)
[236] R. Biscay, J. C. Jimenez, J. J. Riera, and P. A. Valdes. Local Linearization method for the numerical solution
ofstochasticdifferentialequations. AnnalsoftheInstituteofStatisticalMathematics,48(4):631–644,December
1996. (p. 97.)
[237] D. R. Cox and H. D. Miller. The Theory of Stochastic Processes. Chapman and Hall/CRC, London, February
1977. (p. 97.)
[238] Thomas Parr, Giovanni Pezzulo, and Karl J. Friston. Active Inference: The Free Energy Principle in Mind,
Brain, and Behavior. MIT Press, Cambridge, MA, USA, March 2022. (p. 99 and 110.)
[239] H.-A.Loeliger. LeastSquaresandKalmanFilteringonForneyGraphs. InRichardE.BlahutandRalfKoetter,
editors, Codes, Graphs, and Systems: A Celebration of the Life and Career of G. David Forney, Jr. on the
OccasionofHisSixtiethBirthday,TheKluwerInternationalSeriesinEngineeringandComputerScience,pages
113–135. Springer US, Boston, MA, 2002. (p. 101.)
[240] H. J. Kappen. Path integrals and symmetry breaking for optimal control theory. Journal of Statistical Me-
chanics: Theory and Experiment, 2005(11):P11011–P11011, November 2005. (p. 101 and 113.)
[241] EmanuelTodorov. Generaldualitybetweenoptimalcontrolandestimation. In2008 47th IEEE Conference on
Decision and Control, pages 4286–4292, December 2008. (p. 101 and 109.)
[242] Bart van den Broek, Wim Wiegerinck, and Bert Kappen. Risk sensitive path integral control. UAI, 2010.
(p. 101 and 113.)
[243] Hazem Toutounji and Gordon Pipa. Spatiotemporal Computations of an Excitable and Plastic Brain: Neu-
ronal Plasticity Leads to Noise-Robust and Noise-Constructive Computations. PLOS Computational Biology,
10(3):e1003512, March 2014. (p. 102.)
[244] Karl Friston, Jérémie Mattout, and James Kilner. Action understanding and active inference. Biological
Cybernetics, 104(1-2):137–160, February 2011. (p. 104 and 105.)
[245] AnatolG.Feldman. Newinsightsintoaction-perceptioncoupling. Experimental Brain Research,194(1):39–58,
March 2009. (p. 104.)
[246] Warren Mansell. Control of Perception Should be Operationalized as a Fundamental Property of the Nervous
System. Topics in Cognitive Science, 3(2):257–261, 2011. (p. 104.)
[247] Vittorio Gallese and Alvin Goldman. Mirror neurons and the simulation theory of mind-reading. Trends in
Cognitive Sciences, 2(12):493–501, December 1998. (p. 105.)
[248] Giacomo Rizzolatti and Laila Craighero. The mirror-neuron system. Annual Review of Neuroscience, 27:169–
192, 2004. (p. 105.)
130
[249] James M. Kilner, Karl J. Friston, and Chris D. Frith. Predictive coding: An account of the mirror neuron
system. Cognitive Processing, 8(3):159–166, September 2007. (p. 105.)
[250] Justin Dauwels. On Variational Message Passing on Factor Graphs. In 2007 IEEE International Symposium
on Information Theory, pages 2546–2550, Nice, June 2007. IEEE. (p. 104.)
[251] RichardFeynman. StatisticalMechanics: ASetOfLectures. WestviewPress,Boulder,Colo,1steditionedition,
March 1998. (p. 104.)
[252] Daniela Andres. On the Motion of Spikes: Turbulent-Like Neuronal Activity in the Human Basal Ganglia.
Frontiers in Human Neuroscience, 12, 2018. (p. 106.)
[253] Gustavo Deco and Morten L. Kringelbach. Turbulent-like Dynamics in the Human Brain. Cell Reports,
33(10):108471, December 2020. (p. 106.)
[254] F. Lopes da Silva. Neural mechanisms underlying brain waves: From neural membranes to networks. Elec-
troencephalography and Clinical Neurophysiology, 79(2):81–93, August 1991. (p. 106.)
[255] N. Kopell, M. A. Whittington, and M. A. Kramer. Neuronal assembly dynamics in the beta1 frequency range
permits short-term memory. Proceedings of the National Academy of Sciences, 108(9):3779–3784, March 2011.
(p. 106.)
[256] LucH.ArnalandAnne-LiseGiraud.Corticaloscillationsandsensorypredictions.TrendsinCognitiveSciences,
16(7):390–398, July 2012. (p. 106.)
[257] György Buzsáki, Nikos Logothetis, and Wolf Singer. Scaling brain size, keeping timing: Evolutionary preser-
vation of brain rhythms. Neuron, 80(3):751–764, October 2013. (p. 106.)
[258] EdwardOtt,CelsoGrebogi,andJamesA.Yorke.Controllingchaos.PhysicalReviewLetters,64(11):1196–1199,
March 1990. (p. 106.)
[259] Chii-Ruey Hwang, Shu-Yin Hwang-Ma, and Shuenn-Jyi Sheu. Accelerating Gaussian Diffusions. The Annals
of Applied Probability, 3(3):897–913, August 1993. (p. 106.)
[260] N.AslimaniandR.Ellaia. Anewhybridalgorithmcombininganewchaosoptimizationapproachwithgradient
descentforhighdimensionaloptimizationproblems.ComputationalandAppliedMathematics,37(3):2460–2488,
July 2018. (p. 106.)
[261] Joachim Gross, Nienke Hoogenboom, Gregor Thut, Philippe Schyns, Stefano Panzeri, Pascal Belin, and Si-
mon Garrod. Speech rhythms and multiplexed oscillatory sensory coding in the human brain. PLoS biology,
11(12):e1001752, December 2013. (p. 106.)
[262] György Buzsáki and Andreas Draguhn. Neuronal oscillations in cortical networks. Science (New York, N.Y.),
304(5679):1926–1929, June 2004. (p. 106.)
[263] Mihaly Csikszentmihalyi. Flow: The Psychology of Optimal Experience. HarperCollins e-books, 1st edition
edition, August 2008. (p. 106.)
[264] HagaiAttias. PlanningbyProbabilisticInference. In9thInt.WorkshoponArtificialIntelligenceandStatistics,
page 8, 2003. (p. 109.)
[265] Matthew Botvinick and Marc Toussaint. Planning as inference. Trends in Cognitive Sciences, 16(10):485–488,
October 2012. (p. 109.)
[266] Raphael Kaplan and Karl J. Friston. Planning and navigation as active inference. Biological Cybernetics,
112(4):323–343, August 2018. (p. 109.)
[267] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and Giovanni Pezzulo. Active
Inference: A Process Theory. Neural Computation, 29(1):1–49, January 2017. (p. 109, 110, and 111.)
131
[268] Lancelot Da Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic, Victorita Neacsu, and Karl Friston. Active
inferenceondiscretestate-spaces: Asynthesis.JournalofMathematicalPsychology,99:102447,December2020.
(p. 109, 110, 111, 114, and 115.)
[269] Alessandro Barp, Lancelot Da Costa, Guilherme França, Karl Friston, Mark Girolami, Michael I. Jordan,
and Grigorios A. Pavliotis. Geometric Methods for Sampling, Optimisation, Inference and Adaptive Agents.
volume 46, pages 21–78. 2022. (p. 109 and 110.)
[270] Daniel Kahneman and Amos Tversky. Prospect Theory: An Analysis of Decision under Risk. Econometrica,
47(2):263–291, 1979. (p. 109.)
[271] Sergey Levine. Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review.
arXiv:1805.00909 [cs, stat], May 2018. (p. 109 and 110.)
[272] Konrad Rawlik, Marc Toussaint, and Sethu Vijayakumar. On Stochastic Optimal Control and Reinforcement
LearningbyApproximateInference. InTwenty-Third International Joint Conference on Artificial Intelligence,
June 2013. (p. 109.)
[273] MarcToussaint. Robottrajectoryoptimizationusingapproximateinference. InProceedingsofthe26thAnnual
International Conference on Machine Learning, ICML ’09, pages 1049–1056, Montreal, Quebec, Canada, June
2009. Association for Computing Machinery. (p. 109.)
[274] HilbertJ.Kappen,VicençGómez,andManfredOpper.Optimalcontrolasagraphicalmodelinferenceproblem.
Machine Learning, 87(2):159–182, May 2012. (p. 109 and 113.)
[275] B. Ziebart. Modeling Purposeful Adaptive Behavior with the Principle of Maximum Causal Entropy. PhD
thesis, Carnegie Mellon University, Pittsburgh, 2010. (p. 109 and 110.)
[276] AlexanderS.Klyubin,DanielPolani,andChrystopherL.Nehaniv. KeepYourOptionsOpen: AnInformation-
Based Driving Principle for Sensorimotor Systems. PLOS ONE, 3(12):e4018, December 2008. (p. 109.)
[277] D. V. Lindley. On a Measure of the Information Provided by an Experiment. The Annals of Mathematical
Statistics, 27(4):986–1005, 1956. (p. 108, 109, and 113.)
[278] David J. C. MacKay. Information-Based Objective Functions for Active Data Selection. Neural Computation,
4(4):590–604, July 1992. (p. 109.)
[279] Pierre-Yves Oudeyer and Frederic Kaplan. What is Intrinsic Motivation? A Typology of Computational
Approaches. Frontiers in Neurorobotics, 1:6, November 2007. (p. 109 and 113.)
[280] Jürgen Schmidhuber. Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990–2010). IEEE Trans-
actions on Autonomous Mental Development, 2(3):230–247, September 2010. (p. 109 and 113.)
[281] Andrew Barto, Marco Mirolli, and Gianluca Baldassarre. Novelty or Surprise? Frontiers in Psychology, 4,
2013. (p. 109 and 113.)
[282] YiSun,FaustinoGomez,andJuergenSchmidhuber. PlanningtoBeSurprised: OptimalBayesianExploration
in Dynamic Environments. arXiv:1103.5708 [cs, stat], March 2011. (p. 109.)
[283] Edward Deci and Richard M. Ryan. Intrinsic Motivation and Self-Determination in Human Behavior. Per-
spectives in Social Psychology. Springer US, New York, 1985. (p. 109.)
[284] Laurent Itti and Pierre Baldi. Bayesian surprise attracts human attention. Vision research, 49(10):1295–1306,
May 2009. (p. 109.)
[285] Thomas Parr, Noor Sajid, Lancelot Da Costa, M. Berk Mirza, and Karl J. Friston. Generative Models for
Active Vision. Frontiers in Neurorobotics, 15, 2021. (p. 109.)
[286] Richard E. Bellman. Dynamic Programming. Princeton University Press, Princeton, NJ, US, 1957. (p. 109.)
[287] K.JÅström. OptimalcontrolofMarkovprocesseswithincompletestateinformation. JournalofMathematical
Analysis and Applications, 10(1):174–205, February 1965. (p. 109.)
132
[288] James O. Berger. Statistical Decision Theory and Bayesian Analysis. Springer Series in Statistics. Springer-
Verlag, New York, 2 edition, 1985. (p. 109 and 113.)
[289] Thomas Parr and Karl J. Friston. Generalised free energy and active inference. Biological Cybernetics,
113(5):495–513, December 2019. (p. 108.)
[290] Lancelot Da Costa, Noor Sajid, Thomas Parr, Karl Friston, and Ryan Smith. Reward Maximization Through
Discrete Active Inference. Neural Computation, 35(5):807–852, April 2023. (p. 110 and 114.)
[291] Karl Friston, Lancelot Da Costa, Danijar Hafner, Casper Hesp, and Thomas Parr. Sophisticated Inference.
Neural Computation, 33(3):713–763, February 2021. (p. 110 and 113.)
[292] Noor Sajid, Lancelot Da Costa, Thomas Parr, and Karl Friston. Active inference, Bayesian optimal design,
and expected utility. In The Drive for Knowledge: The Science of Human Information Seeking. 2022. (p. 110
and 113.)
[293] Danijar Hafner, Pedro A. Ortega, Jimmy Ba, Thomas Parr, Karl Friston, and Nicolas Heess. Action and
PerceptionasDivergenceMinimization.arXiv:2009.01791[cs,math,stat],October2020.(p.110,113,and114.)
[294] Beren Millidge, Alexander Tschantz, Anil K. Seth, and Christopher L. Buckley. On the Relationship Between
ActiveInferenceandControlasInference. InTimVerbelen,PabloLanillos,ChristopherL.Buckley,andCedric
DeBoom,editors,ActiveInference,CommunicationsinComputerandInformationScience,pages3–11,Cham,
2020. Springer International Publishing. (p. 110.)
[295] Thomas H. B. FitzGerald, Philipp Schwartenbeck, Michael Moutoussis, Raymond J. Dolan, and Karl Friston.
Activeinference,evidenceaccumulation,andtheurntask. NeuralComputation,27(2):306–328,February2015.
(p. 111.)
[296] PhilippSchwartenbeck,ThomasH.B.FitzGerald,ChristophMathys,RayDolan,MartinKronbichler,andKarl
Friston. Evidence for surprise minimization over value maximization in choice behavior. Scientific Reports,
5:16575, November 2015. (p. 110 and 111.)
[297] Noor Sajid, Philip J. Ball, Thomas Parr, and Karl J. Friston. Active Inference: Demystified and Compared.
Neural Computation, 33(3):674–712, January 2021. (p. 111.)
[298] Karl J. Friston, Richard Rosch, Thomas Parr, Cathy Price, and Howard Bowman. Deep temporal models and
active inference. Neuroscience & Biobehavioral Reviews, 90:486–501, July 2018. (p. 111 and 113.)
[299] M.BerkMirza,RickA.Adams,ChristophD.Mathys,andKarlJ.Friston.SceneConstruction,VisualForaging,
and Active Inference. Frontiers in Computational Neuroscience, 10, June 2016. (p. 111.)
[300] Jelle Bruineberg and Erik Rietveld. Self-organization, free energy minimization, and optimal grip on a field of
affordances. Frontiers in Human Neuroscience, 8, 2014. (p. 111.)
[301] Ryan Smith, Karl J. Friston, and Christopher J. Whyte. A step-by-step tutorial on active inference and its
application to empirical data. Journal of Mathematical Psychology, 107:102632, April 2022. (p. 110.)
[302] J.S. Yedidia, W.T. Freeman, and Y. Weiss. Constructing Free-Energy Approximations and Generalized Belief
Propagation Algorithms. IEEE Transactions on Information Theory, 51(7):2282–2312, July 2005. (p. 110.)
[303] Thomas Parr, Dimitrije Markovic, Stefan J. Kiebel, and Karl J. Friston. Neuronal message passing using
Mean-field, Bethe, and Marginal approximations. Scientific Reports, 9(1):1889, December 2019. (p. 110.)
[304] KarlFriston,RickAdams,LaurentPerrinet,andMichaelBreakspear. PerceptionsasHypotheses: Saccadesas
Experiments. Frontiers in Psychology, 3, 2012. (p. 112.)
[305] StefanoBalietti,BrennanKlein,andChristophRiedl. Optimaldesignofexperimentstoidentifylatentbehav-
ioral types. Experimental Economics, 24(3):772–799, September 2021. (p. 113.)
[306] AbrahamWald. AnEssentiallyCompleteClassofAdmissibleDecisionFunctions. TheAnnalsofMathematical
Statistics, 18(4):549–555, December 1947. (p. 113.)
133
[307] Lawrence D. Brown. A Complete Class Theorem for Statistical Problems with Finite Sample Spaces. The
Annals of Statistics, 9(6):1289–1300, November 1981. (p. 113.)
[308] Izzet B. Yildiz, Katharina von Kriegstein, and Stefan J. Kiebel. From Birdsong to Human Speech Recog-
nition: Bayesian Inference on a Hierarchy of Nonlinear Dynamical Systems. PLOS Computational Biology,
9(9):e1003219, September 2013. (p. 113.)
[309] HermannHakenandJuvalPortugali.InformationandSelforganization: AUnifyingApproachandApplications.
Entropy, 18(6):197, June 2016. (p. 113.)
[310] Ilya Prigogine. Time, Structure, and Fluctuations. Science, 201(4358):777–785, September 1978. (p. 113.)
[311] Dalton A. R. Sakthivadivel. Entropy-Maximising Diffusions Satisfy a Parallel Transport Law, January 2023.
(p. 113.)
[312] A.S. Klyubin, D. Polani, and C.L. Nehaniv. Empowerment: A universal agent-centric measure of control. In
2005 IEEE Congress on Evolutionary Computation,volume1,pages128–135Vol.1,September2005. (p.113.)
[313] NaftaliTishby,FernandoC.Pereira,andW.Bialek.Theinformationbottleneckmethod.ArXiv,2000.(p.113.)
[314] SusanneStillandDoinaPrecup. Aninformation-theoreticapproachtocuriosity-drivenreinforcementlearning.
Theory in Biosciences = Theorie in Den Biowissenschaften, 131(3):139–148, September 2012. (p. 113.)
[315] Matthew M. Botvinick, Yael Niv, and Andew G. Barto. Hierarchically organized behavior and its neural
foundations: A reinforcement learning perspective. Cognition, 113(3):262–280, December 2009. (p. 113.)
[316] Santosh Manicka and Michael Levin. Modeling somatic computation with non-neural bioelectric networks.
Scientific Reports, 9(1):18612, December 2019. (p. 113.)
[317] Ensor Rafael Palacios, Adeel Razi, Thomas Parr, Michael Kirchhoff, and Karl Friston. On Markov blankets
and hierarchical self-organisation. Journal of Theoretical Biology, 486:110089, February 2020. (p. 113.)
[318] J. A. Scott Kelso. Dynamic Patterns: The Self-Organization of Brain and Behavior. Complex Adaptive
Systems. A Bradford Book, Cambridge, MA, USA, April 1995. (p. 114.)
[319] GustavoDeco,ViktorK.Jirsa,PeterA.Robinson,MichaelBreakspear,andKarlFriston. TheDynamicBrain:
From Spiking Neurons to Neural Masses and Cortical Fields. PLoS Computational Biology, 4(8):e1000092,
August 2008. (p. 114.)
[320] J. A. Scott Kelso. Unifying Large- and Small-Scale Theories of Coordination. Entropy, 23(5):537, May 2021.
(p. 114.)
[321] Karl Friston, Michael Levin, Biswa Sengupta, and Giovanni Pezzulo. Knowing one’s place: A free-energy
approachtopatternregulation. JournalofTheRoyalSocietyInterface,12(105):20141383,April2015. (p.114.)
[322] MaxwellJamesDésormeauRamstead,PaulBenjaminBadcock,andKarlJohnFriston.AnsweringSchrödinger’s
question: A free-energy formulation. Physics of Life Reviews, 24:1–16, March 2018. (p. 114.)
[323] Alexander Tschantz, Manuel Baltieri, Anil K. Seth, and Christopher L. Buckley. Scaling active inference.
arXiv:1911.10601 [cs, eess, math, stat], November 2019. (p. 114.)
[324] Zafeirios Fountas, Noor Sajid, Pedro A. M. Mediano, and Karl Friston. Deep active inference agents using
Monte-Carlo methods. arXiv:2006.04176 [cs, q-bio, stat], June 2020. (p. 114 and 116.)
[325] Ozan Çatal, Tim Verbelen, Toon Van de Maele, Bart Dhoedt, and Adam Safron. Robot navigation as hierar-
chical active inference. Neural Networks, 142:192–204, October 2021. (p. 114.)
[326] SergioRubin,ThomasParr,LancelotDaCosta,andKarlFriston. Futureclimates: Markovblanketsandactive
inferenceinthebiosphere. JournalofTheRoyalSocietyInterface,17(172):20200503,November2020. (p.115.)
[327] TakuyaIsomura, HideakiShimazaki, andKarlJ.Friston. Canonicalneuralnetworksperformactiveinference.
Communications Biology, 5(1):1–15, January 2022. (p. 116.)
134
[328] PabloLanillos,CristianMeo,CorradoPezzato,AjithAnilMeera,MohamedBaioumy,WataruOhata,Alexan-
der Tschantz, Beren Millidge, Martijn Wisse, Christopher L. Buckley, and Jun Tani. Active Inference in
Robotics and Artificial Agents: Survey and Challenges. arXiv:2112.01871 [cs], December 2021. (p. 116.)
135