Steps towards a minimal unifying model of
consciousness: An integration of models of
consciousness based on the free energy principle
Maxwell J. D. Ramstead∗1,2,A, Mahault Albarracin1,3,A, Alex Kiefer1,4,
Kenneth Williford5, Adam Safron6,7, Chris Fields8, Mark Solms9, and
Karl Friston1,2
1VERSES Research Lab, Los Angeles, CA 90016, USA
2Wellcome Centre for Human Neuroimaging, University College London,
London WC1N 3AR, UK
3Département d’informatique, Université du Québec à Montréal, 201, Avenue du
Président-Kennedy, Montréal, H2X 3Y7
4Cognition & Philosophy Lab, Monash University, Wellington Rd, Clayton VIC 3800, Australia
5Department of Philosophy and Humanities, University of Texas at Arlington, Arlington, TX, USA
6Department of Psychiatry & Behavioral Sciences, Johns Hopkins University
School of Medicine, Baltimore, MD, USA
7Institute for Advanced Consciousness Studies, Santa Monica, CA, USA
8Allen Discovery Center, Tufts University, Medford, MA, USA
9University of Cape Town, Cape Town, South Africa
AThese authors contributed equally.
6th July 2023
Abstract
This paper aims to assess whether the recently proposed “inner screen model” of
consciousness that follows from the free-energy principle (FEP) can be regarded as a
minimal unifying model (MUM) of consciousness, thereby providing a common foun-
dational model for consciousness studies, and integrating approaches to consciousness
based on the FEP. We first present the inner screen model, which follows from applying
the quantum information theoretic version of the FEP to the known sparse (nested
and hierarchical) neuroanatomy of the brain. We then review models of conscious-
ness that are premised on the FEP. Specifically, we review Bayesian versions of the
global workspace and attention schema theories, theories premised on world-models
and self-models, and models formalizing the computational structure and properties of
time-consciousness. We then discuss how extant FEP-theoretic models of consciousness
can be situated with respect to the candidate MUM.
∗maxwell.ramstead@verses.ai
1
Additional information
Acknowledgements
The authors thank Philippe Blouin, Guillaume Dumas, Jonas Mago, David Rudrauf, Gré-
goire Sergeant, Lars Sandved Smith, Anil Seth, Toby St Clere Smithe, Jeff Yoshimi, Robert
Worden, the members of the CompPhen Fridays discussion group, and the other members
of the VERSES Research Lab for valuable comments on early versions of this work, and for
useful discussions that shaped the contents of the paper. Special thanks are due to Jakob
Hohwy and Wanja Wiese.
Funding statement
The authors are grateful to VERSES for supporting the open access publication of this
paper. BK acknowledges the support of a grant from the John Templeton Foundation
(61780). KF is supported by funding for the Wellcome Centre for Human Neuroimaging (Ref:
205103/Z/16/Z) and a Canada-UK Artificial Intelligence Initiative (Ref: ES/T01279X/1).
The opinions expressed in this publication are those of the author(s) and do not necessarily
reflect the views of the John Templeton Foundation.
Funding statement
The authors declare no conflicts of interest.
2
1 Introduction
Historically and across disciplines, theoretical development has often been shaped by alter-
nating periods of theoretical integration and differentiation: periods in which subsumption
under common principles is paramount versus periods in which theories proliferate (some-
times wildly) to capture the idiosyncrasies of the target phenomena. This dichotomy has
taken on different guises in the literature: in artificial intelligence, talk of “neats” versus
“scruffies” (terms coined by Schank and Abelson; see (Lehnert, 2013)) goes back at least to
the 1980s; but already in the 1800s, Darwin spoke of the healthy dialectic between so-called
“lumpers” and “hair-splitters,” a distinction later popularized in biology by (Simpson, 1945);
an analogous distinction has also been drawn in terms of “foxes” versus “hedgehogs”, where,
in the words of Greek poet Archilochus, “a fox knows many things, but a hedgehog knows
one big thing” (Berlin, 2013).
The sciences that study the mind and brain (cognitive science, computational neuro-
science, etc.) are arguably at a tipping point in this regard. The past decades have been
unambiguously dominated by “scruffy,” “splitter”-type thinking—which arguably peaked in
the 1990s and early to mid-2000s, with the widespread popularity of approaches based on
“massive modularity” in neuroscience and biology (Carruthers, 2006; Cosmides & Tooby,
1997; Pinker, 2003). The drive towards theoretical integration now seems to be on the rise
again. A core witness to this shift is the growth in popularity of mathematical approaches
to the study of cognition and life that leverage formal principles from physics and informa-
tion theory, e.g., the free energy principle (FEP) (Friston, 2019) and integrated information
theory (IIT) (Tononi, 2012).
Consciousness studies, in particular, remains quite a “scruffy” discipline, brimming with
many models and theories. A recent review of theories of consciousness by (Seth & Bayne,
2022) identifies nearly two dozen contemporary theories, each with an accompanying litera-
ture; and this review was selective, excluding theories that do not feature neural implemen-
tations or correlates. And there over a dozen different models of consciousness in cognitive
science and neuroscience, premised directly on the notion that consciousness is, or can be
modelled as, or in some other way may essentially involve a process of Bayesian inference
(Rorot, 2021). Theories of consciousness are very heterogeneous in their aims and targets.
Some theories of consciousness aim to resolve the so-called “hard problem” (Chalmers, 1996)
of consciousness—i.e., why and how are the functions of the brain accompanied by con-
scious experience—while others offer more circumscribed efforts, aiming instead to model
the manner in which specific kinds of contents of experience are implemented or realized
by neural structures and dynamics. Theories of consciousness also take aim at different
targets: they vary widely, from focusing on the kind of basal awareness with which all con-
scious creatures are endowed, to the kind of consciousness evinced by human beings, covering
“higher-order” cognitive processes, such as interoception, selfhood, first-person perspective,
and mind-reading abilities or “theory of mind”. We will be interested, in this paper, in pro-
viding a unifying framework for theories of this latter type: theories that address the neural
implementation of human-like consciousness, and in particular, theories that take compliance
with known neuroscience as a criterion of success.
3
More recently still, a move towards “neatness” is seen in the field of consciousness studies.
In particular, it was recently proposed that, in order to make progress on the core questions
pertaining to the study of consciousness, we ought to develop “minimal unifying models”
of consciousness (Wiese, 2020). That is, rather than pursue the proliferation of multiple
theories of consciousness, we ought to aim for theoretical unification. According to (Wiese,
2020), a MUM must conform to three criteria. First, a MUM must specify only necessary
properties of (some forms of) conscious experience—which means that a MUM is minimal
in that it does not aim (at least at first) to specify stronger, sufficient conditions for all
conscious experience. Second, the model must include well defined, determinate descriptions
of conscious experience that can be made more specific in further analyses, and that can be
extended into more complex and focused models. Finally, a MUM is unifying in that it ought
to integrate existing theoretical accounts of consciousness by foregrounding their common
assumptions, which entails finding areas of overlap that correspond to necessary properties.
The project of finding a MUM is particularly important to the field of consciousness
studies, given that it is such a "scruffy" discipline presently. Accordingly, this paper aims to
assess whether the recently proposed “inner screen model” of consciousness (Ramstead et al.,
2023) that follows from the FEP can be regarded as a MUM of consciousness, according
to the criteria laid out by (Wiese, 2020). Current approaches to consciousness based on
the FEP each have a specific focus, providing a map of a specific aspect or process of
consciousness (Rorot, 2021). In this paper, our main task will be to show how current
models of consciousness premised on the FEP fit together in a nontrivial way. The proposed
MUM may show how these extant models can be situated in relation to each other, and in
doing so provide a solid foundation for consciousness studies.
We end our introductory remarks with the caveat that this paper is elephantine, in two
senses. First, it has turned out to be a rather long paper. This is in no small part due
to the scope of the literature in need of review; both on the FEP and in consciousness
studies based on the FEP. We have not attempted to comprehensively review all of these
theories in detail, and have instead opted to cluster them according to their shared core
assumptions and commitments. We are also selective, in that we do not consider models
of consciousness that are not premised on the FEP; in particular, we (almost exclusively)
consider theories that have been developed mathematically or that have been implemented
in computational studies. We chose to focus primarily on computational studies for several
reasons. Firstly, the FEP approaches are recapitulative of the most neurologically realistic
and supported approaches to consciousness. This means that they provide a comprehensive
and scientifically grounded framework for understanding consciousness, which aligns with
our goal of providing a rigorous and evidence-based review of the literature.
Secondly, computational studies offer the unique advantage of being able to demonstrate
the theories with computations. This is particularly important in the field of consciousness
studies, where theoretical models often need to be validated through empirical evidence.
Computational studies allow us to simulate these models and observe their predictions,
providing a concrete way to test and validate the theories.
Thirdly, computational studies are inherently interdisciplinary, drawing on insights from
4
neuroscience, psychology, computer science, and mathematics. This interdisciplinary na-
ture aligns with the complexity of consciousness as a phenomenon, which cannot be fully
understood from a single disciplinary perspective.
The second sense in which our paper is elephantine is in the sense of the parable of the
blind men and the elephant. That is, we have tried to identify the core structures that
explain why existing approaches to consciousness are correct to the extent that they are.
In other words, we propose a formal account that, we hope, accommodates what is most
promising in existing accounts of consciousness, and clarifieswhy they explain what they
do. Metaphorically, we have attempted to identify the elephant that undergirds distinct
perspectives on the phenomenon of consciousness.
We acknowledge that several theories of consciousness preceding the “inner screen” model,
which we will discuss below, have also done important work toward providing, in effect,
a MUM for consciousness studies based on the FEP. Examples include integrated world
modeling theory (IWMT) (Safron, 2020a, 2022b), the “winning hypothesis” account (Hohwy,
2022a; Parr, Corcoran, et al., 2019b), and the predictive global neuronal workspace model
(Whyte & Smith, 2021), which have also been concerned with minimally explaining multiple
converging lines of evidence from an FEP-theoretic point of view. Related to this, (Rorot,
2021) has recently reviewed existing theories of consciousness premised on the FEP, to see if
any qualifies as a MUM. Our analysis converges on a conclusion similar to Rorot’s, namely,
thattheoptimizationofprecisionandcomplexityplaysakeyroleinmostFEP-basedtheories
of consciousness. However, Rorot’s work stops short of proposing a MUM. We read our paper
as following up on this work with a particular proposal that attempts to show how these
various theories exhibit a deep convergence in reflecting different aspects of consciousness,
all of which are however derivable from the FEP plus independently plausible assumptions,
as discussed below.
2 The inner screen hypothesis
The FEP characterizes systems that can be decomposed into components called “particles,”
each of which serves as the “environment” of the other. Let us call such a systemU = AB,
where A and B are the components. We regardU as comprising “everything” of interest,
and hence as isolated; in this case,A and B interact only with each other, andB can be
regarded as “everything butA” or simply as “not-A” and vice versa. The FEP states, in
this case, that ifA and B are distinguishable from each other, and hence can be regarded
as having mutually conditionally-independent states, then they can both be regarded as
behaving in a way that maintains their conditional independence, given the states that
separate and couple both systems (the “Markov blanket,” which we discuss next) (Fields
et al., 2022; Fields, Glazebrook, & Levin, 2022). Since independence can only be maintained
if each component can respond adaptively to the actions of the other, the more familiar
formulation of the FEP—as the claim that each system will behave in a way that maximizes
its ability to predict what its interaction partner will do next—is recovered. As Bayesian
inference maximizes predictive power, it is in this latter formulation that the FEP supports
5
a “Bayesian mechanics” of the joint systemU (Ramstead et al., 2023).
There are two main renditions of the FEP: the classical formulation and the quantum
information theoretic formulation. If the state space ofU is described classically, then it
follows that if the dynamics ofU can be represented by a directed acyclic graph (and hence
as a Bayesian causal network), thenA can be considered to be separated fromB by a set
of “boundary” states that form a Markov blanket; this Markov blanket is simply the set of
states ofA through which all causal connections betweenA and B flow. Clearly, in this case,
B also has a Markov blanket, comprising the states ofB immediately causally adjacent to
the Markov blanket ofA. The existence of (either of) these Markov blankets renders the
“internal” (i.e., non-blanket) states ofA and B conditionally independent. As shown in (Fris-
ton, 2019), (Ramstead et al., 2023), if the systemU implements or entails a generative model
that encodes such a Markov blanket, then it will look as if the internal states of components
of U (say, A) “track” the statistics of its interaction partner (say,B). More technically, if
a system U admits a particular partition (into particles with their Markov blanket), then
the internal states of these particles will look as if they encode the parameters of a varia-
tional density over (a probabilistic “best guess” about) about the observable behavior ofB,
i.e., as implementing a probabilistic model of the actions ofB on the Markov blanket, and
vice-versa.
If the state space ofU is described using quantum theory, i.e., as a Hilbert spaceHU, then
it follows that if the dynamics (i.e., the self-interaction)HU of U is such that the joint state
is separable, i.e., not entangled (formally, using the Dirac notation,|U⟩ = |AB⟩ = |A⟩|B⟩),
thenA can be considered to be separated fromB by a decompositional boundaryB that acts
as a holographic screen (Fields et al., 2022). The states of this screen are not in the Hilbert
space HU; they can be regarded as defining an ancillary Hilbert spaceHB. Separability
requires that the interactionHAB defined atB is weak compared to the self-interactionsHA
and HB. This, in turn, requires that the dimension dim(HB) « dim(A), dim(B), a condition
that can only be satisfied ifB is finite, i.e., dim(HB) = N for some finiteN. In this case,
the interaction HAB has 2N eigenvalues, one of which can be viewed as encoded as a bit
array onB at any given time. The particular componentsA and B can then be regarded as
alternatively writing and reading bit strings toB, which functions as a Markov blanket and
guarantees the conditional independence of the states|A⟩ and |B⟩. The internal dynamics
HA and HB can, as in the classical case, be regarded as implementing generative models of
the action onB of B and A respectively, as behaving so as to maximize Bayesian predictive
power. A detailed comparison of this quantum formulation to the classical formulation is
given in (Fields et al., 2023).
While in the classical formulation of the FEP, all states and state transitions, and there-
fore all encoded information is classical, in the quantum formulation, the only classical
information is the information written as a bit array on, and then read from, the boundary
B. This has two immediate consequences:
1. Classical information is defined only relative to the component that wrote it toB
(Fields, Glazebrook, & Marcianò, 2022). There is no “objective” classical information
in the joint systemU, which can in principle be decomposed in an arbitrary number
6
of ways.
2. If the particular componentA itself has components, i.e., ifA = A1A2, and the com-
ponents A1 and A2 communicate classically, then the state|A⟩ must be separable as
|A⟩ = |A1A2⟩ = |A1⟩|A2⟩, each of A1 and A2 must have a boundary that serves as
a holographic screen, and any classical information they exchange must be encoded
on their shared boundaryB12, which serves as a holographic screen and hence as a
Markov blanket.
An internal boundary separating components ofA that communicate classically is an
“internalscreen”; thehypothesisthatanysystemthatencodesinternalmemories(i.e. internal
classical information) has such an internal screen was stated by (Fields, Glazebrook, & Levin,
2021) and developed at length in (Ramstead et al., 2023). It is now known that such inner
screens are required whenever a (quantum) system is capable of deploying measurements
or actions that cannot, whether for in-principle or practical (e.g., energetic) reasons, be
deployed simultaneously (Fields, Glazebrook, & Marcianò, 2022); see (Fields, Glazebrook, &
Marcianò, 2023) for formal details and proof. Interestingly, measurements or actions made
with such “non co-deployable” resources induce intrinsic or “quantum” context-dependence
and hence can have in-principle unpredictable side effects (Fields & Glazebrook, 2022, 2023).
For systems described using classical neuroscience, and hence the classical FEP, mea-
surements (i.e., perceptions) and actions are effectively non co-deployable whenever they
can only be executed serially. In this case, the inner screen hypothesis is the hypothesis
that all such systems have irreducible internal Markov blankets. We have previously shown
that the assumption of irreducible internal Markov blankets leads, via the classical FEP, to
a model of hierarchical processing that allows us to understand where and (functionally)
why consciousness arises in complex nervous systems; see Fig. 1 for a schematic illustra-
tion (Ramstead et al., 2023). Briefly, the model predicts that at every scale, from that of
inter-cellular signal transduction systems to that of whole-brain architecture, components
have Markov blankets that render them conditionally independent of other components at
the same scale. At intermediate organizational scales, such components have both sufficient
input from smaller-scale systems and modulatory constraints from larger-scale systems to en-
code coherent contents of consciousness. We will see in what follows that this model provides
a basis on which to integrate multiple existing, FEP-compliant theories of consciousness, i.e.,
that it provides a MUM.
3 A review of models of consciousness based on the FEP
Many approaches to consciousness have been developed that leverage the (classical) FEP
formulation, explicitly or implicitly. These approaches are premised on the common as-
sumption that consciousness essentially involves a process of inference, which the FEP can
be applied to model. In this section, we review this extant work.
This review is not intended to be exhaustive or comprehensive (and not all are widely
accepted theories: they are just exemplar approaches that may usefully be formalised and
7
Figure 1:Schematic graphic of nested hierarchies as predicted by the inner screen
model. A representation of the repeating, nested Markov blanketed structure of the brain.
Here, the same pattern of sparse coupling (and implicit conditional independencies)—i.e.,
the Markov blanket—repeats at every scale of interest; from neuronal compartments to the
neural cell body, to microcircuits, brain regions, and whole-brain networks. Graphic inspired
by Figure 1 in (Park & Friston, 2013).
integrated under a MUM). The reader is referred to (Rorot, 2021) and (Seth & Bayne, 2022)
for more comprehensive reviews of this literature—with the former focusing on theories of
consciousness in Bayesian approaches to cognitive science (and in particular, those premised
on the FEP), and the latter providing a more general review of theories of consciousness in
neuroscience.
3.1 Bayesian global workspace theories
The first cluster of theories we’ll review comprises Bayesian versions of global workspace
theory, which are all broadly premised on the idea of recasting global workspace theory
through a Bayesian (or explicitly FEP-theoretic) lens. These theories include Bayesian ver-
8
sensation
measurement
reading
System BSystem A
B
action
writing
preparation
System A1System A2
System B
f g
B
C
A = A’s environment B = B’s environment
A B
AB = environment
of joint system, AB
Boundary of the 
joint system, AB
AB
Joint systems and 
combined environments
Holographic
screen
The Inner Screen 
Hypothesis
(A) (B) (C)
Figure 2:Holographic screens and their environments.(A) The boundaryB between
any two mutually separable systems A and B is a holographic screen that encodes, as classical
data, the eigenvalues of the interaction (i.e., the Hamiltonian operator) that couples A to
B (Fields et al., 2022). A’s actions on B are B’s perceptions, etc. Triangles represent
computational processes (quantum reference frames) implemented by A and B, respectively.
(B) A two-component system (A1, A2) interacts with an environment B. The interaction is
mediated by an internal boundary between A1 and A2 that serves as a Markov blanket, and
hence as an internal classical memory structure. The maps f and g implement “perceptions”
of B by A2 and “actions” on B by A1. Graphic adapted and inspired by Fig. 3 of (Fields,
Glazebrook, & Levin, 2021). (C) Markov blankets of joint systems comprise the “faces” of the
Markov blankets of the component systems that are exposed to their common environment.
The environmentAB of the combined systemAB is smaller than either of the environments
(¯A or ¯B) of its components (A or B).
sions of global workspace theory (Hohwy, 2013, 2016, 2022b; Marchi & Hohwy, 2022; Whyte
& Smith, 2021) and Bayesian versions of the attention schema theory (Dolega & Dewhurst,
2019; Fleming, 2020). (Note that although we review IWMT along with theories that focus
and self- and world-modelling—due to its emphasis on the centrality of world modelling
for consciousness—IWMT can also be considered as a proposal for how Bayesian global
workspace and attention schemas are realized in the mammalian nervous system, and poten-
tially also for how artificial intelligence with similar computational features might be realized
or implemented (Safron, 2020a, 2021a, 2022b)).
3.1.1 Global workspace theory
The global workspace theory (GWT) was originally proposed by (Baars & Newman, 1994).
Thisbasicproposalwaslaterdevelopedintoafamilyofbiologicallygroundedmodels; namely,
global neuronal workspace theory (GNWT), by (Dehaene, Kerszberg, & Changeux, 1998);
9
and the dynamic core hypothesis (Edelman & Tononi, 2001; Tononi & Edelman, 1998). This
family is probably the oldest and most established of those reviewed—and unsurprisingly,
GWT is currently one of the most popular frameworks in the neuroscience of consciousness.
Indeed, consistency with GWT is often considered as evidence in favour of a given theory or
model of consciousness.
GWT, and models of consciousness premised on GWT, focus onattentional processes
and their relation to consciousness. They understand consciousness in terms of the availabil-
ity of, and access to, information within the brain (Newman, Baars, & Cho, 1997)—closely
related conceptually to the “fame in the brain” or “multiple drafts” view of consciousness
in philosophy (Dennett, 1991; Dennett & Akins, 2008). Theories that focus on access to
information are sometimes characterized as concerning only “access consciousness” (as op-
posed to “phenomenal consciousness” or subjective awareness), but we note that this term
has generated controversy from both proponents of higher-order thought theory (e.g., the
attention schema theory reviewed below) and structuralist theories (e.g., IIT), which would
either question the phenomenal/access distinction itself, or instead argue that experience is
always unitary, and that “conscious access” would be a more appropriate term for describing
consciousness in terms of capacities to be aware of, manipulate, and report on experiences.
In the classical GWT, consciousness is associated with the availability of information
within a “global workspace” in the brain, allowing various networks to broadcast information
to one another, thereby enabling the emergence of coherent activity and the integration of
information across modalities. Empirically, GWT posits a specific scale of brain activity
intimately related to consciousness. This is the so-called “global workspace,” that has been
modelled with a neural network architecture comprising four recurrently-connected levels
(Raffone & Pantani, 2010). According to GWT, a series of concurrent and competing pro-
cesses are aggregated in this workspace, via which local, regional brain processes are able to
self-organize into a larger-scale network. GWT thus provides a scientific explanation for the
projection of information within the brain, cast as the broadcasting of local information to
make it globally available, thus allowing it to form integrated multi-modal representations
of things in the external world (Baars & Newman, 1994).
GWT has also been used to develop neuroscientific models of consciousness, in which
the phenomena studied in cognitive neuroscience are explained by appealing to the organi-
zation of the brain into a kind of “workspace architecture”: this is known as “global neu-
ronal workspace theory” (GNWT) (Dehaene, Kerszberg, & Changeux, 1998). For instance,
(Volzhenin, Changeux, & Dumas, 2022) presented a model of how the brain processes in-
formation, such that conscious experience occurs. This model is based on three levels of
information processing: the sensorimotor level, the cognitive level, and the conscious level.
The conscious level is, on this view, the one in which information is processed and maintained
even in the absence of external sensory input, and is thought to be characterized by the in-
volvement of interneurons and by spontaneous activity in maintaining representations. The
model incorporates both Hebbian and reinforcement learning mechanisms and performs well
on a variety of cognitive tasks. The optimal parameters for the conscious level of the model
appear to be a good fit with known features of the human brain, such as the importance of
10
inhibitory neurons and the presence of alpha rhythms.
According to GNWT, consciousness arises from “ignition events” in which information
is aggregated and broadcast to a broader set of networks distributed across the brain, via
the global workspace (which may also involve the inhibition of competing processes) (Baars,
Geld, & Kozma, 2021). Proponents of GNWT identify the prefrontal and parietal regions
as the loci of such ignition events; in particular, GNWT identifies the global workspace as
a network of excitatory neurons connecting the prefrontal and parietal cortices (Mashour
et al., 2020). GNWT predicts that the late (stimulus-bound) activation of these regions
results in conscious experience when a stimulus is attended to, and its perceptual features
are selected for ignition; whereas unconscious stimuli are defined as those that fail to attain
this kind of global influence, falling below the threshold for ignition.
TheempiricalpredictionsofGNWThavebeensupportedbyvariousneuroimagingstudies
in various modalities, such as fMRI, EEG, MEG, and intracranial recordings in epilepsy
patients. These results demonstrate widespread activation of frontal and parietal regions
duringconsciousperception, whilethecorrelatesofunconsciousperceptionseemtobelimited
to occipital and temporal regions: see, e.g., (Whyte & Smith, 2021). This large-scale ignition
connects parts of the brain associated with higher-order conceptual representation to sensory
cortices, so making that information more broadly available between these systems, affording
functional synergy. Subconscious stimuli fail to reach the global workspace, but are still
processed below the ignition threshold.
3.1.2 The winning hypothesis model and Bayesian global workspace theory
Thenextfamilyofmodelscomprisesthepopular“winninghypothesis” modelofconsciousness
(see (Rorot, 2021)) and extends to Bayesian global workspace theories. According to the
winning hypothesis account, the framework provided by active inference provides us with
a mechanism for inhibition events, thereby integrating—or perhaps even superseding—the
classical GWT model, and leading to an integrated account of consciousness (Hohwy, 2013,
2022b; Marchi & Hohwy, 2022; Safron, 2020a, 2021a, 2022b). The winning hypothesis
approach leverages policy selection, as well as inference at a meta-cognitive level, to explain
the manner in which the contents of conscious experience are generated.
As discussed above, in predictive coding, the brain effectively evaluates competing hy-
potheses about the most probable cause of its current sensory states. Bayesian global
workspace theories suggest that conscious experience corresponds to this kind of inference.
More precisely, it posits that the current contents of experience are determined by the hy-
pothesis with the highest overall posterior probability, given current data and prior beliefs,
i.e., it corresponds to the brain’s best guess about “what is out there” (Marvan & Havlík,
2021; Parr, Corcoran, et al., 2019a). This approach considers attention and perception to
be two distinct but related aspects of the same process of prediction error minimization,
and argues that the flow of conscious content is driven by beliefs about transition probabil-
ities (Hohwy, Paton, & Palmer, 2016). The accuracy and expected precision of perceptual
hypotheses form the “statistical dimensions of conscious perception”: accurate hypotheses
are good in that they minimise prediction error in a parsimonious manner; while precise
11
hypotheses are the best means for ignoring noise and picking out relevant inputs (Hohwy,
2012, 2013).
In this framework, attention serves a two-fold role in bringing predictions into conscious-
ness, both adjusting precision weightings and acting as a control mechanism to bias competi-
tion among hypotheses. On this view, however, conscious perception does not entail accuracy
and precision at the cognitive level: in some cases, a precise but inaccurate hypothesis might
determine conscious perception, and vice versa (Clark, 2015; Hohwy, 2012, 2013; Hohwy &
Michael, 2017; Hohwy, Paton, & Palmer, 2016; Hohwy & Seth, 2020). Variations of this
hypothesis sometimes emphasise that it is the change in precision weighting of prediction
errors that is necessary for conscious experience, very much in line with formulations of self
modelling: see (Sandved-Smith et al., 2021) and below. Action also serves a crucial function:
what are called ignition events in GNWT are argued to reflect what happens in the switch
from evidence accumulation in perceptual inference to the generation of evidence through
action—so that conscious perception, therefore, is tied specifically to policy selection in the
active inference formulation (see (Hohwy, 2013), esp. pp. 213-219).
While the core winning hypothesis model is independent of GWT, recent extensions
of the GWT approach specifically leverage the tools of active inference, as framed by the
winning hypothesis model. Predictive global workspace theory is a Bayesian version of GWT
(Whyte, 2019; Whyte, Hohwy, & Smith, 2022; Whyte & Smith, 2021), which it implements
using predictive coding. It is based on the idea that the brain generates predictions about
the environment and that these predictions are compared to incoming sensory information.
The resulting difference is measured as a Bayesian prediction error. The most surprising
predictions, or those that deviate the most from the expected outcome, are then broadcast
to the global workspace, where they can be used to update internal models and influence
behaviour.
Predictive GWT suggests that consciousness arises in this global workspace, which in-
tegrates and processes predictions and prediction errors from multiple regions of the brain
and allows information to be broadcast throughout distributed networks. Predictive global
workspace theory proposes that consciousness is a function of the brain’s ability to reconcile
sensory information with the predictions generated by its internal models. The neuronal dy-
namics that entail ignition depend upon forms of inference endowed with sufficient temporal
depth to provide context to the incoming cues. These dynamics can then be coordinated
within the global workspace, enabling goal-oriented behaviour (which requires planning).
3.1.3 Bayesian versions of attention schema theory
Attention schema theory (Graziano, 2017)—of which Bayesian versions exist (Dolega &
Dewhurst, 2019)—proposes that consciousness arises from the brain’s ability to create a
model or schema of attention, which allows it to understand and predict its own actions and
behaviours, as well as those of others. The “frugality theory” builds on this, suggesting that
consciousness arises as a way of conserving cognitive resources.
Vanilla attention schema theory posits that consciousness is a form of subjective aware-
ness that arises from the attention that an agent pays to a given stimulus (Graziano, 2017).
12
The “attention schema,” on this view, is a simplified model that the brain uses to represent
its own attentional processes to itself, and to inform and direct those attentional processes.
According to attention schema theory, whenever we claim to be conscious of something, we
are actually deploying higher-order cognitive processes to introspect our attention schema
and report the information that it holds (cf. higher-order representational approaches to
consciousness, as discussed in the next section (R. Brown, Lau, & LeDoux, 2019)). The
attention schema must be sparse, in order to provide an efficient means of controlling more
complex processes. According to attention schema theory, the deployment of the attention
schema results in the “illusion” of phenomenal consciousness. More specifically, proponents
of attention schema theory suggest that the ethereal and seemingly immaterial (and fluid)
nature of conscious experience is illusory, and that parsimonious explanations of these kinds
of phenomena can be taken as evidence in favor of attention schema theory (Guterstam et al.,
2019; Schurger & Graziano, 2022).
Recently, a Bayesian version of attention schema theory has been proposed (Dolega & De-
whurst, 2019), which also incorporates elements of the “multiple drafts” view. This Bayesian
version of attention schema theory builds on the Bayesian global workspace theories de-
scribed above, with its proponents arguing that the mere fact that a specific hypothesis
currently has the highest posterior probability is not sufficient, in and of itself, to account
for the contents of conscious perception. Rather, it is necessary to first reduce the space
of possible causes of one’s sensations, and for attentional processes to actually probe these
hypotheses. This ties the account of “fame in the brain” back to the attention schema theory,
providing a deflationary theory of consciousness, according to which apparently essential fea-
tures of phenomenal consciousness are illusions created by reflexive access. (We note that,a
priori, the core idea of attention schema theory (viz. that conscious experience of the world
is mediated by the brain’s (sparse) representation of its own attentional processes) is largely
independent of illusionism about consciousness as it is discussed in the philosophy of mind
literature.)
3.1.4 Relation to the inner screen model
It is a tenet of GWT and GNWT that lower levels of hierarchical processing are unlikely
to be experienced consciously, because they encode belief structures that unfold too fast
to be represented in the requisite way (Mashour et al., 2020). We can thus recover a core
aspect of the GNWT formulation from formal considerations about the hierarchical or nested
neuroanatomy of inference. In the parlance of the proposed MUM, the global workspace–or
dynamic core (Safron, 2020a, 2021a, 2022b)–encompasses the irreducible (minimal) Markov
blanket that receives ascending messages from lower levels of the hierarchy (i.e., classical
information on the sensory sector of the inner screen).
Theories of consciousness premised on GWT allow us to model the ways in which con-
sciousness integrates, selects, and privileges afferents from lower hierarchical levels of the
brain (c.f., mental action mediated by the active sector of the inner screen). According to
GWT and its Bayesian implementations, thisaccess dimensionof consciousness is realised
through ignition and through the concurrent inhibition of competing processes, which in
13
terms of the FEP formulation of predictive coding would entail precision-weighting of pre-
dictions and prediction-errors. The ensuing selection of ascending messages is crucial in
addressing attention from the perspectives established above. Please see (Friston, Breaks-
pear, & Deco, 2012) for mathematical and numerical analyses of ignition phenomena as an
emergent property of Bayesian mechanics (i.e., free energy minimisation) under hierarchical
generative models, and (Clark, Friston, & Wilkinson, 2019; Safron, 2021a) for a narrative
account of qualia that foregrounds the role of attentional selection in the Bayesian brain.
The scale for the contents of consciousness follows straightforwardly from the hierarchical
or nested composition of Markov blankets, in which active states of the inner screen intervene
causally in lower processing (i.e., mental action). On this view, it becomes apparent that
an intermediate level of processing is crucial for realising mental action (i.e., instantiating
attentional sets), which is an empirically supported aspect of extant models of consciousness:
e.g., “attended intermediate representations” theory (Marchi & Hohwy, 2022; Prinz, 2012).
In these intermediate levels, the information selected by higher levels is prioritised as a
natural part of Bayesian mechanics under hierarchical generative models. Note that GNWT
often foregrounds the role of cortical hierarchies in the genesis of conscious experience: it is
important to note that the perspective from GNWT often (but not necessarily) assumes that
consciousness requires a brain that possesses neocortices or functional homologues; namely,
characteristics of advanced phenotypes. Finally, the sparsity of the attention schema can be
motivated directly in terms of the FEP as the product of finding an optimal balance between
complexity and accuracy.
3.2 Self-models and world-models
The models that we group here share in common the idea that, for a thing to be conscious,
that thing must necessarily be able to model itself and its world: in other words, to be
conscious is to be to the kind of thing that engages in situated self-modelling. This cluster
of theories comprises integrated world modeling theory (Safron, 2020a, 2020b, 2021a, 2022a,
2022b; Safron, Çatal, & Tim, 2022), self-modelling theory (Metzinger, 2007), the beast ma-
chineapproach(Seth&Tsakiris, 2018), thegenerativeentanglementmodel(Clark, 2019), the
felt uncertainty theory (Solms, 2013), and the projective consciousness model (Rudrauf et al.,
2017; Williford et al., 2018). Theories of consciousness based on higher-order representation,
such as higher-order thought (HOT) (R. Brown, Lau, & LeDoux, 2019; Rosenthal, 2005) and
higher-order perception (Lycan, 1996) theories, as well as varieties of self-representationalism
(Kriegel & Williford, 2006), articulate important conceptual foundations and motivations for
views of consciousness based on self-modelling.
3.2.1 Integrated world modeling theory
Prior to recent work on the inner screen model (Ramstead et al., 2023), integrated world
modeling theory (IWMT) (Safron, 2020a, 2020b, 2021a, 2022a, 2022b; Safron, Çatal, & Tim,
2022) was perhaps the most comprehensive attempt to identify the “elephant” beneath extant
theories of consciousness. IWMT arguably represents the first attempt to provide a MUM
14
for theories of consciousness premised on the FEP, albeit before the term was introduced
by (Wiese, 2020). As such, the proposed MUM could be seen as an attempt to generate
an IWMT-like model, albeit one with a more minimal set of theoretical posits, focusing on
core components that arenecessary for conscious experience, and further describing how
convergent support can be found from other theories.
According to IWMT, consciousness is what it feels like to be a process of integrated
world-modelling. More precisely, consciousness would correspond to the ongoing generation
of inferences or predictions about the likely sensory states of embodied agents; these infer-
ences are conditioned on causal world models, which are in turn trained from histories of
goal pursuit within an ecological niche. This theory is premised on the idea that cognitive
systems are endowed with specific world-modelling capacities. These world models are en-
dowed with spatial, temporal and causal coherence. More specifically, IWMT claims that
consciousness depends on the organization of experience according to Kantian categories of
space (or locality, so affording compositionality with respect to particular properties), time
(or proportional changes in space, so affording prediction), and cause (or regularity in these
changes sufficient to afford modelling/structure-learning). These coherence-making proper-
ties may further require—and be enhanced by—forms of agency that depend on (and allow
for) the learning and deployment of egocentric, perspectival reference frames and the evalu-
ation of counterfactual possibilities—so affording subjectivity as a “point of view” on a “lived
world”. According to IWMT, consciousness is “what it feels like” to be a process capable of
generating an integrated, coherent representation of body and world, where the process of
world-modelling synergystically integrates various sources of information that are available
to, and relevant for, a given agent. These integrative representations allow agents to generate
coherent estimations of agent-world configurations with sufficient speed that they can both
inform and be informed by action-perception cycles on the timescales of their formation.
On the IWMT account, this enables adaptive action selection—broadly construed to include
policy deployment with respect to mental acts (Safron, 2021a)—and the iterative refinement
(cf. lifelong learning) of those policies and world models.
IWMTproposesthatinformationalintegration—orcompression/prediction(Safron, 2022a)—
is facilitated by a mechanism involving the formation and vitiation of dynamical attractors
referred to as “self-organizing harmonic modes” (SOHMs). SOHMs represent a generaliza-
tion of Selen Atasoy’s “connectome harmonics” approach to modelling neuroimaging data
(Atasoy, Donnelly, & Pearson, 2016), by identifying harmonic functions—or coarse-graining
of dynamics, as standing wave descriptions—with respect to simulations of spreading activity
over the graph Laplacian of the white matter topology of the brain, with particular mental
states being characterized as various combinations of these evolving basis functions. (The
construct validity of SOHMs does not depend on the validity of any given analytic tech-
nique; SOHMs are equally compatible with approaches that utilize gross geometric (Pang
et al., 2023), rather than connectomic features of brains). Functioning as synchronization
manifolds, SOHMs are suggested to generate joint beliefs for the subnetworks over which
they form, with belief propagation—cf. marginal message passing (Parr, Markovic, et al.,
2019)—facilitated via principles of communication through coherence (Fries, 2005). That is,
15
synchronization is suggested to afford more complex patterns of coherent neural signaling,
by allowing ensembles of neurons to exchange messages within their respective integration
windows. Further, each SOHM is suggested to function as a kind of workspace (in the compu-
tational sense suggested by GWT), allowing for the integration of information across scales.
These nested harmonics modes are further suggested to provide bases for the deployment
of generative models endowed with varying degrees of temporal depth, with heterarchically
depeer (sensory-decoupled) SOHMs affording the generation of counterfactual observations
and beliefs (contingent on specific courses of action).
SOHMs are thought to be hierarchically (or heterarchically) structured in ways that
evincedegreesofdecomposability(orcompositionality), withsmaller-scaleSOHMsmodelling
more rapidly evolving events, but which can be combined into increasingly large SOHMs for
increasingly complex forms of self- and world-modelling. SOHMs thereby depend on the
capacity of coupling neural ensembles to exhibit resonance (cf. Hopfield networks and re-
stricted Boltzmann machines), which refers to the phenomenon whereby coupled systems
minimize their free energy by adjusting their dynamics to converge upon a shared synchro-
nization manifold (Friston & Frith, 2015; Kachman, Owen, & England, 2017; Palacios et al.,
2019). Abstractly speaking, SOHMs could also be understood as a form of multi-resolution
wavelet analysis for flexibly modelling (and thereby being capable of governing) multi-scale
processes, such as agents and the various environments in which they pursue valued goals.
According to IWMT, if sufficiently complex and coherent modelling can be achieved via
multi-modal integration with egocentric reference frames—thought to be partially imple-
mented by posterior-medial cortices and the head-direction information they receive—then
an agent may be able to iteratively estimate the most likely causes of their sensory states,
thereby realizing a stream of experience organized according to a point of view on a “lived
world.” On the IWMT account, these resonant modes of activity give rise to a combined self-
and-world-model, enabling adaptive modes of inference as descending predictions harmonise
with ascending expectations. More complex self models and various forms of “conscious ac-
cess” are proposed to require coupling with frontal cortices in order for these estimates to
be conditioned upon causal world models with greater temporal depth and counterfactual
richness, specifically canalized into trajectories of overt and covert actions (Safron, 2021a;
Safron, Çatal, & Tim, 2022).
IWMT can be understood as a Bayesian version of G(N)WT. However, IWMT is dis-
tinct from GNWT in that it is committed to the idea ofmultiple kinds of workspaces with
varying scopes and functions, including sub-personal, unconscious local models, realized by
SOHMs. There are two major forms of workspaces posited by IWMT (both of which center
on intermediate-level representations): one kind of workspace is hypothesised to be imple-
mented by posterior cortices, so allowing for iterative state estimation for both overt and
covert action selection; the other workspace comprises broader (e.g., frontal-lobe involving)
zones of integration, so allowing these system-world estimates to be conditioned on high-level
policies with capacities for intentional (endogenous) attentional selection and various forms
of conscious access, including with respect to “mental time travel” for imaginative planning
via prediction and postdiction (Safron, 2020b, 2021a; Safron, Çatal, & Tim, 2022).
16
IWMT provides a critical perspective on GNWT, suggesting that posterior cortices may
have sufficient capacities for integrated information for self-and world-modelling, such that
they could be considered to be both sufficient realizers of phenomenal consciousness and
fairly “global” workspaces. Further, in line with attention schema and higher-order theories
of consciousness, IWMT suggests that subjective experience (i.e., “what it feels like”) corre-
sponds to a specific kind of belief about the causes of one’s sensations, which will be heavily
influenced by various forms of conscious and unconscious access via overt and covert ac-
tions (Safron, 2020a, 2021a, 2022b). That is, while IWMT maintains a separation between
phenomenal consciousness and conscious access, it also acknowledges that these phenom-
ena interact extensively, in ways that can make them challenging to separately analyze and
conceptualize (both in practice and in principle).
Further, IWMT has likened the phase transitions involved in the ignition events of GWT
to “wave function collapse” (Safron, 2022b), when a critical mass of (relatively) densely
interacting elements form a coherently functioning dynamic core. Since neural ensembles
that are external to this core lack access to the densely and mutually interacting elements
of this more encompassing (and richly integrative) SOHM, the establishment of SOHM-
enabled workspaces via self-reinforcing and self-organizing patterns could be thought of as
compressing or coarse-graining the information within the network. In this way, the non-
linear percolating activity contributing to ignition events could be likened to the formation
of an informational “singularity,” in which elements within the scope of each SOHM may
become illegible to external observers (i.e., other SOHMs). The latter must therefore infer
the (compressed) contents of the “bulk” within other SOHMS, based on whatever information
can be transmitted across the boundaries of these sub-systems.
Like several of the theories reviewed below (in particular, the beast machine approach
and felt uncertainty theory), IWMT is closely related to embodied mind theory (Safron,
2021a; Varela, Thompson, & Rosch, 2017). Proponents of IWMT argue that the kind of
world-modelling entailed by IWMT is only possible in embodied agents—that is, agents that
are endowed with, and constrained by the physics and geometry of, a physical body. On this
account, the integration required for world modelling involvescontrol, providing the means to
orient the sensory system towards the world. Consistent with our present proposal, IWMT
claims that action-oriented representations of the body and proprioceptive generative models
may constitute “backbones” for workspace dynamics, structuring all perception according
to relevant affordances, as well as providing sources of intentional control over attentional
selection via covert actions (Safron, 2021a). In integrating embodiment, top-down attention,
and volitional, intentional control, and in working towards a theory apt to account for various
forms of conscious access and self-consciousness, IWMT aims to provide a synergistic and
inclusive (albeit possibly overly-inclusive with respect to ease-of-understanding) account of
how consciousness arises from the dynamic interplay of these processes, and purports to offer
a unifying perspective on the nature of conscious experience and self-awareness.
17
3.2.2 Self-modelling theory
The self-modelling theory (SMT), proposed by (Metzinger, 2007) and later developed un-
der active inference by (Limanowski, 2014), focuses on how the concept of self—and the
experience of selfhood—emerges from the workings of the brain. The theory identifies the
self as the centre of control that connects (interoceptive) sensations from the body with
(proprioceptive) movement in extrapersonal space. On this account, the self emerges from a
temporally extended process that integrates sensory information from multiple sources (in-
cluding exteroceptive ones) into a generative model that includes representations of the self
as the cause of those sensations. The self-model in SMT is egocentric, meaning that it is cen-
tred on the individual’s perspective and experience, and encompasses both the first-personal
(subjective) aspect of experience and third-person experiences of the self (as an object on
a par with others)—a self that is experienced (transparently) as conserved over space and
time.
According to SMT, the self is not a static object, but rather results from a dynamic
process of inference about the most probable causes of the sensory states of an agent. An
active self-model is a functional state that operates beneath the level of conscious awareness
and has a specific causal role. The operation of such a process generates an egocentric,
perspectival experience that is directed towards objects and allows for interaction with the
external world. Self-modelling theory also treats the distinction between “transparent” and
“opaque” mental states or processes (Metzinger, 2003), which was later formalised using
active inference by (Sandved-Smith et al., 2021). A key contribution of this formulation is
the conditioning of precision on latent states at successively higher levels of a deep generative
model. This induces the key notion that representations of “states of being” are in the service
of recognising distinct states of perceptual dispositions and, at the same time, necessary to
deploy attentional sets by contextualising the precision of belief updating processes lower in
the hierarchy.
The terms “transparency” and “opacity” come from the metaphor of seeing something
through a window: the transparency of the window itself enables the thing outside to be
seen, but the window is not experienced itself, except in cases where it becomes opaque.
Accordingly, the experience of the self is often transparent, meaning the agent having that
experience only has access to the contents of their experience and not to the process that
makes that experience possible (i.e., mental action). However, in some special cases, the
experience of self can become opaque, when the agent attends to its experiences directly
(and aspects of the process of experience thus enter into its content). In this sense, the self is
ultimately a particularly adaptive hypothesis about what is causing one’s sensory experience.
3.2.3 The beast machine approach
The beast machine approach (Seth & Tsakiris, 2018) suggests that inference is fundamentally
related to embodied processeses, and grounded in allostatic control realized by predictive
coding (Ainley et al., 2016; Ainley et al., 2012; Apps & Tsakiris, 2014; Barrett, Quigley, &
Hamilton, 2016; Barrett & Simmons, 2015; Fotopoulou & Tsakiris, 2017; Seth, 2015; Seth
18
& Friston, 2016; Seth, Suzuki, & Critchley, 2012). On this view, conscious experience is
constructed from an array of multimodal inputs to the body (with a special emphasis on
interoceptive and proprioceptive afferents). In line with the winning hypothesis model, the
agent’s best guess about what caused these sensory inputs is leveraged to control the body,
enabling intention and purposeful action.
In this approach—like the winning hypothesis model—the brain leverages a generative
model with a set of prior beliefs about what might be causing interoceptive sensory signals.
The beast machine approach foregrounds the contribution to conscious experience ofembod-
ied action, i.e., of moving the body intentionally. In this model, the conscious experience of
selfhood is caused by the generation of predictions about actions, and the conscious experi-
ence of ownership is related to the management of prediction errors issued from interoceptive
and exteroceptive centres of the brain (Seth, 2013). The basic idea is that different kinds of
inputs at different levels of the neural hierarchy generate prediction errors, and that conscious
processing is related to the quashing of a special kind of prediction error. More specifically,
on this view, conscious perception results from minimising proprioceptive prediction errors
during action. Based on beliefs about a specific course of action or policy, proprioceptive
signals are first predicted, and then fulfilled or frustrated—via action. Precision-weighing
also factors in this approach, by determining whether an action is performed (when precision
is lower), or whether the model is updated (if the precision is higher). This kind of precision
weighting has close connections to sensory attenuation; namely,attenuating the (precision of)
sensory consequences of self-made actions (H. Brown et al., 2013; Limanowski, 2017, 2022).
In the beast machine approach, the stability of our sense of embodied selfhood is linked to
the difference in timescales and stability between motor actions and physiological homeosta-
sis. Motor actions are variable, generated in accordance with the demands of a situation, and
may change over time; while physiological homeostasis is fundamentally about maintaining
stability, i.e., maintaining essential variables within a viable range. Interoceptive demands
encode strong priors, which enable the emergence of a stable sense of self over time. Given
this stability, the experience of being a body is transparent (in the sense discussed above with
respect to self-modelling theory): the body is not usually perceived as a mere object—unlike
the visual experience of an object, in which things are perceived as objects due to predictions
the brain makes about how object-related sensory signals would change with certain actions.
Thus, the body and the self are mostly experienced as transparent, and are only turned into
objects of experienceper sewhen attention is directed towards specific processes.
3.2.4 Generative entanglement
Generative entanglement is a theory that attempts to explain consciousness by appeal to the
brain’s construction of a generative model that mixes predictions about states of the world,
states of the body, and our reactive dispositions (Clark, 2019; Clark, Friston, & Wilkinson,
2019). This generative model is used to make predictions about sensory streams, includ-
ing information from the external environment (exteroception), internal bodily sensations
(interoception), and action-specifying (proprioceptive) sensory flows (Clark, 2019).
According to the generative entanglement model, what we experience as qualia are in-
19
ferred latent variables that capture and predict useful patterns in the sensory stream; i.e., the
experience of a quale is an hypothesis that “I feel like this.” They result from deep generative
entanglements that combine information about objective features of the world with infor-
mation about our own physiological states, our action-readiness, and our own longer-term
reactive dispositions. The depth and breadth of a generative model of worldly causes, the
ongoing inflection of those generative-model-based predictions by a stream of interoceptive
and proprioceptive information, and the ability of advanced cognisers to model themselves
and their own reactive dispositions, all play a key role in the constitution of consciousness
on this account. This suggests a graded three-dimensional picture of the core determinants
of conscious experience, with only creatures scoring highly on all three dimensions being
poised to become puzzled about the nature and origins of their own qualitative experiences
(the “meta-hard problem of consciounsess”).
3.2.5 Felt uncertainty theory
According to felt uncertainty theory (Solms, 2013, 2021a, 2021b; Solms & Friston, 2018),
conscious feeling is simply “what it is like to be” a thing that minimises free energy given
a set of homeostatic setpoints, which a Freudian would call “drives” (Solms, 2021a). On
this account, the locus or correlate of the basicstate of consciousnessin the brain (arguably
identifiable with what Rosenthal has called “creature consciousness” as opposed to “state con-
sciousness” (Rosenthal, 2005)) is a set of upper brainstem structures (Solms, 2021b). Feeling
per se derives from brainstem activity, and especially from the upper brainstem structures
of the periaqueductal grey (PAG) and reticular activating system (Solms, 2013). Felt un-
certainty theory can be read as an attempt to reverse the dominant trend of cortico-centric
approaches to consciousness, suggesting that the contributions of cortex to consciousness
have been exaggerated. In felt uncertainty theory, the perceptual contents of conscious ex-
perience, or “mental solids,” come from the top-down constraining effect of cortical structures
on brainstem activity; but the primary locus of conscious feeling itself is sub-cortical. On
this view, consciousness entails the relation: “I feel like thisabout that.”
Felt uncertainty theory dovetails with the beast machine approach and IWMT—albeit
with some potential differences regarding the neuroanatomical substrates of affective con-
sciousness (Safron, 2021b; Seth, 2021)—in that it posits that the brain contains a repre-
sentation of the internal body (i.e., a representation of homeostatic needs or drives, as well
as homeostatic error signals) and a representation of the external body (as an object of
action and perception) (Solms, 2013). Individuals are endowed with spatially distributed
sensory receptors, which allow them to form a map of their own extended bodies as “men-
tal solids.” The affective representation of the internal body corresponds to need-detector
systems, which map onto what Freud called theid. Affect functions to regulate the body
through homeostasis. The body responds to affective cues, and must act allostatically on the
external world to respond to its homeostatic needs. The homeostatic body map is mostly
realized by brain structures around the hypothalamus, including various parts distributed
within the hypothalamic complex. The external, third-person representation of the body
corresponds to a special part of the generative model that represents external objects.
20
According to felt uncertainty theory, the maintenance of the external milieu supervenes
or depends on that of the internal milieu, insofar as homeostatic perception and control is a
prerequisite for allostatic perception and control. To build up the external body representa-
tion, and most of cognition, individuals leverage traces or memories of past events, which are
repurposed for counterfactual and imaginary projection into the future. On this view, the
same parts of the brain are involved in these two processes, namely through the thalamo-
cortico-thalamic circuits. Looking at one’s body implements the same functions as looking at
other bodies, considered as objects in the world: c.f., mirror neuron formulations (Gallese &
Goldman, 1998; Kilner, Friston, & Frith, 2007; Rizzolatti & Craighero, 2004). This external
body-map also consumes motor maps which are produced by the somatosensory and motor
cortices.
The crucial aspects of this theory are (1) that following each action/perception cycle,
residual homeostatic error signals converge on the PAG, where their precisions are priori-
tised by current salience; (2) that the prioritised category—i.e., quality—of need is felt; and
(3) that its fluctuating valence is then utilised by ascending reticular activating neurons
to modulate the agent’s expected precisions in an ensuing action/perception cycle, thereby
rendering it voluntary; while (4) the parallel action/perception policies that respond to the
non-prioritised needs are assigned fixed precision values, and therefore executed automati-
cally. The “felt uncertainty” that gives this theory its name therefore refers to an agent’s
fluctuating confidence in its currently prioritised effort to maintain homeostasis voluntarily.
3.2.6 The projective consciousness model
With few exceptions, self- and world-modelling theories do not attempt to explain how
perspective arises, or why it becomes manifest in the way that it does. The projective con-
sciousness model (PCM) (Rudrauf et al., 2017; Williford et al., 2018; Williford, Bennequin,
& Rudrauf, 2022) formalises aspects of conscious experience different from those formalized
in other theories based on self-modelling; and in doing so it captures some more elusive fea-
tures of conscious experience. Specifically, the PCM formalises the perspectival character of
consciousness and the apparent “zero point” of perception as well as the pervasive, relational
“to me” aspect of conscious experience (sometimes called the “dative of manifestation” in the
phenomenological tradition). Proponents of the PCM propose to use the mathematics of 3D
projective geometry, and the projective transformation group in particular, to provide the
heretofore missing link between the perspectival character of first-person experience and our
experience of an apparently Euclidean, three-dimensional world. According to the PCM,
perspectivally mediated sensory sampling is conducted on the basis of epistemic value or
expected information gained by adopting one perspective over another or by looking at this
rather than that, relative to a given set of goals. The PCM accounts for the perspectival
mediation involved in the epistemic, attention-capturing aspects of perception, imagination,
and action planning. In the parlance of the FEP, the PCM accounts for the perspecti-
val modulation of the epistemic value that underwrites covert action (Friston et al., 2015;
Pezzulo et al., 2016).
Like IWMT (Safron, 2021a), PCM also encompasses some core aspects of G(N)WT
21
(Rudrauf et al., 2017; Williford et al., 2018), but recasts them in terms of the preconditions
for embodied agency. According to the PCM, projective geometry is crucial to defining the
“shape” or geometry of the global workspace, since all modes of perception are integrated
into one perspectival frame centered around an “origin” (e.g., one sees and hears the dog
barking from a “here” or “zero point”, as (Husserl, 1997, 2019) put it) and the planning of all
actions takes into account this perspectival mediation (e.g., one imagines that the trouble
with the car’s engine will be more easily perceptible from beneath the car than from above
the popped hood, i.e., from one perspective vs. another).
The perspectival nature of consciousness is, according to the PCM, fundamentally related
to the experience of embodiment and to the “lived” spatiality of a conscious agent. The
PCM extends the theories just discussed in that it formalises mathematically the perspectival
aspect of conscious experience and the process of perspective-taking operating on a Euclidean
world model. Spatiality is brought to the fore, and projective geometry is used to explain how
the lived embodiment of a conscious agent relates to the structure of the environment. The
PCM also accounts for the elusiveness of the “lived origin”—the sense that the world appears
to a “subject” without that “subject” itself being a fully localisable object in the perceptible
world. Proponents of PCM also argue that something akin to self-modelling (viz., pre-
reflective self-awareness, a minimal form of self-representation or self-acquaintance) can be
derived from the PCM (Williford, Bennequin, & Rudrauf, 2022), and thus that the PCM
provides a formal model of some principal aspects of selfhood and subjectivity.
3.2.7 Relation to the inner screen model
According to the inner screen model, the kind of covert action associated with deeply nested
Markov blankets allows agents to selectively attend to internal and external sources of evi-
dence for various states of being (e.g., feelings and sensations), represented in a format that is
sufficientlycoarse-grained, abstract, andflexibletoenableplanningandcontrol. Thisprocess
of attention allocation enables a form of interoceptive self-modelling, echoing the views from
the beast machine, self-(and-world-)modelling, and felt uncertainty theories, wherein these
fundamental aspects of the first-personal appearance of selfhood are actively constructed
through the internal representation of our own mental states. Thus, according to the pro-
posed MUM, self-modelling and (self-in-)world-modelling are arguably central components
of consciousness.
The self can be modelled from the first-person perspective (as in self-modelling: the self
as the constant locus of diverse interoceptive sensory states) and also from the third-person
perspective (as when the self is represented in world-modelling as one object among many).
The self is located physically in the world because it is embodied, and therefore conscious
systems must also necessarily model the world in which they dwell. Self-models and world-
models have a (deep) temporal structure, which harnesses the causal dependencies between
internal processes and the external states of affairs that these track. Through this causal
structure, consciousness acquires a perspective, directing the causal flow of events in space
and time, and allowing the conscious agent to plan on timescales that extend beyond the
present moment (Chouraqui, 2011; Edelman, 2001; Friston, 2018).
22
In the candidate MUM we have been discussing, the internal Markov blanket (or the in-
ner screen in the quantum formulation) represents a boundary onto which “particles” within
the system can read and write information, thus creating a statistical structure that is
continuously updated based on the interactions between those particles and their (shared)
environment. This process encompasses the generation of predictions about actions in the
beast machine approach (Seth & Tsakiris, 2018), where the brain leverages a generative
model with a set of prior beliefs about what might be causing interoceptive sensory sig-
nals. Managing the flow of information across the inner screen is precisely the same process
as the management of prediction errors in the beast machine approach and extensions of
IWMT (Safron, 2021a), where conscious perception results from minimising proprioceptive
prediction errors during action.
Furthermore, a focus onembodied action—that is, moving the body intentionally—is a
natural fit with the proposed MUM, wherein the active states of the inner screen intervene
causally in lower-level processing, leading to what can be seen as a kind of mental action.
This mental action, instantiated by an attentional set, is plausibly a case of intentional
movement of the body, as discussed in the beast machine theory and related approaches.
The inner screen model also provides a theoretical basis for understanding the stability
of our sense of self across fluctuating sensorimotor processes, as the internal Markov blanket
itself (inner screen) remains stable while the continuous updating of the statistical structure
of the blanket reflects the more transient nature of motor actions. Thus the physiological
homeostasis emphasized in the beast machine, felt uncertainty, and similar approaches can
be related to the persistence of the inner screen in the MUM. The inner screen posited by the
MUM can further be seen as a transparent boundary whose existence becomes apparent only
when information is being written onto it—analogous to the process of directing attention
to specific bodily processes in the beast machine approach.
Felt uncertainty theory focuses on the subcortical systems that orchestrate cortical and
subcortical dynamics from deep in the centre of the brain. This can be understood within
the inner screen model as the implementation of a form of precision weighing prescribed—in
part—by cortical representations (“mental solids”). Felt uncertainty foregrounds the execu-
tive aspects of mental action and the key role of subcortical structures in intervening causally
on cortical dynamics, which may or may not be necessary in themselves for feelings in the
sense of felt uncertainty. This emphasis is based upon empirical evidence from neuropsy-
chology, which suggests that damage to very small subcortical regions vitiates consciousness.
There is a case to be made that in contrast to this, consciousness—as assessed clinically—
can remain largely intact in the absence of large swathes of cortex (see, e.g, (Merker, 2007;
Solms, 2013)). (Note however that interpretations of these findings as suggesting a sufficient
brainstem-basis for consciousness have been disputed (Safron, 2021b).)
Finally, the PCM offers a formal account of subjectivity and point of view as projectively
mediated world-modelling. This modelling allows agents to selectively query specific aspects
of the external world and to construct a subjective perspective on that world. This querying
is based on how much uncertainty is resolved by looking in this rather than that direction, or
from this or that perspective—allowing an agent to focus on specific aspects of the sensorium,
23
representing objects or events—and, crucially, to ignore others actively, by not foregrounding
them. The idea that sampling the world is guided by the expected value of information one
might thereby gather is of course a key aspect of self-evidencing accommodated by the FEP
at the ground level. The extrapersonal world modelling described in the PCM is one of the
foundations upon which the agent establishes a sense of self and is the frame of reference
against which such sampling takes place.
The kind of covert (mental) action appealed to in the inner screen model is integral to the
PCM account. Indeed, one kind of self-evidencing is saccadic sampling of the world, which is
anovert(epistemic)action. ThesamemechanismsareimplicitindeployingPCMfor(covert)
perspective taking. The MUM thus recovers core tenets of the PCM account; implemented
in terms of proactively reading and writing onto an inner screen. On this account, the “live”
data encoded in the global workspace is interpreted by the inferential system as the projective
surface of a Euclidean world model. This process implements epistemic action or foraging,
based on its epistemic value, a score of the information to be gained from new perspectives.
The proposed MUM may have little to say directly concerning the specifically projective
geometerical structure of consciousness posited by the PCM, but only slightly more generally,
something like a Kantian treatment of perception (which treats Euclidean space and time
as categories imposed on “raw” sensory data) is recoverable directly from the holographic
principle that motivates the inner screen model (Fields, Glazebrook, & Marcianò, 2023).
However, if it is true that the projective group facilitates epistemic foraging in a way that
the Euclidean group cannot (see (Sergeant-Perthuis et al., 2023)), and thereby helps to
minimize Free Energy, the projective structure of consciousness can arguably be derived
more directly from the MUM proposed here.
3.3 Computational phenomenology of time-consciousness
The concept of time can be understood in both subjective and objective terms. Subjec-
tive time refers to an individual’s personal experience of temporality, which can vary from
person to person and can be influenced by factors such as emotions, attention, brain func-
tion, and psychopharmacology. In contrast, objective time, though still observer-relative, is
measurable according to clear intersubjective standards (Mensch, 2010).
Since pioneering work in the early 20th century—notably by Husserl (Husserl, 2019),
James (James, 1892), and Bergson (Bergson, 2014)—one aspect of subjective time has been
foregrounded. This is the “specious present,” which refers to the temporal “thickness” of an
individual’s conscious experience of time. This concept suggests that the present moment
is not a discrete point in time, but rather a duration that is perceived as a continuous flow
(by contrast, objective time can still ultimately be divided into discrete measurable units,
such as seconds and minutes). In the parlance of phenomenology, what is at stake is to
describe the manner in which the objects of experience (including the self, insofar as it can
be experienced) are disclosed to consciousness, or “constitued” in the temporal flux of first-
person experience. In early phenomenological work (Husserl, 2019), the specious present has
been linked to the idea of “primal impressions,” “retentions,” and “protentions,” which refer
to the immediate and uninterpreted sensory experience of an individual, and their implicit,
24
online memories of the past and future, respectively. These themes were taken up by later
workinphilosophicalhermeneutics(Gadamer, 2013; Heidegger, 2010), whicharguedthatour
phenomenological experience of the world results from a process of interpretation. On this
view, conscious experience always involves a kind of anticipation or “pro-jection” (German:
Entwurf) into the future, and a kind of “care” or “concern” (German:Sorge)—what one
might call “giving a damn.” Thus, the content of our experience is shaped by the way that
we expect to experience the world, and by the things that matter to us as conscious agents.
More recently, it has been proposed that the specious present can be understood as a
Markov-blanketed structure, with causal coupling between the past and present that are
integrated through the continuity of the Markov blanket (Albarracin et al., 2022; Bogotá
& Djebbara, 2023). Preliminary conceptual work at this intersection has explored the idea
that concern or care as described by hermeneutics can be explored using the deep generative
models of active inference (Ramstead et al., 2020). Further work has explored the idea that
the process of constitution or interpretation, as described by phenomenologists, can be de-
scribed using the technology of generative models, as a form of (active) inference (Ramstead
et al., 2022).
3.3.1 Relation to the inner screen model
The enactive aspect of the MUM proposed here ties into recent work on time-consciousness.
Indeed, this model is consistent with the idea that we are “choice machines” that are able
to “predict ourselves into existence.” According to this view, certain types of brains are
able to select courses of action based on their prediction of future outcomes. This requires
the system to treat sensations in the future as random variables, and to have beliefs about
the future in order to guide its actions. Overall, the hierarchical and temporal structure
of conscious experience reflects the way in which the system of Markov blankets enables
anticipation and preparation for future events, helping us to navigate the world and make
sense of our experiences.
When we plan, we roll our beliefs out into the future—a long way or a little way—in
order to maximise expected information gain or minimise expected free energy (at least, this
is what it looks like from the outside). This links comfortably with the notion of salience,
cashed out in terms of expected information gain, which underwrites active sensing (Ferro
et al., 2010; Friston et al., 2015; Parr & Friston, 2017, 2019a, 2019b). Thus, it must be the
case that if this kind of conscious processing depends upon action, then there has to be a
generative model that can prescribe that action; which means that the agent must have a
generative model of the future; which, in turn, means that time and temporality are baked
into the very definition of being an agent.
The subjective experience of time is closely linked to memory, as our perception of the
past, present, and future is shaped by the events that we have stored in memory (Parr
& Friston, 2017). Indeed, the link between time, perception and memory follows directly
from the symmetry of physical interactions in the quantum information theoretic version
of the FEP formalism (Fields et al., 2022; Fields, Glazebrook, & Marcianò, 2022). This
understanding of time-consciousness can have important implications for our understanding
25
of how individuals perceive and experience the world, and how they make decisions based on
their understanding of time in relation to their memories. It also has practical applications,
such as in the design of technology or the planning of events, where it is crucial to consider
the relationship between time and memory in shaping an individual’s experience. See below
and (Fountas et al., 2022).
We further suggest that any MUM should (and likely must) address the temporal aspect
of consciousness. While some argue that there exist states of mind, such as those induced by
psychedelic drugs and advanced meditative practices, that are without a temporal character,
it is also possible that such claims conflate a (potentially very) thin present moment with the
complete absence of duration (Deane, 2021; Fountas et al., 2022). The experience of time
is in any case clearly an essential feature of paradigmatic human forms of consciousness. Of
course, temporality is not absent from other theories of consciousness: for instance, IWMT
presupposes that temporal coherence is a precondition for consciousness (Safron, 2022b),
and suggests neuro-computational substrates for navigating through time (Safron, Çatal, &
Tim, 2022). However, a focus on richer phenomenological (e.g., Husserlian) accounts of time-
consciousness may be required for addressing these arguably essential properties of conscious
experience.
Table 1:Models of consciousness based on the FEP
Consciousness model Description
Global workspace theory
(GWT)
Consciousness is the result of the brain’s ability to broadcast
information to a global network of processing resources
Projective consciousness
model (PCM)
Consciousness involves a projective geometry which
underwrites sensory sampling, based on the brain’s generative
model of the world
Bayesian attentional
schema theory
Conscious perception is shaped by the ability to deploy a
sparse attentional schema, which representats incoming
sensory information, and involves a process of probabilistic
inference
26
Bayesian global
workspace theories
Consciousness is the result of a dynamic process in which the
brain selects the most probable hypothesis for the current
sensory input, allowing it to predict and anticipate the sensory
inputs that will be needed in the future, and enabling the
selective broadcast of relevant information to the global
workspace
Beast machine approach
Consciousness arises from the brain’s predictive processing,
which involves generating models of the world and
continuously updating them based on incoming sensory
information
Generative entanglement
The brain constructs a generative model of the world that is
entangled with its own physiological states, reactive
dispositions, and action-readiness, and is a crucial aspect in
the formation of conscious experience
Integrated world
modeling theory
(IWMT)
Consciousness emerges from the ability to create and update
spatiotemporally and causally coherent models of the world,
which includes selves and their relations with the
environments in which they find/make themselves
Self-modelling theory
Consciousness arises from the brain’s ability to model and
represent the embodied self, including its emotions, desires,
and intentions
Felt uncertainty theory
Consciousness is the result of the brain’s need to minimize free
energy or uncertainty in its internal model of the world, and is
linked to affective experiences which underwrite voluntary
action
27
Computational
phenomenology of
time-consciousness
Experience is shaped by the brain’s deep hierarchical
collections of knowledge and past experience, and can be
understood as a Markov blanket structure with causal
pathways between the past and present.
3.4 Summary
In summary, we have argued that the “inner screen” model of consciousness (Fields, Glaze-
brook, & Levin, 2021; Ramstead et al., 2023) plausibly serves as a MUM for consciousness
studies. Though our review has focused specifically on approaches to consciousness based
explicitly on the Free Energy Principle, these include variations on very general and widely
accepted paradigms for theorizing about consciousness (such as self-modelling and GWT)
many of whose generic features would also be captured in our proposed MUM.1 The kind of
nested belief updating—or self-evidencing (Hohwy, 2016)—proposed as a basic architecture
for this MUM has four key characteristics:
• Temporal thickness:the implicit planning as inference entails a generative model of
the consequences of action. Because consequences postdate their causes, this implies
a generative model of the future; i.e., a generative model that transcends the present
and acquires temporal depth or thickness (Albarracin et al., 2022; Chouraqui, 2011;
Kirchhoff et al., 2018). Consciousness is, on this view, a process of belief updating
that occurs within a physically realised setting, such as the brain. This realisation
must recapitulate or reflect the causal structure of the sensed world. This requirement
is just a statement of the FEP, and implies that the system of Markov blankets that
subtend conscious processing must be hierarchical in nature.
• Action selection: planning means that one course of (overt or covert) action is
selected as the most likely from a set of plausible paths into the future. This means that
there is an implicit selection among counterfactual futures, all of which are conditioned
on the beliefs of the agent in question (Corcoran, Pezzulo, & Hohwy, 2020; Limanowski
& Friston, 2018; Parr, Pezzulo, & Friston, 2022; Seth, 2015).
• Agency: by definition, the kinds of things that possess the characteristics of temporal
thickness and action selection can be construed as agents, in the sense that they have
a characteristic behaviour; namely, they select courses of action that have well defined
epistemic imperatives and preferences (Friston et al., 2015; Sajid et al., 2021).
• Qualia: action is context-sensitive, because it has to be conditioned upon a “state of
mind” in the implicit generative model. In other words, planning rests upon an inferred
1There is also an argument to be made thatany theory of consciousness consistent with physicalism
ought also to be consistent with the FEP—though advancing this argument would likely be preaching to the
choir.
28
context. This context is a belief state, which is apt to contextualise action; e.g., an
attentional set. This may be interpreted somewhat radically in terms of “Bayesing
qualia” (Clark, Friston, & Wilkinson, 2019); namely, the idea that having a qualitative
experience is, itself, a hypothesis that best explains the sensory impressions on one’s
Markov blankets—an inference that explains why “I am attending to this or that”.
Even if not paired with commitment to a strong form of representationalism about
qualitative character, however, the inner screen model has the resources for explaining
the unusual features of first-person experience that motivate the concept of qualia.
Namely, it cashes out subjective experience in terms of the classical information written
on an internal screen, which needn’t (and, to limit complexity, normally will not — cf.
(Weisberg, 2023)) encode detailed information about its intrinsic physical constitution
or its relations to other physical states, which are generally irrelevant for the purposes
of successfully guiding action.
3.5 Minimal unifying models and empirical predictions
While scientific theories demand empirical verification, it is not clear that this is what is
required to establish that the inner screen model counts as a MUM. Indeed, the MUM
could be understood instead as an integrative framework, whose explanatory power lies in
its parsimony. The present synthesis was developed by combining preexisting models of
consciousness, and accordingly, draws upon the evidence bases for each of these theories. As
such, both the internal coherence of our proposal and the degree of harmonization with other
well-supported models/frameworks can be thought of as a test of the (convergent) validity
of our framework.
Novel hypotheses are, of course, required in order to avoidpost hoc explanation. We
believe that our MUM entails a number of key empirical predictions, which are discussed in
more detail in (Ramstead et al., 2023). Chief among these is the existence of an irreducible
inner Markov blanket, which on our account is a necessary precondition for consciousness.
The identification of a neuro-physiological locus for a kind of “Cartesian theater,” where
cognitive re-presentations are formed—or alternatively, integrated and made available for
widespread “broadcasting”—would indeed be both novel, and surprising to many (but not
all) theorists and experimentalists.
3.6 Projection and consciousness
The proposed MUM of consciousness integrates four senses of the word “projection”:
1. Projection in a sense analogous to that of its common usage projection onto a screen
(cf. “the Cartesian theatre”)
2. Projection as the operation of the projective transformation group (a mathematical
group action)
3. Projection as the broadcasting of information across the brain (global workspace)
29
4. Projectionascounterfactualorimaginativeprojectionintothefuture(activeinference).
The first notion of projection evokes the idea of a screen, as described by the formulation
of Markov blankets under the holographic information theoretic version of the FEP. In this
sense, any Markov blanket serves as the boundary onto which information is “projected,”
much like a metaphorical movie screen or the stage of a theatre. Of course, the projection
metaphor need not lead us to posit the existence of an inner “observer” distinct from the
screen itself—a kind of classical homunlculus, or “small person” in the machine. Here, “obser-
vation” should be taken in the quantum sense of “physical interaction,” such that information
flows from and to the set of nested interacting screens.
The second sense of projection invokes a projective transformation group, which describes
the mathematical transformations that preserve the structure of a projective space, the
type of geometrical structure that captures the perspectival aspects of consciousness and
subjectivity.
The third sense of projection is the idea of “projection” of information across the brain,
as articulated by the global workspace theory. In this sense, the Markov blanket serves as
a mechanism for making information available to different parts of the brain, allowing it to
be integrated in the sense of evidence accumulation and (Bayesian) belief updating.
The fourth sense of projection is the Heideggerian idea of “pro-jection” (Entwurf), which
refers to the anticipatory dynamics of consciousness unfolding at various temporal scales
(Heidegger, 2010), from most proximal (cf. Husserlian “protention”; see (Albarracin et al.,
2022)) to most distal (cf. Sartrean “projects”; (Sartre, Richmond, & Moran, 2022)). In this
sense, the conditional dependencies that define Markov blankets serve as a structure that
enables us to anticipate and prepare for future events, helping us to navigate the world and
to make temporal and narrative sense of our experiences.
3.7 Conclusion
In short, the MUM of consciousness that we have considered suggests that Markov blankets
playacentralroleinthewayweperceiveandinteractwiththeworld, enablingustoconstruct
coherent models of reality. The present synthesis rests on established (to a greater or lesser
extent) models of consciousness, and accordingly, draws upon the evidence bases for each
of these theories. In the preceding, we have engaged in a selective review of the literature
on models of consciousness that are premised on the FEP, and in so doing have considered
how extant theories of consciousness can be read as foregrounding important aspects of the
proposed MUM.
We concluded with a discussion of how multiple senses of “projection” might be integrated
in relation to conscious processing. We believe that this polysemy reflects something more
than an enjoyable semantic coincidence. Rather, it reflects the ways in which the inner screen
model may allow for an integration capable of handling the phenomena of consciousness in
their unity with respect to core functions, as well as in their complex manifestations. We
believe that this is precisely what is required for a MUM, as a framework capable of bringing
together multiple perspectives in ways that allow for convergence of sense-making across per-
30
spectives, while simultaneously respecting and enhancing their diverse expressions. Perhaps
this is also an appropriate description of one of the primary functions of consciousness itself,
in all of its expressions, as a generator of “endless forms most beautiful.”
References
Ainley, V., Apps, M. A. J., Fotopoulou, A., & Tsakiris, M. (2016). ‘Bodily precision’: A pre-
dictive coding account of individual differences in interoceptive accuracy.Philosoph-
ical Transactions of the Royal Society B: Biological Sciences, 371(1708), 20160003.
https://doi.org/10.1098/rstb.2016.0003
Ainley,V.,Tajadura-Jiménez,A.,Fotopoulou,A.,&Tsakiris,M.(2012).Lookingintomyself:
Changes in interoceptive sensitivity during mirror self-observation.Psychophysiology,
49(11), 1672–1676. https://doi.org/10.1111/j.1469-8986.2012.01468.x
Albarracin, M., Pitliya, R. J., Ramstead, M. J. D., & Yoshimi, J. (2022). Mapping Husserlian
phenomenology onto active inference.arXiv. https://doi.org/10.48550/arXiv.2208.
09058
Apps, M. A. J., & Tsakiris, M. (2014). The free-energy self: A predictive coding account of
self-recognition. Neuroscience & Biobehavioral Reviews, 41, 85–97. https://doi.org/
10.1016/j.neubiorev.2013.01.029
Atasoy,S.,Donnelly,I.,&Pearson,J.(2016).Humanbrainnetworksfunctioninconnectome-
specific harmonic waves.Nature communications, 7(1), 10340.
Baars, B. J., Geld, N., & Kozma, R. (2021). Global workspace theory (GWT) and prefrontal
cortex: Recent developments.Frontiers in Psychology, 12, 5163. https://doi.org/10.
3389/fpsyg.2021.749868
Baars, B. J., & Newman, J. (1994). A neurobiological interpretation of Global Workspace
Theory. In A. Revonsuo & M. Kamppinen (Eds.),Consciousness in Philosophy and
Cognitive Neuroscience(pp. 211–226). Psychology Press.
Barrett, L. F., Quigley, K. S., & Hamilton, P. (2016). An active inference theory of allostasis
and interoception in depression.Philosophical Transactions of the Royal Society B:
Biological Sciences, 371(1708), 20160011. https://doi.org/10.1098/rstb.2016.0011
Barrett, L. F., & Simmons, W. K. (2015). Interoceptive predictions in the brain.Nature
Reviews Neuroscience, 16(7), 419–429. https://doi.org/10.1038/nrn3950
Bergson, H. (2014).Time and Free Will: An Essay on the Immediate Data of Consciousness.
Routledge & CRC Press.
Berlin, I. (2013).The Hedgehog and the Fox: An Essay on Tolstoy’s View of History. Prince-
ton University Press. https://doi.org/10.2307/j.ctt24hqz8
Bogotá, J. D., & Djebbara, Z. (2023). Time-consciousness in computational phenomenology:
Atemporalanalysisofactiveinference. Neuroscience of Consciousness,2023,niad004.
https://doi.org/10.1093/nc/niad004
Brown, H., Adams, R. A., Parees, I., Edwards, M., & Friston, K. J. (2013). Active inference,
sensory attenuation and illusions.Cognitive Processing, 14, 411–427. https://doi.org/
10.1007/s10339-013-0571-3
31
Brown, R., Lau, H., & LeDoux, J. E. (2019). Understanding the higher-order approach to
consciousness. Trends in Cognitive Sciences, 23(9), 754–768. https://doi.org/10.
1016/j.tics.2019.06.009
Carruthers, P. (2006).The Architecture of the Mind: Massive Modularity and the Flexibility
of Thought (Illustrated edition). Clarendon Press. https://doi.org/10.1093/acprof:
oso/9780199207077.001.0001
Chalmers, D. (1996).The Conscious Mind. Oxford University Press.
Chouraqui, F. (2011). Temporal thickness in Merleau-Ponty’s notes of May 1959.Chiasmi
International, 13, 407–427. https://doi.org/10.5840/chiasmi20111324
Clark, A. (2015). Surfing uncertainty: Prediction, action, and the embodied mind. Oxford
University Press. https://doi.org/10.1093/acprof:oso/9780190217013.001.0001
Clark, A. (2019). Consciousness as generative entanglement. The Journal of Philosophy,
116(12), 645–662. https://doi.org/10.5840/jphil20191161241
Clark, A., Friston, K. J., & Wilkinson, S. (2019). Bayesing qualia: Consciousness as inference,
not raw datum.Journal of Consciousness Studies, 26(9-10), 19–33. https://www.
ingentaconnect.com/content/imp/jcs/2019/00000026/f0020009/art00002
Corcoran, A. W., Pezzulo, G., & Hohwy, J. (2020). From allostatic agents to counterfactual
cognisers: Active inference, biological regulation, and the origins of cognition.Biology
& Philosophy, 35(3), 32. https://doi.org/10.1007/s10539-020-09746-2
Cosmides, L., & Tooby, J. (1997). The modular nature of human intelligence. In A. B.
Scheibel & J. W. Schopf (Eds.),The Origin and Evolution of Intelligence(pp. 71–
101). Jones; Bartlett. https://www.cep.ucsb.edu/papers/Multimod.pdf
Deane, G. (2021). Consciousness in active inference: Deep self-models, other minds, and
the challenge of psychedelic-induced ego-dissolution.Neuroscience of Consciousness,
2021(2), niab024. https://doi.org/10.1093/nc/niab024
Dehaene, S., Kerszberg, M., & Changeux, J.-P. (1998). A neuronal model of a global
workspace in effortful cognitive tasks.Proceedings of the National Academy of Sci-
ences, 95(24), 14529–14534. https://doi.org/10.1073/pnas.95.24.14529
Dennett, D. (1991).Consciousness Explained. Penguin Books.
Dennett, D., & Akins, K. (2008). Multiple drafts model.Scholarpedia, 3(4), 4321. https:
//doi.org/10.4249/scholarpedia.4321
Dolega, K., & Dewhurst, J. (2019). Bayesian frugality and the representation of attention.
Journal of Consciousness Studies, 26(3-4), 38–63.
Edelman, G. (2001). Consciousness: The Remembered Present. Annals of the New York
Academy of Sciences, 929(1), 111–122. https://doi.org/10.1111/j.1749-6632.2001.
tb05711.x
Edelman, G., & Tononi, G. (2001). A Universe of Consciousness: How Matter Becomes
Imagination. Basic Books.
Ferro, M., Ognibene, D., Pezzulo, G., & Pirrelli, V. (2010). Reading as active sensing: A
computational model of gaze planning during word recognition.Frontiers in Neuro-
robotics, 4. https://doi.org/10.3389/fnbot.2010.00006
32
Fields, C., Glazebrook, J. F., & Marcianò, A. (2023). Communication protocols and quan-
tum error-correcting codes from the perspective of topological quantum field theory.
arXiv:2303.16461 [hp-th].
Fields, C., Fabrocini, F., Friston, K. J., Glazebrook, J. F., Hazan, H., Levin, M., & Marcianò,
A. (2023). Control flow in active inference systems, part i: Classical and quantum
formulations of active inference. IEEE Transactions on Molecular, Biological, and
Multi-Scale Communications, in press. https://doi.org/10.1109/TMBMC.2023.
3272150
Fields, C., Friston, K. J., Glazebrook, J. F., & Levin, M. (2022). A free energy principle for
generic quantum systems.Progress in Biophysics and Molecular Biology, 173, 36–59.
https://doi.org/10.1016/j.pbiomolbio.2022.05.006
Fields, C., & Glazebrook, J. F. (2022). Information flow in context-dependent hierarchi-
cal Bayesian inference.Journal of Experimental & Theoretical Artificial Intelligence,
34(1), 111–142. https://doi.org/10.1080/0952813X.2020.1836034
Fields, C., & Glazebrook, J. F. (2023). Separability, contextuality, and the quantum frame
problem. arxiv:2304.10010.
Fields, C., Glazebrook, J. F., & Levin, M. (2021). Minimal physicalism as a scale-free sub-
strateforcognitionandconsciousness. Neuroscience of Consciousness,2021(2).https:
//doi.org/10.1093/nc/niab013
Fields,C.,Glazebrook,J.F.,&Levin,M.(2022).Neuronsashierarchiesofquantumreference
frames. BioSystems, 219, 104714. https://doi.org/10.1016/j.biosystems.2022.104714
Fields,C.,Glazebrook,J.F.,&Marcianò,A.(2022).Thephysicalmeaningoftheholographic
principle. Quanta, 11, 72–96. https://doi.org/10.12743/quanta.v11i1.206
Fleming, S. M. (2020). Awareness as inference in a higher-order state space.Neuroscience of
Consciousness, 2020(1), niz020. https://doi.org/10.1093/nc/niz020
Fotopoulou, A., & Tsakiris, M. (2017). Mentalizing homeostasis: The social origins of in-
teroceptive inference. Neuropsychoanalysis, 19(1), 3–28. https://doi.org/10.1080/
15294145.2017.1294031
Fountas, Z., Sylaidi, A., Nikiforou, K., Seth, A. K., Shanahan, M., & Roseboom, W. (2022).
A predictive processing model of episodic memory and time perception.Neural Com-
putation, 34(7), 1501–1544. https://doi.org/10.1162/neco_a_01514
Fries, P. (2005). A mechanism for cognitive dynamics: Neuronal communication through
neuronal coherence.Trends in Cognitive Sciences, 9(10), 474–480. https://doi.org/
10.1016/j.tics.2005.08.011
Friston, K. J. (2018). Am I self-conscious? (Or does self-organization entail self-
consciousness?) Frontiers in Psychology, 9, 579. https://doi.org/10.3389/fpsyg.
2018.00579
Friston, K. J. (2019). A free energy principle for a particular physics.arXiv. https://doi.
org/10.48550/arXiv.1906.10184
Friston, K. J., Breakspear, M., & Deco, G. (2012). Perception and self-organized instability.
Frontiers in Computational Neuroscience, 6. https://doi.org/10.3389/fncom.2012.
00044
33
Friston, K. J., & Frith, C. (2015). A duet for one.Consciousness and Cognition, 36, 390–405.
https://doi.org/10.1016/j.concog.2014.12.003
Friston, K. J., Rigoli, F., Ognibene, D., Mathys, C., Fitzgerald, T., & Pezzulo, G. (2015).
Active inference and epistemic value.Cognitive Neuroscience, 6(4), 187–214. https:
//doi.org/10.1080/17588928.2015.1020053
Gadamer, H.-G. (2013).Truth and Method. A & C Black.
Gallese, V., & Goldman, A. (1998). Mirror neurons and the simulation theory of mind-
reading. Trends in Cognitive Sciences, 2(12), 493–501. https://doi.org/10.1016/
S1364-6613(98)01262-5
Graziano, M. S. (2017). The attention schema theory: A foundation for engineering artificial
consciousness. Frontiers in Robotics and AI, 4, 60. https://doi.org/10.3389/frobt.
2017.00060
Guterstam, A., Kean, H. H., Webb, T. W., Kean, F. S., & Graziano, M. S. (2019). Implicit
model of other people’s visual attention as an invisible, force-carrying beam projecting
from the eyes. Proceedings of the National Academy of Sciences, 116(1), 328–333.
https://doi.org/10.1073/pnas.1816581115
Heidegger, M. (2010).Being and Time. SUNY Press.
Hohwy, J. (2012). Attention and conscious perception in the hypothesis testing brain.Fron-
tiers in Psychology, 3, 96. https://doi.org/10.3389/fpsyg.2012.00096
Hohwy, J. (2013).The Predictive Mind. Oxford University Press. https://doi.org/10.1093/
acprof:oso/9780199682737.001.0001
Hohwy, J. (2016). The self-evidencing brain.Nous, 50(2), 259–285. https://doi.org/10.1111/
nous.12062
Hohwy, J. (2022a). Conscious self-evidencing.Review of Philosophy and Psychology, 13(4),
809–828. https://doi.org/10.1007/s13164-021-00578-x
Hohwy, J. (2022b). Conscious self-evidencing.Review of Philosophy and Psychology, 13(4),
809–828. https://doi.org/10.1007/s13164-021-00578-x
Hohwy, J., & Michael, J. (2017). Why should any body have a self?PsyArXiv. https://doi.
org/10.31234/osf.io/fm4cr
Hohwy, J., Paton, B., & Palmer, C. (2016). Distrusting the present.Phenomenology and the
Cognitive Sciences, 15, 315–335. https://doi.org/10.1007/s11097-015-9439-6
Hohwy, J., & Seth, A. K. (2020). Predictive processing as a systematic basis for identifying
the neural correlates of consciousness.Philosophy and the Mind Sciences, 1(2). https:
//doi.org/10.33735/phimisci.2020.II.64
Husserl, E. (1997).Thing and Space: Lectures of 1907(Vol. 7). Springer Science & Business
Media.
Husserl, E. (2019).The Phenomenology of Internal Time-Consciousness. Indiana University
Press.
James, W. (1892). The Stream of Consciousness.Psychology, 151–175. https://psychclassics.
yorku.ca/James/jimmy11.htm
34
Kachman, T., Owen, J. A., & England, J. L. (2017). Self-organized resonance during search
of a diverse chemical space.Physical Review Letters, 119(3), 038001. https://doi.org/
10.1103/PhysRevLett.119.038001
Kilner, J. M., Friston, K. J., & Frith, C. D. (2007). Predictive coding: An account of the
mirror neuron system.Cognitive Processing, 8(3), 159–166. https://doi.org/10.1007/
s10339-007-0170-2
Kirchhoff, M., Parr, T., Palacios, E., Friston, K. J., & Kiverstein, J. (2018). The Markov
blankets of life: Autonomy, active inference and the free energy principle.Journal of
the Royal Society Interface, 15(138), 20170792. https://doi.org/10.1098/rsif.2017.
0792
Kriegel, U., & Williford, K. (2006).Self-Representational Approaches to Consciousness. MIT
Press.
Lehnert, W. C. (2013). Cognition, computers, and car bombs: How Yale prepared me for the
1990s. In R. C. Schank & E. Langer (Eds.),Beliefs, reasoning, and decision making
(pp. 153–184). Psychology Press. https://doi.org/10.4324/9780203773574
Limanowski, J. (2014). What can body ownership illusions tell us about minimal phenomenal
selfhood? Frontiers in Human Neuroscience, 8, 946. https://doi.org/10.3389/fnhum.
2014.00946
Limanowski, J. (2017). (Dis-)attending to the body — Action and self-experience in the
active inference framework. In T. Metzinger & W. Wiese (Eds.), Philosophy and
predictive processing. Frankfurt am Main: MIND Group. https://doi.org/10.15502/
9783958573192
Limanowski, J. (2022). Precision control for a flexible body representation.Neuroscience and
Biobehavioral Reviews, 134, 104401. https://doi.org/10.1016/j.neubiorev.2021.10.023
Limanowski, J., & Friston, K. J. (2018). ‘Seeing the dark’: Grounding phenomenal trans-
parency and opacity in precision estimation for active inference.Frontiers in Psychol-
ogy, 9, 643. https://doi.org/10.3389/fpsyg.2018.00643
Lycan, W. G. (1996).Consciousness and Experience. MIT Press.
Marchi, F., & Hohwy, J. (2022). The intermediate scope of consciousness in the predictive
mind. Erkenntnis, 87, 891–912. https://doi.org/10.1007/s10670-020-00222-7
Marvan, T., & Havlík, M. (2021). Is predictive processing a theory of perceptual conscious-
ness? New Ideas in Psychology, 61, 100837. https://doi.org/10.1016/j.newideapsych.
2020.100837
Mashour, G. A., Roelfsema, P., Changeux, J.-P., & Dehaene, S. (2020). Conscious processing
and the global neuronal workspace hypothesis.Neuron, 105(5), 776–798. https://doi.
org/10.1016/j.neuron.2020.01.026
Mensch,J.R.(2010). Husserl’s Account of Our Consciousness of Time.MarquetteUniversity
Press.
Merker, B. (2007). Consciousness without a cerebral cortex: A challenge for neuroscience
and medicine.Behavioral and Brain Sciences, 30(1), 63–81. https://doi.org/10.1017/
S0140525X07000891
35
Metzinger, T. (2003). Phenomenal transparency and cognitive self-reference.Phenomenology
and the Cognitive Sciences, 2, 353–393. https://doi.org/10.1023/b:phen.0000007366.
42918.eb
Metzinger, T. (2007). Empirical perspectives from the self-model theory of subjectivity:
A brief summary with examples.Progress in Brain Research, 168, 215–278. https:
//doi.org/10.1016/S0079-6123(07)68018-2
Newman,J.,Baars,B.J.,&Cho,S.-B.(1997).Aneuralglobalworkspacemodelforconscious
attention. Neural Networks, 10(7), 1195–1206. https://doi.org/10.1016/s0893-
6080(97)00060-9
Palacios, E., Isomura, T., Parr, T., & Friston, K. J. (2019). The emergence of synchrony in
networks of mutually inferring neurons.Scientific Reports, 9(1), 6412. https://doi.
org/10.1038/s41598-019-42821-7
Pang, J. C., Aquino, K. M., Oldehinkel, M., Robinson, P. A., Fulcher, B. D., Breakspear, M.,
& Fornito, A. (2023). Geometric constraints on human brain function.Nature, 1–9.
Park,H.-J.,&Friston,K.(2013).Structuralandfunctionalbrainnetworks:Fromconnections
to cognition.Science, 342(6158), 1238411. https://doi.org/10.1126/science.1238411
Parr, T., Corcoran, A. W., Friston, K. J., & Hohwy, J. (2019a). Perceptual awareness and
active inference.Neuroscience of Consciousness, 2019(1), niz012. https://doi.org/10.
1093/nc/niz012
Parr, T., Corcoran, A. W., Friston, K. J., & Hohwy, J. (2019b). Perceptual awareness and
active inference [niz012].Neuroscience of Consciousness, 2019(1). https://doi.org/
10.1093/nc/niz012
Parr,T.,& Friston, K.J. (2017). Workingmemory, attention,and saliencein active inference.
Scientific Reports, 7(1), 14678. https://doi.org/10.1038/s41598-017-15249-0
Parr, T., & Friston, K. J. (2019a). Attention or salience?Current Opinion in Psychology,
29, 1–5. https://doi.org/10.1016/j.copsyc.2018.10.006
Parr, T., & Friston, K. J. (2019b). Generalised free energy and active inference.Biological
Cybernetics, 113(5), 495–513. https://doi.org/10.1007/s00422-019-00805-w
Parr, T., Markovic, D., Kiebel, S. J., & Friston, K. J. (2019). Neuronal message passing using
mean-field, bethe, and marginal approximations.Scientific reports, 9(1), 1889.
Parr, T., Pezzulo, G., & Friston, K. J. (2022).Active Inference: The Free Energy Principle
in Mind, Brain, and Behavior. MIT Press.
Pezzulo, G., Cartoni, E., Rigoli, F., Pio-Lopez, L., & Friston, K. J. (2016). Active inference,
epistemic value, and vicarious trial and error.Learning & Memory, 23(7), 322–338.
https://doi.org/10.1101/lm.041780116
Pinker, S. (2003).How the Mind Works. Penguin UK.
Prinz, J. (2012).The Conscious Brain: How Attention Engenders Experience. Oxford Uni-
versity Press USA.
Raffone, A., & Pantani, M. (2010). A global workspace model for phenomenal and access
consciousness. Consciousness and Cognition, 19(2), 580–596. https://doi.org/10.
1016/j.concog.2010.03.013
36
Ramstead, M. J. D., Sakthivadivel, D. A. R., Heins, C., Koudahl, M., Millidge, B., Da Costa,
L., Klein, B., & Friston, K. J. (2023). On Bayesian mechanics: A physics of and by
beliefs [To appear].Interface Focus. https://doi.org/10.1098/rsfs.2022.0029
Ramstead, M. J. D., Seth, A. K., Hesp, C., Sandved-Smith, L., Mago, J., Lifshitz, M.,
Pagnoni, G., Smith, R., Dumas, G., Lutz, A., Friston, K. J., & Constant, A. (2022).
From generative models to generative passages: A computational approach to (neuro)
phenomenology. Review of Philosophy and Psychology, 13(4). https://doi.org/10.
1007/s13164-021-00604-y
Ramstead, M. J. D., Wiese, W., Miller, M., & Friston, K. J. (2020). Deep neurophenomenol-
ogy: An active inference account of some features of conscious experience and of their
disturbance in major depressive disorder. http://philsci-archive.pitt.edu/18377/
Ramstead, M. J., Albarracin, M., Kiefer, A., Klein, B., Fields, C., Friston, K., & Safron, A.
(2023). The inner screen model of consciousness: Applying the free energy principle
directly to the study of conscious experience.arXiv preprint arXiv:2305.02205.
Rizzolatti, G., & Craighero, L. (2004). The mirror-neuron system.Annual Review of Neuro-
science, 27(1), 169–192. https://doi.org/10.1146/annurev.neuro.27.070203.144230
Rorot, W. (2021). Bayesian theories of consciousness: A review in search for a minimal
unifying model. Neuroscience of Consciousness, 2021(2), niab038. https://doi.org/
10.1093/nc/niab038
Rosenthal, D. M. (2005).Consciousness and Mind. Oxford University Press.
Rudrauf, D., Bennequin, D., Granic, I., Landini, G., Friston, K. J., & Williford, K. (2017). A
mathematical model of embodied consciousness.Journal of Theoretical Biology, 428,
106–131. https://doi.org/10.1016/j.jtbi.2017.05.032
Safron, A. (2020a). An integrated world modeling theory (IWMT) of consciousness: Com-
bining integrated information and global neuronal workspace theories with the free
energy principle and active inference framework; toward solving the hard problem
and characterizing agentic causation.Frontiers in Artificial Intelligence, 3, 30. https:
//doi.org/10.3389/frai.2020.00030
Safron, A. (2020b). On the varieties of conscious experiences: Altered beliefs under
psychedelics (albus).PsyArxiv. https://doi.org/10.31234/osf.io/zqh4b
Safron, A. (2021a). The radically embodied conscious cybernetic Bayesian brain: From free
energy to free will and back again.Entropy, 23(6), 30. https://doi.org/10.3390/
e23060783
Safron, A. (2021b). World models and the physical substrates of consciousness: Hidden
sources of the stream of experience?Journal of Consciousness Studies, 28, 30. https:
//doi.org/10.53765/20512201.28.11.210
Safron, A. (2022a). AIXI, FEP-AI, and integrated world models: Towards a unified under-
standing of intelligence and consciousness.PsyArXiv. https://doi.org/10.31234/osf.
io/4qkjp
Safron, A. (2022b). Integrated world modeling theory expanded: Implications for the future
of consciousness.Frontiers in Computational Neuroscience, 16, 30. https://doi.org/
10.3389/fncom.2022.642397
37
Safron, A., Çatal, O., & Tim, V. (2022). Generalized simultaneous localization and mapping
(G-SLAM) as unification framework for natural and artificial intelligences: Towards
reverse engineering the hippocampal/entorhinal system and principles of high-level
cognition. Frontiers in Systems Neuroscience. https://doi.org/10.3389/fnsys.2022.
787659
Sajid, N., Ball, P. J., Parr, T., & Friston, K. J. (2021). Active inference: Demystified and
compared. Neural Computation, 33(3), 674–712. https://doi.org/10.1162/neco_a_
01357
Sandved-Smith, L., Hesp, C., Mattout, J., Friston, K. J., Lutz, A., & Ramstead, M. J. D.
(2021). Towards a computational phenomenology of mental action: Modelling meta-
awareness and attentional control with deep parametric active inference.Neuroscience
of Consciousness, 2021(1). https://doi.org/10.1093/nc/niab018
Sartre, J.-P., Richmond, S., & Moran, R. (2022).Being and nothingness: An essay in phe-
nomenological ontology. Routledge.
Schurger, A., & Graziano, M. (2022). Consciousness explained or described?Neuroscience
of Consciousness, 2022(1), niac001. https://doi.org/10.1093/nc/niac001
Sergeant-Perthuis, G., Rudrauf, D., Ognibene, D., & Tisserand, Y. (2023). Action of the
euclidean versus projective group on an agent’s internal space in curiosity driven
exploration: A formal analysis.
Seth, A. K. (2013). Interoceptive inference, emotion, and the embodied self.Trends in Cog-
nitive Sciences, 17(11), 565–573. https://doi.org/10.1016/j.tics.2013.09.007
Seth, A. K. (2015). Inference to the best prediction — A reply to Wanja Wiese. In T.
Metzinger & J. M. Windt (Eds.). Open MIND. Frankfurt am Main: MIND Group.
https://doi.org/10.15502/9783958570986
Seth, A. K. (2021).Being You: A New Science of Consciousness. London: Faber & Faber.
Seth, A. K., & Bayne, T. (2022). Theories of consciousness.Nature Reviews Neuroscience,
23(7), 439–452. https://doi.org/10.1038/s41583-022-00587-4
Seth, A. K., & Friston, K. J. (2016). Active interoceptive inference and the emotional brain.
Philosophical Transactions of the Royal Society B: Biological Sciences, 371(1708),
20160007. https://doi.org/10.1098/rstb.2016.0007
Seth, A. K., Suzuki, K., & Critchley, H. (2012). An interoceptive predictive coding model of
conscious presence.Frontiers in Psychology, 2. https://doi.org/10.3389/fpsyg.2011.
00395
Seth, A. K., & Tsakiris, M. (2018). Being a beast machine: The somatic basis of selfhood.
Trends in Cognitive Sciences, 22(11), 969–981. https://doi.org/10.1016/j.tics.2018.
08.008
Simpson, G. G. (1945).The Principles of Classification and a Classification of Mammals
(Vol. 85). American Museum of Natural History.
Solms, M. (2013). The conscious id.Neuropsychoanalysis, 15(1), 5–19. https://doi.org/10.
1080/15294145.2013.10773711
Solms, M. (2021a). Revision of drive theory.Journal of the American Psychoanalytic Asso-
ciation, 69(6), 1033–1091. https://doi.org/10.1177/00030651211057041
38
Solms, M. (2021b).The Hidden Spring: A Journey to the Source of Consciousness. Profile
Books.
Solms, M., & Friston, K. J. (2018). How and why consciousness arises: Some considerations
from physics and physiology.Journal of Consciousness Studies, 25(5-6), 202–238.
Tononi, G. (2012). The integrated information theory of consciousness: An updated account.
Archives Italiennes de Biologie, 150(2/3), 56–90. https://doi.org/10.4449/aib.v149i5.
1388
Tononi, G., & Edelman, G. (1998). Consciousness and complexity.Science, 282(5395), 1846–
1851. https://doi.org/10.1126/science.282.5395.1846
Varela, F. J., Thompson, E., & Rosch, E. (2017).The Embodied Mind, Revised Edition:
Cognitive Science and Human Experience. MIT Press.
Volzhenin, K., Changeux, J.-P., & Dumas, G. (2022). Multilevel development of cognitive
abilities in an artificial neural network.Proceedings of the National Academy of Sci-
ences, 119(39), e2201304119. https://doi.org/10.1073/pnas.2201304119
Weisberg, J. (2023).Explanatory optimism about the hard problem of consciousness. https:
//doi.org/10.4324/9781003411581
Whyte, C. J. (2019). Integrating the global neuronal workspace into the framework of pre-
dictive processing: Towards a working hypothesis.Consciousness and Cognition, 73,
102763. https://doi.org/10.1016/j.concog.2019.102763
Whyte, C. J., Hohwy, J., & Smith, R. (2022). An active inference model of conscious ac-
cess: How cognitive action selection reconciles the results of report and no-report
paradigms. Current Research in Neurobiology, 3, 100036. https://doi.org/10.1016/j.
crneur.2022.100036
Whyte, C. J., & Smith, R. (2021). The predictive global neuronal workspace: A formal
active inference model of visual consciousness.Progress in Neurobiology, 199, 101918.
https://doi.org/10.1016/j.pneurobio.2020.101918
Wiese, W. (2020). The science of consciousness does not need another theory, it needs a
minimal unifying model. Neuroscience of Consciousness, 2020(1), niaa013. https:
//doi.org/10.1093/nc/niaa013
Williford, K., Bennequin, D., Friston, K. J., & Rudrauf, D. (2018). The projective con-
sciousness model and phenomenal selfhood.Frontiers in Psychology, 9, 2571. https:
//doi.org/10.3389/fpsyg.2018.02571
Williford, K., Bennequin, D., & Rudrauf, D. (2022). Pre-reflective self-consciousness & pro-
jective geometry.Review of Philosophy and Psychology, 13(2), 365–396. https://doi.
org/10.1007/s13164-022-00638-w
39