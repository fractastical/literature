entropy
Article
Dynamic Expectation Maximization Algorithm for Estimation
of Linear Systems with Colored Noise
Ajith Anil Meera *
 and Martijn Wisse
/gid00030/gid00035/gid00032/gid00030/gid00038/gid00001/gid00033/gid00042/gid00045/gid00001
/gid00048/gid00043/gid00031/gid00028/gid00047/gid00032/gid00046
Citation: Anil Meera, A.; Wisse, M.
Dynamic Expectation Maximization
Algorithm for Estimation of Linear
Systems with Colored Noise. Entropy
2021, 23, 1306. https://doi.org/
10.3390/e23101306
Academic Editors: Thomas Parr,
Manuel Baltieri, Thijs van de Laar,
Kai Ueltzhöffer, Daniela Cialﬁ and
Karl Friston
Received: 10 August 2021
Accepted: 1 October 2021
Published: 5 October 2021
Publisher’s Note:MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afﬁl-
iations.
Copyright: © 2021 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed under the terms and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
Department of Cognitive Robotics, Faculty of Mechanical, Maritime and Materials Engineering,
Delft Institute of Technology, 2628 CN Delft, The Netherlands; m.wisse@tudelft.nl
* Correspondence: ajitham1994@gmail.com
Abstract: The free energy principle from neuroscience has recently gained traction as one of the most
prominent brain theories that can emulate the brain’s perception and action in a bio-inspired manner.
This renders the theory with the potential to hold the key for general artiﬁcial intelligence. Leveraging
this potential, this paper aims to bridge the gap between neuroscience and robotics by reformulating
an FEP-based inference scheme—Dynamic Expectation Maximization—into an algorithm that can
perform simultaneous state, input, parameter, and noise hyperparameter estimation of any stable
linear state space system subjected to colored noises. The resulting estimator was proved to be of the
form of an augmented coupled linear estimator. Using this mathematical formulation, we proved
that the estimation steps have theoretical guarantees of convergence. The algorithm was rigorously
tested in simulation on a wide variety of linear systems with colored noises. The paper concludes
by demonstrating the superior performance of DEM for parameter estimation under colored noise
in simulation, when compared to the state-of-the-art estimators like Sub Space method, Prediction
Error Minimization (PEM), and Expectation Maximization (EM) algorithm. These results contribute
to the applicability of DEM as a robust learning algorithm for safe robotic applications.
Keywords: free energy principle; system identiﬁcation; linear time-invariant (LTI) systems; colored
noise; state space models; robotics
1. Introduction
The free energy principle (FEP) has emerged from neuroscience as a unifying theory
of the brain [1] and has begun to guide the search for a brain-inspired learning algorithm
for robots. Many attempts have been made in this direction, including the state and input
observer [2,3], the adaptive controller for robot manipulators [4–6], the body perception
and action scheme for humanoid robots [ 7], the robot navigation of ground robots [ 8]
etc. However, the design of a parameter estimation algorithm for linear systems with
colored noise remains unexplored. Since the design of an accurate parameter estimator for
dynamic systems sits at the core of control systems and robotics, the reformulation of FEP
into a brain-inspired estimation algorithm has an inﬂuential impact on the industry and
applied robotics.
A wide range of estimators have been proposed in the literature for linear time-
invariant (LTI) systems [9], including the blind system identiﬁcation [ 10–12]. However,
most of them assume the noises to be temporally uncorrelated (white noise), which is
often violated in practice. This results in biased estimation for the least-square (LS)-based
methods [13], and an inaccurate convergence for the iterative methods [ 14]. Although
many attempts have been made to solve this problem, mainly through bias compensation
methods [15,16], none of them perform state, input, parameter, and noise estimation for
systems with colored noises [17]. The only method that does it is the Dynamic Expectation
Maximization (DEM) [ 18] algorithm, which uses FEP to invert a highly nonlinear and
hierarchical brain model from sensory data. However, the disconnect between neuroscience
Entropy 2021, 23, 1306. https://doi.org/10.3390/e23101306 https://www.mdpi.com/journal/entropy
Entropy 2021, 23, 1306 2 of 32
and control system literature hinders the wide use of this method for practical robotics
applications. Although FEP-based tools have already been applied to practical robotics
applications [2–8,19,20], there is a gap in the literature on the applications of DEM owing to
the mathematical formidability of the theory and its lack of formalism in the control systems
domain. Therefore, it is important to reformulate DEM for the control systems audience.
While DEM from computational neuroscience focuses on emulating the brain’s perception
through the hierarchical abstraction of a number of interacting non-linear dynamic systems,
our work focuses on reformulating it into a blind system-identiﬁcation algorithm for an LTI
system with colored noise, which is a well-known challenge in robotics. In this attempt, we
keep all the brain-related approximations intact, thereby aiming for a biologically plausible
parameter estimation algorithm.
According to an FEP proposed by Karl Friston, the brain’s inference mechanism is a
gradient ascent over its free energy, where free energy is the information-theoretic measure
that bounds the brain’s sensory surprisal [21]. FEP emerges as a uniﬁed brain theory [22] by
providing a mathematical description of brain functions [23]; unifying action and percep-
tion [24]; connecting physiological constructs like memory, attention, value, reinforcement,
and salience [23]; and remaining consistent with Freudian ideas[25]. Similarities of FEP
with reinforcement learning [ 26], neural networks [ 21,27], PID controller [ 28], Kalman
Filter [2] and active learning [24] open up possibilities for biologically plausible parameter
estimation algorithms. Although FEP emerged as a brain theory, the recent works have
pushed the boundaries towards systems that survive over time, such as social and cul-
tural dynamics. Notable works include the variational approach to culture [29], collective
intelligence [30], cumulative cultural evolution [31], etc.
Numerous methods have been proposed based on the FEP framework. Predictive
coding [32] models perception through a hierarchy of dynamical systems [ 27] with the
brain’s priors at the top, minimizing the prediction error at each level of the hierarchy.
Bayesian message passing algorithms [ 33,34] use similar ideas for belief propagation.
Active inference [24,35] uses FEP to model the brain’s action and perception under one
framework. On the perception side, there are two main type of methods to deal with
dynamic systems: variational ﬁltering and generalized ﬁltering. Variational ﬁltering [18,36]
uses mean-ﬁeld approximation (conditional independence between densities), whereas
generalized ﬁltering [ 37] does not. DEM [ 18] is a type of variational ﬁltering that uses
a Laplace approximation [ 38] (a ﬁxed-form assumption for the conditional density of
variables), whereas [36] uses ensemble dynamics to model the free form of the conditional
densities. We focus on DEM for this work.
DEM is an FEP-based variational inference algorithm that models the brain’s inference
process as a maximization of its free energy for state, input, parameter, and noise estimation
from data. Although the method shows high similarity to the variational inference [ 39],
the key difference is in the use of generalized coordinates, which enables DEM to track the
evolution of the trajectory of states instead of just the point estimates. This renders DEM
with the capability of gracefully handling colored noises, a feature that conventional point
estimators such as the Kalman Filter (KF) lacks. The modeling of noise color as analytic
using generalized coordinates results in an improved state estimation under colored noise
for LTI systems [2,3] and for nonlinear ﬁltering [40], which directly improves the parameter
estimation accuracy, making DEM a topic of interest [ 20]. This work directly impacts
various sub-domains of robotics community: input estimation to the industrial automation
community for fault detection systems, state estimation to the control systems commu-
nity, parameter estimation to the system identiﬁcation community, and hyperparameter
estimation to the signal processing community.
With this paper, we aim to present DEM to the robotics audience as a robot learning
algorithm for the blind system identiﬁcation of LTI systems with colored noise. We elab-
orate on various components of DEM that are most relevant to the robotics community:
(1) the derivation of the free energy objectives from Bayesian principles, (2) the modeling
of colored noise using generalized coordinates, and (3) the simpliﬁcation of update rules
Entropy 2021, 23, 1306 3 of 32
for LTI systems with colored noise. We reformulate DEM for LTI systems into a form that
is widely used in the robotics domain and use this mathematical formulations to prove
that the estimation steps of DEM have theoretical guarantees of convergence [41]. In our
prior work, we have discussed the stability conditions of our DEM-based linear state and
input observer design [2]. This convergence guarantees and stability criteria are essential
for robot safety while in operation and is of high relevance to the robotics community.
Through extensive simulations on a range of random systems, we show that DEM is a
competitive estimator when compared to other benchmarks in the control systems domain.
The core contributions of the paper are:
1. Reformulating DEM into an estimation algorithm for LTI systems with colored noise
(Section 12).
2. Proving that the estimator has theoretical guarantees of convergence for the estimation
steps (Section 14).
3. Proving through rigorous simulation that DEM outperforms the state-of-the-art sys-
tem identiﬁcation methods for parameter estimation under colored noise (Section 16).
2. Problem Statement
Consider the linear plant dynamics given in Equation (1), where A, B and C are
constant system matrices, x ∈Rn is the hidden state, v ∈Rr is the input and y ∈Rm is
the output.
˙x = Ax + Bv + w, y = Cx + z. (1)
Here, w ∈Rn and z ∈Rm represent the process and measurement noise, respectively.
The notations of the plant are denoted in boldface, whereas its estimates are denoted
in nonboldface letters. The noises in this paper are generated through the convolution
of white noise with a Gaussian kernel. The use of colored noise is motivated by the
fact that in robotics, the unmodelled dynamics and the non-linearity errors can enter the
plant dynamics through the noise terms, thereby violating the white noise assumption in
practice [20].
The goal of this paper is to reformulate DEM for an LTI system such that given the
output of the system y, the estimator computes the associated states x, inputs v, parameter
θ containing the matrices A, B and C, hyperparameters λ that model the noise precision
(Π = eλ), and the uncertainties of all its estimates (Σx, Σv, Σθ, Σλ), with the help of the
prior (learned) knowledge encoded in the robot brain, such that the estimate best predicts
the data. The schematic of the proposed robot brain’s inference process is given in Figure 1.
Figure 1. A simple block diagram of the robot brain’s inference process using DEM. It uses the
measurement data y generated from the environment (also called generative process). DEM enables
the direct fusion of the prior information into the inference process. The concept of generalized
coordinates will be detailed in Section 3.1.
Entropy 2021, 23, 1306 4 of 32
3. Preliminaries
To reformulate DEM into an estimation algorithm for LTI systems, this section intro-
duces the key concepts and terminologies that are familiar to the FEP audience.
3.1. Generative Model
The generative model (plant model) is the robot brain’s estimate of the generative
process in the environment that generated data. The robot brain infers this model via model
evidencing from the measurement data. The key idea behind DEM to deal with colored
noise is to model the trajectory of the time-varying components (states, for example) using
generalized coordinates. The use of generalized coordinates is new to the control systems
literature and is different from the familiar deﬁnition in classical mechanics. In mechanics,
it is the minimum number of independent coordinates that deﬁne the conﬁguration of a
system, whereas in DEM, it is the vector deﬁning the motion of a point using its higher
derivatives. In DEM, the emphasis is on tracking the trajectories of states, inputs and
outputs instead of their point estimates. The states are expressed in generalized coordinates
using its higher-order derivatives, i.e., ˜x = [x x ′x′′ . . .]T. The generalized state vector
˜x with an order of generalized motion of p will have p + 1 terms, with the copy of the
state vector as the ﬁrst term, followed by its p derivatives. The variables in generalized
coordinates are denoted by a tilde, and its components (higher derivatives) are denoted by
primes. The evolution of states is written as:
x′= Ax + Bv + w
x′′= Ax′+ Bv′+ w′
. . .
y = Cx + z
˙y = Cx′+ z′
. . .
(2)
The colored noises are modeled such that the covariance of noise derivatives˜z = [z, z′, z′′, . . .]T
and ˜w = [w, w′, w′′, . . .]T are well deﬁned (to be explained in Section 3.3). The generative
model representing the system is compactly written as:
˙˜x = Dx ˜x = ˜A ˜x + ˜B ˜v + ˜w ˜y = ˜C ˜x + ˜z (3)
where Dx =
[0 1
0 1. .
0 1
0
]
(p+1)×(p+1)
⊗In×n, performs the block derivative operation, equiv-
alent to shifting up all components in generalized coordinates by one block. A similar
deﬁnition holds for Dv (appears later) with size r(d + 1) ×r(d + 1), where p and d are
the order of generalized motion of states and inputs, respectively. Here, ˜A = Ip+1 ⊗A,
˜B = Ip+1 ⊗B, and ˜C = Ip+1 ⊗C, where ⊗is the Kronecker tensor product.
3.2. Parameters and Hyperparameters
To simplify the parameter estimation steps of DEM for LTI systems (Section 13.2) and
to facilitate the convergence proof (Section 14), we introduce an alternative generative
model which is the direct reformulation of Equation (3) given by:
˙˜x = Mθ + ˜w, ˜y = Nθ + ˜z, θ =


vec(AT)
vec(BT)
vec(CT)

 (4)
where
M =


In ⊗xT In ⊗vT In ⊗O1×m
In ⊗x′T In ⊗v′T In ⊗O1×m
. . . . . . . . .

, N =


In ⊗O1×n In ⊗O1×r Im ⊗xT
In ⊗O1×n In ⊗O1×r Im ⊗x′T
. . . . . . . . .

. (5)
Entropy 2021, 23, 1306 5 of 32
Throughout the paper, θ represents the set of parameters, whereas λ =
[λz
λw
]
represents the
hyperparameters that deﬁne the precision matrices (inverse covariance matrices) of the
observation noise and the process noise. For noise modelling, we parametrize the noise
precisions using an exponential relation with the hyperparameters, given by [18]:
Πw(λw) =eλw
Ωw, Πz(λz) =eλz
Ωz, (6)
where Ωw and Ωz represent constant matrices encoding how different noises are correlated.
Here Πw and Πz are the inverse covariances {(Σw)−1, (Σz)−1}or precisions of the noises.
This parameterization ensures the selection of positive deﬁnite noise precision matrices
through hyperparameter updates. We assume zero cross-correlation between w and z. We
also assume that θ and λ are time-invariant.
3.3. Colored Noise
The next step towards handling the colored noise is to embed the noise correlation
between different components in the generalized noises ˜w and ˜z given in Equation (3).
DEM uses generalized coordinates, which models a correlation between noise derivatives
through the temporal precision matrix S (inverse of covariance matrix). The generalized
noise correlation is assumed to be due to a Gaussian ﬁlter, whereS can be calculated as [18]:
S(σ2) =


1 0 − 1
2σ2 ..
0 1
2σ2 0 ..
− 1
2σ2 0 3
4σ4 ..
.. .. .. ..


−1
(p+1)×(p+1)
(7)
where σ (from the Gaussian kernel) denotes the noise smoothness level. While σ2 →0
denotes white noise, nonzero σ2 denotes colored noise. The covariance between noise
derivatives increases exponentially with the order of noise derivatives. Simulations show
that derivatives above 6 can be neglected [18]. The generalized noise precision matrices
are given by ˜Πw = S(σ2) ⊗Πw and ˜Πz = S(σ2) ⊗Πz, where Πw and Πz are the inverse
noise covariances.
3.4. Generalized Motion of the Outputs and Noises
The generalized motion of output ˜y is practically expensive and inaccessible to robotics
systems. Moreover, most sensors such as encoders operate with discrete measurements.
Therefore, as a pre-processing step for estimation (refer to Figure 1), ˜y should be computed
from discrete measurements. The goal is to ﬁrst express the discrete measurements as a
function of output derivatives and then invert the function to compute the derivatives
from the discrete measurements. Given the p temporal derivatives ˜y at time t, the p output
sequence surrounding y can be approximated using Taylor series as follows [18]:
ˆy =


..
y(t −dt)
y(t)
y(t + dt)
..


= (Y ⊗Im)˜y, Yij =
[(
i −ceil
(p+1
2
))
dt
]j−1
(j −1)! , (8)
where i, j = 1, 2,. . ., p + 1, ceil (.) is the smallest integer function and ˆy has the size
m(p + 1) ×1. Therefore, generalized motion of output ˜y at time t is:
˜y = (Y−1 ⊗Im)ˆy. (9)
Using ˜y embeds more temporal information about the plant into the data in the form of
conditional trajectories, with the disadvantage of a time latency of p
2 dt in estimation. For
robotic systems with high sampling rates, this latency in estimation is negligible [ 3,20].
Entropy 2021, 23, 1306 6 of 32
The next section employs this generalized output along with the generative model for
observer designs.
3.5. Notations and Conventions
Throughout the paper, the superscript notation will be used to represent the quantity
being referred to, and the subscript notation will be used to represent the derivative
operation. For example, ˜Πw
λ represents the derivative of the generalized precision of the
process noise w with respect to the hyperparameters λ. The tilde operator ( ˜x) is used
to represent a quantity in its generalized coordinates, whereas the bar operator ( ¯F) is
used to represent the time integral of a quantity. All the probability distributions will
be represented by the p(.) notation, whereas its expectation will be represented by the
⟨p(.)⟩notation.
4. Free Energy Objectives
With the preliminaries in place, we can build up towards the complete DEM algorithm.
Eventually, in Sections 8 and 12, we will see that it is an optimization algorithm that ﬁnds the
best estimates for states, inputs, parameters, and hyperparameters for given measurement
data. This result is achieved by optimizing two objective functions, which are the core
objectives under the entire Free Energy Principle: the free energy and the free action [ 1].
Here we derive and simplify this objective.
The derivation starts from the fundamentals of Variational Inference (VI) [39]. In VI,
the posterior distribution p(ϑ/y) of parameter ϑ, given the measurement y, is expressed as:
p(ϑ/y) = p(y/ϑ)p(ϑ)
p(y) = p(ϑ, y)
p(y) = p(ϑ, y)∫
p(ϑ, y)dϑ. (10)
However, the marginalization over ϑ to calculate p(y) is often intractable because the
search space of ϑ is large. A widely used technique is to introduce a variational distribution
q(ϑ) known as the recognition density, which acts as an approximate representation of the
posterior distribution with q(ϑ) ≈p(ϑ/y). A common method used among variational
Bayes algorithms is to minimize the Kullback–Leibler (KL) divergence between both the
distributions, deﬁned as:
KL(q(ϑ)||p(ϑ/y)) =⟨ln q(ϑ)⟩q(ϑ) −⟨ln p(ϑ/y)⟩q(ϑ), (11)
where ⟨.⟩q(ϑ) represents the expectation over q(ϑ). Substituting Equation (10) in
Equation (11) and using
∫
q(ϑ)dϑ = 1 yields:
KL(q(ϑ)||p(ϑ/y)) =⟨ln q(ϑ)⟩q(ϑ) −⟨ln p(ϑ, y)⟩q(ϑ) + ln p(y). (12)
The rearrangement of terms yield:
ln p(y) =⟨ln p(ϑ, y)⟩q(ϑ) −⟨ln q(ϑ)⟩q(ϑ) + KL(q(ϑ)||p(ϑ/y)),
= ⟨U(ϑ, y)⟩q(ϑ) + H(ϑ)q(ϑ)  
free energy
+KL(q(ϑ)||p(ϑ/y)), (13)
where ln p(y) is the log-evidence, U(ϑ, y) =ln p(ϑ, y) is the internal energy andH(ϑ)q(ϑ) =
−⟨ln q(ϑ)⟩q(ϑ) is the entropy of the density. The free energy term in Equation (13) is
deﬁned as the sum of an energy term and its entropy. It acts as the lower bound on the
log-evidence because the KL divergence term KL(q(ϑ)||p(ϑ/y)) is always positive. The
maximization of free energy minimizes the divergence term in Equation (13) because
the log-evidence is independent of q(ϑ), thereby rendering the variational density q(ϑ)
as a close approximation of p(ϑ/y). Therefore, the difﬁcult evaluation of an intractable
integral term in Equation (10) is converted into a much simpler optimization problem of
maximizing the free energy. This reduces the problem of inference to a direct optimization
Entropy 2021, 23, 1306 7 of 32
of its free energy objectives and is the fundamental idea behind variation inference. The
free energy term in Equation (13) is equivalent to the Evidence Lower Bound (ELBO) [39].
It can be simpliﬁed as:
F = ⟨U(ϑ, y)⟩q(ϑ) + H(ϑ)q(ϑ) =
∫
q(ϑ)U(ϑ, y)dϑ −
∫
q(ϑ) ln q(ϑ)dϑ
=
∫
q(ϑ) ln p(ϑ, y)dϑ −
∫
q(ϑ) ln q(ϑ)dϑ.
(14)
However, when the parameter set to be estimated includes both the time-variant and the
time-invariant parameters, the free action is used as the objective function to be maximized.
The free action is deﬁned as the time integral of the free energy and is given by:
¯F = ¯V(ϑ) + ¯H(ϑ) =
∫
⟨U(ϑ, y)⟩q(ϑ)dt +
∫
H(ϑ)q(ϑ)dt, (15)
where V(ϑ) =⟨U(ϑ, y)⟩q(ϑ) is called the variational free energy (VFE).
The next sections will deal with two main assumptions used in DEM to simplify the
free energy objectives, namely the Laplace approximation and the mean-ﬁeld assumption.
The aim is to derive the simpliﬁed free energy objectives for an LTI system under these
assumptions.
5. Laplace Approximation
The ﬁrst common approach to simplify the free energy objective is to assume the
variational density q(ϑ) to be Gaussian in nature with variational parameters ϑ and Σθ
as its mode and covariance, respectively, [ 38]. Here, the inverse of Σϑ (denoted by Πϑ
and known as the conditional precision), represents the conﬁdence in estimation. The
recognition density takes the following form:
q(ϑ) =N(ϑ : µϑ, Σϑ) = 1√
(2π)n|Σϑ|
e−1
2 (ϑ−µϑ)T Πϑ(ϑ−µϑ). (16)
There are two main advantages with this approximation:
1. It simpliﬁes the internal energy expression U(ϑ, y),
2. It facilitates an easy computation of the conditional precisionΠϑ (derived inSection 7.2)
as the negative curvature of the internal energy at it’s modeµϑ.
Therefore, the main aim of this section is to simplify the expression for internal energy
U(ϑ, y) using the Laplace approximation, for an LTI system with its states, inputs, and
outputs expressed in generalized coordinates.
The internal energy in Equation (13) can be expressed as the sum of log-likelihood
and prior terms as:
U(ϑ, y) =ln p(ϑ, y) =ln p(y/ϑ)  
generative
model
+ ln p(ϑ)
prior
. (17)
The parameter set ϑ includes two types of parameters:
1. the states and inputs, which are time-varying and therefore expressed in generalized
coordinates,
2. the parameters and hyperparameters, which are time-invariant and not expressed in
generalized coordinates.
Equation (17) can be simpliﬁed by assuming the conditional independence of ˜x and ˜v with
θ and λ. This factorization separates the deterministic quantities from the stochastic ones,
thereby providing a separation of temporal scales. This is one of the core ideas behind DEM,
Entropy 2021, 23, 1306 8 of 32
which will be detailed in Section 6. With the redeﬁnition of ϑ = {˜x, ˜v, θ, λ}, Equation (17)
simpliﬁes to:
U(ϑ, y) =ln p(y/ ˜x, ˜v, θ, λ) +ln p( ˜x, ˜v, θ, λ)
= ln p(y/ ˜x, ˜v, θ, λ) +ln p( ˜x/ ˜v, θ, λ) +ln p( ˜v) +ln p(θ) +ln p(λ). (18)
DEM combines the new sensory information y coming from the environment with the
robot brain’s priors (refer to Figure 1) in a Bayesian fashion, through the internal energy
U(ϑ, y) expression given in Equation (18). The next sections will deal with simplifying
U(ϑ, y) and its action ¯U by ﬁrst modeling the probability distributions for the generative
model and the priors.
5.1. Generative Model
The probability distribution p(y/ ˜x, ˜v, θ, λ), given in Equation (18), represents the
generative model that predicts the output from the current parameter estimates. This
probability can be assumed to be Gaussian-distributed, centered around the model’s output
prediction ˜C ˜x (from Equation (3)), with the same uncertainty as that of the measurement
noise ˜Σz. The distribution p(y/ϑ) becomes:
p( ˜y/ϑ) = 1√
(2π)m(p+1)|˜Σz|
e−1
2 ( ˜y−˜C ˜x)T ˜Πz( ˜y−˜C ˜x). (19)
Since the robot cannot directly measure ˜x in Equation (3), we track the motion of the
generalized states through the approximation ˙˜x = ˜x′= Dx ˜x. The prediction for motion is
˜A ˜x + ˜B ˜v with an uncertainty of ˜Σw. The Gaussian distribution becomes:
p( ˜x′/ ˜x, ˜v, ϑ, λ) = 1√
(2π)n(p+1)|˜Σw|
e−1
2 (Dx ˜x−˜A ˜x−˜B ˜v)T ˜Πw(Dx ˜x−˜A ˜x−˜B ˜v). (20)
5.2. Prior Distributions
The remaining distributions p( ˜v), p(θ) and p(λ) are the priors of the robot brain that
can be transferred from prior (learned) experiences to the inference process. Similar to the
previous section, a Gaussian prior is placed over the inputs p( ˜v) =N( ˜v : η ˜v, L ˜v) as well,
with mean η ˜v and prior covariance L ˜v = (P ˜v)−1, as:
p( ˜v) = 1√
(2π)r(d+1)|L ˜v|
e−1
2 ( ˜v−η ˜v)T P ˜v( ˜v−η ˜v). (21)
The prior distribution of parameters θ ∈Rl is assumed to be a Gaussian-centred around
the prior parameter value ηθ, with the prior covariance Lθ = (Pθ)−1:
p(θ) =N(θ : ηθ, Lθ) = 1√
(2π)l|Lθ|
e−1
2 (θ−ηθ)T Pθ(θ−ηθ). (22)
Similarly, a Gaussian prior is placed over the hyperparameters λ ∈R2:
p(λ) =N(λ : ηλ, Lλ) = 1√
(2π)2|Lλ|
e−1
2 (λ−ηλ)T Pλ(λ−ηλ). (23)
A higher value of P ˜v, Pθ and Pλ represents the robot’s higher conﬁdence in its prior
estimates η ˜v, ηθ, and ηλ, respectively.
Entropy 2021, 23, 1306 9 of 32
5.3. Simpliﬁcation of the Internal Energy Action ¯U
This section aims at using the distributions from the previous sections to simplify ¯U.
The logarithm of a Gaussian prior after dropping constants takes the general form:
ln p(θ) =ln N(θ : ηθ, Lθ) =−1
2 (θ −ηθ)T(Lθ)−1(θ −ηθ) −1
2 ln |Lθ| (24)
Therefore, substituting Equations (19)–(23) in Equation (18) and simplifying it using the
prediction error terms ϵ ˜x = Dx ˜x − ˜A ˜x −˜B ˜v, ϵ˜y = ˜y −˜C ˜x, ϵ˜v = ˜v −η ˜v ϵθ = θ −ηθ, and
ϵλ = λ −ηλ, after dropping constants, yields:
U(ϑ, y) =−1
2 ϵθT Pθϵθ + 1
2 ln |Pθ|− 1
2 ϵλT Pλϵλ + 1
2 ln |Pλ|− 1
2 ˜ϵT ˜Π˜ϵ + 1
2 ln |˜Π|, (25)
where ˜ϵ =


ϵ˜y
ϵ˜v
ϵ ˜x

 =


˜y −˜C ˜x
˜v −η ˜v
Dx ˜x − ˜A ˜x −˜B ˜v

, and ˜Π = diag ( ˜Πz, P ˜v, ˜Πw). Here diag (., .) is
the block diagonal operator. Grouping the internal energy terms of the temporal and
nontemporal parameters yields:
U(ϑ, y) =U(t) +U(θ) +U(λ), (26)
where
U(t) =−1
2 ˜ϵT ˜Π˜ϵ + 1
2 ln |˜Π|. (27)
Summing up the internal energy of all the temporal parameters over time yields the action
of internal energy as follows:
¯U = U(θ) +U(λ) +∑
t
U(t)
= −1
2 ϵθT Pθϵθ + 1
2 ln |Pθ|− 1
2 ϵλT Pλϵλ + 1
2 ln |Pλ|−∑
t
1
2 ˜ϵT ˜Π˜ϵ + 1
2 ∑
t
ln |˜Π|.
(28)
It can be observed from Equation (28) that the robot’s priors(η ˜v, P ˜v, ηθ, Pθ, ηλ, Pλ) enter
the free energy objective through the internal energy term. Intuitively, this can be seen
as the direct inﬂuence of the robot’s prior beliefs on the inference process through the
mismatches in the robot’s predictions. These weighed prediction errors drive the robot’s
desire to maintain an equilibrium between its internal model and the generative process in
the environment. A large mismatch between the robot’s predictions and the data results in
a large prediction error, which gets precision-weighted and enters the free energy objective
through its internal energy.
6. Mean-Field Approximation
The second widely used assumption for the simpliﬁcation of free energy objectives
is the factorization of parameters into independent subdensities for the recognition den-
sity [18], given by:
q(ϑ) =∏
i
q(θi) =q( ˜x)q( ˜v)q(θ)q(λ). (29)
This approximation assumes the conditional independence between subdensities (states
and parameters, for example). The subdensities are assumed to interact with each other
only through the mean-ﬁeld quantities. The strong biological plausibility of this approx-
imation in terms of biological brain’s inference process is delineated in [ 27]. The main
advantage of this approximation is the simpliﬁcation of ¯V in Equation (15). However,
the mathematical proof for this simpliﬁcation is missing from the DEM literature [ 18].
Therefore, this section aims to ﬁll this gap by deriving these proofs by delineating all the
intermediate assumptions.
Entropy 2021, 23, 1306 10 of 32
6.1. Simpliﬁcation of the Entropy Action ¯H
The entropy of the density in Equation (14), given by H(ϑ)q(ϑ) = −⟨ln q(ϑ)⟩q(ϑ), can
be simpliﬁed for all parameters as:
H(ϑ)q(ϑ) = −
∫ ∫ ∫ ∫
q( ˜x, ˜v, θ, λ) ln q( ˜x, ˜v, θ, λ)d ˜xd ˜vdθdλ (30)
Substituting the mean-ﬁeld assumption given in Equation (29) in Equation (30) and using
the property of normalized recognition densities
∫
q(θi)dθi = 1 yields:
H(ϑ)q(ϑ) = H(θ) +H(λ) +H(t), (31)
where H(θ) = −⟨ln q(θ)⟩q(θ), H(λ) = −⟨ln q(λ)⟩q(λ) and H(t) = −⟨ln q( ˜x)⟩q( ˜x)−
⟨ln q( ˜v)⟩q( ˜v). We place the Laplace approximation over the marginals of the recognition
densities of all parameters as:
q(θ) =N(θ : µθ, Σθ) = 1√
(2π)l|Σθ|
e−1
2 (θ−µθ)T Πθ(θ−µθ)
q(λ) =N(λ : µλ, Σλ) = 1√
(2π)2|Σλ|
e−1
2 (λ−µλ)T Πλ(λ−µλ)
q( ˜x) =N( ˜x : µ ˜x, Σ˜x) = 1√
(2π)n(p+1)|Σ˜x|
e−1
2 ( ˜x−µ ˜x)T Π˜x( ˜x−µ ˜x)
q( ˜v) =N( ˜v : µ˜v, Σ˜v) = 1√
(2π)r(d+1)|Σ˜v|
e−1
2 ( ˜v−µ ˜v)T Π˜v( ˜v−µ ˜v).
(32)
The recognition densities given in Equation (32) might look similar to the priors distribu-
tions given in Equations (21)–(23), mainly due to the common Gaussian distribution. The
prior distributions are centered around the prior mean and prior covariances, whereas the
recognition density is centered around the mean µi and conditional covariance Σi of the
i-th parameter set.
The action of entropy can be calculated by substituting Equation (32) in Equation (31)
and summing up the entropy terms of time dependent parameters with respect to time.
Upon dropping the constant terms, it simpliﬁes to:
¯H = H(θ) +H(λ) +∑
t
H(t) =1
2 ln |Σθ|+ 1
2 ln |Σλ|+ 1
2 ∑
t
ln |Σ˜x|+ 1
2 ∑
t
ln |Σ˜v|, (33)
Equation (33) shows how the uncertainty in the robot’s inference directly enters the objec-
tive ¯F, through ¯H.
6.2. Mean-Field Terms
Given the simpliﬁed expressions for ¯U and ¯H, the next step towards ﬁnding ¯F in
Equation (15) is to evaluate ¯V given by:
¯V =
∫
⟨U(y, ϑ)⟩q(ϑ)dt (34)
U(y, ϑ) can be simpliﬁed using the second-degree Taylor series expansion near the mean
µϑ = {µ ˜x, µ˜v, µθ, µλ}as:
U(y, ˜x, ˜v, θ, λ) =U(y, µϑ) +
4
∑
i=1
U(y, µϑ)θi (θi −µi) +
4
∑
i=1
4
∑
j=1
(θi −µi)TU(y, µϑ)θiθj (θj −µj), (35)
where we use the shorthand U(y, µϑ) =U(y, ϑ)|ϑ=µϑ and U(y, µϑ)ϑ = U(y, ϑ)ϑ|ϑ=µϑ . This
approximation of the internal energy has nontrivial implications in terms of the biological
Entropy 2021, 23, 1306 11 of 32
brain’s decision-making process [21]. The second order approximation is justiﬁed because
the Laplace and mean-ﬁeld approximations entail an internal energy that is quadratic in ˜x,
˜v, and θ, as given in Equation (25), thereby reducing all its higher-order derivatives to zero.
Moreover, the higher derivatives ofU(y, µϑ) with respect to λ, reduce to zero because of the
assumptions made in Section 9. By differentiating Equation (25) at the mean µi, U(y, µϑ)θi
can be found to be all zeroes, which upon substitution in Equation (35) simpliﬁes to:
U(y, ϑ) =U(y, µϑ) +
4
∑
i=1
4
∑
j=1
(θi −µi)TU(y, µϑ)θiθj (θj −µj). (36)
Substituting it in Equation (34), upon simpliﬁcation yields:
¯V = ¯U(y, µϑ) +
∫
Wdt (37)
where
W = 1
2
4
∑
i,j=1
⟨(θi −µi)TU(y, µϑ)θiθj (θj −µj)⟩q(ϑi)q(ϑj)
= 1
2
4
∑
i,j=1
⟨tr
(
(θi −µi)TU(y, µϑ)θiθj (θj −µj)
)
⟩q(ϑi)q(ϑj)
= 1
2
4
∑
i,j=1
⟨tr
(
(θj −µj)(θi −µi)TU(y, µϑ)θiθj
)
⟩q(ϑi)q(ϑj)
= 1
2
4
∑
i,j=1
tr
[
⟨(θj −µj)(θi −µi)T⟩q(ϑi)q(ϑj)U(y, µϑ)θiθj
]
= 1
2
4
∑
i,j=1
tr
[
Σij U(y, µϑ)θiθj
]
Since the parameters ϑi are assumed to be independent of each other, the covariance
between them drops to zero, resulting in:
¯V = ¯U(y, µϑ) +1
2
∫ 4
∑
i=1
tr
[
ΣiU(y, µϑ)θiθi
]
dt
= ¯U(y, µϑ) +
∫ [
W ˜x + W ˜v + Wθ + Wλ]
dt,
(38)
where
Wϑi
= 1
2 tr
[
ΣiU(y, µϑ)θiθi
]
(39)
is deﬁned as the mean-ﬁeld term. Equation (38) shows that ¯V is the sum of internal energy
action and the mean ﬁeld terms. The simpliﬁcation of ¯V is one of the main advantages
of using mean-ﬁeld approximation. However, this approximation can be relaxed to build
Generalized Filtering [ 37,42], which is mainly relevant to nonlinear identiﬁcation. It
involves the modeling of parameters and hyperparameters in generalized coordinates
(together with states) for online system identiﬁcation. However, in this work, we take a
simpler approach.
7. Simpliﬁed Free Energy Objectives
This section aims at simplifying the free energy objectives using the results from
Sections 5 and 6.
Entropy 2021, 23, 1306 12 of 32
7.1. Simpliﬁcation of Free Action
¯F is simpliﬁed by substituting Equations(28), (33) and (38) into Equation (15), yielding:
¯F =−1
2(ϵθTPθϵθ)|ϑ=µϑ + 1
2 ln|Pθ|−1
2(ϵλTPλϵλ)|ϑ=µϑ + 1
2 ln|Pλ|−∑
t
1
2(˜ϵT ˜Π˜ϵ)|ϑ=µϑ
+ 1
2 ∑
t
(ln|˜Π|)|ϑ=µϑ + 1
2 ∑
t
(ln|Σ˜x|+ln|Σ˜v|) +1
2 ln|Σθ|+ 1
2 ln|Σλ|
+ 1
2 ∑
t
tr[Σ˜xU(y, µϑ)˜x˜x +Σ˜vU(y, µϑ)˜v˜v +ΣθU(y, µϑ)θθ +ΣλU(y, µϑ)λλ
].
(40)
We highlight three important terms in Equation (40): the combined prediction error of
(generalized) outputs, inputs, and states E = 1
2 (˜ϵT ˜Π˜ϵ)|ϑ=µϑ , the log determinant of noise
precision G = (ln |˜Π|)|ϑ=µϑ , and the mean ﬁeld term Wϑi
= 1
2 tr
[
ΣiU(y, µϑ)θiθi
]
. These
terms will be used rigorously in the rest of the document.
7.2. Simpliﬁcation of the Parameter Precisions
One of the main advantages of Laplace approximation is the simple evaluation of
the covariance associated with the parameter estimation. This is achieved by setting the
gradient of the free action with respect to individual parameter covariance as zero. The
free action gradients with respect to covariance of paramaters ϑi is given by:
∂ ¯F
∂Σi = ∂
∂Σi
(1
2 ln |Σi|+ 1
2 ∑
t
tr(ΣiU(y, µϑ)ϑiϑi ))
)
= 1
2
(
(Σi)−1 + ¯U(y, µϑ)ϑiϑi
)
. (41)
The optimal parameter covariance is the covariance that maximizes the free action with
zero gradients. Assuming that the parameter covariances are time-invariant, and equating
the gradients to zero yields Πi = −¯U(y, µϑ)ϑiϑi , resulting in:
Π˜x = −U(y, µϑ)˜x ˜x, Π˜v = −U(y, µϑ)˜v ˜v, Πθ = −¯U(y, µϑ)θθ , Πλ = −¯U(y, µϑ)λλ (42)
From Equation (42), it is clear that the precision of parameters can be estimated just by
evaluating the negative curvature of the internal energy at the conditional mode. These
precision values denote the conﬁdence of the estimator in the parameter estimate. Ideally,
the parameter precision increases as the estimation process proceeds. Intuitively, the robot
is more conﬁdent about its estimates (higher precision) when its predictions on the sensory
data show the least variance.
7.3. Free Action at Optimal Precision
Substituting Equation (42) into Equation (39) at optimal precisions results in constant
mean ﬁeld terms. Therefore, the mean ﬁeld terms in the free action given in Equation (40),
reduces to a constant under the optimal precision given by Equation (42). Therefore, the
free action at optimal precision for an LTI system reduces to:
¯F =−1
2 ∑
t
[
(˜y−˜C˜x)T ˜Πz(˜y−˜C˜x)
⏐⏐⏐ϑ=µϑ
  
prediction error of outputs
+ (˜v −η˜v)TP˜v(˜v −η˜v)
⏐⏐⏐ϑ=µϑ
  
prediction error of inputs
]
−1
2 (θ −ηθ)TPθ(θ −ηθ)
⏐⏐⏐ϑ=µϑ
  
prediction error of parameters
−1
2 (λ−ηλ)TPλ(λ−ηλ)
⏐⏐⏐ϑ=µϑ
  
prediction error of hyperparameters
−1
2 ∑
t
(Dx ˜x −˜A˜x −˜B˜v)T ˜Πw(Dx ˜x −˜A˜x −˜B˜v)
⏐⏐⏐ϑ=µϑ
  
prediction error of (generalized) states
+ 1
2nt ln|ΣX|
  
state and input entropy
+ 1
2nt [ln|˜Πz|+ln|P˜v|+ln|˜Πw|]⏐⏐⏐ϑ=µϑ
  
noise entropy
+ 1
2 ln|ΣθPθ|
  
parameter entropy
+ 1
2 ln|ΣλPλ|
  
hyperparameter entropy
(43)
Entropy 2021, 23, 1306 13 of 32
Note that the free action is not a function of the latent variables (ϑ = {˜x, ˜v, θ, λ}) but the
sufﬁcient statistics (µϑ, Σϑ) of the approximate posterior. For example, the weighted output
prediction error term of ¯F is (˜y − ˜C ˜x)T ˜Πz(˜y − ˜C ˜x)
⏐⏐⏐ϑ=µϑ = (˜y −µ ˜Cµ ˜x)T ˜Πz
⏐⏐⏐λz=µλz (˜y −
µ ˜Cµ ˜x), where
⏐⏐⏐ϑ=µϑ denotes the evaluation at ϑ = µϑ, ( ˜x = µ ˜x, ˜v = µ˜v, θ = µθ, λ = µλ). We
regroup the time-dependent components into one variableX =
[µ ˜x
µ˜v
]
, and use capital letters
for the mean estimates of time-independent components (Θ = µθ, Λ = µλ). Note that X, Θ,
and Λ are part of the generative model and are the mean estimate of the components of
plant dynamics.
7.4. Equivalence with the EM Algorithm
One of the most popular approaches to solve the Expectiation Maximization (EM)
algorithm for state space models is to use the Maximum Likelihood Estimation (MLE),
where the objective function is the log-likelihood of data, given by [43]:
ln L = −1
2 ∑
t
(xt −Axt−1 −But−1)TΠw(xt −Axt−1 −But−1) −nt
2 ln |Σw|
−nt
2 ln |Σz|− 1
2 ln |Σx|− 1
2 (x0 −µ)TΠx(x0 −µ) −1
2 ∑
t
(yt −Cxt)TΠz(yt −Cxt).
(44)
Comparing the objective functions of EM and DEM given by Equation(44) and Equation (43),
respectively, DEM is equivalent to EM when:
• the mean ﬁeld terms are neglected,
• the generalized motion is not considered, and
• the robot’s priors on ϑ are not considered.
Therefore, DEM can be considered as a generalized version of the EM algorithm with
additional capabilities.
The free action at optimal precision (Equation (43)) is the sum of prediction errors
(PE) and entropy of generalized states, parameters, noise, and hyperparameters and is
independent of mean-ﬁeld terms. Although the mean-ﬁeld terms turns into a constant at
optimal precision, their gradients do not. This property is leveraged in Section 8 to account
for the uncertainties in the parameter estimation during state estimation and vice versa,
through the gradient of mean-ﬁeld terms.
8. Update Rules for Estimation
The Free Energy objectives (Section 4), together with the two simplifying approxi-
mations (Sections 5 and 6), will be combined with an optimization procedure to form the
ultimate DEM algorithm. The optimization procedure itself consists of the following two
sets of update rules:
1. a gradient ascent over its free action ¯F for the time invariant parameters θ and λ,
2. a gradient ascent over its free energy F for the time varying parameters X,
where F and ¯F are related throughF = ∂ ¯F
∂t . The core idea is that the time varying parameters
˜x and ˜v can be estimated online from the robot’s instantaneous free energy, whereas the
time-invariant parameters θ and λ can be estimated from its free action after observing a
sequence of data. Accordingly, the update rules for both the gradient ascends are given by
∂µi
∂a = ki ∂ ¯F
∂µi , (45)
for the ath parameter update of the time invariant parameters and
∂µi
∂t = Dµi + ki ∂F
∂µi , (46)
Entropy 2021, 23, 1306 14 of 32
for the time=varying parameters, where ki is the learning rate. The presence of Dµi
term in Equation (46) differentiates the update rule from the general gradient ascent
equation used in machine learning. This is to accommodate the boundary condition that
when F is maximized, ∂F
∂µi = 0 and ˙µi = Dµi. In other words, when the free energy is
maximized, the motion of the generalized states becomes their generalized motion [ 44].
However, the update equations for the time-invariant parameters, θ and λ, do not require
the Dµi term. Therefore, the update equations at tth time, ath parameter update step, and
bth hyperparameter update step, after regrouping the (generalized) states and inputs as
X =
[µ ˜x
µ˜v
]
, is given by:
∂X
∂t = DX + kX ∂F
∂X , ∂Θ
∂a = kΘ ∂ ¯F
∂Θ, ∂Λ
∂b = kΛ ∂ ¯F
∂Λ, (47)
where D = diag (Dx, Dv). Note that the gradient update rules are written not on the latent
variables ( ˜x, ˜v, θ and λ), but on their mean estimates (X, Θ and Λ). Since the update rules
should be implemented in the discrete domain for robotics applications, Equation (47)
is discretized under local linearization with the corresponding Jacobians as JX = D +
kX ∂2 F
∂X2 , JΘ = kΘ ∂2 ¯F
∂Θ2 , and JΛ = kΛ ∂2 ¯F
∂Λ2 . The (generalized) state and input update at time t,
parameter update at step a and hyperparameter update at step b are given by:
Xt+∆t = Xt +
(
eJX ∆t −I
)
(JX)−1 ∂X
∂t ,
Θa+1 = Θa +
(
eJΘ
−I
)
(JΘ)−1 ∂Θ
∂a ,
Λb+1 = Λb +
(
eJΛ
−I
)
(JΛ)−1 ∂Λ
∂b .
(48)
Equation (48) shows that the update rules are dependent only on the gradients and curva-
tures of the free energy objectives.
8.1. The DEM Algorithm
The DEM algorithm is an iterative model inversion algorithm that uses Equations (42)
and (48) to perform estimation on causal dynamic systems. It can be expressed using
three steps:
1. D step: (generalized) state and input estimation,
2. E step: parameter estimation,
3. M step: noise hyperparameter estimation,
a nomenclature that is similar to the EM algorithm. Figure 2 shows an intuitive block
diagram that demonstrates the inference process of DEM as a coupled dynamics between
D, E, and M steps. The data from the environment and the robot brain’s prior distributions
are used to infer the generative process. The pseudocode given in Algorithm 1 demon-
strates how DEM performs estimation using only the gradient and curvatures of the free
energy objectives. The next sections will focus on deriving the algebraic expressions for
these quantities.
Entropy 2021, 23, 1306 15 of 32
Figure 2. The DEM algorithm is represented using three coupled steps: D, E, and M steps. The
algorithm combines the data from the environment with the robot’s prior beliefs to infer the states,
inputs, parameters and hyperparameters of the system. For each parameter update in the E step,
the D step updates the (generalized) states and inputs for all times instances, and the M step
iterates until hyperparameter convergence, as demonstrated in Algorithm 1. The dynamic process
is the generative model in Section 3.1, the priors are the distributions given in Section 5.2 and the
generalized coordinates block is deﬁned in Section 3.4. Section 13 will elaborate on the D, E, and
M blocks.
8.2. Updated Equations for Estimation
The free energy gradients in Equation (47) can be evaluated by differentiating
Equation (40) with µi. Substituting the resulting expression in Equation (47), upon simpliﬁ-
cation yields:
˙X = DX + kX
[
−EX + WX
X + WΘ
X + WΛ
X
]
∂Θ
∂a = kΘ
[
−Pθϵθ
⏐⏐⏐ϑ=µϑ + ∑
t
(
−EΘ + WX
Θ + WΘ
Θ + WΛ
Θ
)]
∂Λ
∂b = kΛ
[
−Pλϵλ
⏐⏐⏐ϑ=µϑ + ∑
t
(−EΛ + WX
Λ + WΘ
Λ + WΛ
Λ + GΛ)
]
,
(49)
where Eµi = ∂E
∂µi = 1
2
∂(˜ϵT ˜Π˜ϵ)
⏐⏐⏐ϑ=µϑ
∂µi is the gradient of the prediction error with respect to
µi, Wµi
µj = ∂Wµi
∂µj = 1
2
∂
∂µj tr
[
ΣiU(y, µϑ)µiµi
]
is the gradient of the mean ﬁeld term of µi with
respect to µj, and GΛ = 1
2
∂
∂Λ ln |˜Π|
⏐⏐⏐ϑ=µϑ is the gradient of the log-determinant of the
precision matrix with respect to Λ. From Equation (49), the Jacobians that are required for
the updates given in Equation (48) can be evaluated as:
JX = D + kX
[
−EXX + WX
XX + WΘ
XX + WΛ
XX
]
JΘ = kΘ
[
−Pθ + ∑
t
(
−EΘΘ + WX
ΘΘ + WΘ
ΘΘ + WΛ
ΘΘ
)]
JΛ = kΛ
[
−Pλ + ∑
t
(
−EΛΛ + WX
ΛΛ + WΘ
ΛΛ + WΛ
ΛΛ + GΛΛ
)]
(50)
The Jacobians are employed in different loops corresponding to the D, E, and M steps in
the Algorithm 1.
Entropy 2021, 23, 1306 16 of 32
Algorithm 1: Dynamics Expectation Maximization
Data: Time series data of output y
Result: X, Θ, Λ, Π˜x, ˜v, Πθ, Πλ
a = 0;
while Θ not converged do
for t = 0:∆t:T do ⊿ D step
∂X
∂t = DX + kX ∂F
∂X ;
JX = D + kX ∂2 F
∂X2 ;
Xt+∆t = Xt + (eJX ∆t −I)(JX)−1 ∂X
∂t ;
end
while Λ not converged do ⊿ M step
∂Λ
∂b = kΛ ∂ ¯F
∂Λ ;
JΛ = kΛ ∂2 ¯F
∂Λ2 ;
Λ ← −Λ + (eJΛ
−I)(JΛ)−1 ∂Λ
∂b ;
end
¯Fa ← −Equation (43) ⊿ ¯F at optimal precision
if ¯Fa > ¯Fa−1 then ⊿ update Θ if ¯F increased
∂Θ
∂a = kΘ ∂ ¯F
∂Θ ;
JΘ = kΘ ∂2 ¯F
∂Θ2 ;
Θ ← −Θ + (eJΘ
−I)(JΘ)−1 ∂Θ
∂a ; ⊿ E step
end
a++ ;
Π˜x, ˜v = −U(y, µϑ)[˜x
˜v
][˜x
˜v
]; ⊿ update generalized state precision
Πθ = −¯U(y, µϑ)θθ ; ⊿ parameter precision
Πλ = −¯U(y, µϑ)λλ ; ⊿ hyperparameter precision
end
8.3. Update Equation for Precision of Estimates
The uncertainty in estimation is represented by the inverse of precision matrices Πϑi
.
Differentiating Equations (25) and (28) twice and substituting it into Equation (42) upon
simpliﬁcation yield:
Π˜x, ˜v = −U(y, µϑ)[˜x
˜v
][˜x
˜v
]= EXX
Πθ = −¯U(y, µϑ)θθ = Pθ + ∑
t
EΘΘ
Πλ = −¯U(y, µϑ)λλ = Pλ + ∑
t
(
EΛΛ −GΛΛ)
)
(51)
The only unknowns in the DEM update equations given by Equations (49)–(51) are the
gradients and curvatures of E, W, and G. Sections 9–11 will deal with evaluating the simpli-
ﬁed algebraic expressions for these gradients and curvatures. Using these simpliﬁcations,
Section 12 will proceed towards expanding Algorithm 1.
9. Gradients of (Log Determinant of) Precision
This section aims at evaluating the gradients of the log determinant of noise precision
(GΛ, GΛΛ) that are required for the hyperparameter update rules of the DEM algorithm.
The precision matrix for hyperparameter estimation is modeled as:
˜Π = diag ( ˜Πz, P ˜v, ˜Πw) =diag (eλz
(S ⊗Ωz), P ˜v, eλw
(S ⊗Ωw)), (52)
Entropy 2021, 23, 1306 17 of 32
where S is the noise smoothness matrix given by Equation (7) and Ωz, Ωw are the constant
matrices given in Equation (6). Here the precision matrix is parametrized using λ =
[λz
λw
]
,
which is the only unknown in Equation (52). Therefore, the log determinant of precision
and its gradients can be written as:
G = ln |˜Π|
⏐⏐⏐ϑ=µϑ , GΛ = 1
2
[tr( ˜Πλz ˜Π−1)
tr( ˜Πλw ˜Π−1)
]⏐⏐⏐ϑ=µϑ ,
GΛiΛj = 1
2 tr( ˜Πλiλj ˜Π−1 −˜Πλi ˜Π−1 ˜Πλj ˜Π−1)
⏐⏐⏐ϑ=µϑ ,
(53)
where λi is the ith element in λ. The gradients of precision in Equation(53) can be evaluated
by differentiating Equation (52) as:
˜Πλz = diag (eλz
(S ⊗Ωz), O, O) =diag ( ˜Πz, O, O),
˜Πλw = diag (O, O, eλw
(S ⊗Ωz)) =diag (O, O, ˜Πz),
˜Πλzλw = O, ˜Πλwλz = O.
(54)
Substituting Equations (52) and (54) in Equation (53) yields:
GΛ = 1
2
[tr(In ˜Πz )
tr(In ˜Πw )
]
= 1
2
[
n ˜Πz
n ˜Πw
]
, (55)
where In ˜Πz is the identity matrix of size n ˜Πz
, which is the size of the ˜Πz matrix. Πw
and Πz are modeled to have an exponential relation with λ, so that any updates on λ
would result in positive semi-deﬁnite precision matrices. However, this relation entails an
inﬁnitely differentiable precision matrix with respect to λ, increasing the computational
complexity of the algorithm. Therefore, an approximation is made by forcefully setting
˜Πλzλz = ˜Πλwλw = O, while maintaining the exponential relation between ˜Π and λ, thereby
ensuring that the optimization process proceeds along the correct gradients ˜Πλ. Together
with Equation (54), this approximation results in ˜Πλλ = O. This assumption has two
direct consequences:
• It simpliﬁes all the update rules given in Equations (49) and (50),
• It simpliﬁes the precision update rule for hyperparameters given in Equation (51).
A direct consequence of this approximation is in the simpliﬁcation of GΛΛ in Equation (53),
expressed as:
GΛΛ = −1
2
[tr( ˜Πλz ˜Π−1 ˜Πλz ˜Π−1) tr( ˜Πλz ˜Π−1 ˜Πλw ˜Π−1)
tr( ˜Πλw ˜Π−1 ˜Πλz ˜Π−1) tr( ˜Πλw ˜Π−1 ˜Πλw ˜Π−1)
]⏐⏐⏐ϑ=µϑ , (56)
which upon substitution of Equations (52) and (54) yields:
GΛΛ = −1
2
[tr(In ˜Πz ) O
O tr (In ˜Πw )
]
= −1
2
[
n ˜Πz
O
O n ˜Πw
]
, (57)
where n ˜Πz
= m(p + 1) and n ˜Πw
= n(p + 1) are the sizes of ˜Πz and ˜Πw, respectively.
From Equations (55) and (57), GΛ and GΛΛ are constants, and can be pre-computed in
Algorithm 1.
10. Gradients of Prediction Error
As opposed to the result above, the gradients of the prediction errors are not constant,
as is shown in this section.
Entropy 2021, 23, 1306 18 of 32
10.1. Gradients of Prediction Error Along (Generalized) States
The error in prediction of (generalized) outputs, inputs and states is represented
together by ˜ϵ, which makes up the precision weighted prediction error deﬁned by E =
1
2 ˜ϵT ˜Π˜ϵ
⏐⏐⏐ϑ=µϑ , where ˜Π = diag ( ˜Πz, P ˜v, ˜Πw). The error and its gradient are:
˜ϵ =


˜y −˜C ˜x
˜v −η ˜v
Dx ˜x − ˜A ˜x −˜B ˜v

, ˜ϵX
⏐⏐⏐ϑ=µϑ =


−˜C O
O I
Dx − ˜A −˜B

. (58)
The gradient of prediction error with respect to X can be simpliﬁed as:
EX = ˜ϵT
X ˜Π˜ϵ
⏐⏐⏐ϑ=µϑ = A1X + B1
[ ˜y
−η ˜v
]
, (59)
where A1 =
[˜CT ˜Πz ˜C + (Dx − ˜A)T ˜Πw(Dx − ˜A) −(Dx − ˜A)T ˜Πw ˜B
−˜BT ˜Πw(Dx − ˜A) P ˜v + ˜BT ˜Πw ˜B
]⏐⏐⏐ϑ=µϑ and
B1 =
[−˜CT ˜Πz O
O P ˜v
]⏐⏐⏐ϑ=µϑ . Since EX is linear in X, differentiating Equation (59) with
respect to X yields a simple expression for curvature EXX as:
EXX = ˜ϵTX ˜Π˜ϵX
⏐⏐⏐ϑ=µϑ =
[˜CT ˜Πz ˜C+ (Dx −˜A)T ˜Πw(Dx −˜A) −(Dx −˜A)T ˜Πw ˜B
−˜BT ˜Πw(Dx −˜A) P˜v + ˜BT ˜Πw ˜B
]⏐⏐⏐ϑ=µϑ . (60)
10.2. Gradients of Prediction Error Along Parameters
To evaluate the gradients of prediction error along the parametersΘ, the reformulated
deﬁnition of ˜ϵ is used:
˜ϵ =


˜y −Nθ
˜v −η ˜v
Dx ˜x −Mθ

, ˜ϵΘ = (˜ϵθ)|θ=µθ =


−N
O
−M

, (61)
where M and N are given in Equation (5). This is to ensure that the variable Θ can be
separated out of the expression for EΘ such that it is linear in Θ as follows:
EΘ = (˜ϵT
θ ˜Π˜ϵ)|ϑ=µϑ = −
[
NT O M T]˜Π


˜y −Nθ
˜v −˜η
Dx ˜x −Mθ


⏐⏐⏐ϑ=µϑ
= (NT ˜Πz N + MT ˜Πw M)
⏐⏐⏐ϑ=µϑ Θ −
[
NT ˜Πz MT ˜ΠwDx]⏐⏐⏐ϑ=µϑ
[˜y
µ ˜x
]
= A2Θ −B2
[˜y
µ ˜x
]
.
(62)
Since EΘ is linear in Θ, differentiating Equation (62) with respect to Θ yields a simple
expression for EΘΘ as:
EΘΘ = (˜ϵT
θ ˜Π˜ϵθ)
⏐⏐⏐ϑ=µϑ =
[
NT ˜Πz N + MT ˜Πw M
]⏐⏐⏐ϑ=µϑ = A2. (63)
10.3. Gradients of Prediction Error Along Hyperparameters
The gradients of prediction error along the hyperparameters Λ is simpler, and is given
by EΛ = 1
2 ˜ϵT ˜Πλ ˜ϵ
⏐⏐⏐ϑ=µϑ , EΛΛ = 1
2 ˜ϵT ˜Πλλ ˜ϵ
⏐⏐⏐ϑ=µϑ , which upon using ˜Πλλ = 0, gives:
EΛ = 1
2 tr( ˜Πλ ˜ϵ˜ϵT)
⏐⏐⏐ϑ=µϑ = 1
2
[ tr( ˜Πz(˜y −˜C ˜x)(˜y −˜C ˜x)T)
tr( ˜Πw(Dx ˜x − ˜A ˜x −˜B ˜u)(Dx ˜x − ˜A ˜x −˜B ˜u)T)
]⏐⏐⏐ϑ=µϑ ,
EΛΛ = 1
2 ˜ϵT ˜Πλλ ˜ϵ
⏐⏐⏐ϑ=µϑ = 0.
(64)
Entropy 2021, 23, 1306 19 of 32
In summary, Equations (59), (62) and (64) represent the gradients of the prediction error
term, whereas Equations (60), (63) and (64) represent its curvatures. The next section will
deal with evaluating the analytic expressions for all the gradients and curvatures of the
mean ﬁeld term.
11. Gradients of Mean Field Terms
This section aims to derive the analytic expressions for the mean ﬁeld terms and their
gradients: Wµi
µj and Wµi
µjµj , ∀µ ∈{X, Θ, Λ}.
11.1. Gradients of Mean Field Terms along Hyperparameters
In this section, we prove that all the gradients and curvatures of WΛ (namely WΛ
µi and
WΛ
µiµi ) are zeroes. The mean ﬁeld term for hyperparameters Λ can be expressed as:
WΛ = 1
2 tr
[
ΣλU(y, µϑ)λλ
]
. (65)
To compute the gradients of WΛ, we need the curvature of internal energy with respect
to λ. This can be evaluated by ﬁrst differentiating Equation (25) with respect to λ and
evaluating it at ϑ = µϑ, which yields:
U(y, µϑ)λ = U(y, ϑ)λ
⏐⏐⏐ϑ=µϑ = −Pλϵλ
⏐⏐⏐ϑ=µϑ −1
2 (˜ϵT ˜Πλ ˜ϵ)
⏐⏐⏐ϑ=µϑ + GΛ, (66)
where GΛ is given by Equation (55). Upon further differentiation, we get:
U(y, µϑ)λλ = −Pλ −1
2 (˜ϵT ˜Πλλ ˜ϵ)
⏐⏐⏐ϑ=µϑ + GΛΛ. (67)
The assumption of ˜Πλλ = 0 applied to Equation (67) yields:
U(y, µϑ)λλ = −Pλ + GΛΛ (68)
which contains only constants. Therefore, the assumption of ˜Πλλ = 0 reduces all the
gradients and curvatures of mean ﬁeld terms of Λ to zeros:
WΛ
µi = 1
2 tr
[
ΣλU(y, µϑ)λλµi
]
= 0, WΛ
µiµi = 0. (69)
Since the internal energy given in Equation (25) is quadratic in ϑi, and since ˜Πλλ = 0, all
the gradients and curvatures of the mean ﬁeld term of ϑi with respect to itself are zeros:
Wµi
µi = 1
2 tr
[
Σϑi
U(y, µϑ)ϑiϑiµi
]
= 0, Wµi
µiµi = 0. (70)
11.2. Gradients of Mean Field Terms Along Generalized States
The mean-ﬁeld term of the combined generalized states X can be expressed as:
WX = 1
2 tr
[
ΣXU(y, µϑ)XX
]
. (71)
The curvature of internal energy with respect to X can be calculated by differentiating
Equation (25) with respect to X twice, resulting in U(y, µϑ)XX = −1
2 ˜ϵT
X ˜Π˜ϵX. Substituting it
in Equation (71) upon differentiation with Θ yields:
Entropy 2021, 23, 1306 20 of 32
WX
Θi = −1
2tr(ΣX ˜ϵT
Xθi ˜Π˜ϵX)
⏐⏐⏐ϑ=µϑ = −1
2tr
(
ΣX
[
−˜CT
θi O −˜AT
θi
O O −˜BT
θi
]
˜Π


−˜C O
O I
Dx −˜A −˜B

)⏐⏐⏐ϑ=µϑ
= −1
2tr
[
ΣX
[˜CT
θi ˜Πz ˜C−˜AT
θi ˜Πw(Dx −˜A) ˜AT
θi ˜Πw ˜B
−˜BT
θi ˜Πw(Dx −˜A) ˜BT
θi ˜Πw ˜B
]]⏐⏐⏐ϑ=µϑ ,
(72)
where the gradient of the mean ﬁeld with respect to Θ is given by
WX
Θ =
[
WX
Θ1 WX
Θ2 . . . WX
Θi
]T
. Similarly, the elements of the curvature matrix of the
mean ﬁeld term with respect to Θ is given by:
WX
ΘiΘj = −1
2tr(ΣX ˜ϵT
Xθi ˜Π˜ϵXθj )
⏐⏐⏐ϑ=µϑ = −1
2tr[ΣX
[˜CT
θi ˜Πz ˜Cθj + ˜AT
θi ˜Πw ˜Aθj ˜AT
θi ˜Πw ˜Bθj
˜BT
θi ˜Πw ˜Aθj ˜BT
θi ˜Πw ˜BT
θj
]]⏐⏐⏐ϑ=µϑ . (73)
The gradient and curvature of the mean ﬁeld term of X with respect to Λ can be evalu-
ated as:
WX
Λ = −1
2tr(ΣX ˜ϵTX ˜Πλ˜ϵX)
⏐⏐⏐ϑ=µϑ = −1
2tr( ˜Πλ˜ϵXΣX ˜ϵTX)
⏐⏐⏐ϑ=µϑ
= −1
2
[ tr(˜Πz ˜CΣx ˜CT)
tr( ˜Πw[
(Dx−˜A), −˜B
]ΣX[(Dx−˜A)T
−˜BT
])
]⏐⏐⏐ϑ=µϑ
WX
ΛΛ = −1
2tr( ˜Πλλ˜ϵXΣX ˜ϵTX)
⏐⏐⏐ϑ=µϑ = 0,
(74)
where Σx is a component of ΣX =
[Σ˜x Σ˜x ˜v
Σ˜x ˜v Σ˜v
]
. Here the curvature WX
ΛΛ vanishes due to the
assumption that ˜Πλλ = 0.
11.3. Gradients of Mean Field Terms Along Parameters
The mean-ﬁeld term of the parameters Θ can be expressed as
WΘ = 1
2 tr
[
ΣθU(y, µϑ)θθ
]
= 1
2 tr
[
Σθ(−Pθ −˜ϵT
θ ˜Π˜ϵθ)
]⏐⏐⏐ϑ=µϑ . (75)
Differentiating Equation (75) with X and substituting Equation (61) in it yields the gradi-
ent as:
WΘ
X = −1
2


tr
(
Σθ
(
NT
X1 ˜Πz N + MT
X1 ˜Πw M
))
tr
(
Σθ
(
NT
X2 ˜Πz N + MT
X2 ˜Πw M
))
. . .


⏐⏐⏐ϑ=µϑ , (76)
and the elements of the curvature matrix as:
WΘ
Xi Xj = −1
2 tr
(
Σθ(
NT
Xi ˜Πz NXj + MT
Xi ˜Πw MT
Xj
))⏐⏐⏐ϑ=µϑ . (77)
Differentiating Equation (75) with respect to λ yields the gradient and curvature as:
WΘ
Λ = −1
2 tr(Σθ ˜ϵT
θ ˜Πλ ˜ϵθ)
⏐⏐⏐ϑ=µϑ = −1
2 tr( ˜Πλ ˜ϵθΣθ ˜ϵT
θ )
⏐⏐⏐ϑ=µϑ ,
= −1
2
[tr( ˜Πλz ˜ϵθΣθ ˜ϵT
θ )
tr( ˜Πλw ˜ϵθΣθ ˜ϵT
θ )
]⏐⏐⏐ϑ=µϑ = −1
2
[tr( ˜Πz NΣθ NT )
tr( ˜Πw MΣθ MT )
]⏐⏐⏐ϑ=µϑ
WΘ
ΛΛ = −1
2 tr( ˜Πλλ ˜ϵθΣθ ˜ϵT
θ )
⏐⏐⏐ϑ=µϑ = 0.
(78)
Here, WΘ
ΛΛ vanishes due to the assumption that ˜Πλλ = 0.
12. The Complete DEM Algorithm
By combining the gradients found from Sections 9, 10, and 11 with the Algorithm 1,
we can ﬁnalize the full DEM algorithm so that it can iteratively compute the estimates and
the associated precisions from data.
Entropy 2021, 23, 1306 21 of 32
12.1. DEM Estimates
The main equations that are required to perform the update rules of DEM given in
Equation (48) can be summarized as:
˙X = DX+kX(−EX +WΘ
X ), JX = D+kX(−EXX +WΘ
XX)
∂Θ
∂a = kΘ
[
−Pθϵθ
⏐⏐⏐ϑ=µϑ +∑
t
(
−EΘ +WX
Θ
)]
, JΘ = kΘ
[
−Pθ +∑
t
(
−EΘΘ+WX
ΘΘ
)]
∂Λ
∂b = kΛ
[
−Pλϵλ
⏐⏐⏐ϑ=µϑ +∑
t
(−EΛ +WX
Λ +WΘ
Λ +GΛ)
]
, JΛ = kΛ(−Pλ +ntGΛΛ)
(79)
where EX, EXX , EΘ, EΘΘ, EΛ, WΘ
X , WΘ
XX , WX
Θ, WX
ΘΘ, WX
Λ , WΘ
Λ , GΛ, andGΛΛ are given by
Equations (55), (57), (59), (60), (62)–(64), (72)–(74), (76)–(78), respectively. The hyperpa-
rameter update rule can be further simpliﬁed to reduce the computational complexity as:
∂Λ
∂b = −kΛPλϵλ
⏐⏐⏐ϑ=µϑ + kΛnt
2
[
n ˜Πz
n ˜Πw
]
−kΛ
2
[tr( ˜Πz A3)
tr( ˜ΠwB3)
]⏐⏐⏐ϑ=µϑ (80)
where
A3 = ∑
t
(
(˜y −˜C ˜x)(˜y −˜C ˜x)T + NΣθ NT + ˜CΣ˜x ˜x ˜CT)
B3 = ∑
t
(
(Dx ˜x − ˜A ˜x −˜B ˜u)(Dx ˜x − ˜A ˜x −˜B ˜u)T + MΣθ MT +
[
(Dx−˜A), −˜B
]
ΣX[(Dx−˜A)T
−˜BT
])
.
Substituting Equation (57) to the expression for JΛ in Equation (79) yields:
JΛ = −kΛ(Pλ + nt
2
[
n ˜Πz
O
O n ˜Πw
]
), (81)
which is independent of Λ. This reduces the algorithm’s computational complexity, asJΛ
can now be pre-computed.
12.2. Precision of Estimates
This section simpliﬁes the precision for DEM’s estimates for an LTI system. The
conﬁdence in the estimate of (generalized) states and inputs can be simpliﬁed using
Equations (51) and (60) as:
Π˜x, ˜v = EXX =
[˜CT ˜Πz ˜C + (Dx − ˜A)T ˜Πw(Dx − ˜A) −(Dx − ˜A)T ˜Πw ˜B
−˜BT ˜Πw(Dx − ˜A) P ˜v + ˜BT ˜Πw ˜B
]⏐⏐⏐ϑ=µϑ . (82)
From Equation(82), the precisions for state and input estimation areΠ˜x ˜x = ˜CT ˜Πz ˜C + (Dx −
˜A)T ˜Πw(Dx − ˜A) and Π˜v ˜v = P ˜v + ˜BT ˜Πw ˜B, respectively. The cross-correlation between the
(generalized) states and inputs are given by −˜BT ˜Πw(Dx − ˜A). Since Π˜x, ˜v is independent
of X, it can be updated outside the D step.
Combining the results of Equations (51) and (63) yields the precision of parameter
estimates Πθ, which is independent of Θ, as:
Πθ = Pθ + ∑
t
EΘΘ = Pθ + ∑
t
[
NT ˜Πz N + MT ˜Πw M
]⏐⏐⏐ϑ=µϑ . (83)
From Equations (51), (57) and (64), the precision of hyperparameter estimation is:
Πλ = Pλ + ∑
t
(
EΛΛ −GΛΛ)
)
= Pλ + nt
2 diag (n ˜Πz
, n ˜Πw
), (84)
which is a constant and hence is never updated in the algorithm. In conclusion, the
estimation using Equation (79), along with the precision of these estimates given by
Equations (82)–(84) completely deﬁne the DEM algorithm for an LTI system with col-
ored noises. The complete DEM algorithm is given in Algorithm 2.
Entropy 2021, 23, 1306 22 of 32
Algorithm 2: Dynamics Expectation Maximization
Data: Time series data of output y
Result: (X, Θ, Λ), (Π˜x, ˜v, Πθ, Πλ)
a = 0;
Evaluate ˜y from y ⊿ Equation (9)
Precompute gradients ˜Aθi , ˜Bθi , ˜Cθi , NXi , MXi ;
Set all priors: η ˜v, P ˜v, ηθ, Pθ, ηλ, Pλ ;
Initialize Θ, Λ, ΠX, Πθ, Πλ with their priors ;
GΛ, GΛΛ ← −Equation (55) and (57) ;
Πλ ← −Pλ −ntGΛΛ ;
JΛ ← −kΛ(
−Pλ + ntGΛΛ
)
;
while Θ not converged do ⊿ E step loop
Set EΘ, EΘΘ, E1 to zero ;
WΘ
XX ← −f indWΘ
XX (NX, MX, ˜Π, Πθ) ; ⊿ Equation (77)
EXX ← −f indEXX (A, B, C, ˜Π) ; ⊿ Equation (60)
JX ← −D + kX(−EXX + WΘ
XX );
for t = 0:∆t:T do ⊿ D step loop
// Perform D step ;
WΘ
X ← −Equation (76) ;
EX ← −Equation (59) ;
∂X
∂t ← −DX + kX(−EX + WΘ
X );
Xt+∆t ← −Xt + (eJX ∆t −I)(JX)−1 ∂X
∂t ;
// Accumulate terms for E step ;
M, N ← −Equation (5); ⊿ use new X
A2, B2 ← −Equation (62) ;
EΘ ← −EΘ + A2Θ −B2
[ ˜y
µ ˜x
]
;
EΘΘ ← −EΘΘ + A2 ;
// Accumulate terms for M step ;
˜ϵ, ˜ϵX, ˜ϵΘ ← −Equation (58), (61) ;
E1 ← −E1 + ˜ϵ˜ϵT + ˜ϵXΣX ˜ϵT
X + ˜ϵΘΣθ ˜ϵT
Θ;
end
while Λ not converged do ⊿ M step loop
∂Λ
∂b ← −kΛ(
−Pλϵλ + GΛ −1
2
[tr( ˜Πλz E1)
tr( ˜Πλw E1)
])
;
Λ ← −Λ + (eJΛ
−I)(JΛ)−1 ∂Λ
∂b ;
˜Π ← −Equation (52) ; ⊿ update with new Λ
end
¯Fa ← −f ind ¯F(X, ΠX, Θ, Πθ, Λ, Πλ) ; ⊿ Equation (43)
if ¯Fa > ¯Fa−1 then ⊿ update Θ if ¯F increased
WX
Θ, WX
ΘΘ ← −Equation (72), (73) ;
∂Θ
∂a ← −kΘ[−PθϵΘ −EΘ + ntWX
Θ ] ;
JΘ ← −kΘ[−Pθ −EΘΘ + ntWX
ΘΘ] ;
Θ ← −Θ + (eJΘ
−I)(JΘ)−1 ∂Θ
∂a ; ⊿ E step
A, B, C ← −Equation (4) ; ⊿ update with new Θ
end
a++ ;
Π˜x, ˜v = EXX ; ⊿ update generalized state precision
Πθ = Pθ + EΘΘ ; ⊿ update parameter precision
end
Entropy 2021, 23, 1306 23 of 32
13. Translation into Simpliﬁed Mathematical Form
Although the pseudocode derived in the previous sections is sufﬁcient to replicate the
DEM algorithm for an LTI system with colored noise, it is not sufﬁcient to analyze DEM
using the standard control systems tools for stability checks, convergence, etc. Therefore,
in this section we translate the algorithm into a simpliﬁed mathematical form that control
engineers can easily analyze. The following subsections aim at converting the DEM updates
into a coupled linear system.
13.1. State and Input Estimation as a Linear Observer
This section deals with reformulating the D step of DEM for an LTI system as a
(generalized) state and input observer. Substituting Equation (59) in Equation (79) with a
learning rate of kX = 1 yields [2]:
˙X =
[˙˜x
˙˜v
]
= (D −A1)X −B1
[ ˜y
−η ˜v
]
+ WΘ
X . (85)
We now aim to mathematically prove that the (generalized) state and input observer
of DEM can be reduced into an augmented LTI system, for which an exact discretization
can be performed. We proceed by simplifying the mean ﬁeld terms in Equation (39) as:
WΘ
X = −1
2


tr
(
Σθ(NT
X1 ˜Πz N + MT
X1 ˜Πw M)
)
tr
(
Σθ(NT
X2 ˜Πz N + MT
X2 ˜Πw M)
)
. . .


⏐⏐⏐ϑ=µϑ
= −1
2


vec(ΣθT)T(I ⊗(NT
X1 ˜Πz)vec(N))+
vec(ΣθT)T(I ⊗(MT
X1 ˜Πw)vec(M))
. . .


⏐⏐⏐ϑ=µϑ
=(ZN
X vec(N) +ZM
X vec(M))
⏐⏐⏐ϑ=µϑ ,
(86)
where,
ZN
X = −1
2(I ⊗vec(ΣθT)T)


I ⊗(NT
X1 ˜Πz)
I ⊗(NT
X2 ˜Πz)
. . .

, ZM
X = −1
2(I ⊗vec(ΣθT)T)


I ⊗(MT
X1 ˜Πw)
I ⊗(MT
X2 ˜Πw)
. . .

. (87)
Since M and N can be obtained from linear transformation of X, vec(M) and vec(N) can
be written as:
vec(M) =ZMX and vec(N) =ZN X, (88)
where ZM and ZN are matrices with elements 0 and 1. This leads to the mean ﬁeld term
being expressed as a linear transformation of X:
WΘ
X = (ZN
X ZN + ZM
X ZM)
⏐⏐⏐ϑ=µϑ X. (89)
Substituting Equation (89) into Equation (85) simpliﬁes the observer as:
˙X = A4X + B4
[ ˜y
−η ˜v
]
,
A4 = D −A1 + (ZN
X ZN + ZM
X ZM)
⏐⏐⏐ϑ=µϑ and B4 = −B1.
(90)
The (generalized) state and input observer given by Equation (90) is of the form of an
augmented LTI system. Therefore, an exact discretization can be used to solve it without
using the second order gradient JX as given in Equation (48). This reduces the algorithm’s
computational complexity because EXX and WΘ
XX for JX calculation are no longer necessary.
Figure 3 shows the simpliﬁed control diagram of the observer. The stability condition of
Entropy 2021, 23, 1306 24 of 32
this observer (under known θ and λ) and its similarity with the Kalman Filter is discussed
in our prior work [2]. To evaluate WΘ
X , one could either use Equation (89) or Equation (76).
Equation (90) is derived mainly for simpliﬁcation and exact discretization.
Figure 3. The DEM algorithm for an LTI system, with the D step simpliﬁed as an augmented LTI
system given by Equation (90). The D-step block corresponds to the D-step loop in Algorithm 2 and
operates at a different frequency from the E and M blocks.
13.2. Parameter Estimation—System Identiﬁcation
This section aims to mathematically prove that the E step can be reduced to an
augmented LTI system, for which an exact discretization can be performed. We proceed by
ﬁrst simplifying the parameter update equation given in Equation (79):
∂Θ
∂a = −Pθ(Θ −ηθ)
⏐⏐⏐ϑ=µϑ + ∑
t
(−EΘ + WX
Θ ). (91)
Grouping all WX
Θi using Equation (72) yields:
WX
Θ = −1
2
(
I ⊗vec(ΣXT )T
)


I ⊗˜ϵT
Xθ1 ˜Π
I ⊗˜ϵT
Xθ2 ˜Π
. . .

vec(˜ϵX)
⏐⏐⏐ϑ=µϑ = Zϵ
θ vec(˜ϵX)
⏐⏐⏐ϑ=µϑ (92)
where
˜ϵT
Xθi ˜Π = −
[˜CT
θi ˜Πz O ˜AT
θi ˜Πw
O O ˜BT
θi ˜Πw
]
, vec(˜ϵX) =−vec
[ ˜C O
O O
˜A ˜B
]
+ vec
[O O
O I
Dx O
]
= −Zθθ + ZI.
(93)
Here Zθ and ZI are constant matrices with elements 0 and 1. Substituting vec(˜ϵX) from
Equation (93) in Equation (92) yields:
WX
Θ = −(Zϵ
θ Zθ)|ϑ=µϑ Θ + (Zϵ
θ ZI )|ϑ=µϑ . (94)
Substituting Equations (62) and (94) in Equation (91), simpliﬁes the parameter update
equation to
∂Θ
∂a = A5Θ + B5,
A5 = −[Pθ + nt(Zϵ
θ Zθ)|ϑ=µϑ + ∑
t
A2], B5 = Pθηθ + nt(Zϵ
θ ZI )|ϑ=µϑ + ∑
t
B2
[ ˜y
µ ˜x
]
,
(95)
Entropy 2021, 23, 1306 25 of 32
where A2 and B2 are given in Equation (62). Equation (95) is a linear differential equation
in Θ for which an exact discretization can be computed. For each Θ update in Algorithm 2,
A2 and B2 are also updated, consequently updating A5 and B5. Therefore, Equation (95)
is equivalent to a linear time- varying system. Figure 4 shows the simpliﬁed parameter
estimation step of the robot brain. To evaluate WX
Θ, one could use either Equation (72) or
Equation (94). Equation (94) was derived mainly for the exact discretization and for the
convergence proof in Section 14.
Figure 4. The DEM algorithm for an LTI system, with the E step simpliﬁed as an augmented LTI
system given by Equation (95). The E-step block corresponds to the E-step outer loop in Algorithm 2
and operates at a different frequency when compared to the D and M blocks. The dotted lines
illustrate the ﬂow of variables from other blocks and demonstrate the coupled nature of D, E, and M
steps. This diagram is illustrative and should not be confused with a control diagram.
13.3. Hyperparameter Update
The update equation in Equation (80) can be simpliﬁed as:
∂Λ
∂b =kΛ
[
−Pλϵλ + nt
2
[
n ˜Πz
n ˜Πw
]
−1
2
[eλz
tr((S ⊗Ωz)A3)
eλw
tr((S ⊗Ωw)B3)
]]⏐⏐⏐ϑ=µϑ
=−kΛ
2
[tr((S ⊗Ωz)A3) O
O tr ((S ⊗Ωw)B3)
]
eΛ −(kΛPλ)Λ+ (kΛPληλ + kΛnt
2
[
n ˜Πz
n ˜Πw
]
)
=a1eΛ +a2Λ+a3,
(96)
where a1, a2, and a3 are constants that are independent ofΛ. Since Equation (96) is nonlinear
in Λ, an approximate discretization like the conventional Gauss–Newton update scheme
given in Equation (48) should be used for the M step. In summary, the D and E steps follow
an exact discretization, whereas the M step follows an approximate discretization.
14. Convergence Proof for Parameter and Hyperparameter Estimation
In robotics, it is important that learning algorithms provide a stable solution, especially
when robot safety during operation is a concern. Therefore, a proof of convergence for DEM
is important for its widespread use in robotics as a learning algorithm. However, the DEM
literature lacks any such mathematical proof of convergence for the estimator. Therefore,
this section aims at providing one for the parameter and hyperparameter estimation step
on LTI systems.
Since the update equation given by Equation (95) is a linear differential equation,
proving that A5 ≺O is sufﬁcient to prove thatΘ converges to a stable solution. Substituting
the expression for A2 from Equation (62) to the A5 in Equation (95), yields:
A5 = −[Pθ + ntZϵ
θ Zθ + ∑
t
(NT ˜Πz N + MT ˜Πw M)]
⏐⏐⏐ϑ=µϑ . (97)
Entropy 2021, 23, 1306 26 of 32
Since the prior precision matrix can be chosen to be positive deﬁnite, Pθ ≻ O. It is
straightforward to note from the expression for A2 in Equation (62) that ∑t A2 ≻ O,
because ˜Πz ≻O, ˜Πw ≻O =⇒ NT ˜Πz N ≻O, and MT ˜Πw M ≻O. Therefore, the proof of
convergence is complete if we prove that Zϵ
θ Zθ ≻O. Simplifying the expressions for Zϵ
θ
and Zθ from Equations (92) and (93), after some nontrivial linear algebra [41], yields:
Zϵ
θ Zθ = 1
2
∂ ˜θ
∂θ
T
Z1Z2
∂ ˜θ
∂θ (98)
where
Z1 = diag ( ˜Πw ⊗I, ˜Πw ⊗I, ˜Πz ⊗I), ∂ ˜θ
∂θ = diag (vec ˜AT
vecA T , vec ˜BT
vecB T , vec ˜CT
vecCT ),
Z2 =


I ⊗Σ˜x ˜xT I ⊗Σ˜v ˜xT O
I ⊗Σ˜x ˜vT I ⊗Σ˜v ˜vT O
O O I ⊗Σ˜x ˜xT

.
It is straightforward from Equation (98) that Zϵ
θ Zθ ≻O because Z1 ≻O, and Z2 ≻O.
Combining all the results from this section, Pθ ≻O, Zϵ
θ Zθ ≻O and ∑t A2 ≻O, =⇒
A5 ≺O. This completes the proof that the parameter estimation step of DEM converges
for an LTI system. Similarly, from Equation (81), JΛ ≺O proves the convergence of
hyperparameter estimation step. For a detailed account of the linear algebra behind the
proof of convergence, readers may refer to [41].
15. A Demonstrative Example
This section aims to provide the proof of concept for DEM through simulation for the
estimation of an LTI system with colored noise. Since the algorithm can ﬁnd an inﬁnite
number of solutions for a black box estimation of˜x, ˜v, θ and λ from y, a black box estimation
is not ideal as a demonstrative example. Therefore, we restrict this section to the joint
estimation of x, A, B, Πw, and Πz from known y and C.
15.1. Generative Model
A stable LTI system of the form Equation (3) was selected, with randomly generated
parameters θi ∈[−1, 1] having
A =
[ 0.0484 0.7535
−0.7617 −0.2187
]
, B =
[0.3604
0.0776
]
, C =


0.2265 −0.4786
0.4066 −0.2641
0.3871 0.3817
−0.1630 −0.9290

.
A Gaussian bump input signal of v = e−0.25(t−12)2
was centered around t = 12s and
sampled at dt = 0.1s till T = 32s was used. The colored noise was generated with a
smoothness value of σ = 0.5 for the Gaussian kernel. The noise precisions were Πw = e8 I2
and Πz = e8 I4, making λz = λw = 8. The embedding order of the generalized motion of
states and inputs were p = 6 and d = 2, respectively.
15.2. Priors for Estimation
As discussed in Section 5.2, three prior distributions are necessary for the algorithm.
Since the inputs are known, the input prior ηv is initialized with the known input v,
and a tight prior precision of Pv = e32 I1 is used to restrict any changes in v. Simi-
larly, since the parameter C is known, the corresponding prior parameters in ηθ are
initialized with C, with tight priors of Pθi
= e32. The prior parameters ηθi
for the un-
known A and B matrices are randomly sampled from the range of [ −2,2], and a low
prior precision of Pθi
= e6 is used to encourage exploratory behavior. In summary,
ηθ =
[
vec(rand (2, 2)T)T vec(rand (2, 1)T)T vec(CT)T]T and Pθ = diag (e6 I4, e6 I2, e32 I8).
Entropy 2021, 23, 1306 27 of 32
Since the hyperparameters are unknown, their priors were set to zero λ = [0 0]T, with a
prior precision of Pλ = e3 I2 to encourage exploration.
15.3. Results of Estimation
The data y generated from the system in Section 15.1 was used to run the DEM
algorithm given in Algorithm 2. Figure 5a demonstrates the successful state estimation of
the algorithm. The results of parameter estimation (A and B) are shown in Figure 5b. The
updates began from randomly selected priors ηθ, marked by red circles, to ﬁnally converge.
Table 1 shows that the DEM’s estimate ofA and B are close to the real values.
Table 1. DEM’s estimate ofA and B converges to real value.
θ1 θ2 θ3 θ4 θ5 θ6
Real 0.048 0.753 −0.761 −0.218 0.360 0.077
Estimate 0.034 0.714 −0.769 −0.219 0.333 0.098
This conﬁrms that the parameter estimation can converge close to the real parameters,
even when ηθ is randomly selected from the range ηθ ∈[−2, 2] that is double the size
of the real parameter range θi ∈[−1, 1]. Figure 5c shows the successful hyperparameter
convergence close to λz = λw = 8.
0 10 20 30
Time(s)
-1
-0.5
0
0.5
Real states
Estimated states
(a) State estimation.
0 5 10 15 20 25
E step iteration, a
-2
-1
0
1
2Estimated parameter (b) Parameter estimation.
0 5 10 15 20 25
E step iteration
0
2
4
6
8Estimated hyperparameters
z
w
(c) Hyperparameter estimation.
Figure 5. The results of DEM’s estimation process. (a) The estimated states in blue closely resembles
the real states in red. (b) The parameter estimation starts from randomly selected ηθ, marked by red
circles and converges with each E step iteration a. (c) Both the hyperparameters start from ηλ = 0,
and converge close to the correct value of 8.
DEM’s conﬁdence on its estimates increase with the E step iterations, as can be seen
from Figure 6a, which demonstrates an increase in parameter precision Πθ. A similar trend
can be observed for ΠX. However, Πλ remains a constant during the entire algorithm,
as proved in Section 12.2. The key idea behind DEM’s inference is the maximization of
free energy objectives. Read together, Figures 5 and 6 demonstrates that DEM successfully
Entropy 2021, 23, 1306 28 of 32
estimates ˜x, θ and λ, with increasing conﬁdence on its estimates as the estimation proceeds
by maximizing ¯F from Equation (40). In summary, DEM can be used for the joint estimation
of states, parameters and hyperparameters of an LTI system, subjected to colored noise.
0 10 20
E step iterations, a
0
0.5
1
1.5
2
Parameter precision 
105
(a)
0 5 10 15 20 25
E step iteration
0
0.5
1
1.5
2
2.5Free energy action
104 (b)
Figure 6. Maximization of ¯F improves the conﬁdence on estimates. ( a) Parameter precision Πθ.
(b) Free action ¯F(a) −¯F(0).
16. Benchmarking
This section deals with benchmarking DEM against the state-of-the-art parameter
estimation methods such as Expectation Maximization (EM), Subspace method (SS), and
Prediction Error Minimization (PEM), for black-box estimation (fully unknown x, θ and λ).
16.1. Evaluation Metric for Parameter Estimation
For the black box identiﬁcation, with completely unknown x, θ, and λ, there are
inﬁnite solutions with accurate input–output mapping. However, for LTI systems, there
exists a unique transformation for identical systems. We use the companion canonical
form to check the validity of parameter estimation by transforming both the real and the
estimated parameters into their companion canonical form and then using the (square of)
Euclidean distance between them as the sum of squared error (SSE) in parameter estimation.
This evaluation metric will be used for parameter estimation in the next section.
16.2. Simulation Setup
A total of 500 (5 ×100) different randomly generated stable systems were used with
ﬁve different noise smoothness values for parameter estimation. All systems were selected
with same number of parameters nθ = 14 (n = 2, m = 4 and r = 1), with each θi ∈[−1, 1],
while ensuring that A matrix is stable. All the noises were generated with the precision of
e6(Πw = e6 I2×2, Πz = e6 I4×4), with the embedding orders of states and inputs asp = 6 and
d = 2. A Gaussian bump of v = e−0.25∗(t−12)2
was used as the input signal with dt = 0.5s
and T = 32s. The prior parameter was randomly initialized such that all ηθi
∈[−2, 2] with
a tight prior precision of Pθ = e4 I14×14. Both the hyperparameter priors ηλi
were set to
zero, with a prior precision of Pλ = e−4 I2×2.
The System Identiﬁcation toolbox from MATLAB was used for SS ( n4sid()) and
PEM methods. The solution of SS was used to initialize PEM. An implementation of
EM algorithm for state space models was written in MATLAB based on [ 45]. n4sid() is
inherently designed to handle colored noise, whereas the implemented EM algorithm is
not. The code for the DEM algorithm will be openly available at: https://github.com/
ajitham123/DEM_LTI.
16.3. Results
The results shown in Figure 7 demonstrate the superior performance of DEM in
comparison with EM, PEM, and SS, with minimum SSE during parameter estimation
across different noise smoothness. Additionally, EM and PEM exploded occasionally
(<5% times), resulting in outliers in SSE, which were removed for better visualization.
Entropy 2021, 23, 1306 29 of 32
DEM demonstrated a consistent performance without generating any such outliers or
exploding solutions, which could be explained by DEM’s convergence guarantees for
parameter estimation under colored noise [41], as proved in Section 14. In summary, DEM
is a competitive parameter estimator for LTI systems with colored noise.
=0.1 =0.3 =0.5 =0.7 =0.9
noise smoothness
0
100
200
300
400
500SSE of parameter estimation
EM
PEM
SS
DEM
Figure 7. The sum of all SSE of Θ for 100 random systems each, for 5 different noise smooth-
nesses. DEM outperforms EM, PEM, and SS with minimum SSE for parameter estimation under
colored noise.
17. Discussion
The quest for a brain-inspired learning algorithm for robots has culminated in the
free energy principle that postulates biological brain’s perception as an optimization over
its free energy objectives. FEP is of prime importance to robotics because of the use of
generalized coordinates that enables it to gracefully handle colored noises. Colored noises
appear in real robotics systems through the unmodeled dynamics and the non-linearity
errors in the model, thereby providing an advantage for DEM during estimation when
compared to other estimators. An example could be the unmodeled wind disturbances
acting on an unmanned aerial vehicle while in ﬂight, or the non linearity errors in the
dynamic model of a robotic manipulator arm involved in a pick and place operation. The
scope of this work spans across the blind system identiﬁcation of such linear dynamic
systems with colored noise.
The fundamental difference between this work and the prior work is in the reformu-
lation of DEM for an LTI system. While DEM from computational neuroscience focuses
on emulating the biological brain’s perception through the hierarchical abstraction of a
number of non-linear dynamic systems that interact with each other, our work focuses on
reducing this method into an algorithm for the system identiﬁcation of an LTI system with
colored noise, which is a well-known problem in robotics. This reformulation enables the
standard analysis for convergence, stability and unbiased estimation, which is an essential
analysis in practical robotics. It also enables DEM to be compared with other existing
estimation algorithms in a control systems domain. The widespread use of DEM in robotics
necessitates these mathematical analyses, especially when concerning the stable and safe
operation of robots in industry and during human–robot interaction.
An algorithm with proved convergence for estimation is preferred for safe robotic
applications. Therefore, one of the main contribution of this work was the reduction of
the estimation algorithm into a coupled augmented system to prove the convergence
of parameter and hyperparameter estimation steps. This work also demonstrated the
successful applicability of DEM for the estimation of a randomly selected LTI system.
Furthermore, we showed through rigorous simulations on a wide range of randomly
generated LTI systems that DEM is a competitive algorithm for system identiﬁcation under
colored noise, thereby widening the scope of DEM to a large number of LTI systems
in robotics.
One of the main drawbacks of the algorithm is its higher computational complexity
when compared to the estimation algorithms that do not keep track of the trajectory of
states. Therefore, future work can focus on the online estimation using DEM with reduced
Entropy 2021, 23, 1306 30 of 32
computational load. Future work can also focus on extending this algorithm for linear time
varying systems to deal with robots with changing system parameters while in operation—
a delivery drone dropping deliveries in mid-ﬂight, for example. From a practical robotics
point of view, DEM’s parameter estimation module can be directly applied to a wide range
of robots such as quadrotors, robotic arms, wheeled robots, etc. for black-box system
identiﬁcation, the input estimation module can be employed for fault-detection systems,
and the hyperparameter estimation module can be used for online noise estimation for
robust control. DEM can also be extended with a control loop for active inference to perform
simultaneous perception and action on robots. This would result in the development of
cognitive robots that can learn the generative model in the environment by interacting with
it and actively seeking new information (active learning) for uncertainty resolution. This
would inﬂuence multiple domains in robotics such as human–robot interaction for task
learning, swarm robotics for collective learning and distributed control, informative path
planning of aerial robots for environment monitoring, etc. The development of such brain-
inspired autonomous agents sits at the core of cognitive robotics research. In summary,
DEM has a huge potential to be the bioinspired learning algorithm for future robots.
18. Conclusions
The free energy principle from neuroscience has a great potential to be one of the most
prominent frameworks for learning and control for the autonomous systems in future.
Therefore, this paper converted the FEP-based inference scheme called DEM into a joint
state, input, parameter, and hyperparameter estimation algorithm for LTI systems with
colored noise. We derived the mathematical framework of DEM for LTI systems to prove
that the resulting estimator is a combination of linear estimators that are coupled. We
provided the proof of convergence for the estimation steps. Through rigorous simulations
on randomly generated linear systems with colored noise at varying smoothness levels,
we demonstrated that the DEM algorithm outperforms EM, PEM, and SS methods for
parameter estimation with minimal estimation error. In light of the potential for DEM to
solve the parameter estimation problem, the future research will aim at applying DEM to a
quadcopter ﬂying in wind.
Author Contributions: A.A.M.: Conceptualization, methodology, software, validation, formal analy-
sis, writing—original draft preparation, visualization. M.W.: Conceptualization, writing—review and
editing, supervision. All authors have read and agreed to the published version of the manuscript.
Funding: This research received no external funding.
Data Availability Statement: The MATLAB code for the DEM algorithm will be openly available at:
https://github.com/ajitham123/DEM_LTI.
Acknowledgments: The authors would like to thank Karl Friston for the thought-provoking discus-
sions on the use of generalized coordinates within the FEP framework.
Conﬂicts of Interest: The authors declare no conﬂict of interest.
Abbreviations
The following abbreviations are used in this manuscript:
LTI system Linear time invariant system
DEM Dynamic Expectation Maximization
FEP Free energy principle
KF Kalman Filter
KL divergence Kullback–Leibler divergence
Entropy 2021, 23, 1306 31 of 32
References
1. Friston, K. The free-energy principle: A uniﬁed brain theory? Nat. Rev. Neurosci. 2010, 11, 127–138. [CrossRef] [PubMed]
2. Anil Meera, A.; Wisse, M. Free Energy Principle Based State and Input Observer Design for Linear Systems with Colored Noise.
In Proceedings of the 2020 American Control Conference (ACC), Denver, CO, USA, 1–3 July 2020; pp. 5052–5058.
3. Bos, F.; Anil Meera, A.; Benders, D.; Wisse, M. Free Energy Principle for State and Input Estimation of a Quadcopter Flying in
Wind. arXiv 2021, arXiv:2109.12052.
4. Pezzato, C.; Ferrari, R.; Corbato, C.H. A novel adaptive controller for robot manipulators based on active inference. IEEE Robot.
Autom. Lett. 2020, 5, 2973–2980. [CrossRef]
5. Pezzato, C.; Hernandez, C.; Wisse, M. Active Inference and Behavior Trees for Reactive Action Planning and Execution in
Robotics. arXiv 2020, arXiv:2011.09756.
6. Baioumy, M.; Duckworth, P .; Lacerda, B.; Hawes, N. Active inference for integrated state-estimation, control, and learning.arXiv
2020, arXiv:2005.05894.
7. Oliver, G.; Lanillos, P .; Cheng, G. Active inference body perception and action for humanoid robots.arXiv 2019, arXiv:1906.03022.
8. Çatal, O.; Verbelen, T.; Van de Maele, T.; Dhoedt, B.; Safron, A. Robot navigation as hierarchical active inference.Neural Netw.
2021, 142, 192–204. [CrossRef]
9. Lennart, L. System Identiﬁcation: Theory for the User; PTR Prentice Hall: Upper Saddle River, NJ, USA, 1999; Volume 28.
10. Zhang, L.Q.; Cichocki, A.; Amari, S. Kalman ﬁlter and state-space approach to blind deconvolution. In Neural Networks for
Signal Processing X, Proceedings of the 2000 IEEE Signal Processing Society Workshop, Sydney, Australia, 11–13 December 2000; IEEE:
Piscataway, NJ, USA, 2000; pp. 425–434.
11. Han, R.; Bohn, C.; Bauer, G. Blind identiﬁcation of state-space models in physical coordinates. arXiv 2021, arXiv:2108.08498.
12. Abed-Meraim, K.; Qiu, W.; Hua, Y. Blind system identiﬁcation. Proc. IEEE 1997, 85, 1310–1322. [CrossRef]
13. Zhang, Y. Unbiased identiﬁcation of a class of multi-input single-output systems with correlated disturbances using bias
compensation methods. Math. Comput. Model. 2011, 53, 1810–1819. [CrossRef]
14. Liu, X.; Lu, J. Least squares based iterative identiﬁcation for a class of multirate systems. Automatica 2010, 46, 549–554. [CrossRef]
15. Zheng, W.X. On a least-squares-based algorithm for identiﬁcation of stochastic linear systems. IEEE Trans. Signal Process. 1998,
46, 1631–1638. [CrossRef]
16. Zhang, Y.; Cui, G. Bias compensation methods for stochastic systems with colored noise. Appl. Math. Model. 2011, 35, 1709–1716.
[CrossRef]
17. Cui, T.; Chen, F.; Ding, F.; Sheng, J. Combined estimation of the parameters and states for a multivariable state-space system in
presence of colored noise. Int. J. Adapt. Control. Signal Process. 2020, 34, 590–613. [CrossRef]
18. Friston, K.J.; Trujillo-Barreto, N.; Daunizeau, J. DEM: A variational treatment of dynamic systems. Neuroimage 2008, 41, 849–885.
[CrossRef] [PubMed]
19. van de Laar, T.; Özçelikkale, A.; Wymeersch, H. Application of the free energy principle to estimation and control. arXiv 2019,
arXiv:1910.09823.
20. Anil Meera, A.; Wisse, M. A Brain Inspired Learning Algorithm for the Perception of a Quadrotor in Wind. arXiv 2021,
arXiv:2109.11971.
21. Buckley, C.L.; Kim, C.S.; McGregor, S.; Seth, A.K. The free energy principle for action and perception: A mathematical review. J.
Math. Psychol. 2017, 81, 55–79. [CrossRef]
22. Hohwy, J. The Predictive Mind; Oxford University Press: Oxford, UK, 2013.
23. Friston, K. The free-energy principle: A rough guide to the brain? Trends Cogn. Sci. 2009, 13, 293–301. [CrossRef]
24. Friston, K.J.; Daunizeau, J.; Kilner, J.; Kiebel, S.J. Action and behavior: A free-energy formulation. Biol. Cybern. 2010, 102, 227–260.
[CrossRef] [PubMed]
25. Carhart-Harris, R.L.; Friston, K.J. The default-mode, ego-functions and free-energy: A neurobiological account of Freudian ideas.
Brain 2010, 133, 1265–1283. [CrossRef]
26. Friston, K.J.; Daunizeau, J.; Kiebel, S.J. Reinforcement learning or active inference? PLoS ONE 2009, 4, e6421. [CrossRef] [PubMed]
27. Friston, K. Hierarchical models in the brain. PLoS Comput. Biol. 2008, 4, e1000211. [CrossRef] [PubMed]
28. Baltieri, M.; Buckley, C.L. PID control as a process of active inference with linear generative models. Entropy 2019, 21, 257.
[CrossRef]
29. Veissière, S.P .; Constant, A.; Ramstead, M.J.; Friston, K.J.; Kirmayer, L.J. Thinking through other minds: A variational approach to
cognition and culture. Behav. Brain Sci. 2020, 43, e90. [CrossRef] [PubMed]
30. Kaufmann, R.; Gupta, P .; Taylor, J. An active inference model of collective intelligence. arXiv 2021, arXiv:2104.01066.
31. Miu, E.; Gulley, N.; Laland, K.N.; Rendell, L. Innovation and cumulative culture through tweaks and leaps in online programming
contests. Nat. Commun. 2018, 9, 1–8. [CrossRef] [PubMed]
32. Friston, K.; Kiebel, S. Predictive coding under the free-energy principle. Philos. Trans. R. Soc. Biol. Sci. 2009, 364, 1211–1221.
[CrossRef]
33. Parr, T.; Markovic, D.; Kiebel, S.J.; Friston, K.J. Neuronal message passing using Mean-ﬁeld, Bethe, and Marginal approximations.
Sci. Rep. 2019, 9, 1–18. [CrossRef]
34. van de Laar, T.W.; de Vries, B. Simulating active inference processes by message passing. Front. Robot. AI 2019, 6, 20. [CrossRef]
Entropy 2021, 23, 1306 32 of 32
35. Friston, K.; FitzGerald, T.; Rigoli, F.; Schwartenbeck, P .; Pezzulo, G. Active inference and learning. Neurosci. Biobehav. Rev. 2016,
68, 862–879. [CrossRef]
36. Friston, K.J. Variational ﬁltering. NeuroImage 2008, 41, 747–766. [CrossRef]
37. Friston, K.; Stephan, K.; Li, B.; Daunizeau, J. Generalised ﬁltering. Math. Probl. Eng. 2010, 2010. [CrossRef]
38. Friston, K.; Mattout, J.; Trujillo-Barreto, N.; Ashburner, J.; Penny, W. Variational free energy and the Laplace approximation.
Neuroimage 2007, 34, 220–234. [PubMed]
39. Blei, D.M.; Kucukelbir, A.; McAuliffe, J.D. Variational inference: A review for statisticians. J. Am. Stat. Assoc. 2017, 112, 859–877.
[CrossRef]
40. Balaji, B.; Friston, K. Bayesian state estimation using generalized coordinates. In Proceedings of the Signal Processing, Sensor
Fusion, and Target Recognition XX, Orlando, FL, USA, 5 May 2011; Volume 8050, p. 80501Y.
41. Anil Meera, A.; Wisse, M. On the convergence of DEM’s linear parameter estimator. In International Workshop on Active Inference;
Springer: Berlin/Heidelberg, Germany, 2021; accepted.
42. Li, B.; Daunizeau, J.; Stephan, K.E.; Penny, W.; Hu, D.; Friston, K. Generalised ﬁltering and stochastic DCM for fMRI. Neuroimage
2011, 58, 442–457. [CrossRef]
43. Mader, W.; Linke, Y.; Mader, M.; Sommerlade, L.; Timmer, J.; Schelter, B. A numerically efﬁcient implementation of the expectation
maximization algorithm for state space models. Appl. Math. Comput. 2014, 241, 222–232. [CrossRef]
44. Friston, K. A free energy principle for a particular physics. arXiv 2019, arXiv:1906.10184.
45. Cara, F.J.; Juan, J.; Alarcón, E. Using the EM algorithm to estimate the state space model for OMAX. Practice 2014, 1000, 3.