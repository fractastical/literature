Active sampling: A
machine-learning-assisted framework for
finite population inference with optimal
subsamples
Henrik Imberg1, Xiaomi Yang2, Carol Flannagan2,3, Jonas B¨ argman2
1Department of Mathematical Sciences,
Chalmers University of Technology and University of Gothenburg
2Division of Vehicle Safety, Chalmers University of Technology
3University of Michigan Transportation Research Institute
Abstract
Data subsampling has become widely recognized as a tool to overcome compu-
tational and economic bottlenecks in analyzing massive datasets. We contribute to
the development of adaptive design for estimation of finite population characteris-
tics, using active learning and adaptive importance sampling. We propose an active
sampling strategy that iterates between estimation and data collection with optimal
subsamples, guided by machine learning predictions on yet unseen data. The method
is illustrated on virtual simulation-based safety assessment of advanced driver assis-
tance systems. Substantial performance improvements are demonstrated compared
to traditional sampling methods.
Keywords: active learning, adaptive importance sampling, computer simulation experi-
ments, inverse probability weighting, optimal design, traffic safety assessment
1
arXiv:2212.10024v3  [stat.ME]  4 Jul 2024
1 Introduction
We consider a deterministic computer simulation experiment which for a given input z
returns a fixed output y. The input space is assumed to be discrete and the simulation ex-
periment hence characterized by the set of complete input-output pairs {(zi, yi)}N
i=1, where
N is the size of the experiment. The aim our experiment it to calculate a characteristic
θ = h(ty), ty =
NX
i=1
yi, (1)
for some differentiable functionh : Rd → R and d-dimensional vector of totalsty. Examples
of such a characteristic include, e.g., a total, mean, ratio, or correlation coefficient. This
is also known as a finite population inference problem (Beaumont and Haziza, 2022). We
further assume that N is large, as is the computational cost of each single experiment,
rendering complete enumeration unfeasible. In such circumstances, researches often resort
to subsampling.
Subsampling methods have seen a huge increase in popularity over the past few years
across many different areas of statistics. For instance, Ma et al. (2015, 2022) introduced
leverage sampling for big data regression, which subsequently inspired similar developments
for logistic regression (Wang et al., 2018; Yao and Wang, 2019) generalized linear models
(Ai et al., 2021b; Yu et al., 2022), and quantile regression (Ai et al., 2021a; Wang et al.,
2021). Similarly, Dai et al. (2022) developed an optimal subsampling method for regres-
sion using a minimum energy criterion. Sometimes subsampling is induced by economical
rather than computational constraints. In this setting, Imberg et al. (2022) developed an
optimal subsampling method for two-phase sampling experiments. A similar measurement-
2
constrained experiment problem was addressed by Zhang et al. (2021) using a sequential
subsampling procedure and by Meng et al. (2021) using a space-filling Latin hypercube
sampling method.
For computer simulation experiments, subsampling methods using adaptive design for
Gaussian process response surface modeling are commonly employed. Together with ac-
tive learning and Bayesian optimization, this provides a powerful framework for computer
experiment emulation (Gramacy and Apley, 2015; Sun et al., 2017; Lei et al., 2021; Lim
et al., 2021). Another popular approach is model-free space-filling methods using, e.g.,
Latin hypercube sampling designs (see, e.g., Cioppa and Lucas, 2007; Zhang et al., 2024;
Zhou et al., 2024). Others have utilized methods based on optimal transport, e.g., for kernel
density estimation (Zhang et al., 2023). For estimating a simple statistic, such as a mean or
ratio, however, importance sampling and adaptive importance sampling remains prominent
(Bucher, 1988; Oh and Berger, 1992; Feng et al., 2021). Importance sampling is widely
known, easy to implement, and provides consistent estimates under minimal assumptions
(Fishman, 1996; Fuller, 2009). Some recent developments include adaptive importance
sampling for quantile estimation (Pan et al., 2020) and online monitoring of data streams
(Liu et al., 2015; Xian et al., 2018).
There has also been a considerable interest in subsampling and adaptive design in
machine learning, particularly in the context of active learning (MacKay, 1992; Cohn, 1996;
Settles, 2012). Adaptive importance sampling methods for active learning were developed
in, e.g., Bach (2007), Beygelzimer et al. (2009) and Imberg et al. (2020). Active learning
has also been utilized for deep learning (Ren et al., 2021), Gaussian processes (Sauer et al.,
3
2023) and adaptive design of experiments (Lookman et al., 2019; Sun et al., 2021), to
mention a few.
Returning to the finite population inference problem (1), this is a classical problem in
statistics and hence has achieved considerable attention over the years, particularly in the
survey sampling literature. Common approaches to estimation include importance sam-
pling methods and/or using estimators that utilize information of known auxiliary variables
to improve estimator efficiency (see, e.g., Cassel et al., 1976; Deville and S¨ arndal, 1992;
Kott, 2016; Ta et al., 2020). Methods utilizing machine learning in survey sampling have
just recently begun to emerge (Breidt and Opsomer, 2017; Kern et al., 2019; McConville
and Toth, 2019; Sande and Zhang, 2021). Although there has been a substantial amount
of work on subsampling and adaptive design in the statistical literature, there is to our
knowledge little done at the intersection of machine learning and adaptive design for the
finite population inference problem (1).
Contributions To fill the gap in adaptive design and machine learning for finite popu-
lation inference, we propose an active sampling strategy for estimation of finite population
characteristics. Our method iterates between estimation and data collection with optimal
subsamples, guided by machine learning predictions on yet unseen data. The proposed
sampling strategy interpolates in a completely data-driven manner between simple random
sampling when no auxiliary information is available and optimal importance sampling as
more information is acquired. Consistency and asymptotic normality of the active sam-
pling estimator is established using martingale central limit theory. Methods for variance
estimation are proposed and conditions for consistent variance estimation presented.
4
Outline The structure of this paper is as follows: We start by presenting a motivating
example in crash-causation-based scenario generation for virtual vehicle safety assessment
in Section 2. Mathematical preliminaries and notation is introduced in Section 3. In the
end of this section we also derive an optimal importance sampling scheme for estimating
a finite population characteristic while accounting for uncertainty in the study variables of
interest. This is then incorporated in the active sampling algorithm proposed in Section
4. An empirical evaluation on simulated data is conducted in Section 5 and application to
virtual vehicle safety assessment in Section 6. Additional theoretical results and proofs are
provided in Appendix A.
2 Motivating example
Traffic safety is a problem worldwide (World Health Organization, 2018). Safety systems
have been developed to improve traffic safety and have shown the potential to avoid or
mitigate crashes. However, when developing both advanced driver assistance systems and
automated driving systems, there is a need to assess the impact on safety of the systems
before they are on the market. One way to do that is by running virtual simulations
comparing the outcome of simulations both with and without a specific system (Seyedi
et al., 2021; Leledakis et al., 2021).
We consider a virtual simulation experiment based on a glance-and-deceleration crash-
causation model where a driver’s off-road glance behavior and braking profile are repre-
sented by discrete (empirical) probability distributions, using a similar setup as in B¨ argman
et al. (2015) and Lee et al. (2018). The outcome of the simulations is a distribution of impact
5
speeds of all the crashes generated by all combinations of the eyes-off-road glace duration
and the maximum deceleration during braking. Here “all combinations” is the problem.
Complete enumeration becomes practically unfeasible in high-dimensional (many param-
eters varied) or high-resolution (many levels per parameter) settings, and subsampling is
inevitable.
A small toy example of our problem and illustration of the proposed active sampling
method is provided in Figure 1. The figure shows the output of a computer simulation
experiment to evaluate the impact speed reduction with an automatic emergency braking
system (AEB) compared to a baseline manual driving scenario (without AEB) in a rear-end
collision generation. The impact speed and impact speed reduction depend on the maximal
deceleration during braking and the driver’s off-road glance duration, i.e., the time the
driver of the ’following’ car is looking off-road (e.g., due to distraction). By iteratively
learning to predict the response surface of Figure 1 A while running the experiment, an
accurate estimate of the overall safety benefit of the AEB system may be obtained by
adaptive importance sampling (Figure 1 B). In doing so, computational demands can be
substantially reduced compared to complete enumeration.
3 Finite population sampling
We introduce the mathematical framework and notation in Section 3.1, presented in the
context of the crash-causation-based scenario generation application outlined above. Tradi-
tional methods for sample selection and estimation are reviewed in Section 3.2 and optimal
importance sampling schemes discussed in Section 3.3.
6
Figure 1: A: Simulated impact speed reduction with an automatic emergency braking system
(AEB) compared to a baseline manual driving scenario (without AEB) in a computer experiment
of a rear-end collision generation. In the bottom right corner, no crash was generated in the
baseline scenario; such instances are non-informative with regards to safety benefit evaluation. B:
Corresponding optimal active sampling scheme. Active sampling oversamples instances in regions
where there is a high probability of generating a collision in the baseline scenario (attempting
to generate only informative instances) and with a large predicted deviation from the average.
These instances will be influential for estimating the safety benefit of the AEB system.
3.1 Target characteristic and scope of inference
Assume we are given an index set or dataset D with N instances or elements i = 1, . . . , N.
Associated with each element i in D is a vector ( yi, zi), where yi is a vector of outcomes
or response variables, and zi a vector of design variables and auxiliary variables. We are
interested in a characteristic θ = h(ty) for some differentiable function h : Rd → R and
d-dimensional vector of totals ty = PN
i=1 yi.
In the context of crash-causation-based scenario generation, the index set D represents
7
a collection of N potential simulation scenarios of interest. The response variables yi are
outcomes of the simulation, including, e.g., whether a crash occurred or not, impact speed
if there was a crash, and impact speed reduction with an advanced driver assistance system
compared to some baseline driving scenario. The auxiliary variables zi contain scenario
information, such as simulation settings and parameters that are under the control of the
investigator, and any additional information that is available without running the actual
simulation. Characteristics of interest include, e.g., the mean impact speed reduction and
crash avoidance rate with an advanced driver assistance system compared to some baseline
driving scenario, when restricted to the relevant set of crashes (Figure 1).
3.2 Unequal probability sampling
In our application, as in many computer simulation experiment applications, running all
N simulations of interest to observe the outcomes {yi}N
i=1 is computationally unfeasible.
Hence, we assume that observing complete data is affordable only for a subset S ⊂ D
of size n. We consider the case when the subset S is selected using unequal probability
sampling, i.e., by a random mechanism where each instance i ∈ Dhas a strictly positive
and possibly unique probability of selection. In this section we also restrict ourselves to
non-adaptive designs. We let Si be the random variable representing the number of times
an element i is selected by the sampling mechanism, assuming that sampling may be with
replacement. Hence, the subsample S is the random set given by S = {i ∈ D: Si > 0}.
We will primarily consider multinomial sampling designs but note that the methodology of
our paper is applicable also for other designs, such as the Poisson sampling design (Till´ e,
8
2006), with minimal modifications.
In this context, an estimator for the finite population characteristic (1) may be obtained
by sample weighting as
ˆθ = h(ˆty), ˆty =
X
i∈S
Siwiyi, (2)
where wi = 1/µi and µi = E[Si]. We note that ˆty is an unbiased estimator of the total ty
provided that µi > 0 for all i ∈ D, and furthermore a consistent estimator under general
conditions (Hansen and Hurwitz, 1943; Horvitz and Thompson, 1952). Consequently, ˆθ is
a consistent estimator for θ under mild assumptions (see, e.g., Fuller, 2009).
3.3 Optimal importance sampling schemes
When the function h is linear and all h(yi) are positive, it is well-known that the optimal
sampling scheme for θ in terms of minimizing the variance of the estimator ˆθ is given by
µi ∝ h(yi), in fact producing an estimator with zero variance (Fishman, 1996). In general,
one can show that the optimal importance sampling scheme for a characteristic θ = h(ty)
and non-linear function h(u) is of the form µi ∝
∇h(ty)T yi
 (Proposition 1). A proof is
provided in Appendix A.1.
Proposition 1 (Optimal importance sampling scheme, yi known) Let {yi}N
i=1 be
fixed. Let {mk}k≥1 be an increasing sequence of positive integers andSk = (Sk1, . . . , SkN ) ∼
Multinomial(mk, π) a corresponding sequence of random vectors. Let ˆθk be defined for the
kth random vector Sk as in (2). As a function of π = (π1, . . . , πN ), the asymptotic mean
9
squared error AMSE(ˆθ) := limk→∞ E[mk(ˆθk − θ)2] is minimized by
π∗
i =
√ci
PN
j=1
√cj
, i = 1, . . . , N, (3)
with ci =
∇h(u)T yi
2
u=ty
.
We note that the result of Proposition 1 is of limited practical use as it requires all the
yi’s to be known. Inspired by active learning (Settles, 2012), we introduce in Section 4 an
active sampling algorithm that overcomes this limitation through sequential sampling with
iterative updates of the estimate for the total ty and predictions for the yi’s. However, as
shown in the experiments in Section 5, naively plugging in the predictions immediately to
the importance sampling scheme of Proposition 1 often results in poor performance. Indeed,
accounting for prediction error is essential to control the variance of the active sampling
estimator. We therefore in Proposition 2 propose an optimal importance sampling scheme
to minimize the expected mean squared error of our estimator forθ, treating the unobserved
values of theyi’s as random variablesY i. Integrated with flexible machine learning models,
this will be the key ingredient of the active sampling method introduced in Section 4.
Proposition 2 (Optimal importance sampling scheme, yi unknown) Let {yi}N
i=1,
ty = PN
i=1 yi and θ = h(ty) be fixed but unknown constants. Consider, as a proxy for
yi, a collection of random variables {Y i}N
i=1 with means E[Y i] = ηi and finite, positive
semi-definite covariance matrices Cov(Y i) = Σi. Let mk, Sk, ˆθk and AMSE(ˆθ) be defined
as in Proposition 1. Then, the expected asymptotic mean squared error EY [AMSE(ˆθ)] is
minimized by (3) with ci =

(∇h(u)T ηi)2 + ∇h(u)T Σi∇h(u)

u=ty
.
For a proof, see Appendix A.1.
10
4 Active sampling
In this section we propose an active sampling strategy for finite population inference with
optimal subsamples using adaptive importance sampling and machine learning. The active
sampling algorithm is described in Section 4.1. Variance estimation for the active sampling
estimator is discussed in Section 4.2 and asymptotic properties in Section 4.3. We conclude
by a brief discussion on sample size calculations for the active sampling method in Section
4.4.
4.1 Active sampling algorithm
The active sampling method is summarized in Algorithm 1. The algorithm is executed
iteratively in K iterations k = 1, . . . , Kand chooses, in each iteration, nk new instances at
random (possibly with replacement) from the index set D = {1, . . . , N}. Once a new batch
of instances has been selected we observe or retrieve the corresponding data yi and update
our estimates of the characteristics of interest. In our application, this is done by running a
virtual computer simulation. The process continues until a pre-specified maximal number
of iterations K is reached, or the target characteristic is estimated with sufficient precision,
based on a pre-specified precision target δ for the standard error of the estimator. Methods
for variance estimation are discussed in Section 4.2.
A key component of the active sampling algorithm is the inclusion of an auxiliary
model or surrogate model f(y|z) for the distribution of the unobserved data yi given
auxiliary variables zi. At this stage any prediction model or machine learning algorithm
may be used. The first two moments of the response vector are then used as input to the
11
Algorithm 1 Active Sampling
Input: Index set D = {1, . . . , N}, target characteristic θ = h(ty) (to be estimated),
precision target δ >0, maximal number of iterations K, batch sizes {nk}K
k=1.
Initialization: Let m0 = 0, ˆt
(0)
y = 0, and L0 = ∅.
1: for k = 1, 2, . . . , K do
2: Learning (only if k > 1): Train prediction model f(yi|zi) on the labeled dataset
{(yi, zi)}i∈Lk−1 . Let ˆyi and ˆΣi be the predicted mean and estimated residual covari-
ance matrix for Y i, respectively. ∗
3: if k > 1 and Learning step was successful† then
4: Optimization: Calculate sampling scheme πk as
πki ∝ √ci, c i =
h
(∇h(u)T ˆyi)2 + ∇h(u)T ˆΣi∇h(u)
i
u=ˆt(k−1)
y
, i ∈ D.
5: else
6: Fallback: Set πki ∝ 1 for all i ∈ D.
7: end if
8: Sampling: Draw vector sk = (sk1, . . . , skN ) ∼ Multinomial(nk, πk).
9: Labeling: Retrieve data yi for selected instance(s) i : ski > 0. Update labeled set
Lk = Lk−1 ∪ {i ∈ D: ski > 0}.
10: Estimation: Let µki = nkπki, wki = 1/µki, mk = mk−1 + nk, and
ˆty,k =
X
i:ski>0
skiwkiyi, ˆt
(k)
y = 1
mk

mk−1ˆt
(k−1)
y + nkˆty,k

, ˆθ(k) = h(ˆt
(k)
y ).
11: Estimate the variance of ˆθ(k) according to (4).
12: if
q
dVar(ˆθ(k)) < δthen
13: Termination: Stop execution. Continue to 16.
14: end if
15: end for
16: Output: Estimate ˆθ(k), labeled dataset {(yi, zi)}i∈Lk and selection history {sj, µj}k
j=1.
∗Although the value of yi is assumed to be fixed (but unknown) it is modeled here as a random variable
Y i to account for prediction uncertainty around the true value.
†The prediction model could be fitted (converged and non-trivial model achieved) and prediction R-squared
(regression) or prediction accuracy (classification) on hold-out data (e.g., by cross-validation) > 0.
optimal importance sampling scheme of Proposition 2. When the covariance matrices of the
response vectors are not immediately available from the model, they may be estimated from
the residuals. We suggest that this is done using the method of moments on hold-out data,
e.g., by cross-validation. Underestimation of the residual variance may otherwise cause
12
unstable performance by assigning sampling probabilities too close to zero with highly
variable sample weights and increased estimation variance as a result. In practice, one
may also need to make further simplifying assumptions, including assumptions about the
mean-variance relationship and correlation structure of the response variables.
In each iteration k, the active sampling estimator ˆθ(k) of the characteristic θ is con-
structed in three steps. First, we define an estimator ˆty,k for the total ty using data
acquired in the current iteration. This estimator is then combined with the estimators
from the previous iterations to produce a pooled estimator ˆt
(k)
y . Finally, our estimator for
θ is obtained using the plug-in estimator h(ˆt
(k)
y ). We note that the pooled estimator ˆt
(k)
y
is an unbiased estimator for the finite population total, provided that πki > 0 for all k
and i. Consequently, one may expect our estimator ˆθ(k) to be consistent for θ under mild
assumptions. We will return to this in Section 4.3.
By gathering data in a sequential manner, we are able to learn from past observations
how to sample in an optimal way in future iterations. The proposed active sampling scheme
interpolates in a completely data-driven manner between simple random sampling when the
prediction error is large (or no model has been fitted) and the optimal importance sampling
scheme of Proposition 1 when the prediction error is small. Importantly, unbiased inferences
for θ are obtained even if the surrogate modelf(y|z) would be biased. This is due to the use
of importance sampling and inverse probability weighting. However, the performance of the
active sampling algorithm in terms of variance depends on the adequacy of the prediction
model and capability of capturing the true signals in the data. It also depends on the
signal-to-noise-ratio between the inputs or auxiliary variables zi and response vectors yi.
13
The stronger the association, the greater the potential benefit of active sampling.
4.2 Variance estimation
To estimate the variance of our estimator ˆθ(k), we first need an estimator of the covariance
matrix Ψ(k) = Cov(ˆt
(k)
y ) for the pooled estimator ˆt
(k)
y of the finite population total ty.
Given such an estimate, the variance of ˆθ(k) = h(ˆt
(k)
y ) may be estimated using the delta
method as
dVar(ˆθ(k)) = ∇h(u)T ˆΨ
(k)
∇h(u)

u=ˆt(k)
y
, (4)
(see, e.g., Sen and Singer, 1993). Three different approaches to variance estimation are pre-
sented below and evaluated empirically in Section 6. A theoretical justification is provided
by Proposition S1 and Corollary S1 in Appendix A.2.
Method 1 (Design-based variance estimator): First, we may proceed as for the
estimator of the finite population total ty and use a pooled variance estimator
ˆΨ
(k)
1 = m−2
k
kX
j=1
n2
j ˆΦj,
where ˆΦj are (any) unbiased estimators of the conditional covariance matrices Φj =
Cov(ˆty,j|S1, . . . ,Sj−1). Each of the covariance matrices Φj may be estimated using stan-
dard survey sampling techniques. For instance, under the multinomial design we may use
Sen-Yates-Grundy estimator for Φj, i.e.,
ˆΦj = nj
nj − 1
X
i∈D
Sji
 yi
µji
−
ˆty,j
nj
 yi
µji
−
ˆty,j
nj
T
, µ ji = njπji,
provided that nj ≥ 2 (Sen, 1953; Yates and Grundy, 1953). For fixed-size designs with
nj = 1, other estimators must be used.
14
Method 2 (Martingale variance estimator): Alternatively, we may use the squared
variation of the individual estimates ˆty,j and estimate Ψ(k) by
ˆΨ
(k)
2 = m−2
k
kX
j=1
n2
j

ˆty,j − ˆt
(k)
y

ˆty,j − ˆt
(k)
y
T
.
This estimator arises immediately from the martingale theory used for our asymptotic
analyses in Appendix A.2. This method is particularly useful when the batch sizes are
small and the number of iterations large.
Method 3 (Bootstrap variance estimator): Finally, variance estimation may be con-
ducted by non-parametric bootstrap (Efron, 1979; Davison and Hinkley, 1997). If sub-
sampling is done with replacement, the importance-weighted bootstrap should be used to
account for possible differences in the number of selections per observation. Specifically,
the bootstrap sample size should be equal to the total sample size mk = Pk
j=1 nj (num-
ber of distinct selections), and the selection probabilities for the bootstrap proportional to
the number of selections Pk
j=1 sji per instance i. One way to achieve this with ordinary
bootstrap software is to create an augmented dataset with one record for each of the sji
selections, and perform ordinary non-parametric bootstrap on the augmented dataset. An
estimate of the covariance matrix of ˆt
(k)
y can then be obtained by
ˆΨ
(k)
3 = 1
B − 1
BX
b=1

˜t
(k)
y,b − ¯t(k)
y

ˆt
(k)
y,b − ¯t(k)
y
T
,
where ¯t(k)
y = 1
B
PB
b=1 ˜t
(k)
y,b is the mean of B bootstrap estimates ˜t
(k)
y,b of ty.
15
4.3 Asymptotic properties and interval estimation
Using the martingale central limit theorem of Brown (1971), we show that under mild
assumptions our active sampling estimator is consistent and asymptotically normally dis-
tributed, for fixed N and bounded batch sizes nk, as the number of iterations tends to
infinity (Proposition S1 and Corollary S1, Appendix A.2). The essential conditions for this
to hold are (in the scalar case) that:
i) the sampling probabilities are properly bounded away from zero,
ii) the total variance Var(Pk
j=1 ˆty,j ) tends to infinity as the number of iterations k → ∞,
and
iii) the ratio of the total variance Var( Pk
j=1 ˆty,j ) to the sum of conditional variances
Pk
j=1 Var(ˆty,j |S1, . . . ,Sj−1) converges in probability to 1 as k → ∞.
Similar conditions are sufficient also for consistent variance estimation. In this setting, we
note that the importance sampling scheme in Algorithm 1 remains optimal in the sense
of minimizing the variance contribution (or mean squared error contribution) from each
iteration of the algorithm, given the information available so far.
In practice, the first assumption may be violated by overfitting and underestimation
of the residual variance in the learning step of the active sampling algorithm. Both of
these issues may cause variance inflation and an erratic behavior of the estimator due
to incidentally large sample weights. The second assumption could be violated, e.g., for a
linear estimator in a noise-free setting where a perfect importance sampling scheme yielding
zero variance may be found. Indeed, an optimal importance sampling estimator would in
16
this case have zero variance and hence would not converge towards a normal limit. In most
cases, however, estimation- and prediction uncertainty are intrinsic to the problem, and the
second assumption is trivially fulfilled in most realistic applications. The third assumption
is more of technical nature and needed to ensure that the statistical properties of the active
sampling estimator can be deduced from a single execution of the algorithm. Empirical
justification for these assumptions is provided in Section 6.
Confidence intervals can be calculated using the classical large sample formula
ˆθ(k) ± zα/2 × SEˆθ(k) (5)
where ˆθ(k) is the estimate of the characteristic θ, SE ˆθ(k) =
q
dVar(ˆθ(k)) the corresponding
standard error, and zα/2 the α/2-quantile of a standard normal distribution. Under the
assumptions stated above, such a confidence interval has approximately 100 × (1 − α)%
coverage of the true population characteristic θ, under repeated subsampling from D, in
large enough samples.
4.4 How many samples are needed?
An important practical question is how many samples or iterations of the active sampling
algorithm that are required for estimating a characteristic θ with sufficient precision. This
question can be addressed as follows. First, a pilot sample may be selected to obtain an
initial estimate of θ with a corresponding estimate for the variance. A precision calculation
may then be conducted using standard theory for simple random sampling designs, and
the number of samples needed for a certain level of precision deduced. This would give a
conservative estimate of the sample size needed for the active sampling algorithm, which
17
usually can be terminated for sufficient precision with much smaller samples. Importantly,
the pilot sample can be re-used in the first iteration of the active sampling algorithm and
hence comes at no additional cost. It also possible to monitor the precision of the active
sampling estimator during execution of the algorithm and possibly update the precision
target or iteration limit as needed.
5 Simulation experiments
We evaluated the empirical performance of the active sampling method by repeated sub-
sampling on synthetic data. Methods are described in Section 5.1 and results in Section
5.2.
5.1 Data and Methods
We generated a total of 24 datasets with varying support, signal-to-noise-ratio, and degree
of non-linearity in the association between a scalar auxiliary variable zi and scalar response
variable yi. This was done as follows. First, N = 103 data points zi were generated on a
uniform grid from 0.001 to 1. This was taken as our auxiliary variable. Next we generated
a variable yi according to a Gaussian process, using a Gaussian kernel with bandwidth σ.
This was taken as the study variable of interest. We varied the bandwidth σ = 0.1, 1, 10,
corresponding to a non-linear, polynomial, and linear scenario (Figure 2). We also varied
the residual variance to obtain a coefficient of determination R2 = 0.10, 0.50, 0.75, 0.90 for
the true model, corresponding to a low, moderate, high, and very high signal-to-noise ratio.
Finally, we normalized the response variable to have unit variance, positive correlation
18
with the auxiliary variable, and support on the positive real line (strictly positive scenario,
min1≤i≤N yi = 0.1) or zero mean (unrestricted scenario, ¯y = 0, yi ∈ R).
Figure 2: Examples of three synthetic datasets with varying degree of non-linearity. Data were
generated according to a Gaussian process, using a Gaussian kernel with bandwidth σ.
We used active sampling to estimate the finite population mean ¯ y using a linear esti-
mator h(u) = u/N, yi = yi, and non-linear (H´ ajek) estimatorh(u) = u2/u1, y = (1, yi)T .1
The active sampling algorithm was implemented according to Algorithm 1 with a batch
size of nk = 10 or nk = 50 observations per iteration. The learning step was implemented
using a simple linear regression model, generalized additive model (thin plate spline), ran-
dom forests, gradient boosting trees, and Gaussian process regression surrogate model for
yi given zi. For comparison we implemented simple random sampling using the before-
mentioned estimators (linear and non-linear), control variate estimator (Fishman, 1996),
and ratio estimator (S¨ arndal et al., 2003). We also compared to importance sampling
with probability proportional to the auxiliary variable zi. We finally implemented a naive
1In the non-adaptive setting, the linear estimator is given by N−1 P
i∈S Siwiyi and the H´ ajek estimator
by ˆN−1 P
i∈S Siwiyi, ˆN = P
i∈S Siwi.
19
version of the active sampling algorithm ignoring prediction uncertainty, i.e., setting the
residual covariance matrix equal to zero in the optimization step of the algorithm. This is
the same as to plug in the predictions from the surrogate model into the formula for the
theoretically optimal sampling scheme of Proposition 1, treating the predictions as known
true values of the yi’s. Each sampling method was repeated 500 times for sample sizes up
to n = 250 observations.
The performance was measured by the root mean squared error of the estimator (eRMSE)
for the finite population mean ¯y, calculated as
RMSE(ˆθ) =
vuut 1
m
MX
m=1
(ˆθm(n) − θ)2, (6)
where ˆθm(n) is the estimate in the mth simulation from a sample of size n, M = 500 the
number of simulations, and θ = ¯y the characteristic of interest (i.e., the ground truth).
The experiments were implemented using theR language and environment for statistical
computing (R Core Team, 2023), version 4.2.3. The R code is available online at https:
//github.com/imbhe/ActiveSampling.
5.2 Results
The results of active sampling compared to four benchmark methods are shown in Figure
3 for the strictly positive scenario, linear estimator, batch size nk = 10, and linear or gen-
eralized additive surrogate model. Results under other settings are presented in Appendix
C.1.
There were substantial reductions in eRMSE with active sampling compared to both
simple random sampling and standard variance reduction techniques in the non-linear (σ =
20
0.1) and polynomial ( σ = 1) scenarios when a generalized additive surrogate model was
used (Figure 3). Similar results were observed also using random forests, gradient boosting
trees, and Gaussian process regression as surrogate models (Figure S1, Appendix C.1). In
contrast, there was a slight advantage of the standard variance reduction techniques in the
linear setting (σ = 10). Batch size influenced the performance, with a better performance
when using a smaller (nk = 10) compared to larger batch size (nk = 50). However, the effect
of batch size was attenuated as the number of iterations increased (Figure S2, Appendix
C.1). The benefits of active sampling were somewhat smaller in the unrestricted scenario
(¯y = 0, yi ∈ R) and for non-linear estimators. Still, sample size reductions of up to 30%
were achieved compared to simple random sampling for the same level of performance
(Figure S3 and S4, Appendix C.1).
Notably, active sampling never performed worse than simple random sampling, even for
a misspecified model (i.e., when applying a linear surrogate model to non-linear data; Figure
3, Figure S3 and S4 in Appendix C.1). In contrast, a naive implementation of the active
sampling algorithm, ignoring prediction uncertainty, resulted in worse performance than
simple random sampling. This was particularly exacerbated in low signal-to-noise ratio
settings, for non-positive data, non-linear estimators, and misspecified models (Figure S5
and S6, Appendix C.1).
6 Application
We next implemented active sampling on the crash-causation-based scenario generation
problem introduced in Section 2. The data, model, and simulation set-up is described
21
Figure 3: Performance of active sampling using a linear surrogate model (LM) or generalized
additive surrogate model (GAM) compared to simple random sampling, ratio estimator, control
variates, and importance sampling for estimating a finite population mean in a strictly positive
scenario (all yi > 0) using a linear estimator ( h(u) = u/N) and batch size nk = 10. Results
are shown for 12 different scenarios with varying signal-to-noise ratio ( R2) and varying degree
of non-linearity ( σ) (cf. Figure 2). Shaded regions are 95% confidence intervals for the root
mean squared error of the estimator (eRMSE) based on 500 repeated subsampling experiments.
Asterisks show the smallest sample sizes for which there were persistent significant differences
(p < .05) between active sampling and simple random sampling.
22
in Section 6.1, together with methods for performance evaluation. Empirical results are
presented in Section 6.2.
6.1 Data and Methods
Ground truth dataset The data used for scenario generation in this study were recon-
structed pre-crash kinematics of 44 rear-end crashes from a crash database provided by
Volvo Car Corporation. This database contains information about crashes that occurred
with Volvo vehicles in Sweden (Isaksson-Hellman and Norin, 2005). We constructed a
ground truth dataset by running virtual simulations for all 1,005 combinations of glance
duration (67 levels, 0.0–6.6s) and deceleration (15 levels, 3.3–10.3 m/s 2) for all 44 crashes.
Additionally, each scenario configuration was associated with a prior probability pi of
occurring in real life, estimated by the empirical probability distribution of the glance-
deceleration distribution in real crashes. The simulations were run under both manual
driving (baseline scenario) and automated emergency braking (AEB) system conditions,
producing a dataset of 44,220 pairs of observations. Running the complete set of simula-
tions took about 50 hours, running 26 threads in parallel on a high-performance computer
equipped with 24 Intel ® Xeon® CPU E5-2620 processors.
Outcomes and measurements The outputs of the simulations were the impact speed
under both scenarios (baseline and AEB). We also calculated the impact speed reduction
(continuous) and crash avoidance (binary) of the AEB system compared to the baseline
scenario. The aim in our experiments was to estimate the benefit of the AEB system, as
measured by mean impact speed reduction and crash avoidance rate compared to baseline
23
manual driving, given that there was a crash in the baseline scenario. Accounting for the
prior observation weights (scenario probabilities) pi, the target characteristic θ may in this
case be written as
θ =
PN
i=1 pi(yi,0 − yi,1)I(yi,0 > 0)PN
i=1 piI(yi,0 > 0)
(7)
where yi,0 is the outcome of the simulation (e.g, impact speed or binary crash indicator) un-
der the baseline scenario, yi,1 the corresponding outcome with the countermeasure (AEB),
and I(yi,0 > 0) a binary indicator taking the value 1 if there was a collision in the baseline
scenario and 0 otherwise. The observation weights pi are known a priori and need not be
learned from data. This makes our problem particularly suitable for importance sampling
methods. Note also that there may be large regions in the input space generating no crash
(cf. Figure 1), hence providing no information for the characteristic θ. Active sampling
offers an opportunity to learn and exploit this feature during the sampling process.
As auxiliary variables we used the glance duration and maximal deceleration during
braking, i.e., the inputs to the virtual simulation experiment, and an a priori known
maximal impact speed per original crash event. The maximal impact speed was considered
as a means to summarize a 44-level categorical variable (ID of the original crash event)
as a single numeric variable in the random forest algorithm used for the learning step
of the active sampling method; see Implementation below and Appendix B for further
details. Although comprising only three variables, this corresponds with ordinary statistical
methods to an 88-dimensional vector of auxiliary variables (or greater, if non-linear terms
are included), counting all the interactions between glance duration and deceleration with
the 44 original crash events.
24
Confidence interval coverage rates We evaluated the large-sample normal confidence
intervals (5) with the three different methods for variance estimation described in Sec-
tion 4.2: the design-based (pooled Sen-Yates-Grundy) estimator, martingale estimator,
and bootstrap estimator. The empirical coverage rates of the confidence intervals were
calculated using 500 repeated subsampling experiments.
Active sampling performance evaluation We evaluated the performance of the ac-
tive sampling method for estimating the mean impact speed reduction or crash avoidance
rate of an AEB system compared to baseline driving (without AEB). Active sampling
performance was evaluated against simple random sampling, importance sampling, Latin
hypercube sampling (Cioppa and Lucas, 2007; Meng et al., 2021), leverage sampling (Ma
et al., 2015, 2022), and active learning with Gaussian processes. Two importance sam-
pling schemes were considered: a density sampling scheme with probabilities proportional
to the prior observation weights pi, and a severity sampling scheme that additionally at-
tempts to oversample high-severity instances (i.e., with low deceleration and long glances).
Each subsampling method was repeated 500 times up to a total sample size of n = 2, 000
observations. The performance was measured by the root mean squared error of the esti-
mator (eRMSE) compared to ground truth, calculated as in (6). The results are presented
graphically as functions of the sample size, i.e., the number of baseline-AEB simulations
pairs.
Implementation The empirical evaluation was implemented using the R language and
environment for statistical computing, version 4.2.1 (R Core Team, 2023). Active sampling
25
was implemented with a batch size of nk = 10 observations per iteration. Random forests
(Breiman, 2001) were used for the learning step of the algorithm. We also performed
sensitivity analyses for the choice of machine learning algorithm using extreme gradient
boosting (Chen and Guestrin, 2016) and k-nearest neighbors. Latin hypercube sampling
was implemented similarly to Meng et al. (2021). Statistical leverage scores for the leverage
sampling method were calculated using weighted least squares with the two auxiliary vari-
ables (off-road glance duration and maximal deceleration during braking) as explanatory
variables and the prior scenario probabilities pi as weights. The Gaussian process active
learning method was implemented using a probabilistic uncertainty scheme, with proba-
bilities proportional to the posterior uncertainty (standard deviation) of the predictions.
This was chosen based on computational considerations and to promote exploration of
the design space. For Gaussian process active learning, estimation was conducted using a
model-based estimator by evaluating the predictions over the entire input space. All other
methods used observed data rather than predicted values for estimation. Further imple-
mentation details are provided in Appendix B. The R code and data are available online at
https://github.com/imbhe/ActiveSampling.
6.2 Results
Confidence interval coverage rates The empirical coverage rates of large-sample nor-
mal confidence intervals under active sampling are presented in Figure 4. There was a
clear under-coverage in small samples, as expected. Both the pooled Sen-Yates-Grundy
estimator and bootstrap variance estimator produced confidence intervals that approached
26
the nominal 95% confidence level relatively quickly as the sample size increased. Coverage
rates were somewhat lower with the martingale variance estimator, and more iterations
where needed before the nominal 95% level was reached.
Figure 4: Empirical coverage rates of 95% confidence intervals for the mean impact speed reduction
(A) and crash avoidance rate (B) using active sampling. The lines show the coverage rates with
three different methods for variance estimation in 500 repeated subsampling experiments. A batch
size of nk = 10 observations per iteration was used.
Active sampling performance evaluation The eRMSE with active sampling com-
pared to five benchmark methods is presented in Figure 5. Simple random sampling and
Latin hypercube sampling overall performed worst and had similar performance. Active
learning using Gaussian processes had good performance for the crash avoidance (which
was relatively constant over the input space, with 80% of all crashes avoided by the AEB),
but poor performance for the impact speed reduction (which varied more and was harder
to predict). With the other methods, estimation variance in the early iterations was largely
27
driven by the variance of the scenario probability weights in the subsample. In contrast,
estimation variance for the model-based (Gaussian process) response surface estimator was
attenuated by evaluating predictions over the entire input space. Leverage sampling and
the two importance sampling schemes had similar performance, with a slight advantage
of severity importance sampling for estimating the crash avoidance rate. Active sampling
optimized for a specific characteristic had best performance on the characteristic for which
it was optimized. Significant improvements compared to the best performing benchmark
method were observed from around 400 samples for estimating the crash avoidance rate
and 700 observations for estimating the mean impact speed reduction.
The benefit of active sampling increased with the sample size. At n = 2, 000 observa-
tions, a reduction in eRMSE of 20–39% was observed compared to importance sampling.
Accordingly, active sampling required up to 46% fewer observations than importance sam-
pling to reach the same level of performance on the characteristic for which it was optimized.
Moreover, active sampling performance was on par with that of traditional methods when
evaluated on characteristics other than the one it was optimized for. Similar results were
observed when using k-nearest neighbors and extreme gradient boosting as auxiliary models
for the learning step of the active sampling algorithm (Figure S7, Appendix C.2).
Active sampling was also relatively fast and required about 60 seconds for running 200
iterations (generating n = 2, 000 samples) on a laptop computer equipped with an AMD
Ryzen 7 PRO 585OU 1.90 GHz processor. The Gaussian process active learning method
required approximately 270 seconds to generate the same number of samples.
28
Figure 5: Root mean squared error (eRMSE) for estimating the mean impact speed reduction (A)
and crash avoidance rate (B). The lines show the performance using simple random sampling, im-
portance sampling, Latin hypercube sampling, leverage sampling, Gaussian process active learn-
ing, and active sampling optimized for the estimation of the mean impact speed reduction and
crash avoidance rate. Shaded regions represent 95% confidence intervals for the eRMSE based on
500 repeated subsampling experiments. Asterisks show the smallest sample sizes for which there
were persistent significant differences (p < .05) between active sampling and the best performing
benchmark method.
7 Discussion
We have presented an active sampling framework for finite population inference with op-
timal subsamples. Active sampling outperformed standard variance reduction techniques
in non-linear settings, and also in linear settings with moderate signal-to-noise ratio. We
evaluated the performance of active sampling for safety assessment of advanced driver
assistance systems in the context of crash-causation-based scenario generation. Substan-
29
tial improvements over traditional importance sampling methods were demonstrated, with
sample size reductions of up to 50% for the same level of performance in terms of eRMSE.
In our application, active sampling was also superior to space-filling, leverage sampling,
and Gaussian process active learning methods.
Our work contributes to the ongoing development of subsampling methods in statistics
and for computer simulation experiments in particular. In this context, Gaussian processes
and space-filling methods have been particularly popular and shown great success for a
variety of tasks (Cioppa and Lucas, 2007; Sun et al., 2017; Feng et al., 2020; Batsch et al.,
2021; Lim et al., 2021). In our application, however, neither space-filling methods nor
Gaussian process active learning performed as well as importance sampling or active sam-
pling. Although we cannot rule out that another implementation of the Gaussian process
active learning method could have had better performance, the active sampling framework
is less model-dependent and thus is superior for finite population inference. Furthermore,
we have proved theoretically that active sampling provides consistent estimators under
general conditions. This was also confirmed in our experiments. In our application, we
believe that the model-based (Gaussian process) approach to computer experiment emu-
lation is affected by the high complexity of our problem, involving not only one but 44
response surfaces (one per original crash event) that must be learned simultaneously. Yet,
this is a fairly small example for scenario generation problems (cf. Ettinger et al., 2021;
Duoba and Baby, 2023) and comprises only a fraction of the crashes in the original crash
database (Isaksson-Hellman and Norin, 2005). Substantial sample sizes would be needed
to accurately model all of the response surfaces. Active sampling, targeting a much simpler
30
problem, requires only a rough sketch of the response surface(s) to identify which regions
are most informative for estimating the characteristic of interest.
The choice of batch size influenced the performance of the active sampling algorithm,
although less so when the number of iterations were large. In practice, one may need
to balance the benefits of a smaller batch size on increased statistical efficiency with the
benefits of a larger batch size (involving fewer model updates) on increased computational
efficiency. With flexible machine learning methods and proper hyper-parameter tuning,
carefully avoiding overfitting, we expect this to hold irrespective of the dimension of the
problem, although in higher dimensions larger batch sizes may be favored both for compu-
tational efficiency and numerical stability. The choice of prediction model had limited influ-
ence on performance, as long as the model was flexible enough to capture the true signals in
the data. In computer simulation experiment applications, both computational aspects and
anticipated performance should be considered for choosing an appropriate model. It is also
possible to utilize several machine learning algorithms in the early iterations of the active
sampling algorithm to identify the computationally simplest possible model that does not
compromise the accuracy of the estimate. Importantly, active sampling was never worse
than simple random sampling, even for a misspecified model. Moreover, using an overly
complex model (e.g., a non-linear auxiliary model when the true association is linear) only
resulted in a minor loss of efficiency of the active sampling estimator. In contrast, ignoring
prediction uncertainty resulted in poor performance, particularly in non-linear settings and
for misspecified models.
This paper illustrated the active sampling method in an application to generation of sim-
31
ulation scenarios for the assessment of automated emergency braking. In this application,
the computation time for running the active sampling algorithm is orders of magnitudes
smaller than the computation time for running the corresponding virtual computer experi-
ment simulations. The computational overhead of the training and optimization steps of the
active sampling algorithm is thus negligible. The gain in terms of sample size reductions for
a given eRMSE therefore translates to a corresponding reduction in total computation time
of equal magnitude. The precision obtained by active sampling at n = 2, 000 observations
corresponds to an error margin of about ± 0.5 km/h for the mean impact speed reduction
and ±1.0 percentage points for the crash avoidance rate, which may be considered suffi-
cient in a practical setting. This corresponds to savings of about 95% in computation time
compared to complete enumeration. Not only can the method be applied more broadly
in the traffic safety domain, such as for virtual safety assessment of self-driving vehicles
of the future, but it can be applied to a wide range of subsampling applications. Future
research on the topic may pursue more efficient methods of partitioning the dataset into
areas where the outcomes are more precisely predicted or known (where subsampling is
less useful) and those where outcomes are less precisely predicted, as well as demonstrate
practical applications further.
8 Conclusion
We have introduced a machine-learning-assisted active sampling framework for finite pop-
ulation inference, with application to a deterministic computer simulation experiment.
We proved theoretically that active sampling provides consistent estimators under general
32
conditions. It was also demonstrated empirically to be robust under different choices of
machine learning model. Methods for variance and interval estimation have been proposed,
and their validity in the active sampling setting was confirmed empirically. Properly ac-
counting for prediction uncertainty was crucial for the performance of the active sampling
algorithm. Substantial performance improvements were observed compared to traditional
variance reduction techniques and response surface modeling methods. Active sampling is
a promising method for efficient sampling and finite population inference in subsampling
applications.
Acknowledgment
We would like to thank Volvo Car Corporation for allowing us to use their data and sim-
ulation tool, and in particular Malin Sv¨ ard and Simon Lundell at Volvo for supporting in
the simulation setup. We further want to thank Marina Axelson-Fisk and Johan Jonas-
son at the Department of Mathematical Sciences, Chalmers University of Technology and
University of Gothenburg, for valuable comments on the manuscript.
Funding
This research was supported by the European Commission through the SHAPE-IT project
under the European Union’s Horizon 2020 research and innovation programme (under the
Marie Sk lodowska-Curie grant agreement 860410), and in part also by the Swedish funding
agency VINNOVA through the FFI project QUADRIS. Also Chalmers Area of Advance
33
Transport funded part of this research.
Conflict of interest
The authors report there are no competing interests to declare.
SUPPLEMENTARY MATERIAL
Supplementary Appendix: Additional theoretical results and proofs (Appendix A), de-
tails on the implementation of the sampling methods in the application (Appendix
B), and additional experiment results (Appendix C).
R code and data: R code and data used for the empirical evaluation in Section 5, appli-
cation in Section 6, and replication of main results (Figure 3–5) is available online at
https://github.com/imbhe/ActiveSampling.
References
Ai, M., Wang, F., Yu, J., and Zhang, H. (2021a). Optimal subsampling for large-scale
quantile regression. Journal of Complexity , 62:101512.
Ai, M., Yu, J., Zhang, H., and Wang, H. (2021b). Optimal subsampling algorithms for big
data regressions. Statistica Sinica, 31:749–772.
Bach, F. R. (2007). Active learning for misspecified generalized linear models. In Advances
in Neural Information Processing Systems 19 .
34
B¨ argman, J., Lisovskaja, V., Victor, T., Flannagan, C., and Dozza, M. (2015). How does
glance behavior influence crash and injury risk? A ‘what-if’ counterfactual simulation
using crashes and near-crashes from SHRP2. Transportation Research Part F: Traffic
Psychology and Behaviour , 35:152–169.
Batsch, F., Daneshkhah, A., Palade, V., and Cheah, M. (2021). Scenario optimisation
and sensitivity analysis for safe automated driving using Gaussian processes. Applied
Sciences, 11(2):775.
Beaumont, J.-F. and Haziza, D. (2022). Statistical inference from finite population samples:
A critical review of frequentist and Bayesian approaches. Canadian Journal of Statistics ,
50(4):1186–1212.
Beygelzimer, A., Dasgupta, S., and Langford, J. (2009). Importance weighted active learn-
ing. In Proceedings of the 26th International Conference on Machine Learning .
Boyd, S. and Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press,
Cambridge, UK.
Breidt, F. J. and Opsomer, J. D. (2017). Model-assisted survey estimation with modern
prediction techniques. Statistical Science, 32(2):190–205.
Breiman, L. (2001). Random forests. Machine Learning, 45:5–32.
Brown, B. M. (1971). Martingale central limit theorems. The Annals of Mathematical
Statistics, 42(1):59–66.
35
Bucher, C. G. (1988). Adaptive sampling — an iterative fast Monte Carlo procedure.
Structural safety, 5(2):119–126.
Cassel, C. M., S¨ arndal, C.-E., and Wretman, J. H. (1976). Some results on general-
ized difference estimation and generalized regression estimation for finite populations.
Biometrika, 63(3):615–620.
Chen, T. and Guestrin, C. (2016). XGBoost: A scalable tree boosting system. In Proceed-
ings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining.
Cioppa, T. M. and Lucas, T. W. (2007). Efficient nearly orthogonal and space-filling latin
hypercubes. Technometrics, 49(1):45–55.
Cohn, D. A. (1996). Neural network exploration using optimal experiment design. Neural
Networks, 9(6):1071–1083.
Dai, W., Song, Y., and Wang, D. (2022). A subsampling method for regression problems
based on minimum energy criterion. Technometrics, 65(2):192–205.
Davison, A. C. and Hinkley, D. V. (1997). Bootstrap Methods and Their Applications .
Cambridge University Press, Cambridge, UK.
Deville, J.-C. and S¨ arndal, C.-E. (1992). Calibration estimators in survey sampling.Journal
of the American Statistical Association , 87(418):376–382.
Duoba, M. and Baby, T. V. (2023). Tesla Model 3 autopilot on-road data. Technical report,
36
Livewire Data Platform; National Renewable Energy Laboratory; Pacific Northwest Na-
tional Laboratory, Richland, WA.
Efron, B. (1979). Bootstrap methods: Another look at the jackknife. The Annals of
Statistics, 7(1):1 – 26.
Ettinger, S., Cheng, S., Caine, B., Liu, C., Zhao, H., Pradhan, S., Chai, Y., Sapp, B., Qi,
C. R., Zhou, Y., Yang, Z., Chouard, A., Sun, P., Ngiam, J., Vasudevan, V., McCauley,
A., Shlens, J., and Anguelov, D. (2021). Large scale interactive motion forecasting for
autonomous driving: The Waymo open motion dataset. In Proceedings of the IEEE/CVF
International Conference on Computer Vision (ICCV) .
Feng, S., Feng, Y., Yu, C., Zhang, Y., and Liu, H. X. (2020). Testing scenario library gen-
eration for connected and automated vehicles, part I: Methodology. IEEE Transactions
on Intelligent Transportation Systems , 22(3):1573–1582.
Feng, S., Yan, X., Sun, H., Feng, Y., and Lui, H. X. (2021). Intelligent driving intelligence
test for autonomous vehicles with naturalistic and adversarial environment.Nature Com-
munitations, 12(748):1–14.
Fishman, G. S. (1996). Monte Carlo. Springer, New York, NY.
Fuller, W. A. (2009). Sampling Statistics. Wiley, Hoboken, NJ.
Gramacy, R. B. and Apley, D. W. (2015). Local Gaussian process approximation for large
computer experiments. Journal of Computational and Graphical Statistics , 24(2):561–
578.
37
Hall, P. and Heyde, C. (1980). Martingale Limit Theory and Its Application . Academic
Press, New York, NY.
Hansen, M. H. and Hurwitz, W. N. (1943). On the theory of sampling from finite popula-
tions. The Annals of Mathematical Statistics , 14(4):333–362.
Ho, D. E., Imai, K., King, G., and Stuart, E. A. (2011). MatchIt: Nonparametric prepro-
cessing for parametric causal inference. Journal of Statistical Software , 42(8):1–28.
Horvitz, D. G. and Thompson, D. J. (1952). A generalization of sampling without replace-
ment from a finite universe.Journal of the American Statistical Association, 47(260):663–
685.
Imberg, H., Jonasson, J., and Axelson-Fisk, M. (2020). Optimal sampling in unbiased active
learning. In Proceedings of the 23rd International Conference on Artificial Intelligence
and Statistics.
Imberg, H., Lisovskaja, V., Selpi, and Nerman, O. (2022). Optimization of two-phase
sampling designs with application to naturalistic driving studies. IEEE Transactions on
Intelligent Transportation Systems, 23(4):3575–3588.
Isaksson-Hellman, I. and Norin, H. (2005). How thirty years of focused safety development
has influenced injury outcome in Volvo cars. Annual Proceedings. Association for the
Advancement of Automotive Medicine, 49:63–77.
Karatzoglou, A., Smola, A., Hornik, K., and Zeileis, A. (2004). kernlab – an S4 package
for kernel methods in R. Journal of Statistical Software , 11(9):1–20.
38
Kern, C., Klausch, T., and Kreuter, F. (2019). Tree-based machine learning methods for
survey research. Survey Research Methods, 13(1):73–93.
Kott, P. S. (2016). Calibration weighting in survey sampling. WIREs Computational
Statistics, 8(1):39–53.
Kuhn, M. (2008). Building predictive models in R using the caret package. Journal of
Statistical Software, 28(5):1–26.
Lee, J. Y., Lee, J. D., B¨ argman, J., Lee, J., and Reimer, B. (2018). How safe is tuning
a radio?: using the radio tuning task as a benchmark for distracted driving. Accident
Analysis & Prevention, 110:29–37.
Lei, B., Kirk, T. Q., Bhattacharya, A., Pati, D., Qian, X., Arroyave, R., and Mallick,
B. K. (2021). Bayesian optimization with adaptive surrogate models for automated
experimental design. npj Computational Materials , 194:1–12.
Leledakis, A., Lindman, M., ¨Osth, J., W˚ agstr¨ om, L., Davidsson, J., and Jakobsson, L.
(2021). A method for predicting crash configurations using counterfactual simulations
and real-world data. Accident Analysis & Prevention, 150:105932.
Lim, Y.-F., Ng, C. K., Vaitesswar, U., and Hippalgaonkar, K. (2021). Extrapolative
Bayesian optimization with Gaussian process and neural network ensemble surrogate
models. Advanced Intelligent Systems, 3(11):2100101.
Liu, K., Mei, Y., and Shi, J. (2015). An adaptive sampling strategy for online high-
dimensional process monitoring. Technometrics, 57(3):305–319.
39
Lookman, T., Balachandran, P. V., Xue, D., and Yuan, R. (2019). Active learning in
materials science with emphasis on adaptive sampling using uncertainties for targeted
design. npj Computational Materials , 5(21):1–17.
Ma, P., Chen, Y., Zhang, X., Xing, X., Ma, J., and Mahoney, M. W. (2022). Asymp-
totic analysis of sampling estimators for randomized numerical linear algebra algorithms.
Journal of Machine Learning Research , 23(177):1–45.
Ma, P., Mahoney, M. W., and Yu, B. (2015). A statistical perspective on algorithmic
leveraging. Journal of Machine Learning Research , 16:861–911.
MacKay, D. J. C. (1992). Information-based objective functions for active data selection.
Neural Computation, 4(4):590–604.
McConville, K. S. and Toth, D. (2019). Automated selection of post-strata using a model-
assisted regression tree estimator. Scandinavian Journal of Statistics , 46(2):389–413.
Meng, C., Xie, R., Mandal, A., Zhang, X., Zhong, W., and Ma, P. (2021). LowCon: A
design-based subsampling approach in a misspecified linear model. Journal of Compu-
tational and Graphical Statistics , 30(3):694–708.
Oh, M.-S. and Berger, J. O. (1992). Adaptive importance sampling in Monte Carlo inte-
gration. Journal of Statistical Computation and Simulation , 41(3–4):143–168.
Pan, Q., Byon, E., Ko, Y. M., and Lam, H. (2020). Adaptive importance sampling for
extreme quantile estimation with stochastic black box computer models. Naval Research
Logistics, 67(7):524–547.
40
Pregibon, D. (1981). Logistic regression diagnostics. The Annals of Statistics, 9(4):705–724.
R Core Team (2023). R: A Language and Environment for Statistical Computing . R
Foundation for Statistical Computing, Vienna, Austria.
Ren, P., Xiao, Y., Chang, X., Huang, P.-Y., Li, Z., Gupta, B. B., Chen, X., and Wang, X.
(2021). A survey of deep active learning. ACM Computing Surveys , 54(9):1–40.
Sande, L. and Zhang, L. (2021). Design-unbiased statistical learning in survey sampling.
Sankhya A, 83:714–744.
Sauer, A., Gramacy, R. B., and Higdon, D. (2023). Active learning for deep Gaussian
process surrogates. Technometrics, 65(1):4–18.
Sen, A. (1953). On the estimate of the variance in sampling with varying probabilities.
Journal of the Indian Society of Agricultural Statistics , 5:119–127.
Sen, P. and Singer, J. (1993). Large Sample Methods in Statistics: An Introduction with
Applications. CRC Press, Boca Raton, FL.
Settles, B. (2012). Active learning.Synthesis Lectures on Artificial Intelligence and Machine
Learning, 6(1):1–114.
Seyedi, M., Koloushani, M., Jung, S., and Vanli, A. (2021). Safety assessment and a para-
metric study of forward collision-avoidance assist based on real-world crash simulations.
Journal of Advanced Transportation, 2021:1–24. Article ID 4430730.
41
Sun, F., Gramacy, R. B., Haaland, B., Lawrence, E. C., and Walker, A. C. (2017). Emu-
lating satellite drag from large simulation experiments. SIAM/ASA Journal on Uncer-
taintity Quantification, 7:720–759.
Sun, J., Zhou, H., Xi, H., Zhang, H., and Tian, Y. (2021). Adaptive design of exper-
iments for safety evaluation of automated vehicles. IEEE Transactions on Intelligent
Transportation Systems, 23(9):14497–14508.
S¨ arndal, C.-E., Swensson, B., and Wretman, J. (2003). Model Assisted Survey Sampling .
Springer, New York, NY.
Ta, T., Shao, J., Li, Q., and Wang, L. (2020). Generalized regression estimators with
high-dimensional covariates. Statistica Sinica, 30(3):1135–1154.
Till´ e, Y. (2006).Sampling Algorithms. Springer, New York, NY.
Wang, H., Zhu, R., and Ma, P. (2018). Optimal subsampling for large sample logistic
regression. Journal of the American Statistical Association , 113(522):829–844.
Wang, X., Peng, H., and Zhao, D. (2021). Combining reachability analysis and importance
sampling for accelerated evaluation of highway automated vehicles at pedestrian crossing.
ASME Letters in Dynamic Systems and Control , 1(1):011017.
World Health Organization (2018). Global status report on road safety 2018 . URL https:
//www.who.int/publications/i/item/9789241565684.
Wright, M. N. and Ziegler, A. (2017). ranger: A fast implementation of random forests for
high dimensional data in C++ and R. Journal of Statistical Software , 77(1):1–17.
42
Xian, X., Wang, A., and Liu, K. (2018). A nonparametric adaptive sampling strategy for
online monitoring of big data streams. Technometrics, 60(1):14–25.
Yao, Y. and Wang, H. (2019). Optimal subsampling for softmax regression. Statistical
Papers, 60:585–599.
Yates, F. and Grundy, P. M. (1953). Selection without replacement from within strata
with probability proportional to size. Journal of the Royal Statistical Society. Series B
(Methodological), 15(2):253–261.
Yu, J., Wang, H., Ai, M., and Zhang, H. (2022). Optimal distributed subsampling for max-
imum quasi-likelihood estimators with massive data. Journal of the American Statistical
Association, 117(537):265–276.
Zhang, J., Meng, C., Yu, J., Zhang, M., Zhong, W., and Ma, P. (2023). An optimal
transport approach for selecting a representative subsample with application in efficient
kernel density estimation. Journal of Computational and Graphical Statistics, 32(1):329–
339.
Zhang, M., Zhou, Y., Zhou, Z., and Zhang, A. (2024). Model-free subsampling method
based on uniform designs. IEEE Transactions on Knowledge and Data Engineering ,
36(3):1210–1220.
Zhang, T., Ning, Y., and Ruppert, D. (2021). Optimal sampling for generalized linear mod-
els under measurement constraints. Journal of Computational and Graphical Statistics ,
30(1):106–114.
43
Zhou, Z., Yang, Z., Zhang, A., and Zhou, Y. (2024). Efficient model-free subsampling
method for massive data. Technometrics, 66(2):240–252.
44
A Additional theoretical results and proofs
This appendix contains additional theoretical results and proofs. The optimality of the
importance sampling schemes in Proposition 1 and 2 is proven in Appendix A.1. An
asymptotic analysis of the active sampling estimator is presented in Appendix A.2.
For a sequence of random variables {X, Xn, n≥ 1}, we use Xn
d
→ X, Xn
p
→ X and
Xn
Lr
→ X to denote convergence of Xn to X in distribution, in probability, and in rth mean,
respectively. We will also make use of the following results:
i) Dominated convergence theorem: Let {X, Xn, n≥ 1} be a sequence of random
variables such that Xn
p
→ X and E[supj≥1 |Xj|] < ∞. Then Xn
L1
→ X.
ii) Cram´ er-Wold theorem: Let X, X1, X2, . . .be random vectors in Rd. Then Xn
d
→
X if and only if, for every fixed λ ∈ Rd, we have λT Xn
d
→ λT X.
iii) Delta method : Let {Xn} be a sequence of random vectors such that √n(Xn −
τ0)
d
→ N(0, Γ0). Consider a function h : Rd → R and assume that h(u) is differen-
tiable in a neighborhood of τ = τ0. Then
√n(h(Xn) − h(τ0))
d
→ N
 
0, h(τ0)T Γ0∇h(τ0)

as n → ∞, (S.1)
provided that h(τ0)T Γ0∇h(τ0) > 0.
For further details, we refer to Sen and Singer (1993).
45
A.1 Optimal importance sampling schemes
We present in this section proofs of Proposition 1 and 2. First, two lemmas are presented.
Lemma 1
Let S = (S1, . . . , SN ) ∼ Multinomial(n, π), π = (π1, . . . , πN ), µ := E[S] = ( µ1, . . . , µN ).
Let
ˆty =
NX
i=1
Siwiyi, w i := E[Si]−1 = (nπi)−1.
Then the covariance matrix of ˆty is given by
Cov(ˆty) = 1
n
 NX
i=1
yiyT
i
πi
−
NX
i,j=1
yiyT
j
!
.
Lemma 2
Let π = (π1, . . . , πN ) and consider the function
f(π) =
NX
i=1
ci
πi
(S.2)
for some coefficients ci > 0. Subject to the constraints
NX
i=1
πi = 1, π i > 0,
f(π) is minimized by π∗ = (π∗
1, . . . , π∗
N ) with
π∗
i =
√ci
PN
j=1
√cj
, i = 1, . . . , N.
Proof of Lemma 1
By properties of the multinomial distribution, we have that
µi := E[Si] = nπi, Var(Si) = nπi(1 − πi), Cov(Si, Sj) = −nπiπj,
46
for i, j= 1, . . . , N, i̸= j. Hence,
Cov(ˆty) = Cov
 NX
i=1
Siwiyi
!
=


NX
i=1
nπi(1 − πi)
n2π2
i
yiyT
i −
NX
i,j=1
i̸=j
nπiπj
n2πiπj
yiyT
j


= 1
n


NX
i=1
1 − πi
πi
yiyT
i −
NX
i,j=1
i̸=j
yiyT
j

 = 1
n
 NX
i=1
yiyT
i
πi
−
NX
i,j=1
yiyT
j
!
.
□
Proof of Lemma 2
Using the method of Lagrange multipliers (Boyd and Vandenberghe, 2004), we introduce
the auxiliary function
Λ(π, λ) = f(π) + λg(π), g (π) =
NX
i=1
πi − 1 .
Critical points of the Lagrangian are found by solving the equation system
∇Λ(π, λ) = 0 ⇔



g(π) = 0
−∇πf(π) = λ∇πg(π)
.
Since ∂f (π)
∂πi
= −ci/π2
i and ∂g(π)
∂πi
= 1 , this implies that λ = c1/π2
1 = . . .= cN /π2
N , and
further that |πi| ∝ |√ci|. Since ci > 0, πi > 0 and PN
i=1 πi = 1, we obtain
π∗
i =
√ci
PN
j=1
√cj
, i = 1, . . . , N. (S.3)
Thus, the point (π∗, λ∗) with entries π∗
i defined according to (S.3) and λ∗ = c1/π∗2
1 is a
stationary point of Λ(π, λ). Hence, π∗ is a stationary point of f(π) under the specified
constraints. Specifically, π∗ is a local minimum. Since we consider a convex function over
a convex set, π∗ also is a global minimum. This proves the optimality of (S.3). □
47
Proof of Proposition 1
Let ˆty,k = PN
i=1 Skiwkiyi, wki = (mkπi)−1, and ˆθk = h(ˆty,k). Since Sk ∼ Multinomial(mk, π),
it can be written as the sum Sk = X1 + . . .+ Xmk of mk independent multinoulli ran-
dom variables Xj ∼ Multinomial(1, π), j = 1 , . . . , k. The estimator ˆty,k can there-
fore also be written as the sum ˆty,k = Pmk
j=1 Tj of mk independent random variables
Tj = 1
mk
PN
i=1 π−1
i Xjiyi with common mean m−1
k ty. Since {yi}N
i=1 and π are fixed, the
covariance matrices of {Tj}j≥1 are all finite. By the central limit theorem for triangular
arrays of independent random variables, it follows that
√mk(ˆty,k − ty)
d
→ N(0, Γ0) as k → ∞.
The asymptotic covariance matrix Γ0 is obtained from Lemma 1 as
Γ0 =
 NX
i=1
yiyT
i
πi
−
NX
i,j=1
yiyT
j
!
.
By the delta method (S.1), it follows that
√mk(ˆθk − θ)
d
→ N(0, γ2) as k → ∞,
with γ2 = ∇h(ty)T Γ0∇h(ty). The asymptotic mean squared error of ˆθ is thus given by
AMSE(ˆθ) = ∇h(ty)T
 NX
i=1
yiyT
i
πi
−
NX
i,j=1
yiyT
j
!
∇h(ty). (S.4)
To minimize (S.4), it suffices to minimize
∇h(ty)T
NX
i=1
yiyT
i
πi
∇h(ty),
which can be written on the form (S.2) with ci =
∇h(u)T yi
2
u=ty
. The desired result now
follows from Lemma 2. □
48
Proof of Proposition 2
The asymptotic mean squared error AMSE(ˆθ) was given in the proof of Proposition 1 by
(S.4). Substituting the unknown constants yi with the random variables Y i, we obtain the
expected asymptotic mean squared error of ˆθ as
EY [AMSE(ˆθ)] = E
"
∇h(u)T
 NX
i=1
Y iY T
i
πi
−
NX
i,j=1
Y iY T
j
!
∇h(u).
#
u=ty
. (S.5)
To minimize (S.5), it suffices to minimize
NX
i=1
E

h(u)T Y iY T
i ∇h(u)

u=ty
πi
. (S.6)
Using the equality E[X2] = E[X]2 + Var(X), we have that
E

(∇h(u)T Y i)2
= E[∇h(u)T Y i]2 + Var
 
∇h(u)T Y i

= (∇h(u)T E[Y i])2 + ∇h(u)T Cov(Y i) ∇h(u)
= (∇h(u)T ηi)2 + ∇h(u)T Σi∇h(u). (S.7)
Inserting (S.7) into (S.6), the result now follows Lemma 2 with
ci =

(∇h(u)T ηi)2 + ∇h(u)T Σi∇h(u)

u=ty
. □
49
A.2 Central limit theorems
We provide in Proposition S1 conditions under which the active sampling estimatorˆt(k)
y of a
scalar total ty is consistent and asymptotically normally distributed, and present consistent
variance estimators. A generalization to multivariate estimators and to characteristics
defined as smooth functions of totals is provided in Corollary S1. To show asymptotic
normality of our active sampling estimator, we use the following result of Brown (1971):
Lemma 3 (Martingale central limit theorem)
Consider a sequence {Xj}∞
j=1 of random variables such that E[Xj] = E[Xj|X1, . . . , Xj−1] =
0 and E[X2
j ] < ∞. Let σ2
j = E[ X2
j |X1, . . . , Xj−1], Uk = Pk
j=1 Xj, V 2
k = Pk
j=1 σ2
j , and
u2
k = E[U2
k ] = E[ V 2
k ]. Assume that V 2
k u−2
k
p
→ 1 as k → ∞, and that the Lindeberg-Feller
condition holds:
u−2
k
kX
j=1
E[X2
j I(|Xj| > εuk)] → 0 as k → ∞ for all ε >0. (S.8)
Then
Uk/uk
d
→ N(0, 1) as k → ∞.
A corresponding central limit theorem for active sampling is presented below.
Proposition S1 (Central limit theorem, nk bounded, k → ∞)
Consider a finite index set D = {1, . . . , N} with corresponding data y1, . . . , yN , and infinite
sequence {nj}∞
j=1 with nj ∈ N, nj < N. Let {Sj}∞
j=1 be an infinite sequence of random
vectors Sj = (Sj1, . . . , SjN ) ∈ NN such that PN
i=1 µji = nj, where µji := E[Sji|S1, . . .Sj−1]
are assumed to be strictly positive for all j, i. Let ty = P
i∈D yi, ˆty,j = P
i∈D
Sjiyi
µji
, mk =
50
Pk
j=1 nj, ˆt(k)
y = 1
mk
Pk
j=1 njˆty,j , σ2
j = Var(ˆty,j |S1, . . . ,Sj−1), A2
k = Pk
j=1 n2
j σ2
j , and b2
k =
Var(Pk
j=1 njˆty,j ). Assume that
(A1) Sji/µji have uniformly bounded second moments,
(A2) bk → ∞as k → ∞, and
(A3) A2
kb−2
k
p
→ 1 as k → ∞.
Then
ˆt(k)
y − ty
bk/mk
d
→ N(0, 1) as k → ∞, and (S.9)
b−2
k
kX
j=1
n2
j
 ˆty,j − ˆt(k)
y
2 p
→ 1 as k → ∞. (S.10)
Furthermore, if ˆσ2
j are unbiased estimators of the conditional variances σ2
j , i.e.,
E[ˆσ2
j |S1, . . . ,Sj−1] = σ2
j , and
(A4) b−2
k Var(Pk
j=1 n2
j ˆσ2
j ) are uniformly bounded,
then additionally we have that
b−2
k
kX
j=1
n2
j ˆσ2
j
p
→ 1 as k → ∞. (S.11)
The first result (S.9) establishes asymptotic normality of the active learning estimator
ˆt(k)
y under the specified conditions. We note that bk = O(m1/2
k ), so the convergence of ˆt(k)
y
to ty is at the usual parametric rate m−1/2
k . The second result (S.10) proves the consis-
tency of the martingale variance estimator m−1
k
Pk
j=1 n2
j

ˆty,j − ˆt(k)
y
2
, and the third (S.11)
consistency of the design-based variance estimator m−1
k
Pk
j=1 n2
j ˆσ2
j (cf. Section 4.2).
51
Since, in any sensible probability sampling design, Sji have finite second moments, the
first assumption (A1) is fulfilled if the sampling probabilities (and corresponding means
µji) are properly bounded away from zero. The second assumption (A2) requires the
total variance Var(Pk
j=1 njˆty,j ) to tend to infinity with k. This may at first sight seem to
contradict the purpose of active sampling, which is to make the variance as small as possible.
Indeed, if all the yi’s have the same sign it is theoretically possible to construct a sampling
strategy that produces an estimator with zero variance, which clearly does not converge to
a normal limit. In practice, however, finding the true optimal design is not possible and a
sampling strategy with good performance generally also fulfills the assumptions (A1) and
(A2).
The third assumption states that the sum of conditional variances asymptotically should
behave like the total variance. Hence, the statistical properties of the active sampling
estimator can be deduced from a single execution of the algorithm. Empirical justification
for this assumption is provided in Section 6. We note that the fourth assumption (A4),
needed for consistency of the classical variance estimator, is stronger than the second (A2).
To see this, note that (A4) requires ˆσ2
j to have bounded second moments for every j. But
ˆσ2
j depends on Sji/µ2
ji, which is larger than Sji/µji for all j, isuch that µji ≤ 1, as is the
case for all or nearly all j, iin all realistic subsampling applications. For fixed-size designs
ˆσ2
j also depend on the joint selection probabilities, which means that E[ SjiSjl] need to be
properly bounded away from zero for consistent variance estimation. Note, in particular,
that this requires all nj ≥ 2 for fixed-size designs, whereas (A2) makes no such restriction.
Before providing a proof, we present below a generalization to vectors of totals and
52
smooth functions of totals.
Corollary S1 (Multivariate central limit theorem, nk bounded, k → ∞)
Consider a finite index set D = {1, . . . , N} with corresponding data y1, . . . ,yN ∈ Rd.
Let {nj}∞
j=1, {Sj}∞
j=1, µji and mk be defined as in Proposition S1. Let ty = P
i∈D yi,
ˆty,j = P
i∈D
Sjiyi
µji
, and ˆt
(k)
y = 1
mk
Pk
j=1 njˆty,j. Consider a function h : Rd → R, and
assume that h(u) is differentiable in a neighborhood of u = ty, with ∇h(u)|u=ty ̸= 0. Let
Φj = Cov(ˆty,j |S1, . . . ,Sj−1), Ak = Pk
j=1 n2
j Φj and Bk = Cov(Pk
j=1 njˆty,j ). Assume that
i) Sji/µji have uniformly bounded second moments,
ii) m−1
k Bk converges elementwise to some matrix Ψ0, and Ψ0 is full rank,
iii) λT Bkλ → ∞as k → ∞for every λ ∈ Rd \ 0, and
iv) AkB−1
k
p
→ Id×d (elementwise) as k → ∞.
Then
√mk

ˆt
(k)
y − ty

d
→ N(0, Ψ0) as k → ∞, and
√mk

h(ˆt
(k)
y ) − h(ty)

d
→ N(0, γ2
0) as k → ∞,
provided that γ2
0 > 0, where γ2
0 = ∇h(u)T Ψ0∇h(u)|u=ty . Moreover, the asymptotic covari-
ance matrix Ψ0 and variance γ2
0 can be consistently estimated by
ˆΨ
(k)
= 1
m2
k
kX
j=1
n2
j

ˆty,j − ˆt
(k)
y

ˆty,j − ˆt
(k)
y
T
,
ˆγ2
k = ∇h(u)T ˆΨ
(k)
∇h(u)|u=ˆt(k)
y
.
Furthermore, if ˆΦj are unbiased estimators of the conditional covariance matrices Φj, i.e.,
E[ ˆΦj|S1, . . . ,Sj−1] = Φj, and
53
iv) (λT Bkλ)−1Var(Pk
j=1 λT ˆΦjλ) are uniformly bounded for every λ ∈ Rd \ 0,
then the asymptotic covariance matrix Ψ0 and variance γ2
0 can also be consistently estimated
by
eΨ
(k)
= 1
m2
k
kX
j=1
n2
j ˆΦj,
eγ2
k = ∇h(u)T eΨ
(k)
∇h(u)|u=ˆt(k)
y
.
Proof of Proposition S1
Let Xj = nj(ˆty,j − ty), Uk = Pk
j=1 Xj, V 2
k = Pk
j=1 E[X2
j |X1, . . . , Xj−1] = A2
k, and u2
k =
E[U2
k ] = E[ V 2
k ] = b2
k. Note that E[Xj] = 0 , and that Xj by (A1) have uniformly bounded
second moments, and hence that maxj≤k E[X2
j ] are uniformly bounded. Since uk → ∞as
k → ∞, we therefore have that maxj≤k u−1
k Xj
L2
→ 0, which implies
max
j≤k
u−1
k Xj
p
→ 0. (S.12)
This in turn is equivalent to the weaker Lindeberg-Feller condition
u−2
k
kX
j=1
X2
j I(|Xj| ≥εuk)
p
→ 0 for all ε >0, (S.13)
since P(maxj≤k u−1
k Xj > ε) = P(Pk
j=1 u−2
k X2
j I(|Xj| > εuk) > ε2). But
E
"
u−2
k
kX
j=1
X2
j I(|Xj| ≥εuk)

#
≤ u−2
k E
" kX
j=1
X2
j
#
= 1 for all k. (S.14)
By the dominated convergence theorem, (S.13) and (S.14) implies the Lindeberg-Feller con-
dition (S.8), which together with (A3) according to Lemma 3 gives
Uk/uk
d
→ N(0, 1) as k → ∞.
54
The first result (S.9) now follows by noting that
Uk/uk =
Pk
j=1 nj(ˆty,j − ty)
bk
=
m−1
k
Pk
j=1 nj(ˆty,j − ty)
bk/mk
=
ˆt(k)
y − ty
bk/mk
.
For (S.10), we first note that ˆty,k = Op(1) and ˆt(k)
y = ty + Op(bk/mk). Hence
b−2
k
kX
j=1
n2
j
 ˆty,j − ˆt(k)
y
2
= b−2
k
kX
j=1
n2
j
 ˆty,j − ty + Op(bk/mk)
2
= b−2
k
kX
j=1
n2
j
 ˆty,j − ty
2
+ Op(b−1
k ).
Next,
E
b−2
k
kX
j=1
n2
j
 ˆty,j − ˆt(k)
y
2
− 1
 = E
b−2
k
kX
j=1
n2
j
 ˆty,j − ty
2
+ Op(b−1
k ) − 1

≤ E
b−2
k
kX
j=1
n2
j
 ˆty,j − ty
2
− 1
 + E[Op(b−1
k )].
Note now that (A3) is equivalent to limk→∞ E|A2
kb−2
k − 1| (Brown, 1971, Lemma 1), which
together with (S.12) and the Lindeberg-Feller condition (S.8) implies that the first term
vanishes as k → ∞(Hall and Heyde, 1980, Theorem 3.5). As does the second term, since
ˆty,j have uniformly bounded second moments. Hence, (S.10) now follows since convergence
in mean implies convergence in probability.
For the last result (S.11), we note that E[Pk
j=1 n2
j ˆσ2
j ] = b2
k, and
Var
 
b−2
k
kX
j=1
n2
j ˆσ2
j
!
=
Var(Pk
j=1 n2
j ˆσ2
j )
b2
k
1
b2
k
→ 0 as k → ∞,
since the first factor by (A4) is bounded and the second goes to zero as k → ∞. This
completes the proof. □
Proof of Corollary S1
The result follows immediately from Proposition S1 by application of the Cram´ er-Wold
theorem and the Delta method (Sen and Singer, 1993) .
55
B Additional method and implementation details
Additional details on the implementation of the sampling methods in the application (Sec-
tion 6) are provided below.
B.1 Active sampling
Optimal sampling schemes Optimal sampling schemes for active sampling in the
crash-causation-based scenario generation application are derived below. Note first that
the characteristic of interest (7) can be written on the form (1) with yi = pi(ri, rixi)T and
h(u) = u2/u1, where ri is a binary indicator taking the value 1 if there was a crash in the
baseline scenario and 0 otherwise, pi the prior observation weight (scenario probability),
and xi the impact speed reduction or crash avoidance indicator with the AEB compared
to baseline driving (without the AEB). The observation weights pi are known a priori and
need not be learned from data, whereas ri and xi can only be observed by running the
corresponding virtual simulation. We therefore introduce the random variables Ri, Xi to
describe our uncertainty in the variables of interest ( ri, xi), and Y i = pi(Ri, RiXi)T . Since
the two components of Y i are correlated through the common factor Ri and Y i = 0 if
Ri = 0, we model ( Xi, Ri) as
Ri|zi ∼ f(ri|zi)
Xi|Ri, zi ∼ f(xi|ri, zi).
Using the law of total expectation and total covariance (conditioning on Ri) to evaluate
the expectation and covariance matrix of Y i, we obtain the optimal sampling scheme for
56
the active sampling algorithm as
πki ∝ √ci, c i = p2
i ˆri
h
(ˆxi − ˆθ(k−1))2 + ˆσ2
i
i
, (S.15)
where ˆri is the predicted probability of generating a crash in the baseline scenario, ˆ xi the
predicted impact speed reduction or probability of crash avoidance with the AEB given
that there was a crash in the baseline scenario, σ2
i the residual error (root mean squared
prediction error for regression, standard deviation
p
ˆxi(1 − ˆxi) for classification), and ˆθ(k−1)
the estimate of the characteristic of interest from the previous iteration of the algorithm.
In the light of (S.15), it is optimal in the absence of prior information about ri and xi to set
πki ∝ pi. Hence, this was also used in the initial iteration(s) of the active sampling algorithm
until reliable predictions were obtained, i.e., until the prediction R-squared (regression) or
prediction accuracy (classification) was greater than zero when evaluated on hold-out data.
Learning and prediction For the learning step of the active sampling algorithm, we
used random forest regression for continuous outcomes (impact speed reduction) and ran-
dom forest classification for binary outcomes (crash/no-crash under baseline and coun-
termeasure scenarios) (Breiman, 2001). The random forest method was chosen for the
following reasons: i) it is fast and flexible, ii) it is capable of finding non-linear and non-
monotonic patterns, as well as interactions between variables, without the need for explicit
feature construction, and iii) measures of generalization error and prediction performance
are readily available through estimates of residual variance, prediction R-squared and ac-
curacy on hold-out (out-of-bag) data.
Explanatory variables were the input parameters to the simulations (off-road glance
57
duration and maximal deceleration), and an a priori known case-specific maximal impact
speed. The maximal impact speed could be retrieved by running a single simulation per
original crash event at the maximal glance duration and minimum deceleration. Although
in reality this would count as 44 extra simulations (one per original crash event) it has only
a minor effect on the overall performance evaluation and hence not accounted for in the
presentation of the results.
Random forests were fitted using 100 trees with variance splitting rule for regression,
and gini splitting rule for classification. Other hyper-parameters (minimum node size and
number of variables to split upon) were selected with 5-fold cross validation, using a random
grid search of minimum node size from 1 to 20 and number of variables to split upon from
1 to 3. All predictions were set equal if the model could not be fitted or produced a
prediction R-squared less than 0 on hold-out data, thus resorting to density importance
sampling (πki ∝ pi). To reduce computation time, prediction models were updated every
10th new observation up to a sample size of n = 100 observations, thereafter every 25th new
observation up to a sample size of n = 500 observations, thereafter every 50 th observation
up to a sample size of n = 1, 000 observations, and so on.
We also performed sensitivity analyses for the choice of machine learning algorithm using
extreme gradient boosting (XGBoost, Chen and Guestrin, 2016) and k-nearest neighbors
(k-NN). As before, the hyper-parameters (learning rate, maximum tree-depth and number
of boosting rounds for XGBoost, and number of neighbors for k-NN) were tuned by using
cross-validation.
58
B.2 Importance sampling
Two different importance sampling schemes were considered: density importance sampling
and severity importance sampling. With density importance sampling, the sampling prob-
abilities were selected proportional to the prior observation weights pi, since instances with
large observation weights by design of the scenario generation framework have a larger
contribution to estimation. Since our aim was safety benefit evaluation of an advanced
driver assistance system compared to a baseline driving scenario, and the potential safety
benefit increases with impact severity, we hypothesized that oversampling of high-severity
instances would lead to further variance reduction in the safety benefit evaluation. We
therefore also included severity importance sampling, which attempts to oversample high-
severity instances by assigning sampling probabilities proportional topi ×oi ×di ×mi, where
pi is the prior observation weight of instance i, oi is the corresponding off-road glance du-
ration, di is the maximal deceleration, and mi an a priori known maximal possible impact
speed of instance i. To account for scale differences between variables, all variables (off-road
glance duration, deceleration, maximal impact speed) were transformed a common scale
by mapping the values onto the interval [0 .1, 1] before calculating the severity sampling
scheme.
B.3 Latin hypercube sampling
Latin hypercube sampling was implemented as in Meng et al. (2021), stratified by cases
(i.e., by the original crash events). In brief, the input parameters (off-road glance duration
and maximal deceleration during braking) were first transformed to the unit square [0 , 1]2
59
by dividing by the maximum value. For each of the 44 cases, m points were generated
at random according to a Latin square design on [0 , 1]2. These points were then matched
to the closest point in the design space. The sample size was varied from m = 1, . . . ,46
observations per case, producing subsamples of n = 44, 88, . . . ,2024 observations in total.
B.4 Leverage sampling
Leverage sampling (Ma et al., 2015, 2022) utilizes importance sampling with probabilities
proportional to the statistical leverage scores {hi}N
i=1 of a linear model with covariates
{zi}N
i=1. Using weighted least squares, the leverage scores hi are given by the diagonal
elements of the ’hat matrix’
H = W1/2Z(ZT WZ)−1ZT W1/2,
where W is a diagonal weight matrix and Z a design matrix with rows (1 , zT ) (Pregibon,
1981). In our application, the elements of W were chosen equal to the prior scenario
weights pi, and zi as the off-road glance duration and maximal deceleration during braking
for an instance i. Note that the statistical leverage scores only depend on the weights and
covariates, not the outcomes, and hence could be calculated without additional information
about the outcomes of the simulations.
B.5 Gaussian process active learning
Gaussian process active learning was initialized using simple random sampling. New sam-
ples were selected at random using probabilistic uncertainty sampling, i.e., with proba-
bilities proportional to the posterior uncertainty of the predictions (standard deviation).
60
This is relatively fast and promotes exploration of the design space, particularly in regions
with high prediction uncertainty. Constant predictions were used (i.e., the observed sample
mean) if the model could not be fitted. Both subsampling and model fitting were stratified
by cases, i.e., performed separately for each original crash event. In each iteration, one
sample per case was selected, corresponding to a total batch size of 44 observations per
iteration. Estimation was conducted according to (7), replacing the true values by their
corresponding predictions.
B.6 Software
All sampling methods and experiments were implemented using the R language and en-
vironment for statistical computing, version 4.2.1 (R Core Team, 2023). Random forests
were implemented using the ranger R-package version 0.14.1 (Wright and Ziegler, 2017),
extreme gradient boosting using xgboost version 1.7.5.1, and k-nearest neighbors using
caret version 6.0-94 (Kuhn, 2008). caret was also used for hyper-parameter tuning. Latin
hypercube sampling was implemented using the lhs package version 1.1.6, with matching
using MatchIt version 4.5.5 (Ho et al., 2011). Gaussian process regression was imple-
mented using kernlab version 0.9-32 (Karatzoglou et al., 2004). The complete R code for
the active sampling algorithm, simulation experiments, and data are available online at
https://github.com/imbhe/ActiveSampling.
61
C Supplemental Figures
C.1 Additional results: Simulation experiments
Figure S1: Performance of active sampling using a linear model (LM), generalized additive model
(GAM), Gaussian process regression (GPR) or random forests (RF) surrogate model, compared to
simple random sampling. The curves show the root mean square errors (eRMSEs) for estimating
a finite population mean in a strictly positive scenario (all yi > 0) using a linear estimator
(h(u) = u/N) and batch size nk = 50. Shaded regions are 95% confidence intervals for the
eRMSEs based on 500 repeated subsampling experiments.
62
Figure S2: Performance of active sampling (AS) using a generalized additive surrogate model
with a batch size of nk = 10 or 50 samples per iteration, compared to simple random sampling.
The curves show the root mean square errors (eRMSEs) for estimating a finite population mean
in a strictly positive scenario (all yi > 0) using a linear estimator ( h(u) = u/N). Shaded regions
are 95% confidence intervals for the eRMSEs based on 500 repeated subsampling experiments.
63
Figure S3: Performance of active sampling using a linear surrogate model (LM) or generalized
additive surrogate model (GAM) compared to simple random sampling, ratio estimator, control
variates and importance sampling for estimating a finite population mean in a non-restricted
scenario (yi ∈ R) using a linear estimator ( h(u) = u/N) and batch size nk = 10. The curves and
shaded regions are the root mean squared errors (eRMSEs) of the estimators and 95% confidence
intervals for the eRMSEs, respectively, based on 500 repeated subsampling experiments. Asterisks
show the smallest sample sizes for which there were persistent significant improvements ( p < .05)
with active sampling compared to simple random sampling.
64
Figure S4: Performance of active sampling using a linear surrogate model (LM) or generalized
additive surrogate model (GAM) compared to simple random sampling, ratio estimator, control
variates and importance sampling for estimating a finite population mean in a non-restricted
scenario ( yi ∈ R) using a non-linear estimator ( h(u) = u2/u1, yi = (1 , yi)T ) and batch size
nk = 10. The curves and shaded regions are the root mean squared errors (eRMSEs) of the
estimators and 95% confidence intervals for the eRMSEs, respectively, based on 500 repeated
subsampling experiments. Asterisks show the smallest sample sizes for which there were persistent
significant improvements (p < .05) with active sampling compared to simple random sampling.
65
Figure S5: Performance of naive active sampling (ignoring prediction uncertainty) using a linear
surrogate model (LM) or generalized additive surrogate model (GAM) compared to simple random
sampling for estimating a finite population mean in a strictly positive scenario ( yi > 0) using a
linear estimator (h(u) = u/N) and batch size nk = 10. The curves and shaded regions are the root
mean squared errors (eRMSEs) of the estimators and 95% confidence intervals for the eRMSEs,
respectively, based on 500 repeated subsampling experiments.
66
Figure S6: Performance of naive active sampling (ignoring prediction uncertainty) using a linear
surrogate model (LM) or generalized additive surrogate model (GAM) compared to simple random
sampling for estimating a finite population mean in a non-restricted scenario ( yi ∈ R) using a
non-linear estimator ( h(u) = u2/u1, yi = (1 , yi)T ) and batch size nk = 10. The curves and
shaded regions are the root mean squared errors (eRMSEs) of the estimators and 95% confidence
intervals for the eRMSEs, respectively, based on 500 repeated subsampling experiments.
67
C.2 Additional results: Application
Figure S7: Root mean squared error (eRMSE) for estimating the mean impact speed reduction (A)
and crash avoidance rate (B) using three different machine learning models in the active sampling
algorithm: random forests, extreme gradient boosting, and k-nearest neighbors. Shaded regions
are 95% confidence intervals for the eRMSE based on 100 repeated subsampling experiments.
68