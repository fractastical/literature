Integrating Active Learning in Causal Inference with Interference:
A Novel Approach in Online Experiments
Hongtao Zhu
National University of Singapore
Singapore, Singapore, Singapore
hongtao.zhu@u.nus.edu
Sizhe Zhang
Tencent
Singapore, Singapore, Singapore
Yang Su
Tencent
Palo Alto, California, USA
yaangsu@global.tencent.com
Zhenyu Zhao
Tencent
Palo Alto, California, USA
Nan Chen
National University of Singapore
Singapore, Singapore, Singapore
isecn@nus.edu.sg
ABSTRACT
In the domain of causal inference research, the prevalent potential
outcomes framework, notably the Rubin Causal Model (RCM), often
overlooks individual interference and assumes independent treat-
ment effects. This assumption, however, is frequently misaligned
with the intricate realities of real-world scenarios, where interfer-
ence is not merely a possibility but a common occurrence. Our
research endeavors to address this discrepancy by focusing on the
estimation of direct and spillover treatment effects under two as-
sumptions: (1) network-based interference, where treatments on
neighbors within connected networks affect oneâ€™s outcomes, and
(2) non-random treatment assignments influenced by confounders.
To improve the efficiency of estimating potentially complex ef-
fects functions, we introduce an novel active learning approach:
Active Learning in Causal Inference with Interference (ACI). This
approach uses Gaussian process to flexibly model the direct and
spillover treatment effects as a function of a continuous measure of
neighborsâ€™ treatment assignment. The ACI framework sequentially
identifies the experimental settings that demand further data. It
further optimizes the treatment assignments under the network
interference structure using genetic algorithms to achieve efficient
learning outcome. By applying our method to simulation data and
a Tencent game dataset, we demonstrate its feasibility in achieving
accurate effects estimations with reduced data requirements. This
ACI approach marks a significant advancement in the realm of
data efficiency for causal inference, offering a robust and efficient
alternative to traditional methodologies, particularly in scenarios
characterized by complex interference patterns.
CCS CONCEPTS
â€¢ Mathematics of computing â†’Probability and statistics .
KEYWORDS
Causal inference, Network interference, Gaussian process regres-
sion, Active learning, Experimental design, Genetic optimization
1 INTRODUCTION
1.1 Motivation
In the realm of causal inference, observational studies have tradi-
tionally relied on regression-based and matching-based approaches
to estimate treatment effects. They work with messy data and seek
to estimate treatment effects using regression models [6, 16, 20, 22]
or matching methods [1, 2]. Most studies assumed the absence of
interference between two individuals, meaning that one individ-
ualâ€™s information, including treatment, features, and outcomes, does
not affect others. In reality, interference is prevalent. For example,
one personâ€™s increased online gaming time may be influenced by
their friendsâ€™ participation in certain in-game activities. Studies
in other domains, including but not limited to health [12, 13], ed-
ucation [11, 15, 36], social interactions [ 8], and politics [ 5] have
shown interference affects treatment effects. Clearly, considering
interference in causal inference is a highly practical and relevant
topic.
1.2 Related work
Presently, numerous studies within the field of causal inference
aim to estimate treatment effects through experimental or non-
experimental approaches. The majority of these investigations are
grounded in the potential outcomes framework [7, 29], commonly
referred to as the Rubin Causal Model (RCM), which is under-
pinned by three core assumptions: Stable Unit Treatment Value
Assumption (SUTVA) [30], Exchangeability Assumption and Pos-
itivity Assumption [14, 28]. Based on this framework, numerous
methodologies for effect estimation in causal inference have been
developed [1, 2, 6, 20, 26, 38]. Notably, all the methods discussed ear-
lier are based on the assumption of no interference (SUTVA), which
posits that one individualâ€™s information, including treatment, fea-
tures, and outcomes, does not affect others. However, interference
is a common occurrence in the real world, where one individualâ€™s
actions or treatment can impact othersâ€™ outcomes. This real-world
interference adds complexity to causal inference and often necessi-
tates the use of advanced statistical and modeling techniques.
Recently, the number of papers addressing causal inference with
interference or estimating treatment effects in the presence of in-
terference has grown significantly. There is a growing emphasis on
estimating two distinct effects: the direct treatment effect, which
refers to the impact of an individualâ€™s own treatment on their out-
come, and the spillover effect, alternatively termed the indirect
treatment effect, which pertains to the influence of treatments as-
signed to an individualâ€™s neighbors on the individualâ€™s outcome
[17].
Current methods for causal inference in the presence of interfer-
ence can be broadly categorized into two main groups: randomized
arXiv:2402.12710v1  [stat.ME]  20 Feb 2024
Conferenceâ€™17, July 2017, Washington, DC, USA Zhu et al.
experiments and observational studies. Randomized experiments
methods employ specific randomization techniques, such as cluster
randomization or network randomization [3â€“5, 8, 17, 27, 33]. Early
methods were developed to estimate the overall treatment effects
in the presence of interference, which is the sum of both the direct
treatment effects and the spillover effects [27]. A two-stage random-
ization procedure has been proposed to facilitate the estimation
of direct treatment effects and spillover effects separately within
clusters [17]. There have also been refinements in controlling the
variance of treatment effects to obtain better Horvitzâ€“Thompson
type estimators [3]. Additionally, complex scenarios have been in-
troduced, for example, [8] uses Encouragement Designs to explore
the endogenous behavior of interest. However, these methods can-
not be applied in observational studies or in specific experiments
where proper randomization is not feasible.
In terms of observational studies, some research focuses on the
intricacies of causal and network structures, providing direction
and theoretical foundation for the further estimation of treatment
effects. Notably, studies utilizing Directed Acyclic Graphs (DAGs)
have been instrumental in elucidating the causal structure in the
presence of interference. For example, works by Ogburn and Sher-
man present a potential outcomes framework under interference,
revealing the intricate structure of interference and guiding further
statistical analysis [24, 32]. The following Figure 1, as illustrated
in [24], displays the causal structure in the scenario where inter-
ference is present. With a clear definition of causal structure and
effects, several methodologies [9, 10, 19, 21, 23, 34, 35] have been de-
veloped to effectively estimate potential outcomes or effects under
various treatment levels.
Figure 1: Illustrative causal structure of individual ğ‘–interfer-
ing with individual ğ‘—.
The use of Inverse Probability Weighting (IPW) methods has
also been extended to address network inference [21, 34]. [21] build
upon the work of [ 34] to introduce a robust IPW estimator to
estimate effects based on clusters. However, similar to traditional
IPW estimation, this method heavily relies on correct specification
of propensity score functions and assumes treatment assignments
through Bernoulli allocation strategies. It could lead to significant
biases in treatment effect estimation if the model structure of the
propensity score functions is misspecified.
Another branch of methodologies has been developed focusing
on network-based approaches (a network example is shown in Fig-
ure 2). These include the Targeted Maximum Likelihood Estimator
(TMLE) [23, 35], methods within the Bayesian framework [9, 10],
and applications of Graph Neural Networks (GNNs) [19].
The Targeted Maximum Likelihood Estimator (TMLE), as pro-
posed in [ 35], has been utilized in observational studies within
networks to estimate average potential outcomes in the presence of
interference [23]. In their research, [23] employed an approach that
Figure 2: The social network of 50 individuals.
integrates the covariates and treatments of neighbors. However,
TMLE remains a parametric method, relying on correct model spec-
ification. Its primary objective is to estimate the average potential
outcome under a determined treatment assignment strategy, which
differs from the focus of our research.
The Bayesian framework has been applied to address interfer-
ence, allowing for more flexible modeling assumptions and complex
model structures [9, 10]. This approach is also network-based and
involves integrating information from neighbors. The estimand in
their work aligns with ours, focusing on average effect functions
with the integrated treatment level as input. However, a significant
challenge arises due to the "Curse of Dimensionality" in the context
of high-dimensional covariates. Sparse data in such scenarios tend
to skew results towards the prior, impacting the robustness and
reliability of the outcomes.
Machine learning techniques, such as deep learning, are also
employed to estimate interference effects. Graph Neural Networks
(GNNs) have been proposed as a potential solution to the causal
inference with interference problem [19]. A key advantage of GNNs
is their ability to circumvent the loss of information often encoun-
tered when integrating neighborsâ€™ data. However, it is worth noting
that GNNs underperform when dealing with overly complex social
networks.
In summary, current observational studies in causal inference
with interference fall short in effectively addressing the challenges
in estimating treatment effects. The most common issue is they
rely on correct parametric model assumptions, making it difficult
to adapt to the complex real-world problems.
1.3 Contributions
In this paper, we consider the estimation of direct treatment effects
and spillover effects when network-based interference is present in
online experiments. Instead of relying on parametric model speci-
fication, we propose a nonparametric method based on Gaussian
process (GP) to quantify the effects at different degree of the inter-
ference.
GP is a flexible regression model that can approximate a wide
range of functional relationships. In addition, GP provides uncer-
tainty quantification and points out the areas that require more
samples to improve the approximation accuracy. This feature makes
Integrating Active Learning in Causal Inference with Interference:
A Novel Approach in Online Experiments Conferenceâ€™17, July 2017, Washington, DC, USA
it particularly useful in online experiments, where sequential ex-
perimental designs are relatively easier to conduct. Hinging on this
feature, we propose an active learning strategy for designing and
analyzing online experiments. Unlike experiments without interfer-
ence, where the treatment assignment can be precisely conducted,
the degree of interference can hardly be controlled precisely in
networks. Therefore, even with active learning in choosing the
experimental design, we still need to integrate methods from ob-
servational studies to utilize all samples best.
In our proposed framework, we use GP to model the potential
outcomes of each individual, given the treatment and covariates of
the individual and its neighbors. Because of the varying network
structure, the number of neighbors or the degree of interference
can be different. We use active learning to determine the design of
new experiments so that we can have data at desired interference
levels. This iterative process continues until the budget runs out
or the effects have been estimated with sufficient accuracy. The
diagram of the iterative process is illustrated in Figure 3.
Figure 3: The structure of our active learning framework
designed for causal inference with interference (GA: Genetic
algorithm, GRP: Gaussian process regression). A detailed
exposition of this framework is provided in Section 3.
In summary, our workâ€™s contributions include: (1) We introduce
active learning to causal inference with interference, by which we
dynamically select the most informative data points to enhance
efficiency and accuracy in effect estimation. (2) We employ a non-
parametric method for effect estimation, which is resistant to model
misspecification and adept at capturing non-linear relationships.
(3) We proposed a genetic algorithm to optimize the treatment
assignments to have the desired level of network interference.
The remainder of this article is organized as follows. Section 2
presents the model formulation and introduces the potential out-
comes framework that takes into account network-based interfer-
ence. Section 3 discuss in details our methodology, including GP
modeling, active learning strategy, and treatment assignment opti-
mization. Section 4 demonstrates the performance of the method
through simulations and an empirical study using a real dataset.
Section 5 concludes the paper with discussions.
2 PRELIMINARIES AND PROBLEM
FORMULATION
In this section, we outline the key assumptions relevant to our
study and provide a comprehensive methodology for integrating
covariates and treatments.
2.1 Network assumption
To represent networks for allğ‘›individuals, we utilize a relationship
matrix denoted as ğ‘Š âˆˆRğ‘›Ã—ğ‘›. In this matrix, vector ğ‘Šğ‘– represents
the relationships of individual ğ‘– with all its neighbors, and ele-
ment ğ‘¤ğ‘–ğ‘— indicates the strength of the relationship between two
individuals, ğ‘– and ğ‘—. When ğ‘– and ğ‘— are not neighborsâ€”implying no
connection such as in-game friendsâ€”the value ğ‘¤ğ‘–ğ‘— is set to 0. In
contrast, if ğ‘– and ğ‘— are neighbors, ğ‘¤ğ‘–ğ‘— is assigned a positive real
number reflecting the strength of their relationship. As a special
case, ğ‘Š âˆˆRğ‘›Ã—ğ‘› takes binary values, with ğ‘¤ğ‘–ğ‘— = 1 denoting the
existence of the relationship between ğ‘–and ğ‘—, and 0 otherwise. Fig-
ure 4 displays a sub-network of the network presented in Figure 2
for individual 1. This sub-network includes individual 1 and all
its neighbors, with individual 1 defined as the central node of this
specific sub-network.
Figure 4: Illustrative Sub-Network Centered Around Indi-
vidual 1, where connections indicate relationships between
individuals, e.g., ğ‘¤1,0 = 1.
2.2 Potential outcomes framework with
interference
Building upon [ 29] and [ 24], we define our potential outcomes
framework with interference as follows. In our notation, we employ
ğ‘Œ to denote the outcome, ğ´to represent a binary treatment, i.e.,
ğ´= 0 or 1, and ğ¶ to represent confounders with dimension ğ‘. An
individual ğ‘–is completely characterized by {ğ‘Œğ‘–,ğ´ğ‘–,ğ¶ğ‘–}.
We denote the number of neighbors of individual ğ‘– as ğ‘šğ‘–, and
neighbors of individual ğ‘– belongs to the collection ğ‘ğ‘“
ğ‘– = {ğ‘— |ğ‘¤ğ‘–ğ‘— >
0}. For notation simplicity, we group the data for allğ‘šğ‘– neighbors
as ğ‘Œğ‘
ğ‘– = [ğ‘Œğ‘— | ğ‘— âˆˆğ‘ğ‘“
ğ‘– ] âˆˆRğ‘šğ‘– , ğ´ğ‘
ğ‘– = [ğ´ğ‘— | ğ‘— âˆˆğ‘ğ‘“
ğ‘– ] âˆˆRğ‘šğ‘– ,
ğ¶ğ‘
ğ‘– = [ğ¶ğ‘— | ğ‘— âˆˆğ‘ğ‘“
ğ‘– ]âˆˆ Rğ‘šğ‘– Ã—ğ‘. Throughout this article, we use
Conferenceâ€™17, July 2017, Washington, DC, USA Zhu et al.
uppercase letters to indicate random variables, and lowercase letters
to indicate a realization, unless otherwise specified.
Each central individual often possesses its unique neighbor struc-
tures. For instance, the number of neighbors for individual ğ‘–might
differ from that of individualğ‘—. Consequently, the treatments(ğ‘ğ‘–,ğ‘ğ‘
ğ‘– )
and (ğ‘ğ‘—,ğ‘ğ‘
ğ‘— )may have distinct dimensions and levels. To tackle
this issue, a transformation function ğ‘”ğ‘– is introduced:
ğºğ‘– = ğ‘”ğ‘–(ğ´ğ‘
ğ‘– ,ğ‘Šğ‘–) (1)
Here, ğºğ‘– can represent the proportion of neighbors who have been
subject to the treatment, or equivalently, the proportion of1 within
ğ´ğ‘
ğ‘– . This approximation is similar to the one used by [9, 10].
It is essential to acknowledge that varying network structures
can lead to differences in the sizes of ğ¶ğ‘
ğ‘– and ğ¶ğ‘
ğ‘— . Furthermore,
the size of ğ¶ğ‘
ğ‘– can become considerably large, given the substan-
tial number of neighbors. Considering that individuals receiving
different treatments in observational studies are likely to have differ-
ent distributions in covariates, we aim to control the transformed
neighbor covariates within the same and reasonable size while
minimizing information loss during the approximation process. To
clarify further, our objective is to approximate neighbor covariates
in a manner that retains, to a certain extent, their distribution infor-
mation within specificğ´ğ‘
ğ‘– conditions. To achieve this, we introduce
a transformation function â„ğ‘–:
Ëœğ¶ğ‘
ğ‘– = â„ğ‘–(ğ¶ğ‘
ğ‘– ,ğ´ğ‘
ğ‘– ,ğ‘Šğ‘–) (2)
For example, Ëœğ¶ğ‘
ğ‘– could represent the average of ğ¶ğ‘
ğ‘– , i.e.,
Ëœğ¶ğ‘
ğ‘– =
Ãğ‘šğ‘–
ğ‘—=1 ğ¶ğ‘
ğ‘–,ğ‘—
ğ‘šğ‘–
,
where ğ‘šğ‘– can be any natural number (ğ‘šğ‘– âˆˆN), accounting for the
variable number of neighbors among central individualğ‘–. Of course,
other reasonable choices of ğ‘”ğ‘–,â„ğ‘– functions can be used.
Considering the neighborsâ€™ information, an individual ğ‘–can be
characterized by {ğ‘Œğ‘–,(ğ´ğ‘–,ğºğ‘–),ğ‘‹ğ‘–}where ğ‘‹ğ‘– = (ğ¶ğ‘–, Ëœğ¶ğ‘
ğ‘– ). The three
causal assumptions from section 2.2 can be expressed as follows:
â€¢Assumption of consistency under interference:
ğ‘Œğ‘–(ğ‘,ğ‘”)= ğ‘Œğ‘– when (ğ´ğ‘–,ğºğ‘–)= (ğ‘,ğ‘”) (3)
â€¢Exchangeability assumption:
ğ‘Œğ‘–(ğ‘,ğ‘”)âŠ¥ âŠ¥(ğ´ğ‘–,ğºğ‘–)| ğ‘‹ğ‘– (4)
â€¢Positivity assumption:
ğ‘ƒ((ğ´ğ‘–,ğºğ‘–)= (ğ‘,ğ‘”)| ğ‘‹ğ‘–)> 0 (5)
2.3 Causal estimands
When considering the treatment(ğ‘,ğ‘”)and the controlled level(0,0),
we define an individualâ€™s overall treatment effect (represented as
IOTEğ‘–), direct treatment effect (represented as IDTEğ‘–) and spillover
effect (depicted as ISEğ‘–) as follows:
IOTEğ‘–(ğ‘”)= E[ğ‘Œ(1,ğ‘”)|ğ‘‹ğ‘–]âˆ’E[ğ‘Œ(0,0)|ğ‘‹ğ‘–]
IDTEğ‘–(ğ‘”)= E[ğ‘Œ(1,ğ‘”)|ğ‘‹ğ‘–]âˆ’E[ğ‘Œ(0,ğ‘”)|ğ‘‹ğ‘–]
ISEğ‘–(ğ‘”)= E[ğ‘Œ(0,ğ‘”)|ğ‘‹ğ‘–]âˆ’E[ğ‘Œ(0,0)|ğ‘‹ğ‘–]
Similarly, we provide average level effects as follows, with aver-
age overall treatment effect ğœ1, average direct treatment effect ğœ1,0
and average spillover effect ğœ0:
ğœ1 (ğ‘”)= E[E[ğ‘Œ(1,ğ‘”)|ğ‘‹]âˆ’E[ğ‘Œ(0,0)|ğ‘‹]]
ğœ1,0 (ğ‘”)= E[E[ğ‘Œ(1,ğ‘”)|ğ‘‹]âˆ’E[ğ‘Œ(0,ğ‘”)|ğ‘‹]]
ğœ0 (ğ‘”)= E[E[ğ‘Œ(0,ğ‘”)|ğ‘‹]âˆ’E[ğ‘Œ(0,0)|ğ‘‹]]
3 PROPOSED METHOD
We divide our proposed method into two parts. First, we use a
method based on Gaussian process regression to estimate potential
outcomes, thereby estimating individual treatment effects and av-
erage treatment effects. Second, we use active learning to identify
how to assign new samples so that the treatment effects can be
better estimated.
3.1 Gaussian Process Regression for Treatment
Effects
Our proposed approach employs Gaussian Process Regression (GPR)
to assess the treatment effects on the entire population at a specific
treatment level ğ´= ğ‘and ğº = ğ‘”. Specifically, we model the poten-
tial outcome as at treatment level ğ‘as ğ‘“ğ‘(ğ‘”,ğ‘‹). This methodology
leverages all available observational data, especially outcomes from
experimental settings, when the condition ğ´= ğ‘is met. We aim to
forecast the potential outcomes for the whole population under the
treatment level ğ´= ğ‘and ğº = ğ‘”.
To implement Gaussian Process regression, we define our kernel
function as ğ‘˜((ğ’™,ğ‘”),(ğ’™â€²,ğ‘”â€²)). For more detailed examples of this
kernel function, refer to the Appendix A.1. Consider a training
dataset for a specific treatment ğ´ = ğ‘, with size ğ‘›ğ‘¡. This dataset
comprises integrated covariates ğ‘¿ğ’• = (ğ‘‹ğ‘¡,1,...,ğ‘‹ ğ‘¡,ğ‘›ğ‘¡ )ğ‘‡, integrated
neighborsâ€™ treatments ğ’ˆğ’• = (ğ‘”ğ‘¡,1,...,ğ‘” ğ‘¡,ğ‘›ğ‘¡ )ğ‘‡, and their actual out-
comesğ’šğ’• = (ğ‘¦ğ‘¡,1,...,ğ‘¦ ğ‘¡,ğ‘›ğ‘¡ )ğ‘‡. By following the maximum likelihood
framework, we can estimate the hyper-parameters to maximize
the marginal (log) likelihood of the training data, as shown in Ap-
pendix A.2. Our goal is to predict the potential outcomes for the
entire population, which includes a total of ğ‘›individuals with in-
tegrated covariates ğ‘¿ = (ğ‘‹1,...,ğ‘‹ ğ‘›)ğ‘‡, under the treatment level
ğ´= ğ‘,ğº = ğ‘”. The predicted outcome function values are denoted
as ğ’‡ğ’‚ (ğ‘”,ğ‘¿)= [ğ‘“ğ‘(ğ‘”,ğ‘‹1),...,ğ‘“ ğ‘(ğ‘”,ğ‘‹ğ‘›)]ğ‘‡.
To estimate the average treatment effects, we should determine
the average potential outcome function ğ‘šğ‘(ğ‘”)for the entire pop-
ulation under the treatment level (ğ´= ğ‘,ğº = ğ‘”). This function is
expressed as follows:
ğ‘šğ‘(ğ‘”)= Eğ‘‹[ğ‘“ğ‘(ğ‘”,ğ‘‹)]=
âˆ«
ğ‘“ğ‘(ğ‘”,ğ‘‹)ğ‘‘P(ğ‘‹), (6)
which can be estimated by:
Ë†ğ‘šğ‘(ğ‘”)= 1
ğ‘›
ğ‘›âˆ‘ï¸
ğ‘–=1
ğ‘“ğ‘(ğ‘”,ğ‘‹ğ‘–)= 1
ğ‘›ğ’†ğ‘‡ Â·ğ’‡ğ’‚ (ğ‘”,ğ‘¿), (7)
where ğ’† = (1,..., 1)ğ‘‡ with length ğ‘›.
We represent the kernel matrix used in our model as follows:
ğ¾(ğ‘¿ğ’•,ğ’ˆğ’• ),(ğ‘¿ğ’•,ğ’ˆğ’• ))= ğ‘²ğ’• , ğ¾((ğ‘¿,ğ’ˆ),(ğ‘¿,ğ’ˆ))= ğ‘²âˆ—and ğ¾((ğ‘¿ğ’•,ğ’ˆğ’• ),
(ğ‘¿,ğ’ˆ))= ğ‘²ğ’•,âˆ—, where ğ’ˆ = (ğ‘”,...,ğ‘” )ğ‘‡ is a vector with length ğ‘›. It
Integrating Active Learning in Causal Inference with Interference:
A Novel Approach in Online Experiments Conferenceâ€™17, July 2017, Washington, DC, USA
then follows that these potential outcomes adhere to a multivariate
normal distribution, characterized by the mean:
E[ğ’‡ğ’‚ (ğ‘”,ğ‘¿)]= ğ‘²ğ‘»
ğ’•,âˆ—Â·[ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° ]âˆ’1 Â·ğ’šğ’• (8)
And covariance matrix:
Cov[ğ’‡ğ’‚ (ğ‘”,ğ‘¿)]= ğ‘²âˆ—âˆ’ğ‘²ğ‘»
ğ’•,âˆ—Â·[ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° ]âˆ’1 Â·ğ‘²ğ’•,âˆ— (9)
Following the definitions of overall treatment effects function
and spillover effects function, their estimators can be shown as
follows,
Ë†ğœ1 (ğ‘”)= Ë†ğ‘š1 (ğ‘”)âˆ’E[Ë†ğ‘š0 (0)] (10)
Ë†ğœ0 (ğ‘”)= Ë†ğ‘š0 (ğ‘”)âˆ’E[Ë†ğ‘š0 (0)] (11)
The linear combination of multivariate normal distributions still
follows a normal distribution. Therefore, we have,
Ë†ğœ1 (ğ‘”)âˆ¼ ğ‘(E[Ë†ğ‘š1 (ğ‘”)]âˆ’ E[Ë†ğ‘š0 (ğ‘”)],ğ‘‰ğ‘ğ‘Ÿ [Ë†ğ‘š1 (ğ‘”)])
âˆ¼ğ‘
1
ğ‘›(E[ğ’‡1 (ğ‘”,ğ‘¿)]âˆ’ E[ğ’‡0 (0,ğ‘¿)]), 1
ğ‘›2 (ğ’†ğ‘‡Î£[ğ’‡1 (ğ‘”,ğ‘¿)]ğ’†)
 (12)
Ë†ğœ0 (ğ‘”)âˆ¼ ğ‘(E[Ë†ğ‘š0 (ğ‘”)]âˆ’ E[Ë†ğ‘š0 (ğ‘”)],ğ‘‰ğ‘ğ‘Ÿ [Ë†ğ‘š0 (ğ‘”)])
âˆ¼ğ‘
1
ğ‘›(E[ğ’‡0 (ğ‘”,ğ‘¿)]âˆ’ E[ğ’‡0 (0,ğ‘¿)]), 1
ğ‘›2 (ğ’†ğ‘‡Î£[ğ’‡0 (ğ‘”,ğ‘¿)]ğ’†)
 (13)
3.2 Active Learning with Optimal Assignments
To improve the estimation accuracies, we can iteratively update
the experimental design. Our iteration is consist of two steps. The
first step identifies the the experimental condition (ğ‘âˆ—,ğ‘”âˆ—)based
on existing estimation. It is expected that additional samples with
this setting will improve the overall treatment effects. In the second
step, given the target (ğ‘âˆ—,ğ‘”âˆ—), we choose appropriate networks and
optimize the treatment assignments for subsequent experiment.
3.2.1 The selection of the target.In the initial experiments, condi-
tions ğ´= 1,ğº = 1 and ğ´= 0,ğº = 0 should have been included. For
network data, these two scenarios are easily achievable. This can
be done by simply setting the treatment for all individuals in the
network to either 1 or 0. Consequently, all the data in the current
network will satisfy the aforementioned conditions.
The treatment level selection is determined at the location where
the variance of the functions Ë†ğœğ‘(ğ‘”)is maximum. Because of the
unique feature of Gaussian process, this variance function is ana-
lytically available. This can be mathematically defined as:
ğ‘âˆ—,ğ‘”âˆ—= argmax
ğ‘,ğ‘”
Var[Ë†ğœğ‘(ğ‘”)].
We want to highlight that in active learning literature, other type
of criteria can be used as well. For example, choosing the (ğ‘âˆ—,ğ‘”âˆ—)
such that the integrated mean square error of the entire function
can be reduced most.
3.2.2 Mapping the pair (ğ‘âˆ—,ğ‘”âˆ—)onto the vectorAâˆ—. Upon the se-
lection of the target condition (ğ‘âˆ—,ğ‘”âˆ—), it becomes imperative to
determine the assignments for subsequent experiments, thereby
facilitating the active learning process. This necessitates the al-
location of a vector-based treatment Aâˆ—within the network. To
enhance the efficacy of the matching method in estimating effects,
the mapping from (ğ‘âˆ—,ğ‘”âˆ—)to Aâˆ—aims to achieve two primary
objectives: first, it maximizes the volume of data within a small
interval surrounding the target (ğ‘âˆ—,ğ‘”âˆ—), which is (ğ´= ğ‘âˆ—,ğº âˆˆGâˆ—);
second it maximizes the dispersion of the covariates ğ‘‹ within the
range (ğ´= ğ‘âˆ—,ğº âˆˆGâˆ—). (Gâˆ—= [ğ‘”âˆ—âˆ’ğ›¼/2,ğ‘”âˆ—+ğ›¼/2])
In the realm of applications, our sample data often encompass
multiple networks or can be easily segmented into multiple net-
works, each with distinct configurations and sizes. Specifically, we
consider a scenario with ğ‘„ networks. The ğ‘-th network, denoted
by ğ‘ = ğ‘ğ‘, comprises ğ‘›ğ‘ individuals. These heterogeneous net-
works exhibit distinct structural properties, leading to heterogeneity
in the transformation from treatment assignment Ağ’’ to the net-
work interference measure (transformed neighbor treatment) ğº,
as well as in the transformation of covariates within neighboring
units. For this network, after being assigned with vector-based
treatment Ağ’’, we have some individuals under treatment with
(ğ´= ğ‘âˆ—,ğº âˆˆGâˆ—). This subset of individuals owns a covariates set
ğ‘¿ğ’“ğ’’ (Ağ‘)= (ğ‘‹ğ‘Ÿ
ğ‘,1 (Ağ’’),...,ğ‘‹ ğ‘Ÿ
ğ‘,ğ‘›ğ‘Ÿğ‘ (Ağ’’ )(Ağ’’))ğ‘‡ with length ğ‘›ğ‘Ÿğ‘(Ağ’’).
In order to obtain the optimal Aâˆ—ğ’’, we maximize the fitness func-
tion for different networks (by using the genetic algorithm in algo-
rithm 2) ([18]),
max
Ağ’’ âˆˆRğ‘›ğ‘
ğ‘›ğ‘Ÿ
ğ‘ (Ağ’’ )âˆ‘ï¸
ğ‘–=1
ğ‘›ğ‘Ÿ
ğ‘ (Ağ’’ )âˆ‘ï¸
ğ‘—=1
ğ‘‘2 (ğ‘‹ğ‘Ÿ
ğ‘,ğ‘–(Ağ’’),ğ‘‹ğ‘Ÿ
ğ‘,ğ‘—(Ağ’’)), (14)
where ğ‘‘(ğ‘‹ğ‘Ÿ
ğ‘,ğ‘–(Ağ’’),ğ‘‹ğ‘Ÿ
ğ‘,ğ‘—(Ağ’’))denotes the distance between these
two covariates, which could be the Euclidean distance, the Man-
hattan distance, or other similar distance measures, to describe
dispersion while also relating to the number of samples.
Each network (for example, the ğ‘-th network) will obtain an op-
timal solution Aâˆ—ğ’’, along with the corresponding optimal value ğ¹âˆ—ğ‘.
The amount of data in the vicinity of the targeted interval around
(ğ‘âˆ—,ğ‘”âˆ—)is denoted as ğ‘›ğ‘Ÿğ‘(Aâˆ—ğ’’). Upon selecting a target (ğ‘âˆ—,ğ‘”âˆ—), to
effectively utilize the matching method, we define the lower bound
of data volume for (ğ´= ğ‘âˆ—,ğº âˆˆGâˆ—)as ğ‘€.
In summary, algorithm 1 shows the Active Learning Algorithm
with initializationğ‘ = {ğ‘1,...,ğ‘ ğ‘„}, and the datasetğ· = {ğ‘‹,ğ´,ğº,ğ‘Œ },
which initially starts as a set containing only the data of covariates,
with other elements being empty. Note, in algorithm 1,ğ· |(ğ´=ğ‘âˆ—,ğºâˆˆGâˆ—)
denotes the subset of data entries inğ·that have been experimented
with and stored, satisfying the conditions (ğ´ = ğ‘âˆ—,ğº âˆˆGâˆ—). The
notation
ğ· |(ğ´=ğ‘âˆ—,ğºâˆˆGâˆ—)
 denotes the number of such entries.
4 EXPERIMENTAL RESULTS
4.1 Simulation Data Experiment
Our simulation experiments utilized 100 networks, each contains
100 individuals with three features. Among these, ğ‘‹1 is a binary
variable taking on values of 0 or 1, while the other two, ğ‘‹2 and ğ‘‹3,
are continuous variables ranging from 0 to 1. The actual outcome
ğ‘Œğ‘–(ğ‘,ğ‘”)for each individual under the treatment level (ğ‘,ğ‘”)is given
by:
ğ‘Œğ‘–(ğ‘,ğ‘”)=(ğ›½1,1 Â·ğ¶21,ğ‘–+ğ›½1,2 Â·ğ¶2,ğ‘–+ğ›½1,3 Â· 1
ğ¶3,ğ‘–+1)Â·ğ‘
+(ğ›½0,1 Â·ğ¶21,ğ‘–+ğ›½0,2 Â·ğ¶2,ğ‘–+ğ›½0,3 Â· 1
ğ¶3,ğ‘–+1)Â·(1âˆ’ğ‘)
+
 
(ğ›½ğ‘1,1 Â·(ğ¶ğ‘1,ğ‘–)2 +ğ›½ğ‘1,2 Â· 1
1+ğ¶ğ‘2,ğ‘–
+ğ›½ğ‘1,3 Â·ğ¶ğ‘3,ğ‘–)Â·ğ‘”
+(ğ›½ğ‘0,1 Â·(ğ¶ğ‘1,ğ‘–)2 +ğ›½ğ‘0,2 Â· 1
1+ğ¶ğ‘2,ğ‘–
+ğ›½ğ‘0,3 Â·ğ¶ğ‘3,ğ‘–)Â·(1âˆ’ğ‘”)
!
Â·(ğ‘”âˆ’0.5)+ğœ€ğ‘–,
(15)
Conferenceâ€™17, July 2017, Washington, DC, USA Zhu et al.
Algorithm 1 Active learning Algorithm Description
Input networks ğ‘ and dataset ğ·, lower bound ğ‘€, empty points
set ğ¸, using treatment levels number upper limit ğ‘‡
Get initial targeted treatment level (ğ‘âˆ—,ğ‘”âˆ—)
for ğ‘– in ğ‘‡ do
for ğ‘ğ‘ in ğ‘ do
Get Aâˆ—ğ’’, ğ¹âˆ—ğ‘,ğ‘šâˆ—ğ‘by fitting the formula eq. (14) under targeted
treatment level (ğ‘âˆ—,ğ‘”âˆ—)
if ğ‘›ğ‘Ÿğ‘(Aâˆ—ğ’’)â‰¥ ğ‘€âˆ’
ğ· |(ğ´=ğ‘âˆ—,ğºâˆˆG)
 then
ğ‘ = ğ‘ \ğ‘ğ‘
Do the treatment assignment Aâˆ—ğ’’ on ğ‘ğ‘, and add data to
ğ·
end if
end for
if ğ‘›ğ‘Ÿğ‘(Aâˆ—ğ’’)for all ğ‘ğ‘ in ğ‘ is smaller than ğ‘€âˆ’
ğ· |(ğ´=ğ‘âˆ—,ğºâˆˆG)

then
Sort ğ¹âˆ—for all networks decreasingly. Get rank ğ‘…
Get ğ‘˜ with Ãğ‘˜âˆ’1
ğ‘–=1 ğ¹âˆ—
ğ‘…âˆ’1 (ğ‘–) < ğ‘€ âˆ’
ğ· |(ğ´=ğ‘âˆ—,ğºâˆˆG)
 and
Ãğ‘˜
ğ‘–=1 ğ¹âˆ—
ğ‘…âˆ’1 (ğ‘–) â‰¥ğ‘€âˆ’
ğ· |(ğ´=ğ‘âˆ—,ğºâˆˆG)

Assign treatment {Aâˆ—
ğ‘¹âˆ’1 (1),..., Aâˆ—
ğ‘¹âˆ’1 (ğ’Œ)} onto
{ğ‘ğ‘…âˆ’1 (1),...,ğ‘ ğ‘…âˆ’1 (ğ‘˜)}, and add data to ğ·
ğ‘ = ğ‘ \{ğ‘ğ‘…âˆ’1 (1),...,ğ‘ ğ‘…âˆ’1 (ğ‘˜)}
end if
Add (ğ‘âˆ—,ğ‘”âˆ—)to ğ¸
Do Gaussian Process Regression to get average overall treat-
ment effect functions and average spillover effect functions
Select new (ğ‘âˆ—,ğ‘”âˆ—)
end for
where the neighborhood averages ğ‘‹ğ‘
ğ‘˜,ğ‘– for ğ‘˜ = 1,2,3 are defined as:
ğ¶ğ‘
ğ‘˜,ğ‘– =
Ãğ‘›
ğ‘—=1 ğ‘¤ğ‘–ğ‘— Â·ğ¶ğ‘˜,ğ‘—
Ãğ‘›
ğ‘—=1 ğ‘¤ğ‘–ğ‘—
, ğ‘˜ = 1,2,3. (16)
Based on our active learning framework applied to this simula-
tion data, we obtained the results shown in Figure 5. Note that after
initializing the calculations for the points (0,0)and (1,1), our next
choice of points was (0,0.5)and (1,0.5). This intuitive selection
aids in our initial Gaussian process regression, after which we adopt
a treatment level selection method based on maximum uncertainty.
We observe that in Figure 5(d), we have achieved considerably
good regression results for both overall treatment effects function
and spillover effects function. At this point, we have only used 9
networks, conducting experiments on a total of 100 Ã—9 individuals.
This number is significantly less than the 100 Ã—100 = 10,000
individuals in the complete dataset. In essence, our method has
enabled us to make accurate estimates of the average effects for
10,000 individuals using only a limited number of experiments.
The simple random treatment allocation (RTA) is applied for com-
parison. It first randomly selects theğ‘”âˆ—for subsequent experiments,
and then it also randomly generates the vector-based treatments
allocation based on ğ‘”âˆ—, as detailed in Appendix A.4. From the sim-
ulation comparisons, the proposed ACI method surpass those of
(a) Experimented with 4 networks
 (b) Experimented with 6 networks
(c) Experimented with 7 networks
 (d) Experimented with 9 networks
Figure 5: Active Learning in Causal Inference with Inter-
ference (ACI) method: The light pink and dark blue curves
represent the estimated average overall and spillover effects,
respectively. Points along these curves represent sequentially
selected treatment levels. It should be noted that there may
be instances where two updates occur simultaneously, yet
not all are depicted graphically; for example, transitioning
from subfigure (a) to (b) introduces two additional sequential
treatment levels. The actual scenarios of these effects are
shown by two orange dashed curves.
the RTA method. Moreover, the ACI method demonstrates a pro-
cess where a function is sequentially optimized in a data-driven
manner. Although the RTAâ€™s predicted functions also show im-
provement, they reach a certain limit, making it challenging to fit
good functions perfectly across the entire range.
Additionally, the Estimated Integral Square Errors (EISE), defined
below,
ğ¸ğ¼ğ‘†ğ¸(Ë†ğœ1)=
âˆ«
(Ë†ğœ1 (ğ‘”)âˆ’ğœ1 (ğ‘”))2 ğ‘‘ğ‘”
ğ¸ğ¼ğ‘†ğ¸(Ë†ğœ0)=
âˆ«
(Ë†ğœ0 (ğ‘”)âˆ’ğœ0 (ğ‘”))2 ğ‘‘ğ‘”
for two different average effects functions at different stages are
presented in Table 1.
These superiorities of the ACI method can be attributed to two
main reasons: (i) the RTA method lacks a data-driven selection of
the optimal treatment level for the next experiment based on exist-
ing experimental results; (ii) RTA does not utilize an optimization
algorithm to map the target treatment level to an optimal vector-
based treatment level, making it challenging to capture the data
characteristics at this target treatment level fully.
Moreover, it is important to emphasize that RTA essentially em-
ploys the GPR method. Although it cannot guarantee optimal data
selection in the active learning phase, as can be observed in Fig-
ure 6(d), the predicted functions remain accurate within certain
ranges where data is readily available. This further illustrates the
Integrating Active Learning in Causal Inference with Interference:
A Novel Approach in Online Experiments Conferenceâ€™17, July 2017, Washington, DC, USA
(a) Experimented with 4 networks
 (b) Experimented with 6 networks
(c) Experimented with 7 networks
 (d) Experimented with 9 networks
Figure 6: Comparative random treatment allocation (RTA)
method: The light pink and dark blue curves illustrate
the regression-derived average overall treatment effect and
spillover effect . The light green vertical lines represent the
position of the randomly selected ğ‘”âˆ—.
Table 1: Comparison of EISE for ACI and RTA
Experimented
networksâ€™
number
Effect
functions EISE
ACI RTA
4 ğœ1 (ğ‘”) 85.39438557 447.59047721
ğœ0 (ğ‘”) 1814.645103 765.83402693
6 ğœ1 (ğ‘”) 338.79261773 565.92932241
ğœ0 (ğ‘”) 395.465169 968.10501448
7 ğœ1 (ğ‘”) 592.60175094 34.5195497
ğœ0 (ğ‘”) 51.28109163 443.99716071
9 ğœ1 (ğ‘”) 31.74120205 39.42437691
ğœ0 (ğ‘”) 14.60991894 517.14218562
advantage of our GPR method. However, to elaborate further, Fig-
ure 6 achieves better results within a certain range largely due
to good fortune. Given that our experiments are conducted on a
network-level basis, the number of individuals involved in each
experiment correlates with the size of the network. This leads to
the possibility, under the RTA method, of obtaining a significant
amount of data at various treatment levels due to favorable cir-
cumstances. Yet, even under these conditions, its results are still
inferior to ACIâ€™s. Not to mention that, in reality, we might be able
to use graph theory knowledge to delineate smaller yet reasonable
networks for experimentation.
4.2 Real Data Experiment
Working in partnership with Tencent, we conducted a practical
evaluation of our proposed methodology using data from an online
experiment on a mobile game. This gaming experiment aimed to
ascertain whether or not a treatment led to increased player engage-
ment compared to the control group. Engagement was measured,
for example, by the average online time of the user population. Our
analysis investigated the effects of own treatment ğ´and integrated
neighborsâ€™ treatment ğº on the average online time across the user
community. We established relational networks among the partici-
pants, considering in-game social connections, and included both
the number of friends and the KDA ratio (Kill, Death, Assist ratio,
an common indicator of gaming proficiency) as key covariates. Em-
ploying an active learning approach in conjunction with Gaussian
Process regression, we achieved significant results with the esti-
mated effects functions. As depicted in Figure 7, we successfully
predicted the overall potential outcomes function and the spillover
potential outcomes function, using experimental data from 33523
individuals among the entire population of 125286 individuals.
Figure 7: The case studyâ€™s implementation of the Active
Learning in Causal Inference with Interference (ACI) method:
The light pink and dark blue functions represent the esti-
mated average overall and spillover potential outcomes, re-
spectively. Points along these curves represent sequentially
selected treatment levels. The horizontal lines in light pink
and dark blue, respectively, signify the predicted potential
outcomes under treatment and control conditions, excluding
the consideration of interference.
As shown in Figure 7, the results indicated that both the overall
treatment effects function and the spillover effects function increase
at the beginning and then decrease after reaching the maximum.
This aligns with psychological patterns observed in gaming, where
having a few treated friends might encourage oneâ€™s increased en-
gagement in the game. However, if too many friends receive treat-
ment, it can lead to a decrease in an individualâ€™s effect due to a
lack of perceived exclusivity or feelings of jealousy. Moreover, we
observe the peak of the overall treatment effects occurs to the right
of the spillover effects, suggesting that individuals who are treated
themselves are more tolerant of a larger proportion of their friends
being treated. Additionally, the small difference between the overall
treatment effect and spillover effect at the endpoints whenğº = 0 or
ğº = 1 reflects that when all or none of an individualâ€™s friends are
Conferenceâ€™17, July 2017, Washington, DC, USA Zhu et al.
treated, the individualâ€™s own treatment has minimal effects. This is
consistent with the inherent social nature of the game.
Based on the results, we identified the treatment level that yields
the maximum effect (ğ´= 1,ğº = 0.612). However, it is not feasible
to allocate everyone in the population to this treatment level (ğ´=
1,ğº = 0.612). While determining the optimal decision-making
strategy based on the estimated functions is not the primary focus
of this paper, the results roughly suggest that treating about 50%
of the individuals in the population could potentially achieve the
optimal average treatment effect.
Additionally, we conducted an analysis under the assumption
of ignoring interference. This resulted in two horizontal lines in
fig. 7. We found that the average treatment effect, while ignor-
ing interference, is a negative value, âˆ’0.673. In contrast, when
considering interference, the optimal average treatment effect at
(ğ´= 1,ğº = 0.612)is a positive value, 2.681. This indicates that ig-
noring interference in the analysis could mislead decision-making,
suggesting a complete rejection of the treatment, which is not the
case in reality. This discrepancy arises because the distribution of
ğº in the population used for the experiment tends to favor smaller
values, where the direct treatment effects are negative, leading to
a negative average treatment effect when interference is ignored.
This underscores the necessity and advantage of considering inter-
ference, as emphasized by our proposed method.
5 CONCLUSION
We propose a novel active learning approach that enables data-
driven experimental design, facilitating causal research and estima-
tion of treatment effects in extensive network data with interference,
using minimal data. Our method, validated through simulation ex-
periments, demonstrates the feasibility of obtaining accurate effects
estimation with reduced data requirements, significantly enhanc-
ing data efficiency. Additionally, a real-world data application has
confirmed our approachâ€™s practical usability and value in actual
business contexts.
Looking forward, potential innovations could involve increasing
network complexity beyond the static network structures used in
this paper. In real-world settings, dynamic network structures are
common, where relationships might exist only temporarily, and
individuals might have different neighborhoods at varying times.
Moreover, the current methodology for integrating neighborsâ€™ co-
variates and treatments may not be the most effective way to extract
information from neighborhoods. Advanced techniques like neural
networks or other dimensionality reduction methods might be more
efficient to extract information from neighborhoods. Moreover, re-
garding the current method of integrating neighborsâ€™ treatments,
within a network, the states (ğ‘ = 0,ğ‘” = 0)and (ğ‘ = 1,ğ‘” = 1)
are easily achievable. However, reaching states like (ğ‘= 0,ğ‘” = 1)
and (ğ‘ = 1,ğ‘” = 0)can be challenging. If a sufficient number of
these two types of data is required, extensive experimentation
across multiple networks may be necessary. Perhaps a method
could be developed, for instance, by using the easily attainable
states (ğ‘ = 0,ğ‘” = 0)and (ğ‘ = 1,ğ‘” = 1), or by combining other
readily available treatment level scenarios. This could enable the
estimation of outcomes under challenging treatment levels like
(ğ‘= 0,ğ‘” = 1)and (ğ‘= 1,ğ‘” = 0)without the need for direct experi-
mentation in these hard-to-achieve conditions. Furthermore, guided
by our estimated functions, decision-making can be informed to
potentially determine what percentage of individuals in the pop-
ulation should be treated, or to devise an optimal vector-based
treatment assignment for a group within a network.
REFERENCES
[1] Alberto Abadie and Guido Imbens. 2002. Simple and bias-corrected matching
estimators for average treatment effects.
[2] Alberto Abadie and Guido W Imbens. 2011. Bias-corrected matching estimators
for average treatment effects. Journal of Business & Economic Statistics 29, 1
(2011), 1â€“11.
[3] Peter M Aronow and Cyrus Samii. 2017. Estimating average causal effects under
general interference, with application to a social network experiment. (2017).
[4] Sarah Baird, J Aislinn Bohren, Craig McIntosh, and Berk Ozler. 2014. Designing
experiments to measure spillover effects. (2014).
[5] Jake Bowers, Mark M Fredrickson, and Costas Panagopoulos. 2013. Reasoning
about interference between units: A general framework. Political Analysis 21, 1
(2013), 97â€“124.
[6] Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian
Hansen, Whitney Newey, and James Robins. 2018. Double/debiased machine
learning for treatment and structural parameters.
[7] David Roxbee Cox. 1958. Planning of experiments. (1958).
[8] Dean Eckles, RenÃ© F Kizilcec, and Eytan Bakshy. 2016. Estimating peer effects in
networks with peer encouragement designs. Proceedings of the National Academy
of Sciences 113, 27 (2016), 7316â€“7322.
[9] Laura Forastiere, Edoardo M Airoldi, and Fabrizia Mealli. 2021. Identification
and estimation of treatment and interference effects in observational studies on
networks. J. Amer. Statist. Assoc. 116, 534 (2021), 901â€“918.
[10] Laura Forastiere, Fabrizia Mealli, Albert Wu, and Edoardo M Airoldi. 2022. Es-
timating causal effects under network interference with Bayesian generalized
propensity scores. The Journal of Machine Learning Research 23, 1 (2022), 13101â€“
13161.
[11] Bryan S Graham, Guido W Imbens, and Geert Ridder. 2010.Measuring the effects of
segregation in the presence of social spillovers: a nonparametric approach . Technical
Report. National Bureau of Economic Research.
[12] M Elizabeth Halloran and Claudio J Struchiner. 1991. Study designs for dependent
happenings. Epidemiology 2, 5 (1991), 331â€“338.
[13] M Elizabeth Halloran and Claudio J Struchiner. 1995. Causal inference in infec-
tious diseases. Epidemiology (1995), 142â€“151.
[14] Miguel A HernÃ¡n and James M Robins. 2010. Causal inference.
[15] Guanglei Hong and Stephen W Raudenbush. 2006. Evaluating kindergarten
retention policy: A case study of causal inference for multilevel observational
data. J. Amer. Statist. Assoc. 101, 475 (2006), 901â€“910.
[16] Yiyan Huang, Cheuk Hang Leung, Qi Wu, Xing Yan, Shumin Ma, Zhiri Yuan,
Dongdong Wang, and Zhixiang Huang. 2022. Robust causal learning for the
estimation of average treatment effects. In 2022 International Joint Conference on
Neural Networks (IJCNN) . IEEE, 1â€“9.
[17] Michael G Hudgens and M Elizabeth Halloran. 2008. Toward causal inference
with interference. J. Amer. Statist. Assoc. 103, 482 (2008), 832â€“842.
[18] Adam KoÅ‚acz and PrzemysÅ‚aw Grzegorzewski. 2016. Measures of dispersion for
multidimensional data. European Journal of Operational Research 251, 3 (2016),
930â€“937.
[19] Michael P Leung and Pantelis Loupos. 2022. Unconfoundedness with network
interference. arXiv preprint arXiv:2211.07823 (2022).
[20] Fan Li, Kari Lock Morgan, and Alan M Zaslavsky. 2018. Balancing covariates via
propensity score weighting. J. Amer. Statist. Assoc. 113, 521 (2018), 390â€“400.
[21] Lan Liu, Michael G Hudgens, and Sylvia Becker-Dreps. 2016. On inverse
probability-weighted estimators in the presence of interference. Biometrika
103, 4 (2016), 829â€“842.
[22] Xinwei Ma and Jingshen Wang. 2020. Robust inference using inverse probability
weighting. J. Amer. Statist. Assoc. 115, 532 (2020), 1851â€“1860.
[23] Elizabeth L Ogburn, Oleg Sofrygin, Ivan Diaz, and Mark J Van der Laan. 2022.
Causal inference for social network data. J. Amer. Statist. Assoc. (2022), 1â€“15.
[24] Elizabeth L Ogburn and Tyler J VanderWeele. 2014. Causal diagrams for interfer-
ence. (2014).
[25] Carl Edward Rasmussen, Christopher KI Williams, et al. 2006. Gaussian processes
for machine learning . Vol. 1. Springer.
[26] James M Robins, Andrea Rotnitzky, and Lue Ping Zhao. 1994. Estimation of
regression coefficients when some regressors are not always observed. Journal
of the American statistical Association 89, 427 (1994), 846â€“866.
[27] Paul R Rosenbaum. 2007. Interference between units in randomized experiments.
Journal of the american statistical association 102, 477 (2007), 191â€“200.
Integrating Active Learning in Causal Inference with Interference:
A Novel Approach in Online Experiments Conferenceâ€™17, July 2017, Washington, DC, USA
[28] Paul R Rosenbaum and Donald B Rubin. 1983. The central role of the propensity
score in observational studies for causal effects. Biometrika 70, 1 (1983), 41â€“55.
[29] Donald B Rubin. 1974. Estimating causal effects of treatments in randomized and
nonrandomized studies. Journal of educational Psychology 66, 5 (1974), 688.
[30] Donald B Rubin. 1980. Randomization analysis of experimental data: The Fisher
randomization test comment. Journal of the American statistical association 75,
371 (1980), 591â€“593.
[31] Eric Schulz, Maarten Speekenbrink, and Andreas Krause. 2018. A tutorial on
Gaussian process regression: Modelling, exploring, and exploiting functions.
Journal of Mathematical Psychology 85 (2018), 1â€“16.
[32] Eli Sherman and Ilya Shpitser. 2018. Identification and estimation of causal
effects from dependent data. Advances in neural information processing systems
31 (2018).
[33] Michael E Sobel. 2006. What do randomized studies of housing mobility demon-
strate? Causal inference in the face of interference. J. Amer. Statist. Assoc. 101,
476 (2006), 1398â€“1407.
[34] Eric J Tchetgen Tchetgen and Tyler J VanderWeele. 2012. On causal inference in
the presence of interference. Statistical methods in medical research 21, 1 (2012),
55â€“75.
[35] Mark J Van der Laan. 2014. Causal inference for a population of causally connected
units. Journal of Causal Inference 2, 1 (2014), 13â€“74.
[36] Tyler J VanderWeele, Guanglei Hong, Stephanie M Jones, and Joshua L Brown.
2013. Mediation and spillover effects in group-randomized trials: a case study of
the 4Rs educational intervention. J. Amer. Statist. Assoc. 108, 502 (2013), 469â€“482.
[37] Francesco Vivarelli and Christopher Williams. 1998. Discovering hidden features
with Gaussian processes regression. Advances in Neural Information Processing
Systems 11 (1998).
[38] Shu Yang and Yunshu Zhang. 2023. Multiply robust matching estimators of
average and quantile treatment effects. Scandinavian Journal of Statistics 50, 1
(2023), 235â€“265.
A APPENDIX
A.1 Combined kernel function
In order to perform Gaussian Process Regression (GPR), we need
to define our kernel to represent the correlation between two data
points. In our GPR problem, the features are of two types: one is the
integrated neighborsâ€™ treatment ğº, and the other is the integrated
covariates ğ‘‹. In the causal structure, these two types of variables
have distinct properties; hence, they should not be considered equiv-
alent in the kernel. For instance, the kernel function is employed to
model the influence of neighborsâ€™ treatments and the interaction
between this treatment and covariates on the potential outcome
([25]),
ğ‘˜((ğ’™,ğ‘”),(ğ’™â€²,ğ‘”â€²))= ğ‘˜ğ‘”(ğ‘”,ğ‘”â€²)+
ğ‘âˆ‘ï¸
ğ‘—=1
ğ‘˜ğ‘—((ğ‘¥ğ‘—,ğ‘”),(ğ‘¥â€²
ğ‘—,ğ‘”â€²)) (17)
Alternatively, with a primary focus on scenarios where the covari-
ates ğ‘‹ are high-dimensional, and recognizing that different types
of covariates exert anisotropic effects on the outcome, we have
developed a specific kernel to tackle this issue. This kernel is inten-
tionally designed to mirror the distinct causal relationships between
ğº and ğ‘‹, and to effectively capture the anisotropic nature inherent
within ğ‘‹,
ğ‘˜((ğ‘¥,ğ‘”),(ğ‘¥â€²,ğ‘”â€²))=ğœ2
ğ‘¥ exp

âˆ’1
2 (ğ‘¥âˆ’ğ‘¥â€²)ğ‘‡ğ‘„(ğ‘¥âˆ’ğ‘¥â€²)

(18)
+ğœ2
ğ‘” exp
 
âˆ’ 1
2ğœ†2ğ‘”
(ğ‘”âˆ’ğ‘”â€²)2
!
Where ğ‘„ is a positive definite, diagonal matrix, borrowing idea
from [25] and [37].
A.2 Optimizing hyper-parameters
To optimize the hyperparameters such as the length-scale and sig-
nal variance in Gaussian Process Regression (GPR), one typically
maximizes the marginal (log) likelihood function of the training
data ([25, 31]).
Given a set of training data and hyper-parameters denoted as ğœ½,
the log marginal likelihood is expressed as:
log ğ‘(ğ’šğ’• |ğ‘¿,ğ’ˆ,ğœ½)= âˆ’1
2ğ’šğ‘»
ğ’• [ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° ]âˆ’1ğ’šğ’• âˆ’1
2 log |ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° |
âˆ’ğ‘›ğ‘¡
2 log 2ğœ‹
To utilize gradient descent methods such as Standard Gradi-
ent Descent, Conjugate Gradient Descent, and Limited-memory
Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno Algorithm, itâ€™s necessary to
calculate the partial derivatives of the log likelihood function Equa-
tion A.2 with respect to the hyper-parameters ğœ½. The derivative
can be expressed as:
ğœ•log ğ‘(ğ’šğ’• |ğ‘¿,ğ’ˆ,ğœ½)
ğœ•ğœƒğ‘—
= 1
2ğ’šğ‘»
ğ’• [ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° ]âˆ’1ğ’šğ’•
âˆ’1
2 tr
 
[ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° ]âˆ’1 ğœ•[ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° ]
ğœ•ğœƒğ‘—
!
= 1
2 tr
 
ğœ¶ ğœ¶ğ‘» âˆ’[ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° ]âˆ’1
 ğœ•[ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° ]
ğœ•ğœƒğ‘—
!
with ğ›¼ = [ğ‘²ğ’• +ğœ2
ğ‘¡ğ‘° ]âˆ’1ğ’šğ’• .
A.3 Genetic Algorithm
The algorithm 2 presents a simplified version of the genetic algo-
rithm used in our computations. In practice, to prevent overfitting,
an early stopping criterion is implemented, which terminates the
algorithm if there is no improvement in the fitness value within
a certain number of generations. Additionally, the initialization
function, roulette-wheel selection function, and crossover muta-
tion function utilized within the algorithm have been specifically
tailored to address our particular problem set.
A.4 Random treatment allocation
Similar to the proposed method, the random treatment allocation
also initiates with base points ğ´= 1,ğº = 1 and ğ´= 0,ğº = 0. Then,
the selection process alternates between points with ğ´ = 1 and
ğ´= 0, striving for a balance in representation. However, we decide
ğ‘”âˆ—randomly from a uniform distribution over the interval (0, 1),
denoted as ğ‘”âˆ—âˆ¼U(0,1). After determining ğ‘”âˆ—, to ensure compara-
bility with the guidelines of the proposed method, it is necessary
to ensure that the simulation of the random treatment allocation
method uses the same number of networks as the proposed method.
Assume that the proposed method uses ğ‘ğ‘¢ networks and predicts
effect values for ğ‘›ğ‘¢ (ğ´,ğº)point pairs. The number of networks
used for treatment assignments in the random treatment allocation
can be represented as ğ‘µğ’“ , a vector of length ğ‘›ğ‘¢, as seen in Algo-
rithm 3. Subsequently, for nodes of selected networks, we assign
ğ´= 1 to a proportion of nodes as determined by ğ‘”âˆ—.
Conferenceâ€™17, July 2017, Washington, DC, USA Zhu et al.
Algorithm 2 Optimization for Current Network
Input: target neighborsâ€™ treatment ğ‘”, targetâ€™s own treatment ğ‘,
blocking length ğ›¼, relation matrix ğ‘Š, number of epochs epoch,
parameter ğ‘˜, number of batches per epoch ğ¾
Initialize the initial set of ğ¾ parents Ağ‘²
for each epoch ğ‘– do
Calculate fitness value ğ¹ğ¾ for the ğ¾ parent vector-based treat-
ments Ağ‘² using eq. (14)
for ğ‘–in ğ¾ do
Select two parents from theğ¾parents using a roulette-wheel
selection method
Generate two children by crossover of the two selected
parents, and calculate the fitness value for each child using
eq. (14); select the child with the higher fitness value
Store this selected child in Ağ‘²
ğ‘ª
end for
From Ağ‘² and Ağ‘²
ğ‘ª , selectğ¾treatments with the higher fitness
value to update Ağ‘²
end for
return The best treatment assignment is the one in Ağ‘² with
the highest fitness value
Algorithm 3 Even Distribution of an Integer
Require: Integer ğ‘ğ‘¢, number of parts ğ‘›ğ‘¢
Ensure: Vector ğ‘µğ’“ of length ğ‘›ğ‘¢ with distributed values
ğ‘ğ‘ğ‘ ğ‘’ â†âŒŠğ‘ğ‘¢/ğ‘›ğ‘¢âŒ‹
ğ‘Ÿğ‘’ğ‘šğ‘ğ‘–ğ‘›ğ‘‘ğ‘’ğ‘Ÿ â†ğ‘ğ‘¢ mod ğ‘›ğ‘¢
Initialize vector ğ‘µğ’“ [1 ...ğ‘› ğ‘¢]to ğ‘ğ‘ğ‘ ğ‘’
for ğ‘– = 1 to ğ‘Ÿğ‘’ğ‘šğ‘ğ‘–ğ‘›ğ‘‘ğ‘’ğ‘Ÿ do
ğ‘µğ’“ [ğ‘–]â† ğ‘µğ’“ [ğ‘–]+1
end for
return ğ‘µğ’“