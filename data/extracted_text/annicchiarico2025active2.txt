An Active Inference perspective on Neurofeedback Training
Coˆ me ANNICCHIARICO1,2, Fabien LOTTE2, and Jérémie MATTOUT1
1COPHY Team, Lyon Neuroscience Research Center, CRNL, INSERM, U1028,
Lyon, FRANCE
2POTIOC Team, INRIA centre at the University of Bordeaux / LaBRI, Talence,
FRANCE
2025-05-07
Abstract
Neurofeedback training (NFT) aims to teach self-regulation of brain activity through real-
time feedback, but suffers from highly variable outcomes and poorly understood mechanisms,
hampering its validation. To address these issues, we propose a formal computational model
of the NFT closed loop. Using Active Inference, a Bayesian framework modelling perception,
action, and learning, we simulate agents interacting with an NFT environment. This enables
us to test the impact of design choices (e.g., feedback quality, biomarker validity) and subject
factors (e.g., prior beliefs) on training. Simulations show that training effectiveness is sensitive
to feedback noise or bias, and to prior beliefs (highlighting the importance of guiding instruc-
tions), but also reveal that perfect feedback is insufficient to guarantee high performance. This
approach provides a tool for assessing and predicting NFT variability, interpret empirical data,
and potentially develop personalized training protocols.
1 Introduction
Brain-Computer Interfaces (BCIs) encompass a large number of technologies specialized in ac-
quiring brain signals, analyzing them and translating them into commands or information for an
external system [SKW12]. Neurofeedback is a specific use-case of BCIs in which the signals, typi-
cally acquired using electroencephalography (EEG), are aimed at promoting the self-modulation of
brain activity. The ability of animals to control their own brain activity through Neurofeedback-
driven operant-conditioning has been established as early as the 1970’s [Fet69]. Beyond those first
experiments, the nature of the learning mechanisms that would allow a human to control a BCI
is still very much debated [WKWN14, HCW+15, SRS+17, CCS+20]. In fact, effective control of
such interfaces has proven very difficult or even impossible for a significant proportion of users
leading to the emergence of the debated concepts of BCI illiteracy [VB10, Tho19] and Neurofeed-
back non-responders [AARST18].
Neurofeedback training attempts to teach subjects how to control specific biomarkers derived
from their own brain activity (or neuromarker). A neuromarker designates a measurable neuro-
physiological activity that is assumed to specifically and truthfully reflect a psychological or mental
state of interest. The most widespread Neurofeedback protocols featuring EEG measurements tar-
get spontaneous brain rhythms, that is oscillations in specific frequency bands [MMM16, ABB+17],
with a relatively loose spatial resolution. Other, less common approaches involve different brain
markers (such as connectivity estimates) or more involved measuring apparati like functional Mag-
netic Resonance Imaging (fMRI) [BBPD20] or magnetoencephalography (MEG) [OHL+15], with
better spatial resolution but narrower out-of-the-lab application perspectives.
[EGSPA19] enumerates three major domains of application of Neurofeedback. First, NFT train-
inghasbeenusedbyresearcherstoimprovehealthysubjectscognitiveperformances[Gru14,Gru13,
YHKI17]. This approach relies on brain plasticity to initiate directional changes in healthy subjects
behaviour, in areas such as attention, spelling, confidence, etc. [LZH21]. Another emerging field of
use of NFT is as a scientific tool [SRS+17]. Indeed, Neurofeedback can be used to favour the emer-
gence of specific neurophysiological patterns and study the associated behavioural ones [BBPD20]
1
arXiv:2505.03308v1  [q-bio.NC]  6 May 2025
Figure 1: A schematic representation of the neurofeedback closed-loop paradigm.1. The subject
physiological brain signals (electromagnetic, BOLD signal, etc.) are acquired using EEG, MEG,
fMRI, etc.2. They are used to infer the hidden subject cognitive state that caused it. The experi-
menter derives a task-specific feedback from the infered state. Note that this latent state inference
relies on strong hypotheses made by the experimenter about parts of the neurophysiological /
measuring process underlying the neurofeedback.3. The subject perceives the feedback through
various sensory means. (auditory, visual, etc.) and tries to relate it to its own cognitive state
(4.).The subject thus tries to learn the relationship between his hidden cognitive states and the
indicator displayed on the screen. On the left, a few other factors which may influence the cognitive
dynamics of the subject training are shown.
as well as the associated subjective reports. Most neurofeedback studies however focus on the devel-
opment of non-pharmacological therapies for psychiatric and neurological disorders such as Atten-
tional Deficit and Hyperactivity Disorder (ADHD). [EGSPA19, ACT+20, HSHB20, DAH+19], in-
somnia [HPH+82, SGG+17, LBJPB21, HCBI11, LLZ+22], anxiety [MPP+11, HZL+21, CXB+21],
epilepsy [ZWLH09, SBWK14], chronic pain [RdlVJM20], etc. Such NFT paradigms usually aim at
having a significant (positive) impact on behavioral symptoms (e.g. focusing and learning abilities
in children with attention disorder).
Wide-scale adoption of neurofeedback protocols for therapy by the general public has radically
increased in the last decade, yet no consensus on the efficacy of neurofeedback therapies has been
reached by the scientific community [LSSO95, MFGF+14, CFB+16]. One of the principal chal-
lenges in evaluating the overall efficacy of NFT lies in its broad therapeutic claims, which have led
to its application across a diverse range of biomarkers. This diversity complicates the comparison of
findings across different studies. Furthermore, the disorder-specific relevance of these biomarkers is
often inadequately validated [BBC+19]. Typically, researchers rely on empirical evidence showing
a significant correlation between a cognitive disorder (e.g., attention deficit) and a specific neuro-
marker deviation (e.g., the theta/beta power ratio as measured by EEG). They hypothesize that
normalizing this deviation will consequently enhance cognitive function in the affected individuals.
To test these hypotheses and disambiguate effects beyond placebo or non-specific training factors,
double-blind randomized control trials have become the gold standard in Neurofeedback studies.
However, randomized controlled trials are particularly cumbersome to set up. The outcome of
existing studies are difficult to synthesize as they differ in many aspects including the targeted
population and biomarkers, the design and protocol used, etc. Moreover, sample size is often
limited. As a result, evidence is scarce and fragile [MMM16, EGSPA19, TKLM20, RMYBCSZ21].
For example, although neurofeedback therapy for ADHD patients has become common practice,
several studies concluded that changes in subjects’ behaviour cannot be proved to be more than a
placebo effect [LGH+07, AS13, CTCB13]. Even if the training is successful on the short term, the
long-term effects of neurofeedback therapies are often lackluster and in need of complementary solu-
tions [MHS+09]. This has led to debates regarding how experiments should be performed: what is
the aim of the training, how to implement a proper control condition e.g. with sham feedback, how
to evaluate the effect and specificity of the training, etc. [DBVSWB13, CPS+14, vDBVSWB14].
2
In recent years, although a few experimental studies and meta-analysis concluded in favor of
encouraging results [ARS+09, ABB+17, PBAEG21], others pointed the empty part of the glass.
This obvious difficulty faced by the community to draw solid and common conclusions, has led to
a call for protocol and reporting standardization [MFGF+14, TVOR18, REGZ+20]. Moreover, to
explain the inconsistency of the results, researchers have also shown interest in comparing method-
ological and technical details of those approaches and proposing different explanations for success
or failure [MMM16, CFB+16, BCB+19].
This joint effort and strong call for strengthening our methodology is very encouraging and a
clear sign of maturation of the young science of neurofeedback. However, it still lacks a common
generic description of the training process, used to clearly articulate our hypotheses around our
partial understanding of the mechanism at play during NFT. This missing piece is a mandatory
next step to further guide the development of neurofeedback, as it should act as a common lan-
guage for researchers to1. understand what are the fundamental goals of NFT,2. formalize
what hypotheses are made when designing a training paradigm,3. quantifythe effect of explicit
and implicit training factors in order to predict the outcome and4. communicate their results
and interpret the ability (or inability) of the subjects to control their brain activity. This paper
shows that the Active Inference framework[FFR+16], briefly outlined in 2.2.1, can be leveraged to
provide a complete description of BCI / NF training. In the remainder of this introduction, we give
the reader an overview of the main components of a neurofeedback training loop and of the main
factors explaining the variability between outcomes. Then, we give a quick overview of existing
modeling works that tackled the NFT problem. Finally, we motivate the introduction of a novel
high-level subject-centered model of BCI interaction to account for all the previously explained
factors.
Neurofeedback uncertainties and hypotheses :Neurofeedback training relies on numer-
ous functional components. There have been efforts by the scientific community to formalize which
elements of the neurofeedback pipeline could explain training failures. [ABB+17] summarizes the
main advantages and pitfalls of neurofeedback in children with ADHD. The authors point out
two categories of issues that mostly affect the efficacy of the training: technical ones related to
recordings or trial design parameters (signal quality, processing algorithms, reward threshold and
timing, feedback nature, session structure and frequency, trial-based and session-based learning
curves, experimenter’s influence, transfer exercises...) and issues related to learning mechanisms
(learnability, perceptibility, mastery, motivation, autonomy). Predictive approaches such as those
introduced in [AARST18, WEE20] focus on figuring out which neurophysiological markers could
explain training success or failure, and which mechanisms explain the differences of outcomes be-
tween subjects.
Finally, [BBC+19] propose several intrinsic factors challenging neurofeedback efficacy and slow-
ing its recognition as a valid therapeutic method by the larger neuroscientific community. First
is the biomarker hypothesis used to infer subject cognitive states. We still struggle to understand
the exact relationship between brain activity features and cognitive dimensions. It is also chal-
lenging to understand how a mental disorder affects brain activity. This limits attempting to use
brain-wide physiological signals as a vector for therapy requires to specific, reliable and observable
marker [YHY+17]. Second, a lot of neurofeedback training factors are subject-specific. We have
a very superficial knowledge on how to best fit the neurofeedback loop to the subject, and the
effect of endogenous factors (motivation, attention, drowsiness,etc.) and exogenous factors (effect
of instructions, task set, feedback design) is still hardly quantified. Finally, there is a significant
lack of understanding of the mechanisms behind conscious regulation of brain mechanisms. This
broad expression hides a semantic ambiguity between two key questions with regard to the practice
of neurofeedback : (1.) How is the subject learning ? and (2.) What is the subject learning ?
Although related, they tackle different angles of the paradigm :
• "How is the subject learning ?" targets the pseudo-algorithm that best describes subject
knowledge gathering during a training session. The nature of most NF exercises as ex-
ploratory tasks with the goal of optimizing a positive feedback naturally points towards op-
erant conditioning (Skinner) [GHA+09a]. Subjects favor actions that led to positive (changes
in the) feedback, and refrain from actions that produced opposite effects. However, operant
conditioning alone struggle to tackle the issue of generalization after training, in the absence
of an explicit reward. An alternative view, that we will showcase in this paper, formalizes
3
the training as learning an efficient representation of the full neurofeedback loop. Instead
of learning what actions lead to positive feedbacks, subjects learn how their actions affected
their (mental) environment, with increasing the feedback being just part of their drive.
• "Whatisthesubjectlearning?"focusesonthegoalofthetrainingandtheeffectofthesessions
onthedynamicsofthesubject. Althoughintimatelylinkedtothepreviouspoint, itfocuseson
what part of the subject dynamics are affected by the training. In operant conditioning, what
is learnt is often the mapping between a stimulus (e.g. a low level of feedback) and an action
probability. This is somewhat limited as it struggles to explain why such a training would
have any usefulness in the absence of an explicit feedback (in effect reducing the true NF
effect to a simple habit). Two potentially compatible elements may mitigate this fact : first,
NFT may be a way for the subject to learn how to interpret implicit (interoceptive) feedback
signals (heart rate, metacognitive awareness, etc.). By associating these signals with the
performed actions during training (following some kind of classical conditionning (Pavlov)),
the subject becomes able to use this knowledge outside of the training environment. Second,
subjects may learn how actions affect hidden states rather than what actions to perform given
a specific feedback. This is in line with [VKC21] who argue that skill learning [GHA+09b],
defined as a conscious and active mechanism of model building following observations, plays
an integral part during neurofeedback training.
Factors of neurofeedback efficacy :Numerous pivotal elements have been demonstrated to
strongly influence the outcome of BCI training. Ideally, models of Neurofeedback training should
capture one or several of the following effects :
• F1 : biomarker specificity. We still have superficial knowledge about brain dynamics
and the scientific consensus about how physiological markers relate to a behavioural (and
cognitive) features is often approximate and consistently shifting [PCB+20]. Nonspecific
biomarkers may be affected by several cognitive dimensions, and regulating them may lead
to unwanted cognitive alteration : for instance, motor imagery training [ZCY+22] may cause
anxiety [CXB+21] because the chosen biomarkers may share common features. Training a
wide array of possible cognitive states may induce several possible limitations: the cognitive
training can fail due to the subject focusing on non-targeted cognitive states that prompt a
positive feedback [MJL14, RBCC13, GSF+17]. Physiological markers depending on several,
possibly unrelated cognitive states also constitute poor training indicators, as their value can
change depending on state combinations and prevent efficient learning. Finally, the cognitive
pathways involved in self-regulating may affect unwanted cognitive dimensions (e.g. "to focus
my attention, i have learnt to act in a way that also causes anxiety...").
• F2 : measurement noise. The brain signals used to provide a feedback to the subject
may be significantly altered during measurement. It may be due to deformation/diffusion
through the subject’s head, measurement noise sources, loss of resolution, blind spots, etc.
The experimenter uses aforward model to reconstruct the raw physiology of the brain
using measurements, but these inferences may be flawed and induce significant error sources
: for instance, high feedback noise may prevent subjects from effectively finding out which
mental strategy worked well to increase the feedback / find patterns in how the feedback
responds to their mental actions. This may render the training useless as the indicator seems
uncontrollable or random.
• F3 : user factors (both exogenous and endogenous).Several factors linked to patient
cognition and behaviour have a significant influence on the course of a BCI training. Ex-
ogenous elements such as the experimenter instructions before and during the training, the
task set or the form of the feedback provided to the subjects have been recognized as signifi-
cant factors of training success [JLB+18, REGZ+20, RPM+21]. The influence of endogenous
factors such as subject fatigue, motivation or particular emotions on BCI training have a sig-
nificant impact on training [RBCC13, MJL14, GSF+17], but these effects have also proven
difficult to explain. Some modeling studies, such as [OLPS17], have made use of spontaneous
noise in the brain activity as a way to describe internal endogenous perturbations, but as
far as we know, these elements haven’t yet been the object of explicit quantitative modelling
and we believe it constitutes a key point to explain training outcomes. Thankfully, recent
approaches in the field of predictive coding and Active Inference have taken to model the
cognitive effect of some endogenous factors (mindfulness, emotions), and provided conceptual
frameworks to study their effect on training [HSP+21, SSHL+20].
4
• F4: learningmechanisms. BecauseBCI/Neurofeedbacktrainingarelearningparadigms,
they require the experimenter to design a well thought-out environment to guide the evolution
of the subject. The nature of the learning mechanisms at play during BCI training has been
wildly debated (see above).
• F5 : placebo effect. Finally, the impact of placebo effects on the training outcome has
proven hard to disentangle from "true" NF effect [OMHT23]. The prevailing consensus in
neurofeedback studies is to systematically assess Neurofeedback protocols through double-
blind studies [FMFV+17, SGG+17, REGZ+20]. This has led [TLR17] to coin the term of
"superplacebo" for NFT : a paradigm in which both experimenter and subject believe in the
therapeutic benefits of a practice despite of the lack of supporting evidence, leading to an
increased placebo effect and more biaised reporting . Other approaches underlined that the
placebo effect was a integral part of the neurofeedback training [OLRV21], playing a neutral-
ization or amplification role in the training efficacy. Whatever argument eventually prevails,
the non-specific mechanisms of NFT related to the technology and the user [WK18, PRNL21],
within or outside of the training proper, are crucial features of theses studies, while still some-
times under-reported.
Existing modeling works :Modeling approaches have built upon those theoretical leads to
create computational representations of neurofeedback training. The objective of these studies is to
capture part of the dynamics inherent to neurofeedback training, explain the current experimental
results and hopefully predict the impact of some parameters on the training outcome. Previous
formalization approaches have focused on defining the key concepts of neurofeedback, most partic-
ularly subject feedback perception, feedback control and learning. Gaume et al. [GVMS+16] have
proposed a formal description of the psychological dynamics involved in neurofeedback and derived
a control-theory inspired model of NFT, featuring both implicit and explicit feedback modalities.
However, they did not provide an explicit computational model describing the dynamics of the
training . Davelaar has proposed multi-stage,anatomical-based model of EEG brainwave regula-
tion through neurofeedback [Dav18] as well as multi-stage model of neurofeedback subject learning
phases [Dav20]. In the former, pools of excitatory and inhibitory neurons were used to generate
artificial EEG data, as described in [Izh03]. An artificial striatal unit made of 1000 binary neu-
rons controlled the peak alpha frequency chosen as marker. The agent looked for the responsible
group of neurons through incremental probability updating using the feedback provided to him.
This approach was a low-level model of neuron selection which described the physiological path-
ways involved during self-regulation of the subjects but did not tackle higher-level function. For
instance, the model did not describe training effect on user mental state or the impact of prior
biases. [OLPS17] investigated the influence of temporal factors on subjects ability to self-regulate.
It proposed a model of subject self-regulation during fMRI neurofeedback training involving a diffi-
cult credit assignment problem, modulated by feedback delay and noise. Importantly, two distinct
learning structures were compared to test the influence of different subject learning strategies.
Cognitive learning was meant to represent explicit strategies the subjects could pick when faced
with the feedback, whereas automatic learning was associated with a more implicit modality where
the subject tried to control an unconstrained set of cognitive states given a feedback signal, in a
formulation reminiscent of reinforcement learning (RL). More recently, a study by Lubianiker and
colleagues [LPDH22] featured a family of models similar to the ones shown in this paper, that
mapped traditional NFT components to canonical (model-free) RL elements. According to this
formulation, the feedback provided to the subjects constitutes states and the NF subjects are as-
similated to RL agents having to pick actions by learning a value function, relating those states
and potential mental actions. Although the proposed framework constitutes an adequate approx-
imation for the initial interaction between a subject and the BCI loop, it struggles to account for
later parts of the training, especially the ability of subjects to learn a more refined representation
of the environment or transfer the acquired knowledge in another environment. We argue that a
more model-based account of subject experience during NFT is needed to account for these phe-
nomenons and to capture the effect of endogenous factors such as subject motivation, experimenter
instructions, and more generally to allow for a better interpretability of training mechanisms and
outcomes.
Motivation :This paper aims at improving upon the previous approaches to by providing an
alternative perspective on BCI/neurofeedback training. All in all, this paper answers a triple need
expressed by the neurofeedback community :
5
• 1. We propose a complete family of models based on the Active Inference framework, allowing
us to describe subject learning during NFT, from the initial exploratory steps to the transfer
learning. This family of models is generic and may feature a number of alternative hypotheses
regarding the driving mechanisms / goals of training.
• 2. We show how one may use this formulation to clearly frame NF training goals and
hypotheses :What kind of change is my neurofeedback training aiming for within the subjects
? What are my assumptions regarding the biomarker I am using ? How do I expect my
instructions to affect the training ?
• 3. Weshowthatthisfamilyofmodelsmaybeusedtoanswerresearcherquestionsandprovide
broad estimators for subject parameters. If the experimenters have precise expectations
regarding some key parameters of the training (noise of the biomarker, layout of the cognitive
states of the subject, etc.) , we may be able to explain variability in results and eventually
predict subject training curves depending on their internal parameters. This may eventually
lead to increased therapeutic efficiency through the design of training paradigms tailored for
each individual.
Our approach breaks from the previously established works by modeling the evolution of sub-
ject beliefs during training. Similarly to [LPDH22], we describe the whole BCI loop as an action
selection problem, but we leverage Active Inference to equip the subjects with a broader variety
of internal representation(s) of their environment. This allows us to explicitly model subject per-
ceptual uncertainty, the effect of prior beliefs about their environment (beliefs about the feedback,
about their ability to control their brain activity), of experimenter instructions, of various mental
representations, etc. Contrary to the works of Davelaar and Oblak, our formulation focuses on
cognitive aspects of training and does not make explicit the brain activity of the subjects, instead
considering a direct mapping between their cognitive activity and the provided feedback.
2 Methods
2.1 Learning through interaction: a cognitive model of BCI Training
Neurofeedback , and more generally BCI interaction, can be understood as a distinctive form of
human–machine interaction characterized by a bidirectional learning process between two primary
agents: the subject and the experimenter. In this setting, the subject engages with an artificial
environment using modulations of their own neural activity, while the experimenter designs and
calibrates the environment’s responses to these neural signals. The efficacy of neurofeedback thus
depends on the internal models and assumptions held by both parties: the subject’s evolving
understanding of how to interact with the system, and the experimenter’s hypotheses about the
neural correlates of cognitive or behavioral traits.
The experimenter :When designing the feedback loop, the experimenter typically presumes
a relationship between measurable neurophysiological patterns and certain behavioral or cognitive
traits of interest—for instance, enhanced theta activity or decreased beta activity in individuals
with attentional deficits. Our framework introduces an intermediary conceptual construct—the
cognitive system—which serves to link observable behavior with measurable brain activity. Thus,
targeting a neural biomarker implicitly entails targeting a constellation of cognitive states that
can be externally inferred via behavior. For example, neurofeedback interventions for conditions
such as ADHD or insomnia often aim to modulate attentional processes [ACT+20, MMM16], un-
der the assumption that these are reflected in specific EEG signal features [MFBF+19, PCB+19].
This cognitive model allows us to decompose the neurofeedback interaction into two interrelated
components: (1) a biomarker hypothesis, which posits a mapping between cognitive states and
neurophysiological signals, and (2) a forward model, which describes how brain signals are pro-
cessed and transformed into feedback stimuli. In this light, the feedback presented to the subject
constitutes an inferred estimate of their ongoing cognitive state—for instance:"The feedback is
low, which means that your attention level is low".
The subject : In this environment, subjects have to perform two tasks simultaneously : a
perception task and a decision making task. First, they must make sense of the feedback ("The
feedback is low, what does it mean regarding my attention level ?"). Second, they must figure out
a mental strategy that allows them to increase the feedback or control its level voluntarily (How
can my actions change my cognitive state in order to perform well ?). Note that in this case,
6
the actions performed are mental actions (concentrate, perform mental imagery, recall a memory,
inner speech, etc.). To be able to better navigate this environment across training, subjects need to
learn the rules of the neurofeedback environment to perform more informed inferences. Our model
assumes that the subjects use the provided feedback to build an (approximate) internal representa-
tion of his/her environment and learn from an history of feedback observations and mental actions.
Note that the complexity of this representation need not match the full neurofeedback loop, but
it should allow them to navigate it as efficiently as possible. To be able to capture the effect of in-
trinsic factors within the NF subjects, like their prior knowledge of self-regulation, our model thus
explicitly describes how the beliefs of the subject about their cognitive states evolve across training.
To sum-up, we cast NF (and by extension BCI) training as a joint exercise of feedback percep-
tion and mental decision-making and learning for the subject. This exercise is particularly arduous
due to the numerous uncertainties surrounding the system (see 1) and to the numerous factors
affecting the training outlined above. Although the nature of the learning mechanisms leveraged
during neurofeedback/BCI training is still a matter of debate [EGHH17, VKC21], common ma-
chine learning paradigms have been proposed to account for such representation building. The
most notorious is probably that of model-free Reinforcment Learning [LPDH22], though we argue
that a more complex model-based approach grounded in the Active Inference framework provides
the basis for a broader family of subject representations that may be more applicable in the NF
context (e.g., explicit modeling of beliefs/uncertainty, handling partial observability, potential for
better generalization/transfer, explaining effect of instructions/priors). In the next section, we
introduce this framework and explain how it formalizes subject learning in BCI contexts.
For the remainder of this study, we separate an instance of neurofeedback training temporally
as follows : the whole training comprisesT specific trials (noted†∈ [ [1,T] ]) , which are themselves
made ofT timesteps. We notet∈[ [1,T] ]an individual timestep.
2.2 A quick introduction to Active Inference
The Active Inference Framework (AIF) [FFR+16, SSPF20] is a broad term that encompasses a
family of models able to perform perception, action and learning through the minimization of
a single cost function (namely the Variational Free Energy). It provides a biologically plausible
framework for modelling subject cognitive states dynamics in response to feedback. This section
provides a concise overview of AIF’s theoretical foundations and its applicability to representing
learning processes in NF and related BCI paradigms.
2.2.1 Theoretical foundations
Active Inference operationalizes the Bayesian brain hypothesis [KP04], which posits that the brain
constructs and maintains a generative model of its environment to predict incoming sensory data
and guide adaptive behaviour. This perspective suggests that maintaining homeostasis (i.e., re-
maining within viable physiological bounds) requires organisms to continuously minimize predic-
tion errors through updating their internal model and selecting appropriate actions. Perception
corresponds to updating beliefs about the current causes of sensory input (model inversion), while
learning involves refining the model parameters over longer timescales [SSPF20].
A key tenet of AIF is the distinction between the generative process—the actual, often unob-
servable, dynamics of the environment generating sensory data—and the agent’s internal generative
model—a probabilistic, approximate representation of this process (see Figure 2). The agent in-
teracts with the external world solely through its sensory inputs (observations) and motor outputs
(actions), which constitute the statistical boundary known as a Markov blanket. Consequently,
inferring the hidden states of the environment (s∗) based on observations (o) is fundamentally an
inference problem, constrained by the information available at this boundary. The brain must
entertain beliefs about the hidden causes of its sensations and update these beliefs in a Bayesian
manner. Selecting actions that either reduce uncertainty about the world (exploration) or lead
to preferred outcomes (exploitation) allows the agent to maintain accurate beliefs and ensure its
continued existence. The inherent limitations on computational resources necessitate a balance
between model accuracy and complexity, aligning with principles like Occam’s razor, which is
implicitly handled by the VFE minimization [MG05].
AIF formalizes the generative model as a joint probability distribution over observationso
and latent variablesθ, P(o,θ) = P(θ)P(o|θ) (Eq. ). Here θ encompasses hidden statess, model
7
Figure 2: Generative process and generative model : the subject’s brain models the neurofeedback
environment to predict outcomes and optimize its actions. Remarkably, BCI training casts cogni-
tive states as external "environment" variables and includes them in its generative model. It is thus
necessary to make a distinction between the hidden states themselves and how they are perceived
internally by the subject. The agent can only interact with its environment through boundary
states (its sensory and active states).
parameters, structure Mand hyper-parameters ξ [DCPS+20]. We assume that observations are
caused by those parameters following thelikelihood P(o|θ) . The subject initial belief about the
values of those states can be expressed asP(θ) = P(s,ξ, M) (the so-calledprior). To leverage this
model, an agent needs to perform inference over the model parameters by computing the posterior
distribution P(θ|o) statistical inference. In effect, it needs to answer the following question:Given
the current observable data, what would be the most likely causes in my model?. This is done using
the famous Bayes’ Theorem :
P(θ|o)
Posterior
=
Likelihood
P(o|θ)
Prior
P(θ)
P(o)
Evidence
(1)
However, calculating the normalization constant, the model evidenceP(o) =
∫
θ∈Θ P(o,θ)dθ=∫
θ∈Θ P(o|θ)P(θ)dθ (equation ) is typically computationally intractable for complex models due to
the high-dimensional integration involved.As an example of the previous assertion, let’s imagine,
for a fixed model structurem0 and a given set of hyper-parametersξ0, a set of 3 latent states
s1,2,3 with 10 possible values each (which is arguably a very simple environment). Such a state
space leads to a summation over 1000 values ofθ to compute an individual posteriorP(θi|o), and
therefore 1000 computations of likelihoodsP(o|θ). In practice, this vulnerability to the curse of di-
mensionality has led to a need to either shunt the calculation ofP(o) (as in Maximum-A-Posteriori
estimators) or approximateP(o) using methods like Monte-Carlo Sampling.
To circumvent this intractability, AIF employs Variational Inference (VI). VI reframes the in-
ference problem as an optimization problem by introducing an approximate posterior distribution
q(θ|χ) parametrized by variational parametersχ. The aim of variational inference is to minimize a
measure of distance between the true distributionP(θ|o) and our proposed approximation. Math-
ematically, we can define the optimal approximation as the function minimizing the KL-divergence
between P and q :
q∗= q(θ|χ∗) with χ∗= argmin
χ
DKL[q(θ|χ)||P(θ|o)]
8
= argmin
χ
∫
θ∈Θ
q(θ|χ) ln q(θ|χ)
p(θ|o) dθ (Continuous formulation)
= argmin
χ
∑
θ∈Θ
q(θ|χ) ln q(θ|χ)
p(θ|o) (Discrete formulation)
Where DKL is the Kullback-Leibler Divergence between two distributions. IfDKL[Q||P] = 0,
then Q= P and the inference problem is solved.Effectively, it means that the previous inference
problem, has been cast as a more ’classical’ optimization problem. [MSB21] Further transforma-
tions give :
DKL[q(θ|χ)||P(θ|o)]  
Error to minimize
= DKL[q(θ|χ)||P(θ,o)
P(o) ]
= DKL[q(θ|χ)||P(θ,o)] + Eq(θ|χ)[ln P(o)]
= DKL[q(θ||χ)||P(θ,o)]  
Variational Free Energy
+ ln P(o)
- Surprise
(2)
Wecanthusdefineaquantity F= DKL[q(θ|χ)||P(θ,o)] whichverifies F≥ DKL[q(θ|χ)||P(θ|o)].
Fis theVariational Free Energy, which creates an upper bound on the error between the true
posterior and the proposed approximation. The negative free energy term−F also provides a
lower bound on model (log) evidence (ELBO). Maximizing the ELBO / minimizing the variational
free energy would allow us to minimize "surprisal", which is defined as the negative log probability
of a given outcome−ln P(o) (not to be confused with psychological ’surprise’). Variational infer-
ence consists in minimizing Variational Free Energy (VFE) which mechanistically minimizes two
quantities: the difference between the true posterior distributionP(θ|o) and its approximationq
as well as surprisal, in effect maximizing model evidence. For the next steps, we assume a discrete
observation and latent state space.
F=
∑
θ∈Θ
q(θ|o,χ) ln q(θ|o,χ)
P(o,θ) = Eq(θ|χ)[ln q(θ|χ)
P(o,θ)] −ln P(o) (3)
By minimizing the free energy functional expressed in 3, agents thus build increasingly accurate
models of their environment.
Planning as inference:AIF extends this minimization principle to action selection. Agents
areassumedtoselectactions, orsequencesofactions(policies π), inordertominimizetheExpected
Free Energy (EFE) under a policy [SBPF21, FFR+17]. EFE quantifies the free energy expected
upon executing a particular policy, considering future potential observations and state transitions.
By rewriting the heavy notationq(θ|χ) to q(θ|π), we get [SBPF21] :
Fπ = DKL[q(θ|π)||P(θ|o,π)]  
Evidence bound
− ln P(o)
Log evidence
(4)
Planning in such a way naturally balances the expected utility of outcomes (reaching preferred
states, encoded in prior preferences over outcomes) and the expected information gain (reducing
uncertainty about the hidden states or model parameters) [PF19a]. Our implementation utilizes
an expansion of the original Active Inference planning scheme : the sophisticated inference scheme
[FDCH+20], whichperformsatreesearchoverpossiblefutureaction-outcomesequencestoevaluate
EFE and select the optimal policy, albeit potentially computationally intensive for long planning
horizons.
This unified formulation allows agents to build increasingly coherent internal generative models,
be it through inferring the hidden variables in the model, acting to resolve uncertainty about them
or learning the intrinsic dynamics of the system. In essence, AIF posits that perception, action
selection, and learning all emerge from a single imperative: minimizing free energy (VFE for
perception and learning, EFE for action selection). This happens accross three different steps: 1)
during inference, the most likely hidden states are guessed using knowledge about hidden state
evolution and observations. This is a very short-term mechanic, which is leveraged once per
timestep during sequential simulations. 2) After state inference, agents perform actions to pursue
desired outcomes [SSPF20] and resolve uncertainty. 3) Finally, the agent changes its general
9
model of the world. This evolution affects wider timescales by updating its representation of
general environment dynamics. Together, these three instrumental mechanisms provide a general
description of agent planning and behaviour during a single trial as well as accross a large number
of trials :
With θ= ( θst∈[0,T]

Belief about latent states
,
Agent actions / policy
 
θut∈[0,T−1] , θ α
Agent graph hyperparameters (see next section)
) :



θst = argmin
θst
F(θ,ot)
θut = argmin
θut
F(θ,ot)
θα = argmin
θα
T∑
t=0
F(θ,ot)
(5a)
(5b)
(5c)
With 5a the hidden state inference (computed every timestep), 5b the action selection (com-
puted every timestep) and 5c the environment dynamics learning (computed at the end of one
trial).
2.2.2 Discrete Active Inference : Variational Inference in a Markov Decision Process
To apply AIF to NF training, we model the subject-environment interaction using a discrete
Partially Observable Markov Decision Process (POMDP), as depicted in Figure 3. This formalism
allows us to explicitly differentiate between the true environmental dynamics (generative process)
and the subject’s internal representation (generative model).
The generative process defines the objective reality of the NF loop. It is formalized using a
Hidden Markov Model which explicitely describes the true latent cognitive state of the subjectˆst,
as well as the rules of the environment :
• The true distribution of initial statesP(ˆs0) parametrized by the upper-case vectorD.
• The true transitions between states influenced by subject actionsP( ˆst+1|ˆst,ut) parametrized
by the upper-case matrixB.
• The true mapping from these states to observable feedback (ot), P(ot|ˆst) parametrized by
the upper-case matrixA.
These components proposed a description of the subject brain activity and feedback design and
remained fixed throughout a simulation.
The generative model represents the subject’s subjective beliefs and understanding of the NF
environment. Contrarily to the generative process, the generative model uses categorical prob-
ability distribution to represent the current (belief) state, denoted using the bold-casest. The
generative model includes the following mappings :
• The subject’s beliefs about the initial state distribution,P(s0) parametrized by the lower-case
vector d.
• The subject’s beliefs about the state transition ruleP(st+1|st,ut) parametrized by the lower-
case matrixb.
• The subject’s beliefs about the observation mapping,P(ot|st) parametrized by the lower-case
matrix a.
• Thesubject’spriorpreferencestowardscertainobservations, P(ot) parametrizedbythelower-
case vectorc.
• The subject’s prior over actions, representing biaises towards recurring strategies ,P(ut)
parametrized by the lower-case vectore.
These matrices have initial values that encode subject prior beliefs about their environments (e.g.
before training, how do I think the feedback relates to my hidden cognitive state ?), but may
evolve significantly through learning across trials depending on observed outcomes (feedback levels,
performed actions). This representation allows the agent to maintain an easily interpretable model
of its environment, and a way to quantify how confident the agent is about the dynamics it models.
10
Figure 3: The Partially Observable Markov Decision Process (POMDP) used to model training.
The environment (generative) process figures a set of hidden states (ˆ st), corresponding to the
subject "actual" cognitive states in our formulation. Although impossible to see directly, each state
stochastically generates stimuli observable by the subject (ot) depending on a true observation
function A. It may consist in some external feedback or in an interoceptive observer the subject
must learn to interpret. Possible state transitions (B) and starting states (D) are fixed before
training. The subject generative model of the cognitive regulation is shown above, featuring a set
of perceived states (st). The subject models the feedback as a realization of hidden states with the
function a, and the effect of his/her mental actionsut on those states with the functionb. The
Active Inference agent uses this formulation to update their model on two distinct timescales by
minimizing their Free Energy following the equations described in [FDCH+20, DCPS+20]. On the
timestep timescale, it infers the hidden states that best match observations and prior beliefs, and
the actions that best match its habits/preferences/exploration drive. On the trial timescale, the
agent updates its beliefs about the environment dynamics (a,b,d) to better predict and navigate
it.
11
2.2.3 Mathematical Formalism
This section details the core mathematical equations governing perception, planning, and learning
within the AIF-POMDP framework. We assume the subject potentially perceives multiple obser-
vation modalities (m) arising from multiple hidden state factors (f). Vectorized parameters are
bolded. For simplicity, we omit factor/modality superscripts where unambiguous.
Emission mappings:(formally P(ot|st)).
For the generative process :
For t∈[ [0,T] ],ot ∼ A[ˆst] (6)
For the generative model :
Fort∈[ [0,T] ],P(ot|st,a) = Cat(aNst) (7)
Where aN is the normalizeda matrix to ensure it sums to 1 for each statest, ∼ is the sampling
operation and Cat is the categorical distribution.
Initial states and transitions:(formally P(s0) and P(st+1|st,ut)) :
For the generative process :
{ ˆs0 ∼ D
For t∈[ [0,T −1] ],u ∈[ [1,U] ], ˆst+1 ∼ Bu[ˆst]
(8a)
(8b)
For the generative model :
{ P(s0|d) = Cat(d)
For t∈[ [0,T −1] ],u ∈[ [1,U] ], P (st+1|st,ut,b) = Cat(bN[ut]st)
(9a)
(9b)
Where bN is the normalizedb matrix to ensure it sums to 1 for each state / action pairsst,ut.
Perception :Under the sophisticated inference scheme, the posterior belief update simplifies
to a combination of likelihood evidence and prior beliefs based on the previous state and action,
implementing a practical Bayesian filter :
st = σ(ln(aN ·ot) + ln(bN[ut]st−1)) (10)
Where σ is the softmax function and·is the inner product, meaning thataN ·ot = aT
Not.
Planning and decision-making :Active inference agents attempt to minimize theexpected
free energy [FFR+17] (EFE) of their model by performing actions that (a.) lead to preferred
outcomes (in our case, a high positive feedback level) and (b.) improve the agent knowledge about
its environment. The EFE can be seen as a sort of objective function when the agent plans its
next move. Sophisticated inference agents [FDCH+20] build a tree of future actions and outcomes
to plan their next actions. This planning scheme was chosen over traditional active inference
because it allowed for more flexible action selection without requiring predefined action sequences
(or policies). For each prospective timestepτ, an action - outcome branch(ot,ut) has the following
negative EFE :
G(uτ,oτ) = gu(su
τ+1,su
τ,ou
τ+1)  
EFE for the timestepτ+ 1
+ uo
τ+1.G(uτ+1,oτ+1)ou
τ+1  
EFE for the subsequent timesteps
(11)
gu(su
τ+1,su
τ,ou
τ+1) is the (negative) EFE estimator for the prospective timestepτ+1 (and only this
one !) if the expected state and observations after actionuτ and observationoτ are (su
τ+1,ou
τ+1)
and the previous posteriorsu
τ. In this study, we used the following (negative) EFE estimator :
gu(s,s−,o) = e[u]
Habits
+ o[lno + c]  
Risk
+ s.H
Ambiguity
− o ·Was 
Novelty-seeking
(emissions)
−s ·Wb[u]s−  
Novelty-seeking
(transitions)
H = −diag(a ·lna)
Wa = 1
2(a⊙−1 −a⊙−1
0 )
Wb = 1
2(b⊙−1 −b⊙−1
0 )
(12)
12
Where H is the entropy vector associated witha and Wa and Wb are novelty terms computed
every timestep pushing subjects towards prospects of yet unexplored state transitions or outcome
generation. X0 is the sum of all the Dirichlet counts for a parameter matrixX and X⊙−1 is the
element-wise inverse of all elements of matrixX.
This results in a counterfactual planning scheme in which the agents visualize every plausible
future action-outcome paths and seek the ones who maximize the feedback preference (risk term)
butalsoallow agentstoimprove theirknowledgeoftheenvironment (ambiguityandnoveltyseeking
terms). Finally, mental actions are picked through sampling the one resulting in the smallest EFE
:
ut ∼ σ(γG(ut,ot)) (13)
With γ the action selection inverse temperature, leading to more random action selection when
γ − →0 and deterministic action selection whenγ − →+∞.
The Expected Free Energy (EFE) estimator presented here can be modified to account for
agents who are less novelty-driven by removing the weightsWa or Wb or changing the prior
knowledge of the agents (accounting for prior instructions or beliefs about the dynamics of the
neurofeedback system).In practice, the tree search demonstrated was conducted for short temporal
horizons, which is not an issue as we assumed a gradual preference matrix for the subjects.
Learning: agents use Bayesian learning to update their representation of latent environment
variables a,b,d through a correlation-based incremental process. After a trial, a subject uses pre-
vious observations and inferences to update its model through Bayesian belief updating. Because
the latter is generally hard to compute (for dimensional-related reasons explained before), Active
Inference uses the Dirichlet distributions as the conjugate prior for the categorical distribution :



d†+1 = d†+ s†,0
b†+1 = b†+
T−1∑
t=0
s†,t+1 ⊗s†,t ⊗u†,t
a†+1 = a†+
T∑
t=0
o†,t ⊗s†,t
(14a)
(14b)
(14c)
Where ⊗is the outer tensor product and∀t,†, s†,t is the state posterior at timet computed during
trial †.
This means that the learned posterior is also a Dirichlet distribution, and computing the posterior
given new data is made very easy [KE]. In essence, the Active Inference agent counts specific
state/observations co-occurrences and increments the Dirichlet parameters of its model (thea,b,d
distributions) accordingly. This allows agents to learn flexible representations of their environment.
This learning mechanism operates on a slower timescale (trial-by-trial) compared to perception
and action selection (timestep-by-timestep). The duration of trials can influence initial exploration
patterns. Due to the accumulative nature of Dirichlet updates, prior beliefs become increasingly
entrenched with experience, potentially reducing flexibility in adapting to changes unless mech-
anisms such as parameter decay (’forgetting’) are introduced [HSP+21]. Importantly, effective
learning requires informative priors; agents with uninformative (e.g., flat) initial priors struggle to
build coherent models from observations [MKG22], underscoring the potential role of instructions
or prior experiences in facilitating BCI skill acquisition.
Numerous approaches [FFR+16, PF19b, FDCH+20, TSB20, DCPS+20, HSP+21, SSHL+20,
SFW21] have documented how Variational Free Energy and Expected Free Energy gradients are
computed with respect to subject model variables and parameters during state inference, action
inference and learning. In this section, we have provided a simplified account of the model updates
but we strongly encourage the interested reader to see the previously cited approaches for a more
complete explanation of the computations behind our simulations.
2.3 Neurofeedback training modeling with Active Inference
2.3.1 Models of training under uncertainty
Applying the AIF-POMDP framework allows us to formally model the subject’s experience and
learning trajectory during NF training, explicitly addressing the inherent uncertainties involved.
13
Neurofeedback training components Active Inference Component
The latent cognitive activity of the subject, driving the
feedback through a mapping with brain signals Hidden states vectorˆ s.
The subject perception of its own cognitive activity.In a
first order approximation, we consider that this perceptive
state has negligible influence on the biomarker.
Perceived states vectors.
Feedback provided to the subject Observation vectoro
Truerelationship between subject cognitive activity and
perceptible feedback. Affected by noise, biomarker hy-
pothesis, experimenter choices regarding pipeline design,
etc.
True perception matrixCat(A) = P(o|ˆs).
Perceivedrelationshipbetween subject cognitive activity
andperceivedfeedback. Affectedbyexperimenterinstruc-
tions regarding feedback meaning, belief about feedback
efficacy, blindness of patients regarding treatment, etc.
Perception modelCat(a) = P(o|s).
Truedynamics of cognition. Effect of subject mental ac-
tions and spontaneous evolution.
True transition/action matrix Cat(B) = P(ˆst+1|ˆst,ut)
(and initial statesCat(D) = P(ˆs0)).
Perceiveddynamics of cognition. Subject representation
of its own mental actions and ability (or inability) to con-
trol its own states. Affected by experimenter instructions
regarding mental strategies to control the feedback, pre-
vious knowledge, etc.
Transition model Cat(b) = P(st+1|st,ut) (and initial
states modelCat(d) = P(s0)).
Subjectendogenousdrivetowardshighperformances(cost
of effort, expectations behind treatment, motivation, fa-
tigue, etc.)
Preference matrixCat(c) = P(ot).
Subject bias towards a certain mental strategy Subject habitsCat(e) = P(ut).
Simulate control groups with various types of feedback
(sham, feedback of varying bias and noise) and partici-
pants
Subjects with varying priors (a,b,c,d and e) or experi-
ments with varying characteristics (A,B,D,etc.).
Report subjects training curves. Simulated agents cognitive statess and feedback levelso
reached across trials.
Table 1: Correspondence between traditional components of NeuroFeedback Training systems
(from [REGZ+20]) and the Active Inference generic components we use to simulate training.
Table 1 provides a direct mapping between conventional NF components, drawing from consensus
guidelines [REGZ+20], and the corresponding elements within our AIF model.
NF / BCI training is quite distinct from most behavioural paradigms usually explored with the
AIF Framework. One of the major distinction rests in the fact that the paradigm is affected by a
very significant amount of uncertainty. Two primary sources of uncertainty are central to the NF
learning challenge and are captured naturally within AIF: 1) thePerceptual Uncertainty: the
ambiguity regarding the relationship between the subject’s latent cognitive state and the observed
feedback signal. This is represented by the discrepancy between the true likelihood mapping (A)
and the subject’s learned model (a). Factors like signal noise, the choice of biomarker, and feedback
processing contribute toA whereas experimenter instructions and prior beliefs shape the initiala.
2) Control Uncertainty:Ambiguity regarding the topology of the relevant cognitive state space
and the effectiveness of specific mental actions in transitioning between states. This is represented
bythediscrepancybetweenthetruestatetransitiondynamics( B)andthesubjectlearntmodel( b).
We use the canonical Active Inference model components to describe subject experience during
amentaltrainingtask. Thisentailsdescribinghowthesubjectcognitiveactivityevolvesinresponse
to his / her perception of the feedback and, in a second time, how a subject may select a variety
of mental actions that affect it. We formalize the cognitive topology explored by the subjects as a
set of discrete latent statesˆ s. Not all states are modelled equal however! Some are more preferable
than others because they correlate with experimenter preferences regarding subject brain signals.
Because cognitive dynamics are driven by Bayesian dynamics in the Active Inference formulation,
the way beliefs evolve when confronted with new observations is heavily influenced by the quality
of initial priors and by the level of subjective uncertainty the subjects entertains. This idea is
central to the way we model neurofeedback and its therapeutic efficacy.Figure 4 provides a visual
14
(a) Inference during trials : The subject uses the feedback (right) to infer the true hidden mental
state st (marked with a star) given its model of the world (matricesafor perception andbfor transitions).
Planning then occurs when the subject infers his/her next action to get to specific hidden statesst+1 and
achieve prefered observations (see matrixC). Note that state inference and action selection are complex
processes accounting for various MDP dynamics and balancing information-seeking and reward-seeking
behaviour in an all encompassing (Expected) Free Energy minimization dynamic [SFW22].
(b) Learning between trials :On a slower timescale, the agent uses its belief about what the hidden
states were during the previous trialst∈[0,T] to update its model of the environment through correlations.
The history of the observations are used to update the perception modela and the history of its actions
u to update the transition model.
Figure 4: The Active Inference framework unifies agent perception, action and learning by itera-
tively minimizing these functions across different timescales.
representation describing how we employ the overarching Active Inference framework to elucidate
subjects’ perception, planning, and learning throughout various BCI training sessions.
Mental actions: The agent can change its current cognitive stateˆst by performing mental
actions ut. The agent may not initially know how its action will influence its mental states. Thus it
needs a transition model of its own mental actionsb = P(st+1|st,ut). In practice, we use a matrix
to keep track of this model. The true dynamics of cognitive regulations, writtenB = P(ˆst+1|ˆst,ut)
are unknown by the subject and must be inferred.
Perception: The agent is not able to directly observe what its current mental state is, but
15
must infer it. We represent this belief as a distribution over the current statess. To do that,
it needs to rely on external (feedback) or internal (meta-cognitive or interoceptive) observation
modalities. Again, the agent may not know the true mappingA = P(o(
t1),...,o (
tM)|ˆst) and tries
to approximate it by updating its own distributiona = P(o(
t1),...,o (
t1)|st). (here, 1,...,M are the
various observation modalities. In most BCI paradigms, 1 feedback modality is provided but there
are exception, notably multimodal feedback and interoception)
Thankfully, one does not need a perfect model of the feedback to derive evidence in order to
learn how to control it. Humans have been shown able to derive coherent ans structured models of
interactions from broad priors. However, in the precise case of non-invasive BCI interaction, the
low signal-to-noise ratio adds a layer of complexity to the already tough inference problem and
may explain poor subject performances. As is often the case in natural environments, the agent
generative model and the process it tries to mimic may end up differing wildly and lead to inaccu-
rate hidden state perception and sub-optimal actions. A subject model’s quality is not evalutated
on its ability to mirror the causes of its observations perfectly (which would be both incredibly
complex and computationally implausible), but on its capacity to support accurate predictions and
goal-directed control.
In considering this representation of the BCI training loop, one may pose the following ques-
tion: according to this formulation, what would be the mechanistic goal of NF / BCI training ?
This representation proposes several answers : First and foremost, learning within the model corre-
sponds to the agent progressively mapping its internal cognitive landscape and discovering effective
mental actions for navigation, while potentially refining its model of the proposed (BCI-induced)
feedback signal. Then, the reinforcement of action sequences leading to desired feedback results
in the formation of robust control strategies, analogous to habit formation. Finally, the standard
neurofeedback loop may be expanded to incorporate an interoceptive observation modality. Un-
der this formulation, the subject receives two types of sensory information at each timestep: the
explicit, externally provided feedback, and an internal, interoceptive signal. Crucially, learning
in this context involves not only interpreting the explicit feedback but also developing the abil-
ity to recognize and regulate internal bodily signals associated with successful control. This has
been cited as a potential enabler of BCI training and a key mechanism in ensuring post-training
homeostasis [Dav18].
2.3.2 Underlying hypotheses
Our Active Inference formulation of BCI cognitive training makes a few implicit modeling hy-
potheses. First, and most importantly, we dissociate subject perception of their own cognitive
state ("What I believe about my current attention level") and their actual cognitive state ("My cur-
rent attention level"). For example, in the case of attention training, we assume that the subject’s
cognitive attention level is distinctly regulated by an independent process during a neurofeedback
session. This assumes that the subject needs to make an inference on its current attention state by
using the feedback signal and potential internal sensations. Moreover, we assume that the feedback
signal is not directly affected by the subject regulatory process.
Second, it assumes the structure of cognitive state space of the regulated dimension as well
as how the subject represents it. To propose an accurate description of neurofeedback training,
we have to set a plausible space of cognitive states the agents may navigate to mimic training
exercises. Due to the uncertainty surrounding most mental training paradigms however, it is
necessarily an approximation. In this paper, we propose a very generic graph in order to showcase
the capacities of the leveraged framework in modelling different neurofeedback properties. We
discuss this modelling choice and its implications in the discussion.
Third, the tabular Active Inference formalism discretizes the feedback values, the topographies
of (true and perceived) cognitive states as well as the actions a subject may select. Although
continuous spectra may be more sensible representation for some of those model variables (feedback
or actions for instance), making use of Active Inference’s discrete formulation allows us to create
more complex cognitive graphs and interactions, while retaining computational tractability.
2.3.3 Neurofeedback Inference Problem and performance indicators
Within this framework, the agent’s task during each NF trial†∈ [ [1,T] ]can be cast as an inference
problem over the sequence of states, actions, and model parameters that best explain the observed
feedback under the agent’s generative model. Formally, the agent seeks to optimize its beliefs
16
Figure 5: Full model. The environment (generative process) forwards observations to the subject
as a discrete feedback value (hereot = 4) and reacts to subject actionsut ∼Πt. In our simulations,
the process state topography was a simple graph with 5 possible states and 5 possible ooutcomes.
Possible state transitions are showed with blue arrows (B) and starting state with red arrows (D).
Each state may generates outcomes based on the feedback mapping (A) following a normal law
N(µ,σprocess) (unbiaised noisy feedback). Initially, the agentbelieves each state is correlated with
a specific feedback level following a normal lawN(µ,σmodel) (unbiaised noisy feedback). Given
these priors, the agent attempts to learn state transitions and starting values (b and d) in order
to achieve higher feedback levels. This is done in 3 steps : the subject uses its priors to1. infer
the hidden states,2. pick the best actions (for exploratory or exploitative purposes) and finally
3. update its mapping from the observed succession of actions/observations.
about:
θ†
NF = ( θs
Hidden states
,
Policy selection

θu , θ α
Model parameters
)
= (θs0:T,θu0:T−1,θa,θb)
(NeuroFeedback Inference problem)
where θs0:T represents beliefs about the sequence of hidden states,θu0:T−1 represents the sequence
of actions (policy) chosen,θa (= a) represents beliefs about the observation likelihood mapping,
and θb (= b) represents beliefs about the state transition dynamics contingent on actions. Learning
corresponds to updatingθa and θb across trials. In this framework, if the generative model and
process sport the same state space dimensions, agent performance may be quantified in terms of
distances between true environment dynamics (A,B) and learnt environment mechanics (a,b).
We give more detailed accounts of this performance metric in the Annex.
3 Simulations
3.1 General Simulation Setup
To explore NF dynamics using this framework, we simulated AIF agents engaged in a task requiring
the regulation of a single cognitive dimension, represented by discrete latent statesˆs. The agents
17
received feedback signal(s)o and possessed prior preferencesc favoring higher feedback values.
The objective was to learn a sequence of mental actionsut to transition from initial, less preferred
states towards target states associated with higher feedback, potentially overcoming initially in-
accurate models of perception (a) and control (b). Figure 5 illustrates the general model structure.
Generative Process (Environment):
• State Space and Dynamics (B,D): The true latent state space consisted ofNs = 5
discrete states (ˆs∈{0,1,2,3,4}). Subject mental actions (e.g. performing mental imagery,
inner speech, memorizing task, etc.) provoked changes in subject mental states. In all
subsequent models, the agent could only move from a stateito the adjacent statesi−1 and
i+ 1, or remain in the current state. Transitions were probabilistic: a specific "up" action
could increase the state index (ˆs→ˆs+ 1) with probabilitypup = 0.99 (if ˆs <4), otherwise
remaining in the current state. Any other action, or the "up" action failing, resulted in
remaining in the current state. Additionally, a "cognitive pull" towards a baseline state was
implemented: if the agent did not successfully execute the "up" action, there was a probability
prest = 0.5 of transitioning to the next lower state (ˆs→ˆs−1, if ˆs >0). These values were
chosen to model a task requiring sustained effort against a baseline tendency. Agents initial
state was always in the bottom 2 states, encoded by the matrixD.
• Observations (Cat(A) = P(ot|ˆst)): The environment generated observationsot from a
set ofNo = 5 possible values (o∈{0,1,2,3,4}), based on the current (true) hidden mental
state. The primary observation modality was anexplicit feedback signal, whose likelihood
followed a discretized normal distribution centered on the true state indexˆst with standard
deviation σprocess : Afeedback ∼Discretize(N(ˆst,σprocess)) (we provide more information on
that discretization process in the annex). The value ofσprocess determined the feedback noise
level and typically varied between 0 (perfect feedback) and 2.0 (very noisy feedback). A
feedback noise of 5.0 could be considered as akin to a sham feedback signal (almost entirely
decorrelated from regulated cognitive activity). In some simulations (Section 3.2.4), a second
observation modality was proposed in the form of animplicit (interoceptive) observation
modality (Aintero). This signal also depended on the true state ˆst, following Aintero =
Discretize(N(ˆst,σintero
process)), providing a potentially independent source of information about
the latent state. The reliability of this observation source was also made to vary :σintero
process ∈
[0.0,2.0].
Generative Model (Agent):
• State Space and Preferences (d,c): The agent’s model assumed the same number of
states (Ns = 5 ) and observations (No = 5 ). Pre-training initial state beliefs d†=0 were
uniform. For thetransition Model (b), agents started with uninformed priors about the
effects of their actions. The initial transition modelb†=0 was initialized as a matrix where
each possible transition(st,ut) →st+1 had an equal, small probability mass, scaled by an
initial concentration parameterkb. Formally, the Dirichlet priors were set such thatb†=0 =
kb1 (where 1 represents a tensor of appropriate dimensions filled with ones).kb controlled
the agent’s initial confidence in this uniform prior; lower values imply faster learning from
experience. Throughout simulations,kb = 0.01 was used, reflecting low initial confidence and
a prompting an exploratory drive in synthetic subjects.
• Likelihood Model (Cat(a) = P(ot|st)): The agent’s model of the explicit feedback was
initialized based on an assumed relationship between hidden state and provided feedback.
This prior was typicallyafeedback ∼Discretize(N(st,σmodel)). The initial confidence in this
prior was controlled by a concentration parameterk1a. Specifically, the initial Dirichlet
counts were set via:
afeedback
†=0 = (k1a ·Discretize(N(st,σmodel)) + ϵ1) (15)
where ϵ is a small constant (e.g., 0.01) adding minimal uniform probability to prevent zero-
likelihood issues, andk1a scales the initial counts, determining resistance to updating this
prior. Higherk1a meansstrongerinitialbelief. Whentheinteroceptivemodalitywasincluded
(Section 3.2.4), agents started with an additional completely uniform prior regarding its
mapping: aintero
†=0 = k2a1, typically with a high concentration parameterk2a = 10.0, reflecting
high initial confidence about the uncertain meaning of this signal relative to the cognitive
18
state. This reflects an observation modality to which we’re accustomed but which mapping
with the targeted cognitive state has not been noticed until the training.
aintero
†=0 = k2a ·1 (16)
• Preferences and habits: Preferences c were set to favor higher feedback values linearly
(highest preference foro= 4, lowest foro= 0). Habitse were initially uniform and were not
learnt in these simulations.
Note that for simplicity’s sake and to allow for the direct comparison of true and learnt envi-
ronment rules,this study’s generative processes and models will always feature similar state space
sizes, though a mismatch between regulated state space and subject representation is an interesting
modelling prospect (see 5).
Key parameters manipulated across simulations are summarized in Table 2. Unless otherwise
specified, agents learn both transition (b) and likelihood (a) models over trials. Due to the stochas-
tic nature of the processes, N = 10 agent instances were simulated for each parameter set to ensure
robustness of conclusions.
Model parameters Parameters Used in simulations
M1 : Topography of
the hidden states of
the generative model /
process
One cognitive dimension. To get from a state to the next,
the agent must pick an action depending on its starting
state.
M1 was used in all sim-
ulations, but alterna-
tive topographies are
described in annex.
Variance of the feed-
back generative pro-
cess σprocess
Set the hidden rule behind the generation of a specific
feedback. How noisy compared to the true cognitive state
?
All.
Variance of the intero-
ceptive generative pro-
cess σintero
process
Set the hidden rule behind the generation of a specific in-
teroceptive signal. How noisy compared to the true cog-
nitive state ?
3.2.4.
Variance of the subject
generative model of the
feedback σmodel
Settheexpectationsofthesubjectregardingthereliability
of feedback when the training starts. 3.2.2,3.2.3 and 3.2.4.
Initialconfidenceofthe
subject in its action
model k1b
How much weight the agent gives to its initial action
model. The subject starts with a flat / noisy prior regard-
ing its mental actions. We set how confident the agent is
regarding this mapping with this factor. Higher values
mean the subject is much less prone to changing its tran-
sition beliefs and may require a longer training to achieve
results.
k1b = 0.01 in all simu-
lations .
Confidence of the sub-
ject in its feedback
model k1a / in its inte-
roceptive mappingk2a
How much weight the agent gives to its initial external
feedback model / internal observation modality. Higher
values mean the subject gives more credit to those prior
instructions / beliefs and is much less prone to chang-
ing its observation model despite contradicting evidence.
These parameter only had an influence when the simulated
agents learned observation mappings.
3.2.3 and 3.2.4 [feed-
back] 3.2.4[interocep-
tion].
Presence of an inte-
roceptive observation
modality (IO)
If agents were given an alternative observation signal to
complement the external (BCI based) feedback. 3.2.4.
Table 2: A general sum-up of the parameters we leverage in our simulations.
3.2 Tackling BCI questions with simulations
The AIF framework enables simulating diverse NF scenarios to address specific questions about
training mechanisms. We focused on the following key aspects:
19
3.2.1 How does the noise of the feedback affect the training ?
To isolate the impact of external feedback quality, we first simulated agents whose perception
model a was fixed throughout training and assumed perfect feedback fidelity. Specifically, agents
operated witha = INo, meaning they fully trusted the feedback as a direct readout of their state
(st = ot). Learning was restricted to the action modelb, simplifying the inference problem (Eq.
NeuroFeedback Inference problem) to updating onlyθb:
θ†
NF = (θs,θu,θα)
= (θs,θu,  θa, θ b
ACTION belief
) (Partial NF Inference problem)
Of course, that simplification did not imply anything concerning the true feedback matrix of the
generative processA. We varied the true noise level of the generative process feedback,σprocess,
across conditions representing:
• High-fidelity feedback (σprocess ≈0.1): True mapping A ≈INs. Agent’s assumption
holds true.
• Noisy feedback(σprocess = 0.5): A is informative but imperfect, representing typical BCI
variability.
• Sham feedback(σprocess = 5.0): A is nearly uniform, providing minimal information about
ˆst.
Training trajectories (states, feedback, learnedb) were analyzed to assess how objective feedback
noise affects learning when the agent assumes perfect feedback.
3.2.2 Influence of Initial Expectations about Feedback Quality
In a second time, we questionned how the agent’s initial belief about feedback reliability influenced
training, while still keeping the perception modela fixed (no learning ofθa). Unlike Section 3.2.1,
the fixeda was not necessarily identity but reflected varying levels of assumed noise, parameterized
byσmodel in the initial setupa ∼Discretize(N(st,σmodel)). We varied both the true feedback noise
σprocess (as before) and the agent’s fixed assumptionσmodel (from near-perfect ≈0.01 to very
unreliable = 2.5) to understand how congruence between reality and expectation affects mental
action learning (b).
3.2.3 Modelling changing subject confidence in the feedback
Wethenenabledagentstolearntheirperceptionmodel a alongsidetheiractionmodel b, addressing
the full inference problem (Eq. NeuroFeedback Inference problem). This simulation explored
how agents adapt their beliefs about feedback reliability based on experience. We examined the
interplay between: a) the true feedback noise (σprocess), b) the agent’s initial belief about this noise
(σmodel used in Eq. 15), and c) the agent’s initial confidence in this belief, set by the concentration
parameterk1a (varied from 1.0 to 10.0). This setup models situations where subjects might initially
trust or distrust experimenter instructions about feedback meaning and subsequently revise these
beliefs.
Training outcomes and the evolution of the learned perception modela were assessed. We
ran similar simulations as in section 3.2.2 with the true feedback noiseσprocess and the initial
subject feedback modelσmodel both varying between 0.01 and 2.0. and plotted the evolution of
the cognitive states / models of the subjects in order to investigate how initial beliefs (σmodel)
and confidence (k1a) interact with true feedback noise (σprocess) when agents can adapt their
perception model.
3.2.4 Simulating training with Interoceptive Learning
Finally, to investigate potential mechanisms for NF skill generalization (i.e., self-regulation without
external feedback), we introduced a second, implicit observation modality intended to represent
interoception (IO agents). These agents received both the standard external feedback (charac-
terized byσprocess, initial modelσmodel, confidencek1a) and an internal signal (characterized by
σintero
process and confidence k2a). In these simulations, we compared three typical interoceptive sig-
nals : highly informative (σintero
process = 0.0), highly uninformative (σintero
process = 2.0) and intermediate
(σintero
process = 0.9). Importantly, here the subject was much more accustomed to the latter source of
20
information (translating into a highk2a initial confidence parameter set to 10.0 in our simulations)
but had not related these internal observations to their current cognitive states (flat initial prior):
agents started with highly uncertain priors about the interoceptive mapping (aintero
†=0 uniform, Eq.
16) They were able to learn bothafeedback and aintero alongside b. We compared the performance
and learned models of IO agents versus agents receiving only external feedback, across various
levels of external feedback noise (σprocess) and initial beliefs (σmodel). The accuracy of the learned
interoceptive mapping aintero at the end of training was used as a proxy for the potential for
post-training generalization.
4 Results
The figures presented in this section and the simulations used to generate the results are available at
https://github.com/Erresthor/ActivPynference_Public/tree/main/paper_scripts/paper_
ActiveInference_BCI
4.1 How does the noise of the feedback affect the training ?
High-fidelity feedback :We first simulated a set of 10 artificial agents using a perfect feedback
to self-regulate. Figures 6b,6c,6d show a representation of one of these agents internal variables
during three trials (1, 5 and 15). The figures upper rows show observations (observed outcome
and sampled distribution), the middle rows show the hidden states (true hidden value and subject
inference) and the lower rows depict agent posterior over actions (how desirable a given action
appears to the subject) and selected action (in this case the action among the biggest action
posteriors). In all three trials, the agents were embedded with a perfect perception model, thus
making perception a trivial task and explaining the certainty with which the agents inferred their
hidden mental states given feedback. The subject used the initial trials to test actions and learn the
transition rules. By trial 15 however, the action model was informed enough to prompt exploitative
behaviour in the subject (always taking the shortest path towards the wanted state). A clear
explorative/exploitative shift is noticeable at the trial level. Figure 6e gives an account of the
same situation, but at the whole training scale. This time, the results of all 10 subjects are shown
and subject performances are quantified using a set of metrics (defined in Annex) to allow for better
readability. We plot the average feedback level and cognitive state achieved by the agents during
the last 15 trials of the training. We also plot the summed KL-divergence between their transition
and observation models, and their true counterparts. Again we notice the explorative/exploitative
shift around trial 10.
Unbiased but noisy feedback :Figure 7 shows how agent performances are affected by a
noisy feedback with no bias. This may describe various parts of the BCI pipeline, and especially the
biomarker used. Toquestionthe usefulness ofnoisy biomarkers, a noisierfeedback(σprocess = 0.5)
was provided to the subjects. As previously expected, higher levels of noise led to lower overall
feedback and cognitive levels and a final action model of poorer quality. Despite a rather low
amount of noise, performances at the end of the training were significantly affected and it prompted
us to simulate a wider range of biomarker noises.
Sham feedback :The agents who attempted to learn to regulate their hidden states using
sham feedback did not manage to improve their performances significantly. This comes as no sur-
prise as we did not implement any non specific mechanism that would explain successful regulation.
The associated figure is available in Annex.
Figure 8 shows the training efficacy fall-off depending on the noise of the selected biomarker.
Basing ourselves on the previous simulations, we plot the training of subjects with feedbacks of
varying qualities. We selected the true feedback noise randomly betweenσprocess = 0.01 (perfect
feedback) and σprocess = 2 .5 (sham feedback). For all data points, the subject expected the
feedback to be perfect (σmodel = 0.01) and did not update this belief during training. We plot the
average cognitive regulation achieved by the artificial subjects at the end of the training (avg. last
20 trials) and the quality of their model. As expected, a lower biomarker quality leads to worse
self-regulation performances. The efficacy of the training falls of dramatically forσprocess ≃0.5,
eventually rendering the whole training paradigm nearly useless aroundσprocess ≃1.5. This shows
that when navigating a complex environment with sparse feedback, the reliability of the signal
is primordial to achieve self-regulation. In the next section, we explore if this conclusion can be
somewhat mitigated by agent explicit modelling of the noise.
21
(a) True effect of mental actions.
(b) Trial 1.
 (c) Trial 5.
(d) Trial 15.
 (e) Training curves.
Figure 6: Simulated trials of 10 agents with a perfect model of a perfect feedback (a = A = I5)
but no initial model of mental actions. The true effect of those mental actions is shown in 6a (each
action has a different effect depending on the state of the agent (x-axis), and leads the subject
to another state (y-axis). We represent artificial agent behaviour and learning across trials. We
show how individual trials are conducted (6b, 6c, 6d), with the observations (first row), subject
mental states (second row) and action taken (third row). The colored dots represent the true
(observed/hidden/selected)valuesandtheblack-and-whitebackgroundrepresentsthedistributions
from which they were sampled (top/bottom row) and the subject infered current cognitive state
(middle row). We also plot the subject transition model during the trial to explain why it may have
picked some actions rather than others. Because this representation doesn’t easily qualify several
subjects accross 100+ trials, we also displayed training curves of the subjects (6e). It consists
in the evolution of their average feedback level, mental state, as well as transition and feedback
model error accross trials. The subjects were initially very uncertain about which action to take
in the initial trials, but their perception was always certain and the subjects knew exactly what
were their cognitive state at any point. Because the action model of the subject started off too
incomplete, the agent first engaged in explorative behaviour to gather informations and improve
its model. It quickly made sense of the available data and built a good model of its mental actions.
By trial 10, the model of the agent is good enough that it only focuses on achieving high feedback
levels. 22
(a) Trial 1.
 (b) Trial 5.
(c) Trial 15.
 (d) Training curves.
Figure 7: Simulated trials of 10 agents with a naive model (σmodel = 0.01) and a noisy feedback
(σmodel = 0.5). In contrast to figure 6, observations were sampled from a noiser distribution and
created mismatches between subject inferences and true mental states (7b), thus leading to lower
learnt transition model quality and regulation performances.
23
Figure 8: Subject performance metrics at the end of the training for various levels of biomarker
noise. We plot the average mental state achieved during the last 15 trials of the (100 trials)
training [left] as well as the error of the transition model learnt by the subjects at the end of the
training [right]. Each point corresponds to the a single agent which believed that the feedback
was perfect (a = I5) but was provided with a true feedback noiseσprocess ∈[0.0,2.5] (x-axis). The
noise associated with the chosen biomarker has a huge influence on agent performance and training
efficacy, and subject ability to learn from the feedback fall off dramatically after a certain threshold
(≃0.3)
24
(a) Trial 1.
 (b) Trial 5.
(c) Trial 15.
 (d) Training curves.
Figure 9: Simulated trials of 10 agents with a cautious model (σmodel = 0.5) and a perfect feedback
(σmodel = 0.01). Here, subjects explicitly doubted the meaning of a specific feedback value, assum-
ing that it could have been generated by a range of cognitive states (driven byσmodel). Although
the subjects were overly cautious about the feedback, they still managed to self-regulate optimally.
4.2 Influence of Initial Expectations about Feedback Quality
We provided artificial subjects with a diversity of feedback noises. In contrast with previous
simulations, agents were cautious about the indication of this feedback. This meant that subject
perception of their cognitive state was not a trivial endeavour. Figure 9 shows the main difference
with simulations of section 4.1 : the subjects beliefs about their mental state became much more
uncertain, leading to less radical mental action learning. Indeed, the subjects uncertainty regarding
the explicit feedback reflected on what they were able to learn from it : if they doubted it too much,
it proved very difficult to develop an accurate model of interaction with the feedback. Despite that
fact, a reasonable amount of caution towards the feedback did not lead to significant impairment
regarding self-regulation for a perfect feedback. 9d.
In fact, cautious subjects (σmodel = 0.5) performed better than naive subjects (σmodel = 0.01)
when the feedback stood in the criticalσprocess ≃0.5 range 11. As one would expect, subjects who
have a better understanding of the feedback tend to limit overfitting from noisy observations and
build a better model of their mental actions.
We generalized those findings to a wider set of true feedback noise / subject feedback noise
expectations combinations to figure out which set of subject initial expectations would favor learn-
ing from even noisy feedback. Figure 12a shows performance metrics for 20 x 20 groups of 10
agents. Each group trained used a specific(σprocess,σmodel) set of parameters. We show the final
average mental state (last 15 trials), feedback model error and action model error for each of these
groups. As expected, good learning only occurs when the feedback quality is good enough, and
when the subjects actually believed that the feedback contained some useful information about
25
(a) Trial 1.
 (b) Trial 15.
(c) Trial 150.
 (d) Training curves.
Figure 10: Simulated trials of 10 agents with a cautious model (σmodel = 0.5) and a noisy feedback
(σmodel = 0.5). Here, subjectsexplicitly doubted themeaning ofa specificfeedback value, assuming
that it could have been generated by a range of cognitive states (driven byσmodel). The explicit
modellingofthenoiseinherenttothesystemallowedsubjecttoeventuallyself-regulatemuchbetter
than when they believed the feedback was perfect (7), underlining the importance of subject priors
(and experimenter instructions) in a noisy context.
26
Figure 11: Compared training curves of two groups of 10 agents provided with a noisy feedback
(σprocess = 0.5). The "naive" group (blue) expected the feedback to be perfect (σmodel = 0.01),
whereas the "cautious" group had less optimistic expectations (σmodel = 0.5), much closer to the
truth. Due to being less sensible to noisy observations, the cautious group was less prone to model
overfitting and eventually, albeit less quickly, developed a better understanding of their mental
actions.
27
(a) Agent performance map for a given expected feedback noise (x-axis) and true feedback noise (y-axis).
(b) Optimal subject internal belief depending on feedback noise.
Figure 12: Simulated trials for 20x20 groups of 10 agents. Each group trained used a specific
(σprocess,σmodel) ∈ [0.01,2.0] ∗[0.01,2.0] set of parameters.12a shows the final average mental
state (last 15 trials) and action model error (defined as the KL divergence between subject model
b and the true mental transitionsB) for each of these groups. Figure 12b focuses on a few specific
true feedback noise values and shows which subject prior model parameters lead to good regulation
results. This simulation yields expected results (the training can only be useful if the feedback isn’t
too noisy, if the subjects trust the feedback somewhat, etc.), and less instinctive ones (subjects
with some degree of cautionσmodel ≃0.5 learn better than naive ones whatever the actual level of
feedback noise).
28
their mental activity. More surprisingly, having a perfect model of the true feedback (i.e. knowing
exactly the mapping from one’s mental state to the observed feedback) did not always result in
better mental action models. Finally, it appears that finding the optimal subject expectations
with regard to the quality of the chosen biomarker is a balancing act. In the simple simulations
we conducted, the optimal subject expectations parameter evolved dynamically with the quality of
the feedback 12b. However, for small biomarker noises (σprocess ∈[0.3,1.0]), σmodel ≃0.5 yielded
the best training results, suggesting that when the feedback provided is reasonably noisy, cautious
priors lead to better learning efficiency. The cautious subjects also performed well under perfect
feedback, suggesting that under our approximations, a small degree of flexibility in the subject
feedback perception led to overall better learning.
4.3 Modelling changing subject confidence in the feedback
Previous simulations have shown how the noise affecting the biomarker affected the training of
a subject depending on its expectations. However, they also assumed that those expectations
were fixed and did not change accross the training. We believe this oversimplification glosses
over one of the major mechanics of BCI training : the subject changing level of confidence about
the reliability of the provided feedback accross the trials. The next simulations featured the
same model as previous sections (3.2.1 and 3.2.2) with an important distinction : the subjects
dynamically changed their observation mapping (relating cognitive state and observation), thus
accounting for BCI training-specific dual perception-action uncertainty.
We show the results of these simulations in figure 13. First, we simulated very typical training
setups, namely a cautious subject provided with a perfect feedback 13a, a naive subject provided
with a noisy feedback 13b and a cautious subject provided with a noisy feedback 13c. In an
effort to reduce their Free Energy, the agents updated their models of the feedback (bottom right
plots). Because the agents learnt action and perception models simultaneously, those learning
trajectories affected one another dynamically. In general, this manifested as a deterioration of
the feedback model while the action model improved. Once the mental action topography was
sufficiently explored, the models of the agents converged towards local free-energy minima.Figure
13d generalizes these remarks to a wider range of true feedback / subject expectation parameters.
Finally, we wanted to know if questioning the quality of the feedback provided negatively
impacted BCI training subjects. We compared the performances of these feedback-learning agents
to the results showed in 12a (fixed feedback mappings). Our simulations (13e) showed that the
impact actually varied based on the subject’s initial model : when the subject’s model initially
closelyalignedwiththetruefeedbackprocess, continuouslylearningthefeedbacktendedtohurtthe
performances of the training? In turn, for subjects with feedback mappings significantly divergent
from the ground truth (such as naive or overly cautious subjects), learning the feedback resulted in
better action mappings, displaying some kind of ’protection mechanism’ preventing subjects from
learning damaging mental actions.
4.4 Simulating training with Interoceptive Learning
We ran simulations where agents were provided with an additional (interoceptive) observation
modality. Simulated subjects internal signals were either informative (lowσintero
model) or uninformative
(high σintero
process). Figure 14 shows the performance maps of agents with various degrees of internal
observation abilities. Overall, agents equipped with an internal observation modality outperformed
agents relying on the external feedback only. Particularly noteworthy is the superior performance
of subjects with precise internal signals, as depicted in Figure 14b, where they demonstrated the
ability to decipher high-noise feedback. This suggests that the substantial decline in training
efficiency, as evident in the alarming drop shown in Figure 8, might be alleviated by leveraging
this alternative observation pathway. Importantly, the efficacy of this supplementary observation
route is contingent upon the quality of the interoceptive pathway.
5 Discussion
The aim of this paper was two-fold : first, showing how the cognitive system of the subject
could help describe the complex regulation mechanisms at work during Neurofeedback Training.
Second, demonstrating how the Active Inference framework could provide a pertinent set of tools to
computationally model training and contribute to BCI research by testing computationally various
hypotheses and the effect of possible instructions.
29
(a) σprocess = 0.01,σmodel = 0.5
 (b) σprocess = 0.5,σmodel = 0.01
 (c) σprocess = 0.5,σmodel = 0.5
(d) Agent performance map for a given expected
feedback noise (x-axis) and true feedback noise (y-
axis).
(e) Final mental state and action model error differ-
ences between 12a and 13d. Blue values means con-
tinuously updating your feedback belief led to better
performances.
(f) Optimal subject internal belief depending on feedback noise. Simultaneously learning action and feed-
back mapping leads to lower performances,higher within-group variance and the absence of the optimal
subject caution prior noticeable in 12b.
Figure 13: Simulated trials of agents which updated their model of the feedback and their action
model simultaneously. The agents trusted their feedback priors (k1a = 10 .0) and dynamically
updated their feedback model. We show the training curves for some typical cases (agent confidence
/ feedback quality mismatches) in 13a,13b,13c. We generalize these results to(σprocess,σmodel) ∈
[0.01,2.0]∗[0.01,2.0] in13d. Agentsupdatingtheirfeedbackmodelledtooveralllowerperformances
compared to 12. Our model suggests that for lower values ofk1a, it was easier for subjects to doubt
the reliability of the feedback signal rather than learning complex mental actions.
30
(a) No interoceptive observation modality.
 (b) σintero ≃ 0.0
(c) σintero ≃ 0.9
 (d) σintero ≃ 2.0
Figure 14: Simulated training results for four groups of agents. Agents of group 1 14a had no
interoception (just like in figure 13d). Agents of groups 2,3,4 (14b,14c,14d) were all equipped with
an interoceptive observation modality characterized by a specific noise (σintero ≃0.0,σintero ≃0.9
and σintero ≃2.0 respectively). Each group was subdivided in 20 x 20 subgroups of 10 agents, each
using a specific(σprocess,σmodel) set of parameters. The figures show the final average mental state
(last 15 trials), learnt action model error and learnt interoceptive model error for each subgroup
of agents.
5.1 Cognitive regulation at the heart of Neurofeedback learning
In usual neurofeedback mechanism accounts, brain activation has long been considered as the inde-
pendent variable, with cognition and behaviour being dependent variables [SRS+17]. We suggest
an alternative framing approach based on subject cognitive control of the feedback. In such a
formulation, the subject guides the dynamics of the training through perception, mental actions
and learning. In this formulation, brain activity is partially predicted by cognitive dynamics, in
turn dependent on high level perception, planning and learning. Note that these processes need
not beconscious for the subject. In over words, our model thus does not extend explicitly to the
physiological dimension of subjects’ brains, but focuses on the cognitive states they are coupled
with. Of course, the assumed link between the modeled cognitive states and the actual measured
biomarkers remains a critical (and often weak) point in practice, reinforcing the importance of
biomarker selection and proper reporting [REGZ+20].
Ability to generalize :Training success or failure is a difficult concept to formalize clearly,
mainly because the appreciation of a successful training varies heavily depending on the paradigm.
Moreover, the ability of subjects to transfer the knowledge gathered from training into situations
outside of the training environment is crucial for the success of BCI / neurofeedback training,
especially in therapeutic approaches. On the one hand, a general argument can be made that
BCI training is in essence a cognitive exercise aiming to provide the subjects with a way to learn
adequate mental strategies. Following this argument, an untrained subject lacks a cognitive model
accurate enough to navigate its (mental) environment easily. This may lead to observable be-
havioural afflictions, or the inability to control an external device, etc. Training would allow
subjects to build an accurate model of perception and action, making them able to control their
cognition more willingly, or build reliable internal observers (metacognition). Thus, training suc-
cessfully would be synonym to building a good internal model. Following our Active Inference
formulation, this would mean that a successful training would minimize the difference between
the true environment dynamicsA, B and the modeled dynamicsa,b in the targeted cognitive
dimension.
Another prevalent hypothesis postulates the learning of an alternative, internal observation
modality : other modeling approaches such as [Dav18] have already theorized the emergence of
an interoceptive observation pathway during training and discussed their ability to reinforce an
ongoing training and then be used as the only reinforcer after training. Our model show this
reinforcing effect during training (see simulation 4.4), and underlines the importance of this "gut-
feeling" as it would render the training useless to the subject when cut from the external feedback.
31
In the initial simulations, we greatly simplified the nature of subject experience during training.
Indeed, we assumed that the only way for the subject to infer their cognitive activity was to use
an external (BCI-equipped) observation pipeline. Although this representation may suffice when
the end-goal of training is learning how to use an external device, it falls short when tackling
neurofeedback generalization problems : when deprived of the external feedback, how would the
subject perform self-regulation ? We believe that empirical problem is solved through learning an
internal observation modality. We modeled this interoceptive pathway as an independent obser-
vation modality, similar to the external feedback, but other representations, such as hierarchical
models [HSP+21, SSHL+20], may provide promising alternatives.
Tool learning & illiteracy :Although the task the synthetic agents were given would have
been trivial if the subjects knew all the dynamics of the environment (What is the effect of my
actions on my mental states ?and How does a given mental state translate to a feedback level ?),
it proved much harder when they were facing uncertainty from one (or both) modalities. Learning
to interact with a new tool requires the user to build a comprehensive model of observations
and actions. During BCI interaction this is particularly difficult, because subjects beliefs about
observation and action modalities lack the prior evidence needed to dissipate this uncertainty. To
learneffectively, thesubjectneedstobequiteconfidentinpartofitsmodel, inordertoprogressively
design better and better interaction models. Our simulations have shown that high amount of
uncertainties in the subject model led to poor training performances, even in the advent of a
precise feedback. This is true in every environment (indeed, in the Active Inference literature, most
approaches focus on learning either observation matrices given known action matrices [FFR+16,
SFW21, TSB20] or the contrary.) In our approach however, because neurofeedback and other
BCI-based applications rely on a much more uncertain set of dynamics, the model we propose will
feature various levels of uncertainty in both agent perception and action beliefs. The complexity
of the inference problem and its dependence to subject initial priors is a first explanation for high
inter-subject heterogeneity.
Finally, our simulations suggest that in some cases, it may be easier for the subject to explain their
own poor training performances by questioning the reliability of the feedback provided (regardless
of its actual intrinsic quality), rather than their own failure to figure out the adequate transition
rules. Simulated agents who continuously updated their confidence in the feedback performed
worse than their more naive counterparts when the feedback reliability was high and matched
their initial beliefs, but better when the feedback was of poorer quality. It remains to be seen
wether such fine training effects may be captured using the data from usual BCIT tasks.
5.2 Modeling BCI training
The Active Inference framework proves particularly suitable for modelling Brain-Computer Inter-
face (BCI) training for several reasons:
• It accommodates subject-specific internal parameters and learning environment criteria ef-
fectively.
• It encompasses both action, perception and learning, essential components of BCI training
dynamics.
• Its versatility enables the modelling of various types of training loops and subject models
within a unified framework. The generic nature of the model described in the paper means
that the framework accounts for the great diversity in BCI training protocols (biomarkers,
feedback design, trained cognitive dimension).
• Possible extensions of the model offers scalability and hierarchical structuring, accommodat-
ing the complexity of BCI training scenarios. [FRP+17, PRF18]
• The framework reflects various timescales, encompassing quick processes such as state infer-
ence and decision making, and slower ones like learning.
By leveraging Active Inference, it becomes possible to conceptualize subject behaviour during
BCI training as akin to navigating through an uncertain environment. Crucially, this formalism
incorporates numerous initial and hyper-parameters, empowering modelers to replicate the reality
of BCI training. Manipulating these parameters enables the exploration of the potential limitations
of specific training protocols and their effects on agent behaviour. Of particular significance are the
biomarker reliability (including bias and noise) underlying the feedback and the priors within the
32
subject model (representing the subject’s initial beliefs about the system at the onset of training).
Our basic simulations demonstrate that a perfectly designed feedback mechanism alone does not
ensure successful training. Consequently, we can establish links between fundamental elements of
the BCI training protocol [REGZ+20] and information theory-based variables to investigate learn-
ing efficacy. The broad applicability of the Active Inference framework presents both advantages
and challenges. On one hand, its generic nature allows for the modeling of a diverse array of
situations using the same set of tools. On the other hand, this versatility necessitates a wide range
of parameters, making the model difficult to test and ultimately challenging to fit. To restrict the
space of simulated parameters, we imposed constraints on the initial values of these parameters.
Specifically, we:
• Assumed the true topography of the mental states of the subject and their representation
in the subject model. We also chose to limit state transitions to neighboring mental states
in order to describe a continuous process. Finally, we used spontaneous state-transitions
towards lower states to mirror a mental resting state.
• Modeled the Feedback / biomarker as noisy, but unbiaised, in effect refraining from delving
into the expansive model space of specific biomarker biaises, as their effects may prove trivial
and difficult to thoroughly examine. We also described the subject initial feedback priors
noisy but unbiaised for the same reason.
Explaining BCI training variability :In our study, one of the primary objectives was to
elucidate the inter-subject differences observed in certain studies, where some participants suc-
ceeded in regulating their brain activity while others did not, leading to what has been termed
"BCI illiteracy". Within our formalism, these individual differences can be attributed to several
factors. Firstly, within a single group of agents with similar internal parameters, the stochas-
tic nature of the biomarker noise, and the decision-making process of our agents may introduce
randomness, particularly when multiple actions exhibit similar perceived value. As a result, simu-
lating the behaviour of a single agent with specific characteristics did not suffice, necessitating the
examination of mean performance indicators across multiple agents with similar initial properties
to draw meaningful conclusions.
Our proposed formalization underscores the structural sources of uncertainty inherent in generic
BCI training paradigms, emphasizing the complexity of the training task due to high uncertainty
in both perception and action domains. Typically, when faced with uncertainty regarding a set
of dynamics, strong priors in other dimensions can facilitate the interpolation and construction
of a coherent model of the uncertain dimension. However, in many BCI applications, including
neurofeedback, agents often start with uncertain priors in both perception and action, making
it challenging to establish the relationship between feedback and cognitive states. This dual un-
certainty offers a plausible mechanistic explanation for the variability observed in neurofeedback
efficacy studies.
Furthermore, discrepancies in initial parameters can contribute to group effects in the outcome
of the training process, with variations stemming from factors such as motivation, habits, and prior
knowledge. Our model allows researchers to shed light on the impact of these group differences by
considering alternative preference matrices, action habits, and prior models.
Nevertheless, our simulations demonstrate that under appropriate conditions, the challenges
posed by this uncertainty may be addressed, and successful model learning and system navigation
may be achieved even with imperfect priors. Simulated trainings with the additionnal interoceptive
observer proved much more succesful. Agents equipped with this additionnal observatory pathway
required less demanding priors qualities to achieve satisfactory outcomes.
5.3 What lessons for BCI experimenters ?
Our basic simulations have underlined the general dynamics of some parameters of neurofeedback
training. First, we showed the importance of the reliability of the biomarker used : the threshold
noise above which the subjects became unable to self-regulate was especially low with a brutal
fall-off. This indicated that neurofeedback training paradigms based on nonspecific biomarkers
may face tough odds. In general, the ability of the subjects to make sense of the feedback was
directly related to how discriminant it was, i.e. how different two distinct mental states manifested
themselves in the feedback.
The priors of the subjects regarding the feedback and their mental strategy played a particu-
larly important role in our simulations. Although these priors may depend on subject/population-
specific parameters, they are heavily influenced by experimenter instructions. In general, a normal-
ization and clarification of the instructions given to the subjects has long been called for [REGZ+20]
33
and constitutes an important first step to (1.) simplify the patient task, (2.) allow for better re-
productibility, (3.) better explain the outcome of training. A more well-defined set of training
parameters may also be used to better understand the causes of training failure and hopefully,
solve them. More precisely though, basic simulations showed that :
• Feedback :In general, agents benefited from a limited amount of prior caution regarding the
feedback, i.e. not being too naive about its accuracy. Doubting the feedback (4.3) acted as a
protection mechanism in very poor conditions (i.e. when subject priors were significantly off
or when feedback noise was significantly high) to avoid learning flawed correlations. However,
it also hurt the performances of subjects with as initially adequate feedback perception,
suggesting that experimenters should honestly communicate about the reliability of their
NFT paradigms, though the nature of this communications remains vague.
• Mental strategies: In our simulations, we deliberately restricted the number of available
mental actions to facilitate learning within a feasible timeframe. Prompting agents to explore
a specific subset of their mental actions (through low initial action mapping confidence) was
crucial for initiating the necessary process of exploration and learning. This suggests that
pushing subjects to try out specific mental strategies at the start of the training is particularly
important, and may prevent training if overlooked. This is a debated issue in the litterature,
with some arguing that providing a clear set of strategies and showing examples may promote
the learning of the BCI skill [LLM13], while others warn against vague instructions that may
be incongruent to the desired outcome [EJSV16].
• Interoception :We described subjects ability to perceive their own mental states without
the feedback as an independent internal observation modality . More than just an reinforcing
mechanism during training, we argue it is actually a necessary pathway to allow subjects to
use the knowledge acquired during neurofeedback training once deprived of the external
feedback. To favor learning thisgut intuition, the experimenter instructions should drive the
subjects towards attending internal signals. More generally, this interoceptive observation
pathway has been cited as a prime candidate for post-training effect retention, by allowing
homeostasis [Dav18].
5.4 Modeling limits
Although our models of BCI interaction are, necessarily, greatly simplified, a few limitations are
worthy of a mention, both within and beyond the perimeter of our approach :
• Physiological activity of the subject : Brain Activity regulation has been at the center of
Neurofeedback training, with some studies assessing the success of their training based on
the degree physiological regulation (while sometimes forgetting to check its effect on subject
behaviour). Some pre-existing modeling approaches have explicitly described its evolution
through regulation. We chose to render the dimension implicit by providing a direct function
mapping cognition and feedback. Simulating the NF subject physiology is a necessary next
step for our model to be deployed and used in actual BCI practice.
• Subject observable behaviour during and after training : Although cognitive actions directly
related to the feedback are modelled, observable behaviour is not simulated. Of course, this
is a major limit of our approach as it prevents us from comparing the results of regulation
and behaviour (the usual end goal of neurofeedback training).
• The temporal dynamics of the feedback training loop : Previous neurofeedback modeling ap-
proaches have tackled the influence of temporal factors such as delays or continuous feedback
on training [OLPS17] . However, due to the sequential nature of our framework, it may not
be fit to explore the effect of feedback temporality on human perception on its own.
• Subject behaviour outside of the training environment. This thematic is particularly im-
portant when talking about therapeutic neurofeedback. The effect of NFT on the subjects
outside of the training sessions proper is not simulated directly : we can only make simpli-
fying assumptions regarding the relationship between agents models after training (learning,
habits, etc.) and their performances in other situations. This would most likely be linked to
concepts such as transfer learning that we don’t consider here.
34
Those limits prevent us from accounting for some dimensions of the training. Additionally, some
hypotheses have been made regarding the properties of the subject generative model and cognitive
states. Those hypotheses are summed-up in section 2.2 and tend to make (reasonable) assumptions
on perception and action selection rules during neurofeedback.
5.5 Next leads
The work presented here paves the way for three main developmental axes.
First, Active Inference models are good candidates to be used in (Bayesian) parameter esti-
mation methods [JJ00]. This would allow researchers to use experimental training data to figure
out the most likely subject / training pipeline characteristics to explain their results. Beyond
better result interpretation, proven training models may be used as the basis for training outcome
predictors or adaptive training protocols.
Second, equipping the model with a neurophysiological component in order to explicitly feature
the biomarker used during training would allow us toclose the loopand propose a more complete
approximation of the coupling between cognition and physiology in the brain. This may eventually
allow us to confront alternative models to experimental results in order to more closely fit subject
internal models as they interact with the BCI. Although tricky, this could be achieved by using
the predicted synthetic physiological responses generated during belief update [FFR+16]. Alter-
natively, adapting compatible methods used in signal classification such as deep autoregressive
Hierarchical Markov Model [WAMH18] may prove interesting.
Third, possible extensions of the current (cognitive) model to specific cognitive dynamics such
as attention may prove instrumental to study the influence of (meta-)cognitive dimensions such
as attention. Active Inference based approaches such as [HSP+21, SSHL+20] have already tack-
led the question of attention and valence in the Active Inference framework, and models of self-
regulation using this set of models may yield more specific training curves for neurofeedback train-
ing paradigms targetting ADHD.
6 Concluding remarks
This paper seeks to contribute to the neurofeedback efficacy debate by proposing a new model-
ing angle, namely the cognitive system of the subject. Importantly, our study makes the brain
activity of the subject implicit. We propose a generic family of models to characterize most brain-
computer interface training paradigms as complex inference problems that subjects must solve
through perception, action and learning despite uncertain priors and feedback. This formulation
allows researchers to explicitly model the effect of key variables such as the prior confidence of the
subjects, the influence of experimenter instructions, the quality of the feedback or the motivation
of the subjects, where previous physiology-based modeling approaches struggled.
We utilize the Active Inference framework to simulate the behavior of biologically plausible
artificial agents tasked with solving our proposed problems. This endeavor enables experimentation
on thousands of synthetic subjects, allowing us to estimate the outcomes of basic experimental
protocols without relying on time-consuming and often underpowered studies.
The predictions derived from these minimal models were used to provide a first quantitative
account of the influence of biomarker noise, subject expectations and learning mechanisms in neuro-
feedback training. Finally, this mechanistic account of subject experience suggests that developing
a precise interoceptive signal not only makes the training easier but may also be essential in order
to generalize the effect of neurofeedback training to everyday life environments.
7 Acknowledgements
The authors thank L. Da Costa for the insightful discussions.
8 Competing interests
The authors declare no competing interests.
35
9 Ressources
Computations of the Active Inference agents were made on a custom Python implementation
of the SPM12 toolbox MatlabMDP_VB_X.m and MDP_VB_XX.m scripts (available at
https://www.fil.ion.ucl.ac.uk/spm/) with minimal changes. The custom package used is
publicly available at url:https://github.com/Erresthor/ActivPynference_Public.
References
[AARST18] O. Alkoby, A. Abu-Rmileh, O. Shriki, and D. Todder. Can we predict who will
respond to neurofeedback? a review of the inefficacy problem and existing pre-
dictors for successful eeg neurofeedback learning. Neuroscience, 378:155–164, 5
2018.
[ABB+17] M. Arns, J.-M. Batail, S. Bioulac, M. Congedo, C. Daudet, D. Drapier, T. Fovet,
R. Jardri, M. Le-Van-Quyen, F. Lotte, D. Mehler, J.-A. Micoulaud-Franchi,
D. Purper-Ouakil, and F. Vialatte. Neurofeedback: One of today’s techniques
in psychiatry? L’Encéphale, 43(2):135–145, April 2017.
[ACT+20] MartijnArns, CRichardClark, MarkTrullinger, RogerdeBeus, MarthaMack, and
Michelle Aniftos. Neurofeedback and Attention-Deficit/Hyperactivity-Disorder
(ADHD) in children: Rating the evidence and proposed guidelines. Appl. Psy-
chophysiol. Biofeedback, 45(2):39–48, June 2020.
[ARS+09] Martijn Arns, Sabine De Ridder, Ute Strehl, Marinus Breteler, and Anton Coenen.
Efficacyofneurofeedbacktreatmentinadhd: theeffectsoninattention, impulsivity
and hyperactivity: a meta-analysis. Clinical EEG and neuroscience, 40:180–189,
2009.
[AS13] Martijn Arns and Ute Strehl. Evidence for efficacy of neurofeedback in adhd?
American Journal of Psychiatry, 170:799–800, 7 2013.
[BBC+19] J.-M. Batail, S. Bioulac, F. Cabestaing, C. Daudet, D. Drapier, M. Fouillen,
T. Fovet, A. Hakoun, R. Jardri, C. Jeunet, F. Lotte, E. Maby, J. Mattout,
T. Medani, J.-A. Micoulaud-Franchi, J. Mladenovic, L. Perronet, L. Pillette,
T. Ros, and F. Vialatte. EEG neurofeedback research: A fertile ground for psy-
chiatry? L’Encéphale, 45(3):245–255, June 2019.
[BBPD20] Yasaman Bagherzadeh, Daniel Baldauf, Dimitrios Pantazis, and Robert Desimone.
Alpha Synchrony and the Neurofeedback Control of Spatial Attention.Neuron,
105(3):577–587.e5, February 2020.
[BCB+19] Aurore Bussalb, Marco Congedo, Quentin Barthélemy, David Ojeda, Eric Acqua-
viva, Richard Delorme, and Louis Mayaud. Clinical and experimental factors
influencing the efficacy of neurofeedback in adhd: a meta-analysis.Frontiers in
Psychiatry, 10:PMC6388544, 10 2019.
[CCS+20] Marie-Constance Corsi, Mario Chavez, Denis Schwartz, Nathalie George, Laurent
Hugueville, Ari E. Kahn, Sophie Dupont, Danielle S. Bassett, and Fabrizio De Vico
Fallani. Bci learning induces core-periphery reorganization in m/eeg multiplex
brain networks.Journal of Neural Engineering, 18, 10 2020.
[CFB+16] Samuele Cortese, Maite Ferrin, Daniel Brandeis, Martin Holtmann, Pascal Aggen-
steiner, David Daley, Paramala Santosh, Emily Simonoff, Jim Stevenson, Ar-
gyris Stringaris, Edmund J.S. Sonuga-Barke, Phil Asherson, Tobias Banaschewski,
Daniel Brandeis, Jan Buitelaar, David Coghill, Samuele Cortese, David Daley, Ma-
rina Danckaerts, Ralf W. Dittmann, Manfred Döpfner, Maite Ferrin, Chris Hollis,
Martin Holtmann, Eric Konofal, Michel Lecendreux, Aribert Rothenberger, Para-
mala Santosh, Joseph A. Sergeant, Emily Simonoff, Edmund J. Sonuga-Barke,
Cesar Soutullo, HansChristoph Steinhausen, Jim Stevenson, Argyris Stringaris,
Eric Taylor, Saskia van der Oord, Ian Wong, and Alessandro Zuddas. Neurofeed-
back for Attention-Deficit/Hyperactivity Disorder: Meta-Analysis of Clinical and
Neuropsychological Outcomes From Randomized Controlled Trials.Journal of the
American Academy of Child & Adolescent Psychiatry, 55(6):444–455, June 2016.
36
[CGBB23] Théophile Champion, Marek Grzes, Lisa Bonheme, and Howard Bowman. Decon-
structing deep active inference, 2023.
[CPS+14] Rex L. Cannon, H. Edmund Pigott, Tanju Surmeli, Deborah R. Simkin, R. W.
Thatcher, Werner Van den Bergh, Gerald Gluck, Joel F. Lubar, Richard E. Davis,
Dale S. Foster, Jonathan Douglas, A T Malcolm, Donald R. Bars, Kirk Little, Wes
Center, Marvin H. Berman, Harold L. Russell, Barbara Hammer, and J. Lucas
Koberda. The problem of patient heterogeneity and lack of proper training in
a study of eeg neurofeedback in children.The Journal of clinical psychiatry, 75
3:289–90, 2014.
[CTCB13] Andrea Chronis-Tuscano, Anil Chacko, and Russell Barkley. Key issues relevant
to the efficacy of behavioral treatment for adhd.American Journal of Psychiatry,
170:799–799, 7 2013.
[CXB+21] Chao Chen, Xiaolin Xiao, Abdelkader Nasreddine Belkacem, Lin Lu, Xin Wang,
Weibo Yi, Penghai Li, Changming Wang, Sha Sha, Xixi Zhao, and Dong Ming. Ef-
ficacy evaluation of neurofeedback-based anxiety relief.Frontiers in Neuroscience,
15, October 2021.
[DAH+19] Jessica Van Doren, Martijn Arns, Hartmut Heinrich, Madelon A. Vollebregt, Ute
Strehl, and Sandra K. Loo. Sustained effects of neurofeedback in adhd: a sys-
tematic review and meta-analysis. European Child and Adolescent Psychiatry,
28:293–305, 3 2019.
[Dav18] Eddy J. Davelaar. Mechanisms of Neurofeedback: A Computation-theoretic Ap-
proach. Neuroscience, 378:175–188, May 2018.
[Dav20] Eddy J. Davelaar. A multi-stage theory of neurofeedback learning. Lecture Notes
in Computer Science (including subseries Lecture Notes in Artificial Intelligence
and Lecture Notes in Bioinformatics), 12196 LNAI:118–128, 2020.
[DBVSWB13] Martine Van Dongen-Boomsma, Madelon A. Vollebregt, Dorine Slaats-Willemse,
and Jan K. Buitelaar. A randomized placebo-controlled trial of electroencephalo-
graphic (eeg) neurofeedback in children with attention-deficit/hyperactivity disor-
der. The Journal of Clinical Psychiatry, 74:16829, 8 2013.
[DCPS+20] LancelotDaCosta, ThomasParr, NoorSajid, SebastijanVeselic, VictoritaNeacsu,
and Karl Friston. Active inference on discrete state-spaces: A synthesis.Journal
of Mathematical Psychology, 99:102447, December 2020.
[EGHH17] Stefanie Enriquez-Geppert, René J. Huster, and Christoph S. Herrmann. Eeg-
neurofeedback as a tool to modulate cognition and behavior: A review tutorial.
Frontiers in Human Neuroscience, 11, 2 2017.
[EGSPA19] StefanieEnriquez-Geppert, DiedeSmit, MiguelGarciaPimenta, andMartijnArns.
Neurofeedback as a Treatment Intervention in ADHD: Current Evidence and Prac-
tice. Current Psychiatry Reports, 21(6):46, May 2019.
[EJSV16] Davelaar Eddy, Barnby Joe, Almasi Soma, and Eatough Virginia. Neurophe-
nomenology and neurofeedback: a pilot study.Frontiers in Human Neuroscience,
10, 2016.
[FDCH+20] Karl Friston, Lancelot Da Costa, Danijar Hafner, Casper Hesp, and Thomas Parr.
Sophisticated inference, 2020.
[Fet69] E. E. Fetz. Operant conditioning of cortical unit activity. Science (New York,
N.Y.), 163(3870):955–958, February 1969.
[FFR+16] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, John
O’Doherty, and Giovanni Pezzulo. Active inference and learning.Neuroscience &
Biobehavioral Reviews, 68:862–879, September 2016.
[FFR+17] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and
Giovanni Pezzulo. Active Inference: A Process Theory. Neural Computation,
29(1):1–49, January 2017.
37
[FK09] Karl Friston and Stefan Kiebel. Predictive coding under the free-energy principle.
Philosophical Transactions of the Royal Society B: Biological Sciences, 364:1211,
2009.
[FMFV+17] Thomas Fovet, Jean-Arthur Micoulaud-Franchi, François-Benoît Vialatte, Fabien
Lotte, Christophe Daudet, Jean-Marie Batail, Jérémie Mattout, Guilherme Wood,
Renaud Jardri, Stefanie Enriquez-Geppert, and Tomas Ros. On assessing neu-
rofeedback effects: should double-blind replace neurophysiological mechanisms?
Brain, 140(10):e63–e63, October 2017.
[FRP+17] Karl J. Friston, Richard Rosch, Thomas Parr, Cathy Price, and Howard Bow-
man. Deep temporal models and active inference.Neuroscience & Biobehavioral
Reviews, 77:388–402, June 2017.
[FSMF20] Zafeirios Fountas, Noor Sajid, Pedro A. M. Mediano, and Karl Friston. Deep
active inference agents using monte-carlo methods, 2020.
[GHA+09a] Holger Gevensleben, Birgit Holl, Björn Albrecht, Dieter Schlamp, Oliver Kratz,
Petra Studer, Susanne Wangler, Aribert Rothenberger, Gunther H. Moll, and
Hartmut Heinrich. Distinct eeg effects related to neurofeedbacktraining in children
with adhd: a randomized controlled trial. International journal of psychophys-
iology : official journal of the International Organization of Psychophysiology,
74:149–157, 11 2009.
[GHA+09b] Holger Gevensleben, Birgit Holl, Björn Albrecht, Claudia Vogel, Dieter Schlamp,
Oliver Kratz, Petra Studer, Aribert Rothenberger, Gunther H. Moll, and Hart-
mut Heinrich. Is neurofeedback an efficacious treatment for adhd? a randomised
controlled clinical trial. Journal of child psychology and psychiatry, and allied
disciplines, 50:780–789, 2009.
[Gru13] John Gruzelier. Eeg-neurofeedback for optimising performance. ii: Creativity, the
performing arts and ecological validity.Neuroscience and biobehavioral reviews,
44, 11 2013.
[Gru14] John H. Gruzelier. Eeg-neurofeedback for optimising performance. i: A review of
cognitive and affective outcome in healthy participants.Neuroscience & Biobehav-
ioral Reviews, 44:124–141, 2014. AppliedNeuroscience: Models, methods, theories,
reviews. A Society of Applied Neuroscience (SAN) special issue.
[GSF+17] Sebastian Grissmann, Martin Spuler, Josef Faller, Tanja Krumpe, Thorsten Zan-
der, Augustin Kelava, Christian Scharinger, and Peter Gerjets. Context sensitivity
of eeg-based workload classification under different affective valence.IEEE Trans-
actions on Affective Computing, pages 1–1, 2017.
[GVMS+16] A Gaume, A Vialatte, A Mora-Sánchez, C Ramdani, and F B Vialatte. A psy-
choengineering paradigm for the neurocognitive mechanisms of biofeedback and
neurofeedback. Neuroscience and Biobehavioral Reviews, 68:891–910, 2016.
[HCBI11] Barbara Hammer, Agatha Colbert, Kimberly Brown, and Elena Ilioi. Neuro-
feedback for insomnia: A pilot study of z-score smr and individualized protocols.
Applied psychophysiology and biofeedback, 36:251–64, 07 2011.
[HCW+15] Shivayogi V. Hiremath, Weidong Chen, Wei Wang, Stephen Foldes, Ying Yang,
Elizabeth C. Tyler-Kabara, Jennifer L. Collinger, and Michael L. Boninger. Brain
computer interface learning for systems based on electrocorticography and intra-
cortical microelectrode arrays. Frontiers in Integrative Neuroscience, 9:1–10, 6
2015.
[HPH+82] Peter J. Hauri, Linda Percy, Carla Hellekson, Ernest Hartmann, and Diane Russ.
The treatment of psychophysiologic insomnia with biofeedback: A replication
study. Biofeedback and Self-regulation 1982 7:2, 7:223–235, 6 1982.
[HSHB20] John Hasslinger, Manoela D.Agostini Souto, Lisa Folkesson Hellstadius, and Sven
Bölte. Neurofeedback in adhd: A qualitative study of strategy use in slow cortical
potential training. PLoS ONE, 15, 6 2020.
38
[HSP+21] Casper Hesp, Ryan Smith, Thomas Parr, Micah Allen, Karl J. Friston, and
Maxwell J. D. Ramstead. Deeply Felt Affect: The Emergence of Valence in Deep
Active Inference.Neural Computation, 33(2):398–446, February 2021.
[HZL+21] Yue Hou, Shuqin Zhang, Ning Li, Zhaoyang Huang, Li Wang, and Yuping Wang.
Neurofeedback training improves anxiety trait and depressive symptom in gad.
Brain and Behavior, 11, 3 2021.
[Izh03] Eugene M. Izhikevich. Simple model of spiking neurons. IEEE Transactions on
Neural Networks, 14:1569–1572, 11 2003.
[JJ00] Tommi S. Jaakkola and Michael I. Jordan. Statistics and Computing, 10(1):25–37,
2000.
[JLB+18] Camille Jeunet, Fabien Lotte, Jean-Marie Batail, Pierre Philip, and Jean-Arthur
Micoulaud Franchi. Using recent bci literature to deepen our understanding of
clinical neurofeedback: A short review.Neuroscience, 378:225–233, May 2018.
[KE] Volodymyr Kuleshov and Stefano Ermon. Bayesian learning.
[KP04] David C. Knill and Alexandre Pouget. The bayesian brain: the role of uncertainty
in neural coding and computation.Trends in Neurosciences, 27:712–719, 12 2004.
[LBJPB21] Florence Lambert-Beaudet, William-Girard Journault, Alexandre Rudziavic
Provençal, and Célyne H Bastien. Neurofeedback for insomnia: Current state
of research.World Journal of Psychiatry, 11:897, 10 2021.
[LGH+07] Ulrike Leins, Gabriella Goth, Thilo Hinterberger, Christoph Klinger, Nicola
Rumpf, and Ute Strehl. Neurofeedback for children with adhd: A comparison
of scp and theta/beta protocols.Applied Psychophysiology Biofeedback, 32:73–88,
6 2007.
[LLM13] FabienLotte, FlorianLarrue, andChristianMühl. Flawsincurrenthumantraining
protocols for spontaneous brain-computer interfaces: lessons learned from instruc-
tional design. Frontiers in Human Neuroscience, 7, 2013.
[LLZ+22] Xiaodong Li, Zhonglin Li, Zhi Zou, Xiaolin Wu, Hui Gao, Caiyun Wang, Jing
Zhou, Fei Qi, Miao Zhang, Junya He, Xin Qi, Fengshan Yan, Shewei Dou, Hongju
Zhang, Li Tong, and Yongli Li. Real-time fmri neurofeedback training changes
brain degree centrality and improves sleep in chronic insomnia disorder: A resting-
state fmri study.Frontiers in Molecular Neuroscience, 0:48, 2 2022.
[LPDH22] Nitzan Lubianiker, Christian Paret, Peter Dayan, and Talma Hendler. Neurofeed-
back through the lens of reinforcement learning.Trends Neurosci., 45(8):579–593,
August 2022.
[LSSO95] J. F. Lubar, M. O. Swartwood, J. N. Swartwood, and P. H. O’Donnell. Evaluation
of the effectiveness of EEG neurofeedback training for ADHD in a clinical set-
ting as measured by changes in T.O.V.A. scores, behavioral ratings, and WISC-R
performance. Biofeedback and Self-Regulation, 20(1):83–99, March 1995.
[LZH21] C. Loriette, C. Ziane, and S. Ben Hamed. Neurofeedback for cognitive enhance-
ment and intervention and brain plasticity.Revue Neurologique, 177:1133–1144,
11 2021.
[MFBF+19] Jean Arthur Micoulaud-Franchi, Jean Marie Batail, Thomas Fovet, Pierre Philip,
Michel Cermolacce, Aurore Jaumard-Hakoun, and François Vialatte. Towards
a pragmatic approach to a psychophysiological unit of analysis for mental and
brain disorders an eeg-copeia for neurofeedback. Applied Psychophysiology and
Biofeedback, 44:151–172, 5 2019.
[MFGF+14] Jean-Arthur Micoulaud-Franchi, Pierre Alexis Geoffroy, Guillaume Fond, Régis
Lopez, Stéphanie Bioulac, and Pierre Philip. EEG neurofeedback treatments in
children with ADHD: an updated meta-analysis of randomized controlled trials.
Frontiers in Human Neuroscience, 8:906, 2014.
39
[MG05] IainMurrayandZoubinGhahramani. Anoteontheevidenceandbayesianoccam’s
razor. 2005.
[MHS+09] Brooke S.G. Molina, Stephen P. Hinshaw, James M. Swanson, L. Eugene Arnold,
Benedetto Vitiello, Peter S. Jensen, Jeffery N. Epstein, Betsy Hoza, Lily Hecht-
man, Howard B. Abikoff, Glen R. Elliott, Laurence L. Greenhill, Jeffrey H. New-
corn, Karen C. Wells, Timothy Wigal, Robert D. Gibbons, Kwan Hur, and Patri-
cia R. Houck. The MTA at 8 Years: Prospective Follow-up of Children Treated for
Combined-Type ADHD in a Multisite Study.Journal of the American Academy
of Child & Adolescent Psychiatry, 48(5):484–500, May 2009.
[Mil19] Beren Millidge. Deep active inference as variational policy gradients, 2019.
[MJL14] Christian Mähl, Camille Jeunet, and Fabien Lotte. Eeg-based workload estimation
across affective contexts.Frontiers in Neuroscience, 8, June 2014.
[MKG22] Wei Ji Ma, Konrad Kording, and Daniel Goldreich. Bayesian models of perception
and action, 2022.
[MMM16] H. Marzbani, H. Marateb, and M. Mansourian. Methodological Note: Neuro-
feedback: A Comprehensive Review on System Design, Methodology and Clinical
Applications. Basic and Clinical Neuroscience Journal, 7(2), 2016.
[MPP+11] Afsaneh Moradi, Farzaneh Pouladi, Nooshin Pishva, Bagher Rezaei, Maliheh Tor-
shabi, and Zahra Alam Mehrjerdi. Treatment of anxiety disorder with neuro-
feedback: Case study. Procedia - Social and Behavioral Sciences, 30:103–107, 1
2011.
[MSB21] Beren Millidge, Anil Seth, and Christopher Buckley. Predictive coding: a theoret-
ical and experimental review. 07 2021.
[OHL+15] Yuka O Okazaki, Jörn M Horschig, Lisa Luther, Robert Oostenveld, Ikuya Mu-
rakami, and Ole Jensen. Real-time MEG neurofeedback training of posterior al-
pha activity modulates subsequent visual detection performance. Neuroimage,
107:323–332, February 2015.
[OLPS17] Ethan Oblak, Jarrod Lewis-Peacock, and James Sulzer. Self-regulation strategy,
feedback timing and hemodynamic properties modulate learning in a simulated
fmri neurofeedback environment. PLoS computational biology, 13:e1005681, 07
2017.
[OLRV21] Jay A. Olson, Michael Lifshitz, Amir Raz, and Samuel P.L. Veissière. Super
placebos: A feasibility study combining contextual factors to promote placebo
effects. Frontiers in Psychiatry, 12:644825, 3 2021.
[OMHT23] Ryoji Onagawa, Yoshihito Muraoka, Nobuhiro Hagura, and Mitsuaki Takemi.
An investigation of the effectiveness of neurofeedback training on motor perfor-
mance in healthy adults: A systematic review and meta-analysis. NeuroImage,
270:120000, April 2023.
[PBAEG21] Miguel Garcia Pimenta, Trevor Brown, Martijn Arns, and Stefanie Enriquez-
Geppert. <p>treatment efficacy and clinical effectiveness of eeg neurofeedback
as a personalized and multimodal treatment in adhd: A critical review</p>.
Neuropsychiatric Disease and Treatment, 17:637–648, 2 2021.
[PCB+19] Christie Picken, Adam R. Clarke, Robert J. Barry, Rory McCarthy, and Mark
Selikowitz. The theta/beta ratio as an index of cognitive processing in adults with
the combined type of attention deficit hyperactivity disorder.Clinical EEG and
Neuroscience, 51(3):167–173, December 2019.
[PCB+20] Christie Picken, Adam R. Clarke, Robert J. Barry, Rory McCarthy, and Mark
Selikowitz. The theta/beta ratio as an index of cognitive processing in adults with
the combined type of attention deficit hyperactivity disorder.Clinical EEG and
Neuroscience, 51:167–173, 5 2020.
[PF19a] Thomas Parr and Karl J. Friston. Generalised free energy and active inference.
Biological Cybernetics, 113(5-6):495–513, December 2019.
40
[PF19b] Thomas Parr and Karl J. Friston. Generalised free energy and active inference.
Biological cybernetics, 113:495–513, 12 2019.
[PRF18] Giovanni Pezzulo, Francesco Rigoli, and Karl J. Friston. Hierarchical active infer-
ence: A theory of motivated control.Trends in Cognitive Sciences, 22(4):294–306,
April 2018.
[PRNL21] Léa Pillette, Aline Roc, Bernard N’Kaoua, and Fabien Lotte. Experimenters’
influence on mental-imagery based brain-computer interface user training.Inter-
national Journal of Human-Computer Studies, 149:102603, May 2021.
[RBCC13] Raphaelle N. Roy, Stephane Bonnet, Sylvie Charbonnier, and Aurelie Campagne.
Mental fatigue and working memory load estimation: Interaction and implications
for eeg-based passive bci. In 2013 35th Annual International Conference of the
IEEE Engineering in Medicine and Biology Society (EMBC). IEEE, July 2013.
[RdlVJM20] Rubén Roy, Rocío de la Vega, Mark P. Jensen, and Jordi Miro. Neurofeedback
for pain management: A systematic review.Frontiers in Neuroscience, 14:671, 7
2020.
[REGZ+20] Tomas Ros, Stefanie Enriquez-Geppert, Vadim Zotev, Kymberly D Young, Guil-
herme Wood, Susan Whitfield-Gabrieli, Feng Wan, Patrik Vuilleumier, François
Vialatte, Dimitri Van De Ville, Doron Todder, Tanju Surmeli, James S Sulzer,
Ute Strehl, Maurice Barry Sterman, Naomi J Steiner, Bettina Sorger, Surjo R
Soekadar, Ranganatha Sitaram, Leslie H Sherlin, Michael Schönenberg, Frank
Scharnowski, Manuel Schabus, Katya Rubia, Agostinho Rosa, Miriam Reiner,
Jaime A Pineda, Christian Paret, Alexei Ossadtchi, Andrew A Nicholson, Wenya
Nan, JavierMinguez, Jean-ArthurMicoulaud-Franchi, DavidMAMehler, Michael
Lührs, Joel Lubar, Fabien Lotte, David E J Linden, Jarrod A Lewis-Peacock,
Mikhail A Lebedev, Ruth A Lanius, Andrea Kübler, Cornelia Kranczioch, Yury
Koush, Lilian Konicar, Simon H Kohl, Silivia E Kober, Manousos A Klados,
Camille Jeunet, T W P Janssen, Rene J Huster, Kerstin Hoedlmoser, Laurence M
Hirshberg, Stephan Heunis, Talma Hendler, Michelle Hampson, Adrian G Guggis-
berg, RobertGuggenberger, JohnHGruzelier, RainerWGöbel, NicolasGninenko,
Alireza Gharabaghi, Paul Frewen, Thomas Fovet, Thalía Fernández, Carlos Es-
colano, Ann-Christine Ehlis, Renate Drechsler, R Christopher deCharms, Stefan
Debener, Dirk De Ridder, Eddy J Davelaar, Marco Congedo, Marc Cavazza, Mar-
inus H M Breteler, Daniel Brandeis, Jerzy Bodurka, Niels Birbaumer, Olga M
Bazanova, Beatrix Barth, Panagiotis D Bamidis, Tibor Auer, Martijn Arns, and
Robert T Thibault. Consensus on the reporting and experimental design of clini-
cal and cognitive-behavioural neurofeedback studies (CRED-nf checklist).Brain,
143(6):1674–1685, June 2020.
[RMYBCSZ21] Pablo Riesco-Matias, José Ramon Yela-Bernabé, Antonio Crego, and Elena
Sánchez-Zaballos. What do meta-analyses have to say about the efficacy of neu-
rofeedback applied to children with adhd? review of previous meta-analyses and
a new meta-analysis.Journal of Attention Disorders, 25:473–485, 2 2021.
[RPM+21] Aline Roc, Lea Pillette, Jelena Mladenovic, Camille Benaroch, Bernard N’Kaoua,
Camille Jeunet, and Fabien Lotte. A review of user training methods in brain
computer interfaces based on mental tasks. Journal of Neural Engineering,
18(1):011002, February 2021.
[SBPF21] Noor Sajid, Philip J. Ball, Thomas Parr, and Karl J. Friston. Active Inference:
Demystified and Compared.Neural Computation, 33(3):674–712, March 2021.
[SBWK14] Ute Strehl, Sarah M. Birkle, Sonja Wörz, and Boris Kotchoubey. Sustained reduc-
tion of seizures in patients with intractable epilepsy after self-regulation training
of slow cortical potentials 10 years after.Frontiers in Human Neuroscience, 8, 8
2014.
[SFW21] Ryan Smith, Karl Friston, and Christopher Whyte. A Step-by-Step Tutorial on
Active Inference and its Application to Empirical Data. preprint, PsyArXiv, Jan-
uary 2021.
41
[SFW22] Ryan Smith, Karl J. Friston, and Christopher J. Whyte. A step-by-step tutorial
on active inference and its application to empirical data.Journal of Mathematical
Psychology, 107:102632, 4 2022.
[SGG+17] Manuel Schabus, Hermann Griessenberger, Maria-Teresa Gnjezda, Dominik P. J.
Heib, Malgorzata Wislowska, and Kerstin Hoedlmoser. Better than sham? A
double-blind placebo-controlled neurofeedback study in primary insomnia.Brain,
140(4):1041–1052, April 2017.
[SKW12] Jerry J. Shih, Dean J. Krusienski, and Jonathan R. Wolpaw. Brain-computer
interfaces in medicine.Mayo Clinic Proceedings, 87:268, 2012.
[SRS+17] Ranganatha Sitaram, Tomas Ros, Luke Stoeckel, Sven Haller, Frank Scharnowski,
Jarrod Lewis-Peacock, Nikolaus Weiskopf, Maria Laura Blefari, Mohit Rana,
Ethan Oblak, Niels Birbaumer, and James Sulzer. Closed-loop brain training:
the science of neurofeedback.Nature Reviews Neuroscience, 18(2):86–100, Febru-
ary 2017.
[SSHL+20] Lars Sandved-Smith, Casper Hesp, Antoine Lutz, Jérémie Mattout, Karl Friston,
and Maxwell James Ramstead. Towards a computational (neuro)phenomenology
of mental action: modelling meta-awareness and attentional control with deep-
parametric active inference. preprint, PsyArXiv, June 2020.
[SSPF20] Ryan Smith, Philipp Schwartenbeck, Thomas Parr, and Karl J. Friston. An active
inferenceapproachtomodelingstructurelearning: Conceptlearningasanexample
case. Frontiers in Computational Neuroscience, 14:41, 5 2020.
[Tho19] Margaret C. Thompson. Critiquing the concept of bci illiteracy. Science and
engineering ethics, 25:1217–1233, 8 2019.
[TKLM20] Lucas Trambaiolli, Simon Kohl, David Linden, and David Mehler. Neurofeedback
training in major depressive disorder: a systematic review of clinical efficacy, study
quality and reporting practices. 09 2020.
[TLR17] Robert T. Thibault, Michael Lifshitz, and Amir Raz. Neurofeedback or neuro-
placebo? Brain, 140(4):862–864, April 2017.
[TSB20] Alexander Tschantz, Anil K. Seth, and Christopher L. Buckley. Learning
action-oriented models through active inference. PLOS Computational Biology,
16:e1007805, 4 2020.
[TVOR18] Robert T. Thibault, Samuel Veissière, Jay A. Olson, and Amir Raz. Treating adhd
with suggestion: Neurofeedback and placebo therapeutics. Journal of attention
disorders, 22:707–711, 6 2018.
[Uel18] Kai Ueltzhöffer. Deep active inference. Biological Cybernetics, 112(6):547–573,
October 2018.
[VB10] Carmen Vidaurre and Benjamin Blankertz. Towards a cure for bci illiteracy. Brain
Topography, 23:194, 6 2010.
[vDBVSWB14] Martine van Dongen-Boomsma, Madelon A. Vollebregt, Dorine Slaats-Willemse,
and Jan K. Buitelaar. Dr van dongen-boomsma and colleagues reply.The Journal
of Clinical Psychiatry, 75:5149, 3 2014.
[VKC21] Antti Veikko Petteri Veilahti, Levas Kovarskis, and Benjamin Ultan Cowley. Neu-
rofeedback Learning Is Skill Acquisition but Does Not Guarantee Treatment Bene-
fit: Continuous-TimeAnalysisofLearning-CurvesFromaClinicalTrialforADHD.
Frontiers in Human Neuroscience, 15:668780, June 2021.
[WAMH18] Min Wang, Sherif Abdelfattah, Nour Moustafa, and Jiankun Hu. Deep gaussian
mixture-hidden markov model for classification of eeg signals.IEEE Transactions
on Emerging Topics in Computational Intelligence, 2(4):278–287, August 2018.
[WEE20] Lydia Anna Weber, Thomas Ethofer, and Ann Christine Ehlis. Predictors of
neurofeedback training outcome: A systematic review. NeuroImage: Clinical,
27:102301, 1 2020.
42
[WK18] Guilherme Wood and Silvia Erika Kober. Eeg neurofeedback is under strong
control of psychosocial factors. Applied Psychophysiology and Biofeedback,
43(4):293–300, August 2018.
[WKWN14] Guilherme Wood, Silvia Erika Kober, Matthias Witte, and Christa Neuper.
On the need to better specify the concept of "control" in brain-computer-
interfaces/neurofeedback research. Frontiers in Systems Neuroscience, 8:171, 9
2014.
[YHKI17] Ayumu Yamashita, Shunsuke Hayasaka, Mitsuo Kawato, and Hiroshi Imamizu.
Connectivity neurofeedback training can differentially change functional connec-
tivity and cognitive performance.Cerebral Cortex, 27:4960–4970, 10 2017.
[YHY+17] Takashi Yamada, Ryu Ichiro Hashimoto, Noriaki Yahata, Naho Ichikawa, Yujiro
Yoshihara, Yasumasa Okamoto, Nobumasa Kato, Hidehiko Takahashi, and Mitsuo
Kawato. Resting-state functional connectivity-based biomarkers and functional
mri-based neurofeedback for psychiatric disorders: A challenge for developing
theranostic biomarkers. The international journal of neuropsychopharmacology,
20:769–781, 10 2017.
[ZCY+22] Qing Zhou, Ruidong Cheng, Lin Yao, Xiangming Ye, and Kedi Xu. Neurofeedback
training of alpha relative power improves the performance of motor imagery brain-
computer interface.Frontiers in Human Neuroscience, 16, April 2022.
[ZWLH09] Longlian Zhao, Wenqing Wu, Zuoqing Liang, and Guangshu Hu. Changes in
eeg measurements in intractable epilepsy patients with neurofeedback training.
Progress in Natural Science, 19:1509–1514, 11 2009.
43