HAL Id: tel-01382731
https://theses.hal.science/tel-01382731v1
Submitted on 17 Oct 2016
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in F rance or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Active inference of network neutrality
Riccardo Ravaioli
T o cite this version:
Riccardo Ravaioli. Active inference of network neutrality . Other [cs.OH]. Université Nice Sophia
Antipolis, 2016. English. ￿NNT : 2016NICE4044￿. ￿tel-01382731￿
UNIVERSITE NICE SOPHIA ANTIPOLIS
ECOLE DOCTORALE STIC
SCIENCES ET TECHNOLOGIES DE L’INFORMATION ET DE LA COMMUNICATION
T H E S E
pour l’obtention du grade de
Docteur en Sciences
de l’Université Nice Sophia Antipolis
présentée et soutenue par
Riccardo RAVAIOLI
ACTIVE INFERENCE OF NETWORK NEUTRALITY
Thèse dirigée par Guillaume URVOY-KELLER
et Chadi BARAKAT
soutenue le 13 juillet 2016
Jury :
Prof.   Françoise Baude Président
Prof. Kavé SALAMATIAN Rapporteur
Ass. Prof.  Marco MELLIA Rapporteur
Ass. Prof. Timur FRIEDMAN Examinateur
Prof.   Guillaume URVOY-KELLER Directeur de thèse
Dr.      Chadi BARAKAT (HDR) Directeur de thèse
Mention : Informatique

Abstract
In the last decade, some ISPs have been reported to discriminate
against speciﬁc user trafﬁc, especially if generated by bandwidth-
hungry applications (e.g., peer-to-peer , video streaming) or compet-
ing services (e.g. V oice-over-IP). Network neutrality , a design prin-
ciple according to which a network should treat all incoming pack-
ets equally , h as been widely debated ever since. In this thesis we
present ChkDiff, a novel tool for the detection of trafﬁc differentia-
tion at the Internet access. In contrast to existing work, our method is
agnostic to both the applications being tested and the shaping mech-
anisms deployed by an ISP . The experiment comprises two parts,
in which we check for differentiation separately on upstream and
downstream trafﬁc that we previously dump directly from the user .
In the upstream direction, ChkDiff replays the user ’s outgoing traf-
ﬁc with a modiﬁed TTL value in order to check for differentiation on
routers at the ﬁrst few hops from the user . By comparing the result-
ing delays and losses of ﬂows that traversed the same routers, and
analyzing the behaviour on the immediate router topology spawn-
ing from the user end point, we manage to detect instances of trafﬁc
shaping and attempt to localize shapers. Our study on the respon-
siveness of routers to TTL-limited probes consolidates our choice of
measurements in the upstream experiment. In the downstream ex-
periment, we replay the user ’s incoming trafﬁc from a measurement
server and analyze per-ﬂow one-way delays and losses, while tak-
ing into account the possibility of multiple paths between the two
endpoints. Along the chapters of this thesis, we provide a detailed
description of our methodology and a validation of our tool.

Résumé
Durant la dernière décennie, des F AI ont été accusés de discriminer
certains types de traﬁc utilisateur générés par des applications gour-
mandes en bande passante (peer-to-peer , streaming vidéo) ou par
des services concurrents (V oice-over-IP). La neutralité des réseaux,
un principe selon lequel un réseau devrait traiter tous les paquets
entrants de la même manière, a été largement débattue. Dans cette
thèse, nous présentons ChkDiff, un nouvel outil pour la détection de
la différentiation du traﬁc dans le réseau d’accès. Contrairement aux
travaux existants, notre méthode est agnostique à la fois vis-à-vis des
applications testées et des mécanismes de shaping déployés. ChkD-
iff comprend deux phases dans lesquelles nous testons séparément
le traﬁc montant et descendant capturé auparavant dans la machine
de l’utilisateur . Dans la direction montante, ChkDiff rejoue le traﬁc
sortant de la machine de l’utilisateur avec une valeur TTL modi-
ﬁée aﬁn de pouvoir tester les routeurs aux premiers sauts. En com-
parant les délais et les pertes des paquets des ﬂux qui ont traversé
les mêmes routeurs et en analysant les résultats sur la topologie des
routeurs traversés, nous montrons que nous pouvons détecter les cas
de différentiation et localiser les shapers. Notre étude sur la réac-
tivité des routeurs aux sondes avec TTL limité consolide notre choix
de mesures dans l’expérimentation sur le traﬁc montant. Dans la
direction descendante, nous rejouons le traﬁc entrant dans la ma-
chine de l’utilisateur à partir d’un serveur de mesure et analysons
pour chaque ﬂux les délais unidirectionnels et les pertes, tout en
tenant compte la possibilité de trajets multiples entre le serveur et
l’utilisateur . Le long des chapitres de cette thèse, nous fournissons
une description détaillée de notre méthodologie et une validation de
notre outil.

Acknowledgements
I would like to express my deepest gratitude to my supervisors, Guil-
laume Urvoy-Keller and Chadi Barakat, for their constant guidance,
tireless mentoring and invaluable insights throughout my years as a
PhD student.
I would also like to thank my family for their precious uncondi-
tional support: without them, I would not be the person I am today .
This dissertation would not have been possible without funding
from Labex UCN@Sophia.

Contents
1 Introduction 15
2 Context and Related Work 19
2.1 A few examples of discriminatory practices 19
2.2 Internet Neutrality 21
2.3 T rafﬁc differentiation 23
2.4 Legislative efforts 24
2.5 T ools for the detection of trafﬁc differentiation 25
3 ICMP rate limitation 43
3.1 Overview 44
3.2 Experimental setup 45
3.3 Analysis of ICMP rate limitation 46
3.4 Characterization of routers 48
3.5 Delay 56
3.6 Related Work 56
3.7 Summary 57
4 ChkDiff: the upstream experiment 59
4.1 Design of the tool 60
4.2 V alidation in a neutral scenario 66
4.3 V alidation in a non-neutral scenario 67
4.4 Assessment with respect to existing methods 75
4.5 Summary 76
10 inference of network neutrality violations with active me asurements
5 ChkDiff: the downstream experiment 79
5.1 Methodology 79
5.2 V alidation 87
5.3 Discussion 91
5.4 Assessment with respect to existing methods 93
5.5 Summary 94
6 Conclusion 95
6.1 Summary 95
6.2 Future directions 96
List of Figures
3.1 Loss rates for all experiments, arranged by probing rate. 45
3.2 Mean RTT box plots for all experiments, arranged by probing
rate. 45
3.3 A typical timeseries for an on-off rate-limited router . 46
3.4 A typical timeseries for a generically rate-limited router . 47
3.5 Phases in the responsiveness of routers to TTL-probes 49
3.6 CDFs of BS, IBT and overall answering rate for on-off routers. 51
3.7 Distribution of r1 for fr-onoff-irr routers. 52
3.8 Answering rate over expected answering rate in irr phase for on-
off routers. 52
3.9 Answering rate for generically rate-limited ( rl) routers. 53
3.10 CDFs of BS, IBT and answering rate for on-off routers, arranged
by router vendor . 54
3.11 Distribution of vendors and percentage of routers in each cate-
gory for Cisco, Juniper and “others”. 55
3.12 V eriﬁcation of inferred parameters on a controlled rate-limited
machine. 56
3.13 RTT CoV box plots for all experiments, arranged by probing
rate. 57
4.1 An example with shapers at different hops affecting selected
ﬂows. 64
4.2 Expected output of ChkDiff for the network topology in Fig-
ure 4.1. 64
4.3 Distribution of ﬂow sizes, in number of packets, for the packet
trace used for validation. 66
4.4 Incidence of false positives in the delay analysis when the re-
played trace contains unaltered original packets, and when it
contains packets of the same size. Results are over 1 run. 66
4.5 Middlebox conﬁguration. 67
4.6 Precision and recall of the combined analysis, for the case of
one shaped ﬂow in Scenario 1. In each circle, we report in the
upper-left quarter the result of only the delay analysis, in the
upper-right quarter the result of only the loss analysis, and in
the lower half the result of the combined analysis, which rejects a
ﬂow if either the delay or the loss analysis fails. 68
12 inference of network neutrality violations with active me asurements
4.7 Recall of the loss analysis as we vary fr, for the case of uniform
drops on the whole trafﬁc and on one selected ﬂow (Scenario
2). 68
4.8 Precision and recall of the combined analysis, for the case of
multiple shaped ﬂows, in Scenario 1. 70
4.9 Recall of the loss analysis as we vary fr, for the case of uniform
drops on the whole trafﬁc and on multiple selected ﬂows (Sce-
nario 2). 70
4.10 Precision and recall of the combined analysis, for the case of mul-
tiple shaped ﬂows with a WiFi connection, in Scenario 1. 71
4.11 Recall of the loss analysis as we vary fr, for the case of uniform
drops on the whole trafﬁc and on multiple selected ﬂows with a
WiFi connection (Scenario 2). 71
4.12 Scenario 1 with multiple shaped ﬂows and ICMP rate limita-
tion. 72
4.13 Scenario 2 with multiple shaped ﬂows and ICMP rate limita-
tion. 73
5.1 The two experiments in ChkDiff. 80
5.2 Conﬁguration of client and server . 85
5.3 Timeseries of an experiment with packets following multiple
paths. 86
5.4 Setup used in the validation of ChkDiff, along with the shaper
conﬁguration. 87
5.5 Distribution of ﬂow sizes for the trace we used in the validation
of the tool. 88
5.6 Recall of the combined analysis (delay and losses) for Scenario
1 over wired, WiFi and 3G connections. 89
5.7 Recall of the loss analysis as we vary fr in Scenario 2 from the
server located in Germany , over wired, WiFi and 3G connec-
tions. 90
5.8 Recall of the loss analysis as we vary fr in Scenario 2 from
the server located in Ireland, over wired, WiFi and 3G connec-
tions. 91
5.9 Recall of the loss analysis as we vary fr in Scenario 2 from
the server located in Oregon, over wired, WiFi and 3G connec-
tions. 92
List of T ables
2.1 Comparison of existing methods for the detection of neutrality
violations. 41
2.1 Comparison of existing methods for the detection of neutrality
violations. 42
3.1 Number of routers in each category . 48
4.1 Number of true and false positives when replaying the original
and a shufﬂed trace at different sending rates. 74

1
Introduction
The increasing popularity of bandwidth-hungry applications, like
peer-to-peer and video streaming, has induced some Internet Ser-
vice Providers (ISPs) in the last decade to deploy some trafﬁc man-
agement techniques that offer degraded performance instead of best-
effort service to speciﬁc trafﬁc ﬂows. Reported cases abound: from
blocking of BitT orrent trafﬁc when a user is actively sharing ﬁles, to
reduced performance of NetFlix by a few U.S. operators and throt-
tling of Y ouT ube during peak hours in the evening. Also competing
services such as V oIP have been the target of ISPs, for instance when
all V onage calls were systematically blocked by a regional mobile
operator and when Apple’s FaceTime was disabled for mobile cus-
tomers who did not opt for a more expensive data plan.
All these examples constitute clear violations of Internet neutral-
ity , a principle according to which a network should treat all its in-
coming trafﬁc equally , without deliberately offering worse or better
performance to any trafﬁc of its choice. There has been discussion 1
1 Jon Crowcroft. Net neutrality: the
technical side of the debate: a white pa-
per . SIGCOMM Comput. Commun. Rev. ,
37:49–56, January 2007
about whether the Internet has been conceived and implemented as
a strictly level-playing ﬁeld, but from a broader point of view it is
generally agreed upon that all attempts that selectively deteriorate
certain types of Internet trafﬁc over others are, to say the least, con-
troversial. Because of this, legislative efforts aiming at prohibiting
cases like the above ones have appeared in a number of countries,
the ﬁrst of which to approve such laws were Chile in 2010 and the
Netherlands in 2012.
T rafﬁc differentiation is typically carried out in two steps: ﬁrst a
ﬂow is identiﬁed by inspecting packet ﬁelds at the IP , transport or ap-
plication layer , then a differentiation technique is applied to packets
belonging to that ﬂow , generally leading to the corresponding user
application experiencing larger delays and more losses (translating
into a lower throughput), when it is not blocked all together .
In the literature several tools have been described in recent years
to try to establish whether an ISP applies trafﬁc differentiation to
speciﬁc applications (e.g., BitT orrent, Y ouT ube, Skype, etc.) 2 and
2 Marcel Dischinger , Alan Mislove, An-
dreas Haeberlen, and Krishna P . Gum-
madi. Detecting BitT orrent Blocking.
In Proceedings of the 8th ACM SIG-
COMM Conference on Internet Measure-
ment (IMC’ 08), V ouliagmeni, Greece,
October 2008
Marcel Dischinger , Massimiliano
Marcon, Saikat Guha, Krishna Gum-
madi, Ratul Mahajan, and Stefan
Saroiu. Glasnost: Enabling End Users
to Detect T rafﬁc Differentiation. In Pro-
ceedings of the 7th Symposium on Net-
worked Systems Design and Implementa-
tion (NSDI) , San Jose, CA, Apr 2010
Partha Kanuparthy and Constan-
tine Dovrolis. Diffprobe: detecting ISP
service discrimination. In Proceedings
of the 29th conference on Information com-
munications, INFOCOM’ 10, pages 1649–
1657, Piscataway , NJ, USA, 2010. IEEE
Press
with the use of speciﬁc differentiation techniques (e.g., port blocking,
token-bucket shaper , PowerBoost, etc.). 3
3 Robert Beverly , Steven Bauer , and
Arthur Berger . The Internet is not a
big truck: toward quantifying network
neutrality . In Passive and Active Network
Measurement, pages 135–144. Springer ,
2007
Partha Kanuparthy and Constan-
tine Dovrolis. Shaperprobe: End-to-end
detection of isp trafﬁc shaping using ac-
tive methods. In Proceedings of the 2011
ACM SIGCOMM Conference on Internet
Measurement Conference , IMC ’ 11, pages
473–482. ACM, 2011
Udi W einsberg, Augustin Soule,
and Laurent Massoulié. Inferring traf-
ﬁc shaping and policy parameters using
end host measurements. In INFOCOM,
pages 151–155, 2011
In this thesis, we propose novel method for the detection of traf-
ﬁc differentiation at the access ISP that differs from existing work in
16 inference of network neutrality violations with active me asurements
that it is both independent from the applications tested by the user
and the shaping technique deployed by the network operator . While
most methods in the literature replay an application ﬂow and a refer-
ence ﬂow with a variety of techniques and compare the performance
of the two ﬂows to infer differentiation, we replay the whole user
trafﬁc with minimal modiﬁcations and compare the performance of
each application run by the user against the rest of the user trafﬁc,
which we take as baseline. W e detect differentiation by analyzing the
distribution of delays and the number of losses of each ﬂow , which
are the two metrics that are directly affected by a shaper that wants
to degrade the performance of selected trafﬁc.
W e implemented this in a tool we called ChkDiff, 4 which ﬁrst 4 The code is available on a
dedicated web page: http:
//chkdiff.gforge.inria.fr/
dumps regular user trafﬁc for a time window of a few minutes, dur-
ing which the user is expected to run the Internet applications she in-
tends to test, and then spawns two different experiments that replay
the captured trafﬁc in respectively the upstream and downstream
direction. In both cases, we shufﬂe the trace in such a way that the
position of the packets of each ﬂow inside the trace can be modeled
as a Poisson process, which guarantees us - according to the P AST A 5 5 Poisson Arrivals See Time A verages.
property - that each replayed ﬂow will see the same network condi-
tions. Clearly , we preserve the order of packets of each ﬂow while
shufﬂing.
In the upstream experiment, 6 we replay the user outgoing trafﬁc 6 Riccardo Ravaioli, Guillaume Urvoy-
Keller , and Chadi Barakat. T owards a
general solution for detecting trafﬁc dif-
ferentiation at the internet access. In
T eletrafﬁc Congress (ITC 27), 2015 27th In-
ternational, pages 1–9. IEEE, 2015
against the routers in her immediate vicinity in order to test whether
the user ’s access ISP deploys any shapers targeting any of the previ-
ously executed applications. For each hop at distance k to the user ,
we re-inject the trace into the network with a forged Time-T o-Live
(TTL) ﬁeld in the IP header of each packet, so that routers at hop
k will generate ICMP time-exceeded error messages, with which we
compute per-ﬂow Round-T rip Times (RTT s) and losses. ChkDiff in-
fers that a ﬂow has been differentiated when its empirical delay dis-
tribution fails the one-sided two-sample Kolmogorov-Smirnov test
against the delays of all other ﬂows in the trace, or when its loss
count is not compatible with the overall loss rate of the rest of the
trace, through a tailored binomial-inspired test. By analyzing the
performance of ﬂows across successive hops, we are also able to pin-
point the position of a shaper with respect to the user .
In order to justify our choice of measurements in the upstream
experiment, we performed a detailed study of the responsiveness of
routers to TTL-limited probes and a characterization of how ICMP
rate limitation is implemented. 7 With a large-scale measurement 7 Riccardo Ravaioli, Guillaume Urvoy-
Keller , and Chadi Barakat. Character-
izing ICMP Rate Limitation on Routers.
In IEEE International Conference on Com-
munications (ICC) , 2015
campaign from 180 PlanetLab nodes, we probed at increasing rates
850 routers up to hop 5 and analyzed their responsiveness. W e found
out that almost one third of the routers hit are fully responsive at
least up to relatively high rates ( 2500 packets per second ( pps)), a
small fraction ( 3.9%) of routers is unresponsive and almost 60% im-
plement ICMP rate limitation, whose most common form is an on-off
pattern deﬁned by the burst size of the generated packets and the
inter-burst time, which we characterize in details. Also, most routers
chapter 1 . introduction 17
are fully responsive at rates that are between one and two orders of
magnitude higher than those commonly used by tools running these
measurements. W e also found no correlation between probing rates
and the resulting RTT s, which means that our choice of probing rate
does not reach any capacity limits on routers and does not cause any
additional delay in the returned ICMP replies.
In the downstream experiment of ChkDiff, 8 we replay the user 8 Riccardo Ravaioli, Guillaume Urvoy-
Keller , and Chadi Barakat. T esting for
trafﬁc differentiation with chkdiff: the
downstream case. In T eletrafﬁc Congress
(ITC 28), 2016 28 th International . IEEE,
2016
incoming trafﬁc from a measurement server and measure per-ﬂow
one-way delays and losses in order to infer differentiation. Since
there might be NA T s, ﬁrewalls and middleboxes along the path be-
tween the user and our server , we take the necessary measures to
open connections, ﬁnd NA T mappings for the ﬂows in the trace, ad-
just sequence numbers and avoid ﬁrewall timeouts. Unlike other
proposals in the literature, we take into account the possibility of
multiple paths between the two end points and base our analysis
accordingly . Flow delays are grouped with a clustering algorithm
that isolates a posteriori the different paths and ﬂags as shaped those
ﬂows that could not be assigned to any discovered path. W e inte-
grate this delay analysis with the loss analysis that we also applied
in the upstream case in order to detect trafﬁc differentiation.
The thesis is organized as follows: in Chapter 2 we describe a few
representative cases of trafﬁc differentiation, introduce the concept
of Internet neutrality and review existing methods for the detection
of trafﬁc differentiation; in Chapter 3 we study the responsiveness of
routers to TTL-limited probes and characterize routers also accord-
ing to their vendor; in Chapter 4 we provide a detailed description
of the methodology of the upstream experiment in ChkDiff and val-
idate the tool in a controlled setup with a wired and WiFi connec-
tion, under two different shaping scenarios, and also with a router
implementing ICMP rate limitation; in Chapter 5 we illustrate the
downstream experiment of ChkDiff and validate it using real Inter-
net paths from three different server locations and over wired, WiFi
and 3G connections; we give closing remarks and discuss future di-
rections in Chapter 6.

2
Context and Related Work
T rafﬁc management is commonplace in most network architectures:
it is essential in case of congestion in the network and useful when
certain managed services (e.g., voice over broadband, IPTV , etc.)
have latency or jitter constraints. On the other hand, when trafﬁc
management is used to purposely discriminate certain types of traf-
ﬁc over others, it becomes a more controversial matter , as it directly
harms the openness and neutrality of the Internet.
In this chapter we ﬁrst present a few blatant cases of discrimina-
tory practices performed by ISPs (Section 2.1), introduce the concept
of Internet neutrality and offer arguments in favour and against it
(Section 2.2); then, we explain how trafﬁc differentiation is gener-
ally implemented in today’s networks (Section 2.3) and summarize
the legislative efforts in various countries to preserve a neutral and
open Internet (Section 2.4). Finally , we describe and evaluate exist-
ing methods in the literature for the detection of trafﬁc differentiation
(Section 2.5).
2.1 A few examples of discriminatory practices
In the last decade, several cases of discriminatory practices have been
reported by Internet users, concerning mostly bandwidth-hungry
applications like peer-to-peer and video streaming, and competing
services, like V oice-over-IP (V oIP) and even search engine queries.
W e detail here a few exemplary cases for each type of targeted ser-
vice.
Peer-to-peer . One of the ﬁrst cases that emerged is that of U.S. oper-
ator Comcast in 2005, when it deliberately blocked upstream trafﬁc
of BitT orrent users who were actively sharing ﬁles with end users lo-
cated in other networks. 1 By injecting forged TCP RST packets when 1 Dslreports: comcast is using sand-
vine to manage p 2p connections.
URL: http://www.dslreports.com/
forum/r18323368-Comcast-is-
using-Sandvine-to-manage-P2P-
Connections.
the transfer reached a certain threshold, Comcast was terminating
uploads at the boundaries of its network, thus effectively reducing
the cost of the extra connectivity that Comcast itself would have had
to buy from backbone providers.
V ideo streaming. An ISP might also decide to target video streaming
services, as for instance did U.S. wireless carrier MetroPCS in 2011,2 2 MetroPCS 4G Data-Blocking Plans
May Violate Net Neutrality . URL:
http://www.wired.com/2011/01/
metropcs-net-neutrality/
20 inference of network neutrality violations with active me asurements
when it openly blocked all video streaming web sites except for
Y ouT ube and went as far as offering unlimited Y ouT ube access, most
probably following a special agreement between the two providers.
Other times Y ouT ube was negatively impacted by ISPs, as reported in
2011 by hundreds of ﬁxed network users in France 3 and Germany 4 : 3 Respect my net. URL: http://
respectmynet.eu/view/205
4 Respect my net. URL: http://
respectmynet.eu/view/196
the download rate was signiﬁcantly throttled during peak hours in
the evening, up to a point in which, for the case of French opera-
tor Free, resolutions of 720p and 1080p appeared to be blocked and
only 480p seemed to work, even though at a lowered speed. A more
subtle way to degrade performance was observed in 2014 with U.S.
operators Comcast and V erizon, 5 which for months failed to upgrade 5 Netﬂix performance on V eri-
zon and Comcast has been
dropping for months, 2013.
URL: http://arstechnica.com/
information-technology/2014/02/
netflix-performance-on-verizon-
and-comcast-has-been-dropping-
for-months
their peering infrastructure despite a general increase in NetFlix traf-
ﬁc. This was the consequence of a dispute between the two ISPs and
NetFlix and resulted in a worse video experience for NetFlix users.
Another example of an ISP targeting video services is that of French
mobile operator Bouygues, 6 which in 2011 was found to be intercept-
6 Bouygues télécom ﬁltre malhonnête-
ment son réseau 3G et inspecte vos
données. URL: http://grapsus.net/
blog/post/Bouygues-Telecom-
filtre-malhonnetement-son-reseau-
3G-et-inspecte-vos-donnees
ing users’ HTTP requests for ﬂash videos that exceeded 20 MB, to
which it would respond with a 403 Forbidden HTTP error message;
furthermore, all TCP connections exceeding 10 MB were terminated.
V oice-over-IP . Impairment of V oIP has been the objective of some
ISPs that offer a similar voice service. For instance, in 2005 a regional
ISP in the U.S. blocked all trafﬁc of V oIP application V onage; 7 uproar 7 V onage says broadband
provider blocks its calls. URL:
http://www.cnet.com/news/vonage-
says-broadband-provider-blocks-
its-calls/
among customers urged V onage to ﬁle a complaint to the Federal
Communications Commission (FCC), which eventually condemned
such practice. Between 2007 and 2009, A T&T obtained from Apple a
complete block of all V oIP applications on the iPhone, 8 until in 2009 8 Group asks FCC to probe
iPhone Skype restrictions. URL:
http://fortune.com/2009/04/03/
group-asks-fcc-to-probe-iphone-
skype-restrictions/
it ﬁnally allowed Skype, even if only when the device was connected
to WiFi. More recently , in 2012 A T&T customers owning an iPhone
had Apple’s video-calling application FaceTime blocked, unless they
opted for a more expensive data plan. 9 WhatsApp calls, Skype and 9 A T&T blocking iPhone’s FaceTime
app would harm consumers and
break net neutrality rules. URL:
http://www.freepress.net/press-
release/99480/att-blocking-
iphones-facetime-app-would-
harm-consumers-and-break-net-
neutrality
Viber are currently blocked in the United Arab Emirates, where the
telecommunications authority delegated to the two licensed telecom
providers of the country the power to allow or not V oIP services
through their networks. 10
10 WhatsApp V oice Calling Already
Banned by UAE’s Etisalat: Report.
2015. URL: http://gadgets.ndtv.com/
apps/news/whatsapp-voice-calling-
already-banned-by-uaes-etisalat-
report-672283
Redirection of search queries. An ISP could also have its own search
engine and might want to redirect customers to it. This is what
Windstream Communications, a U.S. DSL provider , did in 2010 when
it was found to redirect to its own search engine all queries that
were made using the Google toolbar in web browser Firefox. 11 By 11 Phone Company Helps Make
the Case for Net Neutrality . URL:
http://www.savetheinternet.com/
blog/10/04/05/phone-company-
helps-make-case-net-neutrality
using Deep Packet Inspection (DPI), the ISP was able to intercept
users’ search requests to Google, prevent them from reaching the
actual destination, and provide its customers with the result of its
own search engine to the same query . In 2012 a dozen U.S. ISPs
were reported to hijack queries that included speciﬁc keywords and
redirect them through afﬁliate networks, in order monetize on those
particular searches. 12 12 Widespread Hijacking of Search
T rafﬁc in the United States. URL:
https://www.eff.org/deeplinks/
2011/07/widespread-search-
hijacking-in-the-us
chapter 2 . context and related work 21
VPN’s. VPN’s might have their speed throttled too, regardless of
the trafﬁc they carry (since it is encrypted). This was the case in
2014 of Comcast subscribers who wanted to run OpenVPN with its
default conﬁguration (UDP trafﬁc over port 1194) and experienced a
strangely low speed, which doubled as soon as they switched to TCP
and a different port number . 13 13 I just doubled my PIA VPN through-
put that I am getting on my router by
switching from UDP: 1194 to TCP: 443.
URL: http://www.reddit.com/r/VPN/
comments/1xkbca/i_just_doubled_my_
pia_vpn_throughput_that_i_am
2.2 Internet Neutrality
The cases described in Section 2.1 are clear examples of ways an
Internet service provider can tamper with user trafﬁc and discrimi-
nate certain applications. This is against the end-to-end principle in
general and network neutrality in particular . The end-to-end design
principle of network communications 14 states that all application- 14 J. H. Saltzer , D. P . Reed, and D. D.
Clark. End-to-end Arguments in Sys-
tem Design. ACM T rans. Comput. Syst. ,
2(4):277–288, November 1984
speciﬁc functions should be implemented on end hosts and inter-
mediate nodes are exclusively in charge of forwarding packets and
delivering them to the destination. Internet neutrality , a term ﬁrst
coined by Tim Wu 15 in 2003 but a long-standing implicit principle, 15 Tim Wu. Network neutrality , broad-
band discrimination. Journal of T elecom-
munications and high T echnology law ,
2:141, 2003
goes one step further: 16
16 http://www.timwu.org/network_
neutrality.html
“
...a maximally useful public information network aspires to treat all
content, sites, and platforms equally . This allows the network to carry
every form of information and support every kind of application.
Tim Wu
”
While there are different interpretations of this principle, from
a radical one stating that all incoming packets should be treated
equally by a network, to a looser one according to which similar
applications should experience similar performance, what we are in-
terested to verify in this thesis is that no trafﬁc ﬂow is offered sig-
niﬁcantly degraded performance compared to the rest of the user
trafﬁc.
2.2.1 Arguments in favour
A neutral Internet, as advocated for example by non-proﬁt organi-
zation Save The Internet 17 , would foster competition and innovation 17 www.savetheinternet.com
in Internet contents, since the success or failure of online companies
has always been dictated by the quality of the services they offer and
not by special deals with ISPs. The risk of a non-neutral Internet is
to switch from a model where ISPs simply provide the infrastruc-
ture of a “dumb” network, as according to the end-to-end principle,
to a model where they play the role of gatekeepers, deciding which
contents are granted a faster access and which are not. Indeed, with
the exception of court orders, an ISP should not enforce any control
over the data it forwards. From a less technical point of view , a non-
neutral Internet would ultimately harm free speech and democratic
participation in the W eb, 18 thus undermining its original aspiration
18 Lawrence Lessig and Robert W .
McChesney . No T olls on The
Internet. June 2006. URL:
http://www.washingtonpost.com/
wp-dyn/content/article/2006/06/07/
AR2006060702108.html
to offer a wide variety of independent sources of information and to
generate innovative contents. Vint Cerf, 19 co-inventor of TCP/IP and 19 Vint Cerf speaks out on
net neutrality . URL: https:
//googleblog.blogspot.fr/2005/
11/vint-cerf-speaks-out-on-net-
neutrality.html
22 inference of network neutrality violations with active me asurements
an advocate of neutrality , also points out that with little competition
among broadband providers, as it is the case in the U.S. market, a
non-neutral Internet would put in the hands of a few the power of
affecting what people do and see.
Tim Wu, 20 one of the most active scholars in the debate, claims 20 Tim Wu. Network neutrality , broad-
band discrimination. Journal of T elecom-
munications and high T echnology law ,
2:141, 2003
that the Internet inherently aspires to neutrality , however imperfect
that might be. According to Wu, the end-to-end principle, a key
design idea of the Internet, is proof of this. He continues to observe
that the diversity of applications running on the Internet, each one
with different requirements, makes it difﬁcult to defend a deﬁnition
of neutrality regardless of applications; it is more logical to think of a
neutral network as one that enforces equal treatment among similar
applications.
2.2.2 Arguments against
On the other hand, opponents of network neutrality claim that band-
width prioritization is necessary for future innovation, as ISPs are
more inclined to improve and modernize their networks if they have
additional revenues, especially if coming from content providers like
Y ouT ube or Netﬂix that base their business on a massive use of net-
work bandwidth and could be accused of free-riding the existing net-
work infrastructure. Another argument against enforcing network
neutrality rules is that throughout the history of the Internet, there
has never been a true level-playing ﬁeld, since large companies have
always had an advantage over smaller ones by the deployment of
replicating servers and the purchase of high-bandwidth services.
Jon Crowcroft further elaborates on this, 21 stating that historically
21 Jon Crowcroft. Net neutrality: the
technical side of the debate: a white pa-
per . SIGCOMM Comput. Commun. Rev. ,
37:49–56, January 2007
Jon Crowcroft. T alk on Net
Neutrality , December 2006. URL:
"http://www.cl.cam.ac.uk/~jac22/
talks/neut.ppt.gz"
Jon Crowcroft. T alk on Newt
or Notrality , July 2011. URL:
"https://www.cl.cam.ac.uk/~jac22/
talks/notrality.ppt"
the Internet has never been made of just “dumb pipes”; on the con-
trary , it comprises or depends already on a number of elements that
directly alter its performance and accessibility: TCP throughput and
its dependence on round trip time (and thus on the distance between
a server and a user), making cache and proxy servers essential to
give a signiﬁcant advantage to companies that deploy them; inter-
domain routing algorithm BGP natively supporting routing discrim-
ination; NA T s and ﬁrewalls effectively cutting out portions of the
Internet. Moreover , services like V oIP , IPTV , videoconferencing and
online games come with expectations in performance and sometimes
with a cost for users, in which case it is the users themselves that
would demand that such services be prioritized.
Pappas et al. 22 claim that a strong deﬁnition of network neutrality , 22 Christos Pappas, Katerina Argyraki,
Stefan Bechtold, and Adrian Perrig.
T ransparency Instead of Neutrality . In
Proceedings of the 14th ACM Workshop
on Hot T opics in Networks , HotNets-XIV ,
pages 22:1–22:7. ACM, 2015
in which all packets should be treated equally by a network, is not
only unrealistic, but also not at all desirable: applications with dif-
ferent needs, having for instance latency or bandwidth constraints,
naturally result in better Quality of Experience (QoE) for users if
treated accordingly across the network. Rather then enforcing im-
practical rules on ISPs, it is more important to ask them for increased
transparency about their trafﬁc management practices.
Indeed - whatever the position - it is generally agreed that any
chapter 2 . context and related work 23
action taken by an ISP to discriminate trafﬁc should be made public,
so that users can make an informed decision and freely choose the
provider that best suits their needs. T ransparency is therefore what
we also advocate here.
2.3 T rafﬁc differentiation
In order to discriminate a ﬂow , a shaper has to perform two steps,
involving ﬁrst the identiﬁcation of the ﬂow it wants to affect and
then the application of the desired differentiation technique to it.
1. Flow identiﬁcation. An incoming packet can be associated to a
known application by inspecting its IP header (source and desti-
nation IP addresses), its transport protocol header (port numbers),
or its application payload. In this last case, devices are said to ap-
ply Deep Packet Inspection (DPI). Additional criteria can be taken
into account by an ISP , such as time of the day (for example during
peak hours), network load (if the network is congested), or even
user behaviour (in case of heavy bandwidth usage).
2. Differentiation. Once a packet has been identiﬁed as belonging to a
certain application that is meant to receive different treatment than
regular trafﬁc, a variety of differentiation techniques are possible.
Packets of a ﬂow can be entirely dropped, as in the case of port
blocking; they can be deprioritized in order to decrease the overall
ﬂow throughput; their rate can be shaped with token or leaky
bucket-like techniques; they can be subject to a ﬁxed or variable
dropping rate; or they can be routed over a slower link. An ISP can
also cause a lower throughput to a ﬂow or block it by interfering
with it directly at the transport and application layers: at the TCP
layer , it can reduce the advertised window size by overwriting
the corresponding header ﬁeld, or it can inject a TCP RST packet
in order to terminate the connection; at the application layer , it
can for example intercept HTTP requests and inject HTTP error
messages that effectively impair the download of the requested
resource (as seen in Section 2.1). Still at the application layer , an
ISP can redirect HTTP requests to servers of its choice. 23 23 This is a form of differentiation that
does not necessarily alter the perfor-
mance of a ﬂow , but modiﬁes the con-
tents requested by a user without the
user ’s consent.
While all these techniques can overlap with trafﬁc management
practices, they constitute violations of Internet neutrality when they
are used to purposely offer worse performance to selected ﬂows.
The First-Come-First-Serve (FCFS) service policy might not yield
the best results in case of contention of network resources with cer-
tain types of trafﬁc, for example for network control and manage-
ment. This is why trafﬁc differentiation has been integrated into
Internet protocols right from the beginning, with the T ype of Ser-
vice (T oS) 24 ﬁeld of the IP header originally allowing applications to 24 P . Almquist. RFC 1349: T ype of
Service in the Internet Protocol Suite.
1992. URL: https://tools.ietf.org/
html/rfc1349
indicate the quality of service desired along the network path. The
T oS ﬁeld was later redeﬁned as Differentiated Services Code Points
(DCSP),25 which allowed to specify the requested per-hop behaviour . 25 S. Blake, F . Baker , and D. Black. RFC
2474: Deﬁnition of the Differentiated
Services Field (DS Field) in the IPv 4
and IPv 6 Headers. 1998. URL: https:
//tools.ietf.org/html/rfc2474
24 inference of network neutrality violations with active me asurements
While today’s end-user applications do not use this ﬁeld anymore, it
is still extensively used by ISPs to mark incoming packets and map
them to different internal routes before forwarding them to an exter-
nal network. It is worth noting, however , that there has never been
a homogeneous end-to-end usage of the DSCP ﬁeld across different
network operators, for engineering and economic reasons.
More generally , every network architecture today includes ways
of differentiating trafﬁc, 26 especially to handle congestion events, but 26 BIT AG T echnical W orking Group.
Differentiated T reatment of Internet
T rafﬁc. 2015also to limit a user ’s bandwidth to their purchased rate, to offer bet-
ter performance to IP-based services offered by the ISP (e.g., IPTV
and carrier grade voice) and to comply with the QoS parameters of
Service Level Agreements (SLAs) for business connectivity services.
2.4 Legislative efforts
Historically , the idea of neutrality in a communication network came
about in 1860 with a US federal law stating that “messages from any
individual, company , or corporation, or from any telegraph lines”
should be “impartially transmitted in the order of their reception,
excepting that the dispatches of the government shall have prior-
ity”.27 Nevertheless, it is only in the last dozen years that the idea 27 http://cprr.org/Museum/Pacific_
Telegraph_Act_1860.htmlof guaranteeing neutrality inside the Internet drew considerable at-
tention from the media, the research community (for the technical,
economical and legislative aspects it entails) and also law makers.
The ﬁrst countries to approve laws that explicitly enforce network
neutrality in the Internet were Chile 28 in 2010 and the Netherlands 29 28 Chile, primer país en incorporar la
neutralidad en la red. URL: http:
//www.elmundo.es/elmundo/2010/07/
16/navegante/1279272468.html
29 Net neutrality enshrined
in dutch law . URL: http:
//www.theguardian.com/technology/
2011/jun/23/netherlands-enshrines-
net-neutrality-law
in 2012. In the United States, after a 5-year-long debate, 30 network
30 https://www.whitehouse.gov/net-
neutrality
neutrality rules were ﬁnally approved in February 2015, prohibiting
arbitrary blocking and throttling of services, and increasing trans-
parency at the access ISP and in backbone networks. 31 In France,
31 FCC. Protecting and promoting
the open internet. April 2015. URL:
https://www.federalregister.gov/
articles/2015/04/13/2015-07841/
protecting-and-promoting-theopen-
internet
following a national T elecoms Package of 2009, the National Regula-
tory Authority ARCEP 32 was assigned increased powers in the mon-
32 Autorité de régulation des commu-
nications électroniques et des postes.
http://www.arcep.fr/
itoring of network neutrality and issued a series of recommendations
for ISPs in 2010 and 2012.
In the European Union, a review of the European T elecoms Pack-
age in 2009 introduced the ﬁrst provisions for increased transparency
and started discussions about more comprehensive regulations, which
were approved in October 2015 and have been effective since 30th
April 2016. Thanks to this, the European legislation now (i) forbids
any discriminatory treatment of Internet trafﬁc and guarantees the
right of all users to access and distribute contents of their choice;
(ii) limits the circumstances under which an ISP can apply restric-
tive trafﬁc management policies to its network (for example in case
of congestion, exceptional security threats or speciﬁc court orders);
(iii) states explicitly that optimized services should not degrade the
performance of regular trafﬁc; (iv) calls for monitoring of the com-
mercial practices of ISPs and (v) strengthens the transparency obli-
gations of ISPs, especially pertaining trafﬁc management. The text
mandates that the National Regulatory Authorities (NRAs) should
chapter 2 . context and related work 25
be in charge of enforcing these rules.
However , currently there is no general consensus on how NRAs
should verify that ISPs do not apply any discriminatory practices to
user trafﬁc. For example, a NRA could decide to adopt a reactive
approach, by expecting users to ﬁle reports and act upon them, or to
have a proactive approach, in which measurements should be per-
formed on each ISP operating on the national territory . NRAs also
face the problem of selecting the tools to run such measurements.
It has been observed 33 that NRAs inside the European Union have 33 Ioannis Koukoutsidis. Public QoS
and net neutrality measurements. Jour-
nal of Information , 5, 2015adopted a variety of measurement tools, 34 most of which simply fo-
34 BEREC. Annex of monitoring
quality of internet access services in
the context of net neutrality . BEREC
Report BoR ( 14) 117, September 2014.
URL: http://berec.europa.eu/eng/
document_register/subject_matter/
berec/download/1/4602-monitoring-
quality-of-internet-access-se _
1.pdf
cus on network troubleshooting to conduct their veriﬁcations, and
among the tools proposed by the research community (which we re-
view in details in Section 2.5) only one, NANO, has been adopted
by a handful of European NRAs. Nonetheless, the Body of Euro-
pean Regulators of Electronic Communications (BEREC) 35 has been
35 http://berec.europa.eu/
releasing a number of documents providing NRAs with recommen-
dations and best practices on how to enforce network neutrality and
when to intervene. A framework for the evaluation of Quality of
Service (QoS) has been discussed, as well as when and how mini-
mum QoS requirements should be set. 36 Also, guidelines have been 36 BEREC. A framework for Qual-
ity of Service in the scope of Net
Neutrality . BEREC Report BoR ( 11)
53, December 2011. URL: http:
//berec.europa.eu/eng/document_
register/subject_matter/berec/
download/0/117-a-framework-for-
quality-of-service-in-th _0.pdf
provided on a few key problems: 37 (i) what the regulatory is-
37 BEREC. Guidelines for qual-
ity of service in the scope of net
neutrality . BEREC Report BoR ( 12)
131, November 2012. URL: http:
//berec.europa.eu/eng/document_
register/subject_matter/berec/
download/0/1101-berec-guidelines-
for-quality-of-service- _0.pdf
sues are with regard to QoS and Internet neutrality; (ii) which in-
stances of service degradation require further investigation by NRAs
and (iii) when regulatory intervention is necessary . More recently , a
BEREC report also discussed 38 the requirements for network mea-
surements to have legal value and described possible measurement
methodologies, which could be hardware or software based, target-
ing an ISP or going up to Internet Exchange Points (IXP’s), using
active or passive techniques and applicable to ﬁxed, wireless and
mobile setups. The ultimate goal is to reach a convergence of met-
rics and methods across European countries, so as to have a uniform
framework and allow cross-country measurements.
2.5 T ools for the detection of trafﬁc differentiation
A number of methods for the detection of trafﬁc differentiation have
been proposed in recent years in the literature. When performing
measurements, one can do it passively , by collecting information
from existing user trafﬁc, or actively , by injecting trafﬁc on the net-
work and carrying out measurements on it. Among the proposed
tools that detect trafﬁc differentiation, NANO (Section 2.5.6) is the
only one using passive measurements, while all other ones use ac-
tive probing. Among these, relative discrimination is the most com-
mon technique: an application ﬂow mimicking the behaviour of an
application to test and a reference (or baseline) ﬂow that is not sup-
posed to experience differentiation are replayed between a user and
a measurement server . By comparing the performance of the two
ﬂows, one can infer whether the application ﬂow has been differen-
tiated. This is the technique adopted, with various modiﬁcations in
26 inference of network neutrality violations with active me asurements
their methodology , in BT-T est (Section 2.5.1), Glasnost (Section 2.5.2),
DiffProbe (Section 2.5.3), ShaperProbe (Section 2.5.4), Packsen (Sec-
tion 2.5.5), NetPolice (Section 2.5.8) and Differentiation Detector (Sec-
tion 2.5.7), which is also the only tool that is implemented speciﬁcally
for mobile networks. Zhang et al. (Section 2.5.9) on the other hand
proposed a model that show when it is feasible to observe and local-
ize violations of network neutrality . Finally , Neubot (Section 2.5.10)
does not directly infer neutrality violations, but routinely collects
measurements from end users in order to have a global picture to
monitor over time.
T able 2.1 summarizes the key aspects of each methodology , which
we assess globally in Section 2.5.11.
2.5.1 BT-TEST
Reports on BitT orrent discrimination being performed at the time by
Comcast in the United States were largely covered by Internet me-
dia.39 Regular users, though, did not have tools to evaluate whether 39 Packet forgery by ISPs: A report
on the comcast affair . URL: https:
//www.eff.org/wp/packet-forgery-
isps-report-comcast-affair
their ISP was differentiating BitT orrent trafﬁc. The few existing network-
troubleshooting tools required expert knowledge in order to be ap-
plied to this particular differentiation case.
BT-T est40 enables users to verify whether: (i) their ISP is block- 40 Marcel Dischinger , Alan Mislove, An-
dreas Haeberlen, and Krishna P . Gum-
madi. Detecting BitT orrent Blocking.
In Proceedings of the 8th ACM SIG-
COMM Conference on Internet Measure-
ment (IMC’ 08), V ouliagmeni, Greece,
October 2008
ing BitT orrent trafﬁc using forged RST packets; (ii) their ISP is able
to identify BitT orrent ﬂows by looking at port numbers, BitT orrent
protocol messages, or both and (iii) differentiation affects uploads,
downloads, or both.
The tool checks for RST packet injection and only tests BitT orrent
ﬂows.
Outline of the method. BT-T est replays eight different ﬂows between
the user and a measurement server . Flows vary in the TCP port num-
ber ( 6881, a well-known BitT orrent port, or 4711, not associated with
any protocol) the direction (upstream or downstream) and the ap-
plication payloads (BitT orrent-like or randomized but with the same
size and ordering as in BitT orrent ﬂows). Each of the eight resulting
combinations is run twice and lasts 10 seconds. The server performs
a complete link-level packet capture, thus avoiding the burden of re-
quiring administrator privileges on the client side, where the user
simply runs a Java applet. The client only keeps track of Java excep-
tions with error messages of interest.
Differentiation is detected when (i) the server-side packet trace
contains at least one incoming RST packet and (ii) IO exceptions sig-
naling a terminated connection are seen by the applet. By examining
the results obtained in each test, the tool identiﬁes how the ISP clas-
siﬁes ﬂows as BitT orrent, that is to say whether the discrimination is
based on the port number or on the protocol messages, and whether
it affects upstream or downstream BitT orrent ﬂows.
chapter 2 . context and related work 27
Results from tests in the wild. It was found that Comcast blocked up-
loads only when a user had ﬁnished the download of a ﬁle and up-
loaded it altruistically . As for ﬂows identiﬁed as BitT orrent through
inspection of message protocols, by looking at the ﬂow trace on the
server it was possible to determine at which point of the message
exchange the ISP triggered differentiation. Interestingly , contrary to
what some ISPs had claimed at the time, no differentiation during
peak-hours was evident from the large sample of gathered tests.
User’s point of view. The user starts the test trough a Java applet
included in a dedicated web page, waits for the test to complete and
then results are immediately displayed. The tool is not currently
available, as it was superseded by Glasnost (Section 2.5.2).
2.5.2 Glasnost
With no tool at the time being suitable to be used by the large public,
Glasnost41 aims to be a widely-usable tool whose primary focus is 41 Marcel Dischinger , Massimiliano
Marcon, Saikat Guha, Krishna Gum-
madi, Ratul Mahajan, and Stefan
Saroiu. Glasnost: Enabling End Users
to Detect T rafﬁc Differentiation. In
Proceedings of the 7th Symposium on
Networked Systems Design and Imple-
mentation (NSDI) , San Jose, CA, Apr
2010
non-savvy users.
The three main design principles are:
• Low barrier of use (simple and intuitive interface, no installa-
tion of additional software required, no administrative privileges
needed, quick computation of results, results immediately dis-
played to the user).
• Accuracy of results and no space for misinterpretation (reducing
the effects of confounding factors, minimizing false positives at
the expense of false negatives and retaining positive results in case
the tool is challenged to justify its ﬁndings).
• Easiness of evolution (extendibility of the system and avoiding
white-listing).
Outline of the method. The tool emulates an application ﬂow and a
reference ﬂow , of which only the latter should trigger differentia-
tion, if any shaper is deployed along the path. The difference be-
tween the two ﬂows is on port numbers and application payload,
whereas all ﬁelds at the IP layer remain unchanged. Glasnost in-
terleaves these two ﬂows and sends them between the user and a
measurement server 5 times. Each ﬂow lasts 60 seconds to allow
TCP to achieve a stable throughput. Since throughput in TCP is di-
rectly affected by any differentiation technique, that is what the tool
compares between the two ﬂows.
T wo steps are involved in the analysis:
1. Noise ﬁltering . In order to identify noisy paths, the tool analyzes
the variance of throughput of the two ﬂows. Noise is calculated
as the difference between maximum and median throughput, di-
vided over the maximum throughput. All tests affected by high
28 inference of network neutrality violations with active me asurements
noise are discarded. From empirical tests, up to a 20% of differ-
ence between median and maximum throughput is to be expected
in the absence of considerable noise.
2. Differentiation detection. The idea is that in scenarios with low
noise, most throughput measurements lie close to the maximum
throughput. Since noise tends to lower the throughput, the maxi-
mum throughput is a good approximation of the throughput that
ﬂows could achieve without cross trafﬁc. In the ﬁrst implemen-
tation of the tool, differentiation is inferred when the maximum
throughput of the two ﬂows differs by more than 20%. In such
version of Glasnost the total duration of the test was 20 minutes,
which proved to be too long for most users, who abandoned the
test before its completion. The test duration was then reduced
down to 6 minutes and the minimum difference between maxi-
mum ﬂow throughputs for differentiation detection was increased
to 50%, in order to minimize false positives.
Results from tests in the wild. The ﬁrst test implemented in Glasnost
checked whether ISPs differentiated BitT orrent ﬂows based on con-
tent or port numbers, downstream or upstream. 21% of users were
affected by differentiation and not all customers of the same ISP
which performed differentiation were affected. Detailed results are
available online, sorted by country and ISP . 42 42 http://broadband.mpi-sws.org/
transparency/results/
User’s point of view. A user needs to go on the Glasnost web page 43 43 http://www.measurementlab.net/
tools/glasnost/(hosted by M-Lab 44 ) and select an application ﬂow to test. The test
44 Measurement Lab is an open plat-
form for researchers to deploy Inter-
net measurement tools. URL: http:
//www.measurementlab.net
Constantine Dovrolis, Krishna Gum-
madi, Aleksandar Kuzmanovic, and
Sascha D. Meinrath. Measurement lab:
overview and an invitation to the re-
search community . SIGCOMM Comput.
Commun. Rev. , 40:53–56, June 2010
is carried out through a Java applet, for a total duration of 6 minutes,
after which the results are displayed. Currently , available tests are:
BitT orrent, eMule and Gnutella for peer-to-peer applications; ﬂash
video for video streaming applications; POP , IMAP 4, HTTP transfer ,
SSH transfer and Usenet for more generic services.
Advanced users are provided with a tool 45 which automatically
45 http://broadband.mpi-sws.org/
transparency/createtest.html
generates a new Glasnost test from the packet-level trace of an appli-
cation. It extracts packet size, payload, order of packets exchanged
and inter-packet timing. The output is used directly by the Glasnost
applet. The application ﬂow preserves ordering at the expense of
timing, since it is assumed that ISPs usually identify applications by
looking only at the sequence of protocol messages. The reference
ﬂow differs from the application ﬂow in its payloads and port num-
bers. The user uploading the trace can set port numbers to speciﬁc
values, otherwise they are randomly chosen.
2.5.3 DiffProbe
Starting from the assumption that any form of discrimination results
in high delays or high loss rates, the goal of DiffProbe 46 is to detect 46 Partha Kanuparthy and Constantine
Dovrolis. Diffprobe: detecting ISP ser-
vice discrimination. In Proceedings of the
29th conference on Information communi-
cations, INFOCOM’ 10, pages 1649–1657,
Piscataway , NJ, USA, 2010. IEEE Press
if:
• the trafﬁc of an application is being classiﬁed as low-priority by
an ISP;
chapter 2 . context and related work 29
• the ISP performs delay discrimination, loss discrimination, or both;
• the scheduler type, implementing Strict Priority (SP) or W eighted
Fair Queueing (WFQ), can be identiﬁed.
When no differentiation is taking place, the tool assumes that ISPs
use the First-Come-First-Served (FCFS) scheduling discipline and
DropT ail buffer management policy .
Outline of the method. At ﬁrst, an estimation of upstream and down-
stream path capacities between client and measurement server is per-
formed using trains of packets. Then, an application ( A) and a refer-
ence ( P) ﬂow are sent simultaneously during two replay phases and
one-way delays, as well as the number of lost packets, are measured
for the two ﬂows. Flow A uses a pre-recorded trace of Skype or V on-
age and it keeps the same port numbers, transport protocol, packet
sizes, inter-packet gaps and payloads as in the respective original
application, while the last four payload Bytes are overwritten with
the sender timestamp for easier one-way delay measurement. Flow
P is crafted with the same number of packets and the same packet
sizes as in ﬂow A; payloads are randomized (excluding the sender ’s
timestamp) and port numbers are those not commonly associated
with any service, so that packets are unlikely to be classiﬁed as low
priority . Packets of ﬂow P are sent at about the same time as those
of ﬂow A.
The experiment comprises two phases, which DiffProbe performs
downstream and upstream:
• Balanced Flow Period (BLP). Both ﬂows are sent at their nominal
rates.
• Load Increase Period (LIP). The rate of ﬂow P is scaled up so as to
maximize the chances of queueing in the ISP network. This way ,
ﬂows A and P should saturate the user ’s access link.
The ﬁrst comparison DiffProbe performs is between the 90th-percentile
of delays of ﬂow P during the LIP phase and the median delay of
ﬂow P during the BLP phase. If the former is not signiﬁcantly larger
than the latter , differentiation cannot be detected, since the exper-
iment did not seem to trigger any queueing. The ISP might still
deploy some kind of differentiation, but it has no signiﬁcant effect
on the user ’s trafﬁc.
Delay discrimination detection. The tool ﬁrst checks for equality of
the delay distributions of ﬂow A and ﬂow P during the LIP phase.
It selects only the packets that might have experienced queueing by
considering, for each packet in ﬂow A, the ﬁrst packet in P sent no
later than the transmission time of an MTU-sized packet in the bot-
tleneck link. If no such sample in P exists, this packet of ﬂow A is
discarded. If it does exist, a pair containing the delay of the two sam-
ples (one for ﬂow A, one for ﬂow P) is added to the set of delays to
30 inference of network neutrality violations with active me asurements
analyze. After removing from this set the delays that are too close to
the propagation delay , estimated as the minimum delay of each ﬂow ,
the propagation delay is subtracted from each sample, so that the
resulting delay values will approximate the queueing delays experi-
enced by the packets of the two ﬂows. On these values, the tool runs
the non-parametric Kullback-Leibler (KL) divergence test, which re-
jects the two input sets if they do not follow the same distribution.
When this is the case, DiffProbe goes on to test for inequality of the
two empirical distributions: it checks that all higher percentiles (be-
tween 50th and 95th) of the empirical delay distribution of ﬂow A
are larger than the corresponding ones of ﬂow P. If this holds true,
the tool reports that delay discrimination was applied to ﬂow A.
Furthermore, DiffProbe attempts to identify whether the packet
scheduling algorithm used for differentiation is Strict Priority (SP)
or W eighted Fair Queueing (WFQ). In a SP scheduler , an arriving
P packet will never experience queueing delays due to backlogged
low-priority packets, while in a WFQ scheduler it could. Therefore,
for each burst of P packets the tool now only considers the ﬁrst
packet, which is the only one that is most likely to not have been
backlogged behind other high priority packets. In this subset of P
packets, the tool examines the variability of the delay distribution:
with SP scheduling it should be very small, whereas with WFQ it
should be signiﬁcantly higher .
Loss discrimination detection. DiffProbe also compares the losses of
ﬂows A and P in order to discover discriminatory buffer managers.
T o ensure that the two ﬂows sample the same congestion events, the
same pairing as in the delay analysis is performed. On the resulting
samples, the tool runs the two-proportion z-test for equal population
proportions, which will fail if the loss events in the two ﬂows differ
considerably .
V alidation and results from tests. The tool was validated in a simu-
lated environment. T ests in residential ISPs, located in the US and in
Europe, did not show any differentiation.
User’s point of view. The user chooses between a Skype and a V onage
UDP trace, each 10 minutes long, and launches the test from the
command line. Results are shown upon completion of the test. 47 47 http://netinfer.net/diffprobe/
2.5.4 ShaperProbe
An extension of DiffProbe (Section 2.5.3), ShaperProbe 48 attempts to 48 Partha Kanuparthy and Constantine
Dovrolis. Shaperprobe: End-to-end de-
tection of isp trafﬁc shaping using ac-
tive methods. In Proceedings of the 2011
ACM SIGCOMM Conference on Internet
Measurement Conference , IMC ’ 11, pages
473–482. ACM, 2011
verify whether an ISP is shaping user trafﬁc and, more speciﬁcally ,
if the user connection drops automatically to a low rate after some
time, due to a shaper .
T rafﬁc shaping is modeled as a token bucket, allowing a maximum
burst of trafﬁc to be serviced at the peak capacity of the link, while
any remaining trafﬁc is serviced at a lower rate (i.e. the shaping rate).
chapter 2 . context and related work 31
PowerBoost is an example of a shaper based on such mechanism. 49, 50 49 In the version deployed by Comcast
in the U.S, it allows faster downloads
up to 20 MB of data and faster up-
loads up to 10 MB, after which it de-
creases the speed to the regular pro-
visioned one. Since it increases a
user ’s contractual speed, it is actually
a form of positive shaping. http://
www.dslreports.com/faq/14520
50 Srikanth Sundaresan, W alter De Do-
nato, Nick Feamster , Renata T eixeira,
Sam Crawford, and Antonio Pescapè.
Measuring home broadband perfor-
mance. Communications of the ACM ,
55(11):100–109, 2012
Outline of the method. The capacity of the path between user and
server is estimated in both directions before starting the actual ex-
periment: the sender sends trains of back-to-back packets and the
receiver estimates the path capacity by measuring the dispersion of
each train. Then the sender probes the receiver at a rate equal to
the path capacity . The receiver records the received-rate timeseries
by discretizing time into intervals of duration D and estimating the
receiving rate for each interval as the amount of bits received over
interval D. Probing stops when either the receiver sees a level shift in
the timeseries or the duration of the probing exceeds 60 seconds. The
experiment is carried out in upstream and downstream directions. In
case a level shift is detected, shaping parameters are estimated:
• the shaping rate as the median rate after the level shift;
• the burst size based on the number of Bytes sent before the level
shift.
It is worth pointing out that, since shaping mechanisms like Power-
Boost affect all ﬂows regardless of their origin, the replayed trace
reproduces a single ﬂow which does not belong to any speciﬁc ap-
plication.
V alidation and results from tests in the wild. In order to test the accu-
racy of the method, ShaperProbe was validated on two ISPs where
the shaping ground truth was known and in an emulated wide-area
setup. The measurement server used to be hosted on M-Lab. Re-
sults from M-Lab users showed that U.S. operators Comcast and Cox
were indeed shaping trafﬁc of a large fraction of their users, while
evidence from other U.S. operators only involved between 5 and 10%
of their subscribers who ran DiffProbe.
User’s point of view. The user runs the tool from the command line.
The experiment lasts for about 3 minutes, after which results are
immediately displayed. 51 51 http://netinfer.net/diffprobe/
shaperprobe.html
Passive variant for TCP ﬂows. A passive technique which uses an op-
timized version of ShaperProbe was also proposed. It takes as input
an application packet trace and it is particularly useful whenever an
ISP performs shaping on ﬂows based on packet ﬁelds that are difﬁ-
cult to replicate with active probing to a server , such as destination
and source IP addresses. In order for ShaperProbe to apply to a TCP
ﬂow the authors had to take into account that:
• a level shift in TCP throughput occurs every time TCP decreases
its window due to timeouts or packet losses;
• TCP does not send a constant rate stream, making it difﬁcult to
estimate the number of tokens in the token bucket - indeed, tokens
32 inference of network neutrality violations with active me asurements
can accumulate when the TCP throughput is below the shaping
rate;
• Accumulation of tokens might also happen when shaping kicks
in, as it might trigger TCP back-offs and timeouts.
Therefore it is essential to be able to distinguish throughput level
shifts due to a shaper from those due to TCP back-offs. This is done
by analyzing the variability of a carefully constructed timeseries of
cumulative Bytes received at the receiver .
This passive method was validated using a large set of NDT traces
collected at M-Lab. Also, consistent results were found between
active and passive methods by having the passive variant analyze
ShaperProbe experiment traces.
2.5.5 Packsen
Existing tools either focused on simply detecting the existence of
ﬂow discrimination (BT-T est, Glasnost, NANO) or required relatively
long calculations to obtain accurate results (DiffProbe). Packsen 52 52 Udi W einsberg, Augustin Soule, and
Laurent Massoulié. Inferring trafﬁc
shaping and policy parameters using
end host measurements. In INFOCOM,
pages 151–155, 2011
detects trafﬁc shaping and infers its parameters, with a faster infer-
ence and still high detection accuracy , even in the presence of cross
trafﬁc. As seen in other methods in the literature, it replays an appli-
cation (BitT orrent) and a reference (HTTP) ﬂow , and compares their
performance.
Outline of the method. The experiment is made of up to three phases,
aimed at respectively detecting shaping, inferring the shaper type
and its parameters, and inferring WFQ shaper weights in case of
signiﬁcant cross trafﬁc. The computational cost increases with each
phase.
1. Detection of shaping . T wo short interleaved ﬂows of 20 packets
each are sent to a measurement server . The tool then compares
the distribution of inter-arrival times of the two ﬂows with the
Mann-Whitney U-test, which is accurate also on small samples.
If the test rejects the two ﬂows, the tool infers that shaping took
place and moves to the next phase.
2. Inference of shaper type and parameters. The experiment is repeated,
but with ﬂows of 100 packets each. Packsen then compares the
values observed for sent and received bandwidth; the former is as-
sumed to estimate the sender ’s bandwidth, while the latter should
estimate the bandwidth induced by the shaper . A Strict Priority
(SP) scheduler is recognized when the sent bandwidth dominates
the received bandwidth. If this does not happen, the tool assumes
that the scheduler implements W eighted Fair Queueing (WFQ)
and estimates the ﬂow weights.
3. Inference of WFQ weights with cross trafﬁc. In the presence of heavy
cross trafﬁc, phase 2 does not yield correct results for WFQ sched-
ulers. The tool analyzes the arrival times of selected ﬂow packets
chapter 2 . context and related work 33
from phase 2 and infers WFQ weights, while taking into account
cross trafﬁc, which it models as a Poisson process. The experi-
ment in phase 2 is repeated several times until the variance in the
results is sufﬁciently low .
Results from tests. V alidation was carried out both in a controlled
testbed with emulated cross trafﬁc and with a large set of PlanetLab
nodes.
User’s point of view. The tool is not available for public use.
2.5.6 NANO
Existing tools for detection of trafﬁc differentiation are typically spe-
ciﬁc to an application or focus on a particular differentiation mech-
anism. Also, their use of active probing makes it easy for an ISP
to detect injected measurement ﬂows and treat them accordingly ,
by ether blocking or prioritizing them. Nano 53 overcomes all this 53 Mukarram Bin T ariq, Murtaza Moti-
wala, Nick Feamster , and Mostafa Am-
mar . Detecting network neutrality vio-
lations with causal inference. ACM SIG-
COMM CoNext , page 289, 2009
by performing passive measurements and using causal inference to
quantify the causal relationship between an ISP and the observed
service degradation.
Causal inference. Let the action taken by an ISP be treatment variable
X and let the observed service performance be outcome variable Y.
In order to establish a causal relation between X and Y, all the factors
that might generate interference should be identiﬁed. They could be:
(i) client-based: application, operating system, computer conﬁgura-
tion and the user ’s local network service contract; (ii) network-based:
client and ISP location (with respect to the location of servers on
the Internet), or a path segment to a particular service provider not
sufﬁciently provisioned and (iii) time-based: time of the day , since
service performance might vary widely throughout the day , both for
ISPs and service providers. Once measurements are gathered, they
are divided into strata so as to have in each stratum similar values
for each confounding variable. Within a stratum NANO can easily
compute the measure of the observed effect (the association value),
on outcome variable Y (the service performance), and claim that it
converges to causal effect. Therefore association can be used as a
metric of causal effect within a stratum.
Outline of the method. Instead of attempting to detect a speciﬁc be-
haviour , NANO directly observes the performance of trafﬁc and tries
to infer the causes of degraded performance in case of its occurrence.
A NANO agent resides on an end host, collects trafﬁc data from
it and aggregates trafﬁc statistics that it later sends to a centralized
server . In particular , an agent collects features that help to identify
the client setup, it determines the topological location of the client
and their ISPs and it timestamps all collected data. These will be
the confounding factors sent to the server . An agent analyzes IP ,
34 inference of network neutrality violations with active me asurements
transport and application protocol headers to identify the services
run by the user and for each ﬂow it measures throughput and jitter ,
and counts losses as well as possible incoming TCP RST packets.
A server receives data from the agents and applies the following
actions to detect trafﬁc differentiation:
1. It stratiﬁes the data. Bins (ranges of values) are created for each con-
founding variable. Adjacent strata are combined if the distribution
of outcome variable Y conditioned on the treatment variable X is
identical in more strata.
2. It establishes baseline and causality. It takes as baseline the average
performance of all other clients with similar values for all con-
founding variables except for the access ISP .
3. It infers the discrimination criteria. A decision tree is used to gener-
ate rules indicating the discrimination criteria that the ISP applies.
V alidation. The validation setup included:
• agents running on clients deployed on Emulab hosts, so that con-
founding variables on the client side could be controlled.
• ISPs represented by shapers also running on Emulab hosts, in or-
der to directly apply various discrimination techniques (proba-
bilistic dropping of packets on all ﬂows or on ﬂows exceeding a
certain length, dropping of TCP acknowledgements, dropping of
packets for a particular service or destination, and TCP RST injec-
tion);
• Content providers on PlanetLab nodes, which ensured that exper-
iments used real Internet paths;
• a server on a regular Internet host.
NANO correctly identiﬁed discriminating and neutral ISPs in all val-
idation tests.
Due to the methodology used to infer differentiation, a deploy-
ment of NANO in the wild would require a large user base in order
to correctly establish causal inference.
User’s point of view. NANO agents are voluntarily installed by end
users,54 who are asked to manually provide details about their net- 54 https://noise-lab.net/projects/
old-projects/nano/work interface (wired or wireless), the type of contract with their
ISP and their geographic location. The project appears to have been
discontinued.
2.5.7 Differentiation Detector
Recently Differentiator Detector , 55 a tool for the detection of trafﬁc 55 Arash Molavi Kakhki, Abbas Razagh-
panah, Anke Li, Hyungjoon Koo, Ra-
jesh Golani, David Choffnes, Phillipa
Gill, and Alan Mislove. Identifying traf-
ﬁc differentiation in mobile networks.
In Proceedings of the 2015 ACM Confer-
ence on Internet Measurement Conference ,
pages 239–251. ACM, 2015
differentiation in mobile networks, was proposed. It addresses the is-
sue of scalability to arbitrary applications by fully replaying between
the user and a measurement server a previously dumped ﬂow . It also
chapter 2 . context and related work 35
avoids all sorts of rooting or jailbreaking on a user ’s mobile phone
by moving the task of capturing trafﬁc to a server and by replaying
ﬂows right from the application layer .
Outline of the method. The experiment comprises two phases:
• Dump. At ﬁrst, the user is asked to run on her Android mobile
phone the application she intends to test after connecting to Med-
dle,56 a VPN proxy over IPsec, which relays trafﬁc between user 56 Ashwin Rao, Justine Sherry , Arnaud
Legout, Arvind Krishnamurthy , W alid
Dabbous, and David Choffnes. Med-
dle: middleboxes for increased trans-
parency and control of mobile trafﬁc. In
Proceedings of the 2012 ACM conference on
CoNEXT student workshop , pages 65–66.
ACM, 2012
and destination and dumps the selected application ﬂow . The
VPN proxy then produces a transcript describing the packet ex-
change that took place in downstream and upstream directions,
and the corresponding inter-packet times. This transcript is then
delivered to both the user and a measurement server , so that they
can replicate the behaviour of the selected ﬂow . In the current
version of the tool, this phase is skipped and the user is provided
with a set of pre-recorded traces to replay .
• Replay. User and measurement server replay the ﬂow ﬁrst as it
is, while of course overwriting the original server-side IP address
with the IP address of the measurement server , and then through
an encrypted VPN. The idea is that a shaper that wants to affect a
given application will be able to identify the corresponding ﬂow
when replayed out of the VPN, but not when the packets are en-
crypted. The replay phase is carried out twice to minimize the
effects of possible noise. For TCP ﬂows, throughput and Round-
T rip Times (RTT’s) are measured on the captured trace from the
server side, while for UDP ﬂows the client computes the ﬂow jitter
from the inter-packet timings at the application layer . Losses are
recorded for all ﬂows.
In order to evaluate the performance of the application and the
control ﬂows, that is to say the ﬂows replayed respectively outside
and inside the VPN, the tool ﬁrst runs the two-sample Kolmogorov-
Smirnov test, which assesses the maximum vertical distance between
two empirical CDF’s. Then, the tool applies a tailored test that rejects
the ﬂows if the normalized area between their empirical CDF’s is
greater than a given threshold. The reason behind this is to take into
account also the horizontal distance between the two curves before
declaring that a ﬂow has been differentiated. The analysis on ﬂow
losses simply compares maximum and average ﬂow losses over the
two replays.
V alidation and results from tests in the wild. Differentiation Detector
was validated with two commercial shapers, which correctly identi-
ﬁed application ﬂows and disregarded control ﬂows. The authors of
the tool were able to reverse engineer the ﬂow classiﬁcation mecha-
nism of these two shapers and found out that ﬂows get mostly iden-
tiﬁed as belonging to a particular application with the use of regu-
lar expressions on packet payloads (Deep Packet Inspection) and by
looking at port numbers.
36 inference of network neutrality violations with active me asurements
T ests from users in most major mobile providers in the U.S. showed
cases of shaping for Y ouT ube, NetFlix and Spotify in the ﬁrst semester
of 2015.
User’s point of view. The user needs to install Differentiation Detec-
tor57 from Google Play and then selects one application ﬂow to test 57 http://dd.meddle.mobi/index.html
between Y ouT ube, NetFlix, Spotify , Skype, Viber and Google Hang-
out. The outcome of the test is shown right after the experiment.
2.5.8 NetPolice
As opposed to all other methods so far described, which test a user ’s
access ISP , NetPolice 58 aims at detecting trafﬁc differentiation in back- 58 Ying Zhang, Zhuoqing Morley Mao,
and Ming Zhang. Detecting trafﬁc
differentiation in backbone isps with
netpolice. In Proceedings of the 9th
ACM SIGCOMM Conference on Internet
Measurement Conference , IMC ’ 09, pages
103–115. ACM, 2009
bone ISPs. It selectively probes from a number of hosts ingress and
egress routers of backbone ISPs with TTL-limited packets and an-
alyzes the loss rates observed along the same ingress-egress path
segments. It is able to detect content differentiation based on packet
payloads or port numbers and routing differentiation based on the
next-hop and previous-hop autonomous system (AS).
Outline of the method. The methodology used by NetPolice can be
broken down into three steps:
1. Path selection. Given a set of hosts running NetPolice, the tool
runs traceroute to all preﬁx destinations on the Internet in or-
der to discover which source-destination pairs cross which ingress
and egress routers of backbone ISPs along the path and at which
hops such routers are found. Afterwards the tool selects the set of
paths to test so that it minimizes the number of experiments per
host while still having an exhaustive picture of an ISP ingress and
egress points, probed from various sources and with various IP
destination addresses.
2. Path measurement. Each host is instructed to test a given path a
number of times and does so by sending packets with applica-
tion contents and the speciﬁed TTL values so that they expire at
the targeted ingress and egress ISP routers and generate ICMP
time-exceeded error messages. Probing is performed at a constant
rate of 1 packet per second (pps) for 200 seconds, so as to min-
imize losses due to routers implementing ICMP rate limitation.
Sent packets are the same size ( 200 Bytes) and have port numbers
and application payloads from 5 different applications: BitT orrent,
SMTP , PPLive, V oiP and HTTP .
3. Differentiation detection. For the same pair of ingress and egress
routers, NetPolice computes the per-experiment loss rate of this
internal path by subtracting the ingress loss rate from the egress
loss rate. Then, it veriﬁes whether probes belonging to the ﬁve
applications, coming from different sources and destined to dif-
ferent IP preﬁxes, experienced similar loss rates along this path
segment. In order to detect content-based differentiation, it runs
chapter 2 . context and related work 37
the Kolmogorov-Smirnov (KS) test between the loss rate distribu-
tion of experiments carrying HTTP trafﬁc (used as baseline) to
that of experiments carrying any of the other four tested applica-
tions. Similarly , but regardless of the applications, NetPolice runs
the KS test on the loss rate distribution of experiments traversing
the same AS right before reaching the target ingress-egress pair ,
against the loss rate distribution of experiments that crossed a dif-
ferent AS. It then runs the KS test on the set of experiments routed
to different AS’s after the same ingress-egress path.
Results from tests. A measurement campaign was performed from
200 PlanetLab hosts, targeting 18 backbone ISPs. Content-based dif-
ferentiation was found in 4 ISPs, while routing-based differentiation
was found in 10; the observed difference in loss rates was up to 5%.
Since only a fraction of paths in a given ISP indicated trafﬁc differ-
entiation, it was conjectured that a high network load on a subset
of all internal paths of an ISP might trigger differentiation. By also
analyzing the T ype of Service (TOS) ﬁeld in the quoted IP packet of
returned ICMP time-exceeded messages, a correlation was occasion-
ally found between the observed TOS value and the resulting loss
rates.
User’s point of view. NetPolice is not intended for end users.
2.5.9 Neutrality Inference through Network T omography
Zhang et al. 59 recently proposed a theoretical tomography-inspired 59 Zhiyong Zhang, Ovidiu Mara, and
Katerina Argyraki. Network neutral-
ity inference. In Proceedings of the 2014
ACM Conference on SIGCOMM , SIG-
COMM ’ 14, pages 63–74, New Y ork,
NY , USA, 2014. ACM
framework where they claim that, given the topology of a network
and external end-to-end path measurements over its paths, such ob-
servations are inconsistent with each other when the network is non-
neutral. The authors describe the conditions that are necessary to
observe neutrality violations and to localize them on speciﬁc links,
independently of how trafﬁc differentiation is implemented.
Since network tomography essentially assumes that a network is
neutral and that a neutral link has the same properties for all paths
traversing it, a neutral network can be represented by a solvable sys-
tem of equations where the sum of unknown speciﬁc link properties
of a given path equals a measured metric on that path. The insight of
this work is that if such system is unsolvable, it indicates a possible
neutrality violation.
Outline of the model. The proposed model can be split into three
contributions:
1. Observability of neutrality violations. For any network where a neu-
trality violation is detected there exists at least one equivalent
neutral network that, given the same trafﬁc input, would cause
the same external observations as in the original non-neutral net-
work. This equivalent neutral network is constructed so that any
non-neutral link in the original non-neutral network is split into
38 inference of network neutrality violations with active me asurements
two links: (i) a regular link that retains the same properties that
originally applied to non-differentiated trafﬁc, and (ii) an extra
link, called virtual link, inserted in such a way in the network
topology that only differentiated trafﬁc ﬂows through it and has
the same properties originally applied to differentiated trafﬁc. The
model claims that a neutrality violation is externally observable if
and only if the equivalent neutral network contains at least one
virtual link that is distinguishable from any link in the original
non-neutral network. That is to say , if there is at least one virtual
link whose set of paths traversing it differs from the sets of paths
traversing all other links in the original network.
2. Localization of neutrality violations. Once a network has been de-
tected to be non-neutral, the non-neutral links can be pinpointed
to a link sequence of the original network, as long as this link
sequence is crossed by a sufﬁciently diverse number of paths. A
system of equations is constructed as described above, but only
over the network slice containing the suspected link sequence. If
this system is unsolvable, then the link sequence is non-neutral.
3. Algorithm. Zhang et al. ﬁnally proposed an algorithm that, given
as input the topology of a network and the results of measure-
ments over its paths, it outputs any non-neutral link sequences. It
ﬁrst checks for observable neutrality violations and then attempts
to localize them by verifying, for each link sequence, the unsolv-
ability of the system of equations composed of pairs of paths that
intersect exactly at this link sequence.
V alidation. The method was validated in an emulated environment,
ﬁrst in a simpler case with only one shared link, where the shaper
was deployed, and then in a more complex case with several shared
links. The algorithm proved to produce no false negatives or false
positives in both scenarios.
User’s point of view. It is not intended for end users.
2.5.10 Neubot
A project that differs from the ones thus far described is Neubot 60 , 60 Simone Basso, Antonio Servetti, and
Juan Carlos De Martin. The network
neutrality bot architecture: a prelimi-
nary approach for self-monitoring of
Internet access QoS. In Computers and
Communications (ISCC), 2011 IEEE Sym-
posium on , pages 1131–1136. IEEE, 2011
which monitors the access link of users by regularly running dis-
tributed performance measurements and collects the data on a cen-
tralized server , where results are made available to researchers for
later use. The tool does not explicitly infer neutrality violations.
Outline of the method. The tool regularly performs four transmission
tests from end users, in the background. A vailable tests are HTTP ,
BitT orrent, raw TCP and DASH (Dynamic Adaptive HTTP stream-
ing). Every 30 minutes, Neubot measures upstream and downstream
throughput, as well as the Round-T rip Time (RTT) over the four tests.
chapter 2 . context and related work 39
Results from tests. No global analysis with respect to trafﬁc differen-
tiation has been provided to this date. A comparison of throughput
and RTT between access ISPs in the T urin area was published, but
no further analysis was made. An aggregate study of available data
over time and over different ISPs would be an added value to the
project.
User’s point of view. The user needs to install the tool, 61 which runs 61 http://www.neubot.org/
measurement tests periodically and upon user request. Users can
also view statistics of the quality of their link over time on a dedi-
cated web page.
2.5.11 Discussion
The main features of each of the reviewed methodologies are sum-
marized in T able 2.1 for a more direct comparison.
W e saw that most of the methods in the literature that make use
of active measurements rely on the joint replay of an application
and a control ﬂow , of which a shaper targeting that same applica-
tion should only affect the former and not the latter . This is the case
of BT-T est, Glasnost, DiffProbe, Packsen, NetPolice and Differentia-
tion Detector . This technique has a non-negligible drawback, since it
takes for granted that the modiﬁcations applied to the control ﬂow
are such that a shaper will not affect it in any way . In order to create a
control ﬂow , the most common approach is to modify port numbers
or payloads of an application ﬂow . A port number can be modiﬁed
so that it belongs to a different application that is supposed to not
be shaped, as in the case of NetPolice with HTTP , or it can be chosen
within the range of high values not registered for any application, 62 62 Service Name and T ransport Protocol
Port Number Registry . IANA. URL:
www.iana.org/assignments/port-
numbers
as in Glasnost, DiffProbe and Packsen. Expecting that one speciﬁc
service, for instance HTTP , is never shaped, might be true in most
cases, but it is not a robust assumption that could apply to any type
of network. As for high unassigned port numbers, it might not also
be a safe option, as reported by the authors of Differentiator Detec-
tor , who noticed that the two commercial shapers at their disposal
labeled trafﬁc with high port numbers as peer-to-peer . Another pos-
sibility is to randomize packet payloads, since Deep Packet Inspec-
tion (DPI) devices often run regular expression patterns on incoming
packets to match them with known applications. While this would
deﬁnitely avoid DPI classiﬁcation, we cannot assume in advance that
port numbers will not be taken into consideration by shapers in any
network. Differentiation Detector tries to overcome this by replaying
the control ﬂow inside a VPN, but we saw in Section 2.1 that VPNs
too might be the target of differentiation.
Among the tools intended for end users, another common limit is
that they do not scale easily to any application a user might want to
test, even though the underlying methodology is not dependent on
a particular application. The application ﬂow is always provided
directly by the tool developers from a set of pre-recorded traces,
40 inference of network neutrality violations with active me asurements
which is the case of Glasnost, DiffProbe and Packsen. Glasnost works
around this problem by allowing advanced users to create their own
test from traces captured from running applications; it is deﬁnitely
an added value, but it is not an easily scalable solution, since a new
customized test has to be created each time a user wants to test a
new application. Differentiation Detector , on the other hand, should
in principle create a customized experiment from the trafﬁc of the ap-
plication selected by the user , but in the version released up to this
date is only available with a set of pre-recorded traces. ShaperProbe
instead focuses on level shifts in throughput, which for example with
PowerBoost apply to any ﬂow , and therefore it is not concerned with
the type of trafﬁc it replays.
Furthermore, only one application at a time can be tested in all the
reviewed active methods. This is a direct consequence of detecting
differentiation by comparing an application to a control ﬂow . Even
when multiple application traces are provided, a user still needs to
run the tool separately on each one of them in order to test them
all. This is not the case of NANO, the only passive method so far
proposed in the literature: it continuously measures the performance
of all user applications (with the possibility of excluding some for
security reasons) while they run on the end host. The main limitation
in NANO is that, in order for it to correctly infer differentiation, it
needs a very large user base, in the order of thousands according to
its authors.
It must also be pointed out that, if a differentiation detection tool
becomes popular , a replayed pre-recorded application ﬂow can be
easily white-listed by an ISP and offered regular service, thus effec-
tively circumventing the underlying methodology . An experiment
in which the replayed trafﬁc is not the same same across all users
would deﬁnitely represent an advantage.
In the reviewed methods, the metrics analyzed to detect differen-
tiation are mostly throughput, delays and losses. Indeed, the effect
of a shaper on a ﬂow translates into higher delays, possibly more
losses, and consequently an overall lower throughput. Delays and
losses alone already fully capture the effects of a shaping device and
can also provide a better insight on the performance of a ﬂow over
time.
With the tool we propose in this thesis, ChkDiff, we try to over-
come the limitations described above for active methods, as will be
described in Chapters 4 and 5. The approach seen in NetPolice
for backbone networks, making use of TTL-limited probes, is the
most similar in spirit to the upstream experiment in ChkDiff. Before
delving into the details of our methodology , we need to understand
how routers respond to such probes, whether ICMP rate limitation
is prevalent and how it is implemented. W e do this in the next chap-
ter , where we corroborate the validity of measurements using ICMP
time-exceeded feedback from intermediate routers.
chapter 2.context and related work 41
T able 2.1: Comparison of existing methods for the detection of neutrality viola-
tions.
T ool Active
or
Passive
Experiment Measured Met-
rics
Application Speciﬁc? Detection Method A vailability of Re-
sults
Currently
available
BT-T est Active. Replays synthetic control
and application ﬂows, vary-
ing port numbers, direction
(upstream or downstream)
and payload.
TCP RST injec-
tion.
Y es, it only tests BitT orrent
ﬂows.
Checks for RST injection and determines
what factor (port, payload, direction) trig-
gered differentiation.
Immediately . No, but up-
graded by
Glasnost.
Glasnost Active. Replays synthetic control
and application ﬂows, vary-
ing port numbers, direction
(upstream or downstream)
and payload.
Throughput. Y es, but extendable. A vail-
able tests: BitT orrent,
eMule, Gnutella, Flash,
POP , IMAP 4, HTTP trans-
fer , SSH transfer , Usenet.
Checks whether the throughput of the two
ﬂows differs by more than 50%.
Immediately . Y es.
DiffProbe Active. Replays control and appli-
cation ﬂows at original and
sustained rates.
One-way delays,
losses.
No, but limited to the set
of synthetic traces provided
by the authors (Skype, V on-
age).
Checks for delay discrimination by run-
ning Kullback-Leibler test on the delay
distribution of selected packets of the two
ﬂows. Infers scheduler type (SP or WFQ).
Checks for loss discrimination by running
two-proportion z-test on the losses of the
two ﬂows in selected instants of the exper-
iment.
Immediately . Y es.
ShaperProbe Active. Replays a default trace at
the path capacity .
Instantaneous re-
ceived through-
put.
No, but the replayed trace
does not belong to any ap-
plication.
Checks for a level shift in the received
throughput. Estimates shaping rate and
burst size.
Immediately . Y es.
Packsen Active. Replays control and appli-
cation ﬂows, interleaved.
The ﬁrst replay lasts 20 s,
the second one 100 s.
Inter-arrival
times and band-
width.
No, but limited to the syn-
thetic trace provided by the
authors (BitT orrent).
In the ﬁrst experiment, it runs Mann-
Whitney U-test on the distributions of
inter-arrival times of the two ﬂows to de-
tect differentiation. Then, it compares sent
and received bandwidth in the second ex-
periment to infer the scheduler type (SP or
WFQ).
Immediately . Not available.
NANO Passive. It passively measures the
performance of the applica-
tions run by the user .
Throughput, jit-
ter , losses, TCP
RST injection.
No. It compares the user performance to a
baseline of all other users with a similar
setup, location, and time of the experi-
ments, but connected to a different ISP .
Immediately , pro-
vided that a large
enough baseline of
users with similar
characteristics is
available.
Discontinued.
Continues on the next page.
42 inference of network neutrality violations with active measurements
T able 2.1: Comparison of existing methods for the detection of neutrality viola-
tions.
T ool Active
or
Passive
Experiment Measured Met-
rics
Application Speciﬁc? Detection Method A vailability of Re-
sults
Currently
available
Differentiator
Detector
Active. Replays the packet ex-
change of a given applica-
tion through (control ﬂow)
and out (application ﬂow)
of a VPN.
For TCP ﬂows:
RTT’s, through-
put, losses. For
UDP ﬂows: jitter ,
losses.
No, but the current tool
only provides pre-recorded
application traces (Y ouT ube,
Netﬂix, Spotify , Skype,
Viber and Google Hang-
out).
It runs the two-sample Kolmogorov-
Smirnov test on the RTT distribution of
the two ﬂows, as well as a tailored test on
the area between the two CDF curves. It
compares maximum and average losses of
the two ﬂows over two replays.
Immediately . Y es.
NetPolice Active. It probes ingress and egress
routers of a given ISP from
several hosts with TTL-
limited packets.
Losses. No, but limited to the syn-
thetic traces provided by the
authors. A vailable traces:
BitT orrent, SMTP , PPLive
and V oIP . HTTP trace is
used as baseline for content-
based differentiation detec-
tion.
T o detect content-based differentiation on
a given ingress-egress router pair , it runs
the two-sample Kolmogorov-Smirnov test
on the distribution of losses of applica-
tion and control ﬂows, from all the exper-
iments targeting that path segment. Simi-
larly , it runs the same test to detect routing
differentiation based on previous-hop AS
and next-hop AS.
Not intended for
end users.
Not intended
for end users.
T omography-
inspired
model
Active. End-to-end path measure-
ments across all paths of a
given network.
W orks in princi-
ple on any end-
to-end measure-
ment.
No. Given the exact topology of a network,
it forms a system of equations where the
sum of unknown link properties of a given
path equals the measured end-to-end met-
ric along that path. If the system is un-
solvable, the network is not neutral. The
model also tries to identify non-neutral
links.
Not intended for
end users.
Not intended
for end users.
Neubot Active. Four transmission tests to a
server every 30 minutes.
Throughput,
RTT .
No, but limited to the syn-
thetic traces provided by the
authors: HTTP , BitT orrent,
raw TCP and DASH .
It does not directly infer differentiation,
but it monitors a user ’s access link over
time.
Statistics are avail-
able on a dedicated
web page.
Y es.
3
ICMP rate limitation
Several tools proposed by the research community rely on feedback
from intermediate routers in order to infer network characteristics.
T raceroute-based path discovery 1 is a notable example: by sending 1 V an Jacobson. traceroute. URL: ftp:
//ftp.ee.lbl.gov/traceroute.tar.gz
Brice Augustin, Xavier Cuvellier ,
Benjamin Orgogozo, Fabien Viger ,
Timur Friedman, Matthieu Latapy ,
Clémence Magnien, and Renata T eix-
eira. A voiding traceroute anomalies
with paris traceroute. In Proceedings
of the 6th ACM SIGCOMM conference
on Internet measurement , pages 153–158.
ACM, 2006
probes with increasing Time-T o-Live (TTL) values until a given des-
tination is reached, traceroute elicits ICMP time-exceeded errors on
intermediate routers and the whole path to a destination is uncov-
ered. By merging paths to many destinations, we can even infer the
topology of the Internet (e.g. CAIDA ’s skitter project 2 ), or the topol-
2 K Claffy , T racie E Monk, and Daniel
McRobb. Internet tomography . Nature,
7(11), 1999
ogy of speciﬁc ISP networks (e.g. Rocketfuel 3). ICMP feedback from
3 Neil Spring, Ratul Mahajan, and
David W etherall. Measuring ISP topolo-
gies with rocketfuel. ACM SIG-
COMM Computer Communication Re-
view, 32(4):133–145, 2002
routers is also used to discover path performance properties such
as bandwidth and delay . For example, Pathneck 4 tries to localize
4 Ningning Hu, Li Li, Zhuoqing Mor-
ley Mao, Peter Steenkiste, and Jia W ang.
A measurement study of internet bot-
tlenecks. In INFOCOM 2005. 24th An-
nual Joint Conference of the IEEE Com-
puter and Communications Societies. Pro-
ceedings IEEE , volume 3, pages 1689–
1700. IEEE, 2005
and characterize the bottleneck link on a given path, and Pathchar 5
5 Allen B Downey . Using pathchar to
estimate internet link characteristics. In
ACM SIGCOMM Computer Communica-
tion Review , volume 29, pages 241–250.
ACM, 1999
leverages the relationship between transmission time and delay to
infer the bit rate of network links.
The main problem that arises when making use of TTL-limited
probes is that ICMP feedback from routers is often neither instanta-
neous nor entirely reliable. Indeed, as the generation of ICMP error
messages takes place in the slow path of the data plane, manufactur-
ers and operators impose a low priority on it, in order to minimize
the overall load on routers. Other internal tasks mostly related to
the control plane, like route computation and management opera-
tions, might take precedence over it, especially when resources are
shared between slow path and control plane. In addition, in order
to further reduce the impact of ICMP message generation, the re-
sponsiveness to expiring packets is often limited by a hard-wired
or conﬁgurable maximum rate, 6 above which routers simply ignore 6 RA Steenbergen. A practical guide to
(correctly) troubleshooting with tracer-
oute. North American Network Operators
Group, pages 1–49, 2009
any expired packets and stay silent. All these limitations of the ICMP
generation process can have repercussions on measurement tools and
need to be thoroughly understood.
In this chapter , we try to shed light on the way ICMP rate lim-
itation is implemented on routers and analyze its impact on active
measurements. W e proceeded for this purpose with a large-scale
measurement campaign on PlanetLab, where we targeted at various
probing rates 850 routers located at different depths into the network.
Our contributions are the following:
• W e identify an on-off pattern in the way ICMP rate limitation is
44 inference of network neutrality violations with active me asurements
most often implemented and devise a taxonomy of routers ac-
cordingly .
• W e determine the most popular conﬁguration parameters on rate-
limited routers, with respect also to their vendors.
• W e demonstrate that the measured round-trip time for TTL-limited
probes is not correlated with the choice of probing rate.
Developers of measurement tools who might have a concern about
exceeding rate limitation thresholds can draw lessons from our ﬁnd-
ings, as we show that it is relatively easy to observe an answering
pattern and possibly ﬁlter it out. On the other hand, when it is es-
sential to have a high answering rate, it might be of use to know in
advance which settings are the most common across vendors.
For the purpose of the upstream experiment in ChkDiff (Chap-
ter 4), we will see that we can indeed use TTL-limited probes to
measure RTT s and we can send packets at relatively high probing
rates without hitting any capacity limits of routers.
W e presented the results of this chapter in a paper published at
ICC ’ 15.7 7 Riccardo Ravaioli, Guillaume Urvoy-
Keller , and Chadi Barakat. Character-
izing ICMP Rate Limitation on Routers.
In IEEE International Conference on Com-
munications (ICC) , 20153.1 Overview
Before delving into an accurate description of our measurement setup,
we provide upfront two results: one introduces the effect of ICMP
rate limitation on active probes, the other adds an important insight
on the delays obtained.
First, we ask ourselves which fraction of routers is affected by
ICMP rate limitation and at which probing rates this is most evi-
dent. In Figure 3.1, we plot the loss rates that we experienced when
probing a large set of routers with TTL-limited packets at different
sending rates in the range of [ 1, 2543] packets per second (pps). The
loss rate, which we deﬁne as the number of received ICMP time-
exceeded messages over the number of sent probes, is drawn in a
separate bean plot for each probing rate. Bean plots show a scatter
plot of all individual values on top of a kernel density estimate of
the probability density function of the data. Median and mean are
denoted, respectively , by a blue cross and a short green horizontal
line. T wo trends are evident in Figure 3.1: (i) the median loss rate
remains very low for probing rates up to 372 packets per second
(pps) and it progressively increases up to 90% with higher probing
rates; (ii) a non-negligible fraction of experiments shows the above
behaviour already for rates higher than 54 pps. But when exactly
does ICMP rate limitation take place? How is it most commonly im-
plemented and what are the most frequent conﬁgurations? W e will
address these questions in Sections 3.3 and 3.4.
Besides being concerned about collecting a sufﬁcient number of
responses, we are interested to know whether the delay associated
to them is in any way biased by the sending rate that we choose. In
chapter 3 . icmp rate limitation 45
1
 19
 39
 54
 75
 104
 144
 199
 272
 372
 503
 678
 907
 1183
 1552
 2009
 2543
sending rate (pps)
0
20
40
60
80
100
loss rate (%)
all ttls
Figure 3.1: Loss rates for all experi-
ments, arranged by probing rate.
1
 19
 39
 54
 75
 104
 144
 199
 272
 372
 503
 678
 907
 1183
 1552
 2009
 2543
sending rate (pps)
10
-1
10
0
10
1
10
2
10
3
10
4
10
5
mean RTT (ms)
all ttls
Figure 3.2: Mean RTT box plots for all
experiments, arranged by probing rate.
order to verify this, we plot in Figure 3.2 the mean Round-T rip Time
of each experiment, arranged by probing rate (a full description of
the measurement campaign is presented in Section 3.2). The box
plots are self-explanatory: both the medians and the IQRs 8 appear 8 IQR is the Inter-Quartile Range, de-
ﬁned as the difference between the 75th
and the 25th percentiles of the consid-
ered distribution. It corresponds, by
deﬁnition, to the length of the box and
aggregates 50% of the samples.
steady across all the tested probing rates. W e can therefore conclude
that the choice of probing rate has no visible inﬂuence on the average
round-trip time. W e can also observe that a few experiments resulted
in mean values that are far away from the core of the distribution (at
1, 10 and up to 60 seconds). These outliers start to appear at 75 pps
and seem to follow a linear increase. Such behavior was limited to
a dozen routers that persistently behave in this way and constitute
an exception as compared to the rest of routers in our dataset. W e
further discuss the delay distribution in Section 3.5.
3.2 Experimental setup
W e conducted our measurement campaign from 180 PlanetLab hosts,
each of which located at a different site in order to avoid overlapping
measurements. Each run lasted 30 seconds and targeted one single
hop along the path from a PlanetLab host to a ﬁxed IP destination. A
single experiment consisted in sending at a constant rate ICMP echo-
request probes (similar to what the Ping tool uses) with a forged IP
Time-T o-Live (TTL) value, so that the packets would expire on the
router at the desired hop and generate ICMP time-exceeded error
messages. Each sent probe was 28 Bytes in length ( 20 Bytes for the
IP header and 8 Bytes for the ICMP header), with no extra payload
added to the end of the packet.
46 inference of network neutrality violations with active me asurements
Figure 3.3: A typical timeseries for an
on-off rate-limited router .
The choice of ICMP for our probes instead of UDP or TCP fol-
lowed the results by Gunes and Sarac, 9 who showed with large-scale 9 Mehmet H Gunes and Kamil Sarac.
Analyzing router responsiveness to ac-
tive measurement probes. Passive and
Active Network Measurement , pages 23–
32, 2009
measurements that, in comparison, ICMP probes elicit the highest
number of responses. W e decided to target the ﬁrst 5 hops from
each PlanetLab host in order to include in our dataset both edge
and backbone routers. The IP destination address was a public IP
address assigned to a machine in our use. It was kept unchanged
in all probes, thus effectively reaching no more than one router per
hop, except for only 3 cases in which per-packet load balancers were
encountered (a low prevalence in line with what was observed in
large-scale measurements by the authors of Paris T raceroute 10). W e 10 Brice Augustin, Timur Friedman, and
Renata T eixeira. Measuring load-
balanced paths in the internet. In Pro-
ceedings of the 7th ACM SIGCOMM con-
ference on Internet measurement , pages
149–160. ACM, 2007
selected 17 exponentially-spaced sending rates between 1 and 4000
packets per seconds, in order to capture the behaviour of routers at
low and relatively high probing regimes. W e note here that the ma-
jority of PlanetLab hosts could not fully keep up with the desired
sending rates, especially with the highest ones ( > 1500 pps). Conse-
quently in all ﬁgures, for a desired probing rate r, we actually show
the median of all measured sending rates achieved by the Planet-
Lab hosts when instructed to probe at rate r. Every (host , ho p , rate )
tuple was tested 3 times. W e tried to stress routers as little as pos-
sible between experiments by shufﬂing the order of sending rates
and by never choosing the same hop in consecutive experiments.
The measurement campaign was performed in the ﬁrst two weeks of
February 2014 using NEPI, 11 a Python-based library for the deploy- 11 Alina Quereilhac, Mathieu Lacage,
Claudio Freire, Thierry T urletti, and
W alid Dabbous. Nepi: An integration
framework for network experimenta-
tion. In Software, T elecommunications and
Computer Networks (SoftCOM), 2011 19th
International Conference on , pages 1–5.
IEEE, 2011
ment of experiments on network evaluation platforms. Our result-
ing dataset includes over 45000 path measurements and 850 distinct
routers. Only 53 routers appeared in more than one path, generally
at hops 4 or 5 from hosts in the same country .
3.3 Analysis of ICMP rate limitation
In the dataset we collected, two types of rate limitation were present.
In the ﬁrst one, which we call on-off, the router followed a clear an-
swering pattern. In the second one, which we will just call rate-limited
(rl), the overall answering rate is constant, but without a visible pat-
tern.
chapter 3 . icmp rate limitation 47
Figure 3.4: A typical timeseries for a
generically rate-limited router .
3.3.1 On-off
A typical example of an experiment targeting an ICMP rate-limited
on-off router is displayed in the timeseries in Figure 3.3, where we
report on the x-axis the time at which the probe was sent and on the
y-axis the corresponding round-trip time if an ICMP time-exceeded
packet was received for this probe. Whenever no reply was received,
a red cross appears on the x-axis at y= 0. W e deﬁne:
• a burst as any series of consecutive answered probes delimited
by unanswered probes. What we are interested in is the size of a
burst ( BS), in packets.
• an Inter-Burst Time (IBT) as the time interval between the ﬁrst
probe of a burst and the ﬁrst probe of the next burst.
A period coincides therefore with the occurrence of a burst, fol-
lowed by a series of unanswered probes.
T olerance to noise. In experiments similar to the one in Figure 3.3,
occasional unanswered probes inside a burst would split that burst
into smaller ones, according to the above deﬁnition. If instead we
tolerate the occurrence of a few unanswered probes (that we call a
gap and denote its size by g) and decide to end a burst only when
more than g unanswered probes appear in a row , we are able to catch
also those cases of visually identiﬁable bursts that a more conserva-
tive approach would miss. This allows us to account for potential
losses in the network and occasional interruptions in the generation
of ICMP time-exceeded packets on routers when more urgent tasks,
for example related to fast path operations, need to take place.
On-off behaviour . If we represent each experiment as a series of burst
sizes (BS’s) and Inter-Burst Times (IBT’s), we can determine the de-
gree of regularity of the observed burstiness by examining the coef-
ﬁcient of variation 12 (CoV ) of the two metrics, which we call CoVBS
12 The coefﬁcient of variation is deﬁned
as the ratio between the standard devia-
tion of a random variable and its mean.
It measures the variability of a distribu-
tion in units of the mean and enables
a direct comparison between distribu-
tions having different means.
and CoVI BT . Through a careful visual inspection of many timeseries,
we observed that a signiﬁcant fraction of routers featured a typical
on-off pattern when answering to our probes, where an on state is a
state in which all or nearly all probes are answered and an off state
is a state during which no answer is received. This essentially corre-
sponds to a variant of a token bucket where tokens, valid only for the
48 inference of network neutrality violations with active me asurements
duration of one period, are generated periodically and in bursts, with
each token being a ticket to send out an ICMP reply when needed.
Once all tokens expire, the router simply ignores any arising event
requiring the transmission of an ICMP reply and continues to do so
until the next period, when a new burst of tokens arrives. T aking
into consideration the presence of noise as previously described, we
deﬁne an experiment as on-off when both its CoVBS and CoVI BT lie
below an empirically chosen threshold of 0.05. That is to say that,
when the series of BS’s and of IBT’s contain values that do not differ
from one another by more than 5%, the router is ﬂagged as on-off
for this experiment. The threshold of 0.05 appeared to be a good
trade-off that minimizes the incidence of false positives.
3.3.2 Generic rate limitation
W e will see in Section 3.4 that a fraction of routers in our dataset
are indeed rate-limited when being probed at rates higher than a
router-speciﬁc threshold, but the way in which they respond does
not follow an on-off or any other recognizable pattern. An example is
provided in Figure 3.4, where it is clear that, even though the number
of unanswered probes is approximately the same every second, the
order at which the router decides whether to generate ICMP time-
exceeded replies is not as predictable as in the on-off case. W e now
move to a more detailed characterization of routers based on their
responsiveness.
3.4 Characterization of routers
In our measurement campaign, we observed that the vast majority of
routers behave according to three responsiveness phases depending
on the rate at which we probe. As we probe at increasingly high
rates, we have, in order of appearance:
• fully responsive phase , in which a router replies to the probes it
receives in a timely manner . The loss rate is < 5%, with sporadic
exceptions attributable to the router load, network congestion or
other minor causes. [rmin , r0 ) is the range of probing rates at which
this phase takes place.
Category Description # of routers (%)
fr Fully Responsive 257 (30.2%)
fr-irr Fully Responsive then Irregular 51 (6.0%)
fr-rl Fully Resp. then Generically Rate Limited 118 (13.9%)
fr-onoff Fully Responsive then On-Off 211 (24.8%)
fr-onoff-irr Fully Resp. then On-Off then Irregular 180 (21.2%)
unresponsive No answer 33 (3.9%)
T able 3.1: Number of routers in each
category .
chapter 3 . icmp rate limitation 49
fully
responsive
rate-limited
(on-off or rl)
irregular
rmin r0 r1 rmax Figure 3.5: Responsiveness of routers to
TTL-limited probes, broken down into
three phases, according to the rate at
which we send probes.
• rate-limited phase , where ICMP rate limitation is turned on as
a result of a probing rate higher than a router-speciﬁc threshold.
If on-off, the router responds at a constant rate and any excess
probes at every time period will be simply discarded. If generi-
cally rate-limited ( rl), the router has an overall constant answering
rate, but excess probes are dropped without a clear order . Refer
to Section 3.3 for more details. This phase is deﬁned in [r0 , r1 ].
• irregular phase , during which the router reaction is less predictable
than before. The rate at which we probe hits a capacity limit and
the router fails to reply in a regular way . Generally , two things
might happen: the loss rate gradually increases to 100%, or the on-
off pattern is not as precisely observable as before, with the overall
responsiveness being nonetheless roughly unchanged. This is the
behaviour observed in (r1 , rmax ].
The three phases are displayed in Figure 3.5, where we called: rmin
the minimum probing rate at which we hit a router (in our case
1 pps); r0 the minimum probing rate at which rate limitation ap-
pears (with r0 being necessarily ≥ rrl , the rate at which a router is
conﬁgured to reply when in the rate-limited phase); r1 the highest
probing rate at which we notice a well-deﬁned rate limitation; rmax
the maximum rate at which we probe. Our classiﬁcation
of routers is based on which of the three phases occur in the set of
probing rates in [rmin , rmax ] used in our measurement campaign. As
mentioned in Section 3.2, we tested exponentially-spaced rates in the
range [1, 4000 ] pps, but most PlanetLab nodes failed to achieve the
highest values. T ypically , a router will have a fully-responsive ( fr)
phase, followed by a rate-limited phase (if conﬁgured), and possi-
bly by an irregular phase ( irr ). W e can now devise the following
taxonomy:
• Rate-limited routers. Routers where a rate-limited phase occurred.
W e deﬁne three sub-categories:
a) fr-onoff. Routers that are fully responsive in [rmin , r0 ) and on-
off for higher probing rates, that is to say in [r0 , rmax ], with
r1 ≥ rmax .
b) fr-onoff-irr. Routers that are on-off only within a given range
of probing rates, above which they exhibit an irregular be-
haviour . They are fully responsive, as in the previous case, in
[rmin , r0 ), but have an on-off phase in [r0 , r1 ], with r1 < rmax .
An irregular phase appears in (r1 , rmax ].
c) fr-rl. Routers that are fully responsive up to r0 , after which
their answering rate is constant at a value rrl (with rrl neces-
50 inference of network neutrality violations with active me asurements
sarily ≤ r0 ), without the occurrence of any on-off pattern. W e
note here that no fr-rl-irr routers were encountered.
• Non rate-limited routers. Routers in which the rate-limited phase
is not observed. W e have two cases:
a) fr. Routers that are fully responsive for the entire range [rmin , rmax ],
in which they reply to all (or nearly all) probes. The condition
veriﬁed here is that the loss rate in the majority of the exper-
iments is < 5%, a value arbitrarily chosen as an indication of
high responsiveness. This essentially corresponds to the case
in which no rate-limited or irregular phase took place for prob-
ing rates in [rmin , rmax ].
b) fr-irr. Routers that are fully responsive (loss rate < 5%) up to
a given probing rate rirr , after which their loss rate starts to
increase, without any rate-limiting pattern being observed.
• Unresponsive. Routers that are conﬁgured to never reply to ex-
piring IP packets. 33 such cases were encountered, amounting to
a mere 4% of the total number of routers in the dataset.
Interestingly , the six categories appeared quite evenly spread out
with regard to the hop-distance from the PlanetLab hosts.
In our subsequent analysis, we chose to use a gap value of 4, since
it maximizes the number of on-off rate-limited routers without being
so high as to include possible false positives. The breakdown for our
set of 850 routers is detailed in T able 3.1. The vast majority ( 96%) of
routers are responsive, which is good news, as tools like traceroute
are key instruments for network troubleshooting. 30% of the routers
answer to all probes (up to the maximum probing rate used in our
experiments), while about 60% feature rate limitation at some point,
either with a clear on-off pattern ( 46%) or without ( 13.9%).
3.4.1 On-off routers
For a given on-off router , its on-off behaviour can be described by its
(BS, I BT ) pair . If we divide BS by I BT , we obtain the rate limitation
threshold of an on-off router , or in other words its answering rate
ronoff during the on-off phase.
Distribution of Burst Size. In Figure 3.6(a) we compare the cumu-
lative distribution functions (CDF’s) of burst sizes for fr-onoff and
fr-onoff-irr routers. In the case of the 211 fr-onoff routers (as seen
in T able 3.1), burst sizes span from 1 to 39,000 packets. The most
common values are: 1 (25%), 50 (20%), 500 (15%), 20 (10%), and 250
(10%). Almost all remaining values are multiples of 50, each one of
them not occurring in more than 5% of all cases. As for the 180 fr-
onoff-irr routers, while the set of burst sizes is similar to that of the
fr-onoff, we found a much larger fraction of routers conﬁgured at 50
pps. The most frequent values are the following: 50 (70%), 250 (7%)
and 500 (7%). Even though the two CDF’s look fairly different, the
chapter 3 . icmp rate limitation 51
10
0
10
1
10
2
10
3
10
4
10
5
burst size (packets)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
fr-onoff
fr-onoff-irr
(a) Burst Size CDF .
10
-2
10
-1
10
0
10
1
10
2
IBT (s)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
fr-onoff
fr-onoff-irr (b) Inter-Burst Time CDF .
10
0
10
1
10
2
10
3
10
4
answering rate (pps)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
fr-onoff
fr-onoff-irr
(c) Answering rate CDF by router Figure 3.6: CDFs of BS, IBT and overall
answering rate for on-off routers.
set of burst sizes for both router categories includes reasonable val-
ues that a network administrator could have very well picked. W e
will see in Section 3.4.3 that this is due to a dominance, among the
fr-onoff-irr, of Juniper routers, which are mostly rate-limited at 50
pps.
Distribution of Inter-Burst Time. Similarly to what we did for the
burst size, we now study the distribution of the Inter-Burst Time,
shown in Figure 3.6(b). The two curves are rather similar , with 1
second as the most frequent value. W e also observe a larger fraction
of fr-onoff routers at I BT = 0.01 s. In the case of fr-onoff routers,
the values span from 4 ms to 30 s with the most common ones be-
ing: 1 s ( 70%), 0.01 s ( 10%), 2 s ( 5%) and 10 s ( 5%). For fr-onoff-irr
routers the observed range is ( 0.01 s, 60 s), where we have: 1 s ( 85%),
0.02 s ( 5%) and 10 s ( 5%). W e can also notice outliers on the right-
hand side of the CDF curves: about a dozen PlanetLab hosts used
in our measurement campaign were heavily loaded at the time and
our 30-second experiments lasted in reality up to 2 minutes (with
the measured probing rates being considerably smaller than the de-
sired ones); surprisingly , this let us ﬁnd a couple of cases where a
52 inference of network neutrality violations with active me asurements
10
2
10
3
r
1
 (pps)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
fr-onoff-irr
Figure 3.7: Distribution of r1 for fr-
onoff-irr routers.
0
 1
 2
 3
 4
 5
(1 - loss rate) / ( r
onoff
 / sending rate)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
Figure 3.8: Answering rate over expected
answering rate in irr phase for on-off
routers.
very long series of answered probes (see the outliers in the BS CDF)
was interrupted every 30 or 60 seconds by a relatively short series of
unanswered packets. Our suspicion is that this is most likely due to
an internal process requesting the router resources at those precise
intervals.
Distribution of answering rate r onoff . W e consider the resulting an-
swering rate in the on-off phase by dividing BS over I BT . With
1 second as the most common I BT , there are no surprises in Fig-
ure 3.6(c): the values are roughly the same seen in Figure 3.6(a). The
most common values for fr-onoff routers are (in packets per second):
500 (28%), 50 (18%), 100 (15%), 1 (15%), 20 (10%), 250 (10%), 400 (9%)
and 250 (5%). In the case of fr-onoff-irr routers, the CDF shows a
dominant value: 50 (75%). The other observed answering rates are:
250 (8%), 500 (8%), 400 (5%) and 10 (5%). W e can also notice that
50% of fr-onoff routers have a rate limitation threshold ≤ 100 pps,
whereas 60% of the fr-onoff-irr have a lower threshold: 50 pps or less.
Behaviour in (r1 , rmax ]. W e said that on-off routers of type fr-onoff-
irr cease to be on-off at probing rates higher than r1 , which varies
from router to router . In Figure 3.7 we show the distribution of r1 ,
chapter 3 . icmp rate limitation 53
102 103
answering rate (pps)
0.0
0.2
0.4
0.6
0.8
1.0CDF
Figure 3.9: Answering rate for generi-
cally rate-limited ( rl) routers.
which reveals that 76% of these routers moved to the irregular phase
already when we probed them at less than 76 pps, with this value
being r1 for 45% of them. In order to study what happens during the
irregular phase, we plotted in Figure 3.8 the CDF of the (per-router)
average ratio between the actual answering rate of each experiment
in the irr phase and the answering rate if the router were still in the
on-off phase. In the curve, values close to 0 indicate little (or no)
responsiveness, which is the case for around 10% of these routers.
V alues on 1 suggest that, even though the on-off pattern is not as
strictly enforced as before, the overall answering rate is the same as
in the on-off phase. This is true for around 20% of routers in this
category . V alues between 0 and 1, where more than 50% of routers
lie, show instead a decreased answering rate. W e leave for future
study an explanation for the outliers on the right-hand side of the
curve, which indicate an unexpected increase in responsiveness.
3.4.2 Generically rate-limited routers
Generically rate-limited routers keep the answering rate constant for
all probing rates in the rate-limited phase. In Figure 3.9 we study the
distribution of answering rates for these routers. Compared to the
answering rates seen for the on-off category , here the values are sen-
sibly higher: almost 50% are rate-limited at 2000 pps, 20% at roughly
1000 pps and 15% at 100 pps.
3.4.3 V endors
ICMP rate-limitation parameters can be hard-coded into a router or
conﬁgurable by its administrator , depending on the router vendor .
For example, according to Cisco documentation, 13 Cisco 6500 and 13 Cisco. TTL expiry attack identiﬁ-
cation and mitigation. URL: http://
www.cisco.com/web/about/security/
intelligence/ttl-expiry.html
7600 routers can be conﬁgured with the desired answering rate and
burst size. Steenbergen 14 reports that in Cisco GSR routers the lim-
14 RA Steenbergen. A practical guide to
(correctly) troubleshooting with tracer-
oute. North American Network Operators
Group, pages 1–49, 2009
itation rate is hard-coded, which is also the case for Juniper routers,
whose answering rates vary depending on the model: 50, 250 or 500
pps. With this in mind, we ﬁngerprinted the routers in our dataset in
order to determine their most common conﬁgurations. For routers
54 inference of network neutrality violations with active me asurements
10
0
10
1
10
2
10
3
10
4
10
5
burst size (packets)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
cisco
juniper
others
(a) Burst Size CDF by vendor .
10
-2
10
-1
10
0
10
1
IBT (s)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
cisco
juniper
others (b) Inter-Burst Time CDF by vendor .
10
0
10
1
10
2
10
3
10
4
answering rate (pps)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
cisco
juniper
others
(c) Answering rate CDF by vendor . Figure 3.10: CDFs of BS, IBT and
answering rate for on-off routers, ar-
ranged by router vendor .
at hop 1 we simply looked up their MAC address, whereas for all
other ones we used the technique described by V anaubel et al., 15 15 Y ves V anaubel, Jean-Jacques Pan-
siot, Pascal Mérindol, and Benoit Don-
net. Network ﬁngerprinting: TTL-based
router signatures. In Proceedings of the
2013 conference on Internet measurement
conference, pages 369–376. ACM, 2013
through which we can identify a router as Cisco, Juniper or “others”
by considering the IP TTL of the response to an ICMP echo-request
and the IP TTL of the response to a TTL-limited probe. The distri-
bution of vendors seems to follow the known prevalence of Cisco in
the market: 59% of routers were labeled Cisco, 30.5% Juniper and
10.5% others. In Figure 3.11 we see how the different categories
are distributed for each vendor: Cisco has a large fully-responsive
component ( 50.8%), almost all ( 95.8%) Juniper routers are on-off and
those marked as “others” are also mainly on-off ( 74.1%). For on-off
routers, we show in Figure 3.10 the distribution of BS, IBT and an-
swering rate arranged by vendor . A few considerations: (i) Cisco
routers are mostly conﬁgured at 20, 100 or 500 pps; (ii) IBT is gen-
erally always 1 second, except for Cisco routers, which display more
values (probably as a consequence of being conﬁgurable in software)
and (iii) most Juniper routers are rate-limited at 50 pps, the dominant
value we saw previously for fr-onoff-irr routers. It is no coincidence,
as these are mostly Juniper .
chapter 3 . icmp rate limitation 55
cisco
59.0%
juniper
30.5%
others
10.5%
(a) Distribution of vendors.
fr
50.9%
fr-irr
6.7%
fr-onoff
18.8%
fr-onoff-irr
3.8% fr-rl
19.8%
(b) Distribution of router types for Cisco routers.
fr2.4%
fr-irr1.8%
fr-onoff
31.3%
fr-onoff-irr
64.5%
(c) Distribution of router types for Juniper routers.
fr
13.0%
fr-irr
7.4%
fr-onoff
68.4%
fr-onoff-irr
5.6%
fr-rl5.6%
(d) Distribution of router types for “other ” routers.
Figure 3.11: Distribution of vendors
and percentage of routers in each cat-
egory for Cisco, Juniper and “others”.
3.4.4 V alidation by controlled experiments
W e resorted to controlled experiments in order to verify that (i) we
infer the correct on-off parameters, and (ii) PlanetLab hosts do not
add any bias . W e arbitrarily chose 60 machines from the Planet-
Lab testbed, each one of which located at a different site, and in-
structed them to probe (in sequence) a machine in our control, where
we emulated the on-off behaviour of routers with the use of Linux
iptables.16 For simplicity , we did not make the ICMP echo-request
16 http://www.netfilter.org/
projects/iptables
probes expire on this machine, but we directly replied to them with
ICMP echo-reply messages. Similarly to our large-scale measure-
ments, each single experiment lasted 30 seconds, during which a
PlanetLab host probed our machine at a constant rate. W e picked
12 exponentially-spaced probing rates in the interval [ 1, 1000] pps
and tested each rate twice. On the machine in our control, we em-
ulated an on-off router by using for a ﬁrst round of measurements
a rate limitation of 20 pps ( BS = 20 packets, I BT = 1 second) and
for a second round a value of 50 pps ( BS = 50 packets, I BT = 1
second). In Figure 3.12 we show the CDF of the measured average
Burst Size ( BS) and Inter-Burst Time ( I BT ). While for the I BT the
correct value is precisely measured, an error of up to 2 units is often
encountered in the estimation of the BS parameter . After a manual
56 inference of network neutrality violations with active me asurements
20
 25
 30
 35
 40
 45
 50
 55
average BS (packets)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
20 pps
50 pps
(a) Burst Size CDF .
0.97
 0.98
 0.99
 1.00
 1.01
 1.02
 1.03
 1.04
average IBT (s)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
20 pps
50 pps (b) Inter-Burst Time CDF .
Figure 3.12: V eriﬁcation of inferred pa-
rameters on a controlled rate-limited
machine.
inspection of several experiments, we can only conclude that it is an
implementation-dependent issue: the BS parameter is simply not al-
ways as rigorously enforced as the I BT in iptables. Nonetheless, the
correct inference of the above parameters lets us exclude the exis-
tence of any bias coming from the PlanetLab hosts or the networks
where they reside.
3.5 Delay
In Section 3.1 we observed that the rate at which we send probes does
not inﬂuence the resulting round-trip time, whose mean value is sta-
ble across all probing rates under consideration. W e add here further
evidence to support our claim by analyzing the per-experiment RTT
variability . For each experiment, we took the coefﬁcient of varia-
tion (CoV) of all its round-trip times and plotted in Figure 3.13 all
CoVs arranged by probing rate and regardless of the hop distance.
Apart from the case of 1 packet per second, for which the CoVs refer
to samples of only 30 RTT’s (as each experiment lasts 30 seconds),
where apparently less variability occurs, for all other probing rates
there does not seem to be any noticeable difference across them. The
interquartile range appears stable, with a very slight decrease of the
median for higher rates. Therefore, we can apparently conclude that
the sending rate has no direct impact on the round-trip time of TTL-
limited probes: its mean is not altered, and neither is its variability .
3.6 Related Work
T o the best of our knowledge, our work is the ﬁrst of its kind to
attempt to precisely characterize ICMP rate-limitation on routers at
a large scale. Gunes and Sarac 17 analyzed publicly available tracer- 17 Mehmet H Gunes and Kamil Sarac.
Analyzing router responsiveness to ac-
tive measurement probes. Passive and
Active Network Measurement , pages 23–
32, 2009
oute data collected between 1999 and 2008, and noticed that in recent
years network operators have conﬁgured routers to become increas-
ingly less cooperative to active probing. Then, they conducted large-
chapter 3 . icmp rate limitation 57
scale measurements with direct (i.e. destined to a router) and indi-
rect (i.e. traceroute-like) probes and compared the responsiveness of
routers according to the chosen protocol: ICMP , TCP or UDP . They
concluded that ICMP probes elicit the highest number of responses
for both direct and indirect probes, followed by TCP and UDP in the
case of direct probes, and by UDP and TCP for indirect ones. It is
also based on this ﬁnding that we decided to use ICMP probes in
our measurements. Govindan and Paxson 18 proposed a technique 18 Ramesh Govindan and V ern Paxson.
Estimating router ICMP generation de-
lays. In Passive & Active Measurement
(P AM), 2002
to estimate the time taken by a router to generate an ICMP time-
exceeded message: given a router R located on the path from host A
to host B, they compared the one-way delay from A to B experienced
by direct probes and by spoofed TTL-limited probes that expire on
R but whose ICMP error message is sent to B. They found out that
for most routers the slow path time is less than 0.5 ms. Malone and
Luckie19 tackled an issue tightly related to the use of TTL-limited 19 David Malone and Matthew Luckie.
Analysis of ICMP quotations. Passive
and Active Network Measurement , pages
228–232, 2007
probes: the matching between probes and ICMP time-exceeded mes-
sages, based on the quoted contents of the expired probes inside
the returned ICMP message. They detailed a variety of packet ﬁeld
modiﬁcations applied by routers and middleboxes that might result
in discrepancies between the quoted packet and the original probe.
Incidentally , they also pointed out that in their measurements there
were a few tens of probes that experienced incredibly high RTT’s,
spanning from 10 to 300 seconds. W e encountered exactly the same
kind of outliers when analyzing our dataset (as can be seen in Fig-
ure 3.2). Layouni et al., 20 who studied in depth the causes behind 20 Farah Layouni, Brice Augustin, Timur
Friedman, and Renata T eixeira. Origine
des étoiles dans traceroute. In Colloque
Francophone sur l’Ingénierie des Protocoles
(CFIP), 2008
undisclosed routers in traceroute, also reported very high round-trip
times and attributed them to high activity in the control plane, which
at least in our dataset seems more likely to be caused by our own
probing rather than by other parallel processes.
3.7 Summary
Although the use of ICMP rate limitation on routers in the Inter-
net has been known for a long time, no previous study had tack-
led the problem of precisely characterizing how this function is im-
plemented in the wild. W e analyzed the RTT distribution obtained
when targeting routers with TTL-limited probes and found that it
is apparently uncorrelated with the chosen probing rate. W e intro-
1 19 39 54 75 104 144 199 272 372 503 678 907 1183 1552 2009 2543
sending rate (pps)
0
2
4
6
8
10
12RTT CoV
Figure 3.13: RTT CoV box plots for all
experiments, arranged by probing rate.
58 inference of network neutrality violations with active me asurements
duced a classiﬁcation of routers based on their responsiveness across
different probing rates and observed that rate limitation most often
consists of an on-off process, where the router alternates between a
state in which it answers to all probes and a state during which it re-
mains silent. W e analyzed in details the conﬁguration parameters of
on-off routers: burst size, for which we detected a variety of values,
and inter-burst time, generally equal to 1s. A future direction for
this work could extend our measurements to go deeper into the core
of the Internet and group routers with respect to the ISP that man-
ages them. This will allow us, for example, to check if ISPs apply a
consistent conﬁguration across their routers.
Now that we have shown that round-trip times obtained with
TTL-limited packets can be used for delay measurements, we can
introduce in the next chapter the upstream experiment of our tool,
ChkDiff, which relies on this type of feedback from intermediate
routers to infer differentiation and localize shapers.
4
ChkDiff: the upstream experiment
The neutrality of the Internet has been a hot topic ever since, around
a decade ago, bandwidth-hungry applications (e.g., peer-to-peer , video,
media streaming) started to gain success among users and a num-
ber of ISPs took measures to counter possible detrimental effects on
the connectivity they provided. Arbitrary decisions, as for exam-
ple blocking of BitT orrent trafﬁc in the upstream direction 1 by an 1 Dslreports: comcast is using sand-
vine to manage p 2p connections.
URL: http://www.dslreports.com/
forum/r18323368-Comcast-is-
using-Sandvine-to-manage-P2P-
Connections.
operator in the U.S., have since then been reported. As we saw in
Chapter 2, other examples include: throttling of Y ouT ube in France 2
2 Respect my net. URL: http://
respectmynet.eu/view/205
and Germany 3 during evening hours, when link utilization reaches
3 Respect my net. URL: http://
respectmynet.eu/view/196
its peak; degraded performance over a VPN using OpenVPN default
port4 in the U.S.; most recently , evident decrease in performance for
4 I just doubled my PIA VPN through-
put that I am getting on my router by
switching from UDP: 1194 to TCP: 443.
URL: http://www.reddit.com/r/VPN/
comments/1xkbca/i_just_doubled_my_
pia_vpn_throughput_that_i_am
Netﬂix trafﬁc in early 2014 by two U.S. operators. 5
5 Netﬂix performance on V eri-
zon and Comcast has been
dropping for months, 2013.
URL: http://arstechnica.com/
information-technology/2014/02/
netflix-performance-on-verizon-
and-comcast-has-been-dropping-
for-months
But since trafﬁc differentiation is rarely revealed by ofﬁcial sources
and certainly does not appear in Service Level Agreements (SLA ’s),
it becomes of utmost importance to be able to detect it from within
the network. A number of tools for the detection of trafﬁc differen-
tiation have thus emerged in the literature in the past few years (we
reviewed them in Chapter 2). The method we propose here differs
from existing work in its attempt to be independent both from the
shaping techniques in use by ISPs at layer 3 (IP) of the protocol stack
and from the user applications that might be targeted. The idea is
that a shaper whose goal is to degrade the performance of selected
trafﬁc might do so according to a variety of packet scheduling and
buffer management policies, but it will typically result on the user
side in larger delays and possibly more losses. Consequently , if we
compare the set of delays of a ﬂow to that of the rest of the trafﬁc,
and we proceed analogously for losses, we should be able to infer
whether any shaping took place. In order for this to be valid for
whatever application the user is running, we reuse her own traf-
ﬁc and replay it with minimal changes so that it targets the routers
at the ﬁrst few hops from her . If any shaper is located in prox-
imity to one (or more) of these routers, packets going through it
will have degraded performance at that hop and at all subsequent
ones, thus allowing us to also pinpoint their relative position. W e
implemented this technique for upstream trafﬁc in a tool we called
ChkDiff,6 through which we can detect the presence and identify 6 The code is available on a
dedicated web page: http:
//chkdiff.gforge.inria.fr/
the location of shapers, by using the ICMP feedback provided by
60 inference of network neutrality violations with active me asurements
routers. W e focus in this chapter on the validation of ChkDiff in the
upstream direction: we stress the tool under different shaping sce-
narios and assess its resilience against sources of error such as trafﬁc
variation and ICMP rate limitation on routers.
The chapter is organized as follows: in Section 4.1 we present the
functioning of our method in details, along with a discussion of all
the technical adjustments needed for the tool to work; in Sections 4.2
and 4.3 we validate ChkDiff in respectively a controlled neutral and
non-neutral environment and show that it is able to successfully de-
tect shaping even when a large fraction of the trafﬁc is differentiated;
we compare our method to existing work in Section 4.4 and give
concluding remarks in Section 4.5.
The results of this chapter were presented in a paper published
at ITC 27.7 An early draft of this work was presented at CoNEXT 7 Riccardo Ravaioli, Guillaume Urvoy-
Keller , and Chadi Barakat. T owards a
general solution for detecting trafﬁc dif-
ferentiation at the internet access. In
T eletrafﬁc Congress (ITC 27), 2015 27th In-
ternational, pages 1–9. IEEE, 2015
2012.8
8 Riccardo Ravaioli, Chadi Barakat, and
Guillaume Urvoy-Keller . Chkdiff:
checking trafﬁc differentiation at In-
ternet access. In Proceedings of the
2012 ACM conference on CoNEXT student
workshop, pages 57–58. ACM, 2012
4.1 Design of the tool
The strength of ChkDiff lies on its ability to not depend on the kind
of shaping technique affecting delays and losses in use by ISPs and
on the applications (or rather , trafﬁc ﬂows) that might be targeted.
W e achieve this by implementing the following design ideas in the
core of our tool:
• Use of real user trafﬁc. W e conduct all experiments with previously
dumped user trafﬁc, so that the results yielded by our tool will
refer to the exact set of applications run by the user .
• T race is left (almost) intact. This ensures that any shapers traversed
by our trace will have the same behaviour they would have if the
packets had been generated by their respective applications. As
we will see in the following subsections, the only modiﬁcations
applied to packets are in the TTL ﬁeld, in order to hit the router(s)
at the desired hop, and in the application payload, in which we
enforce the same size on all packets so as to avoid different trans-
mission times.
• Baseline for comparison is the entire trafﬁc. By the deﬁnition of net-
work neutrality , a ﬂow that is not differentiated will be treated in
the same way as the rest of the (non-differentiated) trafﬁc by any
given router . On the other hand, a ﬂow that is differentiated by
a shaper will typically display higher delays or losses, depend-
ing on the scheduling and buffer management techniques in use. 9 9 More speciﬁcally , a shaper will still
be able to classify ﬂows as if they
were coming from their respective orig-
inal applications, when it does so by
inspecting IP , transport-layer header
ﬁelds or application payloads. If it
implements stateful TCP ﬂow analy-
sis, our replayed trace would proba-
bly bypass it. After this ﬂow identi-
ﬁcation phase, a shaper will apply a
differentiation technique to the selected
ﬂows. ChkDiff is able to detect tech-
niques resulting in higher delays and
losses; techniques that interfere directly
with the transport or application layer ,
such as TCP RST injection and HTTP
redirections, will not be detected.
When compared to the delays and losses of the rest of the trace,
this ﬂow will stand out. Our statistical analysis is based on that.
W e will show in the validation section that we are able to success-
fully detect shaping when over half of the trafﬁc is differentiated.
The execution of ChkDiff is summarized in Algorithm 1.
A trafﬁc trace is captured during a user ’s regular Internet activ-
ity; it is then processed and arranged into ﬂows. For each hop h
chapter 4 . chkdiff : the upstream experiment 61
Algorithm 1 ChkDiff execution
1: Capture user trafﬁc
2: for each hop h ∈ {1, 2... k} do
3: for each run r ∈ {1, 2, 3 } do
4: shufﬂe trace
5: replay trace with T T L ← h
6: collect ICMP time-exceeded replies
7: end for
8: detect shaped ﬂows at hop h
9: end for
10: aggregate results and locate shaper(s), if any
we intend to test, we shufﬂe the trace so as to minimize any bias in
the network conditions that our ﬂows will experience: we keep the
ordering of packets within each ﬂow and modify the global packet
ordering to be resilient to side trafﬁc. W e set the TTL ﬁeld of the IP
header of each packet to h and we replay the trace. Routers at hop
h, if responsive, will reply with ICMP time-exceeded error messages,
through which we compute single packet Round-T rip Times (RTT’s)
to hop h. Any shaper located between the user and hop h must have
affected packets belonging to the ﬂows it is conﬁgured to differen-
tiate, before the ICMP error messages were elicited. W e repeat this
operation 3 times for the same hop in order to ﬁlter out false pos-
itives and we claim that a ﬂow has been shaped when it has been
rejected in our statistical analysis across all three runs. Once all the
ﬁrst k hops have been tested, we compare the results and attempt to
localize the shapers.
In the rest of this section, we will describe each of the above steps
in detail.
4.1.1 T rafﬁc trace
The ﬁrst action taken by ChkDiff is to dump outgoing user trafﬁc
while the user runs her usual network applications. This is the trace
that will be replayed from the end user host towards routers at the
hops nearby in the following steps. Since we focus in this chapter on
the upstream direction, we expect the user to execute applications
generating some non-trivial outgoing trafﬁc that is not limited to
HTTP requests or TCP ACK’s: for example media upload, V oIP , ﬁle
sharing and instant messaging.
4.1.2 Flows and trace preparation
T race classiﬁcation into ﬂows. The packets in the dumped trace are
arranged into 5-tuple ﬂows, that is to say according to source and
destination IP addresses, source and destination port numbers and
transport protocol.
62 inference of network neutrality violations with active me asurements
Fixed-size packets. Next, we need to prepare the trace we have to
replay . Packets of different size, if sent along the same path to the
same destination, will inevitably have different transmission times.
As we will see in Section 4.2, this is a non-negligible source of error
if, as it is in our case, we make the assumption that the delays of all
packets going along the same path should be comparable. This is
especially true if we measure delays to the closest hops, where the
delay variability could be low enough to be comparable to or even
smaller than the difference in transmission times between small and
large packets. In order to overcome this, we force every packet of
our trace to be of the same size S (in Bytes), with S being the size
of the largest packet in our trace, by adding random padding at the
end of packets with shorter payloads. Through this, we preserve all
original payloads so that packets can still be intercepted by shapers
implementing Deep Packet Inspection (DPI).
Shufﬂing packets. Before replaying our trace, an additional step is
required. Since our analysis will be in terms of ﬂows, we have to
ensure that they all see the same network conditions while being in-
jected into the network. It is therefore necessary to shufﬂe packets
so that they exhibit such property . W e assign a weight to each ﬂow
in our trafﬁc according to its original size in packets and normalize
it by the sum of all ﬂows sizes, such that all weights sum to 1. For a
trace with f ﬂows, any ﬂow i with size si , in number of packets, will
have weight pi = si / ∑
f
k=1 sk . A queue is thus created for each ﬂow ,
where the per-ﬂow packet order is maintained, since it might reveal
useful information to a shaper for ﬂow identiﬁcation. W e now pick
packets randomly from each queue according to the ﬂow weight and
put them aside, ready to be replayed. Whenever a queue becomes
empty , its weight is set to 0 and weights of all other ﬂows are up-
dated accordingly , so that they always sum to 1. By popping packets
from each queue in the above fashion, we obtain for every ﬂow an
ordered sequence of 0’s and 1’s indicating whether a packet in the
resulting shufﬂed trace came from that ﬂow or not. Given a ﬂow i,
such sequence of 0’s and 1’s can be seen as a Bernoulli process with
a probability equal to the weight of ﬂow i, let us say pi . Now , if we
consider the spacing (or inter-packet time) Wi between any two con-
secutive packets from ﬂow i, we can see that it follows a geometric
distribution with parameter pi : P(Wi = w) = (1 − pi )w−1 pi . The
geometric distribution being the discrete version of an exponential
distribution, packets of ﬂow i see the real network conditions accord-
ing to the P AST A property (Poisson Arrivals See Time A verages). 10 10 Ronald W W olff. Poisson arrivals
see time averages. Operations Research ,
30(2):223–231, 1982As this property applies to all ﬂows, it enables us to reach our initial
goal: letting all ﬂows observe the same network conditions, provided
that the network offers a stationary service.
Furthermore, shufﬂing is particularly useful when having to coun-
teract side trafﬁc and ICMP rate limitation, as we will see shortly .
chapter 4 . chkdiff : the upstream experiment 63
4.1.3 Replay
ICMP rate limitation. In Chapter 3 we studied the responsiveness of
routers to TTL-limited probes. Through a large measurement cam-
paign, we examined possible bias in the Round-T rip Times of these
probes and how ICMP rate-limitation is implemented on routers.
W e demonstrated that there did not appear to be any correlation be-
tween a slow or high probing rate (in the range [ 1, 4000] packets per
second) and the resulting Round-T rip Times. In other words, even at
high rates, we were not hitting any capacity limits that might have
slowed down the generation of ICMP messages and contributed to
the total packet delay . This is good news, since it tells us that the
choice of probing rate does not mar the delays we obtain. There will
deﬁnitely be a delay component due to the generation of the ICMP
error message (estimated to be in the order of the submillisecond), 11 11 Ramesh Govindan and V ern Paxson.
Estimating router ICMP generation de-
lays. In Passive & Active Measurement
(P AM), 2002
since it takes place in the router slow path, which is usually im-
plemented in software instead of hardware and does not have high
priority compared to other router operations. But this delay compo-
nent will have roughly the same weight in all RTT’s toward the same
router and therefore will not constitute a source of error .
When using TTL-limited probes as in our case, we must also make
sure that we obtain a sufﬁcient number of replies, since it is a fairly
widespread practice for manufacturers and network administrators
to limit at a ﬁxed maximum rate the responsiveness of routers to
these expiring probes. W e tested 850 routers from PlanetLab hosts
up to hop 5 and demonstrated that ICMP rate limitation is imple-
mented as an on-off process with typical values in [20, 500 ] packets
per second ( pps). In light of this, the shufﬂing technique presented
above has the undoubted advantage that unanswered probes would
be spread fairly evenly across ﬂows, since ﬂow packets themselves
are spread evenly across the trace. A non-shufﬂed trace replayed
to an ICMP rate-limiting router would instead incur more variable
losses among ﬂows, which would inevitably impair any loss analy-
sis. W e will discuss the robustness of our tool to ICMP rate limitation
in Section 4.3.
T esting the ﬁrst k hops. In order to locate the position of a shaper ,
we need to replay the shufﬂed trace as many times as the number of
hops we want to test, by increasing the IP TTL of all packets at every
experiment. For the choice of k, a value of 3 or 4 should suit most
cases and provide a large enough picture of what happens at the
user ’s Internet access, including ISP routers and those right after the
ISP boundaries. The user trace being made of ﬂows with different
IP destination addresses, testing routers that are further away is of
increasing complexity due to a reduction in terms of samples per
router as we move away from the user .
64 inference of network neutrality violations with active me asurements
Figure 4.1: An example with shapers at
different hops affecting selected ﬂows.
hop 1 hop 2 hop 3 hop 4 shapers?
ﬂow 0 ❉ ✖ ✖ ✖ hop 2
ﬂow 1 ❉ ❉ ❉ ✖ hop 4
ﬂow 2 ❉ ❉ unresp ❉ none
ﬂow 3 ❉ ❉ unresp ✖ hops 3,4
ﬂow 4 ❉ ❉ unresp unresp not until hop 2
Figure 4.2: Expected output of ChkDiff
for the network topology in Figure 4.1.
4.1.4 Results analysis
W e focus our analysis on the study of Round-T rip Times and losses.
In both cases, the approach is similar: we consider large ﬂows only ,
that is those with at least 20 answered packets (a typical minimum
sample size in statistical analysis), and we analyze these ﬂows one at
a time, comparing them against all the rest of the trafﬁc as a whole
(large and small ﬂows indifferently). W e reject a ﬂow if it fails at least
one between the delay and the loss analysis in all three experiments
against the same router .
Delays. W e compare the distribution of delays of a ﬂow to the de-
lay distribution of the rest of the trace using a statistical test. Our
null hypothesis is that, in an environment without differentiation,
if we sample the total set of delays obtained, they will all appear
to be drawn from the same distribution as all the other delays of
the trace. W e conduct our analysis by applying two-sample one-
sided Kolmogorov-Smirnov test, which has the beneﬁt of being non-
parametric, in that it does not make assumptions on the underlying
distribution of the data it is checking. The test takes as statistic the
maximum vertical deviation between the Cumulative Distribution
Functions (CDF’s) of two samples. W e chose the one-sided version
of this test because, while the two-sided Kolmogorov-Smirnov test
looks for the maximum vertical deviation between two curves with-
out including in its result whether this vertical distance was due to
the ﬁrst curve being above the second one or the other way around,
the one-sided version looks for this deviation in one given direc-
tion. Applied to our scenario, we can test whether a ﬂow experi-
enced worse (i.e. larger) delays than the rest of the trace by checking
whether its CDF lies below the CDF of its baseline, and to which
extent.
chapter 4 . chkdiff : the upstream experiment 65
Losses. In order to check if the loss rate of a ﬂow differs signiﬁcantly
from that of the rest of the trace, we proceed by using an argument
inspired from the binomial distribution. If we want to examine the
losses (i.e. the number of unanswered packets) experienced by ﬂow
i, we let p be the loss rate of the rest of the trafﬁc as a whole, and
si be the original number of packets of ﬂow i. If the loss events of
ﬂow i were not caused by a shaper , its number of losses li can be
modeled as a binomial random variable of parameters B(si , p). T o
test whether this holds true, we can approximate this binomial as a
normal random variable of parameters N(si p, si p(1 − p)) and verify
that the loss events li lie within α standard deviations of the normal
mean. With α being a function of the signiﬁcance level we want to
achieve, we check that ps −α
√
p(1 − p)si < li < psi + α
√
p(1 − p)si .
The right side of this last condition is the one we are interested in, as
it indicates - when it does not hold - that the ﬂow experienced more
losses than it should have, and it is what we check in our analysis.
Combined analysis. Since a shaper might cause longer delays or extra
losses to affected ﬂows, we combine the delay and the loss analyses
described above and reject a ﬂow when it fails at least one of them.
Repetition of experiments. Statistical tests are operated at a certain
conﬁdence level, which in our tool we set to 99%. Due to the high
number of ﬂows in a user trace, we are bound to have a number of
false positives, whatever action we take. T o work around this issue,
we adopt a simple strategy . W e repeat an experiment three times (at
the same constant probing rate) to router(s) at the same hop-distance
and claim that a ﬂow has been shaped only when it was rejected in
all three runs.
4.1.5 Results Aggregation
After collecting traces and analyzing delays and losses for the ﬁrst
k hops, we need to aggregate results in order to attempt to localize
shapers, if ever a ﬂow was rejected in any of those hops. A shaper
positioned right before hop h, with h ∈{ 1, 2, ... k}, will cause tar-
geted ﬂows to fail the delay or loss analysis (or both) on all hops
≥ h. When ChkDiff detects this, it declares the ﬂow as being shaped
on the hop segment between h and the previous responsive router .
W e show an example with routers up to hop 4 in Figure 4.1. W e
assume that there is a number of non-differentiated ﬂows from the
user trace passing through each router besides the four shown in
the ﬁgure, and that they contribute to the baseline for the statistical
analysis. In Figure 4.2 we provide the expected output from ChkDiff
based on this scenario. A shaper for ﬂow 0 is deployed right before
the router at hop 2: this means that ﬂow 0 will pass the analysis at
hop 1, but will not at all successive hops. Flow 1 is a similar case, but
at the edge of the tested hops. At hop 3 an unresponsive router , that
is to say a router that is conﬁgured not to reply to expiring packets,
66 inference of network neutrality violations with active me asurements
generates a gap in our assessment, which might be compensated by
the results at the next hop. If at the next hop a ﬂow (ﬂow 2) continues
to pass the test, we can safely claim that it was not shaped along the
whole path under consideration. If instead the ﬂow fails the test, as
we show for ﬂow 3 in our example, we can only say that at hop 3 and
4 it encountered a shaper , without being more speciﬁc. Finally , if the
next hop is also unresponsive, for a ﬂow like ﬂow 4, our conclusion
is simply that no shapers were detected up to the last hop where the
ﬂow passed the analysis.
4.2 V alidation in a neutral scenario
Before validating ChkDiff in the presence of trafﬁc differentiation, it
is important to justify some measures we take when replaying a user
trace: forcing the same size in all packets and aggregating results
across 3 experiments. The packet trace we used here and in
Section 4.3 was captured in a time-window of 3 minutes of a typical
Internet session, in which we performed picture uploading on a so-
cial network, browsing on a news site, and sent a few chat messages.
The trace is made of 6733 packets, arranged into 275 ﬂows, of which
61 are large (i.e. they have more than 20 packets) and comprise 76.8%
of the total amount of packets. The exact distribution of ﬂow sizes is
shown in Figure 4.3.
10
0
10
1
10
2
10
3
flow size (packets)
0.0
0.2
0.4
0.6
0.8
1.0
CDF
Figure 4.3: Distribution of ﬂow sizes, in
number of packets, for the packet trace
used for validation.
0
 1
 2
 3
 4
 5
no. of false positives
0.0
0.2
0.4
0.6
0.8
1.0
CDF
KS
original
fixed size
Figure 4.4: Incidence of false positives
in the delay analysis when the replayed
trace contains unaltered original pack-
ets, and when it contains packets of the
same size. Results are over 1 run.
chapter 4 . chkdiff : the upstream experiment 67
shaping pipe
compensating pipe
100 Mbit/s
pipe
Figure 4.5: Middlebox conﬁguration.
W e claimed in Section 4.1.2 that, by ﬁxing the packet size to a
constant value for all packets in a trace, we were able to remove a
considerable fraction of errors in the delay analysis. W e now show
the incidence of false positives when packets are the original size
and when they are padded to a constant value. For each of the
two options, we ran ChkDiff 100 times in a controlled setup with
no differentiation towards a router under our control at hop 2. In
Figure 4.4 we compare the CDFs of the number of false positives of
the delay analysis for each experiment. 12 The improvement is evi- 12 W e do not consider the loss analysis,
since in our controlled setup the trace
did not experience any losses.dent: we remove all errors in 70% of experiments and are left with
30% of experiments showing mostly 1 false positive.
The next step is to aggregate the results of multiple runs, as de-
scribed in Section 4.1.4 and see if these errors disappear . W e ran
ChkDiff 100 times and observed indeed that no false positives emerged
when considering just two runs. In order to have a safe margin of
error , we use by default three runs in ChkDiff.
4.3 V alidation in a non-neutral scenario
W e tested how the tool copes with different shaping and network
settings in a controlled experimental setup. W e focused on two sce-
narios: Scenario 1, in which we throttle the bandwidth of selected
ﬂows, and Scenario 2, where we apply uniform packet drops. In
our setup, a user machine is connected through cable to a middle-
box, which operates both as a gateway and a shaper , and which is,
in turn, connected to a Cisco router under our control, where our
probes expire. In the middlebox, we deployed a shaper with Dum-
mynet, a popular and versatile network emulation tool. 13 The con- 13 Marta Carbone and Luigi Rizzo.
Dummynet revisited. SIGCOMM Com-
put. Commun. Rev. , 40(2):12–20, April
2010
ﬁguration we used is depicted in Figure 4.5: incoming packets are
directed to either the upper or lower pipe on the left side, depend-
ing on whether they belong respectively to the ﬂows to shape or not.
The upper pipe is traversed by all ﬂows that we intend to shape;
in Scenario 1 it has its own bandwidth bw and queue size, and in
Scenario 2 it induces uniform losses at rate lr. The lower pipe com-
pensates for the transmission delay produced by the upper pipe in
Scenario 1: it adds this constant delay component to the packets of
all non-differentiated ﬂows, so that only the queueing delay in the
upper pipe constitutes the discriminating factor between shaped and
non-shaped packets. In scenario 2, it produces no effect. Finally , all
packets meet at the pipe on the right-hand side, which emulates a
100 Mbit/s link. In Scenario 2 this pipe induces a uniform loss rate
lrall to all ﬂows. All pipes are conﬁgured with a buffer size of 100
68 inference of network neutrality violations with active me asurements
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
precision
TP/P
(a) Precision of the combined analysis
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(b) Recall of the combined analysis
Figure 4.6: Precision and recall of the
combined analysis, for the case of one
shaped ﬂow in Scenario 1. In each cir-
cle, we report in the upper-left quar-
ter the result of only the delay analysis,
in the upper-right quarter the result of
only the loss analysis, and in the lower
half the result of the combined analysis,
which rejects a ﬂow if either the delay
or the loss analysis fails.
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(a) Recall when fr = 20%
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(b) Recall when fr = 40%
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(c) Recall when fr = 60%
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(d) Recall when fr = 80%
Figure 4.7: Recall of the loss analysis
as we vary fr, for the case of uniform
drops on the whole trafﬁc and on one
selected ﬂow (Scenario 2).
packets and a droptail buffer management policy .
4.3.1 One shaped ﬂow
W e start by examining a scenario in which only one ﬂow is being
differentiated by the shaper . W e proceeded by taking the trace pre-
viously described and by adding an extra ﬂow of which we varied
the number of packets in order for it to be a fraction fr of the total
amount of packets of the trace. This is the ﬂow that will be targeted
by the shaper . Our results are in terms of precision and recall, which
show respectively the fraction of detected ﬂows that we know are
indeed shaped, and the fraction of shaped ﬂows that are correctly
detected.14 Perfect performance translates into a precision and recall 14 W e deﬁne precision as being the num-
ber of true positives ( TP) over the
number of positives ( P), and recall
as the number of true positives over
the sum of true positives and false
negatives ( FN), that is to say over
the number of ﬂows that we know
were shaped. More details can be
found on http://en.wikipedia.org/
wiki/Precision_and_recall
of 100%.
Shaping pipe (Scenario 1). In this conﬁguration the bandwidth bw of
the upper pipe on the left side is set as a function of the average send-
chapter 4 . chkdiff : the upstream experiment 69
ing rate r (in bits per second) of the shaped ﬂow , computed before the
experiment begins. W e chose bw = kbw r, so that a fraction kbw ∈(0, 1 ]
of packets of the shaped ﬂow would use all the available pipe band-
width bw and the rest would queue up. W e ran ChkDiff 3 times
for each combination of kbw and fr, with kbw ∈{ 0.2, 0.4, 0.6, 0.8, 1.0 }
and fr ∈{ 0.2, 0.4, 0.6, 0.8 }. These are the values we used also in all
the following experiments in Scenario 1. The results are provided in
Figure 4.6, where we chose a compact representation in which each
circle shows in the upper-left quarter the result of the delay analysis,
in the upper-right quarter the result of the loss analysis and in the
lower half the result of the combined analysis. Since in this scenario
a shaping pipe causes queueing delays and, in case its queue ﬁlls
up, drops packets, we directly evaluate the beneﬁts of combining the
two analyses in such setting. In this basic scenario, we see that the
combined analysis manages to always identify the shaped ﬂow . At
kbw = 1 we observe that the ﬂow still experienced some queueing, as
a result of the pipe bandwidth being a function of the average sending
rate of the ﬂow and not of its instantaneous rate.
Uniform drops (Scenario 2). Our goal in Scenario 2 is to verify to
which extent ChkDiff manages to identify a shaped ﬂow , when losses
affect a selected ﬂow and the entire trafﬁc at different rates. W e
conﬁgured the shaper so that the upper pipe in Figure 4.5 drops a
fraction lr of the packets of the ﬂow to shape, and the pipe on the
right-hand side, where all trafﬁc goes, has a drop rate lrall . W e var-
ied again the size of the targeted ﬂow and ran experiments with
fr ∈ {0.2, 0.4, 0.6, 0.8 }. For this and all the following experiments
in Scenario 2, we chose lr ∈ {0.05, 0.1, 0.2, 0.4, 0.6, 0.8 }and lrall ∈
{0.2, 0.4, 0.6, 0.8 }. W e do not include the graphs on precision, since
all results show a precision of 100%, which means that we never en-
countered any false positives or , in other words, all the ﬂows detected
by ChkDiff as being shaped were indeed shaped. On the other hand,
some false negatives (i.e. shaped ﬂows that go undetected) did occur ,
so our analysis will focus on recall. In Figure 4.7 we present the re-
sults for this scenario. W e only show the results of the loss analysis,
since in this scenario delays are not affects. On the X-axis we plot
the loss rate lrall for all packets of the trace, whereas on the Y -axis
we show the overall loss-rate lrshaped experienced by the shaped ﬂow:
1 − (1 − lr)(1 − lrshaped ). The tool achieves 100% recall in all cases
except those in which, with a low fr and a fairly high ( ≥ 40%) overall
loss rate, the loss rate of the shaped ﬂow is close to the global one.
The added loss rates on the lower diagonal of the graphs correspond
to lr = 0.05, which could be too low to be noticeable on samples of
relatively small size. In all other cases, the tool correctly identiﬁed
the shaped ﬂow .
70 inference of network neutrality violations with active me asurements
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
precision
TP/P
(a) Precision of the combined analysis
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(b) Recall of the combined analysis
Figure 4.8: Precision and recall of the
combined analysis, for the case of mul-
tiple shaped ﬂows, in Scenario 1.
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(a) Recall when fr = 20%
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(b) Recall when fr = 40%
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(c) Recall when fr = 60%
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(d) Recall when fr = 80%
Figure 4.9: Recall of the loss analysis
as we vary fr, for the case of uniform
drops on the whole trafﬁc and on mul-
tiple selected ﬂows (Scenario 2).
4.3.2 Multiple shaped ﬂows
W e now move to a more complex scenario, in which multiple ﬂows
are being targeted by the shaper . In order to select which ﬂows to
shape, given a fraction fr of the trace size to differentiate, we iter-
atively picked the ﬂow whose size (in Bytes) was the closest to the
target fr, until the total amount was reached.
Shaping pipe (Scenario 1). W e set the bandwidth bw of the shaping
pipe as a function of the average sending rate of all packets belong-
ing to the ﬂows to shape. All shaped ﬂows pass through the same
shaping pipe so as to be able to compensate for one transmission
time only in the lower pipe. W e present the results for this scenario
in Figure 4.8. While the precision reached appears to be optimal,
the recall plots show that, quite expectedly , when the shaped ﬂows
amount to a large fraction of the trace, the baseline for comparison
becomes too weak for the test to work.
chapter 4 . chkdiff : the upstream experiment 71
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
precision
TP/P
(a) Precision of the combined analysis
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(b) Recall of the combined analysis
Figure 4.10: Precision and recall of the
combined analysis, for the case of mul-
tiple shaped ﬂows with a WiFi connec-
tion, in Scenario 1.
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(a) Recall when fr = 20%
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(b) Recall when fr = 40%
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(c) Recall when fr = 60%
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(d) Recall when fr = 80%
Figure 4.11: Recall of the loss analysis
as we vary fr, for the case of uniform
drops on the whole trafﬁc and on mul-
tiple selected ﬂows with a WiFi connec-
tion (Scenario 2).
Uniform drops (Scenario 2). In the scenario with uniform drops, we
used a different shaping pipe for each ﬂow to differentiate, in order
to have the same loss rate lr for all shaped ﬂows. Results are pro-
vided in Figure 4.9, where we omitted the plots on precision, since
it reached the optimal value ( 100%) for all combinations of parame-
ters. In the four subplots, we are mostly interested in the area with
lrall ∈ [0.0, 0.2 ], as it best represents a realistic setting: in a network
with no ( 0%) or relatively high ( 20%) packet drops, a shaper causes
losses of various degrees to part of the trafﬁc passing through it.
For completeness, we also show cases with higher losses and a large
fraction of affected trafﬁc. When 20% of the trafﬁc is targeted, we are
able to detect all differentiated ﬂows, except when the shaped ﬂows
experience just 5% more of losses, on top of the 20% overall loss rate
of the trace. W e observe that, as we shape an increasing fraction of
the trace, the loss analysis signiﬁcantly degrades. The reason is that,
with several ﬂows being differentiated, the baseline will necessarily
72 inference of network neutrality violations with active me asurements
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
r = 30pps
0
20
40
60
80
100
recall
TP/(TP + FN)
(a) Recall of the combined analysis, r =
30 pps
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
r = 50pps
0
20
40
60
80
100
recall
TP/(TP + FN)
(b) Recall of the combined analysis, r =
50 pps
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
r = 80pps
0
20
40
60
80
100
recall
TP/(TP + FN)
(c) Recall of the combined analysis, r =
80 pps
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
r = 100pps
0
20
40
60
80
100
recall
TP/(TP + FN)
(d) Recall of the combined analysis, r =
100 pps
Figure 4.12: Scenario 1 with multiple
shaped ﬂows and ICMP rate limitation
at 20 pps.
include more and more shaped ﬂows and the statistical analysis will
be impacted. However , this constitutes an extreme case for our tool
and it is unlikely to be encountered in practice.
4.3.3 Multiple shaped ﬂows over WiFi
W e repeat the same experiments as in the previous section, with
multiple shaped ﬂows, but we use a WiFi connection between the
client and the middlebox in order to stress the delay analysis. Fig-
ures 4.10 and 4.11 show the results for respectively Scenarios 1 and
2. In both cases, the results are qualitatively similar to the previous
setup, where we used a wired connection.
4.3.4 ICMP rate limitation
W e also wanted to verify how resilient our analysis is when we en-
counter a router that implements ICMP rate limitation. W e tested
ChkDiff in the same wired experimental setups as before and conﬁg-
ured the router to respond at most at 20 pps (with a burst size of 20
packets and a period of 1 second), a common setting we found for
Cisco routers, as seen in Chapter 3. W e repeated the experiments of
Scenarios 1 and 2 at different sending rates ( 30, 50, 80 and 100 pps)
higher than the ICMP rate limitation threshold. Our aim is to stress
our tool when an additional source of losses is present and see how
high our sending rate r can be, with respect to the rate limitation
chapter 4 . chkdiff : the upstream experiment 73
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
 fr = 20%, rate= 30pps
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(a) Recall of the loss analysis,
fr = 20%, r = 30 pps
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
 fr = 20%, rate= 100pps
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(b) Recall of the loss analysis,
fr = 20%, r = 100 pps
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
 fr = 40%, rate= 30pps
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(c) Recall of the loss analysis,
fr = 40%, r = 30 pps
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
 fr = 40%, rate= 100pps
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(d) Recall of the loss analysis,
fr = 40%, r = 100 pps
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
 fr = 60%, rate= 30pps
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(e) Recall of the loss analysis,
fr = 60%, r = 30 pps
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
 fr = 60%, rate= 100pps
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(f) Recall of the loss analysis,
fr = 60%, r = 100 pps
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
 fr = 80%, rate= 30pps
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(g) Recall of the loss analysis,
fr = 80%, r = 30 pps
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
 fr = 80%, rate= 100pps
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(h) Recall of the loss analysis,
fr = 80%, r = 100 pps
Figure 4.13: Scenario 2 with multiple
shaped ﬂows and ICMP rate limitation
at 20 pps.
implemented on the router side, while still minimizing errors.
In Figure 4.12 we show the recall plots of the combined analysis
in the case of Scenario 1, where a shaping pipe throttles the band-
width of multiple selected ﬂows. Since ICMP rate limitation only
causes packet drops, it is no surprise that the delays are no more af-
fected than they were in the previous case when the router was fully
responsive (Figure 4.8 (b)). W e omit here and in the next scenario
the results for one shaped ﬂow , since they always showed maximum
74 inference of network neutrality violations with active me asurements
precision and recall.
W e conducted again the experiments of Scenario 2, where uniform
drops are applied to selected ﬂows and to the whole trafﬁc with
different probabilities, and we provide the results in Figure 4.13. For
constraints of space, we only show the results for the minimum and
maximum probing rates we considered: 30 and 100 pps. W e observe
that the loss test experiences considerable degradation only in the
extreme case of multiple shaped ﬂows corresponding to 80% of the
trace. Most importantly , varying the probing rate from 1.5 (30 pps,
with a router-induced loss rate of 33%) to 5 times ( 100 pps, with a
router-induced loss rate of 80%) the ICMP rate limitation threshold
of the router does not appear to alter signiﬁcantly the results.
4.3.5 A more complex scenario
In a realistic setting, if a user dumps her own trafﬁc while some TCP
ﬂows are being targeted by a shaper that throttles their bandwidth,
the sending rate of these ﬂows inside the captured trace will already
have been reduced by the shaper . If ChkDiff replays this trace at its
original sending rate, the TCP ﬂows that were previously throttled
will now comply with the shaper ’s policies and will not of course
experience any further degradation. It is therefore important to scale
up our probing rate with respect to the original one, in order to be
able to trigger and detect the presence of a shaper .
W e set up a wired scenario with a shaper , ICMP rate limitation
and cross trafﬁc. In the same way as in Section 4.3.1, we created a
ﬂow constituting 20% of the total trace size and injected it in our
trace so that it would be evenly spread out and have consequently
a constant sending rate rﬂow . The shaper was conﬁgured as in the
previous case of a shaping pipe affecting one ﬂow only , and its band-
width was set to rﬂow . The router activated ICMP rate limitation at
50 pps, a common value for Juniper routers, as we showed in Chap-
ter 3. Finally , we added some cross trafﬁc ﬂowing on average at 20%
of our sending rate and implemented as a series of bursts of ping
packets following a Poisson process. W e conﬁgured the bandwidth
of the pipe on the right-hand side in Figure 4.5 to be equal to the
sum of the rate of the trace and of the cross trafﬁc. This way , the
whole trace also experiences queueing.
In this setup, we assess whether a shufﬂed trace replayed at a
constant rate is indeed more robust to transient network conditions
than the original trace replayed as it is. W e increased the probing rate
r by a factor of 1.5, 2, 4, 8 and 16 times the original probing rate rorig
Rate
1x 1.5x 2x 4x 8x 16x
Original
trace
T rue Positives 0 1 1 1 1 1
False Positives 11 3 3 1 2 1
Shufﬂed
trace
T rue Positives 0 1 1 1 1 1
False Positives 0 0 0 0 0 0
T able 4.1: Number of true and false pos-
itives when replaying the original and a
shufﬂed trace at different sending rates.
chapter 4 . chkdiff : the upstream experiment 75
of the trace (with rorig = 64 pps) and counted in T able 4.1 the number
of false positives of the delay analysis across 3 runs. W e see that, even
though in both cases we correctly identify the shaped ﬂow already
at 1.5 x, we never encounter any false positives when replaying a
shufﬂed trace. With the original trace, on the other hand, we always
obtained some false positives; their number seems to decrease with
high probing rates only because the amount of ﬂows with sufﬁcient
samples also decreases.
4.4 Assessment with respect to existing methods
A number of tools for the detection of trafﬁc differentiation have
been proposed in the literature in the past few years, as detailed in
Chapter 2.
A work that has some aspects in common with the upstream ex-
periment of ChkDiff is NetPolice, 15 where the authors were able to 15 Ying Zhang, Zhuoqing Morley Mao,
and Ming Zhang. Detecting trafﬁc
differentiation in backbone isps with
netpolice. In Proceedings of the 9th
ACM SIGCOMM Conference on Internet
Measurement Conference , IMC ’ 09, pages
103–115. ACM, 2009
detect differentiation in backbone networks with the use of TTL-
limited probes. Using synthetic traces made of HTTP , peer-to-peer ,
BitT orrent and other application ﬂows, they probed ingress and egress
routers of backbone ISPs from a large set of PlanetLab nodes in or-
der to notice any difference in loss rates along the same path seg-
ment: if any difference was observed, they tried to attribute it to
content-based differentiation (with the HTTP ﬂow as baseline) or ,
when the discrepancy was between different IP sources or destina-
tions, to routing-based differentiation. Our approach does leverage
TTL-limited probes, but it is client-oriented (in a traceroute-like man-
ner), it focuses on the user ’s access ISP , and does not make assump-
tions on which ﬂows should be considered as non-differentiated in
its analysis.
One of the ﬁrst tools presented to the scientiﬁc community was
BT-T est,16 which checks for TCP reset packets injected by ISPs dur-
16 Marcel Dischinger , Alan Mislove, An-
dreas Haeberlen, and Krishna P . Gum-
madi. Detecting BitT orrent Blocking.
In Proceedings of the 8th ACM SIG-
COMM Conference on Internet Measure-
ment (IMC’ 08), V ouliagmeni, Greece,
October 2008
ing the replaying of a typical BitT orrent packet exchange between a
user and controlled server . Its aim was to disclose a practice that had
been recently reported by some U.S.-based users. The same authors
later proposed a more comprehensive tool, Glasnost, 17 that compares
17 Marcel Dischinger , Massimiliano
Marcon, Saikat Guha, Krishna Gum-
madi, Ratul Mahajan, and Stefan
Saroiu. Glasnost: Enabling End Users
to Detect T rafﬁc Differentiation. In
Proceedings of the 7th Symposium on
Networked Systems Design and Imple-
mentation (NSDI) , San Jose, CA, Apr
2010
the maximum throughput of an application ﬂow (e.g., BitT orrent,
Y ouT ube, etc) to that of a control ﬂow whose packets are the same
as in the application ﬂow except for their payload, which is random-
ized. The packets of the two ﬂows are interleaved so as to experience
the same network conditions and are replayed to a server . This tech-
nique expects trafﬁc differentiation to happen at the application layer
by means of deep packet inspection, and to result in lower through-
put for the affected application. ChkDiff is also able to detect such
cases, since a lower throughput is the result of higher packet delays,
but we do not make the assumption that a shaper targets a speciﬁc
application and that it discriminates according to packet payloads.
A tool that also focuses on a speciﬁc application and control ﬂow
is DiffProbe, 18 which attentively analyzes the delay and loss distri- 18 Partha Kanuparthy and Constantine
Dovrolis. Diffprobe: detecting ISP ser-
vice discrimination. In Proceedings of the
29th conference on Information communi-
cations, INFOCOM’ 10, pages 1649–1657,
Piscataway , NJ, USA, 2010. IEEE Press
butions of the two ﬂows during a replaying phase at the normal
76 inference of network neutrality violations with active me asurements
application sending rate and during a replaying phase at a higher
rate, which attempts to create congestion at possible shapers along
the path. The control ﬂow is crafted much in the same way as pre-
viously described, with the addition of transport layer ﬁelds such
as port number being modiﬁed in order to bypass shapers. This tool
was soon followed by ShaperProbe, 19 which assumes that differentia- 19 Partha Kanuparthy and Constantine
Dovrolis. Shaperprobe: End-to-end de-
tection of isp trafﬁc shaping using ac-
tive methods. In Proceedings of the 2011
ACM SIGCOMM Conference on Internet
Measurement Conference , IMC ’ 11, pages
473–482. ACM, 2011
tion happens through a token bucket and tries to infer its parameters
(buffer size and processing rate). It sends at the path capacity trains
of packets back-to-back to a server and, if they traverse a shaper , it
expects to observe a level shift in the received rate at the destina-
tion. While both methods undoubtedly provide more insight than
ChkDiff on the characteristics of shapers, they analyze the behaviour
of one application at a time and, even if in principle they can adapt
to any application, they are in practice limited to the packet traces
provided with the executables (i.e. Skype, in this case). Packsen 20 20 Udi W einsberg, Augustin Soule, and
Laurent Massoulié. Inferring trafﬁc
shaping and policy parameters using
end host measurements. In INFOCOM,
pages 151–155, 2011
has a similar approach to DiffProbe, but it improves on it by using
a less computationally expensive statistical analysis in order to infer
the shaper type and parameters.
Nano21 differs from existing solutions in that it carries out passive 21 Mukarram Bin T ariq, Murtaza Moti-
wala, Nick Feamster , and Mostafa Am-
mar . Detecting network neutrality vio-
lations with causal inference. ACM SIG-
COMM CoNext , page 289, 2009
measurements on user trafﬁc and compares it against a data set of
other users in the same geographical area, with comparable machine
setups, at the same time of the day , but connected to a different ISP .
While this method is undeniably independent of user applications
and differentiation techniques, its main disadvantage is that it needs
a fairly large number of users for it to be operational.
More recently , a theoretical framework for the inference and lo-
calization of neutrality violating links has been proposed. 22 After 22 Zhiyong Zhang, Ovidiu Mara, and
Katerina Argyraki. Network neutral-
ity inference. In Proceedings of the 2014
ACM Conference on SIGCOMM , SIG-
COMM ’ 14, pages 63–74, New Y ork,
NY , USA, 2014. ACM
conducting measurements from different vantage points traversing
the same links, it builds a linear system of equations in the same
fashion as in network performance tomography . When the network
is neutral, such system is supposed to be solvable and it infers prop-
erties of the links. When instead a link is not neutral, the measure-
ments are inconsistent and the system unsolvable. The deployment
of such method would require a large and diverse user base, where
several vantage points perform measurements on the same set of
paths and send the results to a central server , which would process
the data and infer differentiation. Our approach is instead conﬁned
to the network performance experienced by the end user who runs
the tool: no aggregation of results across users is necessary .
4.5 Summary
In this chapter we presented the upstream experiment of ChkDiff,
a novel tool for the detection of trafﬁc differentiation at the Inter-
net access. After replaying the user outgoing trafﬁc to the routers at
the ﬁrst few hops, the tool applies a statistical analysis to delays and
losses in order to infer whether any of the replayed ﬂows experienced
degraded performance. W e validated ChkDiff in a controlled envi-
ronment with different setups and showed its robustness to ICMP
chapter 4 . chkdiff : the upstream experiment 77
rate limitation.
In the next chapter , we extend ChkDiff so that it includes an ex-
periment for downstream trafﬁc, which we shufﬂe and replay to the
user from a dedicated measurement server in order to detect differ-
entiation.

5
ChkDiff: the downstream experiment
W e saw in the previous chapter that ChkDiff directly addresses the
problems of scalability to different user applications and of applica-
bility to different shaping techniques affecting delays and losses. W e
achieve this by performing active measurements with the real user
trafﬁc, comparing the performance of a ﬂow against the performance
of the rest of the replayed trafﬁc, and by analyzing for each ﬂow its
delays and losses, which reﬂect any alteration introduced by a shaper
inside the network.
This chapter complements Chapter 4, in which we focused on the
user ’s upstream trafﬁc and replayed it with low TTL values in a
traceroute-like manner against the routers at the ﬁrst few hops away
from the user in order to detect differentiation and localize shapers.
W e extend this with a new experiment in the downstream direction,
where we replay the user ’s incoming trafﬁc from a server , measure
one-way delays and losses, and check for differentiation on a per-
ﬂow basis. W e describe in details the measures taken by ChkDiff
in order to successfully deliver the replayed trace and validate the
tool in two differentiation scenarios, with the server located in three
different data centers, and over wired, WiFi and 3G connections.
The chapter is organized as follows: in Section 5.1 we provide
a detailed description of the methodology we used in ChkDiff; in
Section 5.2 we validate the tool; we discuss our method in Section 5.3
and assess it with respect to related work in Section 5.4; we give
closing remarks in Section 5.5.
W e presented the results of this chapter in a paper published at
ITC 28.1 1 Riccardo Ravaioli, Guillaume Urvoy-
Keller , and Chadi Barakat. T esting for
trafﬁc differentiation with chkdiff: the
downstream case. In T eletrafﬁc Congress
(ITC 28), 2016 28 th International . IEEE,
2016
5.1 Methodology
The design of a new tool for the detection of trafﬁc differentiation has
to necessarily consider two weak points of existing methods: the dif-
ﬁculty to scale to different applications and the limitation to speciﬁc
differentiation techniques. As illustrated in Chapter 4, we overcome
this in three steps: a) we use the real trafﬁc of a user and not a syn-
thetic trace; b) we minimize the modiﬁcations to the trace needed for
the experiment to work and c) we analyze the performance of a ﬂow
in terms of delays and losses with respect to the rest of the trace in
80 inference of network neutrality violations with active me asurements
(a) Upstream experiment
 (b) Downstream experiment
Figure 5.1: The two experiments in
ChkDiff.
order to infer neutrality violations: these two metrics alone are able
to capture the effect of shapers at the IP layer .
A complete run of ChkDiff consists of two experiments, one that
replays the user ’s outgoing trafﬁc (upstream direction) to the routers
at the ﬁrst few hops away from the user and one that replays the
user ’s incoming trafﬁc (downstream direction) from a measurement
server to the user . W e report in Algorithm 2 an outline of a full
execution of ChkDiff.
At ﬁrst the tool dumps client trafﬁc for a time window of typ-
ically 3-5 minutes, while the user is asked to run the applications
and services of an Internet session she wishes to test. Next, packets
are grouped into 5-tuple ﬂows (source and destination IP addresses,
transport protocol, source and destination port numbers), which are
further arranged into an outgoing trace, traceout , and an incoming
one, tracein . W e now brieﬂy recall the upstream experiment, fully
described in Chapter 4, and then go on to illustrate in detail the
methodology for the downstream case.
5.1.1 Upstream experiment, in a nutshell
Non-trivial outgoing trafﬁc that an access ISP might want to differ-
entiate includes media uploading, P 2P ﬁle sharing and V oIP; a run
of ChkDiff in the upstream direction should ideally test at least one
type of such trafﬁc. Before conducting the actual experiment, we
shufﬂe traceout in such a way that the position of the packets of each
ﬂow inside the trace follows a Poisson process, so that according
to the P AST A property (Poisson Arrivals See Time A verages), 2 each 2 Ronald W W olff. Poisson arrivals
see time averages. Operations Research ,
30(2):223–231, 1982ﬂow will see the same network conditions when the trace is replayed.
chapter 5 . chkdiff : the downstream experiment 81
The order of packets within each ﬂow is preserved. As in the ﬁrst
half of Algorithm 2, we consider the ﬁrst few hops away from the
user , at or in proximity of her access ISP network (up to hop 3 or 4,
as in Figure 5.1(a)), and for each hop h we replay traceout at a con-
stant sending rate higher than the original one and with a modiﬁed
IP TTL set to h, so that the trace will expire on the router(s) at hop
h and generate ICMP time-exceeded messages. W e showed the va-
lidity of this ICMP feedback in Chapter 3, along with its robustness
to ICMP rate-limitation. Each ﬂow having its own set of Round-T rip
Times (RTT’s) and losses, we can now compare its performance up
to a given hop to that of the rest of the ﬂows along the same path.
W e use Kolmogorov-Smirnov test to analyze delays and a binomial-
inspired test to analyze losses. By aggregating the results of each
ﬂow across consecutive hops we are able to infer the presence of a
shaper and localize it in terms of number of hops from the client.
5.1.2 Downstream experiment
In this chapter , we present the downstream version of ChkDiff and
validate it experimentally . In brief, the experiment in the down-
stream direction consists in taking all necessary measures to replay
the original incoming ﬂows, having the server replay the trace to
the client and ﬁnally analyzing the results in a way that takes into
account the possibility of having multiple paths to the client (Fig-
Algorithm 2 ChkDiff complete execution
1: Capture user trafﬁc, store into traceout and tracein
2: ⊲ Upstream experiment
3: for each hop h ∈ {1, 2... k} do
4: for each run r ∈ {1, 2, 3 } do
5: shufﬂe traceout
6: replay traceout with T T L ← h
7: collect ICMP time-exceeded replies
8: end for
9: detect shaped ﬂows at hop h
10: end for
11: aggregate results and locate shaper(s), if any
12: ⊲ Downstream experiment
13: for each run r ∈ {1, 2, 3 } do
14: shufﬂe tracein
15: for each ﬂow f in tracein do
16: ﬁnd NA T mapping for f
17: initiate connection from client
18: end for
19: replay tracein from server to client
20: compute one-way delays and losses
21: end for
22: detect shaped ﬂows
82 inference of network neutrality violations with active me asurements
ure 5.1(b)).
The second half of Algorithm 2 outlines the main steps of the
downstream experiment, which we describe in details in the remain-
der of this section. First, we need to shufﬂe tracein in the same way
we did in the upstream experiment. This allows us to eliminate cross
trafﬁc noise from the effects of possible neutrality violations. Then,
for a replayed ﬂow to be able to successfully reach the client, we need
to deal with possible Network Address T ranslation (NA T) and ﬁre-
wall devices a user might be behind and also other possible middle-
boxes that might be deployed along the path from the server . After
all connections are initiated from the client side, the server replays
the shufﬂed tracein to the client at a rate higher than the original one.
W e compute One-W ay Delays (OWD’s) for each ﬂow and note the
number of losses, if any . In order to infer differentiation, we run a
clustering analysis on delays so that we can distinguish when differ-
ent delay distributions are due to shaping and when they are due to
a variety of paths. Lastly , a test on ﬂow losses completes the analysis.
W e elaborate now on each of the above actions.
Getting ready for replaying. As opposed to the upstream experiment
(Chapter 4), we do not truncate or pad packets in tracein to a ﬁxed
size. In the upstream experiment the low variability of the total delay
along a short wired path is in the same order of magnitude as the
variability of the transmission delay , which is proportional to the
packet size. That makes it impractical to replay packets exactly as
captured, since ﬂows with large packets over a wired connection
experience larger delays solely because of their packet size. For the
downstream case, we examine a much longer path in terms of hops
and delays, and such source of error is canceled out by the inherent
delay variability along a larger path. Therefore we are able to replay
the packets with their original payloads, as seen by the client upon
receiving them.
Replaying incoming trafﬁc from a single source (i.e. our server)
means that we cannot keep the original source IP addresses of the
user trace, for two main reasons. Firstly , most access networks today
are conﬁgured to drop outgoing packets with a source address that
does not belong to the address space of the access network itself. In
other words, they do not allow IP address spooﬁng. 3 Secondly , as we 3 BCP 38 - Network Ingress Filter-
ing: Defeating Denial of Service At-
tacks which employ IP Source Ad-
dress Spooﬁng. URL: https://
tools.ietf.org/html/bcp38
will see shortly , if a NA T device is present, we can replay a ﬂow only
if we ﬁnd the mapping applied by the NA T to that ﬂow for external
endpoints. Since we are not in control of other endpoints (that is to
say , all network applications or services run by the user) than our
measurement server , we need to overwrite the IP source address of
each packet in tracein with the IP address of the server; original port
numbers are retained. Conversely , in the upstream experiment the
original source and destination IP addresses are preserved. How-
ever , even if in the downstream case we lose the ability to reveal
shapers based on the source IP address, we can combine upstream
and downstream experiments to overcome the limitations of both.
chapter 5 . chkdiff : the downstream experiment 83
Furthermore, the commercial shapers studied in a recent work 4 do 4 Arash Molavi Kakhki, Abbas Razagh-
panah, Anke Li, Hyungjoon Koo, Ra-
jesh Golani, David Choffnes, Phillipa
Gill, and Alan Mislove. Identifying traf-
ﬁc differentiation in mobile networks.
In Proceedings of the 2015 ACM Confer-
ence on Internet Measurement Conference ,
pages 239–251. ACM, 2015
not use this piece of information to classify ﬂows.
After being shufﬂed, tracein is sent via FTP to the server . While we
deploy a server with a public IP address, listening on a known port,
a client is likely less easy to reach: a few network elements need to
be considered before we can replay the trace to the client.
• NA T’s. In today’s networks, where IPv 4 addresses are running
out, deploying a NA T device has become a widespread practice.
For our purposes, this means that the client’s view of a ﬂow might
not be the same as the server ’s. Since the trace to replay is orig-
inally as seen by the client, we might need to modify the desti-
nation IP address and port number in order to reach the client
from an external endpoint (Figure 5.1(b)). NA T devices are usu-
ally deﬁned according to how they map the same source pair
X: x of IP address X and port number x of an internal network
when different external destination IP addresses and port num-
bers are reached (for instance Y1 : y1 and Y2 : y2 ).5 W e distinguish 5 RFC 4787 - Network Address T rans-
lation (NA T) Behavioral Requirements
for Unicast UDP. URL: http://
tools.ietf.org/html/rfc4787
RFC 5382 - NA T Behavioral Re-
quirements for TCP. URL: http://
tools.ietf.org/html/rfc5382
four cases: (i) in the simplest scenario the mapping is indepen-
dent of the external destination endpoint and will not change for
the same source pair X: x; (ii) some NA T’s generate the same map-
ping only with same external destination IP address ( Y1 ≡ Y2 ) or
(iii) with the same external destination IP address and port number
(Y1 ≡ Y2 and y1 ≡ y2 )) and (iv) the mapping might be connection-
dependent and vary each time a new connection to the same ex-
ternal destination pair is initiated.
• Firewall. W e assume that any user is protected by a ﬁrewall from
the outer network. Consequently , all ﬂows need to be initiated
from the user side (a technique called hole punching) before the
server can replay the trace. For TCP ﬂows, we reproduce the
whole 3-way handshake without the interaction of the kernel on
both endpoints. W e assign an initial sequence number for each
side of a TCP ﬂow and modify it accordingly in the data packets.
For UDP ﬂows, we only send one probe from the client.
• Initial sequence numbers. It has been observed that some mid-
dleboxes overwrite the initial sequence number of TCP ﬂows. 6 6 Michio Honda, Y oshifumi Nishida,
Costin Raiciu, Adam Greenhalgh, Mark
Handley , and Hideyuki T okuda. Is it
still possible to extend TCP? In Proceed-
ings of the 2011 ACM SIGCOMM Confer-
ence on Internet Measurement Conference ,
IMC ’ 11, pages 181–194, New Y ork, NY ,
USA, 2011. ACM
Gregory Detal, Benjamin Hesmans,
Olivier Bonaventure, Y ves V anaubel,
and Benoit Donnet. Revealing middle-
box interference with tracebox. In Pro-
ceedings of the 2013 Conference on Internet
Measurement Conference , IMC ’ 13, pages
1–8, New Y ork, NY , USA, 2013. ACM
Since ﬁrewalls can easily keep track of the sequence numbers and
reject inconsistent packets, it is important to intercept the over-
written sequence number from the SYN packet of the TCP hand-
shake and modify all subsequent sequence and acknowledgement
numbers individually for each TCP ﬂow .
• Timeouts. In NetFilter , 7 the standard ﬁrewall provided in Linux,
7 NetFilter: Firewalling, NA T and
packet mangling for Linux. URL:
www.netfilter.org
the TCP timeout for established connections is 5 days, while for
UDP it is only 30 seconds whether packets have been seen in one
or both directions. This means that we need to make sure that the
time elapsing between two consecutive packets of each UDP ﬂow ,
initial probes included, is less than 30 seconds. NA T mappings ex-
pire too in order to remove stale entries from the NA T table. Given
the large amount of commercial NA T devices, we refer in this case
84 inference of network neutrality violations with active me asurements
to the requirements and guidelines found in the RFC’s. For UDP
ﬂows the timeout should not be less than 2 minutes, while 5 min-
utes is recommended; 8 for TCP if the connection is not yet in the 8 RFC 4787 - Network Address T rans-
lation (NA T) Behavioral Requirements
for Unicast UDP. URL: http://
tools.ietf.org/html/rfc4787
established state, the timeout should not be less than 4 minutes,
and if it is already in the established state it should be no less than
2 hours and 4 minutes.9 These values are all large enough for 9 RFC 5382 - NA T Behavioral Re-
quirements for TCP. URL: http://
tools.ietf.org/html/rfc5382
the purpose of our experiment and do not interfere with ChkD-
iff. Finally , to avoid unnecessary synchronization between client
and server , we do not actually send any acknowledgments from
the client side for the TCP ﬂows we replay . In the Linux kernel,
the socket parameter TCP_USER_TIMEOUT sets the maximum
amount of time that data can be transmitted without being ac-
knowledged. Its default value is 20 minutes,10 which is roughly 10 Linux Programmer ’s Manual - TCP
protocol . URL: http://man7.org/
linux/man-pages/man7/tcp.7.html
one order of magnitude larger than a single run of ChkDiff.
Given that our goal is not to classify all possible devices along a
path but to rapidly deliver the trace to the client, we take a conserva-
tive approach and assume that the most stringent restrictions among
the above ones are in place. W e expect the NA T to be connection-
dependent and perform a per-ﬂow mapping discovery already dur-
ing the hole punching initiated by the client against her ﬁrewall. For
each ﬂow , we encrypt the client’s view of its source IP address and
port number and add it to the payload of its SYN packet or UDP
probe, as NA T devices are expected to overwrite every occurrence of
the client’s own IP address in a packet. W e set the client-side initial
sequence number of TCP ﬂows in accordance to the acknowledge-
ment numbers used in the trace (since no packets are sent from the
client during the replaying phase, the acknowledgement number of
a TCP ﬂow sent by the server is constant across packets of the same
ﬂow). From the server side, for TCP ﬂows, we keep track of incoming
SYN packets along with the observed sequence numbers and client’s
source pair , and mimic the TCP handshake; for UDP ﬂows we just
keep track of client’s and server ’s views of the client-side source pair .
When these two views differ , we modify the client-side IP address
and port number of the corresponding ﬂows in tracein with the pair
as seen by the server . The server also overwrites the acknowledge-
ment number of a TCP ﬂow , when the number in the trace does not
match the sequence number seen in the received SYN packet. Ad-
ditionally , in order to overcome the relatively short timeout on UDP
ﬂows, we enforce a maximum interval of 30 seconds between any
two UDP packets of the same ﬂow when shufﬂing tracein and start
a timeout on the client side to make sure that we do not exceed 30
seconds between the initial UDP probe of a ﬂow and its ﬁrst occur-
rence in the trace. W e discard the current run of the experiment and
start a new one if ever this timeout expires. In any case, during an
ordinary execution of ChkDiff only a few seconds elapse between
hole punching and the start of the replaying phase.
W e avoid the overhead of opening a socket for each ﬂow and re-
playing the trace from the application layer by injecting packets with
chapter 5 . chkdiff : the downstream experiment 85
Figure 5.2: Conﬁguration of client and
server .
tcpreplay11 directly between the IP layer and the Network Interface 11 T cpreplay . URL: http:
//tcpreplay.appneta.com/Card. Since we are emulating TCP and UDP ﬂows below the IP layer ,
we need to prevent our packets from reaching their respective client
applications, which could cause unsolicited trafﬁc or unexpected ap-
plication behaviour . Also, our hole-punching probes target ports on
the server on which no process should be listening and will trigger
TCP reset packets for TCP SYN probes, ICMP port-unreachable mes-
sages for UDP probes and real application packets if ever a process
is indeed listening. As error messages cross a ﬁrewall on their way
to the user , the corresponding newly-created connection entries are
removed. Therefore, we need a way to distinguish between experi-
ment packets and regular trafﬁc, so that we can drop the former right
before they reach the IP stack and we can allow the latter to pass
through. W e achieve this by assigning a unique number to each user
session and overwrite with this value the 2-Byte IP ID ﬁeld of each
experiment packet between a given user and the server . Through a
combined use of tcpdump and iptables, as shown in Figure 5.2, we
dump the experiment packets right at the Network Interface Card
and drop them before they reach the kernel, so that error messages
are never generated at either endpoint.
Replay. W e are now ready to replay the trace from the server at
a constant packet rate higher than the original one (by default, we
replay it at twice the original rate).
W e dump the replayed trace on both the server and the client and
then for each ﬂow we measure One-W ay Delays and note the number
of lost packets. For simplicity , we avoid any clock synchronization
between user and server: any effect due to clock skewing is not ex-
pected to disrupt the measured delays for the short time window of
one experiment (a few tens of seconds) and in any case will affect all
ﬂows equally , as they are evenly spread across the trace.
Once the server has completed the replaying phase, the client
closes the emulated TCP connections by sending an RST packet for
each TCP ﬂow in tracein . This has the added beneﬁt of clearing space
86 inference of network neutrality violations with active me asurements
Figure 5.3: Timeseries of an experiment
with packets following multiple paths.
Each packet is represented by a black
dot.
in the open connection table of the ﬁrewall, if ever a per-user restric-
tion is active.
Results analysis. The study of delays between two endpoints across
a path of several hops has to necessarily take into account the pos-
sibility of multiple paths. Discovering the paths taken by each ﬂow
would be cumbersome: ﬁrst of all, we do not know the exact hash
function applied in a load balancing decision and we observed that
some data centers, where the measurement server could be deployed,
make a massive use of load balancers; second of all, it would take
some extra time, as we would need to probe at low rates (i.e. 1 packet
per second) to bypass ICMP rate limitation - as seen in Chapter 3 -
and have a complete view of each path. An example is provided in
the timeseries of Figure 5.3, where we can visually identify at least
ﬁve different paths; a direct comparison between any two ﬂows be-
comes harder in this case. In the absence of the ground truth, we
can rely on the fact that non-differentiated ﬂows following the same
path will have similar delay distributions, which a clustering algo-
rithm can group together . A differentiated ﬂow going on any of the
available paths will show a distribution signiﬁcantly different from
that of all other ﬂows and should not belong to any of the discovered
groups. W e combine this with a loss analysis in order to capture the
behaviour of shapers.
• Delays. Our choice of clustering algorithm for delays is dbscan, 12 12 Martin Ester , Hans-Peter Kriegel, Jörg
Sander , and Xiaowei Xu. A density-
based algorithm for discovering clus-
ters in large spatial databases with
noise. In Kdd, volume 96, pages 226–
231, 1996
which groups together points that are in the same high-density
area and labels as outliers those that do not belong to any found
cluster . As a representative point for each ﬂow we take its 25th
percentile: it is close enough to the real path delay , it discards
possible queueing delays and it is robust to delay variations due
for example to WiFi. The algorithm then takes two parameters:
the minimum number n of core samples to form a cluster and
the maximum distance ǫ between any two samples for them to be
included as core points in a cluster . Since we expect shaped ﬂows
to stand out from non-shaped ﬂows, we set n to 2. As for ǫ, we
need a value that reﬂects the delay variations of a path: we take
the core values ( 2nd quartile range, i.e. the 25th-50th percentile
chapter 5 . chkdiff : the downstream experiment 87
Figure 5.4: Setup used in the validation
of ChkDiff, along with the shaper con-
ﬁguration.
range) of the delay distribution of each ﬂow , we aggregate them
and then pick for ǫ a large value in this set, the 75th percentile.
The output of dbscan will be a set of clusters of ﬂows and a set
of outliers. W e label the latter as having failed the delay analysis.
• Losses. W e compare the losses of a ﬂow to the loss rate of the rest
of the trace as a whole, in the way illustrated in Chapter 4. The
reasoning is the following: if a ﬂow i with si packets has not been
differentiated, its number of lost packets can be modeled as a bi-
nomial random variable of parameters B(si , p), where p is the loss
rate of the rest of the trace. If we approximate this binomial to a
normal random variable of parameters N(si p, si p(1 − p)), we can
verify whether the number of lost packets li of ﬂow i lies within
α standard deviations of the normal mean, where α is approxi-
mated to 2.58 for our chosen signiﬁcance level of 99%. Since we
are interested to know whether a ﬂow experienced more losses
than it should have with the global loss rate p, we check that
li < psi + α
√
p(1 − p)si . If the condition does not hold, the ﬂow
is rejected by our loss analysis.
Since a shaper affects the delays or the losses of a ﬂow , or both,
we reject a ﬂow if it fails either analysis.
W e repeat the whole experiment three times in order to remove
transient errors and claim that a ﬂow was differentiated if in all three
runs it failed the combined analysis of delays and losses.
5.2 V alidation
W e validate the downstream experiment of ChkDiff in wired, WiFi
and 3G setups (Figure 5.4) with a client located in France and the
server located in three different Amazon data centers: Germany , Ire-
land and Oregon (USA). The client is directly connected to a mid-
dlebox, where the shaper is deployed and which serves also as the
client’s gateway . In the WiFi setup, the client is connected to the
gateway through a dedicated WiFi network operating on the same
channel as the local University WiFi network to cause more link-level
collisions. In the 3G setup, the client is connected to the middlebox
via a wired connection and the middlebox is connected via WiFi to a
88 inference of network neutrality violations with active me asurements
mobile phone functioning as hotspot. W e test ChkDiff in the two dif-
ferentiation scenarios seen in Chapter 4: given a set of ﬂows we want
to differentiate, in Scenario 1 we throttle their bandwidth and in Sce-
nario 2 we apply a uniform packet drop rate to them. W e conﬁgure
dummynet13 on the middlebox to shape incoming trafﬁc, as shown 13 Marta Carbone and Luigi Rizzo.
Dummynet revisited. SIGCOMM Com-
put. Commun. Rev. , 40(2):12–20, April
2010
in the upper part of Figure 5.4. Flows to shape are forwarded to
the upper pipe, which applies the desired differentiation technique
according to the scenario we test; ﬂows that we do not intend to
differentiate go through the lower pipe, which only adds a constant
delay equal to the transmission delay of the upper pipe in Scenario
1 and has no effect in Scenario 2. This way , in Scenario 1 the differ-
ence in delays between shaped and non-shaped ﬂows is due only to
the queueing delay at the upper pipe. A ﬁnal pipe, where all ﬂows
eventually go, emulates a 100 Mbit/s link. In Scenario 2 this last pipe
causes uniform drops on the whole trace.
In all experiments we replay a trace of approximately 9000 pack-
ets captured during an Internet session of 3 minutes that included
watching a short streaming video, browsing a news website and
making a call on Skype. In dummynet, our pipes have a buffer length
of 100 packets and use droptail buffer management policy .
5.2.1 Shaping pipe (Scenario 1)
In this scenario, we compute in tracein the overall sending rate of the
ﬂows to shape and set the shaping pipe to a fraction kbw < 1 of this
value. The second parameter we vary is the fraction fr of packets
we shape. When picking which ﬂows to differentiate, we choose
iteratively the ﬂow closest to the target fr, until the desired size is
reached. All ﬂows we differentiate go through the same shaping
pipe. By combining delay and loss analysis, we show that we can
effectively identify all shaped ﬂows as long as the fraction fr does
not constitute most of tracein , which is what we expect when we take
the whole trace as baseline for comparison.
Figure 5.5: Distribution of ﬂow sizes for
the trace we used in the validation of
the tool.
(a) CDF of ﬂow sizes in # of packets.
 (b) CDF of ﬂow sizes in KB.
chapter 5 . chkdiff : the downstream experiment 89
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(a) Frankfurt, wired connection.
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(b) Ireland, wired connection.
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(c) Oregon, wired connection.
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(d) Frankfurt, WiFi connection.
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(e) Ireland, WiFi connection.
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(f) Oregon, WiFi connection.
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(g) Frankfurt, 3G connection.
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(h) Ireland, 3G connection.
0.2 0.4 0.6 0.8
fr
0.2
0.4
0.6
0.8
1.0kbw
0
20
40
60
80
100
recall
TP/(TP + FN)
(i) Oregon, 3G connection.
Figure 5.6: Recall of the combined anal-
ysis (delay and losses) for Scenario 1
over wired, WiFi and 3G connections.
W e present in Figure 5.6 the results in terms of recall 14 for each of
14 The deﬁnition of recall we use is
the classic one: the number of true
positives over the sum of true posi-
tives and false negatives; in our spe-
ciﬁc case, it is the number of differen-
tiated ﬂows correctly detected as differ-
entiated by the combined analysis over
the number of ﬂows that we know were
shaped, whether or not we have de-
tected them. A recall of 100% indi-
cates that we have correctly identiﬁed
all shaped ﬂows, while a recall of 0%
indicates that we have missed them all.
W e do not include the results in terms
of precision, commonly deﬁned as the
number of true positives over the num-
ber of positives, since we found it for
all experiments to be the optimal one,
at 100%; in short, we never ﬂagged a
non-differentiated ﬂow erroneously .
the three server locations over wired, WiFi and 3G connections. For
each pair of fr and kbw we show a pie where the colour of the upper-
left quarter represents the result of the delay analysis, the colour of
the upper-right quarter represents the result of the loss analysis, and
the colour of the lower half is the outcome of the combined analysis.
If for fr ≤ 40% in almost all cases the delay analysis sufﬁces to detect
all shaped ﬂows, for fr = 60% we see that combining the delay and
loss analysis is essential for a correct output. When kbw = 1.0 the
shaping pipe is conﬁgured with the average bit rate of incoming
packets, so the ﬂows that are supposedly being differentiated might
not be shaped at all, hence the uncertain outcome on the top row of
each graph.
In this scenario, ChkDiff appears to cope just as well with a wired
90 inference of network neutrality violations with active me asurements
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(a) Recall when fr = 20%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(b) Recall when fr = 40%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(c) Recall when fr = 60%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(d) Recall when fr = 80%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(e) Recall when fr = 20%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(f) Recall when fr = 40%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(g) Recall when fr = 60%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(h) Recall when fr = 80%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(i) Recall when fr = 20%
(3G connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(j) Recall when fr = 40%
(3G connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(k) Recall when fr = 60%
(3G connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(l) Recall when fr = 80%
(3G connection)
Figure 5.7: Recall of the loss analysis as
we vary fr in Scenario 2 from the server
located in Germany , over wired, WiFi
and 3G connections.
connection as it does with WiFi and 3G. Over the two wireless con-
nections, there seems to be more noise that is in any case neutralized
for the most part when combining the two analysis.
5.2.2 Uniform drops (Scenario 2)
W e consider now a shaper that uniformly drops packets of selected
ﬂows at a loss rate lr (upper-right pipe in Figure 5.4) and of the
whole trace at a loss rate lrall (left pipe in the same ﬁgure). As op-
posed to the previous scenario, we deploy here a dedicated shaping
pipe for each ﬂow we want to differentiate. W e vary lr and lrall , as
well as the fraction fr of trafﬁc impacted by lr. Shaped ﬂows will
thus have an overall loss rate lrshaped equal to 1 − (1 − lr )(1 − lrall ).
W e show the results for each of the three server locations also used in
Scenario 1, over the three types of connection previously considered
(Figures 5.7, 5.8 and 5.9). Since in this scenario the differentiation
we apply does not affect delays, we focus only on the outcome of
the loss analysis. For completeness, results are shown also for high
values of lrall , even if in practice a global loss rate of 20% is already
able to disrupt TCP connections. Results appear qualitatively similar
regardless of where the server is located. W e observe for both wired
and wireless setups that when fr is less than half of the trace, ChkD-
iff is able to detect all differentiated ﬂows except for the cases on
chapter 5 . chkdiff : the downstream experiment 91
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(a) Recall when fr = 20%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(b) Recall when fr = 40%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(c) Recall when fr = 60%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(d) Recall when fr = 80%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(e) Recall when fr = 20%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(f) Recall when fr = 40%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(g) Recall when fr = 60%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(h) Recall when fr = 80%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(i) Recall when fr = 20%
(3G connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(j) Recall when fr = 40%
(3G connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(k) Recall when fr = 60%
(3G connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(l) Recall when fr = 80%
(3G connection)
Figure 5.8: Recall of the loss analysis as
we vary fr in Scenario 2 from the server
located in Ireland, over wired, WiFi and
3G connections.
the bottom diagonal, where the difference in loss rate between dif-
ferentiated and non-differentiated ﬂows is the lowest ( 5%, 10% and
sometimes 20%). Experiments over WiFi and 3G seem to be only
slightly worse than over wired for the lowest values of lrall .
5.3 Discussion
A full run of ChkDiff in upstream and downstream directions is able
to detect differentiation when, regardless of its implementation, it
directly worsens the throughput, packet delay and losses of user ap-
plications. This is the typical effect introduced by a shaper . Even
though throughout the thesis we used the terms shaping and dif-
ferentiation interchangeably , the former is a subset of the latter and
shaping is what we aim at detecting with our current tool. As we saw
in the validation section, we cannot precisely reveal shaping when
most of the user trafﬁc is affected, as our baseline in the analysis
would mainly be made of differentiated ﬂows. T o counteract this, a
user should be running different applications during the capturing
phase, so as to have a variety of ﬂows to check against. In the ex-
treme case, if really an ISP throttles the bandwidth of all trafﬁc for a
given user , it would not be possible to discern it from severe network
congestion from the view point of this particular user .
92 inference of network neutrality violations with active me asurements
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(a) Recall when fr = 20%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(b) Recall when fr = 40%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(c) Recall when fr = 60%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(d) Recall when fr = 80%
(wired connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(e) Recall when fr = 20%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(f) Recall when fr = 40%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(g) Recall when fr = 60%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(h) Recall when fr = 80%
(WiFi connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 20%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(i) Recall when fr = 20%
(3G connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 40%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(j) Recall when fr = 40%
(3G connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 60%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(k) Recall when fr = 60%
(3G connection)
0.0 0.2 0.4 0.6 0.8
lrall
0.0
0.2
0.4
0.6
0.8
1.0
lrshaped
fr = 80%
0
10
20
30
40
50
60
70
80
90
100
recall
TP/(TP + FN)
(l) Recall when fr = 80%
(3G connection)
Figure 5.9: Recall of the loss analysis as
we vary fr in Scenario 2 from the server
located in Oregon, over wired, WiFi and
3G connections.
In this work, we assume that ISPs select ﬂows to differentiate
based on packet ﬁelds (IP addresses, ports and payload). W e do
not directly address classiﬁcation based on ﬂow bandwidth, but we
make sure that we replay the trace at a higher global rate than the
original one. An alternative for shufﬂing that we have not yet fully
explored would be to rearrange the packets of a ﬂow inside the trace
in a way that would also take into account the original ﬂow rate, so
that it would be straightforward to scale up the ﬂow rates when re-
playing the trace. If instead an ISP shapes certain trafﬁc at speciﬁc
times of the day (e.g. peak hours), ChkDiff will simply report it as
differentiated if executed during those hours.
There exist other techniques for differentiation other than shaping,
as we saw in the reported cases of trafﬁc differentiation in Chapter 2.
When an ISP performs port blocking 15 or , more in general, block- 15 Robert Beverly , Steven Bauer , and
Arthur Berger . The Internet is not a
big truck: toward quantifying network
neutrality . In Passive and Active Network
Measurement, pages 135–144. Springer ,
2007
ing of entire applications, the trafﬁc generated by a user connected
through that ISP would only consist of a few outgoing requests, cer-
tainly not enough for ChkDiff to work. In case users suspect their
ISP to apply such policies, they could for example capture their own
trafﬁc in a different network (e.g., using a cell phone as a hotspot)
and then replay it against the suspected ISP . Alternatively , we could
envisage to provide along with our tool, or let advanced users up-
load, a set of ﬂows from well-known applications that a user could
chapter 5 . chkdiff : the downstream experiment 93
inject into their own traces. When a ﬂow experiences worse per-
formance due to interconnection provisioning between an ISP and
a content provider , we can detect differentiation with the upstream
experiment if the problem affects upstream trafﬁc and is localized
within 3-4 hops from the user . The downstream experiment, as in all
other measurement tools making use of a server , would probably by-
pass any suspected links directly connected to the content provider
in question. Another possible differentiation technique is RST packet
injection, through which an ISP could terminate selected TCP con-
nections, as for example did Comcast in 2007 for BitT orrent users
sharing their ﬁles. 16 W e do not currently implement detection of in- 16 Packet forgery by ISPs: A report
on the comcast affair . URL: https:
//www.eff.org/wp/packet-forgery-
isps-report-comcast-affair
jected RST packets, but it would be an easy addition: we would just
need to dump RST packets on the user side and verify if they belong
to any ﬂow in the replayed trace. W e will soon complement ChkDiff
with this extra feature in future work.
Also, we do not detect differentiation when it aims at providing
better treatment to selected trafﬁc. Such behaviour could be the re-
sult of an agreement between a content provider and an ISP and it
does not necessarily imply any worse conditions for the rest of the
trafﬁc than in normal network conditions. It would be interesting
to redeﬁne the delay analysis in both upstream and downstream ex-
periments to account for this, as it could reveal what services and
applications are favoured in a given network. W e plan to address
this in future work.
The tool is available for Linux machines on the web page of the
project.17 W e currently provide a server located in our lab, where no 17 http://chkdiff.gforge.inria.fr/
trafﬁc differentiation is taking place.
5.4 Assessment with respect to existing methods
Many tools for the detection of trafﬁc differentiation have appeared
in the literature in recent years, as detailed in Chapter 2. Among the
ﬁrst ones, BT-test 18 checks for injected RST packets while emulating
18 Marcel Dischinger , Alan Mislove, An-
dreas Haeberlen, and Krishna P . Gum-
madi. Detecting BitT orrent Blocking.
In Proceedings of the 8th ACM SIG-
COMM Conference on Internet Measure-
ment (IMC’ 08), V ouliagmeni, Greece,
October 2008
a BitT orrent packet exchange between a user and a server . Other
tools compare the performance of a synthetic application ﬂow to the
performance of a similar ﬂow with some modiﬁed or randomized
packet ﬁelds (port numbers or payloads), so that a shaper targeting
such application would affect the former and not the latter . Glas-
nost19 looks for differences in throughput between these two ﬂows,
19 Marcel Dischinger , Massimiliano
Marcon, Saikat Guha, Krishna Gum-
madi, Ratul Mahajan, and Stefan
Saroiu. Glasnost: Enabling End Users
to Detect T rafﬁc Differentiation. In
Proceedings of the 7th Symposium on
Networked Systems Design and Imple-
mentation (NSDI) , San Jose, CA, Apr
2010while DiffProbe 20 attempts to create congestion in the ISP network 20 Partha Kanuparthy and Constantine
Dovrolis. Diffprobe: detecting ISP ser-
vice discrimination. In Proceedings of the
29th conference on Information communi-
cations, INFOCOM’ 10, pages 1649–1657,
Piscataway , NJ, USA, 2010. IEEE Press
by scaling up the replaying rate of application and control ﬂows, and
then analyzes their delay and loss distributions. ShaperProbe 21 ex-
21 Partha Kanuparthy and Constantine
Dovrolis. Shaperprobe: End-to-end de-
tection of isp trafﬁc shaping using ac-
tive methods. In Proceedings of the 2011
ACM SIGCOMM Conference on Internet
Measurement Conference , IMC ’ 11, pages
473–482. ACM, 2011
pands on DiffProbe by considering the case of a shaper implemented
as a token bucket and tries to infer its parameters as the received rate
at the destination shows a level shift. Packsen 22 also tries to identify
22 Udi W einsberg, Augustin Soule, and
Laurent Massoulié. Inferring trafﬁc
shaping and policy parameters using
end host measurements. In INFOCOM,
pages 151–155, 2011
the shaper type and its parameters, but claims to use a more efﬁcient
statistical analysis. As opposed to ChkDiff, these tools are limited
to the set of application traces made available by their authors (e.g.,
Skype, BitT orrent, Y ouT ube, etc), which would make it hard to main-
94 inference of network neutrality violations with active me asurements
tain them in the long run.
A recent work, Differentiator Detector , 23 aims at solving this by 23 Arash Molavi Kakhki, Abbas Razagh-
panah, Anke Li, Hyungjoon Koo, Ra-
jesh Golani, David Choffnes, Phillipa
Gill, and Alan Mislove. Identifying traf-
ﬁc differentiation in mobile networks.
In Proceedings of the 2015 ACM Confer-
ence on Internet Measurement Conference ,
pages 239–251. ACM, 2015
replaying between user and server a captured user trace and re-
producing the same original application behaviour (ports, payloads,
inter-packet times) at the application layer , ﬁrst through a direct path
between the two endpoints (application ﬂow) and then through a
VPN tunnel to a middlebox (control ﬂow). It measures throughput,
RTT distribution and losses in order to detect shaping. Even though
our tool replays separately upstream and downstream trafﬁc, in the
upstream direction it tests the real hops where the original packets
went instead of testing the path between client and server , and in
the downstream direction it deals in a more robust and scalable way
with NA T devices.
Nano24 differs from existing solutions in that it carries out passive 24 Mukarram Bin T ariq, Murtaza Moti-
wala, Nick Feamster , and Mostafa Am-
mar . Detecting network neutrality vio-
lations with causal inference. ACM SIG-
COMM CoNext , page 289, 2009
measurements on user trafﬁc and compares it against a data set of
other users in the same geographical area, with comparable machine
setups, at the same time of the day , but connected to a different ISP .
While this method is undeniably independent of user applications
and differentiation techniques, its main disadvantage is that it needs
a fairly large number of users for it to be operational. ChkDiff on the
other hand depends solely on the end user running it.
5.5 Summary
W e extended with a downstream experiment ChkDiff, a tool which
enables users to detect differentiation on their own trafﬁc. After ﬁrst
checking for degraded trafﬁc performance on upstream trafﬁc, the
tool replays user incoming ﬂows from a measurement server to the
user and analyzes delays and losses to verify whether each ﬂow ex-
perienced the same network conditions as the rest of the trace. While
in the upstream direction our tool proved to be robust to rate limita-
tion in the ICMP feedback generated by routers, in the downstream
case we successfully cope with NA T’s and middleboxes in front of
the client and with end-to-end measurements possibly comprising a
diversity of paths between server and client. W e validated ChkDiff in
the wild, with two differentiation scenarios over three types of con-
nections: wired, WiFi and 3G. W e showed that it correctly identiﬁes
shaped ﬂows when up to half of a user trace is affected.
In future work, we envisage to include in the tool tests that check
for differentiation techniques that do not necessarily alter delays and
losses, as for instance TCP RST injection. W e also intend to run a
study with volunteers in a variety of wired and mobile setups in
order to have a mapping of the current practices of ISPs.
6
Conclusion
In this thesis, we presented and validated ChkDiff, a novel tool for
the detection of trafﬁc differentiation at the access ISP , and conducted
a study on the responsiveness routers to TTL-limited probes. W e
conclude with a summary of our contributions in Section 6.1 and a
discussion about future directions in Section 6.2.
6.1 Summary
Compared to existing work, the strength of ChkDiff lies in its ability
to test any application run by the user and to apply to any shaping
technique deployed by an ISP that results in degraded ﬂow perfor-
mance. Our tool runs measurements directly on previously-captured
user trafﬁc and comprises two experiments, according to the direc-
tion of the trafﬁc. In both cases we shufﬂe the user trace in such a
way that, when replayed, all ﬂows will experience the same network
conditions.
In the upstream experiment, we replay outgoing user trafﬁc against
the routers at the ﬁrst few hops away from the user by forging the
TTL ﬁeld of each packet. With the ICMP time-exceeded replies
returned by intermediate routers we compute per-ﬂow delays and
losses and infer differentiation by comparing the performance of
each ﬂow against that of the rest of the trace. By repeating this
experiment across successive hops, we are also able to localize the
position of possible shapers in terms of number of hops from the
user . W e validated this in wired and WiFi setups in two different
shaping scenarios, where we respectively throttled the bandwidth of
selected ﬂows and applied a uniform loss rate to selected ﬂows and
to the whole trace. W e showed that ChkDiff is able to correctly detect
shaped ﬂows when up to 60% of trafﬁc undergoes bandwidth throt-
tling and when up to 40% of trafﬁc is subject to a higher loss rate
than the whole trace. W e also validated our tool in the presence of
ICMP rate limitation and showed that it does not alter signiﬁcantly
our results, even when only 20% of probes receive a reply .
In order to corroborate our choice of measurements in the up-
stream experiment, we ﬁrst studied the responsiveness of routers to
TTL-limited probes with a large-scale campaign from 180 hosts in
PlanetLab. Among the 850 routers we tested, we found that almost
96 inference of network neutrality violations with active me asurements
a third of them were fully responsive in the range of probing rates
we considered (up to 2500 pps), around 4% were unresponsive and
around 60% implemented ICMP rate limitation. Among these, the
most common form of ICMP limitation displays an on-off pattern,
deﬁned by the burst size of the generated packets and the inter-burst
time, which we characterized also according to the router vendors.
Even at relatively high probing rates, we did not hit any capacity
limits that resulted in larger delays. This means that in the upstream
experiment of ChkDiff we can probe at rates at least within the range
we tested without impairing the measurements of round-trip times.
In the downstream experiment, we replay incoming user trafﬁc
from a measurement server and detect differentiation by measuring
per-ﬂow one-way delays and losses. W e take the necessary actions to
handle NA T s, ﬁrewalls and middleboxes and, unlike other methods,
we consider the possibility of having multiple paths between server
and client when analyzing ﬂow delays. W e validated this in wired,
WiFi and 3G setups using a measurement server deployed in three
different data center locations, under the two shaping scenarios al-
ready used for the upstream experiment. Similarly to the upstream
case, results showed that ChkDiff successfully detects differentiation
when up to 60% of trafﬁc has its bandwidth throttled and up to 40%
of trafﬁc experiences a higher loss rate than the overall one. The re-
sults were qualitatively similar across the three types of connection,
thus proving the robustness of our analysis.
6.2 Future directions
A natural next step for our project would be to distribute the tool
to a wider audience. First, we could ask undergraduate students at
our University to download and run it, so as to have a global view of
trafﬁc differentiation practices by French access ISPs. Then, we could
envisage a collaboration with M-Lab, 1 which already hosts servers 1 www.measurementlab.net
for or offers visibility to tools for differentiation detection (Glasnost,
Neubot) and network monitoring and troubleshooting (e.g., NDT ,
Pathload2, BISmark, MobiPerf, etc.). M-Lab could ideally host our
measurement server for the downstream experiment in a number of
locations, in order to be able to test different paths to the user . Along
with this, we could also collect anonymized results from users and
publish per-country statistics, similarly to what is done for Glasnost. 2 2 http://broadband.mpi-sws.org/
transparency/results/A mobile version of ChkDiff could also be implemented, perhaps
in a lightweight version that reduces the measurement overhead.
Porting to Android and iOS presents several challenges, especially
in the capture and replay of trafﬁc, since in a mobile environment
we should not expect to have administrator privileges on the device.
Alternatives to the usage of tcpdump and tcpreplay should be ex-
plored. Currently , as shown in the validation section of Chapter 5,
a user can check if her mobile operator applies shaping on her 3G
connection simply by turning her mobile phone into a WiFi hotspot
and connecting a computer to it. With this approach, we can easily
bibliography 97
test desktop applications, but not mobile ones.
As we saw in Chapter 2, both the United States and the European
Union have adopted regulations that enforce network neutrality and
restrict the number of cases in which an ISP is allowed to apply trafﬁc
differentiation. Nevertheless, no tool is currently widely adopted by
National Regulatory Authorities (NRAs) and even then NRAs can
only check for differentiation on a limited set of applications, for
instance by running Glasnost. ChkDiff could be a solution for this,
with users sending the output of ChkDiff to their national NRA in
case of detection of trafﬁc differentiation.
In our tool, we check for differentiation on the exact paths cov-
ered by the original trace only in the upstream experiment. In the
downstream direction, since IP spooﬁng is not a viable solution in
today’s networks, 3 we needed to resort to replaying from a measure- 3 BCP 38 - Network Ingress Filter-
ing: Defeating Denial of Service At-
tacks which employ IP Source Ad-
dress Spooﬁng. URL: https://
tools.ietf.org/html/bcp38
ment server using the server IP address as source IP address in all
packets of the trace. This is the same technique used by all other
tools that perform active measurements: they test for differentiation
along the path between the server and the user , which in the vicinity
of the user might not cover exactly the hops traversed by the original
ﬂows. This is not necessarily an issue, but it is certainly a limitation
of this type of measurements. As a workaround, as hinted above, we
could offer the option to replay the downstream trace from different
server locations in order to cover more paths to the user .
Finally , our methodology infers neutrality violations from Qual-
ity of Service (QoS) parameters, without taking into account Quality
of Experience (QoE). In other words, we only consider the results
of network measurements (delays and losses) and not the effects on
the usability of applications. This could be a direction to explore.
ACQUA,4 a parallel project in our research team, tries to predict 4 htttp://project.inria.fr/acqua
with machine-learning techniques the QoE of popular applications
(e.g. Skype, Y ouT ube) based on the measured QoS. W e could inte-
grate ACQUA into our project in order to also infer if a detected
differentiation mechanism signiﬁcantly degrades the usability of an
application. Moreover , since an equal treatment of trafﬁc does not
necessarily translate into an equally good QoE for applications with
different requirements (e.g., ﬁle sharing, video streaming, V oIP , IPTV ,
etc), we could also envisage to explore which shaping mechanisms
do not degrade but improve the QoE of different types of applications.

Bibliography
[1] A T&T blocking iPhone’s FaceTime app would harm
consumers and break net neutrality rules. URL:
http://www.freepress.net/press-release/99480/att-
blocking-iphones-facetime-app-would-harm-consumers-
and-break-net-neutrality .
[2] BCP 38 - Network Ingress Filtering: Defeating Denial of Ser-
vice Attacks which employ IP Source Address Spooﬁng. URL:
https://tools.ietf.org/html/bcp38.
[3] Bouygues télécom ﬁltre malhonnêtement son réseau 3G et
inspecte vos données. URL: http://grapsus.net/blog/post/
Bouygues-Telecom-filtre-malhonnetement-son-reseau-3G-
et-inspecte-vos-donnees .
[4] Chile, primer país en incorporar la neutralidad en la
red. URL: http://www.elmundo.es/elmundo/2010/07/16/
navegante/1279272468.html.
[5] Dslreports: comcast is using sandvine to manage p 2p connec-
tions. URL: http://www.dslreports.com/forum/r18323368-
Comcast-is-using-Sandvine-to-manage-P2P-Connections.
[6] Group asks FCC to probe iPhone Skype restrictions. URL:
http://fortune.com/2009/04/03/group-asks-fcc-to-probe-
iphone-skype-restrictions/.
[7] I just doubled my PIA VPN throughput that I am
getting on my router by switching from UDP: 1194 to
TCP:443. URL: http://www.reddit.com/r/VPN/comments/
1xkbca/i_just_doubled_my_pia_vpn_throughput_that_i_am.
[8] Linux Programmer ’s Manual - TCP protocol . URL: http://
man7.org/linux/man-pages/man7/tcp.7.html.
[9] MetroPCS 4G Data-Blocking Plans May Violate Net Neu-
trality . URL: http://www.wired.com/2011/01/metropcs-net-
neutrality/.
[10] Net neutrality enshrined in dutch law . URL:
http://www.theguardian.com/technology/2011/jun/23/
netherlands-enshrines-net-neutrality-law .
100 inference of network neutrality violations with active me asurements
[11] NetFilter: Firewalling, NA T and packet mangling for Linux.
URL: www.netfilter.org.
[12] Packet forgery by ISPs: A report on the comcast af-
fair . URL: https://www.eff.org/wp/packet-forgery-isps-
report-comcast-affair.
[13] Phone Company Helps Make the Case for Net Neutral-
ity . URL: http://www.savetheinternet.com/blog/10/04/05/
phone-company-helps-make-case-net-neutrality .
[14] Respect my net. URL: http://respectmynet.eu/view/205.
[15] Respect my net. URL: http://respectmynet.eu/view/196.
[16] RFC 4787 - Network Address T ranslation (NA T) Behavioral Re-
quirements for Unicast UDP. URL: http://tools.ietf.org/
html/rfc4787.
[17] RFC 5382 - NA T Behavioral Requirements for TCP. URL: http:
//tools.ietf.org/html/rfc5382.
[18] Service Name and T ransport Protocol Port Number Registry.
IANA. URL: www.iana.org/assignments/port-numbers.
[19] T cpreplay . URL: http://tcpreplay.appneta.com/.
[20] Vint Cerf speaks out on net neutrality . URL: https:
//googleblog.blogspot.fr/2005/11/vint-cerf-speaks-
out-on-net-neutrality.html .
[21] V onage says broadband provider blocks its calls. URL:
http://www.cnet.com/news/vonage-says-broadband-
provider-blocks-its-calls/ .
[22] Widespread Hijacking of Search T rafﬁc in the United States.
URL: https://www.eff.org/deeplinks/2011/07/widespread-
search-hijacking-in-the-us .
[23] Netﬂix performance on V erizon and Comcast has been drop-
ping for months, 2013. URL: http://arstechnica.com/
information-technology/2014/02/netflix-performance-on-
verizon-and-comcast-has-been-dropping-for-months .
[24] FCC. Protecting and promoting the open internet. April 2015.
URL: https://www.federalregister.gov/articles/2015/
04/13/2015-07841/protecting-and-promoting-theopen-
internet.
[25] WhatsApp V oice Calling Already Banned by UAE’s Eti-
salat: Report. 2015. URL: http://gadgets.ndtv.com/apps/
news/whatsapp-voice-calling-already-banned-by-uaes-
etisalat-report-672283.
[26] P . Almquist. RFC 1349: T ype of Service in the Internet Protocol
Suite. 1992. URL: https://tools.ietf.org/html/rfc1349.
bibliography 101
[27] Brice Augustin, Xavier Cuvellier , Benjamin Orgogozo, Fabien
Viger , Timur Friedman, Matthieu Latapy , Clémence Magnien,
and Renata T eixeira. A voiding traceroute anomalies with paris
traceroute. In Proceedings of the 6th ACM SIGCOMM conference
on Internet measurement , pages 153–158. ACM, 2006.
[28] Brice Augustin, Timur Friedman, and Renata T eixeira. Measur-
ing load-balanced paths in the internet. In Proceedings of the 7th
ACM SIGCOMM conference on Internet measurement , pages 149–
160. ACM, 2007.
[29] Simone Basso, Antonio Servetti, and Juan Carlos De Martin.
The network neutrality bot architecture: a preliminary ap-
proach for self-monitoring of Internet access QoS. In Comput-
ers and Communications (ISCC), 2011 IEEE Symposium on , pages
1131–1136. IEEE, 2011.
[30] BEREC. A framework for Quality of Service in the scope of Net
Neutrality . BEREC Report BoR ( 11) 53, December 2011. URL:
http://berec.europa.eu/eng/document_register/subject_
matter/berec/download/0/117-a-framework-for-quality-
of-service-in-th _0.pdf.
[31] BEREC. Guidelines for quality of service in the scope of net
neutrality . BEREC Report BoR ( 12) 131, November 2012. URL:
http://berec.europa.eu/eng/document_register/subject_
matter/berec/download/0/1101-berec-guidelines-for-
quality-of-service- _0.pdf.
[32] BEREC. Annex of monitoring quality of internet access
services in the context of net neutrality . BEREC Report BoR
(14) 117, September 2014. URL: http://berec.europa.eu/
eng/document_register/subject_matter/berec/download/1/
4602-monitoring-quality-of-internet-access-se _1.pdf.
[33] BEREC. Monitoring quality of internet access services
in the context of net neutrality . BEREC Report BoR ( 14)
117, September 2014. URL: http://berec.europa.eu/eng/
document_register/subject_matter/berec/download/0/
4602-monitoring-quality-of-internet-access-se _0.pdf.
[34] Robert Beverly , Steven Bauer , and Arthur Berger . The Internet is
not a big truck: toward quantifying network neutrality . In Pas-
sive and Active Network Measurement , pages 135–144. Springer ,
2007.
[35] S. Blake, F . Baker , and D. Black. RFC 2474: Deﬁnition of the
Differentiated Services Field (DS Field) in the IPv 4 and IPv 6
Headers. 1998. URL: https://tools.ietf.org/html/rfc2474.
[36] Marta Carbone and Luigi Rizzo. Dummynet revisited. SIG-
COMM Comput. Commun. Rev. , 40(2):12–20, April 2010.
102 inference of network neutrality violations with active me asurements
[37] Cisco. TTL expiry attack identiﬁcation and mitiga-
tion. URL: http://www.cisco.com/web/about/security/
intelligence/ttl-expiry.html.
[38] K Claffy , T racie E Monk, and Daniel McRobb. Internet tomog-
raphy . Nature, 7(11), 1999.
[39] Jon Crowcroft. T alk on Net Neutrality, December 2006. URL:
"http://www.cl.cam.ac.uk/~jac22/talks/neut.ppt.gz".
[40] Jon Crowcroft. Net neutrality: the technical side of the debate:
a white paper . SIGCOMM Comput. Commun. Rev. , 37:49–56, Jan-
uary 2007.
[41] Jon Crowcroft. T alk on Newt or Notrality, July 2011. URL:
"https://www.cl.cam.ac.uk/~jac22/talks/notrality.ppt".
[42] Gregory Detal, Benjamin Hesmans, Olivier Bonaventure, Y ves
V anaubel, and Benoit Donnet. Revealing middlebox interfer-
ence with tracebox. In Proceedings of the 2013 Conference on Inter-
net Measurement Conference , IMC ’ 13, pages 1–8, New Y ork, NY ,
USA, 2013. ACM.
[43] Marcel Dischinger , Massimiliano Marcon, Saikat Guha, Krishna
Gummadi, Ratul Mahajan, and Stefan Saroiu. Glasnost: En-
abling End Users to Detect T rafﬁc Differentiation. In Proceedings
of the 7th Symposium on Networked Systems Design and Implemen-
tation (NSDI) , San Jose, CA, Apr 2010.
[44] Marcel Dischinger , Alan Mislove, Andreas Haeberlen, and Kr-
ishna P . Gummadi. Detecting BitT orrent Blocking. In Proceedings
of the 8th ACM SIGCOMM Conference on Internet Measurement
(IMC’08), V ouliagmeni, Greece, October 2008.
[45] Constantine Dovrolis, Krishna Gummadi, Aleksandar Kuz-
manovic, and Sascha D. Meinrath. Measurement lab: overview
and an invitation to the research community . SIGCOMM Com-
put. Commun. Rev. , 40:53–56, June 2010.
[46] Allen B Downey . Using pathchar to estimate internet link char-
acteristics. In ACM SIGCOMM Computer Communication Review ,
volume 29, pages 241–250. ACM, 1999.
[47] Martin Ester , Hans-Peter Kriegel, Jörg Sander , and Xiaowei Xu.
A density-based algorithm for discovering clusters in large spa-
tial databases with noise. In Kdd, volume 96, pages 226–231,
1996.
[48] Ramesh Govindan and V ern Paxson. Estimating router ICMP
generation delays. In Passive & Active Measurement (P AM) , 2002.
[49] BIT AG T echnical W orking Group. Differentiated T reatment of
Internet T rafﬁc. 2015.
bibliography 103
[50] Mehmet H Gunes and Kamil Sarac. Analyzing router respon-
siveness to active measurement probes. Passive and Active Net-
work Measurement , pages 23–32, 2009.
[51] Michio Honda, Y oshifumi Nishida, Costin Raiciu, Adam Green-
halgh, Mark Handley , and Hideyuki T okuda. Is it still possible
to extend TCP? In Proceedings of the 2011 ACM SIGCOMM Con-
ference on Internet Measurement Conference , IMC ’ 11, pages 181–
194, New Y ork, NY , USA, 2011. ACM.
[52] Ningning Hu, Li Li, Zhuoqing Morley Mao, Peter Steenkiste,
and Jia W ang. A measurement study of internet bottlenecks. In
INFOCOM 2005. 24th Annual Joint Conference of the IEEE Com-
puter and Communications Societies. Proceedings IEEE , volume 3,
pages 1689–1700. IEEE, 2005.
[53] V an Jacobson. traceroute. URL: ftp://ftp.ee.lbl.gov/
traceroute.tar.gz.
[54] Partha Kanuparthy and Constantine Dovrolis. Diffprobe: de-
tecting ISP service discrimination. In Proceedings of the 29th
conference on Information communications , INFOCOM’ 10, pages
1649–1657, Piscataway , NJ, USA, 2010. IEEE Press.
[55] Partha Kanuparthy and Constantine Dovrolis. Shaperprobe:
End-to-end detection of isp trafﬁc shaping using active meth-
ods. In Proceedings of the 2011 ACM SIGCOMM Conference on
Internet Measurement Conference , IMC ’ 11, pages 473–482. ACM,
2011.
[56] Ioannis Koukoutsidis. Public QoS and net neutrality measure-
ments. Journal of Information , 5, 2015.
[57] Farah Layouni, Brice Augustin, Timur Friedman, and Renata
T eixeira. Origine des étoiles dans traceroute. In Colloque Franco-
phone sur l’Ingénierie des Protocoles (CFIP) , 2008.
[58] Lawrence Lessig and Robert W . McChesney . No T olls on The
Internet. June 2006. URL: http://www.washingtonpost.com/
wp-dyn/content/article/2006/06/07/AR2006060702108.html.
[59] David Malone and Matthew Luckie. Analysis of ICMP quota-
tions. Passive and Active Network Measurement , pages 228–232,
2007.
[60] Arash Molavi Kakhki, Abbas Razaghpanah, Anke Li,
Hyungjoon Koo, Rajesh Golani, David Choffnes, Phillipa Gill,
and Alan Mislove. Identifying trafﬁc differentiation in mobile
networks. In Proceedings of the 2015 ACM Conference on Internet
Measurement Conference , pages 239–251. ACM, 2015.
[61] Christos Pappas, Katerina Argyraki, Stefan Bechtold, and
Adrian Perrig. T ransparency Instead of Neutrality . In Pro-
ceedings of the 14th ACM Workshop on Hot T opics in Networks ,
HotNets-XIV , pages 22:1–22:7. ACM, 2015.
104 inference of network neutrality violations with active me asurements
[62] Alina Quereilhac, Mathieu Lacage, Claudio Freire, Thierry
T urletti, and W alid Dabbous. Nepi: An integration framework
for network experimentation. In Software, T elecommunications
and Computer Networks (SoftCOM), 2011 19 th International Con-
ference on , pages 1–5. IEEE, 2011.
[63] Ashwin Rao, Justine Sherry , Arnaud Legout, Arvind Krishna-
murthy , W alid Dabbous, and David Choffnes. Meddle: mid-
dleboxes for increased transparency and control of mobile traf-
ﬁc. In Proceedings of the 2012 ACM conference on CoNEXT student
workshop, pages 65–66. ACM, 2012.
[64] Riccardo Ravaioli, Chadi Barakat, and Guillaume Urvoy-Keller .
Chkdiff: checking trafﬁc differentiation at Internet access. In
Proceedings of the 2012 ACM conference on CoNEXT student work-
shop, pages 57–58. ACM, 2012.
[65] Riccardo Ravaioli, Guillaume Urvoy-Keller , and Chadi Barakat.
Characterizing ICMP Rate Limitation on Routers. In IEEE Inter-
national Conference on Communications (ICC) , 2015.
[66] Riccardo Ravaioli, Guillaume Urvoy-Keller , and Chadi Barakat.
T owards a general solution for detecting trafﬁc differentiation
at the internet access. In T eletrafﬁc Congress (ITC 27), 2015 27 th
International, pages 1–9. IEEE, 2015.
[67] Riccardo Ravaioli, Guillaume Urvoy-Keller , and Chadi Barakat.
T esting for trafﬁc differentiation with chkdiff: the downstream
case. In T eletrafﬁc Congress (ITC 28), 2016 28th International . IEEE,
2016.
[68] J. H. Saltzer , D. P . Reed, and D. D. Clark. End-to-end Argu-
ments in System Design. ACM T rans. Comput. Syst. , 2(4):277–
288, November 1984.
[69] Neil Spring, Ratul Mahajan, and David W etherall. Measuring
ISP topologies with rocketfuel. ACM SIGCOMM Computer Com-
munication Review , 32(4):133–145, 2002.
[70] RA Steenbergen. A practical guide to (correctly) troubleshoot-
ing with traceroute. North American Network Operators Group ,
pages 1–49, 2009.
[71] Srikanth Sundaresan, W alter De Donato, Nick Feamster , Re-
nata T eixeira, Sam Crawford, and Antonio Pescapè. Measur-
ing home broadband performance. Communications of the ACM ,
55(11):100–109, 2012.
[72] Mukarram Bin T ariq, Murtaza Motiwala, Nick Feamster , and
Mostafa Ammar . Detecting network neutrality violations with
causal inference. ACM SIGCOMM CoNext , page 289, 2009.
bibliography 105
[73] Y ves V anaubel, Jean-Jacques Pansiot, Pascal Mérindol, and
Benoit Donnet. Network ﬁngerprinting: TTL-based router sig-
natures. In Proceedings of the 2013 conference on Internet measure-
ment conference , pages 369–376. ACM, 2013.
[74] Udi W einsberg, Augustin Soule, and Laurent Massoulié. In-
ferring trafﬁc shaping and policy parameters using end host
measurements. In INFOCOM, pages 151–155, 2011.
[75] Ronald W W olff. Poisson arrivals see time averages. Operations
Research, 30(2):223–231, 1982.
[76] Tim Wu. Network neutrality , broadband discrimination. Journal
of T elecommunications and high T echnology law , 2:141, 2003.
[77] Ying Zhang, Zhuoqing Morley Mao, and Ming Zhang. Detect-
ing trafﬁc differentiation in backbone isps with netpolice. In
Proceedings of the 9th ACM SIGCOMM Conference on Internet Mea-
surement Conference , IMC ’ 09, pages 103–115. ACM, 2009.
[78] Zhiyong Zhang, Ovidiu Mara, and Katerina Argyraki. Network
neutrality inference. In Proceedings of the 2014 ACM Conference on
SIGCOMM, SIGCOMM ’ 14, pages 63–74, New Y ork, NY , USA,
2014. ACM.

List of Publications
[79] Riccardo Ravaioli, Chadi Barakat, and Guillaume Urvoy-Keller .
Chkdiff: checking trafﬁc differentiation at internet access. In Pro-
ceedings of the 2012 ACM conference on CoNEXT student workshop ,
pages 57–58. ACM, 2012.
[80] Riccardo Ravaioli, Guillaume Urvoy-Keller , and Chadi Barakat.
Characterizing ICMP rate limitation on routers. In IEEE Interna-
tional Conference on Communications (ICC) , 2015.
[81] Riccardo Ravaioli, Guillaume Urvoy-Keller , and Chadi Barakat.
T owards a general solution for detecting trafﬁc differentiation
at the internet access. In T eletrafﬁc Congress (ITC 27), 2015 27 th
International, pages 1–9. IEEE, 2015.
[82] Riccardo Ravaioli, Guillaume Urvoy-Keller , and Chadi Barakat.
T esting for trafﬁc differentiation with chkdiff: the downstream
case. In T eletrafﬁc Congress (ITC 28), 2016 28th International , pages
1–9. IEEE, 2016.