ACCEPTED PREPRINT, IEEE TUFFC, 2024 1
Active inference and deep generative modeling
for cognitive ultrasound
Ruud JG van Sloun Member, IEEE
Abstractâ€” Ultrasound has the unique potential to offer ac-
cess to medical imaging to anyone, everywhere. Devices
have become ultra-portable and cost-effective, akin to the
stethoscope. Nevertheless, and despite many advances,
ultrasound image quality and diagnostic efficacy are still
highly operator- and patient-dependent. In difficult-to-
image patients, image quality is often insufficient for re-
liable diagnosis. In this paper, we put forth the idea that
ultrasound imaging systems can be recast as information-
seeking agents that engage in reciprocal interactions with
their anatomical environment. Such agents autonomously
adapt their transmit-receive sequences to fully personal-
ize imaging and actively maximize information gain in-situ.
To that end, we will show that the sequence of pulse-echo experiments that an ultrasound system performs
can be interpreted as a perception-action loop: the action is the data acquisition, probing tissue with acoustic
waves and recording reflections at the detection array, and perception is the inference of the anatomical
and or functional state, potentially including associated diagnostic quantities. We then equip systems with a
mechanism to actively reduce uncertainty and maximize diagnostic value across a sequence of experiments,
treating action and perception jointly using Bayesian inference given generative models of the environment
and action-conditional pulse-echo observations. Since the representation capacity of the generative models
dictates both the quality of inferred anatomical states and the effectiveness of inferred sequences of future
imaging actions, we will be greatly leveraging the enormous advances in deep generative modelling (generative
AI), that are currently disrupting many fields and society at large. Finally, we show some examples of cognitive,
closed-loop, ultrasound systems that perform active beamsteering and adaptive scanline selection, based on
deep generative models that track anatomical belief states.
Index Termsâ€” Deep generative models, deep learning, active inference, ultrasound imaging, perception and
action, cognitive imaging, computational imaging, adaptive compressed sensing.
I. I NTRODUCTION
U
LTRASOUND (US) has the potential to revolution-
ize and democratize medical imaging due to its cost-
effectiveness and portability. However, achieving consistent,
precise and robust diagnostics remains a challenge. The diag-
nostic performance of US is dependent on skilled operators
and exams still fail frequently on hard-to-image patients. The
group of hard-to-image patients is moreover growing rapidly
due to the rising incidence of obesity worldwide. Studies show
that reduced image quality leads to worse observer variabil-
ity, reproducibility, and accuracy of diagnostic parameters in
ultrasound exams [1], [2].
The biggest adversaries for ultrasound image quality and di-
agnostic accuracy stem from patient- and user-specific factors,
Â©2024 IEEE. DOI: 10.1109/TUFFC.2024.3466290. Submitted on July
5, 2024; accepted on September 16, 2024. This work was supported by
the European Research Council (ERC) under the ERC starting grant nr.
101077368 (US-ACT), and the Dutch Research Council (NWO) under
VIDI grant nr. 20381
Ruud JG van Sloun is with the Eindhoven University of Technology,
Eindhoven, The Netherlands (e-mail: r.j.g.v.sloun@tue.nl)
i.e. patient geometry and user interaction. These factors thus
vary across exams, and within exams. Given this, it is rea-
sonable to hypothesize that optimal imaging requires closed-
loop, goal-directed system behaviour, through sequential op-
timal experiment (=transmit-receive) design via its reciprocal
interactions with the physical environment.
Based on this hypothesis, this paper proposes a brain-
inspired paradigm for such a cognitive ultrasound transmit-
receive control system. It recognizes that the cycle of ultra-
sound data acquisition and reconstruction can be interpreted as
a perception-action loop: the action is the acquisition, probing
the anatomy, and the perception is the reconstruction that
infers what object most likely generated that acquired data.
This data acquisition cycle has associated costs (e.g. time and
energy), and hence in practice one always deals with partial
observations of the time-varying object.
Perception-action loops are commonly used in neuroscience
and cybernetics to explain the behaviour of intelligent agents,
which also typically deal with partial observations of the world
around them. A now widely-accepted brain theory is that
agents establish an internal generative model of the world in
arXiv:2410.13310v1  [eess.SP]  17 Oct 2024
2 ACCEPTED PREPRINT, IEEE TUFFC, 2024
order to efficiently infer causes of their sensations, and plan
useful future actions, all driven by an intrinsic motivation [3]:
minimization of uncertainty.
Through this lens, we will interpret the ultrasound imaging
system as an agent, more specifically an active perceiver [4],
[5], which strives to perform actions and perceptions that
minimize uncertainty about the anatomical world across a
sequence of imaging experiments and resulting observations.
To be effective at achieving this, the agent must understand
the environment, and the consequences that actions have on
observations of that environment. We postulate that this can be
achieved by equipping the agent with generative models that
govern these beliefs. Through probabilistic inference, an agent
can then optimally plan its measurements, autonomously seek
value, and continuously update its imaging strategy based on
the incoming sensor data. In effect, full system behaviour is
governed by the single holistic information-theoretic objective
to minimize uncertainty.
The above ambition becomes practical only when the
agentâ€™s generative model is sufficiently expressive to reflect
diverse, yet plausible, anatomical states and the intricacies
of the relationship between an anatomical state, transmit-
receive parameters (e.g. transmit waveforms or receive com-
pression/sampling), and the observations. This is not at all
trivial. Anatomical states (e.g. reflectivity) are typically repre-
sented on a spatial grid of tens- to hundreds of thousands of
pixels, and the relationship between these pixels is intricate,
with structure at various hierarchical scales. Additionally, there
is structure in time, again at various scales. Moreover, since the
agentsâ€™ actions are determined by evaluating some expected
observational value functional across hypotheses about the
current (and future) state, it is critical that these hypotheses
are not only plausible and consistent (i.e. they agree with the
observations done thus far), but that they cover all modes of
the true distribution to prevent collapse of the system into a
degenerate, â€œignorantâ€, mode.
Deep generative models, such as normalizing flows and dif-
fusion models, have revolutionized generative modeling on all
these aspects (scale, plausibility, and diversity) in past years.
They are revolutionary in terms of sample fidelity and have
already been used effectively to solve challenging image-based
inverse problems. We are currently seeing the very first use
cases for such models in ultrasound image reconstruction [6]â€“
[9], and will here also elucidate their potential in the context
of active inference and closed-loop cognitive ultrasound.
The remainder of this paper is organized as follows. In sec-
tions II and III we will introduce perception-action loops, and
the rationale for using deep generative models, respectively.
We will give some special attention to diffusion models. Then
in section IV, we will give a formal description of what exactly
we mean by â€œperceptual inferenceâ€, the rationale for choosing
a Bayesian approach, and various approaches to executing this
tractably. We will then, in section V, dive into the inference
of actions (the active part of active inference), the design of
criteria that measure the value of actions, and mechanisms to
evaluate expected future value based on generative predictions
of â€œwhat may happenâ€. Section VI gives an overview of
methods for approximating the generative density functions
as well as the action-value functions in complex models when
exact computation is intractable. Then, in section VII, we
will give some concrete examples that have tutorial value,
illustrating the potential utility of the presented approaches
in the context of ultrasound. Finally, in section VIII, we
will discuss future research directions, open questions, and
outstanding challenges, and then conclude in section IX.
Table I gives a glossary of some terms and symbols that are
used throughout this paper.
TABLE I
GLOSSARY OF TERMS AND SYMBOLS USED IN THIS PAPER .
Term Definition
x, y, a Random variables.
xâ€², yâ€², aâ€² Deterministic variables.
Ë†y, Ë†a Data points.
xi, yi Samples from a probability density function.
p(x, y, a) A (probabilistic) generative model across states, ob-
servations and actions. We will use both generative
models based on first principles, and deep generative
models, learned from data.
p(x, y, aâ€²) A generative model across states and observations
evaluated for a particular deterministic action aâ€².
Shorthand notation for p(x, y, a= aâ€²).
p(x|Ë†y, Ë†a) A Bayesian posterior distribution for the states given
past and present observations and actions. Shorthand
notation for p(x|y = Ë†y, a= Ë†a).
q(x|Ë†y, Ë†a) An approximate posterior distribution.
Eq(x) f(x) The expected value of function f(x) when x âˆ¼
q(x).
I(x, y|aâ€²) The mutual information between state x and ob-
servation y, for a particular action aâ€². Reflects the
information gain of an experiment with action aâ€².
H(y|aâ€²) The marginal entropy of observations y, for a par-
ticular action aâ€². Reflects the uncertainty about out-
comes of observations y for an action aâ€².
H(y|x, aâ€²) The conditional entropy of y given x, for a
particular action aâ€². Equal to the expectation
Exâ€²âˆ¼q(x) H(y|x = xâ€², a = aâ€²). Reflects the
remaining uncertainty about y when given the state
x.
sÎ¸(x) A neural-network-based approximation of the true
score function of a probability distribution p(x):
âˆ‡x log p(x). Used in diffusion models to draw sam-
ples from the data distribution.
|Î£| Determinant of a covariance matrix Î£, also referred
to as the generalized variance.
II. P ERCEPTION -ACTION LOOPS
â€œEach movement we make by which we alter the appearance
of objects should be thought of as an experiment designed
to test whether we have understood correctly the invariant
relations of the phenomena before usâ€ â€” Helmholtz [10]
Intelligent agents, such as the brain, continuously engage
in interactions with their environment. These interactions
are reciprocal, i.e. agents take actions which affect their
environment, and their environment in turn affects their
observations. These observations solicit new actions, closing
the so-called perception-action loop. Useful actions are those
that lead to desired outcomes/observations. To be effective at
achieving this, an agent must understand the environment, and
the consequences of actions on that environment. Rational
agents thus pursue the understanding of their environment
through actions that lead to information gain, while at the
same time being goal-directed. Such behavior requires the
VAN SLOUN: COGNITIVE ULTRASOUND 3
ability to make predictions about the environment, and thus
agents embody a generative model.
This paper will be concerned only with perception-action
loops in which actions influence the observation/measurement
of an environmental state, but not the state itself. The agent
is thus an active perceiver. As we will see, this has some
implications for the way we factorize generative models and
their approximate posteriors. Some of the assumptions and
parameterizations used here will therefore deviate from what
is typical in the control/cybernetics literature, which assumes
actions impact states of the environment, rather than observa-
tions thereof. We will further restrict ourselves to agents that
have no explicit preferences about outcomes, other than to seek
information gain. They are â€œscientistsâ€ planning successive
experiments to better understand what phenomenon causes
their observations.
The ultrasound action space
At this point, it becomes useful to briefly discuss
what the action space of an ultrasound agent entails.
Many of the controllable sensing parameters in ultra-
sound are similar to those commonly considered in
cognitive radar systems. They include both transmit
and receive parameters. On the transmit side, at the
most abstract level, the agent is tasked with the design
of an optimal, maximally informative, transmit code.
At the most fine-grained level, this code is governed
by a complete shaping of the transmit waveforms
and timing for each of the transmitters, subject to
the constraints of feasibility imposed by the analog
transmit chain. A more coarse representation would
be to only control the delays and gains applied to
each transmitter, shaping the transmit beam. Practical
ultrasound systems typically execute a sequence of
such coded transmit events (e.g. a series of focused
scan lines), and many practical codes will need to be
considered in the context of a full sequence to evaluate
the impact they have on the information gain achieved
by that sequence.
We define the following time-discretized perception-action
loop. At time point t, an agent equipped with a generative
model selects an action, which manifests in an excitation of
the environment. This in turn results in a new sensory state
Ë†yt. Confronted with the updated sensory data Ë†y0:t, the agent
then revisits its beliefs about the environment (including future
states it may take, and observations that may follow from that),
and computes a new posterior belief about the state. Figure 1
gives an overview of the perception-action loop.
The agentâ€™s generative model over observations y0:T , envi-
ronmental states x0:T , and actions a0:T is given by:
y0:T , x0:T , a0:T âˆ¼ p(y0:T , x0:T , a0:T ), (1)
with
p(y0:T , x0:T , a0:T ) = p(y0:T |x0:T , a0:T )p(x0:T , a0:T )
= p(y0:T |x0:T , a0:T )p(x0:T )p(a0:T |x0:T ),
(2)
Environment
(external states)
Action
Perception
Sensory 
states
Markov blanket
(ultrasound probe)
Ì‡ğ‘¥ğ‘¥ğ‘’ğ‘’ = ğ‘“ğ‘“ğ‘’ğ‘’ ğ‘¥ğ‘¥ğ‘’ğ‘’, ğ‘ğ‘ğ‘¡ğ‘¡ + ğ‘›ğ‘›ğ‘’ğ‘’
ğ‘ğ‘(ğ‘¦ğ‘¦0:ğ‘‡ğ‘‡, ğ‘¥ğ‘¥0:ğ‘‡ğ‘‡, ğ‘ğ‘0:ğ‘‡ğ‘‡)
ï¿½ğ‘¦ğ‘¦ğ‘¡ğ‘¡ = ğ‘“ğ‘“ğ‘¦ğ‘¦ ğ‘¥ğ‘¥ğ‘’ğ‘’(ğ‘¡ğ‘¡), ğ‘ğ‘ğ‘¡ğ‘¡ + ğ‘›ğ‘›ğ‘¦ğ‘¦
ğ‘ğ‘ ğ‘¥ğ‘¥0:ğ‘¡ğ‘¡| ï¿½ğ‘ğ‘0:ğ‘¡ğ‘¡, ï¿½ğ‘¦ğ‘¦0:ğ‘¡ğ‘¡
âˆˆ ğ‘„ğ‘„
Generative model
Approximate posterior
Active 
states
ğ‘ğ‘ğ‘¡ğ‘¡
âˆ— = ğ‘“ğ‘“ğ‘ğ‘ğ‘¡ğ‘¡ ğ‘ğ‘ ğ‘¥ğ‘¥ğ‘¡ğ‘¡:ğ‘‡ğ‘‡, ğ‘¦ğ‘¦ğ‘¡ğ‘¡:ğ‘‡ğ‘‡|ğ‘ğ‘ğ‘¡ğ‘¡, ï¿½ğ‘ğ‘0:ğ‘¡ğ‘¡âˆ’1, ï¿½ğ‘¦ğ‘¦0:ğ‘¡ğ‘¡âˆ’1
Agent 
(internal states)
1
2
3
Fig. 1. At time point t, an agent equipped with a generative model p
selects an action (1), which manifests in an excitation of the environ-
ment (2). The excitation â€œchangesâ€ the environment (e.g. it introduces
compressional waves). This in turn results in a new sensory state Ë†yt.
Confronted with the updated sensory data Ë†y0:t, the agent then revisits
its beliefs about the environment (including future states it may take,
and observations that may follow from that), and computes a new
(approximate) posterior q (3). The ultrasound probe contains the active
and sensory states, and acts as a Markov blanket that separates the
agent from its environment; they only interact via the active and sensory
states. The distinction betweenxe, the environmental states, andx, the
internal states, is to make explicit that the agentâ€™s model is in general an
approximate model of the true physical environment.
by which we make explicit that actions impact observations,
not states (active perception), and that the state impacts the
distribution across actions (adaptivity). In section V we will
show how the latter dependency manifests precisely in our
framework, but in a nutshell it comes down to the maximiza-
tion of an information-theoretic action-value functional of the
conditional generative model p(y0:T , x0:T |a0:T ). Note that the
active-perception model foregoes that in reality, actions do im-
pact the physical environment (they introduce compressional
waves), and considers all these effects part of the observation
model p(y0:T |x0:T , a0:T ). This distinction between the agentâ€™s
internal model, and the true environment is also made explicit
in Figure 1.
Throughout this tutorial, we also refer to the generative
models given above as priors. Whenever these prior beliefs
are revised through exposure to information in the form of
data/measurements, we refer to the revised beliefs as posteri-
ors. We refer to the updating of beliefs in the face of data as
perceptual inference, which will be treated in section IV. De-
veloping a sufficiently accurate generative model that enables
reasoning about futures with the detail and diversity needed for
fulfilling the agentsâ€™ objectives is key. Our agent is tasked with
inferring high-dimensional, high-resolution images, for which
the requirements are particularly challenging. We will now
briefly discuss how recent developments in deep generative
modelling alleviate some of these challenges, offering new
opportunities for active inference in the context of high-
dimensional data.
III. D EEP GENERATIVE MODELS
The potential gains of using accurate generative priors in
ultrasound perception-action loops can perhaps most easily be
understood when realizing that most combinations of pixels
that form images are not interesting at all. Although a 5-second
4 ACCEPTED PREPRINT, IEEE TUFFC, 2024
Simple tractable 
latent distribution
ğ’›ğ’›ğ‘–ğ‘– 
ğ’›ğ’› âˆˆ â„ğ‘ğ‘ğ‘§ğ‘§ ğ’™ğ’™ âˆˆ â„ğ‘ğ‘2
ğ’™ğ’™ğ‘–ğ‘– 
Deep generative 
modeling
ğ’™ğ’™ğ‘–ğ‘– âˆ¼ ğ‘ğ‘(ğ’™ğ’™)
ğ‘ğ‘ğœƒğœƒ(ğ’™ğ’™|ğ’›ğ’›)
ğ’›ğ’›ğ‘–ğ‘– âˆ¼ ğ‘ğ‘(ğ’›ğ’›)
Highly-structured
data distribution
Low-dim manifold 
embedded in â„ğ‘ğ‘2
 ğ“œğ“œ
Fig. 2. Real-world high-dimensional data such as ultrasound images lie on a low-dimensional manifold embedded in that high-dimensional space.
This manifold is typically very intricate and non-smooth in the high-dimensional data space, and images that lie on it are highly structured. Deep
generative learning allows modeling of such highly-structured distributions and sampling of novel datapoints that lie on these low-dimensional
manifolds. This is enabled by transforming samples from a tractable distribution (such as an isotropic Gaussian) zi âˆ¼ RNz into samples from
the true data distribution xi âˆ¼ RN2
. There are many ways of achieving this, e.g. via a conditional distribution pÎ¸(x|z) trained using variational
inference, game theory (adversarial models), or just maximum likelihood for specific invertible models (normalizing flows). Alternatively, iterative
sampling methods learn to estimate the gradients of the true data distribution at a plurality of noise scale manifolds that successively corrupt the data
distribution into a tractable isotropic normal. These gradients then allow for reversing this process using reverse diffusion or Langevin dynamics.
high-quality ultrafast video can in principle represent more
than a trillion unique instances, the vast majority of those
hypothetical instances is unstructured and unnatural. If one
were to completely at random draw an instance vector x âˆˆ
RNxÃ—NyÃ—Nt, the resulting sample would with overwhelming
probability be classified as â€œnoiseâ€. In fact, one has to draw an
extremely large amount of samples in this fashion (with this
amount scaling very quickly in the number of dimensions),
until any ultrasound image is sampled. Only a tiny fraction of
that space is occupied by plausible ultrasound images. This
is the manifold hypothesis: real-world high-dimensional data
(such as images) lie on low-dimensional manifolds embedded
within the high-dimensional space [11]. To use generative
models in perception-action loops is to use the structure of
the natural world. It allows systems to track states on a low-
dimensional manifold, rather than in the very high-dimensional
data space. Deep generative models can be used to accurately
describe the complex hierarchical structure in spatio-temporal
imaging data (see Fig. 2).
In principle one could choose to learn the entire generative
model in Eqn. (1) from data. Given a training dataset of L
samples {(Ë†y1
0:T , Ë†x1
0:T , Ë†a1
0:T ), ...,(Ë†yL
0:T , Ë†xL
0:T , Ë†aL
0:T )}, one would
then fit a deep generative model to the joint distribution.
Often we will use the factorization in Eqn. (2), and when
possible make use of modelling and physics to describe the
conditional observation density p(y0:T |x0:T , a0:T ), which we
will often be able to further decompose into memoryless
factors p(yt|xt, at). Many observation models are reasonably
assumed to be Gaussian, with its mean being some (possibly
nonlinear) function of the state xt and action at. This leaves
us with the modelling of the prior p(x0:T )
How much structure (in space and time) should be imposed
on x0:T amounts to the classic bias-variance trade-off. One
way to reduce bias is to factorize the prior, e.g. by only
imposing structure locally in space or time (patches). That
is, we assume that there is a factorization
p(x) =
Y
i
p(xi), (3)
with factors p(xi) governing the density functions for non-
overlapping individual patches xi âˆˆ RMxÃ—MyÃ—Mt.
Given this, we can now fit a deep generative model for
p(x) to its data samples. Deep generative modelling comes
in many flavours, and which technique to use is a design
choice. We refer the reader to the book by Tomczak [12]
for an excellent overview. In this paper, we are mostly
concerned with the generation of samples, i.e. xi âˆ¼ p(x),
where p(x) is some complex data distribution (e.g. that of
images). This is enabled by drawing samples from some
tractable, simple distribution zi âˆ¼ p(z), and transforming
those into samples from p(x). Using variational inference
[13] one can optimize an evidence lower bound to p(x)
by jointly learning the generative conditional distribution
pÎ¸(x|z) and a variational posterior qÏ•(z|x) that is amortized
across the training dataset, given a tractable prior e.g.
p(z) = N(0, I). Another alternative is to use game theory
and train models that play a game against a neural adversary
trying to detect whether generated samples come from the
true data distribution or are generated by the model [14].
We can also train models directly using maximum likelihood
when using specific invertible models, i.e. normalizing flows
[15]. Iterative sampling methods instead learn to estimate the
gradients of the true data distribution at a plurality of noise
scale manifolds that successively corrupt the data distribution
into a tractable isotropic normal. These gradients then allow
for reversing this process using reverse diffusion methods or
Langevin dynamics. We will now briefly review diffusion
models as they will later be used in our examples.
Diffusion models: Diffusion models are state-of-the-art in
image and video generation. A notable challenge that diffusion
models overcome is the need for explicit normalization of
learned density functions (i.e. assuring that
R
p(x)dx = 1 ).
VAN SLOUN: COGNITIVE ULTRASOUND 5
Such normalization is typically achieved by imposing specific
constraints on the architecture (e.g., using flows [15]) or using
variational approximate inference methods. Instead, diffusion
models indirectly parameterize the (log) data distribution by
learning to approximate its gradient, the score function.
The score function appears when reversing a forward
stochastic differential equation (SDE) that progressively adds
Gaussian white noise to samples drawn from the data distribu-
tion p(x), such that eventually these samples become samples
from a standard Normal distribution [16]. The forward SDE
is as follows:
dx = âˆ’Î²(ts)
2 xdts +
p
Î²(ts)dw, (4)
where x(0) is an initial noise-free sample, ts âˆˆ [0, T ], Î²(ts)
is the noise schedule, w is a standard Wiener process, and
x(T ) âˆ¼ N(0, I). As said, this SDE can be reversed using the
score function [17]:
dx =

âˆ’Î²(ts)
2 x âˆ’ Î²(ts)âˆ‡x log pts(x)

dts +
p
Î²(ts)d Â¯w,
(5)
where Â¯w is a standard Wiener process running backwards.
Following the notation by [18], the discrete setting of the SDE
is represented using xts = x(tsT/N ), Î²ts = Î²(tsT/N ), Î±ts =
1 âˆ’ Î²ts, Â¯Î±ts = Qts
s=1 Î±s.
The diffusion model performs reversal of the forward SDE
by learning the score function using a neural network param-
eterised by Î¸, conditioned on the timestep ts, sÎ¸(xts, ts) â‰ˆ
âˆ‡x log pts(x)|x=xts . The parameters are learned using denois-
ing score matching [19]. To sample from p(x), one can then
sample from a standard normal, and revert the SDE using
the learned score function. This is an iterative process, with a
neural network function evaluation at each iteration, and hence
its vanilla implementation is time-consuming. Accelerating
diffusion models is hence a very active research theme today,
with many solutions for fast sampling being developed [20].
IV. P ERCEPTUAL INFERENCE
We will now make the perception step in our perception-action
loop explicit. Perception is the act of updating beliefs about
the states governed by the generative model in Eqn. (1) given
new information. Indeed, information is that which induces
a change of beliefs. Note that this is distinct from learning,
which is to infer the generative model (functional form and/or
parameters) itself and occurs across longer timescales. In the
following, we will assume that the agent has established or
has access to a sufficiently accurate generative model. This
may be obtained through past interactions and observations
(training data) and/or injected knowledge of physics, that is
available at t = 0.
At time step t the agent first takes an action Ë†at, which
leads to observations Ë†yt. Given the tuple of all observations
and actions performed thus far, which we denote as Ë†Â¯y0:t =
(Ë†y0:t, Ë†a0:t), a rational agent will seek the minimal update
of past/prior beliefs about x0:t that satisfies the constraints
imposed by the new data - beliefs must only be revised to the
extent required by the new information [21], [22]. Such belief
updates in the face of data are given by Bayes rule:
p(x0:t|Ë†Â¯y0:t) = p(Ë†Â¯y0:t, x0:t)
p(Ë†Â¯y0:t) = p(Ë†Â¯y0:t|x0:t)p(x0:t)
p(Ë†Â¯y0:t) . (6)
The numerator can be evaluated using the known genera-
tive model Eqn. (1). Unfortunately, computing the marginal
p(Ë†Â¯y0:t) =
R
p(Ë†Â¯y0:t|x0:t)p(x0:t)dx0:t quickly becomes infeasi-
ble for high-dimensional states. In practice we will therefore
typically approximate the true posterior distribution, using an
approximate posterior q(x0:t|Ë†Â¯y0:t). We will elaborate on this
in section VI.
Perceptual inference also revisits hypotheses about what has
yet to come. That is, our posterior beliefs about the past
and present yield updated priors about the future. Using
the generative model in Eqn. (2), and assuming that (i) at
timestep t, the actions Ë†a0:t and observations Ë†y0:t are known,
i.e. q(y0:t, a0:t) = Î´(y0:t âˆ’ Ë†y0:t)Î´(a0:t âˆ’Ë†a0:t), (ii) actions only
influence observations and not states (active perception), and
(iii) yt is only a function of xt and not of past states (the
observation model is memoryless), the approximate posterior
projected also into future states and observations, for a de-
terministic sequence of hypothetical future actions aâ€²
t+1:T , is
given by:
q(x0:T , yt+1:T |aâ€²
t+1:T , Ë†Â¯y0:t)
(ii)
= p(yt+1:T |x0:T , aâ€²
t+1:T )q(x0:T |Ë†Â¯y0:t)
(iii)
= p(yt+1:T |xt+1:T , aâ€²
t+1:T )q(x0:T |Ë†Â¯y0:t)
= p(yt+1:T |xt+1:T , aâ€²
t+1:T )| {z }
observation model
p(xt+1:T |x0:t)| {z }
state evolution
q(x0:t|Ë†Â¯y0:t)| {z }
current posterior
.
(7)
Note the explicit distinction between known forward gen-
erative processes, indicated by p(Â·), and approximations of
the exact Bayesian posteriors under the generative process,
indicated by q(Â·).
Equation (7) enables the generation of hypothetical state-
observation pairs in the future, which are revisited in-situ as
new data Ë†Â¯y comes in:
q(xt+1:T , yt+1:T |aâ€²
t+1:T , Ë†Â¯y0:t)
= Eq(x0:t|Ë†Â¯y0:t) p(yt+1:T |xt+1:T , aâ€²
t+1:T )p(xt+1:T |x0:t).
(8)
We will now proceed with the selection of information-
optimal actions based on these hypothetical futures.
V. A CTIVE INFERENCE AND INFORMATION GAIN
â€œWhat is the first and most fundamental thing a newborn
infant has to do? If one subscribes to the free energy
principle, the only thing it has to do is to resolve uncertainty
about causes of [. . . ] sensations. â€ â€“ Friston [23]
The active inference paradigm postulates that an agentâ€™s
desires are encoded by their generative models, which
attribute more mass to states and observations that are aligned
with preferred outcomes [24]. Humans desire to stay alive
and hence place a strong prior on equilibrium conditions
6 ACCEPTED PREPRINT, IEEE TUFFC, 2024
manifesting in e.g. homeostasis, and subsequent observations
such as â€œnot being hungry or too coldâ€. In active inference,
these priors subsequently drive inference of actions through
the pursuit of observations and rational beliefs about hidden
states that are not surprising. In doing so, agents actively
resist the increase of posterior entropy.
As mentioned before, we will here restrict our treatment
to agents that take actions that are purely â€œscientificâ€ in
nature, i.e. they maximize information gain, placing no ex-
plicit utilitarian preference on particular observations. We will
discuss agents that do not strive for survival but â€œjustâ€ seek
to understand the world from the viewpoint of an external
observer [3].
We start by defining the action-value functional,V (Â·), which
evaluates the expected future value for each sequence of
actions aâ€²
t+1:T given a probability density function govern-
ing our present beliefs about future states and observations
V (aâ€²
t+1:T ; q(xt+1:T , yt+1:T |aâ€²
t+1:T , Ë†Â¯y0:t)). For brevity, we will
let the conditioning on the probability density function be
implicit in what follows. We will also use the shorthand
notation Ï„ = t + 1 : T. We seek to minimize uncertainty
about the state xÏ„ , and hence our action-value-functional of
choice will be the negative expected posterior entropy:
V (aâ€²
Ï„ ) â‰œ âˆ’ H(xÏ„ |yÏ„ , aâ€²
Ï„ , Ë†Â¯y0:t) (9)
= Eq(xÏ„ ,yÏ„ |aâ€²Ï„ ,Ë†Â¯y0:t) log q(xÏ„ , yÏ„ |aâ€²
Ï„ , Ë†Â¯y0:t)
q(yÏ„ |aâ€²Ï„ , Ë†Â¯y0:t) ,
and the optimal action is:
aâˆ—
Ï„ = arg max
aâ€²Ï„
V (aâ€²
Ï„ ). (10)
Colloquially, the system will pursue actions that are ex-
pected to â€œsharpenâ€ the posterior the most. As was already
shown by Lindley [25], minimizing expected posterior entropy
is equivalent to maximizing the conditional mutual information
between state and future observations, such that we have:
aâˆ—
Ï„ =arg max
aâ€²Ï„
I(xÏ„ , yÏ„ |aâ€²
Ï„ , Ë†Â¯y0:t) (11)
=arg max
aâ€²Ï„
Eq(xÏ„ ,yÏ„ |aâ€²Ï„ ,Ë†Â¯y0:t) log p(yÏ„ |xÏ„ , aâ€²
Ï„ )
| {z }
âˆ’H(yÏ„ |xÏ„ ,aâ€²Ï„ ,Ë†Â¯y0:t)
âˆ’Eq(yÏ„ |aâ€²Ï„ ,Ë†Â¯y0:t) log q(yÏ„ |aâ€²
Ï„ , Ë†Â¯y0:t)
| {z }
H(yÏ„ |aâ€²Ï„ ,Ë†Â¯y0:t)
. (12)
Note that we again explicitly distinguish factors that are
inferred based on past data (the approximate posteriors q(Â·))
and forward generative models p(Â·). The conditional mutual
information can also be interpreted as the expected prior-
posterior gain, i.e. the expected divergence between the prior
and posterior, or colloquially, â€œhow much it has been updatedâ€.
The larger the update, the more information has been gained
from the measurement.
From Eqn. (12) we can also appreciate that maximizing
mutual information, or information gain, can be achieved
by selecting the actions that maximize the marginal differ-
ential entropy of future observations H(yÏ„ |aâ€²
Ï„ , Ë†Â¯y0:t), if the
conditional entropy of the observations given the state is not
dependent on the actions, i.e. H(yÏ„ |xÏ„ , aâ€²
Ï„ ) = H(yÏ„ |xÏ„ ), âˆ€aâ€²
Ï„ .
This is often a reasonable assumption for active perceivers
and generally holds for observation models of the form yt =
f(xt, at) +nt in which the remaining entropy in yt given full
knowledge of xt is solely determined by the noise nt, and
thus independent of at.
VI. I MPLEMENTING PERCEPTION -ACTION LOOPS
Estimating the entropies in Eqn. (12) is not trivial in practice,
especially for the flexible class of density functions needed to
accurately describe high-dimensional images and their (possi-
bly nonlinear) observations. It is worth reiterating that simple
linear models based on members of the exponential family
that do have closed-form expressions are insufficient for what
we try to achieve. Instead, we hypothesise that performing
approximate inference with accurate (deep) generative models
is more fruitful than pursuing exact inference with overly
simple models. This confronts us with the daunting task
of performing reliable approximate inference using highly
nonlinear (deep) generative models. For the sake of brevity, in
what follows we make the dependency of future observations
on the actions aâ€²
Ï„ implicit and use shorthand notation Ë†Â¯y to
indicate the tuple of all past observations and actions Ë†Â¯y0:tâˆ’1.
A. Approximate posterior inference
A common approach to approximating the posterior density
function is to use a set of samples/particles {x1
0:T , ..., xNp
0:T } âˆ¼
p(x0:T |Ë†Â¯y) and weights {w1, ..., wNp} that are proportional
to the probability of the sample belonging to the target
distribution:
q(x0:T |Ë†Â¯y) =
NpX
i=1
wiÎ´(x0:T âˆ’ xi
0:T ), (13)
with P
i wi = 1 . Sampling methods make no explicit as-
sumptions about the functional form of the density functions
and hence have low bias. This does come at the expense of
relatively high variance, and resolving it requires paying a
computational price, e.g. in terms of the number of samples
required to get good (mode) coverage of the distribution.
Many methods allow for effective and/or efficient sampling
from a posterior. For instance, deep generative diffusion
models enable posterior sampling by integrating a data-
consistency/likelihood step into the reverse diffusion process
[18]. Another alternative is to use classic sequential Monte-
Carlo methods (e.g. particle filters) [26]. These methods
exploit the sequential structure of states to perform highly
efficient tracking of the distribution under arbitrary (possibly
non-differentiable) nonlinear forward models. Such forward
models can be physics-based, or learned from data, e.g. a
pre-trained deep generative latent variable model that fits
p(xt) =
R
z p(xt|z)p(z)dz using variational inference [13].
An extensive review of methods for approximating posterior
distributions given nonlinear high-dimensional models is
beyond the scope of this paper. We refer the interested reader
to [18], [27]â€“[29]. As before, we will however give some
special attention to diffusion models.
VAN SLOUN: COGNITIVE ULTRASOUND 7
Diffusion posterior sampling: The reverse diffusion pro-
cess can be conditioned on a measurement obtained us-
ing a model y|x âˆ¼ p(y|x) to produce samples from the
posterior p(x|y). This is done by changing the uncondi-
tional score function in (5) into a posterior score function
âˆ‡xts log pts(xts|y). However, the posterior score is not trivial
to evaluate, as refactoring it into a (data-conditional) likelihood
score, âˆ‡xts log pts(y|xts), and the original (unconditional)
prior score, requires computing the intractable likelihood of
noise-perturbed states. This has led to various approximate
guidance schemes [18], [30], [31], most of which exploit
Tweedieâ€™s formula, which can be thought of as a one-step
denoising process from ts â†’ 0 using our trained diffusion
model to estimate the true fully-denoised sample x0 as follows:
Ë†x0 =E[x0|xts]
â‰ˆ 1p
Â¯Î±(ts)
(xts + (1 âˆ’ Â¯Î±(ts))sÎ¸(xts, ts)). (14)
Diffusion Posterior Sampling (DPS) uses (14) to approximate
âˆ‡xts log p(y|xts) â‰ˆ âˆ‡xts log p(y|Ë†x0), which for (non)linear
Gaussian likelihood models leads to a guidance gradient
âˆ‡xts ||y âˆ’ f(Ë†x0)||2
2 that can be straightforwardly evaluated.
This measurement-guidance gradient step is then alternated
with the standard reverse diffusion steps using the uncondi-
tional score.
B. Approximate entropy models
Given a set of posterior samples, the next step is to estimate
the entropy terms in our action-value function. Recall that
our action-value function is the action-conditional mutual
information between state and future observations, and de-
composes into two entropies: The marginal entropy of the
observations, H(yÏ„ |Ë†Â¯y), and the state-conditional entropy of
the observations, H(yÏ„ |xÏ„ , Ë†Â¯y) (see Eqn. (12)). In the most
general case, both depend on the action, although there are
many practical examples for which the latter dependency is
negligible (recall the discussion at the end of Section V).
We nevertheless start with the expected conditional entropy
(the remaining uncertainty about yÏ„ if xÏ„ were known) as
choosing a reasonable entropy model is more straightforward.
Assuming a forward measurement model with additive Gaus-
sian noise nÏ„ , i.e. yÏ„ = f(xÏ„ , aÏ„ ) + nÏ„ , the conditional
entropy model is also a Gaussian. Given posterior samples
{x1
Ï„ , ..., xNp
Ï„ } âˆ¼p(xÏ„ |Ë†Â¯y) with uniform weights, we then have
that:
H(yÏ„ |xÏ„ , Ë†Â¯y) = Eq(xÏ„ ,yÏ„ |Ë†Â¯y) âˆ’log p(yÏ„ |xÏ„ ) (15)
= âˆ’ Eq(xÏ„ |Ë†Â¯y) Ep(yÏ„ |xÏ„ ) log p(yÏ„ |xÏ„ ) (16)
= âˆ’ 1
Np
NpX
i=1
Ep(yÏ„ |xiÏ„ ) log p(yÏ„ |xi
Ï„ ) (17)
â‰ˆ constant + 1
Np
NpX
i=1
1
2 log |ËœÎ£yÏ„ (xi
Ï„ )| (18)
âˆ—
= constant + 1
2 log |ËœÎ£yÏ„ |, (19)
with ËœÎ£yÏ„ (xi
Ï„ ) being the sample covariance, estimated using
Np samples from {y1
Ï„ , ..., yNp
Ï„ } âˆ¼p(yÏ„ |xi
Ï„ ), and the equality
in Eqn. (19) being true if ËœÎ£yÏ„ (xi
Ï„ ) = ËœÎ£yÏ„ for all xi
Ï„ .
We now proceed with the marginal entropy H(yÏ„ |Ë†Â¯y). Col-
loquially, this reflects the diversity of futures that may be
observed for each of the actions. Ultimately, only one observa-
tion will manifest, but it is the diversity in hypothetical future
observations that measures the uncertainty that one has about
the result of an imaging experiment. Approximating it requires
choosing a reasonable marginal model, which is not obvious.
In general, the marginal distribution over future observations
p(yÏ„ |Ë†Â¯y) may be multimodal, as the posterior distribution
p(xÏ„ |Ë†Â¯y) is likely multimodal too for high-dimensional states
and partial observations. Nevertheless, in the examples of
section VII we will see that approximating the marginal as
a multivariate Gaussian is often a reasonable choice from a
pragmatic perspective.
To illustrate this, consider the following thought experiment.
An agent evaluates the expected value of two candidate actions
by sampling expected observations in R1 for both of them. The
first action results in a unimodal empirical distribution over hy-
pothetical observations of which all samples have some small
nonzero â„“2 distance to each other. The second action results
in a bimodal distribution over hypothetical observations, with
the â„“2 distance among samples within each mode being close
to zero, but the â„“2 distance between the modes being very
large. Fitting a (unimodal) Gaussian entropy model to both
distributions would lead to a higher marginal entropy for the
latter: the large â„“2 distance between the modes would dominate
the variance. As such the agent would select the latter action.
In many risk-sensitive applications, such as medical imaging,
selecting the latter action would arguably indeed be preferred,
as it would discriminate between two equally plausible but
(semantically) very different modes. The entropy of a Gaussian
marginal is a reasonable surrogate for this â€œdistanceâ€, although
the model fit itself can be poor (as in the bimodal example
given above). The analogy is less intuitive for observations in
RN , but it is clear that in that case one should also model the
correlation across the elements in the observation vector.
Assuming that the marginal observations indeed follow a
multivariate Gaussian pdf, i.e. q(yÏ„ |Ë†Â¯y) = N(Âµy|Ë†Â¯y, Î£y|Ë†Â¯y), and
that we are given posterior samples {y1
Ï„ , ..., yNp
Ï„ } âˆ¼q(yÏ„ |Ë†Â¯y),
we have:
H(yÏ„ |Ë†Â¯y) â‰ˆ constant + 1
2 log |ËœÎ£y|Ë†Â¯y|, (20)
where ËœÎ£y|Ë†Â¯y is the sample covariance, estimated using Np
samples from p(yÏ„ |Ë†Â¯y). This result is intuitive: the determinant
|ËœÎ£y|Ë†Â¯y| is also called the generalized variance, and is equal to
the product of the eigenvalues of ËœÎ£y|Ë†Â¯y.
Alternatively, we can start from the approximate posterior
family in Eqn. (13) to derive a model for the marginal. Again,
assuming Gaussian measurements yÏ„ = f(xÏ„ , aÏ„ ) + nÏ„ , we
obtain that q(yÏ„ |Ë†Â¯y) is a mixture of Gaussians, i.e.:
q(yÏ„ |Ë†Â¯y) =
NpX
i=1
wiN(Âµi, Î£i), (21)
8 ACCEPTED PREPRINT, IEEE TUFFC, 2024
Action
Perception
1
2
Heart rate
estimation
TX 
sequence
RX Doppler 
processing
steer
ğ‘ğ‘ ğ’™ğ’™0:ğ‘¡ğ‘¡| ï¿½ï¿½ğ’šğ’š0:ğ‘¡ğ‘¡
ğ‘ğ‘ğ‘¡ğ‘¡
âˆ— = ğ¼ğ¼(ğ’šğ’šğ‘¡ğ‘¡, ğ’™ğ’™ğ‘¡ğ‘¡|ğ‘ğ‘ğ‘¡ğ‘¡
â€², ï¿½ï¿½ğ’šğ’š0:ğ‘¡ğ‘¡âˆ’1)
Sequential Monte Carlo
Agent 
ï¿½ğ’šğ’šğ‘¡ğ‘¡
ğ‘ğ‘ ğ’™ğ’™ğ‘¡ğ‘¡, ğ’šğ’šğ‘¡ğ‘¡|ğ‘ğ‘ğ‘¡ğ‘¡
â€², ï¿½ï¿½ğ’šğ’š0:ğ‘¡ğ‘¡âˆ’1
Generative predictions
Fetal heartProbe
ğ”¼ğ”¼ğ‘ğ‘(ğ’™ğ’™ğ‘¡ğ‘¡| ï¿½ï¿½ğ’šğ’š0:ğ‘¡ğ‘¡)(ğ’™ğ’™ğ‘¡ğ‘¡)
Posterior mean
3
(a)
Time [min]
Angle [rad]
(c)
Time [min]
Heart-rate [bpm]
GT
Estimates
GT
Estimates
(b)
Fig. 3. Example: Active beamsteering using sequential Monte-Carlo [32]. (a) Doppler target tracking using cognitive ultrasound. (1) The agent
selects the action (beamsteering angle Î¸tx
t ) that has the highest expected information gain given generative predictions q(xt, yt|aâ€²
t, Ë† y0:tâˆ’1). (2)
This action prompts a new Doppler observation Ë† yt, which in turn triggers an update of the posterior q(x0:t|Ë† y0:t), implemented using a sequential
Monte Carlo method. (3) Finally, the posterior mean fetal heart location at that timestep is communicated to a heart rate estimation module
alongside the received Doppler data. (b) Real-time lab setup mimicking the scenario described in (a), using a phased array transducer mounted on
a translation stage that transmits a focused beam controlled by the agent to track a â€œbeatingâ€ chicken heart. (c) Positional tracking and heart rate
estimation (red) from adaptively steered focused beams, against ground truth (blue).
where Âµi = f(xi
Ï„ , aÏ„ ). A variational approximation to the
marginal differential entropy is then given by [33]:
H(yÏ„ |Ë†Â¯y) â‰ˆ âˆ’
NpX
i=1
wi log
NpX
j=1
wjeâˆ’KL[N(Âµi,Î£i)||N(Âµj,Î£j)]
+
NpX
i=1
wiH[N(Âµi, Î£i)],
(22)
which can be evaluated in closed form. If one assumes that the
measurement noise has constant diagonal isotropic covariance
Î£i = Î£j = Ïƒ2
yI, Eqn. (22) further simplifies to:
H(yÏ„ |Ë†Â¯y) â‰ˆ constant âˆ’
NpX
i=1
wi log
NpX
j=1
wje
âˆ’
||Âµiâˆ’Âµj||2
2
2Ïƒ2y , (23)
which illustrates the intuitive connection between distance
among the samples in observation space and the differential
entropy.
We now have all the ingredients to close the ultrasound
perception-action loop: (1) perceptual inference of anatomical
state posteriors using deep generative models, followed by
(2) action selection through maximization of an approximate
action-conditional mutual information between future states
and future observations.
VII. E XAMPLES
We will now illustrate the concepts described above in the
context of concrete ultrasound imaging applications. From
sections VII-A, to VII-C, we will cover (A) active inference
with low-dimensional generative models based on first princi-
ples, (B) perceptual inference with complex data-driven deep
generative models in high dimensions, and finally, (C) active
inference using deep generative models.
A. Active beamsteering using sequential Monte-Carlo
1) Generative model: We start with an agent that is tasked
with the sequential selection of optimal focused transmit
beams for tracking the position of a moving Doppler target
xt = ( Î¸t, zt, Ï‰t), with Î¸t its angular position, zt its axial
position, and Ï‰t its Doppler frequency at timestep t [32]. The
observation at timestep t, Ë†yt âˆˆ RNÎ¸ , is an angular power
Doppler profile. It is computed by pixel-based receive beam-
forming and subsequent Doppler processing of an ensemble of
channel data coming from focused transmits with a fixed focal
depth ztx and steering angle Ë†at = Î¸tx
t . The agentâ€™s generative
model given a series of actions aâ€²
0:T is given by:
p(y0:T , x0:T |aâ€²
0:T ) = p(y0:T |x0:T , aâ€²
0:T )p(x0:T ), (24)
with
p(x0:T ) = p(x0)
TY
t=1
p(xt|xtâˆ’1), (25)
assuming x has sequential Markovian structure, with lin-
ear Gaussian state transition dynamics p(xt|xtâˆ’1) =
N(Axtâˆ’1, Î£x), and a Gaussian memoryless nonlinear obser-
vation model p(yt|xt, at) = N(f(xt; at), Î£y). Here, f(Â·; at) :
R3 â†’ RNÎ¸ is a forward observation function that maps the
target state to a simulated power Doppler profile, using an
approximate action-conditional transmit beamprofile.
2) Perception: We here track the posterior using particle
filtering [26], a sequential Monte-Carlo method based on the
posterior family in Eqn. (13). We use the state transition prior
as the proposal distribution (bootstrap particle filter), i.e. we
draw proposals as xi
t âˆ¼ p(xi
t|xi
tâˆ’1), and update the weights
of the resulting Np particles by their likelihood given the new
VAN SLOUN: COGNITIVE ULTRASOUND 9
GT EchoNet dehazed EchoNet input
(a) (b)input ğ’šğ’š
gCNR
4 5 6 8 9
Input NCSNv2 BM3D Ours
0.70
0.75
0.80
0.85
0.90
FWHMlat[px]
7
dehazed ï¿½ğ’™ğ’™
Fig. 4. Example: Multipath haze suppression using diffusion models. (a) Example input y and dehazed output Ë† x(top) along with automatic left-
ventricular (LV) segmentations by EchoNet [34] (bottom). Note how the LV area is underestimated on the hazy, cluttered, input data, and how this is
improved after dehazing. (b) Tradeoff between tissue contrast (gCNR) and lateral resolution (FWHM), showing how dehazing by generative diffusion
models (ours) greatly improves the gCNR while compromising much less on resolution than denoising methods such as BM3D. It also compares
favourably against a discriminative neural network using supervised training on phantom data (NCSNv2). Image adapted from [6].
observations, i.e.:
Ë†wi
t = wi
tâˆ’1p(Ë†yt|xi
t, aâ€²
t), (26)
and then normalize such that wi
t = Ë†wi
tP
i Ë†wi
t
. As per common
practice, we additionally perform resampling of particles to
avoid degeneracy [26]. This posterior update then allows sam-
pling updated futures from p(yt+1|Ë†y0:t, aâ€²
t+1), using the par-
ticles yi
t+1 âˆ¼ p(yt+1|xi
t+1, aâ€²
t+1), with xi
t+1 âˆ¼ p(xi
t+1|xi
t).
These hypothetical futures are used to drive action selection.
3) Action: At each timestep t, the agent greedily selects the
next beamsteering action aâˆ—
t+1 by maximizing the expected
information gain I(yt+1, xt+1|aâ€²
t+1, Ë†y0:t) across a discrete
set of candidate actions aâ€²
t+1 âˆˆ Sa, which in light of the
aforementioned generative model is equivalent to maximizing
the marginal differential entropy of the observations: the
conditional entropy is constant for all actions, and solely
determined by the receiver noise covariance Î£y. We further
assume a marginal multivariate Gaussian distribution and
approximate the differential entropy using Np samples from
the marginal {y1
t+1, ...,yNp
t+1} âˆ¼p(yt+1|Ë†y0:t, aâ€²
t+1) as:
aâˆ—
t+1 =arg max
aâ€²
t+1âˆˆSa
1
2 log |ËœÎ£(aâ€²
t+1, Ë†y0:t)|. (27)
This action yields a new observation Ë†yt+1, which in turn
prompts an update of the posterior distribution (perception),
closing the loop.
4) Results: Figure 3 shows a real-time implementation
of the perception-action loop for a dynamic Doppler target
mimicking a beating fetal heart in a lab setup. We use an
s5-1 phased array transducer (Philips) mounted on a motion
stage, and connected to the Verasonics Vantage 256 system.
At each timestep t, we perform a Doppler transmit sequence
(ensemble length: 2000 frames, PRF: 1.5 kHz, center fre-
quency: 3.125 MHz) with an adaptively-steered focused beam
at Î¸tx
t . After pixel-based receive beamforming, we compute the
integral across the depth and Doppler axes to get an observed
power-Doppler angular profile Ë†yt. The information-seeking
agent accurately tracks the moving target and retains precise
downstream heart-rate estimates by adequately steering the
beam and maintaining high Doppler SNR. Performance was
also quantified for various Doppler SNR levels in-silico, with
SNR defined relative to the peak Doppler signal under ideal
steering. These results show that heart rate estimation using
cognitive adaptive steering remained accurate (within 5 bpm of
the ground truth) at about 20dB lower SNR levels compared to
non-adaptive steering, a direct result of the dramatic reduction
in beamforming gain when the target moved out of the static
beam.
B. Multipath haze suppression using diffusion models
1) Generative model: The previous example shows how
cognitive ultrasound imaging improves target tracking given a
physics-based model of the observations and a linear Gaussian
state transition function in R3. To move to more complex and
high-dimensional states, such as high-resolution reflectivity
maps in RNÃ—N , we will first need to expand the modelling.
We will therefore train a generative diffusion model from data.
We consider an agent that is tasked with the suppression
of multipath clutter (â€œhazeâ€) from (linearly) beamformed RF
data patches y âˆˆ RNÃ—N in cardiac imaging [6]. To that end,
we define the following generative model, assuming linear
scattering:
p(y, x, h) = p(y|x, h)p(x)p(h), (28)
10 ACCEPTED PREPRINT, IEEE TUFFC, 2024
(a) (b)
ğ‘ ğ‘ ğœƒğœƒ(ï¿½ğ‘¥ğ‘¥ğœğœ, ğœğœ)
A(ğ‘ğ‘ğ‘¡ğ‘¡
âˆ—)
ğ‘¥ğ‘¥ğ‘¡ğ‘¡âˆ’1
âˆ—
ğ‘¥ğ‘¥ğ‘¡ğ‘¡+1
âˆ—
ğ‘¥ğ‘¥ğ‘¡ğ‘¡
âˆ—
Unobserved anatomy
Past observations
ï¿½ğ‘¦ğ‘¦ğ‘¡ğ‘¡âˆ’ğ‘‡ğ‘‡+1:ğ‘¡ğ‘¡âˆ’1
ï¿½ğ‘¦ğ‘¦ğ‘¡ğ‘¡ = A ğ‘ğ‘ğ‘¡ğ‘¡
âˆ— ğ‘¥ğ‘¥ğ‘¡ğ‘¡
âˆ—
Acquire scanlines
Select scanlines
Posterior sampling
ğ‘¥ğ‘¥ğ‘¡ğ‘¡
(ğ‘–ğ‘–)~ğ‘ğ‘(ğ‘¥ğ‘¥ğ‘¡ğ‘¡| ï¿½ï¿½ğ‘¦ğ‘¦ğ‘¡ğ‘¡âˆ’ğ‘‡ğ‘‡+1:ğ‘¡ğ‘¡)
ï¿½ğ‘¥ğ‘¥ğ‘¡ğ‘¡âˆ’1
ï¿½ğ‘¥ğ‘¥ğ‘¡ğ‘¡+1
Maximum 
likelihood
ï¿½ğ‘¥ğ‘¥ğ‘¡ğ‘¡
Conditional Temporal 
Diffusion Model
ğ‘ğ‘ğ‘¡ğ‘¡
âˆ— = argmax ğ¼ğ¼(ğ‘¦ğ‘¦ğ‘¡ğ‘¡, ğ‘¥ğ‘¥ğ‘¡ğ‘¡|ğ‘ğ‘ğ‘¡ğ‘¡
â€²)
Action
Iterative denoising
Reconstructions
Perception
Discretized time ğ‘¡ğ‘¡
ğ‘ğ‘ğ‘¡ğ‘¡
â€² âˆˆ ğ‘†ğ‘†ğ‘ğ‘
Fig. 5. Example: Active subsampling using temporal diffusion models. (a) Overview of the perception-action loop for ultrasound scanline selection.
At timestep t, the agent acquires k scanlines that maximize expected information gain. It then combines them with the past k(T âˆ’ 1) scanlines
acquired at timesteps t âˆ’ T + 1 :t âˆ’ 1, and perform perceptual inference via diffusion posterior sampling to yield samples x(i)
t . The most likely
sample is selected as the final reconstruction. Next, the posterior samples are used to estimate expected information gain at timestep t + 1, and
the action aâˆ—
t+1 that maximizes it is used to acquire the next scanlines. (b) Mean absolute reconstruction error (MAE) of a cognitive agent (Max
information Sampling) vs a random agent (Random Sampling). Both use the conditional temporal diffusion model for inference. Each blue dot is a
hold-out test sequence from the CAMUS dataset. Points above the red dashed line are points for which cognitive imaging outperforms a random
scanline selection.
where x âˆˆ RNÃ—N is the beamformed direct path contribution,
and h âˆˆ RNÃ—N is the multipath component. The generative
model assumes that the direct and multipath RF data are
statistically independent, governed by their respective priors
p(x) and p(h). We further assume that p(y|x, h) is a linear
Gaussian model of the form N(x + h, Ïƒ2
nI). We perform
denoising score matching on (unpaired) training data samples
{Ë†x1, ...,Ë†xL}, and {Ë†h1, ...,Ë†hL} to learn two score functions,
conditioned on the SDE timestep ts: âˆ‡xts log pÏ„ (xts) â‰ˆ
sÎ¸(xts, ts) and âˆ‡hts log pts(hts) â‰ˆ sÏ•(hts, ts). For architec-
tural and training details see [6].
2) Perception: We then perform diffusion posterior sam-
pling xts, hts âˆ¼ p(xts, hts|y) through the formulation of a
joint conditional diffusion process {xts, hts|y}tsâˆˆ[0,T ], in turn
producing a joint conditional reverse-time SDE:
d(xts, hts) =

f(ts)(xts, hts) âˆ’ . . .
g(ts)2âˆ‡xts,hts log p(xts, hts|y)

dÏ„ + g(ts)d Â¯wts,
(29)
where the posterior score at SDE timestep ts,
âˆ‡xts,hts log p(xts, hts|y), is approximated as:
ï£±
ï£´ï£´ï£²
ï£´ï£´ï£³
âˆ‡xts log p(xts, hts|y) â‰ƒ sÎ¸(xts, ts)
+âˆ‡xts log p(y|xts, hts)
âˆ‡hts log p(xts, hts|y) â‰ƒ sÏ•(hts, ts)
+âˆ‡hts log p(y|xts, hts)
,
(30)
in which we use the generative model in Eqn. (28), Bayes rule,
and that the gradient of the marginal p(y) with respect to x and
h is zero. As noted in section VI-A, the conditional distribution
of y given noise-perturbed states xts and hts, p(y|xts, hts),
is generally intractable, unlike the known data likelihood
factor in the generative model p(y|x0, h0). Following Song
et al . [19], we therefore approximate it as p(y|xts, hts) â‰ˆ
p(Ëœyts|xts, hts) = N(xts + hts, Ï2I), with Ëœyts âˆ¼ q(yts|y0)
being a noise-perturbed observation.
3) Results: We evaluate performance on 1020 cardiac ultra-
sound RF frames from two difficult-to-image volunteers across
4 cardiac views (three chamber, four chamber, parasternal
long axis and parasternal short axis), acquired using an X5-
1C matrix transducer connected using a Philips EPIQ scanner
in harmonic imaging mode. Figure 4a qualitatively shows
how dehazing significantly boosts tissue contrast, as well as
improving the downstream left-ventricular segmentation. In
Fig. 4b, we quantitatively evaluate performance, showing that
our deep generative dehazing model strikes a good balance
between tissue contrast and resolution, comparing favourably
to other methods.
C. Active subsampling using temporal diffusion models
1) Generative Model: Our final example concerns an agent
that performs adaptive compressive sensing [35], [36] through
active subsampling of ultrasound scanlines. We will use the
approach by Nolan et al. [37] to design subsampling masks
that maximize information gain given a diffusion-based gen-
erative model. Subsampling transmit events (be it scanlines,
diverging waves, or otherwise) is typically used to minimize
costs associated with data acquisition, such as acquisition time.
Our agent is tasked with the reconstruction of a sequence of
T ultrasound frames x1:T âˆˆ RNzÃ—NyÃ—T from goal-directed
partial observations y1:T âˆˆ RNzÃ—kÃ—T , with a budget of k <
Ny focused scanlines per frame. We formulate the following
observation model:
yt = A(at)xt, (31)
with A(at) being the time-varying (structured) subsampling
matrix that given action at selects all samples belonging to K
VAN SLOUN: COGNITIVE ULTRASOUND 11
scanlines from the vectorized frame xt. The agentâ€™s generative
model is then given by:
p(y1:T , x1:T |aâ€²
1:T ) =p(y1:T |x1:T , aâ€²
1:T )p(x1:T ), (32)
=p(x1:T )
TY
t=1
p(yt|xt, aâ€²
t), (33)
assuming a Gaussian memoryless linear observation model
p(yt|xt, aâ€²
t) = N(A(aâ€²
t), Î£y) that can be factorized in time.
We will again use a diffusion model to establish the spa-
tiotemporal generative prior p(x1:T ). To that end, we sample
sequences of T = 4 frames Ë†Â¯xl
t = [ Ë†xl
tâˆ’T+1, ...,Ë†xl
t] from the
CAMUS dataset [38], and convert them into polar coordinates.
We use denoising score-matching to train the (now spatiotem-
poral) score function sÎ¸(Â¯xts, ts) â‰ˆ âˆ‡Â¯xts log pts(Â¯xts) using
a U-Net architecture based on [39]. We use 400 videos for
training and 50 for testing. One video contained about 19
frames on average.
2) Perception: At each timestep t, we consider the T
most recent measurements Ë†ytâˆ’T+1:t, and use diffusion pos-
terior sampling to generate a total of 16 posterior samples
{Â¯x(1)
t , ...,Â¯x(16)
t } âˆ¼ p(Â¯xt|Ë†ytâˆ’T+1:t), tracking a distribution
over plausible anatomical state sequences. To that end,
we again exploit Tweedyâ€™s formula and perform likelihood-
guidance of the reverse diffusion process making use of the
factorization in Eqn. (33). The posterior sample with the
highest likelihood is used to produce reconstruction Ë†xt which
is compared with the ground truth xâˆ—
t .
3) Action: Using the generative forward model, we project
the posterior samples x(i)
t into hypothetical future obser-
vations yt+1|aâ€²
t+1, and greedily choose the k lines that
maximize expected information gain at timestep t + 1, i.e.
aâˆ—
t+1 = arg max
aâ€²
t+1âˆˆSa
I(yt+1, xt+1|aâ€²
t+1, Ë†ytâˆ’T+1:t), using a pixel-
wise Gaussian marginal entropy model. As in the first exam-
ple, the conditional entropy is constant across the actions, and
solely determined by Î£y. In effect, the agent will thus select
those lines that have the highest generalized variance across
the posterior samples, in order to resolve that uncertainty.
Figure 5a gives an overview of the approach.
4) Results: The model successfully tracks the anatomical
dynamics over time and generates accurate reconstructions
preserving important anatomical details using only 12.5% of
the scan lines per frame. We compare the cognitive sampling
strategy to random sampling and find that maximum informa-
tion sampling almost always outperforms random sampling
(see Figure 5b). We also find that maximum information
sampling with 4 lines outperforms random sampling with 6
lines, indicating that cognitive sampling, in this case, is worth
50% more measurements.
VIII. D ISCUSSION
This paper gives a new interpretation of the ultrasound
transmit-receive cycle as a perception-action loop, in which
pulse-echo experiments are adaptively designed to maximize
information gain given a generative model. It treats ultrasound
imaging as an active inference problem [24], with clear ties
to other fields that have a long tradition, such as Bayesian
experiment design [40], active perception [4], active hypoth-
esis testing [41], and adaptive compressed sensing [36]. We
postulate that recent advances in deep generative modelling
unlock the potential of these approaches for high-dimensional
imaging [37], [42], and specifically ultrasound.
Active inference also shares similarities with other fields,
such as reinforcement learning (RL) and stochastic optimal
control [43]. In stochastic optimal control, policies are de-
signed to minimize an expected KL divergence to a goal prior.
Like in active inference, actions are selected based on real-
time simulations (inference) of future states based on past and
present observations. In both active inference and stochastic
optimal control, an optimal policy can be specified as some
explicit functional of a probability density function about the
expected future, e.g. an explicit information measure (such
as the mutual information), a free energy, or a divergence
such as the KL divergence. In deep RL, optimized policies are
derived from data based on (delayed) rewards computed using
simulations of actions and resulting observations (episodes).
In some variants of RL, it is the action-value function that is
learned from data (Q learning), and the policy is to execute
the action that maximizes this action-value function [44].
The examples given in this paper illustrate the concept of
cognitive ultrasound, but also have limitations. In example
VII-C, we considered focused adaptive beamsteering actions
that lead to individual beamformed lines, while improved res-
olution could be achieved using software-based retrospective
transmit beamforming. For instance, transmit sequences can be
designed to optimize recovery of the full multistatic dataset
that is in turn used for retrospective transmit beamforming
[45]. Moreover, the cognitive ultrasound paradigm extends to-
wards optimization of other transmit parameters, including the
waveform. Its efficacy hinges upon an accurate and sufficiently
fast model that predicts the consequences of changing such
parameters on the received channel data, based on all the
channel data received in the past. Neural approximations of
physics-based acoustics simulators may allow flexible trade-
offs between inference speed and accuracy.
Using cognitive imaging, a system might in the future
perform very resource-efficient 3D scanning, e.g. using com-
binations of focused and unfocused transmissions in 3D that
jointly maximise the information gain. Moreover, a cognitive
ultrasound system might optimize the full transmitted wave-
field to minimize the impact of the acoustic window and other
patient-specific challenges in difficult-to-image patients. This
again requires modeling and inclusion of multipath effects.
Multipath could either be modeled as stochastic structured
noise (as we did for the de-hazing example), or as a determin-
istic element of the forward model. In the stochastic setting,
a cognitive system could e.g. strive to shape the statistics of
the multipath signal such that it is easily separated from the
direct path.
While we see a lot of opportunities and possible appli-
cations, there are also many open questions and challenges.
First, using deep generative models introduces a bias that
is highly desired (the structure of the natural world), but it
12 ACCEPTED PREPRINT, IEEE TUFFC, 2024
potentially also introduces undesired biases e.g. arising from
inadequate or biased sampling of the true data distribution
when training. Care must be taken not to make priors too infor-
mative and restrictive. Second, accurate posterior estimation in
complex models comes with high computational complexity,
and balancing this accuracy with efficiency for real-time im-
plementations is not trivial, potentially requiring hierarchical
inference with adaptive complexity. Third, inferring sequences
of future actions across longer time horizons (instead of our
current greedy approach) is computationally daunting, with
naive implementations growing exponentially in complexity
with time. This will likely require clever sequential reduction
of the action space. Future work should be geared towards
addressing these challenges.
IX. C ONCLUSION
Ultrasound systems engage in repeated reciprocal interactions
with the anatomical environment that they probe, and this
cycle of probing and receiving data can be interpreted as a
perception-action loop. Active inference offers a probabilis-
tic framework for developing agents that implement such
perception-action loops, which when augmented with deep
generative models that govern anatomical beliefs, unlocks
closed-loop high-dimensional imaging. We here showed how
these principles can be used for cognitive ultrasound systems
that maximize information gain by changing their probing of
the environment. The promise that this holds for ultrasound
imaging is significant; it may spur a paradigm shift in the
design of systems, akin to cognitive radar systems, that au-
tonomously strive to maximize diagnostic value in-situ.
ACKNOWLEDGMENT
The author would like to thank Tristan Stevens, Ois Â´Ä±n Nolan,
Wessel van Nierop, and Beatrice Federici, for their contribu-
tions in particular to section VII.
Ruud J.G. van Sloun is an Associate Profes-
sor at the Department of Electrical Engineer-
ing at the Eindhoven University of Technology.
He received the M.Sc. and Ph.D. degree (both
cum laude) in Electrical Engineering from the
Eindhoven University of Technology, Eindhoven,
The Netherlands, in 2014, and 2018, respec-
tively. From 2019-2020 he was a Visiting Pro-
fessor with the Department of Mathematics and
Computer Science at the Weizmann Institute of
Science, Rehovot, Israel, and from 2020-2023
he was a kickstart AI fellow at Philips Research. He received an
ERC starting grant, an NWO VIDI grant, an NWO Rubicon grant,
and a Google Faculty Research Award. His current research interests
include closed-loop image formation, deep generative learning for signal
processing and imaging, active signal acquisition, model-based deep
learning, compressed sensing, ultrasound imaging, and probabilistic
signal and image reconstruction.
REFERENCES
[1] G. D. Cole, N. M. Dhutia, M. J. Shun-Shin, K. Willson, J. Harrison,
C. E. Raphael, M. Zolgharni, J. Mayet, and D. P. Francis, â€œDefining the
real-world reproducibility of visual grading of left ventricular function
and visual estimation of left ventricular ejection fraction: impact of
image quality, experience and accreditation,â€ The international journal
of cardiovascular imaging , vol. 31, pp. 1303â€“1314, 2015.
[2] Y . Nagata, K. Yuichiro, O. Takeshi, O. Kyoko, N. Akemi, O. Yutaka, and
T. Masaaki, â€œImpact of image quality on reliability of the measurements
of left ventricular systolic function and global longitudinal strain in 2d
echocardiography,â€ Echo Research & Practice, vol. 5, no. 1, pp. 28â€“39,
2018.
[3] M. Biehl, C. Guckelsberger, C. Salge, S. C. Smith, and D. Polani,
â€œExpanding the active inference landscape: more intrinsic motivations
in the perception-action loop,â€ Frontiers in neurorobotics , vol. 12,
p. 387187, 2018.
[4] R. Bajcsy, â€œActive perception,â€ Proceedings of the IEEE , vol. 76, no. 8,
pp. 966â€“1005, 1988.
[5] R. Bajcsy, Y . Aloimonos, and J. K. Tsotsos, â€œRevisiting active percep-
tion,â€ Autonomous Robots, vol. 42, pp. 177â€“196, 2018.
[6] T. S. Stevens, F. C. Meral, J. Yu, I. Z. Apostolakis, J.-L. Robert, and
R. J. Van Sloun, â€œDehazing ultrasound using diffusion models,â€ IEEE
Transactions on Medical Imaging , 2024.
[7] Y . Zhang, C. Huneau, J. Idier, and D. Mateus, â€œUltrasound image
reconstruction with denoising diffusion restoration models,â€ in Interna-
tional Conference on Medical Image Computing and Computer-Assisted
Intervention, pp. 193â€“203, Springer, 2023.
[8] H. Lan, Z. Li, Q. He, and J. Luo, â€œFast sampling generative model
for ultrasound image reconstruction,â€ arXiv preprint arXiv:2312.09510 ,
2023.
[9] H. Asgariandehkordi, S. Goudarzi, A. Basarab, and H. Rivaz, â€œDeep
ultrasound denoising using diffusion probabilistic models,â€ in2023 IEEE
International Ultrasonics Symposium (IUS) , pp. 1â€“4, IEEE, 2023.
[10] F. Hermann Ludwig, Selected Writings of Hermann Von Helmholtz .
Conn, Wesleyan University Press, 1971.
[11] C. Fefferman, S. Mitter, and H. Narayanan, â€œTesting the manifold
hypothesis,â€ Journal of the American Mathematical Society , vol. 29,
no. 4, pp. 983â€“1049, 2016.
[12] J. M. Tomczak, Deep Generative Modeling . Springer, 2021.
[13] D. P. Kingma and M. Welling, â€œAuto-encoding variational bayes,â€ arXiv
preprint arXiv:1312.6114, 2013.
[14] A. Creswell, T. White, V . Dumoulin, K. Arulkumaran, B. Sengupta, and
A. A. Bharath, â€œGenerative adversarial networks: An overview,â€ IEEE
signal processing magazine , vol. 35, no. 1, pp. 53â€“65, 2018.
[15] I. Kobyzev, S. J. Prince, and M. A. Brubaker, â€œNormalizing flows:
An introduction and review of current methods,â€ IEEE transactions on
pattern analysis and machine intelligence , vol. 43, no. 11, pp. 3964â€“
3979, 2020.
[16] Y . Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and
B. Poole, â€œScore-based generative modeling through stochastic differ-
ential equations,â€ arXiv preprint arXiv:2011.13456 , 2020.
[17] B. D. Anderson, â€œReverse-time diffusion equation models,â€ Stochastic
Processes and their Applications , vol. 12, no. 3, pp. 313â€“326, 1982.
[18] H. Chung, J. Kim, M. T. Mccann, M. L. Klasky, and J. C. Ye, â€œDiffusion
posterior sampling for general noisy inverse problems,â€ arXiv preprint
arXiv:2209.14687, 2022.
[19] Y . Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and
B. Poole, â€œScore-based generative modeling through stochastic differ-
ential equations,â€ in International Conference on Learning Representa-
tions, 2021.
[20] C. Meng, R. Rombach, R. Gao, D. Kingma, S. Ermon, J. Ho, and T. Sal-
imans, â€œOn distillation of guided diffusion models,â€ in Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
pp. 14297â€“14306, 2023.
[21] E. T. Jaynes, â€œOn the rationale of maximum-entropy methods,â€ Proceed-
ings of the IEEE , vol. 70, no. 9, pp. 939â€“952, 1982.
[22] A. Caticha, â€œEntropic dynamics, time and quantum theory,â€ Journal of
Physics A: Mathematical and Theoretical , vol. 44, no. 22, p. 225303,
2011.
[23] K. J. Friston, â€œSelf-evidencing babies: Commentary on â€œmentalizing
homeostasis: The social origins of interoceptive inferenceâ€ by fo-
topoulou & tsakiris,â€ Neuropsychoanalysis, vol. 19, no. 1, pp. 43â€“47,
2017.
[24] K. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbeck, G. Pezzulo, et al.,
â€œActive inference and learning,â€Neuroscience & Biobehavioral Reviews,
vol. 68, pp. 862â€“879, 2016.
VAN SLOUN: COGNITIVE ULTRASOUND 13
[25] D. V . Lindley, â€œOn a measure of the information provided by an
experiment,â€ The Annals of Mathematical Statistics , vol. 27, no. 4,
pp. 986â€“1005, 1956.
[26] O. Capp Â´e, S. J. Godsill, and E. Moulines, â€œAn overview of existing
methods and recent advances in sequential monte carlo,â€ Proceedings
of the IEEE , vol. 95, no. 5, pp. 899â€“924, 2007.
[27] N. Chopin, O. Papaspiliopoulos, et al. , An introduction to sequential
Monte Carlo, vol. 4. Springer, 2020.
[28] C. Zhang, J. B Â¨utepage, H. Kjellstr Â¨om, and S. Mandt, â€œAdvances in vari-
ational inference,â€ IEEE transactions on pattern analysis and machine
intelligence, vol. 41, no. 8, pp. 2008â€“2026, 2018.
[29] T. S. Stevens, H. van Gorp, F. C. Meral, J. Shin, J. Yu, J.-L. Robert,
and R. J. van Sloun, â€œRemoving structured noise with diffusion models,â€
arXiv preprint arXiv:2302.05290 , 2023.
[30] J. Song, A. Vahdat, M. Mardani, and J. Kautz, â€œPseudoinverse-guided
diffusion models for inverse problems,â€ in International Conference on
Learning Representations, 2022.
[31] L. Rout, N. Raoof, G. Daras, C. Caramanis, A. Dimakis, and S. Shakkot-
tai, â€œSolving linear inverse problems provably via posterior sampling
with latent diffusion models,â€ Advances in Neural Information Process-
ing Systems, vol. 36, 2024.
[32] B. Federici, R. J. van Sloun, and M. Mischi, â€œActive inference for closed-
loop transmit beamsteering in fetal doppler ultrasound,â€ arXiv preprint
arXiv:2410.04869, 2024.
[33] J. R. Hershey and P. A. Olsen, â€œApproximating the kullback leibler di-
vergence between gaussian mixture models,â€ in 2007 IEEE International
Conference on Acoustics, Speech and Signal Processing-ICASSPâ€™07 ,
vol. 4, pp. IVâ€“317, IEEE, 2007.
[34] D. Ouyang, B. He, A. Ghorbani, M. P. Lungren, E. A. Ashley, D. H.
Liang, and J. Y . Zou, â€œEchonet-dynamic: a large new cardiac motion
video data resource for medical machine learning,â€ in NeurIPS ML4H
Workshop, pp. 1â€“11, 2019.
[35] H. Van Gorp, I. Huijben, B. S. Veeling, N. Pezzotti, and R. J. Van Sloun,
â€œActive deep probabilistic subsampling,â€ in International Conference on
Machine Learning, pp. 10509â€“10518, PMLR, 2021.
[36] G. Braun, S. Pokutta, and Y . Xie, â€œInfo-greedy sequential adaptive com-
pressed sensing,â€ IEEE Journal of selected topics in signal processing ,
vol. 9, no. 4, pp. 601â€“611, 2015.
[37] O. Nolan, T. S. Stevens, W. L. van Nierop, and R. J. van Sloun, â€œActive
diffusion subsampling,â€ arXiv preprint arXiv:2406.14388 , 2024.
[38] S. Leclerc, E. Smistad, J. Pedrosa, A. Ã˜stvik, F. Cervenansky, F. Es-
pinosa, T. Espeland, E. A. R. Berg, P.-M. Jodoin, T. Grenier, et al. ,
â€œDeep learning for segmentation using an open large-scale dataset in
2d echocardiography,â€ IEEE transactions on medical imaging , vol. 38,
no. 9, pp. 2198â€“2210, 2019.
[39] A. Beres, â€œDenoising diffusion implicit models,â€ 2022.
[40] K. Chaloner and I. Verdinelli, â€œBayesian experimental design: A review,â€
Statistical science, pp. 273â€“304, 1995.
[41] M. Naghshvar and T. Javidi, â€œActive sequential hypothesis testing,â€
2013.
[42] K. C. van de Camp, H. Joudeh, D. J. Antunes, and R. J. van Sloun,
â€œActive subsampling using deep generative models by maximizing
expected information gain,â€ in ICASSP 2023-2023 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP) ,
pp. 1â€“5, IEEE, 2023.
[43] K. Rawlik, M. Toussaint, and S. Vijayakumar, â€œOn stochastic optimal
control and reinforcement learning by approximate inference,â€ 2013.
[44] T. Hester, M. Vecerik, O. Pietquin, M. Lanctot, T. Schaul, B. Piot,
D. Horgan, J. Quan, A. Sendonaris, I. Osband, et al. , â€œDeep q-
learning from demonstrations,â€ in Proceedings of the AAAI conference
on artificial intelligence , vol. 32, 2018.
[45] J. Spainhour, K. Smart, S. Becker, and N. Bottenus, â€œOptimization
of array encoding for ultrasound imaging,â€ Physics in Medicine and
Biology, 2024.