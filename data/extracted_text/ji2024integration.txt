Citation: Ji, M.; Pan, K.; Zhang, X.;
Pan, Q.; Dai, X.; Lyu, Y. Integration of
Sense and Control for Uncertain
Systems Based on Delayed Feedback
Active Inference. Entropy 2024, 26, 990.
https://doi.org/10.3390/e26110990
Received: 9 October 2024
Revised: 1 November 2024
Accepted: 12 November 2024
Published: 18 November 2024
Copyright: Â© 2024 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed under the terms and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
Article
Integration of Sense and Control for Uncertain Systems Based on
Delayed Feedback Active Inference
Mingyue Ji 1, Kunpeng Pan 1, Xiaoxuan Zhang 1, Quan Pan 1, Xiangcheng Dai 2 and Yang Lyu1,*
1 School of Automation, Northwestern Polytechnical University, Xiâ€™an 710129, China;
jmy123@mail.nwpu.edu.cn (M.J.); pankunpeng@mail.nwpu.edu.cn (K.P .);
xiaoxuanzhang@mail.nwpu.edu.cn (X.Z.); quanpan@nwpu.edu.cn (Q.P .)
2 School of Automation, Nanjing University of Information Science and Technology, Nanjing 210044, China;
202283240029@nuist.edu.cn
* Correspondence: lyu.yang@nwpu.edu.cn
Abstract: Asa result of the time lag in transmission, the data obtained by the sensor is delayed and
does not reflect the state at the current moment. The effects of input delay are often overlooked in
active inference (AIF), which may lead to significant deviations in state estimation and increased
prediction errors, particularly when the system is subjected to a sudden external stimulus. In this
paper, a theoretical framework of delayed feedback active inference (DAIF) is proposed to enhance
the applicability of AIF to real systems. The probability model of DAIF is defined by incorporating a
control distribution into that of AIF. The free energy of DAIF is defined as the sum of the quadratic
state, sense, and control prediction error. A predicted state derived from previous states is defined
and introduced as the expectation of the prior distribution of the real-time state. A proportional-
integral (PI)-like control based on the predicted state is taken to be the expectation of DAIF preference
control, whose gain coefficient is inversely proportional to the measurement accuracy variance. To
adaptively compensate for external disturbances, a second-order inverse variance accuracy replaces
the fixed sensory accuracy of preference control. The simulation results of the trajectory tracking
control of a quadrotor unmanned aerial vehicle (UAV) show that DAIF performs better than AIF in
state estimation and disturbance resistance.
Keywords: active inference; input delay; predicted state; preference control
1. Introduction
The human brain can infer and predict hidden states of the world model by minimizing
the error between inner and posterior beliefs [1]. Active inference (AIF), proposed by Carl
Friston [2], is a comprehensive theory that integrates statistical mechanics and brain science
to endow agents with human-like abilities when interacting with the external world [ 3].
In contrast to prevalent artificial intelligence algorithms such as deep learning and rein-
forcement learning, AIF does not rely on large amounts of empirical data. Within the
framework of AIF, agents perform state inferences against hidden states of the external
world model and autonomously take preference actions by minimizing free energy [4].
AIF is a unified theory that integrates information theory and cybernetics [5]. From
an information-theoretic perspective, it functions as a Bayesian inference machine that
approximates model evidence using variational methods [6]. In practical industrial systems,
the presence of model uncertainty and measurement uncertainty cannot be overlooked. The
hidden states of uncertain systems can be highly complex, making it challenging to compute
all probability distributions of their measurements through Bayesian inference, such as the
2-D distributed pose estimation of multi-agent systems [7]. AIF introduces an approximate
distribution to estimate the marginal probabilities of the proposed measurements [ 8].
From a cybernetic perspective, AIF is a preference control that maximizes expectations [9].
Unlike traditional control algorithms, it does not require the pre-determination of model
Entropy 2024, 26, 990. https://doi.org/10.3390/e26110990 https://www.mdpi.com/journal/entropy
Entropy 2024, 26, 990 2 of 20
parameters for AIF preference control. In fact, due to the nonlinear, strong coupling,
high-dynamic, and uncertain characteristics of generally uncertain systems, the model
parameters can only be approximated as a probability distribution. In utilizing mean-field
approximation [10] and Laplace transforms [ 11], the probability distribution within the
Bayesian framework can be approximated as a Gaussian distribution function, transforming
the probability model into a linear generative model with noise. The parameters of the
generative model are contingent upon the mean of the probability distribution, while
estimation accuracy and control hinge on the variance [12].
The mathematical expression of AIF can be seen as a fusion of variational filtering
and preference control [13]. Variational filters aim to minimize the variational free energy
(VFE) [8], while preference control aims to minimize the expected free energy (EFE) [ 3].
Although the direct relationship between AIF and traditional control theory has not been
proven, it is noteworthy that the free energy, which can be expressed as a form of the
quadratic state prediction error and quadratic sense prediction error [14], bears a resem-
blance to the criterion of the linear quadratic form in linear quadratic regulator (LQR)
control [15]. Additionally, the structure of the AIF preference controller shares similarities
with a PI controller [16], where the gain coefficients are determined by the inverse variance
of the measurement distribution and its derivative. If the system experiences a significant
disturbance, it is advisable to employ an adaptive tuning mechanism for setting the gain
coefficients of the PI controller to improve its robustness [ 17,18]. Similarly, the inverse
variance precision of the preference control should also be adjusted using an adaptive
tuning mechanism rather than fixed constants [16].
As depicted in Figure 1, AIF, as a general artificial intelligence algorithm, has been
widely utilized for the perception, control, and planning of uncertain systems [19]. General
systems are inevitably exposed to various uncertain disturbances in complex environments;
for instance, a quadrotor UAV may encounter wind and electromagnetic disturbances
during operations [20â€“22]. AIF has demonstrated its superiority in agent perception and
control. For example, the dynamic expectation maximum (DEM), which outperforms
the classical Kalman filter [23] in handling color noise during filtering processes [ 24], is
employed for the state estimation of uncertain systems [25]. Furthermore, AIF preference
control [26] surpasses model reference adaptive control in adapting to internal and external
parameter perturbations in 7-DOF robotic arm experiments [27]. Agents may autonomously
execute preferred actions based on predicted future system states [28]. Maximum expected
path planning experiments with mobile robots [29] indicate that hierarchical models within
deep AIF exhibit promising potential in more complex environments with partially observ-
able and high-dimensional inputs [30]. Additionally, AIF continues to be optimized as the
theory advances, such as through unbiased AIF [31] and multisensory AIF [32].
As a new theory, AIF has some drawbacks. The estimated state is biased toward the
target state due to the influence of the target prior, resulting in a degradation of estimation
quality [33], such as false positive failures in fault diagnosis and fault tolerance control [16].
The absence of modeling in preference control within AIF may lead to saturation issues.
When the approximate model is derived from sensor data of an unknown and uncertain
system, input delay is often overlooked in general AIF. The delayed feedback from the
world model [34] to the generative model may result in the controller being unable to act
on the system promptly due to signal transmission and system reaction delays [35,36]. The
delay feedback threatens system security as even a small input delay may cause significant
oscillations [37]. Additionally, the state estimation of AIF may reflect the delayed state
rather than the current state. The measure-dependent preference control is currently not
applicable due to the delayed sensor data obtained in the generative model [38].
Inspired by the literature described above, a novel framework of delayed feedback
active inference (DAIF) is proposed for the uncertain system with an input delay. The main
contribution of this paper can be summarized as follows:
(1) Compared with AIF, the state estimation of DAIF is proved to not exhibit bias
toward the target state. The linear generative model of DAIF for a general uncertain
Entropy 2024, 26, 990 3 of 20
system with an input delay is proposed. The free energy of DAIF is defined as the sum of
the quadratic state, sense, and control prediction errors, and the optimized form of state
estimation and preference control is given.
(2) Due to this, the data obtained by the sensor are delayed as a result of transmission
delay; rather than obtaining real-time data, a predicted state of the current time is defined
and obtained by the delayed state and input. They are encoded in the prior state in the
generative model of DAIF. The introduction of the predicted state compensates for the
AIFâ€™s inability to match real-time data online.
(3) In contrast to AIF, the control distribution is considered in the probabilistic model
of DAIF. An epitaxial delayed feedback PI control based on the predicted state is defined
and introduced as the expectation of the DAIF preference control. The fixed gain coefficient
is replaced by the second-order inverse variance accuracy of the measurement distribution
to improve the anti-disturbance performance of the uncertain system.
Uncertain system with 
unknown dynamics   
ç ”ç©¶å†…å®¹-ä¸»ä½“ç ”ç©¶æ¡†æ¶
Generative model
Desired 
planning
PID-like 
control
Dynamic expec-
tation maximum
Delayed 
feedback
Sensor
data
Figure 1. Diagram of the framework of AIF for an uncertain system.
The main structure of this paper is given as follows: The theoretical framework for
AIF is provided in Section 2. The theoretical framework for DAIF is presented in Section 3.
Section 4 compares the performance of AIF and DAIF using the simulation of a quadrotor
UAV . Finally, the conclusion is summarized in Section 5.
2. Preliminaries
AIF is a posterior theory grounded in Bayesian inference (BIF) that utilizes mea-
surements to infer the hidden states of a system, aligning its internal belief with the
observed world through preference control. This section presents the theoretical framework
and concepts.
2.1. Probabilistic Model of AIF
The probability model of AIF is given by
p(xt | yt) = p(yt | xt)p(xt)
p(yt) ,
where xt and yt are the partially observable hidden states and corresponding measurements
at time step t. Depending on the research object, at as the preference control can be torque,
Entropy 2024, 26, 990 4 of 20
force, acceleration, or velocity. p(xt), p(xt | yt), p(yt), and p(yt | xt) are the prior, posterior,
and marginal probabilities and the likelihood distribution.
Remark 1. Model and measurement uncertainties are inherent in real systems, leading to the
presence of noisy sensory inputs known as partially observable hidden states.
An approximate posterior distribution q(zt) is introduced to infer the posterior distri-
bution p(xt | yt) of the hidden states by minimizing the KL divergence as follows:
DKL (q(z)tâˆ¥p(xt | yt)) =
Z
q(zt) ln q(zt)
p(xt | yt)dxt.
Remark 2. Calculating the posterior distribution directly is infeasible due to the intricate nature
of the marginal probabilities of all hidden states. Therefore, a variational method is proposed for
obtaining an approximate posterior distribution. The probability distributions in AIF are commonly
assumed to follow Gaussian distributions. The variance reflects the confidence level in the internal
belief, with a smaller variance indicating a stronger focus on the expected value.
2.2. Variational Free Energy
Variational free energy (VFE) can also be referred to as free energy and is defined
by the KL divergence between the approximate distribution q(zt) and joint distribution
p(xt, yt) [39]. As depicted in Figure 2, FAIF can be represented by the KL divergence
between q(zt) values, and p(xt | yt) subtracts the model evidence ln(p(yt, at)) :
Surprise
State inference by Active control by
()( )ln d ( , )
()( )ln d ln( ( , ))()
( ( ) ( )) ln( ( , )) ln( ( , ))
t
AIF t t
tt
t
t t t t
tt
KL t t t t t t t
qFq p
qqp p
D q p p p
=âˆ’
=âˆ’
= âˆ’ ï‚³âˆ’
ïƒ²
ïƒ²
zzx xy
zz x y axy
z x y y a y a
âˆ£
â€– âˆ£
min
t
AIFF
z
min
t
AIFF
a
.
Figure 2. Free energy as the optimization objective for both estimation and control.
VFE is an upper bound on the model evidence. Minimizing free energy equates to
maximizing model evidence, also referred to as minimization â€˜surpriseâ€™ [10].
Remark 3. Minimizing free energy serves as a performance metric, akin to the loss function in
deep learning. This process forms a closed loop where state inference induces active control, and
active control, in turn, modulates state inference.
The generative model of AIF, as depicted in Figure 3, is constructed based on the sensor
data from the external system. The external system, characterized by model uncertainty wt
and measurement uncertainty vt, is described as follows:
ï£±
ï£²
ï£³
Ë™ xt = f(xt, Ut) + wt,
yt = g(xt) + vt,
(1)
where f(xt, Ut) is a linear or nonlinear function dependent on the state xt and control input
Ut, while g(xt) is also a function of the state. wt and vt are generally assumed to follow
Gaussian noise with zero mean as N
 
0, Î£Âµt

and N(0, Î£ot ). Î£Âµt and Î£ot are the covariance
matrices that represent the confidence of inference and control.
Entropy 2024, 26, 990 5 of 20
Preference control
Generative model External system
Free energy
Sensor data
( )
( )
,t tt t
t tt
ï£±= +ï£´ï£² = +ï£´ï£³
x fxU w
y gx v
ï€¦
{ },
1 constant2 tt
AIF i i i
i
F
âˆˆ
= +âˆ‘
Î¼ o
Îµ Î©Îµï‚•
,,,
t tt tÎ¼ Î¼ ooÎµÎ© Î©Îµ
t
tAIF
t
tt
FÎº âˆ‚âˆ‚=âˆ’ âˆ‚âˆ‚
a
oa oa
ï€¦
Internal belief
Ë† Ë†(,,)
Ë†()
t ttt t
t tt
ï£± = +ï£´ï£² = +ï£´ï£³
Î¼ f Î¼ xa w
og Î¼ v
ï€¦
Figure 3. Normal AIF for state estimation and preference control of uncertain system.
As a theory rooted in brain neuroscience, AIF primarily focuses on serving as a gener-
ative model. The prior of the hidden state p(xt) is represented by a Gaussian distribution
with an expectation of Âµt. Similarly, the likelihood distribution p(yt|xt ) is also encoded
using a Gaussian distribution with an expectation ofot. The generative model for system (1)
is expressed by ï£±
ï£²
ï£³
Ë™Âµt = Ë†f(Âµt, Ë† xt, at) +wt,
ot = Ë† g(Âµt) +vt,
(2)
where the generative function Ë†f(Âµt, Ë† xt, at) is dependent on the state estimation Âµt, target
state Ë† xt, and preference control at, while Ë† g(Âµt) represents the mapping function between
the state Âµt and sensory input ot.
In utilizing the mean-field approximation and Laplace transform [40], the free energy
in AIF is characterized as a quadratic linear type of prediction error as follows:
FAIF = 1
2 âˆ‘
iâˆˆ{Âµt,ot}
ÎµâŠ¤
i â„¦iÎµi + constant , (3)
where ÎµÂµt = Ë™Âµt âˆ’ (Ë† xt âˆ’ Âµt) and Îµot = ot âˆ’ Âµt are the state and sense prediction errors.
â„¦i
iâˆˆ{Âµt,ot}
= Î£âˆ’1
i
iâˆˆ{Âµt,ot}
is the inverse variance. ÎµiT denotes the transpose of the matrix of Îµi.
The belief updating and preference control can be described by the optimized format
about the gradient descent of free energy as follows [13]:
ï£±
ï£²
ï£³
Ë™Âµt = DÂµt âˆ’ ÎºÂµt
âˆ‚FAIF
âˆ‚Âµt
= DÂµt âˆ’ ÎºÂµt ÎµT
Âµt
â„¦Âµt ,
Ë™ at = âˆ’Îºat
âˆ‚FAIF
âˆ‚ot
âˆ‚ot
âˆ‚at
= âˆ’Îºat ÎµT
ot â„¦ot
âˆ‚ot
âˆ‚at
,
(4)
where ÎºÂµt and Îºat are the gradient descent step sizes. D is the differential (shift) operator
matrix. âˆ‚ot
âˆ‚at
is a mapping that relates the preference control to the sensory input [27].
Agents consistently limit their sensory perception of uncertainty in the external en-
vironment to a narrow range of possibilities to counteract the inherent tendency toward
disorder [38]. They may update their perception by minimizing free energy and actively
provide feedback to the generative model through preference-based behavior driven by
prediction error. In AIF, agents continually adjust their expected internal beliefs through
ongoing senseâ€“inferenceâ€“control, aligning more closely with organismic instincts.
Remark 4. The internal belief in the generative model is also the expected state of the approximate
distribution. Minimizing free energy allows for obtaining internal beliefs with the highest confidence.
The preference control feedback to the generative model serves as an inverse model that determines
Entropy 2024, 26, 990 6 of 20
the necessary adjustments in actions at to elicit a corresponding change in sensory observations ot.
In this manner, actions are generated based on prediction errors, providing a straightforward form of
feedback control.
3. The Framework of DAIF
This section presents the framework of delayed feedback active inference (DAIF) for
uncertain systems with input delay. In contrast to the normal AIF framework for general
systems, DAIF only allows obtaining the prior of the delayed state, not the current state due
to input delay. Consequently, a predicted state derived from the delayed state is proposed
as the expected value of the state. Additionally, a PI-like delayed feedback control based on
the predicted state is introduced as the expected value of preference action in the generative
model. The overall framework of DAIF is illustrated in Figure 4.
Predictive 
state à´¤ğ±ğ‘¡
Preference control
Generative model External system
Free energy
Sensor data
Delayed 
feedback 
control à´¥ğ”ğ‘¡âˆ’ğœ
,tt ï´ï´âˆ’âˆ’xU
t ï´âˆ’U
Target state à·œğ±ğ‘¡
Internal belief
t t t t
t t t
ï´âˆ’= + +ïƒ¬
ïƒ­ =+ïƒ®
x Ax BU w
y Cx v
t t t t
t t t
ïƒ¬ = + +ïƒ¯ïƒ­ =+ïƒ¯ïƒ®
Î¼ AÎ¼ Ba w
oC Î¼ v
ï» ï½,,
1 ln ( )ln 22 tt
DAIF i i
i
F MSPE p q r ï°
ïƒ
ïƒ¦ïƒ¶
= âˆ’ + + +ïƒ§ïƒ·ïƒ§ïƒ·ïƒ¨ïƒ¸
ïƒ¥
tÎ¼ oa
Î©
t
DAIF
t
t
Fï« ï‚¶=âˆ’ ï‚¶
Î¼Î¼ Î¼
t
DAIF
t
t
Fï« ï‚¶=âˆ’ ï‚¶
aa a
    ,
   , ,
,,
ttt
tt
ttt
ï´âˆ’
Î¼ oa
xU
Î¼ oa
Î© Î© Î©
Figure 4. DAIF for state estimation and preference control of uncertain system.
3.1. Probabilistic Model of DAIF
For an uncertain system with hidden state xt, measurement yt, and delayed control
input Utâˆ’Ï„, the probabilistic model is denoted as pt(xt, yt, Utâˆ’Ï„). In contrast to AIF, DAIF
considers the control distribution p(Utâˆ’Ï„ | xt). The probability distribution of the model is
factorized accordingly as follows:
pt(xt, yt, Utâˆ’Ï„) = p(Utâˆ’Ï„ | xt)p(yt | xt)p(xt). (5)
DAIF aims to infer the posterior distribution over the state and control,p(xt, Utâˆ’Ï„ | yt),
from the available sensory data. A joint approximate distribution q(xt, Utâˆ’Ï„) is introduced
for variational inference. The free energy of DAIF can be defined as complexity minus
accuracy, as follows:
FDAIF = R
q(xt, Utâˆ’Ï„) ln q(xt,Utâˆ’Ï„ )
p(xt,yt,Utâˆ’Ï„ ) dxt
= R
q(xt, Utâˆ’Ï„) ln q(xt,Utâˆ’Ï„ )
p(xt,Utâˆ’Ï„ |yt) dxt âˆ’ ln(p(yt))
= DKL (q(xt, Utâˆ’Ï„)âˆ¥p(xt, Utâˆ’Ï„ | yt)) âˆ’ ln(p(yt)).
where complexity is the KL divergence between q(xt, Utâˆ’Ï„) and p(xt, Utâˆ’Ï„|yt), while
accuracy measures sensory surprisal.
Remark 5. Input delay is the consequence of signal transmission or delayed response, which is an
unavoidable phenomenon. Even a minor delay, if overlooked, can have significant implications for
the system and pose a security threat. Therefore, DAIF is more suitable for real uncertain systems
than AIF.
Entropy 2024, 26, 990 7 of 20
3.2. Predicted State
The dynamic model of the uncertain system with an input delay Ï„ can be represented
by a nominal system along with model uncertainty wt and measurement uncertainty vt,
as follows: ï£±
ï£²
ï£³
Ë™ xt = Axt + BUtâˆ’Ï„ + wt,
yt = Cxt + vt,
(6)
where xt and yt are the state and measurement at time t with the delayed input Utâˆ’Ï„.
(A, C) is observable, and (A, B) is controllable.
The internal dynamics of the generative model for system (6) is represented in a similar
form as follows: ï£±
ï£²
ï£³
Ë™Âµt = ËœAÂµt + ËœBat + wt,
ot = ËœCÂµt + vt,
(7)
where the parameters
  ËœA, ËœB, ËœC

are solely dependent on the nominal system and do not
account for model and measurement uncertainty, whereÂµt, ot, and at represent the expec-
tation of state xt, measurement yt, and delayed control input Utâˆ’Ï„, respectively. Both of
the model parameters of (6) and (7) only pertain to the nominal system, thus satisfying
ËœA = A, ËœB = B, and ËœC = C.
Remark 6. The model parameters of (A, B, C) that are dependent on the system itself are typically
obtained through the process of identifying system parameters. The external or internal uncertainties
result in the unknown dynamics of the system (6).
Definition 1. With the use of the method of constant variation to solve Equation (6), a predicted
state Â¯ xt at time t is defined by
Â¯ xt = eAÏ„xtâˆ’Ï„ +
Z t
tâˆ’Ï„
eA(tâˆ’s)[BU(s âˆ’ Ï„) +w(s)]ds. (8)
The complex integral Î“t = R t
tâˆ’Ï„ eA(tâˆ’s)BU(s âˆ’ Ï„)ds can be discretized according to [41]:
Step 1:
Let T denote the sampling period and Ï„ = NT âˆ’ Î·, where N is a positive integer and
0 < Î· < T. When the sampling period is sufficiently small, the control input during each sampling
period satisfies
Ut = UkT , kT â‰¤ t < (k + 1)T.
Î“t can be transformed into
Î“t = R t
tâˆ’Ï„ eA(tâˆ’s)BU(s âˆ’ Ï„)ds
= R 0
âˆ’Ï„ eâˆ’AsBU(s + t âˆ’ Ï„)ds
= eA(NTâˆ’Î·) R Tâˆ’Î·
0 eâˆ’AsdsBUtâˆ’2NT+Î· + eA(Nâˆ’1)T R T
0 eâˆ’AsdsBUtâˆ’(2Nâˆ’1)T+Î·
+... + eAT R T
0 eâˆ’AsdsBUtâˆ’(N+1)T+Î·.
Step 2:
Suppose that Ï†(Î¶) =R Î¶
0 eâˆ’AsdsB, Î“t can be rewritten as
Î“t = eA(NTâˆ’Î·)Ï†Tâˆ’Î·Utâˆ’2NT+Î· + eA(NTâˆ’1)Ï†TUtâˆ’2NT+T+Î· + . . .+ eA(T)Ï†TUtâˆ’NTâˆ’T.
Step 3:
Let Î· = 0 and Î“t be simplified as
Î“t = eA(NT)Ï†TUtâˆ’2NT + eA(NTâˆ’1)Ï†TUtâˆ’2NT+T + . . .+ eA(T)Ï†TUtâˆ’NTâˆ’T.
Entropy 2024, 26, 990 8 of 20
Then, the predicted state can be obtained through discrete summation involving the delayed state
and control input.
3.3. Preference Control
The target state Ë† xt is encoded in the distribution p(Utâˆ’Ï„ | xt), which serves as the prior
for the DAIF preference control. Since the AIF preference control follows a PI-like control
form, the proposed DAIF preference control is expected to follow a similar form. Before
designing the control strategy based on this expectation, it is necessary to transform the
delay system (6) into a delay-free one through an integral transformation as follows:
Ïˆt = xt +
Z t
tâˆ’Ï„
eâˆ’A(sâˆ’t+Ï„)[BU(s) +Ï‰(s)]ds. (9)
and the new state Ïˆt and original state xt satisfy Ïˆt = eAÏ„xt+Ï„ [35]. The state equation of
the delay-free system is given by
Ë™Ïˆt = AÏˆt + eâˆ’AÏ„BUt + eâˆ’AÏ„Ï‰t. (10)
For system (10), the target state is Ë†Ïˆt = eAÏ„ Ë† xt+Ï„, and the tracking error is Î·t = Ïˆt âˆ’ Ë†Ïˆt.
In replacing the current time t with the delayed time t âˆ’ Ï„, the delay feedback control of
system (6) is given by
Ë™Utâˆ’Ï„ = âˆ’Îºat â„¦ot Î·tâˆ’Ï„ âˆ’ ÎºË™ at â„¦Ë™ ot Ë™Î·tâˆ’Ï„
= âˆ’Îºat â„¦ot
 
eAÏ„xt âˆ’ Ë†Ïˆtâˆ’Ï„

âˆ’ ÎºË™ at â„¦Ë™ ot

eAÏ„ Ë™ xt âˆ’ Ë™Ë†Ïˆtâˆ’Ï„

. (11)
The gain coefficients â„¦ot and â„¦Ë™ ot represent the inverse variance of the measurementâ€™s
probability density, also referred to as sensory accuracy, which quantifies the deviation
between sensory and expectation. They play a crucial role in determining the performance
of preference control (11). The proportional term drives the state toward the target state,
while the derivative term reduces fluctuations by adjusting the rate of change of the state.
To optimize sense prediction performance, we replace fixed sensory precision with
adaptive turning sensory precision. It is promising to substitute sensory accuracy with the
logarithmic precision of the inverse variance as follows:
bâ„¦i
iâˆˆ{ot,Ë™ ot}
= ln â„¦i
iâˆˆ{ot,Ë™ ot}
.
We utilize a second-order online adaptive turning scheme based on generalized filter-
ing as described in [16], which is provided by
ï£±
ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£³
Ë™Ë†â„¦ot = Ë†â„¦â€²
ot ,
Ë™Ë†â„¦ot
â€²
= âˆ’âˆ‚FDAIF
âˆ‚ Ë†â„¦ot
âˆ’ Îº Ë†â„¦ot
Ë†â„¦â€²
ot
= âˆ’1
2

exp
  Ë†â„¦ot

Îµot
2 âˆ’ 1

âˆ’ Îº Ë†â„¦ot
Ë†â„¦â€²
ot .
(12)
Due to the input delay, only the delay state xtâˆ’Ï„ in Equation (11) can be perceived at
time t, but not xt. Thus, it is proposed to replacext with the predicted state Â¯ xt in Definition 1,
and Â¯Utâˆ’Ï„ as the expectation of the DAIF preference control is given by
Ë™Â¯Utâˆ’Ï„ = âˆ’Îºat
Ë†â„¦ot
 
eAÏ„ Â¯ xt âˆ’ Ë†Ïˆtâˆ’Ï„

âˆ’ ÎºË™ at
Ë†â„¦Ë™ ot

eAÏ„ Ë™Â¯ xt âˆ’ Ë™Ë†Ïˆtâˆ’Ï„

. (13)
All the probability distributions in Equation (5) are assumed to be the multivariate
Gaussian distribution as follows:
p(xt) =
s â„¦Âµt

(2Ï€)p exp

âˆ’1
2 ÎµT
Âµt
â„¦Âµt ÎµÂµt

,
Entropy 2024, 26, 990 9 of 20
p(yt | xt) =
s
|â„¦ot |
(2Ï€)q exp

âˆ’1
2 ÎµT
ot â„¦ot Îµot

,
p(Utâˆ’Ï„ | xt) =
s
|â„¦at |
(2Ï€)r exp

âˆ’1
2 ÎµT
at â„¦at Îµat

,
where ÎµÂµt = Âµt âˆ’ Â¯ xt, Îµot = ot âˆ’ ËœCÂµt, and Îµat = at âˆ’ Â¯Utâˆ’Ï„ are the state prediction error,
sense prediction error, and control prediction error. The free energy function of DAIF is
given by
FDAIF = 1
2 âˆ‘
iâˆˆ{Âµt,ot,at}
 
ÎµâŠ¤
i â„¦iÎµi âˆ’ ln|â„¦i|

+ 1
2 (p + q + r) ln 2Ï€. (14)
where p, q, and r are, respectively, the dimensions of vectorsÂµt, ot, and at.
The state estimation and preference control of DAIF can be achieved using gradient
descent on FDAIF like AIF as follows:
ï£±
ï£²
ï£³
Ë™Âµt = âˆ’ÎºÂµt
âˆ‚FDAIF
âˆ‚Âµt
= âˆ’ÎºÂµt â„¦Âµt (Âµt âˆ’ Â¯ xt),
Ë™ at = âˆ’Îºat
âˆ‚FDAIF
âˆ‚at
= âˆ’ Îºat â„¦at (at âˆ’ Â¯Utâˆ’Ï„).
(15)
Remark 7. The free energy of DAIF encodes the expected state, measurement, and control input,
unlike AIF. Therefore, minimizing the free energy can be interpreted as reducing the prediction error
of the state and sense using minimal energy, which is formally similar to the linear quadratic optimal
criterion of LQR control. The added control prediction error in Equation (14) biases the preference
for control toward expectation when minimizing free energy.
3.4. Convergence Analysis of AIF and DAIF
As depicted in Figure 5, we provide a visual explanation of the generative probabilistic
model using factor graphs. In AIF, the target state Ë† xt is encoded in the prior p(xt), whereas
it is encoded in the conditional probability p(Utâˆ’Ï„|xt ) in DAIF. The preference control is
not explicitly modeled as a random variable in the generative model of the AIF [2], and it is
directly related to the sensory inputs [38]. In contrast to AIF, DAIFâ€™s probabilistic model
takes into account the control distribution p(Utâˆ’Ï„ | xt).
Theorem 1. The stable value of the estimated state in AIF is contingent upon the target signal. In
contrast, the convergence value in DAIF is not biased toward the target signal but rather depends
on the predicted state.
Proof of Theorem 1. The steady-state expectation Âµâˆ— in AIF and DAIF can be obtained by
solving the derivative of free energy function (3) and (14) with respect to the estimated
state as follows:
âˆ‚FAIF
âˆ‚Âµt
= 0 â‡’ Âµâˆ—
AIF = â„¦Âµt ot + â„¦ot (Ë† xt âˆ’ Âµt)
â„¦Âµt + â„¦ot
, (16)
âˆ‚FDAIF
âˆ‚Âµt
= 0 â‡’ Âµâˆ—
DAIF = â„¦Âµt ot + â„¦ot Â¯ xt
â„¦Âµt + â„¦ot
. (17)
The convergence value of the AIFâ€™s steady-state expectation is influenced by the target
state Ë† xt, as indicated by Formulas (16) and (17). Consequently, when the system experiences
a sudden disturbance or sensor failure, it may not provide timely feedback to the generative
model due to inevitable input delay. This could result in a significant deviation from the
desired optimal state at the present moment. However, the convergence value of the AIFâ€™s
steady-state expectation is associated with the predicted state Â¯ xt and remains unbiased
toward the target signal, thereby compensating for the limitation of AIF.
Entropy 2024, 26, 990 10 of 20
() ttp yx() tp x tytx
AIF for delay-free system
() ttp Ï„âˆ’Ux
t Ï„âˆ’U
() ttp yx
DAIF for system with input delay 
Encodes
ï¿½ğ±ğ±ğ‘¡ğ‘¡
Figure 5. Factor graphs of DAIF (above) and AIF (below).
4. Results
4.1. Trajectory Tracking Control of a Quadrotor UAV
We employed a simulation example of a quadrotor UAV to contrast the performance
of AIF and DAIF in state estimation and preference control for an uncertain system with
input delay. The UAV systemâ€™s parameters and corresponding values in this paper are
detailed in Table 1. The dynamic model of the quadrotor UAV can be obtained as in [42]:
ï£±
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³
Â¨x = âˆ’K1
m Ë™x + U1
m (cos Ïˆ sin Î¸ cos Ï• + sin Ïˆ sin Ï•),
Â¨y = âˆ’K2
m Ë™y + U1
m (sin Ïˆ sin Î¸ cos Ï• âˆ’ cos Ïˆ sin Ï•),
Â¨z = âˆ’K3
m Ë™z + U1
m cos Î¸ cos Ï• âˆ’ g,..
Ï• = âˆ’K4l
Iz
Ë™Ï• + l
Ix U2 + Ë™Î¸ Ë™Ïˆ Iyâˆ’Iz
Ix + Jr
Ix
Ë™Î¸Î¾r,
Â¨Î¸ = âˆ’K5l
Iz
Ë™Î¸ + l
Iy U3 +
.
Ï• Ë™Ïˆ Izâˆ’Ix
Iy âˆ’ Jr
Iy
.
Ï• Î¾r,
Â¨Ïˆ = âˆ’K6l
Iz
Ë™Ïˆ + U4
Iz +
.
Ï• Ë™Î¸ Ixâˆ’Iy
Iz .
(18)
The three Euler angles Ï•, Î¸, and Ïˆ represent the roll, the pitch, and the yaw. They
satisfy Ï• âˆˆ (âˆ’Ï€/2, Ï€/2), Î¸ âˆˆ (âˆ’Ï€/2, Ï€/2), and Ïˆ âˆˆ (âˆ’Ï€, Ï€).
Figure 6 illustrates the trajectory tracking control diagram of the quadrotor utilizing
DAIF. During task execution, the UAV is inevitably subjected to external disturbances such
as wind or electromagnetic interference, resulting in model and measurement uncertainty.
Abrupt disturbances can lead to pulse-like control inputs or even system failure. Mini-
mizing energy consumption during sudden disturbances poses a significant challenge for
the system. In the classical AIF framework, feedback delays may impact estimation and
control performance due to the neglect of input delay. Through experiments on the linear
and circular target tracking of UAVs, we conducted a comprehensive comparison between
AIF and DAIF, while also analyzing the effects of inverse variance accuracy and input delay
within the DAIF framework.
Predictive 
state
Belief updating Preference 
action
Generative modelInternal belief Uncertain system with 
an input delay
Sensor data
Precision 
learning Delayed 
feedback 
control
External disturbances
wind electromagnetic   
Free energy
Figure 6. Diagram of trajectory tracking control of the quadrotor UAV based on DAIF.
Entropy 2024, 26, 990 11 of 20
Table 1. The descriptions and values of the UAV systemâ€™s parameters.
Symbol Description Value
m the total mass 2 kg
g the acceleration of gravity 9.8 m/s2
l the centrifugal pitch of the
UAV 0.2 m
Ki the drag coefficients 0.01 N/m
Ix, Iy, Iz
the inertias of the quadrotor
UAV 1.5 Nm2/rad
Jr the inertia of the propeller 1 Ns2/rad
Î¾r
the angular speed of the
propeller -
[x, y, z]T the position of the quadrotor
UAV -
[Ï•, Î¸, Ïˆ]T the three Euler angles -
U1 the total thrust -
U2 the roll input -
U3 the pitch input -
U4 the yawing input -
4.1.1. Linear Target Trajectory Tracking
It is assumed that the linear target trajectory in the X-O-Z plane is represented by the
equation x âˆ’ z + 1 = 0, and the quadrotor UAV begins from the initial position(âˆ’1, âˆ’1).
The linear motion of the quadrotor UAV is primarily dependent onU1 and U3. Assuming
that the roll angle Ï• and yaw angle Ïˆ of system (18) are 0 radians, we obtain a linear motion
system of UAV as follows
ï£±
ï£´ï£²
ï£´ï£³
Â¨x = âˆ’K1
m Ë™x + U1
m sin Î¸,
Â¨z = âˆ’K3
m Ë™z + U1
m cos Î¸ âˆ’ g,
Â¨Î¸ = âˆ’K5l
Iz
Ë™Î¸ + l
Iy U3,
(19)
Let Î»t =

x Ë™x z Ë™z Î¸ Ë™Î¸
T be the state and Ït be the measurement vector.
System (19) can be rewritten in matrix form with input delay Ï„, model uncertainty wt, and
measurement uncertainty vt as follows
ï£±
ï£²
ï£³
Ë™Î»t = A1Î»t + B1Utâˆ’Ï„ + wt,
Ït = C1Î»t + vt,
(20)
where A1 =
ï£®
ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°
0 1 0 0 0 0
0 âˆ’K1
m 0 0 0 0
0 0 0 1 0 0
0 0 0 âˆ’K3
m 0 0
0 0 0 0 0 1
0 0 0 0 0 âˆ’K5l
Iz
ï£¹
ï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£»
, B1 =
"
0 sin Î¸
m 0 cos Î¸
m 0 0
0 0 0 0 0 l
Iy
#T
,
Utâˆ’Ï„ =
 U1(t âˆ’ Ï„)
U3(t âˆ’ Ï„)

, and C1 = I6Ã—6. I6Ã—6 is a sixth-order identity matrix.
The generative model of system (20) is supposed to be
ï£±
ï£²
ï£³
Ë™Âµt = A1Âµt + B1at + wt,
ot = C1Âµt + vt,
(21)
where Âµt =

Âµ1 Ë™Âµ1 Âµ2 Ë™Âµ2 Âµ3 Ë™Âµ3
T and ot =

o1 Ë™o1 o2 Ë™o2 o3 Ë™o3
T are the
expectations of the state and measurement. at =

a1 a2
T is the preference control. The
Entropy 2024, 26, 990 12 of 20
inverse variance precision, prediction error, and free energy are denoted byâ„¦i = â„¦i Â· I6Ã—6,
Îµi, and F1, where i âˆˆ {Âµt, ot, at}.
The trajectory tracking target vector of system (20) is set to be ËœÎ»t =
Ëœx, Ëœz, ËœÎ¸
T =hâˆš
2
2 t,
âˆš
2
2 t + 1, Ï€
4
iT
. The learning parameters satisfy ÎºÂµ = 100, Îºa = 200 and Îº bâ„¦ot
= 8.
All the probability distributions are assumed to be the standard Gaussian distribution. The
inverse variance precision isâ„¦i = e0. The total simulation time is 25 s, and the step size is
set to 0.001 s. It is assumed that the total thrustU1 is subject to a stochastic excitation that
is described by Î´t âˆˆ [40, 80] during the time interval of 10 s to 15 s, which may be sudden
disturbances from wind or electromagnetic sources. The simulation results are shown in
Figures 7â€“12.
0 5 10 15 20 25T i m e [ s ] 
-5
0
5
10
15
20
25
30E s t i m a t i o n o f x [ m ] 
7 1 - A I F 7 1 - D A I F x 
10 12 142
4
6
8
10
Figure 7. State estimation of x in system (19) .
0 5 10 15 20 25T i m e [ s ] 
-5
0
5
10
15
20
25
30E s t i m a t i o n o f z [ m ] 
7 2 - A I F 7 2 - D A I F z 
10 12 14
4
6
8
10
12
Figure 8. State estimation of z in system (19).
0 5 10 15 20 25T i m e [ s ] 
0.78
0.785
0.79E s t i m a t i o n o f 3 [ r a d ] 
7 3 - A I F 7 3 - D A I F 3 
Figure 9. State estimation of Î¸ in system (19).
Entropy 2024, 26, 990 13 of 20
0 5 10 15 20 25T i m e [ s ] 
0
50
100
150
200P r e f e r e n c e c o n t r o l a 1 [ N ] a 1 - A I F a 1 - D A I F 
Figure 10. Preference control of the generative model (21).
0 5 10 15 20 25T i m e [ s ] 
0
2
4
6
8
10
12
14F r e e e n e r g y F 1 [ J ] 
F 1 - A I F F 1 - D A I F 
Figure 11. Free energy of the generative model (21).
-2 0 2 4 6 8 10 12 14 16 18x [ m ] 
-5
0
5
10
15
20
25z [ m ] 
A I F t r a j e c t o r y D A I F t r a j e c t o r y T a r g e t t r a j e c t o r y 
Figure 12. Linear motion trajectory of UAV in X-O-Z plane.
4.1.2. Circular Target Trajectory Tracking
We assumed that the UAV follows a circular path with a radius of 10 m in the X-Y
plane, centered at (0, 0), and represented by the function x2 + y2 = 100. The initial position
is (12, 0). The yaw angle of the UAV increases uniformly at a rate of 0.28 rad/s. It is
assumed that the roll angle Ï• of system (18) is 0 radians, and the curved motion system is
obtained by ï£±
ï£´ï£²
ï£´ï£³
Â¨x = âˆ’K1
m Ë™x + U1
m sin Î¸ cos Ïˆ,
Â¨y = âˆ’K2
m Ë™y + U1
m sin Î¸ sin Ïˆ,
Â¨Ïˆ = âˆ’K6l
Iz
Ë™Ïˆ + U4
Iz .
(22)
Entropy 2024, 26, 990 14 of 20
Let Î»â€² t =

x Ë™x y Ë™y Ïˆ Ë™Ïˆ
T and Ïâ€²
t be the state and measurement vector.
Equation (22) can be rewritten as the matrix form with input delay Ï„, model uncertainty
wâ€²
t, and measurement uncertainty vâ€²
t as follows
ï£±
ï£²
ï£³
Ë™Î»â€² t = A2Î»â€² t + B2Uâ€²tâˆ’Ï„ + wâ€²t,
Ïâ€²
t = C2Î»â€² t + vâ€²t,
(23)
where A2 =
ï£®
ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£¯ï£°
0 1 0 0 0 0
0 âˆ’K1
m 0 0 0 0
0 0 0 1 0 0
0 0 0 âˆ’K2
m 0 0
0 0 0 0 0 1
0 0 0 0 0 âˆ’K6l
Iz
ï£¹
ï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£ºï£»
, B2 =
"
0 sin Î¸ cos Ïˆ
m 0 cos Î¸ sin Ïˆ
m 0 0
0 0 0 0 0 1
Iz
#T
,
Uâ€²tâˆ’Ï„ =
"
U1(t âˆ’ Ï„)
U4(t âˆ’ Ï„)
#
, and C2 = I6 .
The generative model of system (23) is supposed to be
ï£±
ï£²
ï£³
Ë™Âµâ€²
t = A2Âµâ€²
t + B2aâ€²t + wâ€²t,
oâ€²t = C2Âµâ€²
t + vâ€²t,
(24)
where Âµâ€²
t =

Âµ4 Ë™Âµ4 Âµ5 Ë™Âµ5 Âµ6 Ë™Âµ6
T and oâ€²t =

o4 Ë™o4 o5 Ë™o5 o6 Ë™o6
T are
the expectation of the state and measurement. The preference control is aâ€²t =

a3 a4
T.
The inverse variance precision, prediction error, and free energy are denoted by
â„¦i = â„¦i Â· I6Ã—6, Îµi, and F2, where i âˆˆ {Âµâ€²
t, oâ€²t, aâ€²t}.
The trajectory tracking target vector of system (23) is set to be ËœÎ»â€² t = [ Ëœx, Ëœy, ËœÏˆ]T =
[10 cos(0.28t), 10 sin(0.28t), 0.28t]T. It is also assumed that the total thrust U1 is subject to a
stochastic excitation that is represented by Î´t âˆˆ [40, 80] during the time interval of 10 s to
15 s. The other parameters are set to be the same as the linear motion of the quadrotor UAV
in the X-O-Z plane. The simulation results are shown in Figures 13â€“18.
4.1.3. Discussion
The state estimations for systems (19) and system (22) in the generative model of
AIF and DAIF when Ï„ = 0.1 s are depicted in Figures 7â€“9 and 13â€“15. Despite the pitch
input U3 and yawing input U4 not being intended to experience sudden disturbances, the
estimation for Î¸ and Ïˆ in AIF lags and deviates from the real states compared to DAIF. The
estimations for the position coordinates of the quadrotor UAV fluctuate when subjected to
a sudden disturbance at 10 s. It is evident that the state estimations in AIF exhibit more
fluctuations and take longer to recover than those in DAIF. It is important to note that the
generative model is derived from data in the delayed state from the sensor, and measure-
dependent preference control essentially involves delayed feedback in AIF, resulting in
long lag errors that hinder adaptation to large attacks or disturbances. As shown in
Figures 13 and 14, the effects of lag error appear greater in estimating nonlinear targets.
Utilizing real-time predicted state and delay-feedback PI control as expectations for state
estimation and preference control leads to better anti-disturbance performance in DAIF.
Time history diagrams for preference controlsa1 and a3 are depicted in Figures 10 and 16.
When sudden perturbations occur, both a1 and a3 undergo mutations. These preference-
controlled mutations can be seen as the agentâ€™s spontaneous response to disturbances.
In neglecting the impact of input delay, AIF requires more energy consumption due to
accumulated lag error, resulting in greater mutation of preference control compared to
DAIF. As depicted in Figures 11 and 17, DAIF effectively mitigates this disparity, resulting
in consistently minimal and stable free energy even in the presence of sudden perturbations.
Entropy 2024, 26, 990 15 of 20
The trajectories of the quadrotor UAV in linear and circular motion are depicted in
Figure 12 and Figure 18, respectively. Utilizing second-order adaptive sensory accuracy as
the coefficient of preference control allows the UAV to exhibit anti-disturbance performance
in AIF and DAIF. Due to delayed measurement data not aligning with the real-time state,
AIF is unable to immediately compensate for sudden perturbations, resulting in a relax-
ation process for the quadrotor UAV . In comparison, the quadcopter UAV demonstrates
superior anti-disturbance performance in DAIF as the predicted state closely mirrors the
real-time state.
0 5 10 15 20 25T i m e [ s ] 
-15
-10
-5
0
5
10
15
20E s t i m a t i o n o f x [ m ] 
7 4 - A I F 7 4 - D A I F x 
10 12 14
-15
-10
-5
0
Figure 13. State estimation of x in system (22).
0 5 10 15 20 25T i m e [ s ] 
-15
-10
-5
0
5
10
15E s t i m a t i o n o f y [ m ] 
7 5 - A I F 7 5 - D A I F y 
Figure 14. State estimation of y in system (22).
0 5 10 15 20 25T i m e [ s ] 
0
2
4
6
8E s t i m a t i o n o f A [ r a d ] 
7 6 - A I F 7 6 - D A I F A 
Figure 15. State estimation of Ïˆ in system (22).
Entropy 2024, 26, 990 16 of 20
0 5 10 15 20 25T i m e [ s ] 
0
50
100
150
200
250P r e f e r e n c e c o n t r o l a 3 [ N ] a 3 - A I F a 3 - D A I F 
Figure 16. Preference control of the generative model (24).
0
20
40
60
80
-10
F r e e e n e r g y F 2 [ J ] 100
120
10
x [ m ] 
0 5
y [ m ] 
0-510 -10
F 2 - A I F F 2 - D A I F 
Figure 17. Free energy of the generative model (24).
-15 -10 -5 0 5 10 15x [ m ] 
-15
-10
-5
0
5
10
15y [ m ] 
A I F t r a j e c t o r y D A I F t r a j e c t o r y T a r g e t t r a j e c t o r y 
Figure 18. Circular motion trajectory of UAV in X-O-Y plane.
4.2. Precision Learning and Delay Size Analysis
The state estimations for different prediction precision values in DAIF are illustrated
in Figures 19â€“22. It is evident that asâ„¦Âµ and â„¦Âµâ€² increase from eâˆ’4 to e0, the mutation of the
state estimates decreases and the system state can return to normal more rapidly. Prediction
accuracy essentially represents the inverse variance of the approximate distribution. Greater
prediction accuracy can reduce estimation uncertainty and bring the estimated state closer
to the predicted state.
Entropy 2024, 26, 990 17 of 20
0 5 10 15 20 25T i m e [ s ] 
-5
0
5
10
15
20
25
307 1 [ m ] 
+ 7 = e 0 
+ 7 = e ! 1 
+ 7 = e ! 2 
+ 7 = e ! 3 
+ 7 = e ! 4 
10 11 12 13 14 154
6
8
10
Figure 19. State estimation Âµ1 for different prediction accuracy â„¦Âµ.
0 5 10 15 20 25T i m e [ s ] 
0
5
10
15
20
25
307 2 [ m ] 
+ 7 = e 0 
+ 7 = e ! 1 
+ 7 = e ! 2 
+ 7 = e ! 3 
+ 7 = e ! 4 
10 11 12 13 14 15
6
8
10
12
Figure 20. State estimation Âµ2 for different prediction accuracy â„¦Âµ.
0 5 10 15 20 25T i m e [ s ] 
-10
0
10
207 4 [ m ] 
+ 7 = e 0 
+ 7 = e ! 1 
+ 7 = e ! 2 
+ 7 = e ! 3 
+ 7 = e ! 4 
10 11 12 13 14 15-14-12-10-8-6-4-2
Figure 21. State estimation Âµ4 for different prediction accuracy â„¦Âµâ€² .
Entropy 2024, 26, 990 18 of 20
0 5 10 15 20 25T i m e [ s ] 
-10
0
10
20
30
407 5 [ m ] 
+ 7 = e 0 
+ 7 = e ! 1 
+ 7 = e ! 2 
+ 7 = e ! 3 
+ 7 = e ! 4 
10 11 12 13 14 15-10
0
10
Figure 22. State estimation Âµ5 for different prediction accuracy â„¦Âµâ€² .
We set the state prediction accuracy to be â„¦Âµ = â„¦Âµâ€² = 1 and gradually increased the
input delay from 0.1 s to 0.9 s. We conducted 5 sets of UAV trajectory tracking experiments
with varying input delays, each set consisting of 20 trials. We quantify the predictive
performance using the sum of the squared prediction error (SSPE) in state, sense, and
control. As depicted in Figures 23 and 24, significant state and control prediction errors
were observed as a result of the sudden disturbance-induced mutation in the predicted
state and delayed feedback preference control. However, adaptive prediction accuracy led
to a minimal perception prediction error. The error bar plot of the SSPE indicates that both
the state prediction error and control prediction error increase with higher input delay,
highlighting the significance of considering input delay in our analysis.
= =0.1s = =0.3s = =0.5s = =0.7s = =0.9s0
1
2
3
4
5
6
7
8
9
10SSPE of linear trajectory tracking 
State prediction errorSense prediction errorControl prediction error
Figure 23. SSPE of linear trajectory tracking for different input delay Ï„.
= =0.1s = =0.3s = =0.5s = =0.7s = =0.9s0
10
20
30
40
50
60
70
80SSPE of circular trajectory tracking 
State prediction errorSense prediction errorControl prediction error
Figure 24. SSPE of circular trajectory tracking for different input delay Ï„.
Entropy 2024, 26, 990 19 of 20
5. Conclusions
This paper introduces a novel DAIF algorithm for uncertain systems with input delay.
This algorithm incorporates a predicted state as the current state expectation, designs
a delayed feedback PI control as the preferred control expectation, and implements an
adaptive tuning mechanism with a gain coefficient. Both AIF and DAIF are utilized for the
trajectory tracking of a quadrotor UAV . Simulation results demonstrated that the estimation
accuracy of DAIF based on predicted states is higher than that of AIF, and the DAIF
preference control performs better than AIF when the uncertain system with an input delay
is subjected to sudden disturbance. The existence of input delay will increase the prediction
error, so it cannot be ignored.
Author Contributions: Q.P .: conceptualization; X.D.: investigation; X.Z.: data curation; K.P .: formal
analysis; M.J.: software, validation, visualization, and writing; Y.L.: conceptualization, methodol-
ogy, supervision, and writing. All authors have read and agreed to the published version of the
manuscript.
Funding: This work is supported by the National Natural Science Foundation of China (Nos. 62203358,
62233014).
Institutional Review Board Statement: Not Applicable.
Data Availability Statement: The data presented in this study are available on request from the
corresponding author.
Conflicts of Interest: The authors declare no conflict of interest.
References
1. Friston, K.; Moran, R.J.; Nagai, Y.; Taniguchi, T.; Gomi, H.; Tenenbaum, J. World model learning and inference.Neural Netw. 2021,
144, 573â€“590. [CrossRef]
2. Friston, K. The free-energy principle: A unified brain theory? Nat. Rev. Neurosci. 2010, 11, 127â€“138. [CrossRef]
3. Friston, K.; FitzGerald, T.; Rigoli, F.; Schwartenbeck, P .; Pezzulo, G. Active inference: A process theory.Neural Comput. 2017, 29,
1â€“49. [CrossRef]
4. LeCun, Y.; Bengio, Y.; Hinton, G. Deep learning. Nature 2015, 521, 436â€“444. [CrossRef]
5. Safron, A. Integrated world modeling theory (iwmt) implemented: Towards reverse engineering consciousness with the free
energy principle and active inference. In Active Inference: First International Workshop, IWAI 2020, Co-Located with ECML/PKDD 2020,
Ghent, Belgium, 14 September 2020, Proceedings 1; Springer: Berlin/Heidelberg, Germany, 2020; pp. 135â€“155.
6. Jordan, M.I.; Ghahramani, Z.; Jaakkola, T.S.; Saul, L.K. An introduction to variational methods for graphical models. Mach. Learn.
1999, 37, 183â€“233. [CrossRef]
7. Fang, X.; Li, J.; Li, X.; Xie, L. 2-d distributed pose estimation of multi-agent systems using bearing measurements. J. Autom. Intell.
2023, 2, 70â€“78. [CrossRef]
8. Friston, K.J. Variational filtering. NeuroImage 2008, 41, 747â€“766. [CrossRef]
9. Parr, T.; Pezzulo, G.; Friston, K.J.Active Inference: The Free Energy Principle in Mind, Brain, and Behavior; MIT Press: Cambridge, MA,
USA, 2022.
10. Opper, M.; Winther, O. Gaussian processes for classification: Mean-field algorithms.Neural Comput. 2000, 12, 2655â€“2684. [CrossRef]
11. Mathys, C.; Daunizeau, J.; Friston, K.J.; Stephan, K.E. A bayesian foundation for individual learning under uncertainty. Front.
Hum. Neurosci. 2011, 5, 39. [CrossRef]
12. Beck, J.L.; Katafygiotis, L.S. Updating models and their uncertainties. i: Bayesian statistical framework. J. Eng. Mech. 1998, 124,
455â€“461. [CrossRef]
13. Buckley, C.L.; Kim, C.S.; McGregor, S.; Seth, A.K. The free energy principle for action and perception: A mathematical review.
J. Math. Psychol. 2017, 81, 55â€“79. [CrossRef]
14. Pezzato, C.; Baioumy, M.; Corbato, C.H.; Hawes, N.; Wisse, M.; Ferrari, R. Active inference for fault tolerant control of robot
manipulators with sensory faults. In Active Inference: First International Workshop, IWAI 2020, Co-Located with ECML/PKDD 2020,
Ghent, Belgium, 14 September 2020, Proceedings 1; Springer: Berlin/Heidelberg, Germany, 2020; pp. 20â€“27.
15. Baltieri, M.; Buckley, C.L. Nonmodular architectures of cognitive systems based on active inference. In Proceedings of the 2019
International Joint Conference on Neural Networks (IJCNN), Budapest, Hungary, 14â€“19 July 2019; pp. 1â€“8.
16. Baltieri, M.; Buckley, C.L. Pid control as a process of active inference with linear generative models. Entropy 2019, 21, 257.
[CrossRef] [PubMed]
17. Ã…strÃ¶m, K.J.; HÃ¤gglund, T.; Astrom, K.J. Advanced PID Control; ISAâ€”The Instrumentation, Systems, and Automation Society
Research Triangle Park: Research Triangle Park, NC, USA, 2006; Volume 461.
Entropy 2024, 26, 990 20 of 20
18. Ã…strÃ¶m, K.J.; Panagopoulos, H.; HÃ¤gglund, T. Design of pi controllers based on non-convex optimization. Automatica 1998, 34,
585â€“601. [CrossRef]
19. Lanillos, P .; Cheng, G. Active inference with function learning for robot body perception. In Proceedings of the International
Workshop on Continual Unsupervised Sensorimotor Learning, IEEE Developmental Learning and Epigenetic Robotics (ICDL-
Epirob), Tokyo, Japan, 5 August 2018.
20. Chao, H.; Cao, Y.; Chen, Y. Autopilots for small unmanned aerial vehicles: A survey.Int. J. Control. Autom. Syst. 2010, 8, 36â€“44.
[CrossRef]
21. Jung, S.; Ariyur, K.B. Enabling operational autonomy for unmanned aerial vehicles with scalability.J. Aerosp. Inf. Syst. 2013, 10,
517â€“529. [CrossRef]
22. Adamski, M. Analysis of propulsion systems of unmanned aerial vehicles. J. Mar. Eng. Technol. 2017, 16, 291â€“297. [CrossRef]
23. Meera, A.A.; Wisse, M. Free energy principle based state and input observer design for linear systems with colored noise. In
Proceedings of the 2020 American Control Conference (ACC), Denver, CO, USA, 1â€“3 July 2020; pp. 5052â€“5058.
24. Friston, K.J.; Trujillo-Barreto, N.; Daunizeau, J. Dem: A variational treatment of dynamic systems. Neuroimage 2008, 41, 849â€“885.
[CrossRef]
25. Bas, F.; Meera, A.A.; Benders, D.; Wisse, M. Free energy principle for state and input estimation of a quadcopter flying in wind. In
Proceedings of the 2022 International Conference on Robotics and Automation (ICRA), Philadelphia, PA, USA, 23â€“27 May 2022;
pp. 5389â€“5395.
26. Meo, C.; Lanillos, P . Multimodal vae active inference controller. In Proceedings of the 2021 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS), Prague, Czech Republic, 27 Septemberâ€“1 October 2021; pp. 2693â€“2699.
27. Pezzato, C.; Ferrari, R.; Corbato, C.H. A novel adaptive controller for robot manipulators based on active inference. IEEE Robot.
Autom. Lett. 2020, 5, 2973â€“2980. [CrossRef]
28. Pitti, A.; Quoy, M.; Lavandier, C.; Boucenna, S. Complementary working memories using free-energy optimization for learning
features and structure in sequences. In Proceedings of the Workshop Brain PIL New Advances in Brain-Inspired Perception,
Interaction and Learning, ICRA2020, Paris, France, 31 May 2020.
29. Ã‡atal, O.; Verbelen, T.; Van de Maele, T.; Dhoedt, B.; Safron, A. Robot navigation as hierarchical active inference.Neural Netw. 2021,
142, 192â€“204. [CrossRef]
30. Mazzaglia, P .; Verbelen, T.; Dhoedt, B. Contrastive active inference. Adv. Neural Inf. Process. Syst. 2021, 34, 13870â€“13882.
31. Baioumy, M.; Pezzato, C.; Ferrari, R.; Corbato, C.H.; Hawes, N. Fault-tolerant control of robot manipulators with sensory faults
using unbiased active inference. In Proceedings of the 2021 European Control Conference (ECC), Rotterdam, The Netherlands, 29
Juneâ€“2 July 2021; pp. 1119â€“1125.
32. Meo, C.; Franzese, G.; Pezzato, C.; Spahn, M.; Lanillos, P . Adaptation through prediction: Multisensory active inference torque
control. IEEE Trans. Cogn. Dev. Syst. 2022, 15, 32â€“41. [CrossRef]
33. Baioumy, M.; Duckworth, P .; Lacerda, B.; Hawes, N. Active inference for integrated state-estimation, control, and learning. In
Proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA), Xiâ€™an, China, 30 Mayâ€“5 June 2021;
pp. 4665â€“4671.
34. Liepe, J.; Kirk, P .; Filippi, S.; Toni, T.; Barnes, C.P .; Stumpf, M.P . A framework for parameter estimation and model selection
from experimental data in systems biology using approximate bayesian computation. Nat. Protoc. 2014, 9, 439â€“456. [CrossRef]
[PubMed]
35. Zhou, Y.; Wang, Z. Robust motion control of a two-wheeled inverted pendulum with an input delay based on optimal integral
sliding mode manifold. Nonlinear Dyn. 2016, 85, 2065â€“2074. [CrossRef]
36. Zhou, Y.; Wang, Z.; Chung, K.-W. Turning motion control design of a two-wheeled inverted pendulum using curvature tracking
and optimal control theory. J. Optim. Theory Appl. 2019, 181, 634â€“652. [CrossRef]
37. Li, J.; Kuang, Y.; Mason, C.C. Modeling the glucoseâ€“insulin regulatory system and ultradian insulin secretory oscillations with two
explicit time delays. J. Theor. Biol. 2006, 242, 722â€“735. [CrossRef]
38. Friston, K.; Samothrakis, S.; Montague, R. Active inference and agency: Optimal control without cost functions. Biol. Cybern. 2012,
106, 523â€“541. [CrossRef]
39. Friston, K.J.; Daunizeau, J.; Kilner, J.; Kiebel, S.J. Action and behavior: A free-energy formulation. Biol. Cybern. 2010, 102, 227â€“260.
[CrossRef]
40. Oliver, G.; Lanillos, P .; Cheng, G. An empirical study of active inference on a humanoid robot.IEEE Trans. Cogn. Dev. Syst. 2021,
14, 462â€“471. [CrossRef]
41. Cai, G.-P .; Huang, J.-Z.; Yang, S.X. An optimal control method for linear systems with time delay. Comput. Struct. 2003, 81,
1539â€“1546. [CrossRef]
42. Xiong, J.-J.; Zheng, E.-H. Position and attitude tracking control for a quadrotor uav. ISA Trans. 2014, 53, 725â€“731. [CrossRef]
Disclaimer/Publisherâ€™s Note: The statements, opinions and data contained in all publications are solely those of the individual
author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to
people or property resulting from any ideas, methods, instructions or products referred to in the content.