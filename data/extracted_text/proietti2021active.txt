Available online at www.sciencedirect.com
ScienceDirect
Physics of Life Reviews 46 (2023) 92–118
www.elsevier.com/locate/plrev
Review
An active inference model of hierarchical action understanding, 
learning and imitation
Riccardo Proietti a, Giovanni Pezzulo b,∗, Alessia Tessaria,c
a Department of Psychology, University of Bologna, Italy
b Institute of Cognitive Sciences and Technologies, National Research Council, Rome, Italy
c Alma Mater Research Institute for Human-Centered Artiﬁcial Intelligence, University of Bologna, Bologna, Italy
Received 29 May 2023; accepted 31 May 2023
Available online 5 June 2023
Communicated by J. Fontanari
Abstract
We advance a novel active inference model of the cognitive processing that underlies the acquisition of a hierarchical action 
repertoire and its use for observation, understanding and imitation. We illustrate the model in four simulations of a tennis learner 
who observes a teacher performing tennis shots, forms hierarchical representations of the observed actions, and imitates them. Our 
simulations show that the agent’s oculomotor activity implements an active information sampling strategy that permits inferring the 
kinematic aspects of the observed movement, which lie at the lowest level of the action hierarchy. In turn, this low-level kinematic 
inference supports higher-level inferences about deeper aspects of the observed actions: proximal goals and intentions. Finally, the 
inferred action representations can steer imitative responses, but interfere with the execution of different actions. Our simulations 
show that hierarchical active inference provides a uniﬁed account of action observation, understanding, learning and imitation and 
helps explain the neurobiological underpinnings of visuomotor cognition, including the multiple routes for action understanding in 
the dorsal and ventral streams and mirror mechanisms.
© 2023 The Authors. Published by Elsevier B.V . This is an open access article under the CC BY license (http://
creativecommons .org /licenses /by /4 .0/).
Keywords: Action understanding; Active inference; Hierarchical model; Action representation; Visuomotor control
1. Introduction: action understanding as a hierarchical inference problem
Understanding actions performed by others is vital for social cognition. An action can be deﬁned as a sequence 
of kinematic bodily movements (e.g., movements of the left arm and ﬁngers) elicited and monitored by a goal (e.g., 
grasping an object). Hence, we assume that action understanding amounts to inferring the actor’s goal by observing 
her movement kinematics, such as the positions of her limbs, angles of joints, their relative positions, and respect to 
* Corresponding author at: Institute of Cognitive Sciences and Technologies, National Research Council, 00185 Rome, Italy.
E-mail address: giovanni.pezzulo@istc.cnr.it (G. Pezzulo).
https://doi.org/10.1016/j.plrev.2023.05.012
1571-0645/© 2023 The Authors. Published by Elsevier B.V . This is an open access article under the CC BY license (http://
creativecommons .org /licenses /by /4 .0/).
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
objects and the context [81]. In turn, since an action may result from many movements, the inference of action goals 
from observed movements constitutes an inverse problem [35,81].
Several researchers proposed that to solve this inverse (one-to-many) problem, the brain adopts a probabilistic 
strategy, which can be formulated in Bayesian terms as:
p(goal | movement) = p(goal) ∗ p(movement | goal)/p(movement)
In the above equation, the (posterior) probability of an action goal given the observed movement p(goal | movement) is 
proportional to the (prior) probability of the goal p(goal) before observing the movement and the probability p(move-
ment | goal) that a speciﬁc goal generates the observed movement (likelihood). These two (prior and likelihood) terms 
constitute a so-called generative model of how actions are generated, that the brain uses (technically, “inverts”) for 
action recognition -o r the inference about the action goal that may have produced an observed movement [5,6,42,91].
It has been proposed that the brain uses the same generative model for both action execution and recognition and 
this generative model is structured hierarchically [26,70,87,90,114]. In this study, we present a computational analysis 
of these hierarchical action representations, by considering four levels of representation of an exempliﬁcative set of 
skilled movements, namely, tennis movements; see Fig. 1. At the bottom of the hierarchy, the kinematic level encodes 
the kinematic features of movements (e.g., speed and acceleration) of actions. For example, in our tennis context, the 
kinematic level regards speciﬁc body parts involved in the execution of a tennis shot. At this level we also consider 
tools, such as a stick or a tennis racket, that can be incorporated into the body schema, to extend a person’s action 
capabilities [104]. One step higher in the hierarchy, we formalise a postural level where different combinations of 
body parts constitute segments that are the building blocks of tennis movements. In this context, we refer to large-
scale body parts (e.g. arm, leg, head) and their position relative to other body parts, that we might deﬁne “movement 
segments” and both knowledge about our own body and a general representation of the human body are involved (for 
a discussion of the role of body parts in imitation, see [113,157]). The further hierarchical level encodes the proximal 
goal of the action, such as the aim to execute a particular tennis shot, by enacting a sequence of segments. The highest, 
intention level represents the ultimate reason for executing the action, which in this setting corresponds to a general 
class of shots: forehand, backhand, or smash. Notably, each class of shots has multiple realisations at the proximal 
goal and kinematic levels (e.g., a forehand can be done to the left or right). This reﬂects the fact that intentions can 
be generic and agnostic about particular realisations, with action representations being more disentangled from motor 
aspects [96,97]. For example, the intention to reach a holiday destination could be realised by taking a ﬂight, or by 
travelling by car or by train.
In sum, the hierarchical arrangement of the generative model illustrated in Fig. 1 implies that the brain encodes 
a rich cognitive representation of actions, which links together more abstract features of action at higher levels (i.e., 
the intentions they realise and the contexts in which they can be successfully deployed) to functional or anatomo-
kinematic rules at lower levels [69]. Importantly, in this hierarchical setting, action understanding amounts to inferring 
the higher levels of the hierarchy (e.g., goals and intentions) by only having access to movement observations. Action 
understanding also paves the way to imitating the observed actions.
The aim of this paper is to propose a uniﬁed computational account of the cognitive processing underlying action 
observation, understanding, learning and imitation abilities. This novel proposal is grounded in the framework of active 
inference, which provides a normative perspective on brain computations and behaviour [119]. While our proposal is 
domain-general, we illustrate it in a generative model of a “tennis task”, in which a naive tennis player (henceforth, 
the learner) infers and imitates the actions executed by an expert player (henceforth, the teacher). Please consider 
that in our study, the game of tennis is taken as an exempliﬁcative scenario; the naive and expert tennis players do 
not recognize or reproduce the bodily movements of human tennis players, but only an abstract representation of 
these movements (i.e., combinations of abstract movement features, see below the model description). While the 
task structure consists of an abstract, toy-example, the model aims to provide a general and biologically plausible 
account of action understanding, learning, and imitation. Our simulations will show that the inferential dynamics 
supporting the recognition, learning and imitation of (tennis) actions, as well as the saccadic movements that promote 
(active) perception, emerge naturally from the active inference formulation and align well with empirical results and 
neurobiological models from previous literature.
In the next sections of this paper, we discuss four simulations of the tennis task using active inference. Each simu-
lation is designed to illustrate one speciﬁc aspect of the framework that is relevant to explain how we understand and 
93
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
Fig. 1. This schematic illustrates the hierarchical representation of an action repertoire in the example scenario that we adopt in this paper: playing 
tennis. The hierarchy comprises three levels of hidden variables which are inferred (segments, proximal goals, and intentions) and an observation 
layer (kinematics). The higher the level of the hidden variable, the more the representation is associated with abstract and generalised action 
meanings. Here, kinematics aspects are exempliﬁed with body parts which spatial relations constitute different body segments; proximal goals 
denote sequences of segments that realize tennis shots, in this case a left or right forehand; rather, intentions denote the most general class of shots, 
here forehand, that entails multiple realisations at the proximal goal and kinematic levels. Note that this schematic (and our computational model) 
omits the motor level, which is responsible for the speciﬁcation of patterns of muscle activity to execute the movements speciﬁed at the kinematic 
level. This schematic also illustrates that in this hierarchical setting, action understanding amounts to inferring the higher levels of the hierarchy 
(e.g., goals and intentions) by only having access to low-level (kinematic) observations.
imitate actions. The ﬁrst simulation illustrates the core mechanisms of active inference in play during action under-
standing, highlighting its inferential and active nature. This simulation shows the empirical predictions (e.g., beliefs 
updating, oculomotor dynamics and response selection and times) that can be derived by casting action understand-
ing as a process of (active) inference over a hierarchical generative model of segments, goals, and intentions. The 
second simulation illustrates how during the observation of familiar actions, oculomotor dynamics are guided by the 
imperative of reducing uncertainty (about which action one is observing), which is automatically elicited in active 
inference in ambiguous contexts. This simulation also illustrates the way prior beliefs and the motor knowledge of 
the observed movements can inﬂuence the observation pattern. The third simulation illustrates how during the ob-
servation and learning of novel actions, oculomotor dynamics are guided by the imperative to pursue novelty, which 
arises automatically in active inference when the observed actions are unknown and the context affords learning. This 
simulation also illustrates that the learning process creates a more reliable (likelihood) mapping between lower and 
higher levels of representation and affords a deep (semantic) level of action understanding. Finally, the fourth simula-
tion illustrates how in active inference, action observation automatically facilitates the execution of imitative actions 
but interferes with the execution of alternative actions. This is because both action understanding and execution rest 
on shared (ideomotor) codes across perception and action. Finally, we illustrate the neurobiological implications and 
the possible neural implementation of our proposed model.
94
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
2. Active inference simulations during action understanding and imitation
2.1. Simulation 1: hierarchical inference about actions in a tennis task
The tennis task involves two people: an experienced player (teacher), who demonstrates how to perform different 
kinds of tennis shots correctly; and a naive player (learner), who observes the teacher’s actions and tries to understand 
and imitate them. The computational model describes formally how the learner performs action understanding and 
imitation, by observing how the teacher’s body movements unfold over time.
As illustrated in Fig. 2D, the learner’s visual scene encodes the movements of the teacher. The visual elements of 
the scene are the teacher’s body parts, and their relative position in a four-slot quadrant. Each combination of body 
parts corresponds to a speciﬁc segment. Each segment is univocally deﬁned by the relative position of two body parts. 
Speciﬁcally, segment 1 occurs whenever the head is beside the foot; segment 2 occurs whenever the head is beside 
the racket; and segment 3 occurs whenever the head stands diagonally with respect to the racket. The body part hand
covers the two remaining locations in each conﬁguration of segments. The transitions between segments represent the 
teacher’s movements to hit the ball, or her proximal goals. Here, the teacher has six possible proximal goals (right
or left forehand, right or left backhand, right or left smash), each deﬁned by a unique sequence of four segments. 
For example, the sequence of segments 3-1-3-2 corresponds to the right backhand. Finally, proximal goals can be 
further classiﬁed into three intentions (forehand, backhand or smash) that abstract away from the speciﬁcs of (left or 
right) actions. In this sense, intentions can be interpreted as effector-independent, according to the “limb-independent 
coding” of movements [133]a s the intention of executing e.g., a backhand shot is independent and generalised from 
its side of execution (left or right backhand).
Although this is a schematic organisation of actions, it entails plausibility given how the same action at higher level 
can be executed by different combinations at a lower level. Indeed, when we observe an action or aim to perform a 
well-known action, many schemas are partially activated, as they are alternative means of achieving the same goal 
(e.g., [154]) even if only one schema will be selected at the end.
In the model, action understanding is cast as the inference of the three kinds of hidden variables (intentions, 
proximal goals, and segments) based on movement (body part kinematics) observations. In turn, this hierarchical 
inference can be conceptually divided into three kinds of inferences, see Fig. 2. The ﬁrst kind of inference only regards 
the most superﬁcial features of action, i.e., the inference of segments from kinematic observations. In the model, the 
learner can only execute a saccade and observe a single body part of the teacher at a time (i.e., the positioning of head, 
hand or leg) but she can accumulate this information over time to infer the teacher’s segment, deﬁned here as a speciﬁc 
combination of body parts. Fig. 2D shows the example of a learner performing saccades (red dots) to different body 
parts, which are informative about which of three possible segments she is observing. Fig. 2C shows the dynamics of 
the inference about segments in the computational model. The model maintains beliefs (as probability distributions, 
where darker colours denote higher probabilities) about segments and updates them when it obtains novel information 
via further saccades. Fig. 2B shows the belief dynamics associated with the second kind of inference, which regards 
a deeper aspect of the observed movements: the one that concerns proximal goals. This second kind of inference uses 
the results of the ﬁrst kind of inference (i.e., the inferred segments) as observations. The speciﬁc example illustrated in 
Fig. 2B regards the inference that the teacher’s proximal goal is executing a right backhand, based on the fact that the 
sequence of observed segments is 3-1-3-2. Fig. 2A shows the third kind of inference, which regards the most general 
aspect of the observed movement: the intention. The speciﬁc example illustrated in Fig. 2A regards the inference 
of the backhand intention. Finally, Fig. 2E shows that the learner can imitate the observed action by executing the 
sequence of segments that she previously inferred. The possibility of imitating observed actions rests on the fact that 
the model infers (forms beliefs about) the observed sequence of actions or policy. In other words, imitation is simply 
the enactment of the policy that was inferred with the highest probability (the ways beliefs about the observed action 
are translated into a motor response are described in the Methods section). Alternatively, the agent could select an 
imitative response that differs from the sequence of segments that was previously inferred, but still realises the same 
intention (we remind that intentions have different realisations). For example, the agent could imitate a right backhand 
by executing a left backhand. While in our simulations we do not allow for this ﬂexibility in imitation, this could be 
simply done by ﬁrstly inferring an intention (e.g., backhand) and then selecting one of the different sequences of 
segments that realises the intention, either randomly or by considering which is the most contextually appropriate.
95
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
Fig. 2. Results of Simulation 1. The ﬁgure shows the belief dynamics of an active inference agent (the “learner”) during action observation, its 
oculomotor behaviour and its imitative motor response. The Panels A-D correspond to the four hierarchical levels of the model shown in Fig. 1. 
Here, we describe them in the reverse order, starting from the bottom (kinematic observation) level to the top (intention) level. Panel D shows 
the observations of the learner agent, at different timesteps. These are the movement segments of the teacher during a tennis shot (here, a right 
backhand). Each segment corresponds to a different combination of body parts. The blue line represents the simulated oculomotor behaviour of the 
learner agent and the red dots the saccade locations. Note that the learner can only make saccades to one body part at a time but can integrate this 
information over time, to infer the current movement segment of the teacher. Panel C shows the learner’s probabilistic beliefs about the observed 
movement segments: the darker the colour of each cell, the larger the posterior belief about a speciﬁc segment. Please note that these (and the other) 
beliefs change over time, as the learner obtains more information about the teacher’s segments. Panel B shows the dynamics of the probabilistic 
beliefs associated with the sequences of segments, where each sequence corresponds to one of the proximal goals of the teacher. Panel A shows 
the probabilistic beliefs associated with the highest level of representation: the intentions. Finally, panel E shows the imitative response executed 
by the learner where she correctly executes the same sequence of segments that she has observed.
2.2. Simulation 2: observation of familiar actions and the role of uncertainty and prior knowledge in active sensing
In the previous simulation, we explained that the learner employed saccades to gather information about the 
teacher’s segments, proximal goals, and intentions, but we did not explain how she selected the next saccades. The 
second simulation aims to show that in active inference, action understanding is achieved by engaging sequences of 
96
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
Fig. 3. Results of Simulation 2: the dynamics of action understanding of two learners, with no prior knowledge (left learner) or incorrect prior 
knowledge (right learner). The D panels show the different oculomotor dynamics for the two cases, respectively. The A, B and C panels show the 
different belief dynamics for the two cases, with the same notation as in Fig. 2. Note that at timestep 3, the right learner (with misleading priors) 
strongly believes to observe a left forehand and segment 2. However, after inferring she is observing segment 1, she changes her mind and correctly 
infers she is observing a right smash. On the contrary, at timestep 3, the left learner (with ﬂat priors) assigns the same probability to the left forehand 
and the right smash and to the two possible incoming segments (1 and 2). After observing segment 1, she correctly infers she is observing a right 
smash, without signiﬁcant surprise. Although the right one employed more time to correctly categorise the observed action, both learners correctly 
imitate the action, see panel E.
eye movements that gather salient information [43,60,54,117]. Salience is determined by a prediction on where to 
perform the next ﬁxation to help reduce uncertainty about the observed action. This is in keeping with theories of 
perception as an active process, which involves planning sequences of (oculomotor) actions that lead to optimal infor-
mation foraging and proactively gathers information to reduce uncertainty [14,112,161]. This uncertainty-reduction 
imperative is one of the components of the (expected free energy) equation that guides the selection of policies in ac-
tive inference; see the Methods for details. This imperative becomes more prominent when there is some uncertainty 
to resolve, such as when the learner does not know which action she is observing, but loses importance if the learner 
has prior knowledge about the action – unless this prior knowledge is misleading.
Consider a learner who is observing the teacher executing a right smash shot in two different conditions (see Fig. 3). 
In one condition, illustrated in the left panels of Fig. 3, the learner has no prior knowledge about the teacher’s goal (i.e., 
she has a ﬂat prior belief). In the other condition, illustrated in the right panels of Fig. 3, the learner has been informed 
that the teacher will perform a left forehand shot (i.e., she has a misleading prior belief). In both cases, eye movements 
are engaged to solve the uncertain aspects of the action as they are directed towards the most salient location of the 
scene, which tests the learner’s hypotheses. However, what is deemed to be the most salient location to gaze depends 
on the learner’s hypotheses or prior beliefs (which are of course updated after gathering novel observations). As an 
effect, the patterns of eye movements and belief updating of the left panels of Fig. 3 and the right panels of Fig. 3
are different. In both cases, the learner eventually recognizes the correct proximal goal (right smash); however, this 
process is slightly slower in the latter case, when she starts from a misleading prior. This can be observed by looking 
97
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
at the simulated reaction times for each timestep of the simulation (obtained by considering the time spent to compute 
the simulation, see the Methods section), below the D panels.
This simulation permits appreciating how active perception and the dynamics of belief updating - and  hence 
whether recognition will be successful or unsuccessful, fast or slow - depend on the learner’s prior beliefs. This is 
because the prior beliefs determine the salience of visual locations and which location to gaze next. In this perspec-
tive, salience is not associated with basic properties of the stimulus such as noise, but it is deﬁned formally as an 
information gain - and  is therefore high in locations that have a high potential to resolve uncertainty [43,60,54]. 
Speciﬁcally, salience can be formalised as a Bayesian surprise, which corresponds to the divergence between the 
prediction of a generative model and the actual outcome. Before a saccade, the learner can use her generative model 
to estimate Bayesian surprise and hence the salience of each location - and then select the highest salience location 
[80,78,79]. Using this method, a salient location corresponds to the one expected to reduce uncertainty, if a saccade 
were performed towards it [117]. Empirical research shows that this notion of Bayesian surprise characterises well 
which aspects of a visual scene capture human attention [78,111,132].
Another important point to notice is that prior information can come from different sources: it can be provided 
exogenously (for example, via verbal or contextual cues) or be generated endogenously, on the basis of the learner’s 
own motor knowledge. A consistent body of evidence has shown that eye movements are engaged coherently during 
both action execution and observation, suggesting that they come from the same generative model that encodes one’s 
own motor knowledge [49]. More broadly, this suggests that the parameters employed for categorising and encoding 
action representations are shared with those for action execution – which is a feature implemented in our model (see 
the Methods for a description of the model parametrization). This feature has been widely studied in relation to the 
mirror system [3,16,29,28,34,102,103,120,122,135]. Later, we will elaborate further on this topic.
2.3. Simulation 3: observation of novel actions: the role of novelty in active sensing and learning
So far, we assumed that the learner already knows the teacher’s actions that she observes. This simulation illustrates 
what happens when the learner ﬁrstly observes novel segments and then learns a never-observed proximal goal.
There is a fundamental difference between the (active) perception of known and unknown actions. As discussed 
above, the perception of known actions is directed towards salient locations that reduce uncertainty about what action 
a person is observing. In turn, to calculate saliency, the learner needs to be endowed with a generative model that 
permits predicting “what would I see if I observe, in a speciﬁc moment, that location of the teacher’s body?” By 
deﬁnition, during the observation of unknown actions, the learner’s model is incomplete and hence she cannot make 
reliable action predictions that are necessary to assess what is salient. More broadly, the learner needs to be familiar 
with the speciﬁcs of the human body to better predict possible (in contrast to impossible) movements [153,157]. In 
the case of an unknown action, oculomotor behaviour is mainly driven by the novelty of sensory evidence rather 
than saliency or Bayesian surprise. Observing unknown actions induces a novelty-seeking, curious behaviour that 
is mainly driven by bottom-up processes such as attentional capture (e.g., orienting responses) [151]o r perceptual 
curiosity, deﬁned as “the interest in and giving attention to novel perceptual stimulation” [12,33], as opposed to the 
prominence of top-down, expectation-guided processes during the pursuit of salient information.
The patterns of oculomotor movements related to salience (Fig. 2) and novelty (Fig. 4) are signiﬁcantly different. 
Visually sampling unknown actions generally requires more saccades because many locations provide novel infor-
mation, and the learner cannot predict in advance which segment she will observe next; this is because she has no 
knowledge of how segments are determined in the unknown action. The novelty-seeking behaviour is crucial to re-
solve the learner’s “semantic knowledge gap” regarding the acquisition of the unknown mapping between body parts 
and segments in the learner’s generative model. In Bayesian terms, this unknown mapping corresponds to the like-
lihood p(o|s) and it regards the relations between hidden states (s) at a higher hierarchical level – here, the level of 
segments – and the possible outcomes (o) at the level below – here, the body part kinematics. As illustrated in Fig. 4, 
sampling novel locations permits the learner to ﬁll in this knowledge gap, and to learn the likelihood mapping between 
body parts and their combinations [7,9,68,147].
Fig. 5 illustrates schematically how the novel knowledge that the agent acquired through novelty sampling permits 
it to learn the likelihood mappings of the higher hierarchical levels of the generative model. Speciﬁcally, the likelihood 
mapping illustrated in Fig. 5 encodes the probabilistic relations between the levels of the segments and the proximal 
goals. Fig. 5A shows the real statistics of the environment (called generative process in active inference), which in 
98
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
Fig. 4. Results of Simulation 3: observation and imitation of a novel action. In panel D are shown the simulated oculomotor dynamics when the 
learner observes an unknown action, here corresponding to the sequence of segments 1-3-2-1. In this case, visual attention is driven by both surprise 
and novelty. The latter induces the sampling of several novel locations, resulting in a larger number of saccades compared to previous cases, in 
which the observed actions were known. In panels C and B, it can be noted how the probabilistic beliefs are more spread across the hidden states 
resulting in much larger amount of uncertainty. This leads the student to an “undecided” intention categorization in panel A.
our example corresponds to the real and objective mapping between proximal goals and segments. Each row of the 
panel shows the sequence of segments expected under a particular proximal goal: the ﬁrst three columns represent the 
segments (1 to 3) at the quadrant location 1; the second three columns represent the segments at the quadrant location 
2; the third three columns represent the segments at the quadrant location 3; and the last four columns represent the 
segments at the quadrant location 4. For example, the fourth row shows that performing a left backhand elicits the 
sequence of segments 3-2-1-3 (these segments are marked in black, which correspond to the fact that they have a high 
probability). Fig. 5B shows the learner’s generative model before learning (to put it simply, her knowledge about the 
statistics of the environment). This generative model is analogous to the generative process, but the row corresponding 
to the left backhand is grey, which indicates that the learner has no knowledge about the sequence of segments elicited 
by this proximal goal (technically, she has a ﬂat belief state). The (likelihood) mapping between the left backhand
99
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
Fig. 5. Results of Simulation 3: how the generative model is updated when a novel action is learned. In this example, the part of the generative model 
that is updated is the (likelihood) mapping between segments and goals. For each panel (A, B, C), the rows represent the goals and the columns 
represent the three segments for each of the four quadrant locations. In each square, a darker tint represents a larger probabilistic contingency 
between the states (goals) and the observations (segments). Panel A shows the contingencies of the so-called generative process, which correspond 
to the true statistics of the environment. The generative process represents the real probability of observing a segment given a goal. In panel B is 
represented the likelihood of the learner’s generative model before learning. In the generative process the goal left backhand corresponds to the 
sequence of segments 3-2-1-3. However, before learning, the learner’s generative model does not include this mapping yet, but, instead, a “ﬂat” 
mapping between the left backhand goal and all the possible segments (grey tint, as probabilities are spread). Panel C shows that, after learning 
from 12 simulation trials, the learner has acquired knowledge about these contingencies and the likelihood mapping in the generative model is 
almost completely aligned with that of the generative process (tints are close to black and white).
goal and the corresponding sequence of segments is the “semantic knowledge gap” that the learner has to ﬁll by 
learning. Finally, Fig. 5C shows that after some trials, the learner has (almost completely) ﬁlled in this gap as she 
learned a sufﬁciently reliable (likelihood) mapping between the left backhand goal and the corresponding sequence 
of segments.
Crucially, we assume that the quality of the likelihood mapping of the learner’s generative model determines her 
semantic understanding of the observed actions. Speciﬁcally, a strong likelihood mapping between two levels of the 
action representation hierarchy affords a deep, semantic understanding of the action meaning. Conversely, a weak (or 
ﬂat) likelihood mapping cannot afford semantic understanding. This is because the likelihood mapping establishes a 
link between the different levels of action description in the hierarchy of Fig. 1. Learning a likelihood mapping creates 
a link between two representation levels, therefore expanding the learner’s action vocabulary with novel conceptual 
representations. Furthermore, and importantly, this learning process grounds the novel action representations at higher 
100
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
hierarchical levels into sensorimotor experiences at lower hierarchical levels – which is key for semantic understanding 
within theories of embodied and grounded cognition [8,124,143,162]. The embodied approach argues that processing 
conceptual representations requires eliciting sensorimotor experiences, for example, by simulating them [163]. Motor 
representations are then automatically elicited when we activate conceptual representations [4,62,109], as shown in the 
context of language [17–19,37,71]. Note that here the term “sensorimotor experiences” should be intended broadly, 
to encompass multiple exteroceptive, proprioceptive and interoceptive modalities – all of which can become linked to 
action representation during the learning of likelihood mappings.
In sum, conceptual-semantic learning is the process that allows a novel, meaningless action to be associated with 
semantic meaning by establishing links between action representations across hierarchical levels, such as between 
conceptual representations of the action vocabulary and sensorimotor processes. This perspective implies that a novel 
observed action has no semantic meaning until the connections between higher and lower levels of description of the 
action (or likelihood mappings) are established. Until semantic meaning (in the sense described above) is established, 
the learner will be able to discriminate between actions at the kinematic level, but not to understand their meaning 
or the underlying intention – as these actions are neither present in her action vocabulary, nor they are linked to 
any existing intention [140,139]. In this condition, their representation is supposed to be episodic in memory but not 
semantic [154]. This distinction between a shallow level of action understanding that only involves its kinematics and 
a deeper level that also involves proximal goals and intentions is crucial when the representation is used to execute an 
action, such as during imitation, as we illustrate in the next simulation.
2.4. Simulation 4: facilitation and interference between observed and executed actions
There is increasing evidence that the neuronal underpinnings of action execution and observation are largely shared, 
at least in humans and other primates (but also possibly in other animals). This was most iconically demonstrated by 
the discovery of mirror neurons: a set of neurons (originally found in the pre-motor area F5 of the macaque, [41]) that 
discharge both during the observation of an action directed to an object and its execution. Mirror neurons are part of 
a much wider action-observation network (AON) constituted by three bilateral cortical areas reciprocally connected: 
the ventral premotor cortex, the inferior parietal lobule, and the superior temporal sulcus [135]. Further studies have 
suggested that the engagement of the mirror system depends on the observer’s motor knowledge [3,29,28,34,120]. 
To explain the above ﬁndings, various researchers have proposed that action observation and understanding are based 
on motor resonance and the automatic activation of the motor system in the observer’s brain [136,137]; on a “motor 
simulation” of the observed action in one’s own nervous system [3,29,28,34,65,69,87,120]; or on shared (ideomotor) 
neural codes for perception and action [76,83].
Another convergent line of research has shown that action observation and execution reciprocally and continuously 
inﬂuence each other: observing an action can produce automatic visuomotor priming [22] and the automatic imitation 
of the same action [74,160]b u t interferes with the simultaneous execution of different actions [92]. Observing an 
action compatible with the performed movement (e.g. lifting the index ﬁnger while observing an index ﬁnger moving 
upwards) facilitates reaction times, whereas observing a movement incompatible with the performed one slows down 
reaction times and accuracy (e.g. lifting the index ﬁnger while observing a ﬁnger press [22]) – possibly, because both 
actions need to be simultaneously encoded in the mirror system [30].
In this simulation, we illustrate how the model accounts for automatic facilitation and interference effects, given 
that its representations of (beliefs about) actions are shared across perception and action in the model hierarchy. We 
compare two cases: in the ﬁrst case (left panels of Fig. 6), the learner is instructed to observe an action (left smash) and 
then to produce an imitative response. In the second case (right panels of Fig. 6), the learner is instructed to observe 
the left smash action but to produce an incongruent action (a left forehand).
Fig. 6 shows that observing an action facilitates the execution of congruent, imitative responses (left panels) but 
interferes with the execution of incongruent actions (right panels) as shown empirically. This becomes evident by 
considering that during the execution of the same (left smash) action, the beliefs about policies (see the Methods) are 
more uncertain in the E panel on the right compared to the E panel on the left.
101
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
Fig. 6. Results of Simulation 4: the dynamics of motor priming (left panels) and interference (right panel) for two learners. The left learner observes 
a left smash and imitates the same action (motor priming). The right learner observes a right forehand but executes a left smash (motor interference). 
The discrepancy can be observed in the less precise “target segments” in the E panel to the right, where the grey tint indicates candidate target 
segments that correspond to the observed sequence 1-3-2-3. The panels follow the same notation as Fig. 2: the panels A-C show belief dynamics at 
the levels of intentions, proximal goals and movement segments, respectively. Panel D shows observations and Panel E shows imitative responses.
2.5. Summary and discussion of the simulations
The simulations described in this section help illustrate the key mechanisms of active inference that are relevant 
to model how we understand and imitate actions. Here, we summarise them by highlighting three main points. First, 
action observation and understanding can be cast as inferential processes that engage active information-gathering 
strategies (see Simulation 1). Understanding an action requires a hierarchical generative model to produce a cascade 
of perceptual hypotheses and predictions (about what action one is currently observing, the sequence of motor acts 
and the ensuing observations) and active sampling strategies to test the predictions by selecting the most salient 
observations. That an action repertoire is hierarchically arranged is a common assumption across theoretical and 
neurobiological studies [70,81,114]. Here, we move from theoretical descriptions of hierarchies to a fully implemented 
computational model. Our proposal emphasises that the hierarchical action representation constitutes a generative 
model that supports inferential dynamics and the active selection of relevant information. This perspective, therefore, 
aligns action understanding to a broader view of predictive coding and inference in the brain [52,53,56,119,130,128].
Second, there is a fundamental difference between oculomotor dynamics during the observation of familiar actions 
(Simulation 1 and 2) versus novel actions (Simulation 3). In the former case, when the observed action is already 
part of the learner’s action repertoire (and generative model), oculomotor strategies are guided by the imperative of 
reducing uncertainty about what action one is observing. In the latter case, when the action is not part of the learner’s 
action repertoire (and generative model), oculomotor strategies are guided by novelty-seeking. Importantly, the two 
imperatives of uncertainty-reduction and novelty-seeking emerge naturally from the active inference framework (and 
in particular from the expected free energy equation, see the Methods). In both cases, the observation policy maximises 
information gain; however, the type of uncertainty is different during the observation of familiar and novel actions. 
102
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
In the former case, the model needs to resolve uncertainty about the hidden states causing the observations (this is 
called hidden state exploration and is driven by salience). In contrast, in the latter case, the model needs to establish 
how hidden states generate outcomes driven by uncertainty about the model parameters (this is called parameter 
exploration and is driven by novelty). Notably, these two imperatives prescribe two different behaviours [147]. Hidden 
state exploration predicts that the learner actively seeks salient observations that allow for unambiguously inferring 
the hidden states that generate the outcomes. In contrast, parameter exploration predicts that the learner actively seeks 
for novel combinations of hidden states and outcomes, because this determines the learning of how outcomes are 
generated. Only via this novelty-seeking behaviour can the learner acquire knowledge about the relationships between 
different levels of action representation and between hidden states and observations (for novel actions), hence ﬁlling 
the gaps in her generative model. This is important insofar as we assume that the meaning in action semantics emerges 
from pursuing novelty across the multiple hierarchical levels of action representation. Novelty is the computational 
aspect essential to build long term representations as it represents a form of ignorance: by exploring novel visual 
locations the “novel” becomes familiar and ignorance is solved. The learner can still track novel actions without an 
integrated action representation, but this would not correspond to a deep semantic representation in our account.
Third, in the proposed model, hierarchical action representations and internal models are shared across action 
execution and perception. The sharing can prime the execution of actions that are congruent with an observed action 
and interfere with incongruent actions. This is important insofar it highlights the importance of engaging one’s action 
repertoire during the observation of actions executed by others, as highlighted by a large body of neurobiological 
evidence -a s we will elaborate below.
3. Neurobiological underpinnings of the proposed model
So far, we have described the functioning of the hierarchical active inference model but disregarded its relations 
with neurobiological ﬁndings about action execution and understanding. Here, we brieﬂy discuss the ways the hier-
archical active inference model links to neurobiological ﬁndings about the functioning of dorsal and ventral visual 
streams and the action observation network.
3.1. Mapping the model’s computational strategies into the multiple-routes model for action understanding
Simulations 1, 2 and 3 suggest that the visuomotor system recapitulates and solves the trade-off between engag-
ing explorative saccades and goal-directed saccades at the neurocognitive level (see the Methods for the rationale). 
Furthermore, the visuomotor system solves the trade-off between salience and novelty-driven exploratory behaviour, 
which is particularly relevant for modulating learning. To recap, both novelty and salience (as Bayesian surprise) elicit 
attentional capture and arousal that direct appropriate responses and enhance learning. Even though they are usually 
confounded, they are distinct concepts: while novelty is associated with acquiring representations (as we showed), 
surprise relates to improving predictions. Indeed, novelty entails a divergence from memory, while surprise entails a 
divergence from expectations [9]. Thus, the fundamental prediction of our formalisation is that during action observa-
tion, if the context allows for learning, observation will be driven by both novelty and surprise. On the opposite side, 
when observation is restricted on inference about movement kinematics it will be driven only by surprise. We suggest 
that surprise and novelty might recruit partially distinct neuronal circuits and computational strategies. A strategy 
named parameter exploration [147]i s driven by visual novelty and is engaged to obtain meaning about actions, which 
translation is associated with skilful motor control. A strategy named hidden states exploration is driven by salience 
(Bayesian surprise) and is engaged to recognize the kinematic aspect of actions, and the motor translation is associated 
with short-term, online, sensorimotor, and ﬂexible responses.
This description ﬁts well with multiple-routes models for action understanding, tool-use and imitation. A two-
routes cognitive model (initially proposed by Rothi et al. [141], and later developed by others (e.g., Buxbaum & 
Randerath [25]; Cubelli et al. [36]; Rumiati & Tessari [144]; Tessari et al. [155]); based on the study of apraxic patients, 
proposes that the visuomotor system, during the translation of the visual input (gestures or objects) into a motor 
program (the corresponding action), can follow a semantic route recalling conceptual and semantic representations of 
action, or a direct route that bypasses semantic information transforming the visual input into a motor act. Here, we 
propose a parallelism: within the semantic route, actions are observed according to salience and novelty-driven visual 
attention and then imitated according to procedural motor control (see the Methods for an illustration of how motor 
103
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
control is implemented in the model). On the other hand, within the direct route, actions are observed according only 
to salience-driven attention and imitated according to a form of non-conceptual goal-directed motor control. These 
goals are motor goals as interpreted by the theory of direct matching imitation as the GOADI [166]. Here, the observed 
movement is not imitated as a whole, but decomposed into simpler motor chunks that are executed individually. In 
our model, these chunks are encoded as goals to be achieved at the Action Execution level. Therefore, we suggest 
that the two routes may encode two distinct cognitive and behavioural strategies that correspond to the salience-driven 
hidden state’s exploration over movements with motor goal-directed control for the direct route and both novelty-
and salience-driven parameters exploration with procedural control for the semantic route. Furthermore, semantic 
encoding is hierarchical in terms of cognitive representation, which is also reﬂected in the neuroanatomy as it will be 
explained soon. Our prediction is supported by studies in the context of imitation where, when the context is not stable 
enough, the cognitive strategy for action recognition and imitation is empowering the direct route with surprise-driven 
exploration (hidden state exploration) even when meaningful actions are displayed (see [158,156,155,154,159]). The 
alternative strategy (parameter exploration) is engaged when there are enough stable regularities in the world to be 
learned. Therefore, surprise-driven hidden state exploration will be useful in conditions where behaviour must be 
adapted to trial-by-trial changes.
Similarly, our account of the two strategies can be associated with the two-action system model for encoding object 
affordances in the context of tool use: one pathway entails affordances based on objects structure and is specialised for 
visuomotor interactions with objects based on currently observed visual information, such as shape, size, and location 
that are constantly updated and processed online (i.e., the Structure system). The other pathway entails their functional 
manipulation and relies upon long-term, conceptual representations and extracts the features of the action that remain 
constant across occurrences (i.e., the Function system; [13,84]). Once again, at the computational level, the Structure 
system resembles the idea of surprise-driven hidden state exploration and motor goal-directed control. The Func-
tion system resembles what we have proposed for novelty-driven parameter exploration, as it permits extracting the 
constant features of the action and learning the contingencies between kinematic and higher-level, semantic aspects.
The cognitive processes underlying the two routes have been extensively investigated in several neuropsychological 
studies with brain-damaged patients with a focus on the neural and cognitive correlates of imitation of familiar and 
novel actions [1,2,10,36,67,107,121,145,155] and support a network in the left hemisphere: lesions of the ventro-
dorsal stream (from medial superior temporal area, MT/MST, to the inferior parietal lobule, and then to the ventral 
premotor cortex) produce impairments to more conceptual aspects of action representation, such as skilled use and 
pantomime of objects (e.g., [105,106,156,155]). On the contrary, the direct route and the processing of new movements 
have been associated with the dorso-dorsal stream (from V3a to V6 to V6a, to the superior parietal lobule, and then 
to the dorsal pre-motor areas [13,75,105,108,156,155]). At last, the processing of known gestures and the semantic 
route have been related to regions belonging to both the ventral (from V2 and V4 to the posterior inferotemporal, 
the central and the anterior inferotemporal areas) and the ventro-dorsal streams [75,105,106,134,145,156,164,165], 
suggesting that the ventral stream might decode the meaning of a movement (and intransitive gestures particularly), 
and the ventro-dorsal stream the tool-related, meaningful gestures. The dorso-ventral structures also allow us to infer 
the possible functions from structure [13,66,73] and can discover the alternative functions of familiar tools [73,142]. 
This ability recalls the parameter exploration strategy we have argued to emerge during learning.
In sum, we propose that there is a correspondence between the salience-driven, low-level hidden state exploration 
plus the motor goal-directed control (at the computational-cognitive level of description), the direct route (at the 
algorithmic level) and the dorso-dorsal route (at the anatomical level). On the other hand, we propose a correspondence 
between salience and novelty-driven parameter exploration plus procedural control (at the computational-cognitive 
level), the semantic route (at the algorithmic level) and the ventral and ventro-dorsal streams (at the anatomical level). 
Finally, higher semantic aspects, such as abstract and symbolic representations, can be associated with the ventral 
stream. See Fig. 7 for a graphical illustration of this proposed taxonomy.
3.2. The action observation network
In simulation 4, we investigated the interactions between action observation and execution. It has been proposed 
that these two processes reciprocally and continuously inﬂuence each other, since motor and visual knowledge share a 
common representation [64]. In our model, understanding and execution are inﬂuenced by a common memory param-
104
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
Fig. 7. A putative neural implementation of the proposed hierarchical model (a modiﬁed version of the neuro-cognitive model proposed by Tessari, 
Proietti & Rumiati [ 158], on Cognitive Neuropsychology). Visuomotor cognition is distributed onto multiple routes in the dorsal and ventral 
pathways. According to our proposal, the dorso-dorsal stream is mainly dedicated to lower-level aspects of action representations, the dorso-ventral 
pathway affords more general aspects of action semantics and the ventral stream is dedicated to the most abstract features. Please see the main text 
for explanation.
eter, as shown in simulation 2 (and in details in the Methods), where prior experience (including motor knowledge) 
can inﬂuence eye movements at the observation level.
At a neurophysiological level, the mirror neuron system (a cortical circuit connecting the ventral premotor cortex, 
inferior parietal lobule and superior temporal sulcus) was associated with understanding the meaning of the observed 
(object-oriented) action by extracting and representing its meaning and goal [50,136,135]. This has led to the direct-
matching hypothesis [77] that argues that action understanding occurs when the visual representation of the observed 
action is mapped onto the observer’s own motor representation of the same action. More recently, a predictive coding 
account of the mirroring phenomenon has been advanced: it has been proposed that the mirror neuron system follows 
a predictive coding scheme in relation to action observation where the most likely cause of the observed movement 
is inferred by minimising prediction error in the cortical hierarchy of the action-observation network (AON; [58,91]). 
Generally speaking, on the predictive coding account, what the visuomotor system does during action observation 
is resolving the inverse (inference) problem created by the one-to-many mapping of action-to-goals. For this, the 
visuomotor system represents the best explanation of the observed action as a generative model (p(goal | movement)), 
where the AON predicts the sensory consequences of what would be the most likely set of movements to be executed 
to achieve that goal. The predictive coding scheme supports the continuous comparison between the predicted sensory 
information and the actual sensory input, and ultimately the inference of the action goal (when prediction error is 
minimised). A crucial assumption is that mirror neurons discharge during the observation of an action because they are 
part of the same generative model that predicts the sensory input related to that action [58,91]. Hence, the functional 
role associated with the mirror neuron system is predictive action monitoring. Motor resonance is not achieved by 
a direct matching mechanism but by emulative action inference or motor, embodied, simulation [35,63,86,85,123]. 
Please note that the predictive coding formalisation is very similar to the Bayesian belief updating method adopted in 
our model, with two main differences. First, our model is formulated in discrete time, whereas predictive coding is 
formulated in continuous time – which implies not just a formal difference but also a different form for the “neuronal 
message passing” in the two schemes (see [119]f o r details). Second, and importantly, here we use active inference, 
which extends predictive coding to also cover action dynamics. In the model proposed here, the generative model 
105
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
(putatively corresponding to the AON) supports oculomotor control in addition to movement prediction. In other 
words, our model would imply the AON and the mirror neuron system in the active perception of observed movements 
[43]–  a hypothesis that remains to be tested in future studies.
4. General discussion
We have shown how action observation, understanding and execution can be represented in a hierarchical active 
inference model to illustrate a plausible way of how the visuomotor system may compute visual information and 
translate it into a motor program.
Our model highlights that perception can be treated as an inferential process based on a hierarchical generative 
model, and is based on active information sampling strategies. Indeed, in the proposed model, building a perceptual 
representation requires an active process of selecting salient data to test the expectations of an internal generative 
model – and how this saliency can be inﬂuenced by prior information. Furthermore, our model highlights a funda-
mental difference between oculomotor strategies that are guided by uncertainty reduction and prior knowledge during 
the observation of familiar actions, versus novelty-seeking during the observation of novel actions. Crucially, pursuing 
novelty generates exploratory behaviour that permits acquiring knowledge about the relationships between the several 
levels of action representation. We argue that this novelty-based learning process is critical to acquire meaningful 
action semantics. In our model, the procedural memory [45–47] might correspond to cached priors (E) about policies 
that are learned over time and support incremental, implicit learning of rule- or pattern-based relations via repetitive 
exposures (e.g., [32,115]). This type of learning requires relatively few cognitive resources, and, although the learning 
process is gradual and slow, motor patterns can be applied quickly and automatically once acquired [152]u s i n g then a 
motor chunk retrieval process [156]. Through repetitive exposures and practice, the procedural memory system reﬁnes 
action policies and motor patterns, gradually improving performance and reducing prediction errors (see, [32,115], 
for similar assumptions).
Another relevant aspect of our model is that it reuses the same internal models and codes across action prediction, 
understanding and response preparation. Sharing common models and codes produces mirror responses, priming 
or interference effects, depending on the congruency between observed and executed actions. Finally, we discussed 
the putative neuroanatomical correlates of key mechanisms of the model. We highlighted that the different visual 
exploration and motor control strategies used by the model could map to different routes of visuomotor cognition 
within the dorsal and ventral pathways.
Interestingly, most of the appealing features of our simulations stem directly from the active inference, provid-
ing a general framework to model the functioning of control hierarchies, in which the different hierarchical levels 
are not modularized, but rather inﬂuence each other reciprocally [128,129]. While the idea that action perception, 
understanding and imitation exploit hierarchical representations is not novel [70,114], the computational implemen-
tation offered here could be used to produce more speciﬁc, quantitative predictions. One set of predictions regards 
the neuronal dynamics we expect to observe during action observation and imitation, if they correspond to (active) 
inferential processes, as assumed here. The belief dynamics plotted in Figs. 2-6 can be easily mapped into (simulated) 
neuronal population dynamics, using the methods illustrated by Friston et al. [56]. More broadly, the model proposed 
here would suggest that we should observe a hierarchy of action predictions during action observation, as it has been 
recently shown during natural language comprehension [72].
Another set of predictions regards the unique assumptions that our model makes about the structure of the genera-
tive model – and the ways messages are propagated from one level to the others during inference – which distinguish 
it from previous hierarchical and deep active inference models used to address (for example) reading dynamics [61]. 
For example, a novelty of our proposal is the fact that the Action Execution level (that is responsible for imitative 
responses in our simulations) is simultaneously inﬂuenced by the Action Understanding and the Action Observation 
levels, via different pathways; see the methods and Fig. 8 for a clariﬁcation of the mutual dependencies between levels. 
This organization of the model provides a formal perspective that permits understanding several experimental ﬁndings 
and formulating novel empirical predictions, which could be tested experimentally in future studies. For example, at 
the behavioural level, this model predicts that during the semantic learning of action, humans will vary their pattern 
of observation according to the amount of stimulus novelty and salience that drives the sampling of new saccade 
locations. This highlights the different contributions of novelty and surprise to attentional capture [9]. Furthermore, 
we extended the notion that cues and expectations can alter motor behaviour by showing that these alterations (e.g., 
106
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
[82]) can be level-of-representation-speciﬁc, as in the case of affordances. This may suggest further investigations of 
mirroring or motor resonance, which seems to be stronger at lower levels of representations (e.g., object-oriented ac-
tions) and to disappear as the action becomes more symbolic and abstracted [35]. The systematic testing of the model 
predictions in experimental conditions is an objective that we intend to pursue in future research. Indeed, the active 
inference framework has been used to simulate various neurological and psychopathological conditions, see Chapter 
9 of [119]. The hierarchical generative model for action understanding and imitation discussed in this paper might 
be particularly appropriate as a starting point to explore the cognitive processes and abnormalities of motor planning, 
sequencing, and execution associated with apraxia. Doing this would require expressing speciﬁc hypotheses about 
the causes of apraxia (or other disorders) in the form of elements of hierarchical active inference; namely, the priors 
and likelihood functions that specify the (hierarchical) relations between intentions, goals and actions. For example, 
it would be possible to hypothesise that ideational apraxia (which impairs action planning and selection on verbal 
command) stems from an imprecise likelihood mapping between states and observations at the intention level. Once 
these hypotheses are expressed in the form of a (hierarchical) active inference model, the model could be validated 
by simulating different scenarios and tasks that are relevant to ideational (or other, different types of) apraxia, by sys-
tematically comparing simulated behaviours with empirical data and clinical observations. Furthermore, it would be 
possible to use the model for advanced data analysis and to identifying speciﬁc parameters of the model that explain 
the symptoms of apraxia (or other disorders) in patient populations; see [93,99,126,146,148,149]f o r examples of this 
kind of “computational phenotyping” in computational psychiatry.
Finally, while the goal of the present papers was to propose a general formal (active inference) scheme for vi-
suomotor cognition, the proposed model could be further elaborated by including more realistic and detailed motor 
control models that permit simulating sophisticated behavioural tasks, beyond the simple tennis example used here by 
associating the kinematic level with a generative model for continuous variables, as shown in [118] and [116].
5. Methods
In this section, we provide a summary description of the active inference framework and introduce the hierarchical 
generative model that we used to realise the simulations of this paper.
5.1. Active inference under the free energy principle
Active inference is a recent formal framework to explain cognition and behaviour that is gaining prominence 
across multiple domains of cognitive science and neuroscience [119,129]. Active inference derives from the free 
energy principle, which describes in statistical and information-theoretical terms how a biological agent restricts itself 
within a limited set of sensory states to avoid the natural tendency to reach thermodynamic equilibrium and, as a 
consequence, death [51]. A key assumption of active inference is that to avoid surprising and potentially disruptive 
sensory states, the agent must encode and update a probabilistic generative model, or a probabilistic mapping between 
sensory states and the present and future observations that they generate. The generative model serves to implement 
approximate (variational) free energy minimization that -i n active inference - implements both perception and action 
planning. Speciﬁcally, in addition to the generative model, variational inference requires an auxiliary distribution 
(aka recognition density q) that encodes an approximate posterior over the agent’s beliefs; see [11]u s e d to minimise 
approximate surprisal in the present (variational free energy) and in the future (expected free energy).
5.2. V ariational free energy (F)
Variational free energy is minimised to perform perception and perceptual learning, by estimating posterior beliefs 
about hidden states. The equation below shows how the variational free energy (F) for a given policy π (sequence of 
actions) is calculated. Variational free energy can be decomposed into two terms. The former is a complexity term that 
scores a (Kullback Leibler or KL) divergence between the posterior beliefs about states of the auxiliary distribution 
(q(s|π)), and the posterior beliefs about states of the generative model (p(s|π)). The latter is an accuracy, which scores 
(logarithm of the) the probability of observations given model beliefs about states (ln p(o|s)). These two terms jointly 
ensure that the agent engages in a continuous perception-action cycle; namely, it updates its (posterior) beliefs about 
107
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
the states represented on the model to better ﬁt its observations; and selects courses of actions that actively sample the 
observations predicted by the model; please see [56]f o r a derivation of variational free energy and technical details.
F(π)  
Variational FE
= DKL[q(s | π) || p(s | π)]  
Complexity
−Eq(π)[lnp(o | s)]  
Accuracy
5.3. Expected free energy (G)
Active inference can also be used to model planning, which corresponds to selecting a course of actions that 
minimises the agent’s free energy in the long run. Planning consists in inferring the variables upon which the states 
that can be controlled are conditioned on. This requires calculating and minimising another formal quantity, the 
expected free energy associated to each policy π. Once the expected free energy of each policy is calculated, it is 
translated into a prior value of policies p(π) through a softmax function. Using this prior value for action selection 
ensures that the selected policies are those expected to minimise more free energy in the long run.
As shown in the equation below,
G(π)  
Expected FE
= DKL[q(o | π) || p(o)]  
Risk
+Eq(π)[H[p(o | s)]]  
Ambiguity
expected free energy (G) can be decomposed in two terms. The former is risk, which scores the (KL) divergence 
between the probability of outcomes given a policy (q(o|π)) and the distribution of preferred outcomes in the agent’s 
generative model (p(o)). The latter is an expected ambiguity, which scores the expected value of the entropy (H) of 
the model’s likelihood function (p(o|s). Taken together, these two terms ensure that the agent plans adaptively and 
balances exploitation (or utility maximisation) and exploration (or information gain). Minimising risk leads to the 
exploitation of preferred observations and determines goal-directed behaviour. This is because by minimising the 
ﬁrst term, the agent comes closer to its preferences or goals. Minimising ambiguity generates instead exploratory, 
information-seeking behaviour that aims to minimise the uncertainty about the states of the world.
In sum, expected free energy drives an agent to maximise utilitarian behaviour and explore all options in a way 
that confers an exploratory aspect upon behaviour. Expected free energy represents a single objective function shared 
by information-seeking behaviour and the achievement of prior preferences. It is worth noting that in most practical 
settings, when there is uncertainty about what course of actions will be more effective, the agent needs to minimise 
ambiguity ﬁrst (to reduce the uncertainty) before being able to minimise risk (to achieve goals). This solution to the 
problem of balancing exploration and exploitation emerges automatically in active inference [60].
5.4. Policy selection
Once expected free energy has been calculated, the policy is selected according to the following equation, which 
represents a (prior) distribution over the policies:
π0 = σ(lnE − γG )
This distribution comprises two components. The former is a learned prior over the policies (an E vector), which 
reﬂects the number of times a policy has been previously selected and can be considered a habitual component of 
policy selection. The latter is the expected free energy G that is calculated anew at each simulation and can be 
considered a deliberative component of policy selection. The balance between these two terms is determined by a 
precision term (γ), which encodes the conﬁdence of beliefs about G. Finally, the equation includes σ, which is a 
normalised exponential (softmax) function that normalises its values to ensure that it is a probability distribution.
5.5. The hierarchical generative model used in the simulations
Active inference is a generic framework to model cognitive phenomena but realising each set of simulations re-
quires designing a speciﬁc generative model. To realise the simulations reported in this article, we used the hierarchical 
generative model shown in Fig. 8. The hierarchical arrangement of the generative model shown in Fig. 8 reﬂects – and 
108
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
Fig. 8. Schematic of the hierarchical generative model used in this article. (A) The Action Understanding level. At this level, there are two hidden 
state factors and two outcome modalities. The ﬁrst factor is the proximal goal performed by the teacher (the sequence of segments) while the second 
factor is the categorization of the intention. The two outcome modalities are exteroception and feedback. (B) The Action Observation level. At this 
level, there are two hidden state factors and two outcome modalities. The hidden factors are the three possible segments of the teacher and the four 
possible eye positions of the agent. The two outcome modalities are exteroception (what) and proprioception (where). (C) The Action Execution 
level. At this level, there are one hidden factor and one outcome modality. The hidden factor is the segment executed. The outcome modality is 
proprioception. The notation used in the generative model follows standard conventions to describe generative models under active inference [56]. 
Nodes denote probability distributions and edges denote probabilistic relations between them. The capitalised letters A-E denote the matrices of 
the model: the A (likelihood), B (transition function), C (prior over observations), D (prior about hidden states), E (prior about policies) matrices. 
The G denotes expected free energy. The lowercase letters a, d and e denote parameters of the respective matrices. The lowercase letters s, o and 
π denote hidden states, observations and policies, respectively. The symbol γ is a precision parameter used for policy selection. See the main text 
and [61]f o r technical details.
109
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
formalises – the hierarchical organisation of action representations shown in Fig. 1; see [61,111]f o r related models in 
active inference and [20,52,88,89,95]f o r a broader view of hierarchical models in the brain.
In the generative model shown in Fig. 8, hidden state factors correspond to different states of the world, such as 
the location (where) and category (what) of an element (e.g., the teacher body parts). Outcome modalities correspond 
to the possible observations. Multiple outcome modalities are involved in accounting for parallel sources of sensory 
input, such as visual inputs and proprioceptive sensations.
The generative model is organised as a partially observable Markov decision process (POMDP) that entails two 
general features. The ﬁrst is the partial observability, which means that the true states of the world are hidden and can 
only be inferred by observations that may have a degree of uncertainty. The second feature is the Markov property, 
according to which beliefs about future states, on which the agent organises its behaviour, depend only on the states 
at the current time and not on the past ones [56].
Our generative model comprises three levels that are reciprocally connected. The Action Understanding level 
models the inference of proximal goals from segments and of intentions from proximal goals (hence formalising the 
functioning of levels 3 and 4 in Fig. 1). The Action Observation level models the recognition of movement kinematics 
and segments (hence formalising the functioning of levels 1 and 2 in Fig. 1) as well as action observation dynamics, 
or the active sampling of information. Finally, the Action Execution level models motor responses.
Action recognition exploits the reciprocal connections between the Action Understanding and the Action Observa-
tion levels. The hidden states at the Action Understanding level are propagated top-down to inﬂuence states transitions 
at the Action Observation level, by setting their prior beliefs [61]. In other words, the Action Understanding level gen-
erates the hypotheses that are tested by engaging saccades at the Action Observation level. On the other hand, the 
posterior beliefs about segments at the Action Observation level are propagated bottom-up and become observable 
outcomes at the Action Understanding level [61]. This provides bidirectional interactions between variables at dif-
ferent levels of the hierarchy, because the inference of each latent variable is simultaneously inﬂuenced by messages 
passed from different directions.
Please note also that as usual in hierarchical models, state transitions at different levels proceed at different time 
rates. Speciﬁcally, the Action Understanding level proceeds at a slower time rate because to generate an outcome at 
each time step, it must “wait” for all the outcomes from the Action Observation level. In our simulations, to categorise 
a sequence of segments and their goal, the agent employs ﬁve timesteps, each requiring at most four timesteps of 
segment categorization at the Action Observation level. Various studies have shown that the different routes of action 
processing can have different time courses. Long-term sensorimotor representations are processed slowly, require an 
active maintenance of information for relatively long periods [13], [24] and are driven by a relatively long-lasting 
activation of the ventro-dorsal stream. On the other hand, visually-derived information about the environment used to 
guide reaching and grasping movements is rapidly activated and processed online in the dorso-dorsal stream [13], but 
it is more transient and decays more rapidly [131,138]
In addition, the simulated reaction times are obtained by running the toc function in Matlab to evaluate the time 
employed for the categorization of each segment and the associated proximal goal.
The execution of motor actions exploits the reciprocal connections between all three levels. The translation from 
observed movements into goals occurs at the Action Understanding level, whereas the translation from goals into 
procedural motor responses uses the connections between the Action Understanding and Action Execution levels. 
Finally, goal-directed motor responses occur thanks to the connections between the Action Observation and Action 
Execution levels. Please see below for a discussion of procedural versus motor goal-directed pathways in the model. 
Note that the Action Execution level proceeds at its own pace and it is not temporally linked to the other levels.
The generative model shown in Fig. 8 generates outcomes as follows: a policy is selected at the Action Understand-
ing level using a softmax function of expected free energy. The state-transition probabilities (B matrices) prescribed 
by the selected policy determine the sequence of hidden states. These hidden states generate outcomes at this level 
(through the A matrixes) and the initial hidden states at the Action Observation level (through to the D vectors). Please 
note that during inference, new observation can lead to a revision of hidden states and of the expected free energy (via 
the C matrices), hence inﬂuencing policy selection. This means that the agent starts acting driven by a given policy 
but can select new policies along the way based on new observations.
Computationally, the agent solves the task by engaging in approximate Bayesian inference and (variational) belief 
updating [11]. Variational Bayes is based on introducing an arbitrary distribution called variational density or recog-
nition density q(s) and rendering it maximally similar to the true posterior probability of the generative model p(s|o). 
110
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
This is done by assuming a speciﬁc form for q (e.g., Gaussian, known as the Laplace assumption, see [59]) and then 
optimising it by the iterative updating of its sufﬁcient statistics through a gradient descent algorithm. Interestingly, 
active inference assumes that this form of variational inference can be directly mapped into a set of hypotheses about 
how messages are transmitted at the neural level and used to predict neuronal responses during hidden states estima-
tion and action selection [56,57]. Under the hypothesis that the brain encodes a generative model of its sensations, and 
that different groups of neurons encode the beliefs speciﬁed in the generative model (e.g., beliefs about intentions, 
proximal goals and segments), the belief dynamics illustrated in Figs. 2-6 can be equated to the dynamics of neural 
activity of these groups of neurons, which evolve in a way that minimise free energy.
5.6. Action recognition dynamics are driven by salience and/or novelty, in context-dependent ways
Action recognition dynamics are guided by different drives, depending on the context. In the context of familiar, 
meaningful actions (Simulations 1, 2 and 4) observation policies are driven by the need to reduce uncertainty about 
hidden states. This uncertainty is represented by Bayesian surprise as it scores the divergence between the predicted 
and the actual outcomes. Generally speaking, the model tends to predict a familiar sequence of segments that it has 
seen most often in the past (see below) and that are encoded into prior beliefs over the initial states D at the Action 
Understanding level. Hence, when recognising a familiar, meaningful action, high-level prior expectations generate 
hypotheses about movement kinematics that are veriﬁed by engaging epistemic actions – eye movements that sample 
information to reduce uncertainty. Eye movements are directed towards salient locations, which are the locations that 
the model expects to reduce uncertainty the most, if a saccade were performed towards them [43,54,117]. In this 
perspective, salience is deﬁned as information gain, or the potential resolution of uncertainty about hidden states [60].
The observation of novel actions (Simulation 3) is substantially different from the observation of familiar actions, 
as the model has the opportunity to learn novel contingencies between proximal goals and segments. In our model, 
these contingencies are encoded in the (a parameters of the) A matrix that links hidden states (proximal goals) and 
outcomes (segments) at the Action Understanding level. Crucially, when the model is allowed to learn (a) parameters, 
the expected free energy equation has to be expanded to include a new (novelty) term:
G(π)  
Expected FE
= DKL[q(o | π) || p(o)]  
Risk
+Eq(π)[H[p(o | s)]]  
Ambiguity
−Ep(o|s)q(s |π)[DKL[q(A | o,s) || q(A)]]  
Novelty
The novelty term in this expanded equation scores how much the beliefs in the a parameters (mapping states to 
outcomes) are expected to change after a new observation. In turn, including this new term in the expected free energy 
ensures that the agent will tend to select policies that pursue novelties. This entails a form of active learning, during 
which the active inference agent will preferentially look at (novel) locations that it expects to change the a parameters 
the most [147]. In sum, the expanded free energy equation highlights the importance of engaging in two forms of 
exploratory behaviour, which are guided by salience and novelty, respectively. While pursuing salience is useful to 
reduce the uncertainty about hidden states (or ambiguity), pursuing novelty is useful to reduce uncertainty about model 
parameters (or ignorance).
5.7. Two varieties of model learning: model expansion and statistical sequence learning
The model engages in two varieties of learning. The former kind of learning is a model expansion. As discussed 
above, in Simulation 3, we allowed the model to expand its repertoire of semantic action representations by learning 
novel contingencies between proximal goals and segments in the A matrix. This has been done by setting a column that 
encodes one of the proximal goals (left backhand) in the A matrix as a uniform distribution. This way, the likelihood 
mapping for that state entails equal probability for all observations, carrying no information. We allowed learning over 
12 consecutive trials, but we prevented the learner from trying to recognize the left backhand during the ﬁrst 11 trials 
learning. By doing so, we ensured that the learning of the left backhand was done in an unsupervised manner, without 
feedback from correct or incorrect recognition, which would have been misleading in early learning phases; see [150]
for a similar approach.
The latter kind of learning is a process of statistical sequence learning. When the process of action recognition is 
repeated for multiple trials, the agent accumulates information over time and acquires familiarity with the observed 
111
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
sequences of segments. Formally, the agent sequentially updates its prior beliefs about sequence of segments, by 
accumulating Dirichlet distributions in the d parameter [11,15,55]. This statistical learning process ensures that the 
agent can assign a higher prior probability to the sequences of segments that were observed more often in the past.
5.8. Motor control and its two components: procedural and goal-directed
The model determines the selection and control of imitative responses by two components. The ﬁrst component is 
the posterior belief about the proximal goals, as encoded by the prior beliefs over the policies (E) and the associated 
e parameter at the Action Execution level. The e parameter constitutes a form of procedural motor knowledge that 
guides action selection in a habitual manner - which means that the agent expects to execute the (next action in the) 
sequence it has observed more often in the past. The second component that determines action selection is the posterior 
belief about the (recognized) segments, which – via a form of visuo-spatial working memory [27,98]–  inﬂuences the 
agent’s prior preferences (C) and hence in turn the expected free energy (G). In short, the agent expects to execute the 
same action that it has inferred by observing the teacher’s movements. We consider the former a procedural memory 
[45–47]a s it uses cached (E) values that are learned over time and the latter a motor goal-directed form of control as 
it uses expected free energy (G) computations that take the agent’s prior preferences (C) into account.
Which speciﬁc action is executed depends on the weight given to the procedural (E) and motor goal-directed (G) 
components. The relative inﬂuence of the two components is determined by the parameter γ (gamma) that corre-
sponds to the precision of beliefs about the expected free energy. This process of precision weighting corresponds to 
attentional modulation at the cognitive level and to synaptic gain at the neurophysiological level [31,48,117]. In our 
simulations, the modulation of the γ parameter is implicated in the imitative responses for familiar and novel actions. 
When the learner observes a familiar action, the imitative response is mostly driven by the procedural memory (E) 
of the action sequence (the semantic, indirect route in the proposed model), while motor goal-directed control gen-
erated by G can be engaged with a lower level of precision, as a form of online monitoring of the movements (the 
direct route in the proposed model). Notably, by engaging procedural memories, the model processes an entire action 
sequence as a whole rather than evaluating its component actions one by one -a  mechanism that has been some-
times called “chunking” [21,40,39,110] and permits retrieving a known action as a whole from long-term procedural 
memory, without breaking it down into single motor components [156]. In active inference, this sequential knowledge 
is encoded in a (V) matrix that relies on prior beliefs about the policies (E). On the other hand, when the learner 
observes a novel action, she needs to rely on expected free energy (G) computations to perform a step-by-step online 
encoding and monitoring of the movement. In this case, the weight of the procedural component (E) is attenuated, 
reﬂecting the lack of prior experience. Hence, while in the former case imitative responses are more driven by pro-
cedural knowledge, in the latter case they are more driven in a motor goal-directed manner. This trade-off between 
motor goal-directed and procedural (or habitual) control strategies has been often related to a difference between 
model-based and model-free methods of reinforcement learning [38,44,94,101,100,125,127].
Interestingly, the two (procedural and goal-directed) components of action can trigger different actions in the case 
of non-imitative actions, as in Simulation 4. If the agent were instructed to execute a non-imitative action, the motor 
goal-directed (G) component would correctly infer the to-be-executed action. However, as discussed above, the agent’s 
procedural component (E) is implicitly tuned in a way to execute imitative actions. Hence, it would trigger an imitative 
response that interferes with the correct action; see the right panel of Fig. 6.
5.9. The contribution of mirror mechanisms to action observation, understanding and selection
In our model, mirror mechanisms contribute to action observation, understanding and selection in two main ways. 
First, the agent’s motor knowledge about action sequences encoded in the e parameter inﬂuences the d parameter that 
encodes prior expectations about the next observed actions, which guides in a cascade action observation processes 
[43,58]. In this way, the agent implicitly expects to observe the action sequence that she knows the most. Second, 
as discussed above, posterior beliefs about the (inferred) segments at the Action Recognition level become prior 
preferences (C) at the Action Execution level. This means that when a segment is recognized, the agent automatically 
prepares an imitative response that might facilitate the execution of congruent actions but impair the execution of 
incongruent actions, as often observed experimentally [23].
112
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
Software note
The computational model was implemented using standard routines (spm_MDP_VB_X.m) that are freely avail-
able as Matlab code in the latest version of SPM academic software: http://www.ﬁl .ion .ucl .ac .uk /spm/.
Declaration of competing interest
The authors declare no conﬂicts of interest.
Acknowledgements
This research received funding from the European Union’s Horizon 2020 Framework Programme for Research and 
Innovation under the Speciﬁc Grant Agreement No. 945539 (Human Brain Project SGA3) and 952215 (TAILOR) to 
GP, the European Research Council under the Grant Agreement No. 820213 (ThinkAhead) to GP, the PNRR MUR 
project PE0000013-FAIR to GP, and the European Union’s Horizon H2020-EIC-FETPROACT-2019 Programme for 
Research and Innovation under Grant Agreement 951910 (MAIA) to AT.
References
[1] Achilles EIS,  Ballweg CS, Niessen E, Kusch M, Ant JM, Fink GR, et al. Neural correlates of differential ﬁnger gesture imitation deﬁcits in 
left hemisphere stroke. NeuroImage Clin 2019;23:101915. https://doi .org /10 .1016 /j .nicl .2019 .101915.
[2] Achilles EIS, Fink GR, Fischer MH, Dovern A, Held A, Timpert DC, et al. Effect of meaning on apraxic ﬁnger imitation deﬁcits. Neuropsy-
chologia 2016;82:74–83. https://doi .org /10 .1016 /j .neuropsychologia .2015 .12 .022.
[3] Aglioti SM,  Cesari P,  Romani M,  Urgesi C.  Action anticipation and motor resonance in elite basketball players. Nat Neurosci 
2008;11:1109–16. https://doi .org /10 .1038 /nn .2182.
[4] Aziz-Zadeh L, Damasio A. Embodied semantics for actions: ﬁndings from functional brain imaging. J Physiol (Paris) 2008;102:35–9. https://
doi .org /10 .1016 /j .jphysparis .2008 .03 .012. Links and interactions between language and motor systems in the brain.
[5] Baker CL,  Saxe R,  Tenenbaum JB.  Action understanding as inverse planning. Cognition 2009;113:329–49. https://doi .org /10 .1016 /j .
cognition .2009 .07 .005. Reinforcement learning and higher cognition.
[6] Baker CL, Tenenbaum JB, Saxe RR. Bayesian models of human action understanding. Advances in neural information processing systems, 
vol. 18. MIT Press; 2006. p. 99–106.
[7] Baranes A,  Oudeyer P-Y , Gottlieb J. Eye movements reveal epistemic curiosity in human observers. Vis Res 2015;117:81–90. https://doi .
org /10 .1016 /j .visres .2015 .10 .009.
[8] Barsalou LW. Grounded cognition. Annu Rev Psychol 2008;59:617–45. https://doi .org /10 .1146 /annurev.psych .59 .103006 .093639.
[9] Barto A,  Mirolli M, Baldassarre G. Novelty or surprise? Front Psychol 2013;4:907. https://doi .org /10 .3389 /fpsyg .2013 .00907.
[10] Bartolo A,  Cubelli R, Della Sala S, Drei S, Marchetti C. Double dissociation between meaningful and meaningless gesture reproduction in 
apraxia. Cortex 2001;37:696–9. https://doi .org /10 .1016 /s0010 -9452(08 )70617 -8.
[11] Beal M. Variational algorithms for approximate Bayesian inference /. PhD thesis. 2003.
[12] Berlyne DE.  A theory of human curiosity. Br J Psychol 1954;45:180–91. https://doi .org /10 .1111 /j .2044 -8295 .1954 .tb01243 .x. General sec-
tion.
[13] Binkofski F, Buxbaum LJ. Two action systems in the human brain. Brain Lang 2013;127:222–9. https://doi .org /10 .1016 /j .bandl .2012 .07 .007.
[14] Blake A, Yuille AL, editors. Active vision. Artiﬁcial intelligence series. Cambridge, MA, USA: MIT Press; 1992.
[15] Blei DM, Ng AY , Jordan MI. Latent Dirichlet allocation. J Mach Learn Res 2003;3:993–1022.
[16] Bonini L.  The extended mirror neuron network anatomy, origin, and functions. Neuroscientist 2016:1073858415626400. https://doi .org /10 .
1177 /1073858415626400.
[17] Borghi AM, Barca L, Binkofski F, Castelfranchi C, Pezzulo G, Tummolini L. Words as social tools: language, sociality and inner grounding 
in abstract concepts. Phys Life Rev 2019;29:120–53. https://doi .org /10 .1016 /j .plrev.2018 .12 .001.
[18] Borghi AM, Binkofski F. The WAT proposal and the role of language. In: Borghi AM, Binkofski F, editors. Words as social tools: an 
embodied view on abstract concepts. SpringerBriefs in psychology. New York, NY: Springer; 2014. p. 19–37.
[19] Borghi AM, Cimatti F. Embodied cognition and beyond: acting and sensing the body. Neuropsychologia 2010;48:763–73. https://doi .org /10 .
1016 /j .neuropsychologia .2009 .10 .029.
[20] Botvinick MM.  Hierarchical models of behavior and prefrontal function. Trends Cogn Sci 2008;12:201–8. https://doi .org /10 .1016 /j .tics .
2008 .02 .009.
[21] Botvinick MM,  Niv Y , Barto AG. Hierarchically organized behavior and its neural foundations: a reinforcement learning perspective. Cog-
nition 2009;113:262–80. https://doi .org /10 .1016 /j .cognition .2008 .08 .011.
[22] Brass M,  Bekkering H,  Prinz W. Movement observation affects movement execution in a simple response task. Acta Psychol (Amst) 
2001;106:3–22. https://doi .org /10 .1016 /s0001 -6918(00 )00024 -x.
[23] Brass M,  Heyes C. Imitation: is cognitive neuroscience solving the correspondence problem? Trends Cogn Sci 2005;9:489–95. https://
doi .org /10 .1016 /j .tics .2005 .08 .007.
113
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
[24] Buxbaum LJ,  Kalenine S.  Action knowledge, visuomotor activation, and embodiment in the two action systems. Ann NY Acad Sci 
2010;1191(1):201–18. https://doi .org /10 .1111 /j .1749 -6632 .2010 .05447 .x.
[25] Buxbaum LJ,  Randerath J. Limb apraxia and the left parietal lobe. Handb Clin Neurol 2018;151:349–63. https://doi .org /10 .1016 /B978 -0 -
444 -63622 -5 .00017 -6.
[26] Byrne RW,  Russon AE.  Learning by imitation: a hierarchical approach. Behav Brain Sci 1998;21:667–84. https://doi .org /10 .1017 /
S0140525X98001745.
[27] Cai Y , Urgolites Z, Wood J, Chen C, Li S, Chen A, et al. Distinct neural substrates for visual short-term memory of actions. Hum Brain Mapp 
2018;39:4119–33. https://doi .org /10 .1002 /hbm .24236.
[28] Calvo-Merino B, Glaser DE, Grèzes J, Passingham RE, Haggard P. Action observation and acquired motor skills: an FMRI study with expert 
dancers. Cereb Cortex 2005;15:1243–9. https://doi .org /10 .1093 /cercor /bhi007.
[29] Calvo-Merino B,  Grèzes J, Glaser DE, Passingham RE, Haggard P. Seeing or doing? Inﬂuence of visual and motor familiarity in action 
observation. Curr Biol 2006;16:1905–10. https://doi .org /10 .1016 /j .cub.2006 .07 .065.
[30] Catmur C,  Walsh V, Heyes C. Associative sequence learning: the role of experience in the development of imitation and the mirror system. 
Philos Trans R Soc Lond B, Biol Sci 2009;364:2369–80. https://doi .org /10 .1098 /rstb.2009 .0048.
[31] Clark A.  The many faces of precision (Replies to commentaries on “Whatever next? Neural prediction, situated agents, and the future of 
cognitive science”). Front Psychol 2013;4. https://doi .org /10 .3389 /fpsyg .2013 .00270.
[32] Cohen MD,  Bacdayan P. Oganizational routines are stored as procedural memory: evidence from a laboratory. Organ Sci 1994;5:554–68. 
https://doi .org /10 .1287 /orsc .5 .4 .554.
[33] Collins RP, Litman JA, Spielberger CD. The measurement of perceptual curiosity. Pers Individ Differ 2004;36:1127–41. https://doi .org /10 .
1016 /S0191 -8869(03 )00205 -8.
[34] Cross ES,  de C. Hamilton AF,  Grafton ST.  Building a motor simulation de novo: observation of dance by dancers. NeuroImage 
2006;31:1257–67. https://doi .org /10 .1016 /j .neuroimage .2006 .01 .033.
[35] Csibra G,  Gergely G. ‘Obsessed with goals’: functions and mechanisms of teleological interpretation of actions in humans. Acta Psychol 
2007;124:60–78. https://doi .org /10 .1016 /j .actpsy.2006 .09 .007. Becoming an intentional agent: early development of action interpretation 
and action control.
[36] Cubelli R,  Marchetti C, Boscolo G, Della Sala S. Cognition in action: testing a model of limb apraxia. Brain Cogn 2000;44:144–65. https://
doi .org /10 .1006 /brcg .2000 .1226.
[37] Davis CP, Yee E. Building semantic memory from embodied and distributional language experience. WIREs Cogn Sci 2021;12:e1555. 
https://doi .org /10 .1002 /wcs .1555.
[38] Daw ND,  Niv Y , Dayan P. Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control. Nat 
Neurosci 2005;8:1704–11. https://doi .org /10 .1038 /nn1560.
[39] Dezfouli A,  Balleine BW. Actions, action sequences and habits: evidence that goal-directed and habitual action control are hierarchically 
organized. PLoS Comput Biol 2013;9:e1003364. https://doi .org /10 .1371 /journal .pcbi .1003364.
[40] Dezfouli A,  Lingawi NW, Balleine BW. Habits as action sequences: hierarchical action control and changes in outcome value. Philos Trans 
R Soc Lond B, Biol Sci 2014;369:20130482. https://doi .org /10 .1098 /rstb.2013 .0482.
[41] di Pellegrino G, Fadiga L, Fogassi L, Gallese V , Rizzolatti G. Understanding motor events: a neurophysiological study. Exp Brain Res 
1992;91:176–80. https://doi .org /10 .1007 /BF00230027.
[42] Dindo H, Zambuto D, Pezzulo G. Motor simulation via coupled internal models using sequential Monte Carlo. In: Proceedings of IJCAI 
2011; 2011. p. 2113–9.
[43] Donnarumma F, Costantini M, Ambrosini E, Friston K, Pezzulo G. Action perception as hypothesis testing. Cortex 2017;89:45–60. https://
doi .org /10 .1016 /j .cortex .2017 .01 .016.
[44] Donnarumma F, Maisto D, Pezzulo G. Problem solving as probabilistic inference with subgoaling: explaining human successes and pitfalls 
in the tower of Hanoi. PLoS Comput Biol 2016;12:e1004864. https://doi .org /10 .1371 /journal .pcbi .1004864.
[45] Engelkamp J,  Zimmer HD.  Memory for action events: a new ﬁeld of research. Psychol Res 1989;51:153–7. https://doi .org /10 .1007 /
BF00309142.
[46] Engelkamp J, Zimmer HD. Motor programs and their relation to semantic memory. Ger J Psychol 1985;9:239–54.
[47] Engelkamp J,  Zimmer HD. Motor programme information as a separable memory unit. Psychol Res 1984;46:283–99. https://doi .org /10 .
1007 /BF00308889.
[48] Feldman H,  Friston K.  Attention, uncertainty, and free-energy. Front Human Neurosci 2010;4:215. https://doi .org /10 .3389 /fnhum .2010 .
00215.
[49] Flanagan JR, Johansson RS. Action plans used in action observation. Nature 2003;424:769–71. https://doi .org /10 .1038 /nature01861.
[50] Fogassi L, Ferrari PF, Gesierich B, Rozzi S, Chersi F, Rizzolatti G. Parietal lobe: from action organization to intention understanding. Science 
2005;308:662–7. https://doi .org /10 .1126 /science .1106138.
[51] Friston K.  The free-energy principle: a uniﬁed brain theory? Nat Rev Neurosci 2010;11:127–38. https://doi .org /10 .1038 /nrn2787.
[52] Friston K.  Hierarchical models in the brain. PLoS Comput Biol 2008;4:e1000211. https://doi .org /10 .1371 /journal .pcbi .1000211.
[53] Friston K.  A theory of cortical responses. Philos Trans R Soc Lond B, Biol Sci 2005;360:815–36. https://doi .org /10 .1098 /rstb.2005 .1622.
[54] Friston K,  Adams R, Perrinet L, Breakspear M. Perceptions as hypotheses: saccades as experiments. Front Psychol 2012;3:151. https://
doi .org /10 .3389 /fpsyg .2012 .00151.
[55] Friston K,  FitzGerald T, Rigoli F, Schwartenbeck P, O’Doherty JP, Pezzulo G.  Active inference and learning. Neurosci Biobehav Rev 
2016;68:862–79. https://doi .org /10 .1016 /j .neubiorev.2016 .06 .022.
[56] Friston K,  FitzGerald T, Rigoli F, Schwartenbeck P, Pezzulo G. Active inference: a process theory. Neural Comput 2017;29:1–49. https://
doi .org /10 .1162 /NECO _a _00912.
114
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
[57] Friston K,  Kiebel S. Predictive coding under the free-energy principle. Philos Trans R Soc Lond B, Biol Sci 2009;364:1211–21. https://
doi .org /10 .1098 /rstb.2008 .0300.
[58] Friston K,  Mattout J, Kilner J. Action understanding and active inference. Biol Cybern 2011;104:137–60. https://doi .org /10 .1007 /s00422 -
011 -0424 -z.
[59] Friston K,  Mattout J,  Trujillo-Barreto N,  Ashburner J,  Penny W. Variational free energy and the Laplace approximation. NeuroImage 
2007;34:220–34. https://doi .org /10 .1016 /j .neuroimage .2006 .08 .035.
[60] Friston K, Rigoli F, Ognibene D, Mathys C, Fitzgerald T, Pezzulo G. Active inference and epistemic value. Cogn Neurosci 2015;6:187–214. 
https://doi .org /10 .1080 /17588928 .2015 .1020053.
[61] Friston K,  Rosch R, Parr T, Price C, Bowman H. Deep temporal models and active inference. Neurosci Biobehav Rev 2018;90:486–501. 
https://doi .org /10 .1016 /j .neubiorev.2018 .04 .004.
[62] Galetzka C.  The story so far: how embodied cognition advances our understanding of meaning-making. Front Psychol 2017;8. https://
doi .org /10 .3389 /fpsyg .2017 .01315.
[63] Gallese V , Goldman A. Mirror neurons and the simulation theory of mind-reading. Trends Cogn Sci 1998;2:493–501. https://doi .org /10 .
1016 /S1364 -6613(98 )01262 -5.
[64] Gazzola V , Keysers C. The observation and execution of actions share motor and somatosensory voxels in all tested subjects: single-subject 
analyses of unsmoothed fMRI data. Cereb Cortex 2009;19:1239–55. https://doi .org /10 .1093 /cercor /bhn181.
[65] Gergely G, Csibra G.  Teleological reasoning in infancy: the naïve theory of rational action. Trends in cognitive sciences, vol. 7. 2003. 
p. 287–92.
[66] Goldenberg G, Hagmann S. Tool use and mechanical problem solving in apraxia. Neuropsychologia 1998;36:581–9. https://doi .org /10 .1016 /
S0028 -3932(97 )00165 -6.
[67] Goldenberg G,  Hagmann S. The meaning of meaningless gestures: a study of visuo-imitative apraxia. Neuropsychologia 1997;35:333–41. 
https://doi .org /10 .1016 /S0028 -3932(96 )00085 -1.
[68] Gottlieb J,  Oudeyer P-Y . Towards a neuroscience of active sampling and curiosity. Nat Rev Neurosci 2018;19:758–70. https://doi .org /10 .
1038 /s41583 -018 -0078 -0.
[69] Grafton ST. Embodied cognition and the simulation of action to understand others. Ann NY Acad Sci 2009;1156:97–117. https://doi .org /10 .
1111 /j .1749 -6632 .2009 .04425 .x.
[70] Grafton ST,  de C. Hamilton AF.  Evidence for a distributed hierarchy of action representation in the brain. Hum Mov Sci 
2007;2007(26):590–616. https://doi .org /10 .1016 /j .humov.2007 .05 .009. European workshop on movement science.
[71] Hauk O,  Johnsrude I,  Pulvermüller F.  Somatotopic representation of action words in human motor and premotor cortex. Neuron 
2004;41:301–7. https://doi .org /10 .1016 /S0896 -6273(03 )00838 -9.
[72] Heilbron M,  Armeni K, Schoffelen J-M, Hagoort P, de Lange FP. A hierarchy of linguistic predictions during natural language comprehen-
sion. Proc Natl Acad Sci 2022;119:e2201968119. https://doi .org /10 .1073 /pnas .2201968119.
[73] Heilman KM,  Maher LM, Greenwald ML, Rothi LJG. Conceptual apraxia from lateralized lesions. Neurology 1997;49:457–64. https://
doi .org /10 .1212 /WNL .49 .2 .457.
[74] Heyes C. Automatic imitation. Psychol Bull 2011;137:463–83. https://doi .org /10 .1037 /a0022288.
[75] Hoeren M,  Kümmerer D, Bormann T, Beume L, Ludwig VM, Vry M-S, et al. Neural bases of imitation and pantomime in acute stroke 
patients: distinct streams for praxis. Brain 2014;137:2796–810. https://doi .org /10 .1093 /brain /awu203.
[76] Hommel B, Müsseler J, Aschersleben G, Prinz W. The theory of event coding (TEC): a framework for perception and action planning. Behav 
Brain Sci 2001;24:849–78. https://doi .org /10 .1017 /S0140525X01000103.
[77] Iacoboni M,  Woods RP,  Brass M,  Bekkering H,  Mazziotta JC,  Rizzolatti G.  Cortical mechanisms of human imitation. Science 
1999;286:2526–8. https://doi .org /10 .1126 /science .286 .5449 .2526.
[78] Itti L,  Baldi P. Bayesian surprise attracts human attention. Vis Res 2009;49:1295–306. https://doi .org /10 .1016 /j .visres .2008 .09 .007.
[79] Itti L,  Koch C. A saliency-based search mechanism for overt and covert shifts of visual attention. Vis Res 2000;40:1489–506. https://
doi .org /10 .1016 /S0042 -6989(99 )00163 -7.
[80] Itti L,  Koch C,  Niebur E.  A model of saliency-based visual attention for rapid scene analysis. IEEE Trans Pattern Anal Mach Intell 
1998;20:1254–9. https://doi .org /10 .1109 /34 .730558.
[81] Jacob P, Jeannerod M. The motor theory of social cognition: a critique. Trends Cogn Sci 2005;9:21–5. https://doi .org /10 .1016 /j .tics .2004 .11 .
003.
[82] Jacquet PO, Chambon V , Borghi AM, Tessari A. Object affordances tune observers’ prior expectations about tool-use behaviors. PLoS ONE 
2012;7. https://doi .org /10 .1371 /journal .pone .0039629.
[83] James W. The principles of psychology, vol I. New York, NY , US: Henry Holt and Co; 1890.
[84] Jax SA,  Buxbaum LJ.  Response interference between functional and structural actions linked to the same familiar object. Cognition 
2010;115:350–5. https://doi .org /10 .1016 /j .cognition .2010 .01 .004.
[85] Jeannerod M. Motor cognition: what actions tell the self. New York, NY , US: Oxford University Press; 2006.
[86] Jeannerod M. Neural simulation of action: a unifying mechanism for motor cognition. NeuroImage 2001;14:S103–9. https://doi .org /10 .1006 /
nimg .2001 .0832.
[87] Jeannerod M.  The representing brain: neural correlates of motor intention and imagery. Behav Brain Sci 1994;17:187–245. https://doi .org /
10 .1017 /S0140525X00034026.
[88] Kiebel S,  Daunizeau J, Friston K. Perception and hierarchical dynamics. Front Neuroinform 2009;3:20. https://doi .org /10 .3389 /neuro .11 .
020 .2009.
[89] Kiebel S,  Daunizeau J, Friston K. A hierarchy of time-scales and the brain. PLoS Comput Biol 2008;4:e1000209. https://doi .org /10 .1371 /
journal .pcbi .1000209.
115
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
[90] Kilner JM. More than one pathway to action understanding. Trends Cogn Sci 2011;15:352–7. https://doi .org /10 .1016 /j .tics .2011 .06 .005.
[91] Kilner JM, Friston K, Frith CD. Predictive coding: an account of the mirror neuron system. Cogn Process 2007;8:159–66. https://doi .org /10 .
1007 /s10339 -007 -0170 -2.
[92] Kilner JM, Paulignan Y , Blakemore SJ. An interference effect of observed biological movement on action. Curr Biol 2003;13:522–5. https://
doi .org /10 .1016 /s0960 -9822(03 )00165 -9.
[93] Krakauer JW, Shadmehr R. Towards a computational neuropsychology of action. In: Cisek P, Drew T, Kalaska JF, editors. Progress in brain 
research, computational neuroscience: theoretical insights into brain function. Elsevier; 2007. p. 383–94.
[94] Lee SW,  Shimojo S,  O’Doherty JP. Neural computations underlying arbitration between model-based and model-free learning. Neuron 
2014;81:687–99. https://doi .org /10 .1016 /j .neuron .2013 .11 .028.
[95] Lee TS,  Mumford D. Hierarchical Bayesian inference in the visual cortex. J Opt Soc Am A, Opt Image Sci Vis 2003;20:1434–48. https://
doi .org /10 .1364 /josaa .20 .001434.
[96] Leshinskaya A,  Caramazza A.  For a cognitive neuroscience of concepts: moving beyond the grounding issue. Psychon Bull Rev 
2016;23:991–1001. https://doi .org /10 .3758 /s13423 -015 -0870 -z.
[97] Leshinskaya A,  Caramazza A. Nonmotor aspects of action concepts. J Cogn Neurosci 2014;26:2863–79. https://doi .org /10 .1162 /jocn _a _
00679.
[98] Logie RH.  Visuo-spatial processing in working memory. Q J Exp Psychol, A Hum Exp Psychol 1986;38A:229–47. https://doi .org /10 .1080 /
14640748608401596.
[99] Maisto D,  Barca L, Van den Bergh O, Pezzulo G. Perception and misperception of bodily symptoms from an active inference perspective: 
modelling the case of panic disorder. Psychol Rev 2021;128:690–710. https://doi .org /10 .1037 /rev0000290.
[100] Maisto D,  Donnarumma F, Pezzulo G. Divide et impera: subgoaling reduces the complexity of probabilistic inference and problem solving. 
J R Soc Interface 2015;12:20141335. https://doi .org /10 .1098 /rsif .2014 .1335.
[101] Maisto D,  Friston K, Pezzulo G. Caching mechanisms for habit formation in active inference. Neurocomputing 2019;359:298–314. https://
doi .org /10 .1016 /j .neucom .2019 .05 .083.
[102] Maranesi M,  Bruni S, Livi A, Donnarumma F, Pezzulo G, Bonini L. Differential neural dynamics underling pragmatic and semantic affor-
dance processing in macaque ventral premotor cortex. Sci Rep 2019;9:11700. https://doi .org /10 .1038 /s41598 -019 -48216 -y.
[103] Maranesi M,  Livi A, Fogassi L, Rizzolatti G, Bonini L. Mirror neuron activation prior to action observation in a predictable context. J 
Neurosci 2014;34:14827–32. https://doi .org /10 .1523 /JNEUROSCI .2705 -14 .2014.
[104] Maravita A, Iriki A. Tools for the body (schema). Trends Cogn Sci 2004;8:79–86. https://doi .org /10 .1016 /j .tics .2003 .12 .008.
[105] Martin M,  Dressing A, Bormann T, Schmidt C, Kümmerer D, Beume L, et al. Componential network for the recognition of tool-associated 
actions: evidence from voxel-based lesion-symptom mapping in acute stroke patients. Cereb Cortex 2016;27. https://doi .org /10 .1093 /cercor /
bhw226.
[106] Martin M,  Nitschke K, Beume L, Dressing A, Bühler LE, Ludwig VM, et al. Brain activity underlying tool-related and imitative skills after 
major left hemisphere stroke. Brain 2016;139:1497–516. https://doi .org /10 .1093 /brain /aww035.
[107] Mengotti P, Corradi-Dell’Acqua C, Negri GAL, Ukmar M, Pesavento V , Rumiati RI. Selective imitation impairments differentially interact 
with language processing. Brain 2013;136:2602–18. https://doi .org /10 .1093 /brain /awt194.
[108] Mengotti P, Ripamonti E, Pesavento V , Rumiati RI. Anatomical and spatial matching in imitation: evidence from left and right brain-damaged 
patients. Neuropsychologia 2015;79:256–71. https://doi .org /10 .1016 /j .neuropsychologia .2015 .06 .038. Special issue: Sensory motor integra-
tion.
[109] Meteyard L,  Cuadrado SR, Bahrami B, Vigliocco G. Coming of age: a review of embodiment and the neuroscience of semantics. Cortex 
2012;48:788–804. https://doi .org /10 .1016 /j .cortex .2010 .11 .002. Language and the motor system.
[110] Miller GA, Galanter E, Pribram KH. The integration of plans. In: Plans and the structure of behavior. New York, NY , US: Henry Holt and 
Co; 1960. p. 95–102.
[111] Mirza MB, Adams RA, Mathys CD, Friston K. Scene construction, visual foraging, and active inference. Front Comput Neurosci 2016;10.
[112] O’Regan JK. Why red doesn’t sound like a bell: understanding the feel of consciousness. Oxford University Press; 2011.
[113] Ottoboni G, Toraldo A, Proietti R, Cangelosi A, Tessari A. Paradoxical decrease of imitation performance with age in children. Br J Psychol 
2023. https://doi .org /10 .1111 /bjop .12644.
[114] Pacherie E.  The phenomenology of action: a conceptual framework. Cognition 2008;107:179. https://doi .org /10 .1016 /j .cognition .2007 .09 .
003.
[115] Packard MG,  Knowlton BJ. Learning and memory functions of the Basal Ganglia. Annu Rev Neurosci 2002;25:563–93. https://doi .org /10 .
1146 /annurev.neuro .25 .112701 .142937.
[116] Parr T,  Friston KJ. The discrete and continuous brain: from decisions to movement—and  back again. Neural Comput 2018;30:2319–47. 
https://doi .org /10 .1162 /neco _a _01102.
[117] Parr T, Friston KJ. Working memory, attention, and salience in active inference. Sci Rep 2017;7:14678. https://doi .org /10 .1038 /s41598 -017 -
15249 -0.
[118] Parr T, Limanowski J, Rawji V , Friston K. The computational neurology of movement under active inference. Brain 2021;144:1799–818. 
https://doi .org /10 .1093 /brain /awab085.
[119] Parr T, Pezzulo G, Friston K. Active inference: the free energy principle in mind, brain, and behavior. Cambridge, MA, USA: MIT Press; 
2022.
[120] Pedullà L,  Gervasoni E, Bisio A, Biggio M, Ruggeri P, Avanzino L, et al. The last chance to pass the ball: investigating the role of temporal 
expectation and motor resonance in processing temporal errors in motor actions. Soc Cogn Affect Neurosci 2020;15:123–34. https://doi .org /
10 .1093 /scan /nsaa021.
[121] Peigneux P, Van der Linden M, Garraux G, Laureys S, Degueldre C, Aerts J, et al. Imaging a cognitive model of apraxia: the substrate of 
gesture-speciﬁc cognitive processes. Hum Brain Mapp 2004;21:119–42. https://doi .org /10 .1002 /hbm .10161.
116
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
[122] Pezzulo G.  Studying mirror mechanisms within generative and predictive architectures for joint action. Cortex 2013;49:2968–9. https://
doi .org /10 .1016 /j .cortex .2013 .06 .008.
[123] Pezzulo G,  Barsalou LW, Cangelosi A, Fischer MH, McRae K, Spivey MJ. Computational grounded cognition: a new alliance between 
grounded cognition and computational modeling. Front Psychol 2013;3:612. https://doi .org /10 .3389 /fpsyg .2012 .00612.
[124] Pezzulo G,  Barsalou LW, Cangelosi A, Fischer MH, Spivey M, McRae K. The mechanics of embodiment: a dialog on embodiment and 
computational modeling. Front Psychol 2011;2. https://doi .org /10 .3389 /fpsyg .2011 .00005.
[125] Pezzulo G,  Donnarumma F, Maisto D, Stoianov I. Planning at decision time and in the background during spatial navigation. Curr Opin 
Behav Sci 2019;29:69–76. https://doi .org /10 .1016 /j .cobeha .2019 .04 .009.
[126] Pezzulo G, Maisto D, Barca L, den Bergh OV . Symptom perception from a predictive processing perspective. Clin Psychol Eur 2019;1:1–14. 
https://doi .org /10 .32872 /cpe .v1i4 .35952.
[127] Pezzulo G, Rigoli F, Chersi F. The mixed instrumental controller: using value of information to combine habitual choice and mental simula-
tion. Front Psychol 2013;4:92. https://doi .org /10 .3389 /fpsyg .2013 .00092.
[128] Pezzulo G, Rigoli F, Friston K. Hierarchical active inference: a theory of motivated control. Trends in cognitive sciences, vol. 22. 2018. 
p. 294–306.
[129] Pezzulo G,  Rigoli F, Friston K. Active inference, homeostatic regulation and adaptive behavioural control. Prog Neurobiol 2015;134:17–35. 
https://doi .org /10 .1016 /j .pneurobio .2015 .09 .001.
[130] Pezzulo G,  Zorzi M, Corbetta M. The secret life of predictive brains: what’s spontaneous activity for? Trends Cogn Sci 2021;25:730–43. 
https://doi .org /10 .1016 /j .tics .2021 .05 .007.
[131] Pisella L, Gréa H, Tilikete C, Vighetto A, Desmurget M, Rode G, et al. An “automatic pilot” for the hand in human posterior parietal cortex: 
toward reinterpreting optic ataxia. Nat Neurosci 2000;3:729–36. https://doi .org /10 .1038 /76694.
[132] Posner MI,  Petersen SE. The attention system of the human brain. Annu Rev Neurosci 1990;13:25–42. https://doi .org /10 .1146 /annurev.ne .
13 .030190 .000325.
[133] Rijntjes M, Dettmers C, Büchel C, Kiebel S, Frackowiak RS, Weiller C. A blueprint for movement: functional and anatomical representations 
in the human motor system. J Neurosci 1999;19:8043–8. https://doi .org /10 .1523 /JNEUROSCI .19 -18 -08043 .1999.
[134] Rijntjes M,  Weiller C, Bormann T, Musso M. The dual loop model: its relation to language and other modalities. Front Evol Neurosci 
2012;4:9. https://doi .org /10 .3389 /fnevo .2012 .00009.
[135] Rizzolatti G,  Craighero L.  The mirror-neuron system. Annu Rev Neurosci 2004;27:169–92. https://doi .org /10 .1146 /annurev.neuro .27 .
070203 .144230.
[136] Rizzolatti G, Fogassi L, Gallese V . Neurophysiological mechanisms underlying the understanding and imitation of action. Nat Rev Neurosci 
2001;2:661–70. https://doi .org /10 .1038 /35090060.
[137] Rizzolatti G,  Sinigaglia C. The functional role of the parieto-frontal mirror circuit: interpretations and misinterpretations. Nat Rev Neurosci 
2010;11:264–74. https://doi .org /10 .1038 /nrn2805.
[138] Rossetti Y , Revol P, McIntosh R, Pisella L, Rode G, Danckert J, et al. Visually guided reaching: bilateral posterior parietal lesions cause a 
switch from fast visuomotor to slow cognitive control. Neuropsychologia 2005;43:162–77. https://doi .org /10 .1016 /j .neuropsychologia .2004 .
11 .004.
[139] Rothi LJ,  Heilman KM, Watson RT. Pantomime comprehension and ideomotor apraxia. J Neurol Neurosurg Psychiatry 1985;48:207–10. 
https://doi .org /10 .1136 /jnnp .48 .3 .207.
[140] Rothi LJ, Mack L, Heilman KM. Pantomime agnosia. J Neurol Neurosurg Psychiatry 1986;49:451–4. https://doi .org /10 .1136 /jnnp .49 .4 .451.
[141] Rothi LJ,  Ochipa C, Heilman KM. A cognitive neuropsychological model of limb praxis. Cogn Neuropsychol 1991;8:443–58. https://doi .
org /10 .1080 /02643299108253382.
[142] Roy EA, Square PA. Common considerations in the study of limb, verbal and oral apraxia. In: Roy EA, editor. Advances in psychology. 
North-Holland; 1985. p. 111–61.
[143] Rumiati RI, Papeo L, Corradi-Dell’Acqua C. Higher-level motor processes. Ann NY Acad Sci 2010;1191:219–41. https://doi .org /10 .1111 /j .
1749 -6632 .2010 .05442 .x.
[144] Rumiati RI,  Tessari A. Imitation of novel and well-known actions: the role of short-term memory. Exp Brain Res 2002;142:425–33. https://
doi .org /10 .1007 /s00221 -001 -0956 -x.
[145] Rumiati RI, Weiss PH, Tessari A, Assmus A, Zilles K, Herzog H, et al. Common and differential neural mechanisms supporting imitation of 
meaningful and meaningless actions. J Cogn Neurosci 2005;17:1420–31. https://doi .org /10 .1162 /0898929054985374.
[146] Schwartenbeck P, Friston K. Computational phenotyping in psychiatry: a worked example. eNeuro 2016;3. https://doi .org /10 .1523 /ENEURO .
0049 -16 .2016.
[147] Schwartenbeck P, Passecker J, Hauser TU, FitzGerald TH, Kronbichler M, Friston K. Computational mechanisms of curiosity and goal-
directed exploration. eLife 2019;8:e41703. https://doi .org /10 .7554 /eLife .41703.
[148] Smith R,  Friston KJ,  Whyte CJ.  A step-by-step tutorial on active inference and its application to empirical data. J Math Psychol 
2022;107:102632. https://doi .org /10 .1016 /j .jmp .2021 .102632.
[149] Smith R,  Kuplicki R, Feinstein J, Forthman KL, Stewart JL, Paulus MP, et al. A Bayesian computational model reveals a failure to adapt 
interoceptive precision estimates across depression, anxiety, eating, and substance use disorders. PLoS Comput Biol 2020;16:e1008484. 
https://doi .org /10 .1371 /journal .pcbi .1008484.
[150] Smith R,  Schwartenbeck P, Parr T, Friston K. An active inference approach to modeling structure learning: concept learning as an example 
case. Front Comput Neurosci 2020;14:41. https://doi .org /10 .3389 /fncom .2020 .00041.
[151] Sokolov EN.  Higher nervous functions: the orienting reﬂex. Annu Rev Physiol 1963;25:545–80. https://doi .org /10 .1146 /annurev.ph .25 .
030163 .002553.
[152] Squire LR. Memory and the hippocampus: a synthesis from ﬁndings with rats, monkeys, and humans. Psychol Rev 1992;99:195–231. https://
doi .org /10 .1037 /0033 -295X .99 .2 .195.
117
R. Proietti, G. Pezzulo and A. Tessari Physics of Life Reviews 46 (2023) 92–118
[153] Stevens JA, Fonlupt P, Shiffrar M, Decety J. New aspects of motion perception: selective neural encoding of apparent human movements. 
NeuroReport 2000;11:109.
[154] Tessari A,  Bosanac D,  Rumiati RI.  Effect of learning on imitation of new actions: implications for a memory model. Exp Brain Res 
2006;173:507–13. https://doi .org /10 .1007 /s00221 -006 -0395 -9.
[155] Tessari A,  Canessa N, Ukmar M, Rumiati RI. Neuropsychological evidence for a strategic control of multiple routes in imitation. Brain 
2007;130:1111–26. https://doi .org /10 .1093 /brain /awm003.
[156] Tessari A, Mengotti P, Faccioli L, Tuozzi G, Boscarato S, Taricco M, et al. Effect of body-part speciﬁcity and meaning in gesture imitation 
in left hemisphere stroke patients. Neuropsychologia 2021;151:107720. https://doi .org /10 .1016 /j .neuropsychologia .2020 .107720.
[157] Tessari A, Ottoboni G. Does the body talk to the body? The relationship between different body representations while observing others’ body 
parts. Br J Psychol 2022;113:758–76. https://doi .org /10 .1111 /bjop .12558.
[158] Tessari A,  Proietti R,  Rumiati RI.  Bottom-up and top-down modulation of route selection in imitation. Cogn Neuropsychol 
2021;38(7–8):515–30. https://doi .org /10 .1080 /02643294 .2022 .2043264.
[159] Tessari A, Rumiati RI. The strategic control of multiple routes in imitation of actions. J Exp Psychol Hum Percept Perform 2004;30:1107–16. 
https://doi .org /10 .1037 /0096 -1523 .30 .6 .1107.
[160] Tessari A,  Rumiati RI,  Haggard P.  Imitation without awareness. NeuroReport 2002;13:2531–5. https://doi .org /10 .1097 /00001756 -
200212200 -00030.
[161] Tsotsos JK. A computational perspective on visual attention. MIT Press; 2011.
[162] van Elk M, van Schie H, Bekkering H. Action semantics: a unifying conceptual framework for the selective use of multimodal and modality-
speciﬁc object knowledge. Phys Life Rev 2014;11:220–50. https://doi .org /10 .1016 /j .plrev.2013 .11 .005.
[163] V on Hofsten C. Action in development. Dev Sci 2007;10:54–60. https://doi .org /10 .1111 /j .1467 -7687 .2007 .00564 .x.
[164] Weiller C, Bormann T, Saur D, Musso M, Rijntjes M. How the ventral pathway got lost – and what its recovery might mean. Brain Lang 
2011;118:29–39. https://doi .org /10 .1016 /j .bandl .2011 .01 .005.
[165] Weiller C, Musso M, Rijntjes M, Saur D. Please don’t underestimate the ventral pathway in language. Trends Cogn Sci 2009;13:369–70. 
370–371, https://doi .org /10 .1016 /j .tics .2009 .06 .007.
[166] Wohlschläger A, Gattis M, Bekkering H. Action generation and action perception in imitation: an instance of the ideomotor principle. Philos 
Trans R Soc Lond B, Biol Sci 2003;358:501–15. https://doi .org /10 .1098 /rstb.2002 .1257.
118