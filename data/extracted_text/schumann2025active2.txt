arXiv:2506.02215v4  [cs.RO]  11 Jun 2025
Active inference as a unified model of collision avoidance
behavior in human drivers
Julian F. Schumann1, Johan Engstr¨ om2*, Leif Johnson2, Matthew O’Kelly2,
Joao Messias2, Jens Kober1, Arkady Zgonnikov1
1Department of Cognitive Robotics, Delft University of Technology, Netherlands.
2Waymo LLC, Mountain View, CA, USA.
Contributing authors: j.f.schumann@tudelft.nl; jengstrom@waymo.com; leif@waymo.com;
mokelly@waymo.com; messiasj@waymo.com; j.kober@tudelft.nl; a.zgonnikov@tudelft.nl;
Abstract
Collision avoidance – involving a rapid threat detection and quick execution of the appropriate evasive
maneuver – is a critical aspect of driving. However, existing models of human collision avoidance behav-
ior are fragmented, focusing on specific scenarios or only describing certain aspects of the avoidance
behavior, such as response times. This paper addresses these gaps by proposing a novel computational
cognitive model of human collision avoidance behavior based on active inference. Active inference pro-
vides a unified approach to modeling human behavior: the minimization of free energy. Building on
prior active inference work, our model incorporates established cognitive mechanisms such as evidence
accumulation to simulate human responses in two distinct collision avoidance scenarios: front-to-rear
lead vehicle braking and lateral incursion by an oncoming vehicle. We demonstrate that our model
explains a wide range of previous empirical findings on human collision avoidance behavior. Specif-
ically, the model closely reproduces both aggregate results from meta-analyses previously reported
in the literature and detailed, scenario-specific effects observed in a recent driving simulator study,
including response timing, maneuver selection, and execution. Our results highlight the potential of
active inference as a unified framework for understanding and modeling human behavior in complex
real-life driving tasks.
Collision avoidance is a critical skill for human
drivers. It involves the rapid detection of threats
(such as a vehicle ahead suddenly braking) and
deciding on an appropriate evasive maneuver (for
instance, braking or swerving). These maneuvers
are complex, requiring not only precise execution
but also continuous adjustments as the situation
evolves. Furthermore, drivers need to account for
the uncertainty in the future behavior of other
road users: for example, will an oncoming vehicle
encroaching into my lane continue across or move
back to its own lane? Understanding how humans
avoid collisions in traffic can provide insights into
high-stakes, split-second decision making which
has substantial implications for traffic safety.
Behavior models play a key role both in
understanding the mechanisms of human colli-
sion avoidance and in improving traffic safety.
These models are applied in diverse contexts,
such as collision risk estimation [1], understanding
effects of driver distraction [2], modeling take-over
behavior [3], representing human agents in simu-
lated test environments [4], and providing behav-
ioral benchmarks for autonomous vehicles [5, 6].
1
11
iliac.io
I
iiii
iiiii
t
iiii.EEFfiiiiiiii
iiiiiii
ii
iiii
i.ﬁ
I
ieEIDFEEfiiff
Expected 
Free 
Energy
Low
High
Fig. 1: An illustration of the key principles of our active inference model in the opposite-direction lateral
incursion scenario. Upper left panel: The modeled agent (at the bottom, facing forward) is continuously
generating beliefs (represented by the arrows) about how the current driving situation will play out and
what future observations it will make as a consequence of its own actions and the actions of the other
vehicle. In ”normal”, non-conflict situations, the situation typically plays out as expected. The agent thus
initially believes with high certainty that both itself and the oncoming vehicle will remain in their lanes
and pass each other safely. This yields low expected free energy (EFE; green arrows) since the agent’s
expected (and thus preferred) observations (e.g., making progress, avoid collisions) are aligned with the
actual observations. Upper right panel: When the oncoming vehicle suddenly encroaches into the driver’s
lane, the EFE increases rapidly (as indicated by the red arrows) because this new situation is likely to
result in an observed collision in the future, which is strongly disfavored by the agent. In this situation,
the agent’s belief about the oncoming vehicle’s future trajectory also becomes more uncertain, because
the other vehicle can no longer be trusted to follow established traffic norms. The agent thus needs to
imagine a better future with lower EFE – in this case, a scenario where it avoids collision by swerving
left (lower left panel) and take action to make that better future come true (lower right panel).
Besides immediate practical applications, mod-
eling human collision avoidance behavior is an
interesting subject of study in its own right.
Being a highly complex and dynamic task with
extremely high stakes, collision avoidance pro-
vides a unique testbed for theories and models
of cognition previously not validated in the real
world [7–9].
Most existing computational models of human
collision avoidance are mechanistic, that is, are
based on the explicit modeling of cognitive mech-
anisms underlying response timing and evasive
maneuvering. However, they are typically frag-
mented, focusing either on specific scenario types
(e.g., front-to-rear conflicts [10–12] or merg-
ing [13]), specific explanatory factors (such as
off-road glances [1, 14] or cognitive load [2]), or
only reproduce certain aspects of human behav-
ior (such as response times [3, 6, 10, 11, 15] or
2
the extent of steering [16]). Altogether, these mod-
els cover a wide range of scenarios and diverse
aspects of collision avoidance behavior. Yet, each
one of these mechanistic models on its own is
highly specific: they are not designed to generalize
to multiple scenarios or describe multiple aspects
of human behavior.
Recently, machine learning models based on
large datasets of human driving have demon-
strated the ability to generalize across a wide
range of traffic scenarios [4, 17–21]. Because such
models typically generate full motion trajectories,
they also have the potential to represent multi-
ple aspects of collision avoidance behavior and not
just a single metric of interest. However, a key
challenge is that safety-critical behavior such as
collision avoidance is often under-represented in
the datasets used for training [22], which makes
it hard to achieve representative human-like colli-
sion avoidance behavior solely based on learning
from data [23].
Thus, there is currently a lack of models that
can capture the key aspects of human collision
avoidance behavior (response selection, timing,
and execution) all at the same time and across dif-
ferent scenarios. This limits both practical appli-
cations (due to the need to develop a new model
for every new scenario) and fundamental under-
standing of cognitive mechanisms underlying the
behavior of humans in safety-critical situations in
traffic (due to the lack of a unified explanation for
multiple aspects of behavior).
To address this gap, here we present a uni-
fied collision avoidance model based on active
inference. Originating in computational neuro-
science, active inference is a versatile general
framework for understanding and modeling sen-
tient behavior in living systems [24–26] that has
been previously used to model human behavior in
diverse contexts [27–31], including the modeling of
human driver behavior such as car following [32],
responses to driving automation failures [15], and
managing uncertainty around occlusions and non-
driving-related tasks [33]. Building on the model
of Engstr¨ omet al. [33], here we propose an active
inference-based model to capture a spectrum
of human behaviors in collision avoidance. Our
model incorporates several well-known cognitive
mechanisms to represent the dynamics of human
decision making in response to sudden stimuli,
such as looming perception [34, 35] and evidence
accumulation [36–39]. We evaluated our model
against a range of previously reported empiri-
cal findings in two paradigmatic collision avoid-
ance scenarios: the front-to-rear scenario, where
a driver needs to respond to a suddenly braking
vehicle in front, and the opposite-direction lat-
eral incursion scenario, where an oncoming vehicle
suddenly cuts across the driver’s path. Testing the
model in two markedly different scenarios allowed
us to investigate the potential of active inference
as a unified framework for generalizable modeling
of human collision avoidance behavior.
Results
In this work, we use active inference as an overar-
ching framework to guide the modeling. The key
premise of active inference is that all behavior and
cognition can be understood based on the single
principle of minimizingfree energy. An agent mini-
mizing free energy can be conceptually understood
as the agent sensing, and acting upon, the world
in such a way as to minimize its surprise over time.
In the active inference framework, this amounts to
seeking out observations that are expected (unsur-
prising) and preferred given the type of creature
the agent is, reflecting its adaptation to its par-
ticular environment or niche (e.g., a fish expects
and prefers the sensation of being immersed in
water). Agents capable of planning into the future
and modeling the consequences of their actions
(such as human car drivers), select plans that min-
imize the expected surprise, or more generally the
expected free energy (EFE) [24].
Our model implements these principles in the
collision avoidance context (Figure 1). Specifically,
the modeled agent repeatedly evaluates possible
futures under its current policy (i.e., a sequence
of planned actions) – including interactions with
other road users – in terms of their EFE. The
driver then selects policies that minimize EFE by
realizing observations that align with the driver’s
preferences such as avoiding collisions (yielding
pragmatic value) while obtaining new information
to reduce uncertainty about the environment’s
future (yielding epistemic value ) [24, 33].
Fundamentally, agents cannot have perfect
knowledge of the mechanisms underlying the
surrounding world (the generative process), but
3
a
ii
iffiIIi
I I i.IT
iiitf
it I
_ s
t iitii
iis i
ii iiit
tI
I IIII
F
in FF
iF i i
ii.if I
FFiF
iii II.IE O
FI iI oÉÉ
F Ii
is s o
i iiIiiIIi Femi
t
a b
c
Observe to update belief Predict other norm-compliant agent
Accumulate surprise E 
in favor of full re-pland.i
 Sampling (policy extension)e.i Selection (policy extension)
d.ii Sampling (full policy)e.ii Selection (full policy)
f Update world state
E < 1
E ≥ 1
iiiII.IE
i
0
.itiI
E
Fig. 2: Main functional components of our active inference collision avoidance model. At each time step,
the ego agent observes the world state, updates its belief about the world (a), and makes probabilistic
predictions about the actions of the other agent (where future trajectories that adhere to traffic norms are
prioritized) (b). At every time step, the agent accumulates evidence (as measured by surprise associated
with the current state of the world) on the unsuitability of the current policy (c). If the accumulated
evidence reaches a threshold, the agent re-plans the entire policy, selecting the one that minimizes the
expected free energy (EFE) (d.ii and e.ii). Otherwise, it continues using its current policy in an extend
form – i.e., only sampling and then selecting the policy’s last time step (d.i and e.i). The first action in
the new or extended policy is then applied to the environment (f).
instead rely on an internal, not necessarily veridi-
cal, representation of their beliefs about the envi-
ronment, the generative model [24]. Importantly,
an (ego) agent’s generative model is probabilistic,
with the uncertainty about the state of the world
being represented by a set of sample particles.
Our model implements these general principles
in a time-discrete, sequential process (Figure 2)
which incorporates a number of key perceptual,
cognitive, and motor mechanisms.
Looming-based perception. First, the
agent observes the world and updates its belief
(Figure 2a), combining these observations with the
expectations derived from the generative model
propagating its previous belief forward in time.
The model assumes that the agent cannot directly
perceive kinematic states of surrounding objects
(e.g., positions and velocities), but instead uses
the readily available perceptual information [35]:
the object’s visual angle φ subtended at the
driver’s retina, and its derivative, the angular rate
˙φ, commonly referred to as looming [34, 40 ? ].
The model then infers back the kinematic state
from those observations, where – with increasing
distances – equal variations in φ lead to increas-
ingly larger variations in the inferred distance and
therefore increasing uncertainty about the kine-
matic state of the other agent. Additionally, the
agent’s perception accuracy is limited: it cannot
perceive looming with absolute values below a
threshold ˙φ0 [41, 42]. Due to this threshold, the
agent is unable to detect small relative veloci-
ties at long distances; our model thus incorporates
this looming threshold as one possible mechanism
behind delays in recognizing events like abrupt
braking of the other vehicle.
4
Behavior prediction via norm-
conditioned particle filter. After perceiving
the environment, the ego agent predicts the other
vehicle’s behavior (Figure 2b). For this, our model
uses a sample-based approach [33, 43] (i.e., based
on a particle filter). Specifically, the samples
representing the agent’s updated belief about the
other vehicle are propagated forward by the gen-
erative model (in our case using a bicycle model
with additive Gaussian noise). In this way, the
model generates multiple distinct kinematically
plausible future trajectories of the other vehicle,
including the ones that could potentially lead to
a collision. This enables the model to anticipate
rare, long-tail behaviors of the other vehicle and
respond to them appropriately during collision
avoidance, but yields overly pessimistic predic-
tions in non-conflict situations. For instance,
widely dispersed predictions could lead the agent
to anticipate vehicles encroaching into its lane,
incentivizing unnecessary evasive actions. By
contrast, human drivers typically assume that
other vehicles follow traffic rules [44, 45] and
other societal norms for driving [46]. To capture
this, our model assumes that the ego agent uses
a norm-conditioned particle filter for behavior
prediction, by assigning each possible predicted
trajectory a weight based on its adherence to
traffic norms. This allows the model to priori-
tize norm-compliant behaviors when predicting
the actions of the other vehicle. In this way, the
model’s belief about the future trajectory of the
other vehicle is initially constrained by the social
norm that other vehicles typically remain within
their lane unless explicitly indicating otherwise.
However, when another vehicle unexpectedly
initiates a conflict (for example an incursion
towards the ego vehicle’s lane), the model will
eventually take predicted norm-violating trajec-
tories seriously. The reason for this is that the
weights assigned to each predicted particle in the
set are divided by their sum (i.e., sum to 1 across
all predictions). Thus, in cases where the over-
whelming majority of the predicted trajectories
violate the norms, the model still considers these
trajectories rather than disregarding all of them
as non-norm-compliant.
Re-planning full policy based on accu-
mulating surprise. In the next step, based on
the set of previously predicted possible trajecto-
ries of the other vehicle, the agent considers its
own policy, evaluating its current suitability by
calculating the residual information [47] of the
pragmatic value , which can be seen as a mea-
sure of surprise. This surprise signal – the (scaled)
negative pragmatic value associated with the cur-
rently selected policy – essentially indicates how
unsuitable the current policy is given the model’s
preferred observations and how the situation is
expected to develop. The model assumes that the
driver continuously accumulates this surprise sig-
nal as evidence in favor of full policy re-plan
(Figure 2c). On each time step, if the accumulated
evidence has not reached a predefined threshold,
the agent considers it sufficient to continue with
the current policy, and extends this policy one
time step into the future (Figure 2d.i and e.i).
However, if enough evidence in favor of current
policy being unsuitable is accumulated, a set of
completely new policies is sampled and a new full
policy is selected (Figure 2d.ii and e.ii). The first
action from either the extended or the new full
policy is then applied to update the environment
for the next time step (Figure 2f).
Constrained policy sampling. When
proposing new candidate policies, either for exten-
sion (Figure 2d.i) or full re-plan (Figure 2d.ii), the
model uses the cross-entropy method [48]. With
this method, candidate actions are iteratively
resampled, increasingly focusing on the most
promising areas of the action space. To represent
humans’ bounded capacity for planning under
time pressure [13, 49–52], we limit the number of
evaluated policies in this process. Importantly,
the sampled acceleration values are constrained
to reflect that humans operate the gas and brake
pedals with one foot. These constraints include
limiting applied jerks (as humans cannot press
or release pedals instantaneously) and enforcing
a constant holding time of 0 .2 s at acceleration
a0 ≲ 0 ms−2 during transitions in both direc-
tions between acceleration and deceleration (as
humans cannot move their foot between pedals
instantaneously).
Policy selection via expected free energy
minimization. Among the sampled candidate
policies, the model aims to find the policy that
minimizes expected free energy (EFE) – the
cornerstone of the active inference framework
(Figure 2e.i and e.ii). In our model, the pragmatic
5
value part of the EFE is maximized by 1) main-
taining a desired longitudinal velocity, 2) staying
within the current lane (avoiding unnecessary or
unsafe lane changes) and on the road, 3) min-
imizing control inputs (avoid harsh braking or
steering), 4) preventing collisions or at least reduc-
ing their severity (measured by the relative impact
velocity), and 5) avoiding situations where colli-
sions may become inevitable (such as following a
vehicle too closely without sufficient stopping dis-
tance, assuming realistic reaction times). Finally,
maximizing the epistemic value encourages 6)
policies resulting in a large variety of reliable
observations [33]. However, in the present collision
avoidance setting, behavior is mainly expected to
be driven by pragmatic, rather than epistemic,
value since there is not much the driver can do to
reduce uncertainty, especially given that we here
assume that the other vehicle is non-reactive to
the ego agent’s actions.
Model evaluation
We evaluated the model against human data in
two scenarios. In the front-to-rear scenario, we
compared the model to the results of a meta-
analysis of brake response times [53] in experi-
mental driving simulator and field studies (e.g.,
Brookhuis et al. [54] and Lee et al. [55]), and
an analysis of deceleration magnitudes based on
two naturalistic driving datasets captured across
US and Africa reported in [14]. In the opposite-
direction lateral incursion scenario, the model was
compared to human data from a driving simulator
study conducted in UK [56] which was conducted
in parallel to the present work. Thus, by contrast
to the model evaluation for the front-to-rear sce-
nario, which was based on aggregated data, we
were here able to run our model on nearly identical
scenarios for which the human data was collected,
allowing for more detailed comparisons. Impor-
tantly, the same model parameter values were used
for both scenarios.
Front-to-rear scenario
In the front-to-rear scenario, the ego vehicle trails
the other vehicle which is driving in the same
lane; both vehicles have the same initial velocity
which was systematically varied in our simula-
tions together with the initial time gap between
the vehicles. After a short time of driving at con-
stant speed, the other vehicle starts braking with
a high constant deceleration until coming to a
stop. Depending on the initial kinematics of the
vehicles, the ego agent can avoid collision either
solely by braking (Figure 3a) or combined braking
and swerving (Figure 3 b). The model sometimes
avoided a collision by swerving only (i.e., with-
out braking). However, since existing results in the
literature on front-to-rear scenarios typically only
report on braking response performance, we only
compared our models brake response times (i.e.,
for the analysis of those, steering only responses
are not considered).
At lower speeds and larger time gaps, the
model typically avoids collisions by braking only.
In a representative simulation (Figure 3 a), after
the leading agent started braking at t = 0.8 s (first
dashed line), it took the model 0 .6 s to perceive
this (see the ego agent’s belief in the acceleration
plot). At that point (t = 1.4 s, second dashed line),
the model recognized the imminent conflict result-
ing from this change in perceived behavior of the
other vehicle, as can be seen by the rapid decrease
(increase in negative value) in the collision part of
the pragmatic value. This leads to a corresponding
increase in the rate of accumulation of the evi-
dence for a re-plan (i.e., surprise). However, it still
took further 0 .6 s until the accumulated evidence
E reached the threshold, delaying the first notice-
able agent reaction to t = 2 s (third dashed line),
where the agent started to execute a new pol-
icy – emergency braking. This policy was selected
because it allowed the agent to drastically reduce
its EFE via reaching future states with high prag-
matic value, in particular thanks to low collision
probability. This policy was preferred over the
alternative policy of braking and steering into the
adjacent lane because the pragmatic value associ-
ated with lane changing was more negative than
that associated with lower velocity, as the desired
(corresponding to the initial) velocity is compar-
atively low. However, even under this policy, at
t = 2 s, the acceleration has still not changed,
due to the pedal constraints. Consequently, the
first deceleration of the model can be observed at
t = 2.2 s, resulting in a total response time of 1.4 s.
Smaller time gaps and higher initial veloci-
ties can make it kinematically impossible to avoid
collision by braking only. In such situations, the
model typically opts to steer and brake at the
6
t= 2.0 s
a Example - Brake only
t= 1.4 s
b Example - Brake & Steer
˜Xego
Ego vehicle Other vehicle Ego’s belief about Other
Lateral pos Velocity Control effort Collision
−0.01 −1
Prag. value
λGprag
0 2 4
0 1
Time t [s]
Evidence E
0 15 25
Velocity
v [ms−1]
-5 0 5
Accel.
a [ms−2]
-0.05 0 0.05
Steer angle
δ [rad]
0 2 4
Time t [s]
0 1 2 3 4
0 0.5 1
Time gap [s]
P(Brake only)
c
0 1 2 3 4
0 1 2 3
Time gap [s]
Response time [ s]
d
0.0 0.5 1.0 1.5
-8 -6 -4 -2 0
Inv TTC [s−1]
min a [ms−2]
e Data
Brake only
Brake & Steer
Collision
10
25
vego [m/s]
Fig. 3: Evaluation of the model in the front-to-rear scenario. a) In a scenario where initial pre-conflict
kinematics are such that collision can be avoided by braking (initial vehicle velocities v0 = 15 ms−1, a
bumper-to-bumper time gap of 1.5 s), the model typically produces braking-only behavior. The sub-panels
visualize the top-down view of the scenario, the time dynamics of both vehicles’ velocity v, acceleration
a, steering angle δ and (for the ego vehicle) the components of the pragmatic value Gprag (scaled with
the evidence accumulation gain λ) that underlie the accumulated evidence towards a full policy re-plan.
b) In a scenario where braking on its own might not be sufficient to avoid collision ( v0 = 25 ms−1, 1 s
time gap), the model selects a policy that involves both braking and steering towards the opposite lane
(see the model’s selected policies in the topmost plots). c) The likelihood of the ego vehicle deciding to
brake and stay behind the leading other vehicle (without any steering) as a function of time gap, with the
four lines representing four different velocities (ranging from 10 ms −1 to 25 ms−1; the lines representing
20 m/s and 25 m/s are overlapping at zero brake only probability). This data include those samples
where the agent is only steering. d) The relationship between the time gap and the brake response time
of the ego agent in 280 model simulations (see Supplementary Materials 1.3.1). Regression line based
on a meta-analysis of human brake response times [53] is shown for reference. e) The relationship of
the inverse time-to-collision (TTC) at brake onset (defined as max{0,vego−vOV}
∆x ) and the lowest observed
deceleration. Regression line based on the human deceleration magnitude data [14] is shown for reference.
Video replays of the example simulations are available in the supplementary information.
7
same time (for instance, Figure 3 b). Here, due
to the smaller initial distance, the model’s per-
ception delay was noticeably shorter (being only
about 0.2 s, with the modeled agent perceiving the
braking at t = 1 s, the first dashed line). However,
due to the more challenging initial kinematics, it
was more difficult for the model to avoid collision,
despite the shorter perception delay. In particular,
the model switched between different policies four
times. Initially, the model recognized the need to
slightly brake and steer around the other vehicle:
already at the time of the first re-plan ( t = 1.4 s,
second dashed line) the collision component of
EFE was substantially reduced by the chosen pol-
icy. This policy was mostly sufficient in improving
the collision component of the pragmatic value,
but as visible in the top panel (planned trajec-
tory fXego), the agent intends to stay in between
lanes for an extended period. This led to two
further re-plans ( t = 3 .2 s and t = 3 .8 s, third
and fourth dashed lines respectively) to adjust
the trajectory. However, even having passed the
other vehicle already, the model is not completely
successful, with a noticeable lateral position com-
ponent remaining in the pragmatic value. As the
optimal solution of driving in the center of the cur-
rent lane on a free road should have maximized
the pragmatic value, this remaining lateral error
is likely the result of the cross-entropy method
not identifying the optimal policy. This represents
a bounded planning capacity which, as discussed
above, is also present in humans [13, 49–52] and
thus an intended feature of our model.
By systematically varying the initial kinemat-
ics of the vehicles, we assessed the model behavior
across a spectrum of front-to-rear scenarios. Due
to the stochasticity of the model (foremost in
behavior prediction and policy sampling), for each
of the 28 sets of initial conditions we ran the simu-
lation of the front-to-rear scenario 10 times. Based
on these simulations, we analyzed the model’s cho-
sen evasive maneuver, response time, and deceler-
ation magnitude and compared it to human data
reported in the driver behavior literature.
Figure 3c shows the probability that the model
will brake only (without steering) for different
velocities and time gaps. Existing studies on how
human evasive maneuver choice depends on sce-
nario kinematics in front-to-rear scenarios are
limited. Thus, we compared our model results to
the few related studies that exist, but these do not
provide sufficiently detailed analyses for rigorously
evaluating our model’s evasive maneuvering deci-
sions. These studies generally suggest that evasive
maneuver decisions, similar to response timing,
depend on the scenario kinematics (see [56] for a
review). Avoiding collisions is generally kinemat-
ically more feasible by braking at lower speeds
and by steering at higher speeds [57] and human
drivers tend to swerve into an adjacent lane if
a kinematically viable escape path exists [58–
60]. In line with these general observations, our
model prefers braking at lower velocities and
favors combined swerving-and-braking or swerv-
ing only responses at higher velocities, regardless
of the time gap (Figure 3 c). At medium veloc-
ities (15 ms −1) the model behavior is sensitive
to the gap between the vehicles: the longer the
time gap, the higher the probability of a brake-
only maneuver. This pattern reflects a trade-off
between the components of the pragmatic values
associated with collisions, control effort (harsh-
ness of braking and steering), and lateral position.
This dependence of swerving choice on time gap
at intermediate speeds has, to our knowledge, not
been empirically tested and represents an inter-
esting quantitative prediction from our model.
In more urgent scenarios (short time gaps), the
model prefers swerving due to the low prag-
matic value of harsh braking. Conversely, in less
urgent scenarios (larger time gaps), the model opts
for braking since moderate braking avoids colli-
sion without incurring the significant reduction of
pragmatic value due to leaving the lane (while the
deviation from the desired velocity is still tolerable
at those medium speeds).
Regarding brake response times, empirical
studies have consistently found a strong depen-
dence on scenario kinematics [2, 3, 6, 14, 53, 61,
62]. Specifically, more kinematically urgent sce-
narios (e.g., with a small initial time gap and/or
hard lead vehicle braking) lead to shorter response
times while less urgent scenarios lead to longer
response times, with approximately linear rela-
tionship between measures of urgency (e.g., the
initial time gap) and mean response time [6, 53].
Our model produced behavior that is remark-
ably consistent with these findings (Figure 3 d).
Interestingly, compared to the evasive maneuver
decisions, velocities do not seem to significantly
influence brake response times, nor does the final
8
chosen behavior. Furthermore, model response
times remain consistent (approx. 1 s) over the
range of short time gaps (0 .5 s to 1.5 s). This last
result could be a consequence of the evidence
accumulation mechanism requiring certain min-
imum time to trigger a re-plan even at a very
high rate of incoming evidence. Relatedly, the lack
of fast enough responses at short time gaps is a
likely explanation for the collisions observed in
the model (only at the shortest time gap of 0 .5 s).
However, because the data reported in the liter-
ature does not cover such short time gaps, this
model prediction remains to be tested in future
studies.
While response selection and its timing are
comprehensively characterized by the choice of
evasive maneuver and response times, response
execution is a dynamic process and can be char-
acterized by a variety of metrics. Here we focus
on deceleration magnitude, which has been previ-
ously shown to depend on the kinematics of the
front-to-rear scenario: human drivers brake harder
in more kinematically urgent scenarios [14]. Our
model captured this phenomenon: the magnitude
of its braking increased with the inverse time-to-
collision at brake onset (Figure 3e). This behavior
of the model can be explained by the pragmatic
value trade-off between avoiding a collision on the
one hand and avoiding the effort of hard braking
and losing velocity on the other hand. In other
words, the model aimed to not brake harder than
necessary to avoid collision.
Opposite-direction lateral incursion
scenario
For evaluating model behavior in the opposite-
direction lateral incursion scenario, we used
human data from a driving simulator study at
the University of Leeds, UK, reported by John-
son et al. [56]. In this study, vehicles initially
approached each other in opposite lanes when the
computer controlled vehicle unexpectedly steered
toward the participant’s lane along a predefined
path. The study implemented three kinematic
variants differing in incursion ”steepness”: (1) a
steep incursion crossing in front of the participant
at a sharp angle and allowing a relatively easy
escape by steering toward the opposite lane; (2)
a medium incursion at a shallower angle, head-
ing directly toward the participant; (3) a shallow
incursion only partially entering the participant’s
lane, making it possible to find an escape path
by steering slightly toward the shoulder (the orig-
inal study used left-hand traffic, so we are here
avoiding directional terms to prevent confusion).
We re-implemented a reversed (i.e., right-hand
traffic) versions of these scenarios in our simulator
setup (see Supplementary Materials Figure A1),
enabling a direct comparison between human and
model behavior in an nearly identical scenar-
ios. An example of our model implemented in
the steep scenario is shown in (Figure 4 a) and
(Figure 4b) shows an example of the medium sce-
nario (Figure 4 b). When looking at the example
simulations (Figure 4 a and b), we can observe
again that the model needs multiple re-plans
before deciding on the final avoidance maneuver.
Compared to the front-to-rear scenario, where this
is likely caused by the model’s bounded planning
capacity, here this is due to the high uncertainty
when predicting the positions of the other vehicles,
which can be seen in the depictions on the top.
In Figure 4a (steep incursion), a first re-planning
is triggered at 4 .2 s (first dashed line) but this
does not significantly reduce the negative collision
component of the pragmatic value. Additionally,
the model neither initiates large steering maneu-
vers nor significant accelerations/decelerations.
Together, this suggests that the high uncertainty
about the other vehicle’s behavior prevents the
agent from finding an evasive policy that is better
(has lower EFE) than the current policy, instead
delaying the decision. The reason for this is that
due to the wide spread in the belief about possi-
ble future trajectories that the oncoming vehicle
may take, there is yet no evasive policy with lower
EFE than the current non-evasive policy. With
the collision risk unresolved after the first re-plan,
surprise quickly accumulates toward a second re-
plan at 4 .6 s (second dashed line). By this time,
the agents are closer, allowing less space for uncer-
tainty to grow and enabling the model to identify
a steering policy that mitigates the collision risk
(after the second re-plan, the collision component
of the pragmatic value no longer significantly con-
tributes to surprise accumulation). The decision to
swerve toward the left is a result of both the other
vehicle having crossed sufficiently over to the right
side to leave a gap for swerving, and the model’s
stronger preference for moving into the opposite
9
t= 4.6 s
a Example - Steep incursion
˜Xego
t= 5.0 s
b Example - Medium incursion
Ego vehicle Other vehicle Ego’s belief about Other
Lateral pos Velocity Control effort Collision
−0.01 −1
Prag. value
λGprag
0 2 4
0 1
Time t [s]
Evidence E
0 10 20
Velocity
v [ms−1]
-5 0 5
Accel.
a [ms−2]
-0.05 0 0.05
Steer angle
δ [rad]
0 2 4
Time t [s]
Steep Medium Shallow
0 0.5 1
Incursion type
Probability
c
Steep Medium Shallow
0 1 2 3 4 5
Incursion type
Response time [ s]
d
Steer right
Collision
Steer left
Model
Data
Braking
Steering
Fig. 4 : Evaluation of the model in the opposite-direction lateral incursion scenario. a) A steep,
unprompted incursion by the other vehicle leads to the model swerving towards the opposite lane. The
sub-panels visualize the dynamics of both vehicles’ velocity v, acceleration a, steering angle δ and (for
the ego vehicle) the components of the pragmatic value Gprag (scaled with the evidence accumulation
gain λ) that underlie the accumulated evidence towards a full policy re-plan. b) In response to a medium
incursion by the other vehicle, where the model crashed at t = 5.8 s. c) The likelihood of the ego vehicle
successfully avoiding the other vehicle by steering left (toward the opposite lane) or right (toward the
shoulder), or failing to avoid a collision. d) Brake and steer response times. In panels C and D, human
behavior and response times measured in a driving simulator study [56] are shown for reference. Video
replays of the example simulations are available in the supplementary information.
10
lane over leaving the road to the right (similar to
Figure 1). However, it can be seen in Figure 4 a
that this trajectory is not optimal. Namely, as
can be seen in the top plot, the planed trajectory
fXego chosen during the second re-plan at t = 4.6 s
(second dashed line) stays in the oncoming lane,
resulting in a low value for the lateral position
component of the pragmatic value. Consequently,
slight course corrections will likely be performed
later (but this would occur outside the current
simulation window).
Figure 4 b shows an example of the medium
incursion scenario where the model is unable to
avoid a collision. Again, likely due to uncertainty
about the other vehicle’s behavior, the first re-plan
at t = 4.0 s (first dashed line) mainly results in a
sharp deceleration and minor steering towards the
right (i.e., towards the shoulder). While steering
towards the right might seem suboptimal given
the other agent’s current path, it aligns with the
influence of the norm-conditioned particle filter,
which – by weighing those particles returning to
the other vehicle’s original lane higher in the EFE
calculation – biases the model toward believing
the other agent will return to its original lane (for
more details on this, see the following section). At
the second re-plan ( t = 4.6 s, second dashed line),
the model abandons the steering to the right and
steers slightly to the left but mainly just continues
braking. However, this only marginally improves
the collision components of the pragmatic value,
leaving the imminent collision risk unresolved. By
the third re-plan at 5 s (third dashed line), the
agent continues braking, trying to minimize the
impact severity, as by this point, the vehicles,
which are as seen in the top panel still on a direct
collision course with nearly no offset, got so close
that a collision becomes nearly unavoidable. Con-
sequently, even the fourth re-plan (t = 5.4 s, fourth
dashed line) fails to find a satisfactory trajectory,
with the fifth re-plan coinciding with the collision
at t = 5.8 s (fifth dashed line).
As described above, we compared our model
to the human data collected in the driving sim-
ulator study by Johnson et al. [56]. We closely
replicated the scenarios of that study in our simu-
lations (see Supplementary Materials 1.3.2), which
allowed direct comparisons between the model
and the data with respect to the chosen avoid-
ance behavior and both braking and swerving
response times (which were extracted using the
same method; see the Methods section). A key
finding of Johnson et al. [56] was that the partici-
pants’ evasive maneuvering patterns and collision
outcomes were strongly determined by the differ-
ent scenario kinematics in the the three incursion
scenarios. In the steep scenario, most participants
avoided collisions by steering toward the opposite
lane, while in the shallow scenario, participants
typically steered toward the shoulder, passing the
other vehicle on the ”inside”. However, in the
medium scenario, the majority of participants col-
lided with the oncoming vehicle. Since the urgency
(i.e., time to collision at the initial steering of
the oncoming vehicle) was constant across sce-
narios, the high crash rate in the medium case
was attributed to greater uncertainty about the
other vehicle’s future path, leaving no clear escape
route.
As shown in Figure 4 c, our model repro-
duced these results, reliably avoiding collisions in
the steep and shallow scenarios through steer-
ing respectively left (toward the center) or right
(toward the shoulder). Interestingly, the model
also reproduce the human propensity for collision
(although at slightly lower rate) in the medium
scenario. Johnson et al. [56] suggested that, con-
ceptually, a key reason why human drivers tended
to collide in the medium incursion scenario is
the high perceived uncertainty about the oncom-
ing vehicle’s future behavior which prevents the
driver from finding a sufficiently certain escape
path. As described above, the current model offers
a detailed computational account for the possi-
ble mechanisms underlying this phenomenon: the
wide spread (uncertainty) in the behavior pre-
dictions about the oncoming vehicle, as well as
a bias towards expecting that it will return to
its own lane due to the norm-conditioning of the
beliefs, prevents the model to find an evasive pol-
icy in time to avoid collision (see Figure 4b above).
An additional factor behind the observed collision
rates was likely also the model’s bounded planning
capacity. Increasing the model’s planning capacity
– by increasing the number of evaluated policies
in the cross entropy method tenfold – resulted in a
significant drop in the model’s collision rate (from
65% to 50% in the medium incursion scenario, and
from 20% to 0% in the shallow incursion).
Furthermore, Johnson et al. [56] found that
braking and steering response times – measured
11
from initiation of the incursion to the first reac-
tion – were generally long, ranging around 3.5 to
4 seconds. While braking response times did not
vary noticeably with incursion severity, steering
response did decrease consistently from the steep
towards the shallow scenario. Our model gener-
ally reproduced the range of response times, with
closely matched median values (Figure 4 d), but
did not capture the variation in steering response
times. One possible explanation may lie in the
many participants avoiding collision in the steep
scenario primarily by braking before making a
final steering adjustment, delaying their recorded
steering response. In contrast, the model relied
more on steering for collision avoidance, requir-
ing an earlier response. The underlying reason for
these behavioral differences between the model
and human drivers are still unclear but may have
to do with varying individual preferences for brak-
ing versus swerving. Further work is needed to see
if these individual differences can be reproduced
by the model by varying its velocity-, lane change-
and lateral control effort preferences.
Evaluating individual model
mechanisms
Comparison to the empirical data
(Figures 3 and 4) revealed that our model cap-
tured the key aspects of human collision avoidance
performance in the two collision avoidance sce-
narios. To better understand which of the model
mechanisms are essential for capturing the empir-
ical observations, we evaluated the performance of
six simpler models which systematically excluded
the key mechanisms one-by-one (Figure 5).
Removing evidence accumulation . With-
out evidence accumulation, the model fully re-
plans its policy at every time step. Consequently,
it starts reacting to changes in the other vehicle’s
behavior immediately after detecting them. This
resulted in a drastic reduction in response times
across all scenarios ( Figure 5 b). Additionally,
the model without evidence accumulation pre-
dominantly failed to avoid collisions in the shal-
low incursion scenario, contrasting sharply with
human data and the full model. This was mostly
caused by the model initiating braking very early.
Given the uncertainty about the other vehicle,
neither steering left nor steering right allows safe
escape paths, so the agent continues braking, com-
ing to a complete stop. At the point in time where
the certainty about the other agent is low enough
for safely choosing either left or right, the agent
can physically no longer avoid a collision (as it
can not move laterally when stopped). An exam-
ple simulation of this scenario can be found in
the supplementary material. The fact that colli-
sions happened mostly in the shallow incursion
scenarios is likely because in the medium and steep
incursion scenarios, early braking leaves enough
space in front of the ego agent for the other vehicle
to move across, which is not the case in the shal-
low incursion. In this scenario, collision would still
occur if the ego agent stayed in its starting lat-
eral position, which makes braking an insufficient
avoidance mechanism. Based on those observa-
tions, the inclusion of evidence accumulation is
critical for accounting for empirical data on human
response times in both scenarios, as well as evasive
maneuver selection in the shallow lateral incursion
scenario.
Removing added noise in behavior pre-
diction. The model that uses deterministic pre-
dictions about the other vehicle produced response
times in the front-to-rear scenario that are only
slightly longer than for both the full model and the
human data (Figure 5 c), especially given shorter
time-gaps. By contrast, in the opposite direction
lateral incursion scenario, it exhibited substan-
tially shorter response times. The reason for this
apparent discrepancy is that in the front-to-rear
scenario, prediction noise results in ego agent’s
believing that the other vehicle may brake more
aggressively, prompting the model to react earlier.
In the lateral incursion scenario, however, remov-
ing the prediction noise decreases ego agent’s
uncertainty about the other vehicle, leading to
earlier steering responses which, given how these
particular scenarios unfolded, turned out be a
more effective avoidance strategy, as evidenced by
the absence of collisions in this case. However, it
should be noted that this strategy was only more
effective after the fact (i.e., with hindsight of how
the scenario played out). In another counterfac-
tual scenario, where the oncoming vehicle turns
back into its own lane,early swerving could instead
result in collision (see [56] for further discussion
of this important point).
Prediction noise affected not only response
times but also the model’s choice of evasive
12
a Full model
0 0.5 1
P(Brake only)
b no evidence
accumulation
c no prediction
noise
d no pedal
constraints
e no looming
perception
f no looming
threshold
g no norm-con.
particle filter
0 1 2 3 4
0 1 2 3
∆tRT [s]
0 1 2 3 4 0 1 2 3 4 0 1 2 3 4
Time gap [s]
0 1 2 3 4 0 1 2 3 4 0 1 2 3 4
0 0.5 1
-8 -6 -4 -2 0
min a [ms−2]
0 0.5 1 0 0.5 1 0 0.5 1
Inv TTC [s−1]
0 0.5 1 0 0.5 1 0 0.5 1
0 0.5 1
Probability
Steep
Medium
Shallow
0 1 2 3 4 5
∆tRT [s]
Steep
Medium
Shallow
Steep
Medium
Shallow
Steep
Medium
Shallow
Incursion type
Steep
Medium
Shallow
Steep
Medium
Shallow
Steep
Medium
Shallow
Fig. 5 : Evaluation of variants of the model without some of its key mechanisms in the front-to-rear
scenario (top three rows, see Figure 3 for the legend) and the lateral incursion scenario (bottom two rows,
see Figure 4 for the legend). In the second and third rows, dashed gray lines depict regressions to model
simulation results.
maneuver in the lateral incursion scenario. In par-
ticular, the model with deterministic predictions
predominantly opted to avoid the other vehicle
by steering left regardless of the incursion pro-
file. This allowed the model to avoid collisions
in all simulations, but is not consistent with the
human data. Overall, these findings underscore
that behavior prediction noise is crucial for accu-
rately reproducing human behavior particularly in
the lateral incursion scenario, and also confirms
the importance of enabling the model to account
for uncertainty in its predictions to represent the
key collision mechanism in the medium incursion
scenario, as discussed in relation to Figure 4 b.
Removing pedal constraints . The model
not constrained by pedal switching delays resulted
in approximately 0.2 s faster brake response times
in both the front-to-rear and lateral incursion sce-
narios compared to the full model (Figure 5 d).
This matches the delay of 0 .2 s implemented for
13
the switch from acceleration to deceleration. This
delay could potentially be accounted for with-
out pedal constraints by slightly decreasing the
gain factor in the evidence accumulation mech-
anism. This approach would, however, also lead
to increased steering response times in the lateral
incursion scenario, which both in the full model
and this ablation were already slightly slower than
the human data. Thus, we deemed these con-
straints essential for describing human response
times in the front-to-rear scenario.
Removing looming perception. We ana-
lyzed a version of the model which directly
perceived kinematic variables without relying on
looming (Figure 5e) as well as one which perceived
looming but did not have a looming perception
threshold (Figure 5 f). In the front-to-rear sce-
nario, both these models differed from the full
model and the human data in that they pro-
duced faster brake response times at longer time
gaps. For the model without the looming thresh-
old, this is due to the fact that greater time
gaps (and therefore greater distances) require a
larger velocity difference to surpass the looming
detection threshold, which delays responses, as
it needs more time to accumulate. Furthermore,
these results being very similar to the model that
did not perceive looming at all (Figure 5 e) indi-
cates that in this scenario, the looming threshold
was a key factor behind the ability of the model
to capture human response times. Additionally,
while not specifically analyzed here, this effect is
expected to be exacerbated in high speed freeway
scenarios where (given the higher speed) the fol-
lowing distances for a given time gap increase, fur-
ther emphasizing the importance that the model
accounts for this phenomenon. In the opposite
direction lateral incursion scenario, removing the
looming threshold (or looming entirely) did not
have any major effect, as the high relative veloc-
ities overcome the looming threshold very early,
and perception accuracy of longitudinal positions
is far less relevant in that scenario.
In summary, models without either looming
perception or looming threshold resulted in qual-
itative differences between the model and human
data on brake response times in the front-to-rear
scenario and collision rates in the lateral incursion
scenario. This highlights the importance of both
looming-based perception and looming perception
threshold, in addition to the strong theoretical
support.
Removing the norm-conditioned particle
filter. In the model without the norm-conditioned
particle filter, the changes to the overall behav-
ior in the front-to-rear scenario are very minor
compared to the full model (Figure 5 g). How-
ever, in the lateral incursion scenario this change
has a major impact on the collision outcome in
the medium incursion scenario, where the model
now avoids collision in all runs, similar to the
model variant without prediction noise. When the
norm-conditioning is removed, the model treats
all predicted trajectories as equally likely instead
of initially focusing on those where the oncoming
vehicle returns to its own lane. This assumption,
together with the reduced pragmatic value asso-
ciated with lane changes, leads the full model
to initially steer towards the right, costing valu-
able time and creating situations where steering
to the left is no longer a viable solution, and col-
lisions become unavoidable. By contrast, in the
model without norm conditioning, potential colli-
sions along steeper incursion trajectories are taken
more seriously earlier, making an initial steering
to the right less likely. Instead, the model with-
out norm conditioning more frequently evades to
the left immediately in such medium incursion sce-
narios, resulting in the observed lack of collisions.
This aligns with the hypothesized role of norm
conditioning in crashes, as discussed in connection
with Figure 4b.
While these difference already highlight the
importance of the norm-conditioned particle fil-
ter, it has the strongest impact in benign (non-
conflict) scenarios. In such scenarios, the model
with the simple kinematics-based behavior predic-
tion mechanism is unrealistically conservative due
to having to plan for all kinematically possible
futures of the other vehicle — a problem that is
avoided by the model with norm-conditioned par-
ticle filter (see Supplementary Materials 1.4 for an
example).
Overall, all six simpler versions of the model
exhibit qualitative differences compared to the
full model, and none capture the human data
across both scenarios as comprehensively as the
full model. This provides evidence that all of the
analyzed model mechanisms are all important for
capturing human collision avoidance behavior.
14
Additionally, we ran a model ablation where
we ignored the epistemic value when selecting
policies, which however did not result in any
meaningful differences.
Discussion
Building on previous work [33], we here presented
an active inference-based framework for model-
ing human collision avoidance behavior based on
first principles. To our knowledge, this is the
first published computational model that offers
a detailed account of human collision avoidance
behavior across multiple conflict scenarios. Our
model reproduces many key results in the rich
literature on collision avoidance in front-to-rear
scenarios, in particular the dependence of response
times and braking magnitude on scenario kine-
matics. The model also generated several detailed
predictions on how evasive maneuver decisions
(braking vs. swerving) vary with scenario kine-
matics which can be tested in future experiments.
Furthermore, we compared the model directly
to human behavior in an opposite-direction lat-
eral incursion scenario with varying kinematics
obtained in a driving simulator study [56]. This
analysis demonstrated that the model can repro-
duce human evasive maneuver decisions, collision
outcomes, as well as response times in the different
incursion scenarios.
A key novel feature of our model is its ability to
flexibly represent closed-loop collision avoidance
through dynamic replanning of policies, includ-
ing braking, steering, and accelerating actions,
in a way that is qualitatively and quantitatively
similar to human collision avoidance behavior.
In contrast, existing publicly available collision
avoidance models either implement a ”one-shot”,
often predetermined, open-loop evasive maneu-
ver [1, 5, 63] or limited aspects of closed-loop
control, such as intermittent braking but no steer-
ing [11, 64]. Some commercially available models –
the Stochastic Cognitive Model (BMW; [65, 66]),
the driveBOT model (cogniBIT; [67, 68]) – report-
edly implement human-like closed-loop behavior
in collision avoidance scenarios. However, the lack
of available information on the detailed working
principles of these models precludes a meaningful
comparison with the current model.
Our model achieves closed-loop behavior by
continuously evaluating evasive policies based on
their expected free energy, pursuing the policy
with the lowest EFE, and allowing for further re-
planning if the chosen policy turns out to not
yield the preferred (and hence expected) out-
comes (e.g., due to limited planning accuracy or
unexpected changes in how the scenario unfolds).
This, in effect, implements a constraint satisfac-
tion mechanism where different model preferences
are traded against each other in finding the policy
with the highest overall combined pragmatic value
and epistemic value. We observed several exam-
ples of this (Figures 3 and 5) where, for example,
the model generally prefers to brake at low speeds
(since the loss related to the preferred speed is not
as high as the cost of changing lane) and swerve at
higher speeds (where the cost of braking in terms
of speed loss are higher). This yields detailed pre-
dictions of human behaviors in different kinematic
situations that could be further tested empirically.
Another important novel aspect of our model is
its ability to dynamically account for uncertainty
about the future behavior of other agents. This is
particularly important in situations like the lateral
incursion scenario where the driver cannot deter-
mine a priori if the other vehicle will continue
crossing the ego vehicle’s lane or if it will turn back
to its original lane, resulting in a wide range of
potential future trajectories of the other vehicle.
However, the uncertainty may be reduced as the
scenario unfolds, opening up new available escape
paths, or escape affordances[56], as was the case in
the current steep and shallow incursion scenarios.
In such cases, a too early evasive response may be
premature (and non-optimal) and does not prop-
erly reflect human behavior. We saw an example of
this in Figure 5c, where the model without predic-
tion noise responded much faster than humans and
the full model, thus avoiding collision in all cases.
However, such overconfident evasive maneuvering
behavior would be detrimental in the alternative
scenario where the other vehicle is turning back
into its original lane. By representing the uncer-
tainty about the other vehicle’s future positions
using a vehicle dynamics (bicycle) model and a
noisy particle filter, our model is able to handle
such situations and successfully reproduce human
behavior.
It should be noted that in the collision avoid-
ance scenarios simulated in the present study,
there is little opportunity for the driver to reduce
the uncertainty about the oncoming vehicle’s
15
future trajectory through epistemic actions. In
other words, there is little the driver can do to
obtain further information that could help predict
what the other vehicle will do. However, as further
discussed below, in the real world communicative
acts such as honking, flashing headlights or ini-
tially moving to the right in the lane could serve
to reduce uncertainty about the oncoming vehi-
cle driver’s intent, but since the oncoming agent
was here assumed to be non-reactive such aspects
were not addressed in the current work (this is a
topic for future development of the model). Thus,
as expected, disabling the epistemic value com-
ponent of EFE did not significantly change the
current simulation results.
While active inference models can be imple-
mented computationally in many different ways,
following [33], we used a stochastic receding-
horizon control architecture as the basis for the
implementation. This shares similarities with prior
work in robotics, particularly decision-theoretic
approaches that explicitly account for uncertainty
in actuation and sensing by propagating belief
states into the future, often using particle-based
representations, and then selecting actions that
optimize expected outcomes based on this pro-
jected belief evolution [69–71]. However, our work
diverges from these engineering models in two
crucial aspects. First, since our goal is to repre-
sent human driver behavior rather than designing
a robotics controller, the modeling focuses on
capturing key aspects of human driving, such
as response timing and evasive maneuver deci-
sion making, rather than optimizing performance.
Second, our modeled agent minimizes EFE (as
prescribed by the active inference framework),
while traditional state-based reward functions
often employed in the control literature lack such
a neuro-biologically plausible objective.
Our model incorporates an explicit mecha-
nism for evidence accumulation to account for
human response timing, based on existing mod-
els [6, 72 ? –74]. Evidence accumulation models
naturally account for the situation-dependency of
response timing in traffic situations: the faster a
traffic conflict escalates, the faster the human’s
response to it [6, 14]. Compared to existing evi-
dence accumulation models, our model introduces
some key novel aspects. In particular, by contrast
to traditional models that accumulate perceptual
evidence (e.g., looming [ ? ]), our model rather
accumulates surprise. Similar ideas have been
explored in existing models [6, 47, 64], based on
the notion that a traffic conflict by definition is an
extremely rare (and hence surprising) event which
always takes place against a ”default” expecta-
tion of how the situation would normally play
out (Figure 1). This is also the key idea behind
the NIEON (Non-Impaired driver with their Eyes
ON the conflict) response time model which con-
ceptualizes the onset of the stimulus that human
drivers respond to in a traffic conflict as the onset
of surprise (i.e., the violation of the initial default
expectation) [6]. The current model generalizes
this idea in several novel ways. First, instead
of triggering a predefined action such as brak-
ing when the surprising evidence has reached the
threshold, the evidence accumulation here trig-
gers the re-planning of a new policy, using the
EFE-based policy selection mechanism discussed
above. Second, the surprise signal that is being
accumulated is not just the difference between a
predicted and actual signal but rather the nega-
tive pragmatic value of the current policy, that is,
how ”bad” the currently selected default policy
is relative to the agent’s preferred observations.
This provides a straightforward solution to the
known problem of how to determine whether a
given surprise signal is relevant to the agent [47].
While we here model evidence accumulation
explicitly, it can in principle be seen as an
implicit feature of active inference [75]. How-
ever, in practice, it is challenging to accurately
represent human response dynamics implicitly in
a simplified model like ours and, in order to
enable a straightforward tuning of the model’s
response performance to human data, we chose
the current explicit modeling of evidence accumu-
lation. As demonstrated by our simulation results
(Figure 5 b), the inclusion of this mechanism is
essential to account for realistic response times in
our model.
The current model is based on the gen-
eral model predictive control architecture origi-
nally developed for the model of routine driving
described in [33] which, in turn, is based on
the standard discrete-time active inference EFE
model for planning agents formulated as a par-
tially observable Markov decision process [24]. The
original routine driving model in [33] focused pri-
marily on the role of epistemic value in resolving
16
uncertainty when driving around visual occlu-
sions and during visual time sharing (drawing
from the rat-in-a-T-maze example in [24]). How-
ever, that model was not aimed at describing
time-critical behaviors. For instance, in collision
avoidance scenarios its responses to sudden stim-
uli would be overly fast, similar to the ver-
sion of our model without evidence accumulation
(Figure 5 b). Extending the original model [33]
with not only evidence accumulation, but also
other mechanisms such as looming-based per-
ception and norm-conditioned predictions was
essential for capturing human collision avoidance
behavior (Figure 5). Otherwise, the model we
reported here retains the key features of the origi-
nal routine driving model needed for dealing with
uncertainty resolution through epistemic action,
thus offering a powerful and general computa-
tional framework for modeling driving behavior,
also beyond collision avoidance. As in [33], we
employed engineering tools like the cross-entropy
method and particle filters with discrete and con-
tinuous variables. However, while relying on such
established methods, our model does not reduce
to a combination of them; instead, these meth-
ods serve as means for implementing specific
cognitive mechanisms within our active inference
framework.
Our framework is grounded not only in active
inference and the free energy principle [26],
but also enactivist approaches to cognitive sci-
ence [76, 77]. Active inference and enactivist cog-
nitive science share the the foundational notion
that behavior in biological agents results from
a self-organizing process geared towards sustain-
ing the agent’s integrity (existence) over time.
This emphasizes a strong continuity between life
and mind [77–79] and offers a natural solution
to the problem how the certain aspects of the
environment become meaningful and relevant to
an agent [80]. Such an existential imperative can
be described as the organism striving to main-
tain itself in a sparse attractive set of preferred
agent-environment states, where the attractive set
depends on the specific organism in question.
Thus, to survive over time, a fish needs to remain
in water with the right chemical balance and tem-
perature range, obtain food, avoid being eaten
by certain predators etc. This implies that these
particular states are meaningful and relevant to
the fish which then acts in order to observe these
states with a high degree of certainty, thus look-
ing as if it is minimizing free energy over time.
By the same token, we endowed our model with
a (highly simplified) set of preferred states that
are meaningful and relevant to a human car driver
(avoid danger of collision, stay on the road, keep
up progress, avoid too harsh braking/steering) and
defined the model such that it acts (selects and
executes policies) in a way that maximizes the
chance of observing these preferred states.
Related to this, our model also offers a novel
operationalization of the classical notion of affor-
dance, traditionally broadly defined by Gibson [35]
as what the environment ”offers the animal, what
it provides or furnishes, either for good or ill ” (p.
127). Thus, when our model identifies candidate
evasive policies associated with low EFE, these
can be understood as affordances in the sense of
opportunities for actions that are worth pursuing.
The active inference framework offers a further
distinction between pragmatic affordances yield-
ing unsurprising, familiar and preferred observa-
tions and epistemic affordances yielding informa-
tion that can resolve uncertainty about pragmatic
affordances [33, 81, 82] (see [56]) for a further dis-
cussion about this expanded notion of affordances
and its relation to the classical affordance concept
in ecological psychology).
Thanks to its generality, active inference-based
models have been developed for virtually every
facet of biologically-based cognition and behav-
ior, in organisms ranging from single cells [78],
plants [83], individual animals and humans [84]
to social and cultural phenomena [85], which pro-
vides a great source of concepts and ideas for
modeling different aspects of human road user
behavior. Thus, importantly, we see active infer-
ence not just as a computational approach to
model development, but as a general theoretical
framework for understanding road user behavior
that can guide modeling at a conceptual level
and generate novel hypotheses for experimental
studies. At the same time, the great majority
of existing active inference models use relatively
simple toy scenarios, thereby limiting its appli-
cability to real-world human behavior [9]. By
operationalizing active inference in the context of
a dynamically rich task, that is, collision avoid-
ance and evaluating it against human data from
both simulated and real-world driving, this study
17
pushes the boundaries of active inference appli-
cations toward the modeling of complex human
naturalistic behaviors.
While, as discussed above, our model repre-
sents a significant advancement in human collision
avoidance modeling, it has several limitations
that can be addressed in future work. First, in
this work we essentially hand-tuned the model
parameters to fit the human data from the two col-
lision avoidance scenarios. Whereas this highlights
the model’s generalizability and interpretability,
hand-tuning model parameters is impractical at
scale. Future research should explore system-
atic parameter optimization methods, for example
using the approach suggested by Wei et al. [86].
Second, the current model assumes that other
agents are non-reactive, an assumption that in
general case does not hold. Thus, future work
incorporating reactive agents and investigating
the role of communication in agent interactions
driven by epistemic value could extend the model’s
applicability, enabling simulations of interactions
between multiple active inference agents. More-
over, the current model (as well as the original
model in [33]) only reasons at a shallow ”unso-
phisticated” level about how actions bring about
future observations with varying degrees of uncer-
tainty. Further work could explore the possibili-
ties of incorporating sophisticated inference [87],
which enables ”deeper” levels of recursive reason-
ing about how future observations would lead to
updated beliefs and corresponding new actions.
This may be particularly relevant when modeling
interactions between road users.
Third, the model currently only accounts for
perceptual limitations in terms of visual looming,
which, strictly speaking, only applies to objects
located along a straight path of travel relative to
the gaze direction of the observer (in our case, this
means objects located straight ahead of the ego
vehicle). Thus, to represent other types of percep-
tual limitations, alternative perceptual variables
would need to be explored such as, for example
bearing angle as a specification of perpendicular
collision course [88].
Fourth, while mechanisms for dealing with par-
tial observability during occlusions and visual time
sharing were explored in [33], further work is
needed to develop more comprehensive solutions
for representing and reasoning about multiple
agents hidden behind occluding objects or appear-
ing outside the driver’s field of view (see also Wei
et al. [89]).
Finally, while the current policy sampling
and kinematic-based particle filter approach was
demonstrated to work well in the current scenar-
ios, this could be a limiting factor in scaling the
model to a wider range of scenarios, especially
when modeling pre-conflict scenarios with more
complex road infrastructures and road user inter-
actions. To overcome this potential limitation,
machine-learning-based generative models from
existing data-driven models [17, 21, 90–94] could
be leveraged to generate possible futures in the
current model that are evaluated by EFE, either
stand-alone or in combination with the current
kinematic rollouts, thus potentially enhancing the
generalizability of the model.
Overall, our work contributes to the recent
body of research [33, 86] with new evidence that
active inference can serve as a general frame-
work for computational road user modeling. Along
with the emerging real-world applications of active
inference in robotics [95] and artificial intelli-
gence [96], this work can aid the development
of simulated agents used for real-world applica-
tions in advanced driver assistance systems and
autonomous vehicle evaluation.
Methods
Model principles
Our model follows the architecture of the original
model initially formulated by Engstr¨ om et al. [33],
and combines some of the original elements of
that model with multiple new mechanisms. In par-
ticular, our model retains the representation of
probabilistic beliefs using sets of samples and the
correspondingly sample-based estimation of the
expected free energy (see equation (6)) as well as
the cross entropy method used for policy selec-
tion. In addition to these mechanisms, we intro-
duced looming perception, evidence accumulation,
the norm-conditioned particle filter, and the con-
straints on acceleration profiles (see Figure 5 for
the analysis of the impact of these new mecha-
nisms on model behavior). We also modified the
Bayesian belief update (equation (2)) and the
calculation of the epistemic value (equation (7)).
18
In our active inference model, the environment
is represented by the generative process, with a
state of the world η ∈ Ewhich is partially observ-
able by the agent. The agent can influence the
environment with its actions a ∈ A(according to
the state transition probability bp(η′|η, a)), result-
ing in observations o ∈ O, whose dependence on
the world state is described inbp(o|η) (the bp is used
to show these function be part of the generative
process).
The agent has an internal model of the world,
the generative model, with the corresponding par-
tially observable state s ∈ S, and the corre-
sponding state transition function p(s′|s, a) and
observation probability p(o|s). As the generative
model is an abstraction of the real world described
by the generative process, η and s do not nec-
essarily have to represent the same state spaces
(E ̸= S). The agent is uncertain about the state
of the generative model, represented by the prob-
ability density function q(s) (referred to as the
agent’s belief about the state s). Following [33], in
our model the agent represents its belief distribu-
tions q(s) in a non-parametric way as a set of N
samples S = {s1, . . . ,sN } (i.e., a particle filter).
The agent then tries to minimize its free
energy, both in the belief q(s) it forms (variational
free energy) and the actions a it chooses (expected
free energy ). The action and policy selection is
based on the existence of a preference prior p(o)
depicting preferred observations.
Perception
At time t, the agent perceives the world state ηt,
resulting in the observation ot:
ot ∼ bp(o′|ηt) (1)
With this observation, the agent updates its old
belief q(st−1) to q(st). The active inference frame-
work postulates that this update is based on the
minimization of the variational free energy [24],
but in our case we use standard Bayesian updat-
ing:
q(st) ∝ p(ot|st) Eq(st−1)p(st|st−1, at−1) . (2)
Here, the particle filter first advances the
individual samples in St−1 (representing
q(st−1)) using the transition function to
get the expected states SA,t (approximating
qA(st) = exp
 
Eq(st−1) ln p(st|st−1, at−1)

), with
sA,t,n ∼ p(s′|st−1,n, at−1) being randomly sam-
pled. Then, a kernel density estimate [97, 98]
based on SA,t is used to approximate qA(st) as
a Gaussian Mixture Model (GMM). Assuming
that p(ot|st) is Gaussian as well, q(st) can also
be represented as a GMM; this allows straightfor-
ward sampling of St. Compared to the approach
in the original model [33] of weighting samples
sA,t,n ∈ SA,t with p(ot|sA,t,n) and then resam-
pling based thereon, this approach allowed us
to represent large shifts in beliefs outside the
extreme values of the initial set S0.
The agent’s visual perception in our model is
based on looming (Supplementary Materials 1.2.2)
– the optical information immediately available
to humans about the relative motion of objects
straight ahead in the direction of travel [35].
Specifically, the relative position and motion of
objects along the forward path of the agent is
perceived in terms of the visual angle φ sub-
tended by the object at the retina of the observer,
and its derivative, the angular rate ˙ φ (loom-
ing) [34, 40]. Due to the nonlinear relationship
between the observer’s distance to the observed
vehicle (in Figure 2 a referred to as ∆ x) and φ
(with increasing distances, equal variations δ∆x
lead to increasingly smaller δφ), perception errors
for φ and ˙φ will lead, respectively, to increasing
inference errors and therefore uncertainty about
the position and speed of the leading other vehicle
at increasing distances. We represent this aspect
in the model by setting the noise in p(o|s) to be
constant across φ and its derivatives.
At a certain distance, ˙φ is no longer perceptible
to the human eye, which implies a minimal thresh-
old for looming detection [41, 42]. To account for
this, the model incorporates a detection thresh-
old on ˙ φ (i.e., for small | ˙φ|, the means of the
observation probabilities p(o|s) for velocities and
acceleration were set to the values correspond-
ing to ˙φ = 0). This means that changes in the
other vehicle’s velocity cannot be perceived by a
human driver beyond a certain distance, resulting
for example in a delayed recognition if the lead
vehicle suddenly brakes.
19
Behavior prediction
After observing the current state of the world,
the agent applies the state transition function
p(s′|s, a) starting from its current belief q(st)
in order to generate a predicted belief about
the future states of the situation eqs(sτ |πt, q(st))
(with τ ∈ {t + 1 , . . . , t+ H}, an arbitrary
policy π containing the ego agents sequence
of planned actions, and prediction horizon H)
of agents in the scene, as well as the corre-
sponding belief over possible future observations
eqo(oτ |πt, q(st)) = Eeqs(sτ |πt,q(st))p(oτ |sτ ). During
this prediction process, the agent adds noise to the
control inputs of the other agents to represent the
possibility that they might change their behavior.
Practically, the agent advances the
belief eqs(sτ |πt, q(st)) (represented by
eSτ = {sτ,1, . . . ,sτ,N }) to the next time-step
by using the state transition function (in our
case based on a bicycle model [99], see Supple-
mentary Materials 1.2.1) on each of the sample
states sτ,n ∼ p(sτ |sτ−1,n, aτ−1, and applies
additive noise (similarly to forming the expected
belief qA(s) in the belief update). The belief
eqo(oτ |πt, q(st)) is then represented by the set
eOτ = {oτ,1, . . . ,oτ,N }, where oτ,n ∼ p(oτ |sτ,n).
It could be noted that this belief propagation
scheme is unsophisticated in the technical sense
that it does not condition the beliefs about future
states on corresponding counterfactual observa-
tions. While it would theoretically be possible to
use a form of sophisticated inference [87] that
accounts for such conditioning, we here used the
unsophisticated approach for simplicity, similar to
the original model [33] and most existing active
inference models.
A key advantage of this kinematics-based
behavior prediction approach (compared to
machine learning-based data-driven approaches)
is that in a collision avoidance scenario it allows
the model to account for kinematically possible
but low-probability “extreme” (long-tail) behav-
iors of other agent once the conflict has been
initiated, something which is hard to learn based
on data. However, on the flip side, this could
yield too pessimistic behavior predictions prior
to the conflict. For example, if the noise in the
particle filter is high, leading to a high disper-
sion of the particles, the model operates based on
the belief that, for example, any oncoming vehi-
cle may encroach into their lane at any time.
This leads to overly reactive behaviors. Human
drivers, by contrast, typically avoid such pes-
simistic predictions by assuming that other drivers
will adhere to road rules and other established
traffic norms [44, 45]; for example, they typically
assume that oncoming vehicles will stay in their
lane unless there is evidence to the contrary. With-
out such an assumption driving on roads with
multiple adjacent lanes would not be possible.
To address this issue, we introduced the nor-
mative probability density function, pn : O →
(0, 1], reflecting expectations about adherence to
traffic norms, by assigning lower probability val-
ues to future observations that violate established
norms (such as leaving the lane). Thereby, we
implement an assumption into the model that
other road users will behave according to such
norms. While beliefs about traffic norms could
also be implemented directly in the state transi-
tion function p(s′|s, a), we here chose this simpler
approach which was deemed sufficient for present
purposes. This possibility can be explored in
future work.
Specifically, we normalize the probability den-
sities pn(oτ ) across the N particles in eOτ that
represent eqo(oτ |πt, q(st)). This ensures that when
normative behavior is no longer observed (i.e.,
all values of pn(oτ ) for oτ ∈ eOτ are similarly
low), norm violations are still treated as likely
events requiring an appropriate response. Specif-
ically, as there are no norm-compliant particles
to dominate onto the EFE calculation, the norm-
violating particles will now all be considered with
similar importance. This approach – which we
call norm-conditioned particle filter – helps align-
ing the model’s predictions with realistic driving
scenarios while allowing for the anticipation of
norm violations when necessary. As traffic norms
are typically scenario-specific, we defined them
individually per scenario (Supplementary Materi-
als 1.3.1 and 1.3.2).
Policy sampling
Based on the predicted behavior of the other vehi-
cle, the agent selects its policy π. Here, policies
are defined as sequences of H future actions; fol-
lowing the bicycle model, the actions are defined
in terms of acceleration along and steering rate ω.
20
These actions are selected using the cross-entropy
method [33, 48], which iteratively resamples sets
of M candidate policies K times, where the resam-
pling focuses around the subset of the βM best
samples from the previous iteration. Specifically,
the agent takes the mean and variance of this
promising subset (ignoring potential correlations),
and then samples a new set with size M from the
corresponding normal distribution. In contrast to
the original model [33] that randomly picked the
final sampling output from the last iteration’s set,
here we specifically choose the best sample.
To better represent human behavior, the
model incorporates a pedal constraint to filter out
unrealistic changes in acceleration (Supplemen-
tary Materials 1.2.3). As human drivers generally
control acceleration by operating the brake and
gas pedal with a single foot and cannot move the
foot between pedals instantaneously, the model
imposes a constant holding time interval of 0 .2 s
at a0 ≲ 0 ms−2, such that if the model transitions
from a current acceleration along > a0 to a target
acceleration along,f < a0, it must first decelerate
to a0, maintain that value for 0.2 s, and then pro-
ceed to along,f . The same applies for acceleration
changes in the other direction.
Policy roll-out and evaluation
To evaluate a policy π, the agent first uses the
bicycle model to roll out its possible future states
based on π. In the general case, the possible
future states of the agent and the other vehicle
are coupled, hence the agent rolls out its poli-
cies jointly with the predicted futures of the other
vehicle. For the reason of simplicity, however, our
model assumes that in p(s′|s, a) the other vehicle
is unresponsive to the actions of the ego vehicle,
allowing us to separate behavior prediction and
policy roll-out.
Active inference then rests on the fundamental
assumption that an agent prefers policies which
minimize its expected free energy(EFE) G over the
prediction horizon of H time steps (i.e., the best
policy is the one with the lowest EFE). This EFE
combines the desire of the agent to, on the one
hand, observe itself in states that it prefers (max-
imize pragmatic value gpragm) and, on the other
hand, seek information that may reduce uncer-
tainty about the world (maximize epistemic value
gepist):
G(πt, q(st)) =
t+HX
τ=t+1
− gpragm (eqo(oτ |πt, q(st)))
− gepist (eqs(sτ |πt, q(st))) .
(3)
The pragmatic values gpragm is defined as
gpragm (eqo(o)) = Eeqo(o)pn(o) ln p(o) , (4)
while we use the Shannon entropy H to calculate
the epistemic value [24]
gepist (eqs(s)) = Eeqo(o)DKL [eq(s|o)|eqs(s)]
= H(Eeqs(s)p(o|s)) − Eeqs(s)H(p(o|s)) .
(5)
The first term in Equation (5) is known as thepos-
terior predictive entropy and represents the extent
to which a policy is expected to yield a variety
of different observations. The second term, known
as expected ambiguity represents the diversity of
observations expected for a given state, that is,
the extent to which the observations of that state
are unreliable (e.g., due to reduced visibility).
In our particle-based representation, we rep-
resent eqs(s) with the set eS of N particles and
eqo(o) = Eeqs(s)p(o|s) with the set eO, resulting in
the approximations
˜gpragm

eO

=
P
o∈ eO
pn(o) lnp(o)
P
o∈ eO
pn(o) (6)
and
˜gepist

eS, eO

= − 1
N
X
o∈ eO
ln

 1
N
X
s∈eS
p(o|s)


− 1
N
X
s∈eS
H(p(o|s)) ,
(7)
under the assumption that the entropy
H(p(o|s)) : S → R can be calculated analyt-
ically. The original model [33] had calculated
gepist by using KDE methods based on eO to
approximate eqo(o) = Eeqs(s)p(o|s), compared to
us using 1
N
P
s∈eS
p(o|s). We opted for this different
approach, as the original estimation would result
21
in an over-approximation of eqo(o), given that we
evaluate the KDE exclusively at the center of
each kernel. Consequently, we use the following
approximation ˜G for the EFE:
˜G(πt, q(st)) =
t+HX
τ=t+1
− ˜gpragm

eOτ

− ˜gepist

eSτ , eOτ

.
(8)
When evaluating the pragmatic value, we
assume that the preference (i.e. the distribution
of desired observations) p(o) accounts for four
aspects of the agent’s objective: a) to maintain
its desired longitudinal velocity, b) to minimize
the magnitude of control inputs, c) to remain
on the road and within its current lane (e.g.,
avoiding lane markers or opposite lanes), d) pre-
vent collisions, and e) avoiding hazardous situ-
ations. Each of these aspects is represented by
an individual preference function (Supplementary
Materials 1.2.4), which are multiplied together:
p(o) = N(vego|µv, σv) N(along,ego|0, σa) N(ωego|0, σω)
plat(yego) pcoll(o) psafe(o) .
(9)
For psafe(o), the model specifically seeks to
avoid states where, under the assumption that
the other vehicle begins braking suddenly with a
deceleration of aOV,min, the ego vehicle would fail
to avoid a collision despite initiating maximum
braking after a response time of 1 s.
Surprise-based re-planning
Our model assumes that on every time step, the
agent performs planning incrementally, unless it
observes a surprising event, in which case it re-
plans the full policy. Practically, on every time
step the agent takes the policy chosen in the previ-
ous time step, disregards its first action (as it was
already executed) and assumes that the remaining
actions constitute all but the last actions of the
new policy. The above policy selection mechanism
is then used to generate the last action of the new
policy.
In parallel with incremental policy updates, on
every time step the agent accumulates evidence in
favor of a full re-plan, using the accumulation rate
λ:
Et = Et−1 + λϵt . (10)
Here, we follow Engstr¨ omet al. [6] in accumulating
surprise ϵ ≥ 0, defined as the residual information
of the pragmatic value [47]:
ϵt = Hmax
o
ln p(o)−
t+HX
τ=t+1
gpragm (eqo(oτ |πt, q(st))) .
(11)
Under this definition, the surprise is the differ-
ence between the highest pragmatic value possible
and the actual pragmatic value of a policy. For
instance, if a policy would result in the most
preferred observation, the agent would not accu-
mulate any additional evidence. However, if a
policy would lead to an undesired (i.e., a priori
unlikely) observation, much evidence for a re-plan
would be gained.
If the accumulated evidence is below the
threshold of 1, the model then follows the
extended policy. Otherwise, it generates a com-
pletely new policy, applying the above policy
selection mechanism to every action in the policy.
Finally, after the policy is determined, its first
action at is used to update the state of the actual
world. This is done using the state transition
function of the generative process:
ηt+1 ∼ bp(η′|ηt, at) (12)
Model parameters
Each of the key model mechanisms has a num-
ber of parameters associated with it (see Table 1
for an overview of the 26 most essential param-
eters). For 12 of them, the exact values have
been directly adopted from the literature, in par-
ticular the original model [33]. Another thirteen
model parameters were treated as free parame-
ters, and were manually tuned to qualitatively
match the empirical observations. It was not the
purpose of this study to obtain the closest possi-
ble fit to human data so no exhaustive parameter
optimization was performed.
Metrics
Front-to-rear scenario
In this scenario, we used the vehicle trajectory and
driver input data to extract brake response times
and deceleration magnitudes. To that end, we fol-
lowed Markkula et al. [14], extracting response
22
Table 1: An overview of the most essential parameters used in the full model. For tuned parameters,
we normally only tested three to four different parameters, with the drift rate λ being the noticeable
exception.
Parameter Description Source
State transition function p(s′|s, a)
∆t = 0.2 s Time step size Model of routine driving [33]
4.2 m× 1.72 m Vehicle size Matching [56]
w = 3.65 m Lane width Matching [56]
σa,0 = 3 ms−2 Noise applied to other vehicle’s accelera-
tion during belief update
Tuned parameter
σω,0 = 0.4575 ms−2 Noise applied to other vehicle’s steering
rate during belief update
Tuned parameter
σa = 0.6 ms−2 Noise applied to other vehicle’s accelera-
tion during behavior prediction
Tuned parameter
σω = 0.0915 ms−2 Noise applied to other vehicle’s steering
rate during behavior prediction
Tuned parameter
Observation probability p(o|s)
˙φ0 = 0.002 15 s−1 Looming threshold Taken from [42]
Preference function p(o)
µv = v0 Mean of preference distribution of agent’s
velocity v
Model of routine driving [33]
σv = 0.5 ms−1 Standard deviation of preference distribu-
tion of agent’s velocity v
Tuned parameter
σa = 0.1 ms−2 Standard deviation of preference distribu-
tion of agent’s acceleration a
Tuned parameter
σω = 0.02 s−1 Standard deviation of preference distribu-
tion of agent’s steering rate ω
Tuned parameter
gLL = −15000 Pragmatic value for leaving the road Tuned parameter
gLC = −1000 Pragmatic value for driving on a lane
boundary or in opposing lanes
Tuned parameter
gC = −10000 Pragmatic value after collision with rela-
tive velocity of 10 ms−1
Tuned parameter
Policy selection
H = 30 Prediction horizon Model of routine driving [33]
N = 75 Number of particles Model of routine driving [33]
K = 10 Number of iterations of policy sampling Model of routine driving [33]
M = 100 Tuned parameter
β = 0.1 βM samples with lowest EFE are used as
base for next iteration
Model of routine driving [33]
N
 
0, 5 ms−2
Distribution to sample accelerations aτ in
first iteration from
Model of routine driving [33]
(mean) and Tuned parame-
ter (std)
N
 
0, 0.1 s−1
Distribution to sample steering rates ωτ in
first iteration from
Model of routine driving [33]
(mean) and Tuned parame-
ter (std)
a0 = −0.1 ms−2 Acceleration applied when no pedal is
pressed
Logical consideration
λ = 10−5.9 Evidence accumulation drift rate Tuned parameter
23
times by fitting a piecewise-linear function to the
recorded velocity data; the brake response time
was then determined as the time instant when
the first constant line switches to one with falling
velocity. The slope of this line was used as the
estimated deceleration magnitude.
Lateral incursion scenario
In this scenario, we extracted brake and steer-
ing response times following Johnson et al. [56],
by interpolating along the acceleration along and
steering angle δ data to find the time at which
−1 ms−2 and 0 .0077 rad (i.e., a steering wheel
angle of 5 ◦) are exceeded, to extract brake and
steering response times respectively.
Conflict of Interest
JE, MO’K, LJ and JM were employed by
Waymo LLC and conducted the research without
any external funding from third-parties. Tech-
niques discussed in this paper may be described
in U.S. Patent Application Nos. 18/614,428
and 63/657,623. Delft University of Technology
received funding from Waymo LLC for parts of
the research carried out by JFS, but JFS received
no direct financial benefit for his contributions to
the paper.
Acknowledgments
We thank Daphne Cornelisse for creating
figures 1 and 2, as well as Martijn Wisse, Todd
Hester, and Trent Victor for providing helpful
feedback on the manuscript.
Author contributions
Julian F. Schumann : Methodology, Soft-
ware, Validation, Formal analysis, Investigation,
Writing - Original Draft, Visualization. Johan
Engstr¨ om: Conceptualization, Validation, Writ-
ing - Original Draft, Supervision, Project adminis-
tration, Funding acquisition. Leif Johnson: For-
mal analysis, Writing - Review & Editing, Visu-
alization. Matthew O’Kelly : Writing - Review
& Editing. Joao Messias : Writing - Review &
Editing. Jens Kober: Writing - Review & Edit-
ing, Supervision. Arkady Zgonnikov: Resources,
24
Writing - Review & Editing, Supervision, Project
administration, Funding acquisition.
25
1 Supplementary Material
1.1 Active Inference Framework
To model the behavior of human drivers in different scenarios, we combine Active Inference and Evidence
Accumulation. For sake of either notation, we use the shorthand of b1:B = {bi|i ∈ {1, . . . , B}}. Addi-
tionally, while the predicted beliefs about states eqs(sτ ) and observations eqo(oτ ) for τ > tdepend on the
current belief q(st) and the chosen policy πt (sequence of planned actions), so that the correct notation
would be eqs(sτ |πt, q(st)) and eqo(oτ |πt, q(st)) respectively, we will use the shorthand expressions eqs(sτ )
and eqo(oτ ) to improve readability.
1.1.1 Generative process and Generative model
The basic concept of active inference is the idea that a human agent does not know the actual mechanism
underlying their surrounding world (called generative process), but instead relies on an internal model
(the so called generative model) approximating the true world. These describe how the true state of the
world (ηt), a state of the agents’ belief about the world (st)), the agent’s actions (at), and the observations
of the true world ot at a time t interact with each other. Here, the generative process consists out of two
parts:
• The true transition probability bp(ηt+1|ηt, at). It describes how a certain action at time t influences the
future world state.
• The true observation probability bp(ot|ηt). It describes how likely it is that a certain observation can
be perceived given the current state of the world.
Meanwhile, the generative model consists out of two parts as well.
• The internal state transition probability p(st+1|st, at, θs), which might be parameterized by θs.
• The internal observation probability p(ot|st, θo), which might be parameterized by θo.
The second main idea of active inference is that an agent is uncertain about its belief about the world
st, meaning that instead of a single values, we instead assume that the agent holds a probabilistic belief,
denoted by q(st). In general, the agent could also have some uncertainty regarding the generative model
itself (i.e., there is a probabilistic belief q(θ) about the general model ’s parameters θ = {θo, θs}), but
we will not include this assumption in favor of a computationally more efficient model. We represent
stochastic beliefs q(st) by N = 75 equally likely representative samples St = st,1:N .
Given a world with the previous state ηt−1, an belief St−1, and a chosen action at−1, we can update
those in the following way:
1. We randomly sample our future world stateηt using the transition probability of thegenerative process:
ηt ∼ bp(η′|ηt−1, at−1) (A13)
2. We generate the observations ot that the agent makes. Under the assumption that the uncertainties
in the generative process are negligible compared to the uncertainties in the generative model, we use
the expected value:
ot = Ebp(o′|ηt)o′ (A14)
3. We lastly have to update the internal belief of the agent. Here, using variational inference, we get:
q(st) ∝ p(ot|st, θo) Eq(st−1)p(st|st−1, at−1, θs)
∝ p(ot|st, θo) qA(st) (A15)
To apply this to our sample based belief representation, we first generate the updated samples
SA,t = sA,t,1:N that represent qA(st) and follow from the internal state transition probability
26
p(st|st−1, at−1, θs), with sA,t,n ∼ p(s′|st−1,n, at−1, θs). One can then get an explicit approximation
for qA(st) using a Kernel Density Estimate (KDE) based on SA,t, which can be expressed as
qA(st) ≈ 1
N
NX
n=1
N (st|sA,t,n, ΣA,t) . (A16)
At this point, with qA and p(o|s) both known, one could generate the updated belief samples St with
a form of the Metropolis Hastings algorithm, which is however computationally inefficient.
Instead, a faster update is possible, as long as there exists a bijective mapping L under which
p(o|s) can be expressed as a normal distribution:
p(ot|st, θo) = N (L(ot)|µ(L(ot)) + L(Ast + b), Σ(L(ot))) |det JL(ot)|
= N (L(Ast + b)|L(ot) − µ(L(ot)), Σ(L(ot))) |det JL(ot)| (A17)
Then, instead doing our update over s directly, we can instead do it over sL,t = L(Ast + b). Namely,
we can use a KDE to instead calculate qL,A(sL,t), where with sL,A,t,n = L(AsA,t,n + b) we get
qL,A(sL,t) ≈ 1
N
NX
n=1
N (sL,t|sL,A,t,n, ΣL,A,t) . (A18)
Substituting (A18) and (A17) then allows us to express qL(sL,t) as a Gaussian multi mixture model,
from which sampling SL,t is trivial:
q(st) ∝ p(ot|st, θo) qA(st)
⇐⇒ qL(sL,t) ∝ N(sL,t|L(ot) − µ(L(ot)), Σ(L(ot))) qL,A(sL,t)
∝∼
NX
n=1
N (sL,t|L(ot) − µ(L(ot)), Σ(L(ot))) N (sL,t|sL,A,t,n, ΣL,A,t)
∝∼
NX
n=1
wt,n N (sL,t|µt,n, Σt)
(A19)
with µo = L(ot) − µ(L(ot))
Σt =

Σ−1
L,A,t + Σ(L(ot))−1
−1
µt,n = Σt

Σ−1
L,A,tsL,A,t,n + Σ(L(ot))−1µo

(A20)
wt,n ∝ exp

−1
2 (sL,A,t,n − µo)T (ΣL,A,t + Σ(L(ot)))−1 (sL,A,t,n − µo)

.
After sampling sL,t,1:N from the GMM, we can get our final sample St = st,1:N with st,n =
A−1  
L−1(sL,t,n) − b

.
If A is not full rank, we will have to simply assume that the distribution q(st) orthogonally to the
image of A will be identical to the one in qA(st). However, it must be noted that in our simulations
A will be the identity matrix.
In the update of our model, we use a time step size of ∆ t = 0.2 s
27
1.1.2 Expected Free Energy
After the agent updates its internal belief q(s), it then has to generate a new policy πt = at:(t+H−1)
(with at = [πt]1) over a prediction horizon of H time steps (we use H = 30 in our implementation). In
general active inference, it is postulated that such a plan is selected based on the minimization of the
expected free energy G, here defined using the preference function p(o):
G(πt|q(st)) =
t+HX
τ=t+1
g(πt, q(st), τ)
=
t+HX
τ=t+1
−Eeqo(oτ )pn(oτ ) ln p(oτ )| {z }
Pragmatic value gpragm
−
 
H(eqo(oτ )) − Eeqs(sτ )H(p(oτ |sτ , θo))

| {z }
Epistemic value gepist
(A21)
Here, the normative probabilitypn is used to implement some norm-conditioned belief about the likelihood
of observations (i.e., while some observation oτ might be kinematically equally likely to others in eOτ ,
it might be perceived as less likely because it violates some norms, such as driving on the wrong side
of the road). We call this use of pn an norm-conditioned particle filter. It must be noted that it could
be argued that such beliefs are better implemented directly in the state transition function, this would
require a much more detailed balancing ofpn, complicating the fitting of the model. Therefore, for reasons
of simplicity, we chose the current approach. Meanwhile, eqs(sτ ) and eqo(oτ ) correspond to the beliefs that
the agents predicts for internal states and observations when following a certain policy, with
eqs(sτ ) = Eeqs(sτ−1)p(sτ |sτ−1, aτ−1, θs)
eqo(oτ ) = Eeqs(sτ )p(oτ |sτ , θo) (A22)
We use again our sample based approach for belief representation, with eSτ = sτ,1:N representing eqs(st)
(with sτ,n ∼ p(s′|sτ−1,n, aτ−1, θs)) and eOτ = oτ,1:N approximating eqo(oτ ) (where oτ,n ∼ p(o′|sτ,n, θo)).
For the initial step of τ = t + 1, we can assume that eSt = St. Based on this, one can then calculate the
expected free energy g at one timestep with
g(πt, q(st), τ) ≈ −
P
oτ ∈ eOτ
pn(oτ ) lnp(oτ )
P
oτ ∈ eOτ
pn(oτ )
−

H(eqo(oτ )) − 1
N
X
sτ ∈eSτ
H(p(o′|sτ , θo))

 ,
(A23)
where we use the approximation
H(eqo(oτ )) = H
 
Eeqs(sτ )p(oτ |sτ , θo)

= − 1
N
X
oτ ∈ eOτ
ln

 1
N
X
sτ ∈eSτ
p(oτ |sτ , θo)

 (A24)
To maximize G, we use the Cross Entropy Method (CEM) for model predictive control, which is an
iterative method over k ∈ 1, . . . , Kwith K = 20:
28
1. We define a distribution pπ,k(πt) = N(πt|µπ,t,k−1, diag(σ2
π,t,k−1)) over the policy space, from which
we sample the M = 100 policies πt,k,1:M from pπ,k(πt) and calculate the respective expected free
energy (after adjusting for pedals with freal) Gt,k,m = G(freal(πt,k,m), q(st)) (see (A23)).
2. We select the β = 0.1 ∈ [0, 1] percent samples πt,k,1:M with the lowest expected free energy.
3. We update our distribution, where µπ,t,k and σπ,t,k are the mean and standard deviation of the
aforementioned βM selected best plans.
For the first iteration, we choose µπ,t,0 = 0, while we choose as standard deviations in σπ,t,0 value of
5 ms−2 for accelerations a and 0.1 s−1 for steering rates ω. The final policy is then selected as
πt = freal
 
argmin
m∈{1,...,M}
G(freal(πt,K,m), q(st))
!
. (A25)
Here, freal is used to prevent unrealistically control inputs.
1.1.3 Evidence Accumulation
Commonly, the policy πt is re-chosen at every timestep. However, research has shown that humans tend
to make decisions (such a changing preselected policies) only if there is enough evidence supporting such
a decision, in a process called evidence accumulation. Here, we implement this concept by having the
agent accumulate evidence Et towards the need for selecting a new policy. The agent then updates its
policy in the following way:
1. We our previous policy πt−1, resulting in eπt, with [ eπt]1:H−1 = [πt−1]2:H, and only optimize the last
needed time step [ eπt]H with the method described in 1.1.2.
2. We calculate the evidence for choosing a new plan based on the normalized, negative pragmatic value
(i.e., the surprise), with
ϵt = ϵ(eπt|q(st)) = H max
o′
ln p(o′) −
t+HX
τ=t+1
Eeqo(oτ ) ln p(oτ , aτ−1) . (A26)
We then update our accumulated surprise withEt = Et−1+λϵt, where we use a drift rate ofλ = 10−5.9.
3. If we see that Et ≥ 1, then we optimize the full policy πt using the method described in 1.1.2, and set
Et = 0. Otherwise, we use the continued policy eπt as our current policy πt
1.2 Specific Models
While the previous section described our general framework for using active inference, this section will
detail the exact generative process and generative model we used in our scenarios.
1.2.1 State transition probability
When implementing the model, we use for the state transition function of both the generative process
and the generative model a common bicycle model B. In this, model each vehicle can be defined by
three parameters, its width d, its front length lf and its rear length lr. Additionally, the kinematic
state of each agent then consists of its position markers x and y, its longitudinal speed v, its current
heading angle θ and steering angle δ (x = {x, y, v, θ, δ}). Each agent is then controlled by the acceleration
along ∈ [−amax, amax] and steering rate ω ∈ [−ωmax, ωmax] with amax = 8 ms−2 and ωmax = 1 .22 s−1
29
(u = {along, ω}). One then can get the differential equation ˙x = B(x, u):
˙x = v cos (θ + β)
˙y = v sin (θ + β)
˙v = ktire along
˙θ = v
lf + lr
tan (ktire δ) cos (β)
˙δ =
(
0 sgn(ω)sgn(δ)
ktire
> 1
ω Otherwise
with β = arctan
 lr
lf + lr
tan (ktire δ)

(A27)
Here, we use ktire and bδ to represent the limitations imposed by the tire friction:
ktire = amax
max
(
amax,
r
a[long]2 +

v2
lf +lr
δ
2
) (A28)
In each scenario, where we model the ego agent in interaction with the other agents V = {V1, V2, . . .},
we then can generally find the control actions a = uego and η = o = s = {xν, uν|ν ∈ {ego} ∪V }. We
assume that the generative process is deterministic, which allows us to get the following, where fB(x, u)
describes the usage of Heun’s methods to propagate the state forward according to equation (A27):
bp(η′|η, a) = δ
 
x′
ego − fB (xego, a)

δ
 
u′
ego − a

Y
ν∈V
δ (x′
ν − fB (xν, uν)) δ (u′
ν − uν,preset) (A29)
Here, the next control inputs uν,preset are predefined to allow the other vehicle to follow a prescribed
trajectory, which depends on the scenario (see 1.3.1 and 1.3.2). Meanwhile, some uncertainty is involved
in the generative model:
p(s′|s, a, θs) = δ
 
x′
ego − fB (xego, a)

δ
 
u′
ego − a

Y
ν∈V
δ (x′
ν − fB (xν, uν)) N
 
u′
ν|uν, diag(σ2
u)
 (A30)
In our model, we assume σu = σu,0 = [3 ms−2, 0.4575 s−1] when updating our belief (see (A15)) and
σu = 0.2fv
 
Eeqo(o)pn(o)

σu,0 (A31)
when predicting future states during model evaluation (see (A22)). Here, pn is the weighting used in
equation (A23), with
fv(p) = 1
2 max{min {p, 0.505}, 0.01} −0.01 : [0, 1] → [1, 10] (A32)
being used to give the agent less certainty in its belief about the future state of the other vehicle if its
current state violates traffic norms.
30
1.2.2 Observation probability
For the generative process, we assume that observations are exact.
bp(o′|η) = δ (o′ − η) (A33)
For the generative model meanwhile, we use a observation probability that follows the style laid out
in equation (A17). Here, we implement the looming based perception using the bijective mapping
{xego, φ} = L(xego, xOV, uOV|a) with φ = {φ, ˙φ, ¨φ, yOV, θOV, δOV, ωOV}, where looming angleφ, looming
˙φ, and looming rate ¨φ are calculated as:
φ ≈ 2 arctan
 d
2(xOV − xego)

˙φ ≈ −d (vOV cos(θOV) − vego)
(xOV − xego)2 + 1
4 d2
¨φ ≈ d
(xOV − xego)2 + 1
4 d2
 
along,ego − aOV cos(θOV) + 2(xOV − xego) (vOV cos(θOV) − vego)2
(xOV − xego)2 + 1
4 d2
!
.
(A34)
It must be noted that this mapping is a rough one-dimensional estimate assuming thatθego ≈ 0. However,
looming based perception update is the only used if the other agent is roughly in front of it, as it
unreasonable to assume that the ego vehicle would perceive the other vehicle directly with their eyes if
it is not in front of them. So technically, we find that:
if in the actual world state η where
L(o|a) = L(xego, xOV, uOV|a) =
(
{xego, φ} xOV − xego > lr + lf
xego, xOV, uOV Otherwise (A35)
As our state and observation states s and o overlap, in Equation (A17), we use A = I and b = 0. we
also have to implement the looming threshold, for which we use the function µ(oL). Given a looming
threshold of ˙φ0 = 0.002 15 s−1, we can define here:
µ(oL) =
(
µloom (oL) ( xOV − xego > lr + lf ) ∧ (| ˙φ| ≤˙φ0)
0 Otherwise (A36)
with
µloom (oL) =



0
0
0
0
0
0
˙φ
¨φ − d
(xOV−xego)2+ 1
4 d2 aego
0
0
0
0



T
. (A37)
31
Meanwhile, we also have to define the function Σ(oL) = diag

σ (oL)2

, where
σ (oL) = {σego, σOV (oL)} (A38)
with
σego =

0.0002 m, 0.000 001 m, 0.0002 ms−1, 0.000 001, 0.000 001
	
(A39)
and
σOV (oL) =






0.0002 m
0.000 02 m
0.0002 ms−1
0.0002
0.002
0.000 02 ms−2
0.002 s−1



T
xOV − xego < lr + lf



0.000 01
0.000 01 s−1
0.000 001 s−2
0.000 02 m
0.0002
0.002
0.002 s−1



T
(xOV − xego > lr + lf ) ∧ (| ˙φ| > ˙φ0)



0.000 01
0.0043 s−1
0.000 43 s−2
0.000 02 m
0.0002
0.002
0.002 s−1



T
(xOV − xego > lr + lf ) ∧ (| ˙φ| ≤˙φ0)
(A40)
1.2.3 Control limits
We also want to limit the acceleration and deceleration patterns not achievable by actual human input.
To this end, we use freal (equation (A25)), which in our case will use two functions, fpedal and fjerk. fpedal
prevents unrealistically fast switching between gas and brake pedals, by setting for an accelerationalong,τ :
fpedal(along,τ ) =
(
a0 (along,τ−1 − a0)(along,τ − a0) < 0
aτ otherwise (A41)
It must be noted that in our current model we assume that the acceleration observed when releasing both
pedals is a0 = −0.1 ms−2, to approximate the fact that with neutral pedals, wind and roll resistances will
lead to some decelerations.
Meanwhile, fjerk tries to implement realistic speeds at which the pedals can be pressed and released,
by limiting the jerks applied:
fjerk(along,τ ) = min {along,τ−1 + jmin∆t, max {along,τ , along,τ−1 + jmax∆t}} (A42)
32
For the jerk limits, we use:
jmin =
(
−5 ms−3 (along,τ−1 − along,τ−2) < 0 ∧ (along,τ − along,τ−1) > 0
−30 ms−3 otherwise
jmax =



0 ms−3 (along,τ−1 − along,τ−2) > 0 ∧ (along,τ − along,τ−1) < 0(
5 ms−3 along,τ ≥ 0
15 ms−3 along,τ < 0 otherwise
(A43)
Both those functions are applied recursively, with
[freal(π)]τ = fpedal
 
fjerk
 
fpedal
 
[freal(π)]τ−1

(A44)
1.2.4 Preference function
We use the following preference function p when minimizing the expected free energy G (see (A23)):
p(o) = N(vego|v0, σv)N(along,ego|0, σa)N(ωego|0, σω)plat(yego)pcoll(o)psafe(o) (A45)
Here,
plat(yego) = T

yrel (yego) | w − d
2 , gLC, gLL

(A46)
with the triangular function T :
T (x|x0, p1, p2) ∝
(
exp

|x|
x0
p1

|x| ≤x0
exp(p2) otherwise
(A47)
We also need to define the collision preference pcoll:
pcoll(oτ ) = min{pcoll(oτ−1), fcoll(oτ )} (A48)
This minimum is here so that all timesteps following upon a collision are still punished, as the model
itself has no collision mechanics, allowing vehicles to phase through each other. We than get the collision
preference at a single timestep fcoll, where we have collision condition C(o) = |yOV − yego| ≤1.15 d ∧
|xOV − xego| ≤1.15 (lf + lr):
fcoll(o) =



exp

gC

0.2 + 0.8vego−vOV cos(θego−θOV)
10 ms−1

C(o)
(
1 xOV − xego ≤ lr + lf
N

˙φ
φ |0.2 s−1, στ−1

Otherwise Otherwise
. (A49)
Here, the mean for the normal distribution over τ−1 = ˙φ
φ is taken from Markkula et al. [14]. In the
collision cases (C(o)), we adjust the collision cost based on the collision speed, as it is likely that human
agents prefere to collide with lower impact velocities, if a collision cannot be avoided.
Lastly, we define psafe, where we mainly consider the feasibility of braking when in a car following
scenario:
psafe(oτ ) =
(
exp

1
2 gC

0.2 + 0.8vego−vOV cos(θego−θOV)
10 ms−1

Cbrake(o) ∧ aego, req < −amax
1 Otherwise
(A50)
33
Here, the condition Cbrake for being in a car following scenario is defined as:
Cbrake(o) = (|yOV − yego| ≤1.15 d)∧(xOV − xego ≥ (lf + lr))∧(sgn(vego) sgn (vOV cos(θOV)) ≥ 0) (A51)
Meanwhile, aego, req is the required deceleration applied after a reation time of treact needed to avoid a
collision if the other vehicle suddenly started to accelerate towards/brake in front of the ego vehicle with
aOV,test = min{along,OV, aOV,min}.
aego, req = −1
2
max{vego,react, 0}2
max{dego,react − 1.15 (lf + lr), 0}
vego,react = vego + min{along,ego, 0}treact
dego,react =

xOV − 1
2
v2
OV
aOV,test

−

xego + vego treact + 1
2 min{along,ego, 0}t2
react

(A52)
The preference function can then be parameterized by the eight parameters σv = 0 .5 ms−1, σa =
0.1 ms−2, σω = 0 .02 s−1, στ−1 = 0 .125 s−1, gLC = −1000, gLL = −5000, gC = −10000, treact = 1 s.
Meanwhile, depending on the simulation, we choose aOV,min so that the given initial distance and speed
would result in stable car following, with lower bound of amin = −amax = −8 ms−2. Specifically, we
simulate a one-lane front-to-rear scenario with a leading other vehicle at constant velocity v0 for multiple
values of aOV,min. For each simulation, we then extract the steady-state following distance that the agent
chose for following, and the corresponding time gap. When then given a velocity v0 and desired following
distance or desired time gap, we use linear interpolation to extract the corresponding value of aOV,min
from the given data points.
While our framework is aimed to be as generalizable as possible, there are still some changes in
between our two models. Namely, when calculating the yrel from equation (A52), we have to represent
that in the front-to-rear scenario both lanes go in one direction, while in the lateral incursion scenario,
the left lane is designed for oncoming traffic.
1.3 Specific scenarios
1.3.1 Front-to-rear scenario
The first scenario, which models the response of a driver to the leading other vehicle suddenly braking,
contains two vehicles (V = {ego, OV}).
Initial state
In this scenario, there are 12 initial condition, with xego,0 = {0 m, 0 m, v0, 0, 0} and xOV,0 =
{v0∆ttgp,0 + lf + lr, 0 m, v0, 0, 0}, with ∆ ttgp,0 ∈ {0.5 s, 1.0 s, 1.5 s, 2.0 s, 2.5 s, 3.0 s, 3.5 s} and v0 ∈
{10 ms−1, 15 ms−1, 25 ms−1, 35 ms−1}. Meanwhile, we assume a lane width w = 3.65 m, and vehicle sizes
of d = 1.72 m, lf = 2.1 m, and lr = 2.1 m.
Other vehicles behavior
In this scenario, we set uOV,preset so that the other vehicle will drive straight on for exactly 5 s, after which
it will start to decelerate, applying a jerk of −10 ms−3 until reaching an acceleration value of −6 ms−2.
It will keep this acceleration until it comes to a standstill.
34
a Steep
Markkula et al.
Simulated
2.0
2.5
3.0
3.5
0 1 2 3
ytar in [m]
t in [s]
b Medium
Markkula et al.
Simulated
0 1 2 3
t in [s]
c Shallow
Markkula et al.
Simulated
0 1 2 3
t in [s]
Fig. A1: The different maneuvers by the other vehicle. The orange line represents the trajectory used
in our simulation, while the blue line corresponds to the original experiment [56]. t = 0 corresponds to
the start of the maneuver, while the horizontal velocity stays constant. Afterwards, the model continues
along a straight line with constant velocity.
.
Lateral preference
Here, we calculate the lateral relative position yrel from equation (A52) as:
yrel (yego) =



yego yego ≤ w−d
2
w−d
2
w−d
2 < yego ≤ w+d
2
yego − w w+d
2 < yego
(A53)
Norm conditioning
We define the normative probability pn(o) (see (A23)) in the following way, that punishes moving into
the left lane ( p = 0.02) or leaving the road ( p = 0.01) :
pn(o) =



1 −w−d
2 ≤ yOV ≤ w−d
2
0.02 w−d
2 ≤ yOV < 3w−d
2
0.01 Otherwise
(A54)
Given the usage of pn(o) as a weighing function, it is excusable to not normalize it here.
1.3.2 Lateral incursion scenario
The second scenario also only contains out of two vehicles ( V = {ego, OV}).
Initial state
In this scenario, there is a single initial condition, with xego,0 = {0 m, 0 m, v0, 0, 0} and xOV,0 =
{300 m, 0 m, v0, π,0} (the initial velocities v0 = 17.88 ms−1 correspond to 40 mph). Lane width and vehicle
size are identical to the front-to-rear scenario (see 1.3.1)
Other vehicle’s behavior
The other vehicle’s path is preprogrammed in a manner that it start turning to the left when the time
to collision ((xOV − xego)/(vOV + vego)) falls below 5.15 s. This turn will last for 3.3 s, at which point the
other vehicle’s front left corner should start crossing the central lane marker, after which the other vehicle
will follow a straight path. Following [56], we run this scenario in 3 different variants, where after 5 .15 s
seconds, we perceive yOV = −0.4w (Steep incursion), yOV = 0 m (Medium incursion), or yOV = 0.45w
(Shallow incursion) (see Figure A1).
35
5 10 15 20
-2 -1 0 1
Velocity vego [ms−1]
Lateral position yego [m]
Starting condition
Full Model
Model with no norm conditioning
a b
5 10 15 20
Velocity vego [ms−1]
0 2 4 6
-2 -1 0 1
Time t [s]
Lateral position yego [m]
Fig. A2 : Results in the 20 repetitions of the non-incursion scenario, for both the model with norm
conditioned particle filter (blue) and without (red). a) Change of longitudinal velocity vego and lateral
position yego of simulated agents over time. b) The kinematic state of the ego vehicle at the point in time
when passing the oncoming other vehicle.
Lateral preference
Here, we calculate the lateral relative position yrel from equation (A52) as:
yrel (yego) =



yego yego ≤ w−d
2
w−d
2
w−d
2 < yego ≤ 3w−d
2
yego − w 3w−d
2 < yego
(A55)
Norm conditioning
We define the normative probability pn(o) (see (A23)) in the following way, that punishes moving into
the opposite lane ( p = 0.02), and punishes leaving the road even more ( p = 0.01) :
pn(o) =



1 w+d
2 ≤ yOV ≤ 3w−d
2
0.02 −w−d
2 ≤ yOV < w+d
2
0.01 Otherwise
(A56)
Given the usage of pn(o) as a weighing function, it is excusable to not normalize it here.
1.4 Benign scenario
This is a variation of the lateral incursion scenario, where the other vehicle just drives along its lane
without any change in direction or speed. Specifically, we start the vehicles at an initial distance of 150 m,
both driving with 15 ms−1. Those simulations are repeated 20 times for both the full proposed model as
well as the one without the norm conditioned particle filter. As seen in Figure A2, the full model – with
one very jumpy exception – does not deviate from its desired state in response to the other agent. This
is much different in the model without norm conditioning, where the vehicles either move to the right,
36
or brake, or do both. With such behavior not very realistic in everyday driving scenarios, those results
highlight the need for the norm-conditioned particle filter. Of course, it must be noted that similar results
without the norm-conditioned particle filter could be achieved by simply removing the prediction noise,
but it was shown in the main text that that is essential for realistic collision avoidance behavior.
37
References
[1] J. B¨ argman, V. Lisovskaja, T. Victor, C. Flannagan, M. Dozza, How does glance behavior influence
crash and injury risk? A ‘what-if’ counterfactual simulation using crashes and near-crashes from
SHRP2. Transportation Research Part F: Traffic Psychology and Behaviour 35, 152–169 (2015).
https://doi.org/10.1016/j.trf.2015.10.011. URL https://www.sciencedirect.com/science/article/pii/
S136984781500162X
[2] J. Engstr¨ om, G. Markkula, Q. Xue, N. Merat, Simulating the effect of cognitive load on brak-
ing responses in lead vehicle braking scenarios. IET Intelligent Transport Systems 12(6), 427–433
(2018). https://doi.org/10.1049/iet-its.2017.0233. URL https://onlinelibrary.wiley.com/doi/abs/10.
1049/iet-its.2017.0233. eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1049/iet-its.2017.0233
[3] G. Bianchi Piccinini, E. Lehtonen, F. Forcolin, J. Engstr¨ om, D. Albers, G. Markkula, J. Lodin,
J. Sandin, How Do Drivers Respond to Silent Automation Failures? Driving Simulator Study
and Comparison of Computational Driver Braking Models. Human Factors: The Journal of
the Human Factors and Ergonomics Society 62(7), 1212–1229 (2020). https://doi.org/10.1177/
0018720819875347. URL http://journals.sagepub.com/doi/10.1177/0018720819875347
[4] N. Montali, J. Lambert, P. Mougin, A. Kuefler, N. Rhinehart, M. Li, C. Gulino, T. Emrich,
Z. Yang, S. Whiteson, B. White, D. Anguelov, The Waymo Open Sim Agents Challenge. Advances
in Neural Information Processing Systems 36, 59151–59171 (2023). URL https://proceedings.
neurips.cc/paper files/paper/2023/hash/b96ce67b2f2d45e4ab315e13a6b5b9c5-Abstract-Datasets
and Benchmarks.html
[5] P. Olleja, G. Markkula, J. B¨ argman. Validation of human benchmark models for Automated Driving
System approval: How competent and careful are they really? (2024). https://doi.org/10.48550/
arXiv.2406.09493. URL http://arxiv.org/abs/2406.09493. ArXiv:2406.09493
[6] J. Engstr¨ om, S.Y. Liu, A. Dinparastdjadid, C. Simoiu, Modeling road user response timing in nat-
uralistic traffic conflicts: A surprise-based framework. Accident Analysis & Prevention 198, 107460
(2024). https://doi.org/10.1016/j.aap.2024.107460. URL https://www.sciencedirect.com/science/
article/pii/S0001457524000058
[7] P.J. Matusz, S. Dikker, A.G. Huth, C. Perrodin, Are We Ready for Real-world Neuroscience? Journal
of Cognitive Neuroscience 31(3), 327–338 (2019). https://doi.org/10.1162/jocn e 01276. URL https:
//doi.org/10.1162/jocn e 01276
[8] S.G. Shamay-Tsoory, A. Mendelsohn, Real-Life Neuroscience: An Ecological Approach to Brain
and Behavior Research. Perspectives on Psychological Science 14(5), 841–859 (2019). https://doi.
org/10.1177/1745691619856350. URL https://doi.org/10.1177/1745691619856350. Publisher: SAGE
Publications Inc
[9] W. Carvalho, A. Lampinen. Naturalistic Computational Cognitive Science: Towards generalizable
models and theories that capture the full range of natural behavior (2025). https://doi.org/10.48550/
arXiv.2502.20349. URL http://arxiv.org/abs/2502.20349. ArXiv:2502.20349 [q-bio]
[10] Q. Xue, G. Markkula, X. Yan, N. Merat, Using perceptual cues for brake response to a lead vehicle:
Comparing threshold and accumulator models of visual looming. Accident Analysis & Prevention
118, 114–124 (2018). https://doi.org/10.1016/j.aap.2018.06.006. URL https://linkinghub.elsevier.
com/retrieve/pii/S0001457518302239
38
[11] M. Sv¨ ard, G. Markkula, J. B¨ argman, T. Victor, Computational modeling of driver pre-crash brake
response, with and without off-road glances: Parameterization using real-world crashes and near-
crashes. Accident Analysis & Prevention 163, 106433 (2021). https://doi.org/10.1016/j.aap.2021.
106433. URL https://www.sciencedirect.com/science/article/pii/S0001457521004644
[12] C. Guo, X. Wang, L. Su, Y. Wang, Safety distance model for longitudinal collision avoid-
ance of logistics vehicles considering slope and road adhesion coefficient. Proceedings of the
Institution of Mechanical Engineers (2021). URL https://journals.sagepub.com/doi/full/10.1177/
0954407020959744
[13] O. Siebinga, A. Zgonnikov, D.A. Abbink, A model of dyadic merging interactions explains human
drivers’ behavior from control inputs to decisions. PNAS Nexus 3(10), pgae420 (2024). https:
//doi.org/10.1093/pnasnexus/pgae420. URL https://doi.org/10.1093/pnasnexus/pgae420
[14] G. Markkula, J. Engstr¨ om, J. Lodin, J. B¨ argman, T. Victor, A farewell to brake reaction times?
Kinematics-dependent brake response in naturalistic rear-end emergencies. Accident Analysis &
Prevention 95, 209–226 (2016). https://doi.org/10.1016/j.aap.2016.07.007. URL https://www.
sciencedirect.com/science/article/pii/S0001457516302366
[15] R. Wei, A.D. McDonald, A. Garcia, H. Alambeigi, Modeling Driver Responses to Automation Fail-
ures With Active Inference. IEEE Transactions on Intelligent Transportation Systems 23(10),
18064–18075 (2022). https://doi.org/10.1109/TITS.2022.3155381. URL https://ieeexplore.ieee.org/
abstract/document/9733256. Conference Name: IEEE Transactions on Intelligent Transportation
Systems
[16] T. Li, J. Kovaceva, M. Dozza, Modeling collision avoidance maneuvers for micromobility vehicles.
Journal of Safety Research 87, 232–243 (2023). https://doi.org/10.1016/j.jsr.2023.09.019. URL
https://www.sciencedirect.com/science/article/pii/S0022437523001500
[17] Y. Yuan, X. Weng, Y. Ou, K.M. Kitani,AgentFormer: Agent-Aware Transformers for Socio-Temporal
Multi-Agent Forecasting, in IEEE/CVF International Conference on Computer Vision (2021), pp.
9813–9823
[18] S. Suo, S. Regalado, S. Casas, R. Urtasun, Trafficsim: Learning to simulate realistic multi-agent
behaviors, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
(2021), pp. 10400–10409
[19] T. Gu, G. Chen, J. Li, C. Lin, Y. Rao, J. Zhou, J. Lu, Stochastic Trajectory Prediction via Motion
Indeterminacy Diffusion, in Proceedings of the IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition(2022), pp. 17113–17122. URL https://openaccess.thecvf.com/content/CVPR2022/
html/Gu Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion CVPR 2022 paper.
html
[20] M. Igl, D. Kim, A. Kuefler, P. Mougin, P. Shah, K. Shiarlis, D. Anguelov, M. Palatucci, B. White,
S. Whiteson, Symphony: Learning realistic and diverse agents for autonomous driving simulation , in
2022 International Conference on Robotics and Automation (ICRA) (IEEE, 2022), pp. 2445–2451
[21] A. M´ esz´ aros, J.F. Schumann, J. Alonso-Mora, A. Zgonnikov, J. Kober,TrajFlow: Learning Distribu-
tions over Trajectories for Human Behavior Prediction, in 2024 IEEE Intelligent Vehicles Symposium
(IV) (Jeju, 2024)
39
[22] B. Ivanovic, G. Song, I. Gilitschenski, M. Pavone, trajdata: A Unified Interface to Mul-
tiple Human Trajectory Datasets. Advances in Neural Information Processing Systems
36, 27582–27593 (2023). URL https://proceedings.neurips.cc/paper files/paper/2023/hash/
57bb67dbe17bfb660c8c63d089ea05b9-Abstract-Datasets and Benchmarks.html
[23] J.F. Schumann, J. Kober, A. Zgonnikov, Benchmarking Behavior Prediction Models in Gap Accep-
tance Scenarios. IEEE Transactions on Intelligent Vehicles 8(3), 2580–2591 (2023). https://doi.org/
10.1109/TIV.2023.3244280
[24] K. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbeck, G. Pezzulo, Active Inference: A Process
Theory. Neural Computation 29(1), 1–49 (2017). https://doi.org/10.1162/NECO a 00912. URL
https://doi.org/10.1162/NECO a 00912
[25] L. Da Costa, T. Parr, N. Sajid, S. Veselic, V. Neacsu, K. Friston, Active inference on discrete state-
spaces: a synthesis. Journal of Mathematical Psychology 99, 102447 (2020). https://doi.org/10.
1016/j.jmp.2020.102447. URL http://arxiv.org/abs/2001.07203. ArXiv:2001.07203 [q-bio]
[26] T. Parr, G. Pezzulo, K.J. Friston, Active Inference: The Free Energy Principle in Mind, Brain, and
Behavior (MIT Press, 2022). Google-Books-ID: UrZNEAAAQBAJ
[27] R. Smith, P. Badcock, K.J. Friston, Recent advances in the application of predictive coding and
active inference models within clinical neuroscience. Psychiatry and Clinical Neurosciences 75(1),
3–13 (2021). https://doi.org/10.1111/pcn.13138. URL https://onlinelibrary.wiley.com/doi/abs/10.
1111/pcn.13138. eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/pcn.13138
[28] J. Vasil, P.B. Badcock, A. Constant, K. Friston, M.J.D. Ramstead, A World Unto Itself: Human
Communication as Active Inference. Frontiers in Psychology 11 (2020). https://doi.org/10.3389/
fpsyg.2020.00417. URL https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.
2020.00417/full. Publisher: Frontiers
[29] H. Bottemanne, K.J. Friston, An active inference account of protective behaviours during the
COVID-19 pandemic. Cognitive, Affective, & Behavioral Neuroscience 21(6), 1117–1129 (2021).
https://doi.org/10.3758/s13415-021-00947-0. URL https://doi.org/10.3758/s13415-021-00947-0
[30] D.J. Harris, T. Arthur, D.P. Broadbent, M.R. Wilson, S.J. Vine, O.R. Runswick, An Active Inference
Account of Skilled Anticipation in Sport: Using Computational Models to Formalise Theory and
Generate New Hypotheses. Sports Medicine 52(9), 2023–2038 (2022). https://doi.org/10.1007/
s40279-022-01689-w. URL https://doi.org/10.1007/s40279-022-01689-w
[31] F. Novick´ y, A.A. Meera, F. Zeldenrust, P. Lanillos. Precision not prediction: Body-ownership illusion
as a consequence of online precision adaptation under Bayesian inference (2024). https://doi.org/
10.1101/2024.09.04.611162. URL http://biorxiv.org/lookup/doi/10.1101/2024.09.04.611162
[32] R. Wei, A. Garcia, A. McDonald, G. Markkula, J. Engstr¨ om, I. Supeene, M. O’Kelly, World Model
Learning from Demonstrations with Active Inference: Application to Driving Behavior , in Active
Inference, ed. by C.L. Buckley, D. Cialfi, P. Lanillos, M. Ramstead, N. Sajid, H. Shimazaki, T. Ver-
belen (Springer Nature Switzerland, Cham, 2023), Communications in Computer and Information
Science, pp. 130–142. https://doi.org/10.1007/978-3-031-28719-0 9
[33] J. Engstr¨ om, R. Wei, A.D. McDonald, A. Garcia, Matthew O’Kelly, L. Johnson, Resolving uncer-
tainty on the fly: modeling adaptive driving behavior as active inference. Frontiers in Neurorobotics
18 (2024). https://doi.org/10.3389/fnbot.2024.1341750. URL https://www.frontiersin.org/articles/
40
10.3389/fnbot.2024.1341750. Publisher: Frontiers
[34] D.N. Lee, A theory of visual control of braking based on information about time-to-collision.
Perception 5(4), 437–459 (1976). https://doi.org/10.1068/p050437
[35] J.J. Gibson, The Ecological Approach to Visual Perception: Classic Edition (Psychology Press, New
York, 2014). https://doi.org/10.4324/9781315740218
[36] R.D. Luce, Response times: Their role in inferring elementary mental organization (Oxford
University Press on Demand, 1986). Issue: 8
[37] J.I. Gold, M.N. Shadlen, The neural basis of decision making. Annu. Rev. Neurosci. 30(1), 535–574
(2007)
[38] R. Ratcliff, H.P. Van Dongen, Diffusion model for one-choice reaction-time tasks and the cognitive
effects of sleep deprivation. Proceedings of the National Academy of Sciences 108(27), 11285–11290
(2011)
[39] G. Markkula, Modeling driver control behavior in both routine and near-accident driving , in Proceed-
ings of the human factors and ergonomics society annual meeting , vol. 58 (SAGE Publications Sage
CA: Los Angeles, CA, 2014), pp. 879–883
[40] J. Pekkanen, O. Lappi, P. Rinkkala, S. Tuhkanen, R. Frantsi, H. Summala, A computational model
for driver’s cognitive state, visual perception and intermittent attention in a distracted car following
task. Royal Society Open Science 5(9), 180194 (2018). https://doi.org/10.1098/rsos.180194. URL
https://royalsocietypublishing.org/doi/full/10.1098/rsos.180194. Publisher: Royal Society
[41] E.R. Hoffmann, Estimation of Time to Vehicle Arrival—Effects of Age on Use of Available Visual
Information. Perception 23(8), 947–955 (1994). https://doi.org/10.1068/p230947. URL https:
//doi.org/10.1068/p230947. Publisher: SAGE Publications Ltd STM
[42] D. Lamble, M. Laakso, H. Summala, Detection thresholds in car following situations and peripheral
vision: implications for positioning of visually demanding in-car displays. Ergonomics 42(6), 807–815
(1999). https://doi.org/10.1080/001401399185306. URL https://doi.org/10.1080/001401399185306.
Publisher: Taylor & Francis eprint: https://doi.org/10.1080/001401399185306
[43] K.P. Murphy, Machine learning: a probabilistic perspective (MIT press, 2012)
[44] H. Laurent, M. Sangnier, C. Treibich, Traffic safety and norms of compliance with rules: An
exploratory study. Economics Bulletin 41(4), 2464–2483 (2021). URL http://www.scopus.com/
inward/record.url?scp=85125263034&partnerID=8YFLogxK
[45] S. Abbas, S. Fatima, A. Sharif, S.M. Adnan, Drivers’ knowledge, attitude and practices towards
traffic rules and regulations. Journal of Road Safety 35(3), 24–31 (2024)
[46] C. Tennant, C. Neels, G. Parkhurst, P. Jones, S. Mirza, J. Stilgoe, Code, culture, and concrete:
Self-driving vehicles and the rules of the road. Frontiers in Sustainable Cities 3, 710478 (2021)
[47] A. Dinparastdjadid, I. Supeene, J. Engstrom. Measuring Surprise in the Wild (2023). https://doi.
org/10.48550/arXiv.2305.07733. URL http://arxiv.org/abs/2305.07733. ArXiv:2305.07733 [cs]
[48] P.T. de Boer, D.P. Kroese, S. Mannor, R.Y. Rubinstein, A Tutorial on the Cross-Entropy Method.
Annals of Operations Research 134(1), 19–67 (2005). https://doi.org/10.1007/s10479-005-5724-z.
41
URL https://doi.org/10.1007/s10479-005-5724-z
[49] H.A. Simon, A behavioral model of rational choice. The quarterly journal of economics pp. 99–118
(1955)
[50] H. Summala, in Modelling Driver Behaviour in Automotive Environments: Critical Issues in
Driver Interactions with Intelligent Transport Systems , ed. by P.C. Cacciabue (Springer, London,
2007), pp. 189–207. https://doi.org/10.1007/978-1-84628-618-6 11. URL https://doi.org/10.1007/
978-1-84628-618-6 11
[51] H. Oh, J.M. Beck, P. Zhu, M.A. Sommer, S. Ferrari, T. Egner, Satisficing in split-second decision
making is characterized by strategic cue discounting. Journal of Experimental Psychology: Learning,
Memory, and Cognition 42(12), 1937–1956 (2016). https://doi.org/10.1037/xlm0000284. Place: US
Publisher: American Psychological Association
[52] F. Callaway, B. van Opheusden, S. Gul, P. Das, P.M. Krueger, T.L. Griffiths, F. Lieder, Rational
use of cognitive resources in human planning. Nature Human Behaviour 6(8), 1112–1125 (2022).
https://doi.org/10.1038/s41562-022-01332-8
[53] J. Engstroem, Scenario criticality determines the effect of working memory load on brake response
time, in Proceedings of the European Conference on Human Centred Design for Intelligent Transport
Systems (2010), pp. 25–36. URL https://trid.trb.org/View/1150568
[54] K.A. Brookhuis, G. de Vries, D. de Waard, The effects of mobile telephoning on driving performance.
Accident Analysis & Prevention 23(4), 309–316 (1991). https://doi.org/10.1016/0001-4575(91)
90008-S. URL https://www.sciencedirect.com/science/article/pii/000145759190008S
[55] J.D. Lee, B. Caven, S. Haake, T.L. Brown, Speech-based interaction with in-vehicle computers: the
effect of speech-based e-mail on drivers’ attention to the roadway. Human Factors 43(4), 631–640
(2001). https://doi.org/10.1518/001872001775870340
[56] L. Johnson, J. Engstr¨ om, A. Srinivasan, I. ¨Ozturk, G. Markkula, Looking for an out: Affordances,
uncertainty and collision avoidance behavior of human drivers (2025). URL https://arxiv.org/abs/
2505.14842
[57] M. Br¨ annstr¨ om, E. Coelingh, J. Sj¨ oberg, Decision-making on when to brake and when to steer to
avoid a collision. International Journal of Vehicle Safety 7(1), 87–106 (2014). https://doi.org/
10.1504/IJVS.2014.058243. URL https://www.inderscienceonline.com/doi/full/10.1504/IJVS.2014.
058243. Publisher: Inderscience Publishers
[58] V. Venkatraman, J.D. Lee, C.W. Schwarz, Steer or Brake?: Modeling Drivers’ Collision-Avoidance
Behavior by Using Perceptual Cues. Transportation Research Record2602(1), 97–103 (2016). https:
//doi.org/10.3141/2602-12. URL https://doi.org/10.3141/2602-12. Publisher: SAGE Publications
Inc
[59] M. Hu, Y. Liao, W. Wang, G. Li, B. Cheng, F. Chen, Decision Tree-Based Maneuver Prediction for
Driver Rear-End Risk-Avoidance Behaviors in Cut-In Scenarios. Journal of Advanced Transportation
2017, e7170358 (2017). https://doi.org/10.1155/2017/7170358. URL https://www.hindawi.com/
journals/jat/2017/7170358/. Publisher: Hindawi
[60] A. Sarkar, J.S. Hickman, A.D. McDonald, W. Huang, T. Vogelpohl, G. Markkula, Steering or braking
avoidance response in SHRP2 rear-end crashes and near-crashes: A decision tree approach. Accident
Analysis & Prevention 154, 106055 (2021). https://doi.org/10.1016/j.aap.2021.106055. URL https:
42
//www.sciencedirect.com/science/article/pii/S0001457521000865
[61] M.L. Aust, J. Engstr¨ om, M. Vistr¨ om, Effects of forward collision warning and repeated event expo-
sure on emergency braking. Transportation Research Part F: Traffic Psychology and Behaviour
18, 34–46 (2013). https://doi.org/10.1016/j.trf.2012.12.010. URL https://www.sciencedirect.com/
science/article/pii/S1369847813000065
[62] A.D. McDonald, H. Alambeigi, J. Engstr¨ om, G. Markkula, T. Vogelpohl, J. Dunne, N. Yuma,
Toward Computational Simulations of Behavior During Automated Driving Takeovers: A Review
of the Empirical and Modeling Literatures. Human Factors 61(4), 642–688 (2019). https://doi.
org/10.1177/0018720819829572. URL https://doi.org/10.1177/0018720819829572. Publisher: SAGE
Publications Inc
[63] K.D. Kusano, H.C. Gabler, Safety Benefits of Forward Collision Warning, Brake Assist, and
Autonomous Braking Systems in Rear-End Collisions. IEEE Transactions on Intelligent Trans-
portation Systems 13(4), 1546–1555 (2012). https://doi.org/10.1109/TITS.2012.2191542. URL
https://ieeexplore.ieee.org/abstract/document/6180219. Conference Name: IEEE Transactions on
Intelligent Transportation Systems
[64] M. Sv¨ ard, G. Markkula, J. Engstr¨ om, F. Granum, J. B¨ argman, A quantitative driver model of
pre-crash brake onset and control , in Proceedings of the Human Factors and Ergonomics Society
Annual Meeting , vol. 61 (2017), pp. 339–343. https://doi.org/10.1177/1541931213601565. URL
https://cir.nii.ac.jp/crid/1360294647862811264. Publisher: SAGE Publications
[65] A. Fries, F. Fahrenkrog, K. Donauer, M. Mai, F. Raisch, Driver behavior model for the safety assess-
ment of automated driving , in 2022 IEEE Intelligent Vehicles Symposium (IV) (IEEE, 2022), pp.
1669–1674
[66] A. Fries, L. Lemberg, F. Fahrenkrog, M. Mai, A. Das, Modeling driver behavior in critical traffic sce-
narios for the safety assessment of automated driving. Traffic Injury Prevention24(sup1), S105–S110
(2023). https://doi.org/10.1080/15389588.2023.2211187. URL https://doi.org/10.1080/15389588.
2023.2211187. Publisher: Taylor & Francis eprint: https://doi.org/10.1080/15389588.2023.2211187
[67] L.F.A. de Oliveira, L. Schories, L. Brostek, M. Meywerk, Simulation-Based Evaluation of a Generic
Autonomous Emergency Braking System Using a Cognitive Pedestrian Behavior Model , in 27th
International Technical Conference on the Enhanced Safety of Vehicles (ESV) (2023). URL https:
//trid.trb.org/View/2211669. Number: 23-0217
[68] C. R¨ ossert, J. Drever, L. Brostek. Cognitive behavior model replicates road user response timing
in naturalistic rear-end traffic conflicts (2024). https://doi.org/10.31219/osf.io/su5kt. URL https:
//osf.io/su5kt
[69] C. Hubmann, M. Becker, D. Althoff, D. Lenz, C. Stiller, Decision making for autonomous driving
considering interaction and uncertain prediction of surrounding vehicles , in 2017 IEEE intelligent
vehicles symposium (IV) (IEEE, 2017), pp. 1671–1678
[70] S. Brechtel, T. Gindele, R. Dillmann,Probabilistic decision-making under uncertainty for autonomous
driving using continuous POMDPs , in 17th International IEEE Conference on Intelligent Trans-
portation Systems (ITSC) (2014), pp. 392–399. https://doi.org/10.1109/ITSC.2014.6957722
[71] M. Bouton, A. Cosgun, M.J. Kochenderfer, Belief state planning for autonomously navigating urban
intersections, in 2017 IEEE Intelligent Vehicles Symposium (IV) (IEEE, 2017), pp. 825–830
43
[72] J. Pekkanen, O.T. Giles, Y.M. Lee, R. Madigan, T. Daimon, N. Merat, G. Markkula, Variable-Drift
Diffusion Models of Pedestrian Road-Crossing Decisions. Computational Brain & Behavior 5(1),
60–80 (2022). https://doi.org/10.1007/s42113-021-00116-z
[73] A. Zgonnikov, D. Abbink, G. Markkula, Should I Stay or Should I Go? Cognitive Modeling of Left-
Turn Gap Acceptance Decisions in Human Drivers. Human Factors p. 00187208221144561 (2022).
https://doi.org/10.1177/00187208221144561. URL https://doi.org/10.1177/00187208221144561.
Publisher: SAGE Publications Inc
[74] J.F. Schumann, A.R. Srinivasan, J. Kober, G. Markkula, A. Zgonnikov, Using Models Based on Cog-
nitive Theory to Predict Human Behavior in Traffic: A Case Study , in 2023 IEEE 26th International
Conference on Intelligent Transportation Systems (ITSC) (2023), pp. 5870–5875. https://doi.org/
10.1109/ITSC57777.2023.10421837. URL https://ieeexplore.ieee.org/abstract/document/10421837.
ISSN: 2153-0017
[75] T.H.B. FitzGerald, P. Schwartenbeck, M. Moutoussis, R.J. Dolan, K. Friston, Active Inference,
Evidence Accumulation, and the Urn Task. Neural Computation 27(2), 306–328 (2015). https:
//doi.org/10.1162/NECO a 00699. URL https://doi.org/10.1162/NECO a 00699
[76] F.J. Varela, E. Thompson, E. Rosch, The embodied mind, revised edition: Cognitive science and
human experience (MIT press, 2017)
[77] E. Thompson, Mind in life: Biology, phenomenology, and the sciences of mind (Harvard University
Press, 2010)
[78] K. Friston, Life as we know it. Journal of The Royal Society Interface 10(86), 20130475 (2013).
https://doi.org/10.1098/rsif.2013.0475. URL https://royalsocietypublishing.org/doi/full/10.1098/
rsif.2013.0475. Publisher: Royal Society
[79] E.D. Paolo, E. Thompson, R. Beer, Laying down a forking path: Tensions between enaction and
the free energy principle. Philosophy and the Mind Sciences 3 (2022). https://doi.org/10.33735/
phimisci.2022.9187. URL https://philosophymindscience.org/index.php/phimisci/article/view/9187
[80] J. Kiverstein, M.D. Kirchhoff, T. Froese, The Problem of Meaning: The Free Energy Princi-
ple and Artificial Agency. Frontiers in Neurorobotics 16 (2022). https://doi.org/10.3389/fnbot.
2022.844773. URL https://www.frontiersin.org/journals/neurorobotics/articles/10.3389/fnbot.2022.
844773/full. Publisher: Frontiers
[81] K. Friston, in Affordances in Everyday Life: A Multidisciplinary Collection of Essays , ed. by
Z. Djebbara (Springer International Publishing, Cham, 2022), pp. 211–219. https://doi.org/10.1007/
978-3-031-08629-8 20. URL https://doi.org/10.1007/978-3-031-08629-8 20
[82] M.J.D. Ramstead, in Affordances in Everyday Life: A Multidisciplinary Collection of Essays , ed.
by Z. Djebbara (Springer International Publishing, Cham, 2022), pp. 193–202. https://doi.org/10.
1007/978-3-031-08629-8 18. URL https://doi.org/10.1007/978-3-031-08629-8 18
[83] P. Calvo, K. Friston, Predicting green: really radical (plant) predictive processing. Journal of The
Royal Society Interface 14(131), 20170096 (2017). https://doi.org/10.1098/rsif.2017.0096. URL
https://royalsocietypublishing.org/doi/10.1098/rsif.2017.0096. Publisher: Royal Society
[84] T. Van de Maele, B. Dhoedt, T. Verbelen, G. Pezzulo, A hierarchical active inference model of
spatial alternation tasks and the hippocampal-prefrontal circuit. Nature Communications 15(1),
9892 (2024). https://doi.org/10.1038/s41467-024-54257-3. URL https://www.nature.com/articles/
44
s41467-024-54257-3. Publisher: Nature Publishing Group
[85] N. Kastel, C. Hesp, K.R. Ridderinkhof, K.J. Friston, Small steps for mankind: Modeling the emer-
gence of cumulative culture from joint active inference communication. Frontiers in Neurorobotics
16 (2023). https://doi.org/10.3389/fnbot.2022.944986. URL https://www.frontiersin.org/journals/
neurorobotics/articles/10.3389/fnbot.2022.944986/full. Publisher: Frontiers
[86] R. Wei, A.D. McDonald, A. Garcia, G. Markkula, J. Engstrom, M. O’Kelly. An active inference model
of car following: Advantages and applications (2023). https://doi.org/10.48550/arXiv.2303.15201.
URL http://arxiv.org/abs/2303.15201. ArXiv:2303.15201 [cs]
[87] K. Friston, L. Da Costa, D. Hafner, C. Hesp, T. Parr, Sophisticated inference. Neural Computation
33(3), 713–763 (2021)
[88] A. Chohan, G.J. Savelsbergh, P. Van Kampen, M. Wind, M.H. Verheul, Postural adjustments and
bearing angle use in interceptive actions. Experimental brain research 171, 47–55 (2006)
[89] R. Wei, J. Lee, S. Wakayama, A. Tschantz, C. Heins, C. Buckley, J. Carenbauer, H. Thiruvengada,
M. Albarracin, M.d. Prado, P. Horling, P. Winzell, R. Rajagopal. Navigation under uncertainty:
Trajectory prediction and occlusion reasoning with switching dynamical systems (2024). https:
//doi.org/10.48550/arXiv.2410.10653. URL http://arxiv.org/abs/2410.10653. ArXiv:2410.10653
[90] T. Salzmann, B. Ivanovic, P. Chakravarty, M. Pavone, Trajectron++: Dynamically-Feasible Trajec-
tory Forecasting with Heterogeneous Data , in Computer Vision – ECCV 2020 (Cham, 2020), pp.
683–700. https://doi.org/10.1007/978-3-030-58523-5 40
[91] K. Mangalam, Y. An, H. Girase, J. Malik,From Goals, Waypoints & Paths to Long Term Human Tra-
jectory Forecasting, in Proceedings of the IEEE/CVF International Conference on Computer Vision
(2021), pp. 15233–15242. URL https://openaccess.thecvf.com/content/ICCV2021/html/Mangalam
From Goals Waypoints Paths to Long Term Human Trajectory ICCV 2021 paper.html
[92] R. Girgis, F. Golemo, F. Codevilla, M. Weiss, J.A. D’Souza, S.E. Kahou, F. Heide,
C. Pal, LATENT VARIABLE SEQUENTIAL SET TRANSFORMERS FOR JOINT MULTI-
AGENT MOTION PREDICTION , in 10th International Conference on Learning Rep-
resentations, ICLR 2022 (2022). URL https://collaborate.princeton.edu/en/publications/
latent-variable-sequential-set-transformers-for-joint-multi-agent
[93] S. Shi, L. Jiang, D. Dai, B. Schiele, Motion Transformer with Global Intention Localiza-
tion and Local Movement Refinement. Advances in Neural Information Processing Sys-
tems 35, 6531–6543 (2022). URL https://proceedings.neurips.cc/paper files/paper/2022/hash/
2ab47c960bfee4f86dfc362f26ad066a-Abstract-Conference.html
[94] N. Nayakanti, R. Al-Rfou, A. Zhou, K. Goel, K.S. Refaat, B. Sapp, Wayformer: Motion Forecasting
via Simple & Efficient Attention Networks , in 2023 IEEE International Conference on Robotics and
Automation (ICRA) (2023), pp. 2980–2987. https://doi.org/10.1109/ICRA48891.2023.10160609.
URL https://ieeexplore.ieee.org/abstract/document/10160609
[95] P. Lanillos, C. Meo, C. Pezzato, A.A. Meera, M. Baioumy, W. Ohata, A. Tschantz, B. Millidge,
M. Wisse, C.L. Buckley, J. Tani. Active Inference in Robotics and Artificial Agents: Survey and
Challenges (2021). https://doi.org/10.48550/arXiv.2112.01871. URL http://arxiv.org/abs/2112.
01871. ArXiv:2112.01871 [cs]
45
[96] P. Mazzaglia, T. Verbelen, O. C ¸ atal, B. Dhoedt, The Free Energy Principle for Perception and Action:
A Deep Learning Perspective. Entropy 24(2), 301 (2022). https://doi.org/10.3390/e24020301.
URL https://www.mdpi.com/1099-4300/24/2/301. Number: 2 Publisher: Multidisciplinary Digital
Publishing Institute
[97] M.P. Deisenroth, A.A. Faisal, C.S. Ong, Mathematics for Machine Learning (Cambridge University
Press, 2020). Google-Books-ID: pFjPDwAAQBAJ
[98] J. Fischer, O.S. Tas, Information Particle Filter Tree: An Online Algorithm for POMDPs with
Belief-Based Rewards on Continuous Domains , in Proceedings of the 37th International Conference
on Machine Learning (PMLR, 2020), pp. 3177–3187. URL https://proceedings.mlr.press/v119/
fischer20a.html. ISSN: 2640-3498
[99] P. Polack, F. Altch´ e, B. d’Andr´ ea Novel, A. de La Fortelle,The kinematic bicycle model: A consistent
model for planning feasible trajectories for autonomous vehicles? , in 2017 IEEE Intelligent Vehicles
Symposium (IV) (2017), pp. 812–818. https://doi.org/10.1109/IVS.2017.7995816. URL https://
ieeexplore.ieee.org/abstract/document/7995816
46