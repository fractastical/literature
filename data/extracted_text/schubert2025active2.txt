Presented at the 6th International Workshop on Active Inference, 15â€“17 October 2025, Montreal, 
Canada. 
Active Inference for an Intelligent Agent in Autonomous 
Reconnaissance Missions 
Johan Schubert[0000-0002-0262-9908], Farzad Kamrani[0000-0001-9448-6803], 
Tove Gustavi[0009-0003-1886-9265] 
Swedish Defence Research Agency, SE-164 90 Stockholm, Sweden 
{johan.schubert,farzad.kamrani,tove.gustavi}@foi.se 
Abstractâ€”We develop an active inference route-planning method for the au-
tonomous control of intelligent agents. The aim is to reconnoiter a geographical 
area to maintain a common operational picture. To achieve this, we construct an 
evidence map that reflects our current understanding of the situation, incorporat-
ing both positive and â€œnegativeâ€ sensor observations of possible target objects 
collected over time, and diffusing the evidence across the map as time progresses. 
The generative model of active inferenc e uses Dempster-Shafer theory and a 
Gaussian sensor model, which provides input to the agent. The generative process 
employs a Bayesian approach to update a posterior probability distribution. We 
calculate the variational free energy for all positions within the area by assessing 
the divergence between a pignistic probability distribution of the evidence map 
and a posterior probability distribution of  a target object based on the observa-
tions, including the level of surprise associated with receiving new observations. 
Using the free energy, we direct the agentsâ€™ movements in a simulation by taking 
an incremental step toward a position th at minimizes the free energy. This ap-
proach addresses the challenge of explor ation and exploitation, allowing agents 
to balance searching extensive areas of the geographical map while tracking iden-
tified target objects. 
Keywordsâ€”active inference, free energy principle, autonomous agents. 
1 Introduction 
This paper focuses on active inference [1, 2] for the autonomous control of an intelli-
gent agent (e.g., a reconnaissance Unmanned Aerial Vehicle (UAV)) aimed at achiev-
ing and maintaining the best possible situational awareness over time. Active inference 
is a methodology for autonomous decision-making. This methodology is generic and 
based on the concept that a system aims to  minimize its surprise when receiving new 
information. What is unique about active inference is that the method includes two par-
allel approaches for an agent to seek cons istency between reality and the systemâ€™s de-
scription of the environment: either the syst emâ€™s internal representation is updated as 
new information is received, or actions are taken against the environment to change it 
so that it is consistent with its perception. 
2  J. Schubert, F. Kamrani, and T. Gustavi 
Minimizing surprise is inherently impossible. Instead, we aim for the best possible 
action by choosing the one that minimizes fr ee energy. Free energy is an information 
theory concept that refers to the divergence between two probability distributions and 
the element of surprise. One distribution reflects our perception of reality, often de-
scribed as a dynamic common operational picture, while the other is the probability 
after a current observation. When these two distributions align closely, the free energy 
is low. In active inference, the agent seeks to position itself so that its observations 
correspond with its reality model. 
Section 2 formulates the problem statement. Section 3 shows related works. Section 
4 introduces the fundamentals of active inference and free energy. Section 5 provides a 
brief overview of Dempster-Shafer theory, which updates the dynamic common oper-
ational picture. Section 6 describes the simulation environment and sensor model. In 
Section 7, we mathematically describe how to control an agent using active inference 
by minimizing free energy. Section 8 offers an overview of the implementation, and 
finally, Section 9 presents the conclusions drawn from this work. 
2 Problem Statement and Persistent Surveillance 
2.1 Problem Statement 
In the field of autonomous systems, the task of continuously monitoring a specific area 
over an indefinite period is referred to as persistent surveillance. Real-world applica-
tions for persistent surveillance systems in clude surveillance of areas around critical 
infrastructure and military facilities to detect potential intruders with malicious intent. 
It can also be used for surveillance at popular beaches to prevent drowning incidents 
and for monitoring wildlife in sensitive natural areas for preservation purposes. UAVs 
are particularly well-suited for this type of surveillance task due to their wide-angle 
views, speed, and the relative absence of ob stacles in their operational environments, 
which facilitates trajectory planning for the autonomous agents. 
In this paper, we consider a scenario in  which an autonomous agent is assigned the 
task of continuously monito ring a designated area to maintain an accurate and up-to-
date dynamic common operational picture. The agent must be capable of detecting both 
fixed and moving targets and should ideally be able to keep track of the approximate 
locations of these targets, even when they are out of sensor range. Moving targets must 
therefore be revisited as often as necessary  to prevent losing track of them. Addition-
ally, it is requested that no part of the designated area should be left unobserved for 
more than a specified time. 
In persistent surveillance scenarios, the trajectory planning problem for autonomous 
agents is usually defined by a set of specific goals and constraints, which may have 
different priorities. Various methods can be employed to implement the actual trajec-
tory planning or motion control (as discussed in Section 7). This paper specifically aims 
to investigate the feasibility of using active inference for trajectory planning and gen-
eration. The primary research question addressed in this paper can be formulated as 
follows: 
 Active Inference for an Intelligent Agent 3 
Can active inference be used to solve the motion control problem for a single UAV 
conducting multi-objective persistent surveillance over a predefined 2D area? 
2.2 An Active Inference Approach to Persistent Surveillance 
To effectively implement the active infere nce framework for motion control in a per-
sistent surveillance context, several key components must be defined. 
A generative model describes all possible states and their transitions to address these 
considerations. Information about these states is derived from observations made over 
time, allowing us to update our understand ing of the current state. We express uncer-
tainty in the model using Dempster-Shafer theo ry [3, 4]. In this model, the states are 
represented stochastically; each possible transition of target basic belief from one state 
(e.g., position) to the next is specified by transition probabilities. The states are dynam-
ically updated at each time step using a di ffusion algorithm. This model indicates the 
current basic belief of the existence of at least one target object within each possible 
state (see Section 7.1). 
A generative process complements the generative model by managing new observa-
tions made with the agentâ€™s sensor. In the generative process, we use a Bayesian ap-
proach. This process updates the probabilities of all positions within the agentâ€™s sensor 
radius. This update calculates a new probability for each position based on the current 
sensor model while considering the existing probabilities (see Section 7.2). 
Since we cannot directly minimize the surprise an agent experiences when receiving 
new observations, we focus on minimizing the free energy, which serves as an upper 
bound for that surprise. The free energy is defined as the sum of the divergence between 
two probability distributions and the level of surprise, and is our objective function to 
direct the agentsâ€™ movements. For each location within the sensor radius, we compare 
the probability obtained from the generative model with the probability derived from 
observations, striving to minimize the divergence between the two (see Section 7.3). 
At each time step, we calculate the free ener gy for all locations within the sensorâ€™s 
radius. The agent then takes a fixed-length step in the direction that minimizes free 
energy. This approach enables the agent to control itself autonomously, ensuring it 
achieves the best possible common operational picture. The agentâ€™s control is modeled 
by a Multi-Agent Dynamic Simulator (MADS) developed in-house. 
3 Related Works 
3.1 Persistent Surveillance and Motion Control 
Over the years, different methods for addressing the control problem in persistent sur-
veillance (also referred to as persistent mon itoring) have been proposed. This section 
briefly describes some examples. 
Hari et al. [5] examine a persistent monitoring mission for a single UAV, tasked with 
repeatedly visiting n targets of equal priority. Since the targets are fixed, the problem 
simplifies to a classic traveling salesman problem. Brown and Anderson [6] explore a 
4  J. Schubert, F. Kamrani, and T. Gustavi 
more complex maritime surveillance scenario that includes constraints on UAV dynam-
ics and formulate a multi-objective optimization problem aimed at maximizing infor-
mation gain and minimizing fuel consumption. Feasible and optimal solutions are found 
using a trajectory generation method combined with a particle swarm optimization al-
gorithm. Similar to the problem discussed here (in this paper), HÃ¼bel et al. [7] introduce 
a dynamic â€œinformation mapâ€ subject to information decay and use it to derive a gradi-
ent-based control that drives a group of agents to continuously update their situational 
awareness by surveilling an area. Additionally, the authors propose a time-varying den-
sity function that can be integrated into the control algorithm to model moving points 
of interest. Another approach to increase the probability of autonomous agents observ-
ing moving targets during surveillance missions was proposed by Ramasamy and 
Ghose [8]. Assuming that the probability of observing a target is non-uniformly distrib-
uted across a monitored area, Ramasamy and Ghose assign an â€œimportanceâ€ degree to 
each grid point in a discretized map where the UAV in the scenario has detected a 
target. The importance of a grid point depends on the number of detections made there 
and increases the chances of the UAV revisiting that location. Lastly, there is additional 
work documented in the literature that employs reinforcement learning for persistent 
surveillance control. Chen et al. [9] use a multi-agent reinforcement learning approach 
to learn policies for each agent in a team, tasked with continuously monitoring a 2D 
environment with stationary obstacles. To accomplish this, the problem is modeled so 
that a penalty is applied at every time step if a point in the environment is left unmoni-
tored. Mishra et al. [10] present another example of a reinforcement-learning-based 
method for persistent surveillance. 
3.2 Active Inference for Estimation and Control 
Active inference connects perception and action through variational free energy. The-
oretical links to classical estimation and control show that minimizing variational free 
energy yields objectives that combine information-theoretic surprise with control costs, 
leading to linear-quadratic-Gaussian behavior in linear-Gaussian environments [11]. In 
practical terms, active inference has been employed for state estimation of a quadcopter 
using dynamic expectation maximization (DEM). DEM is a perception scheme inspired 
by the brain, based on a data-driven model-learning algorithm [12]. Additionally, active 
inference has been used for adaptive manipulation control in the absence of detailed 
environment models in industrial robots. This method has proven to be scalable even 
when the dynamics of the environment are not explicitly modeled [13]. Active infer-
ence has also been applied to the adaptive control of robot arms using multimodal per-
ception-action and variational autoencoder (VAE)-based state representations. This ap-
proach does not require a dynamic or kinematic model of the robot [14]. Furthermore, 
active inference has been used to develop a torque controller that integrates raw vision 
and proprioception in a streamlined design for a 7-degrees-of-freedom Franka Emika 
Panda robot, capable of online adaptation to changes in dynamics and human interfer-
ence [15]. It has also been employed for fault-tolerant control under sensor faults, de-
livering unbiased state estimation and simp lifying action specification [16]. These re-
sults support our use of free energy for closed-loop control with a soft sensor model.  
 Active Inference for an Intelligent Agent 5 
3.3 Active Inference for Navigation, Exploration, and Bandit Problems 
For mobile agents, active inference under hierarchical generative models enables 
goalâ€‘oriented navigation with topologically consistent maps and practical robot deploy-
ments [17]. Modular active inference systems support flexible, goal-driven navigation, 
avoiding obstacles and choosing high-confidence paths with strong zero-shot generali-
zation to new settings [18]. Curiosity-driven learning for robotic tasks, using the free 
energy principle, employs Bayesian neural networks to represent epistemic uncertainty 
and model complex behaviors [19]. Moreover, retrospective (residual) surprise has 
been introduced as a computational element in active inference, serving as a lower 
bound on the expected free energy [20]. In decision-making, contextual multi-armed 
bandits (CMABs) extend the classical bandit problem by conditioning action selection 
on observed contextual information. Recent active inference models of CMABs 
[21, 22] use expected free energy to guide context-based action selection, balancing 
exploration and exploitation under uncertaintyâ€”an effect we replicate in our approach 
through minimizing a spatial free-energy field over the evidence map. 
3.4 Multi-agent Active Inference, Organizational Adaptation, and Complex 
Tasks 
In multi-agent settings, active inference is used to design adaptive organizations, where 
roles and structures change by minimizing team-level free energy [23â€“25]. For complex 
robotic tasks, active inference combines with behavior trees to enable continuous plan-
ning and robust execution with fewer nodes [26]. Meanwhile, non-modular, cognitively 
inspired active inference architectures are explored for robustness against unknown in-
puts [27]. Recent work extends active inference to autonomous driving by incorporat-
ing action-oriented priors that link perception and control, leading to more human-like, 
collision-avoidant behavior [28]. In socially interactive and multi-agent scenarios, ac-
tive inference applies to human-robot kinesthetic interaction, where meta-priors adjust 
compliance and counter-forces during physical contact [29], and to empathic, socially 
compliant agents that adapt their movements to surrounding individuals and contextual 
norms [30], demonstrating the flexibility of the free-energy framework for coordination 
and interaction tasks. Active inference also applies to hierarchical, embodied percep-
tion-action loops, where multiple sensorimotor pathways associated with different body 
parts are dynamically combined, enabling the robot to reconfigure control and activate 
only the necessary joints for a given task [31]. Our method differs by operationalizing 
free energy over a spatial Dempster-Shafer evidence map and a deterministic soft sen-
sor model, then guiding the agent to move in the direction that minimizes this per-cell 
objective at each step. 
3.5 Our Contribution 
Compared to surveillance controllers [5â€“10] , we introduce a Dempster-Shafer-based 
evidence map with diffusion and a deterministic soft-output sensor model to generate 
cell-wise evidential scores. Then, we steer the platform by minimizing a grid-based 
6  J. Schubert, F. Kamrani, and T. Gustavi 
free-energy objective that compares a pignistic distribution [32] to a posterior derived 
from the latest observation, including observation surprisal. Compared to active infer-
ence controllers and expected free energy-planning methods [13â€“31], our contribution 
is a computationally lightweight free-energy  minimization over the grid map that ( i) 
separates observation and state evidence, ( ii) avoids Monte Carlo sampling by using 
deterministic soft observations, and (iii) provides an effective exploration-exploitation 
balance for persistent reconnaissance. 
4 Active Inference and Free Energy 
The generative model and the generative proce ss are stochastic in nature. Let the out-
come space over all possible states be Î˜ = áˆ¼ğ‘‡, ğ¹áˆ½, where ğ‘‡ denotes the presence of at 
least one target object, and ğ¹ represents the absence of a target object. 
4.1 The Generative Model 
The generative model outlines all possible states and transitions [1, 2]. In this context, 
the states are represented by grid cells, indicating all possible positions on a map. The 
agent and the target objects can transition between states, moving from any grid cell to 
its nearest neighboring cells. 
The probability in the generative model is denoted by ğ‘
à¯«à¯¬
à¯§ áˆºğœ—áˆ», where ğœ— is the state 
and ğ‘à¯«à¯¬
à¯§  is the probability for a grid cell ğ‘à¯«à¯¬ at time ğ‘¡. In each grid cell, we have 
ğ‘à¯«à¯¬
à¯§ áˆºğœ— = ğ‘‡áˆ»+ ğ‘à¯«à¯¬
à¯§ áˆºğœ— = ğ¹áˆ» = 1.                                           áˆº1áˆ» 
We determine the probabilities ğ‘à¯«à¯¬
à¯§  for all grid cells ğ‘à¯«à¯¬ in our stochastic common op-
erational picture based on all observations gathered throughout the scenario. These ob-
servations form our understanding of the situation. More about how ğ‘à¯«à¯¬
à¯§  is calculated 
when scouting with an agent can be found in Chapter 4. 
4.2 The Generative Process 
In the generative process, we handle new ob servations. At each time step, we have an 
incoming a priori probability ğ‘à¯«à¯¬
à¯§ áˆºğœ—áˆ». This probability is equal to the posterior proba-
bility at the previous time step. 
We set 
ğ‘à¯«à¯¬
à¯§ áˆºğœ—áˆ» = ğ‘à¯«à¯¬
à¯§à¬¿à¬µáˆºğœ—|ğœ‘áˆ».                                                    áˆº2áˆ» 
In addition, we initialize the a priori probability for time 0 according to 
ğ‘à¯«à¯¬
à¬´ áˆºğœ—áˆ» = ğœ€.                                                             áˆº3áˆ» 
Using Bayes theorem, we can calculate the posterior probability ğ‘à¯«à¯¬
à¯§ áˆºğœ—|ğœ‘áˆ» in the grid 
cell ğ‘à¯«à¯¬ for the current time step ğ‘¡ based on the a priori probability. 
 Active Inference for an Intelligent Agent 7 
We have 
ğ‘à¯«à¯¬
à¯§ áˆºğœ—|ğœ‘áˆ» = ğ‘à¯«à¯¬
à¯§ áˆºğœ‘|ğœ—áˆ»
ğ‘à¯«à¯¬à¯§ áˆºğœ‘áˆ» ğ‘à¯«à¯¬
à¯§ áˆºğœ—áˆ»,                                            áˆº4áˆ» 
where ğ‘à¯«à¯¬
à¯§ áˆºğœ‘|ğœ—áˆ» represents the likelihood, which indicates the detection probability for 
an observation ğœ‘ = ğ‘‡, as determined by the sensor model, when we have a target object 
ğœ— = ğ‘‡ in the grid cell ğ‘à¯«à¯¬ at time ğ‘¡. In this context, ğ‘à¯«à¯¬
à¯§ áˆºğœ‘áˆ» represents the probability 
of obtaining an observation. The probability can be calculated according to 
ğ‘à¯«à¯¬
à¯§ áˆºğœ‘áˆ» = ğ‘à¯«à¯¬
à¯§ áˆºğœ‘|ğœ— = ğ‘‡áˆ»âˆ™ğ‘à¯«à¯¬
à¯§ áˆºğœ— = ğ‘‡áˆ»+ ğ‘à¯«à¯¬
à¯§ áˆºğœ‘|ğœ— = ğ¹áˆ»âˆ™ğ‘à¯«à¯¬
à¯§ áˆºğœ— = ğ¹áˆ»,       (5) 
where ğ‘à¯«à¯¬
à¯§ (ğœ— = ğ‘‡) denotes the a priori probability discussed earlier, and 
ğ‘à¯«à¯¬
à¯§ (ğœ— = ğ¹) =1 âˆ’ğ‘à¯«à¯¬
à¯§ (ğœ— = ğ‘‡).                                           (6) 
Additionally, ğ‘à¯«à¯¬
à¯§ (ğœ‘|ğœ— = ğ‘‡) represents the likelihood, which is the detection probabil-
ity of the sensor model, with 
ğ‘à¯«à¯¬
à¯§ (ğœ‘|ğœ— = ğ¹) =1 âˆ’ğ‘à¯«à¯¬
à¯§ (ğœ‘|ğœ— = ğ‘‡).                                      (7) 
4.3 The Free Energy 
Based on the generative modelâ€™s ğ‘à¯«à¯¬
à¯§ (ğœ—) and the generative processâ€™s ğ‘à¯«à¯¬
à¯§ (ğœ—|ğœ‘), we 
can now calculate the free energy ğ¹à¯«à¯¬
à¯§  for all grid cells ğ‘à¯«à¯¬ at time ğ‘¡. 
We have 
ğ¹à¯«à¯¬
à¯§ = ğ·à¯„à¯…àµ£ğ‘à¯«à¯¬
à¯§ (ğœ—) âˆ¥ğ‘à¯«à¯¬
à¯§ (ğœ—|ğœ‘)àµ§âˆ’ğ‘™ğ‘›àµ£ğ‘ à¯«à¯¬
à¯§ (ğœ‘)àµ§                                             
= àµ¥ à·ğ‘ à¯«à¯¬
à¯§ (ğœ—) âˆ™ğ‘™ğ‘›á‰† ğ‘à¯«à¯¬
à¯§ (ğœ—)
ğ‘à¯«à¯¬à¯§ (ğœ—|ğœ‘)á‰‡
à°£âˆˆáˆ¼à¯,à®¿áˆ½
àµ©âˆ’ğ‘™ğ‘›àµ£ğ‘ à¯«à¯¬
à¯§ (ğœ‘)àµ§                       (8) 
here ğ·à¯„à¯… is the Kullback-Leibler di vergence [33]. The term âˆ’ğ‘™ğ‘›àµ£ğ‘à¯«à¯¬
à¯§ (ğœ‘)àµ§ represents 
the degree of surprise from an observation, ğ‘à¯«à¯¬
à¯§ (ğœ—) is the probability according to the 
generative model, and ğ‘à¯«à¯¬
à¯§ (ğœ—|ğœ‘) is the posterior probability according to the generative 
process, calculated at each time poin t based on Bayes theorem. Finally, ğ‘à¯«à¯¬
à¯§ (ğœ‘) is the 
probability of an observation as derived in equation (5). 
In active inference, the action that minimizes ğ¹à¯«à¯¬
à¯§  is chosen. This action may involve 
moving to ğ‘à¯«à¯¬ or in its direction. 
5 Dempster-Shafer Theory 
In Dempster-Shafer theory [3, 4], belief is assigned to a proposition through a basic 
belief assignment. The proposition is represented by a subset ğ´ of an exhaustive set of 
mutually exclusive possibilities, referred to as a sample space Î˜. 
8  J. Schubert, F. Kamrani, and T. Gustavi 
The basic belief function ğ‘š is defined as a function from the power set of Î˜ to the 
interval áˆ¾0, 1áˆ¿ 
ğ‘š:2 à®€ â†’ áˆ¾0,1áˆ¿                                                           (9) 
where ğ‘š(âˆ…) =0  and 
à·ğ‘š (ğ´)
à®ºâŠ†à®€
= 1.                                                        (10) 
Here, ğ‘š(ğ´) represents the basic belief assigned to ğ´. 
If we receive additional information abou t the same hypothesis from a different 
source, we combine the two basic belief functions to create a more comprehensive un-
derstanding. This is achieved by computing the orthogonal combination using Demp-
sterâ€™s rule. Let ğµ be a subset of ğ‘šà¬µ and ğ¶ be a subset of ğ‘šà¬¶. The combination of ğ‘šà¬µ 
and ğ‘šà¬¶ results in a new basic belief function ğ‘šà¬µ âŠ•ğ‘šà¬¶ where 
ğ‘šà¬µ âŠ•ğ‘šà¬¶(ğ´) = ğ¾âˆ™ à· ğ‘š(ğµ)
à®»â‹‚à®¼à­€à®º
âˆ™ğ‘š(ğ¶),                                (11) 
where ğ¾ is a normalization constant. 
6 Simulation Environment and Sensor Model 
6.1 Simulation Environment 
The world is represented as a 2D map of a designated reconnaissance area. This map is 
divided into a grid of ğ‘šÃ— ğ‘› square cells indexed based on a coordinate system. Using 
a 2D representation is a deliberate simplification justified by the fact that the scenario 
being examined is much larger in its x and y dimensions compared to any variation in 
its z dimension. Although the simulator can perform 3D movements, this feature was 
disabled during the simulations conducted. The positions of both the agent and any 
target objects are indicated using cell indices in the format ğ‘à¯«à¯¬, where ğ‘¥ and ğ‘¦ are inte-
gers. Each cell is assumed to be large enough  to contain the agent or a target object 
within the reconnaissance area. 
We conduct experiments using active inference for UAV control in M ATLAB. The 
previously mentioned 2D map is the foundation for the generative model describing the 
environment. The simulation environment includes both fixed and moving target ob-
jects. Two predefined movement patterns are available for the moving target objects: 
stationary (no movement) or movement along a straight line. 
We represent uncertainty in the model us ing Dempster-Shafer theory [3, 4]. This 
uncertainty, at the mapâ€™s cell level, provides two evidence-based likelihood values. The 
first is a basic belief, denoted as ğ‘š
à¯«à¯¬
à¯§ (ğœ— = ğ‘‡), which ranges from 0 to 1. It represents 
the basic belief at time t that the cell ğ‘à¯«à¯¬ contains at least one target object. The second 
is an estimated likelihood value, also between 0 and 1, denoted as ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹). This 
 Active Inference for an Intelligent Agent 9 
indicates the basic belief that, at time t, the cell does not contain any target objects. The 
formulas for diffusing basic belief to neighboring cells in the generative model are de-
signed to be independent of the gridâ€™s topology. For example, moving from a square 
grid topology, used in this experiment, to a hexagonal topology only requires changing 
the parameter N, which represents the number of neighboring cells in equations (12) 
and (13) (see Section 7.1). This change adjusts N from eight to six. 
6.2 Sensor Model 
The sensor model serves as an intelligent image sensor designed for ground scouting. 
Its detection radius lets it reliably identify and classify objects as targets or non-targets. 
Each time an object is positively classified as a target, the method also provides a quan-
titative estimate, denoted as ğ‘š
à¯«à¯¬
à¯§ (ğœ— = ğ‘‡), representing the basic belief that this classi-
fication is correct. If an object is identified as a target, the sensor calculates an estimate 
of its coordinates on a 2D map. 
Since the sensor does not actively monitor or classify the absence of targets within 
the search area, it is more challenging to quantify evidence for this condition. If an area 
has been scanned without identified targets, it suggests no targets are present. In loca-
tions where no targets are detected, the sensor  provides a default estimate, denoted as 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹), for the basic belief of target absence. The terrain in the area can influence 
this estimate; for instance, the likelihood of detecting targets is generally lower in for-
ests compared to open fields. 
We implement a simplified version of the se nsor model used in the simulations to 
mimic its behavior as described above. The detection probability for target objects is 
set to 1, meaning that all target objects are detected. However, the probability that a 
detected target object is co rrectly classified is set to 0.7. Additionally, we assume the 
sensor does not generate false detections of target objects. Therefore, the uncertainties 
in the simulated sensor output arise exclusively from the classification process. 
The implementation is based on the premise that a real sensorâ€™s ability to classify 
target objects primarily depends on the distance between the sensor and the potential 
target object. The sensor operates most relia bly when it is focused on objects directly 
beneath the agent to which it is mounted. Consequently, the sensorâ€™s capability to de-
termine whether an area is free of target obj ects is expected to decline as the distance 
from the sensor increases. In the implementation, the default values of ğ‘š
à¯«à¯¬
à¯§ (ğœ— = ğ‘‡) =
0.7 and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) =0 . 3 are applied. These values correspond to the maximum ex-
pected levels of ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) in real-world scenarios. During the sim-
ulation, these default values generate realistic outputs for ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) and 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) as the simulated sensor moves across the 2D map. One-dimensional 
Gaussian functions are used to model how these values decrease with increasing dis-
tance from the sensor. 
When the sensor model is utilized in a simulation, two matrices, with basic beliefs 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹), are generated for all grid cells ğ‘à¯«à¯¬ within the sensor 
radius using two Gaussian functions. The first Gaussian function, which produces 
higher values, is multiplied by a factor to set its maximum value equal to 
10  J. Schubert, F. Kamrani, and T. Gustavi 
ğ‘šà¯«à¯¬
à¯—à¯˜à¯™à¯”à¯¨à¯Ÿà¯§(ğœ— = ğ‘‡) =0 . 7. This function generates ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) for grid cells that contain 
target objects, while for these cells, ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) is set to 0. The second Gaussian func-
tion is employed similarly to create ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) for grid cells that do not contain target 
objects. This function is scaled so that its maximum value equals ğ‘šà¯«à¯¬
à¯—à¯˜à¯™à¯”à¯¨à¯Ÿà¯§(ğœ— = ğ¹) =
0.3. In these grid cells, ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) is set to 0. In other words, in the simulation, our 
sensor does not draw a stochastic categorical observation; instead, it produces a 
deterministic soft output interpreted as the expected correctness of a positive detection 
for each cell within the radius. We encode this soft observation as a score in [0, 1] and, 
for brevity, we write it using the same ğ‘šà¯«à¯¬
à¯§ (â¦) symbols as our map-based evidence. 
Thus, when ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) appears below in the context of the sensor, it should be read 
as a soft observation score produced by the sensor model, not as a posterior belief about 
the state. 
To enhance the sensor modelâ€™s realism, we introduce an assumed standard deviation, 
referred to as ğœà¯£à¯¢à¯¦à¯œà¯§à¯œà¯¢à¯¡, which represents the error in the sensorâ€™s position estimate for 
identified target objects. Considering the an ticipated positioning uncertainty of a sen-
sor, the values for ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) in grid cells located within a distance 
less than the sensorâ€™s radius ğ‘Ÿàµ«ğœà¯£à¯¢à¯¦à¯œà¯§à¯œà¯¢à¯¡àµ¯ are adjusted: ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) is determined by 
the distance to the estimated target position. A Gaussian function, with an appropriate 
standard deviation, is applied for this calculation; ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) is set equal to 0. 
The Gaussian sensor model is utilized in  the generative Dempster-Shafer model to 
quantify the observation basic belief ğ‘šà¯«à¯¬
à¯§ (ğœ—) and in the generative Bayesian process as 
its likelihood ğ‘à¯«à¯¬
à¯§ (ğœ‘|ğœ—). 
7 Controlling an Intelligent Agent 
7.1 The Generative Model 
This work presents the common operational picture using an evidence map, denoted as 
ğº. This evidence map is structured as a grid composed of multiple cells. Each cell cor-
responds to a specific segment of the geogra phical area being monitored, as a grid is 
overlaid on the map of that area. Thus, each cell represents a distinct portion of the 
surveillance zone. 
Each cell ğ‘à¯«à¯¬ in the evidence map is associated with two basic beliefs: ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) 
and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹). Here, ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) indicates the basic belief that the cell at time ğ‘¡ 
contains at least one object of interest, while ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) represents the basic belief 
that the cell is empty. The following conditions apply to the basic beliefs: 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡), ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) â‰¥ 0, and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) + ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) â‰¤ 1 for all cells ğ‘à¯«à¯¬ 
at all times ğ‘¡. The basic belief for cell ğ‘à¯«à¯¬ at time ğ‘¡ is represented by the pair 
á‰€ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡), ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹)á‰, with uncertainty defined as 1 âˆ’ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) âˆ’
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹). 
In Fig. 1, the green area represents ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡), the red area represents 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹), and the white area indicates the uncertainty. 
 Active Inference for an Intelligent Agent 11 
 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡)                                                        ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) 
Fig 1. Illustration of evidence and uncertainty in cell ğ‘à¯«à¯¬. Green indicates ğ‘šà¯«à¯¬à¯§ (ğœ— = ğ‘‡), red in-
dicates ğ‘šà¯«à¯¬à¯§ (ğœ— = ğ¹), and white shows residual uncertainty 1 âˆ’ğ‘šà¯«à¯¬à¯§ (ğœ— = ğ‘‡) âˆ’ğ‘šà¯«à¯¬à¯§ (ğœ— = ğ¹); 
this per-cell Dempsterâ€“Shafer pair forms the basis of the evidence map G. 
The uncertainty 1 âˆ’ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) âˆ’ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) can be considered a genuine uncer-
tainty in cell ğ‘à¯«à¯¬ that the agent should strive to minimize across all cells ğ‘à¯«à¯¬ and at all 
times to maintain a current common operational picture. 
Instead of assigning a single piece of evidence for a positive detection to one specific 
set of grid cells within the assumed detectio n radius of the sensors, we opt to assign 
evidence to each grid cell individually within that radius. This approach offers a more 
detailed representation, as each grid cell ğ‘à¯«à¯¬ receives its value, wh ile significantly re-
ducing the computational complexity involved in updating these values with new sen-
sor measurements. 
Our experiment utilizes a Gaussian distribution with a standard deviation equal to 
the sensor radius, ensuring that the center cell is assigned the highest value. This method 
results in a series of distinct basic belie f distributions â€“ one fo r each grid cell. The 
outcome provides a satisfactory resolution and a relevant spread in the evidence-based 
common operational picture. The diffusion model outlined in equations (12) and (13) 
achieves a dynamic evidence-based common operational picture. 
Given that the observed environment is assumed to be dynamic, the value of older 
information diminishes over time. In the evidence map, this decreasing certainty about 
the locations of already detected objects is represented by the spread of basic belief to 
adjacent cells. 
Regardless of whether the agent observed the state of cell ğ‘
à¯«à¯¬ between times ğ‘¡ and 
ğ‘¡+1 , the basic beliefs ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) in the cell are updated according 
to equations (12) and (13). This is separate from fusion with new observations, which 
is managed in equations (14) and (15). The update for the basic belief is given by: 
ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) =1 âˆ’á‰†1 âˆ’ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡)
ğ‘+1 á‰‡âˆ™ à·‘ á‰† 1 âˆ’
ğ‘šà¯œà¯
à¯§ (ğœ— = ğ‘‡)
ğ‘+1 á‰‡
(à¯œà¯) âˆˆ àµ›à¯¡à¯˜à¯œà¯šà¯›à¯•à¯¢à¯¥à¯¦ à¯¢à¯™ à¯–à³£à³¤àµŸ
 
(12) 
where ğ‘ is the number of neighbors of the cell ğ‘à¯«à¯¬. This means that the basic belief 
ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) of cell ğ‘à¯«à¯¬ is shared among its neighbors and itself (i.e., among nine grid 
cells in the case of a square grid) and then combined using Dempsterâ€™s rule. This causes 
a diffusion of basic belief ğ‘šà¯œà¯
à¯§ (ğœ— = ğ‘‡)over an increasingly larger area over time (in a 
manner similar to an explosion). 
12  J. Schubert, F. Kamrani, and T. Gustavi 
Suppose ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) >0  in cell ğ‘à¯«à¯¬, some of the basic belief ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ‘‡) will be 
propagated to its ğ‘ neighbors. Conversely, if ğ‘šà¯œà¯
à¯§ (ğœ— = ğ‘‡) >0  in adjacent cells, some 
basic belief is propagated into cell ğ‘à¯«à¯¬. 
Furthermore, we have 
ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹) = ğ‘šà¯«à¯¬
à¯§ á‰€ à¬µ
à¯‡à¬¾à¬µá‰(ğœ— = ğ¹) âˆ™à·‘ğ‘š à¯œà¯
à¯§ á‰€ à¬µ
à¯‡à¬¾à¬µá‰(ğœ— = ğ¹)
(à¯œà¯) âˆˆ àµ›à¯¡à¯˜à¯œà¯šà¯›à¯•à¯¢à¯¥à¯¦ à¯¢à¯™ à¯–à³£à³¤àµŸ
(13) 
where ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹) indicates that cell ğ‘à¯«à¯¬ is empty at time ğ‘¡+1 . This suggests that if 
cell ğ‘à¯«à¯¬ will be empty at the next time step (i.e., ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹)), then both its neighbor-
ing cells and the cell itself must currently be empty, meaning ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹). Equation 
(13) contracts basic belief ğ‘šà¯«à¯¬
à¯§ (ğœ— = ğ¹) inward (in a manner similar to an implosion). 
A sensor on an agent gathers information about one or more cells in the evidence 
map. This gathering is influenced by the sensorâ€™s detection radius and the agentâ€™s flight 
altitude. As the flight altitude rises, the likelihood of detecting interesting objects on 
the ground decreases. In our simulations, we keep a constant flight altitude since we 
only model the problem in 2D. 
A positive observation occurs when the sensor detects an object of interest in a spe-
cific cell ğ‘
à¯«à¯¬ at time ğ‘¡, represented as àµ«ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ‘‡),0 àµ¯, where ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ‘‡) indicates 
the basic belief that the positive detection is correct. Conversely, a â€œnegativeâ€ observa-
tion, where the sensor does not det ect any object of interest in cell ğ‘à¯«à¯¬ at time ğ‘¡, is 
represented as á‰€0, ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ¹)á‰. Here, ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ¹) represents the basic belief con-
firming that the negative result is accurate. 
Both ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ¹) fall within the range of áˆ¾0,1áˆ¿. Sensor meas-
urements continuously update the evidence map according to equations (14) and (15) 
below. 
If we obtain a positive observation àµ«ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ‘‡),0 àµ¯, it is combined with the exist-
ing basic belief pair ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹), which are derived using equa-
tions (13) and (14) with Dempsterâ€™s rule [3]. 
We have 
ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) = 
=
ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) + ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ‘‡) âˆ™á‰€1 âˆ’ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) âˆ’ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹)á‰
1 âˆ’ğ‘šà¯«à¯¬à¯§à¬¾à¬µ(ğœ‘ = ğ‘‡) âˆ™ğ‘šà¯«à¯¬à¯§à¬¾à¬µ(ğœ— = ğ¹)    (14) 
and 
ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ¹) =
á‰€1 âˆ’ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ‘‡)á‰âˆ™ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹)
1 âˆ’ğ‘šà¯«à¯¬à¯§à¬¾à¬µ(ğœ‘ = ğ‘‡) âˆ™ğ‘šà¯«à¯¬à¯§à¬¾à¬µ(ğœ— = ğ¹) .                   (15) 
It is assumed that equations (14) and (15) are always applied after equations (12) and 
(13), and at the same time, ğ‘¡. The basic beliefs ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹) on the 
right-hand side represent the results fr om the diffusion update at time step ğ‘¡ + 1 . In 
 Active Inference for an Intelligent Agent 13 
contrast, the values ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ¹) on the left-hand side, indicated 
with an asterisk (*), are the combined re sults from the two updates at the same time 
step ğ‘¡ + 1 . 
If a new â€œnegativeâ€ observation is received in grid cell ğ‘à¯«à¯¬, then á‰€0, ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ¹)á‰ 
is combined with ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹) using Dempsterâ€™s rule. 
We have 
ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) =
ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) âˆ™á‰€1 âˆ’ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ¹)á‰
1 âˆ’ğ‘šà¯«à¯¬à¯§à¬¾à¬µ(ğœ— = ğ‘‡) âˆ™ğ‘šà¯«à¯¬à¯§à¬¾à¬µ(ğœ‘ = ğ¹)                     (16) 
and 
ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ¹) = 
=
ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹) + ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘ = ğ¹) âˆ™á‰€1 âˆ’ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) âˆ’ğ‘šà¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹)á‰
1 âˆ’ğ‘šà¯«à¯¬à¯§à¬¾à¬µ(ğœ— = ğ‘‡) âˆ™ğ‘šà¯«à¯¬à¯§à¬¾à¬µ(ğœ‘ = ğ¹) .  (17) 
A combined result of the two distributions ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) and ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ¹) for ğœ— =
ğ‘‡ is shown in Fig. 2. Here, the fused resu lt in the figure shows the remaining basic 
belief from positive observations after taking into account â€œnegativeâ€ observations. 
7.2 The Generative Process 
In the generative process, we employ a Bayesian approach. When we receive a current 
observation, our goal is to calculate the updated posterior distribution ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—|ğœ‘). We 
must determine this probability distribution across all grid cells, ğ‘à¯«à¯¬, to achieve this. 
This requires a sensor model in the form of a likelihood distribution ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘|ğœ—) and an 
observation model ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘), as well as an a priori distribution ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—). 
We begin with the a priori distribution. It is important to note that the a priori distri-
bution at each time step equals the posterior distribution from the previous time point. 
We have 
ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—) = ğ‘à¯«à¯¬
à¯§ (ğœ—|ğœ‘).                                                  (18) 
Initially, we have set 
ğ‘à¯«à¯¬
à¬´ (ğœ—) = ğœ€ = # ğ‘ğ‘ ğ‘ ğ‘¢ğ‘šğ‘’ğ‘‘ ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ğ‘  ğ‘–ğ‘› ğ‘¡â„ğ‘’ ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ ğ‘ğ‘Ÿğ‘’ğ‘
# ğ‘”ğ‘Ÿğ‘–ğ‘‘ ğ‘ğ‘’ğ‘™ğ‘™ğ‘  ğ‘–ğ‘› ğ‘¡â„ğ‘’ ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ ğ‘ğ‘Ÿğ‘’ğ‘ .                (19) 
Using a likelihood distributio n and our sensor model, we assign probabilities to each 
grid cell ğ‘à¯«à¯¬ within the sensorâ€™s radius based on two Gaussian distributions. 
To calculate the probability of an observation, denoted as ğ‘à¯«à¯¬
à¯§ (ğœ‘), we can express it 
as follows: 
ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘) = ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘|ğœ— = ğ‘‡) âˆ™ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) + ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘|ğœ— = ğ¹) âˆ™ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹),( 2 0 ) 
14  J. Schubert, F. Kamrani, and T. Gustavi 
 
 
Fig. 2. Fused results, ğ‘šà¯«à¯¬à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) derived from the generative model in a simulation scenario 
at 50 seconds (2D on top and 3D below). Values reflect diffusion, equations (12)â€“(13), followed 
by Dempsterâ€“Shafer fusion, equations (14)â€“(17); hi gher values indicate a stronger basic belief 
that a cell contains â‰¥ 1 target (axes in meters; black â€œ+â€ marks show target locations). 
where ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡) is the a priori probability derived earlier in (18) and 
ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ¹) =1 âˆ’ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡).                                      (21) 
Additionally, the likelihood distribution ğ‘à¯«à¯¬
à¯§ (ğœ‘|ğœ— = ğ‘‡) is calculated using a Gaussian 
distribution, similarly to the method described in Section 6.2, starting from 
ğ‘šà¯«à¯¬
à¯—à¯˜à¯™à¯”à¯¨à¯Ÿà¯§(ğœ— = ğ‘‡). 

 Active Inference for an Intelligent Agent 15 
Since the sensor returns a deterministic score, we define the likelihood directly from 
it. Hence, the identification in (22) is just shorthand rather than an inference about the 
state, 
ğ‘
à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘|ğœ— = ğ‘‡) â‰œğ‘š à¯«à¯¬
à¯§à¬¾à¬µ(ğœ— = ğ‘‡), 
ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘|ğœ— = ğ¹) =1 âˆ’ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘|ğœ— = ğ‘‡).                            (22) 
Using the three probability distributions (a priori ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—), likelihood ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘|ğœ—), and 
observation ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘)), we can calculate the desired posterior distribution using Bayes 
theorem. 
We have 
ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—|ğœ‘) = ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘|ğœ—)
ğ‘à¯«à¯¬à¯§à¬¾à¬µ(ğœ‘) ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—).                                       (23) 
Fig. 3 displays the posterior distribution concurrently with Fig. 2. 
7.3 The Free Energy 
The basic belief distribution ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) represents the distribution from the gener-
ative model that we aim to compare with the posterior distribution derived from the 
current observation ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—|ğœ‘). Notably, ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) encompasses values over all 
subsets of the sample space Î˜, including Î˜ itself (where |2à®€| =3 ), while ğ‘à¯«à¯¬
à¯§ (ğœ—|ğœ‘) is 
limited to values associated with the elements of Î˜ (where |Î˜| =2 ). Therefore, we 
must convert the basic belief distribution into a probability distribution to facilitate a 
comparison between these two distributions. This conversion is achieved through a 
pignistic transformation [32], defined as follows: 
ğµğ‘’ğ‘¡ğ‘ƒ(ğœ”) = à· ğ‘š(ğ‘‹)
|ğ‘‹|                                                 
à° âˆˆà¯‘
(24) 
where ğœ”âˆˆÎ˜  and ğ‘‹âŠ†Î˜ . 
We have 
ğ‘à¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) = 1
2 àµ£1+ ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) âˆ’ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ¹)àµ§                  (25) 
and 
ğ‘à¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ¹) = 1
2 àµ£1+ ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ¹) âˆ’ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡)àµ§,                 (26) 
where ğ‘à¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ—) represents a pignistic probability derived from the pignistic transfor-
mation of the basic belief distribution ğ‘šà¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ—). 
16  J. Schubert, F. Kamrani, and T. Gustavi 
 
 
Fig. 3. The posterior distribution ğ‘à¯«à¯¬à¯§à¬¾à¬µ(ğœ—|ğœ‘), calculated after the most recent observation, using 
Bayes rule, equation (23), with the prior, equa tions (18)â€“(21), and Gaussian sensor likelihood, 
equation (22), at the same timestep as Fig. 2, for comparison with the fused belief shown there. 
We can now calculate the free energy of each grid cell ğ‘à¯«à¯¬ within the sensor radius by 
measuring the divergence between ğ‘à¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ—) and ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—|ğœ‘), along with the degree of 
surprise represented by ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘). 
Fig. 4 illustrates the divergence between the pignistic probability distribution 
ğ‘à¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ—) from the generative model and the posterior distribution ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—|ğœ‘) from the 
generative process. 

 Active Inference for an Intelligent Agent 17 
 
 
Fig. 4. The divergence between the model and the actual observation. Cell-wise ğ·à¯„à¯…àµ£ğ‘à¯«à¯¬à¯§à¬¾à¬µâˆ—(ğœ— =
ğ‘‡) âˆ¥ğ‘à¯«à¯¬à¯§à¬¾à¬µ(ğœ—|ğœ‘)àµ§, which is the first term of equation (27) within the sensor footprint ( r = 100 
meters), illustrating where the modelâ€™s belief and the posterior disagree. 
Fig. 5 displays the degree of surprise, indicated as âˆ’ğ‘™ğ‘›àµ£ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘)àµ§. 
We have 
ğ¹à¯«à¯¬ = ğ·à¯„à¯…àµ£ğ‘à¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) âˆ¥ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—|ğœ‘)àµ§âˆ’ğ‘™ğ‘›àµ£ğ‘ à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘)àµ§                                 
= àµ¥ à·ğ‘ à¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ—) âˆ™ğ‘™ğ‘›á‰† ğ‘à¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ—)
ğ‘à¯«à¯¬à¯§à¬¾à¬µ(ğœ—|ğœ‘)á‰‡
à°£âˆˆáˆ¼à¯,à®¿áˆ½
àµ©âˆ’ğ‘™ğ‘›àµ£ğ‘ à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘)àµ§,                (27) 
where ğ·à¯„à¯… is the Kullback-Leibler divergence [33]. 

18  J. Schubert, F. Kamrani, and T. Gustavi 
 
 
Fig. 5. The level of surprise. Surprisal âˆ’ğ‘™ğ‘›àµ£ğ‘à¯«à¯¬à¯§à¬¾à¬µ(ğœ‘)àµ§, which represents the second term of equa-
tion (27), is shown inside the sensor footprint. Outside the footprint, ğ‘(ğœ‘) =0 , so surprisal di-
verges and is omitted. 
The free energy ğ¹à¯«à¯¬ is calculated for all grid cells w ithin the sensor radius and mini-
mized across all grid cells. Finally, the variational free energy is presented in Fig. 6. 
The agentâ€™s position is updated with steps smaller than the sensor radius. Thus, using 
active inference, we gradually move the agentâ€™s position toward the grid cell, which 
minimizes ğ¹à¯«à¯¬. 

 Active Inference for an Intelligent Agent 19 
 
 
Fig. 6. Free energy, denoted as ğ¹à¯«à¯¬, for all grid cells ğ‘à¯«à¯¬. ğ¹à¯«à¯¬ is calculated using equation (27); 
the green â€œÃ—â€ marks argmin F, which the agent uses to set the next waypoint. 
8 Implementation and Results for an Intelligent Agent 
Implementing agent control us ing the free energy  principle and active inference in-
volves calculations, as outlined in Section 7. However, several essential implementa-
tion details and design choices must be considered. 
The generative model and process are evaluated at each simulation time step. Im-
portantly, the free energy is calculated only for positions within the sensor radius; for 
this simulation, we use a sensor radius of 100 meters. This limitation is not merely a 
design choice but a fundamental aspect of the model. According to equation (27), free 

20  J. Schubert, F. Kamrani, and T. Gustavi 
energy is defined as the sum of the Kullback-Leibler divergence between two probabil-
ities, ğ·à¯„à¯…àµ£ğ‘à¯«à¯¬
à¯§à¬¾à¬µâˆ—(ğœ— = ğ‘‡) âˆ¥ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ—|ğœ‘)àµ§, and the surprise, which is calculated as 
âˆ’ğ‘™ğ‘›àµ£ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘)àµ§. Here, ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘) represents the probability of the observation. Outside the 
sensor radius, ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘) equals zero, causing âˆ’ğ‘™ğ‘›àµ£ğ‘à¯«à¯¬
à¯§à¬¾à¬µ(ğœ‘)àµ§ to approach infinity. This 
observation highlights the notion that surprise becomes infinite when faced with im-
possibilities. 
The computational complexity per step of our planner is 
ğ‘‚àµ«ğ‘à¯”à¯šà¯˜à¯¡à¯§à¯¦ 
à¬¶ + ğ‘à¯£à¯¢à¯œğ´à¯š + ğ´à¯š + ğ‘ à¯¥
à¬¶àµ¯,                                    (28) 
where ğ‘à¯”à¯šà¯˜à¯¡à¯§à¯¦ is the number of ag ents in the swarm, ğ´à¯š is the number of grid cells,  
ğ‘à¯£à¯¢à¯œ is the number of points of interest (POI), and ğ‘ à¯¥ is the sensing radius expressed in 
grid cells. In practice, for a 580 Ã— 380 grid with ten agents, six POI, and a sensing 
radius of 100 cells (i.e., 100 meters), each simu lation step took on average 0.12 sec-
onds, which amounts to 36 seconds for a 300-step rollout (one minute wall-clock time 
at five simulation ticks per second, i.e., faster than real time) on a standard laptop 
(M
ATLAB; Intel i7; 32 GB RAM). 
Another design choice focuses on how to select the new waypoint. Once the position 
with the lowest free energy has been identified, we calculate a vector from the agentâ€™s 
current position to the minimum free energy position. The agent then takes an incre-
mental step toward that position. The next waypoint is placed at a fixed distance along 
this vector, which in our simulation is set to half the sensor radius (i.e., a step length of 
50 meters). This approach ensures a consistent distance between successive waypoints. 
This section provides a qualitative analysis of the methodâ€™s behavior based on sim-
ulation observations. The findings indicate that the technique demonstrates favorable 
behavior. After navigating the pre-programmed waypoints (the first three targets), the 
agent continues to search the area in a balanced manner that integrates exploration and 
exploitation. 
An agentâ€™s trajectory (shown as a red line) over a 500-second scenario (Fig. 7) illus-
trates a dynamic balance between tracking various target goals (indicated by black â€œ+â€ 
symbols) and exploring new areas. Black traj ectories represent three moving targets, 
while four targets are stationary. The green â€œ xâ€ indicates the minimum free energy at 
the current time. 
A qualitative analysis of the images using a stochastic model, along with probabil-
istic observations and their divergences, provides insights into the level of surprise ex-
perienced by the agent. This understanding and the concept of free energy help clarify 
the reasons and timing behind the agentâ€™s decision to scout or pursue a target. When 
examining the sequence of images throughout a scenario, a behavior that is intuitively 
and analytically coherent emerges. 
 Active Inference for an Intelligent Agent 21 
 
Fig. 7. The agentâ€™s path entails both reconnaissanc e and target tracking. The trajectory, way-
points, and position of minimum free energy are illustrated. The agents, represented by red 
crosses, select a new waypoint along a vector that points towards the minimum free energy point, 
indicated by the green cross. The black crosses depict the exact locations of the targets from a 
global perspective; these locations remain unknown  to the agents except through sensor obser-
vations. The black â€œ+â€ at the end of black trajectories indicates the final position of a target as it 
exits the map and the simulation. 
9 Conclusions 
A simulation of an intelligent agent demonstrates its ability to autonomously decide 
when to engage in scouting activities and when to track specific targets. This decision-
making process entirely depends on the data acquired through the agentâ€™s sensors. As 
the agent operates, it navigates from its current location towards the designated grid 
cell that minimizes free energy. Free energy quantifies the degree of alignment between 
the agentâ€™s perception of reality and its current obse rvations. The agentâ€™s minimizing 
free energy enhances its comprehension and adaptability to the external environment. 
Additionally, the planner operates efficiently: in our prototype, each step takes approx-
imately 0.12 seconds on average, resulting in 36 seconds for a 300-step rollout using 
standard hardware, which demonstrates its potential for near real-time operation. A 
qualitative analysis of the agentâ€™s behavior during the simulation reveals promising re-
sults. The agentâ€™s ability to balance exploration and exploitation indicates significant 
operational autonomy and efficiency. A quantitative analysis of the active inference 
approach to the persistent monitoring problem has not yet been performed. To achieve 
this, some mission goals need to be formulated, and appropriate metrics for measuring 
goal fulfillment must be defined. Examples  of performance metrics for a combined 
tracking and area coverage scenario, similar to the scenario discussed in this paper, can 
be found, for instance, in [8]. The perf ormance of the implem ented active inference-

22  J. Schubert, F. Kamrani, and T. Gustavi 
based control should be compared to that of a simple baseline control or, ideally, with 
several other control algorithms from the literature, and for some different scenarios. 
Disclosure of Interests. The authors have no competing interests to declare relevant to this arti-
cleâ€™s content. 
References 
1. Parr, T., Pezzulo, G., Friston, K. J.: Active inference: The free energy principle in mind, 
brain, and behavior. The MIT Press, Cambridge, MA (2022). doi:10.7551/mitpress/
12441.001.0001 
2. Buckley, C. L., Kim, C. S., McGregor, S., Seth, A. K.: The free energy principle for action 
and perception: A mathematical review . Journal of Mathem atical Psychology 81, 55â€“79 
(2017). doi:10.1016/j.jmp.2017.09.004 
3. Dempster, A. P.: A generalization of Bayesian inference. Journal of the Royal Statistical 
Society. Series B 30(2), 205â€“247 (1968). doi:10.1111/j.2517-6161.1968.tb00722.x 
4. Shafer, G.: A mathematical theory of evidence. Princeton University Press, Princeton, NJ 
(1976) 
5. Hari, S. K. K., Rathinam, S., Darbha, S., Kalyanam, K., Manyam, S. G., Casbeer, D.: Opti-
mal UAV route planning for persistent monitoring missions. IEEE Transactions on Robotics 
37(2), 550â€“566 (2020). doi:10.1109/TRO.2020.3032171 
6. Brown, A., Anderson, D.: Trajectory opti mization for high-altitude long-endurance UAV 
maritime radar surveillance. IEEE Transactions on Aerospace and Electronic Systems 56(3), 
2406â€“2421 (2020). doi:10.1109/TAES.2019.2949384 
7. HÃ¼bel, N., Hirche, S., Gusrialdi, A., Hatanaka, T., Fujita, M., Sawodny, O.: Coverage con-
trol with information decay in dynamic environments. IFAC Proceedings 41(2), 4180â€“4185 
(2008). doi:10.3182/20080706-5-KR-1001.00703 
8. Ramasamy, M., Ghose, D.: Learning-based preferential surveillance algorithm for persistent 
surveillance by unmanned aerial vehicles. In: Proceedings of the 2016 International Confer-
ence on Unmanned Aircraft Systems, pp . 1032â€“1040. IEEE, Piscataway, NJ (2016). 
doi:10.1109/ICUAS.2016.7502678 
9. Chen, J., Baskaran, A., Zhang, Z., Tokekar, P.: Multi-agent reinforcement learning for visi-
bility-based persistent monitoring. In: Proceedings of the 2021 IEEE/RSJ International Con-
ference on Intelligent Robots and Systems,  pp. 2563â€“2570. IEEE, Piscataway, NJ (2021). 
doi:10.1109/IROS51168.2021.9635898 
10. Mishra, M., Poddar, P., Agrawal, R., Chen, J., Tokekar, P., Sujit, P. B.: Multi-agent deep 
reinforcement learning for pers istent monitoring with sensing, communication, and locali-
zation constraints. IEEE Transactions on Automation Science and Engineering 22, 2831â€“
2843 (2025). doi:10.1109/TASE.2024.3385412 
11. van de Laar, T., Ã–zÃ§elikkale, A., Wymeersch, H.: Application of the free energy principle 
to estimation and control. IEEE Tr ansactions on Signal Processing 69, 4234â€“4244, 2021. 
doi:10.1109/TSP.2021.3095711 
12. Bos, F., Meera, A. A., Benders, D., Wisse, M.: Free energy principl e for state and input 
estimation of a quadcopter flying in wind. In: Proceedings of the 2022 International Confer-
ence on Robotics and Automation, pp. 5389â€“5395. IEEE, Piscataway, NJ (2022). 
doi:10.1109/ICRA46639.2022.9812415 
 Active Inference for an Intelligent Agent 23 
13. Pezzato, C., Ferrari, R., HernÃ¡ndez Corbato, C.: A novel adaptive controller for robot ma-
nipulators based on active inference. IEEE Robotics and Automation Letters 5(2), 2973â€“
2980 (2020). doi:10.1109/LRA.2020.2974451 
14. Meo, C., Lanillos, P.: Multimodal VAE active inference controller. In: Proceedings of the 
2021 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2693â€“
2699. IEEE, Piscataway, NJ (2021). doi:10.1109/IROS51168.2021.9636394 
15. Meo, C., Franzese, G., Pezzato, C., Spahn, M., Lanillos, P.: Adaptation through prediction: 
multisensory active inference torque control. IEEE Transactions on Cognitive and Develop-
mental Systems 15(1), 32â€“41 (2023). doi:10.1109/TCDS.2022.3156664 
16. Baioumy, M., Pezzato, C., Ferrari, R., Corbato, C. H., Hawes, N.: Fault-tolerant control of 
robot manipulators with sensory faults using unbiased active inference. In: Proceedings of 
the 2021 European Control Conference, pp. 1119â€“1125. IEEE, Piscataway, NJ (2021). 
doi:10.23919/ECC54610.2021.9654913 
17. Ã‡atal, O., Verbelen, T., Van de Maele, T., Dhoedt, B., Safron, A.: Robot navigation as hier-
archical active inference. Neural Networks 142, 192â€“204 (2021). doi:10.1016/j.neunet.2021
.05.010 
18. Scholz, F., Gumbsch, C., Otte, S., Butz, M. V.: Inference of affordances and active motor 
control in simulated agents. Frontiers in Neurorobotics 16, 881673 (2022). doi:10.3389/
fnbot.2022.881673 
19. Kawahara, D., Ozeki, S ., Mizuuchi, I.: A curiosity algorithm for robots based on the free 
energy principle. In: Proceedings of the 2022 IEEE/SICE International Symposium on Sys-
tem Integration, pp. 53â€“59. IEEE, Pisc ataway, NJ (2022). doi:10.1109/SII52469.2022
.9708819 
20. Katahira, K., Kunisato, Y., Okimura, T., Yamashita, Y.: Retrospective surprise: A compu-
tational component for active inference.  Journal of Mathematical Psychology 96, 102347 
(2020). doi:10.1016/j.jmp.2020.102347 
21. Wakayama, S., Ahmed, N.: Active Inference for autonomous decision-making with contex-
tual multi-armed bandits. In: Proceedings of the 2023 IEEE International Conference on 
Robotics and Automation, pp. 7916â€“7922 (2023). doi: 10.1109/ICRA48891.2023.10160593 
22. Wakayama, S., Candela, A., Hayne, P., Ahmed,  N.: Active inference for bandit-based au-
tonomous robotic exploration with dynamic pr eferences. IEEE Transactions on Robotics 
41:3841â€“3851 (2025). doi:10.1109/TRO.2025.3577041 
23. Levchuk, G., Pattipati, K., Fouse, A., Serfaty , D.: Application of free energy minimization 
to the design of adaptive multi-agent teams. In: Proceedings SPIE 10206, Disruptive Tech-
nologies in Sensors and Sensor Systems, 102060E (2017). doi:10.1117/12.2263542 
24. Levchuk, G., Fouse, A., Pattipati, K., Serfaty, D., McCormack, R.: Active learning and 
structure adaptation in teams of heterogene ous agents. In: Proceedings SPIE 10653, Next-
Generation Analyst VI, 1065305 (2018). doi:10.1117/12.2305875 
25. Levchuk, G., Pattipati, K., Serfaty, D., Fouse, A., McCormack, R.: Active inference in mul-
tiagent systems: Context-driven collaboration and decentralized purpose-driven team adap-
tation. In: Artificial Intelligence for the Internet of Everything, pp. 67â€“85. Academic Press, 
Cambridge, MA (2019). doi:10.1016/B978-0-12-817636-8.00004-1 
26. 
Pezzato, C., Corbato, C. H., Bonhof, S., Wisse, M.: Active inference and behavior trees for 
reactive action planning and execution in robotics. IEEE Transa ctions on Robotics 39(2), 
1050â€“1069 (2023). doi:10.1109/TRO.2022.3226144 
27. Baltieri, M., Buckley, C. L.: Nonmodular architectures of cognitive systems based on active 
inference. In: Proceedings of the 2019 Interna tional Joint Conference on Neural Networks, 
pp. 1â€“8 (2019). doi:10.1109/IJCNN.2019.8852048 
24  J. Schubert, F. Kamrani, and T. Gustavi 
28. Nozari, S., Krayani, A., Marin, P., Marcenaro, L., Gomez, D. M., Regazzoni, C.: Exploring 
action-oriented models via active inference for autonomous vehicles. EURASIP Journal on 
Advances in Signal Processing 2024, 92 (2024). doi:10.1186/s13634-024-01173-9 
29. Sawada, H., Ohata, W., Tani, J.: Human-robot kinaesthetic interactions based on the free-
energy principle. IEEE Transactions on Systems, Man, and Cybernetics: Systems 55(1), 
366â€“379 (2025). doi:10.1109/TSMC.2024.3481251 
30. Matsumura, T., Esaki, K., Yang, S., Yoshimura, C., Mizuno, H.: Active inference with em-
pathy mechanism for socially behaved artificial agents in diverse situations. Artificial Life 
30(2), 277â€“297 (2024). doi:10.1162/artl_a_00416 
31. Esaki, K., Matsumura, T., Minusa, S., Shao, Y., Yoshimura, C., Mizuno, H., Dynamical 
perception-action loop formation with developmental embodiment for hierarchical active 
inference. In: Buckley, C. L., et al. Active Inference. IWAI 2023. Communications in Com-
puter and Information Science 1915, pp. 14â€“28. Springer, Cham (2023). doi:10.1007/978-
3-031-47958-8_2 
32. Smets, P., Kennes, R.: The transferable belief model. Artificial Intelligence 66(2), 191â€“234 
(1994). doi:10.1016/0004-3702(94)90026-4 
33. Kullback, S., Leibler, R. A.: On information and sufficiency. The Annals of Mathematical 
Statistics 22(1), 79â€“86 (1951). doi:10.1214/aoms/1177729694 