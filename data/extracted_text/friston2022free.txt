Graphical Abstract
The free energy principle made simpler but not too simple
KarlFriston, LancelotDaCosta, NoorSajid, ConorHeins, KaiUeltzhöffer, Grigorios
A. Pavliotis, Thomas Parr
3202
yaM
03
]hcem-tats.tam-dnoc[
3v78360.1022:viXra
Highlights
The free energy principle made simpler but not too simple
KarlFriston, LancelotDaCosta, NoorSajid, ConorHeins, KaiUeltzhöffer, Grigorios
A. Pavliotis, Thomas Parr
• This paper provides a concise description of the free energy principle, starting
from a formulation of random dynamical systems in terms of a Langevin equa-
tion and ending with a Bayesian mechanics that can be read as a physics of
sentience.
• Teleologically, the free energy principle offers a normative account of self-
organisation in terms of optimal Bayesian design and decision-making, in the
sense of maximising marginal likelihood or Bayesian model evidence.
• In summary, starting from a description of the world in terms of random dy-
namical systems, we end up with a description of self-organisation as sentient
behaviour that can be interpreted as self-evidencing; namely, self-assembly,
autopoiesis or active inference.
The free energy principle made simpler but not too simple
Karl Fristona, Lancelot Da Costaa,b,∗, Noor Sajida, Conor Heinsc,d,e, Kai
Ueltzhöffera,f, Grigorios A. Pavliotisb, Thomas Parra
aWellcome Centre for Human Neuroimaging, University College London, London, WC1N 3AR,
United Kingdom
bDepartment of Mathematics, Imperial College London, London, SW7 2AZ, United Kingdom
cDepartment of Collective Behaviour, Max Planck Institute of Animal Behavior, Konstanz
D-78457, Germany
dCentre for the Advanced Study of Collective Behaviour, University of Konstanz, D-78457,
Germany
eDepartment of Biology, University of Konstanz, D-78457, Germany
fDepartment of General Psychiatry, Centre of Psychosocial Medicine, Heidelberg University,
Voßstraße 2, D-69115 Heidelberg, Germany
Abstract
This paper provides a concise description of the free energy principle, starting from a
formulation of random dynamical systems in terms of a Langevin equation and end-
ing with a Bayesian mechanics that can be read as a physics of sentience. It rehearses
the key steps using standard results from statistical physics. These steps entail (i) es-
tablishingaparticularpartitionofstatesbaseduponconditionalindependenciesthat
inherit from sparsely coupled dynamics, (ii) unpacking the implications of this parti-
tion in terms of Bayesian inference and (iii) describing the paths of particular states
withavariationalprincipleofleastaction. Teleologically, thefreeenergyprincipleof-
fers a normative account of self-organisation in terms of optimal Bayesian design and
decision-making, in the sense of maximising marginal likelihood or Bayesian model
evidence. In summary, starting from a description of the world in terms of random
dynamical systems, we end up with a description of self-organisation as sentient be-
haviour that can be interpreted as self-evidencing; namely, self-assembly, autopoiesis
or active inference.
Keywords: self-organisation, nonequilibrium, variational inference, Bayesian,
Markov blanket
∗Corresponding author
Email address: l.da-costa@imperial.ac.uk (Lancelot Da Costa)
Preprint submitted to XXX May 31, 2023
1. Introduction
It is said that the free energy principle is difficult to understand. This is ironic on
three counts. First, the free energy principle (FEP) is so simple that it is (almost)
tautological. Indeed, philosophical accounts compare its explanandum to a desert
landscape, in the sense of Quine [1]. Second, a tenet of the FEP is that everything
must provide an accurate account of things that is as simple as possible—including
itself. Finally, the FEP rests on straightforward results from statistical physics. This
review tries to present the free energy principle as simply as possible but without
sacrificingtoomuchtechnicaldetail. Itstepsthroughtheformalargumentsthatlead
from a description of the world as a random dynamical system [2, 3] to a description
of self-organisation in terms of active inference and self-evidencing [4]. The evidence
in question is Bayesian model evidence, which speaks to the Bayesian mechanics on
offer [5]. These mechanics have the same starting point as quantum, statistical and
classical mechanics. The only difference is that careful attention is paid to the way
that the internal states of something couple to its external states.
Tomakethefollowingaccountaccessible,weuseaconversationalstyle,explaining
the meaning of key mathematical expressions intuitively. Accordingly, simplifying
notation and assumptions are used to foreground the basic ideas. Before starting, it
might help to clarify what the free energy principle is—and why it is useful. Many
theories in the biological sciences are answers to the question: “what must things do,
in order to exist?” The FEP turns this question on its head and asks: “if things exist,
what must they do?” More formally, if we can define what it means to be something,
can we identify the physics or dynamics that a thing must possess? To answer this
question, the FEP calls on some mathematical truisms that follow from each other.
Much like Hamilton’s principle of least action1, it is not a falsifiable theory about
the way ‘things’ behave—it is a general description of ‘things’ that are defined in a
particular way. As such, the FEP is not falsifiable as a mathematical statement, but
it may as well be falsifiable to the extent that its postulates refer to a specific class
of empirical phenomena that the principle aims to describe.
Is such a description useful? In itself, the answer is probably no—in the sense
that the principle of least action does not tell you how to throw a ball. However,
the principle of least action furnishes everything we need to know to simulate the
trajectory of a ball in a particular instance. In the same sense, the FEP allows one
to simulate and predict the sentient behaviour of a particle, person, artefact or agent
1Perhaps a better analogy would be Noether’s theorem (Beren Millidge – personal communica-
tion) [6].
2
(i.e., some ‘thing’). This allows one to build sentient artefacts or use simulations as
observation models of particles (or people). These simulations rest upon specifying
a generative model that is apt to describe the behaviour of the particle (or person)
at hand. At this point, committing to a specific generative model can be taken as a
commitment to a specific—and falsifiable—theory. Later, we will see some examples
of these simulations.
TheremainingsectionsdescribetheFEP.Eachsectionfocusesonanequation—or
set of equations—used in subsequent sections. The ensuing narrative is meant to be
concise, taking us from the beginning to the end as succinctly as possible. To avoid
disrupting the narrative, we use footnotes to address questions that are commonly
asked at each step. We also use figure legends to supplement the narrative with
examples from neurobiology. Most of the following can be found in the literature [5,
7, 8]; however, there are a few simplifications that replace earlier accounts.
2. Systems, states and fluctuations
We start by describing the world with a stochastic differential equation [9]. So
why start here? The principal reason is that we want a description that is consistent
with physics. This follows because things like the Schrödinger equation in quantum
mechanics, fluctuation theorems in statistical mechanics and the Lagrangian formu-
lation of classical mechanics can all be derived from this starting point [10]. In short,
if one wants a physics of sentience, this is the place to start.
We are interested in systems that have characteristic states. Technically, this
means the system has a pullback attractor; namely, a set of states a system will
come to occupy from any initial state [2, 11]. Such systems can be described with
stochastic differential equations, such as the Langevin equation describing the rate
of change of some states x(τ), in terms of their flow f(x), and random fluctuations
ω(τ). The fluctuations are usually assumed to be a normally distributed (white
noise) process, with a covariance of 2Γ:
x˙(τ) = f(x)+ω(τ)
p(ω | x) = N(ω;0,2Γ) ⇒ p(x˙ | x) = N(x˙;f,2Γ) (1)
p(x) =?
The dot notation denotes a derivative with respect to time2. This means that time
and causality are baked into everything that follows, in the sense that states cause
2Question: why is the flow in (1) not a function of time? Many treatments of stochastic
thermodynamics allow for time-dependent flows when coupling one system (e.g., an idealised gas)
3
their motion. The Langevin equation is itself an approximation to a simpler mapping
from some variables to changes in those variables with time. This follows from the
separation into states and random fluctuations implicit in (1), where states change
slowly in relation to fast fluctuations. This (adiabatic) approximation is ubiquitous
in physics [13, 14, 15]. In brief, it means we can ignore temporal correlations in
the fast fluctuations and assume—by the central limit theorem—that they have a
Gaussian distribution. This equips the fluctuations with a probability density, which
means we know their statistical behaviour but not their trajectory or path, which
itself is a random variable [2, 3, 9].
The next step, shared by all physics, is to ask whether anything can be said about
the probability density over the states—the ‘?’ in (1). A lot can be said about this
probability density, which can be expressed in two complementary ways; namely, as
density dynamics using the Fokker-Planck equation (a.k.a. the forward Kolmogorov
equation) or in terms of the probability of a path through state-space using the
path-integral formulation. The Fokker-Planck equation describes the change in the
density due to random fluctuations and the flow of states through state-space [16, 9]:
p˙(x,τ) = ∇·(Γ∇−f(x))p(x,τ) (2)
TheFokker-Planckequationdescribesourstochasticprocessintermsofdetermin-
istic density dynamics—instead of specific realisations—where the density in ques-
tion is over states x(τ) = x . Conversely, the path-integral formulation considers the
τ
probability of a trajectory or path x[τ] ≜ [x(t) : 0 ≤ t ≤ τ] in terms of its action A
(omitting additive constants here and throughout)3:
A(x[τ]) = −lnp(x[τ] | x )
0
τ (cid:90) τ
= ln|(4π)nΓ|+ dtL(x,x˙)
(3)
2
0
(cid:20) (cid:21)
1 1
L(x,x˙) = (x˙ −f)· (x˙ −f)+∇·f
2 2Γ
to another (e.g., a heat reservoir), where it is assumed that the other system changes very slowly,
e.g., [12, 10]. However, the ambition of the FEP is to describe this coupling under a partition of
states. In this setting, separation of temporal scales is an emergent property, where (1) holds at
anygiventemporalscale. See[5]foratreatmentusingtheapparatusoftherenormalisationgroup.
3Question: where does the divergence in the third equality come from? This term arises from
the implicit use of Stratonovich path integrals [10]. Note that we have assumed that the amplitude
ofrandomfluctuationsisstate—andthereforepath—independentin(1),whichmeanswecanplace
it outside the integral in the second equality.
4
Both the Fokker-Planck and path-integral formulations inherit their functional
form from assumptions about the statistics of random fluctuations in (1). For ex-
ample, the most likely path—or path of least action—is the path taken when the
fluctuations take their most likely value of zero. This means that variations away
fromthispathalwaysincreasetheaction. Thisisexpressedmathematicallybysaying
that its variation is zero when the action is minimised.4
x[τ] = argminA(x[τ])
x[τ]
(4)
⇔ δ A(x[τ]) = 0
x
⇔ x˙(τ) = f(x)
In short, the motion on the path of least action is just the flow without random
fluctuations. Paths of least action will figure prominently below; especially, when
considering systems that behave in a precise or predictable way. We will denote the
most likely states and paths with a bold typeface.
Although equivalent, the Fokker-Planck and path-integral formalisms provide
complementary perspectives on dynamics. The former deals with time-dependent
probabilitydensitiesoverstates, whilethelatterconsiderstime-independentdensities
over paths. The density over n states at any particular time is the time-marginal of
the density over trajectories. These probabilities can be conveniently quantified in
terms of their negative logarithms (or potentials) leading to surprisal and action,
respectively (omitting the divergence of the flow in the last line for simplicity):
ℑ(x,τ) ≜ −lnp(x,τ)
A(x[τ]) ≜ −lnp(x[τ] | x )
0
H[p(x,τ)] = E[ℑ(x,τ)]
H[p(x[τ] | x )] = E[A(x[τ])]
0
τ (cid:90) τ 1 (cid:20) 1 (cid:21) τ
= ln[(4π)n|Γ|]+ dt E ω(t)· ω(t) = ln[(4πe)n|Γ|]
p(ω)
2 2 2Γ 2
0
(5)
4OmittingthecontributionofthedivergencetermintheLagrangiantoobtaintheexpressionfor
the path of least action for simplicity, cf. [17]. Taking this simplification at face value means that
we are either: 1) considering a description on a short time-scale as the flow can be approximated
by a linear function with impunity (e.g., linear response theory, see [9]); or 2) we are considering
the limit where random fluctuations have vanishingly small amplitude (e.g., precise particles, see
Sections 7 and 8).
5
The second set of equalities shows that the uncertainty (or entropy) about states
and their paths is the expected surprisal and action, respectively. Perhaps counterin-
tuitively, the entropy of paths is easier to specify than the entropy of states. This fol-
lows because the only source of uncertainty about paths—given an initial state—are
the random fluctuations [10, 9], whose probability density does not change with time.
The last pair of equalities in (5) show that the amplitude of random fluctuations de-
termines the entropy of paths. Intuitively, if the fluctuations are large, then many
distinct paths become equally plausible, and the entropy of paths increases5.
3. Solutions, steady-states and nonequilibria
So far, we have equations that describe the relationship between the dynamics
of a system and probability densities over fluctuations, states and their paths. This
is sufficient to elaborate most physics. For example, we can use the Fokker-Planck
or path-integral formalism to derive quantum mechanics, where the Fokker-Planck
equation becomes the Schrödinger wave equation [18]. We could focus on systems
thatcomprisestatisticalensemblesofsimilarstatestoderivestochasticandstatistical
mechanics in terms of fluctuation theorems [10]. Finally, we could consider large
systems—in which the fluctuations are averaged away—to derive classical mechanics
suchaselectromagnetismand—withasuitablechoice ofpotentialfunctions—general
relativity [19, 20]. All of these mechanics require some boundary conditions: for
example, a Schrödinger potential in quantum mechanics, a heat bath or reservoir
in statistical mechanics and a classical potential for Lagrangian mechanics. At this
point, the FEP steps back and asks, where do these boundary conditions come from?
Indeed, this was implicit in Schrodinger’s question:
“How can the events in space and time which take place within the spatial boundary
of a living organism be accounted for by physics and chemistry?” [21].
We read a boundary in a statistical sense as a Markov boundary [22]6. Why?
Because the only thing we have at hand is a probabilistic description of the system.
And the only way to separate the states of something from its boundary states is in
terms of probabilistic independencies—in this instance, conditional independencies7.
5From a thermodynamic perspective, uncertainty about paths increases with temperature. For
example, the Einstein-Smoluchowski relation relates the amplitude of random fluctuations to a
mobility coefficient times the temperature Γ=µ k T.
m B
6A Markov boundary is a subset of states of the system that renders the states of a ‘thing’ or
particle conditionally independent from all other states [23].
7Noting that if two subsets of states were independent, as opposed to being conditionally inde-
pendent, we would be describing two separate systems.
6
This means we need to identify a partition of states that assigns a subset to a
‘thing’ or particle and another subset to the boundary that separates the thing from
some ‘thing’ else. In short, one has to define ‘thingness’ in terms of conditional
independencies.
However, if things are defined in terms of conditional independencies and condi-
tional independencies are attributes of a probability density, where does the density
come from? The Fokker-Planck equation shows that the density over states depends
upon time, even if the flow does not. This means that if we predicate ‘thingness’ on
a probability density, it may only exist for a vanishingly small amount of time. This
simple observation compels us to consider probability densities that do not change
with time, namely: (i) steady-state solutions to the Fokker-Planck equation or (ii)
the density over paths. We will start with the (slightly more delicate) treatment of
steady-state solutions and then show that the (slightly more straightforward) treat-
ment of densities over paths leads to the same notion of ‘thingness’.
The existence of things over a particular timescale implies the density in (2) does
notchangeoverthattimescale. Thisiswhatismeantbyasteady-statesolutiontothe
Fokker-Planck equation. The ensuing density is known as a steady-state density and,
in random dynamical systems, implies the existence of a pullback attractor [2, 3].
The notion of an attractor is helpful here, in the sense that it comprises a set of
characteristic states, to which the system is attracted over time8. In short, to talk
about ‘things’, we are implicitly talking about a partition of states in a random
dynamical system that has an attracting set—i.e., a steady-state solution to the
Fokker-Planck equation. In short, we consider systems that self-organise towards a
steady-state density9. This solution is also known as a nonequilibrium steady-state
(NESS) density, where the ‘nonequilibrium’ aspect rests upon solenoidal flow, as we
will see next.
The existence of a solution to the Fokker-Planck equation—i.e., the existence of
something—means that we can express the flow of states in terms of the steady-
state density (or corresponding surprisal) using a generalisation of the Helmholtz
decomposition. This decomposes the flow into conservative (rotational, divergence-
free)anddissipative(irrotational, curl-free)components—withrespecttothesteady-
8More precisely, the time-dependent solutions to the Fokker-Planck equation will tend towards
the stationary solution, or steady-state. In other words, the steady-state density becomes a point
attractor in the space of probability densities.
9At this point, the formalism applies equally to steady-states with a high or low entropy, as we
have not committed to a particular form of the steady-state density. Later, we will specialise to
steady-stateswithalowentropytocharacterisethesortofself-organisationthatdescribesbiological
systems, e.g., swarming or flocking [14, 24]
7
state density—referred to as solenoidal and gradient flows, respectively [25, 26, 27,
28, 29, 30, 9]:
p˙(x) = 0 ⇔ f(x) = Ω(x)∇ℑ(x)−Λ(x) = Q(x)∇ℑ(x)− Γ∇ℑ(x) −Λ(x)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Solenoidalflow Gradientflow (6)
(cid:88) ∂Ω (cid:88) ∂Q
ℑ(x) = −lnp(x), Q = −QT, Λ ≜ ij = ij .
i
∂x ∂x
j j
j j
This can be understood intuitively as a decomposition of the flow into two parts.
The first (conservative) part of the flow is a solenoidal circulation on the isocontours
of the steady-state density (or surprisal). This component breaks detailed balance
and renders the steady-state density a nonequilibrium steady-state density [31, 32].
The second (dissipative) part performs a (natural) gradient descent on the steady-
state surprisal and depends upon the amplitude of random fluctuations [33, 34]. The
final term, Λ, can be regarded as a correction term, which is neither curl-free nor
divergence-free, andwhichensuresthattheprobabilitydensityremainsconstantover
time [30].
3.1. Summary
We now have a probabilistic description of a system in terms of a (NESS) density
that admits conditional independencies among states. These conditional indepen-
dencies are necessary to separate the states of things from their boundaries. In the
next step, we will see how conditional independencies inherit from sparse coupling
among states—and how they are used to establish a particular partition of states.
4. Particles, partitions and things
In associating some (stochastic differential) equations of motion with a unique
(NESS) density, we have a somewhat special setup, in which the influences entailed
by the equations of motion place constraints on the conditional independencies of the
NESS density. These conditional independencies can be used to identify a particular
partition of states into external, sensory, active and internal states as summarised
below. This is an important move because it separates the states of a particle (i.e.,
internal states and their sensory and active states) from the remaining (i.e., exter-
nal) states. However, to do this we have to establish how the causal dynamics in
(1) underwrite conditional independencies. This can be done simply by using the
8
curvature (Hessian) of surprisal as follows:
(x ⊥ x ) | b ⇔ p(x) = p(x | b)p(x | b)p(b)
u v u v
∂2ℑ
⇔ ℑ(x) = ℑ(x | b)+ℑ(x | b)+ℑ(b) ⇔ = H = H = 0.
u v uv vu
∂x ∂x
u v
(7)
This says that if the u-th state is conditionally independent of the v-th state, given
the remaining states b, then the corresponding element of the curvature—or Hessian
matrix—of surprisal must be zero. Conversely, a zero entry in the Hessian implies
conditional independence. In sum, any two states are conditionally independent if,
and only if, the change of surprisal with one state does not depend on the other.
We can now use the Helmholtz decomposition (6) to express the Jacobian—i.e.,
the (linear) coupling—of the flow in terms of the Hessian—that entails conditional
independencies (with a slight abuse of the dot product notation):
f(x) = Ω∇ℑ−Λ
⇒ J = ΩH+∇Ω·∇ℑ−∇Λ
(8)
∂f (cid:88) (cid:88) ∂Ω ∂ℑ (cid:88) ∂2Ω
u ui ui
⇒ J = = Ω H + − .
uv ui iv
∂x ∂x ∂x ∂x ∂x
v v i i v
i i i
We can now define sparse coupling as a solution to this equation, in which all the
terms are identically zero10:

Q H
ui iv 
Γ H = 0 : ∀i ⇒ J(x) = 0. (9)
u uv uv
∂Ω /∂x 
ui v
Sparse coupling means that the Jacobian coupling states u and v is zero, i.e., an
absence of coupling from one state to another. This definition precludes solenoidal
coupling with u that depends on v. Because H(x) and Γ are positive definite,
vv u
sparsecouplingrequiresassociatedelementsofthesolenoidaloperatorandHessianto
vanish at every point in state-space, which in turn, implies conditional independence:
Q H = 0 ⇒ Q = −Q = 0
uv vv uv vu (10)
Γ H = 0 ⇒ H = H = 0 ⇔ (x ⊥ x ) | b.
u uv uv vu u v
In short, sparse coupling means that any two states are conditionally independent
if one state does not influence the other. This is an important observation; namely,
10This implicitly precludes edge cases, in which some non-zero terms cancel.
9
that sparse coupling implies a NESS density with conditional independencies. In
turn, this means any dynamical influence graph with absent or directed edges admits
a Markov blanket (the states b above). These independencies can now be used to
build a particular partition as follows:
• The Markov boundary a ⊂ x of a set of internal states µ ⊂ x is the minimal
set of states for which there exists a nonzero Hessian submatrix: H ̸= 0. In
aµ
other words, the internal states are independent of the remaining states, when
conditionedupontheirMarkovboundary,calledactive states. Thecombination
of active and internal states will be referred to as autonomous states: α =
(a,µ).
• The Markov boundary s ⊂ x of autonomous states is the minimal set of states
for which there exists a nonzero Hessian submatrix: H ̸= 0. In other words,
sα
the autonomous states are independent of the remaining states, when con-
ditioned upon their Markov boundary, called sensory states. The combina-
tion of active and sensory (i.e., boundary) states constitute blanket states:
b = (s,a). The internal and blanket states will be referred to as particular
states: π = (s,α) = (b,µ).
• The remaining states constitute external states: x = (η,π).
The names of active and sensory (i.e., blanket) states inherit from the literature,
where they are often associated with biotic systems that act on—and sense—their
external milieu11. In this setting, one can regard external states as influencing inter-
nal states via sensory states (directly or through active states). And internal states
influence external states via active states (directly or through sensory states12). We
will see later how this implies a synchronisation between internal and external states,
in the sense that internal states can be seen as actively inferring external states [7, 8].
Theensuingconditionalindependenciesimpliedbyaparticularpartitioncanbesum-
11Question: why does a particular partition comprises four sets of states? In other words, why
doesaparticularpartitionconsidertwoMarkovboundaries;namely,sensoryandactivestates? The
reason is that this is the minimal partition that allows for directed coupling with blanket states.
For example, sensory states can influence internal states—and active states can influence external
states—withoutdestroyingtheconditionalindependenciesoftheparticularpartition(thesedirected
influences are illustrated in the upper panel of Figure 1 as dotted arrows).
12Question: does this mean that I can act on my world through my sense organs? Yes: much
of biotic action is mediated by (active) motile cytoskeletal filaments, muscles and secretory organs
that lie beneath (sensory) epithelia, such as receptors on the skin or a cell surface.
10
marised as follows:
J = 0 ⇒ H = 0 ⇔ (µ ⊥ η) | b
µη µη
J = 0 ⇒ H = 0 ⇔ (a ⊥ η) | s,µ (11)
aη aη
J = 0 ⇒ H = 0 ⇔ (s ⊥ µ) | a,η
sµ sµ
A normal form for the flow and Jacobian of a particular partition—with sparse
coupling—can be expressed as follows, where α = (a,µ) and β = (η,s):
f(x) = Ω∇ℑ−Λ
    
f (η,b) Q −Γ Q ∇ ℑ(η | b)
η ηη η ηs η
  f s (η,b)   =   −QT ηs Q ss −Γ s     ∇ s ℑ(b | η)  −Λ
 f a (b,µ)   Q aa −Γ a Q aµ  ∇ a ℑ(b | µ) 
f (b,µ) −QT Q −Γ ∇ ℑ(µ | b)
µ aµ µµ µ µ
J(x) = ΩH+∇Ω·∇ℑ−∇Λ
    
J J J Q −Γ Q H H
ηηη ηs ηa ηη η ηs ηη ηs
  J sη J ss J sa   =   −QT ηs Q ss −Γ s     HT ηs H ss H sa  
 J as J aa J aµ   Q aa −Γ a Q aµ  HT sa H aa H aµ 
J J J −QT Q −Γ HT H
µs µa µµ aµ µµ µ aµ µµ
+∇Ω·∇ℑ−∇Λ
∇ Ω = 0, ∇ Ω = 0, ∇ Λ = 0, ∇ Λ = 0
η αα µ ββ η α µ β
(12)
This normal form means that particular partitions can be defined in terms of
sparse coupling. Perhaps the simplest definition—that guarantees a Markov blan-
ket13—is as follows: external states only influence sensory states and internal states
only influence active states. This means that sensory states are not influenced by
internal states and active states are not influenced by external states,
   
η˙(τ) f (η,s,a)+ω (τ)
η η
  s˙(τ)   =   f s (η,s,a)+ω s (τ)   (13)
 a˙(τ)   f a (s,a,µ)+ω a (τ) 
µ˙(τ) f (s,a,µ)+ω (τ)
µ µ
and the noise processes ω (τ),i ∈ {η,s,a,µ} are independent. Under this sparse
i
coupling, it is simple to show that not only are internal and external states con-
13In the absence of solenoidal coupling between autonomous and non-autonomous states, and
constraints on the partial derivatives of the solenoidal coupling in (12); i.e., solenoidal coupling
among autonomous states does not depend upon external states. Similarly, for non-autonomous
and internal states.
11
ditionally independent, but their paths are conditionally independent, given initial
states, using the path integral formulation.
The uncertainty (i.e., entropy) over paths derives from random fluctuations. This
means that if we knew all the influences on the flow at every point in time, we can
evaluate the entropy of external and internal paths from (5):
τ
H[p(η[τ] | b[τ],x )] = ln[(4πe)nη |Γ |]
0 η
2
τ
H[p(µ[τ] | b[τ],x )] = ln[(4πe)nµ|Γ |]
0 µ
2
(14)
⇒
H[p(η[τ] | b[τ],x )] = H[p(η[τ] | µ[τ],b[τ],x )] ⇒ (µ[τ] ⊥ η[τ]) | b[τ],x
0 0 0
H[p(µ[τ] | b[τ],x )] = H[p(µ[τ] | η[τ],b[τ],x )] ⇒ (µ[τ] ⊥ η[τ]) | b[τ],x
0 0 0
The final equalities say that the uncertainty about external (resp., internal) paths
does not change when we know the internal (resp., external) path because external
(resp., internal)statesdonotinfluenceinternal(resp., external)flow. Thismeansthe
external and internal paths do not share any mutual information and are therefore
independent when conditioned on blanket paths (and initial states). From (11), the
initial external and internal states are themselves independent, when conditioned on
blanket states.
Note that the conditional independence of paths inherits directly from the sparse
coupling, without any reference to the NESS density or Helmholtz decomposition.
This can be seen clearly by replacing the partial derivatives in (7) with functional
derivativesandnoting,from(12),thattherearenoflowsthatdependonbothinternal
and external states:
∂2f ∂2L ∂2L ∂2L ∂2L
= 0 ⇒ = = = = 0
∂η∂µ ∂η∂µ ∂η∂µ˙ ∂η˙∂µ ∂η˙∂µ˙
δ2A(x[τ])
⇒ = 0 ⇔ (µ[τ] ⊥ η[τ]) | b[τ],x
0
δη[t]δµ[t]
(15)
δA(x[τ]) (cid:90) (cid:18) ∂L δµ[t′] ∂L d δµ[t′] (cid:19)
= dt′ + +...
δµ[t] ∂µ[t′] δµ[t] ∂µ˙ [t′]dt′ δµ[t]
δ2A(x[τ]) (cid:90) (cid:18) δη[t′′] ∂2L δµ[t′] δη[t′′] ∂2L d δµ[t′] (cid:19)
= dt′dt′′ + +...
δη[t]δµ[t] δη[t] ∂η∂µ δµ[t] δη[t] ∂η∂µ˙ dt′ δµ[t]
These expressions mean that the probability of an internal path, given a blanket
path (and initial states), does not depend on the external path and vice versa.
12
Figure1: Markov blankets. Thisinfluencediagramillustratesaparticularpartitionofstatesinto
internalstates(blue)andexternalstates(cyan)thatareseparatedbyaMarkovblanketcomprising
sensory(green)andactivestates(red). Theedgesinthisgraphrepresenttheinfluenceofonestate
on another, as opposed to conditional dependencies. The diagram shows this partition as it would
be applied to a single-cell organism, where internal states are associated with intracellular states,
thesensorystatesbecomethesurfacestatesorcellmembraneoverlyingactivestates(e.g.,theactin
filaments of the cytoskeleton). The dotted lines indicate allowable directed influences from sensory
(resp., active) to internal (resp., external) states. Particular states constitute a particle; namely,
autonomous and sensory states—or blanket and internal states.
4.1. Summary
In summary, the internal dynamics (i.e., paths) of some ‘thing’ are conditionally
independent of external paths if, and only if, the flow of internal states does not
depend on external states and vice versa (given initial states). We take this as a
necessary and sufficient condition for something to exist, in the sense that it can be
distinguished from everything else. When the initial states are sampled from the
NESS density, the internal states are conditionally independent of external states
(given blanket states), under certain constraints on solenoidal flow. Figure 1 illus-
trates the ensuing particular partition. Note that the edges in this graph represent
the influence of one state on another, as opposed to conditional dependencies. This
is important because directed influences admit conditional independence. These con-
ditional independencies are manifest as zero entries in the Hessian matrices, which
inherit from the sparse, directed coupling of the dynamics.
5. From self-organisation to self-evidencing
Equipped with a particular partition, we can now talk about things in terms
of their internal states and Markov boundary; namely autonomous states. And we
13
can talk about autonomous states and their Markov boundary; namely, particular
states—the states of a particle. The next step is to characterise the flow of the
autonomous states (of a particle, plant or person) in relation to external states. In
other words, we consider the nature of the coupling between the outside and inside
of a particle, across its Markov blanket. It is at this point that we move towards
a (Bayesian) mechanics that is the special provenance of systems with particular
partitions.
The existence of a particular partition means that—given sensory states—one
can stipulatively define the conditional density over external states as being param-
eterised by the most likely internal state [7]14. We will call this a variational density
parameterised by the internal mode µ(τ)15:
q (η) ≜ p(η | s)
µ
α(τ) = (a(τ),µ(τ))
α(τ) = argminℑ(α(τ) | s(τ)) ⇒ (16)
α
α[τ] = argminA(α[τ] | s[τ]) ⇒
α
α˙(τ) = f (s,α)
α
As with the paths of least action, we will use bold typeface to denote a mode or
most likely state, given all the states necessary to specify its likelihood. For au-
tonomous states, we only need the sensory states, because the autonomous states
are conditionally independent of external states.
Inducing the variational density is an important move. It means that for every
sensory state there is a corresponding active mode and an internal mode (or an
autonomous mode in the joint space of active and internal states). The active a(τ),
internalµ(τ)andautonomousα(τ)modesevolveonactive,internal andautonomous
14In other words, the internal mode supplies the sufficient statistics of the conditional density
over external states.
15Question: what if the conditional densities are not well-behaved, e.g., what if there are no
uniquemodes? Theansweristhatwell-behaveddensitiesaregenerallyguaranteedwhenincreasing
the dimensionality of state-spaces using generalised coordinates of motion [35, 36, 37]. In other
words, instead of just dealing with states, we consider states and their generalised motion to arbi-
trarily high order. We will see examples of this later.
14
manifolds16, respectively, whose dimensionality is the same as the sensory states17.
We will see later that these manifolds play the role of centre manifolds; namely,
manifolds on which dynamics do not diverge (or converge) exponentially fast [13].
Crucially, the internal manifold is also a statistical manifold because its states
are sufficient statistics for the variational density. In turn, this means that it is
equipped with a metric and implicit information geometry [39, 40, 41]. Indeed, the
Fisher information metric tensor, which measures changes in the Kullback-Leibler
(KL) divergence resulting from infinitesimal changes in the internal mode, is a Rie-
mannian metric that yields an information distance [42, Appendix B]. This means we
can interpret dynamics on the internal manifold as updating Bayesian beliefs about
external states. This interpretation can be unpacked in terms of Bayesian inference
as follows.
Equation (16) means that for every sensory state there is a conditional density
over external states and a corresponding internal mode with the smallest surprisal.
This mode specifies the variational density, where—by definition—the KL divergence
between the variational density and the conditional density over external states is
zero18. This means we can express the autonomous flow as a gradient flow on a free
energy functional of the variational density19. From (12)
   
f (x) ∇ ℑ(x)
η η
  f s (x)   = Ω   ∇ s ℑ(x)  −Λ, (17)
 f a (π)   ∇ a F(π) 
f (π) ∇ F(π)
µ µ
where the free energy in question is (an upper bound on) the surprisal of particular
16A manifold is a topological (state-) space where each state has a neighbourhood that is home-
omorphic to a portion of an Euclidean space of the same dimension [38]. Intuitively, it is a curved
space,suchasasmoothsurface,inapossiblylargebutfinitenumberofdimensions. Inthisinstance,
the states are conditional modes.
17Thedimensionalityoftheactive,internalandautonomousmanifoldscorrespondstothenumber
of sensory states. This means that both the number of active and internal states must be greater
than the number of sensory states. In turn, this limits the straightforward application of the free
energy principle to particular partitions where the number of active states—and the number of
internal states—exceeds the number of sensory states. In other words, the FEP applies to large
particles with a nontrivial internal dynamics.
18Since the variational and conditional densities over external states are equal, any divergence
between them will vanish, see [43, Section 3.2].
19A functional is a function of a function, here, the free energy is a function of a conditional
density parameterised by the internal mode.
15
states:
F(π(τ)) = E [lnq(η(τ))−lnp(η(τ))−lnp(π(τ) | η(τ))] = ℑ(π(τ))
q
= E [ℑ(η(τ),π(τ))]−H[q(η(τ))]
q
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Expectedenergy Entropy
= E [ℑ(π(τ) | η(τ))]+D[q(η(τ))∥p(η(τ))]
q
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (18)
-veAccuracy Complexity
= D[q(η(τ))∥p(η(τ) | π(τ))]+ℑ(π(τ))
(cid:124) (cid:123)(cid:122) (cid:125)
=0
q = q (η) = p(η | s) = p(η | π)
µ
E[F(π)] = E[ℑ(π)] = H[p(π)]
This variational free energy20 can be rearranged in several ways. First, it can be
expressed as expected energy minus the entropy of the variational density, which
licences the name free energy21. In this decomposition, minimising variational free
energy corresponds to the maximum entropy principle, under the constraint that the
expected energy is minimised [46, 47]. The expected energy is a functional of the
NESS density that plays the role of a generative model; namely, a joint distribution
over causes (external states) and their consequences (particular states)22.
20Question: why is this functional called variational free energy? More generally (for instance
inengineeringapplicationswherethefreeenergyinquestionisalsocalledanevidencelowerbound
[44]) the free energy is a functional of an approximate posterior density q that is an approximation
to the Bayesian posterior, as follows:
q (η)≈p(η |π)⇒F[q]=D[q(η(τ))∥p(η(τ)|π(τ))]+ℑ(π(τ))
µ
(19)
(cid:124) (cid:123)(cid:122) (cid:125)
≥0
The variational density considered in this article is the minimiser of (19), and the free energy eval-
uated at the variational density is the variational free energy. The term ’variational’ inherits from
the use of the calculus of variations in variational Bayes (a.k.a., approximate Bayesian inference),
applied in the context of a mean field approximation or factorised form of the variational density.
Theterm’freeenergy’inheritsfromRichardFeynman’spathintegralformulation, inthesettingof
quantum electrodynamics.
21Question: isvariationalfreeenergythesamekindoffreeenergyfoundinstatisticalmechanics?
The answer is no: the entropy term in the variational free energy is the entropy of a variational
density—over external states—parameterised by internal states. This entropy is distinct from the
entropyofinternalstates. Minimisingvariationalfreeenergyincreases theentropyofthevariational
densityand,usually,reduces theentropyofinternalstates(see[45]foranexample). Mathematically,
we can express the different kind of entropies as H[q(η(τ))]̸=H[p(µ(τ))].
22Question: in practical applications, variational free energy is usually a function of data or
16
Second, variational free energy can be decomposed into the (negative) log like-
lihood of particular states (i.e., negative accuracy) and the KL divergence between
posterior and prior densities (i.e., complexity). Finally, it can be written as the self-
information associated with particular states (i.e., surprisal) plus the KL divergence
between the variational and conditional (i.e., posterior) density, which—by construc-
tion—is zero. In variational Bayesian inference [48], negative surprisal is read as a
log marginal likelihood or model evidence, having marginalised over external states.
In this setting, negative free energy is an evidence lower bound or ELBO [49, 44].
So, in what sense can we interpret (17) in terms of inference? Let us start
by considering the response of autonomous states to some sensory perturbation:
that is, the path of autonomous states conditioned upon sensory states. If sensory
states change slowly, then the autonomous states will flow towards their most likely
value (i.e., their conditional mode) and stay there23. However, if sensory states are
changing, the autonomous states will look as if they are tryingto hit a moving target.
One can formulate this along the lines of the centre manifold theorem [13, 50], where
we have a (fast) flow off the centre manifold and a (slow) flow of the autonomous
mode on the manifold.
α(τ) = ε(τ) + α(τ)
(cid:124)(cid:123)(cid:122)(cid:125) (cid:124)(cid:123)(cid:122)(cid:125) (20)
Offmanifold Onmanifold
ε(τ) ≜ α(τ)−α(τ)
In effect, this is a decomposition in a frame of reference that moves with the
autonomous mode, whose path lies on the centre manifold. We further describe the
off manifold flow using a Taylor expansion around the (time-varying) autonomous
mode24
observed (sensory) states. So, why is variational free energy a function of particular states? Later,
we will see that practical applications correspond to Bayesian filtering, under the assumption that
particular dynamics are very precise. This means that there is no uncertainty about autonomous
paths given sensory paths, and the action of a particular path is the action of a sensory path. In
generalised coordinates of motion—used in Bayesian filtering—the action of a path becomes the
surprisal of a state. In this setting, the variational free energy of particular states is the same as
the variational free energy of sensory states.
23Or, at least in the vicinity, if there are random fluctuations on its motion.
24Note that we are performing a Taylor expansion of a (generally rough) stochastic process ε,
see [51, Chapter 5]. Alternatively, it may be possible to instead consider motion in generalised
coordinatestointroducesmoothrandomfluctuations(seenextSection), sothatεbecomessmooth
and the usual Taylor expansion applies.
17
∂f ∂f
ε˙(τ) = α˙(τ)−α˙(τ) = f (0)+ ε ·ε+... = α ·ε+...
ε
∂ε ∂α
⇒
α˙(τ)−α˙(τ) = J ·(α−α)+... (21)
α
(cid:124) (cid:123)(cid:122) (cid:125)
Offmanifoldflow
= −(Γ ∇ F)·(α−α)+(Q ∇ F)·(α−α)+...
α αα αα αα
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Flowtocentremanifold Flowparalleltothemanifold
This means that the flow at the expansion point is zero, leaving the second
term of the expansion as the first non-vanishing term. This is the Jacobian of the
autonomous flow times the displacement of the current autonomous state from its
corresponding mode. The second-order derivatives of the free energy arise from the
Jacobian of the flow, i.e., substituting (17) into (8). Therefore, the off manifold flow
has a component that flows towards the centre manifold,25 afforded by the gradient
flow, and a component that is parallel to the manifold, afforded by the solenoidal
flow, cf. (6). Taken together, this means that the autonomous states flow in ever-
decreasing circles towards the centre manifold, as illustrated in Figure 2.
But what about the flow on the centre manifold? We know from (17) that the
flow of the autonomous mode can be expressed in terms of free energy gradients:
α˙(τ) = (Q −Γ )∇ F(s,α)+...
αα α α
= (Q −Γ )∇ E [ℑ(s,α | η)]+(Q −Γ )∇ D[q (η)∥p(η)]+... (22)
αα α α q αα α α µ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
-veAccuracy Complexity
This expression unpacks the centre manifold flow in terms of the accuracy and
complexity parts of free energy, where the accuracy part depends upon the sensory
states, while the complexity part is a function of, and only of, autonomous states.
In short, the flow on the centre manifold will look as if it is trying to maximise the
accuracy of its predictions, while complying with prior (Bayesian) beliefs.26 Here,
predictionsarereadastheexpectedsensorystates, underposterior(Bayesian)beliefs
about their causes afforded by the variational density over external states.
25We know that the flow must be towards the centre manifold because the covariance of random
fluctuationsispositivedefinite,andthecurvatureofthefreeenergyispositivedefiniteatitsminima:
i.e., around the expansion point.
26The covariance of random fluctuations Γ is positive definite and the solenoidal matrix field
α
Q isskew-symmetric, thereforetheflowin(22)willseektominimisecomplexityminusaccuracy.
αα
18
Figure 2: Autonomous flows and Bayesian filters. This figure shows two components of the
autonomous flow; namely, a (fast) flow α˙(τ)−α˙(τ) off the (centre) manifold, and a (slow) flow
α˙(τ)on themanifold. Themanifoldhereisthesetofautonomousmodesα(τ)givensensorystates
s(τ) for all time τ, see (16). The decomposition into fast and slow flows means that the manifold
can be thought of as a centre manifold. The left panel shows two components of the fast flow off
the manifold; namely, a flow towards the centre manifold and a flow parallel to the manifold, see
(21). This decomposition rests upon a first-order Taylor expansion of the off manifold flow. The
right panel plots the external mode as a function of the autonomous mode—what is known as a
synchronisation manifold—as a black curvilinear line. The Gaussian (blue and red) distributions
show possible variations in (external and autonomous) conditional modes due to variations in the
sensory states. The arrows represent the centre manifold flow α˙(τ) in the context of this synchro-
nisation manifold, where the tangent vectors represent possible directions of the flow.
19
5.1. Summary
In summary, a particular partition of a nonequilibrium steady-state density im-
plies that autonomous dynamics can be interpreted as performing a particular kind
of inference. This entails a fast flow towards an autonomous centre manifold and a
slow flow on the centre manifold. The centre manifold flow can be interpreted as
Bayesian belief updating, where posterior (Bayesian) beliefs are encoded by points
on an internal (statistical) manifold. In other words, for every point on the statistical
manifold, there is a corresponding variational density or Bayesian belief over exter-
nal states. We are now in a position to express this belief updating as a variational
principle of least action:
α[τ] = argminA(α[τ] | s[τ])
α[τ]
⇔ δ A(α[τ] | s[τ]) = 0
α
(23)
⇔
a˙(τ) = f (s,α) = (Q −Γ )∇ F(s,α)+...
a aa a a
µ˙(τ) = f (s,α) = (Q −Γ )∇ F(s,α)+...
µ µµ µ µ
This is a basis of the free energy principle. Put simply, it means that the inter-
nal states of a particular partition can be cast as encoding conditional or posterior
Bayesian beliefs about external states. Equivalently, the autonomous path of least
action can be expressed as a gradient flow on a variational free energy that can be
read as log evidence. This licences a somewhat poetic description of self-organisation
as self-evidencing [4], in the sense that the surprisal or self-information is known as
log model evidence or marginal likelihood in Bayesian statistics27.
Interestingly, because of the symmetric setup of the Markov blanket, it would be
possible to repeat everything above but switch the labels of internal and external
states—and active and sensory states—and tell the same story about external states
tracking internal states. This evinces a form of generalised synchrony [53, 54, 55, 7],
where internal and external states track each other. Technically, if we consider the
(internal and external) manifolds in the joint space of internal and external states,
27Question: thisBayesianmechanicsseemsaptforinferencebutwhataboutlearningovertime?
We have been dealing with states in a generic sense. However, one can have states that change
over different timescales. One can read slowly changing states as special states that play the role
of parameters; either parameters of the flow or, implicitly, the generative model. In mathematical
and numerical analyses, states and parameters are usually treated identically; i.e., as minimising
variational free energy. Indeed, in practical applications of Bayesian filtering schemes that learn,
the parameters are treated as slowly changing states. See [52, 36] for worked examples.
20
we have something called a synchronisation manifold that offers another perspective
on the coupling between the inside and outside [56, 39, 7].
These teleological interpretations cast particular paths of least action as an op-
timisation process, where different readings of free energy link nicely to various nor-
mative (i.e., optimisation) theories of sentient behaviour. Some cardinal examples
are summarised in Figure 3; see [57, 58, 5, 59] for some formal accounts of these
relationships. Because internal states do not influence sensory (or external) states,
they will look as if they are concerned purely with inference, in the sense that they
parameterise the variational density over external states. However, active states
influence sensory (and external) states and will look as if they play an active role
in configuring (and causing) the sensory states that underwrite inference. In the
neurosciences, this is known as active inference [60, 61, 62].
The link between optimisation and inference is simply that inference is belief
optimisation. However, it is worth unpacking the gradients that ‘drive’ this optimi-
sation. In statistics, variational free energy is used to score the divergence between
a variational density and the conditional density over external (i.e., hidden) states,
given blanket states [49]. Unlike the definition in (18), these densities are not as-
sumed to be equivalent. Variational inference proceeds by optimising the variational
density such that it minimises free energy—often using the gradient flows in (17).
However, there is a subtle difference between the dynamics of (17) and variational
inference. In the former, there is no contribution from the KL-divergence as it is
stipulated to be zero. In the latter, it is only the divergence term that contributes
to free energy gradients. So, is it tenable to interpret gradient flows on variational
free energy as variational inference, or is this just teleological window-dressing? The
next section addresses this question through the lens of Bayesian filtering. In brief,
we will see that the autonomous paths of least action—implied by a particular par-
tition—are the paths of least action of a Bayesian filter. This takes us beyond ‘as
if’ arguments by establishing a formal connection between particular dynamics and
variational inference.
6. Lagrangians, generalised states and Bayesian filtering
Now, say we wanted to emulate or simulate active inference. Given some equa-
tions of motion and statistics of random fluctuations, we could find the stationary
solution to the Fokker Planck equation and accompanying Helmholtz decomposition.
We could then solve (23) for the autonomous paths of least action that characterise
the expected behaviour of this kind of particle, and obtain realisations of synchroni-
sation and inference. See [8] for a worked example using a system of coupled Lorentz
attractors.
21
Figure 3: Markov blankets and self-evidencing. This schematic illustrates various points
of contact between minimising variational free energy and other normative theories of optimal
behaviour. The existence of a Markov blanket entails a certain lack of influences among internal,
blanket and external states. These have an important consequence—internal and active states
are not influenced by external states, which means their dynamics (i.e., perception and action)
are a function of, and only of, particular states, given by a variational (free energy) bound on
surprisal. This has a number of interesting interpretations. Given surprisal is the negative log
probability of finding a particle or creature in a particular state, minimising surprise corresponds
to maximising the value of that state. This interpretation is licensed by the fact that the states
with a high probability are, by definition, characteristic of the particle in question. On this view,
one could relate this to dynamics in reinforcement learning [63], optimal control theory [64] and,
in economics, expected utility theory [65, 66]. Gradient flows that minimise surprisal (i.e., self-
information) lead to a series of influential accounts of neuronal dynamics; including the principle
of maximum mutual information [67, 68], the principles of minimum redundancy and maximum
efficiency [69] and the free energy principle [70]. Crucially, the average or expected surprise (over
time of particular states) corresponds to entropy. This means that action and perception look
as if they are bounding the entropy of particular states. This links nicely with theories of self-
organisation, such as synergetics in physics [24, 14, 71] or homoeostasis in physiology [72, 73, 74].
Finally, the probability of a particular state, is, on a statistical view, model evidence or marginal
likelihood [75, 76], marginalising over the causes of particular states (i.e., external states). This
means that all the above formulations are internally consistent with things like the Bayesian brain
hypothesis, evidence accumulation and predictive coding[57, 77, 58]. Most of these formulations
inheritfromHelmholtz’smotionofunconsciousinference[78],laterunpackedintermsofperception
ashypothesistestinginpsychology[79]andmachinelearning[80]. Althoughnotdepictedhere,the
minimisation of complexity—inherent in the minimisation of free energy—enables thermodynamic
22
and metabolic efficiency via Landauer’s principle [81].
In this section, we take a somewhat pragmatic excursion to suggest a simpler way
to recover the paths of least action; namely, as the solution to a generic (Bayesian)
filtering scheme that is widely used in the engineering literature.
6.1. Dynamics in generalised coordinates of motion
Let us go back to the Langevin equation governing our system
x˙(τ) = f(x)+ω(τ). (24)
In this section, we assume that the random fluctuations driving the motion have
smooth (analytic) sample paths; thus, the Langevin equation considered in the rest
of the article can be seen as the limit of (24) as the fluctuations become rough [82].
This setup speaks nicely to the fact that, in biology, fluctuations are often smooth
up to a certain order—contrariwise to thermal (white noise) fluctuations—as they
are the output of other random dynamical systems. As before, we assume that
the fluctuations are state-independent, and a stationary Gaussian process, e.g., the
smoothing of white noise fluctuations with a Gaussian kernel. Just like in the case of
white noise, Gaussianity can be motivated by the central limit theorem—fluctuations
should be normally distributed at each point in time.
We denote the autocovariance of fluctuations by Γ = 1E[ω(τ)⊗ω(τ +h)]. The
h 2
underlying dynamical systems giving rise to this generic type of smooth noise can
be recovered through a procedure known as stochastic realisation [7, 83, 84]. The
solution to the Langevin equation (24) can be approximated, on a suitably small
interval of time, by a linear Langevin equation in generalised coordinates of motion
⃗x = (x,x′,x′′,...) [85, Section 4]:2829
28Theexpansion(25)isalinearapproximationof (24)[86],obtainedbyrecursivelydifferentiating
(24) and ignoring the contribution of the derivatives of the flow of order higher than one. In other
words, the expansion is exact when the flow is linear, and it is accurate on a short time-scale when
the flow is non-linear.
29The curvature (i.e., second derivative) of the autocovariance Γ′′ is a ubiquitous measure of
0
roughness of a stochastic process [87]. Note that in the limit where the fluctuations ω are uncorre-
lated (e.g., white noise fluctuations), Γ′′ (and higher derivatives) become infinitely large.
0
23

x˙ = x′ = ∇f ·x+ω
x˙′ = x′′ = ∇f ·x′ +ω′     ⃗x ˙ = f(⃗x)+ω⃗
x˙′′ = x′′′ = ∇f ·x′′ +ω′′ ⇔ D⃗x = J⃗x+ω⃗
. . .     p(ω⃗(τ)) = N(ω⃗(τ);0,2Γ)
     
0 1 ∇f Γ Γ′′
0 0
 0 1   ∇f   −Γ′′ −Γ′′′′ 
D = 
 0
... 

, J =
 ∇f


, Γ = 
 Γ′′
0
Γ′′′′
0 

 ...   ...   0
−Γ′′′′
0 ... 
0
(25)
Here, the different variables ⃗x = (cid:0) x,x′,x′′,...,x(n),... (cid:1) can be seen as the posi-
tion, velocity, acceleration, jerk, and higher orders of motion of the process, which
are treated as separate (generalised) states that are coupled through the Jacobian J.
These are driven by smooth fluctuations ω⃗ (i.e., the serial derivatives of ω) whose co-
variance 2Γ can be expressed in terms of the serial derivatives of the autocovariance
[88, Appendix A.5.3].
The generalised states are the coefficients of a Taylor series expansion of the
solution to the Langevin equation (24):
x′′(0) x(n)(0)
x(τ) = x(0)+x′(0)τ + τ2 +...+ τn +..., (26)
2 n!
where (26) holds, typically, only on a small time-interval to which we restrict our-
selves henceforth. In other words, the generalised states at any time-point determine
the system’s trajectory, and vice versa; that is, there is an isomorphism between
generalised states and paths.
This line of reasoning has two advantages. First, it means one can let go of white
noise assumptions on the random fluctuations and deal with smooth or analytic
fluctuations. Second, the linear expansion in generalised coordinates of motion (25)
means that the distribution of generalised states has a simple Gaussian form
1
L(⃗x(τ)) ≜ −lnp(⃗x(τ)) = ⃗x(τ)·M⃗x(τ)
2 (27)
1
M = (D−J)· (D−J).
2Γ
Here, M can be read as a mass matrix. This suggests that precise particles, with
low amplitude random fluctuations, behave like massive bodies. Furthermore, (27)
24
is seen as the Lagrangian in generalised coordinates of motion, due to its formal
similarity with (3). Under the isomorphism between points and paths in generalised
coordinates, the Lagrangian is equivalent to the action; it scores the likelihood of
pathsof (24), asapathcorrespondstoapointingeneralisedcoordinatesofmotion30.
We will reason about the trajectories of the system by analysing the Lagrangian of
generalised states henceforth.
The path of least action corresponds to the minimiser of the Lagrangian, which
can be expressed as follows:
→−
x(τ) = argminL(⃗x(τ))
⃗x(τ) (28)
→−
⇔ ∇L(x(τ)) = 0 ∀τ.
Wecanrecoverthepathofleastactionbysolvingthefollowingequationofmotion
˙
⃗x(τ) = D⃗x−∇L(⃗x)
(29)
∇·D⃗x = 0.
Indeed, this motion can be interpreted as a gradient descent on the Lagrangian, in
a frame of reference that moves with the mode of the distribution of generalised
states [36]. Thus, the convexity of the Lagrangian means that any solution to (29)
convergestothepathofleastaction. Inthissetting, thedivergence-freeflow(i.e., the
first term) is known as a prediction of the generalised state based upon generalised
motion, while the curl-free, gradient flow (i.e., the second term) is called an update.
6.2. Particular partitions in generalised coordinates of motion
We now reintroduce the distinction between internal, external, sensory and active
statesx = (η,s,a,µ). Briefly,asbefore,weassumethattheLangevinequation(24)is
sparselycoupledasin(13). Thisimpliesthatthetrajectoriesinternalandexternalto
the particle are conditionally independent given the trajectories of the blanket (15).
The same sparse coupling structure carries through the expansion in generalised
coordinates (25) so that the motion of generalised states entails trajectories with the
same conditional independencies. Since paths correspond to generalised states, this
yields conditional independence between generalised states, as follows:
(µ⃗ ⊥ ⃗η) | ⃗ b ⇐⇒ L(⃗x) = L(⃗η | ⃗ b)+L(µ⃗ | ⃗ b)+L( ⃗ b). (30)
30Question: how can a point be a path? The generalised states (i.e., temporal derivatives)
approximate the path of the solution to (24) on a suitably small time interval because they are the
coefficients of a Taylor expansion of the path as a function of time (26).
25
We can now recover paths of least action of the particle by equating the La-
grangian with the variational free energy of generalised states. This allows us to
express the internal path of least action as a gradient flow on variational free energy,
which can itself be expressed in terms of generalised prediction errors. From (29),
we have
˙ ⃗
µ⃗(τ) = Dµ⃗ −∇ L(⃗x) = Dµ⃗ −∇ L(µ⃗ | b)
µ⃗ µ⃗ (31)
= Dµ⃗ −∇ L(⃗π) = Dµ⃗ −∇ F(⃗π),
µ⃗ µ⃗
where the free energy of generalised states is analogous to (18)
F(⃗s,⃗a,µ⃗) = E [L(⃗η,⃗π)] −H[q(⃗η)]
q
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Expectedenergy Entropy
= E [L(⃗π | ⃗η)]+D[q(⃗η)∥p(⃗η)]
q
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Accuracy Complexity
= D[q(⃗η)∥p(⃗η | ⃗π)]+L(⃗π)
(32)
→− →− ⃗
q (⃗η) = N(⃗η; µ,Σ(µ)) = p(⃗η | ⃗π) = p(⃗η | b)
µ⃗
1 1
L(⃗η,⃗π) = ε · ε +ε · ε +...
η⃗ η⃗ ⃗s ⃗s
4Γ 4Γ
η s
ε ≜ D⃗η −f (⃗η,⃗s)
η⃗ η⃗
ε ≜ D⃗s−f (⃗η,⃗s).
⃗s ⃗s
Thevariationalfreeenergyofgeneralisedstatesiseasytoevaluate, givenagenerative
model in the form of a state-space model [36]; that is, the generalised flow of external
and sensory states f ,f , and the covariance of their generalised fluctuations Γ ,Γ .
η⃗ ⃗s η s
Note that the parameterisation of the variational density is very simple: the internal
states parameterise the expected external states. Furthermore, the quadratic form
of the Lagrangian means that the variational density over the generalised motion
of external states is Gaussian31. This licenses a ubiquitous assumption in varia-
tional Bayes called the Laplace assumption. Please see [89] for a discussion of the
simplifications afforded by the Laplace assumption.
Crucially, in the absence of active states, the dynamic in (31) coincides with a
generalisedBayesianfilter. GeneralisedfilteringisagenericBayesianfilteringscheme
fornonlinearstate-spacemodelsformulatedingeneralisedcoordinatesofmotion[36];
31Question: why is the covariance of the variational density only a function of the internal
mode? This follows from the quadratic Lagrangian that furnishes an analytic solution to the free
energy minimum. Please see [89] for details.
26
specialcasesincludevariationalfiltering[90],dynamicexpectationmaximisation[91],
extended Kalman filtering [92], and generalised predictive coding.
Furthermore, if the autonomous paths are conditionally independent from ex-
ternal paths, given sensory paths32, the autonomous paths of least action can be
recovered from a generalised gradient descent on variational free energy:
˙
α⃗(τ) = Dα⃗ −∇ L(⃗x) = Dα⃗ −∇ L(α⃗ |⃗s)
α⃗ α⃗ (33)
= Dα⃗ −∇ L(⃗π) = Dα⃗ −∇ F(⃗π).
α⃗ α⃗
In this case, the most likely paths of both internal and active states can be recovered
byagradientdescentonvariationalfreeenergy, andonecansimulateactiveinference
using generalisations of linear quadratic control or model predictive control [93, 94]:
 
˙  
⃗η(τ) f (⃗η,⃗s,⃗a)+ω⃗ (τ)
η⃗ η
  ⃗s ˙ (τ)   =   f ⃗s (⃗η,⃗s,⃗a)+ω⃗ s (τ)   (34)
  ⃗a ˙ (τ)    D⃗a−∇ ⃗a F(⃗s,⃗a,µ⃗) 
µ⃗ ˙ (τ) Dµ⃗ −∇ µ⃗ F(⃗s,⃗a,µ⃗)
This is effectively a (generalised) version of the particular dynamics in (23).
6.3. Summary
This section has taken a somewhat pragmatic excursion from the FEP narrative
to consider generalised coordinates of motion. This excursion is important because
it suggests that the gradient flows in systems with attracting sets are the paths of
least action in Bayesian filters used to assimilate data in statistics [92] and, indeed,
control theory [95].
Working in generalised coordinates of motion is effectively working with paths
and the path integral formulation. Practically, this is useful because one can use
the density over paths directly to evaluate the requisite free energy gradients, as
opposed to solving the Fokker-Planck equation to find the NESS density. Effectively,
the generative model becomes a state-space model, specified with flows and the
statistics of random fluctuations: see (32). These are the sufficient statistics of the
joint density over external and sensory paths.
Hitherto, we have largely ignored random fluctuations in the motion of particular
states to focus on the underlying flows. Are these flows ever realised or does the
principle of least action in (23) only apply to the most likely autonomous paths? In
32This is the case for precise particles, which are defined by particular fluctuations of infinitesi-
mally small amplitude—see next Section and [37].
27
what follows, we will consider a special class of systems, where we suppress particular
fluctuations to recover the behaviour of particles that show a precise or predictable
response to external states. For this kind of particle, the particular paths are always
the paths of least action.
7. From statistical to classical particles
So far, we have a Bayesian mechanics that would be apt to describe a particle
or person with a pullback attractor. But what is the difference between a particle
and a person? This question speaks to distinct classes of things to which the free
energy principle could apply; e.g., molecular versus biological. Here, we associate
biotic self-organisation with the precise and predictable dynamics of large particles.
Thanks to the Helmholtz decomposition (6), it is known that when random fluctua-
tions are large, dissipative flow dominates conservative flow, and we have ensembles
described by statistical mechanics (i.e., small particles). Conversely, when random
fluctuations have a low amplitude, solenoidal flow33 dominates and we have classical
mechanics and deterministic chaos (i.e., of heavenly and n-body problems). Here,
we consider the distinction between statistical and classical mechanics in the setting
of a particular partition.
Itisoftensaidthatthefreeenergyprincipleexplainswhybiologicalsystemsresist
the second law and a natural tendency to dissipation and disorder [96]. However, this
is disingenuous on two counts. First, the second law only applies to closed systems,
while the free energy principle describes open systems in which internal states are
exposed to—and exchange with—external states through blanket states. Second,
there is nothing, so far, to suggest that the entropy of particular states or paths
is small. Everything we have done would apply equally to particles with high and
low entropy densities. So, what distinguishes between high and low entropy systems
(e.g., between candle flames and concierges), respectively?
One answer can be found in the path-integral formulation: from (5), we can
associate the entropy of a path (i.e., history or trajectory of particular states) with
the amplitude of random fluctuations. This licences the notion of precise particles
that are characterised by low or vanishing random fluctuations34. In essence, precise
33And its accompanying correction term Λ, see (6).
34Question: but surely my neurons are noisy? There is a substantial literature that refers to
neuronalandsynapticnoise: e.g.,[97]. However,thepopulationdynamicsofneuronalensemblesor
assemblies are virtually noiseless by the central limit theorem (because they comprise thousands of
neurons), when averaged over suitable spatial and temporal scales. For example, in electrophysiol-
ogy, averaging several fluctuating single trial responses yields surprisingly stable and reproducible
28
particles are simply ‘things’ that are subject to the classical laws of nature; i.e.,
Lagrangian mechanics. In the accompanying limit of small fluctuations on particular
states, every autonomous trajectory is a path of least action. From (5) and (23) this
can be expressed as follows:
lim α˙(τ) = f (π(τ)) ⇔ δ A(α[τ] | s[τ]) = 0 ⇔ α[τ] = α[τ]
α α
Γπ→0
⇒
(35)
a˙(τ) = a˙(τ) = (Q −Γ )∇ F(π)+...
aa a a
µ˙(τ) = µ˙(τ) = (Q −Γ )∇ F(π)+...
µµ µ µ
This suggests that precise particles—such as you and me—will respond to en-
vironmental flows and fluctuations in a precise and predictable fashion. Figure 4
illustrates the difference between generic and precise particles using an information
diagram. Note that for precise particles, there is no uncertainty about autonomous
states, given sensory states. This follows because the flow of autonomous states de-
pends only on sensory states and themselves. Is the behaviour of precise particles a
sufficient description of sentient behaviour?
On one reading, perhaps: one can reproduce biological behaviour by numerically
integrating (23) or (34) under a suitable generative (state-space) model specifying
the motion of external and sensory states35. Figure 5 illustrates the implicit compu-
tational architecture used to simulate sentient behaviour by integrating (23). This
scheme allows one to simulate the internal and active states through sensory states
caused by external dynamics. Figure 6 showcases an example from the active infer-
ence literature, that integrates (34) under a suitably specified generative model, to
simulatesentientbehaviourthatlookslikehandwriting. Thedetailsofthesimulation
and the details of the generative model are not relevant here but are summarised in
the figure legend; what is important is to get a sense of the kind of behaviour that
can be reproduced by integrating (34).
The example in Figure 6 illustrates an application of the free energy principle.
Here, instead of describing a system by deriving its NESS density, we have specified
some equations of motion (and covariance of random fluctuations) to realise par-
ticular dynamics using (34) and (32). In effect, we have simulated self-evidencing,
event-relatedpotentials. FromtheperspectiveoftheFEP,studyingsingleneurons(ortrials)islike
studying single molecules to characterise fluid dynamics.
35A generative model can be specified through the flow of external or sensory states, and the
random fluctuations of their motion; that is, the first two lines of (34). Observing that the free
energy (31) is only a function of these flows and the covariance of fluctuations, it is sufficient to
specify those covariances, rather than the whole structure of the fluctuations.
29
Figure 4: Generic and precise particles. These information diagrams depict the entropy of
external, sensoryandautonomouspaths, whereintersectionscorrespondtosharedormutualinfor-
mation. A conditional entropy corresponds to an area that is outside the variable upon which the
entropyisconditioned. Thediagramontheleftshowsthegenericcase, inwhichuncertaintyabout
paths inherits from random fluctuations that determine the conditional entropies of paths. When
the amplitude of random fluctuations on the motion of particular states is very small, we have
preciseparticlesinwhichthereisnouncertaintyaboutautonomouspaths,givensensorypaths(the
right information diagram). Similarly, there is no uncertainty about sensory paths given external
and autonomous paths. Note that because we are dealing with continuous states, we are implicitly
interpreting the entropies as the limiting density of discrete points (LDDP), which have a lower
bound of zero [46]. (LDDP is an adjustment to differential entropy which ensures that entropy is
lower bounded by zero. LDDP equals the negative KL-divergence between the density in question
and a uniform density). Two relative entropies (information gain and risk) are highlighted as areas
ofintersection. Thesewillplayanimportantrolelater,whendecomposingtheaction(i.e.,expected
free energy) of autonomous paths.
starting from a definition (i.e., state-space generative model) of paths that charac-
terise this kind of particle36.
These simulations speak to a key aspect in the applications of the FEP. Hith-
erto, we have simply defined the variational density as the conditional density over
36The example in Figure 6 used (34) with generalised coordinates of motion up to fourth order.
Numerical analyses suggest that simulating generalised motion up to order six (i.e., ignoring all
subsequent orders of motions) is sufficient in most circumstances [91].
30
Figure 5: Bayesian mechanics and active inference. This graphic summarises the belief
updatingimplicitingradientflowsonvariationalfreeenergy. Thesearethepathstakenbyaprecise
particle or the paths of least action of a generic particle. It illustrates a simple form of (active)
inferencethathasbeenusedinavarietyofapplicationsandsimulations; rangingfromhandwriting
and action observation [98], through to birdsong and generalised synchrony in communication [56].
In brief, sensory states furnish free energy gradients (often expressed as prediction errors), under
some generative model. Neuronal dynamics are simulated as a flow on the resulting gradients to
produce internal states that parameterise posterior beliefs about external states. Similarly, active
states are simulated as a flow on free energy gradients that generally play the role of prediction
errors. In other words, active states mediate motor or autonomic reflexes [99, 100]. An example of
this kind of active inference is provided in the next figure.
external states given a sensory state. However, when simulating precise particles
through a gradient flow on variational free energy, as in (23) or (34), the requi-
site gradients have to be evaluated. In turn, this requires the functional form of
the variational density or posterior distribution, which may be difficult to compute
exactly37. In this case, we take a variational density that approximates the true pos-
37In Bayesian inference, it is well-known that computing the posterior distribution given data
31
Figure 6: Sentient behaviour and action observation. This figure illustrates a simulation
of active inference (here, writing) evinced by a precise particle, in terms of inferences about ex-
ternal states of the world, consequent predictions about sensory input, and ensuing action. The
autonomousdynamicsthatunderwritethisbehaviourrestuponagenerativemodelofsensorystates
in the form of Lotka-Volterra dynamics; see sample sensory trajectories as (arbitrarily) coloured
lines in the upper left inset. The generative model defines the joint density under which internal
trajectories can be seen as parameterising external states. This model is not a description of the
true external states (which here are simply the positions of the joints in the simulated arm—with
dynamics given by simple Newtonian rules). In this generative model, external trajectories are
assumed to follow predator-prey like dynamics such that a succession of peaks are generated for a
subset of external states (or coordinates) in turn. Each coordinate is associated with a location in
Euclidean space that attracts the agent’s finger (the active states); i.e., with a trajectory towards
that attracting point. The resulting attracting point is thus a weighted sum of each possible at-
tracting point weighted by the coordinates following the Lotka-Volterra trajectory. In turn, the
internal states supply predictions of what sensory states should register if the agent’s beliefs were
true. Active states (i.e., the forces driving changes in the angular velocities of the limb joints) try
to suppress the ensuing prediction error by adjusting expected changes in sensed angular velocity,
through exerting forces on the agent’s joints (not shown). The subsequent movement of the arm is
traced out in the lower-left panel. This trajectory has been plotted in a moving frame of reference
sothatitlookslikehandwriting(e.g.,asuccessionof‘j’and‘a’letters). Thelowerrightpanelsshow
theactivityofoneinternalstateduringdistinctphasesof‘action’,and‘action-observation’. During
the action phase, sensory states register the visual and proprioceptive consequences of movement,
32
while under action observation, only visual sensations are available—as if the agent was watching
another agent. The red dots correspond to the times during which this internal state exceeded an
arbitrary threshold. The key thing to note here is that this internal state responds preferentially
when,andonlywhen,themotortrajectoryproducesadown-stroke,butnotanup-stroke—evincing
a cardinal feature of neuronal responses, namely, their functional selectivity. Furthermore, with a
slight delay, this internal state responds during action and action observation. From a biological
perspective, thisis interesting becauseitspeaks toan empiricalphenomenon knownas mirrorneu-
ron activity [101, 102, 103]. Please see [98] for further details.
terior, whence the variational free energy becomes an upper bound on surprisal: see
(19). FromtheperspectiveofBayesianinference, thistakesusfrom(computationally
costly) exact Bayesian inference to (computationally cheap) approximate Bayesian
inference [48, 49, 104]. On one reading of its inception, this is why variational
free energy was introduced [105]; namely, to convert a computationally expensive
marginalisation problem into a computationally manageable optimisation problem.
Note that when using generalised coordinates to realise active inference; i.e., (34),
we are generally employing approximate Bayesian inference: the functional form of
the variational density inherits directly from Gaussian assumptions about random
fluctuations, however the expansion in generalised coordinates on which it is based
upon (29) is generally an approximation to the underlying dynamic (cf. 28).
7.1. Summary
Precise particles, immersed in an imprecise world, respond (almost) determinis-
tically to external fluctuations38. This means, given a generative model (i.e., NESS
density), one can solve the equations of motion in (34) to predict how autonomous
states evolve as they pursue their path of least action. So, why might this limiting
behaviour be characteristically biological?
Precise particles may be the kind of particles that show lifelike or biotic be-
haviour, in the sense they respond predictably, given their initial states and the
history of external influences. The distinction between imprecise (e.g., statistical)
and precise (e.g., classical) particles rests on the relative contribution of dissipa-
tive and conservative flow to their path through state-space, where solenoidal flow
predominates in the precise setting. This means precise particles exhibit solenoidal
behaviour such as oscillatory and (quasi) periodic orbits—and an accompanying loss
of detailed balance, i.e., turbulent and time-irreversible dynamics [106, 107, 30]. On
this view, one might associate precise particles with living systems with character-
istic biorhythms [108, 109, 110, 111]; ranging from gamma oscillations in neuronal
populations, through slower respiratory and diurnal cycles to, perhaps, lifecycles per
se. Turning this on its head, one can argue that living systems are a certain kind of
particle that, in virtue of being precise, evince conservative dynamics, biorhythms
and time irreversibility.
and a generative model p(η | π) = p(η,π)/p(π) is computationally costly as it involves computing
(cid:82)
a (typically) high-dimensional integral p(π)= p(η,π)dη (i.e., a partition function).
38Question: does the absence of random fluctuations preclude dissipative gradient flows? No,
because the gradients can increase with the precision of random fluctuations. In the limit of no
random fluctuations, the steady-state density tends towards a delta function (i.e., a fixed-point
attractor) and the dissipative gradients tend towards infinity.
33
One might ask if solenoidal flow confounds the gradient flows that underwrite
self-evidencing. In fact, solenoidal flow generally augments gradient flows—or at
least this is what it looks like. In brief, the mixing afforded by solenoidal flow can
render gradient descent more efficient [112, 113, 114, 115, 116]. An intuitive example
is stirring sugar into coffee. The mixing afforded by the solenoidal stirring facilitates
the dispersion of the sugar molecules down their concentration gradients. On this
view, the solenoidal flow can be regarded as circumnavigating the contours of the
steady-state density to find a path of steepest descent.
The emerging picture here is that biotic systems feature solenoidal flow, in virtue
of being sufficiently large to average away random fluctuations, when coarse-graining
their dynamics [5]. From the perspective of the information geometry induced by
the FEP, this means biological behaviour may be characterised by internal solenoidal
flows that do not change variational free energy—or surprisal—and yet move on the
internal (statistical) manifold to continually update Bayesian beliefs about external
states. Biologically, this may be a description of central pattern generators [110, 117]
that underwrite rhythmical activity (e.g., walking and talking) that is characteristic
of biological systems [118]. The example in Figure 6 was chosen to showcase the
role of solenoidal flows in Bayesian mechanics that—in this example—arise from the
use of Lotka-Volterra dynamics in the generative model. In psychology, this kind of
conservative active inference may be the homologue of being in a ‘flow state’ [119].
Inshort, preciseparticlesmaybethekindofparticlesweassociatewithlivingsys-
tems. And precise particles have low entropy paths. If so, the question now becomes:
what long-term behaviour does this class of particle show? In other words, instead
of asking which behaviours lead to low entropy dynamics, we can now ask which be-
haviours follow from low entropy dynamics? We will see next that precise particles
appear to plan their actions and, perhaps more interestingly, show information and
goal-seeking behaviour.
8. Path integrals, planning and curious particles
While the handwriting example in Figure 6 offers a compelling simulation of self-
evidencing—in the sense of an artefact creating its own sensorium—there is some-
thing missing as a complete account of sentient behaviour. This is because we have
only considered the response of autonomous states to sensory states over limited
periods of time. To disclose a deeper Bayesian mechanics, we need to consider the
paths of autonomous states over extended periods. This takes us to the final step
and back to the path-integral formulation.
In the previous section, we focused on linking dynamics to densities over (gener-
alised)states. Inbrief, wesawthatinternalstatescanbeconstruedasparameterising
34
(Bayesian) beliefs about external states at any point in time. In what follows, we
movefromdensitiesoverstates todensitiesoverpaths—tocharacterisethebehaviour
of particles in terms of their trajectories.
Inwhatfollows,wewillbedealingwithpredictiveposteriordensitiesoverexternal
andparticularpaths, given(initial)particularstates, whichcanbeexpressedinterms
of the variational density parameterised by the current (initial) internal state:39
q(η[τ],π[τ] | π ) ≜ E [p(η[τ],π[τ] | η ,π )] = p(η[τ],π[τ] | π )
0 qµ 0 0 0 (36)
q (η ) = p(η | π ).
µ 0 0 0
All this equation says is that, given the initial particular states, we can evaluate
the joint density over external and particular paths, because we know the density
over the initial external states, which is parameterised by the initial internal state.
We are interested in characterising autonomous responses to initial particular
states. This is given by the action of autonomous paths as a function of particular
states. In other words, we seek an expression for the probability of an autonomous
paththat(i) furnishesateleologicaldescriptionofself-organisationand(ii) allowsus
to simulate the sentient trajectories of particles, given their sensory streams. Getting
from the action of particular paths to the action of autonomous paths requires a
marginalisation over sensory paths. This is where the precise particle assumption
comes in: it allows us to eschew this (computationally costly) marginalisation by
expressing the action of particular paths as an expected free energy.
Recall that when random fluctuations on the motion of particular states vanish,
there is no uncertainty about autonomous paths, given external and sensory paths.
And there is no uncertainty about sensory paths given external and autonomous
paths. If we interpret entropies as the limiting density of discrete points (see Figure
4), then the uncertainty about particular, autonomous and sensory paths, given
external paths, become interchangeable:
lim H[p(π[τ] | η[τ],π )] = H[p(α[τ] | η[τ],s[τ],π )]+H[p(s[τ] | η[τ],π )]
0 0 0
Γπ→0 (cid:124) (cid:123)(cid:122) (cid:125)
=0
= H[p(s[τ] | η[τ],α[τ],π )]+H[p(α[τ] | η[τ],π )]
0 0 (37)
(cid:124) (cid:123)(cid:122) (cid:125)
=0
⇒
E [lnp(π[τ] | η[τ],π )] = E [lnp(s[τ] | η[τ],π )] = E [lnp(α[τ] | η[τ],π )]
q 0 q 0 q 0
39Question: Why is the variational density parameterised by the initial internal state rather
than the initial internal mode? The answer is that in precise particles, the absence of fluctuations
on particular dynamics means that the internal states always coincides with the internal mode.
35
We can leverage this exchangeability to express the action of autonomous paths
in terms of an expected free energy. From (36) and (37), we have (dropping the
conditioning on initial states for clarity):
(cid:20) (cid:21) (cid:20) (cid:21)
p(η[τ],α[τ]) p(α[τ] | η[τ])p(η[τ])
0 = E ln = E ln
q q
q(η[τ],α[τ]) q(η[τ] | α[τ])q(α[τ])
(cid:20) (cid:21)
p(s[τ] | η[τ])p(η[τ])
= E ln −lnq(α[τ]) = E [A(α[τ])−G(α[τ])]
q q(α[τ])
q(η[τ] | α[τ])
(38)
(cid:2) (cid:3)
= D q(α[τ])∥e−G ⇒ G(α[τ]) = A(α[τ])
Risk Ambiguity
(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)
G(α[τ]) = E [lnq(η[τ] | α[τ])−lnp(η[τ])−lnp(s[τ] | η[τ])]
q(η[τ],s[τ]α[τ])
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Expectedcomplexity Expectedaccuracy
All we have done here is to exchange the density over autonomous paths, conditioned
on external paths, with the corresponding density over sensory paths (in the second
line) thanks to the precise particle assumption. By gathering terms into a functional
of autonomous paths, we recover autonomous action as an expected free energy.
By analogy with the expression for variational free energy (18), the expressions
for the expected free energy in (38) suggest that accuracy becomes ambiguity, while
complexity becomes risk. So why have we called these terms ambiguity and risk?
Ambiguity is just the expected precision or conditional uncertainty about sensory
states given external states. A heuristic example of an imprecise likelihood map-
ping—between external and sensory paths—would be a dark room, where there is
no precise information at hand. Indeed, according to (38), sensory paths into dark
rooms should be highly unlikely. However, this is not the complete story, in the
sense that the risk puts certain constraints on any manifest tendency to minimise
ambiguity.
Here, risk is simply the divergence between external paths given an autonomous
path (i.e., policy or plan), relative to external states of affairs. The marginal density
over external paths is often referred to in terms of prior preferences, because they
constitute the priors of the generative model characterising the particle’s behaviour
[146]. In short, the expression for expected free energy, suggests that particles will
look as if they are (i) minimising the risk of incurring external trajectories that
diverge from prior preferences, while (ii) resolving ambiguity in response to external
events. In this formulation, autonomous paths play the dual role of registering the
influences of external events (via ambiguity), while also causing those events (via
risk).
The autonomous path with the least expected free energy is the most likely path
36
Figure 7: Expected free energy and active inference. This figure illustrates active inference,
and highlights various points of contact with other accounts of sentient, purposeful or intelligent
behaviour. The upper panel casts action and perception as the minimisation of expected and
variational free energy, respectively. Crucially, the path integral formulation of active inference
introduces posterior beliefs over autonomous paths (i.e., policies) that entail a description of plan-
ningasinference[120,121,122]. Whensimulatingactiveinference, posteriorbeliefsaboutexternal
paths, under plausible policies, are optimised by a gradient flow on the variational (free energy)
bound on log evidence—as in Figure 3. These beliefs are then used to evaluate the expected
free energy of allowable policies, from which actions can be selected [123, 124, 125]. Crucially,
expected free energy contains terms that arise in various formulations of optimal behaviour that
predominate in cognitive science, engineering and economics. These terms are disclosed when one
removes certain sourcesof uncertainty. For example, ifwe remove ambiguity, decision-makingmin-
imises risk, which corresponds to aligning predictions with preferences about the external course of
events. This underwrites prospect theory of human choice behaviour in economics [126] and mod-
ernapproachestocontrolasinference[127,128,129], variouslyknownasKalmanduality[130,94],
KL control [131] and maximum entropy reinforcement learning [132]. If we further remove pref-
erences, decision-making maximises the entropy of external trajectories. This maximum entropy
principle [46, 47] can be interpreted as least committing to a presupposed external trajectory and
therefore keeping options open [133]. If we reintroduce ambiguity, but ignore preferences, decision-
making maximises intrinsic value or expected information gain [76]. This underwrites Bayesian
experimental design [134] and active learning in statistics [135], intrinsic motivation and artificial
curiosity in machine learning and robotics [136,31737, 138, 139, 140]. This is mathematically equiv-
alent to optimising expected Bayesian surprise and mutual information, which underwrites visual
search [141, 142] and the organisation of our visual apparatus [69, 68, 67]. Lastly, if we remove
intrinsic value, we are left with maximising extrinsic value or expected utility, which underwrites
expectedutilitytheory[66],gametheory,optimalcontrol[143,144]andreinforcementlearning[63].
BayesianformulationsofmaximisingexpectedutilityunderuncertaintyarealsoknownasBayesian
decision theory [145]. The expressions for variational and expected free energy are arranged to
illustrate the relationship between complexity and accuracy, which become risk and ambiguity in
thepathintegralformulation. Thissuggeststhatrisk-aversepoliciesminimiseexpectedcomplexity
or computational cost [137].
taken by the autonomous states.
G(α[τ]) = A(α[τ])
⇒ α[τ] = argminG(α[τ])
α[τ] (39)
⇒ δ G(α[τ]) = 0
α
E[G(α[τ])] = E[A(α[τ])] = H[p(α[τ])]
In short, expected free energy scores the autonomous action of particles that do
not admit noisy dynamics. Expected free energy has a specific form that inherits
from the assumption that the amplitude of particular fluctuations is small, which
is the case for precise articles by definition. Although variational and expected free
energy are formally similar, they are fundamentally different kinds of functionals:
variational free energy is a functional of a density over states, while expected free
energy is a functional of a density over paths. Variational free energy can also be
read as a function of particular states, while expected free energy is a function of
an autonomous path. Finally, variational free energy is a bound on surprisal, while
expected free energy is not a bound—it is the action of autonomous trajectories.
Expected free energy plays a definitive role in active inference, where it can
be regarded as a fairly universal objective function for selecting autonomous paths
of least action. Figure 7 shows that the expected free energy contains terms that
arise in various formulations of optimal behaviour; ranging from optimal Bayesian
design [134] through to control as inference [132, 127]. We refer the reader to
[147, 148, 149, 150, 151] for formal investigations of the relationship between these
formulations.
Equipped with a specification of the most likely autonomous path—in terms of
expected free energy—we can simulate fairly lifelike behaviour, given a suitable gen-
erative model. An example is provided in Figure 9—relying upon the computational
architecture in Figure 8—which illustrates the ambiguity resolving part of the ex-
pected free energy in a simulation of visual epistemic foraging.
This epistemic aspect of expected free energy can be seen more clearly if we re-
place the conditional uncertainty about sensory paths with conditional uncertainty
about particular paths, noting that they are the same by (37). After rearrange-
ment, we can express expected free energy in terms of expected value and expected
information gain [149, 125]:
G(α[τ]) = E [lnq(η[τ] | α[τ])−lnp(η[τ])−lnp(π[τ] | η[τ])]
q(η[τ],s[τ]|α[τ])
Expectedvalue Expectedinformationgain
(40)
(cid:122) (cid:125)(cid:124) (cid:123) (cid:122) (cid:125)(cid:124) (cid:123)
= E [A(π[τ])]−E [D[p(η[τ] | s[τ],α[τ])∥p(η[τ] | α[τ])]
q(s[τ]|α[τ] q(s[τ]|α[τ])
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Bayesoptimaldecisions Bayesoptimaldesign
38
Figure 8: Bayesian mechanics and active inference. This graphic summarises the belief
updating implicit in the minimisation of variational and expected free energy. It describes active
inferencebaseduponautonomouspathsorpoliciesandhasbeenusedinavarietyofapplicationsand
simulations; ranging from games in behavioural economics [152] and reinforcement learning [153,
154] through to language understanding [155] and scene construction [156]. In this setup, actions
solicitasensoryoutcomethatinformsapproximateposteriorbeliefsabouthiddenorexternalstates
of the world—via minimisation of variational free energy under a set of plausible policies (i.e.,
perceptual inference). The approximate posterior beliefs are then used to evaluate expected free
energy and subsequent action (i.e., active inference). A key insight from simulations is that the
form of the generative model can be quite different from the process by which external states
generatesensorystates. Ineffect, thisenablesagents(i.e., particles)toauthortheirownsensorium
in a fashion that has close connections with econiche construction [157]. Please see [158, 124] for
technical details and for a heuristic discussion of how the belief updating could be implemented in
the brain.
This provides a complementary interpretation of expected free energy. The first
term can be construed as expected cost in the sense it is the expected action of par-
ticular paths. This marginal likelihood scores the plausibility of a particle pursuing
this kind of path and is usually interpreted in terms of expected loss (i.e., negative
expected reward or utility) [66, 63], and pragmatic affordance [153, 123]. The second
39
termcorrespondsto theexpecteddivergencebetweenposteriorbeliefsaboutexternal
paths, given autonomous paths, with and without sensory paths. In other words, it
scores the resolution of uncertainty or expected information gain afforded by sensory
trajectories arising from a commitment to an autonomous path. In this sense, it is
sometimes referred to as epistemic affordance [158].
When simulating the kind of planning and active inference afforded by the path
integral formulation, one usually works with discrete state-spaces and belief updat-
ing over discrete epochs of time [124, 123]. One can see this as a coarse-graining
of continuous space-time into discrete space and time bins, where trajectories of
continuous states become sequences of discrete states x[τ] = (x ,...,x ). In dis-
1 τ
crete state-spaces, the generative model is usually formulated as a partially observed
Markov decision process [147, 124, 88, 159], in which the paths of autonomous states
constitute policies, which determine transitions among external states. Plausible
policies can then be scored with their expected free energy and the next action is
selected from the most likely policy α = (α ,...,α )40
0 τ
a = argminG(a,µ)
a
G = E [lnQ (η ,...,η | η ,a)−lnP (η ,...,η | η )−lnP (s ,...,s | η ,...,η )]
Q µ 1 τ 0 1 τ 0 1 τ 1 τ
(cid:88)
≈ E [lnQ (η | a)−lnP (η | η )]−E [lnP (s | η )]
Q µ t t 0 Q t t
(cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125)
t>0
Risk Ambiguity
µ = argminF(s,a,µ)
µ
(cid:88) (cid:88)
F = E [lnQ (η | a)−lnP (η | η ,a)−lnP (η | η ,a)]− E [lnP (s | η )].
Q µ t t+1 t t t−1 Q t t
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
t<τ t≤0
Complexity Accuracy
(41)
The conditional independencies among states implicit in partially observed Markov
decision processes entail the above functional forms for variational and expected
free energies [124, 123]. Crucially, the posterior over external states uses a mean-
field approximation, in which the joint distribution over current and future states
factorisesintomarginaldistributionsateachpointintime[thisapproximationcanbe
finessed by conditioning on previous states, leading to a different (Bethe) variational
free energy [160, 161]]. Note that the discrete version of variational free energy is
a functional of a distribution over a sequence of states and can be regarded as the
discrete homologue of the variational free energy of generalised states in (32).
40See [124, 88] for a derivation of these functional forms in partially observable Markov decision
processes.
40
The ensuing minimisation of free energy can be formulated as gradient flows
following (17)—between the discrete arrival of new sensory input—in a way that
relates comfortably to neuronal dynamics [123, 124, 42]. In some simulations, one
can mix discrete and continuous state-space models by placing the former on top of
the latter, to produce deep generative models that, through active inference, can be
used to simulate many known aspects of computational anatomy and physiology in
the brain [158].
8.1. Summary
Insummary,wenowhaveathandawayofidentifyingthemostlikelyautonomous
trajectory from any initial particular state that can be used to simulate the sentient
behaviour of precise particles that we have associated with biotic systems. The
expected free energy absorbs two aspects of Bayes optimal behaviour into the same
(objective) functional [149]. On a Bayesian reading, the expected information gain
is exactly the same quantity that underwrites the principles of optimal Bayesian
design [134, 76, 163]. In other words, the principles that prescribe the best way
to solicit evidence that reduces uncertainty about various hypotheses. The second
imperative comes from Bayesian decision theory, where the objective is to minimise
some expected cost function expected under a choice or decision [164, 165, 145].
Teleologically, it is worth reflecting upon the differences between the generative
models that underwrite state-wise and path-wise descriptions of Bayesian mechanics,
respectively. For the state-wise formulation (23), the generative model is just a joint
density over external and particular states, supplied by—or supplying—the NESS
density. For the path-wise formulation (34), (41), the generative model is a joint
distribution over the paths of external and sensory states. In other words, there is
an implicit state-space model of dynamics that can be summarised heuristically as
modelling the consequences of an action on external and sensory dynamics. Because
consequences follow causes, the generative model acquires a temporal depth [166,
155]. This depth required to describe any given particle may, of course, be another
characteristic that distinguishes different kinds of particles. In short, the path-wise
formulation describes particles that plan, under a proximal or distal horizon.
9. Conclusion
There are many points of contact between the variational formulation above and
other normative theories of self-organisation and purposeful behaviour. However,
to focus the narrative we have deliberately suppressed demonstrating precedents,
variants and special cases. Figure 3 highlights a few relationships between the free
41
Figure9: Epistemicforaging. Thisfigureshowstheresultsofanumericalsimulationwhereaface
waspresentedtoanagent,whoseresponseswereobtainedbyselectingactivestatesthatminimised
expectedfreeenergyfollowinganeyemovement. Theagenthadthreeinternalimagesorhypotheses
(i.e., internalstates)abouttheexternalstateshemightsample(anuprightface(blue), aninverted
face (magenta) and a rotated face (green)—shown at the bottom). The agent was presented with
sensorysamplesofanuprightfaceandhervariationalposteriorovertheexternalstatewasobtained
by descending variational free energy over a 12ms time bin until the next saccade (i.e., action) was
emitted. This perception-action cycle was repeated eight times. The agent’s eye movements are
shown as red dots at the end of each saccade in the upper row. The corresponding sequence of
eye movements is shown in the upper-left inset, where the red circles correspond roughly to the
proportion of the visual image sampled. These saccades are driven by the salience maps in the
second row, which correspond to the expected free energy as a function of the policies; namely, the
next saccade or where to look next. As expected free energies are defined in terms of trajectories,
it is best to see the locations of on these salience maps as expressing the expected free energy of
a trajectory that ends in that location. Note that these maps change with successive saccades as
variational posterior beliefs become progressively more confident about the external state. Note
also that salience is depleted in locations that were foveated in the previous saccade because these
locations no longer have epistemic affordance or expected information gain (i.e., the ability to
reduce uncertainty in the expected free energy). In neuroscience, this empirical phenomenon is
known as inhibition of return. Oculomotor resp4o2nses are shown in the third row in terms of the
two oculomotor states corresponding to vertical and horizontal eye movements. The associated
portions of the image sampled (at the end of each saccade) are shown in the fourth row. The fifth
row shows the evolution of variational posterior beliefs about external (a.k.a. hidden) in terms of
the log probability they assign to each possible external state (colour coded) and 90% confidence
intervals. The key thing to note is that the credence about the true external state supervenes over
alternative expectations and, as a result, confidence about the category increases (and confidence
intervals shrink to the mode). This illustrates the nature of evidence accumulation when selecting
a hypothesis or percept that best explains sensory states. Please see [162] for further details.
energy principle and various formulations of self-organisation and sentient behaviour.
In brief, this casts things like reinforcement learning and optimal control theory as
optimisingthemarginallikelihoodofparticularstates, conditioneduponagenerative
model supplied by a nonequilibrium steady-state density. It could be argued that
the link between the free energy principle and established formulations is most direct
for synergetics [14, 167] and related treatments of dissipative structures [168]. There
is also a formal and direct link to information theoretic formulations and Bayesian
statistics. Furthermore, the free energy principle can be regarded as dual to the
constrained maximum entropy principle [169], where the constraints are supplied by
the generative model. Please see [150, 148] for a treatment of things like empower-
ment [170], information bottleneck [171] and predictive information [172, 173].
In a similar vein, there are several accounts of optimal behaviour—in both its
epistemic and pragmatic aspects—that are closely related to the path integral for-
mulation of active inference. Some key relationships are highlighted in Figure 7,
such as intrinsic motivation, artificial curiosity [136, 137, 138] and optimal con-
trol [93, 95, 131]. The interesting thing about these other theories is that they
are predicated on optimising some objective function that can be recovered from
expected free energy by taking various sources of uncertainty off the table. This
discloses things like the objective optimised in reinforcement learning and expected
utility theory in behavioural psychology and economics, respectively [174, 65].
This paper has focused on a single particle and has largely ignored the (exter-
nal) context that leads to generalised synchrony among internal and external states.
This synchronisation goes hand-in-hand with existence per se and the Bayesian me-
chanics supplied by the free energy principle. The very fact that this mechanics rests
uponsynchronisationmayspeaktotheemergenceofsynchronisationamongformally
similar particles; namely, populations or ensembles. In other words, an individual
member of an ensemble or ecosystem owes its existence to the ensemble of which it
is a member—at the level of multicellular organisation or indeed its conspecifics in
evolutionary biology [175]. In a similar vein, the context established by supra- and
subordinate scales plays an existential role. In brief, particles at one scale can only
exist if there is a nonequilibrium steady-state density at a higher scale that entails
Markov blankets of Markov blankets [176]. Due to a separation of temporal scales,
much of the self-evidencing at one scale is absorbed into the fast, random fluctua-
tions at the scale above. For example, the fast electrophysiological fluctuations of a
neuron become, random fluctuations from the point of view of neuronal population
dynamics and sensory motor coordination in the brain [177, 178, 179]. This follows
in a straightforward way from applying the apparatus of the renormalisation group.
Please see [5] for further discussion.
43
For brevity and focus, we have not considered applications of the free energy
principle and active inference in detail. A brief review of the literature in this area
will show that that the majority of applications are in the neurosciences [124] with
some exceptions: e.g., [180, 181]. Recently, there has been an increasing focus on
active inference in the setting of machine learning and artificial intelligence [61, 182,
183, 184, 150, 185, 147]. Much of this literature deals with simulation and modelling
and, specifically, scaling active inference to real-world problems. These developments
speak to the shift in focus from the foundational issues addressed in this article to
their applications. It is quite possible that the foundational aspects of the free energy
principlemayalsoshiftassimplerinterpretationsandperspectivesrevealthemselves.
Additional Information
Funding Statement
KF is supported by funding for the Wellcome Centre for Human Neuroimag-
ing (Ref: 205103/Z/16/Z) and a Canada-UK Artificial Intelligence Initiative (Ref:
ES/T01279X/1). L.D. is supported by the Fonds National de la Recherche, Lux-
embourg (Project code: 13568875). N.S. is funded by Medical Research Council
(MR/S502522/1). C.H. is supported by the U.S. Office of Naval Research (N00014-
19-1-2556). K.U. was supported by the PRIME programme of the German Academic
Exchange Service (DAAD) with funds from the German Federal Ministry of Educa-
tion and Research (BMBF). This publication is based on work partially supported
by the EPSRC Centre for Doctoral Training in Mathematics of Random Systems:
Analysis, Modelling and Simulation (EP/S023925/1). The work of GAP was par-
tially funded by the EPSRC, grant number EP/P031587/1, and by JPMorgan Chase
& Co. Any views or opinions expressed herein are solely those of the authors listed,
and may differ from the views and opinions expressed by JPMorgan Chase & Co.
or its affiliates. This material is not a product of the Research Department of J.P.
Morgan Securities LLC. This material does not constitute a solicitation or offer in
any jurisdiction.
Acknowledgements
We would like to thank Maxwell Ramstead—and participants in his International
Physics Reading Group—who went through [5] in the forensic detail, generating
many of the issues and questions addressed in this paper. We thank our reviewer for
providing detailed and helpful feedback that greatly improved the manuscript.
Competing Interests
The authors have no competing interests.
44
Authors’ Contributions
All authors made substantial contributions to conception and design, and writing
of the article; and approved publication of the final version.
References
[1] A. Clark, Whatever next? Predictive brains, situated agents, and the future
of cognitive science, The Behavioral and Brain Sciences 36 (3) (2013) 181–204.
doi:10.1017/S0140525X12000477.
[2] H. Crauel, F. Flandoli, Attractors for random dynamical systems, Probability
Theory and Related Fields 100 (3) (1994) 365–393. doi:10.1007/BF01193705.
[3] L.Arnold,RandomDynamicalSystems,SpringerMonographsinMathematics,
Springer-Verlag, Berlin Heidelberg, 1998. doi:10.1007/978-3-662-12878-7.
[4] J. Hohwy, The Self-Evidencing Brain, Noûs 50 (2) (2016) 259–285. doi:10.
1111/nous.12062.
[5] K. Friston, A free energy principle for a particular physics, arXiv:1906.10184
[q-bio] (Jun. 2019). arXiv:1906.10184.
[6] E. Noether, Invarianten beliebiger Differentialausdrücke, Nachrichten von der
Gesellschaft der Wissenschaften zu Göttingen, Mathematisch-Physikalische
Klasse 1918 (1918) 37–44.
[7] L. Da Costa, K. Friston, C. Heins, G. A. Pavliotis, Bayesian mechanics for
stationary processes, Proceedings of the Royal Society A: Mathematical, Phys-
ical and Engineering Sciences 477 (2256) (2021) 20210518. arXiv:2106.13830,
doi:10.1098/rspa.2021.0518.
[8] K. Friston, C. Heins, K. Ueltzhöffer, L. Da Costa, T. Parr, Stochastic Chaos
and Markov Blankets, Entropy 23 (9) (2021) 1220. doi:10.3390/e23091220.
[9] G. A. Pavliotis, Stochastic Processes and Applications: Diffusion Processes,
the Fokker-Planck and Langevin Equations, no. volume 60 in Texts in Applied
Mathematics, Springer, New York, 2014.
[10] U. Seifert, Stochastic thermodynamics, fluctuation theorems and molecular
machines, Reports on Progress in Physics 75 (12) (2012) 126001. doi:10.
1088/0034-4885/75/12/126001.
45
[11] H. Crauel, Global random attractors are uniquely determined by attracting
deterministic compact sets, Annali di Matematica Pura ed Applicata 176 (1)
(1999) 57–72. doi:10.1007/BF02505989.
[12] C. Jarzynski, Nonequilibrium Equality for Free Energy Differences, Physical
Review Letters 78 (14) (1997) 2690–2693. doi:10.1103/PhysRevLett.78.
2690.
[13] J. Carr, Applications of Centre Manifold Theory, 1982.
[14] H.Haken, Synergetics: AnIntroductionNonequilibriumPhaseTransitionsand
Self-Organization in Physics, Chemistry and Biology, 2nd Edition, Springer
Series in Synergetics, Springer-Verlag, Berlin Heidelberg, 1978. doi:10.1007/
978-3-642-96469-5.
[15] T. Koide, Perturbative expansion of irreversible work in Fokker–Planck equa-
tion$\less$i$\greater$à la$\less$/i$\greater$quantum mechanics, Journal of
Physics A: Mathematical and Theoretical 50 (32) (2017) 325001. doi:10.
1088/1751-8121/aa7af4.
[16] H. Risken, T. Frank, The Fokker-Planck Equation: Methods of Solution and
Applications, 2nd Edition, Springer Series in Synergetics, Springer-Verlag,
Berlin Heidelberg, 1996. doi:10.1007/978-3-642-61544-3.
[17] D. Dürr, A. Bach, The Onsager-Machlup function as Lagrangian for the most
probable path of a diffusion process, Communications in Mathematical Physics
60 (2) (1978) 153–170. doi:10.1007/BF01609446.
[18] D. Arsenović, N. Burić, D. M. Davidović, S. Prvanović, Lagrangian form of
Schrödinger equation, Foundations of Physics 44 (7) (2014) 725–735. doi:
10.1007/s10701-014-9810-4.
[19] K. Krasnov, A gauge-theoretic approach to gravity, Proceedings of the Royal
Society A: Mathematical, Physical and Engineering Sciences 468 (2144) (2012)
2129–2173. doi:10.1098/rspa.2011.0638.
[20] R. Kleeman, A Path Integral Formalism for Non-equilibrium Hamiltonian
Statistical Systems, Journal of Statistical Physics 158 (6) (2015) 1271–1297.
doi:10.1007/s10955-014-1149-x.
46
[21] E. Schrodinger, What Is Life?: With Mind and Matter and Autobiographical
Sketches, reprint edition Edition, Cambridge University Press, Cambridge ;
New York, 2012.
[22] J.Pearl,GraphicalModelsforProbabilisticandCausalReasoning,in: P.Smets
(Ed.), Quantified Representation of Uncertainty and Imprecision, Handbook of
Defeasible Reasoning and Uncertainty Management Systems, Springer Nether-
lands, Dordrecht, 1998, pp. 367–389. doi:10.1007/978-94-017-1735-9_12.
[23] J.Pearl, Causality, 2ndEdition, CambridgeUniversityPress, Cambridge, U.K.
; New York, 2009.
[24] G. Nicolis, I. Prigogine, Self-Organization in Nonequilibrium Systems: From
Dissipative Structures to Order Through Fluctuations, Wiley-Blackwell, New
York, 1977.
[25] R. Graham, Covariant formulation of non-equilibrium statistical thermody-
namics, Zeitschrift für Physik B Condensed Matter 26 (4) (1977) 397–405.
doi:10.1007/BF01570750.
[26] G.L.Eyink,J.L.Lebowitz,H.Spohn,Hydrodynamicsandfluctuationsoutside
of local equilibrium: Driven diffusive systems, Journal of Statistical Physics
83 (3) (1996) 385–472. doi:10.1007/BF02183738.
[27] J. Shi, T. Chen, R. Yuan, B. Yuan, P. Ao, Relation of a New Interpretation of
Stochastic Differential Equations to Ito Process, Journal of Statistical Physics
148 (3) (2012) 579–590. doi:10.1007/s10955-012-0532-8.
[28] Y.-A. Ma, T. Chen, E. B. Fox, A Complete Recipe for Stochastic Gradient
MCMC, arXiv:1506.04696 [math, stat] (Oct. 2015). arXiv:1506.04696.
[29] A. Barp, S. Takao, M. Betancourt, A. Arnaudon, M. Girolami, A Unifying
and Canonical Description of Measure-Preserving Diffusions, arXiv:2105.02845
[math, stat] (May 2021). arXiv:2105.02845.
[30] L. Da Costa, G. A. Pavliotis, The entropy production of stationary diffusions
(Dec. 2022). arXiv:2212.05125.
[31] P. Ao, Potential in stochastic differential equations: Novel construction, Jour-
nal of Physics A: Mathematical and General 37 (3) (2004) L25–L30. doi:
10.1088/0305-4470/37/3/L01.
47
[32] R. Yuan, Y. Ma, B. Yuan, P. Ao, Potential function in dynamical systems
and the relation with Lyapunov function, in: Proceedings of the 30th Chinese
Control Conference, 2011, pp. 6573–6580.
[33] M. Girolami, B. Calderhead, Riemann manifold Langevin and Hamiltonian
MonteCarlomethods,JournaloftheRoyalStatisticalSociety: SeriesB(Statis-
tical Methodology) 73 (2) (2011) 123–214. doi:10.1111/j.1467-9868.2010.
00765.x.
[34] S.-i. Amari, Natural Gradient Works Efficiently in Learning (1998) 36.
[35] W. Kerr, A. Graham, Generalized phase space version of Langevin equations
and associated Fokker-Planck equations, The European Physical Journal B
- Condensed Matter and Complex Systems 15 (2) (2000) 305–311. doi:10.
1007/s100510051129.
[36] K. Friston, K. Stephan, B. Li, J. Daunizeau, Generalised Filtering, Mathemat-
ical Problems in Engineering 2010 (2010) 1–34. doi:10.1155/2010/621670.
[37] K. Friston, L. Da Costa, D. A. R. Sakthivadivel, C. Heins, G. A. Pavliotis,
M. Ramstead, T. Parr, Path integrals, particular kinds, and strange things
(Nov. 2022). arXiv:2210.12761, doi:10.48550/arXiv.2210.12761.
[38] J. M. Lee, Introduction to Topological Manifolds, Springer, New York, NY,
2011.
[39] T. Parr, L. Da Costa, K. Friston, Markov blankets, information geometry and
stochastic thermodynamics, Philosophical Transactions of the Royal Society A:
Mathematical, Physical and Engineering Sciences 378 (2164) (2020) 20190159.
doi:10.1098/rsta.2019.0159.
[40] N. Ay, J. Jost, H. V. Lê, L. Schwachhöfer, Information Geometry, Vol. 64 of
Ergebnisse Der Mathematik Und Ihrer Grenzgebiete 34, Springer International
Publishing, Cham, 2017. doi:10.1007/978-3-319-56478-4.
[41] S. Amari, Information Geometry and Its Applications, Springer, 2016.
[42] L. Da Costa, T. Parr, B. Sengupta, K. Friston, Neural Dynamics under Active
Inference: PlausibilityandEfficiencyofInformationProcessing, Entropy23(4)
(2021) 454. doi:10.3390/e23040454.
48
[43] S.-i. Amari, H. Nagaoka, Methods of Information Geometry, Vol. 191 of Trans-
lations of Mathematical Monographs, American Mathematical Society, 2007.
doi:10.1090/mmono/191.
[44] C. M. Bishop, Pattern Recognition and Machine Learning, Information Science
and Statistics, Springer, New York, 2006.
[45] K. Ueltzhöffer, L. Da Costa, K. J. Friston, Variational free energy, individual
fitness, and population dynamics under acute stress: Comment on “Dynamic
and thermodynamic models of adaptation” by Alexander N. Gorban et al.,
Physics of Life Reviews 37 (2021) 111–115. doi:10.1016/j.plrev.2021.04.
005.
[46] E. T. Jaynes, Information Theory and Statistical Mechanics, Physical Review
106 (4) (1957) 620–630. doi:10.1103/PhysRev.106.620.
[47] A. Lasota, M. C. MacKey, Chaos, Fractals, and Noise: Stochastic Aspects of
Dynamics, Springer-Verlag, 1994.
[48] M. J. Beal, Variational Algorithms for Approximate Bayesian Inference, Ph.D.
thesis, University of London (2003).
[49] J. Winn, C. M. Bishop, Variational Message Passing, Journal of Machine
Learning Research (2005) 34.
[50] C. J. G. Lang, O. Kneidl, M. Hielscher-Fastabend, J. G. Heckmann, Voice
recognition in aphasic and non-aphasic stroke patients, Journal of Neurology
256 (8) (2009) 1303–1306. doi:10.1007/s00415-009-5118-2.
[51] P. E. Kloeden, E. Platen, Numerical Solution of Stochastic Differential Equa-
tions, Stochastic Modelling and Applied Probability, Springer-Verlag, Berlin
Heidelberg, 1992. doi:10.1007/978-3-662-12616-5.
[52] S.J.Schiff,T.Sauer,Kalmanfiltercontrolofamodelofspatiotemporalcortical
dynamics, Journal of Neural Engineering 5 (1) (2008) 1–8. doi:10.1088/
1741-2560/5/1/001.
[53] B. R. Hunt, E. Ott, J. A. Yorke, Differentiable generalized synchronization of
chaos, Physical Review E 55 (4) (1997) 4029–4034. doi:10.1103/PhysRevE.
55.4029.
49
[54] H. H. Jafri, R. K. B. Singh, R. Ramaswamy, Generalized synchrony of coupled
stochastic processes with multiplicative noise, Physical Review E 94 (5) (2016)
052216. doi:10.1103/PhysRevE.94.052216.
[55] V. Buendía, P. Villegas, R. Burioni, M. A. Muñoz, The broad edge of synchro-
nization: Griffiths effects and collective phenomena in brain networks, Philo-
sophicalTransactionsoftheRoyalSocietyA:Mathematical,PhysicalandEngi-
neering Sciences 380 (2227) (2022) 20200424. doi:10.1098/rsta.2020.0424.
[56] K. J. Friston, C. D. Frith, Active inference, communication and hermeneutics,
Cortex; a Journal Devoted to the Study of the Nervous System and Behavior
68 (2015) 129–143. doi:10.1016/j.cortex.2015.03.025.
[57] K. Friston, The free-energy principle: A unified brain theory?, Nature Reviews
Neuroscience 11 (2) (2010) 127–138. doi:10.1038/nrn2787.
[58] C. L. Buckley, C. S. Kim, S. McGregor, A. K. Seth, The free energy principle
for action and perception: A mathematical review, Journal of Mathematical
Psychology 81 (2017) 55–79. doi:10.1016/j.jmp.2017.09.004.
[59] K. J. Friston, J. Daunizeau, S. J. Kiebel, Reinforcement Learning or Ac-
tive Inference?, PLoS ONE 4 (7) (2009) e6421. doi:10.1371/journal.pone.
0006421.
[60] K. J. Friston, J. Daunizeau, J. Kilner, S. J. Kiebel, Action and behavior: A
free-energy formulation, Biological Cybernetics 102 (3) (2010) 227–260. doi:
10.1007/s00422-010-0364-z.
[61] K. Ueltzhöffer, Deep Active Inference, Biological Cybernetics 112 (6) (2018)
547–573. arXiv:1709.02341, doi:10.1007/s00422-018-0785-7.
[62] M. T. Koudahl, B. de Vries, A Worked Example of Fokker-Planck-Based
Active Inference, in: T. Verbelen, P. Lanillos, C. L. Buckley, C. De Boom
(Eds.), Active Inference, Communications in Computer and Information Sci-
ence,SpringerInternationalPublishing,Cham,2020,pp.28–34. doi:10.1007/
978-3-030-64919-7_4.
[63] A. Barto, R. Sutton, Reinforcement Learning: An Introduction, 1992.
[64] E. Todorov, M. I. Jordan, Optimal feedback control as a theory of motor
coordination, Nature Neuroscience 5 (11) (2002) 1226–1235. doi:10.1038/
nn963.
50
[65] P. Bossaerts, C. Murawski, From behavioural economics to neuroeconomics
to decision neuroscience: The ascent of biology in research on human decision
making, CurrentOpinioninBehavioralSciences5(2015)37–42. doi:10.1016/
j.cobeha.2015.07.001.
[66] J. Von Neumann, O. Morgenstern, Theory of Games and Economic Behavior,
Theory of Games and Economic Behavior, Princeton University Press, Prince-
ton, NJ, US, 1944.
[67] L. M. Optican, B. J. Richmond, Temporal encoding of two-dimensional pat-
terns by single units in primate inferior temporal cortex. III. Information
theoretic analysis, Journal of Neurophysiology 57 (1) (1987) 162–178. doi:
10.1152/jn.1987.57.1.162.
[68] R. Linsker, Perceptual Neural Organization: Some Approaches Based on Net-
work Models and Information Theory, Annual Review of Neuroscience 13 (1)
(1990) 257–281. doi:10.1146/annurev.ne.13.030190.001353.
[69] H. B. Barlow, Possible Principles Underlying the Transformations of Sensory
Messages, The MIT Press, 1961.
[70] K. Friston, J. Kilner, L. Harrison, A free energy principle for the brain, Jour-
nal of Physiology-Paris 100 (1-3) (2006) 70–87. doi:10.1016/j.jphysparis.
2006.10.001.
[71] S. A. Kauffman, The Origins of Order: Self-organization and Selection in Evo-
lution, Oxford University Press, 1993.
[72] W. R. Ashby, Principles of the Self-Organizing Dynamic System, The Journal
of General Psychology 37 (2) (1947) 125–128. doi:10.1080/00221309.1947.
9918144.
[73] R. C. Conant, W. R. Ashby, Every good regulator of a system must be a model
of that system, Int. J. Systems Sci. 1 (2) (1970) 89–97.
[74] C. Bernard, Lectures on the Phenomena of Life Common to Animals and
Plants, Thomas, 1974.
[75] D. J. C. MacKay, Free energy minimisation algorithm for decoding and
cryptanalysis, Electronics Letters 31 (6) (1995) 446–447. doi:10.1049/el:
19950331.
51
[76] D. J. C. MacKay, Information Theory, Inference and Learning Algorithms,
sixth printing 2007 edition Edition, Cambridge University Press, Cambridge,
UK ; New York, 2003.
[77] R. Bogacz, A tutorial on the free-energy framework for modelling perception
and learning, Journal of Mathematical Psychology 76 (2017) 198–211. doi:
10.1016/j.jmp.2015.11.003.
[78] H. von Helmholtz, J. P. C. Southall, Helmholtz’s Treatise on Physiological
Optics., Dover Publications, New York, 1962.
[79] R. L. Gregory, Perceptions as hypotheses, Philosophical Transactions of the
Royal Society of London. Series B, Biological Sciences 290 (1038) (1980) 181–
197. doi:10.1098/rstb.1980.0090.
[80] P. Dayan, G. E. Hinton, R. M. Neal, R. S. Zemel, The Helmholtz Machine,
NeuralComputation7(5)(1995)889–904. doi:10.1162/neco.1995.7.5.889.
[81] R. Landauer, Irreversibility and Heat Generation in the Computing Process,
IBM Journal of Research and Development 5 (3) (1961) 183–191. doi:10.
1147/rd.53.0183.
[82] E.Wong,M.Zakai,Ontherelationbetweenordinaryandstochasticdifferential
equations, International Journal of Engineering Science 3 (2) (1965) 213–229.
doi:10.1016/0020-7225(65)90045-5.
[83] A. Lindquist, G. Picci, Realization Theory for Multivariate Stationary Gaus-
sian Processes, SIAM Journal on Control and Optimization 23 (6) (1985) 809–
857. doi:10.1137/0323050.
[84] S. Mitter, G. Picci, A. Lindquist, Toward a theory of nonlinear stochastic
realization, in: Feedback and Synthesis of Linear and Nonlinear Systems, 1981.
doi:10.1007/BFb0006828.
[85] B. Balaji, K. Friston, Bayesian state estimation using generalized coordinates,
in: I. Kadar (Ed.), SPIE Defense, Security, and Sensing, Orlando, Florida,
United States, 2011, p. 80501Y. doi:10.1117/12.883513.
[86] R. Biscay, J. C. Jimenez, J. J. Riera, P. A. Valdes, Local Linearization method
for the numerical solution of stochastic differential equations, Annals of the
Institute of Statistical Mathematics 48 (4) (1996) 631–644. doi:10.1007/
BF00052324.
52
[87] D. R. Cox, H. D. Miller, The Theory of Stochastic Processes, Chapman and
Hall/CRC, London, 1977.
[88] T. Parr, G. Pezzulo, K. J. Friston, Active Inference: The Free Energy Principle
in Mind, Brain, and Behavior, MIT Press, Cambridge, MA, USA, 2022.
[89] K. Friston, J. Mattout, N. Trujillo-Barreto, J. Ashburner, W. Penny, Varia-
tional free energy and the Laplace approximation, NeuroImage 34 (1) (2007)
220–234. doi:10.1016/j.neuroimage.2006.08.035.
[90] K. J. Friston, Variational filtering, NeuroImage 41 (3) (2008) 747–766. doi:
10.1016/j.neuroimage.2008.03.017.
[91] K. J. Friston, N. Trujillo-Barreto, J. Daunizeau, DEM: A variational treatment
of dynamic systems, NeuroImage 41 (3) (2008) 849–885. doi:10.1016/j.
neuroimage.2008.02.054.
[92] H.-A. Loeliger, Least Squares and Kalman Filtering on Forney Graphs, in:
R. E. Blahut, R. Koetter (Eds.), Codes, Graphs, and Systems: A Cele-
bration of the Life and Career of G. David Forney, Jr. on the Occasion of
His Sixtieth Birthday, The Kluwer International Series in Engineering and
Computer Science, Springer US, Boston, MA, 2002, pp. 113–135. doi:
10.1007/978-1-4615-0895-3_7.
[93] H.J.Kappen,Pathintegralsandsymmetrybreakingforoptimalcontroltheory,
Journal of Statistical Mechanics: Theory and Experiment 2005 (11) (2005)
P11011–P11011. doi:10.1088/1742-5468/2005/11/P11011.
[94] E. Todorov, General duality between optimal control and estimation, in: 2008
47th IEEE Conference on Decision and Control, 2008, pp. 4286–4292. doi:
10.1109/CDC.2008.4739438.
[95] B. van den Broek, W. Wiegerinck, B. Kappen, Risk sensitive path integral
control, UAI (2010).
[96] K. Friston, Life as we know it, Journal of The Royal Society Interface 10 (86)
(2013) 20130475. doi:10.1098/rsif.2013.0475.
[97] H.Toutounji, G.Pipa, SpatiotemporalComputationsofanExcitableandPlas-
tic Brain: Neuronal Plasticity Leads to Noise-Robust and Noise-Constructive
Computations, PLOS Computational Biology 10 (3) (2014) e1003512. doi:
10.1371/journal.pcbi.1003512.
53
[98] K. Friston, J. Mattout, J. Kilner, Action understanding and active in-
ference, Biological Cybernetics 104 (1-2) (2011) 137–160. doi:10.1007/
s00422-011-0424-z.
[99] A. G. Feldman, New insights into action-perception coupling, Experimental
Brain Research 194 (1) (2009) 39–58. doi:10.1007/s00221-008-1667-3.
[100] W.Mansell,ControlofPerceptionShouldbeOperationalizedasaFundamental
Property of the Nervous System, Topics in Cognitive Science 3 (2) (2011) 257–
261. doi:10.1111/j.1756-8765.2011.01140.x.
[101] V. Gallese, A. Goldman, Mirror neurons and the simulation theory of mind-
reading, Trends in Cognitive Sciences 2 (12) (1998) 493–501. doi:10.1016/
S1364-6613(98)01262-5.
[102] G. Rizzolatti, L. Craighero, The mirror-neuron system, Annual Review of
Neuroscience 27 (2004) 169–192. doi:10.1146/annurev.neuro.27.070203.
144230.
[103] J. M. Kilner, K. J. Friston, C. D. Frith, Predictive coding: An account of
the mirror neuron system, Cognitive Processing 8 (3) (2007) 159–166. doi:
10.1007/s10339-007-0170-2.
[104] J. Dauwels, On Variational Message Passing on Factor Graphs, in: 2007 IEEE
International Symposium on Information Theory, IEEE, Nice, 2007, pp. 2546–
2550. doi:10.1109/ISIT.2007.4557602.
[105] R. Feynman, Statistical Mechanics: A Set Of Lectures, 1st Edition, Westview
Press, Boulder, Colo, 1998.
[106] D. Andres, On the Motion of Spikes: Turbulent-Like Neuronal Activity in the
Human Basal Ganglia, Frontiers in Human Neuroscience 12 (2018).
[107] G. Deco, M. L. Kringelbach, Turbulent-like Dynamics in the Human Brain,
Cell Reports 33 (10) (2020) 108471. doi:10.1016/j.celrep.2020.108471.
[108] F. Lopes da Silva, Neural mechanisms underlying brain waves: From neural
membranestonetworks, ElectroencephalographyandClinicalNeurophysiology
79 (2) (1991) 81–93. doi:10.1016/0013-4694(91)90044-5.
54
[109] N. Kopell, M. A. Whittington, M. A. Kramer, Neuronal assembly dynamics
in the beta1 frequency range permits short-term memory, Proceedings of the
National Academy of Sciences 108 (9) (2011) 3779–3784. doi:10.1073/pnas.
1019676108.
[110] L. H. Arnal, A.-L. Giraud, Cortical oscillations and sensory predictions, Trends
in Cognitive Sciences 16 (7) (2012) 390–398. doi:10.1016/j.tics.2012.05.
003.
[111] G. Buzsáki, N. Logothetis, W. Singer, Scaling brain size, keeping timing:
Evolutionary preservation of brain rhythms, Neuron 80 (3) (2013) 751–764.
doi:10.1016/j.neuron.2013.10.002.
[112] E. Ott, C. Grebogi, J. A. Yorke, Controlling chaos, Physical Review Letters
64 (11) (1990) 1196–1199. doi:10.1103/PhysRevLett.64.1196.
[113] C.-R. Hwang, S.-Y. Hwang-Ma, S.-J. Sheu, Accelerating diffusions, The
Annals of Applied Probability 15 (2) (2005) 1433–1444. doi:10.1214/
105051605000000025.
[114] C.-R. Hwang, S.-Y. Hwang-Ma, S.-J. Sheu, Accelerating Gaussian Diffusions,
The Annals of Applied Probability 3 (3) (1993) 897–913. doi:10.1214/aoap/
1177005371.
[115] T. Lelièvre, F. Nier, G. A. Pavliotis, Optimal non-reversible linear drift for the
convergence to equilibrium of a diffusion, Journal of Statistical Physics 152 (2)
(2013) 237–274. arXiv:1212.0876, doi:10.1007/s10955-013-0769-x.
[116] N. Aslimani, R. Ellaia, A new hybrid algorithm combining a new chaos op-
timization approach with gradient descent for high dimensional optimization
problems, Computational and Applied Mathematics 37 (3) (2018) 2460–2488.
doi:10.1007/s40314-017-0454-9.
[117] J. Gross, N. Hoogenboom, G. Thut, P. Schyns, S. Panzeri, P. Belin, S. Garrod,
Speechrhythmsandmultiplexedoscillatorysensorycodinginthehumanbrain,
PLoS biology 11 (12) (2013) e1001752. doi:10.1371/journal.pbio.1001752.
[118] G. Buzsáki, A. Draguhn, Neuronal oscillations in cortical networks, Science
(New York, N.Y.) 304 (5679) (2004) 1926–1929. doi:10.1126/science.
1099745.
55
[119] M. Csikszentmihalyi, Flow: The Psychology of Optimal Experience, 1st Edi-
tion, HarperCollins e-books, 2008.
[120] H. Attias, Planning by Probabilistic Inference, in: 9th Int. Workshop on Arti-
ficial Intelligence and Statistics, 2003, p. 8.
[121] M. Botvinick, M. Toussaint, Planning as inference, Trends in Cognitive Sci-
ences 16 (10) (2012) 485–488. doi:10.1016/j.tics.2012.08.006.
[122] R. Kaplan, K. J. Friston, Planning and navigation as active inference, Biolog-
ical Cybernetics 112 (4) (2018) 323–343. doi:10.1007/s00422-018-0753-2.
[123] K. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbeck, G. Pezzulo, Active
Inference: A Process Theory, Neural Computation 29 (1) (2017) 1–49. doi:
10.1162/NECO_a_00912.
[124] L. Da Costa, T. Parr, N. Sajid, S. Veselic, V. Neacsu, K. Friston, Active infer-
enceondiscretestate-spaces: Asynthesis, JournalofMathematicalPsychology
99 (2020) 102447. doi:10.1016/j.jmp.2020.102447.
[125] A. Barp, L. Da Costa, G. França, K. Friston, M. Girolami, M. I. Jordan,
G. A. Pavliotis, Geometric Methods for Sampling, Optimisation, Inference and
Adaptive Agents, Vol. 46, 2022, pp. 21–78. arXiv:2203.10592, doi:10.1016/
bs.host.2022.03.005.
[126] D. Kahneman, A. Tversky, Prospect Theory: An Analysis of Decision under
Risk, Econometrica 47 (2) (1979) 263–291. arXiv:1914185, doi:10.2307/
1914185.
[127] S. Levine, Reinforcement Learning and Control as Probabilistic Inference: Tu-
torial and Review, arXiv:1805.00909 [cs, stat] (May 2018). arXiv:1805.00909.
[128] K. Rawlik, M. Toussaint, S. Vijayakumar, On Stochastic Optimal Control and
Reinforcement Learning by Approximate Inference, in: Twenty-Third Interna-
tional Joint Conference on Artificial Intelligence, 2013.
[129] M. Toussaint, Robot trajectory optimization using approximate inference, in:
Proceedingsofthe26thAnnualInternationalConferenceonMachineLearning,
ICML ’09, Association for Computing Machinery, Montreal, Quebec, Canada,
2009, pp. 1049–1056. doi:10.1145/1553374.1553508.
56
[130] R. E. Kalman, A New Approach to Linear Filtering and Prediction Problems,
Journal of Basic Engineering 82 (1) (1960) 35–45. doi:10.1115/1.3662552.
[131] H. J. Kappen, V. Gómez, M. Opper, Optimal control as a graphical model
inferenceproblem,MachineLearning87(2)(2012)159–182. arXiv:0901.0633,
doi:10.1007/s10994-012-5278-7.
[132] B. Ziebart, Modeling purposeful adaptive behavior with the principle of max-
imum causal entropy., Ph.D. thesis, Carnegie Mellon University, Pittsburgh
(2010).
[133] A. S. Klyubin, D. Polani, C. L. Nehaniv, Keep Your Options Open: An
Information-Based Driving Principle for Sensorimotor Systems, PLOS ONE
3 (12) (2008) e4018. doi:10.1371/journal.pone.0004018.
[134] D. V. Lindley, On a Measure of the Information Provided by an Experi-
ment, The Annals of Mathematical Statistics 27 (4) (1956) 986–1005. arXiv:
2237191.
[135] D. J. C. MacKay, Information-Based Objective Functions for Active Data Se-
lection, Neural Computation 4 (4) (1992) 590–604. doi:10.1162/neco.1992.
4.4.590.
[136] P.-Y. Oudeyer, F. Kaplan, What is Intrinsic Motivation? A Typology of
Computational Approaches, Frontiers in Neurorobotics 1 (2007) 6. doi:
10.3389/neuro.12.006.2007.
[137] J. Schmidhuber, Formal Theory of Creativity, Fun, and Intrinsic Motivation
(1990–2010), IEEE Transactions on Autonomous Mental Development 2 (3)
(2010) 230–247. doi:10.1109/TAMD.2010.2056368.
[138] A. Barto, M. Mirolli, G. Baldassarre, Novelty or Surprise?, Frontiers in Psy-
chology 4 (2013). doi:10.3389/fpsyg.2013.00907.
[139] Y. Sun, F. Gomez, J. Schmidhuber, Planning to Be Surprised: Optimal
Bayesian Exploration in Dynamic Environments, arXiv:1103.5708 [cs, stat]
(Mar. 2011). arXiv:1103.5708.
[140] E. Deci, R. M. Ryan, Intrinsic Motivation and Self-Determination in Human
Behavior, Perspectives in Social Psychology, Springer US, New York, 1985.
doi:10.1007/978-1-4899-2271-7.
57
[141] L. Itti, P. Baldi, Bayesian surprise attracts human attention, Vision research
49 (10) (2009) 1295–1306. doi:10.1016/j.visres.2008.09.007.
[142] T. Parr, N. Sajid, L. Da Costa, M. B. Mirza, K. J. Friston, Generative Models
for Active Vision, Frontiers in Neurorobotics 15 (2021).
[143] R. E. Bellman, Dynamic Programming, Princeton University Press, Princeton,
NJ, US, 1957.
[144] K. J. Åström, Optimal control of Markov processes with incomplete state in-
formation, Journal of Mathematical Analysis and Applications 10 (1) (1965)
174–205. doi:10.1016/0022-247X(65)90154-X.
[145] J. O. Berger, Statistical Decision Theory and Bayesian Analysis, 2nd Edition,
Springer Series in Statistics, Springer-Verlag, New York, 1985. doi:10.1007/
978-1-4757-4286-2.
[146] T. Parr, K. J. Friston, Generalised free energy and active inference, Biological
Cybernetics 113 (5) (2019) 495–513. doi:10.1007/s00422-019-00805-w.
[147] L. Da Costa, N. Sajid, T. Parr, K. Friston, R. Smith, Reward Maximization
ThroughDiscreteActiveInference, NeuralComputation35(5)(2023)807–852.
doi:10.1162/neco_a_01574.
[148] K. Friston, L. Da Costa, D. Hafner, C. Hesp, T. Parr, Sophisticated Inference,
Neural Computation 33 (3) (2021) 713–763. doi:10.1162/neco_a_01351.
[149] N. Sajid, L. Da Costa, T. Parr, K. Friston, Active inference, Bayesian optimal
design, and expected utility, in: The Drive for Knowledge: The Science of
Human Information Seeking, 2022.
[150] D. Hafner, P. A. Ortega, J. Ba, T. Parr, K. Friston, N. Heess, Action and
PerceptionasDivergenceMinimization, arXiv:2009.01791[cs, math, stat](Oct.
2020). arXiv:2009.01791.
[151] B. Millidge, A. Tschantz, A. K. Seth, C. L. Buckley, On the Relationship Be-
tween Active Inference and Control as Inference, in: T. Verbelen, P. Lanillos,
C. L. Buckley, C. De Boom (Eds.), Active Inference, Communications in Com-
puterandInformationScience, SpringerInternationalPublishing, Cham, 2020,
pp. 3–11. doi:10.1007/978-3-030-64919-7_1.
58
[152] T.H.B.FitzGerald, P.Schwartenbeck, M.Moutoussis, R.J.Dolan, K.Friston,
Activeinference,evidenceaccumulation,andtheurntask,NeuralComputation
27 (2) (2015) 306–328. doi:10.1162/NECO_a_00699.
[153] P. Schwartenbeck, T. H. B. FitzGerald, C. Mathys, R. Dolan, M. Kronbich-
ler, K. Friston, Evidence for surprise minimization over value maximization in
choice behavior, Scientific Reports 5 (2015) 16575. doi:10.1038/srep16575.
[154] N. Sajid, P. J. Ball, T. Parr, K. J. Friston, Active Inference: Demystified and
Compared, Neural Computation 33 (3) (2021) 674–712. arXiv:1909.10863,
doi:10.1162/neco_a_01357.
[155] K. J. Friston, R. Rosch, T. Parr, C. Price, H. Bowman, Deep temporal models
andactiveinference, Neuroscience&BiobehavioralReviews90(2018)486–501.
doi:10.1016/j.neubiorev.2018.04.004.
[156] M. B. Mirza, R. A. Adams, C. D. Mathys, K. J. Friston, Scene Construc-
tion, Visual Foraging, and Active Inference, Frontiers in Computational Neu-
roscience 10 (Jun. 2016). doi:10.3389/fncom.2016.00056.
[157] J.Bruineberg, E.Rietveld, Self-organization, freeenergyminimization, andop-
timal grip on a field of affordances, Frontiers in Human Neuroscience 8 (2014).
[158] K. J. Friston, T. Parr, B. de Vries, The graphical brain: Belief propagation and
active inference, Network Neuroscience 1 (4) (2017) 381–414. doi:10.1162/
NETN_a_00018.
[159] R.Smith, K.J.Friston, C.J.Whyte, Astep-by-steptutorialonactiveinference
and its application to empirical data, Journal of Mathematical Psychology 107
(2022) 102632. doi:10.1016/j.jmp.2021.102632.
[160] J. Yedidia, W. Freeman, Y. Weiss, Constructing Free-Energy Approximations
and Generalized Belief Propagation Algorithms, IEEE Transactions on Infor-
mation Theory 51 (7) (2005) 2282–2312. doi:10.1109/TIT.2005.850085.
[161] T. Parr, D. Markovic, S. J. Kiebel, K. J. Friston, Neuronal message passing
using Mean-field, Bethe, and Marginal approximations, Scientific Reports 9 (1)
(2019) 1889. doi:10.1038/s41598-018-38246-3.
[162] K. Friston, R. Adams, L. Perrinet, M. Breakspear, Perceptions as Hypotheses:
Saccades as Experiments, Frontiers in Psychology 3 (2012). doi:10.3389/
fpsyg.2012.00151.
59
[163] S. Balietti, B. Klein, C. Riedl, Optimal design of experiments to identify latent
behavioral types, Experimental Economics 24 (3) (2021) 772–799. arXiv:
1807.07024, doi:10.1007/s10683-020-09680-w.
[164] A.Wald, AnEssentiallyCompleteClassofAdmissibleDecisionFunctions, The
Annals of Mathematical Statistics 18 (4) (1947) 549–555. doi:10.1214/aoms/
1177730345.
[165] L. D. Brown, A Complete Class Theorem for Statistical Problems with Finite
SampleSpaces, TheAnnalsofStatistics9(6)(1981)1289–1300. doi:10.1214/
aos/1176345645.
[166] I. B. Yildiz, K. von Kriegstein, S. J. Kiebel, From Birdsong to Human
Speech Recognition: Bayesian Inference on a Hierarchy of Nonlinear Dynam-
ical Systems, PLOS Computational Biology 9 (9) (2013) e1003219. doi:
10.1371/journal.pcbi.1003219.
[167] H. Haken, J. Portugali, Information and Selforganization: A Unifying Ap-
proachandApplications, Entropy18(6)(2016)197. doi:10.3390/e18060197.
[168] I. Prigogine, Time, Structure, and Fluctuations, Science 201 (4358) (1978)
777–785. doi:10.1126/science.201.4358.777.
[169] D.A.R.Sakthivadivel,Entropy-MaximisingDiffusionsSatisfyaParallelTrans-
portLaw(Jan.2023). arXiv:2203.08119, doi:10.48550/arXiv.2203.08119.
[170] A. Klyubin, D. Polani, C. Nehaniv, Empowerment: A universal agent-centric
measure of control, in: 2005 IEEE Congress on Evolutionary Computation,
Vol. 1, 2005, pp. 128–135 Vol.1. doi:10.1109/CEC.2005.1554676.
[171] N.Tishby,F.C.Pereira,W.Bialek,Theinformationbottleneckmethod,ArXiv
(2000).
[172] S. Still, D. Precup, An information-theoretic approach to curiosity-driven rein-
forcement learning, Theory in Biosciences = Theorie in Den Biowissenschaften
131 (3) (2012) 139–148. doi:10.1007/s12064-011-0142-z.
[173] S. Still, D. A. Sivak, A. J. Bell, G. E. Crooks, Thermodynamics of Prediction,
Physical Review Letters 109 (12) (2012) 120604. doi:10.1103/PhysRevLett.
109.120604.
60
[174] M. M. Botvinick, Y. Niv, A. G. Barto, Hierarchically organized behavior and
its neural foundations: A reinforcement learning perspective, Cognition 113 (3)
(2009) 262–280. doi:10.1016/j.cognition.2008.08.011.
[175] S. Manicka, M. Levin, Modeling somatic computation with non-neural bio-
electric networks, Scientific Reports 9 (1) (2019) 18612. doi:10.1038/
s41598-019-54859-8.
[176] E. R. Palacios, A. Razi, T. Parr, M. Kirchhoff, K. Friston, On Markov blankets
and hierarchical self-organisation, Journal of Theoretical Biology 486 (2020)
110089. doi:10.1016/j.jtbi.2019.110089.
[177] J. A. S. Kelso, Dynamic Patterns: The Self-Organization of Brain and Be-
havior, Complex Adaptive Systems, A Bradford Book, Cambridge, MA, USA,
1995.
[178] G. Deco, V. K. Jirsa, P. A. Robinson, M. Breakspear, K. Friston, The Dynamic
Brain: From Spiking Neurons to Neural Masses and Cortical Fields, PLoS
Computational Biology 4 (8) (2008) e1000092. doi:10.1371/journal.pcbi.
1000092.
[179] J. A. S. Kelso, Unifying Large- and Small-Scale Theories of Coordination,
Entropy 23 (5) (2021) 537. doi:10.3390/e23050537.
[180] K. Friston, M. Levin, B. Sengupta, G. Pezzulo, Knowing one’s place: A free-
energy approach to pattern regulation, Journal of The Royal Society Interface
12 (105) (2015) 20141383. doi:10.1098/rsif.2014.1383.
[181] M. J. D. Ramstead, P. B. Badcock, K. J. Friston, Answering Schrödinger’s
question: A free-energy formulation, Physics of Life Reviews 24 (2018) 1–16.
doi:10.1016/j.plrev.2017.09.001.
[182] A. Tschantz, M. Baltieri, A. K. Seth, C. L. Buckley, Scaling active inference,
arXiv:1911.10601 [cs, eess, math, stat] (Nov. 2019). arXiv:1911.10601.
[183] A. Barp, L. Da Costa, G. França, K. Friston, M. Girolami, M. I. Jordan,
G. A. Pavliotis, Geometric Methods for Sampling, Optimisation, Inference and
AdaptiveAgents,in: GeometryandStatistics,no.46inHandbookofStatistics,
Academic Press, 2022, pp. 21–78.
61
[184] Z. Fountas, N. Sajid, P. A. M. Mediano, K. Friston, Deep active inference
agents using Monte-Carlo methods, arXiv:2006.04176 [cs, q-bio, stat] (Jun.
2020). arXiv:2006.04176.
[185] O. Çatal, T. Verbelen, T. Van de Maele, B. Dhoedt, A. Safron, Robot navi-
gation as hierarchical active inference, Neural Networks 142 (2021) 192–204.
doi:10.1016/j.neunet.2021.05.010.
62