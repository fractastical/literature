RESEARCH ARTICLE NEUROSCIENCE
APPLIED MATHEMATICS
Deep kinematic inference affords efﬁcient and scalable control
of bodily movements
Matteo Priorellia, Giovanni Pezzulob, and Ivilin Peev Stoianova,1 ID
Edited by Peter Strick, University of Pittsburgh Brain Institute, Pittsburgh, PA; received May 31, 2023; accepted October 24, 2023
Performing goal-directed movements requires mapping goals from extrinsic
(workspace-relative) to intrinsic (body-relative) coordinates and then to motor signals.
Mainstream approaches based on optimal control realize the mappings by minimizing
cost functions, which is computationally demanding. Instead, active inference uses
generative models to produce sensory predictions, which allows a cheaper inversion to
the motor signals. However, devising generative models to control complex kinematic
chains like the human body is challenging. We introduce an active inference architecture
that affords a simple but effective mapping from extrinsic to intrinsic coordinates via
inference and easily scales up to drive complex kinematic chains. Rich goals can be
speciﬁed in both intrinsic and extrinsic coordinates using attractive or repulsive forces.
The proposed model reproduces sophisticated bodily movements and paves the way
for computationally efﬁcient and biologically plausible control of actuated systems.
motor control |kinematics |neurocomputational modeling |predictive coding |active inference
How do the brains of living systems support goal-directed movements implementing
purposeful behavior? A standard assumption is that performing goal-directed actions
requires two mappings reﬂecting perceptual and plant control processes (1). First,
it is necessary to map goals and desired movement trajectories speciﬁed in extrinsic
coordinates (e.g., in Cartesian space) into movements speciﬁed in intrinsic coordinates
(e.g., as joint angles), via a process called inverse kinematics. Second, it is necessary to
map the intrinsic state into the forces needed to move all the muscles of the body, via a
process called inverse dynamics.
These two inversions (kinematic and dynamic) are computationally challenging. While
computing the extrinsic representation of a given joint conﬁguration is easy as the
geometric mapping—the so-called direct kinematics—is univocal, ﬁnding the joint angles
that correspond to a particular position is not straightforward. Computing a motor plan
that brings the agent to that posture is even more difﬁcult, since there are multiple
possibilities of how the movement may be realized —and the computational complexity
increases with the Degrees of Freedom (DoF) of the kinematic chain (e.g., a single arm
versus the entire body).
Mainstream theories based on optimal control provide a solution to the two inversions
that rests upon the optimization of a cost function (2–6). However, realizing certain
movements such as handwriting or walking is difﬁcult, since not all trajectories have
well-deﬁned cost functions (7). Furthermore, the required computations are usually
demanding as the model inversion requires considering the effects of the executed actions.
Because the latter are perceived with delays that vary across and within sensory modalities
(8, 9), they need to be compensated using a forward model, which could introduce
additional errors (10).
Active inference offers an alternative scheme that does not require cost functions
(7, 11–15). It proposes that agents are endowed with a generative model specifying
the dynamics of their hidden states (e.g., hand positions over time) and that desired
goals are encoded as priors over the dynamics (e.g., desired hand positions), which
act as attracting states (16). Goal-directed movements are realized by ﬁrst generating
proprioceptive predictions from the hidden states and then minimizing proprioceptive
prediction errors, or the discrepancy between predicted and current sensations. Crucially,
the mapping between proprioceptive predictions and control signals for the muscles is
quite simple and can be implemented with minimal latency using reﬂex arcs in the spinal
cord rather than requiring complex inverse dynamics computations (13). In fact, the
inverse model maps from proprioceptive sensations to actions, not from hidden states
(either in intrinsic or extrinsic coordinates) to actions, as in optimal control (10).
Note that active inference only uses reﬂex arcs as the last stage of control. Complex
motor patterns are not constructed at the level of reﬂex arcs, but rather generated
by high-level dynamics that predict speciﬁc patterns of proprioceptive predictions (17).
Signiﬁcance
How can we realize sophisticated
purposeful movements? While
agile motor control is now
standard in robotics, the
computational machinery
supporting this capacity in
biological organisms remains
controversial. Active inference
theory assumes that actions arise
by inferring limb trajectories from
the desired eﬀects in an
exteroceptive (e.g., visual) space.
Yet, how it enables eﬀicient motor
control is unclear. Our innovative
solution rests on designing a
hierarchical kinematic model that
mimics the body structure and
predicts the exteroceptive eﬀects
of movements. Tasks like drawing
a circle, reaching and avoiding
objects are realized eﬀiciently
because the transformation of
the desired movements from the
exteroceptive domain into limb
trajectories are computed as
deep inference in the model,
using biologically plausible local
computations only.
Author aﬀiliations: aNational Research Council, Institute
of Cognitive Sciences and Technologies, Padova 35137,
Italy; and bNational Research Council, Institute of
Cognitive Sciences and Technologies, Rome 00185, Italy
Author contributions: M.P. and I.P.S. designed research;
G.P. contributed further to the design; M.P. performed
research; M.P. contributed new reagents/analytic tools;
M.P. analyzed data; and M.P., G.P., and I.P.S. wrote the
paper.
The authors declare no competing interest.
This article is a PNAS Direct Submission.
Copyright © 2023 the Author(s). Published by PNAS.
This article is distributed under Creative Commons
Attribution-NonCommercial-NoDerivatives License 4.0
(CC BY-NC-ND).
1To whom correspondence may be addressed. Email:
ivilinpeev.stoianov@cnr.it.
This article contains supporting information online
at https://www.pnas.org/lookup/suppl/doi:10.1073/pnas.
2309058120/-/DCSupplemental.
Published December 12, 2023.
PNAS 2023 Vol. 120 No. 51 e2309058120 https://doi.org/10.1073/pnas.2309058120 1 of 9
Such predictions encode not just positional terms, but also higher
temporal orders (18), allowing the reﬂex arcs to realize sophis-
ticated instantaneous trajectories that comprise, e.g., velocities
and torques (19, 20). Furthermore, prior expectations over the
model dynamics and the entire hierarchy allow immediate ﬁrst-
guess responses, which are eventually reﬁned by subsequent
feedback (1).
While there is increasing interest in using active inference
methods for biological control and robotics (21–29), their
application in realistic settings has been limited so far, given
two fundamental issues. First, realizing generative models that
afford effective kinematic inversions is challenging. State-of-
the-art robotic implementations skip the kinematic inversion
and realize movements by only relying on intrinsic coordinates
(19, 30). Despite their effectiveness, such schemes do not allow
specifying goals in extrinsic coordinates and hence have several
practical limitations. Other approaches embed conventional
optimal control inversions, such as the Jacobian transpose
(10, 31) or the pseudoinverse (32) directly within the dynamics
of the hidden states. This has the disadvantage that extrinsic and
intrinsic coordinates are mixed up and some computations are
duplicated: Extrinsic priors are mapped into intrinsic coordinates,
which in turn generate the extrinsic predictions to be compared
with sensory observations. Hence, the extrinsic generative model
has to be embedded also in the dynamics function.
Second, and crucially, the above systems do not model (i.e.,
maintain probabilistic beliefs about) the entire kinematic chain
of the body to be controlled, but only the end effector. Therefore,
they fall short of addressing naturalistic bodily movements that
require the simultaneous coordination of multiple limbs and
joints within a complex kinematic chain—such as the body
of living organisms—and they cannot account for movement
restrictions due to obstacles.
Here, we introduce an active inference architecture that
resolves the two above limitations and achieves effective and
scalable motor control. First, we show that a generative model
that maps intrinsic into extrinsic coordinates (IE model) affords
an effective kinematic inversion through inference. Second, we
show that replicating the scheme of the IE model to mimic
the hierarchical structure of the agent’s kinematic chain affords
scalable control of bodily movements.
Results
Kinematic Inversion through an Intrinsic–Extrinsic Model.
Active inference can afford effective motor control through a
kinematic generative model that connects two layers of latent
states, encoding intrinsic ( i) and extrinsic ( e) coordinates,
respectively (Fig. 1A). This “Intrinsic–Extrinsic (IE) model” has
two appealing features compared to optimal control models and
previous active inference implementations.
First, the kinematic inversion—or the mapping from extrinsic
to intrinsic coordinates—emerges naturally from inference, by
inverting the generative mapping from joint angles to Cartesian
positions e = ge(i). This means that the latter does not need
to be also speciﬁed in the model’s dynamics function (10, 31, 32).
In short, an extrinsic attractor (e.g., a point to be reached) ﬁrst
drives the inference of the most likely intrinsic hidden state at the
level above. Then, the latter affects movement execution through
the pathway that generates proprioceptive predictions and ﬁnally
motor commands.
Second, this scheme allows specifying priors at both intrinsic
and extrinsic levels simultaneously, which is needed to realize
advanced movements with multiple constraints (e.g., moving the
arm while keeping the hand horizontally). Specifying attractors
at the intrinsic level is also useful for dealing with particular
actions for which this is more natural, or when extrinsic goals are
difﬁcult to deﬁne. For example, grasping actions can be achieved
by specifying priors over object-speciﬁc joint conﬁgurations
(e.g., precision grip for small objects or power grip for large
objects).
A
 B
 C
Fig. 1. Generative models for deep kinematic inference. ( A) The Intrinsic–Extrinsic (IE) generative model. The two hidden states are intrinsic and extrinsic
coordinates, each with its own dynamics. The proprioceptive generative model extracts joint angles from the intrinsic belief, which are used for both posture
inference and movement. At the same time, the exteroceptive model produces a visual prediction (in the simulations reported below, it is approximated by
directly using the absolute position of the hand). Inverse kinematics is performed by inference, via backpropagation of extrinsic prediction errors. On the other
hand, inverse dynamics from proprioceptive predictions to motor control signals is realized through reflex arcs. ( B) The deep hierarchical generative model
that extends the IE model. The deep model is exemplified for the control of a kinematic plant composed of seven blocks arranged hierarchically, from head to
fingers (note that the bottom level is branched, as there are three fingers). Here, the highest (head) level only encodes an extrinsic oﬀset, namely, the initial
position and orientation of the origin’s reference frame. (C) Factor graph of a single level of the deep hierarchical model. Each blockj has the same structure as
the kinematic generative model shown in Panel A, but with slight diﬀerences. In short, intrinsic beliefs (j)
i and extrinsic beliefs (j)
e are linked by a generative
kinematic model ge, and they encode information about a single kinematic level. They generate proprioceptive predictionsp(j)
p and visual predictions p(j)
v only
at their specific level. Intrinsic and extrinsic beliefs have their own dynamics, encoded in the functions f(j)
i and f(j)
e , which predict future trajectories and are
used for goal-directed behavior. Finally, the extrinsic belief at each level j acts as a prior for the level below j +1.
2 of 9 https://doi.org/10.1073/pnas.2309058120 pnas.org
Extending the IE Model to Mimic the Kinematic Chain.The
IE model introduced above affords efﬁcient control but still
performs the direct kinematics in a single step; in other words,
it does not predict the Cartesian coordinates of the entire
kinematic chain (e.g., the body), but only the position of
the end effector (e.g., the hand). However, the IE model can
be extended hierarchically in a straightforward manner, by
noting that the direct kinematics of a complex structure can be
always decomposed into a sequence of identical transformations
(rotations and translations), one for each component of the chain.
We exploit this fact to design a hierarchical generative model,
composed of as many structurally identical blocks as the number
of elements of the kinematic chain where, crucially, each block
is an IE model (Fig. 1 B and C).
This hierarchical architecture affords direct kinematics by
iterating the same operation across all the levels of the kinematic
chain, with biologically plausible local message passing. Specif-
ically, the Cartesian position of the tip of the body segment at
level j is generated from the intrinsic belief over the body segment
at the same level and the extrinsic belief over the body segment
at the level above j −1. Conversely, the (inverse kinematics)
inference of the extrinsic belief at level j requires messages from
all the extrinsic beliefs at the level below j + 1. In fact, as shown
in Fig. 1B, multiple ﬁngers are attached to the same joint at the
bottom level (the wrist). The ramiﬁcations can be easily treated
by assuming that the inference of the hidden states of the block
at level j uses the average of the prediction errors generated by all
the blocks at the level belowj +1 (33). SeeMaterials and Methods
for more information.
Overall, this biologically plausible form of local message
passing is the same as in hierarchical Predictive Coding for
perceptual inference (34, 35). Here, top-down and bottom-up
messages across blocks encode kinematic predictions and kine-
matic prediction errors, respectively.
Defining Goals for Movement using Attractive or Repulsive
Forces. In active inference, goals for movements can be either
imposed as a higher-level prior or embedded into the dynamics
function at the same level. The latter approach is usually based
on attractors that linearly minimize the distance between the
current and desired states. To generate a dynamic goal, the desired
state can also depend on some components of the belief itself
through a function that embeds movement intentions (16, 36)—
see Materials and Methods.
The deep kinematic model introduced here permits formu-
lating various kinds of goals at intrinsic and extrinsic levels; for
example, the desired angle ∗ of a joint, the desired absolute
position (x∗, y∗), or orientation ∗of a limb. In addition, it is
possible to realize avoidance goals, as shown in Materials and
Methods. Like attractive forces, repulsive forces are speciﬁed for
each block of the kinematic chain, which ensures that every
segment (rather than just the end effector) is pushed away
from an obstacle. Finally, it is possible to deﬁne multiple goals
simultaneously—such as reaching a particular position with
the elbow while maintaining a vertical hand orientation—by
combining multiple attractive and/or repulsive forces at different
levels. This makes the deep model scalable and versatile, as we
show in the next section.
Applications of Deep Kinematic Inference.
Reaching task.We demonstrate the capacity of the deep kine-
matic model in various motor tasks of increasing complexity.
We start from the simple reaching task illustrated in Fig. 2 A,
which consists of moving a 4R robotic arm (blue) with realistic
A
B
C
Fig. 2. Results. ( A) Simulation setup: a 4R robotic arm with realistic joint limits reaching a static target (red circle). The trajectory of each joint is shown
with blue lines. ( B) Comparison between the deep kinematic model (deep), the simpler IE model (IE), and two standard active inference controllers based
on Jacobian transpose (transp) and pseudoinverse (pinv). The blue and red bars denote the performance of the models during perceptual inference and
reaching, respectively. Note that to better probe the model’s ability to perform perceptual inference, we only allow the model to use visual observations, but
not proprioceptive observations during this phase (however, the model can still use proprioceptive observations for reaching). ( C) Evolution over time of the
diﬀerence between true and estimated end eﬀector positions (blue line), and between true and estimated lengths of the body segments (green line), aggregated
over 1,000 trials during inference only. The dashed gray line represents the minimum distance defining a successful inference.
PNAS 2023 Vol. 120 No. 51 e2309058120 https://doi.org/10.1073/pnas.2309058120 3 of 9
joint limits, to reach a static object (red). Here, we compare
the performance of the deep kinematic model (deep) with the
simpler IE model (IE) and two alternative controllers based on
the Jacobian transpose (transp) and the pseudoinverse (pinv). See
SI Appendixfor more details about the latter two controllers.
The simulation results illustrated in Fig. 2 B shows the
performance of the four models for 1,000 trials, with 500 steps for
trial. For each trial, the beliefs of the models are initialized with
random joint angles and segment positions (a more challenging
scenario than starting from congruent intrinsic–extrinsic beliefs).
Furthermore, a random target location is sampled and set as the
reaching goal for the end effector. We evaluate the performance
of the four models with regard to both perceptual inference (blue
bars) and reaching ability (red bars), using various metrics (see
Fig. 2B and Materials and Methods).
The performance of the four models is near-optimal during
both perceptual inference and reaching. The rare failures are
trials in which the models ﬁnd impossible trajectories and
therefore cannot reach the target conﬁgurations (note that we
did not include any prior over the direction of movement). The
performance of the deep model is on par with the other models.
The slightly lower performance compared to the IE model is due
to the deep model requiring more time to propagate messages
across levels, resulting in failed trials when the time steps are
limited. The Jacobian pseudoinverse method performs slightly
better than the other models, but the transpose method has a
much higher ﬁnal error. Nevertheless, in all cases, the average ﬁnal
error is below the minimum distance to consider a trial successful.
Learning and adaptation of the kinematic chain.Unlike state-of-
the-art implementations, the deep model includes beliefs about
the length of the body segments and can infer them over
time, based on sensory observations. This may afford the rapid
adaptation of the agent to changes in the kinematic chain, e.g.,
when using a tool that increases the length of the last segment,
or when a new joint is added to a speciﬁc position. To assess this
capability, we performed an experiment in which the beliefs about
both angles and body segments are randomly initialized. We
evaluated the task over 1,000 trials, by comparing the estimated
positions of every segment (computed from the joint angles
belief) and the estimated lengths with the real values of the same
variables. The simulation results illustrated in Fig. 2C show that
the deep model successfully infers the length of its body segments
(green line) in addition to inferring its joint angles (blue line),
even within a single trial.
In sum, these results show that the deep model is not less
efﬁcient than previous implementations and that in addition
to matching their performance, it also affords self-modeling.
The next simulations will show that the deep model can be
additionally scaled up to account for complex kinematic chains.
Deep inference.Fig. 3 shows an evaluation of the deep kinematic
model using the same robotic arm as in Fig. 2, but equipped with
an increasing number of joints, all having equal length. This
simulation was assessed on 1,000 trials, lasting 2,000 time steps
for trial. Since we removed the angle limits, the performances are
optimal for inference and near-optimal for action. Some trials fail,
because the time needed to backpropagate the attractor toward
the deepest levels exceeds the time limits, affecting both accuracy
and mean error.
More complex control tasks.In addition to the previous simu-
lations, the deep model can also control simpler (e.g., arm-like)
and more complex (e.g., body-like) structures in a variety of tasks,
which require simultaneously tracking a dynamic object (in red)
while avoiding another dynamic object (in green) (Fig. 4A), mak-
ing lateral movements while maintaining a vertical orientation of
the last segment (Fig. 4 B), performing circular movements in
the Cartesian space (Fig. 4 C), avoiding a dynamic object with
a human-like body (Fig. 4 D), reaching simultaneously multiple
targets with different limbs of a human-like body (Fig. 4E), or of a
tree-like body with 28 DoF and multiple ramiﬁcations (Fig. 4F);
see SI Appendix for more information about these and various
other control tasks.
Crucially, the same deep model can achieve all these (and
other) tasks by simply specifying different goals, using attractive
or repulsive forces, or a combination of both, without having to
deﬁne ad hoc cost functions. Compared to other approaches,
the deep model is therefore particularly easy to scale up to
address complex kinematic structures and control problems with
multiple goals.
Fig. 3. Deep inference. Comparison between hierarchical models with increasing DoF (here, kinematic depth). Inference (Top) and reach (Bottom) simulations.
4 of 9 https://doi.org/10.1073/pnas.2309058120 pnas.org
A
 D
B
 E
C
 F
Fig. 4. Applications. Track and avoid ( A), maintain orientation ( B), perform circular trajectory ( C), avoid with a full human body ( D), reach multiple targets
with a full human body ( E), and with a more complex kinematic tree ( F). The trajectories in the first panel represent the hand-obstacle distance (red line), the
hand-target distance (green line), and the minimum distance that the target is considered to be reached (dotted blue line). Instead, the trajectories in the next
two panels show the absolute orientation of every joint (in particular, the purple line is the orientation of the hand). More information about the specific tasks
and other applications can be found in SI Appendix.
Discussion
Active inference proposes that goal-directed movements are
realized by producing predictions with a generative model of
the coupled agent-environment system and then minimizing
the errors between predicted and current sensations. Despite
its strong theoretical appeal (1), this framework has enjoyed
limited applications in motor control and robotics, given the
challenge of specifying appropriate generative models to map
different (extrinsic and intrinsic) coordinates of movement, and
to control complex kinematic structures such as the human body.
Here, we show that a generative (IE) model that maintains
distinct beliefs over intrinsic and extrinsic coordinates affords
effective control of goal-directed movements, because it allows
deﬁning both intrinsic and extrinsic goals as attractive (or
repulsive) states and solving inverse kinematics via (active)
inference, which is typically challenging in other frames like
optimal control. Furthermore, we show that a deep hierarchical
extension of the IE scheme drastically improves its scalability. In
particular, replicating the same IE generative model for each block
of the kinematic chain simpliﬁes the computations of the direct
kinematics and permits controlling complex kinematic structures
that require the simultaneous coordination of multiple segments.
The proposed deep hierarchical architecture has four main
advantages compared to optimal control schemes or state-of-
the-art models in the active inference literature. First, it is
efﬁcient: Performing the kinematic inversion through inference
drastically reduces its computational cost. Second, it is scalable:
It is possible to design generative models for sophisticated
kinematic chains by simply connecting multiple IE models. Since
the overall generative model always mimics the entire kinematic
chain, adding or removing new segments (e.g., to model tool
use) simply requires adding or removing the corresponding
blocks. Third, it affords self-modeling (37) by continuously
inferring the kinematic structure online and rapidly readapting
to changes in limb lengths. Fourth, it affords a biologically
plausible form of inference that only uses local message passing
and asynchronous computations, akin to hierarchical Predictive
Coding for perception (11, 34, 35, 38).
The behavior of the deep kinematic model, which replicates
the same computational block across various levels, bears some
analogies with deep neural networks. It is common to use the
latter (e.g., Variational Autoencoders) as generative models for
active inference agents (16, 30). Despite their effectiveness, the
deep networks are treated as black boxes during inference: The
belief over hidden states only receives a single gradient and
it is unaware of the internal computations performed by the
backpropagation algorithm. This has the downside that the
weights of the generative model have to be learned a priori
and remain constant throughout the active inference process
—hence, the agent cannot adapt them when it receives novel
sensory observations. Furthermore, the agent has no control
over the dynamics of the generative model and cannot control
the intermediate levels of the deep network toward potentially
preferred states. In other words, almost all the hard work is
delegated to the deep network and the only job left to the active
PNAS 2023 Vol. 120 No. 51 e2309058120 https://doi.org/10.1073/pnas.2309058120 5 of 9
inference agent is inferring the highest level of the hidden states.
In contrast, one appeal of Predictive Coding methods is that they
can simultaneously perform hidden state inference and learning
(11, 34, 35, 39). Designing a hierarchical structure that uses the
same rules of prediction error minimization throughout the levels
means that the agent can constantly modify its internal models
to match both sensory observations and prior expectations.
In this study, we focused on the theoretical aspects of
controlling a complex hierarchical structure with multiple con-
straints. For this reason, we used a relatively simple velocity-
controlled system, without considering higher temporal orders.
This implies that the dynamics functions illustrated lack some
of the constraints required to smoothly actuate a real system.
However, such constraints can be easily included in the active
inference scheme used here, by imposing priors at speciﬁc levels
of the hierarchy. We provided one example in the Results section,
when we discussed how the system can incorporate speciﬁc
affordances, but other useful examples can be made. Given
the simple analytical form of the kinematic model, one can
achieve movements with the desired smoothness by expanding
the generalized state space and deﬁning dynamics functions of
increasing temporal orders, as we did for our velocity-controlled
scheme. As a result, jerk minimization can be realized by
maintaining an intrinsic belief with temporal orders up to the
fourth and imposing a limit at the last level (19). Similarly,
an attractor could be deﬁned at the third level, setting speciﬁc
torques to a joint and allowing one to simulate advanced limb
dynamics (20); singularities can also be avoided by predicting
their inﬂuence in advance and embedding them at the intrinsic
level (12). Of note, there is a growing literature about the study
of dynamics and stability properties of active inference agents
(40), which have been used to design robust robotic systems
operating in volatile environments (41, 42). A useful direction of
research would be to combine such studies with the features of a
hierarchical kinematic model that were presented here.
Advanced movements beyond reaching and avoiding tasks—
such as those requiring high-level planning —may be achieved
through a hybrid scheme (18), in which a discrete model plans
an optimal sequence of actions that is in turn realized by a
continuous model like the one exempliﬁed in this study. In
particular, the hybrid scheme allows the agent to model the
environment at a more abstract level, realizing multistep reaching
movements (43), object manipulation tasks (44), smooth goal-
directed movements in animal behavior (45), and planning
trajectories that avoid the local minima arising with artiﬁcial
potential ﬁelds. We plan to simulate these and other advanced
capabilities of hybrid active inference in future works. While
local message passing may seem restricting, it does not hinder
but rather helps achieve the high-level simultaneous coordination
of all limbs. Indeed, a discrete model could still have access to
and impose priors over every element of the kinematic chain,
affording synchronized behavior (44). Then, the hierarchical
structure of the generative model improves the movements that
the agent intends to realize, by predicting the exchange of forces
that will be produced locally between every couple of joints in
the generative process.
Finally, although we exempliﬁed a deep kinematic inference for
the control of human body movements, the same design could be
used to control other, potentially more sophisticated structures,
composed of multiple ramiﬁcations. Generalizing the hierarchical
connections of each level to account for arbitrary transformations
between reference frames—as described in ref. 46—could be
used, e.g., to estimate the depth of an object based on different
camera projections. The deep kinematic inference approach can
therefore pave the way for the efﬁcient and biologically plausible
control of general actuated systems.
Materials and Methods
Hierarchical Active Inference.The core of active inference is the use of
a generative model to generate predictions and minimize any prediction
error resulting from discrepancies between predictions and observations.
The generative model depends on three elements encoded in generalized
coordinates of increasing temporal orders (e.g., position, velocity, acceleration,
etc.): hidden states ˜x, hidden causes ˜v and sensory signals ˜s. These elements
are related by a nonlinear system specifying the generation of sensory signals
and the evolution of latent states over time:
˜s = ˜g(˜x) +ws,
D˜x = ˜f(˜x, ˜v) +wx,
[1]
where D is a differential operator that shifts all the temporal orders by one,
i.e.,: D˜x = [x′, x′′, x′′′, . . .], while ws and wx are noise terms assumed to be
sampled from a Gaussian distribution (see refs. 11 and 47 for more details). The
associated joint probability is factorized into independent distributions:
p(˜s, ˜x, ˜v) =p(˜s|˜x)p(˜x|˜v)p(˜v), [2]
where each distribution is Gaussian:
p(˜s|˜x) =N(˜g(˜x), ˜−1
s ),
p(D˜x|˜v) =N(˜f(˜x, ˜v), ˜−1
x ),
p(˜v|) =N(, ˜−1
v ),
[3]
expressed in terms of precisions or inverse variances˜s, ˜x, and ˜v. Following
a variational inference approach (48), these distributions are inferred through
approximate posteriors q(˜x) and q(˜v). Minimizing the variational free energy
(VFE) F, deﬁned as the difference between the KL divergence of the (real and
approximate) posteriors and the log evidence:
F = E
q(˜x)
[
ln q(˜x)
p(˜x, ˜y)
]
= E
q(˜x)
[
ln q(˜x)
p(˜x|˜y)
]
−ln p(˜y), [4]
reduces to the minimization of prediction errors. As a result, the updates of the
beliefs ˜and ˜respectively over the hidden states and hidden causes become:
˙˜−D˜= −∂F = ∂ ˜gT ˜s ˜"s + ∂˜f
T ˜˜" −DT ˜˜",
˙˜−D˜= −∂F = ∂˜f
T ˜˜" −˜˜"v,
[5]
where ˜"s, ˜", and ˜" are respectively the prediction errors of sensory signals,
dynamics, and priors:
˜"s = ˜s −˜g( ˜),
˜" = D˜−˜f( ˜, ˜),
˜" = ˜−,
[6]
A simple formulation of active inference can deal with several tasks, but its
main strength relies on a hierarchical structure that allows the brain to learn
the inherently hierarchical relations between sensory observations and their
causes (18).
This structure can be easily scaled up by linking every hidden cause with
another generative model; thus, the prior becomes the prediction from the layer
above, while the observation becomes the likelihood of the layer below:
˙˜(j) = D˜(j) + ∂ ˜g(j)T ˜(j)
 ˜"(j)
 + ∂˜f(j)T ˜(j)
 ˜"(j)
 −DT ˜(j)
 ˜"(j)
 ,
˙˜(j) = D˜(j) + ∂˜f(j)T ˜(j)
 ˜"(j)
 −˜(j−1)
 ˜"(j−1)
 ,
[7]
6 of 9 https://doi.org/10.1073/pnas.2309058120 pnas.org
where:
˜"(j)
 = D˜(j)
 −˜f(j)( ˜(j), ˜(j)),
˜"(j)
 = ˜(j+1)
 −˜g(j)( ˜(j)).
[8]
On the other hand, action is realized by minimizing the proprioceptive
component of the VFE with respect to the motor control signals a:
˙a = −∂aFp = −∂a˜sp ˜p ˜"p, [9]
where ∂asp is the partial derivative of proprioceptive observations with respect
to the motor control signals, ˜p are the precisions of proprioceptive generative
models, and ˜"p are the generalized proprioceptive prediction errors:
˜"p = ˜sp −˜gp( ˜). [10]
Kinematic Models: Belief Update.In the IE model (shown in SI Appendix,
Fig. S1), the intrinsic belief i encodes every joint angle in parallel while the
extrinsic belief e only encodes the Cartesian position of the end effector.
Proprioceptive and visual observations are indicated by sp and sv. For a 2R
robotic arm, the intrinsic and extrinsic beliefs are related by:
i =
[1 2
]
,
e =
[xe ye
]
= ge(i),
=
[l1c1 + l2c12 l1s1 + l2s12
]
,
[11]
where ge is a generative model performing forward kinematics, and we used a
compact notation to indicate the sine and cosine of the angles:
c1 = cos(1)
s1 = sin(1)
c12 = cos(1 + 2) =c1c2 −s1s2,
s12 = sin(1 + 2) =c1s2 + s1c2. [12]
The update equation for the intrinsic belief is then a combination of
proprioceptive likelihood, extrinsic likelihood, and intrinsic attractor dynamics:
˙˜i = D˜i −∂i F =
[
′
i + ∂gTpp"p + ∂gTee"e + ∂fT
i i "i
−i "i
]
,
[13]
where gp is the proprioceptive likelihood function, while "p and "e are the
proprioceptive and kinematic prediction errors:
"p = sp −gp(i),
"e = e −ge(i).
[14]
The form of the dynamics functionfi is explained in the following sections. Note
that, although the intrinsic belief includes components up to the ﬁrst order, the
proprioceptive generative model only produces prediction over the 0th order
(i.e., position). The kinematic inversion is performed through the gradient ∂ge:
∂ge =
[
−l1s1 −l2s12
l1c1 + l2c12
]
. [15]
Similarly, the update for the extrinsic belief is a combination of intrinsic prior,
visual likelihood, and extrinsic attractor dynamics:
˙˜e = D˜e −∂e F =
[
′e −e"e + ∂gTv v"v + ∂fT
ee "e
−e "e
]
, [16]
where gv is the visual likelihood function, and "v is the visual prediction error:
"v = sv −gv(e). [17]
As regards the motor control signals, they are computed as in Eq. 9, but only by
minimizing the 0th-order proprioceptive prediction error "p:
˙a = −Δtp"p, [18]
where we approximated the gradient ∂asp by a time constant Δt (49), since the
agent is velocity-controlled.
Concerning the deep kinematic model, if we consider a simple 2D arm, each
block is composed of an intrinsic belief over pairs of joint angles and segment
lengths (j)
i = [(j), l(j)] and an extrinsic belief over the position of the
segment’s extremity and its absolute orientation(j)
e = [x(j), y(j), (j)]. The
resulting kinematic generative model is:
(j)
e = ge((j)
i , (j−1)
e ) =


x(j−1) + l(j)c(j)
,
y(j−1) + l(j)s(j)
,
(j−1) + (j)

. [19]
The update of the intrinsic belief (Eq. 20) is equivalent to the IE model.
˙˜(j)
i =

′(j)
i + ∂gTp(j)
p "(j)
p + ∂i gTe(j+1)
e "(j+1)
e + ∂f(j)T
i (j)
i "(j)
i
−(j)
i "(j)
i

.
[20]
However, "(j)
p now only encodes the prediction error of a single joint. Further,
the gradient of the kinematic generative model with respect to the intrinsic belief
is simpler, since it only depends on the intrinsic components of that level:
∂ge
∂(j)
i
=
[
∂ge
∂lge
]
=

−l(j)s(j)
, l(j)c(j)
, 1
c(j)
, s(j)
, 0

. [21]
Note that the second row of the gradient in Eq.21 allows inferring and learning
segment lengths.
The update of the extrinsic belief (Eq. 22) still includes every component of
the IE model (although separately for each joint), but with the addition of the
extrinsic likelihood from the next layer ∂ege, which in this case is the sum of all
the segments it is attached to.
˙˜(j)
e =
[
′(j)
e −(j)
e "(j)
e + ∑
m ∂e gTe(j+1,m)
e "(j+1,m)
e + ∂gTv (j)
v "(j)
v + ∂f(j)T
e (j)
e "(j)
e
−(j)
e "(j)
e
]
. [22]
The gradient of this new term connects every layer in the hierarchy since
intrinsic beliefs communicate with their extrinsic predictions by:
∂ge
∂(j)
e
=


∂xge
∂yge
∂ge

=


1 0 0
0 1 0
−l(j)s(j)
, l(j)c(j)
, 1

. [23]
Overall, the main differences between the IE model and the basic block of the
hierarchical model are i) in the former, a single level encodes J joint angles in
parallel (where J is the number of joint angles), while the latter is composed ofJ
levels each encoding a single joint angle; ii) in the basic block of the hierarchical
model, there is an additional connection from the extrinsic belief e of level
j −1 to the extrinsic belief of level j.
Ramifications. If we consider a ramiﬁcation with M extrinsic outputs
(j+1,m)
e = ge((j+1)
i , (j)
e ), the update equation for the parent node
(j)
e is proportional to:
˙(j)
e ∝
M∑
m
∂e gT
e(j+1,m)
e "(j+1,m)
e , [24]
PNAS 2023 Vol. 120 No. 51 e2309058120 https://doi.org/10.1073/pnas.2309058120 7 of 9
where "(j+1,m)
e is the extrinsic prediction error of block(j+1, m)and (j+1,m)
e
is the corresponding precision. The latter thus weighs the contribution for each
branch of the level.
Defining Attractive Goals and Repulsive Forces.Goals can be ﬂexibly
formulated at both intrinsic and extrinsic levels through an intention function
i() that linearly combines the current belief with biases h∗to deﬁne the
desired future state ∗(16):
∗= i() =H+ h∗. [25]
In brief, the matrix H performs a transformation of the current belief:
Manipulating and combining only speciﬁc components affords a dynamic
behavior (e.g., reaching a moving target), while using an identity transformation
for the other components lets them free to change since their prediction error
would be zero. Instead, the vector h∗is used to impose a static conﬁguration.
This function could specify, for example, the desired angle ∗of a joint (i.e.,
an intrinsic goal), the desired absolute position (x∗, y∗) or the orientation ∗
of a limb (i.e., extrinsic goals):
i(j)
 ((j)
i ) =
[
∗ l(j)
]
,
i(j)
p ((j)
e ) =
[
x∗ y∗ (j)
]
,
i(j)
 ((j)
e ) =
[
x(j) y(j) ∗
]
.
[26]
All these functions may be realized by a linear combination of the quantities
deﬁned in Eq. 25. Imposing a desired angle ∗would be achieved by:
H =
[
0 0
0 1
]
h∗=
[∗ 0]
. [27]
Beyond static reaching, it is possible to realize a dynamic behavior through the
matrix H, e.g., by imposing that the x coordinate of the end effector will match
the y coordinate:
H =


0 1 0
0 1 0
0 0 1

 h∗=
[0 0 0 ]
. [28]
The same mechanism may be used to track a moving target, which is constantly
inferred through visual observations, as done in ref. 16.
Attractors are then embedded into the dynamics function, which linearly
minimizes the distance between the desired and current states, i.e., fa() =
kaea, where ka is an attractive gain andea = ∗−. For simplicity, we did not
consider the hidden causes of Eq. 1, thus the dynamics function only depends
on the hidden states.
In turn, following the artiﬁcial potential ﬁelds theory, repulsive forces can be
deﬁned as
fr () =
{
kr ·(1/−1/||er ||) ·er /||er ||3, if ||er ||≤ 
0, otherwise, [29]
where kr is a repulsive gain, is the range of inﬂuence of the repulsive force,
er = # −is the difference between a repulsive state # and the belief,
and # is deﬁned ﬂexibly in the same way as the goal state∗. At this point, one
can linearly combine attractive and repulsive forces into the dynamics function
of a single level in order to achieve a complex behavior—e.g., reaching a target
with the end effector while avoiding an obstacle:
′=
∑
n
fn(). [30]
Note that these dynamics functions are always optimistically biased toward the
goal states. Although not problematic in our case, a more advanced controller
such as the one proposed in ref. 50 would provide unbiased state estimates
which may be critical for realistic settings (e.g., for handling collisions) and with
adaptable precisions.
Assessment Metrics.The three metrics used to evaluate perceptual inference
are i) perception accuracy: success in ﬁnding a joint conﬁguration corresponding
to the true target location within 8 pixels; ii) perception error: L2 distance
between the true and estimated target positions at the end of the trial; iii)
perception time: number of time steps needed to successfully estimate the target
position.
The three metrics used to evaluate reaching are iv) reach accuracy: success
in approaching the target within 8 pixels; v) reach error: L2 end effector-target
distance at the end of the trial; vi) reach time: number of time steps needed for
the end effector to reach the target in successful trials. Note that the reaching
task is more challenging than the inference task, since it requires inferring the
ﬁnal arm conﬁguration based on information about only the position of the last
segment.
Data, Materials, and Software Availability.Method data have been de-
posited in GitHub (https://github.com/priorelli/deep-kinematic-inference) (51).
ACKNOWLEDGMENTS. This research received funding from the European
Union’s Horizon H2020-EIC-FETPROACT-2019 Programme for Research and
Innovation under Grant Agreement 951910 to I.P.S., the European Union’s
Horizon 2020 Framework Programme for Research and Innovation under
Grant Agreement 945539 to G.P., the European Research Council under the
Grant Agreement 820213 to G.P., and the Italian Ministry for Research MIUR,
under Grant Agreements PRIN 2017KZNZLN to I.P.S. and PE0000013-FAIR and
IR0000011-EBRAINS-Italy to G.P. The GEFORCE Quadro RTX6000 and Titan GPU
cards used for this research were donated by the NVIDIA Corporation. The funders
had no role in study design, data collection and analysis, decision to publish, or
preparation of the manuscript.
1. M. Floegel, J. Kasper, P. Perrier, C. A. Kell, How the conception of control inﬂuences our
understanding of actions. Nat. Rev. Neurosci.24, 313–329 (2023).
2. E. Todorov, Optimality principles in sensorimotor control. Nat. Neurosci.7, 907–915 (2004).
3. J. Diedrichsen, R. Shadmehr, R. B. Ivry, The coordination of movement: Optimal feedback control
and beyond. Trends Cogn. Sci.14, 31–39 (2010).
4. R. Shadmehr, M. A. Smith, J. W. Krakauer, Error correction, sensory prediction, and adaptation in
motor control. Annu. Rev. Neurosci.33, 89–108 (2010).
5. D. McNamee, D. M. Wolpert, Internal models in biological control. Annu. Rev. Control, Rob., Auton.
Syst. 2, 339–364 (2019).
6. R. F. Stengel, Optimal Control and Estimation(Courier Corporation, 1994).
7. K. Friston, What is optimal about motor control? Neuron 72, 488–498 (2011).
8. D. W. Franklin, D. M. Wolpert, Computational mechanisms of sensorimotor control. Neuron 72,
425–442 (2011).
9. M. M. Hayhoe, Vision and action. Annu. Rev. Vis. Sci.3, 389–413 (2017).
10. K. J. Friston, J. Daunizeau, J. Kilner, S. J. Kiebel, Action and behavior: A free-energy formulation.
Biol. Cybern.102, 227–260 (2010).
11. T. Parr, G. Pezzulo, K. J. Friston, Active Inference: The Free Energy Principle in Mind, Brain, and
Behavior (MIT Press, 2022).
12. L. Pio-Lopez, A. Nizard, K. Friston, G. Pezzulo, Active inference and robot control: A case study.
J. R. Soc. Interface13, 20160616 (2016).
13. R. A. Adams, S. Shipp, K. J. Friston, Predictions not commands: Active inference in the motor
system. Brain Struct. Funct.218, 611–643 (2013).
14. M. Baltieri, C. L. Buckley, “Active inference: Computational models of motor control without
efference copy” inProceedings of the 2019 Conference on Cognitive Computational Neuroscience
(ACM, New York, NY, 2019).
15. P. Lanillos, G. Cheng, “Adaptive robot body learning and estimation through predictive coding”
in IEEE International Conference on Intelligent Robots and Systems(2018), pp. 4083–4090.
16. M. Priorelli, I. P. Stoianov, Flexible intentions: An active inference theory. Front. Comput. Neurosci.
17, 1–41 (2023).
17. H. Brown, K. Friston, S. Bestmann, Active inference, attention, and motor preparation. Front.
Psychol. 2, 1–10 (2011).
18. K. Friston, T. Parr, B. de Vries, The graphical brain: Belief propagation and active inference. Netw.
Neurosci. 1, 222–241 (2018).
19. M. Baioumy, P. Duckworth, B. Lacerda, N. Hawes, “Active inference for integrated state-estimation,
control, and learning” in2021 IEEE International Conference on Robotics and Automation (ICRA)
(2021), pp. 4665–4671.
20. C. Meo, G. Franzese, C. Pezzato, M. Spahn, P. Lanillos, Adaptation through prediction: Multisensory
active inference torque control. IEEE Trans. Cogn. Dev. Syst.15, 32–41 (2023).
21. A. Ciria, G. Schillaci, G. Pezzulo, V. V. Hafner, B. Lara, Predictive processing in cognitive robotics:
A review. Neural Comput.33, 1402–1432 (2021).
8 of 9 https://doi.org/10.1073/pnas.2309058120 pnas.org
22. A. Maselli, P. Lanillos, G. Pezzulo, Active inference uniﬁes intentional and conﬂict-resolution
imperatives of motor control. PLoS Comput. Biol.18, e1010095 (2022).
23. F. Mannella, F. Maggiore, M. Baltieri, G. Pezzulo, Active inference through whiskers. Neural Netw.
144, 428–437 (2021).
24. T. Taniguchi et al., World models and predictive coding for cognitive and developmental robotics:
Frontiers and challenges. Adv. Rob.37, 780–806 (2023).
25. A. Ahmadi, J. Tani, A novel predictive-coding-inspired variational RNN model for online prediction
and recognition. Neural Comput.31, 2025–2074 (2019).
26. C. Pezzato, R. Ferrari, C. H. Corbato, A novel adaptive controller for robot manipulators based on
active inference. IEEE Rob. Autom. Lett.5, 2973–2980 (2020).
27. P. Mazzaglia, T. Verbelen, O. Catal, B. Dhoedt, The free energy principle for perception and action:
A deep learning perspective. Entropy 24, 301 (2022).
28. O. Catal, T. Verbelen, T. Van de Maele, B. Dhoedt, A. Safron, Robot navigation as hierarchical active
inference. Neural Netw.142, 192–204 (2021).
29. T. Matsumoto, J. Tani, Goal-directed planning for habituated agents by active inference using a
variational recurrent neural network. Entropy 22, 564 (2020).
30. C. Sancaktar, M. A. J. van Gerven, P. Lanillos, “End-to-end pixel-based deep active inference for
body perception and action” inIEEE International Conference on Development and Learning and
Epigenetic Robotics(2020), pp. 1–8.
31. K. J. Friston, J. Mattout, J. Kilner, Action understanding and active inference. Biol. Cybern.104,
137–60 (2011).
32. G. Oliver, P. Lanillos, G. Cheng, An empirical study of active inference on a humanoid robot. IEEE
Trans. Cogn. Dev. Syst.14, 462–471 (2021).
33. R. Bogacz, A tutorial on the free-energy framework for modelling perception and learning. J. Math.
Psychol. 76, 198–211 (2017).
34. K. Friston, A theory of cortical responses. Philos. Trans. R. Soc. B: Biol. Sci.360, 815–836
(2005).
35. R. P. N. Rao, D. H. Ballard, Predictive coding in the visual cortex: A functional interpretation of some
extra-classical receptive-ﬁeld effects. Nat. Neurosci.2, 79–87 (1999).
36. M. Priorelli, I. P. Stoianov, “Intention modulation for multi-step tasks in continuous time active
inference” in3rd International Workshop on Active Inference (IWAI 2022)(Grenoble, 2022).
37. J. Bongard, V. Zykov, H. Lipson, Resilient machines through continuous self-modeling. Science
314, 1118–1121 (2006).
38. C. L. Buckley, C. S. Kim, S. McGregor, A. K. Seth, The free energy principle for action and perception:
A mathematical review. J. Math. Psychol.81, 55–79 (2017).
39. A. Ororbia, D. Kifer, The neural coding framework for learning generative models. Nat. Commun.
13, 2064 (2022).
40. A. A. Meera, M. Wisse, Dynamic expectation maximization algorithm for estimation of linear
systems with colored noise. Entropy 23, 1306 (2021).
41. A. A. Meera, P. Lanillos, Adaptive noise covariance estimation under colored noise using dynamic
expectation maximization. arXiv [Preprint] (2023). https://doi.org/10.48550/arXiv.2308.07797
(Accessed 20 August 2023).
42. F. Bos, A. A. Meera, D. Benders, M. Wisse, “Free energy principle for state and input estimation
of a quadcopter ﬂying in wind” in Proceedings—IEEE International Conference on Robotics and
Automation (2022), pp. 5389–5395.
43. T. Parr, J. Limanowski, V. Rawji, K. Friston, The computational neurology of movement under active
inference. Brain 144, 1799–1818 (2021).
44. M. Priorelli, I. P. Stoianov, Slow but ﬂexible or fast but rigid? Discrete and continuous processes
compared. bioRxiv [Preprint] (2023). https://doi.org/10.1101/2023.08.20.554008 (Accessed
21 August 2023).
45. V. H. Sridhar et al., The geometry of decision-making in individuals and collectives. Proc. Natl. Acad.
Sci. U.S.A.118, e2102157118 (2021).
46. M. Priorelli, G. Pezzulo, I. P. Stoianov, Active vision in binocular depth estimation: A top-down
perspective. Biomimetics 8, 445 (2023).
47. K. Friston et al., The free energy principle made simpler but not too simple. Phys. Rep.1024, 1–29
(2022).
48. K. Friston, J. Mattout, N. Trujillo-Barreto, J. Ashburner, W. Penny, Variational free energy and the
Laplace approximation. Neuroimage 34, 220–234 (2007).
49. G. Oliver, P. Lanillos, G. Cheng, Active inference body perception and action for humanoid robots.
arXiv [Preprint] (2019). https://doi.org/10.48550/arXiv.1906.03022 (Accessed 1 May 2023).
50. M. Baioumy, C. Pezzato, R. Ferrari, N. Hawes, “Unbiased active inference for classical control”
in 2022 IEEE/RSJ International Conference on Intel Robots and Systems (IROS)(2022),
pp. 12787–12794.
51. M. Priorelli, Method data of: Deep kinematic inference affords efﬁcient and scalable control of
bodily movements. Github. https://github.com/priorelli/deep-kinematic-inference. Deposited
1 November 2023.
PNAS 2023 Vol. 120 No. 51 e2309058120 https://doi.org/10.1073/pnas.2309058120 9 of 9