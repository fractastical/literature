=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Navigation and Exploration with Active Inference: from Biology to Industry
Citation Key: tinguy2025navigation
Authors: Daria de Tinguy, Tim Verbelen, Bart Dhoedt

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: animals, navigation, exhibit, daria, industry, cognitive, ghent, inference, internal, active

=== FULL PAPER TEXT ===

Navigation and Exploration with Active
Inference: from Biology to Industry
Daria de Tinguy1[0000−0003−1112−049X], Tim Verbelen2[0000−0003−2731−7262], and
Bart Dhoedt1[0000−0002−7271−7479]
1 Ghent university, Ghent, Belgium daria.detinguy at ghent.be
2 Verses, Los Angeles, California, USA
Abstract. By building and updating internal cognitive maps, animals
exhibit extraordinary navigation abilities in complex, dynamic environ-
ments. Inspired by these biological mechanisms, we present a real-time
robotic navigation system grounded in the Active Inference Framework
(AIF).Ourmodelincrementallyconstructsatopologicalmap,infersthe
agent’s location, and plans actions by minimising expected uncertainty
andfulfillingperceptualgoalswithoutanypriortraining.Integratedinto
the ROS2 ecosystem, we validate its adaptability and efficiency across
both 2D and 3D environments (simulated and real-world), demonstrat-
ingcompetitiveperformancewithtraditionalandstate-of-the-artexplo-
ration approaches while offering a biologically inspired navigation ap-
proach.
Keywords: AutonomousNavigation·ActiveInference·Robotics·Topo-
logical maps.
1 Introduction
Animals exhibit remarkable navigation capabilities that allow them to thrive
in complex and unpredictable environments. From migratory birds flying across
continents [8], to rodents learning intricate mazes [31] and humans navigating
subways [3], biological agents demonstrate an ability to explore, localise, and
plan.Thesecapabilitiesrelyoninternalmodelsoftheworld,enablingorganisms
toimaginetrajectoriesandevaluateoutcomesonthefly.Suchabilitiesfarexceed
thoseofmostautonomoussystems,particularlyinreal-worldsettingswherepre-
mapped routes or supervised learning often fail to adapt to dynamic changes [4,
24,5,40].
Neuroscience has suggested that animals navigate using structured internal
representations (cognitive maps) combining spatial, temporal, and relational in-
formation [41,9,3]. Such models are formed and refined through experience,
enabling organisms to infer location, predict outcomes, and choose actions with
minimal supervision. Translating these insights to robotics could enable adap-
tive, data-efficient, and robust behaviour [23,20].
The Active Inference Framework (AIF) offers a principled and biologically
grounded approach to modelling such behaviour, proposing an unifying frame-
work for this endeavour. Rooted in Bayesian inference and predictive coding,
5202
tcO
01
]OR.sc[
2v96270.8052:viXra
2 de Tinguy D. et al.
AIF treats perception, learning, and action as components of a single genera-
tive process: agents minimise expected free energy by updating beliefs about
the world and selecting actions to reduce uncertainty or satisfy preferences [10,
11].While conceptually appealing and biologically plausible, AIF has seen lim-
itedapplicationinembodiedrobotics,withonlyafewrecentworksexploringits
real-world deployment in the context of navigation [32].
In this paper, we present a bio-inspired navigation system that applies AIF
toreal-worldspatialreasoning,localisation,andplanning.Ouragentbuildsand
updates a topological cognitive map on the fly, using it to infer its position
and state, evaluate hypotheses about unvisited areas, and choose actions that
minimise expected surprise. It requires no pre-training, is robust to sensor drift
and environmental change, and adapts continuously.
We validate our approach in a variety of settings, from simple 2D mazes
to large-scale 3D environments (using ROS2 [30]) with realistic dynamics and
sensing. These include structured and unstructured indoor scenarios such as
warehouses and a real-world maze. Our results show interpretable and adaptive
behaviour, supporting efficient planning and generalisation without heavy data
training,movingroboticautonomyclosertotheflexibilityofnaturalnavigation.
The paper is structured as follows: We begin by reviewing navigation strate-
giesthatsupportexplorationunderActiveInference.Wethenpresentourmethod
for topological mapping, belief-based localisation, and goal-directed planning,
along with its application in 2D mazes. The system architecture and its ROS2
implementation are described next, followed by a comprehensive evaluation of
its exploration efficiency in 3D environments (simulated and real-world). We
conclude by discussing current limitations and potential extensions.
2 Related Work
Navigation requires integration of localisation and mapping, decision-making
(where should I go), and motion planning (how should I move). Those are typ-
ically separated in classical navigation pipelines, often focusing on a subset of
navigation and relying on hand-tuned rules or pre-training. Hand-tuned rule
modelsoftenhavelimitedadaptabilityindynamicsettingsaswellaspotentially
computationally intensive or poorly scalable to large environments [4,24], while
learning-basedmethodsrequireextensiveenvironment-specificdataandstruggle
to generalise [20].
Recent work combines mapping and planning via probabilistic or topolog-
ical models [1,17]. They are lightweight models, scalable, and well-suited for
reasoning and planning in complex environments. However, these models often
dependoncostlycomputationsorfailtogeneraliseinlarge,unstructuredanddy-
namic environments. Similarly, self-supervised and dataset-driven methods like
BYOL-Explore [15] or ViKiNG [34] show strong performance in, respectively,
exploration or goal-reaching; however, they require an important training phase
in similar environments, and only fulfil a given task.
Navigation and Exploration with Active Inference: from Biology to Industry 3
Conversely, Active Inference offers a unified, biologically inspired alternative
that treats navigation as inference, avoiding explicit reward functions. Rooted
in the idea that agents minimise surprise through belief updating, AIF enables
continuous adaptation by integrating perception, localisation, and action selec-
tion [28].
Initial works demonstrated how AIF could support emergent animal be-
haviours like exploration and goal-reaching [41] in simplified 2D settings [18,33,
26]. More recent studies introduced cognitive maps and structure learning [21],
or proposed hierarchical modelsfor efficient spatio-temporalplanning[7]. While
these contributions highlight the flexibility of AIF, they remain limited to low-
dimensional, 2D environments and often rely on computationally expensive pol-
icy search.
Notably, G-SLAM [32] demonstrated real-world AIF deployment via unified
mapping and control, but required pre-trained generative models and lacked
compatibility with robotics stacks.
Our work builds on these ideas to demonstrate how AIF can be applied in
real-worldnavigationscenarioswithoutrequiringpriortrainingorrigidpipelines.
Weproposeamodelforroboticnavigationthatefficientlyexploresfullyunknown
environmentsusingmodularcomponents(withROS2)andflexiblesensoryinput
to achieve joint mapping, localisation, and decision-making.
3 Inferring Motion to Foretell Model Growth
Whennavigatinganenvironment,anAIFagentcontinuouslyrefinesitsinternal
model of the world by updating transition probabilities (the likelihood of mov-
ing between states) and observation likelihoods (the probability of perceiving
certain features given a state). These updates are driven by the agent’s actions
and resulting sensory inputs, gradually aligning the model’s predictions with
actual observations. This alignment allows the agent to better anticipate out-
comes and select actions, minimising Expected Free Energy (EFE), to optimise
its navigation strategy.
A key limitation in most advanced models is that they 1) have static state
dimensions (illustrated Figure 1 a) and presented in [26,21]) and/or 2) often
expand their internal state space only after encountering new observations, as
picturedinFigure1b)andpresentedin[13,12].Forinstance,inroom-structured
mazes, new states are added only when the agent physically enters a new room.
However, this strategy causes the agent to forget unexplored possibilities, such
as unvisited rooms observed indirectly (e.g., through visible doors), and thus
cannot use this information to predict or plan future exploration effectively. As
a result, policies evaluated through EFE become short-sighted, focusing only on
directly experienced transitions and ignoring potentially informative unvisited
areas.
To overcome this, our model expands its internal topological map based not
onlyonactualobservationsbutalsoonpredictedstates(aspresentedinFigure1
c)).Byconsideringhypotheticaltransitions(suchasunvisitedroomsbehindseen
4 de Tinguy D. et al.
doors), the agent maintains connectivity across the environment and can revisit
thesepathslater.Thisallowstheagenttoretainawarenessofunexploredoptions
andplanaccordingly.Thisstrategysignificantlyimprovesexplorationefficiency,
enabling more comprehensive and strategic coverage of the environment with
less redundancy and delay.
The core of our model relies on the generative model presented in Figure 1,
where we separately model the inference of the location (state s) from the esti-
matedpositionpastwodistinctlatentvariables.pencodesthebelievedposition
oftheagentconsideringmotion,pastpositionandpaststateconfidence,whiles
isthestaterepresentingthelocalisationoftheagent,consistingofanobservation
and a position. p is deduced from the previous action a , pose p and state
t−1 t−1
s .Whilesisinferredfromthecurrentobservationo(fromwhichweexpectto
t−1
deduce the presence of obstacles), position p and previous state s . Inferring
t−1
those two variables improves the robustness of the system to kidnapping and
ambiguous situations (where an observation changed in a past location).
Fig.1: Left: Factor graph of the POMDP generative model, showing transitions
frompasttofuture(uptotimet+1).Knownobservations(blue)informcurrent
latent states. Future actions follow policy π, influencing inferred positions and
states (orange), and generating predictions of future observations (grey). The
agent’s position p is determined by p and the selected policy, while the
t t−1
latent state s is inferred from o , p , and s . Transitions are parametrised by
t t t t−1
B matrices, and A matrices encode the likelihood of observations given latent
states. Right (a–c): Three ways of structuring the world, progressing from the
most common (a) with a given static world dimension, to (b) a growing state
learning given a new observation, to (c) the structure learned by our proposed
model given expected motions.
This model results in the approximate posterior presented in Equation (1)
τ
(cid:89)
Q(s˜,p˜|o˜,a˜)=Q(s ,p |o ) Q(s ,p |s ,p ,a ,o ) (1)
0 0 0 t t t−1 t−1 t−1 t
t=1
Navigation and Exploration with Active Inference: from Biology to Industry 5
Our model’s key component is its ability to infer both position and latent
state jointly. This enables it to remain robust under visual ambiguity (e.g., per-
ceptual aliasing or kidnapping) while also supporting self-expansion by hypoth-
esising unexplored parts of the environment.
Expanding the agent’s model is also governed by Free Energy minimisation,
i.e.bycomparingwhetheranexpandedmodelbetterexplainscurrentorexpected
observations than our current model at hand. Concretely, given a current model
P, and an alternative, expanded model P˜, the Free Energy difference can be
written as 2 [28]:
(cid:20) (cid:21)
P(θ)
∆F =F[P˜(θ)]−F[P(θ)]=lnE (2)
Q(θ) P˜(θ)
If the free energy of an expanded model is lower than that of the current
model,theagentupdatesitsinternalstructuretoincorporatethenewlyencoun-
tered (or predicted) information, effectively increasing the model’s dimension.
This involves predicting motions leading to previously uncharted states through
the Expected Free Energy (EFE) of policies, where the benefit of updating A
p
is evaluated.
The generative model includes a state transition matrix B and an observa-
s
tion likelihood matrix A . In addition, it features a position likelihood matrix
o
A ,linkingeachstatetoapossiblepose,andatransitionmodelB ,whichdiffers
p p
fromthestandardmatrixform.B isimplementedasalistthattracksimagined
p
positions.Theagentinfersitsnextposebyupdatingthepreviouspositionbased
ontheintendedactionaandtheexpectedcollisionoutcomeP(c),abinaryvari-
able (1 if we expect an obstacle between two poses or 0 otherwise). The EFE of
a policy π is defined in Equation 3. The learning term of this equation quanti-
fies how much we learn about position likelihood in light of possible obstacles,
while the inference term evaluates the next state s and position p given
t+1 t+1
an expected collision c . This mechanism assumes that the agent can detect
t+1
or identify obstacles via its observations o.
G(π)=E [logQ(s ,p ,A |π)−logQ(s ,p ,A |c ,π)−logP(c )]
Qπ t+1 t+1 p t+1 t+1 p t+1 t+1
=−E [logQ(A |s ,p ,c ,π)−logQ(A |s ,p ,π)]
Qπ p t+1 t+1 t+1 p t+1 t+1
(cid:124) (cid:123)(cid:122) (cid:125)
expectedinformationgain(learning)
−E [logQ(s ,p |c ,π)−logQ(s ,p |π)]
Qπ t+1 t+1 t+1 t+1 t+1
(cid:124) (cid:123)(cid:122) (cid:125)
expectedinformationgain(inference)
−E [logP(c )]
Qπ t+1
(cid:124) (cid:123)(cid:122) (cid:125)
expectedcollision
(3)
Policies π may lead the agent toward locations that are not yet represented
in the generative model. To decide whether to expand the model to include
such locations, we evaluate Equation 4, which computes the EFE of the prior
over the position likelihood parameters A . A high expected information gain
p
6 de Tinguy D. et al.
from exploring a particular direction suggests that the model should grow to
accommodate a new pose. However, if a collision c is likely, this suppresses the
probability of creating a new position at that location.
P(A )=σ(−G)
p
G(A )=E [logP(p,s|A )−logP(p,s|c,A )−logP(c)]
p QAp p p
=−E [logP(p,s|c,A )−logP(s|p,A )−logP(p|A )]
QAp p p p
(4)
(cid:124) (cid:123)(cid:122) (cid:125)
expectedinformationgain(expanding)
−E [logP(c)]
QAp
(cid:124) (cid:123)(cid:122) (cid:125)
expectedcollision
If adding parameters to A reduces EFE compared to the current model,
p
thenthemodelexpandsitsparameterspacetoincludeanewpositioninA and
p
consequently B . This entails creating a new state associated with that posi-
p
tion, which increases the dimensionality of all model components. The updated
observation model A assigns uniform probabilities to newly added states, re-
o
flecting the uncertainty about unvisited states. The transition model B forms
s
or updates transition probabilities between existing and newly created states,
considering how much certainty we have about the new state. Details of this
process are further discussed in Section 5.
To ensure robustness to kidnapping (sudden displacements) and observa-
tional ambiguity, the model relies on joint confidence in the inferred state and
pose, conditioned on the previous state, pose, and action. If our current obser-
vation diverges from expectations by a given threshold but the state and pose
transitions remain coherent, the agent updates its observation likelihood while
maintaining confidence in its position. Conversely, if both the observation and
the inferred transitions are surprising, the model reduces confidence in its cur-
rent pose, alerting the model to a possible kidnapping. In such cases, the model
halts further updates until a sequence of consistent observations restores confi-
dence in the agent’s location (confidence in a state reaches the given threshold),
at which point the model updating process can resume.
4 Exploration and Goal Reaching in a Tolman Maze
Our model’s navigation strategy is evaluated in a dynamic maze environment
inspired by the second maze of Tolman’s experiment [36], shown in Figure 2
second column. The original experiment aimed to show evidence of the devel-
opment of a flexible ’cognitive map’ of the maze during exploration and that
such mental representation guided the rat’s behaviour in the reward sessions.
Calling this mental map reorganisation "insight", defined later as "the solution
of a problem by the sudden adaptive reorganization of experience" [29].
Agents begin at a designated start point (bottom of the maze) and must
locate a reward placed at the opposite side. Three possible paths connect the
Navigation and Exploration with Active Inference: from Biology to Industry 7
Fig.2: Our results (second column) compared to L.-E. Martinet & al’s (third
column) [22]. In our study, the agent’s flow paths towards the objective (top of
themap)areshown,withre-planningoccurringwhenthedesiredpathisblocked.
The varying colour gradient of the lines indicates the frequency of selection for
eachpathoverallagents.Asequenceisreadhorizontally,a)isthemazewithout
obstacles,andb)andc)illustrateobstaclesatpointsAandB,respectively.The
occupancy grid maps demonstrate the learning of maze topology by simulated
agents, initially without obstacles, showing a significant preference for Route 1.
WhenablockisintroducedatpointA,theanimalspredominantlychooseRoute
2. With an obstacle placed at point B, the animals mainly opt for Route 3.
start and goal, with Route 1 being the shortest and Route 3 the longest. Two
critical junctions, A and B, can be blocked to restrict access to Routes 1 and 2,
respectively.
Agents start with no prior knowledge of the maze structure or sensory cues,
butareguidedbyapreferenceforredtiles.Autilityweightof2biasestheagent
toward preference-seeking over pure exploration. Learning is cumulative across
all conditions, allowing agents to build and update their knowledge acquired in
earlier runs.
We ran ten agents under three sequential conditions:
– no obstacles, Figure 2 a)
– a blockage at A, Figure 2 b)
– a blockage at B, Figure 2 c)
Each condition involves 12 sequential runs per agent. Every 20 time steps, the
agentis’kidnapped’andrepositionedatthestartwithoutnotice,requiringitto
correct beliefs and infer its new location using sensory inputs.
8 de Tinguy D. et al.
Figure 2 shows the frequency of path selections between conditions of our
model(secondcolumn),comparedtotheresultsfrom[22](thirdcolumn),which
uses 100 agents. Unlike those agents or rats in the original experiment, ours
cannot detect obstacles from afar; it must reach adjacent rooms to perceive
blockages. Cells correspond to discrete rooms, with white blocks indicating ob-
structions.Theagent’sroutedecisionsthusemergefrominternalbeliefupdating
givendirectperceptionofnewobstacles,showinghowtheagenttendstochoose
the most efficient path depending on the situation. Full scenario details and
conclusions are provided in [35].
Theobservedadaptabilityreflectstwocoremechanisms:theagent’scapacity
tosimulateactionoutcomesupto14stepsaheadandtheplasticityofitsinternal
map (its ability to flexibly revise beliefs based on new evidence and adapt to a
kidnapping situation). These traits highlight our model’s potential for efficient,
insight-driven navigation under uncertainty in simple 2D environments.
5 Toward realistic settings
In this section, we are bridging the gap between our principled model working
in low-dimensional settings and our model able to cope with the messiness of
real-world environments.
Toassessthefeasibilityofdeployingourapproachunderrealisticconditions,
we implement it on a physical robot operating in previously unseen realistic
indoor spaces. This setting challenges the model with sensor noise and non-
uniform geometry, aspects often simplified in 2D environments.
Our system is deployed with ROS2 and is modular by design. The AIF-
based planner is module, sensor and platform-agnostic and can interact with
traditional perception modules and motion planning systems as well as diverse
robots (Turtlebot, Turtlebot3 [39] and RosbotXL [16], the used robots and sen-
sorsaredefinedinAppendix7).Eachcomponentcanbeindependentlyreplaced
or refined without disrupting the rest of the pipeline. Future work could incor-
porate more sophisticated perceptual pipelines (e.g., semantic SLAM or learned
embeddings), without requiring changes to the generative model.
ThecompletearchitectureofthenavigationsystemisillustratedinFigure3.
It is made of four modular components: (i) a generative model that performs
mapping, inferring and planning under AIF framework, (ii) an odometry infer-
ence module (localisation) that estimates the state of the agent based on belief
rather than direct sensor readings, (iii) a sensor processing stream (currently
using panoramic visual input) and (iv) a motion control module responsible for
theexecutionofselectedactions.Modulesnewlyaddedormodifiedfromthe2D
experiment to the real-world experiments are highlighted by red contours.
Critically,wedonotrelyonsensoryestimatedposebutontheagent’sinferred
pose, aligning with the epistemic stance of AIF, where belief takes precedence
over sensory measurements. As a result, in the face of occlusion or localisation
drift causing metric misalignment with the ground truth, the agent remains
Navigation and Exploration with Active Inference: from Biology to Industry 9
Fig.3: Overview of the system architecture. Modules interact through belief
propagation,Inferringandplanning(localisation,mappingandactionselection)
rely on the Active Inference framework. The perceptual and motion planning
still use traditional approaches. Believed odometry takes precedence over sensor
odometry. Preferences are expected from the user if we want to reach a target
observation. Red contours highlight newly added or modified modules for Real-
world navigation.
functionally coherent, navigating based on its internal generative model rather
than needing external corrections.
Motion planning is handled by external controllers (e.g., Nav2 [25] or po-
tential field planners [19]) that receive the position of the target state as input.
However, goals are not specified as fixed coordinates but rather as probabilistic
regions(Gaussiandistributions)correspondingtoexpectedposesandassociated
sensory observations. The agent determines it has reached a goal not through
position alone, but when its actual sensory input aligns with its predicted per-
ceptual state.
In deployment, we observe the system’s ability to autonomously construct
and extend its internal model while navigating through 3D spatial layouts. As
explorationunfolds,theagentupdatesitsrepresentationtoaccommodatenewly
encounteredscenes,refiningitsmodelviaaction-perceptioncycles.Whengetting
to the next desired position, the agent captures a panoramic RGB view (taken
with the camera and a rotation of the robot) and the latent cognitive states are
updated via Structural Similarity Metrics (SSIM) between incoming views and
stored experiences. When a discrepancy arises, it updates its internal model:
either refining its observation model or revising its transition model, depending
on its confidence in its current state estimate.
WeuseaLidartoconsidercollisionsasourcameradoesnotprovideaccurate
depth measurement; however, in our model, we still consider this as a visual
observationoanddonotdividetheinformationintoseparateobservations.This
results in a Transition matrix B being updated according to the situation. We
s
use a Dirichlet pseudo-count mechanism defined in Equation 5 with learning
rates (λ). The learning rates are determined by whether we were physically
blockedtowardanobjectiveorweimaginebeingabletoreach(ornot)aposition
10 de Tinguy D. et al.
Table 1: Transition learning rate (λ) depending on the situation
Predicted Predicted
TransitionsPossibleImpossible Possible Impossible
Forward 7 -7 5 -5
Reverse 5 -5 3 -3
according to our sensors. The diverse situations are presented in Table 1. This
continual adaptation of the state transitions according to the situation allows
the agent to rapidly reconfigure its internal map to new or undetected obstacles
(or removed obstacles) and avoid blocked regions, even several steps away, up
to a user-set preferred distance, usually corresponding to the sensor limit. This
increases the adaptability of the model to situations and better fine-tunes its
internal map to the reality of the environment.
B =B +Q(s |s ,π)Q(s )∗B ∗λ (5)
π π t t−1 t−1 π
6 Exploration in realistic environments
(a) 280m2 simulated ware- (b) 5m2 of real environment
house
Fig.4: Final map of exploration in a) Amazon simulated warehouse, b) a real-
world environment. Coloured points signify visited locations, where the same
colourattributionsmeanthesameobservation.Thethicknessofthelinesdepicts
the agent’s believed probability of transitioning between two states given an
action.
We evaluated our model in both simulated and real-world settings. The sim-
ulated environment, built in Gazebo [14], consists of a 280m2 warehouse-like
layout [2], shown in Figure 4(a), while the real-world test was conducted in a
Navigation and Exploration with Active Inference: from Biology to Industry 11
5m2controlledmazeinFigure4(b).Inbothcases,theagentincrementallybuilds
itstopologicalmapusingauser-definedspatialresolution,withaminimumnode
spacing of approximately 2m in simulation and 0.5m in the real environment.
This minimum spacing represents the radius of influence of a state, and this
adaptive granularity enables the agent to scale its representation to match the
environmental complexity.
Theagent’sactionspaceconsistsof13discreteactions:12evenlyspacedori-
entations across 360°, plus a "stay" action. However, when expanding its topo-
logical map, a state can generate transitions up to a maximum of six adjacent
states, rather than creating a new node for every possible direction. This con-
straint is imposed to prevent an overly dense graph structure and maintain a
manageablelevelofconnectivity.Bylimitingthenumberofnewlycreatedstates
perlocation,the agent ensuresthat onlythe mostpromising directionsareused
to expand the map. This approach preserves the flexibility to connect to more
distant or informative states later, particularly when no obstacles are present,
thereby maintaining a sparse yet navigable topological representation of the en-
vironment. Both the number of imagined transitions and available actions can
be tuned by the user, allowing for control over planning granularity and compu-
tational cost.
Each visited location is associated with a sensory observation. According to
theagent’sobservationmodel,locationssharingthesamedotcolourinthemap
visualisation indicate perceptual similarity. The thickness of the edges between
thenodesrepresentstheinferredlikelihoodofsuccessfultransitions,andthicker
edges denote a greater confidence in the navigability between states. In the
real environment, the lidar sometimes hallucinates free space due to incorrect
reflections, and erased connections are visible when the agent attempts to reach
those points.
Fig.5:LidarCoverageofa280m2 warehouseoverthedistancetravelled(m)with
our model, Frontiers and Gbplanner over five runs each.
To evaluate exploration performance, we compared our model against Fron-
tiers [37], which is a classical exploration algorithm aiming for unexplored areas
and Gbplanner [6]. Gbplanner uses a metric map [27] to form its topological
map, then used for exploration. Gbplanner is an improved version of the 2021
12 de Tinguy D. et al.
DARPA’s winner [38]. While being an AI method, our model is not suitable
for comparing our navigation to deep-learning methods due to the absence of
pre-training.
Figure 5 displays the area observed by the robot (considering the Lidar)
over its travelled distance, averaged over five runs per model, initiating at dif-
ferentstartingpointsinthewarehouse.Time-basedmetricswereavoideddueto
variability in simulated time within the Gazebo environment.
Overall, our Active Inference framework outperforms or matches the per-
formance of more traditional approaches (Frontiers) and state-of-the-art explo-
ration systems (Gbplanner), with an efficient goal-oriented exploration (goals
being the next state to reach). Frontiers falls behind in exploration efficiency as
it lacks optimised navigation and requires multiple passes over the same areas.
Especially when some small, unreachable areas have unexplored zones without
a clear frontier. Gbplanner has been built to be robust in underground passages
rather than optimising navigation in large open spaces. Additional experiments
validating the dynamic adaptability of our model can be found in appendix 7.
Theseexperimentsvalidatetheapplicabilityofourapproachbeyondsimula-
tionandintorealisticsettings,layingafoundationformoreflexible,autonomous
navigation in the world based on a biologically plausible strategy.
7 Conclusion
Wehaveillustratedhowabiologicallyinspirednavigationsystemgroundedinthe
ActiveInferenceFramework(AIF)couldbeusedtonavigateinanunknownen-
vironmentwithoutpre-trainingin2Dand3Denvironments(simulatedandreal).
By unifying probabilistic localisation, topological mapping, and belief-driven
planningintoasinglegenerativemodel,ourapproachoffersanalternativetotra-
ditional navigation pipelines that often rely on rigid assumptions, pre-training,
or heavy computational overhead. Our model supports continuous learning and
decision-makingunderuncertainty,leveragingexpectedfreeenergyminimisation
to guide exploration and goal-directed behaviour. The model shows promise in
competing with traditional exploration strategies such as Frontiers [37] or Gb-
planner [6] in exploration strategy efficiency. In addition, our modular architec-
ture ensures compatibility with standard robotics stacks (ROS2), allowing for
straightforward integration with existing perception and control systems.
While promising, our current model still faces limitations related to percep-
tion analysis. Future work will focus on precisely determining the limits of the
current model in real-world situations (including computational load analysis)
as well as enhancing perceptual inference (e.g., via semantic representations or
learnt embeddings), extending hierarchical planning capacities, and improving
computational efficiency for broader deployment. Ultimately, this work moves a
stepclosertobiologicallyplausibleandpracticallycapableroboticnavigationin
open-ended, real-world scenarios.
Navigation and Exploration with Active Inference: from Biology to Industry 13
Acknowledgements
ThisresearchreceivedfundingfromtheFlemishGovernment(AIResearchPro-
gram) under the “Onder-zoeksprogramma Artificiële Intelligentie (AI) Vlaan-
deren” programme and the Inter-university Microelectronics Centre (IMEC).
References
1. An, D., Wang, H., Wang, W., Wang, Z., Huang, Y., He, K., Wang, L.: Etpnav:
Evolving topological planning for vision-language navigation in continuous envi-
ronments (2024), https://arxiv.org/abs/2304.03047
2. aws-robotics: aws-robomaker-small-warehouse-world (2020),
https://github.com/aws-robotics/aws-robomaker-small-warehouse-world, ac-
cessed: 2024-08-01
3. Balaguer, J., Spiers, H., Hassabis, D., Summerfield, C.: Neural mechanisms of
hierarchicalplanninginavirtualsubwaynetwork.Neuron90,893–903(052016).
https://doi.org/10.1016/j.neuron.2016.03.037
4. Campos,C.,Elvira,R.,Gomez,J.J.,Montiel,J.M.M.,Tardos,J.D.:ORB-SLAM3:
An accurate open-source library for visual, visual-inertial and multi-map SLAM.
IEEE Transactions on Robotics 37(6), 1874–1890 (2021)
5. Chaplot, D.S., Gandhi, D., Gupta, S., Gupta, A., Salakhutdinov, R.: Learning to
exploreusingactiveneuralslam.In:InternationalConferenceonLearningRepre-
sentations (ICLR) (2020)
6. Dang,T.,Tranzatto,M.,Khattak,S.,Mascarich,F.,Alexis,K.,Hutter,M.:Graph-
basedsubterraneanexplorationpathplanningusingaerialandleggedrobots.Jour-
nal of Field Robotics 37(8), 1363–1388 (2020), wiley Online Library
7. de Tinguy, Daria and Van de Maele, Toon and Verbelen, Tim and Dhoedt,
Bart: Spatial and temporal hierarchy for autonomous navigation using ac-
tive inference in minigrid environment. ENTROPY 26(1), 32 (2024),
http://doi.org/10.3390/e26010083
8. Dorst, J.P.: Migration. Encyclopedia Britannica (May 15 2024)
9. Epstein, R., Patai, E.Z., Julian, J., Spiers, H.: The cognitive map in humans:
Spatial navigation and beyond. Nature Neuroscience 20, 1504–1513 (10 2017).
https://doi.org/10.1038/nn.4656
10. Friston,K.:Lifeasweknowit.JournaloftheRoyalSociety,Interface/theRoyal
Society 10, 20130475 (06 2013). https://doi.org/10.1098/rsif.2013.0475
11. Friston, K., Moran, R.J., Nagai, Y., Taniguchi, T., Gomi, H., Tenen-
baum, J.: World model learning and inference. Neural Networks 144, 573–
590 (2021). https://doi.org/https://doi.org/10.1016/j.neunet.2021.09.011,
https://www.sciencedirect.com/science/article/pii/S0893608021003610
12. Friston, K., Parr, T., Zeidman, P.: Bayesian model reduction (2019)
13. Friston, K.J., Costa, L.D., Tschantz, A., Kiefer, A., Salvatori, T., Neacsu, V.,
Koudahl, M., Heins, C., Sajid, N., Markovic, D., Parr, T., Verbelen, T., Buckley,
C.L.: Supervised structure learning (2023)
14. gazebosim: (2014), https://classic.gazebosim.org, accessed: 2025-05-27
15. Guo, Z.D., Thakoor, S., Pîslar, M., Pires, B.A., Altché, F., Tallec, C., Saade,
A., Calandriello, D., Grill, J.B., Tang, Y., Valko, M., Munos, R., Azar,
M.G., Piot, B.: Byol-explore: Exploration by bootstrapped prediction (2022),
https://arxiv.org/abs/2206.08332
14 de Tinguy D. et al.
16. Husarion: rosbotxl (2025), https://husarion.com/tutorials/howtostart/rosbotxl-
quick-start/, accessed: 2025-05-21
17. Jardali, H., Ali, M., Liu, L.: Autonomous mapless navigation on uneven terrains.
2024 IEEE International Conference on Robotics and Automation (ICRA) pp.
13227–13233 (2024), https://api.semanticscholar.org/CorpusID:267770585
18. Kaplan, R., Friston, K.: Planning and navigation as active inference. bioRxiv (12
2017). https://doi.org/10.1101/230599
19. Koren, Y., Borenstein, J.: Potential field methods and their inherent limita-
tions for mobile robot navigation. vol. 2, pp. 1398 – 1404 vol.2 (05 1991).
https://doi.org/10.1109/ROBOT.1991.131810
20. Levine,S.,Shah,D.:Learningroboticnavigationfromexperience:principles,meth-
odsandrecentresults.PhilosophicalTransactionsoftheRoyalSocietyB:Biological
Sciences 378(1869) (dec 2022). https://doi.org/10.1098/rstb.2021.0447
21. de Maele, T.V., Dhoedt, B., Verbelen, T., Pezzulo, G.: Integrating cognitive map
learning and active inference for planning in ambiguous environments (2023)
22. Martinet, L.E., Passot, J.B., Fouque, B., Meyer, J.A., Arleo, A.: Map-based
spatial navigation: A cortical column model for action planning. In: Spatial
Cognition VI. Learning, Reasoning, and Talking about Space. Spatial Cogni-
tion 2008. vol. 5248, pp. 39–55. Springer-Verlag, Berlin, Heidelberg (09 2008).
https://doi.org/10.1007/978-3-540-87601-4_6
23. Mirowski, P., Pascanu, R., Viola, F., Soyer, H., Ballard, A.J., Banino, A., De-
nil, M., Goroshin, R., Sifre, L., Kavukcuoglu, K., Kumaran, D., Hadsell, R.:
Learning to navigate in complex environments. CoRR abs/1611.03673 (2016),
http://arxiv.org/abs/1611.03673
24. Mohamed,I.S.,Yin,K.,Liu,L.:Autonomousnavigationofagvsinunknownclut-
tered environments: Log-mppi control strategy. IEEE Robotics and Automation
Letters 7(4), 10240–10247 (2022). https://doi.org/10.1109/LRA.2022.3192772
25. nav2: nav2 (2021), https://docs.nav2.org/, accessed: 2024-12-01
26. Neacsu, V., Mirza, M.B., Adams, R.A., Friston, K.J.: Structure learn-
ing enhances concept formation in synthetic active inference agents. PLOS
ONE 17(11), 1–34 (11 2022). https://doi.org/10.1371/journal.pone.0277199,
https://doi.org/10.1371/journal.pone.0277199
27. Oleynikova, H., Taylor, Z., Fehr, M., Nieto, J.I., Siegwart, R.: Voxblox: Build-
ing 3d signed distance fields for planning. CoRR abs/1611.03631 (2016),
http://arxiv.org/abs/1611.03631
28. Parr, T., Pezzulo, G., Friston, K.: Active Inference: The Free Energy
Principle in Mind, Brain, and Behavior. The MIT Press (03 2022).
https://doi.org/10.7551/mitpress/12441.001.0001
29. Riesen, A.H.: Varying behavioral manifestations of animals: <i>a study in be-
haviour: Principles of ethology and behavioural physiology, displayed mainly in
the rat</i>. s. a. barnett. methuen, london, 1963. 304 pp. 45s.; <i>learning and
instinct in animals</i>. w. h. thorpe. methuen, london, ed. 2, 1963. 568 pp. 63s.
Science141(3578),344–345(1963).https://doi.org/10.1126/science.141.3578.344,
https://www.science.org/doi/abs/10.1126/science.141.3578.344
30. ROS2: Ros2 humble (2022), https://github.com/ros2, accessed: 2025-05-21
31. Rosenberg,M.,Zhang,T.,Perona,P.,Meister,M.:Miceinalabyrinthshowrapid
learning, sudden insight, and efficient exploration. eLife 10, e66175 (jul 2021).
https://doi.org/10.7554/eLife.66175, https://doi.org/10.7554/eLife.66175
32. Safron, A., Çatal, O., Verbelen, T.: Generalized simultaneous local-
ization and mapping (g-slam) as unification framework for natural
Navigation and Exploration with Active Inference: from Biology to Industry 15
and artificial intelligences: towards reverse engineering the hippocam-
pal/entorhinal system and principles of high-level cognition. Frontiers in
Systems Neuroscience 16 (2022). https://doi.org/10.3389/fnsys.2022.787659,
https://www.frontiersin.org/journals/systems-neuroscience/articles/10.3389/fnsys.2022.787659
33. Schwartenbeck, P., Passecker, J., Hauser, T.U., FitzGerald, T.H., Kronbich-
ler, M., Friston, K.J.: Computational mechanisms of curiosity and goal-directed
exploration. eLife 8, e41703 (may 2019). https://doi.org/10.7554/eLife.41703,
https://doi.org/10.7554/eLife.41703
34. Shah, D., Levine, S.: Viking: Vision-based kilometer-scale navigation with ge-
ographic hints. In: Robotics: Science and Systems XVIII. Robotics: Science
and Systems Foundation (Jun 2022). https://doi.org/10.15607/rss.2022.xviii.019,
http://dx.doi.org/10.15607/RSS.2022.XVIII.019
35. de Tinguy, D., Verbelen, T., Dhoedt, B.: Learning dynamic cognitive
map with autonomous navigation. Frontiers in Computational Neu-
roscience 18 (Dec 2024). https://doi.org/10.3389/fncom.2024.1498160,
http://dx.doi.org/10.3389/fncom.2024.1498160
36. TolmanE.C.,H.C.:”insight” inrats.Univ.Calif.Publ.Psychol.4,215–232(1930)
37. Topiwala, A., Inani, P., Kathpal, A.: Frontier based exploration for autonomous
robot (2018), https://arxiv.org/abs/1806.03581
38. Tranzatto,M.,Dharmadhikari,M.,Bernreiter,L.,Camurri,M.,Khattak,S.,Mas-
carich, F., Pfreundschuh, P., Wisth, D., Zimmermann, S., Kulkarni, M., Reijg-
wart, V., Casseau, B., Homberger, T., Petris, P.D., Ott, L., Tubby, W., Waibel,
G.,Nguyen,H.,Cadena,C.,Buchanan,R.,Wellhausen,L.,Khedekar,N.,Ander-
sson, O., Zhang, L., Miki, T., Dang, T., Mattamala, M., Montenegro, M., Meyer,
K., Wu, X., Briod, A., Mueller, M., Fallon, M., Siegwart, R., Hutter, M., Alexis,
K.:Teamcerberuswinsthedarpasubterraneanchallenge:Technicaloverviewand
lessons learned (2022), https://arxiv.org/abs/2207.04914
39. Turtlebot: Turtlebot versions (2024), https://www.turtlebot.com/about/, ac-
cessed: 2024-12-16
40. Walid,J.,Nabil,E.A.:Towardintelligentnavigationforautonomousmobilerobots:
Learningfromtheclassics.In:Bendaoud,M.,ElFathi,A.,Bakhsh,F.I.,Pierluigi,
S.(eds.)AdvancesinControlPowerSystemsandEmergingTechnologies.pp.189–
195. Springer Nature Switzerland, Cham (2024)
41. Zhao, M.: Human spatial representation: What we cannot learn from the
studies of rodent navigation. Journal of Neurophysiology 120 (08 2018).
https://doi.org/10.1152/jn.00781.2017
Appendix
Robots
Our system is robot-agnostic; however, we have to adapt the sensor pipeline to
the specific sensors used. In simulation, we used a TurtleBot3 Waffle with a Pi
cameraanda360-degreelidarwitha12mrange.Intherealenvironment,several
robots have been used; at first, we used the Turtlebot with a forward lidar of
240 degrees of 12 m range and a camera RealSense D435; the Turtlebot4 with
a 360-degree lidar of 8 m range and a camera OAK-D-Pro. Due to uncorrected
drift, the resulting maps did not allow a clear superposition with the layout
of the environment; thus, we used a RosbotXL with a 360-degree lidar of 18m
16 de Tinguy D. et al.
range and a 360-degree camera to better show the results of the navigation.
However, while the Lidar range is 18m, the agent only considers the Lidar up
to 8 consecutive nodes to create or update new transitions to be as reliable as
possible.
(a) Turtlebot3: Waffle (b) Husarion: RosbotXL
Fig.6: Turtlebot3 waffle robot was used in simulation while tests have been
conducted with a turtlebot, turtlebot4 and RosbotXL in the real environment
Handling Dynamic Obstacles
Through equation 3 our model can predict obstacles, and if an obstacle was
not detected (e.g., not detected by the Lidar), it can still recover from a failed
motion. Equation 5 is the main factor of our map flexibility to change with the
learning rates defined in Table 1.
Figure7exemplifiesthisprocesswithanobstacle(e.g.abox)movedbetween
twopositions(fromposition(-1,0)to(-1,-1)overavisitedstate3)whiletheagent
explored a mini warehouse [2] presented in Figure 8. As the agent fails to reach
state 3 after the movement of the box, it adjusts its internal map to reflect the
newreality.Thetransitionprobabilitytothatlocationreduces,andthestateID
atthispositionbecomesincorrect(state1insteadof3)becausetheagentcannot
correct its belief by moving to that location. A new state (state 20) is created
at the former position of the obstacle, and new transitions are established. This
change does not affect any of the other existing states.
This display, in a qualitative way, shows how the model effectively adapts to
change in the environment. The results displayed in Figure 7 is obtained after
the agent circled once around the obstacle to update all adjacent states toward
the obstructed state.
Navigation and Exploration with Active Inference: from Biology to Industry 17
(a) Agent map with an obstacle at posi- (b) Obstacle at position (-1,-1) after 20
tion(-1,0)beforemovingitafterapartial more steps.
exploration
Fig.7: An obstacle was initially placed at position (-1,0) and moved to position
(-1,-1)overstate3duringexploration.Thefailuretoreachthestatereducesthe
transition probabilities, represented as thinner black lines between state nodes
in the graph. The thickness of the link represents the transition certainty be-
tween locations, and each dot colour represents an observation; similar enough
observations hold the same colours.
Fig.8: Top view of a mini warehouse of 36m2.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Navigation and Exploration with Active Inference: from Biology to Industry"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
