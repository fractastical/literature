=== IMPORTANT: ISOLATE THIS PAPER ===
You are revising a summary for ONLY the paper below. Do NOT reference or use content from any other papers.
Paper Title: Is Active Persona Inference Necessary for Aligning Small Models to Personal Preferences?
Citation Key: tang2025is
REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Issues to fix:
1. Title mismatch: Paper title 'Is Active Persona Inference Necessary for Aligning Small Models to Personal Preferences?' not found in summary
2. Too short: 47 words (minimum 200)

Current draft:
Okay, I understand. I will follow all the instructions and guidelines provided, focusing on generating a concise, accurate, and unique summary of the research paper, adhering to all the specified constraints and avoiding repetition. I will prioritize clarity, precision, and a well-structured presentation of the information.Let's begin.

Key terms: soup, chocolate, small, necessary, user, recipe, persona, aligning

=== FULL PAPER TEXT ===
Is Active Persona Inference Necessary for Aligning Small Models to
Personal Preferences?
ZiluTang1,AfraFeyzaAkyürek1,EkinAkyürek2,DerryWijaya1,3,
1BostonUniversity,2MIT,3MonashUniversityIndonesia,
zilutang@bu.edu
Abstract
Passive Alignment: prefix few-shots Active Alignment: Infer preferences & prefix
What’s a fun dessert recipe? What’s a fun dessert recipe?
Aprominentissueinaligninglanguagemod-
Chocolate avocado mousse Chocolate avocado mousse
els (LMs) to personalized preferences is with almond milk is a … with almond milk is a …
underspecification– the lack of information How about vanilla pound How about vanilla pound
cake? cake?
fromusersabouttheirpreferences. Apopular
What does the user prefer?
trendofinjectingsuchspecificationisadding
User might be dairy-free
aprefix(e.g. priorrelevantconversations)to
the current user’s conversation to steer pref- I am sick and want a soup I am sick and want a soup
erence distribution. Most methods passively recipe recipe?
modelpersonalpreferenceswithpriorexample Creamy Finnish salmon soup This is it: Soup-er Healing
always hits the spot … Vegan Ginger Soup. Boil …
preferencespairs. Weaskwhethermodelsben-
Generalization: ✅ Interpretable: ❌ Generalization: ✅ Interpretable: ✅
efitfromactivelyinferringpreferencedescrip-
Contextually-Faithful: ❌ No Bias: ❌ Contextually-Faithful: ✅ No Bias: ✅
tions,andaddressthisquestionbycreatinga
syntheticpersonalizedalignmentdatasetbased Figure1:Weconstructapersonalizedalignmentdataset
on famous people with known public prefer- onfamouspeopletoinvestigatewhetheractivelyinfer-
ences. We then test how effective finetuned ringpreferencesisnecessaryforfinetuningpersonalized
1-8B size models1 are at inferring and align- alignmentmodels. Wefindactivealignmenttobemore
ingtopersonalpreferences. Resultsshowthat interpretable,contextuallyfaithful,andlessbiased.
higher-qualityactiveprefixesleadtobettergen-
eralization,morecontextuallyfaithfulmodels,
andlesssystematicbiasesacrossdifferentpro-
alignment algorithms is mitigating underspecifi-
tectedattributes. Allourresultssuggestactive
cation. User-specific information needs to be in-
alignmentcanleadtoamorecontrollableand
corporated to customize the reward distribution
efficientpathforpersonalizedalignment.2
downstream. Themajorityofpriorworksproposes
passive alignment– learning to influence reward
throughobservingsimilarpriorinteractions. This
1 Introduction
caneitherbeincorporatedthroughfew-shotexam-
Preference alignment has become a standard plesintheprompt(Wangetal.,2024b;Zolloetal.,
pipeline in finetuning models to follow generic 2024),prefixembeddings(Lietal.,2024b;Poddar
human preferences. Most work seeks to opti- etal.,2024),meta-learning(Zhaoetal.,2023;Yang
mize models to produce responses that would be etal.,2024),orpreferenceprototypes(Wangetal.,
preferableonaverage,simplifyingthediverseand 2024b;Parketal.,2024a). Whilepassivealignment
often contradicting space of human preferences. allowsfine-grainedsteeringthatbenefitsfromthe
The focus for personalized alignment emerges scaleofpriorinteractions,activealignmentmeth-
as the demand for adapting models to individual odsseektodirectlyguidepersonalizationwithin-
userpreferencesriseswithindustrialapplications structions. Mostworkwiththisapproachfollows
and fairness concerns for large pretrained mod- Multi-objectiveReinforcementLearning(MORL)
els. One major issue when personalizing generic paradigm(Liuetal.,2014),recognizingthatalign-
mentobjectivesofteninvolvecompetinggoals(e.g.
1Wefindlargermodelsquitegoodatpersonalizationwith
helpfulvs. harmless)withalimitednumberofob-
prompting,henceonlyleverageditfordatasetgeneration.
jectives(typicallylessthanfive)(Jangetal.,2023).
2Wereleaseourresearchartifactsinhttps://github.
com/PootieT/famous-persona However, MORL-based works have yet to show
5202
peS
92
]LC.sc[
2v75231.5052:viXra
whetheractivealignmentcanfullyleveragetheex- Anotherpopularchoiceispredictinghumansur-
pressiveness of natural language instructions for veyresponses(Durmusetal.,2023;Santurkaretal.,
fine-grainedpreferencesteering. Withthisgapin- 2023;Zhaoetal.,2023;Doetal.,2023;Fengetal.,
mind,wesyntheticallygenerateadatasetoffamous 2024; Li et al., 2024a; Hwang et al., 2023; Jiang
peoplewithpubliclyknownpreferences,andcom- et al., 2024). Although measuring opinions can
parepassivevs. activealignment. Wesummarize serveasavaluableevaluationtool, thesetasksin
ourcontributionasfollows: generalarenotforimprovingconversationalassis-
tants. Recentwork(Zolloetal.,2024)synthetically
Dataset of Personal Preference We release a
constructuserspreferencesthroughlinearcombi-
personalizedalignmentdatasetbasedonrealpeo-
nationsofoff-the-shelfrewardmodels. Kirketal.
plewithdiverseandcontradictingpreferences.
(2024)collectsresponsepreferencepairsfromdi-
verseuserbackgrounds,andCastricatoetal.(2025)
Activevs. Passive Wecompareactiveandpas-
synthetically constructs personas and respective
sivealignmentstrategiesacrossfourmodelsofsize
conversations using prompts from PRISM. How-
1-8B,andshowthatactivealignmentcanimprove
ever, none of these datasets contain ground-truth
rewardgeneralizationonunseenpersonas.
persona preferences from which we can evaluate
Contextual Faithfulness We analyze the mod- preference inference (i.e. active alignment). See
els’ attribution pattern to prefixes and find active datasetcomparisonsinAppendix10.
aligned models more contextually faithful. This
Alignment methods. For MORL-based active
improveswiththequalityofinferredpersonas.
alignment,methodsusuallyinvolvemergingsepa-
Systematic Bias We find systematic biases in ratelytrainedadapters,orprogrammaticallycom-
persona inference and alignment and that active posed prompt prefixes (Jang et al., 2023; Wang
alignmentresultsinlessbias. et al., 2024c). Other works focus on pluralistic
alignmentfromgroupperspectives(Sorensenetal.,
2 Background&Relatedworks 2024;Parketal.,2024a),whichtypicallyusemeta-
learning(Zhaoetal.,2023),orEM-likealgorithms
Personalizedalignmentdatasets. Personaliza-
to iteratively cluster and align multiple models
tion has been extensively studied in many fields
(Zhong et al., 2024; Park et al., 2024b). Lastly,
priortoLLMs(Chenetal.,2023),beginningwith
many seek to align during decoding (Chen et al.,
collaborativefilteringinrecommendationsystems
2024b;Khanovetal.,2024;Shietal.,2024;Gao
(Goldberg et al., 1992). With popularization of
etal.,2024b;Huangetal.,2024). Manysuchworks
post-trainingpreferencealignmenttohumanfeed-
areorthogonaltous,wherewefocusonthemost
back (Ouyang et al., 2022), initial personalized
simpleset-up.
alignment datasets take inspiration from MORL-
paradigm (Bai et al., 2022; Ji et al., 2024; Jang Active preference inference and underspecifi-
et al., 2023; Yang et al., 2024; Gao et al., 2024b; cation Inferringhumanpreferencesfromsparse
Poddaretal.,2024;Chakrabortyetal.,2024). Con- examplesorunderspecifiedinstructionsisimpor-
structingsuchdatasetsisrelativelystraightforward. tantforseamlesshuman-AIinteraction(Millietal.,
Simple objectives (e.g. detailed vs. concise re- 2017). Prior works infer different aspects of hu-
sponses) can be controlled in generation through manpreferences,suchasimplicitsocialcontracts
prompting and evaluated with LLMs (Jang et al., (Fränken et al., 2023), constitutions (Chen et al.,
2023). ThebiggestassumptionofMORListhatob- 2024c),anduservalues(Sunetal.,2024;Liuetal.,
jectivesarecompositional,andthespancoversthe 2024;Balepuretal.,2025;Lietal.,2025;Bismay
entirepreferencespace. Thisassumptionisflawed, etal.,2025). Theseworksreinforceourpointthat
however, as human preferences can be infinitely explicitly inferring user preference is crucial for
nuanced(e.g. likingsquashovertennis)sothatno interpretablealignment. Prefixinginferredpersona
amount of objectives can cover the space of per- canalsobeconsideredasaddressingunderspecifi-
sonalpreferences(Slovic,1995;MacIntyre,2013; cation(Leeetal.,2022), whichleadstospurious
AroyoandWelty,2015;Gabriel,2020;Klingefjord correlation and short-cut learning (Geirhos et al.,
etal.,2024). Evenifpreferencespaceiscomposi- 2020). Inpreferencelearning,underspecifieddata
tional,modelingchallengesremain. (Wangetal., – such as users upvoting Reddit posts for various
2024a;Becketal.,2024). latentreasons(Ethayarajhetal.,2022;Parketal.,
2024a)–leadstonon-robustrewards. Asolution 2024). We assume baseline models have no in-
istofullyspecifythepreferencecriteria(Siththa- formation on the persona during generation and
ranjanetal.,2023;Yangetal.,2024),whichinour leverageaChain-of-thought(CoT)prompttoelicit
case,istheinferredpersonas. diverse responses. Through sentence-embedding
clusteringandgenericrewardmodelfiltering,we
3 Methodology obtain four diverse ys per x. Note x and
divergent
corresponding ys are shared across personas of
3.1 TaskDefinition
thataxis,sothesamey foronemightbethey
l w
Preferencealignmenttohumanfeedback(Stiennon for another. Step 4: Label Responses. We use
etal.,2020;Baietal.,2022;Ouyangetal.,2022) GPT4-as-personal-judgetoobtainthebesty from
w
assumesadatasetoftriplesD = {x,y w ,y l }where ysthroughthreeroundsofpair-wisecomparisons.
xrepresentsthe promptgiven tothe LMand y w , Dong et al. (2024); Castricato et al. (2025) show
y l representthepreferredandrespectivelydispre- thatGPT4canapproximatehumanpreferencesas
ferredresponselabeledbythehumanannotator(s). wellasathird-personannotator. Givenextensive
Thetaskofalignmentseekstooptimizeamodel’s publicinformationonthepeopleinourdataset,we
likelihood(π)ofgeneratingy w overy l givenx. In expectGPT4annotationqualitytobesimilar,ifnot
personalizedalignment,weintroducethepersona betterthanathird-personannotator. Weverifythis
variable(e.g. priorconversation,demographics)p i withourhumanannotators,whoagreewithGPT4
for each of the n personas. The objective can be label78%ofthetime. SeeAppendixBformore
definedas: detailsontheconstructionprocess,statistics,and
argmaxE (cid:2) (cid:88) π (y |x,p ) (cid:3) (1) verificationefforts.
x,y
l
,yw∈D p w i
πp
i∈[n] Our final dataset contains 50 personas across
11 axis. Each persona has 100 train and 100 test
whereπ couldbeasingleorasetofpersonalized
p preferencepairs,eachcomposedofhalfpersonal
modelsandD = ∪n D .
i=1 i andhalfdivergentquestions.
3.2 DatasetConstruction
3.3 TrainingandEvaluation
Weconstructourpersonalizationdatasettocontain
Wefocusonfinetuningandevaluatingsmallmod-
diversepersonaswithcontradictingpreferencesin
els (1-8B) as they are primary targets as reward
four steps (Figure 5). Step 1: Select persona.
modelsusedduringreinforcementlearning. Larger
With the help of GPT43, we define 11 axes (top-
models are costly to run, and often do not allow
icsorattributes)throughwhichpreferencesmight
access to internals, which we need for our analy-
differ(e.g. diet,politics)toensurecontrast
sis. Sinceourdatasetconstructionwasdonewith
in opinions. For each axis, we prompt GPT4 to
GPT4, we know large models can customize to
provide at most five sub-categories (e.g. liberal)
personal preferences through prompting in some
along with a famous person associated with the
capacity,andleavetheextensionofouranalysisto
category (e.g. Bernie Sanders). We curate 50 di-
largermodelsforfuturedirections.
versepersonas,eachwithdefinablecontrasts. Step
Throughpreliminarystudies(AppendixI,L),we
2: Generate prompts. We generate two sets of
find small models to be in-effective at in-context
questions (x) – personal (x ) and divergent
personal learningwithfew-shotexamples. Tobalancesim-
(x ) – for each persona to ensure diversity
divergent plicityandperformance,weopt-intofinetuneour
andcontrast. x arebasedonindividualistic
personal modelinamulti-taskfashion(MT),updatingasin-
preferences, and x are shared across per-
divergent glemodel(adapter)forallusers,withalosssimilar
sonasfromthesameaxiswhoprefersdifferentan-
toDPO(Rafailovetal.,2024):
swers4. Wesample100x and100x ,
personal divergent
using half for training and the other half for test- L = −E (cid:2) log (cid:0)
MT i∼[n],(x,yw,y
l
)∼Di
ing. Step 3: Sample Responses. We generate y π θ (y w |p i ,x) π θ (y l |p i ,x) (cid:1)(cid:3)
fromxusingourbaselinemodel ZEPHYR 5 forthe βlog
π (y |p ,x)
−βlog
π (y |p ,x)
,
ref w i ref l i
purpose of on-policy improvement (Meng et al., (2)
where each p = f(x,y ,y ) is a fixed person-
3Weusegpt-4-0613fromOpenAI i w l
4similartocontroversyguidedpromptsinKirketal.(2024) specificprefix. Wetestthefollowingpassiveand
5HuggingFaceH4/zephyr-7b-beta activeprefixes:
PassivePrefixes Werandomlysamplefew-shot SeenPersona UnseenPersona
prefixes(Zhaoetal.,2023)withtwo(x,y )pairs
w noprefix gold noprefix gold
fromeachpersona’strainsplit6. Forembedding-
LLAMA1B .54(.05) .65(.06) .54(.06) .65(.06)
basedmethodVPL(Poddaretal.,2024),wetraina LLAMA3B .51(.05) .61(.05) .50(.05) .59(.06)
variationalauto-encoderthatembeds8-shotsintoa ZEPHYR .53(.05) .62(.05) .52(.06) .61(.05)
MINISTRAL .53(.05) .63(.05) .53(.05) .62(.05)
singleembeddingtoken. Wealsoincludebaseline
prefixtag,anIDstringuniquetoeachuser.
Table1: Across4models,prefixedfinetuningwithgold
personasignificantlyimprovedtotalrewardaccuracy,
ActivePrefixes Forouroraclegoldpersona,we
generalizingtounseenpersonas. Parenthesis=standard
promptGPTtogeneratethebackgroundandprefer-
deviationacrosspersonas.
encesgiventhenameoftheperson. Thisistheonly
prefixwherethenamesarerevealedtotheinference
model. Forpersonaandpersonagpt4,weprompt qualityprefixestobecrucialforgeneralization. In
thebaselinemodelsandGPT4togeneratethesame thenextfewsectionsweseehowclosenon-oracle
information using four random shots7. Note that prefixescanclosethisperformancegap. Example
personaisuniquetoeachinferencemodel. personaprefixesareinAppendixG.2.
We perform five-fold cross-validation (CV)
across axes to evaluate generalization (“seen per- 4 Results&Discussions
son”vs“unseenpersona”)asmodelsneedtoper-
sonalize to new users without training in prac- 4.1 Qualityactivepersonasaremore
tice. We finetune four LMs across two model interpretableandimprovegeneralization
families: LLAMA1/3B, ZEPHYR(7B),andMINIS-
TRAL(8B)8.HyperparametersareinAppendixK. emb(↑) ra.emb(↓) R1(↑) ra.R1(↓) words(↓)
few-shot .22(.09) .15(.06) .19(.03) .18(.03) 563(111)
We show similar results with leave-one-axis-out
ZEPHYR .39(.08) .33(.07) .24(.04) .23(.03) 265(97)
finetuninginAppendixQ,exceptthatpersonasin
LLAMA1B .41(.09) .34(.09) .25(.04) .24(.04) 260(69)
axespoliticsandfamilyarehardtogeneral- LLAMA3B .42(.08) .36(.07) .26(.02) .25(.03) 252(59)
MINISTRAL .42(.08) .36(.07) .26(.04) .25(.03) 259(73)
GPT4 .41(.08) .32(.09) .28(.04) .26(.03) 209(35)
ize.
personagold - .49(.11) - .33(.10) 203(18)
3.3.1 EvaluationMetrics
Table2: Meanandstandarddeviation(acrosspersonas)
Weadoptinternalreference-freerewards9 fromRe-
ofLMinferredpersonaagainstpersonagoldcompared
wardBench (Rafailov et al., 2024; Lambert et al., toarandompersonagold. MINISTRALwinssemanti-
2024)simplicity,anditcanbecalculatedasπ(y w | cally,butpersonagpt4saremoreseparable.
x) > π(y | x)whereπistheLM,andweaverage
l
across(log)tokenprobabilities. Unlessotherwise Good active prefixes are shorter, more separa-
mentioned, we report reward accuracy averaged ble, more interpretable. Given oracle upper-
across personas in the unseen splits (50 personas bound, we first measure how good are the in-
acrossfivemodels,100questionseach). ferred personas compared to persona gold. We
useQwen3-Embedding10 cosinesimilarityand
3.4 DatasetValidation
rouge-1(Lin,2004)tomeasuresemanticsimilarity
Toverifythatpersonalprefixisnecessaryforour andspecificvocabularyrecallforeachmodel’sper-
dataset, we finetune gold persona and compare sona. Wealsoprovidebaselinecomparisonagainst
against no prefix MT baseline. In Table 1, we randompersonagold: alargergapbetweencorrect
seeacrossallmodels, usingpersonagoldsignif- vs. randompersonaindicatesbetterseparabilitybe-
icantly improved total reward accuracy (x tween personas. In Table 2, we see more recent
personal
+ x
divergent
), validating our dataset. We also see modelsperformbettersemantically,with MINIS-
goodgeneralizationinunseenpersonas,suggesting TRALontop,butpersonagpt4winsinseparability.
few-shotarenotbadinseparabilitybuttheworst
6Wefound2-shotstobetheoptimumnumberofshotswith
insemanticsimilarityandlength,thissuggeststhat
baselinemodelgiventhelongresponsenatureofourdataset
7Wefoundsignificantdegradationusingmorethanfour even though passive alignment (few-shot) might
shotsinpreliminaryexperiments. perform well in distinguishing user profiles, the
8meta-llama/Llama-3.2-1B-Instruct, meta-llama/Llama-
prefixesarelikelymuchlessinterpretable.
3.2-3B-Instruct,mistralai/Ministral-8B-Instruct-2410
9Itismoreintuitivelyalignedwithgenerationaswellas
findingsfromChenetal.(2024a). 10Qwen/Qwen3-Embedding-0.6B
0.6
0.5
ycaruccA
lanosreP
Prefix Types
no prefix few-shot persona gpt4 passive prefix
tag persona persona gold active prefix
vpl
0.7
0.6
0.5
Persona trained Persona not trained
ycaruccA
tnegreviD
0.7
0.6
0.5
0.4
0.35 0.40 0.45 0.50 0.55
Total Accuracy (Zephyr no prefix)
Figure2:Finetuningresultswith5-foldCVonZEPHYR.
Errorbarsindicate95%confidenceintervals(CI)across
personas. Dashed line indicates no prefix prompting
baseline. Good quality active prefix (persona gpt4)
generalizeswellespeciallyindivergentquestions.
Betteractiveprefixgeneralizesbetterindiver-
gent questions We plot MT(ZEPHYR) perfor-
mance across prefixes in Table 2. In passive pre-
fixes, both VPL and tag use a single token, yet
tag performs similarly to no prefix while VPL
performs much better. This suggests semantics
ratherthancapacityistheissueinassociatingpref-
erence with prefix. VPL also excels in personal
questionsbutfailsindivergentquestions,indicat-
ingembedding-basedmethodscompressfew-shots
informationwellbutfailstoencodesemanticcon-
trasts (i.e. embeddings for “I like lamp” is close
to that of “I don’t like lamp”) (Tang et al., 2022).
This suggests an important future direction is to
activelyinferpersonacompressedfrommoreshots.
Personagpt4outperformspersona,whichoutper-
formsfew-shot,suggestingpreciseandseparable
prefixes(Table2)aremoreeffective,notonlyfor
computational efficiency but also for generaliza-
tion, especially in divergent questions. We show
similarfindingswithothermodelsinTableM.No-
tably,LLAMA1/3B modelspreferfew-shotsover
self-generatedpersona,whereasitistheopposite
for ZEPHYR and MINISTRAL. InAppendixP,we
investigateprefixsensitivityusingshuffledandal-
ternativepersonasandfindpersonagpt4tobethe
mostrobustacrossvariations.11
More precise prefix, more equitable improve-
ments Weplotfinetuningtotalaccuracyonper-
sonanottrainedagainstprompting ZEPHYR with
11EventhoughGPT4generatesthedatasetandpersona
gpt4,MTcannotexploitanyshortcutstopredictpreferences,
sotheimprovementsstemspurelyfromprefixquality.
)TM(
ycaruccA
latoT
Prefix
no prefix (pearson r=0.61, p=2.2e-21)
tag (pearson r=0.63, p=3e-23)
vpl (pearson r=0.088, p=0.22)
few-shot (pearson r=0.25, p=0.0004)
persona (pearson r=0.31, p=8.3e-06)
persona gpt4 (pearson r=0.27, p=0.00012)
persona gold (pearson r=0.16, p=0.022)
Figure3: MT(personanottrained)vs. ZEPHYRwithno
prefix. WecalculatePearsoncorrelationwithp-value
perprefixes. Betterprefixesresultinlowercorrelation
and more equitable improvement. Dashed line is no
improvements(y=x). Shadedareasindicates95%CI.
no prefix in Figure 3. VPL improves the most
equitably across all personas (the most flat line),
whichindicatesthatcompressingmoreinformation
for each user is crucial. Persona gpt4, persona
andfew-shoteachoutperformsthenextwhilebe-
inglesscorrelatedtothebaseline,suggestingthat
higherqualityprefixesmightalsoalignmoreequi-
tably.
Additionalresults. InAppendixS, Uweshow
similar trends with generational evaluation, and
discussmitigatingalignmenttax(Leeetal.,2024).
4.2 Prefixqualityvs. ContributiveAttribution
Giventhatprefixescontrolrewarddistributions,it
is important to understand how model responses
arecausallydependentonprefixes(i.e. contextual
faithfulness). If algorithms use prefixes solely to
differentiate between users but disregard the un-
derlyingsemantics,finetunedmodelscouldlearn
fromspuriouscorrelationandexhibitcontextually
unfaithfulbehaviors. WeuseContextCite(Cohen-
Wang et al., 2024), to measure contributive attri-
bution from each sentence in the prefix to the re-
sponses(throughsurrogatemodeling12). Inother
words,thescores(x,y) ∈ RL,whereListhenum-
berofsentencesinaprefix,tellsushowimportant
eachsentenceistothelog-likelihoodoftheLMre-
sponse. Foreachpersonaandprompt,wecompute
thedifferences = s(x,y )−s(x,y ). InFig-
diff w l
ure4,weplots (groupedbyrewardaccuracy)
diff
forthetestquestionsofauseracrossfourprefixes
from MT (ZEPHYR) models. We see that active
personaprefixeshavemorecontributingsentences
thataremoreinterpretablethanpassivefew-shot
12WereferreaderstoCohen-Wangetal.(2024)fordetails.
80
60
40
20
0
20
40 60
0 1 2 3 4 5 6 7 8 9 10 11
Prefix Sentence Index
erocS
noitubirttA
persona gold with Chaz Bono, 72/100 Reward Prediction is Accurate
** * * * ** * ** ** results
success
fail
01258911 ::::::01 :: CHBHHR CY e o he eis o s n a a w w u pp o z te o a oe m B i rn u s r s o s a dt l bado h n y o t n e o pa o c r a rl n r i h sl s o te h a o v mi s an e n a p p n i g l Ln of ru e o oA o n e e l s b m n sl t so he at Ae w s e bfn t e r i l io i gg y n s e c t u e gh m a a y rl n o e l pe p ew t s p r a o , i o , nr d ct e m C g h v o tcr a e h o p n ia l a y c e t t i v f e t a o fie m L n t t r rG a o e t n a i t ,gm , Bi n e a lh w T e , a t tt Q r n oh a s i lg t + i wi s n k e s t i d e a s r h c p , t , r , oi a ed ms av mn rs go t s u t hm r oo c s e t e a pn i hu e c b e. c an i u a n w h tit n l n i ia cyl t e d a rh , a s y n n , ho s , d o a f ,k o r v f ie a p n ai b en n i c m ne pg lu i a o oi hp s c n u n ii t u t mo s , o e b n s re r l . ,u te in c a pa s tl nt ye nd ec r dac de t t oa , ae i mi n c o d n c .r eea e a r bp os n o u t y S aut o n r tan e ccsn l eu e ya , v r ir a Bl nee n d o ns t n itb c a oiea a s vt an p ee n e d in dn c tb t s C1 s y h 9a o h e n9 f i r d5 s . y , o an a u lel n - r we d r sm e l ac s b t p or en o a r n cc aei s n s e rgn a b ina a t dgr s a v e Ln o d Gs c Bg o a n eTcy n Q t d h +w e e o r i i r s r m ks b u, a a et n c hs k e i g an r r en o 2 fdo u 0 rr n 0 ei d g8 a . h. nts A.I assistant that mirrors these values and preferences would be ideal for Chaz Bono.
100
75
50
25
0
25
50
75
0 1 2 3 4 5 6 7 8 9 10 11 12
Prefix Sentence Index
erocS
noitubirttA
persona gpt4 with Chaz Bono, 73/100 Reward Prediction is Accurate
** * * ** ** results
success
fail
34111 ::012 ::: TA h RCY d o e ed au si t ut e pi m so ro e n a nt r h a y d 's e l l c ty i ro h n, e a qtts hh n u p ee g i o r e y n uf o s s t a l he el b o e ro t 'w o su s i t t nr hy eg f ol qi e w l p mu , re ct s oh s o m wt en y f t p iot e t h m r n fa t p ri,go o v lhm s e a t i n t rtl ii gi v he kt e id eh s , , , r p ed av e pi go er r rc ste ea ao s eb rn e y u .w n- l ct iat ao rh tn y, io s ,o cn or is p o b i uo ne sf i o i dm nn i t v , e e e s a r r te ls a s pe nt l ec ag de ne , n i s no du .r eg a rg n eid y se t r sn e t l a e it v ipe a es n r si t s o a na s an p lo e it c nh t te s e rr o es f s t y rto o inn u g r m r in e a s din p ict o aa n itn s o e irn o b gf a at s h e he d ei ra o lc n toh t my h e lmi i f r ei ts b mt a ye c lne k t g o r tr o o u p a n ocs d cs . uibralyt eis, pinovsoitlivveed p woritthra eyvael natn odr n porromjeacltis paltaionnn ionfg a wllh geerned deire tidaeryn tinitcieluss.iveness is a consideration.
150
100
50
0
50
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14
Prefix Sentence Index
erocS
noitubirttA
persona with Chaz Bono, 58/100 Reward Prediction is Accurate
* * * ** results
success
fail
2381 :::3 : III ratC e rm ay c t e te ao n r tpbt l h ry eo e mua r dn o e v s map e ced otmin v t s o eb e et l i hr tso eot e h fc no tit eh w y re f at to hnrr e ad w y n a so ml r lcy k i o g tma ho n t m m d li u ka hn er a , igt v a yi e ng aa b r nle e izd e e e nt wda i akct d h eo j , m u g o srmr et ia bu nt en g ci it t n ai o et r e es m ,r t e y ao s n n t ede ed d w Iu a i c n s mau . tr ec r o omu m nymsdei i n tlft g eos dn. tmo autstienrgs mreyla pteladt ftoor mge tnod perro idmeontteit tyh aensed ceaxupsreesss.ion.
60
40
20
0
20
40
60
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32
Prefix Sentence Index
erocS
noitubirttA
few-shot with Chaz Bono, 67/100 Reward Prediction is Accurate
* ** results
success
fail
1204:: C#h#r#is tPorpehfeerrr Sedtr eReets Lpiobnesrea:tion Day (Gay Pride), New York City - 1970
Figure4: Attributions
diff
foreachsentencewithinprefixesforChazBonowithMT(ZEPHYR)model(persona
unseen), grouped by reward accuracy of the questions. For each sentence, we perform student t-test between
success/failscoresandmark*(p<0.05)and**(p<0.01)atthetop. Eachmarkedsentenceisalsodisplayedintext
alongwithitsindices. Activepersonaprefixeshavemorecontributingsentencesthataremoreinterpretable.
prefix. Thistrendholdsforhigherqualitypersonas Model persona few-shot
(gold>gpt4>persona).
LLAMA1B 0.052(.067) 0.045(.057)
LLAMA3B 0.100(.162) 0.117(.112)
Prefix few-shot persona personagpt4 personagold ZEPHYR 0.199(.165) 0.140(.105)
MINISTRAL 0.218(.181) 0.106(.093)
Influencefraction .14(.11) .20(0.17) .36(0.22) .40(.20)
Table3: IFacrosspersonas(unseen)inMT(ZEPHYR). Table4: IFacrossthreeoutoffourmodelsshowself-
Better performing prefixes results in models that are generated active persona leads to more contextually
morecontextuallyfaithful. faithfulmodels.LargerLMsattributestopersonamore.
Withanintuitiveunderstandingofthescorequal-
nificantly(p < 0.05)contributetocorrectreward
itatively,weoperationalizethisasametricwhich
predictionacrossthetest-splitoftheperson13. A
we can measure qualitatively across models and
prefixwithhigherIFindicatesthatmodelsaremore
prefixes. Foreachpersona,wecalculateinfluence
fraction (IF): the fractions of sentences that sig- 13Equivalenttofractionsofsentencewith*inFigure4
causally influenced (i.e. contextuallyfaithful) by Prefix Finetuned InfluentialFraction
theprefix. InTable3,weseethatbetterperform-
few-shot false 0.011(.019)
ingprefixesresultinhigherIF.InTable4,wesee true 0.140(.105)
threeoutoffourmodelsattributetoself-generated
persona false 0.141(.108)
true 0.200(.165)
personamorethanfew-shot,despite LLAMA1B personagold false 0.016(.033)
performingbetterwithfew-shot. Theseresultssug- true 0.399(.202)
gests that better quality active prefixes results in
more contextually faithful models, and even self-
Table 6: Unfinetuned ZEPHYR attributes to self-
generatedpersonamuchbetterthanotherprefixes(high-
generatedpersonacouldleadtobetterattribution.
lighted), suggesting simple rephrasing with base LM
couldleadtomorecontextuallyfaithfulgenerations.
4.3 PrefixDistributionalShiftvs. Attribution
InTable15weshowthatqualityactively-inferred
Prefix Train Inference PositiveFractions
personasarerobusttosurfaceformvariationsbut
bm25 bm25 0.224(.142)
dropperformancewithprefixfromarandomper-
bm25 bm25(reverse) 0.220(.141)
son. Hereweinvestigateattributionsensitivitiesto bm25 - 0.221(.137)
few-shot
varyinginferenceprefixes. - bm25 0.213(.176)
- bm25(reverse) 0.197(.178)
- - 0.197(.170)
TrainPrefix InferencePrefix IF
bm25 bm25 0.282(.177)
few-shot (sameastrain) 0.140(.105) bm25 bm25(reverse) 0.274(.180)
few-shot(alt.seed) 0.142(.087) bm25 - 0.263(.173)
persona
- bm25 0.253(.141)
persona (sameastrain) 0.199(.165)
- bm25(reverse) 0.248(.143)
persona(alt.seed) 0.170(.160)
- - 0.238(.138)
personagpt4 0.179(.158)
personagold 0.145(.153)
Table 7: Number of sentences with positive s in
diff
personagold (sameastrain) 0.398(.202)
ZEPHYR trainedand/orinferencedonretrievedshots.
persona 0.257(.174)
Dash indicates fixed original prefix. Training on re-
personagpt4 0.283(.202)
trievedprefixesincreaseattributionmoresignificantly
forpersonathanfew-shot.
Table5: IFwithalternativeprefixesatinferencetime
forMT(ZEPHYR). Faithfulnessalwaysdecreaseswith
alternativeprefix,andmodelstrainedwithhigherquality
Retrievalduringtrainingimprovescontextual
prefixremainmorefaithful.
faithfulness,moreduringtrainingandwithper-
Qualitypersonaiscrucialduringtrainandtest.
sona. A prefix has different aspects that can in-
InTable5,wecanseebothfew-shotandpersona
fluencepreferencesontheresponsetoaquestion
attributesimilarlytoaprefixusingdifferentshots
(i.e. HalleBerryhasdiabetesandisalsoanAfrican
(alt. seed). Uniquetoactiveprefixes,wecaninfer
AmericanActress),andtheaspectthatinfluences
with varying quality of personas to see if model
thepreferencedistributionforeachquestionmay
adapttochanges. Unfortunately,distributionalshift
bedifferent. Majorityofourinvestigationtrainsa
only lowers attribution, even if we increase the
staticprefixforallquestions. Suchstaticprefixes
qualityofpersonaatinferencetime.
needtocoverallaspectsofthepersona,andLMs
Self-generatedactivepersonamorecausal In havetoselecttherelevantinformationduringgen-
Table 6, we look into IF before and after finetun- eration,placinganupperboundonIF.However,if
ing. Unfinetuned ZEPHYR attributes to persona weweretoprovidedynamicprefixesthatcontain
morethanfew-shotorevenpersonagold,despite relevant information only through retrieval, can
failingatrewardaccuracy(AppendixI). ZEPHYR wefurtherincreasecontextualfaithfulness? Toin-
increasedattributionthroughsimplyinferringpref- vestigatethis,wedynamicallyretrieveshotswith
erences from out-of-distribution few-shot exam- BM25(Robertson et al., 1993; Lù, 2024) that are
plestoin-distributionpersona. Thisispotentially closesttocurrenttrain/testquestionastheprefix.
usefulfordebuggingmodelfaithfulnessingeneral At test time, we vary prefix with static, retrieved
(Turpin et al., 2023), where generations are not prefix,andreverseprefix(shotsfarthestindistance).
reflectiveofinternalmechanisms.14 InsteadofIF,weusepositivefraction: thefraction
of sentences with positive s . In Table 7, we
14WedidnotobservesimilarbehaviorwithLLAMA1/3B, diff
suggestingtheresponsesbeingon-policyisalsocrucial. can see that training with retrieved shots indeed
Top10EasiestPersonastoInfer
across SerenaWilliams(10.0),MikeTrout(10.8),ChazBono(13.4),BernieSanders(13.4),BarackObama(14.6),
shots MeganFox(14.6),LeBronJames(14.8),RichardGere(15.8),DavidBeckham(16.0),JenniferAniston(16.8)
across Beyoncé(13.0),SerenaWilliams(13.2),ZaynMalik(13.6),LeBronJames(14.6),AlexandriaOcasio-Cortez(15.0),
models JenniferAniston(16.4),J.K.Rowling(16.8),DavidBeckham(17.0),MikeTrout(17.0),ChazBono(17.8)
Bottom10HardestPersonastoInfer
across YoshuaBengio(40.8),SamSmith(40.8),MerylStreep(37.8),LatanyaSweeney(37.2),RichardDawkins(33.4),
shots TimnitGebru(33.0),RobertDeNiro(32.8),DonaldTrump(32.6),BillClinton(32.2),OprahWinfrey(30.8)
across SuchiSaria(41.2),YoshuaBengio(38.6),MillieBobbyBrown(38.4),SherylSandberg(37.0),HalleBerry
models (36.6),SamSmith(34.4),BillClinton(32.2),TigerWoods(32.2),LaverneCox(31.0),BillieEilish(30.8)
Table8: Easiestandhardestpersonasbyinferredpersonaquality(averagerankinparenthesis). Colorednames
appearinbothsplits. Weseepersonasinaxissportsand(liberal)politicsareconsistentlyeasytoinferfor
LMs,whilethoseinAI Professorsarehard.
attribute econ.status birthcountry education prof. curr.state religion marriage
persona 0.02 0.05 0.07 0.11 0.22 0.22 0.23
personagpt4 0.02 2e-3 0.17 6e-11 1e-4 3e-4 0.37
personagold 3e-5 0.05 3e-5 2e-13 2e-4 0.08 0.02
few-shot 5e-3 0.02 4e-4 3e-8 1e-4 0.14 0.03
attribute birthstate ethnicity age sexpref. curr.country gender race politics
persona 0.28 0.35 0.39 0.39 0.44 0.45 0.55 0.98
personagpt4 4e-4 2e-4 0.09 0.5 0.16 0.01 0.52 0.58
personagold 8e-5 0.05 0.04 0.06 0.1 2e-5 0.67 0.53
few-shot 0.02 8e-5 2e-3 0.13 0.02 2e-3 0.02 0.43
Table9: P-valuesofone-tailANOVAacrossfourmodelsbeforeandafterfinetuningshowthatfew-shotimprove-
ments are non-uniform (in 12/15 attributes) where as persona improvements are much more equitable (2/14).
Increasingpersonaspecificityandquality(persona→personagpt4→personagold)decreasesimprovement
equity,suggestingaperformancevs. fairnesstrade-off.
increasescontextualfaithfulnessandpersonaben- eragedranks. Weseethatpeopleinaxissports
efitsmorethanfew-shot. Lessimprovementsare and(liberal)politicsconsistentlyappearinthe
observedattesttime. top,whileAI professorsoftenatthebottom.
We suspect this is because public information on
4.4 SystematicBiaswithPersonas? athletes are mostly single-faceted, and the only
underspecification is the sport they play. Liberal
Personainferenceanddatasetbiasexists. Pre-
politicians’viewsondifferentissuesmaybehighly
vious experiments showed that quality actively-
correlated (e.g. supporting minimumwagesindi-
inferredpersonaimproverewardgeneralizationand
catesstronglytheirstanceongaymarriage). Public
result in a model that is more contextually faith-
informationonAI professors,bycontrast,is
ful. However, given the personas are generated,
mostlybasedonobjectivelywrittenpaperswhich
we need to be cautious against systematic biases
revealslittleabouttheirpersonalviews.
(Kovacˇ et al., 2023). We investigate two sources
of bias: persona inference, and finetuning with
Activealignmentmoreequitablethanpassiveaf-
inferred persona. To check whether there is bias
terfinetuning Somepreferencesmightbeeasier
forpersonainference,werepeatpersonainference
tolearnduringfinetuning,skewingoverallprefer-
1) across shots 2) across models with the same
shots15,andmeasurepersonaqualityagainstper- encedistributions. Wecomparetotalrewardaccu-
racydifferencebetweenMTandbaselines(using
sonagold. Weaveragez-scorenormalizedrouge-1
persona prefix) across four baseline LMs to un-
andembeddingsimilarity(Section4.1)andaverage
derstandbiasesfromfinetuning. Weuseone-way
eachperson’sscorerank∈ (0,50). InTable8,we
ANOVA (Lowry, 2014) to test uniformity of im-
show the top and bottom 10 people and their av-
provements across groups (See Appendix F.2,R
15Fourpersonamodels+MT(ZEPHYR)personagpt4 fordemographicsstatisticsandvisualizations). In
Table9,weseethatfew-shotprefixresultsinnon- distributionwhichchangesovertime,whichwould
uniformimprovementsinmoreattributesthanper- beinterestingtomodelinfutureworks. Lastly,we
sona. Wesuspectthisisbecausepersonainference assumefindingsfromourpaperwillgeneralizeto
introducesnoiseand“diffuses”awaystatisticalbi- non-famouspeoplebecauseweinferprefixesper-
ases. Indeed, when we compare persona with in- sona/personagpt4withoutrevealingthenameof
creasingspecificity/quality(persona→persona theperson. However,thequestionsandpreferences
gpt4 → persona gold), improvements becomes couldbebiasedandspecifictofamouspeopleonly.
less equitable. This suggests an inherent trade- Due to its synthetic nature, it is also not impossi-
offbetweenimprovingpersonalizedperformance bleforouroraclepersonagoldtocontainbiased
vs. beingequitable,likelyduetoimbalancedpara- assumptionsthathumansalsomakefromathird-
metric knowledge LMs have on different demo- person perspective. Hence there could be further
graphics. Webelievethistobeanimportantfuture biasesthatwewerenotabletofind.
direction: balancingfairnessvs. improvements.
Betterdiversityinresponses(y). Whengener-
atingcandidateresponseswithCoT,wefinditto
5 Conclusions
influencecontentsthemost,leavingotherstylistic
We constructed FamousPersona, a personalized features mostly unchanged. Future work should
alignmentdatasetonfamouspeople,toanswerour lookintowaystodiversifygenerationsbeyondcon-
research question: is active alignment (inferring tent, which will also make preferences more nu-
personalpreference)betterthanpassivealignment ancedandchallengingtoinfer. Additionally,even
(simplyusingfew-shots)? Resultsfromrewardac- thoughweaimtogeneratediverseresponse,there
curacy generalization, prefix attribution patterns, isnoguaranteethatwewillendupwithonethatis
and bias analysis confirm that actively inferring agoodresponse(allresponsesmightstillbebad).
personaiscrucialforinterpretableandrobustper- Inthesecases,providingmultipleresponseswith
sonalizedalignment. Futurestudiesshouldfocus point-wiseestimationofrewardmightbeabetter
on how to further evaluate and de-bias inferred datasetconstructionmethod. However,itismuch
persona,anddynamicallymodifypersonaprefixes harder for LLM-as-personal-judge. Additionally,
accordingtotheuserquery. wechosetogenerateresponseswith ZEPHYRonly
because we were interested on-policy effects of
Limitations
alignment. To improve the general utility of the
datasetasgenericfinetuningdata,wewouldhave
Ourdatasetpresentsaplaygroundthroughwhich
generated diverse responses with multiple more
boththeoreticiansandpractitionersinAIalignment
capablemodels.
canempiricallyvalidatetheirmethods. Weseparate
limitationsandfutureworksinthefollowingtwo Adaptivepersonalization. Ourresponsegenera-
directions: tionprocessalsomimicsthetrade-offbetweenthe
exploration vs. exploitation problem in RL: is it
Datasetimprovement
bettertoplaysafeandgenerateagenerically-good
Better axes, prompt generation, and label fi- answerorriskformorepersonalizedanswer. Fu-
delity. Theselectionofaxesisnotrepresentative ture work could look into the process through an
ofallaxesthroughwhichhumanpreferencediffers. online/activelearningperspective,balancinggen-
Howeveronecouldarbitrarilyextendthedatasetto eral response quality vs. venturing into personal-
axisofinteresttostudy(e.g. moral,ethicalvalues). ization. Asking follow up clarification questions
Onecouldalsoextendtoincludepeoplefamousin seemslikeapromisingdirection.
differentcountries(andspeakdifferentlanguages),
Betterpreferencemodeling
extending personal preference alignment to mul-
tilingual setting. The quality of our dataset also Tuning on preference inference We did a pre-
dependsonGPT4nothallucinatingwhengenerat- liminary experiment where we train MT models
ingquestions(x)andlabelingpreferences(y /y ). to predict persona gpt4 (over a wrong persona
w l
Onevaliddirectionisactuallyobtainingxorpref- throughDPOobjective)inadditiontoaligningpref-
erence labels from the people we are modeling, erences, similar to a reasoning distillations setup
andunderstandthetrueannotationquality. Beyond (Mukherjeeetal.,2023), whereweconsiderper-
label fidelity, personal preferences is a dynamic sonagpt4asthereasoningtrace. Wedidnotsee
muchimprovement. Futureworkcanexplorefur- ingpersonapreferences,henceeverypersoninthe
therleveragingfindingsinimprovingreasoningin datasethasafixed,detailed,personathatgrounds
LMs(Haoetal.,2024). Onecouldalsopotentially theirquestionsandpreferences. However,itmay
findmiddlegroundbetweentrainingpersonalmod- stillbeanopenquestionhowmuchactivepersona
els(PM)andMTbyfindingtrainingandretrieving inferencehelpsoninteractionswheretheremaynot
“prototypical” personas (Zhong et al., 2024). We beaclearpreferencethatgeneralizesuserbehavior
focusonouranalysison MT models. inothersituations.
Alternativeobjectives Inourwork,wefocuson Ethicalconsiderations
simple methods that are scalable, efficient, and
high-performing. However, many other objec- OurdatasetisentirelygeneratedfromGPT4,hence
tivesandmethodologiesareequallyimportantand thedataset(frompersonaselection,topromptgen-
promising. During multi-task stage learning, we eration and preference labeling) is dependent on
didnotconsidertheperspectiveofdifferentialpri- thequalityofGPT4. Wedonotclaimpersonasin-
vacy (Salemi and Zamani, 2024), whereas in the cludedinourdatasetarefaithfultotheirrealworld
real world, the use of personal data for generic counterparts,norpersonas’belief/preferencestobe
trainingrequiresfurtherscrutinizing. Asoutlined universallygoodorbad,butofferaplaygroundto
bySorensenetal.(2024),onecouldalsoalignto constructsetsofpersonaswithuniqueanddiverse
diverse expectations by explicitly generating all preferences. The authors manually read through
outputpreferences(“overton”),whichcomeatthe mostifnotallpromptsandresponsestomakesure
costofverbosity. Givenourfindingonalignment therearenooffensivecontent. Weemphasizethat
tax,futureworkcanalsoexplorethetrade-offbe- personas’questions,opinions,andpreferencesare
tween personalization and general capability by not the same as the real people they are modeled
adaptingprefixeswithdifferentlevelsofspecifica- after. Modelstrainedonourdatasetshouldnotbe
tionatinferencetime. usedtoimitatefamouspeople’sopinionsotherthan
forresearchpurpose.
FutureAnalysis Although not specific to our dataset, personal-
Scaling up model sizes. Due to compute con- izationcreatesan“echochamber”inwhichusers
would be catered responses that they agree with,
straints,wewerenotabletorunexperimentswith
aggravatingtheissueofsycophancy(Sharmaetal.,
models larger than 8B sizes. It would be inter-
estingtoconfirmwhethertheadvantageofactive 2023). Thereisalsothedangerofgeneratingpo-
prefix over passive increases with larger model tentially unsafe content from personalizing to in-
dividualswithextremeideologiesthatareharmful
scale. Why do some models attribute to prefixes
to themselves or others. Other than the solution
more than others? We thought another reason
we propose of removing personal prefix at infer-
LLAMA1/3B models might perform better with
few-shot is because they were trained on more encetime,webelievethereshouldbeahardlimit
to which personalization can go, perhaps imple-
few-shotdata,henceabletoleveragethefew-shot
mentedthroughmeansofKLdivergence(Rafailov
formatbetter. Withouttransparencyofthetraining
etal.,2024).
proceduresthishypothesisishardtoverify.
Belief projection is another concern in model
Why the bias reduction? Why are active pre- alignment where models make unwarranted as-
fixesabletoreducebiascomparedtopassivepre- sumptions of users given contextual clues. An
fixes? From Appendix R we see persona’s im- importantaspectpersonainferenceistoexplicitly
provementaremoremildandequalacrossdiffer- statetheassumptionsthatmodelshave,suchthat
ent attributes. We conjuncture that this might be thewrongassumptionscanberemovedifnecessary.
thenoiseintroducedinthepersonainferencepro- However,itisimportanttodiscusswheretheright
cess. However,ifthatisthecase,wouldmodelstart lineshouldbebetweenmakingstatistically-based
associatingnon-robustfeatureswithpreferencedis- assumptionsvs. stereotyping.
tributions? Orperhapsitistheexplicitmentioning
ofattributionsthatimprovedit? Acknowledgments
Evaluation on other datasets We constructed WethankPiotrTeterwak,MaanQraitem,Najoung
ourdatasetspecificallyforthepurposeofevaluat- Kim,HayleyRoss,YusufKocygit,GabrielFranco,
Micah Benson for their helpful discussions and Kyunghyun Cho. 2024a. Preference learning al-
advice. Wethankannotatorsfortheirmeticulous gorithms do not learn preference rankings. arXiv
preprintarXiv:2405.19534.
annotationsandanonymousreviewersfortheircon-
structivefeedback. JinChen,ZhengLiu,XuHuang,ChenwangWu,QiLiu,
GangweiJiang,YuanhaoPu,YuxuanLei,Xiaolong
Chen,XingmeiWang,etal.2023. Whenlargelan-
References guage models meet personalization: Perspectives
of challenges and opportunities. arXiv preprint
LoraAroyoandChrisWelty.2015. Truthisalie:Crowd arXiv:2307.16376.
truthandthesevenmythsofhumanannotation. AI
Magazine,36(1):15–24. RuizheChen,XiaotianZhang,MengLuo,WenhaoChai,
andZuozhuLiu.2024b. Pad:Personalizedalignment
Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda atdecoding-time. arXivpreprintarXiv:2410.04070.
Askell, AnnaChen, NovaDasSarma, DawnDrain,
Xiusi Chen, Hongzhi Wen, Sreyashi Nag, Chen Luo,
StanislavFort,DeepGanguli,TomHenighan,etal.
Qingyu Yin, Ruirui Li, Zheng Li, and Wei Wang.
2022. Trainingahelpfulandharmlessassistantwith
reinforcementlearningfromhumanfeedback. arXiv 2024c. Iteralign: Iterativeconstitutionalalignment
preprintarXiv:2204.05862. oflargelanguagemodels. InProceedingsofthe2024
Conference of the North American Chapter of the
NishantBalepur,VishakhPadmakumar,FumengYang, AssociationforComputationalLinguistics: Human
ShiFeng,RachelRudinger,andJordanBoyd-Graber. Language Technologies (Volume 1: Long Papers),
2025. Whoseboatdoesitfloat? improvingperson- pages1423–1433.
alizationinpreferencetuningviainferreduserper-
HyeongKyuChoiandYixuanLi.2024. Beyondhelp-
sonas. AssociationforComputationalLinguistics.
fulnessandharmlessness:Elicitingdiversebehaviors
TilmanBeck,HendrikSchuff,AnneLauscher,andIryna fromlargelanguagemodelswithpersonain-context
Gurevych. 2024. Sensitivity, performance, robust- learning. arXivpreprintarXiv:2405.02501.
ness: Deconstructingtheeffectofsociodemographic
PeterClark,IsaacCowhey,OrenEtzioni,TusharKhot,
prompting. InProceedingsofthe18thConferenceof
AshishSabharwal,CarissaSchoenick,andOyvind
theEuropeanChapteroftheAssociationforCompu-
Tafjord.2018. Thinkyouhavesolvedquestionan-
tationalLinguistics(Volume1: LongPapers),pages
swering? tryarc,theai2reasoningchallenge. ArXiv,
2589–2615.
abs/1803.05457.
YonatanBisk,RowanZellers,RonanLeBras,Jianfeng
Benjamin Cohen-Wang, Harshay Shah, Kristian
Gao,andYejinChoi.2020. Piqa: Reasoningabout
Georgiev,andAleksanderMadry.2024. Contextcite:
physicalcommonsenseinnaturallanguage. InThirty-
Attributingmodelgenerationtocontext. Advancesin
FourthAAAIConferenceonArtificialIntelligence.
NeuralInformationProcessingSystems,37:95764–
95807.
MillenniumBismay,XiangjueDong,andJamesCaver-
lee.2025. Reasoningrec: Bridgingpersonalizedrec-
Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi
ommendationsandhuman-interpretableexplanations
Zheng,ShengdingHu,ZhiyuanLiu,MaosongSun,
throughllmreasoning. InFindingsoftheAssociation
andBowenZhou.2023. Enhancingchat language
forComputationalLinguistics: NAACL2025,pages
modelsbyscalinghigh-qualityinstructionalconver-
8132–8148.
sations. Preprint,arXiv:2305.14233.
Steve Byrnes. 2023. Plan for mediocre alignment of XuanLongDo,KenjiKawaguchi,Min-YenKan,and
brain-like[model-basedRL]AGI—AIAlignment Nancy F Chen. 2023. Choire: Characterizing and
Forum — alignmentforum.org. [Accessed 22-10- predicting human opinions with chain of opinion
2024]. reasoning. arXivpreprintarXiv:2311.08385.
Louis Castricato, Nathan Lile, Rafael Rafailov, Jan- HanzeDong,WeiXiong,DeepanshuGoyal,RuiPan,
PhilippFränken,andChelseaFinn.2025. Persona: Shizhe Diao, Jipeng Zhang, Kashun Shum, and
Areproducibletestbedforpluralisticalignment. In TongZhang.2023. Raft: Rewardrankedfinetuning
Proceedingsofthe31stInternationalConferenceon for generative foundation model alignment. arXiv
ComputationalLinguistics,pages11348–11368. preprintarXiv:2304.06767.
SouradipChakraborty,JiahaoQiu,HuiYuan,AlecKop- YijiangRiverDong,TianchengHu,andNigelCollier.
pel, Furong Huang, Dinesh Manocha, Amrit Bedi, 2024. Can llm be a personalized judge? arXiv
and Mengdi Wang. 2024. Maxmin-rlhf: Towards preprintarXiv:2406.11657.
equitablealignmentoflargelanguagemodelswith
diversehumanpreferences. InICML2024Workshop YannDubois,XuechenLi,RohanTaori,TianyiZhang,
onModelsofHumanFeedbackforAIAlignment. IshaanGulrajani,JimmyBa,CarlosGuestrin,Percy
Liang,andTatsunoriB.Hashimoto.2023. Alpaca-
Angelica Chen, Sadhika Malladi, Lily H Zhang, farm:Asimulationframeworkformethodsthatlearn
Xinyi Chen, Qiuyi Zhang, Rajesh Ranganath, and fromhumanfeedback. Preprint,arXiv:2305.14387.
EsinDurmus,KarinaNyugen,ThomasILiao,Nicholas AriHoltzman,JanBuys,LiDu,MaxwellForbes,and
Schiefer, Amanda Askell, Anton Bakhtin, Carol Yejin Choi. 2019. The curious case of neural text
Chen, Zac Hatfield-Dodds, Danny Hernandez, degeneration. arXivpreprintarXiv:1904.09751.
Nicholas Joseph, et al. 2023. Towards measuring
the representation of subjective global opinions in Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu,
languagemodels. arXivpreprintarXiv:2306.16388. YuanzhiLi, SheanWang, LuWang, WeizhuChen,
etal.2021. Lora: Low-rankadaptationoflargelan-
Kawin Ethayarajh, Yejin Choi, and Swabha guagemodels. InInternationalConferenceonLearn-
Swayamdipta. 2022. Understanding dataset ingRepresentations.
difficultywithV-usableinformation. InProceedings
of the 39th International Conference on Machine JamesYHuang,SailikSengupta,DanieleBonadiman,
Learning, volume 162 of Proceedings of Machine Yi-anLai,ArshitGupta,NikolaosPappas,SaabMan-
LearningResearch,pages5988–6008.PMLR. sour, Katrin Kirchoff, and Dan Roth. 2024. Deal:
Decoding-timealignmentforlargelanguagemodels.
Shangbin Feng, Taylor Sorensen, Yuhan Liu, Jillian arXivpreprintarXiv:2402.06147.
Fisher, Chan Young Park, Yejin Choi, and Yulia
Tsvetkov.2024. Modularpluralism: Pluralisticalign- EunJeongHwang,BodhisattwaMajumder,andNiket
mentviamulti-llmcollaboration. CoRR. Tandon. 2023. Aligning language models to user
opinions. In Findings of the Association for Com-
Jan-PhilippFränken,SamuelKwok,PeixuanYe,Kan- putationalLinguistics: EMNLP2023,pages5906–
ishkGandhi, DilipArumugam, JaredMoore, Alex 5919.
Tamkin, Tobias Gerstenberg, and Noah Goodman.
2023. Socialcontractai: Aligningaiassistantswith Joel Jang, Seungone Kim, Bill Yuchen Lin, Yizhong
implicitgroupnorms. InSociallyResponsibleLan- Wang, Jack Hessel, Luke Zettlemoyer, Hannaneh
guageModellingResearch. Hajishirzi,YejinChoi,andPrithvirajAmmanabrolu.
2023. Personalized soups: Personalized large lan-
IasonGabriel.2020. Artificialintelligence,values,and guagemodelalignmentviapost-hocparametermerg-
alignment. Mindsandmachines,30(3):411–437. ing. arXivpreprintarXiv:2310.11564.
LeoGao,JonathanTow,BaberAbbasi,StellaBiderman, Jiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi
SidBlack,AnthonyDiPofi,CharlesFoster,Laurence Zhang,CeBian,BoyuanChen,RuiyangSun,Yizhou
Golding,JeffreyHsu,AlainLeNoac’h,HaonanLi, Wang, and Yaodong Yang. 2024. Beavertails: To-
KyleMcDonell,NiklasMuennighoff,ChrisOciepa, wardsimprovedsafetyalignmentofllmviaahuman-
Jason Phang, Laria Reynolds, Hailey Schoelkopf, preferencedataset. AdvancesinNeuralInformation
Aviya Skowron, Lintang Sutawika, Eric Tang, An- ProcessingSystems,36.
ishThite, BenWang, KevinWang, andAndyZou.
2024a. Aframeworkforfew-shotlanguagemodel LiweiJiang,SydneyLevine,andYejinChoi.2024. Can
evaluation. languagemodelsreasonaboutindividualistichuman
values and preferences? In Pluralistic Alignment
Songyang Gao, Qiming Ge, Wei Shen, Shihan Dou, WorkshopatNeurIPS2024.
JunjieYe,XiaoWang,RuiZheng,YichengZou,Zhi
Chen, Hang Yan, et al. 2024b. Linear alignment: Maxim Khanov, Jirayu Burapacheep, and Yixuan Li.
A closed-form solution for aligning human prefer- 2024. Args: Alignmentasreward-guidedsearch. In
ences without tuning and feedback. In Forty-first The Twelfth International Conference on Learning
InternationalConferenceonMachineLearning. Representations.
Robert Geirhos, Jörn-Henrik Jacobsen, Claudio Jaehyung Kim and Yiming Yang. 2024. Few-shot
Michaelis, Richard Zemel, Wieland Brendel, personalizationofllmswithmis-alignedresponses.
Matthias Bethge, and Felix A Wichmann. 2020. CoRR.
Shortcutlearningindeepneuralnetworks. Nature
MachineIntelligence,2(11):665–673. HannahRoseKirk,AlexanderWhitefield,PaulRöttger,
AndrewBean,KaterinaMargatina,JuanCiro,Rafael
DavidGoldberg,DavidNichols,BrianMOki,andDou- Mosquera, Max Bartolo, Adina Williams, He He,
glas Terry. 1992. Using collaborative filtering to etal.2024. Theprismalignmentproject: Whatpar-
weaveaninformationtapestry. Communicationsof ticipatory,representativeandindividualisedhuman
theACM,35(12):61–70. feedbackrevealsaboutthesubjectiveandmulticul-
tural alignment of large language models. arXiv
Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, preprintarXiv:2404.16019.
ZhitingHu,JasonWeston,andYuandongTian.2024.
Traininglargelanguagemodelstoreasoninacontin- OliverKlingefjord,RyanLowe,andJoeEdelman.2024.
uouslatentspace. arXivpreprintarXiv:2412.06769. Whatarehumanvalues,andhowdowealignaito
them? arXivpreprintarXiv:2404.10636.
SethHerd.2023. Wehavepromisingalignmentplans
withlowtaxes—AIAlignmentForum—alignment- GrgurKovacˇ,MasatakaSawayama,RémyPortelas,Cé-
forum.org. [Accessed22-10-2024]. dric Colas, Peter Ford Dominey, and Pierre-Yves
Oudeyer. 2023. Large language models as super- YongLin,LuTan,HangyuLin,ZemingZheng,Renjie
positions of cultural perspectives. arXiv preprint Pi,JipengZhang,ShizheDiao,HaoxiangWang,Han
arXiv:2307.07870. Zhao, Yuan Yao, et al. 2023. Speciality vs gener-
ality: Anempiricalstudyoncatastrophicforgetting
KlausKrippendorff.2011. Computingkrippendorff’s in fine-tuning foundation models. arXiv preprint
alpha-reliability. arXiv:2309.06256.
Nathan Lambert, Valentina Pyatkin, Jacob Morrison, ChunmingLiu,XinXu,andDewenHu.2014. Multi-
LJ Miranda, Bill Yuchen Lin, Khyathi Chandu, objectivereinforcementlearning: Acomprehensive
NouhaDziri,SachinKumar,TomZick,YejinChoi, overview. IEEETransactionsonSystems,Man,and
NoahA.Smith,andHannanehHajishirzi.2024. Re- Cybernetics: Systems,45(3):385–398.
wardbench: Evaluatingrewardmodelsforlanguage
modeling. Preprint,arXiv:2403.13787. RyanLiu,JiayiGeng,JoshuaCPeterson,IliaSucholut-
sky,andThomasLGriffiths.2024. Largelanguage
GihunLee,MinchanJeong,YujinKim,HojungJung, modelsassumepeoplearemorerationalthanwere-
Jaehoon Oh, Sangmook Kim, and Se-Young Yun. allyare. arXivpreprintarXiv:2406.17055.
2024. Bapo: Base-anchoredpreferenceoptimization
forpersonalizedalignmentinlargelanguagemodels. Richard Lowry. 2014. Concepts and applications of
CoRR. inferentialstatistics.
YoonhoLee,HuaxiuYao,andChelseaFinn.2022. Di- XingHanLù.2024. Bm25s:Ordersofmagnitudefaster
versifyanddisambiguate: Learningfromunderspec- lexical search via eager sparse scoring. Preprint,
ified data. In ICML 2022: Workshop on Spurious arXiv:2407.03618.
Correlations,InvarianceandStability.
AlasdairMacIntyre.2013. Aftervirtue. A&CBlack.
Jia-Nan Li, Jian Guan, Wei Wu, and Rui Yan. 2025.
Extendedinductivereasoningforpersonalizedpref- MaryLMcHugh.2012. Interraterreliability: thekappa
erence inference from behavioral signals. arXiv statistic. Biochemiamedica,22(3):276–282.
preprintarXiv:2505.18071.
Yu Meng, Mengzhou Xia, and Danqi Chen. 2024.
JunyiLi,CharithPeris,NinarehMehrabi,PalashGoyal, Simpo: Simple preference optimization with a
Kai-WeiChang,AramGalstyan,RichardZemel,and reference-free reward. In Advances in Neural In-
Rahul Gupta. 2024a. The steerability of large lan- formationProcessingSystems(NeurIPS).
guagemodelstowarddata-drivenpersonas. InPro-
ceedingsofthe2024ConferenceoftheNorthAmer- Smitha Milli, Dylan Hadfield-Menell, Anca Dragan,
icanChapteroftheAssociationforComputational andStuartRussell.2017. Shouldrobotsbeobedient?
Linguistics: HumanLanguageTechnologies(Volume InProceedingsofthe26thInternationalJointCon-
1: LongPapers),pages7283–7298. ferenceonArtificialIntelligence,pages4754–4760.
XinyuLi,ZacharyCLipton,andLiuLeqi.2024b. Per- SubhabrataMukherjee,ArindamMitra,GaneshJawa-
sonalizedlanguagemodelingfrompersonalizedhu- har, Sahaj Agarwal, Hamid Palangi, and Ahmed
manfeedback. arXivpreprintarXiv:2402.05133. Awadallah.2023. Orca: Progressivelearningfrom
complexexplanationtracesofgpt-4. arXivpreprint
Chin-Yew Lin. 2004. ROUGE: A package for auto- arXiv:2306.02707.
maticevaluationofsummaries. InTextSummariza-
tionBranchesOut,pages74–81,Barcelona,Spain. LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,
AssociationforComputationalLinguistics. CarrollWainwright,PamelaMishkin,ChongZhang,
SandhiniAgarwal,KatarinaSlama,AlexRay,etal.
StephanieLin,JacobHilton,andOwainEvans.2022. 2022. Training languagemodelsto followinstruc-
TruthfulQA:Measuringhowmodelsmimichuman tionswithhumanfeedback. Advancesinneuralin-
falsehoods. InProceedingsofthe60thAnnualMeet- formationprocessingsystems,35:27730–27744.
ingoftheAssociationforComputationalLinguistics
(Volume1: LongPapers),pages3214–3252,Dublin, Chan Young Park, Shuyue Stella Li, Hayoung Jung,
Ireland.AssociationforComputationalLinguistics. Svitlana Volkova, Tanu Mitra, David Jurgens, and
YuliaTsvetkov.2024a. Valuescope: Unveilingim-
YongLin,HangyuLin,WeiXiong,ShizheDiao,Jian- plicitnormsandvaluesviareturnpotentialmodelof
mengLiu,JipengZhang,RuiPan,HaoxiangWang, social interactions. In Findings of the Association
Wenbin Hu, Hanning Zhang, Hanze Dong, Renjie forComputationalLinguistics: EMNLP2024,pages
Pi, Han Zhao, Nan Jiang, Heng Ji, Yuan Yao, and 16659–16695.
TongZhang.2024. Mitigatingthealignmenttaxof
RLHF. InProceedingsofthe2024Conferenceon Chanwoo Park, Mingyang Liu, Kaiqing Zhang, and
EmpiricalMethodsinNaturalLanguageProcessing, AsumanOzdaglar.2024b. Principledrlhffromhet-
pages580–606,Miami,Florida,USA.Association erogeneousfeedbackviapersonalizationandprefer-
forComputationalLinguistics. enceaggregation. arXivpreprintarXiv:2405.00254.
Sriyash Poddar, Yanming Wan, Hamish Ivison, Ab- feedbackwithoutovergeneralization. arXivpreprint
hishek Gupta, and Natasha Jaques. 2024. Person- arXiv:2402.10893.
alizingreinforcementlearningfromhumanfeedback
withvariationalpreferencelearning. InTheThirty- Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel
eighth Annual Conference on Neural Information Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford,
ProcessingSystems. DarioAmodei,andPaulFChristiano.2020. Learn-
ingtosummarizewithhumanfeedback. Advances
RafaelRafailov,ArchitSharma,EricMitchell,Christo- inNeuralInformationProcessingSystems,33:3008–
pherDManning,StefanoErmon,andChelseaFinn. 3021.
2024. Directpreferenceoptimization:Yourlanguage
modelissecretlyarewardmodel. AdvancesinNeu- Chenkai Sun, Ke Yang, Revanth Gangi Reddy, Yi R
ralInformationProcessingSystems,36. Fung, Hou Pong Chan, ChengXiang Zhai, and
Heng Ji. 2024. Persona-db: Efficient large lan-
Stephen E Robertson, Steve Walker, Susan Jones, guagemodelpersonalizationforresponseprediction
Micheline Hancock-Beaulieu, and Mike Gatford. with collaborative data refinement. arXiv preprint
1993. Okapiattrec-2. InTREC,pages21–34. arXiv:2402.11060.
AlirezaSalemi,ShesheraMysore,MichaelBendersky, ZiluTang,MuhammedYusufKocyigit,andDerryTanti
andHamedZamani.2023. Lamp: Whenlargelan- Wijaya.2022. Augcse: Contrastivesentenceembed-
guagemodelsmeetpersonalization. arXivpreprint dingwithdiverseaugmentations. InProceedingsof
arXiv:2304.11406. the2ndConferenceoftheAsia-PacificChapterofthe
Association for Computational Linguistics and the
AlirezaSalemiandHamedZamani.2024. Comparing 12thInternationalJointConferenceonNaturalLan-
retrieval-augmentationandparameter-efficientfine- guageProcessing(Volume1: LongPapers),pages
tuningforprivacy-preservingpersonalizationoflarge 375–398.
languagemodels. Preprint,arXiv:2409.09510.
Lewis Tunstall, Edward Beeching, Nathan Lambert,
ShibaniSanturkar,EsinDurmus,FaisalLadhak,Cinoo Nazneen Rajani, Kashif Rasul, Younes Belkada,
Lee, Percy Liang, and Tatsunori Hashimoto. 2023. Shengyi Huang, Leandro von Werra, Clémentine
Whoseopinionsdolanguagemodelsreflect? InIn- Fourrier,NathanHabib,NathanSarrazin,OmarSan-
ternationalConferenceonMachineLearning,pages seviero,AlexanderM.Rush,andThomasWolf.2023.
29971–30004.PMLR. Zephyr: Directdistillationoflmalignment. Preprint,
arXiv:2310.16944.
Mrinank Sharma, Meg Tong, Tomasz Korbak, David
Duvenaud,AmandaAskell,SamuelRBowman,Esin MilesTurpin,JulianMichael,EthanPerez,andSamuel
DURMUS, Zac Hatfield-Dodds, Scott R Johnston, Bowman.2023. Languagemodelsdon’talwayssay
ShaunaMKravec,etal.2023. Towardsunderstand- whattheythink: Unfaithfulexplanationsinchain-of-
ingsycophancyinlanguagemodels. InTheTwelfth thoughtprompting. AdvancesinNeuralInformation
International Conference on Learning Representa- ProcessingSystems,36:74952–74965.
tions.
AngelinaWang,JamieMorgenstern,andJohnPDick-
Ruizhe Shi, Yifang Chen, Yushi Hu, Alisa Liu, Han- erson.2024a. Largelanguagemodelscannotreplace
nanehHajishirzi,NoahASmith,andSimonShaolei humanparticipantsbecausetheycannotportrayiden-
Du.2024. Decoding-timelanguagemodelalignment titygroups. arXivpreprintarXiv:2402.01908.
withmultipleobjectives. InICML2024Workshop
onTheoreticalFoundationsofFoundationModels. Danqing Wang, Kevin Yang, Hanlin Zhu, Xiaomeng
Yang, Andrew Cohen, Lei Li, and Yuandong Tian.
Anand Siththaranjan, Cassidy Laidlaw, and Dylan 2024b. Learningpersonalizedalignmentforevalu-
Hadfield-Menell. 2023. Distributional preference ating open-ended text generation. In Proceedings
learning: Understandingandaccountingforhidden of the 2024 Conference on Empirical Methods in
contextinrlhf. InTheTwelfthInternationalConfer- NaturalLanguageProcessing,pages13274–13292,
enceonLearningRepresentations. Miami,Florida,USA.AssociationforComputational
Linguistics.
Paul Slovic. 1995. The construction of preference.
Americanpsychologist,50(5):364. Haoxiang Wang, Yong Lin, Wei Xiong, Rui Yang,
Shizhe Diao, Shuang Qiu, Han Zhao, and Tong
Taylor Sorensen, Jared Moore, Jillian Fisher, Zhang. 2024c. Arithmetic control of llms for di-
Mitchell Gordon, Niloofar Mireshghallah, verseuserpreferences: Directionalpreferencealign-
Christopher Michael Rytting, Andre Ye, Li- ment with multi-objective rewards. arXiv preprint
weiJiang,XimingLu,NouhaDziri,etal.2024. A arXiv:2402.18571.
roadmap to pluralistic alignment. arXiv preprint
arXiv:2402.05070. JasonWei,XuezhiWang,DaleSchuurmans,Maarten
Bosma,FeiXia,EdChi,QuocVLe,DennyZhou,
Moritz Stephan, Alexander Khazatsky, Eric Mitchell, etal.2022. Chain-of-thoughtpromptingelicitsrea-
Annie S Chen, Sheryl Hsu, Archit Sharma, and soninginlargelanguagemodels. Advancesinneural
Chelsea Finn. 2024. Rlvf: Learning from verbal informationprocessingsystems,35:24824–24837.
Wei Xiong, Hanze Dong, Chenlu Ye, Ziqi Wang, 2023). Sincebaselinemodelhasnoinformationon
Han Zhong, Heng Ji, Nan Jiang, and Tong Zhang. theuserinitially,weneedawaytosamplediverse
2024. Iterativepreferencelearningfromhumanfeed-
responses,suchthatthecontrastivepairprovides
back: Bridging theory and practice for rlhf under
the right signal for the model to learn from. Re-
kl-constraint. Preprint,arXiv:2312.11456.
sponsesshouldnotdiffertrivially(e.g. spelling)or
Kailai Yang, Zhiwei Liu, Qianqian Xie, Jimin
intopicswecannotinferfromthepersonadueto
Huang,TianlinZhang,andSophiaAnaniadou.2024.
lackofpublicinformation(e.g. SerenaWilliam’s
Metaaligner: Towardsgeneralizablemulti-objective
alignmentoflanguagemodels. InTheThirty-eighth political affiliation). Our preliminary effort con-
AnnualConferenceonNeuralInformationProcess- firmsthatnaivesamplingmethodsdonotchange
ingSystems. the content of the response much, yielding little
diversity. Instead,wesample50diverseresponses
Siyan Zhao, John Dang, and Aditya Grover. 2023.
Grouppreferenceoptimization: Few-shotalignment usingCoTprompts(i.e. “whataredifferentways
of large language models. In NeurIPS 2023 Work- inwhichtheusermightexpectdifferentanswers”),
shoponInstructionTuningandInstructionFollow-
filterfordiversity(throughclusteringsentenceem-
ing.
beddings), and ensuring that responses selected
HuiyingZhong,ZhunDeng,WeijieJSu,ZhiweiSteven arepreferredequallywithagenericrewardmodel
Wu,andLinjunZhang.2024. Provablemulti-party (Dongetal.,2023;Xiongetal.,2024).
reinforcementlearningwithdiversehumanfeedback.
arXivpreprintarXiv:2403.05006. Cot generation We use CoT prompt H.3 and
prompt model to first select a possible axis the
ThomasPZollo,AndrewWeiTungSiah,NaimengYe,
Ang Li, and Hongseok Namkoong. 2024. Person- prompt belongs to (e.g. politics), and then iden-
alllm: Tailoring llms to individual preferences. In tify all possible sub-categories/angles (e.g. con-
PluralisticAlignmentWorkshopatNeurIPS2024.
servatives) through which the user might expect
the answers. For personal questions, we provide
A ComparisontoExistingDatasets
noconstraintstowhattheaxisandsub-categories
SeeTable10. can be, maximizing the diversity in topic of the
response. Fordivergentquestions,weuseground-
B DetailsofDatasetConstruction
truthaxisandsub-categoriesfromourdataset,to
ensure the difference in the final contrastive pair
B.1 Step1: PersonaSelection
containsthedesiredsignal.
Givenaxisofcontrast,weusePromptH.1onGPT4
Tosample50candidateresponses,wefirstgen-
toprovideatmostfivesub-categories(e.g. liberal)
erate five CoT responses and cache the axis and
alongwithafamouspersonassociatedwiththecat-
sub-categories. ForeachoftheCoTs,wegenerate
egory(e.g. BernieSanders). Detailsofaxes,sub-
10 responses, uniformly sampling sub-categories
categories,andpersonasareinAppendixTable14.
fromthatCoT.WedothisinsteadofusingCoTfor
We leverage GPT4 to sample personas mainly to
all50responsesforefficiencyandtoavoidpossi-
ensurethepeoplearefamousenoughsuchthatthe
blepositionalbiasfromthesub-categories(e.g. if
publicandLLMscanmakeeducatedguessesabout
sub-category“liberal”isalwaysenumeratedbefore
theirpreferences. Wedo,however,recognizethis
“conservatives”,then“conservatives”generations
resultsinabiasedsampleofthehumanpopulation
will be sampled less). See full example in Ap-
(Section6,AppendixF.3),andanalyzesystematic
pendixG.
biasesinSection4.4andAppendixR.
After obtaining the 50 y candidates from the
baselinemodel,weuseapost-processingscriptto
B.2 Step2: GeneratePrompts
remove artifacts strings which might review the
We generate the questions (x) for each persona
identifiable attributes (“For our liberal audience
withPromptH.2. Wemanuallyverifythequality
...”). Wethenproceedtofilterforqualityanddiver-
ofpromptsinAppendixCandanalyzethediversity
sity.
andoverlapofxinAppendixF.4.
Filtering with generic reward model The
B.3 Step3: SampleResponses
first step involves ensuring selected responses
WechoseZEPHYRasourbaselinemodelbecauseit for y
w
,y
l
do not differ much according to
isawellperformingDPO-alignedmodelongeneric a generic reward model. We take a top-
preferencedataset(Dingetal.,2023;Tunstalletal., performing reward models from from Reward-
Dataset Pref.type Open-ended? Realpersona? Verifiablepersona? Synthetic? Personalizedx? Unbiasedy?
LaMP(Salemietal.,2023) personal
PersonalSoup(Jangetal.,2023) multi-objective
HH-RLHF(Baietal.,2022;Yangetal.,2024) multi-objective
OpinionQA(Santurkaretal.,2023) personal
PRISM(Kirketal.,2024) personal
Personal-LLM(Zolloetal.,2024) personal
PERSONA(Castricatoetal.,2025) personal
FamousPersona(Ours) personal
Table 10: Compared to other personalization datasets, our is generated with realistic constraints. Personalized
x=different users ask different questions. Unbiased y=model does not uses user information when generating
response.
Figure5: Datasetgenerationprocedure. Step1: (B.1)personasareselectedinthedatasetaccordingtodifferentaxis
ofdisagreements. Step2: (B.2)promptsaresampledperperson/axis. Step3: (B.3)diverseresponsesaresampled
fromthebaselinemodelandfiltered.Step4:(B.4)preferencesarelabeledbyGPT4throughLLM-as-personal-judge.
DashedanddottedcomponentsaresampledfromGPT4andthebaselinemodel(ZEPHYR)respectfully.
Bench (Xiong et al., 2024; Lambert et al., 2024) personal divergent
(sfairXC/FsfairX-LLaMA3-RM-v0.1) at name validity verifiable validity verifiable
thetimeofthewriting,andobtainascalarreward AOC 1.0 1.0 1.4 1.0
BO 1.4 1.4 2.0 2.0
for each of the responses y. We then sort the ys
BS 1.0 1.2 1.2 1.2
based on reward, and collect 20 responses with B 1.0 1.0 2.2 1.8
smallestrewardrange(i.e. max-min)inacontin- BC 1.0 1.2 2.0 2.0
DT 1.2 1.0 1.2 1.0
uousspan(insortedreward)toensureanytwoys
HB 1.0 1.0 1.2 1.2
withinsuchspanwoulddifferminimallyfromeach LJ 1.0 1.0 1.2 1.6
other. TG 1.4 1.2 1.6 1.6
YB 1.8 1.8 1.2 1.0
Filtering for diversity The next step involves Avg. 1.18 1.18 1.52 1.44
selectingdiverseresponsesamplesfromtheresult- stdev. 0.27 0.26 0.40 0.41
ing pool of 20 responses. We run K-means clus-
Table 11: Results on manual verification of prompt
tering16 onresponses’sentenceembeddingusing
validity and verifiable-ness. Names are represented
sentence-t5-xxl17. For each of k clusters,
withthefirstletteroftheirinitials.
weselectthesamplethatisfarthestfromallother
cluster centers. In our experiment, we pick k=4
sotheresulting4ysarelabeledbyGPT4inthree eraltopic,butnotconclusiveevidenceof
roundsofpairwisecomparison,single-elimination theconnection)
style. (c) score3-notlikely(ifthereislittletono
datasupportingtheconnection,orthere
B.4 Step4: LabelPreferences
areevidencesagainstit)
We label preferences with Prompt H.4. Our hu-
2. Isthisquestionssomethingverifiablethrough
man study for verifying the preference labels are
publiclyknowninformation(verifiable)?
detailedinAppendixD.
(a) score 1 - definitely (the information
C Promptvalidation
mightbeinanarticle,orthereisenough
Due to the synthetic nature of our dataset, we relatedinformationouttherethatissim-
take additional measures to ensure the quality of ilar,throughwhichwecanlikelyguess
prompts(x)generatedbyGPT4. Weassumethat preference. The nature of the question
by using famous people and generating prompts couldalsobemoreobjectiveandthegen-
intopics/axisthattheyareknownfor,wecanrea- eralqualitycanbeverified.)
sonablyguesstheirpreference. Inthissection,we (b) score2-maybe(thereexistsinformation
attempttovalidatethisassumptionmanuallyona onthewebconnectingthepersonatore-
subsetofourdataset. Werandomlysubset10ques- latedtopicbutnotconclusive,orthatthe
tions(halfdivergenthalfpersonal)for10personas’ questioncanleadtosimilarresponses)
testsplit. Weanswer(tothebestofourknowledge) (c) score 3 - not likely (there is little to no
thefollowingtwoquestionsregardingeachprompt: datarelatingthepersontothequestion,
orthereareevidencesagainstit)
1. Isthisquestionssomethingthepersonamight
actuallyaskanAIassistant(validity)? Theauthorsofthispaperdidalltheannotations
forthisverification. WepresentourresultsinTa-
(a) score 1 - definitely (if the person has
ble11andobservethatpersonalquestionsingen-
asked exact or similar questions in the
eralareveryrelevanttothepersonaandverifiable
past,orthatquestionhasbeenaskedby
with public information. Divergent questions are
peoplesimilartotheperson)
slightlylessreliablebutstillmostlyvalidandveri-
(b) score2-maybe(ifthepersonishassome
fiable(withlargervariance).
known information relating to the gen-
Whatwealsonotice,isthatforindividualswho
16https://scikit-learn.org/stable/ havebecomelesspublicovertheyears,maybedue
modules/generated/sklearn.cluster.KMeans. to lack of public coverage (e.g. there are less ar-
html
ticlesaboutBillClintonafterhispresidency),the
17https://huggingface.co/
sentence-transformers/sentence-t5-xxl promptsgeneratedbyGPT4canbearoundtopics
thatareolderandmaybelessrelevanttoday. The
topics could be old enough that the person may
wellhavechangedtheirpreferencesonthesetop-
icssincethetimeofpublication(EllenDeGeneres
stoppedveganismafter202018). Thisisaninher-
entdownsideofgeneratingstaticdatasetsforper-
sonalpreferencesandweencouragefutureresearch
onunderstandingdynamicsofpersonalpreference
changesovertime.
D Labelverificationwithhumans
To verify GPT4’s label accuracy (at least from a
third-personperspective),werecruited9humanan-
notators19 topredictpersonalpreferencegiventhe
sameresponsesGPT4wasgiven. Wesample5per-
sonasfrompoliticsanddiet: DonaldTrump,
JoeBiden,AlexandriaOcasio-Cortez,HalleBerry,
andEllenDeGeneres. Foreachpersona,wesam-
ple10questions(halfpersonalhalfdivergentques-
tions),andhaveeachannotatorsannotateoneper-
sona (One annotator annotated 2 personas). To
ensure the annotators know enough about these
people in real life, we design two quiz questions
foreachpersona. Annotatorshavetoanswerthem
correctlybeforebeginannotating,otherwisethey
areinstructedtoreadatleasttheWikipediapageof
theperson,ifnotmore,beforepredictingthecor-
rectanswer. Thequizquestionsforeachpersonas
arepresentedinTable12.
18https://en.wikipedia.org/wiki/Ellen_
DeGeneres
19Thehumanannotatorsarefriendsoftheauthors,whoare
betweentheageof22-35andfrom4differentcountries.
Persona Quiz1 Quiz2
Donald Beforebecomingpresident,DonaldTrumpwas While libertarians and conservatives tend to
Trump known for his career in business. What type agreethatentrepreneurshipistheprimarymech-
ofbusinessistheTrumpOrganizationprimar- anism for generating prosperity, which belief
ily involved in? A. Real Estate and Hos- systemallowsmaximumindividualfreedom,dis-
pitality B. Venture Capitals C. Entertainment regardingissuessuchassocialdecay?A.Liber-
D.PharmaceuticalIndustry tariansB.ConservativesC.BothD.Neither
Alexandria WhatpoliticalpositiondoesAlexandriaOcasio- WhatmajorlegislationhasAOCbeenapromi-
Ocasio- Cortez (AOC) currently hold? A. Congress- nentadvocatefor?A.TheInfrastructureInvest-
Cortez womenforConnecticutB.SenatorforCalifornia mentandJobsActB.TheAffordableCareAct
C.CongresswomenforNewYorkD.Senator C.TheFreedomtoVoteActD.TheGreenNew
forRhodeIsland Deal
JoeBiden BeforebecomingPresident,whatpositiondid WhatisthemainpurposeoftheAmericanRes-
Joe Biden hold from 2009 to 2017? A. U.S. cue Plan? A. To tighten immigration control
SenatorofVermontB.U.S.SecretaryofState B.Toprovideeconomicreliefandrecovery
C.SpeakeroftheHouseofRepresentativesD. from the COVID-19 pandemic C. To imple-
VicePresidentoftheUnitedStates mentwidespreadtaxcutsforcorporationsD.To
createanewnationalhealthcaresystem
HalleBerry What health condition does Halle Berry have What is the significance of Halle Berry win-
thatputsheronthespecialdiet?A.ArthritisB. ningtheAcademyAwardforBestActress? A.
EpilepsyC.DiabetesD.Parkinson’s ShebecamethefirstBlackwomantowinthe
Academy Award for Best Actress. B. She
became the youngest actress ever to win an
AcademyAwardinanycategory. C.Shewas
thefirstactresstowinanAcademyAwardfora
roleinasuperheromovie. D.Shebecamethe
firstAmericanactresstowinbothanAcademy
AwardandanEmmyAward
Ellen De- What kind of diet best describes Ellen De- Whatisthesignificanceofthe“PuppyEpisode”
Generes Generesdiet(atleastatonepointinherlife)? intheEllenSit-comseriesinrelationtoEllen
A.PaleodietB.VegandietC.KetogenicdietD. DeGeneres? A.Itwasthefirstepisodetowin
GluetenFreediet anEmmyforoutstandingcomedywriting,un-
relatedtoitscontent.B.Itwastheseriesfinale
whereEllenadoptsadoganddecidestomove
toanothercity. C.Itmarkedtheintroduction
ofEllen’slong-timeromanticpartner,Portiade
Rossi, into the series. D. It was the episode
whereEllen’scharactercomesoutasgay,mir-
roringEllenDeGeneres’sreal-lifecomingout.
Table12: Quizquestionsforeachpersonas.
AnnotatorInstruction
unprecedented ability to understand and
AnnotatorInstruction: generate human-like text, opening up a
world of possibilities for how we interact
Thank you for participating in this withandutilizeAIsystems.
annotation exercise. You will be given 10 Response 2: Auto-regressive language
set of conversational data pairs consisting modeling has shown remarkable progress
of a question/prompt and two responses in natural language understanding. While
each. Yourjobistochoosewhichresponse it’sasignificantstepforward,it’sjustone
you think the famous person you are piece of the puzzle. Achieving AGI will
assigned would like more, agree with, or likely require a combination of various
prefer. techniques, including but not limited to
auto-regressivelanguagemodels. AGIwill
There are many ways through which need to understand not only language but
onecouldinferfamouspeople’spreference. also the world in a more comprehensive
Here are some examples you might find way, incorporating various modalities and
helpful: formsofreasoning.
=======Example1======= In this case, Yann might prefer response
Prompt 1 (for Donald Trump): How do I 2 because he is known to advocate for
staysafefromCOVID-19? systemsofmodelingtechniquestoachieve
Response 1: There are many ways to AGI, not purely through auto-regressive
potentiallytreatorstaysafefromCOVID- langauge modeling. If a person agree
19. Exposure to sunlight may reduce the with or advocate for some set of beliefs
potencyofthevirus. Bleachcanalsoknock or agenda, you can assume that they like
outthevirusinaminute. responses that also supports the same
Response 2: Receiving COVID-19 vacci- viewpoints. If a response contain ideas
nationisthemosteffectivewaytoprevent that conflict with the person’s ideology,
infectionanditscomplications. Itprepares mark it as dispreferred. Do not overthink
your immune system with the ability to and consider maybe the person would
recognizethespikeproteinsspecifictothe like to understand opposite viewpoints to
virus,sowhenyouareexposedtoitinthe strengthentheirarguments,etc.
future, the immune system is prepared to
fightitoff. Remember to pay specific attention
to assumptions an response may have on
In this case, Donald might prefer re- the user asking the question. If a person
sponse 1 because he mentioned several of follows a vegan diet, but the response
these alternative methods as treatments recommends meat for a dinner option
for COVID in one of his White House (assumingtheusereatsmeat), thatshould
coronavirus task force briefing. Again, alsobedispreferredbytheperson.
personalpreferenceneednottobefactual.
Lastly, if both responses seem simi-
=======Example2======= lar, you may choose whichever you feel
Prompt 2 (for Yann LeCun): What are answers the prompt better (better general
yourthoughtsonauto-regressivelanguage quality).
modeling? Doyouthinkitisthefutureof
AGI? Your annotation will be used to com-
Response 1: I truly believe that auto- pare how well existing large language
regressive language modeling represents models do on inferring preferences on
a significant part of the future of AGI. famous people. They will not be released,
These models have demonstrated an trained on, and only used for evaluation
purpose.
After passing the quiz, annotators read the in- personas,theirassociatedaxisandsub-categories.
struction(AppendixD),andannotatepreferences. Wenotethatafewoftheentriesarenotup-to-date
InTable13,weshowtheresultsofhumanannota- (Taylor Swift is not single, sorry boys), incorrect
tion. Onaverage,theagreementratebetweenhu- (Transgender is not a category of sexual orienta-
manratersandGPT4acrosspersonasis0.78±0.10. tion),orout-of-date(EllenDeGeneresisnolonger
Ifwecalculatepairwiseannotatoragreementscore vegan). Thisisalimitationofourdatasetbyrely-
using Cohen’s Kappa (McHugh, 2012) or multi- ingonimperfectmodelforgeneration. Notethat
annotator agreement score using Krippendorff’s whenapersonaisgeneratedinmultipleaxes,we
Alpha(Krippendorff,2011),weobtainonaverage assignthemtoalloftheaxes. Forexample,Barack
0.4-0.6,indicatingmoderateamountofagreement Obama is sampled from the age, gender and
(butwithalargevariance). Webelievethisisdue family marriage statusaxis,soforeach
totheambiguousnatureofthetaskofselectingthe axis, Barackwillhave50trainandtestdivergent
preferredresponse,andlackofbackgroundknowl- questions. Forthesepersonas,werandomlysam-
edge for some of the annotators. Two quiz ques- ple50trainquestionsforfairness,andkeepalltest
tionsareperhapsnotenoughofanassurancethat questions.
theannotatorsknowallthebackgroundknowledge
F.2 DemographicsDistribution
neededtomakethedecision. Inaddition,manyof
theannotatorsreportedfeelinglosthavingtoread Wecollectdemographicinformationofthepeople
andcomparelongparagraphsofresponses,which inourdatasetwiththehelpofthelatestGPTmodel
isaninherentlimitingfactorofthehumanworking (and manually verify). In Figure 6 we show the
memory. breakdownofthe50individualsinourdataset. In
AppendixF.3,weshowthatpeoplefromdifferent
persona JB DT HB ED AOC Avg±Stdev. axescontaindemographicsattributesthatarenon-
Human1 0.7 1.0 0.7 0.8 0.8 - uniform. Forinstance,majorityofthepeopleinthe
Human2 0.7 0.9 0.9 0.6 0.7 -
dietaxisarefemaleactresseslivinginCalifornia.
Avg 0.7 0.95 0.8 0.7 0.75 0.78±0.10
Weinvestigatesuchbiasandotherdatasetstatistics
CK-HH 0.17 0.74 0.23 0.52 0.78 0.49±0.28
CK-HG 0.35 0.87 0.61 0.29 0.44 0.51±0.23 (length,diversity,etc)furtherinAppendixF.3.
KA 0.31 0.82 0.48 0.39 0.57 0.51±0.20
Table 13: Human match rate with GPT4. Personas F.3 Majorityattributesperaxis
are represented by their initials. Note that Human 1
In Table 15, we show majority attributes for
andHuman2aredifferentannotatorsacrossdifferent
people included in each axis generated by GPT4.
persona. CK-HH=Cohen’sKappabetweentwohuman
Containing majority attributes indicates a sign
annotator’s label. CK-HG=Average Cohen’s Kappa
of bias. In general, there are a lot of biases
between human and GPT label. KA=Krippendorff’s
Alphaofthreesetsoflabels. in the selection of people generated by GPT4.
Some of the most frequent majority attribute-
value pairs are Current Country: USA,
E Computationalbudgetfordataset Economic Status: Wealthy, Sexual
generation Preference: Heterosexual, and Race:
White. Our dataset targets the US population,
We estimate the cost of the dataset generation to
andwhilethedistributionforsomeattributesmay
be around $500 USD in OpenAI API calls. The
reflectthetruedemographicsoftheUSpopulation,
majority of which is spent on preference labels
afewattributesrevealinherentbiasofourdataset
(GPT4-as-personal-judge). For response genera-
(generation methodology). For example, people
tion,weuseGPUswithatleast40Gmemoryina
who are famous tend to be older (median age
computecluster,lastingaround11GPUdays. Two
being 57), and have had successfully navigated
thirdsoftimeisspentgenerating50responsesper
life and accumulated wealth (all people are in
prompt,whilethelastthirdisspentonfiltering.
the category of wealthy or has moderate
F Detailsofthedatasetandstatistics wealth.
Politicsanddietareamongthetopbiased
F.1 AllpersonasinFamousPersona
axes. Itisnottheintentionoftheauthorsofthispa-
Inthissectionwetakeacloserlookatourdataset pertoincludeonlyfemalecelebritiesaspersonas
composition. In Table 14 we show the list of all in the diet axis, but is unfortunately what was
Axes Category(persona)
sports LeBronJames(BasketballPlayer),SerenaWilliams(TennisPlayer),DavidBeckham(Soccer
Player),TigerWoods(GolfPlayer),MikeTrout(BaseballPlayer)
diet EllenDeGeneres(Veganism),GwynethPaltrow(Gluten-Free),MeganFox(Paleo),Jennifer
Aniston(Mediterranean),HalleBerry(Ketogenic)
politics BernieSanders(Liberal),DonaldTrump(Conservative),RandPaul(Libertarian),Alexandria
Ocasio-Cortez(Progressive),JoeBiden(Centrist)
religion JoelOsteen(Christianity),RichardDawkins(Atheism),MayimBialik(Judaism),RichardGere
(Buddhism),ZaynMalik(Islam)
age MillieBobbyBrown(Children(0-12years)),BillieEilish(Teens(13-19years)),BarackObama
(Adults(20-64years)),SirIanMcKellen(Seniors(65+years))
profession ElonMusk(Entrepreneurs),MerylStreep(Actors),EltonJohn(Musicians),TomBrady(Ath-
letes),J.K.Rowling(Writers)
geographical location ElonMusk(WestCoastUSA),RobertDeNiro(EastCoastUSA),OprahWinfrey(Midwestern
USA),Beyoncé(SouthernUSA),DanielRadcliffe(OutsideUSA)
gender BarackObama(Male),OprahWinfrey(Female),SamSmith(Non-binary),LaverneCox(Trans-
genderFemale),ChazBono(TransgenderMale)
education level NeildeGrasseTyson(DoctoralDegree),QuentinTarantino(HighSchoolEducated),Gordon
Ramsey(VocationalEducation),SherylSandberg(UndergraduateDegree),BillClinton(Gradu-
ateDegree)
AI professors TimnitGebru(AIEthicsProfessors),SuchiSaria(AIinMedicineProfessors),YoshuaBengio
(AIinNeuroscienceProfessors),LatanyaSweeney(AIinDataPrivacyProfessors),Sebastian
Thrun(AutonomousSystemAIProfessors)
family marriage status PrinceHarry(Marriedwithoutchildren),BarackObama(Marriedwithchildren),TaylorSwift
(Single),JeffBezos(Divorced),QueenElizabethII(Widowed)
Table14: Axis,categories,andpersonasincludedinourdataset.
Figure6: DemographicbreakdownofpersonasincludedinFamousPersona
generated by GPT4 (perhaps from training on ar- is perhaps due to the assumption that professors
ticles on fad-diets of Hollywood actresses). For prefer detailed responses containing all the infor-
ourstudies,oneofthemostimportantcriteriafora mationpossible. WhenweuseTFIDF22 tolookat
persontobeincludedinthedatasetisthattheyare thetopdistinguishingwordswithinGPT4reason-
famousenoughsuchthatourLLMjudge(GPT4) ing for AI professor, we do observe words such
hasseenthemduringtrainingandcanproxytheir as“expert”beinggeneratedmuchmorefrequently
preferences. For future studies, we encourage a compared to other axis, which could explain the
more moderated approach that balance bias and biasforlongerresponses.
judgeperformance.
F.6 Agreementperaxis
F.4 Promptdistribution
In Table 16, we count average and standard devi-
Tounderstandthediversityofthepromptsincluded ation of the number of personas preferring each
inourdataset,weembedthepromptsinthetrain y w for every prompt. Note that at the labeling
splitthroughsentence-t5-xxl20. InFigure7, stage, we have 4 diverse y per prompt, so if all
weplotthefirsttwodimenionsofTSNE21 ofthe 5 personas chooses uniformly, the mean should
promptembeddings,andcolor/markpromptsbased be around 1.25. The lower the number (closer to
on the type of question, and axis the prompt is 1.25),themoreuniformthepreferenceis,indicat-
associatedwith. Weseeadiversesetofquestions ingmorediversepreferenceandlessagreement. In
fromdiversepersonas. Thedivergentquestionsare our dataset, religion contains questions with
also more prone to elicit diverse responses. For least agreement, and family/gender has the
thequestionabout“what’sforbreakfast”askedby mostagreement.
Millie Bobby Brown: younger users might make
G QualitativeAnalysisofDataset
cerealforbreakfastwhileolderusersmightwant
something healthier (e.g. fruit) or sophisticated
G.1 Preferencepairs
(e.g. eggbenedict).
InTable17,weshowtwoexamplepreferencepairs
Additionally, we calculate prompt similarity
inourdataset. Weincludeapersonalquestionfrom
(through rouge score (Lin, 2004)) between train
JoeBiden,andadivergentquestioninthedietaxis
andtestsplitforeverypersonaandreportthestatis-
asked to Halle Berry. We include the CoT gener-
ticsinFigure8. Thecloserto0themorediverse
ation as well as GPT4-as-personal-judge reason-
the prompts are. As seen in the plot, majority of
ing. Asseeninthepersonalquestion,thebaseline
thetrainingquestionsremaindis-similartothetest
modelhasnoconstraintsinwhataxisitpicks,and
questionsexceptafewwhererougeisabove0.7.
the categories can be as nuanced as possible. Al-
thoughinthisparticularexample,theCoTaligned
F.5 Lengthdistributionofdataset
with the ground-truth axis of Joe Biden, it is not
Prior work has found that judge models tend to
the case for all generations. In both cases, GPT4
preferlongerresponses(Duboisetal.,2023). We
judge rationale are quite convincing. Addition-
hence plot the preference pair and prefix length
ally, one can see that generations to the prompts
distributioninFigure9. Onaveragey andy are
w l are quite long, which is a distinct difference to
similarinlength,wherepersonalquestions’y are
w otherpersonalizedalignmentdatasetsuchasLaMP
slightlylonger.
(Salemi et al., 2023) and OpinionQA (Santurkar
In Figure 10, we investigate a step further into
et al., 2023). We have also noticed that long re-
thelengthdifference. Thetopfigureshowsthatin
sponsesmakehumanevaluationalotharder.
generalthedifferencebetweeny andy iscloseto
w l
zero,sothereisn’thugelysystematicdifferencein G.2 Inferredpersonas
length. However,ifwelookintothebottomfigure,
Oneoftheuniquefeaturesofourdatasetistheabil-
we can see some axis (e.g. AI Professors)
ity to verify how good models are at inferencing
showssignificantbiasforlongergenerations. This
personas’backgroundandpreferencesbycompar-
20https://huggingface.co/ ingthemtotheorcalepersonagold(generatedby
sentence-transformers/sentence-t5-xxl GPT4giventhenameoftheperson). InTable18,
21https://scikit-learn.org/stable/
modules/generated/sklearn.manifold.TSNE. 22https://scikit-learn.org/stable/modules/generated/sklearn.
html feature_extraction.text.TfidfVectorizer.html
MajorityAttributes/Axis Pol. Diet Edu. Sports Prof. Loc. Reli. Fam. Gender AI Prof. Age Count
CurrentCountry:USA 100 100 80 100 60 100 60 80 80 80 75 11
EconomicStatus:Wealthy 60 100 100 100 100 100 100 100 60 100 10
SexualPreferece:Heterosexual 100 80 100 100 80 100 100 100 100 9
BirthCountry:USA 100 100 80 80 60 60 60 80 8
Race:White 80 80 80 100 60 80 83 80 8
Gender:Male 80 80 80 60 60 80 60 7
FamilyMarriageStatus:Married 80 80 80 80 60 60 6
EducationLevel:ColledgeGraduate 83 67 80 60 4
EducationLevel:HighSchoolGraduate 100 80 60 3
CurrentState:California 100 60 2
Gender:Female 100 60 2
FamilyMarriageStatus:Unmarried 80 75 2
Religion:Christian 80 80 60 3
BirthState:NewYork 60 1
Profession:Politician 71 1
FamilyMarriageStatus:Divorced 60 1
Profession:Actress 57 1
EducationLevel:PhD 80 1
EconomicStatus:ModerateWealth 60 1
MajorityAttributeCount: 10 10 8 8 8 7 7 7 6 6 4
Table15: MajorityAttributes(%)peraxisinFamousPersona. Ifanattribute(e.g. race)doesnothaveamajority
value(i.e. <50%),thecellisleftempty. Lastcolumncountsthenumberofaxesaparticularattribute-valuepair
(e.g. Race: White)isthemajorityfor. Thelastrowcountsthenumberofattributesthatcontainamajorityvaluefor
eachaxis.
Figure7: TSNEofprompt(x)embeddingsintrainingsplit.
axis AI age diet. edu. fam. gen. geo. pol. prof. reli. spo.
mean 1.88 1.71 1.75 1.84 2.00 2.00 1.80 1.84 1.50 1.45 1.61
std 0.99 0.85 0.88 1.01 1.16 1.05 0.96 0.78 0.68 0.69 0.77
Table16: Averagenumberofpersonaspreferringthesameyasy . Smallervalueindicateslessagreement.
w
name prompt CoT preferredresponse(yw) dis-preferredresponse(yl) gpt4judgeratio-
/ ques- (x) nale
tion
type
Joe Canyou Axis: Irecommendimplementingacomprehensivemitigation ThelatestUnitedNationsclimatereporthashighlighted Bothoptionspro-
Biden sum- Politics strategyforU.S.Policythatprioritizesreducinggreen- thatthere’snoremainingdoubtontheseverityandur- vide a summary
(per- marize (specif- housegasemissionswhilefosteringeconomicgrowthand gencyofclimatechange.Scientistshaveconfirmedwith oftheUNclimate
sonal the key ically, developmentopportunities. Thereportwarnsofcatas- 95%confidencethatit’scausedmostlybyhumanactivity. reportanditsim-
ques- points environ- trophicimpactsfromacceleratingglobaltemperatures Yetweseethatmanypoliticiansinyourcategoryremain plicationsforUS
tion) fromthe mental withouturgentandsignificantaction,andunderscoresthe skepticalofthescientificconsensusordismissitoutright. policy. However,
lastU.N. policy) imperativeofkeepingglobalwarmingbelow2degrees Still,expertssaythatinactionwillcostsignificantlymore Output(b)comes
climate Categories: Celsius.Therefore,adheringtoawell-executedmitiga- –includingeconomichardshipsandenvironmentalcatas- acrossasslightly
report Demo- tionstrategyforgreenhousegasreductionisvital.The trophes–thanswiftactiononreducinggreenhousegas confrontational,
and its cratic, UnitedStatesneedsaholisticandrobustgreentransition emissions.Therefore,intermsoffiscalmanagement,it’s questioning the
impli- Republican, thatincludesambitious,fair-mindedemissionstrading notonlyaboutmakinggoodfinancialdecisionsforthe sincerityofpoliti-
cations GreenParty, systems,renewableenergyinitiativessuchasinvestment country.It’salsoimportanttofactortheenvironmental cians’ beliefs
forU.S. Indepen- inrenewablefuelinfrastructure,andthepromotionof crisisthataffectsusallintothatfinancialequation.How- in a partisan
policy? dent (pro- climatetechnologyadvancements. Thiseffortwillaid ever,ifthispointdoesnotswayopinionsregardingpol- manner, a tone
environment), economiesthroughinvestmentopportunitiesandemploy- icydecisioninfavoroftacklingclimatechange,atvery not consistent
and Inde- mentbenefitsthatmitigatetheeconomicriskslinkedto least,acknowledgingitsrealitywillhelpthecountrytake withBiden’sstyle.
pendent abrupttransitionsforfossilfuelsectors,promotingtechno- preparednessandmitigationactionstotackleitsimpacts On the other
(anti- logicalingenuityinstead.Policymakersmustaimtowards betterwheninevitableconsequencessuchassuperstorms, hand, Output
environment). creatinganenergysectormoreadaptivetomarketneeds sealevelrise,andmeltingglaciershit. (a) delivers the
ratherthanonethatstallsinnovationandcompetiveness messageinanon-
forcountries.Inadditiontoeconomicimpacts,disparity confrontational
issuesnecessitateclimatenegotiationsbasedonhistorical and constructive
emissionsofdevelopedcountriescontributingtotoday’s way, which is
environmentalcrises,ratherthantreatingallglobalstake- moreinlinewith
holdersequallyduetodifferencesincapabilities.Devel- Biden’sapproach.
opingeconomiesalsomustbearclimatechangeburdens
differentlytopromoteequityandpreventfuturedisparity
crisesfromcompoundedburdensonalreadychalleng-
ingnations’developmentprocesses.Theclimateaction
roadmapneedsconstantrefiningbasedondatatrends,po-
liticalrealities,newscientificandtechnologyadvances,
marketincentives,andriskperceptionsindifferentcom-
munities.Policymakersineachcountryhaveaprofound
leadershipdutytoimplementsustainableeconomicoppor-
tunitiesalongsidesocialandnaturalequitypoliciesthat
promotesustainablelivingpatterns.Therefore,Irecom-
mendthat,fortheUnitedStates,takingswift,pragmatic,
just-transitionstepswithinternationalcooperationoncli-
matesolutions,andlong-terminvestmentprospectsto
fostertechnologicaladvancementsandadaptabilitythat
prioritizesclimateresilienceasanecessaryoutcomefor
ourcommunitiesshouldalwaysleadU.Sclimatepolicy-
making.Let’stakeclimateactionseriously,ensuringour
economicprosperityfor
Halle Canyou Axis: diet IrecommendtryingdishesfromSoutheastAsiancoun- Surething!Ifyou’relookingforsometastyandhealthy Halle Berry fol-
Berry recom- Categories: triesthathavetraditionallyincorporatedhealthyfats,like veganoptions,youmightenjoyexploringthedelicious lowsaketogenic
(diver- mend Veganism, coconut,avocado,andnuts. Let’stakealookatsome flavorsofinternationalcuisine! Whetheryouwantto diet and tries
gent some Gluten- suggestions:1.Philippines–AdoboChickenSkewers: spicethingsupwithThaiflavors,tastetheMediterranean to consume a
ques- famous Free,Paleo, Insteadoffryingthepopularadobodish,optformaking withGreeksaladandfalafel,orsamplethedelightsof moderateamount
tion, global Mediter- ketogenic-friendlyskewersmadewithbonelesschicken Ethiopia’scuisine,theworldofferssomeamazingplant- ofprotein,avery
axis=diet) cuisines ranean, breasts,vinegar,salt,pepper,garlic,andoliveoil. Use basedtreats!Hereareafewdishesandtheirveganver- smallamountof
with Ketogenic bamboosticksorcoconutlumps(knownascamaronales) sions:1)Buddha’sdelight(alsoknownasLuóhaˇngzha¯o)- carbohydrates,
health- insteadofwoodenskewerstoremainalignedwithyour atraditionalChinesedishoftenservedatBuddhisttemples and a high
ier diet. Thisrecipeissimpleanddelicious,anditserves thattypicallyinvolvesseasonalvegetables,mushrooms, amountofhealthy
alterna- wellonthegrillorpan. 2. Thailand–CoconutCurry driedfruits,andvegetablesservedwithoroversteamed fats. Therefore,
tives? ChickenSoup:Insteadofcoconutmilkorheavycurries, riceorplainvermicellinoodles.2)Vegetablebánhcuốn Output(b), with
choosetoenjoyachicken-coconutsoup.Heatthestove (freshVietnameserolls)–Vietnamesesteamedricerolls its keto-friendly
panwithmedium-heatedoliveoil. Addmincedgarlic, filledwithherbs,vegetarianmockmeat,andvermicelli. global recipes,
ginger,redpepperflakes,lemonbasilleaves,chicken Thesetastyricepaperdelicaciesaretraditionallyfilled alignsbetterwith
breaststrips,fishsauce,vinegar,slicedbellpepper,co- withmeatorporkbutcanalsobefilledwithavariety herdiet.
conutmilkpowder,chickenbonestock,blackpepper,and ofvegetablesorcookedmushrooms.3)Limabeanand
avocado.Simmerandbringoutflavorwithoutguilt.3. kalerisotto-Ahealthyandwholesomevegantakeonthe
Malaysia/Singapore-Prawn&SalmonSaladWrapswith classicrichcream-filledarboriodish,youcantrydiffer-
AvocadoandBroccoli:Toenjoylocalfavoriteseafood entvegetarianalternativesbysubbingcreamandother
inadifferentbutmuchmorehealthyway,prepareadeli- cheesefillings. Thisisalsoaperfectmealchoicefor
ciousseafoodsaladtopackinleafyketogenicgreenssuch allthoselactoseintolerantpeople! 4)AvocadoVegan
ascollardgreens(suannfan),Chinesecabbage,lettuce Ceviche-AvocadoVeganCevicheissimilartoclassic
headsetc. Blendtogethergarlic,ginger,peanutbutter, Peruvianceviche,butmadeusingfreshvegetables.Try
limejuice,andredcurrypowder.Thiswillbecomethe cucumber,peppers,tomatoes,andonions,combinedwith
dressingyou’lluseonshreddedseafood,slicedbellpep- limeandgarnisheddeliciouslytoserveupthisdelicious
pers,redgrapes,redcucumber,steamedbroccoliheads veganceviche. Wehopethishelpssparksomehealthy
andchoppedmint,corianderandThaibasil,tomakethis veganculinaryjourneyasyouventuregloballyinsearch
keto-perfectMalaysiansaladroll.Tokeepcalorieslow, oftasty,flavor-packedtreats!Remember,eatinghealthy
makesurenottorollyourricepapertoowide,keepingan isanincrediblegifttogiveyourbody!HappyEating!
appropriate5inches(13cm)indiameter.Rolltheleaves
firmlybutwithoutcompressingforbetterresults.4.India
–Channa-ChakoraChaat:Thisketoalternativeof
Table17: Exampledatapointinourdataset(next-linecharactersareremovedforformattingpurpose).
Figure 8: Prompt (x) similarity distribution between
trainandtestsplitsmeasuredbyROUGE.
Figure10:Lengthdistributionofthedifferencebetween
y andy (top)anddivergentquestionlengthdistribu-
w l
tionwithineachaxis(bottom)
we show inferred personas for Sir Ian McKellen
and Timnit Gebru, along with their rouge-L(Lin,
2004) score against persona gold. For Sir Ian,
persona inferred is almost entirely irrelevant to
personagoldandreceivesthelowestscore,while
persona gpt4 pins him as someone from the “el-
derly community”. However, neither of them in-
ferredhisactivisminthequeercommunity. Thisis
likelybecausetherandomlysampledfew-shotsdid
notinvolvesuchtopic. ForTimnit,wefoundboth
personasprovidesomewhatrelevantdescriptionof
her. In general, persona from ZEPHYR is more
verbose,structurallyconfusing,andsometimesir-
relevant. personagpt4isoftenverygood,butthe
qualitystilldependsontheshotssampled. Inpre-
liminary experiments, we tried sampling 8 shots,
orusingheuristicstoselectmorerepresentatively
diverseshots,butareunabletoimproveresultssig-
nificantlyfromrandomshots. Thisindicateroom
forimprovementforfuturestudies.
Figure9: Preferencepairandprefix(white-spacedelim-
ited)lengthdistribution
H Promptingdetails
During prompting, we use the default generation
parametersforGPT4andZEPHYRandotherbase-
line models. We use temperature sampling with
t = 1, max token of 512 and top_p = 1.0 (Holtz-
name SirIanMcKellen
persona UserBasicInformation:Name:SarahJohnsonOccupation:ProfessionalwriterandhistorianHobbies:Readinghistoricalfiction,travellingtohistoricalplaces,attending
(ROUGE- historicalevents,andparticipatinginhistoricalreenactments.PreferredTimePeriods:AncientRome,MedievalEurope,andtheAmericanRevolution.UserPreferences:When
L = itcomestohistoricalfiction,Sarahprefersbookswithstrongfemalecharacters,particularlyonesbasedonrealhistoricalfigureslikeCleopatra,Boudicca,andJoanofArc.She
0.105) alsoappreciatesbooksthatdelveintolesser-knownhistoricaleventsorperspectives,suchas“TheNightWatchman”byLouiseErdrich,whichnarratesthelifeofaNative
AmericanmanduringtheUSgovernment’sterminationpolicy.Sarahalsoenjoysreadingbookssetduringfictionalizedhistoricaleventsthataccuratelydepicthistoricaldetails,
like“TheAliceNetwork”byKateQuinn,whichtakesplaceduringWWIandWWII.Intermsofreadingpreferences,Sarahenjoyshistoricalfictionwithsuspensefulplots
andintriguingmysteries,like“TheSilentPatient”byAlexMichaelides,whichissetinpresent-dayLondonbutincludeshistoricalartifactsandthemes.Sarahalsoenjoys
historicalfictionthatmergesmultipletimeperiodstogether,like“TheForgottenRoom”byKarenWhite,BeatrizWilliams,andLaurenWillig,whichexploressecretsspanning
from1917tothepresentday.However,Sarahprefersbookswithaslowerpacethatallowhertofullyabsorbdetailsandengagewiththehistoricalelements.Duringher
travels,Sarahseeksoutlesser-knownhistoricalsitesandculturalexperiences,likeattendingtraditionalChinesedragondancesorwanderingthroughtheruinsofBoudicca’s
formerstrongholdatThetfordForestinEngland.Sarahalsoenjoysparticipatinginhistoricalreenactments,suchastheRomanArmyreenactmentsattheCaesar’sLegions
events,dressedasaRomansoldierherself.Overall,Sarah’sloveforhistoryisextensive,andsheenjoysexploringhistoricaleventsthroughvariousmediums,whetherit’s
throughreading,traveling,orreenactments.Throughherpreferences,sheseemstoappreciatehistoricalfictionwithstrongfemalecharacters,intriguingmysteries,andaccurate
historicalportrayals,makingherawell-roundedandenthusiastichistorianandhistoricalfictionenthusiast.
persona Basedontheuser’squestionandpreferencefordetailedandinformativeresponses,theuserlikelyvaluesaccuracy,comprehensiveknowledge,andthoughtfulconsiderationin
gpt4 responses.Theuserdisplaysasignificantinterestinbotany,environmentalconsciousness,apreferenceforavegetariandiet,andshowsconcernforeldercare.Thissuggestsa
(ROUGE- userwhoisrelativelyolder,possiblyretired,andpassionateaboutpreservingtheenvironment.Theusermightbesomeonewhoenjoystravelandoutdooractivities,targetsa
L = balanceddiet,andishealth-conscious.Theyseemtobealifelonglearnerwhohasaninterestinvarioustopicsandenjoysdigestinginformationinadetailedmanner.The
0.136) userseemstovaluepracticaladvicethatreflectstheirconcernsabouttheenvironment,health,nutrition,andelderlycommunity.Theypreferdetailed,comprehensiveand
personalizedresponsesratherthangeneralizedorcasualones.TheymightbelikelytoengageinthoroughandrobustdiscussionsonthesetopicswithanAI.Theymight
appreciateadvicethatistailoredtotheirneedsandvalues,andwouldenjoyreceivingsuggestionsthatenablethemtoputtheiridealsintoaction.Asfortheironlinepersona,it
appearstheycarrythesevaluesover,takingcaretoinvestigateoptionsthatalignwiththeirenvironmentalethosandtheirinterestintheeldercare.
persona Sure,let’sstartwithsomebasicinformationaboutSirIanMcKellen.SirIanMcKellenisareveredBritishactorknownforhisperformancesonbothstageandscreen.His
gold actingcareerspansseveraldecadesandheisespeciallyrecognizedforhisrolesinShakespeareplays.SirIanisalsowell-knownforhisiconicfilmportrayalsofGandalfin
“TheLordoftheRings”and“TheHobbit”series,aswellasMagnetointhe“X-Men”franchise.Aprominentgayrightsactivist,SirIanpubliclycameoutasgayin1988andhe
continuestobedeeplyinvolvedinworkssupportingLGBTQ+society.Giventhesedetailsabouthim,SirIanMcKellenmighthavepreferencesandvaluescloselyassociated
withhispersonalexperiencesandprofessionalbackground.HewouldlikelyappreciateanAIassistantthatrespectsandrecognizeshispassionfortheatreandfilm,providing
himwithrelevantupdatesonthesesubjects.Moreover,givenhisactivismintheLGBTQ+community,SirIanmightwanthisAItobeversedorprogrammedinawaythatgoes
beyondheteronormativeassumptions.Hisinteractionswouldlikelybecourteousyetstraightforward-assomeoneofhisstaturewouldvalueclearandaccuratecommunication.
Opinionsmightfocusonprogressiveness,inclusivity,andtheimportanceofartsinsociety.TheAIshouldgiveroomforthesetopics.Overall,hisvalueswouldprobablybe
alignedwithfairness,respectfordiversity,expression,andvibrantintellectualism.
name TimnitGebru
persona UserBasicInformation:Theuserisatech-savvyprofessionalwithabackgroundincomputerengineeringandapassionforexploringandworkingwithemergingtechnologies,
(ROUGE- includingAI,neuralnetworks,androbotics.Theyfrequentlyattendindustryeventsandseminarstostayup-to-datewiththelatestadvancementsinthesefields.Theuservalues
L = privacyanddataprotectionhighly,andtheyhaveworkedonprojectsrelatedtoAIprivacyanddatasecurityinthepast.TheypreferpracticalapplicationsofAItechnologyand
0.126) areinterestedinhowitcanbeusedtocreateapositivesocietalimpact,suchasinhealthcare,education,andenvironmentalconservation.Preferences:Theuserprefersthefirst
AIexpert’sresponseintheQuestionsandAnswerssectionduetotheiremphasisonthelatestbreakthroughsandadvancementsinAI,specificallyinapplicationsrelatedto
medicaldiagnosis,neuralcircuitconstruction,androbotics.Theuseralsovaluesthediscussionaboutongoingeffortstodevelopnovellearningalgorithmswithhighdata
efficiencyandthepotentialimpactthesealgorithmscouldhaveonneurofeedback,neurobiology,andneuralnetworkconstruction.Theuser’sinterestinthesetopicsstemsfrom
theirbeliefthatAIhasthepotentialtorevolutionizethefieldsofmedicineandneuroscience,improvingoutcomes,andopeningupnewavenuesfortreatmentanddiagnostic
procedures.Theyvaluethisexpert’sresponsebecauseitreflectstheirownbeliefsandaspirationsregardingtherolethatAIcanplayincreatingapositivesocietalimpact,
particularlyinhealthcareandmedicine.Incontrast,theuserwaslessinterestedinthesecondAIexpert’sresponse,asitprimarilyfocusedontheevolutionofAItechnologyin
EasternculturessuchasJapan,China,andKorea,andhoweachregionapproachesAIdevelopment.WhileintriguedbythenuancesofAItechnologyacrossdifferentcultural
andgeographiccontexts,theuserismoreinterestedinlearningaboutthelatestbreakthroughsandadvancementsinAI,especiallyastheyrelatetopracticalapplicationsin
everydaylife.Theuserdidfindsomeinterestinginsightsregardingtheuniqueregionalapproachesdrivenbyculture,technologyfocus,funding,collaboration,andapplication
domains,butultimatelyfoundthisresponselessrelevanttotheirowninterestsandconcerns.
persona Fromthegivenquestions,itappearstheuserisinterestedinthepracticalapplicationsofAIinspecializedfieldslikejobdisplacement,machinelearning,andmedicalresearch.
gpt4 Theyseemtovalueaccurate,comprehensive,andopen-endedresponsesoverdefinitiveones.Theusermaylikelyhaveabackgroundintechnologyanddatascience,probably
(ROUGE- dabblinginAIandmachinelearningduetohiscomplexinquiriesconcerningAI’simpactonjobdisplacementandthebestprogramminglanguageformachinelearning,
L = andup-to-datedevelopmentsinAImedicalresearch.Basedontheirpreferenceforcomprehensiveandhighlydetailedresponses,theusermaygenerallypreferdepthover
0.140) brevitywheninteractingwithanAIassistant.Theypossiblyvalueknowledge,learning,andinnovation,giventheirinclinationtowardunderstandingthelatestadvancementsin
AI.Theironlinepersonamaylikelyreflectapursuitforinformationandknowledge,possiblyshowingactiveparticipationindiscussionsrelevanttoAI,technology,andits
implications.Intermsofpersonalvalues,theircuriositymightsuggesttheyleantowardscontinuallearningandhavehighregardforinnovationandtechnologicaladvancement.
Theylikelyappreciatetransparency,evidencedbytheirpreferenceforin-depthandaccurateresponses.
persona TimnitGebruisahighlyrespectedresearcherknownforherworkinartificialintelligence,specificallyinthefieldsofcomputervisionandethics.Shewasthetechnicalco-lead
gold ofGoogle’sEthicalArtificialIntelligenceTeam,untilhercontroversialdeparturein2020.Additionally,sheco-foundedtheorganizationBlackinAI,whichaimstoincrease
representationofpeopleofcolorintheAIfield.TimnitholdsaPhDfromtheStanfordArtificialIntelligenceLaboratory,studyingunderFei-FeiLi.Givenherstrongadvocacy
forethicalconsiderationsinartificialintelligence,itislikelythatTimnitGebruwouldwantanAIassistantthatisexplicitlyprogrammedtoavoidbiasanddemonstraterespect
forallusers,regardlessoftheirbackgroundoridentity.Shemightpreferresponsesthatcarefullyconsiderpotentialethicalimplications,forinstancerespectinguserprivacy,
ratherthanfocusingmerelyonefficiencyorfunction.Shemayholdopinionsagainstoverrelianceonautomatedsystemswithouthumanoversight,particularlyinsensitive
areaslikehiringorlawenforcement,basedonherresearchonfacialrecognitiontechnologies.Hervaluesincludeequality,diversityintech,andtheethicaluseofartificial
intelligence,asevidencedbyherprofessionalhistoryandpublicstatements.
Table18: ExampleinferredpersonafromZEPHYR(persona),GPT4(personaGPT4),andGPT4withthenameof
theperson(personagold). Bothpersonaandpersonagpt4areinferredfromrandomlysampled4shotspreference
pairs. ROUGE-Liscalculatedusingpersonagoldasthereference.
man et al., 2019). Only when generating diverse Prompttosamplepersonalquetions
responses(y)fromthebaselinemodel,weincrease
Imagine you are a general-purpose AI
tto2.0anddroptop_pto0.8.
assistant. Given what you know about
• Datasetgeneration {NAME}, what kind of questions would
you expect them to ask you day-to-day?
– Promptpersonaselection(H.1)
Provide{N_RESPONSES}examples.
– Promptx(H.2)
– Prompty(H.3) - Make sure the questions are creative and
– Prompt label (llm-as-personal-judge) diverse(intermsoftopic,length,specificity,
(H.4) etc.) and something you can answer (for
example, do not ask to create any visual
• Prefixgeneration
oraudiooutput,setcalendarreminders,or
query for weather next week because an
– Promptpersonafew-shot(H.5)
AIassistantcannotperformanyactionand
– Promptpersonagold(H.6)
doesnothavereal-timeinformationofthe
• Responsegenerationwithprefix world).
-Thequestionsdonothavetobeexclusively
– Promptywithname(H.7)
dependentontheirprofession,orwhatthey
– Promptywithtag(H.8)
areknownfor.
– Promptywithfew-shot(H.9) - We provide you with a list of catego-
– Promptywithpersona(H.10) rization for you to optionally base your
questionson: {AXES}
H.1 Datasetgeneration: promptpersona - Questions can be broad or specific. If
selection a question is specific, make sure it is
Prompttosamplepersonas groundedandverydetailed.
- Do NOT generate a question they likely
Individualpreferencesmaydifferinmany knowtheanswerto(forexample,aprofes-
axis. Some examples of axes include sor in quantum physics likely knows the
economicviews,politicalalignments,age, latesttrendsinquantumphysicsresearch).
profession. -Trytogeneratequestionswhere{NAME}
would have different preference over the
Take {AXIS} as an example axis, come responsethanthegeneralpublic(subjective
upwithafew(atmostfive)sub-categories questions, questions with no single best
within this axis. Then list some famous answer,questionswithanswerthatdiffers
people who are representative of each betweensituationandperson,etc.)
sub-category within this axis. Make
sure these people are currently living, Here are some example questions
English-speaking,andfamousenoughthat fromsomefamouspeople:
you know about their background, quotes,
preferences,etc. MelindaFrenchGates:
1. Presentmeananalysisofthecorrelation
Please respond in the following for- betweeneducationandeconomicgrowth.
mat: 2. Help me brainstorm some ideas on
-{sub-category},{name},{1-sentencebrief how to start a commencement speech
description} for University of Chicago that celebrates
bravery.
H.2 Datasetgeneration: promptx 3. Summarizethethemostrecentadvance-
ments in malaria vaccine research for me
To sample personal questions (x), we use 3-shot
please?
promptwiththefollowingformat. Wesample20
questionsatatime.
AliWong: - Do NOT generate questions which
1. Whataresomemeditationpracticesfor requires additional information from the
relaxationbetweenshows? user (for example, do NOT ask "exercise
2. List some up-and-coming comedians, recommendataion that is suitable for
what do they seem to have in common in me". Instead just ask "general exercise
theirsuccessstrategies? recommendataions"). Usersdonotassume
3. Canyoufindmesomeeffectiveexercises youknowtheseinformationaboutthem.
todopost-pregnancy? - Try to generate questions where they
4. What’sfunnyaboutteacups? would have different preference over the
response than each other (subjective ques-
RickWarren: tions,questionswithnosinglebestanswer,
1. Whataresomedifferentinterpretations questionswithanswerthatdiffersbetween
oftheBookofRevelation? situation, people, and sub-divisions in
2. HowcanImotivatemychurchcommu- {AXIS},etc.)
nitytoengagemoreincharitywork?
3. Whataresomehipwordsorphrasesthat Now,provide{N_RESPONSES}questions
kids use these days? Give me a couple of that{NAMES}mightaskINCOMMON.
exampleusageaswell.
H.3 Datasetgeneration: prompty
Now,provide{N_RESPONSES}questions
(Chain-of-thoughtpatterntoelicitdiverse
that{NAME}mightask.
response)
To sample divergent questions, we use the fol- Samplingthebasemodedirectlywiththeprompt
lowingprompt. Wesample20questionsatatime. doesnotleadtoresponsesdiverseinopinions,bias,
topic, content, or style. Increasing the sampling
Prompttosampledivergentquetions
temperature do not help as much either. To ex-
plicitly encourage models to generate diverse re-
Imagine you are a general-purpose AI
sponses,weleverageaCoT-likepattern(Weietal.,
assistant. Given what you know about
2022). Note that even though we provide the list
{NAMES}, what kind of questions in
ofaxesincludedinourdataset,generationsdonot
commonwouldyouexpectthemtoaskyou
oftenfollowexactlytheaxesspecified. Welever-
day-to-day? Provide {N_RESPONSES}
agethistogeneratewitespectrumofresponsesfor
examples.
personalquestions.
- Note that these people chosen based
CoTPrompttosampleresponse
on their {AXIS} categories: {PER-
SON_CATEGORIES}, you should base <|im_start|>system
your questions around this topic, but do You are a helpful assistant. You will be
NOT reveal their {AXIS} categories, or givenaquestionfromtheuser,butinstead
theirpreferencesinthequestions. of answering it directly, you are going to
-Focusonthequestionstheymightaskin thinkstepbysteponwhattheusermightbe
common,butexpectdifferentanswers. expectingfromyou. Individualpreferences
- Make sure the questions are creative and maydifferalongmanyaxis(e.g.,religion,
diverse(intermsoftopic,length,specificity, politicalviews). Inthistask,wedefinethe
etc.) and something you can answer (for followingelevendifferentaxis:
example, do not ask to create any visual
oraudiooutput,setcalendarreminders,or sports, diet, politics, religion, age,
query for weather next week because an profession, geographical location, gender,
AIassistantcannotperformanyactionand sexual orientation, education level, AI
doesnothavereal-timeinformationofthe professors,familymarriagestatus.
world).
Choose an axis from above that is tomakeadecisionevenifbotharewrong
the most relevant to the question being (choose the least bad) or equal (choose
asked, then come up with a few (at most randomly). "Concise explanation" is a
eight) categories within this axis (i.e., stringthatprovidesaverybriefexplanation
if axis were religion, categories can be forthedecision.
Christians, Catholics, Muslim, Buddhist, <|im_end|>
and Jewish). At last, assume the user <|im_start|>user
belongstooneofthecategories,andcater Iwillgiveyoutwoexamplesinarow,and
yourresponsetohowtheymightlike,agree youshouldchoosethebestoutputsforboth
with, orbeinterestedin. Youmaychange of them. Note that the correct answer for
the style, content, length, vocabulary, onehasnoimpactontheother.
opinion, stance, oranyrelevantaspectsof
yourresponse. ###Example1
####Instruction1:
Please respond in the following for- PleasesimulateDonaldTrump’spreference
mat: overtheanswersforthequestionsbelow.
Axis: {axischosen}
Categories: {listofcategories} ###Input1:
Chosencategory: {categorychosen} HowdoIstaysafefromCOVID-19?
Response: {specificresponsefortheperson
ofthecategory} ####Output(a)forexample1:
<|im_end|> There are many ways to potentially treat
<|im_start|>user or stay safe from COVID-19. Exposure
{x} to sunlight may reduce the potency of the
<|im_end|> virus. Bleachcanalsoknockoutthevirus
inaminute.
H.4 Datasetgeneration: promptlabel
annotation(GPT4-as-personal-judge) ####Output(b)forexample1:
Receiving COVID-19 vaccination is the
We follow Jang et al. (2023) and use AlpacaE-
mosteffectivewaytopreventinfectionand
val/AlpacaFarm23 toobtaintheGPT4annotation
itscomplications. Itpreparesyourimmune
ofpersonapreferencelabels. Eachquerybatches5
system with the ability to recognize the
preferencepairstolabel.
spikeproteinsspecifictothevirus,sowhen
PrompttoobtainGPT4personalpreference you are exposed to it in the future, the
annotation immunesystemispreparedtofightitoff.
<|im_start|>system
##Example2
You are a helpful assistant that selects the
###Instruction2:
output that best follows the instruction.
Please simulate Yann LeCun’s preference
In the instructions, you will be asked to
overtheanswersforthequestionsbelow.
simulate a person’s preference given a
questionthispersonasks.
###Input2:
Whatareyourthoughtsonauto-regressive
Your answer should be a JSON ob-
languagemodeling? Doyouthinkitisthe
ject with the fields "Concise explanation"
futureofAGI?
and "Output (a) is better than Output (b)".
"Output (a) is better than Output (b)" is a
###Output(a)forexample2:
boolean indicating whether Output (a) is
Itrulybelievethatauto-regressivelanguage
betterthanOutput(b)soyoualwaysneed
modeling represents a significant part of
the future of AGI. These models have
23https://github.com/tatsu-lab/alpaca_
eval/tree/main
demonstrated an unprecedented ability to LeCunasshort-sighted.",
understand and generate human-like text, "Output(a)isbetterthanOutput(b)": false
opening up a world of possibilities for }
howweinteractwithandutilizeAIsystems. <|im_end|>
<|im_start|>user
While there’s still much work to be Great! NowIwillgiveyou5examplesina
done, the advancements we’ve seen row.
with auto-regressive LMs are incredibly
promising. ##Example3:
###Instructionforexample3:
###Output(b)forexample2: {instruction}
Auto-regressive language modeling has
shown remarkable progress in natural ###Inputforexample3:
language understanding. While it’s a {input}
significant step forward, it’s just one
piece of the puzzle. Achieving AGI will ###Output(a)forexample3:
likely require a combination of various {output_1}
techniques, including but not limited to
auto-regressivelanguagemodels. AGIwill ###Output(b)forexample3:
need to understand not only language but {output_2}
also the world in a more comprehensive
way, incorporating various modalities and ##Example4:
formsofreasoning. ###Instructionforexample4:
{instruction}
## Preferred output in JSON format
forexample1-2: ###Inputforexample4:
<|im_end|> {input}
<|im_start|>assistant
### Preferred output in JSON format for ###Output(a)forexample4:
example1: {output_1}
{
"Conciseexplanation": "Output(a)includes ###Output(b)forexample4:
some of the comments President Trump {output_2}
mentioned in one of his White House
coronavirus task force briefing, which ##Example5:
likelyrepresentsomeofhisopinions.", ###Instructionforexample5:
"Output(a)isbetterthanOutput(b)": true {instruction}
}
###Inputforexample5:
### Preferred output in JSON format {input}
forexample2:
{ ###Output(a)forexample5:
"Conciseexplanation": "Output(b)shows {output_1}
only moderate excitement towards au-
toregressive language modeling while ###Output(b)forexample5:
emphasizing that AGI requires systems {output_2}
of techniques, similar to Yann LeCun’s
opinion on this matter. Output (a) is too ##Example6:
enthusiastic about auto-regressive models ###Instructionforexample6:
and will likely be considered by Yann {instruction}
assumptions.
###Inputforexample6:
{input}
##UserQuestion1:
{X1}
###Output(a)forexample6:
###PreferredResponse:
{output_1}
{CHOSEN1}
###Output(b)forexample6:
##UserQuestion2:
{output_2}
{X2}
###PreferredResponse:
##Example7:
{CHOSEN2}
###Instructionforexample7:
Respondwithtwoshortparagraphs,onefor
{instruction}
userbasicinformation,andoneforprefer-
ences.
###Inputforexample7:
{input}
H.6 Prefixgeneration: promptpersonagold
###Output(a)forexample7: Tosamplegoldpersonawiththenameoftheper-
{output_1} son,weusethefollowingprompt.
Prompttosamplepersonagoldfromname
###Output(b)forexample7:
{output_2}
Given the name of a famous person,
can you describe this person with a few
## Preferred output in JSON format
sentences?
forexample3-7:
Given your description, can you guess
<|im_end|>
what their online persona / preferences /
personalvaluesmightbelike. Forexample,
H.5 Prefixgeneration: promptpersona how might they interact with a personal
few-shot AIassistant? Whatkindofanswersmight
they prefer? What opinions might they
To sample persona with few-shot (n=2) training
hold? What values do they support? Stay
examples, we use the following prompt. In pre-
grounded to facts you know and provide
liminary experiments we also tried including dis-
sufficientreasonsforyourassumptions.
preferredresponse(y )anddidnotfindsignificant
l
differenceingeneration.
Thepersonis{NAME}
Prompt to sample persona from training
Respond with two short paragraphs,
preferencedata
oneforuserbasicinformation,andonefor
Given a few questions a user asks an AI preferences.
assistant, and their preference over two
different responses, can you infer a few
H.7 Responsegeneration: promptywith
thingsaboutthisperson?
name
Given your deduction, can you further
Tosamplearesponsegiventhenameofthepersona,
guess what their online persona / prefer-
weusethefollowingprompt.
ences / personal values might be like. For
example, how might they interact with
Prompttosampleyprefixedwithname
a personal AI assistant? What kind of
answersmighttheyprefer? Whatopinions Respond to the following prompt from
might they hold? What values do they {NAME}. Cater the response to how they
support? Staygroundedtofactsyouknow might like, agree with, or be interested
and provide sufficient reasons for your in. You may change the style, content,
length,vocabulary,opinion,stance,orany
relevantaspectsofyourresponsebasedon
H.10 Responsegeneration: Promptywith
{NAME}’sbackground.
persona
{x} To sample response given a persona, we use the
followingprompt. Seeexamplepersonaprefixin
AppendixG.2.
H.8 Responsegeneration: promptywithtag
Prompttosampleyprefixedwithpersona
Tosampleresponsegivenatagprefix,weusethe
following prompt. An example tag is simply the {PERSONA}
string value "<special_person_tag_3>". We tried
using a similar prompt as Prompt H.7 except re- Respondtothefollowingpromptfromthis
placingthenamewithIDtag. Thatalsoyieldvery person. Cater the response to how they
similar performance so we kept this version for might like, agree with, or be interested in.
minimality. Youmaychangethestyle,content,length,
vocabulary,opinion,stance,oranyrelevant
Prompttosampleyprefixedwithtag
aspects of your response based on their
background.
{TAG}{x}
{x}
H.9 Responsegeneration: promptywith
few-shot
I PromptingResults
To sample response given few-shot examples (2-
shotinthisexample),weusethefollowingformat. In preliminary study, we want to understand the
Inpreliminaryexperimentswealsotriedprompting effectofpromptingonourmodelsforpersonaliza-
with dis-preferred response as well and did not tion. Afterall,promptingallowsuserstoflexibly
obtainbetterperformance. adaptmodelbehaviorwithoutchangingmodelpa-
rameters (Santurkar et al., 2023; Kim and Yang,
Prompttosampleyprefixedwithfew-shots
2024;ChoiandLi,2024;Castricatoetal.,2025).
Respondtothefollowingpromptfromthis It is scalable with no tuning while using a sin-
person. Cater the response to how they gle model. However, most LMs are limited by
might like, agree with, or be interested in. contextlength,andpromptingcanover-generalize
Youmaychangethestyle,content,length, (Stephanetal.,2024)inout-of-domainscenarios,
vocabulary,opinion,stance,oranyrelevant lackingfine-grainedcontrol. Inaddition,wealso
aspects of your response based on their promptedmodelwithjustthenameoftheperson,
background. toassesshowmuchdomodelsknowaboutthese
famouspeople.
##Prompt: First,weshowresultswith ZEPHYRmodelwith
{X1} asmall, easiersubset ofpersonawithin axes diet
###PreferredResponse: andpolitics(whichwereferredtoasD small ,and
{CHOSEN1} weuseD full whenreferringtothefulldataset). As
seeninFigure11,performancesdecreaseforper-
##Prompt: sonal but improve for divergent questions–likely
{X2} becausethepersonalizationaspectissimpler(e.g.
###PreferredResponse: liberal vs conservative in politics) to learn.
{CHOSEN2} Persona gold led to the best improvement, out-
performingname,indicatingthatpreferencesneed
##Prompt: to be explicitly stated for personalization. Name
{x} slightlyimprovesovernoprefixhintingatZEPHYR
###PreferredResponse: may have seen our personas during training. Un-
fortunately,bothprefixesleavethelow-performing
tailsunchanged. Few-shotandpersonabothim-
proveperformancesslightly. However,neitherper-
formances necessarily improve with more shots
likelyduetolimitedeffectivecontext. Resultswith
retrieval few-shots in Appendix J across 4 other
modelsconfirmthesamefinding.
0.6
0.4
ycaruccA
lanosreP
baseline and upperbounds few-shot and persona prompts
Prefix
persona
few-shot
0.6
0.4
no prefix name persona gold
Prefix
ycaruccA
tnegreviD
densesentenceembeddings24. InTable20,wecan
seethatretrieved2-shotperformancesarecloseto
fixed-shots across 4 models, confirming the find-
ingswithpromptinginFig11.
Model 2-shottype Personal Divergent
ZEPHYR Fixed 0.487(0.069) 0.498(0.067)
ZEPHYR BM25 0.488(0.064) 0.503(0.067)
ZEPHYR emb 0.492(0.067) 0.501(0.066)
LLAMA1B Fixed 0.472(0.063) 0.492(0.067)
LLAMA1B BM25 0.478(0.063) 0.493(0.064)
LLAMA1B emb 0.474(0.067) 0.487(0.068)
LLAMA3B Fixed 0.478(0.069) 0.490(0.063)
LLAMA3B BM25 0.478(0.074) 0.493(0.065)
LLAMA3B emb 0.485(0.076) 0.498(0.060)
MINISTRAL Fixed 0.484(0.063) 0.491(0.064)
MINISTRAL BM25 0.485(0.066) 0.495(0.065)
MINISTRAL embedding 0.481(0.063) 0.49(0.067)
1 2 3 4 8 16 Table20: Retrieval2-shotperformssimilarlytofixed
shots
few-shots,confirmingdifficultyofpersonalizedalign-
Figure11: PromptingZEPHYRminimallychangesper-
mentin-context.
formance(dashedlineisrandomprediction)onD .
small
Weadditionallyshowpromptingresultsforall
fourmodelsonD full inTable19,averagedacross K Hyperparameters
50personas. Resultsconfirmthatpromptingisnot
effectiveacrossfourmodels.
In Table 21 we detail the best hyperparameters
we find for each type of models. The majority
Model Prefix Divergent Personal
of the tuning was changing the learning rate
ZEPHYR few-shot 0.498 0.487 {5e − 6,1e − 5,2e − 5,5e − 5,1e − 4,2e −
persona 0.511 0.495
4,5e − 4,1e − 3,2e − 3,5e − 3}, batch size
personagpt4 0.509 0.492
personagold 0.505 0.494 {5,10,20,40}, and epoch {2,5,10}, due to
LLAMA1B few-shot 0.492 0.472
different training data sizes. We We try different
persona 0.489 0.476
personagpt4 0.495 0.479
themaxlength{1024,2048,3072,4096}andmax
personagold 0.495 0.477 prompt length {512,1536,2560,3584} to ensure
LLAMA3B few-shot 0.490 0.478
longer prefix do not benefit more from longer
persona 0.493 0.482
personagpt4 0.494 0.482 cut-off, and truncate all sequence length with
personagold 0.495 0.486 1024 tokens, and max_prompt_len=512.
MINISTRAL few-shot 0.491 0.484
We keep LoRA parameters mostly the
persona 0.489 0.483
personagpt4 0.492 0.481 same as Zephyr-7B-beta (lora_r=8,
personagold 0.491 0.484 lora_alpha=32, lora_dropout=0.1). For
hyperparametertuningandbestmodelcheckpoint
Table19: Promptingisgenerallyeffectiveforpersonal-
selection, we sample 200 (out of 4000) of the
izingrewardsacrossallmodelsoneitherdivergentor
entire evaluation set as validation for multitask
personalquestionsacrossfourbaselinemodels.
model, and 40 (out of 100) for personal models.
Alltrainingsaredonewithlessthan12GPUhours
per model, in a compute cluster on GPUs with
J Retrievalfew-shotresults
morethan40Gmemory. ForfinetuningLLAMA1B
andLLAMA3B,weuselearningrateof2e−4and
To understand whether few-shot relevance affect
1e−4respectively.
the ZEPHYR baseline performance, we addition-
ally compare fixed 2-shots vs. shots retrieved us-
ing BM25(Robertson et al., 1993; Lù, 2024) and 24sentence-transformers/all-MiniLM-L6-v2
parameter PM MT(D ) MT(D ) VPL
all small
optimizer paged_adamw_32bit paged_adamw_32bit paged_adamw_32bit paged_adamw_32bit
warmup_ratio 0.1 0.1 0.1 0.1
learningrate 2e-4 5e-5 2e-4 2e-4
batchsize 20 40 40 40
epoch 10 2 10 2
DPO-β 0.01 0.01 0.01 0.01
Table21: Hyperparametersinpersonal(PM),multitaskmodels(MT),andVPLforfinetuningZEPHYRmodel.
L PersonalModels(PM)
In addition to prompting, we tested whether it is
0.6
possible to train personal models PM that learn
individual preferences by finetuning one LoRA
0.4
adaptor(Huetal.,2021)per-personthroughDPO
(Rafailovetal.,2024),similartofinetuningforin-
dividual objectives in MORL (Jang et al., 2023),
withthefollowingloss:
L =−E (cid:2) log (cid:0) βlog π θ (y w |x)
PM (x,yw,yl)∼Dp π (y |x)
ref w
(3)
−βlog π θ (y l |x) (cid:1)(cid:3)
π (y|x)
ref l
Weexpectthistoperformwellifthereissuffi-
cienttrainingdataper-person,atthecostoftraining
multipleadapters. Hyperparameterscanbefound
inAppendixK.Forpersonalmodels,wetrainwith
threerandomseedsperpersonwithD
small
Personalmodels(PM)improvesatacost. As
seeninFigure12,personalmodelsachievemuch
better performance than prompting, especially in
divergent questions. For each PM we addition-
allyevaluateonallotherpersonasinD tosee
small
how model generalizes to unseen personas. Sur-
prisingly, x improves even in untrained a
personal
persona,indicatingcorrelatedxandy . Although
w
high performing, PM fails to generalize at all in
x orleverageinformationinpersonagold.
divergent
PM’s dependence on training data size is per-
son dependent Given 100 training preference
pairs might be unrealistic for real users, we ab-
latenumberoftrainingdatatoobservehowsteep
theperformancedropoffis. Wetrainthreeseeds
foreachfractionofthetotaltrainingdata. InFig-
ureL,weseemodelperformanceincreasealmost
linearly,wherethePM forDonaldTrumpoutper-
formsbaselinewith60pairs,butonlytooklessthan
20forHalleBerry. Thissuggeststheefficiencyof
PM ishighlyspecifictoeachpersona.
ycaruccA
lanosreP
Prefix Types Model
no prefix persona gold PM Zephyr
0.8
0.6
0.4
0.2
Persona trained Persona not trained
ycaruccA
tnegreviD
Figure12: Personalmodel PM resultsinD . Re- small
sults aggregated over 3 random seeds per personal
model. PM models aligns to personal data well, but
fails to generalize to unseen persona or use inferred
preferences.
Figure13: PMperformancewithlessdata(eachdata
amountistrainedwith3randomseeds.Dashedlinesare
ZEPHYRnoprefixperformances. Shadedareaindicates
95%CI.
M Multi-tasktrainingwithother
base-models
WeshowMTtrainingresultsforallfourmodelsin
thissection.
MTgeneralizestounseenpersona. InTable22,
wecanseethatacrossallmodels, MT withmean-
ingful prefix improves over baseline, especially well with persona gold. This suggests that the
withupperboundpersonagold. numberofpersonaneededtounlockgeneralization
is small, as long as the prefix is of good quality.
Bigger model benefits from self-inferred per-
This suggests that better persona inference is an
sonamore. Inbiggermodels(Ministral-8Band
importantfuturedirection.
ZEPHYR,self-inferredpersonaimproveoverfew-
shot a bit more. This could either due to better O VPLimplementationdetail
persona inference, or better preference associa-
Atthetimeofexperimentation,authorsof(Poddar
tionduringMT training. InTable2,weshowthat
et al., 2024) have not released their code. Since
smallermodelisnotnecessarilyworseatinferenc-
VPL was trained as a reward model we have to
ing persona. This suggests that potentially larger
implemented our version of VPL. We follow the
modelsarebetteratassociatingkeywordswithpref-
architectureasweunderstandfromthepaperand
erencemodelinginternally.
keepasmuchhyperparametersthesameaswecan.
N Performancecomparisonacross Inshort,VPLtrainsavariationalauto-encoderthat
ZEPHYR, PT,and MT embeds few-shot preference pairs into a continu-
ousvector,whichisthenusetopredictthereward.
To compare all three family of methods/models
Theencoderusesaself-attentionlayer,attending
(ZEPHYR,PT (ZEPHYR),andMT (ZEPHYR)),we
tocachedembeddingsofthepreferencepairs. For
plotalltheirperformancesinD inFigure14.
small everyforwardpass,VPLrandomlysamplesNtrain-
ForMT,wetrainanadditionalsetofmodelsusing
ingpairsfromtotalofKtrainingpairsallowedfor
personas only in D . We perform 5-fold CV
small auser,calculatesanembedding,andcomputethe
again,usingstratifiedsamplingacrossaxis. Each
loss. We refer reader to (Poddar et al., 2024) for
trainingsplithas8personasand2intestsplit. Hy-
detailedexplanation.
perparametersarefoundinAppendixK.
Forourimplementation,wesetN=8,K=16,and
simplyprefixtheembeddingatthebeginningofthe
Personal model wins only in trained persona
language model and calculate loss the same way
withnoprefix InFigure14leftsubplots,wesee
DPOlossasMTmodel. Thelossback-propagates
PM model is good at learning individual prefer-
tothevariationalauto-encoder,andadjusttheem-
ences. Whentrainedwithnoprefix,itoutperforms
bedding throughout training. One of the reason
MT significantly. However, as soon as we have
thatvplperformssowellinpersonalquestions,is
goodprefixesofthepersonas(personagold), PM
potentiallyduetothelargeK(sinceotherprefixes
performsthesameasMTifnotworseindivergent
either use 2 or 4 train preference pairs as prefix).
accuracy. ItmakesensethatPMdoesnotimprove
WeuselargerN,Kvaluetobeconsistentwithorigi-
becausepersonagoldcontainsredundantinforma-
nalpaperimplementation,andalsofortheintuition
tion. When generalizing to unseen personas, we
thattheauto-encoderneedsmorevariationstolearn
expect PM tofailanditdoes. Thelargevariance
aproperembeddingduetothenoisesampledinthe
indicates it biases model to only store one-sided
forward pass. It is also an inherent advantage of
preference.
embeddingbasedmethods: beingabletocompress
Multi-taskmodelcanmodelcontrastingprefer- informationatthecostofasingletoken. Wereport
enceswithqualityprefix Inthebottomsubplots, thegenerichyperparametersinAppendixK.
we see that with persona gold, MT outperform
PTinbothpersonanottrainedandtrained. Inthe P Prefixsensitivityin MT
trained persona case, the advantage might be the
One of the benefits of conditioning prefix to dis-
result of knowing what the opposite preferences
cretetextistheabilitytomodelpreferencedistri-
might be (“keep your enemies close”), since in-
butionwithinaninterpretable,well-definednatural
creasingnumberofoverallpersonadoesnothelp.
language space. In this section25, we investigate
D containsjustasmanypersonasinthesame
small whethertheprefixisrobustwithalternativeprefix
axisasD . However,trainingonmorepersonas
all than those used during training. To this goal, we
dohelpwithgeneralizationtounseenpersona.
generatetwoalternativesetsofprefixes: 1)weuse
Prefix is crucial for generalization In all four
25Inaddtiontoprefixesmentionedinthemaintext,wealso
subplots,bothMTmodelsperformalmostequally triedname,whichissimplyprefixingthenameofthepersona.
model noprefix tag few-shot persona personagold
ZEPHYR unseen 0.54(0.06) 0.54(0.05) 0.59(0.05) 0.6(0.05) 0.65(0.06)
ZEPHYR seen 0.54(0.05) 0.55(0.05) 0.60(0.05) 0.61(0.06) 0.65(0.06)
LLAMA1B unseen 0.50(0.05) 0.5(0.06) 0.55(0.05) 0.52(0.06) 0.59(0.06)
LLAMA1B seen 0.51(0.05) 0.51(0.05) 0.56(0.06) 0.54(0.05) 0.61(0.05)
LLAMA3B unseen 0.52(0.06) 0.51(0.06) 0.58(0.05) 0.55(0.06) 0.61(0.05)
LLAMA3B seen 0.53(0.05) 0.51(0.05) 0.59(0.05) 0.56(0.06) 0.62(0.05)
MINISTRAL unseen 0.53(0.05) 0.52(0.05) 0.56(0.05) 0.57(0.07) 0.62(0.05)
MINISTRAL seen 0.53(0.05) 0.53(0.05) 0.56(0.05) 0.58(0.06) 0.63(0.05)
Table 22: Multi-task finetuning with different baseline models all lead to noticeable generalization in unseen
personanotinthetrainingsplit. Largermodelrespondstopersonaandpersonagoldbetter.
Figure14: ComparisonofperformanceswithZEPHYRthroughprompting,PM,andMTinD
small
. MTistheonly
methodthatenablesgeneralizationwithcontrastingpreferences.
adifferentseedtoselectdifferentsetsoffew-shot Personalquestionsarehardtopersonalize In
preferencepairstocreateourpersonaorfew-shot Figure15,weseethattheperformanceinpersona
prefixes. 2)weshuffletheprefixesamongdifferent questionsisnotentirelydifferentbetweencorrect
personas(consistentacrossdifferentprefixtypes). (leftthreegroupofbars)andwrong,suggestingthe
Using combinations of two, along with 5 cross- personas inferred are not comprehensive enough
validationsetup,wecreatethefollowingablation forallofthepreferencesapersonmightwant.
settings:
Divergentquestionsshowprefixspecificity In
1. Seenpersonaseenprefix(↑): evaluatingtest thebottomhalfoftheplot(Figure15)however,we
split questions for personas in the training seemuchmoredramaticdifferenceinperformance
split,usingthesameprefixesintraining. betweencorrectandwrongprefixes,indicatesthat
MT ingeneralisabletochangepreferencegiven
2. Seenpersonaunseenprefix(↑): evaluating
specificpersonas.
testsplitquestionsforpersonasinthetraining
split,usingthesameprefixesintraining. Ifa Trained personas perform better In setups
modelweretoberobusttominortextualdif- where persona is seen in training always seem to
ferences,thisperformanceshouldbesimilar performbetterthanpersonanotseenduringtrain-
tosetting1. namedoesnothaveabarinthis ing(Seenpersonaunseenprefixvs. Unseenper-
category(andinsetting6)becauseapersona sona, and seen persona wrong seen prefix vs.
onlyhasonename(usually). unseenpersona),suggestingthatthedistribution
of prompt is also important for test time perfor-
3. Unseen persona (↑): evaluating test split
mance. In another word, having similar persona
questionsforpersonasnotinthetrainingsplit.
in the training set helps generalize to unseen per-
Sincethepersonaisunseen,prefixesforthese
sona with similar preferences. This difference is
personas are unseen. This is the same gen-
higherforpersonagpt4andpersonagoldvs. per-
eralizationsettingasthemainpaper. Higher
sonaandfew-shot,indicatebetterqualitypersona
performanceindicatesbettergeneralizationto
summaryboostsin-domainperformancemore.
newpersonas.
Personalizationisentirelycontributedtoprefix
4. Unseen persona wrong prefix (↓): evaluat-
Whenweremoveprefixesatinferencetime,wesee
ingtestsplitquestionsforpersonasnotinthe
personalizationscorereturnstobaseline,suggest-
training splitusing wrongprefix. The lower
ingthatallofthepersonalizationarebakedintothe
itisindicatemodeliskeepingthepreference
prefixes,andthatremovingthemreturnsthemodel
specificandnotconfusingacrossdifferentper-
tothebaselinestate. Thisisimportanttocustomize
sonas.
theamountofpersonalizationatdeploymenttime.
5. Seenpersonaseenprefix(↓): evaluatingtest
Wrongprefixbeatsnoprefix Thisisacurious
splitquestionsforpersonasinthetrainingsplit
phenomenonthatcouldbeexplainedbythepoten-
using wrong prefix for someone else during
tialamountofoverlapsindifferentpersona’sprefer-
training.
ences. Anevidencethatsupportsthisisthefactthat
6. Unseenpersonawrongprefix(↓): evaluating tagperformsthesameasbaselinewiththewrong
testsplitquestionsforpersonasinthetraining prefix. Tag is the shortest prefix, containing only
splitusingwrongprefixforsomeoneelsethat thetextsequencespecial_person_tag_XX,
isnotseenduringtraining. whereasallotherprefixescontaintextualdescrip-
tions,andorlongerstructuredpromptthatisshared
7. Seen persona no prefix (↓): evaluating test
betweenpersonas(seepromptsinAppendixH).To
splitquestionsforpersonasinthetrainingsplit
further provide evidence for this hypothesis, we
using no prefix at inference time. No prefix
calculate the average ROUGE score between the
trialsallowustounderstandwhetherwecan
original prefix and shuffled prefix for each prefix
recoverbaselinemodelperformancewithno
typeandshowthemin23. SinceROUGEislength
personalization.
normalized, we multiply it by length to provide
8. Unseenpersonanoprefix(↓): evaluatingtest anestimateofthescorenotnormalizedbylength
splitquestionsforpersonasnotinthetraining (totalnumberofsharedwords). Weshowthataf-
splitnoprefixatinferencetime. teraddingstructuredprompt(i.e. “Respondtothe
Figure15: MT(ZEPHYR)modelperformanceusingseenvs. unseenprefixesandshuffled(wrong)personas. Arrow
indicatewhethermetricishigherbetter(↑,withnohatches)orlowerbetter(↓),withhatchesinbars. Crosshatches
indicatenoprefixwasusedduringinference. BlackdashedlineisbaselineperformanceforMTmodeltrainedwith
noprefix.
following prompt from this person ...” ), there is allexceptoneaxisresultinnon-statisticalsignifi-
significantoverlapbetweendifferentprefixtypes cantdifferenceindicateourmethodsdoesgeneral-
excepttag. Thissuggeststhattherearenon-trivial izequitewellbyleveragingnaturallanguageasa
amountofinformationlearnedthroughthesecom- mediumforpreferencespecification.
monfragmentsoftextsaswell.
Do different prefixes generalizes differently
Q Leave-one-axis-out MT acrossaxis? InTable25,weseesimilarresults
asFigure2inthemaintext. Thereisalsonosignif-
Personas sampled from the same axis may share
icantdifferencebetweenperformanceforpersona
moreinformationwithintheaxisthanacrossaxis.
trained vs. untrained. This indicates that MT al-
To understand how well MT generalizes across
lowsgeneralizationacrossaxis.
axis,weconductleave-one-axis-outanalysis: fine-
tuningmodelonallbutoneaxis,andevaluatingon R Performanceacrossdemographic
the one axis not trained on. For this experiment, groups
wecanasktwoquestions:
Personalizedalignmentperformancemightgreatly
1. Aresomeaxesarehardertogeneralize? (Ta- dependonthedemographicsofthepeopleincluded
ble24) inthetrainingdata. Tounderstandhowthemodel
does across different demographic attributes, we
2. Do different prefixes generalizes differently
plot the improvement of MT(ZEPHYR) models
acrossaxis? (Table25)
over their baseline model with prompting across
different prefixes across different demographic
Aresomeaxeshardertogeneralize? Asseen
groups(Figure16).
in Table 24, personal questions remain similar
acrossseenandunseenpersona(6/11axisisworse
S GenerationEvaluationon ZEPHYR
in generalization case). This is more or less be-
causepersonalquestionsdonothavetoadhereto Totestwhetherrewardaccuracyreallyreflectgen-
axis,thuscreatinghigheroverlapbetweenpersonas. erationalimprovements,wetestagoodperforming
Uniquely, axis politics performance drop signif- prefixMT(ZEPHYR)withpersonagptagainstour
icantly when it is unseen during training, likely baselinemodelZEPHYR,asweonlyneedtoshow
becausepoliticiansarealmostexclusivelyknown thattheorderofperformancesremainsimilar. We
fortheirpoliticalopinions,sotheirpersonalques- curateonedivergentandonepersonalquestionfor
tions are more focused on politics. For common allpersonasinourdatasettoevaluategenerations.
questions,wedoseeamoreconsistentdropinper- We use ZEPHYR and MT (persona not trained),
formance (8/11 axis), indicating domain specific withandwithoutpersonagpt4prefix,andevalu-
contrastisstillimportanttoincludeintrainingto ateusingGPT4-as-personal-judge(ResultsinTa-
be able to perform well. However, the fact that ble 26). Consistent with the findings in 2, MT
prefix prefix+structuredprompt
len rouge len*rouge len rouge len*rouge
tag 1 0.76 1 1 0.76 1
few-shot 563 0.25 141 611 0.31 189
persona 264 0.22 58 307 0.34 104
personagpt4 209 0.25 52 252 0.39 98
name 2 0.02 0 44 0.91 40
personagold 203 0.23 47 246 0.37 91
Table23: Averagelength, rouge-Lsumscore, andtheirproductbetweenprefixandshuffledprefix. personais
generatedbyZEPHYR.
axis age AI professors diet education family gender
seen 0.63±0.07 0.58±0.06 0.63±0.06 0.62±0.07 0.62±0.07 0.6±0.06
Personal unseen 0.64±0.06 0.61±0.02 0.56±0.08 0.6±0.07 0.63±0.03 0.58±0.07
p-value 0.769 0.052 0.059 0.456 0.339 0.554
seen 0.67±0.1 0.65±0.09 0.65±0.09 0.67±0.09 0.67±0.09 0.65±0.09
Divergent unseen 0.62±0.08 0.62±0.07 0.71±0.11 0.58±0.11 0.62±0.04 0.62±0.06
p-value 0.245 0.469 0.221 0.092 0.028 0.354
axis geo politics profession religion sports
seen 0.61±0.07 0.61±0.07 0.61±0.07 0.62±0.08 0.62±0.07
Personal unseen 0.6±0.07 0.54±0.04 0.6±0.06 0.65±0.03 0.69±0.07
p-value 0.774 0.003 0.792 0.105 0.071
seen 0.66±0.09 0.65±0.08 0.66±0.09 0.66±0.09 0.67±0.1
Divergent unseen 0.62±0.05 0.65±0.05 0.63±0.06 0.64±0.11 0.68±0.08
p-value 0.082 0.868 0.268 0.718 0.797
Table24: MT(ZEPHYR)withpersonagpt4resultsfinetuningwithleave-one-axis-outset-up. Performancedonot
differsignificantlybetweenseenandunseenpersonasacrossmostaxis,indicatingstronggeneralization. Bolded
cellsindicatestaticalsignificance
noprefix tag few-shot persona personagpt4 name personagold
Personal seen 0.54±0.07 0.56±0.07 0.61±0.08 0.6±0.08 0.61±0.07 0.61±0.07 0.63±0.07
unseen 0.55±0.07 0.56±0.08 0.6±0.08 0.6±0.09 0.61±0.07 0.61±0.07 0.63±0.08
p-value 0.912 0.861 0.823 0.944 0.859 0.867 0.872
Divergent seen 0.53±0.07 0.54±0.07 0.62±0.08 0.63±0.1 0.66±0.09 0.68±0.09 0.69±0.08
unseen 0.52±0.08 0.53±0.08 0.6±0.07 0.6±0.08 0.64±0.08 0.64±0.08 0.67±0.09
p-value 0.789 0.928 0.497 0.448 0.518 0.394 0.597
Table25: MT(ZEPHYR)withpersonagpt4performancewithleave-one-axis-outsetupusingdifferentprefixes
suggestsstronggeneralizationperformanceacrossaxis.
Figure 16: MT(ZEPHYR) model improvements over prompting un-finetuned models with few-shot, persona,
andpersonagoldperformance(unseenduringtraining)acrossdifferentdemographicattributes. Barsaresorted
accordingtoattributefrequency.
with persona gpt4 performs the best on average, sports”,thecontentofsuggestionsmostlyremain
and degrades to baseline after removing prefixes, thesame. MT+personagpt4however,isableto
which are the keys to personalization. However, suggestmuchmorerelevanttacticsfrom“mentor
ZEPHYRwithpersonagpt4isworsethannopre- femaleathletes”,“pledgeaportionof... contract”
fix,indicatingpromptingisnotalwayseffectivefor todedicatedcharities,tocollaboratingwithfedera-
personalizationforsmallmodels. InAppendixT, tionsandengagewiththepublicutilizinghersocial
weconfirmthisqualitatively. influence.
MT without persona reverts back to baseline
ZEPHYR MT Avg.
performance Asseeninbothtables, MT’sgen-
model prefix F T F T
F - 55 53 36 48 erationisverysimilartoZEPHYR’s. Thisdemon-
ZEPHYR
T 45 - 38 42 42
strates that our dataset does not have underlying
F 47 62 - 32 47
MT T 64 58 68 - 63 bias,andthatmulti-taskprefixtrainingisaneffec-
tivewayofprovidingpersonalizationwhenneeded.
Table26: Pairwisewin-rate(%)betweenmodelgener-
ations. F=noprefix,T=prefixed(personagpt4). MT U Alignmenttax
withprefixoutperformsallbaselines.
Acommonphenomenonduringpreferencealign-
ment is so-called alignment tax: model’s degra-
T QualitativeAnalysisofGenerations dations in out-of-domain tasks (Lin et al., 2023).
Other than high-level roadmaps (Herd, 2023;
We include two sets of generation results for Byrnes,2023), Leeetal.(2024)proposestocon-
Alexandria Ocasio-Cortez (AOC) and Serena tinuefinetuneonbasemodel’soutputandLinetal.
Williams as an example to demonstrate the ef- (2024)arguesforselectiveweightaveragingtomit-
fect of personalization with our trained models. igatealignmenttax.
Samples are all generated with temperature sam- Abenefitoffinetuningmodelwithprefixes(ac-
pling of 1.0 and with maximum length cut off at tiveorpassive)isthatwecanmitigatetaxbyremov-
512 tokens. The models we include are the base- ingprefixattesttime. Weinvestigatethisbyaddi-
linemodel(ZEPHYR),andmultitask-trainedmodel tionallyevaluateMT(ZEPHYR)onout-of-domain
(MT(ZEPHYR)),inferencedwithandwithoutpre- tasks. For safety, we report reward accuracy
fixpersonagpt4. 26 on refusals-dangerous/offensive
fromRewardBench(Lambertetal.,2024). Using
Personainferencesuccessfullyuncoversunder-
LLMharness(Gaoetal.,2024a),wetestreason-
specified information In the first example (Ta-
ingthrougharc_easy/challenge,andpiqa
ble 27), we can see that persona gpt4 success-
(Clarketal.,2018;Bisketal.,2020)andfactuality
fullyinfersthatAOCisaliberalpoliticiankeenon
throughtruthfulqa_mc1/2(Linetal.,2022).
lookingfor“equitablesolutiontosocio-economic”
Alignment with different personas results in
problems. Similarly,Table28showsthatGPT4is
varyingperformanceingeneraltasks(safety,rea-
abletoinfermostofSerena’sbackgroundasbeing
soning, factuality)(Figure 17) up to 10% across
possiblyaprofessionalathletes.
individuals. Theimprovementsinsafetyandfac-
MT uses persona information much more ef- tualityacrosstheboardarelikelyduetolabelsig-
fectivelythanZEPHYR Withsuccessfulpersona nalsfromGPT4. Reasoningperformancedegrades
inference, we see that MT + persona gpt4 pro- acrossallpersonas,similartoobservationsby Lee
vides a generation is much more customized. In et al. (2024). This might be due to the questions
Table27weseethegenerationismuchmoresup- focusingmoreonfactualresponsethanreasoning,
portiveoflaborrights,additionallyincludinglabor evenforAI professors. Acrossallthreerows
strikes led by “women and people of color fight- in Figure 17, no prefix performance (red bar) is
ingagainstsystemicinequalityandexploitation”. closertobaselineperformancethanmostifnotall
However, ZEPHYR + persona gpt4 did not con- personas. Indeployment,iftheuserrequestdoes
textualizethestrikesaswellanddeviatesverylittle notrequirepersonalization(e.g. relatingtoobjec-
from ZEPHYR. InTable28,weseesimilarpattern. tive truths), model providers can selectively run
With ZEPHYR +personagpt4,despitemention-
26Weinsteadaggregatebythesummingovertokenslogp
ing“assomeonedeeplycommittedtotheworldof toavoidlengthbiaspresentinthedataset.
name AlexandriaOcasio-Cortez
persona Theuserseemstobewell-informedandinterestedinvariouspolitical,economic,andtechnologicaltopics,displayingaprogressiveorliberalbias.He/sheshowsconcernabout
gpt4 issuessuchasglobalization,internationalhealthcriseslikeCOVID-19,nationaldebt,newtechnologieslikeblockchain,andenvironmentalinitiativesliketheGreenNewDeal.
Theusercouldlikelybeinterestedinpolicymaking,economics,progressivepolitics,environmentalsustainability,orcouldbeworkinginarelatedfield.His/herwayofdelving
intocomplexissuesshowsananalyticalandcriticalmind,whichsuggestsaneducatedindividual,whovaluesfairness,economicbalance,andtechnologicalinnovation.When
interactingwithanAIassistant,thisuserpreferscomprehensive,factualresponsesthataddressthelargercontextofthequestionasked.He/shewouldappreciatenotonlythe
’what’butalsothe’why’and’how’.Anemphasisonequitablesolutionstosocio-economicproblems,sustainablepractices,technologicaladvances,andinformationabout
progressivepoliticsandpolicieswouldoftenbepreferred.Merelyfactualorneutralresponsesmaynotbewell-received.Theassistant’sabilitytopresentinformationfroma
progressiveviewpointmightbehighlyappreciated,contributingtoamoreengagingandsatisfactoryuserexperience.Consequently,itcanbeinferredthatthisuservalues
informed,contextually-rich,andprogressive-leaningdiscourse.Thesepreferenceshintatsomeonewhocaresaboutissuesbeyondtheirimmediateenvironmentandseeksto
understandandsolvecomplexglobalchallengesthroughalensoffairness,sustainability,andinterconnectedness.
prompt Whataresomemajorsuccessfulunionstrikesinthepasttwodecadesandtheireffectsonrespectiveworkplaces?
ZEPHYR 1.VerizonCommunicationsStrike(2016):TheCommunicationsWorkersofAmerica(CWA)andtheInternationalBrotherhoodofElectricalWorkers(IBEW)wentona45-day
strikeagainstVerizonCommunicationsinAugust2016.Thestrikeinvolvedapproximately39,000workersandledtothecompany’sagreementtoprovidejobsecurity,pay
increases,andbetterbenefitsforworkers.2.ChicagoTeachersUnionStrike(2012):In2012,theChicagoTeachersUnionwentonaseven-daystrike.Thestrikeinvolvedover
26,000teachersandsupportstaffandresultedinanewcontractthatincludedpayraises,smallerclasssizes,andincreasedresourcesforschoolsinlow-incomeareas.3.Deere
&CompanyStrike(2012):In2012,theUnitedAutomobile,Aerospace,andAgriculturalImplementWorkersofAmerica(UAW)wentonasix-weekstrikeagainstJohnDeere.
Thestrikeinvolvedapproximately10,000workersandledtoanewcontractthatincludedwageandbenefitincreases,alumpsumpayment,andjobsecurityprovisions.4.
AmericanAirlinesMechanicandRelatedServicesStrike(2019):TheTransportWorkersUnion(TWU)andtheInternationalAssociationofMachinistsandAerospaceWorkers
(IAM)wentona35-daystrikeagainstAmericanAirlinesinOctober2019.Thestrikeinvolvedapproximately30,000mechanicsandrelatedservicesworkersandresultedina
newcontractthatincludedjobsecurityprovisions,improvedbenefits,andpayincreases.5.AtlantaEducatorsStrike(2018):TheAtlantaBoardofEducationandseveral
educationunionswentonaone-daystrikeinJanuary2018.Thestrikeinvolvedapproximately1,200educatorsandresultedinanewcontractthatincludedpayraises,improved
benefits,andjobsecurityprovisions.Thesestrikesledtoimprovementsinworkingconditions,jobsecurity,andwagesforworkersintheserespectiveindustries,demonstrating
thepowerofcollectiveactioninachievingbetteroutcomesforworkersandcommunities.
ZEPHYR Overthepasttwodecades,therehavebeenseveralnotablesuccessfulunionstrikesacrossvariousindustriesthathavehadasignificantimpactontheirrespectiveworkplaces.
+per- Hereareafewexamples:1.VerizonStrike(2016):Over39,000VerizonCommunicationsworkers,includingtechnicians,customerservicerepresentatives,andcallcenter
sona agents,wentonstrikeinApril2016.Theemployeesweredemandinghigherwages,jobsecurity,andbetterbenefits.Afterfourweeksofstriking,Verizonagreedtoanew
gpt4 contractthatincludedsalaryincreases,jobprotection,andimprovementsinretirementbenefits.Asaresultofthestrike,Verizonreportedalossof$110millioninrevenuesand
experienceddecreasedcustomersatisfactionrates,asmanyVerizonservicesexperienceddowntimeduringthestrike.However,thecompanymaintainedthattherevenueloss
wouldnotimpactitsfull-yearearningsguidance.2.NursesatKaiserPermanenteStrike(2015):Inlate2015,around4,000nursesatseveralCalifornia-basedKaiserPermanente
hospitalswentonafive-daystrike.Thenursesweredemandingafaircontractthatincludedhigherwages,staffinglevels,andpatientcareissues.KaiserPermanenteisalarge,
integratedmanagedcareconsortium,providinghealthcareservicestoaround12millionmembers.Thenurses’strikeresultedinasignificantimpactonmedicalservicesat
KaiserPermanente.Thestaffingshortagesledtoanoverburdenedemergencydepartment,andsomepatientsreportedwaitingforseveralhourstoreceivemedicalattention.
Furthermore,electiveproceduresandappointmentswerecanceledorpostponed.3.ChicagoTeachersUnionStrike(2012):In2012,over26,000teachersfromtheChicago
PublicSchoolsSystemwentonstrikeforsevendays.Theeducatorsweredemandinghighersalaries,smallerclasssizes,andjobsecurity,asthedistrictwasplanningtoreplace
tenureandseniority-basedstaffingpolicywithaproposednewsystemthatwouldinsteadmeasureteachers’performancebasedonstudenttestscores.Thestrikeledtoalossof
severaldays’instructionaltimeforstudentsandcreatedwidespreaddisruptioninthecity’sschools.However,theChicagoTeachersUnion’seffortsresultedinincreased
salaries,asmallerclasssize,andarevisedprincipalevaluationsystem.
MT 1.VerizonStrike(2016):TheCommunicationsWorkersofAmerica(CWA)andtheInternationalBrotherhoodofElectricalWorkers(IBEW)wentonasix-weekstrike
againstVerizonCommunications,oneofthelargesttelecommunicationscompaniesintheUS.ThestrikeresultedinVerizonagreeingtoprovidejobsecuritytoabout35,000
employees,aswellasgrantingwageincreasesandimprovementsinretireehealthcarebenefits.2.ChicagoTeachersUnionStrike(2012):Morethan25,000teachersand
supportstaffinChicagowalkedoutforsevendaystodemandbetterworkingconditions,jobsecurity,andhigherpay.Thestrikeresultedinanewcontractthatreversed
someofthenegativeeffectsofthepreviousoneimplementedunderformerChicagoMayorRahmEmanuel.Theagreementincludedsalaryincreasesaswellasprovisions
tolessenclasssizes,eliminatetheuseofmeritpay,andputaholdonforcedschoolclosures.3.JohnDeereStrike(2012):Approximately10,000workersatJohnDeere
factoriesacrossIowa,Illinois,Wisconsin,andKansaswalkedoutforsixweeksovervariousworkrulesandcontracts.ThestrikewasthebiggestchallengefacedbyDeere&
Co.,atopagriculturalmachinerymaker,intwodecades.Thestrikeforcedmanagementtoagreetodouble-digitwageincreases,betterhealthandretirementbenefits,and
otheremployee-friendlypolicies.4.AtlantaJournal-ConstitutionStrike(2000):Morethan250graphicartists,photographers,andtypographicalworkersofTheAtlanta
Journal-Constitutionnewspaperswalkedoutforeightweeks.Theprotestagainstthemanagement’sdesiretoreplacestaffersandtheirunionstatusbroughtresultsastheCox
Enterprises,whoownedthenewspaperthen,eventuallyagreedtoacontractgrantingnewhireslowerwagesbutmaintainingsenioremployeerights.5.NYCHealth+Hospitals
Strike(2014):ThePatientCareFacilitiesunionrepresenting8,000hospitalaidesthreatenedtostrikeaftermonthsofnegotiationsoverhealthcare,wage,andjobsecurityissues.
Thestrikelastedsevendays,resultinginnewcontractswithpayboosts,jobcontrols,andassurancesaboutretirementbenefitstoaround35,000hospitalstaffers.Allthese
strikesandnegotiationsresultedinconcreteagreements
MT Yes,let’stalkaboutlaborrightsandworkers’power!Inrecentyears,there’sbeenaresurgenceofunionorganizingandstrikesacrossthecountry,fightingforhigher
+per- wages,betterbenefits,andsaferworkingconditions. Hereareafewnotableexamples: 1. ChicagoTeachersUnionStrikeof2012: Thishistoricstrikesawnearly
sona 30,000teachersandsupportstaffwalkoffthejobtodemandsmallerclasssizes,improvedworkingconditions,andfairevaluations. TheCTUwonsignificantvic-
gpt4 tories,includinga17%raiseandmoreautonomyovertheirschoolsandcurriculum. 2. OaklandEducationStrikeof2019: Over35,000teachersandstaffers
inOaklandpublicschoolsfollowedtheCTU’slead,stagingamulti-daystrikeforhigherwages,moreresourcesforstudentswithdisabilities,andreducedclass
sizes. Afteratensenegotiationprocess,theyultimatelysecureda12%raise,smallerclasssizes,andanewlearningcenterforstudentswithspecialneeds. 3.
StrikesatAmazonWarehousesin2019: WorkersatAmazonfulfillmentcentersinNewYork,Chicago,andothercitiescoordinatedshortwalkoutsandsickouts
ineffortstoprotecttheirjobsanddemandfairtreatmentamidAmazon’srapidexpansion. Whilenotofficially“strikes,”theseactionswerenonethelesspivotalin
highlightingtheabysmalworkingconditionsAmazonhaslongbeencriticizedfor. Thesestrikesarehelpingtoreinvigoratealong-standingtraditionoflaborsoli-
darityandcollectivebargainingpower.Notably,mostofthesecampaignshavebeenledbywomenandpeopleofcolorfightingagainstsystemicinequalityandexploitation.
ThisresurgentmovementiscrucialinconfrontingthegreedandpowerofcorporationslikeAmazonandholdingourelectedleadersaccountableforworkers’
rights. Thesestrikesalsohelpshedlightonandimprovewidersocietalissuessuchasthestruggletoprovideeducationalresourcestolowincomeneighborhoods. Overall,
unionsarevitalinpromotingstrongeconomicstability,jobsecurity,anddecentworkingconditionsforallworkingAmericans,andit’scriticalthatwesupportand
upliftthemintheirmission.
Table27: QualitativecomparisonofgenerationsbetweendifferentmodelsforapromptfromAlexandriaOcasio-
Cortez. Weunderlineportionsofthetextthatemphasizesuccessfulinferencepersonaorshowseffectofpersonal-
ization.
name SerenaWilliams
persona ##BasicInformationFromthequestionsasked,theuserseemstobeaprofessionalintheworldofsports,likelyacoach,asportsspeaker,orperhapsevenaprofessionalathlete.
gpt4 Theycouldalsobemanagingaprofessionalathlete.Theyarelookingfortipsforaspeechatayouthsportsconference,askingaboutsportsrehabilitationandhigh-altitude
training,implyingadeepinvolvementinsports-relatedactivities,whichrequirethesetopics.Theinterestsextendtosocialmediastrategiesforprofessionalathletes,suggesting
anattempttoincreasetheirpublicimageorthatofsomeonetheymanage—indicatingapossibleroleinsportsmarketingorsocialmediaadvocacy.##Preferencesand
InteractionsTheuserprefersdetailedresponsesthatarenarrativeandrichinspecificadviceandexamples.Thispersonplacesvalueoninformationthatisbothrelevantand
comprehensive,preferringanswersthatdelvedeepintothecontextoftheirquestions-eachonebeingquitespecific.Theirpreferenceforcomprehensiveresponsesthatinclude
amotivationalnarrative(seeninthepreferredresponseforthefirstquestion)suggestsalevelofemotionalintelligenceandanappreciationforinspiringstories.Also,their
preferenceforhigh-levelstrategies,preventativeapproaches,andafocusontechnologicaladvancesimpliesaforward-thinkingmindsetandaninclinationtowardsinnovationin
theirfield.Theyvaluestayingup-to-date,beinginformed,calculated,andstrategic,whichcancontributetotheirprofessionalcapacityintheworldofsports.Thismightalso
implythattheywouldinteractproactivelywiththeirAIassistant,expectingthoroughlydetailed,carefullycraftedresponsesthatareexamplaryandeducational,allowingthem
togaindeeperinsightsandperspectivesintothetopicstheyinquireabout.Asaprobableprofessionalwithinsportsorsportsmanagement,theywouldlikelyholdvaluessuchas
perseverance,teamwork,dedication,innovation,andpersonalgrowth,allofwhicharecommonlyassociatedwithsportsactivitiesandmanagement.
prompt HowcanIgetinvolvedincharityworkthatsupportsgenderequalityinsports?
ZEPHYR 1.Researchorganizations:Startbydoingsomeresearchtofindorganizationsthatfocusonpromotinggenderequalityinsports.Lookfororganizationsthathaveaspecificfocus
onaddressingissuesrelatedtowomen’sparticipation,representation,andopportunitiesinsports.SomeexamplesofsuchorganizationsincludeWomen’sSportFoundation,
InternationalWorkingGroupforWomenandSport,andCoalitiontoUnleashWomen’sPotentialinSports.2.Volunteeropportunities:Onceyou’vefoundafeworganizations,
lookforvolunteeropportunitiesthatmatchyourskillsandpreferences.Someopportunitiesmayinvolvecoachingormentoringgirlsandwomeninsports,organizingevents,
fundraising,oradvocacy.3.Donate:Ifyou’reunabletovolunteer,youcanstillsupporttheseorganizationsbymakingadonation.Mostorganizationshavea“donate”button
ontheirwebsite,andyourcontribution,nomatterhowsmall,canmakeabigdifference.4.Spreadawareness:Promotethecauseonyoursocialmediaprofilesandshare
yourexperienceswithothers.Youcanuseyoursocialmediaplatformstoraiseawarenessabouttheissuesrelatedtogenderequalityinsportsandhelpspreadthewordabout
organizationsthatpromotewomen’sparticipationinsports.5.Advocate:Contactyourlocalrepresentatives,politicians,andsportsfederationstoencouragethemtosupport
women’ssports,promotegenderequalityinitiatives,andcreateopportunitiesforgirlsandwomeninsports.6.Joincampaigns:Participateinsocialmediacampaignsorpublic
demonstrationsorganizedbytheseorganizations.Youcanjoinprotests,walkouts,ordemonstrationsthataimtoraiseawarenessaboutissuesrelatedtogenderequalityinsports.
7.Collaborate:Collaboratewithotherorganizationsandgroupsthatfocusonsimilarcauses.Thiswillhelpyoucreatealargerimpact,shareresourcesandknowledge,and
expandyournetwork.Remember,thekeytomakingadifferenceistotakeaction,nomatterhowsmall,consistent,andpersistentitmaybe.
ZEPHYR Assomeonedeeplycommittedtotheworldofsportsandpassionateaboutpromotinggenderequality,youmaywanttoconsidergettinginvolvedincharityworkthatadvocates
+per- forthiscause.Herearesomesuggestionstohelpyouexploreopportunitiesinthisarea:1.Researchorganizations:Therearenumerousnon-profitorganizationsthatadvocate
sona forgenderequalityinsports.Youmightwanttoresearchsomesuchorganizationsthatresonatewithyourbeliefsandvalues.ThewebsiteCharityNavigatorcanbeagreat
gpt4 resourcetohelpyouidentifyreputableorganizationsinthisfieldthathaveaproventrackrecordofimpactfulwork.Onceyouhavealistoforganizations,youcanreviewtheir
websites,socialmediahandles,andannualreportstolearnmoreabouttheiractivities,initiatives,andachievements.2.Joinanadvocacygroup:Afteridentifyingorganizations
thatinterestyou,considerreachingouttothemtolearniftheyhaveadvocacygroupsthatyoucouldjoin.Thesegroupstypicallyconsistofvolunteersandsupporterswhoshare
similarvaluesandarepassionateaboutpromotinggenderequalityinsports.Beingapartofsuchagroupcanprovideyouwithopportunitiestoconnectwithlike-minded
individuals,learnabouttheissuesfacingwomeninsports,andcontributetoinitiativesthatpromotegenderequality.3.Donateorfundraise:Manynon-profitorganizationshave
fundraisingprogramsthatyoucouldparticipateintoraisefundsfortheirwork.Youcoulddonatemoney,hostafundraiser,orparticipateinacharityevent.Bydonatingor
fundraisingforanorganization,youcancontributetotheirmissionandsupporttheirwork.Additionally,byparticipatinginacharityevent,youcanbringawarenesstothecause.
4.Provideexpertise:Asasportsprofessionalwithyearsofexperience,youcouldofferyourexpertisetoorganizationsworkingtowardsgenderequalityinsports.Dependingon
yourareaofexpertise,youcouldoffertohelpwithcoaching,training,mentoring,ordevelopingprogramsthatpromotewomen’ssports.Offeringyourservicescanbea
meaningfulcontributiontotheorganization’swork.5.Volunteer:Non-profitorganizationstypicallyrelyonvolunteerstoexecutetheirprograms.Asasportsprofessionalwith
abusyschedule,youcouldstillfindtimetovolunteerfororganizationsthatpromotegenderequalityinsports.Ifyourbusyscheduledoesnotallowforlong-termcommitments,
youcouldconsidershorter-termcommitments,suchashelpingoutduringaone-timeevent.6.Spreadawareness:Lastly,oneofthemostimportantwaystopromotegender
MT 1.Lookforlocalorganizations:Startbysearchingfororganizationsinyourareathatsupportgenderequalityinsports.YoucancheckwebsiteslikeGirlsWhoSweat,Women’s
SportsFoundation,UNWomen,orvisityourlocalsportscenter,library,orcommunitycenter.2.Researchopportunities:Onceyouhavefoundpossibleorganizations,go
throughtheirwebsites,socialmedia,orreachouttothemviaemailorphone,andfindoutabouttheircharityevents,volunteerprograms,anddonationcampaigns.3.Attend
events:Attendthecharityeventsorganizedbytheseorganizations.Thiswillgiveyouanopportunitytolearnmoreaboutthecause,meetlike-mindedindividuals,andnetwork
withinfluentialpeopleinthesportscommunity.4.Volunteer:Youcansignuptovolunteerfortheorganizations.Thismayinvolvecoachinggirls’teams,assistingintraining
sessions,organizingtournaments,orworkingasafundraiseratevents.5.Spreadawareness:Spreadawarenessaboutgenderequalityinsportsbysharingandpromoting
theseorganizations’missionsviasocialmedia,word-of-mouth,orpostingflyersinyourcommunity.6.Donate:Finally,youcandonatefinanciallybymakingone-timegifts,
becomingamonthlydonor,orparticipatingincharityauctions,runs,orcyclingeventswhereyourdonationgoesdirectlytoempowergirlsandwomeninsports.Byfollowing
anyone,orall,ofthesesteps,youcanmakearealdifferenceinpromotinggenderequalityinsportsandhelpinggirlsandwomenachievetheirfullpotentialthroughsports.
MT Asasportsprofessional,youhavethepowertomakeasignificantimpactoffthefieldbyadvocatingforgenderequalityinsports. Here are some ways to
+per- get involved in charity work supporting this cause: 1. Research and Partner with Charities: Look up organizations like the WNBA Play-
sona ers Association, Women Win or the Women’s Sports Foundation, and connect with them to learn about their initiatives, events, or campaigns.
gpt4 Collaboratewiththesecharitiesbyprovidingyourtime,socialmediasupport, or resources to help raise awareness and funds. 2. Donate: Contribute fi-
nancially through regular donations, host a fundraiser (online or in-person), or pledgeaportionofyourcontract,awardearningsorprizemoney to sports-
focused charities aligned with gender equality. 3. Mentoring:Volunteertomentorfemaleathletesandhelpthempursuecareersinsportsandleadershiproles.
Mentorship programs facilitate empowerment by sharing expertise, nurturing talent and providing a support system to grow their potential. 4.
SpeakingEngagement:Hostworkshopsforyoungfemales,participateinpaneldiscussions,orpublicspeakingeventsthathighlightandelevateopportunitiesandresources
offeredtofemaleathletes,promoteequalpay,sportstrainingandbetterworkingconditions.5.Collaborations:Youcanconsidercollaboratingwiththeleaguesorfederations
thatfocuspredominantlyonwomen’ssports,participateincollaborativecharityinitiativesandmakeyourplatformavailabletoraisefundsorawarenessbyusinghashtags,
creatingcampaigns,orchallengesthatgarnersupportfromyourfans.6.Leadershiprole:Youcouldaimtocreateateam,charitydrive,ornonprofitorganizationcenteredon
equalityinsports.Leverageyoursocialnetwork,celebritystatusorexistingplatformtoamplifythemessage,rallytroopsbyinvolvingfriends,teammates,andpeersinyour
charityprograms.Bycontributingtotheseinitiatives,youarespreadingthepositiveimpactofthepowerofsportsbeyondtheconfinesofplayingfields,andsettinganexample
forfuturegenerationsofaspiringfemaleathletes.
Table28: QualitativecomparisonofgenerationsbetweenfourdifferentmodelsforapromptfromSerenaWilliams.
Weunderlineportionsofthetextthatemphasizesuccessfulinferencepersonaorshowseffectofpersonalization.
inferencewithoutaprefix.
0.825
0.800
0.775
0.750
0.725
0.700
no pref R ix and D Po an ua lld A . T O ru c m a p sio-C J o o r e t e BB z iedren nie Sa T n im de n r it s Y G o e s b h r u u a B S e u n c g h io S i Se a re ri n aa W T il i l g ia e m rL W s at oa on dy sa S S e w b e a e s n ti e a L y n e T B h r r o u n n D J a a v m id e B s ec M kh ik a e m Trout
ytefaS
0.700
0.675
0.650
0.625
0.600
0.575
Sebastian M Th ik ru e n T T ro ig u e t r W Yo o s o h d u s a B S en u g ch io i B Se a r r n ia ie L S a a ta n n d y e a r s S S e w r e e e n n a e W y i R llia a m nd s L Pe a B ur l on A . J O am ca e s s i D o- a C v o id r t B ez e D c o k n h a a l m d T T r i u m m n p it Ge J b o r e u Bide n n o prefix
gninosaeR
Inference Prefix
personal prefix
no prefix
0.600
0.575
0.550
0.525
0.500
Serena Wi M llia ik m e s Tro n u o t pre T f i i g xerL Wat oa on dya s Sw R e a e n n d e D y Pa avi ud l B A e . c O k c h a a s m io-C Jo o e rt e BY z io ds eh nua B T e im n n g i i t o B G e e rn b i r e u S D a o n n d a e l r d s T S ru u m ch p i L S e a B ri r a on S e Ja b m as e ti s an Thrun
ytilautcaF
Figure 17: Sorted MT(ZEPHYR) with persona gpt4
performance(nottrained)onout-of-domaintasks. No
prefix(aggregatedacross5CVs)returnsmodelclose
to ZEPHYR no prefix (dashed line). Personas are
sampledfromaxessports,AI professors,and
politics. Results with other prefixes are in Ap-
pendixU.
InFigure17,weshowthatbynotusinganypre-
fix at test time for MT models, we recover most
of the baseline model performance. Here, in Fig-
ure 18, we observe that this is generally true re-
gardless of the prefix in reasoning. However for
factuality(OpinionQA),wedonotseesignificant
differencebetweenusingpersonaprefixvsnotus-
ing prefix. This suggests these tasks may have
inherentlydifferentmechanismthataredifferently
affectedduringpreferencefinetuningforpersonal-
ization. ß
Figure 18: Reasoning and factuality performance on
MT(ZEPHYR)modelswithoutusingprefixatinference
time. BlackdashedlineisZEPHYRperformancewith-
outanyprefix.

=== REVISE TO ===
PROFESSIONAL TONE: Begin directly with content - NO conversational openings like 'Okay, here's...'

1. Fix all issues above
2. Title: "Is Active Persona Inference Necessary for Aligning Small Models to Personal Preferences?"
3. Include 10-15 quotes from paper text
   - Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
   - Use consistent quote formatting: 'The authors state: "quote"' or vary attribution phrases
   - Vary attribution phrases to avoid repetition
   - CRITICAL: Only extract quotes that actually appear in the paper text
4. ELIMINATE ALL REPETITION - each sentence must be unique
   - Check before each sentence: 'Have I already said this?' If yes, write something new
   - Vary attribution phrases - do NOT repeat 'The authors state' multiple times
5. Extract methodology, results with numbers, key quotes
6. 1000-1500 words, structured with ### headers

Generate COMPLETE revised summary.