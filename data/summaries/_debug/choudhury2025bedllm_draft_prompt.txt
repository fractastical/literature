=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design
Citation Key: choudhury2025bedllm
Authors: Deepro Choudhury, Sinead Williamson, Adam Goliński

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Abstract: Weproposeageneral-purposeapproachforimprovingtheabilityoflargelanguage
models(LLMs)tointelligentlyandadaptivelygatherinformationfromauseror
otherexternalsourceusingtheframeworkofsequentialBayesianexperimental
design (BED). This enables LLMs to act as effective multi-turn conversational
agentsandinteractivelyinterfacewithexternalenvironments. Ourapproach,which
wecallBED-LLM(Bayesianexperimentaldesignwithlargelanguagemodels),
isbasedoniterativelychoosingquestionsorqueriesthatmaximizetheexpected
in...

Key Terms: task, apple, intelligent, turn, design, information, bayesian, experimental, universityofoxford, gathering

=== FULL PAPER TEXT ===

Preprint
BED-LLM: INTELLIGENT INFORMATION GATHERING
WITH LLMS AND BAYESIAN EXPERIMENTAL DESIGN
DeeproChoudhury SineadWilliamson AdamGolin´ski
UniversityofOxford Apple Apple
NingMiao FreddieBickfordSmith MichaelKirchhof
CityUniversityofHongKong UniversityofOxford Apple
YizheZhang TomRainforth
Apple UniversityofOxford
ABSTRACT
Weproposeageneral-purposeapproachforimprovingtheabilityoflargelanguage
models(LLMs)tointelligentlyandadaptivelygatherinformationfromauseror
otherexternalsourceusingtheframeworkofsequentialBayesianexperimental
design (BED). This enables LLMs to act as effective multi-turn conversational
agentsandinteractivelyinterfacewithexternalenvironments. Ourapproach,which
wecallBED-LLM(Bayesianexperimentaldesignwithlargelanguagemodels),
isbasedoniterativelychoosingquestionsorqueriesthatmaximizetheexpected
information gain (EIG) about the task of interest given the responses gathered
previously. We show how this EIG can be formulated (and then estimated) in
aprincipledwayusingaprobabilisticmodelderivedfromtheLLM’spredictive
distributionsandprovidedetailedinsightsintokeydecisionsinitsconstruction
and updating procedure. We find that BED-LLM achieves substantial gains in
performance across a wide range of tests based on the 20 Questions game and
usingtheLLMtoactivelyinferuserpreferences,comparedtodirectprompting
oftheLLMandotheradaptivedesignstrategies.
1 INTRODUCTION
Intelligent information gathering—the ability to ask the right questions at the right time—is
fundamentaltoeffectiveAIsystems. However,despitetheirmanysuccesses,LLMscurrentlyfall
shortonacrucialaspectofinteractiveintelligence: proactivelyseekingoutinformationfromauser
orexternalenvironmentinanintelligentandadaptivemanner(Labanetal.,2025;Lietal.,2025c).
For example, they have been shown to perform poorly on problems such as multi-turn guessing
games (Bertolazzi et al., 2023; Zhang et al., 2024), task clarification (Chi et al., 2024), IT task
automation(Jhaetal.,2025),andmulti-steptooluse(Patiletal.,2025). Inparticular,whilemodern
LLMsareoftencapableofproducingcoherentandinsightfulquestions(orotherexternalqueries)
inasingle-turnsetting,theytypicallystruggletoappropriatelytailortheirquestionstopreviously
gatheredresponsesoninteractivetasks(Bertolazzietal.,2023;Patiletal.,2025).
Thereis,therefore,apressingneedtoimprovetheabilityofLLMstoadaptivelyaskquestionsbased
onpreviousresponses,andgatherinformationinatargetedmanner. Suchcapabilitiesareessentialfor
awidevarietyofproblems,suchasclarifyinguserintent,personalizingmodelbehaviortoaparticular
user,orgenerallyactingaseffectivemulti-turnconversationalagents. Theyarealsocriticalifwe
wanttouseLLMsindatagatheringtasksorasautomatedagentsindecision-makingpipelines(Wu
et al., 2025). In turn, these capabilities are essential across domains ranging from medical diag-
nosis(Hirosawaetal.,2024),troubleshooting(Jhaetal.,2025),preferencelearning(Handaetal.,
2024;Chakrabortyetal.,2024;Ouyangetal.,2022),andtutoringsystems(Kestinetal.,2025;Liu
etal.,2024a),toconductingautomatedsurveys(Aheretal.,2023;Leeetal.,2024;Jacobsenetal.,
2025),andAI–drivenscientificinquiries(Luetal.,2024;Mandaletal.,2025). Notethatinallthese
1
5202
tcO
81
]LC.sc[
2v48112.8052:viXra
Preprint
problemsitisnotenoughfortheLLMtogeneratefullsetsofsuitablequestionsupfront,weneedit
tobeabletoadaptivelychoosequestionsthataretailoredtothealready-collecteduserresponses.
We propose to address this challenge using the framework of sequential Bayesian experimental
design(BED,Lindley(1956);MacKay(1992);Chaloner&Verdinelli(1995);Sebastiani&Wynn
(2000);Rainforthetal.(2024)),whichprovidesamodel-based,information-theoreticmechanism
for making adaptive design decisions, given a generative model of the experiment. Specifically,
weshowhowtheproblemofinteractiveinformationgatheringwithLLMscanbeformulatedasa
sequentialexperimentaldesignproblemwithamodelderivedfromtheLLM,whereinweiterate
betweenchoosingqueriesbasedonmaximizingtheirexpectedinformationgain(EIG)andupdating
ourbeliefswiththeinformationfromthereceivedresponse.
WecallourapproachBED-LLMandshowhowitssuccessiscriticallydependentonourprecise
modelformulation,beliefupdatingprocedure,andEIGestimationstrategy. Inparticular,weshow
thatitisessentialtoformulatethemodelwithaprecisedistributionpairingthatdoesnotsolelyrely
onin-contextlearningtoupdatebeliefsandusestheLLM’suncertaintiesinthespaceofanswers
ratherthanthemorecomplicatedunderlyinghypothesisspacewearetryingtolearnin.
Together, we find that these innovations provide substantial performance benefits over directly
generatingqueriesfromtheLLMandmorebasicapproximationsofthesequentialBEDframework.
Specifically,wefirstfindthatBED-LLMprovidessubstantialimprovementsinthesuccessratefor
the20QuestionsproblemacrossavarietyofLLMsandtargetquantities.Forexample,whenguessing
celebritieswithasmallmodel,Llama-3.1-8B,weobservea5.8xgaininsuccessrate. Second,we
demonstratenoticeableimprovementsinusingtheLLMformovierecommendations,showingthat
thesebenefitsholdevenwhentheLLM’spredictivemodeldiffersfromthatoftheanswerer.
2 PROBLEM FORMULATION AND BACKGROUND
TherearetwonaturalwaystoimproveLLMs’abilitytogatherinformation: modifyingthemodel
itself (e.g. via test-time- or post-training) or altering how the model is used at deployment time.
Wefocusonthelatter,sinceinformation–gatheringtasksrarelyprovidetask-specificdataupfront
(e.g.auser’sunknownpreferences),anddeployment–timemethodsavoidthecostanddifficultyof
finetuninganLLMaltogetherandareapplicabletoanyexistingLLM.However,weemphasizethat
improvementsatthemodellevel(e.g.,Zhangetal.,2024)wouldbecomplementarytoourapproach.
To formalize the notion of information gathering, we need a concrete idea of what we wish to
learn about. We denote the target quantity of interest as θ, which may represent, for example, a
user’spreferences,theanswertoaquestion,oradesiredpieceofcontent. Westartwithincomplete
informationaboutθ,asrepresentedbyaninitialbeliefdistributionorprior,p(θ),butcanrefinethese
beliefsbymakingqueries,x∈X,totheuserorsomeotherexternalagentandreceivingresponses,
y ∈Y,thatareinformativeaboutθ. Multiplesuchqueries,x ,...,x ,canbeadaptivelyselected
1 n
inasequentialdecision-makingprocesswhereweiterativelychooseeachx basedonthecollected
t
historyh :=(x ,y ) . Asourhistorygrows,wewillupdateourbeliefdistributiontoobtain
t−1 i i i=1:t−1
p(θ;h )viasomemodelupdatingprocedure.1 IntheLLMsetting,thereisconsiderableflexibility
t−1
inhowp(θ;h )isconstructed,asdiscussedin§3.3and§4. Whilep(θ;h )neednotbeexplicitly
t−1 t−1
defined,itprovidesthefoundationforourinformation-theoreticmethodofqueryselection.
Forclarityofexposition,wefocusonthecasewherethex correspondtoexplicitquestionsaskedto
t
theuser,butemphasizethattheapproachappliesmorebroadlytootherformsofexternalinteraction
bytheLLM,suchasretrievingdocumentsorcallingexternalfunctions.
2.1 IN–CONTEXTUPDATINGOFTHEBELIEFDISTRIBUTION
A natural and cheap way to incorporate the interaction history into the LLM is to include it in
thecontext(Brownetal.,2020). IftheLLM’sdistributionovergeneratedtext,z∈Z,isp (z)
LLM
given appropriate prompting, then p (z;h ) is an updated distribution with the previous
LLM t−1
question–responsepairsincontext. Fromthis,wecanderiveanupdatedbeliefdistributionoverθ.
1Wecarefullydistinguishbetweenexplicitprobabilisticconditioning,i.e.p(a|b),andmoregeneraldepen-
dency,p(a;b).Theformercorrespondstotheconditionaldistributionofanassociatedjointdistribution,p(a,b),
whilethelattermaynot.Here,h influencesourdistributiononθ,butitisnotderivedviaajointdistribution.
t−1
2
Preprint
Mostsimply,thiscanbedonebyusingp (z;h )todirectlyqueryaboutθ(e.g.ifθissome
LLM t−1
preference,wecouldprompttheLLMtopredictthispreference). However,asweshowlater,this
approach often fails to appropriately incorporate the information from h , leading to a belief
t−1
distributioninconsistentwithpastobservations. Thisisconsistentwithrecentworkthatshowsthat
incontextupdatingdoesnottreatallcontextualinformationequally(Kossenetal.,2024;Liuetal.,
2024b;Zhangetal.,2024). In§3.3,weintroduceamorerobustmethodforderivingp(θ;h ).
t−1
2.2 INFORMATION–THEORETICEXPERIMENTALDESIGN
ThecoreoftheBEDframeworkisajointgenerativemodelp(θ,y;x)overthetargetquantityθand
outcomes,y,givendesignsx.Mostcommonly,thisisspecifiedasaBayesianmodelusingapriorp(θ)
andlikelihoodp(y|θ;x). Inthegeneralcase,designsarethenchosentomaximizetheexpectationof
someutilityfunctionU(θ,y,x)underthismodel: wechoosex∗ = argmax E [U(θ,y,x)].
x p(θ,y;x)
ThemostcommonchoiceistotakeU(θ,y,x) = logp(θ,y;x)−logp(θ)logp(y;x), wherep(θ)
andp(y;x)arethemarginaldistributionsonθandyimpliedbyourjointmodelandwehaveassumed
thatourcurrentbeliefsonθareindependentofthedesignx. Thisleadstoanobjectivecorresponding
totheexpectedinformationgain(EIG)inθ(Lindley,1956;1972),
EIG (x)=H[p(θ)]−E [H[p(θ|y;x)]] (1)
θ p(y;x)
=H[p(y;x)]−E [H[p(y|θ;x)]], (2)
p(θ)
whereHdenotestheShannonentropy(i.e.,H[p(θ)]=−E [logp(θ)]). Wecanthusequivalently
p(θ)
thinkoftheEIGas: a)themutualinformationbetweenθandy,b)theexpectedinformationgain
overpossibledatasimulatedfromourmodel(wheretheinformationgainisdefinedasthereduction
inentropyfromourprioronθ totheposterior),orc)theexpectedreductioninentropyoverdata
fromobservingθsimulatedfromourprior(Sebastiani&Wynn,2000).
WorkingwiththeEIGishighlysuitedtoasequentialoradaptivedesignapproach,whereinitisgener-
allyreferredtoassequentialBEDorBayesianAdaptiveDesign(Rainforthetal.,2024). Becausethe
EIGisonlyafunctionofourunderlyingmodel,whenweupdatethemodelasnewdatabecomesavail-
able,ourEIGdesignobjectivewillnaturallyupdateaswell. Specifically,toderivetheincremental
EIG(Cavagnaroetal.,2010)forthet-thquery,EIG (x ;h ),wesimplyreplacethejointp(θ,y;x)
θ t t−1
intheaboveformulationwiththeupdatedjointp(θ,y ;h ,x ),withallmarginalsaconditionals
t t−1 t
derived from this (e.g. p(y;x) becomes p(y ;h ,x )). Here this updated joint conventionally
t t−1 t
comesfromaBayesianupdateoftheoriginalmodel.However,inmanycases,thisisnotpracticaland
othernon-Bayesianupdatesareperformedinstead,e.g.inactivelearningtheupdateoftenactually
correspondstoretrainingthemodelwiththenewdata(Galetal.,2017;BickfordSmithetal.,2023).
3 SEQUENTIAL BAYESIAN EXPERIMENTAL DESIGN FOR LLMS
ThesequentialBEDframeworkdescribedin§2.2requirestwocorecomponentstobespecifiedbythe
user: a)aninitialjointmodelp(θ,y;x)overhypothesesθandoutcomesy,givenchosenexperiment
x,andb)aproceduretoderiveanupdatedmodelp(θ,y ;h ,x )afterobservingh . IntheLLM
t t−1 t t−1
setting,thereissignificantflexibilityinthesecriticaldesigndecisions. Inparticular,therearemany
waystoderiveasuitablejointdistributionfromtheLLManditsabilitytolearnin-contextprovides
opportunitiesforupdatemethodsthatgobeyondstandardBayesianmodelupdates.
ModelConstruction AmajorchallengeintheLLMsettingisthatunlikeconventionalprobabilistic
models, in general, p (θ)p (y;[θ,x]) ̸= p (y;x)p (θ;[x,y]). That is, we induce a
LLM LLM LLM LLM
differentjointdistributionifwefirstsampleθthensampleywithθincontext(whichwerefertoasthe
prior–likelihoodpairing),thanifwefirstsampleythensampleθwithyincontext(data–estimation
pairing). Moreover,wecandeviatefromthedistributiondirectlyinducedbytheLLMononeorboth
variables. ThesuccessofusingBEDwithLLMsturnsouttobecriticallydependentonthesechoices.
We delay proper discussion of this complex issue until §4, where we will see that the preferable
setupcandependonproblemsettingand,inparticular,therelativecomplexityofspacesofθand
y. Fornow,wewillfocusonusingtheprior–likelihoodpairing;wewillarguein§4thatthisisthe
advantageoussetupinmanypracticalscenarios. WhilewewillgenerallyusetheLLM’sdirectly
induceddistributionforthelikelihood,weallowthepriortodeviatefromthisinaproblem–specific
manner. Assuch,ourinitialjointmodelwillbep(θ,y;x)=p(θ)p (y;[θ,x]).
LLM
3
Preprint
ModelUpdating Optimallyupdatingthejointmodelinthissettingrequiresincorporatingnew
observationsinawaythatbothfullycapturestheinformationfromnewdataandiscomputationally
tractable. Atoneextreme,wecouldperformfullBayesianupdatesviaapproximateinference,asin
classicalsequentialBED.However,thisdemandsaprohibitivelylargenumberofLLMevaluationsto
accuratelyapproximatetheposterior,anditdoesnotexploitthepoweroftheLLMasaprobabilistic
generativemodel,whereautoregressivesequentialrolloutsoftenleadtomorenuancedanddiverse
behaviorthanrepeatedstaticlikelihoodqueries. Attheotherextreme,simplein-contextupdating,
p(θ;h ) = p (θ;h ), ischeapbut, asweshowlater, failstoreliablycaptureinformation
t−1 LLM t−1
fromnewdata,leadingtoinconsistentbeliefstatesandunderminingthesequentialBEDapproach.
Aswediscussin§3.3,wethereforeemployastrategythatissomewherebetweenthetwo: drawing
samplesinawaythatutilizesp (θ;h )whileencouragingdiversity,thenfilteringoutsamples
LLM t−1
thatareactuallynotcompatiblewithh andrenormalizing. Werefertotheresultingdistributionas
t−1
p (θ;h ). Wedonotupdateourlikelihoodmodelp (θ;h );see§A.1foradiscussion.
f t−1 LLM t−1
BED-LLM Wenowintroduceourspecificalgorithmicapproach,BED-LLM.Here,thequerieswill
correspondtoourdesigns,x(assumedtobeinformofquestionsposedtotheuserinthefollowing
forsimplicity,butcouldalsobe,e.g.,externalfunctioncalls,documentretrieval,websearch,etc),and
theresponsesreceivedwillcorrespondtoouroutcomes,y.UsingtheLLMtoderivejointmodelsover
theseoutcomesandthetargetvariablesθgivenhistories,h asdescribedabove,wecaninterleave
t−1
choosinginformativequestionsbyoptimizingtheincrementalEIG,EIG (x ;h ),andupdating
θ t t−1
ourunderlyingmodelbasedonthereceivedquestion–responsepairs. Specifically,BED-LLMiterates
overthefollowingkeysteps,wheretindexesthecurrentturn:
1. Generatecandidatequestions(§3.1): ProposeacandidatesetofM diverse,multiple-choice
questions,Xcand,byappropriatesamplingoftheLLMbasedontheconversationalcontexth .
t−1
2. ComputeEIGestimator(§3.2): Foreachcandidatex ∈Xcand,estimateEIG (x ;h ).
t θ t t−1
3. Selectandaskoptimalquestion: Choosethequestionx ∈Xcandthatyieldsthehighestesti-
t
matedEIG.Posex totheuser,observeresponsey ,andupdatethehistory,h =(h ,(x ,y )).
t t t t−1 t t
4. Constructupdatedjoint(§3.3): p(θ,y ;h ,x )=p (θ;h )p (y ;[θ,x ]),using
t+1 t t+1 f t LLM t+1 t+1
thenewhistoryandreturntoStep1(unlessaterminationcriterionhasbeenachieved).
Noteourbeliefstateonθafterthet-thturnissimplygivenbyp (θ;h ).
f t
3.1 GENERATINGCANDIDATEQUESTIONS
Asitisnotcomputationallyfeasibletodirectlyoptimizeoverthespaceofpossiblequestions,we
relyonusingtheLLMtoproposediversecandidatequestions,Xcand,thenselectthebestquestion
fromthese. Weconsidertwospecificapproaches: 1)Unconstrainedgeneration. Givenh ,the
t−1
LLMissimplyaskedtoproposenewquestionsbysamplingfromp (x ;h )withappropriate
LLM t t−1
prompting.2)Conditionalgeneration.TheLLMisgivenbothh andageneratedsetofhypotheses
t−1
Θcand = {θ(n)}N , such that we sample from p (x ;[h ,Θcand]). Specifically, the LLM is
n=1 LLM t t−1
promptedtoproposequestionsthat“slice”thehypothesispoolintoroughlybalancedsubsets.
Forbothstrategies,wesampleM questionsjointlywitharelativelyhightemperaturetoencourage
diversity. Conditional generation allows us to “guide” the LLM to propose highly informative
questions. However,itrisksoverfittingtoΘcand. Inpractice,wefinditiseffectivefordiscretespaces
(§6.1),butlesssoforspaceswithcomplex,overlappinghypotheses(§6.2). Werestrictquestionsto
multiple-choiceformattoallowp (y ;[θ,x ])toproducewell-calibratedprobabilities(see§4).
LLM t t
3.2 ESTIMATINGEIGFOREACHQUESTION
To estimate the EIG based on Equation 2 for a given question x , we derive the following Rao-
t
BlackwellizedestimatorbasedontheLLM’spredictivedistribution:
EIG (x ;h )≈1 (cid:80)N (cid:80) p (y ;[θ(n),x ])logp (y ;[θ(n),x ])
θ t t−1 N n=1 yt∈Y LLM t t LLM t t (3)
(cid:80)
− pˆ(y ;[h ,x ])logpˆ(y ;[h ,x ]),
yt∈Y t t−1 t t t−1 t
wherepˆ(y ;[h ,x ]):= 1 (cid:80)N p (y ;[θ(n),x ])andθ(n)∼p (θ;h ),see§3.3. Thisesti-
t t−1 t N n=1 LLM t t f t−1
matorhasbeenusedinotherBEDcontexts(Galetal.,2017;Rainforth,2017). Notethatthesamples
donotneedtobeindependentforthisestimatortoconverge,providedtheysatisfysomeappropriate
formofergodicityordecayingcorrelation(see,e.g.,Billingsley(2013)). Whenconstructingthis
4
Preprint
estimator, we compute the p (y ;[θ(n),x ]) terms using the LLM’s logits whenever possible.
LLM t t
By the Rao-Blackwell theorem, this always produces lower variance than purely sample–based
estimators(Raoetal.,1945),likethoseemployedinHuetal.(2024)andKobalczyketal.(2025).
Avoidingdeterministiclikelihoodassumptions Previousattemptstoapplyinformationcriteriato
choosingqueriesinLLMshavegenerallyassumedresponsesaredeterministicgiven(θ,x )(Cooper
t
etal.,2025;Kobalczyketal.,2025;Huetal.,2024;Mazzaccaraetal.,2024;Piriyakulkijetal.,2023).
Underthisassumption,theEIGsimplifiestothemarginalpredictiveentropy,H[p(y ;x ,h )].
t t t−1
Thisisproblematicas,inpractice,theexpectedlikelihoodentropywillvarywithx . Forexample,
t
ifθ =“Dog”,thentheresponsetothequestion“Isitananimal?” shouldbeclosetodeterministic,
but the expected response to the question “Does it have black fur?” clearly is not. In general,
E [H[p(y |θ;x ,h )]] measures how certainly the question can be answered once θ is
p(θ;ht−1) t t t−1
known. Includingitinourobjectiveisessentialinavoidingquestionsthatareirrelevant,ambiguous,
unclear,orsimplyunhelpfulinourquesttolearnaboutθ. Weprovideanillustrativeexampleofthis
in§A.2.1andempiricalevidenceforthisin§6. GiventhatapproximatingtheEIGwithmarginal
predictiveentropydoesnotprovide meaningful computational savings(asitdoesnotreducethe
requirednumberofLLMcalls),weadviseagainstmakingsuchdeterministiclikelihoodassumptions.
3.3 PRIORCONSTRUCTIONANDBELIEFUPDATING
TheSavageaxioms(Savage,1954)tellusthatarationalagentshouldupdateitsbeliefsinaBayesian
manner. However, doing full Bayesian updates to our model as the history grows is generally
impracticalforcomputationalreasonsintheLLMsetting,asitrequiresapproximateinferenceand
this,inturn,typicallyrequireslargenumbersofexpensivelikelihoodevaluations. Furthermore,the
Savageaxiomsonlyholdifour(implied)priortrulyrepresentsourbeliefs,butwefindthatp (θ)
LLM
is typically heavily overconfident on a small number of possible hypotheses and can struggle to
conveythefullrangeofpossibilitiesevenwithcarefulpromptingandahightemperature(c.f. Fig.5).
AnaturaltractablealternativeistoderiveourbeliefsthroughLLMin-contextupdates,thatis,use
p (θ;h ),notingthatthishasbeenshowntobehavedifferentlytoBayesianupdating(Falck
LLM t−1
etal.,2024;Kossenetal.,2024). However,wefindthatevenstate-of-the-artLLMssuchasGPT-
4o (OpenAI, 2024) often fail to incorporate history faithfully; they regularly sample hypotheses
incompatiblewithpastobservationsandexhibitprematureoverconfidence,withbothissuesbecoming
morepronouncedash grows. Wediscussreasonsfortheseshortfallsin§A.3.
t−1
Toavoidtheseshortfalls,weinsteadproposeanapproachthatbalancestractabilityandfaithfulness.
Althoughwewillstillusep (θ;h )asthebasisforderivingourbeliefstateoverθ (i.e.our
LLM t−1
intermediate prior), we make various alterations to effectively incorporate historical information
and ensure diversity. Our derived distribution, which we refer to as p (θ;h ), differs from
f t−1
p (θ;h ) in two key ways. First, we filter the generated hypotheses according to whether
LLM t−1
they are compatible with the history h . We do this by using the LLM to zero-shot check
t−1
the compatibility of each sampled θ with all the previous question–answer pairs in h (using
t−1
p (y ;[θ,x ])∀i = 1 : t − 1) and then rejecting that sample if an incompatibility is found.
LLM i i
Specifically,asampleisrejectedifthelikelihoodofanobservedanswerfallsbelowapredefined
threshold, chosen to balance robustness to model uncertainty against the need to enforce strict
historical coherence. To reduce the computational cost of generating and evaluating hypotheses,
wefurtherincludeahypothesis-retentionmechanism: anyhypothesesfromthepreviousturnwhich
remainconsistentwiththemostrecentquestionandobservationareretainedinthehypothesisset
withoutregeneration. Second,wemakeanumberofmodificationstopromotediversity. Ratherthan
generate candidates independently, we prompt the LLM to generate batches of candidates using
apromptencouragingdiversity. Afterfilteringthesecandidatesasaboveandremovingduplicates,
wethenimposeauniformdistribution. Detailsofourexactsetupforp (θ;h )aregivenin§E.
f t−1
4 ON THE SPECIFICATION OF p(θ,y t ;h t−1 ,x t ), AND ITS IMPLICATIONS
Aswedescribedin§3,successfullyapplyingsequentialBEDintheLLMsettinghingesuponhowwe
specify,andupdate,thejointdistributionp(θ,y ;h ,x ). Inparticular,aspreviouslyhighlighted,
t t−1 t
therearetwodistinctwaystoderivethejointmodelfromourLLM:usingaprior–likelihoodpairing,
p(θ;h )p(y ;[θ,x ]), or a data–estimation pairing, p(y ;[h ,x ])p(θ;[h ,x ,y ]). The
t−1 t t t t−1 t t−1 t t
firstconstructionmirrorsderivingourbeliefsaboutθfromaconventionalBayesianposteriorwith
5
Preprint
aconcretepriorandlikelihoodderived(atleastpartially)fromtheLLM,whereasthesecondhas
analogies to a marginal-posterior approach (Fong et al., 2023; Falck et al., 2024) in that it that
sampleshypotheticaldataanddrawsinferencesonθgivenhypotheticaldatausingin-contextlearning.
InouroutlinedBED-LLMapproach,weadoptedaprior–likelihoodpairing. Below,wejustifythis
decisionandalsodiscusscertainsettingswherethedata–estimationsetupmightbepreferableinstead.
Modelingflexibility Themostobviousrelativemeritsoftheprior–likelihoodanddata–estimation
pairingsareintheflexibilityinhoweachtermischosen. Theprior–likelihoodpairinggivesusgreater
flexibilitytoconstructapriorsetofbeliefsoverθthatisdistincttotheLLM’sinternalbeliefs,asit
allowsustodirectlycontrolthispriorbychangingp(θ;h ),whereasthepriorisonlyimplicitly
t−1
definedinthedata–estimationpairing. In§3.3weexploitedthisflexibilitythroughourdefinitionof
p (θ;h ). Ontheotherhand,thedata–estimationpairingcouldprovidesomebeneficialflexibility
f t−1
inspecifyinghowthedataitselfissimulatedthroughchangingp(y ;[h ,x ]),whichcould,for
t t−1 t
example,beusefulwhenwehaveaccesstoexternaldatasimulators.
Faithfulnessofconditionaldistributions WhiledeviationsfromrelyingondirectLLMpredictions
are also in principle possible for the conditional models p(y ;[θ,x ]) and p(θ;[h ,x ,y ]), in
t t t−1 t t
practice, these will typically be more difficult and expensive to implement. This is first because
theseconditionalsneedtobeinstantiatedforeachsampledinstanceoftheconditionalvariable(θ
andy respectively),ratherthanjustneedingustosetupasinglemarginaldistribution. Second,to
t
constructestimatorsforEquations(1)and(2),werequireaccesstoconcreteprobabilitiesforthe
conditionaldistributions(inordertocalculateentropies),whereasweonlyneededtodrawsamples
forthemarginaldistributions(inordertoapproximateexpectations). Assuch,theconditionalsneed
tobeexplicitdistributions,oratleastoneswheretheprobabilitycanbecheaplyestimated,sotheyare
moredifficulttodefinethroughtheoutputofsomealgorithmicprocedure,especiallyinlargespaces.
Whenconsideringtheconditionaldistributions,thedecisivequestionontherelativemeritofthetwo
formulationsiswhichconditionalfactorwearewillingtotrusttheLLMtosupplyasafullprobability
distribution. Critically, we rely on how the LLM captures uncertainty in this full distribution—
including, for example, tail behavior—not merely the fidelity of typical samples; the marginal
factors, by contrast, only need to be sampled from. If we accept the LLM’s direct predictive
distributionforp(y ;[θ,x ]),thenwearebasingournotionofuncertaintyaround(andwillneedto
t t
calculate)H[p (y ;[θ,x ])],andifinsteadweplacemorefaithintheLLM’sinternaldistribution
LLM t t
forp(θ;[h ,x ,y ]),thenwearebasingouruncertaintyaroundH[p (θ;[h ,x ,y ])].
t−1 t t LLM t−1 t+1 t+1
Inessence,thechoicebetweenprior–likelihoodanddata–estimationpairingsthuscomesdownto
whetherwebelievetheLLMwillproduceamoreappropriateconditionaluncertaintyoverθory,
alongwithourabilitytonumericallyestimatethisuncertaintycheaply.
Thisdifferencebecomesparticularlynoticeablewhenthecomplexitiesofthespacesofθandydiffer
significantly. Ourabilitytodrawsensiblesamplesofeitherwillgenerallybequiterobusttothese
spacesbeingcomplexorhigh–dimensional;thisiswhereLLMstendtothrive,effectivelygenerating
highlycomplexoutputsinanautoregressivemanner.However,evaluatingtheentropyofadistribution
becomesdramaticallyharderasthedimensionalityorcomplexityincreases(Acharyaetal.,2019;
Paninski, 2003), and the entropy of the predictive distribution of an LLM in such cases will not
typicallyprovideasensiblemeasureofuncertainty(Kadavathetal.,2022;Desai&Durrett,2020).
Assuch,thedecisionbetweenjointformulationsshouldpredominantlybebasedonthecomplexity
ofthespaceofθversusthatofy: weshouldgenerallyfavortheprior–likelihoodformulationifθ
ismorecomplexandthedata–estimationformulationifyismorecomplex. Fortheproblems
that we consider, the space of y is less complex than that of θ, indicating we should, in general,
usetheprior–likelihoodformulation. However,incaseswherethisisnottrue,thedata–estimation
formulationmaybepreferableinstead. Weprovideadditionaldiscussionontheimpactofthechosen
pairingonourentropyestimate,plusdiscussiononthechoiceofθ,in§B.
Extractingthebeliefstate Afurtheradvantageoftheprior–likelihoodconstructionisthatourbelief
stateonθcanbeextracteddirectlyasp (θ;h ). Withthedata–estimationconstruction,wewould
f t−1
havetoestimatethemarginalonθbyintegratingp(y ;[h ,x ])p(θ;[h ,x ,y ])overthesyn-
t t−1 t t−1 t t
theticresponsey . Directaccesstop(θ;h )isalsoimportanttoensurethatourcurrentbeliefstate
t t−1
isindependentofthenextquestionx ,whichisbothintuitivelydesirableandtheoreticallyrequired
t
tobeavalidBEDapproach(Lindley,1972);data–estimationformulationswillgenerallyviolatethis.
6
Preprint
5 RELATED WORK
Several works have explored the baseline ability of LLMs to rapidly learn about a parameter of
interestbyaskingquestions(Zhangetal.,2024;Lietal.,2025b)—effectivelyourNaivebaseline
in §6. While these works demonstrate some ability to adaptively construct information-seeking
questions,theyoftenfailtoextractimportantinformation(Lietal.,2025a).
Some works have further specifically attempted to choose questions based on model-based
uncertaintycriteria(Piriyakulkijetal.,2023;Huetal.,2024;Kobalczyketal.,2025;Mazzaccara
etal.,2024;Cooperetal.,2025). Noneoftheseworksprovidethesamecarefulconsiderationofhow
theunderlyingjointmodelshouldbeformulated,whichunderpinsourownwork,andtheyallassume
deterministiclikelihoodmodelsthatmeantheirobjectivescorrespondtoasample-basedestimateof
marginalpredictiveentropyinpractice,asexplainedin§3.2. Ingeneral,thesepreviousworkshave
alsorequiredrestrictionsonthespaceofallowablehypotheses,θ,andtypicallyrequireadditional
assumptionsand/orapproximations. Moreextensivediscussionofrelatedworkisgivenin§C.
6 EXPERIMENTS
WenowassesshowwellBED-LLMandalternativeinformation-gatheringapproachesworkintwo
practicalscenarios: 20Questions,agameinwhichtheplayerhastoguessatargetentityandcanask
upto20yes-noquestionsabouttheentity;andpreferenceelicitation,ataskinwhichtheagenthasto
predictauser’spreferenceprofileandcanaskfivemultiple-choicequestionstotheuser.
Answerer WeproduceanswerstothequestionerLLM’squestionsusingaseparateanswererLLM.
Theanswererisprovidedwithaground-truthθ∗(atargetentityin20Questionsorauserprofileinpref-
erenceelicitation)andprocessesindividualquestionsfromthequestionerwithoutaccesstoanyofthe
questioner’scontext(i.e. h andthequestioner’sprompts). Wetesttwoquestioner-answerersetups,
t−1
wherethetwoareservedbyseparateinstancesofthesameLLM,ortwodifferentLLMs.Thelattersce-
narioisimportantbecauseinpractice,theanswererwilloftenfollowadifferentdistributionthanthe
questioner’sinternalmodelforreasoningaboutresponses,therebyformingamodelmisspecification.
Baselines WecompareBED-LLMagainsttwoexistingbaselinemethods: NaiveandSplit. Naive
involvespromptingthequestionertodirectlygenerateaninformativenextquestion,withoutexplicit
hypothesesgenerationorcomputingadata-acquisitionobjective,andthensamplingthequestionwith
temperatureT=1;thiswasexploredbyZhangetal.(2024). Splitinvolveschoosingthequestion
thatmostequallysplitsasampledsetofhypothesesΘcand,whichcorrespondstomaximizingthe
marginalpredictiveentropyH[p(y ;x ,h )]inamodelwithadeterministiclikelihood. Assuch,
t t t−1
themethodsofCooperetal.(2025), Huetal.(2024), Kobalczyketal.(2025), Mazzaccaraetal.
(2024) and Piriyakulkij et al. (2023) can all be viewed as variants of this Split baseline. While
Splitisnotapplicabletothepreference-elicitationscenario,whereadeterministiclikelihoodisnot
viable,itistoourknowledgethestate-of-the-artmethodfor20Questions. Wenotethatourown
Split baseline implementation achieves dramatically better results than reported by, for example,
Kobalczyketal.(2025),sothisconstitutesaverystrongbaselinerelativetopreviouswork. Ontopof
this,ourimplementationofNaiveappearstosignficantlyimproveoverthatofZhangetal.(2024),
6.1 20QUESTIONS
Weconsiderthreesetsof20Questionsproblems: Animals,Celebrities,andThings(See§F.1). Each
problemsetcomprises100targetentities{θ∗}100 fromagivencategory. Thespaceofpossibleθ
i i=1
islargeandnotexplicitlydefinedorrestricted: wedonottelltheLLMthissetoftargetentities,so
thespaceofθisboundedonlybywhattheLLMcangenerate. Wenotethatbycomparison,many
previousworkshavereliedonrestrictedspacesforθ(Chanetal.,2025;Huetal.,2024;Piriyakulkij
etal.,2023;Wangetal.,2025).
Toevaluateperformance,ateachturnt∈(0,1,...,20)weextractθtfromp (θ ;h )usinggreedy
i f i t
decodingandwecomputethesuccessrateasthemeanacrossiofI(θt = θ∗). Theseevaluation
i i
guessesarenotpartofthequestioneralgorithmitselfandarenotincludedinh . Inlinewiththe
t−1
originalrulesofthegame,wealsointroduceanexplicitmechanismforthequestionertoguessthe
answerasoneofits20questions: ifthesetoffilteredhypothesescollapsestoasinglecandidate,the
questionerasks“Isit⟨item⟩?”. Acorrectguessendsthegame;otherwisethenegativeresponseis
addedtoh andcountedtowardsthebudget. See§Fforfurtherexperimentaldetails.
t−1
7
Preprint
SuccessRate(%)
Dataset Model Naive Split BED-LLM Entropy Data–Est. ICLBeliefs Impl.Max.
GPT-4o-mini 44±5.0 78±4.2 88±3.3 79±4.1 — 18±3.9 47±5.0
GPT-4o 45±5.0 83±3.8 93±2.6 88±3.3 — 25±4.4 70±4.6
Animals
Llama-3.1-8B 8±2.7 49±5.0 63±4.9 54±5.0 38±4.9 25±4.4 16±3.7
Llama-3.3-70B 40±4.9 65±4.8 79±4.1 68±4.7 40±4.9 33±4.7 54±5.0
Qwen2.5-72B 45±5.0 87±3.4 95±2.2 85±3.6 68±4.7 46±5.0 61±4.9
GPT-4o-mini 30±4.6 53±5.0 72±4.5 55±5.0 — 16±3.7 31±4.7
GPT-4o 45±5.0 63±4.9 86±3.5 64±4.8 — 52±5.0 50±5.0
Celebrities
Llama-3.1-8B 10±3.0 35±4.8 58±5.0 36±4.8 19±3.9 24±4.3 19±3.9
Llama-3.3-70B 33±4.7 43±5.0 55±5.0 46±5.0 26±4.4 27±4.5 37±4.9
Qwen2.5-72B 32±4.7 56±5.0 84±3.7 59±4.9 34±4.8 26±4.4 39±4.9
GPT-4o-mini 26±4.4 38±4.9 49±5.0 37±4.9 — 19±4.0 25±4.4
GPT-4o 34±4.8 40±4.9 64±4.8 49±5.0 — 19±3.9 42±5.0
Things
Llama-3.1-8B 10±3.0 12±3.3 26±4.4 15±3.6 9±2.9 11±3.1 10±3.0
Llama-3.3-70B 34±4.8 46±5.0 55±5.0 48±5.0 19±3.9 15±3.6 34±4.8
Qwen2.5-72B 32±4.7 51±5.0 62±4.9 51±5.0 39±4.9 24±4.3 40±4.9
Table1: Successrate(%)for20Questionsattheendofthegame. Bestresultinbold. ±numbers
(cid:112)
show the standard error of the mean estimated using p(1−p)/(n−1) where p is the success
percentageandnisthenumberofdatapoints.Thisestimatorispositivelybiasedandthusconservative.
Data–Est.isnotpossibletorunforGPTmodelsduetolimitedlogprobssupportinOpenAIAPI.
100
0
%sseccuS slaminAno
Q:GPT-4o-mini Q:Qwen2.5-72B
GPT-4o-mini GPT-4o Llama-3.3-70B Qwen2.5-72B A:Qwen2.5-72B A:GPT-4o-mini
100 90 100 90 90
0 0 0 0 0
90
0
%sseccuS
seitirbeleCno 100 70 100 70 70
0 0 0 0 0
60
0
0 20
Turnt
%sseccuS sgnihTno
80 70 80 60 60
0 0 0 0 0
0 20 0 20 0 20 0 20 0 20
Turnt Turnt Turnt Turnt Turnt
Naive Split BED-LLM Entropy
Figure1: Successrateon20Questions: mean±standarderroracross100targetsperdataset.
BED-LLMimprovesoverNaiveandSplitbaselines OurresultsinTab.1andFig.1showBED-
LLMsignificantlyoutperformingNaiveandSplitacrossallproblemsandLLMs. Particularlynotable
isthatBED-LLM’sfinalsuccessrateistypicallymorethandoublethatofNaive,highlightingthebig
gainsthatcanbeachievedbyusingexplicitEIGmaximisationinsteadofimplicitLLMreasoning.
BED-LLMablations InordertounderstandtheimportanceofBED-LLM’salgorithmiccompo-
nents,wefurtherevaluatefourablationsonthisproblem: Entropy,Data–Estimation,ICLBeliefs
andImplicitMaximization. EachofthesediffersfromBED-LLMwithrespecttoonealgorithmic
component. EntropyreplacestheEIGdata-acquisitionobjectivewiththemarginalpredictiveentropy
H[p(y ;x ,h )](§3.2);thiscontrastswithSplitinthatitusesp (y ;[θ,x ])ratherthana
t t t−1 LLM t+1 t+1
deterministiclikelihood.ImplicitMaximizationinvolvessamplingcandidatequestionsandprompting
thequestionertoselectthemostinformativeone,withoutanyexplicitobjectiveestimation(§3.2).
ICLBeliefsusesθbeliefupdatesderivedfromsimplein-contextlearning,namelyp (θ;h )
LLM t−1
insteadofp (θ;h ),testingtheimportanceofourfilteringmechanism(§3.3). Data–Estimation
f t−1
usesadata–estimationpairingratherthanBED-LLM’sprior–likelihoodsetup(see§D).InTab.1we
seethatBED-LLMcomfortablyoutperformsallalternativeapproaches. Notably,Entropyprovides
8
Preprint
4.5
4.0
3.5
0 5
Turnt
gnitaRnaeM
Q:GPT-4o-mini Q:Qwen2.5-72B
GPT-4o-mini GPT-4o Llama-3.3-70B Qwen2.5-72B A:Qwen2.5-72B A:GPT-4o-mini
4.5 4.5
4.0 4.0 4.0
4.0
3.5 4.0 3.5 3.5
0 5 0 5 0 5 0 5 0 5
Turnt Turnt Turnt Turnt Turnt
Naive BED-LLM Entropy
Figure2: Meanratingacross10filmrecommendations: mean±standarderroracross200users.
thestrongestablationbaseline,withperformancealmostidentical(sometimessuperior)toSplit. This
showsthattheuseofanon-deterministiclikelihoodisbeneficialinallowingustotargetaproper
EIG,ratherthanbecauseitisparticularlydetrimentaltothemarginalpredictiveentropyitself.
Prior–likelihood outperforms data–estimation Our analysis in §4 is validated by our results:
BED-LLM’sprior-likelihoodapproachsubstantiallyoutperformsData–Estimation. Data–Estimation
stilloutperformsNaive,butinterestinglyitperformsworsethanEntropy,highlightingtheimportance
ofestimatinguncertaintyintheyspaceinsteadofθspace. Thesefindingsreinforceourclaimthat
thechoiceofjoint-modelfactorizationisacriticalalgorithmicdecision.
RejectionsamplingandexplicitEIGmaximizationarekey Wealsoseetheimportanceoftwo
otheraspectsofBED-LLM.First,howweproduceourbeliefsoverθmatters: derivingbeliefsusing
simplein-contextlearning,asinICLBeliefs,leadtomassiveperformancedrops. Second,while
BED-LLM’sroutinesforsamplingcandidatequestionsandhypothesesarecrucial,theyalonearenot
sufficient: passingthesamplestoanLLMandpromptingittoselectthehighest-EIGquestion,asin
ImplicitMaximization,worksmuchlesswellthanusingthesamplestoexplicitlymaximizeEIG.
BED-LLMisrobusttoquestioner–answerermismatch OurresultsinFig.1demonstratethatthe
benefitofBED-LLMpersistsevenundermodelmisspecification. Thisisimportantforapplicability
toreal-worldusers,whoseresponseswillfollowadifferentdistributionthanthequestionerLLM.
6.2 PREFERENCEELICITATION
Unlike20Questions,inwhichθisaconcreteentityandmostreasonablequestionshaveclearanswers,
manyreal-worldinformation-gatheringtasksinvolvemoreabstracttargetsandlesspredictabledata
generation. Akeyexampleislearninguserpreferences,whereitmaybedifficulttoexplicitlydefine
aconcreteclosedsetofpossibleθ,anditisalsochallengingfortheLLMtodevelopappropriate
uncertainty estimates. To study such a scenario, we evaluate BED-LLM on inferring users’ film
preferences. Herethetargetwearetryingtogatherinformationaboutissomewhatabstract,andwe
havesomeflexibilityinhowwedefineθinourjointmodel. Ourchosensetupistodefineθtobe
auserprofile,namelyaparagraphoftextdescribingtheuser’sfilmpreferences,withouranswerer
modelpromptedtoemulateauserwithagivenprofile; see§Gforfulldetails. Weconsider200
differentuserprofilesasthegroundtruthθ∗,butaswith20Questionsthissetisnevergiventothe
questioner. BecauseSplitisnotapplicableasabaselinehere(adeterministiclikelihoodassumption
isclearlyunreasonable),webenchmarkwiththesimilarEntropyapproachinstead. Wealsonotethat
data–estimationsetupiscompletelyunviablehereaswellbecauseofthelargeθspace.
Ateachturnt∈(0,1,...,5)weusethequestion-answerhistoryascontextforgeneratingalistof
tenfilmrecommendations. ThislististhenratedinitsfittotheuserprofileusinganLLM-as-judge
setup(Trivedietal.,2024;Zhuetal.,2025). Specifically,theanswererscoreseachfilmonascaleof
1to5(in0.5increments),basedonhowwellthefilmalignswithθ∗;thisscoreisoutputtogether
withabriefjustificationtoincreasereliability. Thefilms’scoresarenotincludedinh .
t−1
OurresultsinFig.2showthat,whileNaiveisoftenastrongbaselineinthispreference-elicitation
scenario,BED-LLMisstillabletoprovideaboostoverbothNaiveandEntropy,producinghigher-
ratedfilmrecommendations. BED-LLM’sbenefitismostclearinscenarioswherethequestioner
belongstoadifferentmodelclasstotheanswerer: hereNaive’sperformanceismuchlessconvincing.
9
Preprint
7 CONCLUSION
Inthiswork,wehaveshownhowtoeffectivelyapplytheframeworkofsequentialBayesianexperimen-
taldesign(BED)totheproblemofinteractiveinformationgatheringwithLLMs.Specifically,wehave
introducedBED-LLM,whichprovidesaspecific,information–theoretic,sequentialBEDapproach
thatmakesavarietyofcarefullyjustifieddesignchoicesinthejoint-modelfactorization,beliefupdat-
ing,andEIGestimation.ParticularlycentraltoBED-LLMistheprior–likelihoodpairingwithfiltering
ofhypothesesforconsistencywiththehistory. BED-LLMisnotablythefirstworkthatusesboththis
prior–likelihoodpairingwithoutmakingadeterministiclikelihoodassumptionthatcausestheEIGto
simplytojustmarginalpredictiveentropy.Together,theseinnovationsleadtosubstantialperformance
improvementscomparedtopreviousapproaches. TheresultsthusconfirmthatprincipledEIG–driven
strategiescanyieldsubstantialgainsforinteractive,multi-turn,informationgatheringproblems.
10
Preprint
REFERENCES
JayadevAcharya,SourbhBhadane,PiotrIndyk,andZitengSun. Estimatingentropyofdistributions
inconstantspace. InAdvancesinNeuralInformationProcessingSystems,2019.
GatiVAher,RosaIArriaga,andAdamTaumanKalai. Usinglargelanguagemodelstosimulate
multiplehumansandreplicatehumansubjectstudies. InInternationalConferenceonMachine
Learning,2023.
ChinmayaAndukuri,Jan-PhilippFränken,TobiasGerstenberg,andNoahDGoodman. Star-gate:
Teaching language models to ask clarifying questions. In Conference on Language Modeling,
2024.
Leonardo Bertolazzi, Davide Mazzaccara, Filippo Merlo, and Raffaella Bernardi. ChatGPT’s
information seeking strategy: Insights from the 20-questions game. In International Natural
LanguageGenerationConference,2023.
FreddieBickfordSmith, AndreasKirsch, SebastianFarquhar, YarinGal, AdamFoster, andTom
Rainforth. Prediction-orientedBayesianactivelearning. InInternationalConferenceonArtificial
IntelligenceandStatistics,pp.7331–7348,2023.
FreddieBickfordSmith,JannikKossen,EleanorTrollope,MarkvanderWilk,AdamFoster,and
TomRainforth. Rethinkingaleatoricandepistemicuncertainty. InInternationalConferenceon
MachineLearning,2025. URLhttps://openreview.net/forum?id=CY9MlORQs5.
PatrickBillingsley. Convergenceofprobabilitymeasures. JohnWiley&Sons,2013.
TomBlau,EdwinVBonilla,IadineChades,andAmirDezfouli. Optimizingsequentialexperimental
designwithdeepreinforcementlearning. InInternationalConferenceonMachineLearning,2022.
Brown,Mann,Ryder,Subbiah,Kaplan,Dhariwal,Neelakantan,Shyam,Sastry,Askell,Agarwal,
Herbert-Voss,Krueger,Henighan,Child,Ramesh,Ziegler,Wu,Winter,Hesse,Chen,Sigler,Litwin,
Gray,Chess,Clark,Berner,McCandlish,Radford,Sutskever,andAmodei. Languagemodelsare
few-shotlearners. InAdvancesinNeuralInformationProcessingSystems,2020.
DanielRCavagnaro,JayIMyung,MarkAPitt,andJanneVKujala. Adaptivedesignoptimization:
A mutual information-based approach to model discrimination in cognitive science. Neural
computation,22(4):887–905,2010.
SouradipChakraborty,JiahaoQiu,HuiYuan,AlecKoppel,FurongHuang,DineshManocha,Am-
ritSinghBedi,andMengdiWang. Maxmin-rlhf: Alignmentwithdiversehumanpreferences. In
InternationalConferenceonMachineLearning,2024.
Kathryn Chaloner and Isabella Verdinelli. Bayesian experimental design: A review. Statistical
Science,pp.273–304,1995.
KwanHoRyanChan,YuyanGe,EdgarDobriban,HamedHassani,andRenéVidal. Conformalinfor-
mationpursuitforinteractivelyguidinglargelanguagemodels. arXivpreprintarXiv:2507.03279,
2025.
YizhouChi,JessyLin,KevinLin,andDanKlein. Clarinet: Augmentinglanguagemodelstoask
clarificationquestionsforretrieval. arXivpreprintarXiv:2405.15784,2024.
Michael Cooper, Rohan Wadhawan, John Michael Giorgi, Chenhao Tan, and Davis Liang. The
curious language model: Strategic test-time information acquisition. In Second Workshop on
Test-Time Adaptation: Putting Updates to the Test! at ICML 2025, 2025. URL https://
openreview.net/forum?id=1Bfo9L5ayn.
ShreyDesaiandGregDurrett. Calibrationofpre-trainedtransformers. InBonnieWebber,Trevor
Cohn,YulanHe,andYangLiu(eds.),ConferenceonEmpiricalMethodsinNaturalLanguage
Processing, pp. 295–302, Online, November 2020. Association for Computational Linguis-
tics. doi: 10.18653/v1/2020.emnlp-main.21. URLhttps://aclanthology.org/2020.
emnlp-main.21/.
11
Preprint
Fabian Falck, Ziyu Wang, and Chris Holmes. Is in-context learning in large language models
Bayesian? Amartingaleperspective. InInternationalConferenceonMachineLearning,2024.
EdwinFong,ChrisHolmes,andStephenGWalker. Martingaleposteriordistributions. Journalofthe
RoyalStatisticalSocietySeriesB:StatisticalMethodology,85(5):1357–1391,2023.
Adam Foster. Variational, Monte Carlo and policy-based approaches to Bayesian experimental
design. PhDthesis,UniversityofOxford,2021.
AdamFoster,DesiRIvanova,IlyasMalik,andTomRainforth. Deepadaptivedesign: Amortizing
sequentialBayesianexperimentaldesign. InInternationalConferenceonMachineLearning,pp.
3384–3395,2021.
YarinGal,RiashatIslam,andZoubinGhahramani. DeepBayesianactivelearningwithimagedata.
InInternationalConferenceonMachineLearning,pp.1183–1192,2017.
KunalHanda,YarinGal,ElliePavlick,NoahGoodman,JacobAndreas,AlexTamkin,andBelindaZ.
Li. Bayesianpreferenceelicitationwithlanguagemodels. arXivpreprintarXiv:2403.05534,2024.
F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. Acm
TransactionsonInteractiveIntelligentSystems,5(4):1–19,2015.
Marcel Hedman, Desi R. Ivanova, Cong Guan, and Tom Rainforth. Step-DAD: Semi-amortized
policy-basedBayesianexperimentaldesign. InInternationalConferenceonMachineLearning,
2025. URLhttps://openreview.net/forum?id=JRg8P2bX8P.
Takanobu Hirosawa, Yukinori Harada, Kazuya Mizuta, Tetsu Sakamoto, Kazuki Tokumasu, and
TaroShimizu. Evaluatingchatgpt-4’saccuracyinidentifyingfinaldiagnoseswithindifferential
diagnosescomparedwiththoseofphysicians:Experimentalstudyfordiagnosticcases. JMIRForm
Res,8:e59267,Jun2024. ISSN2561-326X. doi: 10.2196/59267. URLhttps://formative.
jmir.org/2024/1/e59267.
ZhiyuanHu,ChuminLiu,XidongFeng,YilunZhao,See-KiongNg,AnhTuanLuu,JunxianHe,
PangWeiKoh,andBryanHooi. Uncertaintyofthoughts: Uncertainty-awareplanningenhances
informationseekinginlargelanguagemodels. InAdvancesinNeuralInformationProcessing
Systems,2024.
XunHuanandYoussefMMarzouk. SequentialBayesianoptimalexperimentaldesignviaapproxi-
matedynamicprogramming. arXivpreprintarXiv:1604.08320,2016.
DesiRIvanova,AdamFoster,StevenKleinegesse,MichaelUGutmann,andTomRainforth. Implicit
deepadaptivedesign:policy-basedexperimentaldesignwithoutlikelihoods.InAdvancesinNeural
InformationProcessingSystems,2021.
Rune Møberg Jacobsen, Samuel Rhys Cox, Carla F. Griggio, and Niels van Berkel. Chatbots
for data collection in surveys: A comparison of four theory-based interview probes. In CHI
ConferenceonHumanFactorsinComputingSystems,CHI’25,pp.1–21.ACM,April2025. doi:
10.1145/3706598.3714128. URLhttp://dx.doi.org/10.1145/3706598.3714128.
SaurabhJha,RohanArora,YujiWatanabe,TakumiYanagawa,YinfangChen,JacksonClark,Bhavya
Bhavya,MuditVerma,HarshitKumar,HirokuniKitahara,NoahZheutlin,SakiTakano,Divya
Pathak, Felix George, Xinbo Wu, Bekir O. Turkkan, Gerard Vanloo, Michael Nidd, Ting Dai,
OishikChatterjee,PranjalGupta,SuranjanaSamanta,PoojaAggarwal,RongLee,Pavankumar
Murali,JaewookAhn,DebanjanaKar,AmeetRahane,CarlosFonseca,AmitParadkar,YuDeng,
PratibhaMoogi, PrateetiMohapatra, NaokiAbe, ChandrasekharNarayanaswami, TianyinXu,
LavR.Varshney,RuchiMahindru,AncaSailer,LauraShwartz,DabySow,NicholasC.M.Fuller,
andRuchirPuri. Itbench: Evaluatingaiagentsacrossdiversereal-worlditautomationtasks. In
InternationalConferenceonMachineLearning,2025.
SauravKadavath,TomConerly,AmandaAskell,TomHenighan,DawnDrain,EthanPerez,Nicholas
Schiefer,ZacHatfield-Dodds,NovaDasSarma,EliTran-Johnson,ScottJohnston,SheerEl-Showk,
AndyJones,NelsonElhage,TristanHume,AnnaChen,YuntaoBai,SamBowman,StanislavFort,
DeepGanguli,DannyHernandez,JoshJacobson,JacksonKernion,ShaunaKravec,LianeLovitt,
12
Preprint
KamalNdousse,CatherineOlsson,SamRinger,DarioAmodei,TomBrown,JackClark,Nicholas
Joseph,BenMann,SamMcCandlish,ChrisOlah,andJaredKaplan. Languagemodels(mostly)
knowwhattheyknow. arXivpreprintarXiv:2207.05221,2022.
Greg Kestin, Kelly Miller, Anna Klales, Timothy Milbourne, and Gregorio Ponti. Ai tutoring
outperforms in-class active learning: an rct introducing a novel research-based design in an
authenticeducationalsetting. ScientificReports,15(1):17458,2025.
Katarzyna Kobalczyk, Nicolas Astorga, Tennison Liu, and Mihaela van der Schaar. Active task
disambiguationwithllms. InInternationalConferenceonLearningRepresentations,2025.
JannikKossen,YarinGal,andTomRainforth. In-contextlearninglearnslabelrelationshipsbutis
notconventionallearning. InTheTwelfthInternationalConferenceonLearningRepresentations,
2024. URLhttps://openreview.net/forum?id=YPIA7bgd5y.
PhilippeLaban,HiroakiHayashi,YingboZhou,andJenniferNeville. Llmsgetlostinmulti-turn
conversation. arXivpreprintarXiv:2505.06120,2025.
SangukLee,Tai-QuanPeng,MatthewHGoldberg,SethARosenthal,JohnEKotcher,EdwardW
Maibach,andAnthonyLeiserowitz. Canlargelanguagemodelsestimatepublicopinionabout
globalwarming? anempiricalassessmentofalgorithmicfidelityandbias. PLoSClimate,3(8):
e0000429,2024.
Belinda Z Li, Been Kim, and Zi Wang. Questbench: Can llms ask the right question to acquire
informationinreasoningtasks? arXivpreprintarXiv:2503.22674,2025a.
BelindaZ.Li,AlexTamkin,NoahGoodman,andJacobAndreas. Elicitinghumanpreferenceswith
languagemodels. InTheThirteenthInternationalConferenceonLearningRepresentations,2025b.
URLhttps://openreview.net/forum?id=LvDwwAgMEW.
Yubo Li, Xiaobin Shen, Xinyu Yao, Xueying Ding, Yidi Miao, Ramayya Krishnan, and Rema
Padman. Beyondsingle-turn: Asurveyonmulti-turninteractionswithlargelanguagemodels.
arXivpreprintarXiv:2504.04717,2025c.
Lindley. BayesianStatistics: aReview. SocietyforIndustrialandAppliedMathematics,1972.
Dennis V Lindley. On a measure of the information provided by an experiment. The Annals of
MathematicalStatistics,27(4):986–1005,1956.
JiayuLiu,ZhenyaHuang,TongXiao,JingSha,JinzeWu,QiLiu,ShijinWang,andEnhongChen.
Socraticlm: Exploringsocraticpersonalizedteachingwithlargelanguagemodels. Advancesin
NeuralInformationProcessingSystems,37:85693–85721,2024a.
NelsonFLiu,KevinLin,JohnHewitt,AshwinParanjape,MicheleBevilacqua,FabioPetroni,and
PercyLiang. Lostinthemiddle: Howlanguagemodelsuselongcontexts. Transactionsofthe
AssociationforComputationalLinguistics,12,2024b.
ChrisLu,CongLu,RobertTjarkoLange,JakobFoerster,JeffClune,andDavidHa. Theaiscientist:
Towardsfullyautomatedopen-endedscientificdiscovery. arXivpreprintarXiv:2408.06292,2024.
DavidJCMacKay. Information-basedobjectivefunctionsforactivedataselection. Neuralcomputa-
tion,4(4):590–604,1992.
IndrajeetMandal,JitendraSoni,MohdZaki,MortenM.Smedskjaer,KatrinWondraczek,LotharWon-
draczek,NityaNandGosvami,andN.M.AnoopKrishnan. Autonomousmicroscopyexperiments
throughlargelanguagemodelagents. arXivpreprint: arXiv2501.10385,2025.
DavideMazzaccara,AlbertoTestoni,andRaffaellaBernardi. Learningtoaskinformativequestions:
Enhancingllmswithpreferenceoptimizationandexpectedinformationgain. InFindingsofthe
AssociationforComputationalLinguistics: EMNLP,2024.
SewonMin,XinxiLyu,AriHoltzman,MikelArtetxe,MikeLewis,HannanehHajishirzi,andLuke
Zettlemoyer. Rethinkingtheroleofdemonstrations: Whatmakesin-contextlearningwork? arXiv
preprintarXiv:2202.12837,2022.
13
Preprint
WillieNeiswanger,KeAlexanderWang,andStefanoErmon. Bayesianalgorithmexecution: Esti-
matingcomputablepropertiesofblack-boxfunctionsusingmutualinformation. InInternational
ConferenceonMachineLearning,pp.8005–8015,2021.
OpenAI. Gpt-4osystemcard. arXivpreprintarXiv:2410.21276,2024.
OpenAI. OpenAI o3 and o4-mini system card. System card, OpenAI, April 2025. URL
https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/
o3-and-o4-mini-system-card.pdf. Accessed2025-07-15.
LongOuyang,JeffreyWu,XuJiang,DiogoAlmeida,CarrollWainwright,PamelaMishkin,Chong
Zhang,SandhiniAgarwal,KatarinaSlama,AlexRay,etal. Traininglanguagemodelstofollow
instructions with human feedback. Advances in Neural Information Processing Systems, 35:
27730–27744,2022.
LiamPaninski.Estimationofentropyandmutualinformation.Neuralcomputation,15(6):1191–1253,
2003.
Shishir G Patil, Huanzhi Mao, Fanjia Yan, Charlie Cheng-Jie Ji, Vishnu Suresh, Ion Stoica, and
JosephE.Gonzalez. Theberkeleyfunctioncallingleaderboard(BFCL):Fromtoolusetoagentic
evaluationoflargelanguagemodels. InInternationalConferenceonMachineLearning,2025.
URLhttps://openreview.net/forum?id=2GmDdhBdDk.
WasuTopPiriyakulkij,VolodymyrKuleshov,andKevinEllis. Activepreferenceinferenceusing
languagemodelsandprobabilisticreasoning. arXivpreprintarXiv:2312.12009,2023.
TomRainforth. Automatinginference,learning,anddesignusingprobabilisticprogramming. PhD
thesis,UniversityofOxford,2017.
Tom Rainforth, Adam Foster, Desi R Ivanova, and Freddie Bickford Smith. Modern Bayesian
experimentaldesign. StatisticalScience,39(1):100–114,2024.
CRadhakrishnaRaoetal. Informationandtheaccuracyattainableintheestimationofstatistical
parameters. Bull.CalcuttaMath.Soc,37(3):81–91,1945.
LeonardJSavage. Thefoundationsofstatistics. JohnWiley&Sons,1954.
PaolaSebastianiandHenryPWynn. MaximumentropysamplingandoptimalBayesianexperimental
design. JournaloftheRoyalStatisticalSociety:SeriesB(StatisticalMethodology),62(1):145–157,
2000.
PraptiTrivedi,AdityaGulati,OliverMolenschot,MeghanaArakkalRajeev,RajkumarRamamurthy,
KeithStevens,TanveeshSinghChaudhery,JahnaviJambholkar,JamesZou,andNazneenRajani.
Self-rationalizationimprovesllmasafine-grainedjudge. arXivpreprintarXiv:2410.05495,2024.
JimmyWang, ThomasZollo, RichardZemel, andHongseokNamkoong. Adaptiveelicitationof
latentinformationusingnaturallanguage. arXivpreprintarXiv:2504.04204,2025.
ShirleyWu,MichelGalley,BaolinPeng,HaoCheng,GavinLi,YaoDou,WeixinCai,JamesZou,
JureLeskovec,andJianfengGao. Collabllm: Frompassiveresponderstoactivecollaborators. In
InternationalConferenceonMachineLearning,2025.
YizheZhang,JiaruiLu,andNavdeepJaitly. Probingthemulti-turnplanningcapabilitiesofllmsvia
20questiongames. InProceedingsoftheAssociationforComputationalLinguistics,2024.
YueZhang,YafuLi,LeyangCui,DengCai,LemaoLiu,TingchenFu,XintingHuang,EnboZhao,
YuZhang,YulongChen,etal. Siren’ssongintheaiocean: asurveyonhallucinationinlarge
languagemodels. ACMTransactionsonInformationSystems,42(2),2025.
LianghuiZhu,XinggangWang,andXinlongWang. Judgelm: Fine-tunedlargelanguagemodelsare
scalablejudges. InInternationalConferenceonLearningRepresentations,2025.
14
Preprint
APPENDIX CONTENTS
A Algorithmicconsiderations 16
A.1 Updatingthelikelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
A.2 EstimatingEIGforeachquestion . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
A.2.1 PredictiveentropyisnotagoodapproximationforEIG . . . . . . . . . . . 16
A.2.2 EIGestimator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
A.3 Priorconstructionandbeliefupdating . . . . . . . . . . . . . . . . . . . . . . . . 17
B Additionaldiscussionsondesignchoices 17
B.1 Analternativeviewonthefaithfulnessofconditionaldistributions . . . . . . . . . 17
B.2 Choiceofθ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
B.3 AlignmentbetweenEIGandbeliefupdatingprocedure . . . . . . . . . . . . . . . 18
C Extendedrelatedwork 19
D Data–estimationmethod 20
D.1 EIGEstimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
D.2 Generatingcandidatehypotheses . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
E GeneratingcandidatehypothesesforBED-LLM 22
F Experimentdetailsfor20Questions 23
F.1 Problemsets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
F.2 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
F.3 Algorithmicdetails . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
G Experimentdetailsforpreferenceelicitation 24
G.1 Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
G.2 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
G.3 Algorithmicdetails . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
15
Preprint
A ALGORITHMIC CONSIDERATIONS
A.1 UPDATINGTHELIKELIHOOD
ThesuccessofBED-LLMhingesonourabilitytoupdateourjointdistribution. Asmentionedin§3,
wechoosenottoupdatethelikelihoodmodelasmoredataisgathered,thatis,ourlikelihoodinthe
sequentialsettingwillbep (y ;[θ,x ])insteadofp (y ;[h ,θ,x ]). Themainratio-
LLM t t LLM t+1 t−1 t+1
naleofthischoiceisthatformanyproblemsourbeliefsonθcapturealltherequiredinformationto
predicty|x,henceincludingthehistoryisaddingunnecessarycontextthatcouldinfluencetheLLM’s
behavior in undesirable ways. However, it is important to note that p (y ;[h ,θ,x ])
LLM t+1 t−1 t+1
shouldbeusedinsteadforproblemswhereθ willnotcaptureallinformationfrompreviousdata,
e.g.ifθisabinaryvaluecorrespondingtowhetherwerejectanullhypothesis,oristheanswertoa
particularotherquestionofinterest.
A.2 ESTIMATINGEIGFOREACHQUESTION
Question1 Question2
Question: Question:
Whichicecreamflavorfeelslikethebestmatchfor Whichfilmgenredoestheusermostprefer?
thisuser?
Chooseoneoption: Chooseoneoption:
A. Vanilla A. Action
B. DarkChocolate B. Sci-Fi
C. StrawberrySwirl C. Comedy
D. MintChocolateChip D. Horror
PredictiveEntropy:VeryHigh PredictiveEntropy:High
EIG:0 EIG:High
Figure3: Predictiveentropyvs.expectedinformationgain(EIG)inafilm-preferenceselicitation
task. Left: veryhighpredictiveentropy(answeriscompletelyunknown)butEIG=0becausethe
answerprovidesnoinsightintotheuser’sfilmpreferences. Right: bothpredictiveentropyandEIG
arehighastheanswerisuncertain,butdifferentanswerswouldleadtomarkedlydifferentposterior
updates,makingitinformativeforlearningfilmpreferences. Thisthusdemonstrateshowthetwo
criteriacanselectdifferentquestions.
A.2.1 PREDICTIVEENTROPYISNOTAGOODAPPROXIMATIONFOREIG
Asdiscussedin§3.2,previousinformation-basedqueryselectionmechanismshaveassumedthat
responsesaredeterministicgivenθandx. Thisimpliesthattheexpectedentropyofthelikelihood,
E [H[p(y |θ;x ,h )]], is constant over designs, meaning that maximizing EIG is
p(θ;ht−1) t+1 t+1 t−1
equivalenttomaximizingthemarginalpredictiveentropy,H[E [p(y |θ;x ,h )]].
p(θ;ht−1) t t t−1
In practice, the expected likelihood entropy can and will vary across designs. This variability in
theexpectedlikelihoodentropycanbecrucialinselectinggooddesigns. Here,wewalkthrougha
concreteexamplewherepredictiveentropymightdiffersignificantlyfromEIG.
Fig.3showstwocandidatequestionsthatcouldbeaskedtoelicitfilmpreference. Question1has
highpredictiveentropy: inarandomlyselectedgroupofpeople,wewouldexpecthighvariation
inicecreampreference(regardlessoftheindividual’sfilmpreferences). However,sinceicecream
preferenceisunrelatedtofilmpreference,theanswerwouldnothelpusnarrowdownourhypothesis
space,andtheEIGiszero.
Thisisalsosupportedbyevidenceinourexperiments(§6). BoththeSplitbaseline,andtheEntropy
ablation,assumeadeterministiclikelihood;inparticular,theEntropyablationusesthesameestimator
ofthepredictiveentropyasBED-LLM.Inbothcases,weseetheperformancesignificantlydegrades
relativetousingthefullEIG.Further,omittingtheexpectedlikelihoodentropytermprovidesno
meaningfulcomputationalsaving—thesameLLMevaluationsareusedforthetopandbottomlines
ofEq.3,hencedoingthefullestimateoftheEIGrequiresnoadditionalLLMcallstobemade.
16
Preprint
A.2.2 EIGESTIMATOR
One might be tempted to replace pˆ(y ;[h ,x ]) with p (y ;[h ,x ]) in the EIG
t+1 t−1 t+1 LLM t+1 t−1 t+1
estimationinEq.3,asthetwoessentiallyofferalternativepredictivedistributionsfortheoutcome.
Wealsoadviseagainstthisthough,notingthatitagainprovidesnomeaningfulcomputationalbenefits
(unlessonealsoassumesadeterministiclikelihood,butthiswouldthenmeanwenolongerconsider
θatall). Akeyreasonforavoidingthissubstitutionisthatitwouldmeanwearenolongerestimating
atrueEIG:theinconsistencybetweenthelikelihoodandthemarginaldatadistributionmeansthereis
nolongerajointmodelwhereweareminimisingourexpecteduncertaintyinθ. Wealsofindthatthe
LLMprocessofsamplingθfromp (θ;h )followedbyyfromp (y ;[θ,x ])tendstogivea
f t−1 LLM t t
betteruncertaintyoverresponsesthansamplingydirectlyfromp (y ;[h ,x ]).
LLM t+1 t−1 t+1
A.3 PRIORCONSTRUCTIONANDBELIEFUPDATING
In§3.3,wearguedthatnaivein-contextupdatingisnotsufficientforupdatingourbeliefs: Wefailto
fullyincorporatetheinformationfromthehistoryh ,andweoftenhaveoverconfidentdistributions.
t
Theshortfallsofin-contextlearninginsuchsettingshavealsopreviouslybenotedby,forexample,
(Liuetal.,2024b;Zhangetal.,2025;2024). Weposittworeasonswhytheylikelystruggleinsuch
settings. First,theinformationfromthedifferentexamplesinthehistoryaregenerallyhighlydistinct
intheseinformation-gatheringsettings(indeed,thisispartofouraiminadaptivelydesigninformative
questions),makingitharderfortheLLMtoappropriatelyreconcilealltheprovidedinformationthan
inmanyotherusesofin–contextlearning. Second,θwilloftenrepresentauser–specificvariable
thatcannoteasilybepredictedfromanydataotherthantheuser’sresponsestoquestions: ithas
beenarguedthatmuchofthesuccessofin–contextlearninginLLMsisdowntoimprovingproblem
specificationandlinkingtherequestedtasktodataithasseeninitstraining,ratherthantruly“learning”
fromtheprovidedexamples(Minetal.,2022;Kossenetal.,2024),butthehistoryinoursettingis
rarelyhelpfulforthisduetoitsuser–specificnature.
B ADDITIONAL DISCUSSIONS ON DESIGN CHOICES
B.1 ANALTERNATIVEVIEWONTHEFAITHFULNESSOFCONDITIONALDISTRIBUTIONS
Anotherwayofviewingthedistinctionbetweentheprior–likelihoodanddata–estimationconstruc-
tionsisinwhichoftheEIGforms,Eq.1orEq.2,wecenterourreasoning. Foragivenjointmodel,
thetwoare,ofcourse,mathematicallyequivalent. However,theygiveusdifferentwaysofthinking
aboutwhatitmeanstomaximizetheEIG:reducingentropyinθfromseeingy,orreducingentropy
inyfromseeingθ. This,inturn,givesusawaytoreasonabouthowappropriateourjointmodelis.
Whenwechoosetouseoneofp(y ;[θ,x ])orp(θ;[h ,x ,y ]),wearecenteringourreasoning
t t t−1 t t
aroundtheentropyofthisquantitymakingsense,whileallowingtheotherentropyintheotherform
tobeimplicitlydefinedfromtheresultingjointdistribution;becausethetwoformsareequivalent,
weknowthatifour explicitformissuitable/unsuitable, theimplicitform willbeaswell. If, for
example,wedirectlyfixtheformofp(θ;[h ,x ,y ])usingourLLM’spredictivedistribution,we
t−1 t t
arealsodirectlyrelyingonitsexpectedentropybeingameaningfulmeasureofdesignquality. Ifθ
ishigh–dimensionalandpredominantlyfree–form,theresultingentropyproducedbytheLLMis
unlikelytobemeaningfulandusingthedata–estimationpairingisunlikelytoproduceaneffective
strategy. However, if y is instead quite constrained, the LLM can produce a meaningful entropy
overit,andchoosingamodelbasedontheprior–likelihoodpairingislikelytoimplicitlydefinea
meaningfuldistribution,andthusentropy,onθ. Conversely,ifθisconstrainedandyisfreeform,the
oppositewillholdinstead.
B.2 CHOICEOFθ
Animportantcorollaryofthisreasoningisthatitcanbeimportanttobecarefulinourchoiceof
exactlywhatwetakeθtobe,especiallyifweareusingthedata–estimationformulation. Inparticular,
itisessentialforentropyinthespaceofθtoformameaningfulnotionofuncertainty,evenifthis
entropyisnotbeingmeasuredthroughtheLLM’spredictivedistributionofθdirectly. Thus,while
θ inherentlyrepresentswhatwearetryingtolearnaboutandshouldalwaysbesetupassuch, if
thereisflexibilityinhowexactlyweformulateit,weshouldbecarefultochooseaformthatyields
17
Preprint
anappropriateuncertaintymeasure. Forexample,iftheLLMistryingtoclarifywhatcodeauser
wishesittogenerate,wecouldeitherchooseθtobethecodeitselfor,following(Neiswangeretal.,
2021;BickfordSmithetal.,2023),theoutputthecodeproduces. Heretheentropyovercodeoutputs
inducedbyourdistributiononcodeislikelytobeamuchbettermeasureofuncertaintythanthe
entropyoftherawcodeitself,giventhattherearemultiplewaysonecancodethesameoperation.
B.3 ALIGNMENTBETWEENEIGANDBELIEFUPDATINGPROCEDURE
Ourultimategoalistominimizeuncertaintyinθ,asmeasuredbyitsentropy. Withthisinmind,
wecanusetheexpecteduncertaintyreductionframeworkofBickfordSmithetal.(2025)toprovide
insightsintohowwellourEIGformulationandbeliefupdatingproceduresalign.
Tosimplifydiscussions,fornowweconsiderthesettingwherewechooseasinglequestionxand
obtain a response y. Following Bickford Smith et al. (2025), we can think of the “true” optimal
designasselecting
x∗ =argmin E [H[p(θ;x,y)]], (4)
true x ptrue(y;x)
wherep (y;x)isthetrueresponsedistributionandp(θ;x,y)isourbeliefstateaftertheexperiment.
true
Noteherethattrueoptimaldesignhasnodirectdependencyonourcurrentbeliefsaboutθ;itonly
dependsonp (y;x)andthehypotheticalbeliefsweproduceforgivenobserveddata,p(θ;x,y).
true
Thus,wecannowseethatourchoiceofjointmodelcorrespondstodifferentchoicesforapproximating
thesequantities. AssumingthattheLLMdistributionisuseddirectlyfortheconditionalasper§4,
wethushavethat:
• The prior-likelihood pairing equates to the approximations p (y;x) ≈
true
(cid:82) (cid:82)
p(θ)p (y;[θ,x])dθandp(θ;x,y)≈p(θ)p (y;[θ,x])/ p(θ)p (y;[θ,x])dθ;
LLM LLM LLM
• Thedata–estimationpairingequatestodirectlyspecifyingamodelforp (y;x)andthen
true
usingtheapproximationp(θ;x,y)≈p (θ;[x,y]).
LLM
Theappropriatenessofeachoftheseoptions,therefore,comesdowntohowfaithfultheseapproxima-
tionsarerespectivelytothetruedatadistribution,p (y;x),andhowweactuallyderiveourbelief
true
distributiononθinpracticeoncewehaveseenthenewdata.
The former of these considerations is difficult to control for as we simply do not know the true
responsedistributionanditishardtosaywhichapproachwillthusestimateitbest(thoughwecan
refertothediscussionin§4todeterminewhichbestmatchesourbeliefsaboutthetrueresponse
distribution). However,wedoknowupfronthowweplantoderiveourbeliefdistributiononθin
practice,sowecanusethistoguidewhichjointmodelweformulateourEIGfrom. Namely,we
observethat: a)usingtheprior–likelihoodEIGpairingequatestoassumingwewillmakeaBayesian
updatetoourbeliefsonθ usingthelikelihoodp (y;[θ,x]); b)usingthedata–estimationEIG
LLM
pairingequatestoassumingwewillmakeanin-contextupdatetoourbeliefsonθ,aswearetreating
p(θ;x,y)asp (θ;[x,y]).
LLM
Ourpreferencebetweenthepairingsshouldthereforebeguidedinpartbyhowweplantoupdatethe
modelinpractice. Inparticular,ifweplantomakepureBayesianupdates,thentheprior-likelihood
formulationwilltendtoyieldanEIGthatismorefaithfultoourupdatingprocedure,whileifweonly
makesimplein-contextupdates,thedata–estimationformulationwilltendtoyieldamorefaithful
EIGinstead.
Theupdateweuseinpractice,namelytakingp(θ;x,y) = p (θ;[x,y])asoutlinedin§3.3,canbe
f
seenasbeingsomewherebetweenthein-contextandBayesianupdating: weinitiallysamplefrom
p (θ;[x,y]),butthenperformfilteringandothersteps. Therelativeextenttowhichitresembles
LLM
each will be problem–dependent and again be linked to how much we trust the LLM to capture
uncertaintyinthespaceofθvs.y.
Forthesettingsweconsider,weexpectp (θ;[x,y])togenerallybebetterapproximatedbyaBayesian
f
updatethananin–contextupdate,aligningwithourdecisiontousetheprior–likelihoodformulation.
Thereasonsforthisarethata)thefilteringoftenremovesalargeproportionofthegeneratedsamples,
especiallyatlaterexperimentturns,withp (θ;h )notfullyincorporatinginformationfromthe
LLM t−1
history;b)themaintainingofthesetofoneconsistenthypothesesfromoneturntothenextencourages
18
Preprint
amoreBayesianbehavior,withsamplespersistingunlesscontradictedbyanewlikelihoodterm;and
c)thetypicalprematureoverconfidenceofp (θ;h )toasmallnumberofhypothesesmeansit
LLM t−1
istypicallyunrepresentativeofourbeliefs.
These theoretical benefits are perhaps secondary to the more practical benefits from the ease of
constructinganappropriatemodelintheprior–likelihoodformulationandavoidingdirectuncertainty
estimation in the space of θ. Nonetheless, they help confirm that our choices have not induced
unnecessarymismatchbetweentheEIGformulationandourupdatingprocedure.
ThepictureherecangetasomewhatmorecomplicatedoncewemoveintothesequentialBEDsetting.
Here,ourultimateaimisactuallytominimizeH[p(θ;h )]atsomefinalfuturehorizonT. Now,we
T
onlycareaboutintermediarybeliefstatesp(θ;h )throughtheiraidinfuturedecisionmakingtoward
t
thegoalofminimizingthefinalentropy. Thus,evenifweareworkingwithin-contextupdates,it
mightbethecasethatp(θ;h )onlystartstoproduceameaningfulentropyoncewehaveseenenough
t
datatosufficientlynarrowdownthepossibilitiesonθ. Theoptimalbehaviorinsuchsettingswould
betolearnapolicythatdirectlytargetsthisfinalbeliefstateinsteadofsequentiallytargetingthe
incrementalEIGs. However,thiswilltypicallynotbecomputationallyfeasibleinpracticeandwe
insteadneedtoresorttoamyopicdecision-makingstrategy. Itmightthusstillbebettertousethe
prior–likelihoodformulationinsuchmyopicdecisionmakingsettings,evenifwearesequentially
updatingourbeliefsonθthroughin-contextupdates,ifthisallowsustobetterguidethesequential
decisionstowardsourfinalobjective. ThecoherenceofBayesianupdatingmeansthattheconverseis
unlikelytobetrue,sothisprovidesfurtherevidencetowardsusingtheprior–likelihoodformulation.
C EXTENDED RELATED WORK
Information-based question answering with LLMs Several recent works have (explicitly or
implicitly)lookedatinformationgatheringwithLLMs. MostofthesecanbeframedinaBEDsetting,
withadeterministiclikelihood (Piriyakulkijetal.,2023;Huetal.,2024;Kobalczyketal.,2025;
Cooperetal.,2025),andcanbeseenasvariantsofourSplitbaseline. Piriyakulkijetal.(2023)use
adeterministic0/1answerlikelihoodp(a|x,q)viatheLLMtopruneitemsfromapre-enumerated
finitesetgivenacandidatequestionq. Thequestionisselectedbyminimizingexpectedposterior
entropy. Theymodeluserpreferenceswithabinarygroundtruth,whichwouldnotbeapplicable
in preference-elicitation scenarios with nebulous user profiles. Similarly, Hu et al. (2024) use a
deterministiclikelihoodtominimizeentropyoverafinitesetΩinaclosed-worldsetting. Kobalczyk
etal.(2025)targetambiguoustaskspecificationsinopen-endedgenerationtasksbysamplingasetof
hypotheses(placingauniformprioroverthem)andviewingeachquestionasadeterministicpartition
overthosesamples,lookingforquestionsthatsplitthesamplesroughlyevenly. Cooperetal.(2025)
computeposteriorentropyoveraworkingsetoftop-khypotheses(withoutfiltering)throughheuristic
pruning.
Wangetal.(2025)avoidthepitfallofdeterministiclikelihoods.Theyuseadata–estimationframework
toestimateEIG,focusingonscenarioswherethetargetcanbeexpressedasapredefinedseriesof
multiple-choicequestions. Theirapproachreliesonmeta-trainingapredictivelanguagemodelon
historicquestion/answerpairs,andsoisnotdirectlycomparablewithBED-LLMwhichrequiresno
additionaltrainingordata. Chanetal.(2025)donotmodellikelihoodsorposteriorbeliefs,instead
theyrelyontheexpectedsizeofconformalpredictionsetsasasurrogateuncertaintymetric. This
requirestheuseofanadditionalcalibrationdataset,andisconfinedtoclosed-worldsettingswitha
finitelabelsetandpre-definedqueries.
Post-trainingLLMsforimprovedinformationgathering RatherthanaugmentingafrozenLLM
withtheabilitytoestimateutilityfunctions,someworkshaveinsteadaimedtopost-trainanLLMto
improveitsabilitytoaskquestions(Zhangetal.,2024;Wuetal.,2025;Andukurietal.,2024). Most
donotexplicitlyconsiderinformativenessofquestions: Zhangetal.(2024)andWuetal.(2025)use
reinforcementlearningtechniquestorewardgenerationsthatquicklyleadtothecorrectanswer,and
Andukurietal.(2024)buildsonLietal.(2025b)byfine-tuningonsuccessfultraces. Mazzaccara
etal.(2024)doindirectlyincorporateuncertainty,alsousingadeterministiclikelihood: theyuse
predictiveentropytoidentifyinformativequestions,andtheneitherfine-tuneonthehighest-entropy
question,orperformDPOcomparingthehighest-entropyquestionwithalower-entropyquestion. We
donotaddressfine-tuninginthiswork,focusinginsteadonexploringthecorrectwaytoformulate
BEDusingLLMs.
19
Preprint
Algorithm1Data–EstimationSelectionatTurnt
Require: Historyh ;candidatequestionsXt ;answersets{Y(x)}
t−1 cand
Ensure: Selectedquestionx⋆
t
1: foreachx∈Xt do
cand
2: Obtainpredictiveanswerdistributionp LLM (y;x,h t−1 )forally ∈Y(x)
3: foreachy ∈Y(x)do
4: ComputeentropyH y ←H[p f (θ;h t−1 ∪(x,y))]
5: endfor
(cid:80)
6: ComputeEIG(x)←− y∈Y(x) p LLM (y;x,h t−1 )H y
7: endfor
8: Selectx⋆ t ←argmax x∈Xt EIG(x)
9: returnx⋆ cand
t
CombiningLLMswithparametricmodels Asdiscussedin§4,akeychallengeinadaptingBED
totheLLMsettingisinaligningtheexpectedinformationgainwiththeactualuncertaintiesextracted
fromtheLLMafterupdating. Handaetal.(2024)takeadifferentapproachtothisproblembyusing
the LLM to generate features for an external conventional Bayesian joint model (in their case, a
linearBradley–Terrymodel),ratherthanderivingtheirjointmodelmoredirectlyfromtheLLMitself.
Thiscanbeagoodchoicewhentheproblemiswell-boundedandwealreadyhaveawell-specified
Bayesianmodelformfortheproblemathand;however,thismaybechallenginginarbitrarilylarge
andcomplexhypothesisspaces. Inparticular,theirspecificmethodisnotapplicablemorewidely
beyondthepreferencelearningcontexttheyconsider.
BED IthasbeennotedthatthetraditionalsequentialBEDapproachcansometimesbesuboptimalin
practice,asitonlyoptimizestheEIGofthenextobservation,withoutplanningaheadforthefactthat
designdecisionstakenatagivenstepcanalsoinfluencetheachievableEIGsfromfuturesteps(Foster,
2021). A variety of policy–based BED approaches have subsequently been proposed to address
this(Fosteretal.,2021;Ivanovaetal.,2021;Blauetal.,2022;Huan&Marzouk,2016;Hedmanetal.,
2025),whilealsoremovingtheneedtomakemodelupdatesandconductoptimizationsduringthe
experimentitself. Ourfindingsarecomplementary: byprovidingmorefaithfulmodelfactorizations,
beliefupdates,andEIGestimatorsintheLLMsetting,BED-LLMcouldsupplystrongerbuilding
blocks for policy-based methods, reducing variance, enhancing effectiveness, and improving the
sampleefficiencyofpolicytraining.
D DATA–ESTIMATION METHOD
OurData–Estimationmethodisbasedonamodelderivedfromadata–estimationpairing(§3).
D.1 EIGESTIMATION
Supposeourmodelisgivenbyp(y ;[h ,x ])p(θ;[h ,x ,y ]).Here,itwillclearlybebeneficial
t t−1 t t−1 t t
todirectlyuseEq.1forestimatingtheEIG,asherewedirectlyhaveaccesstoalltherequiredterms,
otherthanp(θ)whichcanbesimplyignoredasitisnotafunctionofxsodoesnotaffectoptimization
ofthequestion. Ifthepossiblevaluesfory areenumerableandwecanevaluatep(y ;[h ,x ])
t t−1 t
in closed–form, we can directly calculate the exact EIG (up to a constant) without requiring any
estimationatall:
(cid:88)
EIG (x)−Const=− p(y ;[h ,x ])H[p(θ;[h ,x ,y ])], (5)
θ t t−1 t t−1 t t
y
wheretheentropyH[p(θ;[h ,x ,y ])]canbeevaluateddirectlyfromthelogitsoftheLLM,orif
t−1 t t
thesearenotavailable,estimatedbysampling.Ifwecannotenumerateyorevaluatep(y ;[h ,x ]),
t t−1 t
wecansimplyinsteadresorttoMonteCarloandusetheestimator:
N
1 (cid:88)
EIG (x)−Const≈− H[p(θ;[c,x,y ])] where y ∼p(y ;[h ,x ]). (6)
θ N n n t t−1 t
n=1
WeprovideanoverviewofhowtodothisintheLLMsettinginAlgorithm1.
20
Preprint
D.2 GENERATINGCANDIDATEHYPOTHESES
Togeneratecandidatevaluesofθforthedata–estimationmethod,weusethepromptinFig.4.
Figure4: Promptforgeneratinghypotheses(andevaluatingtheirprobability)forthedata–
estimationmethod.
Return only the full name of one randomly selected famous person (living or deceased)
consistent with the questions and answers above.
To increase randomness:
1. Internally brainstorm a pool of diverse and representative individuals.
2. Avoid defaulting to the most globally ubiquitous celebrities or famous figures.
Output rules:
- Output ONLY the person’s full name (with spaces, capitalization and accents), nothing
else.
- No extra words, explanations, numbering, or punctuation beyond what’s in the name
itself (hyphens/apostrophes allowed if part of the name).
Fig.5showsanexampleofthedistributionofsamplesobtainedfollowingtworoundsinthe20–
questionsgame. Notethatthesamplesarehighlyconcentratedonjustahandfulofanswers. This
lackofdiversityshowsthatthemodel’sbeliefdistributionisfarmoreconcentratedrelativetothe
variabilityovervalidhypothesesintheground–truthtaskdistribution,whichnegativelyimpactsthe
performanceofthedata–estimationmethod.
Is this person known for their contributions to science?
No.
Is this person known for their contributions to the arts?
Yes.
{
"Vincent van Gogh": 93,
"Salvador Dali": 44,
"Frida Kahlo": 37,
"Georgia O Keeffe": 10,
"August Wilson": 8,
"Auguste Rodin": 8
}
Figure5: AnexampleofthesampledistributiongeneratedusingthepromptinFig.4,conditioned
onthetwoquestion/answerpairsatthetopofthisfigure. Atthisstageofthegame,weindependently
sample200hypothesesfromtheLLMandrecordtheirfrequencies. Notethatthedistributionexhibits
strong mode collapse, with most of the mass highly concentrated on just a few answers, which
negativelyimpactstheperformanceofthedata–estimationmethod. Thissummaryisfordiagnostic
purposes:Algorithm1operatesontheprobabilitiesofindividualsamplesandneverinstantiatessuch
anaggregatedsummary.
21
Preprint
E GENERATING CANDIDATE HYPOTHESES FOR BED-LLM
Figure 6: Prompt for generating candidate hypotheses for the “Things” dataset. Similar
promptswereusedfor“Celebrities”and“Animals”.
You are playing a game of 20 Questions. Using all of the questions and answers so far:
Generate up to {num_samples} candidate entities that satisfy every clue.
Each candidate must be a single, self-contained entity (e.g., "Europa", "Bagpipe",
"Diadem").
List each entity on its own line - no numbering, punctuation, or extra text.
Produce a varied set by identifying features not implied by the clues and diversifying
along them.
Do not repeat any entity.
Return only the list of entities.
AfundamentalchallengeforBED-LLManditsablationsisgeneratingasufficientlydiversesetof
candidatehypothesesfromtheLLM’sbeliefdistribution, thatareconsistentwiththepreviously-
answeredquestions. Below,wedetailthestepswetaketoconstructourdistributionoverhypotheses.
Candidatehypothesesaregeneratedjointly,ratherthanindependently. AsillustratedinFig.5,
therawdistributionp (θ)ishighlyoverconfident,oftenconcentratingmassononlyafewhigh–
LLM
likelihood hypotheses. Thus, it is not practical to directly use the LLM’s distribution as a prior
p(θ). Instead,wejointlysamplecandidatesθandassumeauniformdistributionoverthem. Wecan
viewthisassamplingθsfromamixturedistribution. TheLLMispromptedtogeneratealistofN
hypothesesinasinglerollout,whichcorrespondstodrawingfromtheautoregressivelistdistribution
N
p (θ(1),...,θ(N);h ) = (cid:89) p (θ(n);[θ(1:n−1),h ]).
LLM t t t LLM t t t
n=1
Weuseadiversity-encouragingprompt Weuseapromptdesignedtoelicitstratifiedhypothesesby
encouragingtheLLMtoconsiderdifferentsemanticfeatures(e.g.agegroups,genres,orcategories)
and implicitly diversify across them. An example prompt is shown in Fig. 6. In our generation
prompt,wereversetheorderofthequestion–answerpairsinh toplacethemostrecentquestionat
t
thetopofthecontextwindow(whileretainingearlierexchanges),ensuringthatspecificconstraints
areprioritizedandmitigatingcontextdrift. Forthe20Questionsexperiments, weusedahigher-
than-normaltemperature(T =1.3)toincreasediversityofresponses. Forthepreferenceelicitation
experiments,weusedT =1toobtainmorecoherentresponses.
Candidatesarefilteredbasedonthehistory Foreachcandidate,weusep (θ;h )toassess
LLM t−1
whether it is compatible with the previous question/answer pairs. We filter responses where the
probabilityofthegivenanswerfallsbelowacertainthreshold;inourexperimentswesetthisthreshold
to0.2.
Validcandidatesfrompreviousgenerationsareincluded Wealsofilterthecandidatehypotheses
fromthepreviousgeneration,basedonthemostrecentquestion/answerpair,andincludetheseinour
candidateset.Werepeatthegenerationprocess,keepingthepreviouslygeneratedandfilteredsamples
incontexttoelicitnewgenerations,eithertwiceorthreetimesifsufficienthypotheseshavenotbeen
generated(notingthenumberofpossiblevalidsamplescanbelessthanthenumberrequested).
We assume a uniform distribution over hypotheses While one could in principle reweight
candidates using importance sampling, in practice we choose to not rely on the model’s internal
probabilities. Insteadweapproximatethepriorasauniformdistributionoverthisunion
1 (cid:88)
p (θ;h )≈ δ .
f t |Θ| θ
θ∈Θ
Finally,wenotethatdifferentLLMsresponddifferentlytostrategiesaimingtoincreasediversity:
some benefit more from a higher temperature while others benefit from more repetitions of the
sampling–filteringcycle. Forfairness,inourexperimentswehavekepttheseparametersconstant
acrossmodels.
22
Preprint
F EXPERIMENT DETAILS FOR 20 QUESTIONS
F.1 PROBLEMSETS
Weevaluateacrossthreedistinctproblemsets—Animals,Celebrities,orThings—witheachcon-
tainingamixof100obscureandcommontargets. Here,theproblemsetisjustalistofdifferentθ∗
thatwillbeindividuallyprovidedtotheanswerertoinstantiatedifferentproblems(e.g.weconducta
trialwhereθ∗ =“dog”,thenonewhereθ∗ =“cat”,etc). Thelistoftargetsisneverprovidedtothe
questionermodeltorestrictthesetofpossiblehypotheses: thequestionerisonlypromptedthatis
tryingtoidentifyan“animal”,“celebrity”,or“thing”. Theproblemsetsare
• Animals: asetofanimalspeciesgeneratedwithOpenAI’so3modeltoensureadiversemix
andbalancedtaxonomy.
• Celebrities: adiversesetofpublicfigures,asusedbyZhangetal.(2024).
• Things: acollectionofeverydayandexoticentitiesdrawnfromthewebcorpus,asused
byZhangetal.(2024); itcoversawiderangeofcategories,fromplantsandclothingto
professions,events,andmythicalcreatures.
TocreatetheAnimalsproblemset,wepromptedOpenAIo3(OpenAI,2025,o3-2025-04-16)to
generatealistofanimals,usingthepromptinFig.7. TheresultinglistisshowninFig.8. Alternative
names(after|character)weremanuallyadded.
Figure7: PromptforAnimalsproblemsetgeneration.
You are a zoologist.
Please generate a list of 100 living animal species with very high taxonomic diversity,
including diversity in phyla, classes, orders, and families. Present each animal on a
different line.
F.2 EVALUATION
We assess performance by tracking the questioner’s ability to identify the hidden target θ∗ over
thecourseofeachgame. Ateachturnt,wepromptittoproduceasingleguessforθ∗ viagreedy
decoding—thatis,weextractthehighestlikelihoodcandidatefromthebeliefstateofthequestioner
p (θ;h ). This guess is evaluated against the true target θ∗ (including alternative names) using
f t
case–insensitiveexactstringmatchingandwemeasuretheproportionofcorrectguessesateach
turn. Importantly, these evaluation guesses are not part of the questioner algorithm itself: they
areextractionsfromthequestioner’sbeliefstatep (θ;h )andareexcludedfromh tonotaffect
f t t−1
subsequentquestionselection.Inlinewiththeoriginalrulesofthegame,wealsointroduceanexplicit
mechanismforthequestionertoguesstheansweraspartofits20questions: ifthesetoffiltered
hypotheses collapses to a single candidate, or a direct guess of θ∗ is evaluated as the maximally
informativequestionbytheacquisitionfunction,thequestionerasks“Isit⟨item⟩?”. Thisguessis
evaluatedusingexactstringmatching,asabove. Ifthereisamatch,thegameterminatessuccessfully;
otherwise,ift<20,thegamecontinueswiththequestionandnegativeresponseincludedinh
t−1
andcountedtowardsthe20questionbudget.
F.3 ALGORITHMICDETAILS
Using our sample–then–filter process (see §3.3), we aim to sample at least N = 15 hypotheses,
repeatingthecycleuptothreetimesifneeded(theexactnumberofhypothesescanbelessthan
thisasitmaynotbepossibletogeneratesufficientvalidhypotheses,especiallyinlaterexperiment
turns). ThequestionergeneratesM =15candidatequestionstotest,Xcand,usingthe“conditional
generation” approach of §3.1 when possible, but falling back on “unconditional generation” if
insufficientcandidatehypotheseshavebeengenerated.
23
Preprint
Africanelephant Seaotter Kiwi
Bengaltiger Coralsnake Leafcutterant
Baldeagle Kingcobra Mantisshrimp
Bluewhale Harpyeagle Ocelot
Redkangaroo Lemur Peregrinefalcon
Giantpanda Koala Quetzal
Snowleopard Aye-aye|Ayeaye Raccoon
Greenseaturtle Snowyowl Sandcat
Americanalligator Elk Tarantula
Bottlenosedolphin Wolverine Uakari
Emperorpenguin Caracal Vicuña
Greatwhiteshark Cassowary Wildebeest
Golden poison frog | Golden Quokka Rockhyrax|dassie
poisondartfrog Pangolin Yak
Honeybee Saigaantelope Zebra
Monarchbutterfly Galápagostortoise|Galapagos Bluedragonnudibranch|Blue
Okapi tortoise dragonseaslug
Chimpanzee Sumatranorangutan Chinchilla
Arcticfox Red-eyed tree frog | Redeyed Dhole
Komododragon treefrog Electriceel
Giraffe Europeanbadger Flyingfox
Cheetah Moose Gharial
Hammerheadshark Africangreyparrot Horseshoecrab
Axolotl Scarletmacaw Indigobunting
Orca Blackmamba Jerboa
Puffin Albatross Kakapo
Redpanda Humpbackwhale Lionfish
Platypus Dugong Markhor
Rhinocerosbeetle Anaconda Nautilus
Tasmaniandevil Kookaburra Olivebaboon
Wombat Coyote Pika
Sloth Brownbear Quoll
Blue-ringed octopus | Blue Goldenjackal Rosyboa
ringedoctopus Capybara
Manatee Ibex
Narwhal Japanesemacaque
Figure8: Animalsproblemset(generatedusingOpenAIo3,withmanualcuration)
G EXPERIMENT DETAILS FOR PREFERENCE ELICITATION
G.1 PROBLEMS
To generate a set of ground-truth user profiles, we take a set of 200 real user ratings from the
MovieLens-100Kdataset(Harper&Konstan,2015),thenusean“oracle”LLM(namely,OpenAI’s
o3model)toproduceaparagraphoftextthatisconsistentwitheachdistinctsetofratings,usingthe
promptinFig.10. Aswasthecaseforthe20Questionsproblems,thisproblemsetisneverprovided
tothequestionerandthesetofallowedθisnotconstrained.
BecauseweneedtheLLMtobeabletomeaningfullycaptureuncertaintyinthespaceofresponses,
werestrictquestionstobemultiple-choice. Specifically,thequestioneristaskedwithproducinga
questionalongwithfivepossibleresponsesA/B/C/D/E.Wethendefineeachx tobethequestion
t
coupledwiththepossibleresponses, andeachy tobeoneofthelettersA/B/C/D/Etoprovidea
t
restrictedsetoftokensoverwhichwecanmeasureentropy. OptionEisfurtherconstrainedtoalways
be“noneoftheabove”sothattheanswererisnotcommittedtochoosingoneofthedirectlygenerated
choicesifnonearesuitable.
24
Preprint
100
0
%sseccuS slaminAno
Q:GPT-4o-mini Q:Qwen2.5-72B
GPT-4o-mini GPT-4o Llama-3.3-70B Qwen2.5-72B A:Qwen2.5-72B A:GPT-4o-mini
100 90 100 90 90
0 0 0 0 0
90
0
%sseccuS
seitirbeleCno 100 70 100 70 70
0 0 0 0 0
60
0
0 20
Turnt
%sseccuS sgnihTno
80 70 80 60 60
0 0 0 0 0
0 20 0 20 0 20 0 20 0 20
Turnt Turnt Turnt Turnt Turnt
Naive Split BED-LLM Entropy Data-Est. ICLBeliefs Impl.Max.
Figure9: Fullplotsfor20QuestionsExperiments.
G.2 EVALUATION
Toagainallowtrackingofprogressthroughtheexperiment,aftereachturnoftheinteractiont,the
questionergeneratestenfilmrecommendations,conditionedonh . Theserecommendationsare
t−1
checkedforconsistencywithpriorquestionsandanswers;ifanyarejudgedinconsistentthentheyare
removedandadditionalrecommendationsaregenerated. Thequalityofthefilmrecommendationsis
thenassessedusingan“LLM-as-judge”protocol(Zhuetal.,2025;Trivedietal.,2024). Namely,the
answererevaluateseachofthe10filmsrecommendedbythequestioner,conditionedonthehidden
targetuserprofileθ∗. Itscoreseachfilmonascaleof1to5(in0.5increments),basedonhowwell
therecommendationalignswithθ∗—thisscoreisoutputtogetherwithabriefjustificationtoincrease
reliability. Wereportthemeanratingandstandarderroracross200users,over5question–answer
turns.
G.3 ALGORITHMICDETAILS
ForBED-LLMandEntropy,wecompareM = 8candidatequestionsateachturnandweaimto
generateatleastN =5candidatehypotheses. Weusethe“unconstrainedgeneration”approachof
candidatequestiongeneration(see§3.1)astheuserprofilescanbequitediffuseandweareonly
generatingasmallnumberofpossiblehypothesesthatcanbequiteeasytosplit.
Wenotethatdata–estimationsetupisnotatallviableforthisproblembecausethelargenumberof
tokensandvaryingdimensionalityofeachθsamplemeanthatH[p (θ;[h ,x ,y ])]isnot
LLM t−1 t+1 t+1
onlyinfeasibletoestimate,butalsoisnotameaningfulmeasureofuncertainty.
25
Preprint
Figure10: Promptusedtogenerateground-truthuserprofilesforpreferenceelicitationtask.
You will be given a user’s complete film rating history from the MovieLens dataset,
provided as a dictionary structured by rating levels.
Your task is to thoroughly analyze the user’s preferences across the entire range of
their film ratings (from highest to lowest). Then, write a cohesive, descriptive
paragraph (approximately 5-7 sentences) summarizing the user’s overall film taste
profile.
In your response, explicitly address:
Favored Elements (inferred primarily from 4.5-5.0 ratings):
• Highlight the genres, narrative styles, themes, tones, historical eras, and
emotional experiences that consistently resonate positively with this user.
• Avoid mentioning any specific film titles, characters, or explicit plot points.
Neutral or Mixed Preferences (inferred from ratings around 2.5-4.0):
• Note if there are indications of genre overlap or conditional enjoyment,
such as certain genres or styles they occasionally appreciate under specific
circumstances.
Disliked Elements (inferred primarily from 0.5-1.5 ratings):
• Clearly outline the genres, narrative characteristics, tones, or emotional
impacts that the user consistently finds unappealing or poorly executed.
Your paragraph must be precise, informative, nuanced, and balanced, effectively
capturing the complexity and specificity of the user’s movie preferences. The
resulting profile should be clear and detailed enough for a recommendation system
to accurately predict the user’s likely enjoyment or dislike of other films based on
their established patterns of taste.
Proceed carefully, reasoning explicitly about the user’s overall rating patterns rather
than relying exclusively on extreme ratings, to form a comprehensive, stable, and
representative film preference profile.
26

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
