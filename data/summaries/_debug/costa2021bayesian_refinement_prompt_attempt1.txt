=== IMPORTANT: ISOLATE THIS PAPER ===
You are revising a summary for ONLY the paper below. Do NOT reference or use content from any other papers.
Paper Title: Bayesian Mechanics for Stationary Processes
Citation Key: costa2021bayesian
REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Issues to fix:
1. Title mismatch: Paper title 'Bayesian Mechanics for Stationary Processes' not found in summary
2. Too short: 41 words (minimum 200)

Current draft:
Okay, I understand. I will follow these instructions precisely to generate a summary of the provided text. I will focus on clarity, accuracy, and adherence to the specified guidelines, particularly regarding the avoidance of repetition and the use of appropriate language.

Key terms: stationary, universityofkonstanz, mechanics, state, processes, states, bayesian, germany

=== FULL PAPER TEXT ===
Bayesian Mechanics for
Stationary Processes
rspa.royalsocietypublishing.org
1,2 2
Lancelot Da Costa , Karl Friston , Conor
3,4,5 1
Heins and Grigorios A. Pavliotis
Research
1
DepartmentofMathematics,ImperialCollege
London,LondonSW72AZ,UK
Articlesubmittedtojournal 2
WellcomeCentreforHumanNeuroimaging,
UniversityCollegeLondon,LondonWC1N3AR,UK
3
SubjectAreas: DepartmentofCollectiveBehaviour,MaxPlanck
Stochasticprocesses,mathematical InstituteofAnimalBehavior,KonstanzD-78457,
biology,Bayesianstatistics, Germany
stochasticcontrol,mathematical 4 CentrefortheAdvancedStudyofCollective
modelling,statisticalphysics
Behaviour,UniversityofKonstanz,KonstanzD-78457,
Germany
Keywords:
5
DepartmentofBiology,UniversityofKonstanz,
Markovblanket,variationalBayesian
KonstanzD-78457,Germany
inference,activeinference,
non-equilibriumsteady-state,
predictiveprocessing,free-energy This paper develops a Bayesian mechanics for
adaptivesystems.
principle
Firstly, we model the interface between a system
and its environment with a Markov blanket. This
Authorforcorrespondence: affords conditions under which states internal to the
LancelotDaCosta blanketencodeinformationaboutexternalstates.
e-mail:l.da-costa@imperial.ac.uk Second, we introduce dynamics and represent
adaptivesystemsasMarkovblanketsatsteady-state.
This allows us to identify a wide class of systems
whose internal states appear to infer external states,
consistent with variational inference in Bayesian
statisticsandtheoreticalneuroscience.
Finally, we partition the blanket into sensory and
active states. It follows that active states can be seen
asperformingactiveinferenceandwell-knownforms
of stochastic control (such as PID control), which
areprominentformulationsofadaptivebehaviourin
theoreticalbiologyandengineering.
1 Introduction
Any object of study must be, implicitly or explicitly,
separatedfromitsenvironment.Thisimpliesaboundary
that separates it from its surroundings, and which
persistsforatleastaslongasthesystemexists.
© TheAuthors. PublishedbytheRoyalSocietyunderthetermsofthe
CreativeCommonsAttributionLicensehttp://creativecommons.org/licenses/
by/4.0/, whichpermitsunrestricteduse, providedtheoriginalauthorand
sourcearecredited.
1202
tcO
62
]hp-htam[
3v03831.6012:viXra
2
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
In this article, we explore the consequences of a boundary mediating interactions between
statesinternalandexternaltoasystem.Thisprovidesausefulmetaphortothinkaboutbiological
systems, which comprise spatially bounded, interacting components, nested at several spatial
scales [1,2]: for example, the membrane of a cell acts as a boundary through which the cell
communicates with its environment, and the same can be said of the sensory receptors and
musclesthatboundthenervoussystem.
By examining the dynamics of persistent, bounded systems, we identify a wide class of
systems wherein the states internal to a boundary appear to infer those states outside the
boundary—adescriptionwhichwerefertoasBayesianmechanics.Moreover,ifweassumethat
theboundarycomprisessensoryandactivestates,wecanidentifythedynamicsofactivestates
with well-known descriptions of adaptive behaviour from theoretical biology and stochastic
control.
Inwhatfollows,welinkapurelymathematicalformulationofinterfacesanddynamicswith
descriptionsofbeliefupdatingandbehaviourfoundinthebiologicalsciencesandengineering.
Altogether, this can be seen as a model of adaptive agents, as these interface with their
environmentthroughsensoryandactivestatesandfurthermorebehavesoastopreserveatarget
steady-state.
(a) Outline of paper
Thispaperhasthreeparts,eachofwhichintroducesasimple,butfundamental,move.
(i) The first is to partition the world into internal and external states whose boundary is
modelledwithaMarkovblanket[3,4].Thisallowsustoidentifyconditionsunderwhich
internalstatesencodeinformationaboutexternalstates.
(ii) The second move is to equip this partition with stochastic dynamics. The key
consequenceofthisisthatinternalstatescanbeseenascontinuouslyinferringexternal
states, consistent with variational inference in Bayesian statistics and with predictive
processingaccountsofbiologicalneuralnetworksintheoreticalneuroscience.
(iii) Thethirdmoveistopartitiontheboundaryintosensoryandactivestates.Itfollowsthat
activestatescanbeseenasperformingactiveinferenceandstochasticcontrol,whichare
prominentdescriptionsofadaptivebehaviourinbiologicalagents,machinelearningand
robotics.
(b) Related work
The emergence and sustaining of complex (dissipative) structures have been subjects of
long-standing research starting from the work of Prigogine [5,6], followed notably by Haken’s
synergetics [7], and in recent years, the statistical physics of adaptation [8]. A central theme of
theseworksisthatcomplexsystemscanonlyemergeandsustainthemselvesfarfromequilibrium
[9–11].
Information processing has long been recognised as a hallmark of cognition in biological
systems. In light of this, theoretical physicists have identified basic instances of information
processing in systems far from equilibrium using tools from information theory, such as how
adriveformetabolicefficiencycanleadasystemtobecomepredictive[12–15].
A fundamental aspect of biological systems is a self-organisation of various interacting
components at several spatial scales [1,2]. Much research currently focuses on multipartite
processes—modelling interactions between various sub-components that form biological
systems—andhowtheirinteractionsconstrainthethermodynamicsofthewhole[16–20].
Attheconfluenceoftheseefforts,researchershavesoughttoexplaincognitioninbiological
systems.Sincetheadventofthe20thcentury,Bayesianinferencehasbeenusedtodescribevarious
cognitiveprocessesinthebrain[21–25].Inparticular,thefreeenergyprinciple[23],aprominent
3
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
theoryofself-organisationfromtheneurosciences,postulatesthatBayesianinferencecanbeused
todescribethedynamicsofmultipartite,persistentsystemsmodelledasMarkovblanketsatnon-
equilibriumsteady-state[26–30].
This paper connects and develops some of the key themes from this literature. Starting
from fundamental considerations about adaptive systems, we develop a physics of things that
holdbeliefsaboutotherthings–consistentlywithBayesianinference–andexplorehowitrelates
to known descriptions of action and behaviour from the neurosciences and engineering. Our
contributionistheoretical:fromabiophysicist’sperspective,thispaperdescribeshowBayesian
descriptionsofbiologicalcognitionandbehaviourcanemergefromstandardaccountsofphysics.
From an engineer’s perspective this paper contextualises some of the most common stochastic
control methods and reminds us how these can be extended to suit more sophisticated control
problems.
(c) Notation
LetΠ∈Rd×dbeasquarematrixwithrealcoefficients.Letη,b,µdenoteapartitionofthestates
[[1,d]],sothat
 
Πη Π
ηb
Πηµ
Π=Π Π Π .
 bη b bµ
Πµη Π
µb
Πµ
Wedenoteprincipalsubmatriceswithoneindexonly(i.e.,weuseΠη insteadofΠηη).Similarly,
principalsubmatricesinvolvingvariousindicesaredenotedwithacolon
(cid:34) (cid:35)
Π :=
Πη Π
ηb .
η:b Π Π
bη b
When a square matrix Π is symmetric positive-definite we write Π(cid:31)0. ker, Im and ·−
respectively denote the kernel, image and Moore-Penrose pseudo-inverse of a linear map or
matrix, e.g., a non-necessarily square matrix such as Π µb. In our notation, indexing takes
precedenceover(pseudo)inversion,forexample,
Π− := (cid:0) Π (cid:1)− (cid:54)=(Π−) .
µb µb µb
2 Markov blankets
ThesectionformalisesthenotionofboundarybetweenasystemanditsenvironmentasaMarkov
blanket[3,4],depictedgraphicallyinFigure1.IntuitiveexamplesofaMarkovblanketarethatof
acellmembrane,mediatingallinteractionsbetweentheinsideandtheoutsideofthecell,orthat
ofsensoryreceptorsandmusclesthatboundthenervoussystem.
To formalise this intuition, we model the world’s state as a random variable x with
correspondingprobabilitydistributionpoverastate-spaceX =Rd.Wepartitionthestate-space
ofxintoexternal,blanketandinternalstates:
x=(η,b,µ)
X =E×B×I.
External,blanketandinternalstate-spaces(E,B,I)aretakentobeEuclideanspacesforsimplicity.
AMarkovblanketisastatementofconditionalindependencebetweeninternalandexternal
statesgivenblanketstates.
Definition2.1(Markovblanket). AMarkovblanketisdefinedas
4
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
Figure 1.Markov blanket depicted graphically as an undirected graphical model, also known as a Markov random
field[4,31].(AMarkovrandomfieldisaBayesiannetworkwhosedirectedarrowsarereplacedbyundirectedarrows).The
circlesrepresentrandomvariables.Thelinesrepresentconditionaldependenciesbetweenrandomvariables.TheMarkov
blanketconditionmeansthatthereisnolinebetweenµandη.Thismeansthat,µandηareconditionallyindependent
givenb.Inotherwords,knowingtheinternalstateµ,doesnotaffordadditionalinformationabouttheexternalstateη
whentheblanketstatebisknown.Thusblanketstatesactasaninformationalboundarybetweeninternalandexternal
states.
η⊥µ|b (M.B.)
Thatis,blanketstatesareaMarkovblanketseparatingµ,η[3,4].
TheexistenceofaMarkovblanketcanbeexpressedinseveralequivalentways
(M.B.) ⇐⇒ p(η,µ|b)=p(η|b)p(µ|b) ⇐⇒ p(η|b,µ)=p(η|b) ⇐⇒ p(µ|b,η)=p(µ|b). (2.1)
Fornow,wewillconsidera(non-degenerate)Gaussiandistributionpencodingthedistribution
ofstatesoftheworld
p(x):=N(x;0,Π−1), Π(cid:31)0,
with associated precision (i.e., inverse covariance) matrix Π. Throughout, we will denote the
(positivedefinite)covariancebyΣ:=Π−1.Unpacking(2.1)intermsofGaussiandensities,we
findthataMarkovblanketisequivalenttoasparsityintheprecisionmatrix
(M.B.) ⇐⇒ Πηµ=Πµη=0. (2.2)
Example2.1. Forexample,
 
2 1 0 (cid:34) (cid:35) (cid:34) (cid:35)
2 1 1.5 1
Π=1 2 1⇒Σ−1= ,Σ−1=
  η:b 1 1.5 b:µ 1 2
0 1 2
Then,
(cid:18) (cid:19)
1
p(η,µ|b)∝p(η,µ,b)∝exp − x·Πx
2
(cid:32) (cid:34) (cid:35) (cid:34) (cid:35)(cid:33)
1(cid:104) (cid:105) η 1(cid:104) (cid:105) b
∝exp − η,b Σ−1 − b,µ Σ−1 ∝p(η,b)p(b,µ)∝p(η|b)p(µ|b).
2 η:b b 2 b:µ µ
Thus,theMarkovblanketcondition(2.1)holds.
5
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
(a) Expected internal and external states
Blanket states act as an information boundary between external and internal states. Given
a blanket state, we can express the conditional probability densities over external and internal
states(using(2.1)and[32,Prop.3.13])1
p(η|b)=N(η;Σ Σ−1b, Π−1),
ηb b η
(2.3)
p(µ|b)=N(µ;Σ Σ−1b, Π−1).
µb b µ
This enables us to associate to any blanket state its corresponding expected external and
expectedinternalstates:
η(b)=E[η|b]=E [η]=Σ Σ−1b∈E
p(η|b) ηb b
µ(b)=E[µ|b]=E [µ]=Σ Σ−1b∈I.
p(µ|b) µb b
Pursuing the example of the nervous system, each sensory impression on the retina and
oculomotororientation(blanketstate)isassociatedwithanexpectedscenethatcausedsensory
input (expected external state) and an expected pattern of neural activity in the visual cortex
(expectedinternalstate)[33].
(b) Synchronisation map
A central question is whether and how expected internal states encode information about
expectedexternalstates.Forthis,weneedtocharacteriseasynchronisationfunctionσ,mapping
the expected internal state to the expected external state, given a blanket state σ(µ(b))=η(b).
Thisissummarisedinthefollowingcommutativediagram:
b∈B
η µ
Image(η) Image(µ)
σ
The existence of σ is guaranteed, for instance, if the expected internal state completely
determines the blanket state—that is, when no information is lost in the mapping b(cid:55)→µ(b) in
virtue of it being one-to-one. In general, however, many blanket states may correspond to an
uniqueexpectedinternalstate.Intuitively,considerthevariousneuralpathwaysthatcompress
thesignalarrivingfromretinalphotoreceptors[34],thusmanydifferent(hopefullysimilar)retinal
impressionsleadtothesamesignalarrivinginthevisualcortex.
i Existence
Thekeyfortheexistenceofafunctionσmappingexpectedinternalstatestoexpectedexternal
statesgivenblanketstates,isthatforanytwoblanketstatesassociatedwiththesameexpected
internal state, these be associated with the same expected external state. This non-degeneracy
meansthattheinternalstates(e.g.,patternsofactivityinthevisualcortex)haveenoughcapacity
torepresentallpossibleexpectedexternalstates(e.g.,3Dscenesoftheenvironment).Weformalise
thisinthefollowingLemma:
Lemma2.1. Thefollowingareequivalent:
(i) Thereexistsafunctionσ:Image(µ)→Image(η)suchthatforanyblanketstateb∈B
σ(µ(b))=η(b).
1NotethatΠη,Πµareinvertibleasprincipalsubmatricesofapositivedefinitematrix.
6
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
(ii) Foranytwoblanketstatesb 1 ,b 2 ∈B
µ(b )=µ(b )⇒η(b )=η(b ).
1 2 1 2
(iii) kerΣ µb ⊂kerΣ ηb.
(iv) kerΠ µb ⊂kerΠ ηb.
SeeAppendixAforaproofofLemma2.1.
Example2.2. • Whenexternal,blanketandinternalstatesareone-dimensional,theexistenceofa
synchronisationmapisequivalenttoΠ
µb
(cid:54)=0orΠ
µb
=Π
ηb
=0.
• If Π µb is chosen at random–its entries sampled from a non-degenerate Gaussian or uniform
distribution–then Π µb has full rank with probability 1. If furthermore the blanket state-space
Bhaslowerorequaldimensionalitythantheinternalstate-spaceI,weobtainthatΠ µb isone-
to-one(i.e.,kerΠ
µb
=0)withprobability1.Thus,inthiscase,theconditionsofLemma2.1are
fulfilledwithprobability1.
ii Construction
Thekeyideatomapanexpectedinternalstateµ(b)toanexpectedexternalstateη(b)isto:1)
findablanketstatethatmapstothisexpectedinternalstate(i.e.,byinvertingµ)and2)fromthis
blanketstate,findthecorrespondingexpectedexternalstate(i.e.,byapplyingη):
b∈B
η µ
µ−
Image(η) Image(µ)
σ=η◦µ−
Wenowproceedtosolvingthisproblem.Givenaninternalstateµ,westudythesetofblanket
statesbsuchthatµ(b)=µ
µ(b)=Σ µb Σ b −1b=µ ⇐⇒ b∈µ−1(µ)=Σ b Σ µ − b 1µ. (2.4)
Heretheinverseontherighthandsideof(2.4)isunderstoodasthepreimageofalinearmap.We
knowthatthissystemoflinearequationshasavectorspaceofsolutionsgivenby[35]
(cid:110) (cid:16) (cid:17) (cid:111)
µ−1(µ)= Σ b Σ µ − b µ+ Id−Σ b Σ µ − b Σ µb Σ b −1 b:b∈B . (2.5)
Amongthese,wechoose
µ−(µ)=Σ Σ−µ.
b µb
Definition2.2(Synchronisationmap). Wedefineasynchronisationfunctionthatmapstoaninternal
stateacorrespondingmostlikelyinternalstate23
σ:Imµ→Imη
µ(cid:55)→η(µ−(µ))=Σ
ηb
Σ
µ
−
b
µ=Π
η
−1Π
ηb
Π
µ
−
b
Πµµ.
TheexpressionintermsoftheprecisionmatrixisabyproductofAppendixA.
Note that we can always define such σ, however, it is only when the conditions of Lemma
2.1 are fulfilled that σ maps expected internal states to expected external statesσ(µ(b))=η(b).
Whenthisisnotthecase,theinternalstatesdonotfullyrepresentexternalstates,whichleadsto
apartlydegeneratetypeofrepresentation,seeFigure2foranumericalillustrationobtainedby
2Thismappingwasderivedindependentlyofourworkin[36,Section3.2].
3Replacingµ−(µ)byanyotherelementof(2.5)wouldleadtothesamesynchronisationmapprovidedthattheconditions
ofLemma2.1aresatisfied.
7
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
Figure2.Synchronisationmap:exampleandnon-example.Thisfigureplotsexpectedexternalstatesgivenblanket
statesη(b)(inorange),andthecorrespondingpredictionencodedbyinternalstatesσ(µ(b))(inblue).Inthisexample,
external,blanketandinternalstate-spacesaretakentobeonedimensional.Weshowthecorrespondenceunderthe
conditionsofLemma2.1(leftpanel)andwhenthesearenotsatisfied(rightpanel).Togeneratethesedata,1)wedrew
106samplesfromaGaussiandistributionwithaMarkovblanket,2)wepartitionedtheblanketstate-spaceintoseveral
bins,3)weobtainedtheexpectedexternalandinternalstatesgivenblanketstatesempiricallybyaveragingsamples
fromeachbin,andfinally,4)weappliedthesynchronisationmaptothe(empirical)expectedinternalstatesgivenblanket
states.
samplingfromaGaussiandistribution,inthenon-degenerate(left)anddegeneratecases(right),
respectively.
3 Bayesian mechanics
Inordertostudythetime-evolutionofsystemswithaMarkovblanket,weintroducedynamics
intotheexternal,blanketandinternalstates.Henceforth,weassumeasynchronisationmapunder
theconditionsofLemma2.1.
(a) Processes at a Gaussian steady-state
We consider stochastic processes at a Gaussian steady-state p with a Markov blanket. The
steady-state assumption means that the system’s overall configuration persists over time (e.g.,
itdoesnotdissipate).Inotherwords,wehaveaGaussiandensityp=N(0,Π−1)withaMarkov
blanket(2.2)andastochasticprocessdistributedaccordingtopateverypointintime
xt∼p=N(0,Π−1) foranyt.
Recalling our partition into external, blanket and internal states, this affords a Markov blanket
thatpersistsovertime,seeFigure3
xt=(ηt,bt,µt)∼p⇒ηt⊥µt|bt. (3.1)
Notethatwedonotrequirexttobeindependentsamplesfromthesteady-statedistributionp.
Onthecontrary,xt maybegeneratedbyextremelycomplex,non-linear,andpossiblystochastic
equationsofmotion.SeeExample3.1andFigure4fordetails.
Example 3.1. The dynamics of xt are described by a stochastic process at a Gaussian steady-state p=
N(0,Π−1).Thereisalargeclassofsuchprocesses,forexample:
8
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
Figure3.Markovblanketevolvingintime.WeuseabacillustodepictanintuitiveexampleofaMarkovblanketthat
persistsovertime.Here,theblanketstatesrepresentthemembraneandactinfilamentsofthecytoskeleton,whichmediate
allinteractionsbetweeninternalstatesandtheexternalmedium(externalstates).
Figure 4.Processes at a Gaussian steady-state. This figure illustrates the synchronisation map and transition
probabilitiesofprocessesataGaussiansteady-state.Left:WeplotthesynchronisationmapasinFigure2,only,here,the
samplesaredrawnfromtrajectoriesofadiffusionprocess(3.2)withaMarkovblanket.Althoughthisisnotthecasehere,
onemightobtainaslightlynoisiercorrespondencebetweenpredictionsσ(µ(bt))andexpectedexternalstatesη(bt)—
comparedtoFigure2—innumericaldiscretisationsofadiffusionprocess.Thisisbecausethesteady-stateofanumerical
discretisationusuallydiffersslightlyfromthesteady-stateofthecontinuous-timeprocess[37].Right:Thispanelplotsthe
transitionprobabilitiesofthesamediffusionprocess(3.2),fortheblanketstateattwodifferenttimes.Thejointdistribution
(depictedasaheatmap)isnotGaussianbutitsmarginals—thesteady-statedensity—areGaussian.Thisshowsthatin
general,processesataGaussiansteady-statearenotGaussianprocesses.Infact,theOrnstein-Uhlenbeckprocessis
theonlystationarydiffusionprocess(3.2)thatisaGaussianprocess,sothetransitionprobabilitiesofnon-lineardiffusion
processes(3.2)arenevermultivariateGaussians.
• Stationarydiffusionprocesses,withinitialconditionx 0 ∼p.Theirtime-evolutionisgivenbyan
Itôstochasticdifferentialequation(seeAppendixB):
dxt=(Γ +Q)(xt)∇logp(xt)dt+∇·(Γ +Q)(xt)dt+ς(xt)dWt,
=−(Γ +Q)(xt)Πxtdt+∇·(Γ +Q)(xt)dt+ς(xt)dWt (3.2)
Γ :=ςς(cid:62)/2, Q=−Q(cid:62).
Here, Wt is a standard Brownian motion (a.k.a., Wiener process) [38,39] and ς,Γ,Q are
sufficientlywell-behavedmatrixfields(seeAppendixB).Namely,Γ isthediffusiontensor(halfthe
covarianceofrandomfluctuations),whichdrivesdissipativeflow;Qisanarbitraryantisymmetric
matrixfieldwhichdrivesconservative(i.e.,solenoidal)flow.Weemphasisethattherearenonon-
degeneracyconditionsonthematrixfieldς—inparticular,theprocessisallowedtobenon-ergodic
9
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
or even completely deterministic (i.e., ς≡0). Also, ∇· denotes the divergence of a matrix field
definedas(∇·(Γ +Q))
i
:= (cid:80)
j ∂
∂
xj
(Γ +Q) ij.
• Moregenerally,xtcouldbegeneratedbyanyMarkovprocessatsteady-statep,suchasthezig-zag
processorthebouncyparticlesampler[40–42],byanymean-zeroGaussianprocessatsteady-state
p[43]orbyanyrandomdynamicalsystematsteady-statep[44].
Remark 3.1. When the dynamics are given by an Itô stochastic differential equation (3.2), a Markov
blanket of the steady-state density (2.2) does not preclude reciprocal influences between internal and
externalstates[45,46].Forexample,
   
2 1 0 0 0 1
Π=  1 2 1  , Q≡  0 0 0  , ς≡Id 3
0 1 2 −1 0 0
    
ηt 1 1.5 2 ηt
⇒d

bt 

=−

0.5 1 0.5



bt 

dt+ςdWt.
µt −2 −0.5 1 µt
Conversely,theabsenceofreciprocalcouplingbetweentwostatesinthedriftinsomeinstances,thoughnot
always,leadstoconditionalindependence[30,36,45].
(b) Maximum a posteriori estimation
The Markov blanket (3.1) allows us to harness the construction of Section 2 to determine
expectedexternalandinternalstatesgivenblanketstates
ηt:=η(bt) µt:=µ(bt).
Note that η,µ are linear functions of blanket states; since bt generally exhibits rough sample
paths,ηt,µtwillalsoexhibitveryroughsamplepaths.
Wecanviewthesteady-statedensitypasspecifyingtherelationshipbetweenexternalstates
(η,causes)andparticularstates(b,µ,consequences).Instatistics,thiscorrespondstoagenerative
model,aprobabilisticspecificationofhow(external)causesgenerate(particular)consequences.
By construction, the expected internal states encode expected external states via the
synchronisationmap
σ(µt)=ηt,
whichmanifestsaformofgeneralisedsynchronyacrosstheMarkovblanket[47–49].Moreover,
theexpectedinternalstateµteffectivelyfollowsthemostlikelycauseofitssensations
σ(µt)=argmaxp(ηt|bt) foranyt.
Thishasaninterestingstatisticalinterpretationasexpectedinternalstatesperformmaximuma
posteriori(MAP)inferenceoverexternalstates.
(c) Predictive processing
Wecangofurtherandassociatetoeachinternalstateµaprobabilitydistributionoverexternal
states,suchthateachinternalstateencodesbeliefsaboutexternalstates
qµ(η):=N(η;σ(µ),Π η −1). (3.3)
We will call qµ the approximate posterior belief associated with the internal state µ due to
the forecoming connection to inference. Under this specification, the mean of the approximate
posteriordependsupontheinternalstate,whileitscovarianceequalsthatofthetrueposterior
w.r.t.externalstates(2.3).Itfollowsthattheapproximateposteriorequalsthetrueposteriorwhen
theinternalstateµequalstheexpectedinternalstateµ(b)(givenblanketstates):
10
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
qµ(η)=p(η|b) ⇐⇒ µ=µ(b). (3.4)
Noteapotentialconnectionwithepistemicaccountsofquantummechanics;namely,aworld
governed by classical mechanics (σ≡0 in (3.2)) in which each agent encodes Gaussian beliefs
about external states could appear to the agents as reproducing many features of quantum
mechanics[50].
Underthisspecification(3.4),expectedinternalstatesaretheuniqueminimiserofaKullback-
Leiblerdivergence[51]
µt=argminD
KL
[qµ(η)(cid:107)p(η|b)]
µ
thatmeasuresthediscrepancybetweenbeliefsabouttheexternalworldqµ(η)andtheposterior
distributionoverexternalvariables.ComputingtheKLdivergence(seeAppendixC),weobtain
µt=argmin(σ(µ)−ηt)Πη(σ(µ)−ηt) (3.5)
µ
Intheneurosciences,therighthandsideof(3.5)iscommonlyknownasa(squared)precision-
weighted prediction error: the discrepancy between the prediction and the (expected) state of
the environment is weighted with a precision matrix [24,52,53] that derives from the steady-
state density. This equation is formally similar to that found in predictive coding formulations
ofbiologicalfunction[24,54–56],whichstipulatethatorganismsminimisepredictionerrors,and
indoingsooptimisetheirbeliefstomatchthedistributionofexternalstates.
(d) Variational Bayesian inference
We can go further and associate expected internal states to the solution to the classical
variationalinferenceproblemfromstatisticalmachinelearning[59]andtheoreticalneurobiology
[52,60]. Expected internal states are the unique minimiser of a free energy functional (i.e., an
evidencebound[59,61])
F(bt,µt)≥F(bt,µt)
F(b,µ)=D
KL
[qµ(η)(cid:107)p(η|b)]−logp(b,µ)
(3.6)
=E
qµ(η)
[−logp(x)]− H[qµ] .
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124)(cid:123)(cid:122)(cid:125)
Energy Entropy
The last line expresses the free energy as a difference between energy and entropy: energy or
accuracymeasurestowhatextentpredictedexternalstatesareclosetothetrueexternalstates,
whileentropypenalisesbeliefsthatareoverlyprecise.
Atfirstsight,variationalinferenceandpredictiveprocessingaresolelyusefultocharacterise
theaverageinternalstategivenblanketstatesatsteady-state.Itisthensurprisingtoseethatthe
freeenergysaysagreatdealaboutasystem’sexpectedtrajectoriesasitrelaxestosteady-state.
Figure5and6illustratethetime-evolutionofthefreeenergyandpredictionerrorsafterexposure
toasurprisingstimulus.Inparticular,Figure5averagesinternalvariablesforanyblanketstate:
Intheneurosciences,perhapstheclosestanalogyistheevent-triggeredaveragingprotocol,where
neurophysiological responses are averaged following a fixed perturbation, such a predictable
neural input or an experimentally-controlled sensory stimulus (e.g., spike-triggered averaging,
event-relatedpotentials)[62–64].
Themoststrikingobservationisthenearlymonotonicdecreaseofthefreeenergyasthesystem
relaxestosteady-state.Thissimplyfollowsfromthefactthatregionsofhighdensityunderthe
steady-statedistributionhavealowfreeenergy.Thisoveralldecreaseinfreeenergyistheessence
of the free-energy principle, which describes self-organisation at non-equilibrium steady-state
[23,28,29].Notethatthefreeenergy,evenafteraveraginginternalvariables,maydecreasenon-
monotonically.SeetheexplanationinFigure5.
11
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
Figure5.Variationalinferenceandpredictiveprocessing,averaginginternalvariablesforanyblanketstate.This
figureillustratesasystem’sbehaviourafterexperiencingasurprisingblanketstate,averaginginternalvariablesforany
blanketstate.ThisisamultidimensionalOrnstein-Uhlenbeckprocess,withtwoexternal,blanketandinternalvariables,
initialisedatthesteady-statedensityconditioneduponanimprobableblanketstatep(x0|b0).Upperleft:weplotasample
trajectoryoftheblanketstatesastheserelaxtosteady-stateoveracontourplotofthefreeenergy(uptoaconstant).
Upperright:thisplotsthefreeenergy(uptoaconstant)overtime,averagedovermultipletrajectories.Inthisexample,
therarefluctuationsthatclimbthefreeenergylandscapevanishonaverage,sothattheaveragefreeenergydecreases
monotonically. This need not always be the case: conservative systems (i.e., ς≡0 in (3.2)) are deterministic flows
alongthecontoursofthesteady-statedensity(seeAppendixB).Sincethesecontoursdonotgenerallycoincidewith
thoseofF(b,µ)itfollowsthatthefreeenergyoscillatesbetweenitsmaximumandminimumvalueoverthesystem’s
periodictrajectory.Luckily,conservativesystemsarenotrepresentativeofdissipative,livingsystems.Yet,itfollowsthat
theaveragefreeenergyofexpectedinternalvariablesmayincrease,albeitonlymomentarily,indissipativesystems(3.2)
whosesolenoidalflowdominatesdissipativeflow.Lowerleft:weillustratetheaccuracyofpredictionsoverexternalstates
ofthesamplepathfromtheupperleftpanel.Atsteady-state(fromtimestep∼100),thepredictionsbecomeaccurate.
Thepredictionofthesecondcomponentisoffsetbyfourunitsforgreatervisibility,ascanbeseenfromthelongtime
behaviourconvergingtofourinsteadofzero.Lowerright:Weshowtheevolutionofprecision-weightedpredictionerrors
ξt:=Πη(ηt−σ(µt))overtime.Thesearenormallydistributedwithzeromeanatsteady-state.
4 Active inference and stochastic control
In order to model agents that interact with their environment, we now partition blanket states
intosensoryandactivestates
bt=(st,at)
xt=(ηt,st,at,µt).
Intuitively, sensory states are the sensory receptors of the system (e.g., olfactory or visual
receptors) while active states correspond to actuators through which the system influences the
environment(e.g.,muscles).SeeFigure7.Thegoalofthissectionistoexplainhowautonomous
12
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
Figure 6.Variational inference and predictive processing. This figure illustrates a system’s behaviour after
experiencingasurprisingblanketstate.ThisisamultidimensionalOrnstein-Uhlenbeckprocess,withoneexternal,blanket
andinternalvariable,initialisedatthesteady-statedensityconditioneduponanimprobableblanketstatep(x0|b0).Upper
left:thisplotsasampletrajectoryofparticularstatesastheserelaxtosteady-stateoveracontourplotofthefreeenergy.
Thewhitelineshowstheexpectedinternalstategivenblanketstates,atwhichpointinferenceisexact.Afterstarting
closetothisline,theprocessisdrivenbysolenoidalflowtoregionswhereinferenceisinaccurate.Yet,solenoidalflow
makesthesystemconvergefastertosteady-state[57,58]atwhichpointinferencebecomesaccurateagain.Upperright:
thisplotsthefreeenergy(uptoaconstant)overtime,averagedovermultipletrajectories.Lowerleft:weillustratethe
accuracyofpredictionsoverexternalstatesofthesamplepathfromtheupperleftpanel.Thesepredictionsareaccurate
atsteady-state(fromtimestep∼100).Lowerright:weillustratethe(precisionweighted)predictionerrorsovertime.In
orangeweplotthepredictionerrorcorrespondingtothesamplepathintheupperleftpanel;theothersamplepathsare
summarisedasaheatmapinblue.
states (i.e., active and internal states) respond adaptively to sensory perturbations in order to
maintainthesteady-state,whichweinterpretastheagent’spreferencesorgoal.Thisallowsus
torelatethedynamicsofautonomousstatestoactiveinferenceandstochasticcontrol,whichare
well-knownformulationsofadaptivebehaviourintheoreticalbiologyandengineering.
(a) Active inference
Wenowproceedtocharacteriseautonomousstates,givensensorystates,usingthefreeenergy.
Unpackingblanketstates,thefreeenergy(3.6)reads
F(s,a,µ)=D
KL
[qµ(η)(cid:107)p(η|s,a)]−logp(µ|s,a)−logp(a|s)−logp(s).
Crucially,itfollowsthattheexpectedautonomousstatesminimisefreeenergy
F(st,at,µt)≥F(st,at,µt),
at:=a(st):=E
p(at|st)
[at]=ΣasΣ
s
−1st,
13
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
Figure7.Markovblanketevolvingintimecomprisingsensoryandactivestates.Wecontinuetheintuitiveexample
fromFigure3ofthebacillusasrepresentingaMarkovblanketthatpersistsovertime.Theonlydifferenceisthatwe
partitionblanketstatesintosensoryandactivestates.Inthisexample,thesensorystatescanbeseenasthebacillus’
membrane,whiletheactivestatescorrespondtotheactinfilamentsofthecytoskeleton.
Figure8.Activeinference.Thisfigureillustratesasystem’sbehaviourafterexperiencingasurprisingsensorystate,
averaginginternalvariablesforanyblanketstate.WesimulatedanOrnstein-Uhlenbeckprocesswithtwoexternal,one
sensory,oneactiveandtwointernalvariables,initialisedatthesteady-statedensityconditioneduponanimprobable
sensorystatep(x0|s0).Left:Thewhitelineshowstheexpectedactivestategivensensorystates:thisistheactionthat
performsactiveinferenceandoptimalstochasticcontrol.Astheprocessexperiencesasurprisingsensorystate,itinitially
relaxestosteady-stateinawindingmannerduetothepresenceofsolenoidalflow.Eventhoughsolenoidalflowdrivesthe
actionsawayfromtheoptimalactioninitially,itallowstheprocesstoconvergefastertosteady-state[57,58,73]wherethe
actionsareagainclosetotheoptimalactionfromoptimalcontrol.Right:Weplotthefreeenergyoftheexpectedinternal
state,averagedovermultipletrajectories.Inthisexample,theaveragefreeenergydoesnotdecreasemonotonically—see
Figure5foranexplanation.
whereat denotestheexpectedactivestatesgivensensorystates,whichisthemeanofp(at|st).
Thisresultformsthebasisofactiveinference,awell-knownframeworktodescribeandgenerate
adaptivebehaviourinneuroscience,machinelearningandrobotics[25,60,65–72].SeeFigure8.
(b) Multivariate control
Activeinferenceisusedinvariousdomainstosimulatecontrol[65,69,71,72,74–77],thus,itis
naturalthatwecanrelatethedynamicsofactivestatestowell-knownformsofstochasticcontrol.
Bycomputingthefreeenergyexplicitly(seeAppendixC),weobtainthat
14
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
Figure9.Stochasticcontrol.Thisfigureplotsasamplepathofthesystem’sparticularstatesafteritexperiencesa
surprisingsensorystate.ThisisthesamesamplepathasshowninFigure8(leftpanel),however,herethelinkwith
stochasticcontroliseasiertosee.Indeed,itlooksasifactivestates(inred)areactivelycompensatingforsensorystates
(ingreen):risesintheactivestate-spaceleadtoplungesinthesensorystate-spaceandvice-versa.Noticetheinitial
riseinactivestatestocompensatefortheperturbationinthesensorystates.Activestatesfollowasimilartrajectoryas
sensorystates,withaslightdelay,whichcanbeinterpretedasareactiontime[78].Infact,thecorrespondencebetween
sensoryandactivestatesisaconsequenceofthesolenoidalflow–seeFigure8(leftpanel).Thedampedoscillations
astheparticularstatesapproachtheirtargetvalueof0(ingrey)isanalogoustothatfoundinbasicimplementationsof
stochasticcontrol,e.g.,[79,Figure4.9].
 
(cid:104) (cid:105)
st
(at,µt) minimises (a,µ)(cid:55)→ st,a,µ K

a

(4.1)
µ
K:=Σ−1
b:µ
wherewedenotedbyK theconcentration(i.e.,precision)matrixofp(s,a,µ).Wemayinterpret
(a,µ) as controlling how far particular states [s,a,µ] are from their target set-point of [0,0,0],
wheretheerrorisweightedbytheprecisionmatrixK.SeeFigure9.(Notethatwecouldchoose
any other set-point by translating the frame of reference or equivalently choosing a Gaussian
steady-statecentredawayfromzero).Inotherwords,thereisacostassociatedtohowfaraway
s,a,µarefromtheoriginandthiscostisweighedbytheprecisionmatrix,whichderivesfromthe
stationarycovarianceofthesteady-state.Insummary,theexpectedinternalandactivestatescan
beseenasperformingmultivariatestochasticcontrol,wherethematrixKencodescontrolgains.
Fromabiologist’sperspective,thiscorrespondstoasimpleinstanceofhomeostaticregulation:
maintainingphysiologicalvariableswithintheirpreferredrange.
(c) Stochastic control in an extended state-space
More sophisticated control methods, such as PID (Proportional-Integral-Derivative) control
[77,80],involvecontrollingaprocessanditshigherordersofmotion(e.g.,integralorderivative
terms). So how can we relate the dynamics of autonomous states to these more sophisticated
controlmethods?Thebasicideainvolvesextendingthesensorystate-spacetoreplacethesensory
(cid:16) (cid:17)
(0) (n)
processst byitsvariousordersofmotions˜t= s
t
,...,s
t
(integral,position,velocity,jerk
etc, up to order n). To find these orders of motion, one must solve the stochastic realisation
problem.
15
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
i Thestochasticrealisationproblem
Recallthatthesensoryprocessst isastationarystochasticprocess(withaGaussiansteady-
state). The following is a central problem in stochastic systems theory: Given a stationary
stochastic process st, find a Markov process s˜t, called the state process, and a function f such
that
st=f(s˜t) forall t. (4.2)
Moreover,findanItôstochasticdifferentialequationwhoseuniquesolutionisthestateprocess
s˜t.Theproblemofcharacterisingthefamilyofallsuchrepresentationsisknownasthestochastic
realisationproblem[81].
WhatkindofprocessesstcanbeexpressedasafunctionofaMarkovprocess(4.2)?
There is a rather comprehensive theory of stochastic realisation for the case where st is
a Gaussian process (which occurs, for example, when xt is a Gaussian process). This theory
expressesst asalinearmapofanOrnstein-Uhlenbeckprocess[39,82,83].Theideaisasfollows:
as a mean-zero Gaussian process, st is completely determined by its autocovariance function
C(t−r)=E[st⊗sr], which by stationarity only depends on |t−r|. It is well known that any
mean-zerostationaryGaussianprocesswithexponentiallydecayingautocovariancefunctionis
anOrnstein-Uhlenbeckprocess(aresultsometimesknownasDoob’stheorem)[39,84–86].Thusif
C equalsafinitesumofexponentiallydecayingfunctions,wecanexpressstasalinearfunction
ofseveralnestedOrnstein-Uhlenbeckprocesses,i.e.,asanintegratorchainfromcontroltheory
[87,88]
(0)
st=f(s
t
)
(0) (0) (1) (0)
ds =f (s ,s )dt+ς dW
t 0 t t 0 t
(1) (1) (2) (1)
ds =f (s ,s )dt+ς dW
t 1 t t 1 t
(4.3)
. . .
. . .
. . .
(n−1) (n−1) (n) (n−1)
ds =f (s ,s )dt+ς dW
t n−1 t t n−1 t
(n) (n) (n)
ds
t
=fn(s
t
)dt+ςndW
t
.
Inthisexample,f,f iaresuitablychosenlinearfunctions,ς iarematricesandW(i)arestandard
Brownianmotions.Thus,wecanseestastheoutputofacontinuous-timehiddenMarkovmodel,
(i)
whose(hidden)statess encodeitsvariousordersofmotion:position,velocity,jerketc.These
t
areknownasgeneralisedcoordinatesofmotionintheBayesianfilteringliterature[89–91].See
Figure10.
More generally, the state process s˜t and the function f need not be linear, which enables to
realise non-linear, non-Gaussian processes st [89,92,93]. Technically, this follows as Ornstein-
Uhlenbeck processes are the only stationary Gaussian Markov processes. Note that stochastic
realisationtheoryisnotaswelldevelopedinthisgeneralcase[81,89,93–95].
ii Stochasticcontrolofintegratorchains
Henceforth, we assume that we can express st as a function of a Markov process s˜t (4.2).
Inserting (4.2) into (4.1), we now see that the expected autonomous states minimise how far
themselvesandf(s˜t)arefromtheirtargetvalueofzero
 
(cid:104) (cid:105)
f(s˜t)
(at,µt) minimises (a,µ)(cid:55)→ f(s˜t),a,µ K

a 

. (4.4)
µ
16
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
Figure 10.Continuous-time Hidden Markov model. This figure depicts (4.3) in a graphical format, as a Bayesian
network [3,31]. The encircled variables are random variables—the processes indexed at an arbitrary sequence
of subsequent times t1<t2<...<t9. The arrows represent relationships of causality. In this hidden Markov
model, the (hidden) state process s˜t is given by an integrator chain—i.e., nested stochastic differential equations
s(0),s(1),...,s(n) .Theseprocessess(i),i≥0,canrespectivelybeseenasencodingtheposition,velocity,jerketc,
t t t t
oftheprocessst.
Furthermore,ifthestateprocesss˜t canbeexpressedasanintegratorchain,asin(4.3),then
(i)
wecaninterpretexpectedactiveandinternalstatesascontrollingeachorderofmotions .For
t
(i)
example,iff islinear,theseprocessescontroleachorderofmotions towardsitstargetvalue
t
ofzero.
iii PID-likecontrol
Proportional-integral-derivative(PID)controlisawell-knowncontrolmethodinengineering
[77,80]. More than 90% of controllers in engineered systems implement either PID or PI (no
(1) (0)
derivative) control. The goal of PID control is to control a signal s , its integral s , and its
t t
(2)
derivatives closetoapre-specifiedtargetvalue[77].
t
Thisturnsouttobeexactlywhathappensherewhenweconsiderthestochasticcontrolofan
integratorchain(4.4)withthreeordersofmotion(n=2).Whenf islinear,expectedautonomous
(0) (1) (2)
statescontrolintegral,proportionalandderivativeprocessess ,s ,s towardstheirtarget
t t t
valueofzero.Furthermore,fromf andK onecanderiveintegral,proportionalandderivative
(0) (1) (2)
gains, which penalise deviations of s ,s ,s , respectively, from their target value of zero.
t t t
Crucially,thesecontrolgainsaresimpleby-productsofthesteady-statedensityandthestochastic
realisationproblem.
WhyrestrictourselvestoPIDcontrolwhenstochasticcontrolofintegratorchainsisavailable?
Itturnsoutthatwhensensorystatesst areexpressedasafunctionofanintegratorchain(4.3),
one may get away by controlling an approximation of the true (sensory) process, obtained by
truncatinghighordersofmotionasthesehavelesseffectonthedynamics,thoughknowingwhen
thisiswarrantedisaprobleminapproximationtheory.Thismayexplainwhyintegralfeedback
control(n=0),PIcontrol(n=1)andPIDcontrol(n=2)arethemostubiquitouscontrolmethods
inengineeringapplications.However,whensimulatingbiologicalcontrol—usuallywithhighly
non-linear dynamics—it is not uncommon to consider generalised motion to fourth (n=4) or
sixth(n=6)order[92,96].
It is worth mentioning that PID control has been shown to be implemented in simple
molecular systems and is becoming a popular mechanistic explanation of behaviours such as
bacterialchemotaxisandrobusthomeostaticalgorithmsinbiochemicalnetworks[77,97,98].We
17
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
suggest that this kind of behaviour emerges in Markov blankets at non-equilibrium steady-
state.Indeed,stationaritymeansthatautonomousstateswilllookasiftheyrespondadaptively
to external perturbations to preserve the steady-state, and we can identify these dynamics as
implementationsofvariousformsofstochasticcontrol(includingPID-likecontrol).
5 Discussion
In this paper, we considered the consequences of a boundary mediating interactions between
states internal and external to a system. On unpacking this notion, we found that the states
internaltoaMarkovblanketlookasiftheyperformvariationalBayesianinference,optimising
beliefsabouttheirexternalcounterparts.Whensubdividingtheblanketintosensoryandactive
states,wefoundthatautonomousstatesperformactiveinferenceandvariousformsofstochastic
control(i.e.,generalisationsofPIDcontrol).
InteractingMarkovblankets:Thesortofinferencewehavedescribedcouldbenuancedby
partitioning the external state-space into several systems that are themselves Markov blankets
(suchasMarkovblanketsnestedatseveraldifferentscales[1]).Fromtheperspectiveofinternal
states,thisleadstoamoreinterestinginferenceproblem,withamorecomplexgenerativemodel.
Itmaybethatthedistinctionbetweenthesortsofsystemswegenerallythinkofasengagingin
cognitive,inferential,dynamics[99]andsimplersystemsrestuponthelevelofstructureofthe
generativemodels(i.e.,steady-statedensities)thatdescribetheirinferentialdynamics.
Temporallydeepinference:Thisdistinctionmayspeaktoastraightforwardextensionofthe
treatmentonoffer,fromsimplyinferringanexternalstatetoinferringthetrajectoriesofexternal
states. This may be achieved by representing the external process in terms of its higher orders
ofmotionbysolvingthestochasticrealisationproblem.Byrepeatingtheanalysisabove,internal
statesmaybeseenasinferringtheposition,velocity,jerk,etcoftheexternalprocess,consistently
withtemporallydeepinferenceinthesenseofaBayesianfilter[91](aspecialcaseofwhichisan
extendedKalman–Bucyfilter[100]).
Bayesianmechanicsinnon-Gaussiansteady-states:Thetreatmentfromthispaperextends
easily to non-Gaussian steady-states, in which internal states appear to perform approximate
Bayesian inference over external states. Indeed, any arbitrary (smooth) steady-state density
may be approximated by a Gaussian density at one of its modes using a so-called Laplace
approximation. This Gaussian density affords one with a synchronisation map in closed form4
that maps the expected internal state to an approximation of the expected external state. It
followsthatthesystemcanbeseenasperformingapproximateBayesianinferenceoverexternal
states—precisely,aninferentialschemeknownasvariationalLaplace[101].Werefertheinterested
readertoaworked-outexampleinvolvingtwosparselycoupledLorenzsystems[30].Notethat
variational Laplace has been proposed as an implementation of various cognitive processes in
biological systems [25,52,60] accounting for several features of the brain’s functional anatomy
andneuralmessagepassing[53,70,99,102,103].
Modelling real systems: The simulations presented here are as simple as possible and are
intended to illustrate general principles that apply to all stationary processes with a Markov
blanket (3.1). These principles have been used to account for synthetic data arising in more
refined(andmorespecific)simulationsofaninteractingparticlesystem[27]andsynchronisation
betweentwosparselycoupledstochasticLorenzsystems[30].Clearly,anoutstandingchallenge
istoaccountforempiricaldataarisingfrommoreinterestingandcomplexstructures.Todothis,
onewouldhavetocollecttime-seriesfromanorganism’sinternalstates(e.g.,neuralactivity),its
surrounding external states, and its interface, including sensory receptors and actuators. Then,
one could test for conditional independence between internal, external and blanket states (3.1)
[104]. One might then test for the existence of a synchronisation map (using Lemma 2.1). This
speaks to modelling systemic dynamics using stochastic processes with a Markov blanket. For
example,one couldlearn thevolatility,solenoidal flowand steady-statedensityin astochastic
differentialequation(3.2)fromdata,usingsupervisedlearning[105].
4Anotheroptionistoempiricallyfitasynchronisationmaptodata[27].
18
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
6 Conclusion
This paper outlines some of the key relationships between stationary processes, inference and
control.Theserelationshipsrestuponpartitioningtheworldintothosethingsthatareinternalor
externaltoa(statistical)boundary,knownasaMarkovblanket.Whenequippedwithdynamics,
theexpectedinternalstatesappeartoengageinvariationalinference,whiletheexpectedactive
statesappeartobeperformingactiveinferenceandvariousformsofstochasticcontrol.
Therationalebehindthesefindingsisrathersimple:ifaMarkovblanketderivesfromasteady-
statedensity,thestatesofthesystemwilllookasiftheyarerespondingadaptivelytoexternal
perturbationsinordertorecoverthesteady-state.Conversely,well-knownmethodsusedtobuild
adaptivesystemsimplementthesamekindofdynamics,implicitlysothatthesystemmaintains
asteady-statewithitsenvironment.
Data Accessibility. All data and numerical simulations can be reproduced with code freely available at
https://github.com/conorheins/bayesian-mechanics-sdes.
Authors’Contributions. Conceptualization:LD,KF,CH,GAP;Formalanalysis:LD,KF,GAP;Software:
LD,CH;Supervision:KF,GAP;Writing–originaldraft:LD;Writing–review&editing:KF,CH,GAP.All
authorsgavefinalapprovalforpublicationandagreetobeheldaccountablefortheworkperformedtherein.
CompetingInterests. Wehavenocompetinginterests.
Funding. LDissupportedbytheFondsNationaldelaRecherche,Luxembourg(Projectcode:13568875).
This publication is based on work partially supported by the EPSRC Centre for Doctoral Training in
MathematicsofRandomSystems:Analysis,ModellingandSimulation(EP/S023925/1).KFwasaWellcome
Principal Research Fellow (Ref: 088130/Z/09/Z). CH is supported by the U.S. Office of Naval Research
(N00014-19-1-2556). The work of GAP was partially funded by the EPSRC, grant number EP/P031587/1,
andbyJPMorganChase&Co.Anyviewsoropinionsexpressedhereinaresolelythoseoftheauthorslisted,
andmaydifferfromtheviewsandopinionsexpressedbyJPMorganChase&Co.oritsaffiliates.Thismaterial
isnotaproductoftheResearchDepartmentofJ.P.MorganSecuritiesLLC.Thismaterialdoesnotconstitute
asolicitationorofferinanyjurisdiction.
Acknowledgements. LDwouldliketothankKaiUeltzhöffer,TobyStClereSmitheandThomasParrfor
interestingdiscussions.Wearegratefultoourtwoanonymousreviewersforfeedbackwhichsubstantially
improvedthemanuscript.
A Existence of synchronisation map: proof
WeproveLemma2.1.
Proof. (i) ⇐⇒ (ii)followsbydefinitionofafunction.
(ii) ⇐⇒ (iii)isasfollows
∀b ,b ∈B:µ(b )=µ(b )⇒η(b )=η(b )
1 2 1 2 1 2
(cid:16) (cid:17)
⇐⇒ ∀b ,b ∈B:Σ Σ−1b =Σ Σ−1b ⇒Σ Σ−1b =Σ Σ−1b
1 2 µb b 1 µb b 2 ηb b 1 ηb b 2
(cid:16) (cid:17)
⇐⇒ ∀b∈B:Σ Σ−1b=0⇒Σ Σ−1b=0
µb b ηb b
⇐⇒ kerΣ ⊂kerΣ
µb ηb
(iii) ⇐⇒ (iv) From [106, Section 0.7.3], using the Markov blanket condition (2.2), we can
verifythat
ΠµΣ
µb
=−Π
µb
Σ
b
ΠηΣ
ηb
=−Π
ηb
Σ
b
.
19
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
SinceΠµ,Πη,Σ bareinvertible,wededuce
kerΣ ⊂kerΣ
µb ηb
⇐⇒ kerΠµΣ
µb
⊂kerΠηΣ
ηb
⇐⇒ ker−Π Σ ⊂ker−Π Σ
µb b ηb b
⇐⇒ kerΠ ⊂kerΠ .
µb ηb
B The Helmholtz decomposition
Weconsideradiffusionprocessxt onRd satisfyinganItôstochasticdifferentialequation(SDE)
[39,107,108],
dxt=f(xt)dt+ς(xt)dWt, (A1)
where Wt is an m-dimensional standard Brownian motion (a.k.a., Wiener process) [38,39] and
f:Rd→Rd,ς:Rd→Rd×maresmoothfunctionssatisfyingforallx,y∈Rd:
• Bounded,lineargrowthcondition:|f(x)|+|ς(x)|≤K(1+|x|),
• Lipschitzcondition:|f(x)−f(y)|+|ς(x)−ς(y)|≤K|x−y|,
(cid:80) (cid:12) (cid:12)
forsomeconstantKand|ς|= ij(cid:12)ς ij(cid:12).Thesearestandardregularityconditionsthatensurethe
existenceanduniquenessofasolutiontotheSDE(A1)[108,Theorem5.2.1].
Wenowrecallanimportantresultfromthetheoryofstationarydiffusionprocesses,known
as the Helmholtz decomposition. It consists of splitting the dynamic into time-reversible (i.e.,
dissipative) and time-irreversible (i.e., conservative) components. The importance of this result
innon-equilibriumthermodynamicswasoriginallyrecognisedbyGrahamin1977[109]andhas
beenofgreatinterestinthefieldsince[39,110–112].Furthermore,theHelmholtzdecomposition
iswidelyusedinstatisticalmachinelearningtogenerateMonte-Carlosamplingschemes[39,73,
113–116].
LemmaB.1(Helmholtzdecomposition). Foradiffusionprocess(A1)andasmoothprobabilitydensity
p>0,thefollowingareequivalent:
(i) pisasteady-stateforxt.
(ii) Wecanwritethedriftas
f=f +f
rev irrev
f rev :=Γ∇logp+∇·Γ (A2)
f :=Q∇logp+∇·Q.
irrev
whereΓ =ςς(cid:62)/2isthediffusiontensorandQ=−Q(cid:62) isasmoothantisymmetricmatrixfield.
∇·denotesthedivergenceofamatrixfielddefinedas(∇·Q)
i
:= (cid:80)
j ∂
∂
xj
Q ij.
Furthermore,f revisinvariantundertime-reversal,whilef
irrev
changessignundertime-reversal.
In the Helmholtz decomposition of the drift (A2), the diffusion tensor Γ mediates the
dissipativeflow,whichflowstowardsthemodesofthesteady-statedensity,butiscounteracted
byrandomfluctuationsWt,sothatthesystem’sdistributionremainsunchanged—togetherthese
formthetime-reversiblepartofthedynamics.Incontrast,Qmediatesthesolenoidalflow—whose
direction is reversed under time-reversal—which consists of conservative (i.e., Hamiltonian)
dynamics that flow on the level sets of the steady-state. See Figure 11 for an illustration. Note
that the terms time-reversible and time-irreversible are meant in a probabilistic sense, in the
20
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
sensethattime-reversibilitydenotesinvarianceundertime-reversal.Thisisoppositetoreversible
and irreversible in a classical physics sense, which respectively mean energy preserving (i.e.,
conservative)andentropycreating(i.e.,dissipative).
Figure11.Helmholtzdecomposition.Theupperleftpanelshowsasampletrajectoryofatwo-dimensionaldiffusion
process(A1)onaheatmapofthe(Gaussian)steady-statedensity.TheupperrightpanelillustratestheHelmholtz
decompositionofthedriftintotime-reversibleandtime-irreversibleparts:thetime-reversiblepartofthedriftflowstowards
thepeakofthesteady-statedensity,whilethetime-irreversiblepartflowsalongthecontoursoftheprobabilitydistribution.
The lower panels plot sample paths of the time-reversible (lower left) and time-irreversible (lower right) parts of the
dynamics.Purelyconservativedynamics(lowerrightpanel)arereminiscentofthetrajectoriesofmassivebodies(e.g.,
planets) whose random fluctuations are negligible, as in Newtonian mechanics. The lower panels help illustrate the
meaningoftime-irreversibility:Ifweweretoreversetime(c.f.,(A3)),thetrajectoriesthetime-reversibleprocesswould
be,onaverage,nodifferent,whilethetrajectoriesofthetime-irreversibleprocesswouldflow,say,clockwiseinsteadof
counterclockwise,whichwouldclearlybedistinguishable.Here,thefullprocess(upperleftpanel)isacombinationofboth
dynamics.Aswecanseethetime-reversiblepartaffordsthestochasticitywhilethetime-irreversiblepartcharacterises
non-equilibriaandtheaccompanyingwanderingbehaviourthatcharacteriseslife-likesystems[11,117].
Proof. "⇒" Itiswell-knownthatwhenxtisstationaryatp,itstime-reversalisalsoadiffusion
processthatsolvesthefollowingItôSDE[118]
dx−
t
=f−(x−
t
)dt+ς(x−
t
)dWt
(A3)
f−:=−b+p−1∇·(2Γp).
Thisenablesustowritethedriftfasasumoftwoterms:onethatisinvariantundertime
reversal,anotherthatchangessignundertime-reversal
f +f− f −f−
f= + =:f +f .
2 2 rev irrev
21
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
Itisstraightforwardtoidentifythetime-reversibleterm
f rev =p−1∇·(Γp)=p−1Γ∇p+p−1p∇·Γ =Γ∇logp+∇·Γ. (A4)
Fortheremainingterm,wefirstnotethatthesteady-statepsolvesthestationaryFokker-
Planckequation[39,119]
∇·(−fp+∇·(Γp))=0.
Decomposingthedriftintotime-reversibleandtime-irreversibleparts,weobtainthatthe
time-irreversiblepartproducesdivergence-free(i.e.,conservative)floww.r.t.thesteady-
statedistribution
∇·(f p)=0.
irrev
Nowrecallthatany(smooth)divergence-freevectorfieldisthedivergenceofa(smooth)
antisymmetricmatrixfieldA=−AT [109,110,120]
f p=∇·A.
irrev
WedefineanewantisymmetricmatrixfieldQ:=p−1A.Itfollowsfromtheproductrule
fordivergencesthatwecanrewritethetime-irreversibledriftasrequired
f =Q∇logp+∇·Q.
irrev
"⇐" From(A4)wecanrewritethetime-reversiblepartofthedriftas
f rev =p−1∇·(Γp). (A5)
In addition, we define the auxiliary antisymmetric matrix field A:=pQ and use the
productrulefordivergencestosimplifytheexpressionofthetime-irreversiblepart
f =p−1∇·A.
irrev
Notethat
∇·(f p)=0
irrev
asthematrixfieldAissmoothandantisymmetric.Itfollowsthatthedistributionpsolves
thestationaryFokker-Planckequation
∇·(−fp+∇·(Γp))=∇·(−f p−f p+∇·(Γp))=∇·(−f p)=0.
rev irrev irrev
C Free energy computations
Thefreeenergyreads(3.6)
F(b,µ)=D
KL
[qµ(η)(cid:107)p(η|b)]−logp(b,µ).
Recalling from (2.3), (3.3) that qµ(η) and p(η|b) are Gaussian, the KL divergence between
multivariateGaussiansiswell-known
qµ(η)=N(η;σ(µ),Π
η
−1), p(η|b)=N(η;η(b),Π
η
−1),
1
⇒D
KL
[qµ(η)(cid:107)p(η|b)]=
2
(σ(µ)−η(b))Πη(σ(µ)−η(b)).
Furthermore,wecancomputethelogpartition
(cid:34) (cid:35)
1(cid:104) (cid:105) b
−logp(b,µ)= b,µ Σ−1 (uptoaconstant).
2 b:µ µ
22
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
NotethatΣ
b
−
:µ
1 istheinverseofaprincipalsubmatrixofΣ,whichingeneraldiffersfromΠ b:µ,a
principalsubmatrixofΠ.Finally,
(cid:34) (cid:35) 1 1(cid:104) (cid:105) b
F(b,µ)=
2
(σ(µ)−η(b))Πη(σ(µ)−η(b))+
2
b,µ Σ
b
−
:µ
1
µ
(uptoaconstant).
References
1. CasperHesp,MaxwellRamstead,AxelConstant,PaulBadcock,MichaelKirchhoff,andKarl
Friston.
AMulti-scaleViewoftheEmergentComplexityofLife:AFree-EnergyProposal.
In Georgi Yordanov Georgiev, John M. Smart, Claudio L. Flores Martinez, and Michael E.
Price, editors, Evolution, Development and Complexity, Springer Proceedings in Complexity,
pages195–227,Cham,2019.SpringerInternationalPublishing.
2. MichaelKirchhoff,ThomasParr,EnsorPalacios,KarlFriston,andJulianKiverstein.
TheMarkovblanketsoflife:Autonomy,activeinferenceandthefreeenergyprinciple.
JournalofTheRoyalSocietyInterface,15(138):20170792,January2018.
3. JudeaPearl.
GraphicalModelsforProbabilisticandCausalReasoning.
InPhilippeSmets,editor,QuantifiedRepresentationofUncertaintyandImprecision,Handbook
of Defeasible Reasoning and Uncertainty Management Systems, pages 367–389. Springer
Netherlands,Dordrecht,1998.
4. ChristopherM.Bishop.
PatternRecognitionandMachineLearning.
InformationScienceandStatistics.Springer,NewYork,2006.
5. G.NicolisandI.Prigogine.
Self-Organization in Nonequilibrium Systems: From Dissipative Structures to Order Through
Fluctuations.
Wiley-Blackwell,NewYork,June1977.
6. AlbertGoldbeter.
Dissipative structures in biological systems: Bistability, oscillations, spatial patterns and
waves.
PhilosophicalTransactionsoftheRoyalSocietyA:Mathematical,PhysicalandEngineeringSciences,
376(2124):20170376,July2018.
7. HermannHaken.
Synergetics:AnIntroductionNonequilibriumPhaseTransitionsandSelf-OrganizationinPhysics,
ChemistryandBiology.
SpringerSeriesinSynergetics.Springer-Verlag,BerlinHeidelberg,secondedition,1978.
8. NikolayPerunov,RobertA.Marsland,andJeremyL.England.
StatisticalPhysicsofAdaptation.
PhysicalReviewX,6(2):021036,June2016.
9. KateJeffery,RobertPollack,andCarloRovelli.
Onthestatisticalmechanicsoflife:Schr\"odingerrevisited.
arXiv:1908.08374[physics],August2019.
10. JeremyL.England.
Statisticalphysicsofself-replication.
TheJournalofChemicalPhysics,139(12):121923,August2013.
11. DominicJ.SkinnerandJörnDunkel.
Improvedboundsonentropyproductioninlivingsystems.
ProceedingsoftheNationalAcademyofSciences,118(18),May2021.
12. BenjaminDunnandYasserRoudi.
LearningandinferenceinanonequilibriumIsingmodelwithhiddennodes.
PhysicalReviewE,87(2):022127,February2013.
13. SusanneStill.
ThermodynamicCostandBenefitofMemory.
PhysicalReviewLetters,124(5):050601,February2020.
14. SusanneStill,DavidA.Sivak,AnthonyJ.Bell,andGavinE.Crooks.
23
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
ThermodynamicsofPrediction.
PhysicalReviewLetters,109(12):120604,September2012.
15. KaiUeltzhöffer.
Onthethermodynamicsofpredictionunderdissipativeadaptation.
arXiv:2009.04006[cond-mat,q-bio],September2020.
16. GülceKardes¸andDavidH.Wolpert.
ThermodynamicUncertaintyRelationsforMultipartiteProcesses.
arXiv:2101.01610[cond-mat],March2021.
17. DavidH.Wolpert.
Minimalentropyproductionrateofinteractingsystems.
NewJournalofPhysics,22(11):113013,November2020.
18. DavidH.Wolpert.
UncertaintyRelationsandFluctuationTheoremsforBayesNets.
PhysicalReviewLetters,125(20):200602,November2020.
19. GavinE.CrooksandSusanneStill.
Marginalandconditionalsecondlawsofthermodynamics.
EPL(EurophysicsLetters),125(4):40005,March2019.
20. JordanM.HorowitzandMassimilianoEsposito.
ThermodynamicswithContinuousInformationFlow.
PhysicalReviewX,4(3):031015,July2014.
21. AlexandrePouget,PeterDayan,andRichardS.Zemel.
Inferenceandcomputationwithpopulationcodes.
AnnualReviewofNeuroscience,26(1):381–410,March2003.
22. DavidC.KnillandAlexandrePouget.
TheBayesianbrain:Theroleofuncertaintyinneuralcodingandcomputation.
TrendsinNeurosciences,27(12):712–719,December2004.
23. KarlFriston.
Thefree-energyprinciple:Aunifiedbraintheory?
NatureReviewsNeuroscience,11(2):127–138,February2010.
24. RajeshP.N.RaoandDanaH.Ballard.
Predictive coding in the visual cortex: A functional interpretation of some extra-classical
receptive-fieldeffects.
NatureNeuroscience,2(1):79–87,January1999.
25. KarlJ.Friston,JeanDaunizeau,JamesKilner,andStefanJ.Kiebel.
Actionandbehavior:Afree-energyformulation.
BiologicalCybernetics,102(3):227–260,March2010.
26. Karl J. Friston, Erik D. Fagerholm, Tahereh S. Zarghami, Thomas Parr, Inês Hipólito, Loïc
Magrou,andAdeelRazi.
Parcelsandparticles:Markovblanketsinthebrain.
arXiv:2007.09704[q-bio],July2020.
27. KarlFriston.
Lifeasweknowit.
JournalofTheRoyalSocietyInterface,10(86):20130475,September2013.
28. ThomasParr,LancelotDaCosta,andKarlFriston.
Markovblankets,informationgeometryandstochasticthermodynamics.
PhilosophicalTransactionsoftheRoyalSocietyA:Mathematical,PhysicalandEngineeringSciences,
378(2164):20190159,February2020.
29. KarlFriston.
Afreeenergyprincipleforaparticularphysics.
arXiv:1906.10184[q-bio],June2019.
30. KarlFriston,ConorHeins,KaiUeltzhöffer,LancelotDaCosta,andThomasParr.
StochasticChaosandMarkovBlankets.
Entropy,23(9):1220,September2021.
31. MartinJ.WainwrightandMichaelI.Jordan.
GraphicalModels,ExponentialFamilies,andVariationalInference.
FoundationsandTrends®inMachineLearning,1(1–2):1–305,2007.
32. MorrisL.Eaton.
MultivariateStatistics:AVectorSpaceApproach.
InstituteofMathematicalStatistics,2007.
24
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
33. ThomasParr.
TheComputationalNeurologyofActiveVision.
Ph.D.Thesis,UniversityCollegeLondon,London,2019.
34. MarkusMeisterandMichaelJ.Berry.
TheNeuralCodeoftheRetina.
Neuron,22(3):435–450,March1999.
35. M.James.
Thegeneralisedinverse.
TheMathematicalGazette,62(420):109–114,June1978.
36. MiguelAguilera,BerenMillidge,AlexanderTschantz,andChristopherL.Buckley.
HowparticularisthephysicsoftheFreeEnergyPrinciple?
arXiv:2105.11203[q-bio],May2021.
37. JonathanC.Mattingly,AndrewM.Stuart,andM.V.Tretyakov.
ConvergenceofNumericalTime-AveragingandStationaryMeasuresviaPoissonEquations.
SIAMJournalonNumericalAnalysis,48(2):552–577,January2010.
38. L.C.G.RogersandDavidWilliams.
Diffusions, Markov Processes, and Martingales: Volume 1: Foundations, volume 1 of Cambridge
MathematicalLibrary.
CambridgeUniversityPress,Cambridge,secondedition,2000.
39. GrigoriosA.Pavliotis.
Stochastic Processes and Applications: Diffusion Processes, the Fokker-Planck and Langevin
Equations.
Numbervolume60inTextsinAppliedMathematics.Springer,NewYork,2014.
40. JorisBierkens,PaulFearnhead,andGarethRoberts.
TheZig-Zagprocessandsuper-efficientsamplingforBayesiananalysisofbigdata.
TheAnnalsofStatistics,47(3):1288–1320,June2019.
41. JorisBierkensandGarethRoberts.
A piecewise deterministic scaling limit of lifted Metropolis–Hastings in the Curie–Weiss
model.
TheAnnalsofAppliedProbability,27(2):846–882,April2017.
42. AlexandreBouchard-Côté,SebastianJ.Vollmer,andArnaudDoucet.
The Bouncy Particle Sampler: A Nonreversible Rejection-Free Markov Chain Monte Carlo
Method.
JournaloftheAmericanStatisticalAssociation,113(522):855–867,April2018.
43. CarlEdwardRasmussen.
GaussianProcessesinMachineLearning.
InOlivierBousquet,UlrikevonLuxburg,andGunnarRätsch,editors,AdvancedLectureson
MachineLearning:MLSummerSchools2003,Canberra,Australia,February2-14,2003,Tübingen,
Germany, August 4 - 16, 2003, Revised Lectures, Lecture Notes in Computer Science, pages
63–71.Springer,Berlin,Heidelberg,2004.
44. LudwigArnold.
RandomDynamicalSystems.
SpringerMonographsinMathematics.Springer-Verlag,BerlinHeidelberg,1998.
45. MartinBiehl,FelixA.Pollock,andRyotaKanai.
ATechnicalCritiqueofSomePartsoftheFreeEnergyPrinciple.
Entropy,23(3):293,March2021.
46. KarlJ.Friston,LancelotDaCosta,andThomasParr.
SomeInterestingObservationsontheFreeEnergyPrinciple.
Entropy,23(8):1076,August2021.
47. HaiderHasanJafri,R.K.BrojenSingh,andRamakrishnaRamaswamy.
Generalizedsynchronyofcoupledstochasticprocesseswithmultiplicativenoise.
PhysicalReviewE,94(5):052216,November2016.
48. D.CuminandC.P.Unsworth.
GeneralisingtheKuramotomodelforthestudyofneuronalsynchronisationinthebrain.
PhysicaD:NonlinearPhenomena,226(2):181–196,February2007.
49. EnsorRafaelPalacios,TakuyaIsomura,ThomasParr,andKarlFriston.
Theemergenceofsynchronyinnetworksofmutuallyinferringneurons.
ScientificReports,9(1):6412,April2019.
25
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
50. StephenD.Bartlett,TerryRudolph,andRobertW.Spekkens.
ReconstructionofGaussianquantummechanicsfromLiouvillemechanicswithanepistemic
restriction.
PhysicalReviewA,86(1):012103,July2012.
51. S.KullbackandR.A.Leibler.
OnInformationandSufficiency.
TheAnnalsofMathematicalStatistics,22(1):79–86,March1951.
52. RafalBogacz.
Atutorialonthefree-energyframeworkformodellingperceptionandlearning.
JournalofMathematicalPsychology,76:198–211,February2017.
53. KarlFristonandStefanKiebel.
Predictivecodingunderthefree-energyprinciple.
PhilosophicalTransactionsoftheRoyalSocietyB:BiologicalSciences,364(1521):1211–1221,May
2009.
54. ZenasC.Chao,KanaTakaura,LipingWang,NaotakaFujii,andStanislasDehaene.
Large-Scale Cortical Networks for Hierarchical Prediction and Prediction Error in the
PrimateBrain.
Neuron,100(5):1252–1266.e3,May2018.
55. Sandra Iglesias, Christoph Mathys, Kay H. Brodersen, Lars Kasper, Marco Piccirelli,
HannekeE.M.denOuden,andKlaasE.Stephan.
HierarchicalPredictionErrorsinMidbrainandBasalForebrainduringSensoryLearning.
Neuron,80(2):519–530,October2013.
56. NathanielD.Daw,SamuelJ.Gershman,BenSeymour,PeterDayan,andRaymondJ.Dolan.
Model-BasedInfluencesonHumans’ChoicesandStriatalPredictionErrors.
Neuron,69(6):1204–1215,March2011.
57. MichelaOttobre.
MarkovChainMonteCarloandIrreversibility.
ReportsonMathematicalPhysics,77:267–292,June2016.
58. LucRey-BelletandKostantinosSpiliopoulos.
IrreversibleLangevinsamplersandvariancereduction:Alargedeviationapproach.
Nonlinearity,28(7):2081–2103,July2015.
59. DavidM.Blei,AlpKucukelbir,andJonD.McAuliffe.
VariationalInference:AReviewforStatisticians.
JournaloftheAmericanStatisticalAssociation,112(518):859–877,April2017.
60. ChristopherL.Buckley,ChangSubKim,SimonMcGregor,andAnilK.Seth.
Thefreeenergyprincipleforactionandperception:Amathematicalreview.
JournalofMathematicalPsychology,81:55–79,December2017.
61. MatthewJamesBeal.
VariationalAlgorithmsforApproximateBayesianInference.
Ph.D.Thesis,UniversityofLondon,2003.
62. OdeliaSchwartz,JonathanW.Pillow,NicoleC.Rust,andEeroP.Simoncelli.
Spike-triggeredneuralcharacterization.
JournalofVision,6(4):484–507,July2006.
63. R.J.Sayer,M.J.Friedlander,andS.J.Redman.
The time course and amplitude of EPSPs evoked at synapses between pairs of CA3/CA1
neuronsinthehippocampalslice.
The Journal of Neuroscience: The Official Journal of the Society for Neuroscience, 10(3):826–836,
March1990.
64. StevenJ.Luck.
AnIntroductiontotheEvent-RelatedPotentialTechnique.
ABradfordBook,Cambridge,MA,USA,secondedition,May2014.
65. KaiUeltzhöffer.
DeepActiveInference.
BiologicalCybernetics,112(6):547–573,December2018.
66. BerenMillidge.
Deepactiveinferenceasvariationalpolicygradients.
JournalofMathematicalPsychology,96:102348,June2020.
67. R. Conor Heins, M. Berk Mirza, Thomas Parr, Karl Friston, Igor Kagan, and Arezoo
Pooresmaeili.
26
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
DeepActiveInferenceandSceneConstruction.
FrontiersinArtificialIntelligence,3:81,2020.
68. PabloLanillos,JordiPages,andGordonCheng.
Robotself/otherdistinction:Activeinferencemeetsneuralnetworkslearninginamirror.
InEuropeanConferenceonArtificialIntelligence.IOSpress,April2020.
69. TimVerbelen,PabloLanillos,ChristopherBuckley,andCedricDeBoom,editors.
Active Inference: First International Workshop, IWAI 2020, Co-Located with ECML/PKDD 2020,
Ghent,Belgium,September14,2020,Proceedings.
CommunicationsinComputerandInformationScience.SpringerInternationalPublishing,
2020.
70. RickA.Adams,StewartShipp,andKarlJ.Friston.
Predictionsnotcommands:Activeinferenceinthemotorsystem.
BrainStructure&Function,218(3):611–643,May2013.
71. CorradoPezzato,RiccardoFerrari,andCarlosHernándezCorbato.
ANovelAdaptiveControllerforRobotManipulatorsBasedonActiveInference.
IEEERoboticsandAutomationLetters,5(2):2973–2980,April2020.
72. GuillermoOliver,PabloLanillos,andGordonCheng.
Anempiricalstudyofactiveinferenceonahumanoidrobot.
IEEETransactionsonCognitiveandDevelopmentalSystems,pages1–1,2021.
73. TonyLelièvre,FrancisNier,andGrigoriosA.Pavliotis.
Optimalnon-reversiblelineardriftfortheconvergencetoequilibriumofadiffusion.
JournalofStatisticalPhysics,152(2):237–274,July2013.
74. MagnusT.KoudahlandBertdeVries.
AWorkedExampleofFokker-Planck-BasedActiveInference.
InTimVerbelen,PabloLanillos,ChristopherL.Buckley,andCedricDeBoom,editors,Active
Inference,CommunicationsinComputerandInformationScience,pages28–34,Cham,2020.
SpringerInternationalPublishing.
75. KarlFriston.
WhatIsOptimalaboutMotorControl?
Neuron,72(3):488–498,November2011.
76. CansuSancaktar,MarcelvanGerven,andPabloLanillos.
End-to-EndPixel-BasedDeepActiveInferenceforBodyPerceptionandAction.
arXiv:2001.05847[cs,q-bio],May2020.
77. ManuelBaltieriandChristopherL.Buckley.
PIDControlasaProcessofActiveInferencewithLinearGenerativeModels.
Entropy,21(3):257,March2019.
78. RobertJKosinski.
Aliteraturereviewonreactiontime.
ClemsonUniversity,10(1),2008.
79. TonyRoskillyandDrRikardMikalsen.
MarineSystemsIdentification,ModelingandControl.
Butterworth-Heinemann,Amsterdam;Boston,illustratededitionedition,March2015.
80. KarlJohanÅström.
PidControllers.
InternationalSocietyforMeasurementandControl,January1995.
81. SanjoyMitter,GiorgioPicci,andAndersLindquist.
Towardatheoryofnonlinearstochasticrealization.
InFeedbackandSynthesisofLinearandNonlinearSystems,1981.
82. AndersLindquistandGiorgioPicci.
LinearStochasticSystems:AGeometricApproachtoModeling,EstimationandIdentification.
SeriesinContemporaryMathematics.Springer-Verlag,BerlinHeidelberg,2015.
83. AndersLindquistandGiorgioPicci.
RealizationTheoryforMultivariateStationaryGaussianProcesses.
SIAMJournalonControlandOptimization,23(6):809–857,November1985.
84. J.L.Doob.
TheBrownianMovementandStochasticEquations.
AnnalsofMathematics,43(2):351–369,1942.
85. MingChenWangandG.E.Uhlenbeck.
27
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
OntheTheoryoftheBrownianMotionII.
InSelectedPapersonNoiseandStochasticProcesses.Dover,2014.
86. LucRey-Bellet.
OpenClassicalSystems.
In Stéphane Attal, Alain Joye, and Claude-Alain Pillet, editors, Open Quantum Systems
II: The Markovian Approach, Lecture Notes in Mathematics, pages 41–78. Springer, Berlin,
Heidelberg,2006.
87. MikhailKryachkov,AndreyPolyakov,andVadimStrygin.
Finite-timestabilizationofanintegratorchainusingonlysignsofthestatevariables.
In201011thInternationalWorkshoponVariableStructureSystems(VSS),pages510–515,June
2010.
88. KonstantinZimenko,AndreyPolyakov,DenisEfimo,andWilfridPerruquetti.
Finite-timeandfixed-timestabilizationforintegratorchainofarbitraryorder*.
In2018EuropeanControlConference(ECC),pages1631–1635,June2018.
89. K.J.Friston.
Variationalfiltering.
NeuroImage,41(3):747–766,July2008.
90. K.J.Friston,N.Trujillo-Barreto,andJ.Daunizeau.
DEM:Avariationaltreatmentofdynamicsystems.
NeuroImage,41(3):849–885,July2008.
91. KarlFriston,KlaasStephan,BaojuanLi,andJeanDaunizeau.
GeneralisedFiltering.
MathematicalProblemsinEngineering,2010:1–34,2010.
92. ThomasParr,JakubLimanowski,VishalRawji,andKarlFriston.
Thecomputationalneurologyofmovementunderactiveinference.
Brain,(awab085),March2021.
93. S.N.Gomes,G.A.Pavliotis,andU.Vaes.
Mean Field Limits for Interacting Diffusions with Colored Noise: Phase Transitions and
SpectralNumericalMethods.
MultiscaleModeling&Simulation,18(3):1343–1370,January2020.
94. T.J.S.TayorandM.Pavon.
Onthenonlinearstochasticrealizationproblem.
StochasticsandStochasticReports,26(2):65–79,February1989.
95. A.E.Frazho.
Onstochasticrealizationtheory.
Stochastics,7(1-2):1–27,January1982.
96. KarlJ.Friston,ThomasParr,andBertdeVries.
Thegraphicalbrain:Beliefpropagationandactiveinference.
NetworkNeuroscience,1(4):381–414,December2017.
97. MichaelChevalier,MarianaGómez-Schiavon,AndrewH.Ng,andHanaEl-Samad.
Design and Analysis of a Proportional-Integral-Derivative Controller with Biological
Molecules.
CellSystems,9(4):338–353.e10,October2019.
98. Tau-MuYi,YunHuang,MelvinI.Simon,andJohnDoyle.
Robustperfectadaptationinbacterialchemotaxisthroughintegralfeedbackcontrol.
ProceedingsoftheNationalAcademyofSciences,97(9):4649–4653,April2000.
99. KarlFriston.
HierarchicalModelsintheBrain.
PLoSComputationalBiology,4(11):e1000211,November2008.
100. R.E.Kalman.
ANewApproachtoLinearFilteringandPredictionProblems.
JournalofBasicEngineering,82(1):35–45,March1960.
101. KarlFriston,JérémieMattout,NelsonTrujillo-Barreto,JohnAshburner,andWillPenny.
VariationalfreeenergyandtheLaplaceapproximation.
NeuroImage,34(1):220–234,January2007.
102. KarlFriston.
Atheoryofcorticalresponses.
Philosophical Transactions of the Royal Society B: Biological Sciences, 360(1456):815–836, April
2005.
28
.......................................................... rspa.royalsocietypublishing.org
ProcRSocA0000000
103. GiovanniPezzulo.
AnActiveInferenceviewofcognitivecontrol.
FrontiersinPsychology,3,2012.
104. Jean-PhilippePelletandAndréElisseeff.
UsingMarkovBlanketsforCausalStructureLearning.
JournalofMachineLearningResearch,9(43):1295–1342,2008.
105. BelindaTzenandM.Raginsky.
Neural Stochastic Differential Equations: Deep Latent Gaussian Models in the Diffusion
Limit.
ArXiv,2019.
106. RogerA.Horn.
MatrixAnalysis:SecondEdition.
CambridgeUniversityPress,NewYork,NY,2ndeditionedition,December2012.
107. L.C.G.RogersandDavidWilliams.
Diffusions, Markov Processes and Martingales: Volume 2: Itô Calculus, volume 2 of Cambridge
MathematicalLibrary.
CambridgeUniversityPress,Cambridge,secondedition,2000.
108. BerntØksendal.
StochasticDifferentialEquations:AnIntroductionwithApplications.
Universitext.Springer-Verlag,BerlinHeidelberg,sixthedition,2003.
109. RobertGraham.
Covariantformulationofnon-equilibriumstatisticalthermodynamics.
ZeitschriftfürPhysikBCondensedMatter,26(4):397–405,December1977.
110. GregoryL.Eyink,JoelL.Lebowitz,andHerbertSpohn.
Hydrodynamicsandfluctuationsoutsideoflocalequilibrium:Drivendiffusivesystems.
JournalofStatisticalPhysics,83(3):385–472,May1996.
111. P.Ao.
Potentialinstochasticdifferentialequations:Novelconstruction.
JournalofPhysicsA:MathematicalandGeneral,37(3):L25–L30,January2004.
112. HongQian.
Adecompositionofirreversiblediffusionprocesseswithoutdetailedbalance.
JournalofMathematicalPhysics,54(5):053302,May2013.
113. Yi-AnMa,TianqiChen,andEmilyB.Fox.
ACompleteRecipeforStochasticGradientMCMC.
arXiv:1506.04696[math,stat],October2015.
114. AlessandroBarp,SoTakao,MichaelBetancourt,AlexisArnaudon,andMarkGirolami.
AUnifyingandCanonicalDescriptionofMeasure-PreservingDiffusions.
arXiv:2105.02845[math,stat],May2021.
115. PratikChaudhariandStefanoSoatto.
Stochasticgradientdescentperformsvariationalinference,convergestolimitcyclesfordeep
networks.
InInternationalConferenceonLearningRepresentations,February2018.
116. XiaowuDaiandYuhuaZhu.
OnLargeBatchTrainingandSharpMinima:AFokker–PlanckPerspective.
JournalofStatisticalTheoryandPractice,14(3):53,July2020.
117. IchiroAoki.
Entropyproductioninlivingsystems:Fromorganismstoecosystems.
ThermochimicaActa,250(2):359–370,February1995.
118. U.G.HaussmannandE.Pardoux.
TimeReversalofDiffusions.
AnnalsofProbability,14(4):1188–1205,October1986.
119. HannesRiskenandTillFrank.
TheFokker-PlanckEquation:MethodsofSolutionandApplications.
SpringerSeriesinSynergetics.Springer-Verlag,BerlinHeidelberg,secondedition,1996.
120. Realanalysis-Everydivergence-freevectorfieldgeneratedfromskew-symmetricmatrix.
https://math.stackexchange.com/questions/578898/every-divergence-free-vector-field-
generated-from-skew-symmetric-matrix.

=== REVISE TO ===
PROFESSIONAL TONE: Begin directly with content - NO conversational openings like 'Okay, here's...'

1. Fix all issues above
2. Title: "Bayesian Mechanics for Stationary Processes"
3. Include 10-15 quotes from paper text
   - Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
   - Use consistent quote formatting: 'The authors state: "quote"' or vary attribution phrases
   - Vary attribution phrases to avoid repetition
   - CRITICAL: Only extract quotes that actually appear in the paper text
4. ELIMINATE ALL REPETITION - each sentence must be unique
   - Check before each sentence: 'Have I already said this?' If yes, write something new
   - Vary attribution phrases - do NOT repeat 'The authors state' multiple times
5. Extract methodology, results with numbers, key quotes
6. 1000-1500 words, structured with ### headers

Generate COMPLETE revised summary.