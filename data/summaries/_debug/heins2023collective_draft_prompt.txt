=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Collective behavior from surprise minimization
Citation Key: heins2023collective
Authors: Conor Heins, Beren Millidge, Lancelot da Costa

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Abstract: Collective motion is ubiquitous in nature; groups of animals, such as fish, birds,
and ungulates appear to move as a whole, exhibiting a rich behavioral repertoire that
ranges from directed movement to milling to disordered swarming. Typically, such
macroscopic patterns arise from decentralized, local interactions among constituent
components (e.g., individual fish in a school). Preeminent models of this process de-
scribeindividualsasself-propelledparticles,subjecttoself-generatedmotionand‘soci...

Key Terms: surprise, konstanz, collective, university, mathematics, research, minimization, london, behavior, behaviour

=== FULL PAPER TEXT ===

Collective behavior from surprise minimization
Conor Heins∗a,b,c,e, Beren Millidged, Lancelot Da Costae,f,g, Richard P. Mannh,
Karl Fristone,g, and Iain D. Couzin†a,b,c
aDepartment of Collective Behaviour, Max Planck Institute of Animal Behavior, Konstanz D-78457, Germany
bCentre for the Advanced Study of Collective Behaviour, University of Konstanz, Konstanz D-78457, Germany
cDepartment of Biology, University of Konstanz, Konstanz D-78457, Germany
dMedical Research Council Brain Networks Dynamics Unit, University of Oxford, Oxford OX1 3TH, UK
eVERSES Research Lab, Los Angeles, CA 90016, USA
fDepartment of Mathematics, Imperial College London, London SW7 2AZ, UK
gWellcome Centre for Human Neuroimaging, University College London, London, WC1N 3AR, UK
hDepartment of Statistics, School of Mathematics, University of Leeds, Leeds, LS2 9JT, UK
Abstract
Collective motion is ubiquitous in nature; groups of animals, such as fish, birds,
and ungulates appear to move as a whole, exhibiting a rich behavioral repertoire that
ranges from directed movement to milling to disordered swarming. Typically, such
macroscopic patterns arise from decentralized, local interactions among constituent
components (e.g., individual fish in a school). Preeminent models of this process de-
scribeindividualsasself-propelledparticles,subjecttoself-generatedmotionand‘social
forces’ such as short-range repulsion and long-range attraction or alignment. However,
organisms are not particles; they are probabilistic decision-makers. Here, we introduce
an approach to modelling collective behavior based on active inference. This cognitive
framework casts behavior as the consequence of a single imperative: to minimize sur-
prise. Wedemonstratethatmanyempirically-observedcollectivephenomena,including
cohesion, milling and directed motion, emerge naturally when considering behavior as
driven by active Bayesian inference — without explicitly building behavioral rules or
goals into individual agents. Furthermore, we show that active inference can recover
and generalize the classical notion of social forces as agents attempt to suppress predic-
tion errors that conflict with their expectations. By exploring the parameter space of
the belief-based model, we reveal non-trivial relationships between the individual be-
liefs and group properties like polarization and the tendency to visit different collective
states. We also explore how individual beliefs about uncertainty determine collective
decision-making accuracy. Finally, we show how agents can update their generative
model over time, resulting in groups that are collectively more sensitive to external
fluctuations and encode information more robustly.
∗cheins@ab.mpg.de
†icouzin@ab.mpg.de
1
4202
yaM
41
]OA.niln[
4v40841.7032:viXra
Significance Statement
We introduce a model of collective behavior, proposing that individual members within a
group, such as a school of fish or a flock of birds, act to minimize surprise. This active
inference approach naturally generates well-known collective phenomena such as cohesion
and directed movement without explicit behavioral rules. Our model reveals intricate rela-
tionships between individual beliefs and group properties, demonstrating that beliefs about
uncertainty can shape collective decision-making accuracy. As agents update their genera-
tive model in real-time, groups become more sensitive to external perturbations and more
robust in encoding information. Our work provides fresh insights into understanding collec-
tive dynamics and could inspire strategies in the study of animal behavior, swarm robotics
and distributed systems.
Introduction
The principles underlying coordinated group behaviors in animals have inspired research in
disciplines ranging from zoology to engineering to physics [1–3]. Collective motion in partic-
ular has been a popular phenomenon to study, due in part to its striking visual manifestation
and ubiquity (e.g., swarming locusts, schooling fish, flocking birds and herding ungulates),
and in part to the simplicity of models that can reproduce many of its qualitative features;
like cohesive, directed movement [4–7]. Because of this, collective motion is often cited as a
canonical example of a self-organizing complex system, wherein collective properties emerge
from simple interactions among distributed components.
Popular theoretical models cast collective motion as groups composed of self-propelled
particles (SPPs) that influence one another via simple ‘social forces.’ Early models like the
Vicsek model [6] consider only a simple alignment interaction, where each particle aligns
its direction of travel with the average heading of its neighbors. While oversimplifying
the biological mechanisms in play, SPP models — like the Vicsek model — are useful for
their amenability to formal understanding, e.g., the computation of universal quantities and
relations through hydrodynamic and mean-field limits [8–11].
Recent research has shifted towards more biologically-motivated approaches that aim to
model the specific behavioral circuits and decision-rules that govern individual behaviors
[12–15]. While these models are less analytically-tractable than SPP models, they are more
appealingtodomainspecialistslikebiologists, astheycangeneratepredictionsaboutsensory
features in an individual’s environment that are necessary and sufficient for evoking behav-
ior. Furthermore, these predictions can be tested experimentally [14, 16]. This data-driven
approach can thus provide mechanistic insights into the biological and cognitive origins of
decision-making [13, 17].
In this work, we propose a model class that blends the first-principles, theoretical ap-
proach of physical models with biological-plausibility, resulting in an ecologically-valid but
theoretically-grounded agent-based model of collective behavior. Our model class is based
on active inference, a framework for designing and describing adaptive systems where all
2
aspects of cognition — learning, planning, perception, and action — are viewed as a process
of inference [18–21]. Active inference originated in theoretical neuroscience as a normative
account of self-organizing, biological systems as constantly engaged in predictive exchanges
with their sensory environments [22–25].
Collective motion models: from self-propelled particles to
Bayesian agents
In popular self-propelled particle models, an individual’s movement is described as driven
by a combination of social and environmental forces. These forces are often treated as
vectorsthatcapturevarioustendenciesseeninbiologicalcollectivemotion, suchasrepulsion,
attraction (to neighbors or external targets), and alignment. These forces can then be
combined with various nonlinearities and weights to capture mechanisms of interaction.
In contrast, the active inference approach forgoes specifying explicit vectorial forces, and
instead starts by modelling all behavior as the solution to an inference problem, namely
the problem of inferring the latent causes of sensations. Perception and action strive to
improve the agent’s predictions of sensory inputs, based on its internal model of its world
(see Figure 1A). By equipping this internal model with expectations about the environment’s
underlying tendencies, ‘social forces’ can emerge naturally as agents attempt to suppress
sensory data that are mismatched with their expectations. This perspective-shift offers a
unifying modelling ontology for describing adaptive behavior, while also resonating with
cybernetic principles like homeostatic regulation and process theories of neural function like
predictive coding [26–29].
Active inference blends the construct validity of cognitivist approaches with the first-
principles elegance of physics-based approaches by invoking minimization of a single, all-
encompassing objective function that explains behavior: surprise, or, under certain assump-
tions, prediction error. As an example of this perspective shift, in this work we investigate
a specific class of generative models that can be used to account for the types of collective
behaviors exhibited by animal groups. In doing so, we hope to showcase the benefits of
the framework, while also proposing a testable model class for use in studies of biological
collective motion.
Active inference and generative models of behavior
A common pipeline in the quantitative study of animal behavior involves selecting a can-
didate behavioral algorithm or decision rule that may explain a given behavior, and then
fitting the parameters of the candidate model to experimental or observational data [16, 30].
While these approaches often yield strong quantitative fits to data, the explanatory power of
the models reduces to the interpretation of hard-coded parameters, which often have opaque
relationships to real biological mechanisms or constructs [31].
3
A
Classical self-propelled particles Active inference agents
Social forces Inference y
t
Agent Environment Agent Environment
Sector-sxpe t cific average distance Hidden statSeesn in xs t o e cr r oi f m a m c o e ptorris e the agen x t’s tenvironment
1
xh,l= Kl ∑
j∈Nl
∥rj−
x
r∥
x h,2 a
t
x
Decision rules h,1 Control
y y
y x B t t − − 1 1 p( D x˜ y x y , t t n y˜ a ) m y x i t t c + + 1 1 genera g f t ( ( i x x v t t e ) ) y x t t mo d d d d d x x g f t t e x x l t t ′ ′ x y     t′ t′     r Fxot′ = ′ c al [ !p r a ( x r 1 g G F h S y˜ , e o , e l = c r n , = c e a t 2 t x S l [ o n ˜ ] K r 1 a er ) 1 - l e g cs , e ∑ j∈ p r t r n = N eo 2 t a l c ] ∥ ri t fi- r p i s j c v − p x a ( e h ev r y˜ , ec 1 ∥ yr m i | ahfig,c x y 1e ˜ o h d ) a , d 1 iv p se h t e y a ( y ,r h n2 l x a ˜ y , h c y 2 g h e , y ) x h 4 , e h 4 h , , 3 , 3 2 di x x s h t h , a 4 ,4 n x c h xe ,3 h,3 H S t id h e 0 S f d e c r ee t o s o n e c S t r m c h - st e t s to e o p a c t r t e r t e - s h c - o s s e i 2 s p fi er x c p e - c t s c e s c y o o i p fi o e h c b r e c , m l s c i - c fi e d s p ti r p x i cr ofi s v O h i t e 4 s a c O x O y , r a l oe t s c - n b i y o z o i s b bt c b , fi s h h h n e pb s s e c s e , s l e se x e er a y e h r d c r v g r h , r v l x i i e , v s va l vfi a 6 n h t a a a tt , t c a a l t ii ’ t t s s r o n o i i e i d z o o e o c n n , n s h in e n n a s v , s m si t x r y a y o p y h y h 8 n n l h h , e , h l m l , c, d l l , e el f n r a o t x a r m e h r e ,l 1 s 0 a s m am ple p d le 1 2 f d ro m
Time-series Generalized coordinates
Generative model
Figure 1: A: Schematic illustrating!p(y˜,tx˜h)=ep(By˜|ax˜)yp(ex˜s)ian per0spe2ctiOv4 Obbseseerrvvaa 6ittiinoonn,yth 8 ,lhe10 co12ntext of our single
agents, where the hidden states of the environment are segregated from a focal agent by
means of sensory data y (right panel of A). This contrasts with classic self-propelled particle
t
models (left panel of A), where environmental or social information manifests in terms of
socialforcesonthefocalindividual,whoemitsitsownactionsbasedonhand-crafteddecision-
rules (e.g., changes to heading direction). B: Schematic illustration of the sector-specific
distance tracking. The left panel shows a Bayesian network representation of a dynamic
generative model (i.e., a time-series model), that represents the time-evolution of a latent
variable x and simultaneous observations y . Shown are both a standard time-series
1,...,T 1,...T
representation (lower left) and its equivalent representation as generalized coordinates of
motion x˜ = (x ,x′,x′′,...) (right). We show the orders of differentiation used for our model
t t t t
in practice (3 orders of motion for x˜ and 2 orders of motion for y˜). The middle panel of B
showshoweachcomponentofthevectorialhiddenstatex = (x ,...,x )iscomputedasthe
h,1 h,L
average nearest-neighbor distance for the neighbors within each visual sector. Observations
are generated as noisy, Gaussian samples centered on the sector-wise distance hidden state
(right panel of B). This requires the agent to estimate the true hidden state x by performing
t
inference with respect to a generative model of how sensory data are generated p(y˜,x˜).
4
In the active inference framework we rather ask: what is the minimal model an organism
might have of its environment that is sufficient to explain its behavior? Behavior is cast as
the process by which the agent minimizes surprise or prediction error, with respect to this
model of the world [22, 32]. The principle of prediction-error minimization enjoys empirical
support in neuroscience [26, 33] and a theoretical basis in the form of the Free Energy
Principle [22, 23, 25], an account of all self-organizing systems that casts them as implicit
models of their environments, ultimately in the service of minimizing the surprise (a.k.a.,
self-information) associated with sensory states [34–36].
What states-of-affairs count as surprising hinges on a generative model that can assign
a likelihood to sensory data. When it comes to modelling behavior driven by this principle,
the challenge then becomes specifying a generative or world model, whereby a particular
pattern of behavior simply emerges by minimizing surprise.
According to active inference, agents minimize surprise by changing their beliefs about
the world (changing which observations are considered surprising) or by acting on the world
to avoid surprising sensory data. The former strategy is thought to correspond to passive
processes such as perception and learning, whereas the latter corresponds to processes like
active sensing and movement. Action is thus motivated by the desire to generate sensations
that are as least surprising as possible.
In this paper, we describe the motion of mobile, mutually-sensing agents as emerging
from a process of collective active inference, whereby agents both estimate the hidden causes
of their sensations, while also actively changing their position in space in order to minimize
prediction error. In contrast to models that use pre-specified behavioral rules for generat-
ing behavior, generative models entail collective behavior by appealing to a probabilistic
representation of how an organism’s sensory inputs are generated.
A generative model for a (social) particle
We now consider a sufficient generative model for an individual in a moving group. We equip
thisindividual, hereafterreferredasthefocalagent, witharepresentationofasimplerandom
variable: the local distance x between itself and its neighbors. For generality, we can expand
this into a multivariate random variable to describe a set of distances x = (x ,x ,...,x )
1 2 L
that track the distance between the focal agent and its neighbors within L different sensory
sectors (see Figure 1B). We analogize these L sectors to adjacent visual fields of an agent’s
field of view [37, 38].
The focal agent possesses a model of the distance(s) x and its sensations thereof y.
In particular, our focal agent represents the dynamics of x using a stochastic differential
equation (a.k.a., a state-space model) defined by a drift f and some stochastic forcing ω —
we refer to this component of the generative model as the dynamics model. The stochastic
term ω captures the agent’s uncertainty about paths of x over time. The agent also believes
it can sense x via observations y, mediated by a sensory map, which we call the observation
model. This is defined by some (possibly non-linear) function g with additive noise z. The
agent’s generative model is then fully described by a pair of equations that detail 1) the
5
time-evolution of the distance and 2) the simultaneous generation of sensory samples of the
distance:
Dx˜ = ˜ f +ω˜ y˜ = g˜ +z˜ (1)
All random variables are described using generalized coordinates of motion with the
convention q˜ = {q,q′,q′′,...}. Generalized coordinates allow us to represent the trajectory
of a random variable using a vector of local time derivatives (position, velocity, acceleration,
etc.). The matrix D is a generalized derivative operator that moves a vector of generalized
coordinates up one order of motion D(x,x′,x′′,...)⊤ = (x′,x′′,x′′′,...)⊤. The generalized
functions ˜ f and g˜ therefore operate on vectors of generalized coordinates (see SI Appendix,
Section A for details on generalized coordinates and filtering).
Generalized filtering and active inference
An agent equipped with this dynamic generative model then performs active inference by
updating its beliefs (state estimation, or filtering) and control states (action) to minimize
surprise.
Inference entails updating a probabilistic belief over hidden states x˜ in the face of sensory
data y˜. Our agents solve this filtering problem using generalized filtering [39, 40], an algo-
rithm for approximate Bayesian inference and parameter estimation on dynamic state-space
models. This is achieved by minimizing the variational free energy F, a tractable upper
bound on surprise (i.e., negative log evidence or marginal likelihood). The agent minimizes
thefreeenergywithrespecttoabeliefdistributionq(x˜)withparametersν; thisapproximates
the true posterior q (x˜) ≈ p(x˜|y˜), which is the optimal solution in the context of Bayesian
ν
inference. The true posterior p(x˜|y˜) is difficult to compute for many generative models
due to the difficult calculation of the marginal (log) likelihood lnp(y˜). Variational methods
circumvent this intractable marginalization problem by replacing it with a tractable opti-
mization problem: namely, adjusting an approximate posterior to match the true posterior
by minimizing F with respect to its (variational) parameters ν.
We parameterize q(x˜) as a Gaussian with mean-vector µ˜, which is a natural choice for
this generative model since the assumption of normally-distributed noises z˜,ω˜ imply that
the true posterior will be Gaussian near the posterior mode argmaxp(x˜|y˜). The implicit
Gaussian (i.e., Laplace) assumption is ubiquitous in the modelling and signal processing
literature [41] and can be regarded as a ‘minimal’ assumption, by appeal to things like
the central limit theorem and related principles (e.g., Jaynes’ maximum entropy principle).
According to generalized filtering, µ˜ is updated using a sum of prediction errors:
6
dµ˜
∝ −∇ F(µ˜,y˜)
µ˜
dt
∝ ε˜ −ε˜
z ω
where ε˜ = y˜ −g˜(µ˜)
z
ε˜ = Dµ˜ − ˜ f(µ˜) (2)
ω
The ensuing evidence accumulation can be regarded as a natural generalization of predic-
tive coding [26, 42, 43], where beliefs about local trajectories µ˜ are updated using a running
assimilation of sensory and model prediction errors: ε˜ and ε˜ , respectively. For notational
z ω
clarity, we have omitted terms that weigh these prediction errors; the so-called generalized
sensory and model precisions Π
˜z,Π ˜ω,
which encode the agent’s assumptions about the mag-
nitude and correlation structure of noise. The importance of these precisions will become
clearlater, whenunderstandingtherelationshipbetweenprecision-weightedpredictionerrors
and social forces.
While inference entails changing the approximate posterior means µ˜ to best explain
sensory data, action entails changing the data itself to better match the data to one’s current
beliefs. Similar to the update scheme in (A.21), actions are also updated by minimizing free
energy:
da
= −∇ F(µ˜,y˜(a))
a
dt
= −∇ F(µ˜,y˜(a))∇ y˜(a)
y˜ a
∝ −ε˜⊤∇ y˜(a) (3)
z a
Actions thus are updated using a product of sensory prediction errors ε˜ and a ‘sensori-
z
motor contingency’ ∇ y˜(a) or reflex arc. This sort of ‘reflexive action’ — where control is
a
simplytargetedatminimizingsensorypredictionerrors—underliesactiveinferenceaccounts
of motor control [27, 44], and can be formally related to proportional-integral-derivative
(PID) control [45]. These prediction errors measure how far an agent’s observations are from
its expectations; the agent then acts using (3) to minimize this deviation. Active inference
agents are thus driven to act in a way that aligns with their (biased) expectations about the
world [46]. In the next section, we will see how building a particular type of bias into each
agent’s generative model leads to the appearance terms in (3) that resemble social forces.
Social forces as a consequence of predictive control
In particular, we take the agent’s action to be its heading direction a = v, and examine the
case where the agent observes the distance to its neighbors within a single sensory sector,
i.e., L = 1, x = (x ). We distinguish the agent’s representation of the distance x from the
1
actual distance using the subscript h. Therefore x = (x ,x ,...,x ) denotes the average
h h,1 h,2 h,L
7
distances (and corresponding sensory samples y ) calculated using the actual positions of
h
other agents. For the case of L = 1, and assuming the agent observes both the distance and
its rate of change y′ , this is:
h,1
1 (cid:88)
x = ∥r −r∥ y = x +z
h,1 j h,1 h,1 h,1
K
j∈Nin
dx
x′ = h,1 y′ = x′ +z′ (4)
h,1 dt h,1 h,1 h,1
N is the set of neighbors within the agent’s single sensory sector, K is the size of this
in
set, r is the focal agent’s position vector, and r is the position vectors of neighbor j. The
j
sensory observation of the generalized distance y˜ = (y ,y′ ) is a sample of the hidden
h h,1 h,1
state, perturbed by some additive noises z˜ = (z ,z′ ). By expanding the active inference
h,1 h,1
control rule in (3), we arrive at the following differential equation for the heading vector:
dv
= ξ′∆ˆr
dt z
ξ′ = π′ (y′ −µ′ )
z z,1 h,1 h,1
1 (cid:88) ∆r
∆ˆr = j ,∆r = r −r (5)
j j
K ∥∆r ∥
j
j∈Nin
The average vector ∆ˆr is exactly the (negative) ‘sensorimotor contingency’ term ∇ y˜(a)
a
from (3) (see SI Appendix, Section A for detailed derivations):
1 (cid:88) r−r
∇ y˜(v) = ∇ y = j = −∆ˆr (6)
v r
K ∥r−r ∥
j
j∈Nin
The simple action update in (5) means that the focal agent moves along a vector pointing
towards the average position of its neighbors. Whether this movement is attractive or repul-
sive is determined by the sign of the precision-weighted prediction error ξ′ = π′ (y′ −µ′ ),
z z,1 h,1 h,1
and its magnitude depends on two factors: 1) the sensory precision or ‘reliability’ π′ that
z,1
the agent affords observations of the rate-of-change of y ; and 2) the degree to which these
h,1
rate-of-change observations deviate from their predicted value y′ −µ′ .
h,1 h,1
The presence of both attractive and repulsive forces depends on the agent’s model of the
˜ ˜
distance dynamics, captured by the functional form of f. In particular, consider forms of f
that relax x to some attracting fixed point η > 0. Equipped with such a stationary model of
the local distance, inference dynamics (c.f., (A.21)) will constantly bias its predictions µ ac-
cording to the prior belief that the distance is pulled to η. Given this biased dynamics model
and the action update in (3), such an agent will move to ensure that distance observations
y˜ are equal to the fixed point η.
h
This action update shows immediate resemblance to the attractive and repulsive vectors
common to social force-based models [4, 5, 7], which often share the following general form:
8
(cid:88) r
ij
F ∝
attr
∥r ∥
ij
j∈ZA
1 (cid:88) r
ij
F ∝ −
repul
K ∥r ∥
ij
j∈ZR
(7)
where Z ,Z refer to distance-defined zones of attraction or repulsion, respectively. In
A R
the active inference framework, these social forces emerge as the derivative of the observa-
tions with respect to action ∇ y˜, where the sign and magnitude of the precision-weighted
a
sensory prediction error ξ′ determines whether the vector is attractive (towards neighbors)
z
or repulsive (away from neighbors). The transition point between attraction and repulsion
is therefore given by η, the point at which prediction errors switch sign.
An important consequence of this formulation is that, unlike the action rule used in social
force-based models, the ‘steady-state’ solution occurs when all social forces disappear (when
prediction errors vanish). In this case, the agent ceases to change its heading direction and
adopts its previous velocity. This occurs when the agent’s sensations align with its (biased)
predictions y ≈ η. In classic SPP models, this is equivalent to the different social force
h,1
vectors exactly cancelling each other.
Wecanthereforeinterpretsocialforce-basedmodelsaslimitingcasesofdistance-inferring
active inference agents, because one can conceive of social forces as just those forces induced
by free energy gradients; namely, the forces that drive belief-updating. In the case of our
active inference agents, attractive and repulsive forces emerge naturally when we assume A)
agents model the local distance dynamics as an attractor with some positive-valued fixed
point η; B) agents can act by changing their heading direction and C) agents observe at least
the first time derivative of their observations (e.g., y′ , but see SI Appendix, Section A for
h,1
detailed derivations).
It is worth highlighting the absence of an explicit, vectorial alignment force in this model,
consistent with experimental findings in two species of fish [12, 17]. The heading vectors of
neighbors is nevertheless implicitly incorporated into the calculation of first-order predic-
tion errors ξ′ via the first order hidden state x′ (c.f., (4) and SI Appendix, Eq.(A.40)).
z h,1
In particular, the x′ (from which the observations y′ are sampled) is equivalent to the
h,1 h,1
‘relative velocity’ term used in so-called selective attraction and repulsion models, where the
instantaneous rate at which neighbours approach or move away, is used to drive movement
[47]. However, explicit alignment forces as seen in the Vicsek model [6] and 2- and 3-Zone
Couzin models [7, 48] can also be recovered if we assume agents have a generative model of
theaverageanglebetweentheirheadingvectorandthoseoftheirneighbors(seeSI Appendix,
Section B for derivations of alignment forces).
9
Multivariate sensorimotor control
Having recovered social forces as free energy gradients in the case of a single sensory sector
(L = 1), we now revisit the general formulation of the generative model’s state-space, where
the hidden variable x is treated as an L-dimensional vector state: x = (x ,x ,...,x ), with
1 2 L
correspondingly L-dimensional observations y = (y ,y ,...,y ).
1 2 L
Specifically, we consider each x to represent the average distance-to-neighbors within
l
one of a subset of adjacent sensory sectors, where each sector is offset from the next by
a fixed inter-sector angle (see Figure 1B for a schematic of the multi-sector set-up). The
rest of the generative model is identical; the agents estimate these distances (and their
temporalderivativesx′,x′′,...)whilechangingtheirheadingdirectiontominimizefreeenergy.
l l
Following the same steps as in the case of a single sector, the resulting update rule for v is
a weighted sum of ‘sector-vectors’, where generalized observations from each sector-specific
modality y˜ are used to compute the prediction errors that scale the corresponding sector-
l
vector. This generalizes the scalar-vector product in (5) to a matrix-vector product:
dv
˜⊤ ˆ
= ξ ∆R
dt z
 
∇ y˜
v 1
∇ y˜ 
∆R ˆ = − v . 2  (8)
 . 
.
 
∇ y˜
v L
where now the (negative) sensorimotor contingency −∇ y˜ = ∆R ˆ is a matrix whose rows
a
contain the partial derivatives ∇ y˜ (i.e. the ‘sector-vectors’). Each sector-vector is a vector
v l
pointing towards the average neighbor position within sector l.
Numerical results
Given a group of active inference agents — equipped with the generative models described
in previous sections — it is straightforward to generate trajectories of collective motion by
integrating each agent’s heading vector over time: r˙ = v ,i ∈ {1,2,...,N} where N is the
i i
number of agents. We update all heading directions {v }N and beliefs {µ˜ }N in parallel
i i=1 i i=1
via a joint gradient descent on their respective free energies:
v˙ = −∇ F(µ˜ ,y˜ ) µ˜˙ = −∇ F(µ˜ ,y˜ )
1 v1 1 1 1 µ˜ 1 1 1
v˙ = −∇ F(µ˜ ,y˜ ) µ˜˙ = −∇ F(µ˜ ,y˜ )
2 v2 2 2 2 µ˜ 2 2 2
. .
. .
. .
v˙ = −∇ F(µ˜ ,y˜ ) µ˜˙ = −∇ F(µ˜ ,y˜ ) (9)
N vN N N N µ˜ N N N
10
A Polarized Milling Disordered
B Polarization Milling probability
Figure 2: A: Example snapshots of different collective states in schools of N = 50 active
inference agents. Each line represents the trajectory of one individual, and color gradient
represents time, from earliest (light blue) to latest (purple). The polarized regime in the
left panel was simulated with the default parameters listed in supplementary Table E1. The
milling regime (middle panel) was achieved by increasing the variance of velocity fluctuations
(encoded in σ2 ) from 0.01 to 0.05 (relative to the default configuration) and increasing λ
z′,h z
from 1.0 to 1.2. The disordered regime was achieved by increasing the sensory smoothness
parameter to 2.0 and decreasing η from 1.0 to 0.5 and α from 0.5 to 0.1 (relative to the
default configuration). B: Average polarization (left) and milling probability (right) shown
as a function of the two factorized components of the sensory precision, Γ (log-transformed)
z
and λ . For each combination of precision parameters, we ran 500 independent trials of ‘free
z
schooling,’ and then averaged the quantities of interest across trials. Each ‘free schooling’
trial lasted 15 seconds (1500 time steps with dt = 0.01s); the time-averaged metrics (polar-
ization and milling probability, respectively, were computed from the last 10 seconds of the
trial.
11
For the simulation results shown here, each agent tracks the average distance x within
l
a total of L = 4 sensory sectors that each subtend 60◦ (starting at −120◦ and ending
at +120◦, relative to the focal agent’s heading direction) and observe the sector-specific
distances calculated using all neighbors lying within 5.0 units of the focal agent’s position.
Each agent represents the vector of local distances as a generalized state with 3 orders of
motion: x˜ = {x,x′,x′′}, µ˜ = {µ,µ′,µ′′}. Agents can observe the first and second orders
of the distance y˜ = {y,y′}, i.e. the distance itself and its instantaneous rate-of-change. In
the numerical results to follow, we use active inference to study the relationship between the
properties of individual cognition (e.g., the parameters of agent-level generative models) and
collective phenomenology.
Collective regimes
Simulated groups of these distance-inferring agents display robust, cohesive collective motion
(see Figure 2A and Supplemental Movies S1-S5). Figure 2A displays examples of different
types of group phenomena exhibited in groups of active inference agents, whose diversity
and types resemble those observed in animal groups [49, 50] and in other collective motion
models [6, 7, 51]. These range from directed, coherent movement with strong inter-agent
velocity correlations (‘polarized motion’) to group rotational patterns, like milling, which
features high angular momentum around the group’s center-of-mass.
Relating individual beliefs to collective outcomes
In all but the most carefully constructed systems [31, 52, 53], the relationship between
individual and collective representations is often opaque. In particular, the relationship
between individual level uncertainty or ‘risk’ and collective behavior is an open area of
research. For instance, some research has indicated that increased risk-sensitivity at the level
of the individual may lead to decreased risk-encoding at the collective level [54]. Inspired by
these observations, we use active inference to examine the quantitative relationship between
uncertainty at the individual level and collective phenomenology. We begin by examining
common metrics of group motion like polarization and angular momentum [7]. In Figure
2B we explore how polarization and angular momentum are affected by two components
of agent-level sensory uncertainty (i.e., inverse sensory precision): 1) the absolute precision
that agents associate to sensory noise and 2) the autocorrelation or ‘smoothness’ associated
to that noise.
These components are encoded in each agent’s observation model, which assumes gener-
alized distance observations y˜ are normally-distributed around the generalized state x˜:
P(y˜|x˜) = N(y˜;x˜,Σ ˜z) (10)
Wherewefocusontheparameterizationoftheinverseofthecovariancematrix,a.k.a.,the
(cid:16) (cid:17)−1
precision matrix Π
˜z
= Σ
˜z
. This precision matrix factorizes into two sub-matrices, one
12
encoding the amplitude of random fluctuations z and one encoding their temporal smooth-
ness, i.e., the inverse of the covariance between different derivatives of random fluctuations
(e.g., between z and z′):
Π ˜z = Πz ⊗Π ˜z
 
Γ 0 ... 0
z,1
 0 Γ 
z,2
where Πz =   . .
.
...   (11)
 
0 Γ
z,L
(cid:20) (cid:21)
1 0
Π
˜z
= (12)
0 2λ2
z
Intuitively, Γ encodes the variance or amplitude that the agent associates with the noise
z
in each of its L sensory sectors z , and λ encodes how ‘smooth’ the agent believes the
l z
noise is [40, 55]. A higher value of λ implies that the agent believes sensory noise is more
z
serially-correlated (e.g., random fluctuations in optical signals caused by smooth variations
in refraction due to turbulence in water). Section C.1 of the SI Appendix shows how the
smoothnessparameterλ canbederivedfromanoiseprocesswithaGaussianautocorrelation
z
function. The consequences of this parameterization can be mapped back to the first-order
prediction errors ξ′ that drive action in (5) and (8):
z
 
2Γ λ2(y′ −µ′ )
z,1 z h,1 h,1
2Γ λ2(y′ −µ′ )
ξ′ =  z,2 z h . ,2 h,2  (13)
z  . 
.
 
2Γ λ2(y′ −µ′ )
z,L z h,L h,L
Here, we have simply written the precision assigned to noise z in a particular sensory
h,l
sector as a product of the amplitude and smoothness parameters: π′ = 2Γ λ2.
z,l z,l z
Figure2Bshowshowthedifferentcomponents(amplitudeandsmoothness)oftheagent’s
beliefs about uncertainty determine group behavior, as quantified by average polarization
and milling probability. Average polarization is defined here as the time average of the
polarization of the group, where the polarization at a given time p(t) measures the alignment
of velocities of agents comprising the group [7, 56]:
T N
1 (cid:88) 1 (cid:88)
pˆ= p(t) p(t) = ∥ v (t)∥ (14)
i
T −t N
0
t=t0 i=1
Note that the time average is calculated once steady-state has been reached, where the
beginning of this state is indicated by t (for the heatmaps shown in 2B, we calculate these
0
average metrics with t = 5s). High average polarization indicates directed, coherent group
0
movement. The left panel of Figure 2B shows how Γ and λ contribute to the average
z z
13
polarization of the group. An increase in either parameter causes polarization to decrease
and angular momentum to increase, reflecting the transition from directed motion to a
milling regime, where the group rotates around its center of mass. We calculate the milling
probability (c.f. right panel of Figure 2B) as the proportion of trials where the time-averaged
angular momentum surpassed 0.5. The average angular momentum can be used to quantify
the degree of rotational motion, and is calculated as the time- and group-average of the
individual angular momenta around the groups’ center of mass c:
T N
1 (cid:88) 1 (cid:88)
mˆ = m(t) m(t) = ∥ r (t)×v (t)∥ (15)
ic i
T −t N
0
t=t0 i=1
where r is a relative position vector for agent i, defined as the vector pointing from the
ic
group center c to agent i’s position: r −c. We observed a large range of Γ and λ for which
i z z
the milling regime (high average angular momentum) was stable (Figure 2B, right side).
This stands in contrast to earlier self-propelled particular models like the original 3-zone
Couzin model, where milling was only stable under a relatively limited range of parameters
[7].
These collective changes can be understood by recalling how first-order prediction errors
ξ′ (and thus the velocity update) depend on Γ and λ :
z z z
ξ′ ∝ 2Γ λ2 (16)
z z z
In practice, this means that as the group believes in more predictable (less rough) first-
order sensory information y′, the group as a whole is more likely to enter rotational, milling-
z
like regimes. However, the enhancing effect of these first-order prediction errors ξ′ on ro-
z
tational motion is bounded; if prediction errors are over-weighted (e.g. high Γ and/or λ ),
z z
the group becomes more polarized again and likely to fragment (see SI Appendix, Fig. E1).
This fragmentation probability occurs at both low and high levels of Γ and λ , implying
z z
that there is an optimal range of individual-level sensory precision where cohesive group
behavior (whether polarized or milling) is stable. Thus, our model predicts that assuming
one’s sensory information is highly-precise is neither required, or in fact even desirable, for
animals in order to facilitate collective motion.
We have seen how one can use active inference to relate features of individual-level beliefs
(in this case, beliefs about sensory precision) to collective patterns, focusing in the present
case on common metrics for studying collective motion like polarization and the tendency
to mill.
In the following sections, we move from looking at group-level patterns that occur during
free movement, to studying the consequences of individual-level uncertainty for collective
information-processing. We begin by investigating how collective information transfer de-
pends on individual-level beliefs about the relative precisions associated with different types
of sensory information.
14
A B
Proportion informed
ycaruccA
Average
accuracy
laicoS−zΓ
gol
log Γz−Target
Figure 3: A: Collective accuracy as a function of proportion informed or p for differing
inf
values of the sensory precision assigned to social observations Γ . Average accuracy for
z−Social
each condition (combination of p ,Γ ,Γ ) was computed as the proportion of
inf z−Social z−Target
successful hits across 500 trials. Here, the average accuracy is further averaged across all the
values of the Γ parameter, meaning each accuracy here is computed as the average of
z−Target
15000 total trials (500 trials per condition × 30 different values of Γ ). B: Collective
z−Target
accuracy as a function of both the social and target precisions (Γ ,Γ , shown
z−Social z−Target
in log-scale) averaged across values of p ranging from p = 0.15 to p = 0.40. Each
inf inf inf
condition’s accuracy was computed as the proportion of accurate decisions from 500 trials.
15
Collective information transfer
In this section, we take inspiration from the collective leadership and decision-making liter-
ature to investigate how individuals in animal groups can collectively navigate to a distant
target [48, 57–59]. This phenomenon is an example of effective leadership through collective
information transfer and is remarkable for a number of reasons; one that speaks to its emer-
gent nature, is the fact that these collective decisions are possible despite — and indeed even
because of — the presence of uninformed individuals in the group [57]. Figure 3A shows
that active inference agents engaged in this task reproduce a result from earlier work [48] on
the relationship between the proportion of uninformed individuals and collective accuracy.
Namely, as the proportion of informed individuals increases, so does the accuracy of reaching
the majority-preferred target. In the same vein as earlier sections, we also investigated the
dependence of this effect, as well as the average target-reaching accuracy, on individual-level
beliefs.
We operationalize the notion of an agent being ‘informed’ (about an external target) by
introducing a new latent variable to its generative model; this variable x represents the
target
distance between the informed agent’s position r and a point-mass-like target with position
vector T = [T ,T ]. We thus define this new hidden state and observation as follows:
1 2
x = ∥T − r∥, y = x + z . Just like the ‘social’ distance observations y ,
target target target target h
this target distance observation y represents a (potentially-noisy) observation of the
target
true distance x . As before, the agent represents both the target distance x and
target target
its observations y using generalized coordinates of motion. Each informed agent has
target
a dynamics model of x˜ , whereby they assume the target-distance is driven by some
target
drift function f (x ) = −α x which relaxes to 0. As with the social distances,
target target t target
we truncate the agent’s generalized coordinates embedding of the target distance to three
orders of motion and the generalized observations to two orders of motion.
Each informed agent maintains a full posterior belief µ˜ = (µ˜ ,µ˜ ,...,µ˜ ,µ˜ ) about
1 2 L target
the local distances x˜ ,x˜ ,...,x˜ as well as the target distance x˜ .
1 2 L target
Using identical reasoning to arrive at the action updates in (5) and (8), one can augment
thematrix-vectorproductin(8)withanextrasensorimotorcontingencyandpredictionerror
that represents target-relevant information:
dv ˜⊤
(cid:20)
∆R
ˆ(cid:21)
= ξ
dt z ∆T
T−r
∆T = −∇ y˜ = (17)
v target
∥T−r∥
This matrix-vector product can then be seen as a weighted combination of social and
target vectors, with the weights afforded to each equal to their respective precision-weighted
prediction errors:
16
dv
ˆ
= ξ ∆R+ ξ ∆T (18)
social target
dt
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Socialvector Targetvector
This expression is analogous to the velocity update in Equation (3) of Ref. [48], where
a ‘preferred direction’ vector is integrated into the agent’s action update with some pre-
determined weight. This weight is described as controlling the relative strengths of non-
social vs. social information. For active inference agents, the weighting of target-relevant
information emerges naturally as a precision-weighted prediction error (here represented as
ξ ), and the target-vector itself is equivalent to a sensorimotor reflex arc, that represents
target
the agent’s assumptions about how the local flow of the target distance y′ changes as a
target
function of the agent’s heading direction v. An important consequence of this construction,
is that, unlike in previous models where this weight is ‘baked-in’ as a fixed parameter, the
weight assigned to the target vector is dynamic, and fluctuates according to how much the
agent’sexpectationsaboutthetargetdistanceµ˜ predictthesensedtargetdistancey .
target target
Using this new construction, we can simulate a group of active inference agents, in which
some proportion p of agents represent this extra set of target-related variables as described
inf
above. To generate y˜ observations for these informed individuals, we placed a spatial
target
targetatafixeddistanceawayfromthegroup’scenter-of-massandthenallowedtheinformed
individuals to observe the generalized target distance y˜ = (y ,y′ ). We then
target target target
integratedthecollectivedynamicsovertimeandmeasuredtheaccuracywithwhichthegroup
was able to navigate to the target (see Materials and Methods for details). By performing
hundreds of these trials for different values of p , we reproduced the results of Ref. [48] in
inf
Figure 3. We see that as the number of informed individuals increases, collective accuracy
increases. However, this performance gain depends on the agents‘ beliefs about sensory
precision, which we now dissociate into two components: Γ ( the precision assigned
z-Social
to the social distance observations) and Γ (the precision assigned to target distance
z-Target
observations). By varying these two precisions independently, which respectively scale ξ
social
and ξ in (18), we can investigate the dependence of collective accuracy on the beliefs of
target
individual agents about the uncertainty attributed to different sources of information.
Figure 3A shows the average collective accuracy as a function of p , for different levels
inf
of the social distance precision Γ . The pattern that emerges is that the social preci-
zSocial
sion, that optimizes collective decision-making, sits within a bounded range. The general
effect of social precision is to essentially balance the amplification of target-relevant infor-
mation throughout the school, with the need for the group to maintain cohesion. When
social precision is too high, agents over-attend to social information and are not sensitive
to the information provided by informed individuals; when it is too low, the group is likely
to fragment and will not accurately share target-relevant information; meaning only the in-
formed individuals will successfully reach the target. Figure 3B shows that a similar optimal
precision-balance exists for Γ . Here, we show average collective accuracy (averaged
zTarget
across values of p as a function of social- and target-precision. Maximizing collective
inf
accuracy appears to rely on agents balancing the sensory precision they assign to different
17
sources of information; under the active inference model proposed here, this balancing act
can be exactly formulated in terms of the variances (inverse precisions) afforded to different
types of sensory cues.
Online plasticity through parameter learning
The ability of groups to tune their response to changing environmental contexts, such as
rapid perturbations or informational changes, is a key feature of natural collective behavior
[15, 54]. However, many self-propelled particle models lack a generic way to incorporate this
behavioral sensitivity [48] and exhibit damped, ‘averaging’-like responses to external inputs
[60]. This results from classical models usually equipping individuals with fixed interaction
rules and constant weights for integrating different information sources. While online weight-
updating rules and evolutionary algorithms have been used to adaptively tune single-agent
parameters in some cases [48, 59, 61], these approaches are often not theoretically principled
and driven by specific use-cases [with notable exceptions [62–64]].
Active inference offers an account of tune-able sensitivity, using the same principle used
to derive action and belief-updating in previous sections: minimizing surprise. In practice,
this sensitivity emerges when we allow agents to update their generative models per se in
real-time. Updating generative model parameters over time is often referred to as “learning”
in the active inference literature [65], since it invokes the notion of updating beliefs about
parameters rather than states, where parameters and states distinguish themselves by fast
and slow timescales of updating, respectively. We leverage this idea to allow agents to adapt
their generative models and thus adapt their behavioral rules, referring to this process as
plasticity, in-line with the notion of short-term plasticity in neural circuits [66]. To enable
agents to update generative model parameters, we can simply augment the coupled gradient
descent in (9) with an additional dynamical equation, this time by minimizing free energy
with respect to model parameters, which we subsume into a set θ:
θ ˙ = −∇ F(µ˜,y˜,θ) (19)
θ
The generative model parameters θ represent the statistical contingencies or regularities
agents believes govern their sensory world; this includes the various precisions associated
with sensory and process noises Π
˜z,Π ˜ω
and the parameters of the dynamics and observation
models, ˜ f,g˜. Since the free energy is a smooth function of all the generative model parame-
ters, in theory learning can be done with respect to any parameter using procedure entailed
by (19).
In practice, combining parameter-learning with active inference usually implies a separa-
tion of timescales, whereby learning or plasticity occurs concurrently to state inference and
action but at a slower update rate. In all the results shown here, agents update parame-
ters an order of magnitude more slowly than they update beliefs or actions. To furnish a
interpretable example of plasticity, in the simulations described here, we enabled agents to
update their beliefs about the sensory smoothness parameter λ . We chose sensory smooth-
z
ness due to its straightforward relationship to the magnitude of sensory prediction errors
18
A Pseudo-motion B
stimulus y y y y
1 2 3 4
``
C
Stimulated Stimulus-evoked
agent neural activity
y y y y 1 2 3 4 μμ
11
y 1 y 1 y 2 y 2 μμ 22 y y 3
3 μμ
33
y y 4 μμ
4 44
Pseudo-motion Stimulated Stimulus-evoked neural activity stimulus agent
emit
sulumitS
1.0
0.8
+1
0.6
0 0.4
0.2
-1
0.0
2.5 5.0 7.5 10.012.515.017.5
Time since perturbation (seconds)
5 10 15 20 25 5 10 15 20 25 Perturbation size (number of agents changed) Perturbation size (number of agents changed)
))θ(soc(!
edutingam
gninrut
puorG
1.0
0.8
0.4
0.2
0.0
edutingam
gninrut detargetnI
1.0
1.4
1.2 0.8
0.6 0.4
0.2
0.0
esnopser
fo ytilibaborP
Learning enabled, post-perturbation Learning enabled P L r e e a - r p n e in rt g u r d b is a a ti b o l n e d p , e p r o io s d t- ( p s e a r m tu e rb h a i t s i t o o n ries) S Le e a lf- r p n r in o g p e d ll i e sa d b p le a d rticles
Learning enabled
Learning disabled
0.6
Figure 4: A: Schematic of the sensory perturbation protocol. The ‘pseudo-motion’ stim-
ulus consists of repetitively perturbing the agent’s sensory sectors with a moving wave of
prediction errors in the agent’s velocity-observation modality y′. The top panel shows stim-
h
ulus pattern as a heatmap over (amplitude over time) with two repetitions, starting from
negative (red, sectors 1 and 2) and transitioning to positive (blue, sectors 3 and 4) prediction
errors. The sign-switch in the stimulus (from negative to positive) mimics a moving object
that first moves towards focal individual and then moves away. The temporal order of the
stimulus across the sectors can be used to selectively emulate a right-moving vs. left-moving
object, relative to the focal individual’s heading-direction. The bottom panel shows how
the stimulated agent’s beliefs about the distance hidden state µ changes over the course
of the motion stimulus, with these beliefs being analogized to hypothetical neural activity.
B: Response magnitude to a perturbation in presence or absence of parameter learning.
Left panel: example pair of 2-D trajectories of active inference agents with matched pre-
perturbation histories, in response to an individual perturbation. The ability to perform
parameter-learning is left on in one stochastic realization (green) and turned off in the other
(blue), following the perturbation. Right panel: initialization-averaged collective responses
(group turning angle) to perturbation of active inference agents when learning is enabled or
disabled. The perturbation response of a 2-zone self-propelled particle model (purple line)
based on [48] is also shown for reference. C: Collective response as a function of the num-
ber of perturbed individuals, comparing simulations where parameter-learning is enabled to
those where it’s disabled. Shown is the mean response with highest density regions (HDRs)
of integrated turning magnitude within 500-1000 ms of the perturbation (left) and response
probability (right) computed from N = 200 independent initializations of each condition.
i
For each initialization, the average metric is computed across N = 50 independent real-
r
izations that were run forward from the same point in time, following a sensory prediction
error perturbation (to a randomly-chosen set of perturbed agents). Response probability is
computed as the proportion of independent realizations, per initialization, where the group
turning rate exceeded π radians within the first 10 seconds of the perturbation.
19
(c.f. the relation in (16) and SI Appendix, Section C). As agents tune λ to minimize free
z
energy, belief updating and action will at the same time become quadratically more or less
responsive to sensory information.
One example of where behavioral plasticity is crucial for collective information processing
is a group’s ability to rapidly amplify behaviorally-relevant information, e.g., detecting the
presence of a predator [67–69]. To study the effect of behavioral plasticity on collective re-
sponsiveness,weperturbedsingleagentsingroupsofactiveinferenceagentswhileenablingor
disabling online plasticity. We perturbed groups by inducing transient ‘phantom’ prediction
errors in random subsets of agents and measuring the resulting turning response of the group
(see Materials and Methods for details). These prediction errors were structured (see Figure
4A) to mimic a transient visual stimulus, e.g., a loom stimulus or approaching predator [70],
which reliably induces a sustained turning response in the chosen individual [60]. Figure 4
shows the effect of enabling plasticity on the size and sensitivity of collective responses to
these perturbations. Not only do plasticity-enabled groups respond more strongly to per-
turbations of single-agents, compared to their plasticity-disabled counterparts (4B), but the
magnitude of the collective response is also more sensitive to the size of the perturbation
(4C). As has been measured in biological collectives [71], the plasticity-enabled groups col-
lectively encode the size of perturbations with higher dynamic range than plasticity-disabled
controls.
The active inference framework provides a flexible and theoretically-principled approach
to modeling adaptive, collective behavior with tuneable sensitivity, that eschews ad-hoc
update rules or expensive evolutionary simulations. The plasticity mechanism proposed here
is not limited to updating beliefs about sensory smoothness: it can be extended to update
beliefs about any model parameter using the same principle. The ability to adapt generative
model parameters in real-time represents a promising avenue for future research in active
inference and collective behavior, and may lead to more biologically-plausible hypotheses
about the mechanisms underlying adaptive responses in the natural world.
Discussion
We have proposed active inference as a flexible, cognitively-inspired model class that can
be used in the theoretical study of collective motion, as well as in empirical settings as an
individual-level model of behavior. By framing behavior as the consequence of prediction-
error minimization — with respect to an individual’s world model — we offer examples of
how naturalistic collective motion emerges in, where individual behavior is driven by the im-
perative to minimize the surprisal associated with sensory signals. Under mild distributional
assumptions, this surprise is scored by an interpretable proxy; namely, prediction error. In
the particular case of collective motion, a group of active inference agents equipped with
a simple generative model of local social information can recover and generalize the social
forces that have been the core mechanism in classical SPP models of collective motion. The
active inference framework also provides a probabilistic interpretation of ad-hoc ‘weight’ pa-
rameters that are often used in these models, in terms of the precisions that agents associate
20
to different types of sensory information.
We have also shown how the active inference framework can be used to characterize
the relationship between generative model parameters and emergent information-processing
capacities, as measured by collective information transfer and responsiveness to external
perturbations. Active inference’s generality allows us to relax the typically-static behavioral
rules of SPP models, by enabling agents to flexibly tune their sensitivity to prediction errors.
This is achieved via principled processes like parameter learning (i.e., ‘plasticity’), and can
be used to model naturalistic features of collective behavior, such as the tendency to amplify
salient (i.e., precise) information, that have largely evaded modelling in the SPP paradigm,
except in cases where adaptation rules are explicitly introduced [48, 59]. However, when
we simply allow agents to update parameters, in addition to beliefs and agents, using the
principle of surprise-minimization, many hallmarks of these naturalistic behaviors can be
easily obtained.
The surprise minimization approach adopted here is both theoretically grounded in fun-
damentalphysical, cyberneticandinformationalprinciples[23, 72–74]whilealsobiologically-
inspired, due to the scalability of the belief and action update rules, which are hypothesized
to be implementable on neuronal circuits [43]. Our approach thus also harmonizes with
modern ‘data-driven’ approaches in behavioral biology, that aim to quantitatively estimate
the behavioral algorithms used by different biological systems directly from experimental
data [13–15].
By providing a flexible modeling approach that casts perception, action, and learning
as manifestations of the single drive to minimize surprise, we have highlighted active infer-
ence as a toolbox for studying collective behavior in natural systems. Future work in this
area could explore how the framework can be used to investigate other forms of collective
behavior (not just collective motion), like multi-choice decision-making, social foraging and
communication [75, 76]. The results shown in the current work serve primarily as a proof of
concept: we started by writing down a specific, hypothetical active inference model of agents
engaged in group movement, and then generated naturalistic behaviors by integrating the
resulting equations of motion (i.e., free energy gradients) for this particular model. Taking
inspiration from fields like computational psychiatry [77, 78], we emphasize the ability to
movefromsimpleforwardmodellingofbehaviortodata-drivenmodelinversion, wherebyone
hopes to infer the values of parameters that best explain empirical data (of e.g., behavioral
movement data). Instead of using ‘force mapping’ techniques to estimate social forces from
behavioral measurements [79, 80], our approach would instead frame the problem as one of
computational phenotyping, where alternative generative models that a particular animal
might be equipped with, could be estimated from behavioral or neural data acquired from
that animal. The resulting ‘social forces’ or interaction rules would then emerge as those
behaviors that minimize surprise, relative to the generative model that best explains the an-
imal’s behavior. Both the estimation of model parameters and alternative model structures
can be achieved through Bayesian model inversion and system identification methods like
Bayesian model selection, averaging or reduction [81].
21
Materials and Methods
Forallsimulationswerandomlyinitializedthepositionsand(unit-magnitude)velocitiesofN
particles, and integrated the equations of motion for active inference and generalized filtering
using a forwards Euler-Maruyama scheme with an integration window of ∆t = 0.01s (see SI
Appendix, Section E for details). We varied group size N and the length of the simulation
T (in seconds) depending on the experiment. Detailed background on generalized filtering,
activeinference,andderivationsspecifictothegenerativemodelweusedforcollectivemotion
can be found in the SI Appendix, Section A. All other parameters used for simulations,
unless stated otherwise, are listed in SI Appendix, Table E.1. The code (written in JAX
and Julia) used to perform simulations can be found in the following open-source repository:
https://github.com/conorheins/collective_motion_actinf [82].
Quantifying fragmented groups
For all experiments, we excluded trials where the group failed to maintain cohesion (or
fragmented) to a sufficient degree. We deemed any given trial fragmented, when at least one
individualwasfurtherthan2.0dimensionlessunitsawayfromallotherindividualsforatleast
3 of the last 10 seconds of the trial. For the perturbation experiments, groups were excluded
if this criterion was reached during the last 5 seconds of the 20 second post-perturbation
period.
Collective information transfer experiments
For each trial of collective target-navigation, we initialized a group of N = 30 agents with
random positions and velocities (centered on the origin) and augmented the generative mod-
els of a fixed proportion p of the total number of agents, where p ranged from 0.05 to
inf inf
1.0, with extra latent and observed variables representing the distance to the target with
position vector T. The distance to the target was always 10 units from the origin. We
measured collective accuracy as follows: we count a given trial as successful if the group is
able to navigate to within 0.25 units of the target without losing cohesion within T = 15
seconds (the length of each trial). The accuracy for a given experimental condition was then
computed as the proportion of successes observed in 500 total trials.
Perturbation experiments
For the perturbation experiments, we simulated N = 200 randomly-initialized independent
i
runs of N = 50 agents, which we term independent initializations. We ran each initialization
forward for T = 100 seconds, a point at which metrics like average polarization, angular mo-
mentum, and median nearest-neighbor distance were highly likely to have stopped changing
and fluctuate around a stationary value. Starting at T = 100 we then split each initializa-
tion into two further sets of N = 50 parallel realizations. Each realization used a different
r
22
random seed used to A) generate the action- and observation-noises; and B) select the candi-
date agent(s) for perturbation. Note that the splitting of seeds at T = 100 means that each
realization has an identical history up until that point. We enabled parameter learning of
λ in one set of realizations and we left it disabled in the other. We then perturbed random
z
subsets of agents in both learning-enabled and -disabled realizations (2% - 50% of the group,
i.e., 1 to 25 agents), by transiently inducing first-order prediction errors ξ′ in the perturbed
z
individuals. We computed the relative group turning angle after the perturbation for 20s to
generate the plots in Figure 4B and C.
Acknowledgements: The authors would like to thank Brennan Klein, Jake Graving,
Armin Bahl, Dimitrije Markovic, Thomas Parr, Pawel Romanczuk, and Manuel Baltieri
for discussions during the writing of this manuscript, and Maya Polovitskaya for creating the
fish schematic used in the figures. CH and IDC acknowledge support from the Office of Naval
Research Grant N0001419-1-2556, Germany’s Excellence Strategy-EXC 2117-422037984 (to
IDC), the Max Planck Society, the European Union’s Horizon 2020 research and Innovation
Programme under the Marie Skłodowska-Curie Grant agreement (to IDC; #860949), the
PathFinder European Innovation Council Work Programme (to IDC; #101098722), and the
John Templeton Foundation (to CH; #61780). LD is supported by the Fonds National de
la Recherche, Luxembourg (Project code: 13568875) and the Engineering and Physical Sci-
ences Research Council Centre for Doctoral Training in Mathematics of Random Systems:
Analysis, Modelling and Simulation (EP/S023925/1). RPM is supported by UK Research
and Innovation Future Leaders Fellowship MR/S032525/1 and the Templeton World Charity
Foundation Inc. TWCF-2021-20647. KF is supported by funding for the Wellcome Centre
for Human Neuroimaging (Ref: 205103/Z/16/Z), a Canada-UK Artificial Intelligence Initia-
tive (Ref: ES/T01279X/1) and the European Union’s Horizon 2020 Framework Programme
for Research and Innovation under the Specific Grant Agreement No. 945539 (Human Brain
Project SGA3).
References
[1] Peter F Major and Lawrence M Dill. “The three-dimensional structure of airborne bird
flocks”. In: Behavioral Ecology and Sociobiology 4.2 (1978), pp. 111–122.
[2] Scott Camazine, Jean-Louis Deneubourg, Nigel R Franks, James Sneyd, Eric
Bonabeau, and Guy Theraulaz. Self-organization in biological systems. Princeton uni-
versity press, 2003.
[3] Michael Rubenstein, Christian Ahler, and Radhika Nagpal. “Kilobot: A low cost scal-
able robot system for collective behaviors”. In: 2012 IEEE International Conference
on Robotics and Automation. IEEE. 2012, pp. 3293–3298.
[4] Ichiro AOKI. “A Simulation Study on the Schooling Mechanism in Fish”. In: NIPPON
SUISAN GAKKAISHI 48.8 (1982), pp. 1081–1088. doi: 10.2331/suisan.48.1081.
23
[5] Craig W Reynolds. “Flocks, herds and schools: A distributed behavioral model”. In:
Proceedings of the 14th annual conference on Computer graphics and interactive tech-
niques. 1987, pp. 25–34.
[6] Tamás Vicsek, András Czirók, Eshel Ben-Jacob, Inon Cohen, and Ofer Shochet. “Novel
type of phase transition in a system of self-driven particles”. In: Physical review letters
75.6 (1995), p. 1226.
[7] Iain D Couzin, Jens Krause, Richard James, Graeme D Ruxton, and Nigel R Franks.
“Collective memory and spatial sorting in animal groups”. In: Journal of theoretical
biology 218.1 (2002), pp. 1–12.
[8] John Toner and Yuhai Tu. “Flocks, herds, and schools: A quantitative theory of flock-
ing”. In: Physical review E 58.4 (1998), p. 4828.
[9] David JT Sumpter. “The principles of collective animal behaviour”. In: Philosophical
transactions of the royal society B: Biological Sciences 361.1465 (2006), pp. 5–22.
[10] Eric Bertin, Michel Droz, and Guillaume Grégoire. “Boltzmann and hydrodynamic
description for self-propelled particles”. In: Physical Review E 74.2 (2006), p. 022101.
[11] Pierre Degond and Sébastien Motsch. “Continuum limit of self-driven particles with
orientation interaction”. In: Mathematical Models and Methods in Applied Sciences
18.supp01 (2008), pp. 1193–1215.
[12] James E Herbert-Read, Andrea Perna, Richard P Mann, Timothy M Schaerf, David
JT Sumpter, and Ashley JW Ward. “Inferring the rules of interaction of shoaling fish”.
In: Proceedings of the National Academy of Sciences 108.46 (2011), pp. 18726–18731.
[13] Daniel S Calovi, Ugo Lopez, Sandrine Ngo, Clément Sire, Hugues Chaté, and Guy
Theraulaz. “Swarming, schooling, milling: phase diagram of a data-driven fish school
model”. In: New journal of Physics 16.1 (2014), p. 015026.
[14] Andrew M Hein, Douglas L Altshuler, David E Cade, James C Liao, Benjamin T
Martin, and Graham K Taylor. “An algorithmic approach to natural behavior”. In:
Current Biology 30.11 (2020), R663–R675.
[15] Ashkaan K Fahimipour, Michael A Gil, Maria Rosa Celis, Gabriel F Hein, Benjamin T
Martin,andAndrewMHein.“Wildanimalssuppressthespreadofsociallytransmitted
misinformation”. In: Proceedings of the National Academy of Sciences 120.14 (2023),
e2215428120.
[16] Jacques Gautrais, Francesco Ginelli, Richard Fournier, Stéphane Blanco, Marc So-
ria, Hugues Chaté, and Guy Theraulaz. “Deciphering interactions in moving animal
groups”. In: PLoS computational biology 8.9 (2012), e1002678.
[17] Yael Katz, Kolbjørn Tunstrøm, Christos C Ioannou, Cristián Huepe, and Iain D
Couzin. “Inferring the structure and dynamics of interactions in schooling fish”. In:
Proceedings of the National Academy of Sciences 108.46 (2011), pp. 18720–18725.
[18] Karl J Friston, Jean Daunizeau, and Stefan J Kiebel. “Reinforcement learning or active
inference?” In: PloS one 4.7 (2009), e6421.
24
[19] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and Gio-
vanniPezzulo.“Activeinference:aprocesstheory”.In:Neural computation 29.1(2017),
pp. 1–49.
[20] Thomas Parr, Giovanni Pezzulo, and Karl J Friston. Active inference: the free energy
principle in mind, brain, and behavior. MIT Press, 2022.
[21] Lancelot Da Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic, Victorita Neacsu,
and Karl Friston. “Active inference on discrete state-spaces: a synthesis”. In: Journal
of Mathematical Psychology 99 (2020), p. 102447.
[22] Karl Friston. “A theory of cortical responses”. In: Philosophical transactions of the
Royal Society B: Biological sciences 360.1456 (2005), pp. 815–836.
[23] Karl Friston, James Kilner, and Lee Harrison. “A free energy principle for the brain”.
In: Journal of Physiology-Paris 100.1-3 (2006), pp. 70–87.
[24] Karl Friston. “What is optimal about motor control?” In: Neuron 72.3 (2011), pp. 488–
498.
[25] Karl Friston, Lancelot Da Costa, Noor Sajid, Conor Heins, Kai Ueltzhöffer, Grigorios
A. Pavliotis, and Thomas Parr. “The Free Energy Principle Made Simpler but Not Too
Simple”. In: Physics Reports. The Free Energy Principle Made Simpler but Not Too
Simple 1024 (June 2023), pp. 1–29. issn: 0370-1573. doi: 10.1016/j.physrep.2023.
07.001. (Visited on 08/30/2023).
[26] Rajesh PN Rao and Dana H Ballard. “Predictive coding in the visual cortex: a func-
tional interpretation of some extra-classical receptive-field effects”. In: Nature neuro-
science 2.1 (1999), pp. 79–87.
[27] Rick A Adams, Stewart Shipp, and Karl J Friston. “Predictions not commands: active
inferenceinthemotorsystem”.In:Brain Structure and Function 218.3(2013),pp.611–
643.
[28] Abdullahi Ali, Nasir Ahmad, Elgar de Groot, Marcel Antonius Johannes van Gerven,
and Tim Christian Kietzmann. “Predictive coding is a consequence of energy efficiency
in recurrent neural networks”. In: Patterns 3.12 (2022).
[29] Charlotte Caucheteux, Alexandre Gramfort, and Jean-Rémi King. “Evidence of a pre-
dictive coding hierarchy in the human brain listening to speech”. In: Nature human
behaviour 7.3 (2023), pp. 430–441.
[30] Kevin N Laland. “Social learning strategies”. In: Animal Learning & Behavior 32.1
(2004), pp. 4–14.
[31] Peter M Krafft, Erez Shmueli, Thomas L Griffiths, Joshua B Tenenbaum, et al.
“Bayesian collective learning emerges from heuristic social learning”. In: Cognition 212
(2021), p. 104469.
[32] Manuel Baltieri and Christopher L Buckley. “Generative models as parsimonious de-
scriptions of sensorimotor loops”. In: arXiv preprint arXiv:1904.12937 (2019).
25
[33] Cem Uran, Alina Peter, Andreea Lazar, William Barnes, Johanna Klon-Lipok,
Katharine A. Shapcott, Rasmus Roese, Pascal Fries, Wolf Singer, and Martin Vinck.
“Predictive coding of natural images by V1 firing rates and rhythmic synchronization”.
In: Neuron 110.7 (2022), 1240–1257.e8. issn: 0896-6273. doi: https://doi.org/10.
1016/j.neuron.2022.01.002. url: https://www.sciencedirect.com/science/
article/pii/S0896627322000022.
[34] Karl Friston. “The free-energy principle: a rough guide to the brain?” In: Trends in
cognitive sciences 13.7 (2009), pp. 293–301.
[35] Jakob Hohwy. “The self-evidencing brain”. In: Noûs 50.2 (2016), pp. 259–285.
[36] Karl Friston. “A free energy principle for a particular physics”. In: arXiv preprint
arXiv:1906.10184 (2019).
[37] Bertrand Collignon, Axel Séguret, and José Halloy. “A stochastic vision-based model
inspired by zebrafish collective behaviour in heterogeneous environments”. In: Royal
Society open science 3.1 (2016), p. 150473.
[38] Renaud Bastien and Pawel Romanczuk. “A model of collective behavior based purely
on vision”. In: Science advances 6.6 (2020), eaay0792.
[39] Karl Friston, Klaas Stephan, Baojuan Li, and Jean Daunizeau. “Generalised filtering”.
In: Mathematical Problems in Engineering 2010 (2010).
[40] Karl Friston, Jérémie Mattout, Nelson Trujillo-Barreto, John Ashburner, and Will
Penny. “Variational free energy and the Laplace approximation”. In: Neuroimage 34.1
(2007), pp. 220–234.
[41] David JC MacKay and David JC Mac Kay. Information theory, inference and learning
algorithms. Cambridge university press, 2003.
[42] JannekeFMJehee,ConstantinRothkopf,JeffreyMBeck,andDanaHBallard.“Learn-
ing receptive fields using predictive feedback”. In: Journal of Physiology-Paris 100.1-3
(2006), pp. 125–132.
[43] Michael W Spratling. “A review of predictive coding algorithms”. In: Brain and cogni-
tion 112 (2017), pp. 92–97.
[44] Antonella Maselli, Pablo Lanillos, and Giovanni Pezzulo. “Active inference unifies in-
tentional and conflict-resolution imperatives of motor control”. In: PLoS computational
biology 18.6 (2022), e1010095.
[45] Manuel Baltieri and Christopher L Buckley. “PID control as a process of active infer-
ence with linear generative models”. In: Entropy 21.3 (2019), p. 257.
[46] Christopher L Buckley, Chang Sub Kim, Simon McGregor, and Anil K Seth. “The
free energy principle for action and perception: A mathematical review”. In: Journal
of Mathematical Psychology 81 (2017), pp. 55–79.
[47] Pawel Romanczuk, Iain D Couzin, and Lutz Schimansky-Geier. “Collective motion due
to individual escape and pursuit response”. In: Physical Review Letters 102.1 (2009),
p. 010602.
26
[48] Iain D Couzin, Jens Krause, Nigel R Franks, and Simon A Levin. “Effective leader-
ship and decision-making in animal groups on the move”. In: Nature 433.7025 (2005),
pp. 513–516.
[49] Ch Becco, Nicolas Vandewalle, Johann Delcourt, and Pascal Poncin. “Experimental
evidences of a structural and dynamical transition in fish school”. In: Physica A: Sta-
tistical Mechanics and its Applications 367 (2006), pp. 487–493.
[50] Kolbjørn Tunstrøm, Yael Katz, Christos C Ioannou, Cristián Huepe, Matthew J Lutz,
andIainDCouzin.“Collectivestates,multistabilityandtransitionalbehaviorinschool-
ing fish”. In: PLoS computational biology 9.2 (2013), e1002915.
[51] IreneGiardina.“Collectivebehaviorinanimalgroups:theoreticalmodelsandempirical
studies”. In: HFSP journal 2.4 (2008), pp. 205–219.
[52] Rafael Kaufmann, Pranav Gupta, and Jacob Taylor. “An active inference model of
collective intelligence”. In: Entropy 23.7 (2021), p. 830.
[53] Conor Heins, Brennan Klein, Daphne Demekas, Miguel Aguilera, and Christopher L
Buckley. “Spin glass systems as collective active inference”. In: Active Inference: Third
International Workshop, IWAI 2022, Grenoble, France, September 19, 2022, Revised
Selected Papers. Springer. 2023, pp. 75–98.
[54] Matthew MG Sosna, Colin R Twomey, Joseph Bak-Coleman, Winnie Poel, Bryan C
Daniels, Pawel Romanczuk, and Iain D Couzin. “Individual and collective encoding
of risk in animal groups”. In: Proceedings of the National Academy of Sciences 116.41
(2019), pp. 20556–20561.
[55] Thomas Parr, Jakub Limanowski, Vishal Rawji, and Karl Friston. “The computational
neurology of movement under active inference”. In: Brain (2021).
[56] JeromeBuhl,DavidJTSumpter,IainDCouzin,JoeJHale,EmmaDespland,EdgarR
Miller, and Steve J Simpson. “From disorder to order in marching locusts”. In: Science
312.5778 (2006), pp. 1402–1406.
[57] Iain D Couzin, Christos C Ioannou, Güven Demirel, Thilo Gross, Colin J Torney, An-
drew Hartnett, Larissa Conradt, Simon A Levin, and Naomi E Leonard. “Uninformed
individuals promote democratic consensus in animal groups”. In: science 334.6062
(2011), pp. 1578–1580.
[58] Ariana Strandburg-Peshkin, Damien R Farine, Iain D Couzin, and Margaret C Cro-
foot. “Shared decision-making drives collective movement in wild baboons”. In: Science
348.6241 (2015), pp. 1358–1361.
[59] Vivek H Sridhar, Liang Li, Dan Gorbonos, Máté Nagy, Bianca R Schell, Timothy
Sorochkin, Nir S Gov, and Iain D Couzin. “The geometry of decision-making in indi-
viduals and collectives”. In: Proceedings of the National Academy of Sciences 118.50
(2021).
27
[60] Allison Kolpas, Michael Busch, Hong Li, Iain D Couzin, Linda Petzold, and Jeff
Moehlis. “How the spatial position of individuals affects their influence on swarms:
a numerical comparison of two popular swarm dynamics models”. In: PloS one 8.3
(2013), e58525.
[61] AnastasiaBizyaeva,AlessioFranci,andNaomiEhrichLeonard.“Nonlinearopiniondy-
namics with tunable sensitivity”. In: IEEE Transactions on Automatic Control (2022).
[62] HeikoHamann.“Evolutionofcollectivebehaviorsbyminimizingsurprise”.In:Artificial
Life Conference Proceedings. MIT Press One Rogers Street, Cambridge, MA 02142-
1209, USA journals-info ... 2014, pp. 344–351.
[63] Tanja Katharina Kaiser and Heiko Hamann. “Innate Motivation for Robot Swarms by
Minimizing Surprise: From Simple Simulations to Real-World Experiments”. In: IEEE
Transactions on Robotics 38.6 (2022), pp. 3582–3601.
[64] Daniela Gandolfi, Francesco M Puglisi, Giulia M Boiani, Giuseppe Pagnoni, Karl J
Friston, Egidio D’Angelo, and Jonathan Mapelli. “Emergence of associative learning
in a neuromorphic inference network”. In: Journal of Neural Engineering 19.3 (2022),
p. 036022.
[65] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, Giovanni
Pezzulo, et al. “Active inference and learning”. In: Neuroscience & Biobehavioral Re-
views 68 (2016), pp. 862–879.
[66] MatthiasHHennig.“Theoreticalmodelsofsynapticshorttermplasticity”.In:Frontiers
in computational neuroscience 7 (2013), p. 45.
[67] Ashley JW Ward, James E Herbert-Read, David JT Sumpter, and Jens Krause. “Fast
and accurate decisions through collective vigilance in fish shoals”. In: Proceedings of
the National Academy of Sciences 108.6 (2011), pp. 2312–2315.
[68] Ariana Strandburg-Peshkin, Colin R Twomey, Nikolai WF Bode, Albert B Kao, Yael
Katz, Christos C Ioannou, Sara B Rosenthal, Colin J Torney, Hai Shan Wu, Simon
A Levin, et al. “Visual sensory networks and effective information transfer in animal
groups”. In: Current Biology 23.17 (2013), R709–R711.
[69] Jacob D Davidson, Matthew MG Sosna, Colin R Twomey, Vivek H Sridhar, Simon
P Leblanc, and Iain D Couzin. “Collective detection based on visual information in
animal groups”. In: Journal of the Royal Society Interface 18.180 (2021), p. 20210142.
[70] Roy Harpaz, Minh Nguyet Nguyen, Armin Bahl, and Florian Engert. “Precise visuo-
motor transformations underlying collective behavior in larval zebrafish”. In: Nature
communications 12.1 (2021), p. 6578.
[71] Luis Gómez-Nava, Robert T Lange, Pascal P Klamser, Juliane Lukas, Lenin Arias-
Rodriguez, David Bierbach, Jens Krause, Henning Sprekeler, and Pawel Romanczuk.
“Fish shoals resemble a stochastic excitable system driven by environmental perturba-
tions”. In: Nature Physics (2023), pp. 1–7.
28
[72] Roger C Conant and W Ross Ashby. “Every good regulator of a system must be a
model of that system”. In: International journal of systems science 1.2 (1970), pp. 89–
97.
[73] AlexanderDWissner-GrossandCameronEFreer.“Causalentropicforces”.In:Physical
review letters 110.16 (2013), p. 168702.
[74] Hannes Hornischer, Stephan Herminghaus, and Marco G Mazza. “Structural transition
inthecollectivebehaviorofcognitiveagents”.In:Scientific reports 9.1(2019),p.12477.
[75] Daniel Ari Friedman, Alec Tschantz, Maxwell JD Ramstead, Karl Friston, and Axel
Constant. “Active Inferants: an active inference framework for ant colony behavior”.
In: Frontiers in behavioral neuroscience 15 (2021), p. 647732.
[76] Mahault Albarracin, Daphne Demekas, Maxwell JD Ramstead, and Conor Heins.
“Epistemic communities under active inference”. In: Entropy 24.4 (2022), p. 476.
[77] P Read Montague, Raymond J Dolan, Karl J Friston, and Peter Dayan. “Computa-
tional psychiatry”. In: Trends in cognitive sciences 16.1 (2012), pp. 72–80.
[78] Ryan Smith, Paul Badcock, and Karl J Friston. “Recent advances in the application of
predictive coding and active inference models within clinical neuroscience”. In: Psychi-
atry and Clinical Neurosciences (2020). url: https://onlinelibrary.wiley.com/
doi/abs/10.1111/pcn.13138.
[79] R Escobedo, V Lecheval, V Papaspyros, F Bonnet, F Mondada, Clément Sire, and
Guy Theraulaz. “A data-driven method for reconstructing and modelling social inter-
actions in moving animal groups”. In: Philosophical Transactions of the Royal Society
B 375.1807 (2020), p. 20190380.
[80] Rajnesh K Mudaliar and Timothy M Schaerf. “An examination of force maps targeted
at orientation interactions in moving groups”. In: Plos one 18.9 (2023), e0286810.
[81] William D Penny, Jérémie Mattout, and N Trujillo-Barreto. “Bayesian model selection
and averaging”. In: Statistical Parametric Mapping: The analysis of functional brain
images. London: Elsevier (2006).
[82] Conor Heins. Collective Motion ActInf. Deposited on July 27, 2023. 2023. url: https:
//github.com/conorheins/collective_motion_actinf.
29
A An active inference model of collective motion
Eachagentwithinourmodelofcollectivemotionmaintainsaninternalmodelofitslocalenvi-
ronment represented by average distances to its neighbours. These distances are partitioned
into L sensory sectors x = x ,x ,...,x , with each agent observing noisy versions of these
1 2 L
distances through a corresponding sensory channel y = y ,y ,...,y . Each agent estimates
1 2 L
the hidden distance variable(s) x over time using its observed sensory states y. In practice,
each agent implements this through a form of variational Bayesian inference developed for
continuous data-assimilation in dynamic environments called generalized filtering, which can
be seen as a variational, more flexible version of Kalman filters. This dynamic inference
process entails updating posterior beliefs about x using a gradient descent on variational
free energy. In the case of Gaussian assumptions about observation and state noise, these
free energy gradients resemble a precision-weighted average of sensory and state prediction
errors. This comprises the state-estimation component of active inference and is unpacked
in detail in Section A.1.
In addition to estimating the hidden distance variable with generalized filtering, each
agent also changes its heading direction v in order to minimize the same variational free
energy functional. When the agent’s model of the distance dynamics is strongly ‘biased’
by a prior belief that the steady-state value of the distance variable(s) x˜ hovers around a
particular value η, then agents will change their heading in a way that appears like they
‘want’ to maintain this target distance between them and their neighbours. Concretely, this
means they move closer to neighbors when the sensed distance y is larger than expected,
and move away from neighbors when y is smaller than expected.
This symmetry between belief updating and action, as both following the gradients of
the same loss function, is what theoretically distinguishes active inference from other con-
tinuous control schemes, which often use different objectives for estimation and control. In
the following sections we detail the processes of state-estimation and action under active
inference.
A.1 Generalized filtering overview
Agents estimate hidden states x as the variational solution to a Bayesian inference problem;
they achieve this in practice using an online-filtering algorithm known as generalized filtering
[1, 2]. Generalized filtering is a generic Bayesian filtering scheme for non-linear state-space
models formulated in generalized coordinates of motion [3]. It subsumes, as special cases,
variational filtering [4], dynamic expectation maximization [5] and generalized predictive
coding [6]. This inversion scheme relies on a simple dynamical generative specification of
hidden states x and how they relate to observations y. The generative model starts by
postulatingthatthetimeevolutionofavariablexisgivenbyastochasticdifferentialequation
with the following form:
dx
t
= f(x )+ω (A.1)
t t
dt
30
where f is some deterministic flow function (i.e., a vector field) that depends on the
current state x , and ω is a (smooth) additive Gaussian noise process. Under generalized
t t
filtering, we successively differentiate (A.1), to finesse the difficult computation of the paths
or trajectories of x locally in time, by instead focusing on the much easier problem of
t
computing the serial derivatives of x . This allows one to express a local trajectory of
t
⃗x = {x ,x ,...,x } in terms of the derivatives of x , i.e., x˜ = (x′,x′′,x′′′,...,x[n],...),
t t+1 t+T t t t t t t
where x[n] := dn x . We used the notation x˜ to denote a vector of these higher orders
t dtn t t
of motion at time t, a representation known as generalized coordinates. The equivalence
between generalized coordinates and paths locally in time follows from Taylor’s theorem,
where the path of x around some time t can be expressed as a combination of its higher
order derivatives:
(cid:88) ∞ x[n]
x = x[0] + hn (A.2)
t+h t n!
n=1
Note that the (local in time) equality between a path ⃗x and its Taylor series only holds
when the sample paths of x are analytic functions, which itself requires f to be analytic
t
and the noise process ω to be analytic (in particular non-white noise fluctuations) [7].
t
Successively differentiating the base equation in (A.1) (and ignoring contributions of the
flow of order higher than one) yields a series of stochastic differential equations that describe
the evolution of each order of motion x[n] as depending on its own state and the nth derivative
t
of the noise [3]:
x˙ = f(x)+ω
x˙′ = f x′ +ω′
x
x˙′′ = f x′′ +ω′′
x
.
.
.
˜
⇒ Dx˜ = f +ω˜
where, following the notation used in [1–3], we use the notation f for the Jacobian (i.e.,
x
matrix of first order partial derivatives) of the flow function f evaluated at x, i.e., Jf(x), and
omit the time variable from our notation for conciseness. Note that the above construction
assumes a local linearization of f around x, in the sense that it ignores the contribution of
higher order derivatives of the flow [3]. The D is the time derivative operator in generalised
˜
coordinates, with identity matrices along the first leading (block) diagonal and f,ω˜ are the
generalized flow function and generalized noises, respectively:
     
0 I f(x[0]) ω[0]

... ...
 f x[1]  ω[1]
D =   f ˜ =  x .  ω˜ =  . 


...
I




.
.




.
.


0 f x x[n] ω[n]
31
Here, n is some chosen order at which to truncate the derivatives. This truncation means
that the Taylor expansion of a path⃗x in (A.2) is rendered an approximation – valid locally in
time. Having specified a dynamics over x (and its reformulation in generalized coordinates),
we are in a position to specify the observation model. In generalized filtering, the generative
model of state dynamics is supplemented with an observation model that maps hidden states
x to their sensory consequences y via some (differentiable) sensory map g(x) and additive
Gaussian smooth fluctuations z:
y = g(x )+z (A.3)
t t t
Likethestates,wecansimilarlyexpressobservationsingeneralizedcoordinatesbysucces-
sivelydifferentiating(A.3)toobtainasimilarsingleexpressionforthegeneralizedobservation
equation:
y = g(x)+z
y′ = g x′ +z′
x
y′′ = g x′′ +z′′
x
.
.
.
⇒ y˜= g˜+z˜
where here the ith motion of observations y[i] is not a function of itself but rather that of
the motion of the (generalized) hidden states x[i] and fluctuations z[i]. In other words, the
motion of observations tracks the simultaneous motion of the states, subject to any nonlin-
earities in the sensory map g and the motion of the noise z. Given Gaussian assumptions on
the generalised noises ω˜ and z˜, we can then write down the full hidden state and observation
model p(y˜,x˜) in terms of Gaussian densities:
Dx˜ = f
˜
+ω˜ ω˜ ∼ N(ω˜;0,Σ
˜ω)
y˜= g˜+z˜ z˜∼ N(z˜;0,Σ
˜z)
=⇒ p(y˜,x˜) = p(y˜|x˜)p(Dx˜|x˜)
= N(y˜;g˜,Σ
˜z)N(Dx˜;f ˜
,Σ
˜ω)
(A.4)
This Gaussian specification of the generative model licenses efficient, online update rules
for the sufficient statistics of approximate posterior beliefs that track the expected value of
the generalised hidden state x˜. This relies on a simple expression for the variational free
energy of this state-space model; as we will see in the following sections, this not only enables
efficient state estimation (a.k.a, updating beliefs about hidden states x˜), but also algorithms
for inferring generative model parameters.
32
A.2 State estimation under generalized filtering
Generalized filtering relies on optimizing posterior beliefs in order to minimize variational
free energy F, an upper bound on the surprise associated with observations y under some
generative model m:
F ≥ −lnp(y;m) (A.5)
(cid:124) (cid:123)(cid:122) (cid:125)
surprise
where the model m defines a joint distribution over observations and latent variables
p(y,ϑ). The latent variables themselves ϑ are often split into hidden states x and parameters
θ. Exact Bayesian inference entails obtaining the posterior distribution over latent variables
p(ϑ|y), which can be expressed using Bayes rule:
p(y,ϑ)
p(ϑ|y) = (A.6)
p(y)
(cid:90)
p(y) ≜ p(y,ϑ)dϑ (A.7)
where hereafter we leave out the dependence on the model m.
In order to compute the posterior exactly, one has to compute the marginal probability of
observations p(y), also known as the marginal likelihood or model evidence. Computing the
marginal likelihood is often intractable or difficult in practice, motivating the introduction
of the variational bound, the free energy F, also known as the (negative) evidence lower-
boundorELBO.ThiscanbeshownbywritingF astheKullback-Leiblerdivergencebetween
some "variational" distribution q(ϑ;ν) over latent variables with parameters ν and the true
posterior p(ϑ|y):
F = E [lnq(ϑ)−lnp(y,ϑ)]
q
= D (q(ϑ;ν)||p(ϑ|y))−lnp(y) (A.8)
KL
(cid:124) (cid:123)(cid:122) (cid:125)
surprise
=⇒ F ≥ −lnp(y) (A.9)
The upper bound holds because the Kullback-Leibler divergence is always non-negative
D (p||q) ≥ 0. Intuitively, as the variational distribution q(ϑ;ν) better approximates the
KL
true posterior distribution p(ϑ|y), where the (in)accuracy of the approximation is measured
by the KL divergence, then the tighter the free energy bounds the surprise. This decom-
position also makes clear why minimizing F with respect to variational parameters ν is a
way to update the variational distribution q to approximate the true posterior p(ϑ|y). The
variational distribution is thus often referred to as an approximate posterior, where the ex-
act posterior obtained by applying Bayesian rule as in Equation (A.6) corresponds to the
variational posterior that minimises F.
33
Now we turn to deriving the Laplace-approximation to the variational free energy (VFE)
for the Gaussian state-space models used in generalised filtering. The Laplace approxima-
tion is an analytically tractable way to approximate the true posterior with a Gaussian
distribution, which simplifies inference to an online filtering algorithm that corresponds to
minimizing a sum of squared prediction errors.
Recall that our goal is to perform inference on the latent variables ϑ by optimizing an
approximate posterior distribution q(ϑ;ν). In our case, we let ϑ = {x,θ} where x are hidden
states and θ encompass other generative model parameters (e.g., hyperparameters of the
generative model like f
˜
,g˜,Σ
˜z,Σ ˜ω).
For now we focus on inference over hidden states x
and treat parameter inference later. Under the Laplace approximation we use a Gaussian
distribution for the approximate posterior distribution q(x;ν):
q(x;ν) = N(x;µ,Σν) (A.10)
(cid:124)(cid:123)(cid:122)(cid:125)
ν
where the variational parameters ν are comprised of the sufficient statistics of a Gaussian
distribution: the mean µ and covariance Σν. We add the subscript ν to the variational
variance to distinguish it from generative model covariances, e.g. Σ
˜z,Σ ˜ω.
We can now arrive at a more specific expression for the variational free energy using the
Gaussian form of the variational distribution. We start by decomposing the free energy into
the sum of an expected energy term and a (negative) entropy, where the energy is defined
as the negative log joint density over states and observations: −lnp(x,y) and the negative
entropy is that of the variational posterior i.e., E [lnq(x;ν)]:
q
1
F = E [−lnp(x,y)]− [ln|Σ|+dln2πe] (A.11)
q
2
where d is the dimensionality of x and the full term on the right follows from the entropy
of a multivariate Gaussian: H[N(x;µ,Σ)] = 1 [ln|Σ|+dln2πe].
2
AdditionalassumptionsallowonetofurthersimplifytheexpectedenergytermE [−lnp(x,y)];
q
namely, if we assume that the posterior is tightly peaked around the mean µ and that p(x,y)
is twice-differentiable in x, we can motivate a 2nd-order Taylor expansion of the expected
energy term around its mode, i.e. when x = µ:
(cid:34) (cid:35)
(cid:12) (cid:12)
E [−lnp(x,y)] ≈ E −lnp(µ,y)−∇ lnp(x,y) (cid:12) (cid:12) (x−µ)− 1 (x−µ)⊤∇2 lnp(x,y) (cid:12) (cid:12) (x−µ)
q q x (cid:12) 2 x (cid:12)
x=µ x=µ
(cid:32) (cid:33)
(cid:12)
1 (cid:12)
= −lnp(µ,y)− tr Σ∇2 lnp(x,y)(cid:12) (A.12)
2 x (cid:12)
x=µ
Combining this approximation of the expected energy with the remaining terms in the
variational free energy, we can now write the full expression of the Laplace-approximated
free energy F :
L
34
(cid:32) (cid:33)
(cid:12)
1 (cid:12) 1
F = −lnp(µ,y)− tr Σ∇2 lnp(x,y)(cid:12) − (ln|Σ|+dln2πe) (A.13)
L 2 x (cid:12) 2
x=µ
A useful feature of this expression is that the optimal variational covariance Σν can
obtained by setting the derivative of F with respect to the covariance Σ equal to 0 and
L
solving for Σ, i.e. finding the values of the covariance that minimize the F :
L
(cid:32)
(cid:12)
(cid:33)−1
∂F L = 0 ⇐⇒ Σν = − ∇2 lnp(x,y) (cid:12) (cid:12) (A.14)
∂Σ x (cid:12)
x=µ
i.e., the optimal variance of the variational distribution is the curvature of the Laplace
energy around its mode. Substituting this expression back into the full free energy, we can
then write an expression that only depends on the mean vector µ of the variational density,
since the variatonal variance Σν is now expressed as a function of the mean:
1 1
(cid:0) (cid:1)
F = −lnp(µ,y)+ tr Σν(Σν)−1 − (ln|Σν|+dln2πe)
L
2 2
(cid:124) (cid:123)(cid:122) (cid:125)
=d
1
= −lnp(µ,y)− (ln|Σν|+dln2π) (A.15)
2
This means that the Laplace approximation to the variational free energy is a function of
onlythevariationalmeanµandsensoryobservationsy, becausethevariationalvarianceΣν is
itself a function of µ. Belief updating then consists in minimizing the Laplace-approximated
free energy F with respect to µ:
L
µ˙ ∝ −∇ F (µ,y) (A.16)
µ L
Which consists of descending the gradient of the energy and log determinant terms with
respect to µ. When the generative model p(x,y) is Gaussian, the energy term is quadratic
in µ and y. This means that its gradient can be written in terms of precision-weighted
prediction errors, which score the difference between the expected observations (given the
current value of µ) and the actual observations y. This notion of using prediction errors to
estimate hidden quantities is also known as predictive coding [8–10]. The log determinant
term — in all of our cases of interest — turns out to have a vanishing gradient with respect
to µ. In summary, the free energy gradient is a sum of precision-weighted prediction errors,
and µ evolves to minimize those prediction errors.
To illustrate this, we take the simplest example — that of a linear, static, joint Gaussian
generative model, where the prior over hidden states p(x) is a Gaussian density with mean η
35
and covariance Σω, and the observation model p(x|y) is a Gaussian density with mean g(x),
which is some linear function of the hidden state:
y ∼ N(g(x),Σz), x ∼ N(η,Σω). (A.17)
For this linear Gaussian generative model, the variational mean µ only influences the
expected energy term of F , because the optimal covariance Σν is independent of µ. Thus
L
we ignore the constant entropy term and write out the energy as a sum of precision-weighted
prediction errors:
−lnp(µ,y) = −lnp(y|µ)−lnp(µ)
1
(cid:2) (cid:3)
= εTΠzε +εTΠωε
2 z z ω ω
where Πz = (Σz)−1, Πω = (Σω)−1
and ε = y −g(µ), ε = µ−η (A.18)
z ω
We can write out gradients of this quadratic energy function to yield the update equation
for the means µ as in (A.16), and see that µ changes as a precision-weighted sum of ‘sensory‘
and ‘model’ prediction errors (up to additive constants):
µ˙ = −∇ F (µ,y)
µ L
(cid:20) (cid:21)
1
(cid:0) (cid:1)
= −∇ εTΠzε +εTΠωε
µ 2 z z ω ω
(cid:2) (cid:3)
= − (g )TΠzε +Πωε (A.19)
µ z ω
Note that the variational means only depend on the terms of F containing ε and ε , so
L z ω
that the update reduces to a gradient descent on a sum of squared prediction errors. This
belief update scheme illustrates the key principles of predictive coding under the Laplace
approximation: conditional means, denoted as µ, change as a function of precision-weighted
prediction errors. The concept of precision-weighting in belief updating is intuitive: if the
generative model attributes higher variance to sensory fluctuations as compared to state
variance (i.e., Πz < Πω), then sensory data is relatively unreliable and consequently makes
a smaller impact on posterior beliefs. Therefore, the adjustment to the posterior mean
µ in (A.19) is primarily influenced by the state prediction error term Πωε or the prior.
ω
Conversely, when sensory information is allocated higher precision (lower variance) relative
to prior beliefs (i.e., Πz > Πω), belief updates will strongly rely on sensory data.
We apply the above steps to derive the Laplace-approximated free energy with a Gaus-
sian posterior q(x;ν) to the dynamical generative model in (A.4),which is constructed from
Gaussian densities. Note that we use the tilde notation to now indicate that all variables are
vectors of generalised coordinates, e.g., y˜,x˜, etc. Proceeding exactly as above, the Laplace
36
free energy is a sum of the energy, a log determinant term, and a constant term, i.e. (A.15).
Unlike in the linear Gaussian case, the potential non-linearity in the flows make that the log
determinant term varies with respect to µ. However, as it turns out its gradient is approxi-
mately zero under the local linear approximation. Therefore, the only term that matters in
the free energy as its gradient does not vanish is the energy term. In summary, we write:
F ∝ ε˜TΠ ˜zε˜ +ε˜TΠ ˜ωε˜ (A.20)
L z z ω ω
ε˜ ≜ y˜−g˜
z
ε˜ ≜ Dµ˜−f ˜
ω
Here, the so-called ‘generalised errors’ ε˜ and ε˜ encapsulate sensory and state prediction
z ω
errors across orders of motion. Belief updating is again performed using a gradient descent
on free energy, but the dynamic nature of inference necessitates an additional ’motion’ term:
dµ˜
= Dµ˜−∇ F
µ˜ L
dt
= Dµ˜+g⊤ξ ˜ +f⊤ξ ˜ −D⊤ξ ˜
µ˜ z µ˜ ω ω
where ξ
˜
= Π
˜zε˜
z z
ξ
˜
= Π
˜ωε˜
(A.21)
ω ω
The additional term Dµ˜ places the gradient descent within the context of the expected
movement of the conditional means µ˜, and hence of the free energy minimum. This concept
has been referred to as ’gradient descent in a moving frame of reference’ [1]. This implies
that free energy minimization does not occur when the beliefs cease moving, but rather when
the belief update rate dµ˜ is identical to the beliefs about the motion itself Dµ˜, in other words
dt
when ∂F = 0 ⇐⇒ Dµ˜ = dµ˜. This additional temporal correction proves beneficial in a
∂µ˜ dt
dynamic data assimilation regime, where incoming observations are integrated online with
beliefs that are evolving according to their own prior dynamics [1].
A.3 Active inference for continuous control
Active inference casts action or control as issuing from the same process of free energy min-
imization as used for state estimation; the only difference is that we now have an additional
set of variables, actions a, that can be changed to minimize free energy as well. The update
equation for actions a closely resembles that used to update the variational mean µ, i.e., a
gradient descent on the (Laplace-encoded) variational free energy:
da ∂F (µ,y(a))
L
= −
dt ∂a
∂F ∂y(a)
L
= − (A.22)
∂y(a) ∂a
37
where we have now introduced a dependence between of observations y on actions a.
This allows us to express the free energy gradient with respect to action as the product
of the derivative of the free energy with respect to observations ∇ F (µ,y(a)) and the
y L
derivative of the function mapping from actions to observations ∂y(a). The free energy
∂a
gradient with respect to observations is exactly the sensory prediction error ∇ F (µ,y(a)) =
y L
ξ = Π(y − g(x)). This assumed dependence of observations on actions underwrites the
z
notion that active inference agents cannot directly measure how their actions affect hidden
states, but may only do so via their sensory consequences. This has been speculated to
explain the architecture of descending motor pathways in corticospinal systems, where motor
commands are ‘unpacked’ into proprioceptive predictions at the level of spinal circuits and
other lower motor nuclei. Action is thus realized by minimizing proprioceptive prediction
errors via classical reflex arcs [11]. The reflex arc term ∂y(a) of (A.22) is analogous to a
∂a
forward model in motor control [12], because it reflects the agent’s implicit assumptions
about how the agent’s own actions lead to their (anticipated) sensory consequences. This
sort of update rule leads active inference agents to minimize sensory prediction errors via
these ‘baked-in’ sensorimotor contingencies. In this way active inference has been referred
to as ‘action by self-fulfilling prophecy’ [6]. In other words, the agent generates top-down
expectations of ‘preferred’ sensory inputs, which then generates prediction errors which can
then be suppressed through low-level motoric reflexes [11].
A.4 Filtering and control for a self-propelled particle
Having derived a routine for state estimation and action through a generalized gradient
flow on the Laplace-approximated variational free energy F , we can now apply this to
L
the simulation of collective motion. In what follows, we write down a sufficient generative
model for a single self-propelled agent and unpack the corresponding free energy gradients
((A.20) and (A.22)) using the structure and parameters of the chosen generative model. In
this section we unpack the per-agent generative model of local distances described in the
main text and demonstrate how a more parametric, unconstrained version of social forces
are reproduced by minimizing free energy with respect to the distance-tracking generative
model.
A.4.1 A generalised filter for local distances and their time evolution
As described in the main text, each agent represents a an L-dimensional vector x where
x = (x ,x ,...,x ).1 The agent not only represents the instantaneous value (or ‘position’) of
1 2 L
x but also its generalized motion, which we truncate at 3rd order:
1We use the bold notation x to represent a vector-valued variable
38
x˙ = f(x)+ω
x˙′ = f x′ +ω′
x
x˙′′ = f x′′ +ω′′
x
⇒ Dx˜ = ˜ f +ω˜
The flow at the first order f is a linear dynamical system with drift matrix A and fixed
point with value η:
f(x) = −A(x−η) (A.23)
TheeigenvaluesoftheL×LmatrixAdeterminetherateatwhichthehiddenstatesxare
assumed to relax to their expected value of η. In general, this matrix can be parameterized
arbitrarily to encode different kinds of linear couplings among the different hidden states
x ,x ,...,x . In the present work we parameterize A simply as a diagonal matrix with a
1 2 L
singlediagonalvalueα > 0, whichcanalsobeexpressedasanα-scaledversionoftheidentity
matrix L×L identity matrix I :
L
A = −αI (A.24)
L
In combination with the amplitude of random fluctuations Σω, α determines how quickly
the hidden states relax to their mean value of η.2 The generalised flow function ˜ f can thus
be written as a linear function of the generalised state x˜:
    
f(x) A 0 0 x−η
˜ f = f x x′  = −0 A 0 x′ 
f x′′ 0 0 A x′′
x
    
−αI 0 0 x−η x−η
L
=  0 −αI L 0  x′  = −α x′  (A.25)
0 0 −αI x′′ x′′
L
where 0 are L × L matrices of zeros. We assume a multivariate Gaussian form for the
generalized noises ω˜, meaning the density over the generalized motion Dx˜ is a Gaussian
density, which we hereafter refer to as the ‘dynamics model’ or ‘dynamical prior’:
P(Dx˜|x˜) = N(Dx˜; ˜ f,Σ ˜ω) (A.26)
2Heuristically, it is an exponential decay rate.
39
˜
Consistentwiththeblockdiagonalformofthegeneralisedflowfunctionf, wealsoassume
the covariance of the generalized noises Σ
˜ω
factorizes into a Kronecker product of ‘spatial’
and ‘temporal’ covariance matrices, i.e.,
Σ ˜ω = Σω ⊗Σ ˜ω (A.27)
where the spatial covariance Σω (note the bold superscript ω) represents covariance
between L noise processes at the zero-th order ω[0], i.e., Σω = E[ω[0]⊗ω[0]], and Σ ˜ω encodes
(cid:16) (cid:17)
covariance between different derivatives of the first order noise, i.e., ∀m,n : Σ
˜ω
=
nm
E[ω[n]·ω[m]]. The entries of this covariance matrix can be written in terms of the derivatives
of the autocorrelation function of the random fluctuations evaluated at lag 0, ρ(0):
ρ(h) ≜ (Σω)−1E[ω[0](τ)·ω[0](τ +h)]
 
1 0 ρ¨(0)
 0 −ρ¨(0) 0 
⇒ Σ ˜ω =  ρ¨(0) 0 ρ¨¨(0)   (A.28)
 
...
The checkerboard structure in the matrix reflects the fact that fluctuations at the first
order are orthogonal to their motion (first derivative), but anti-correlated with their 2nd,
4th, ..., etc. derivatives. A derivation of the temporal covariance matrix from the autocor-
relation function of the first-order fluctuations can be found in Appendix A.5.3 of [13]. In
the generative models of our agents, we assume a Gaussian autocorrelation function with
"smoothness" parameter λ , which yields a simple parameterization of Σ
˜ω:
ω
ρ(h) = e− 2λ h ω 2 (A.29)
 1 0 − 1 ...
2λ2
ω
 0 1 0 
⇒ Σ ˜ω =  2λ2 ω  (A.30)
− 1 0 3 
 2λ2 4λ4 
. .
.
ω ω ...
A higher value of λ dampens the variance of the generalised fluctuations at higher orders
ω
of differentiation. The correspondence of increasing λ to an increasingly-autocorrelated
ω
process at the first order becomes intuitive once we consider the case of standard white
noise, i.e., the derivative of the Wiener process, whose higher orders of motion have infinite
variance (the state of the process at a given time changes infinitely quickly). This ability to
handle differentiable noise goes beyond the usual Markovian assumptions made in standard
state space models (e.g., Kalman-Bucy filters), which assume that the driving noise is white.
We parameterize the L×L spatial covariance Σω through its precision matrix Πω, as a
diagonal matrix whose entries are given by a single precision (inverse variance) Γ :
ω
40
 −1
Γ 0 0 ...
ω
 0 Γ 0 
ω
Σω = (Πω)−1 =   (A.31)
 0 0 Γ 
ω
 . .
.
... 
The observation likelihood describes sensory observations y = {y ,y ,...,y } as noise-
1 2 L
perturbed copies of the hidden states x. We truncate generalized observations at second
order, i.e., agents can sense the first order hidden state x and its motion x′:
y = x+z
y′ = x′ +z′ (A.32)
This can be equivalently expressed as a linear function g˜ of the full generalised state
x˜ = {x,x′,x′′}, where g˜ represents multiplication with a non-invertible matrix that discards
acceleration information x′′:
y˜ = g˜ +z˜
 
(cid:20) (cid:21) (cid:20) (cid:21) x (cid:20) (cid:21)
y I 0 0 z
= L x′ + (A.33)
y′ 0 I 0 z′
L x′′
We leverage the same assumptions about the sensory noises z˜ as we did for the state
noises ω˜ to end up with the following multivariate Gaussian form for the observation model:
p(y˜|x˜) = N(y˜;g˜,Σ ˜z) (A.34)
We parameterize the likelihood model’s sensory noises z˜ identically to the state noises ω˜,
namely using a spatial precision parameter Γ and temporal smoothness parameter λ .
z z
HavingspecifiedthedynamicsandobservationmodelsintermsofGaussiandistributions,
we can write out the full generative model as a joint Gaussian density over (generalized)
hidden states and observations. We can furthermore define an approximate posterior over
the hidden states x˜ that has a multivariate Gaussian form Q(x˜) = N(x˜;µ˜;Σν), which can be
summarized entirely in terms of its posterior mean vector µ˜, due to the fact that under the
Laplace approximation the variational covariance depends directly on the mean. From here,
we can define the Laplace-approximated variational free energy for this generative model as
proportional to a sum of squared prediction errors:
41
p(y˜,x˜) = p(y˜|x˜)p(Dx˜|x˜)
= N(y˜;g˜,Σ ˜z)N(Dx˜;f ˜ ,Σ ˜ω) (A.35)
1 (cid:104) (cid:16) (cid:17) (cid:105)
F = ε˜⊤Π ˜zε˜ +ε˜⊤Π ˜ωε˜ −ln |Π ˜z||Π ˜ω||Πν| +3Lln2π
L 2 z z ω ω
where Πν ≜ (Σν)−1
 
(cid:20) (cid:21) µ′ +α(µ−η)
y−µ
ε˜ z = y˜ −g˜(µ˜) = y′ −µ′ , ε˜ ω = Dµ˜ − ˜ f(µ˜) =  µ′′ +αµ′  (A.36)
αµ′′
where the sensory prediction errors ε˜ score the difference between the generalized ob-
z
servations y,y′ and their expected values µ,µ′, and the model or process prediction errors
ε˜ score the difference between the motion of the generalized means Dµ˜ and their expected
ω
motion ˜ f(µ˜), which has been expanded above using the linear form of the flow function de-
tailed in (A.25). Note that here, due to the Laplace approximation, the generative model’s
expectation functions g˜, ˜ f are evaluated at the variational mean µ˜, rendering the variational
beliefs a moving point-estimate of the hidden states x˜.
Filteringconsistsofupdatingµ˜ asageneralizedgradientflowonthisenergyfunctionalF
L
as in (??). To be explicit, below we expand these free energy gradients using the particular
forms of g˜, ˜ f used by our self-propelled particle agent:
dµ˜
= Dµ˜ −∇ F
µ˜ L
dt
= Dµ˜ +∇ g˜⊤ξ ˜ +∇ ˜ f⊤ξ ˜ −D⊤ξ ˜
µ˜ z µ˜ ω ω
(cid:20) (cid:21)
y−µ
where ξ
˜
= Π
˜z
z y′ −µ′
 
µ′ +α(µ−η)
ξ ˜ = Π ˜ω  µ′′ +αµ′ 
ω
αµ′′
 
(cid:20) I 0 0 (cid:21) −αI L 0 0
∇ µ˜ g˜ = 0 L I 0 , ∇ µ˜ ˜ f =  0 −αI L 0  (A.37)
L 0 0 −αI
L
This sort of filtering scheme means that the agent’s beliefs µ˜ will evolve as a moving
average of incoming sensory data y˜ subject to a dynamical bias or "drag", which is a con-
sequence of the latent belief that hidden states x continuously relax towards a fixed point
at η. Specifically, the beliefs are constantly pulled closer to the data in order to minimize
˜ ˜
sensory prediction errors ξ ; however, this process itself incurs state prediction errors ξ
z ω
that will pull the beliefs back towards the fixed point. This constant tug of war between
sensory and process prediction errors can be shifted disproportionately in one direction by
42
adjusting the relative precisions of the likelihood vs. dynamical models, respectively. If the
process precision Π
˜ω
is high relative to the observation precision Π
˜z,
then the beliefs will
tend to their expected fixed point of η. A similar enhancement of prior bias can be achieved
by increasing the drift rate α of the dynamics model, which increases the force driving µ
towards η — this was the approach taken in [14], for example.
Notethatwhennumericallyintegratingthedifferentialequationin(A.37)withaforwards
Eulerscheme, oneusesafinitenumberofiterationstoupdatethevariationalmeansµ˜, which
we term n , and a step-size κ which scales the size of the increment to µ˜ [6]. In all
InferIter µ
simulations shown here, we set n = 1,κ = 0.1 (see Table E.1 for details).
InferIter µ
A.4.2 Closing the loop with observations and action
Inordertointerprettherandomvariablesofthegenerativemodelasrepresentingbehaviorally-
relevant features of an agent’s world, we now turn to specfiying the generative process, i.e.,
the actual physics of the world that our self-propelled particle agents will inhabit. In this
section we detail how the observations y˜ for a single agent are generated from the positions
and velocities of other active inference agents, and how actions can be generated through
active inference, which in this contexts means changing continuous control variables using a
gradient descent on the same free energy used to derive the belief update equations of the
previous section.
We now shift our perspective to that of a single agent, hereafter referred to as the focal
individual or focal agent, and specify how its sensory data y˜ are generated. We start by
describing univariate hidden states and corresponding observations, where the true hidden
variable is an average nearest-neighbor distance x . We add the h subscript to distinguish
h
these ‘real’ variables (hidden states, observations, noise terms) from their representations in
the generative model (e.g., x˜, y˜).
We indicate the focal individual with index i; so the agent i-relative hidden state x
h,i
denotes the average nearest-neighbor distance from the perspective of agent i. This average
distance x is calculated from the K neighbors that form the interaction set N of the ith
h,i in
focal individual. How to define the interaction set N is a choice to make in each simulation,
in
but for the case of recapitulating classical, distance-dependent social forces models, we define
N as those neighbors that are within a fixed distance R of the focal individual’s position:
in 0
1 (cid:88)
x ≜ ∥∆r ∥
h,i ij
K
j∈Nin
where N ≜ {j ̸= i : ∥∆r ∥ ≤ R } (A.38)
in ij 0
K ≜ |N |
in
∆r ≜ r −r (A.39)
ij j i
An additional filter on N that is common to self-propelled particle models, is to only
in
include neighbors that subtend some angular extent (also known as a ‘vision cone’ or ‘visual
43
field’) relative to the focal agent’s velocity vector v . This is the approach taken in [15], for
i
instance, and in the simulations examined in the main text we do the same.
The vector r denotes the 2-D coordinate of the focal agent, and r is that of neighbor j.
i j
r thus represents the relative displacement vector of neighbour j, from the perspective of
ij
the focal agent i.
We also define the first temporal derivative of the local average distance x′ :
h,i
x˜ ≜ (x ,x′ )
h,i h,i h,i
x′ ≜ dx h,i = ∇ x ·v + (cid:88) (cid:0) ∇ x ·v (cid:1) (A.40)
h,i dt ri h,i i rj h,i j
j∈Nin
where v is the velocity or heading vector of neighbour j. The expression in (A.40) means
j
that we can compute the first derivative or velocity of the distance x′ as a function of the
h,i
positions and velocities of all agents, as opposed to some discrete-time approximation, e.g.,
x′ ≈ x h,i (t+∆t)−x h,i (t) for some small ∆t. Note that this expression for x′ assumes a local
h,i ∆t h,i
linearization of x at the radius defined by R , i.e., this linearization will be a poor predictor
h,i 0
of the actual change in the state x (t + ∆t) − x (t) when neighbors are instantaneously
h,i h,i
leaving or entering the interaction set N . Observations y˜ are perturbed versions of the
in h,i
hidden states with additive generalised fluctuations z˜ :
h,i
y = x +z
h,i h,i h,i
y′ = x′ +z′
h,i h,i h,i
˜
where p(z˜ ) = N(z˜ ;0,Σ ) (A.41)
h,i h,i z,h
In all simulations we parameterize the z˜ as independent Gaussian variables, i.e.,
h,i
(cid:20) (cid:21)
σ2 0
Σ ˜ = z,h (A.42)
z,h 0 σ2
z′,h
where the two variances σ2 and σ2 can be set independently. The ‘perception’ step
z,h z′,h
of our active inference process proceeds by providing these observations to the filtering
equations in (A.37). The result is that posterior means µ˜ appears to track x˜ over time,
h,i
while additionally estimating its higher-order motion (acceleration) via µ′′′.
Finally, we now furnish a scheme for updating actions by mapping the control variables
a and sensorimotor contingency terms of (A.22) to the case of our distance-tracking self-
propelled agent.
We let actions be identifiable with the heading vector v of the focal individual, i.e.,
i
a = v . For the simulations presented in the current paper, we always asserted that this
i
heading have unit magnitude, but in general this constraint is not necessary.
Given this definition of actions, we can unpack the sensorimotor contingency term ∂y(a)
∂a
that appeared in the active inference control equation of (A.22), now letting a = v and
44
turning partial derivatives into Jacobians to account for vectorial nature of actions (being a
velocity in 2-D) and observations (being comprised of two generalized coordinates):
dv
i = −∇ y˜ (v )⊤∇ F (A.43)
dt
vi h,i i y˜
h,i
(vi) L
Note here that observations y˜ are a function of actions; this is because observations are
h,i
a linear function of hidden states, which themselves are linear in the velocity vector of the
focal individual v via the relation in (A.40). Importantly, however, the distance observation
i
y does not directly depend on the v — only the distance velocity y′ does. This means
h,i i h,i
the sensorimotor contingency in (A.43) is comprised of non-zero partial derivatives only for
y′ :
h,i
(cid:20) (cid:21) (cid:20) (cid:21)
∇ y (v ) 0
∇ y˜ (v ) = vi h,i i = (A.44)
vi h,i i ∇ y′ (v ) ∇ x
vi h,i i ri h,i
This has an important consequence for action, when we consider the form of the second
part of the action update in (A.43), the free energy gradient term ∇ F :
y˜ L
h,i
(cid:20) (cid:21)
Γ (y −µ)
∇ F = ξ ˜ = Π ˜ ε˜ = z h,i (A.45)
y˜ h,i L z z z 2Γ λ2(y′ −µ′)
z z h,i
The free energy gradient with respect to observations is simply the generalized (precision-
˜
weighted) sensory error ξ , which we have written in terms of the observations y˜ , posterior
z h,i
beliefs µ˜ and precision parameters Γ ,λ . The sparse form of the sensorimotor contingency
z z
in (A.44) means that the 0th-order prediction error ξ will have no effect on behavior and
z
only the velocity prediction errors ξ′ will be relevant for the update to v , i.e.,
z i
 
dv
dt
i = −ξ
z
∇
vi
y
h,i
(v
i
)+ξ
z
′∇
vi
y
h
′
,i
(v
i
)
(cid:124) (cid:123)(cid:122) (cid:125)
=0
= −ξ′∇ x
z ri h,i
= 2Γ λ2(y′ −µ′)∆ˆr
z z h,i
1 (cid:88) ∆r
where ∆ˆr = ij (A.46)
K ∥∆r ∥
ij
j∈Nin
Note that, as for the inference update in (A.37), we update v using a fixed number
i
of action iterations n and step-size κ , where here we set n = 1,κ = 0.1.
ActionIter a ActionIter a
This action update equation has a few key implications for the behavior of active inference
agents equipped with this type of generative model, and its relationship to ‘classical’ self-
propelled particle models like the Couzin-Aoki model and the Reynolds or BOIDS model
45
[15–17]. The first is the fact that the sensorimotor contingency is identical to the ‘social
force’ vector used to drive interactions in self-propelled particle models ∆ˆr; this the average
of the vectors pointing from each neighbor in the interacting set to the focal agent’s position
r . The sign of the precision-weighted prediction error ϵ′ determines whether the social
i z
force is attractive (pointing towards other agents) or repulsive (pointing away from other
agents). Secondly, the fact that actions only depend on velocity observations, rather than
state observations, means that agents will adjust their heading according to how the (sensed)
distance is instantaneously changing (its velocity), rather than its value. This lends action
a predictive, anticipatory power and accounts for why we observe robust polarized motion
in the absence of an explicit alignment term like in classic self-propelled particle models [15,
18]. The alignment-like forces emerges from the fact that the velocity vectors of other agents
v ,j ∈ N are integrated into the computation of y′ via the relation in the second line of
j in h,i
(A.40).
One of the defining features of other self-propelled particle models like the Couzin-Aoki
model [15, 16] is the presence and priorization of interaction zones. The two main zones
used in these models, and which on their own are sufficient for group cohesion, are a narrow
repulsion zone defined by some radius r and a wider attraction zone with radius r , where
r a
r > r . Neighboring agents within the repulsive radius exert repulsive forces on the focal
a r
agent, while those beyond the repulsion radius but within the attraction zone exert attrac-
tive forces, where the difference between attraction and repulsion is given by the sign of the
force vector ∆ˆr. The active inference model leads to an effective notion of zones, but rather
than being explicitly encoded, these zones emerge through the fixed-point attractor η pa-
rameterizing the generative model’s dynamics model f. This is made clear when we examine
the precision-weighted prediction error ξ′, which itself is a function of velocity observations
z
y′ and velocity beliefs µ′. Consider the limiting case of when inference is strongly biased
h,i
by the dynamics model f (i.e., in the case that Γ > Γ or large α); the generalised beliefs
ω z
µ˜ will be strongly drawn to the setpoint η of the dynamics prior, i.e.,
   
µ η
µ˜ = µ′  ≈ 0
µ′′ 0
Underthisassumption, theprecision-weightedpredictionerrorξ′ approximates2Γ λ2y′ ,
z z z h,i
and thus signals whether neighbors are instantaneously approaching or moving away from
the focal agent, where ξ′ < 0 indicates they are approaching and ξ′ > 0 indicates they are
z z
moving away. This in turn determines whether the update to the focal agent’s action v
i
is repulsive or attractive, as its sign determines the direction of the social force vector ∆ˆr.
Although the first order distance y does not directly drive action, it does so indirectly
h,i
through its effect on inference of µ′. If we consider the case when the sensed distance y
h,i
drops below the setpoint η, then one can reason through the cascade of prediction errors
that ultimately lead to a repulsive force. As a direct consequence of a drop in y below
h,i
µ, sensory prediction errors ξ will become negative, whose minimization will require µ to
z
move below η. This process in turn incurs slower-moving (negative) model prediction errors
46
ξ , whose minimization drives µ back to its fixed point of η, given the dynamic constraint
ω
for the beliefs to relax to their fixed point. In order to accomplish this upward movement
of µ, either the rate of change of µ or the sensed distance itself must be positive, i.e., µ˙ > 0
or y > 0. In the absence of positive y , model prediction errors will drive µ′ (and hence
h,i h,i
µ˙) above 0. This temporarily sets a larger radius of repulsion, i.e., a larger range of y′ for
h,i
which ξ′ is negative and for which repulsive forces impact the focal agent’s velocity. This
z
causes the agent to move away from its neighbors and thus further increase y , under the
h,i
assumption that the agent’s prediction of the distance dynamics are correlated with the true
change in x . Belief updating and action thus work together to accelerate the return of
h,i
˜ ˜
µ towards η and ξ ,ξ towards 0; for this reason active inference is often described as an
z ω
account of action and perception driven by ‘self-fulfilling prophecy’ [6].
Inordertoimbueactionwithamoredirectcouplingtotheneighbors‘distancesasisdone
in the classical self-propelled particle models, rather than the velocity of the distance, one
could hand-craft the sensorimotor contingency term ∇ y˜ to enforce a coupling between
vi h,i
y and v . This would render the action rule equivalent to a ‘soft’-form of PD control
h,i i
[14], where errors on both the first order state (y − µ) ≈ (y − η) and its derivative
h,i h,i
(y′ −µ′) ≈ y′ would drive changes to the velocity.
h,i h,i
A.5 Extending to multiple sensory sectors
The results of the previous sections can be straightforwardly extended to the multivariate
case as explored in the main text. The focal agent now senses the local distance computed
across a set of distinct sensory sectors. For the model explored in the current work, we split
up the computation of the local distance variable into a set of L sensory adjacent sectors
that comprise an arc of a given angle, relative to the agent’s heading vector v . We define
i
the multivariate distance hidden state as follows (dropping the focal agent index i from the
sector-specific hidden states to avoid subscript overload):
 
x
h,1
x 
h,2
x =  .  (A.47)
h,i  . 
.
 
x
h,L
1 (cid:88)
where x ≜ ∥∆r ∥
h,l ij
K
l
j∈N
l
where N is the set of neighbors in the lth sensory sector, and K = |N | (c.f., (A.39)). As
l l l
with the scalar hidden state defined above, we also equip the vector of sector distances x
h,i
with corresponding sector-specific, generalized observations y˜ , i.e.
h,i
47
y = x +z (A.48)
h,i h,i h,i
y′ = x′ +z′
h,i h,i h,i
where p(z˜ ) = N(z˜ ;0,Σ ˜ ) (A.49)
h,i h,i z,h
such that the focal individual now observes a vector of local (noise-perturbed) distances
˜
and their first orders of motion. Note that the generalized covariance matrix here Σ is now
z,h
a 2L × 2L size matrix, that encodes the covariance structure between sector-specific noise
and their generalized orders. For all simulations we generated uncorrelated noise across
the different sectors, although spatially-smooth noise could be modelled by introducing off
diagonal elements in Σ ˜ , i.e., E[z z ] ̸= 0.
z,h h,l h,k
The agent’s generative model is also extended to the multivariate state-space formulation
we began with, using a vector of generalised hidden states x˜ = (x˜ ,x˜ ,...,x˜ ) to estimate
1 2 L
the local distance within each sensory sector. Belief-updating consists in updating a vector
of generalised means µ˜ through integration of (A.37).
The action update has an identical form as before, except now the sensorimotor con-
tingency term ∇ y˜ (v ) is a collection of partial derivative vectors, one for each sensory
vi h,i i
sector:
dv
i = −∇ y˜ (v )⊤∇ F
dt
vi h,i i y˜
h,i
L
 
0
.
 . . 
 
(cid:20) (cid:21)  0 
∇ y (v )  
∇ y˜ (v ) = vi h,i i = ∇ x  (A.50)
vi h,i i ∇ y′ (v )  ri h,1
vi h,i i ∇ x 
 ri h,2
 . . 
 . 
∇ x
ri h,L
ThelastLrowsofthisJacobianmatrixencodethegradientsofthesector-specificdistance
velocities y′ with respect to the focal agent’s action; these partial derivatives are vectors
h,l
pointing from the average position of the neighbors in sector l towards the focal individual.
When we combine the Jacobian matrix in (A.50) with the sensory prediction error term
y˜ (i.e., the free energy gradients ∇ F ), we are left with the following update for the
h,i y˜ L
h,i
velocity:
48
 
∆ˆr
1
dv ∆ˆr 
i = ξ′ ·∆R ˆ = (cid:2) ξ′ ξ′ ... ξ′ (cid:3) · . 2 
dt z z,1 z,2 z,L  . . 
 
∆ˆr
L
L L
(cid:88) (cid:88)
= ξ′ ∆ˆr = 2Γ λ2 (y′ −µ′)∆ˆr (A.51)
z,l l z z h,l l l
l=1 l=1
1 (cid:88) ∆r
where ∆ˆr = ij
l
K ||∆r ||
l ij
j∈N
l
The action thus becomes a weighted sum of ‘sector-vectors’ ∆ˆr , which are vectors point-
l
ing from the focal agent’s position r towards the average position of the neighbors in N .
i l
The weights that scale each ∆ˆr are the precision-weighted prediction errors associated with
l
velocity observations emanating from the appropriate sector ξ′ ∝ (y′ −µ′). The fact we
z,l h,l l
can pull the spatiotemporal precision terms 2Γ λ2 outside the sum over sector-vectors, inher-
z z
its from a between-sector independence assumption, built into the agent’s sensory likelihood
model P(y˜|x˜) (see (A.31)). If the generative model allowed for between-sector correlations
(i.e. Σz was not diagonal), then the action update would include cross-terms that couple
prediction errors from one sector to the sector-vector from another sector.
An active inference agent equipped with such a multivariate representation of the local
neighbor-distances thus engages in a sort of ‘predictive balancing-act’, differentially respond-
ing more or less to each part of its sensory field in accordance with how much sensations
deviate from their posterior expectations µ′, where the sign and degree of this deviation is
l
scored by ξ′ .
z,l
Gaussianity of the generative model
One may question the use of a Gaussian form for the generalized noises z˜,ω˜ and a linear
form for ˜ f and g˜. These assumptions guarantee a simple generative model whose free energy
gradients (with respect to both the state belief µ˜ and action v) are linear in the generalized
distance observations y˜. The reason we use a Gaussian form here, is to achieve those simple,
linear free energy gradients, i.e., those which align with the classical social forces seen in
SPP models (more specifically, the selective attraction-and-repulsion forces first described in
[19]); in other words, it is exactly an active inference model equipped with this sort of model
(and observations with two generalized coordinates, aka position and velocity) that acts in
a way equivalent to being driven by vectorial social forces. Note that this also means the
Laplace approximation to the posterior over x˜ is not an approximation at all, but leads to
exact inference.
Existing social force models where the forces are linear in the state, can thus be read
as special cases of active inference agents equipped with Gaussian generative models – this
is a close cousin to the relationship between linear PID controllers and Gaussian active
49
inference models derived in [14]. However, if we were to use a different, non-Gaussian of the
generative model (either through breaking Gaussianity of the noise model or by introducing
nonlinear forms of ˜ f,g˜), then the updates to the beliefs and actions would no longer be
linear functions of the generalized posterior means µ˜ and observations y˜, but could be
arbitrary, nonlinear functions of these variables – and the resulting social forces would have
no guaranteed interpretation in terms of attraction and repulsion. Such extensions are
an interesting avenue for future work; one interesting possibility would be to explore new
extensions of social forces, where the noises z˜,ω˜ are assumed to belong to the exponential
˜
family and that the dynamics model f is smooth and contains attracting fixed points (i.e.,
˜
regions of x˜ where the derivatives of f vanish). A obvious consequence of such assumptions,
is that when the posterior belief µ˜ is near these fixed points, i.e., µ˜ ≈ argmin ∇ ˜ f(x˜) =⇒
x˜ x˜
µ˜′ = 0,wewouldstillrecoverattractiveandrepulsivesocialforceswhosemagnitudewouldbe
approximately linear in the distance observations y˜. This is equivalent to making a locally-
quadratic (i.e., Laplace) approximation to the free energy landscape around its minima –
this corresponds to just those points in belief-space where the posterior is well-approximated
by a Gaussian.
B Alignment forces from active inference on angles
In previous sections we have shown how repulsive and attractive forces emerge from active
inference models in which the agent entertains a latent representation of the average local
distance between itself and its neighbors, and how its heading direction couples to (the
derivative of) that variable. In this section we derive alignment-based social forces, like
those that appear in the Reynolds, Couzin, and Vicsek models [15, 17, 18], as a special case
of active inference, where an agent infers the (cosine) angle between its own heading and
that of its neighbors, and acts under the prior belief that this angle tends to 0.
As before, we start with a generative model that represents a generalised latent variable
x˜ that evolves in time with Gaussian additive fluctuations ω˜ . We use the ϕ subscript
ϕ ϕ
to distinguish this angle-tracking latent variable from the distance-tracking variable of the
previous section. We truncate the generalized representation of this state at second order,
i.e. x˜ = {x ,x′ }, leading to a dynamical equation and corresponding likelihood of the
ϕ ϕ ϕ
following form:
x˙ = −α (x −1)+ω
ϕ ϕ ϕ ϕ
x˙′ = −α x′ +ω′
ϕ ϕ ϕ ϕ
˜ ˜
=⇒ p(Dx˜ |x˜ ) = N(Dx˜ ;f ,Σ ) (B.52)
ϕ ϕ ϕ ϕ ω
ϕ
(cid:34) (cid:35)
(cid:20) −α (x −1) (cid:21) σ2 0
where f ˜ = ϕ ϕ , Σ ˜ = ω ϕ (B.53)
ϕ −α x′ ω ϕ 0 σ2
ϕ ϕ ω′
ϕ
The observation model describes a mapping from the 0th-order state to a corresponding
observation thereof, perturbed again by Gaussian innovations:
50
y = x +z
ϕ ϕ ϕ
=⇒ p(y |x ) = N(y ;x ,σ2 ) (B.54)
ϕ ϕ ϕ ϕ z
ϕ
Following the same steps as we did previously for the multivariate, distance-tracking
generative model, we can write down the Laplace-approximated variational free energy of
this model as a quadratic function of the observations and generalized means µ˜ :
ϕ
F ∝ ε⊤Π ε +ε˜⊤ Π ˜ ε˜
L z ϕ z ϕ z ϕ ω ϕ ω ϕ ω ϕ
where ε ≜ y −µ
z ϕ ϕ
ϕ
ε˜ ≜ Dµ˜ −f ˜
ω ϕ ϕ
ϕ
The agent performs a gradient descent on F to infer the value of x˜ in light of sensory
L ϕ
observations. ThisinferenceisencodedbyaGaussianvariationalposteriorwithmeanµ˜ . As
ϕ
before, we can tune model parameters such that inference is strongly biased by the dynamics
˜
model f , where the zeroth-order of motion µ ≈ 1. The reason we set the set-point at 1
ϕ ϕ
becomes evident when we consider the generation of sensory data and actions.
Assume that the focal agent with index i observes the local average cosine angle between
its own heading vector v and those of its neighbors v ,j ∈ N , where neighbors are once
i j in
again defined by membership in some interaction zone3:
1 (cid:88)
y = v⊤v = ⟨cos(θ ⟩ (B.55)
ϕ K i j ij Nin
j∈Nin
where the equivalence between the dot products and the cosine angle is assured when we
assume all v ,k ∈ {i}∪N have unit magnitude. Recall that if two unit-magnitude vectors
k in
v ,v are parallel, their dot product (cosine angle) is 1. When we once again assume that
i j
agents act by adjusting their heading direction, then the action update given the continuous
active inference rule in (A.22) has the following form:
dv 1
i = − (y −µ )vˆ ≈ (1−y )vˆ (B.56)
dt σ2 ϕ ϕ ϕ
z
ϕ
1 (cid:88)
where vˆ = v (B.57)
j
K
j∈Nin
The approximation in the first line holds when we assume the sensory variance σ2 is
z
ϕ
1 and the dynamics prior (either via increasing α or decreasing σ2 ) dominates inference
ω
ϕ
3For notational convenience and because it doesn’t change the derivations, we omit observation noise on
y .
ϕ
51
such that µ ≈ 1. In this case, the focal agent i then updates its velocity using the average
ϕ
neighbor velocity. This is proportional to the alignment force in e.g. [15, 18], except that
it is also scaled by how unaligned the focal individual is with its neighbourhood, scored by
1−y .
ϕ
C Online parameter estimation
In this section we derive update rules for the generative model parameters using a simple
gradient descent scheme on the Laplace-approximated variational free energy. In the active
inference literature this process of updating parameters, as opposed to beliefs about states,
is often analogized to online learning or neural plasticity [20, 21].
C.1 Updating sensory smoothness
In this section we derive an update equation for the sensory smoothness parameter λ , which
z
captures the generative model’s assumptions about the temporal autocorrelation structure
of sensory noise z.
Recall the formulation of state space models in generalized coordinates of motion in
Section A.1. In addition to providing a concise description of local paths of the state ⃗x in
t
terms of its higher derivatives x′,x′′,...,x[n], stochastic differential equations in generalized
coordinates also allow one to express serial correlations in the noises at the first order z, by
assumingthatitcanbedifferentiated(hasnon-zero, smoothautocovariance)andrepresented
in terms of hierarchical or generalized noises z′,z′′,z′′′,...,z[n].
Recall the parameterization of the generalized sensory precision Π
˜z
as a factorization
into two precision matrices, that respectively represent agent’s beliefs about the ‘spatial’ and
‘temporal’ covariance structure. We parameterize these with the two precision parameters
Γ and λ . Γ encodes the agent’s belief about the overall magnitude of the fluctuations, and
z z z
λ encodes beliefs about their their serial correlations in time, assuming a Gaussian form for
z
their autocorrelation:
Π
˜z
= S(λ )⊗Π(Γ )
z z
 
Γ
11
 Γ 
22
Π(Γ z ) =   ...  
 
Γ
LL
 1 0 − 1 ...−1
2λ2
z
 0 1 0 
S(λ ) =  2λ2 z  (C.58)
z − 1 0 3 
 2λ2 4λ4 
. .
.
z z ...
52
We implement a form of behavioral plasticity by allowing agents to update λ using
z
observations. We accomplish this using a gradient descent on variational free energy:
dλ ∂F
z
= −κ (C.59)
θ
dt ∂λ
z
where the ‘learning rate’ κ is typically set to be at least an order of magnitude lower
θ
than the update rate of inference κ ; in all simulations we use κ = 0.001 and n = 1
µ θ LearnIter
iteration. This enforces a separation of timescales that is typical in generalized filtering and
state-space models that perform simultaneous state- and parameter-estimation [3, 5, 14].
To compute the gradients of the variational free energy with respect to λ , we can start
z
by expressing those components of the (Laplace-approximated) variational free energy that
depend on λ :
z
(cid:16) (cid:17)
F(λ ) = ε˜⊤Π ˜zε˜ −ln detΠ ˜z (C.60)
z z z
where we only have included the terms that depend on the sensory precision Π
˜z
due to
its dependence on λ . The full gradient is then simply:
z
(cid:16) (cid:17)
∂F ε˜⊤Π ˜zε˜ ∂ln detΠ
˜z
= z z − (C.61)
∂λ ∂λ ∂λ
z z z
Starting with the case of a single sensory sector L = 1, then the generalized prediction
error ε˜ is a vector of prediction errors, one for each order of motion: ε˜ = {ε ,ε′,ε′′,...}
z z z z z
where a sensory prediction error at a given order of motion is simply: ε[n] = y[n]−g˜[n], where
z
the n subscript refers to an order of differentiation. In the case of 3 generalized coordinates
for the simple scalar case:
∂F 6
= 4Γ λ (ε′)2 +ε′′(8Γ ε′′λ3 +2Γ ε λ )+2Γ λ ε ε′′ −
∂λ z z z z z z z z z z z z z z λ
z z
6
= 4Γ λ (ε ε′′ +(ε′)2 +2λ2(ε′′)2)− (C.62)
z z z z z z z λ
z
Meaning that the update for the λ parameter can be simplified to (omitting the learning
z
rate κ ):
θ
dλ 6
z = −4Γ λ (ε ε′′ +(ε′)2 +2λ2(ε′′)2)+ (C.63)
dt z z z z z z z λ
z
In the case of the distance-tracking generative model we explore in the main text, we
assume that the agents can only observe the 0th (position, y) and 1st (velocity, y′) orders of
53
motion of the hidden states x˜. This means there are no longer 2nd-order prediction errors ε′′
z
and the update becomes even simpler:
dλ 6
z = −4Γ λ (ε′)2 +
dt z z z λ
z
6
≈ −4Γ λ (y′ )2 + (C.64)
z z h,i λ
z
where approximation in the second line results in the case of ‘biased’ inference, i.e.,
µ ≈ η =⇒ µ′ ≈ 0, allowing us to replace the velocity prediction error y′ −µ′ with y′ .
h,i h,i
Given that spatial and temporal precisions are independent from each other due to the
factorization of the generalized precision matrix, and further given the diagonal structure of
the spatial precision Π (i.e., independence in random fluctuations across sensory sectors),
z
we can write an update for λ that is a sum of squared prediction errors across sensory
z
sectors:
L
dλ (cid:88) 6L
z ≈ −4Γ λ (y′ )2 − (C.65)
dt z z h,l λ
z
l=1
The quadratic form of this update means that the update to the smoothness parameter
decays in proportion with the overall magnitude of the velocity prediction errors, regardless
of its sign. This means that if the distance is fluctuating quickly in any direction, then the
agent will infer that fluctuations are slightly-less serially-correlated at the 0th order, reflected
by a decrease in λ .
z
D Adding a target representation into the generative model
As described in the main text, it is straightforward to add an additional observation model
and dynamics model to an agent’s generative model to represent the distance between itself
and some abstract spatial target, which in the context of the collective information transfer
experiments, we represent with T:
x˙ = −α x +ω y = x +z
target target target target target target target
x˙′ = −α x′ +ω′ y′ = x′ +z′ (D.66)
target target target target target target target
We truncate the generalized hidden states at third order x˜ = (x ,x′ ,x′′ )
target target target target
and the observations at second order y˜ = (y ,y′ ). When the agent assumes the
target target target
generalized noises ω˜ and z˜ are zero-mean and normally-distributed with covariances
target target
Σ
˜ωtarget
and Σ
˜ztarget
and leverage the Laplace approximation exactly as we did in the previ-
ous section, then we can supplement the Laplace-approximated free energy in (A.35) with
additional terms corresponding to target-related prediction errors:
54
1 (cid:104) (cid:105)
F ∝ ε˜⊤ Π ˜z-Socε˜ +ε˜⊤ Π ˜ω-Socε˜ +ε˜⊤ Π ˜z-Tarε˜ +ε˜⊤ Π ˜ω-Tarε˜ +C
L 2 z-Soc z-Soc ω-Soc ω-Soc z-Tar z-Tar ω-Tar ω-Tar
(D.67)
Here we use the suffixes "-Soc" or "-Tar" to indicate ‘social’ relevant information (re-
lated to the average neighbor distance) and the ‘target’ prediction errors. C captures all
the additional terms (log determinants of precision matrices, etc.) that are constant with
respect to the posterior means µ˜ = (µ˜ ,µ˜ ). Following the same reasoning as used
Social Target
to derive the inference and action rules for the case of the social distance hidden states
and observations(x˜ ,y˜ ), we can do the same to derive active inference rules for the
Social Social
target-relevant hidden states and observations x˜ ,y˜ :
target target
dµ˜ dv
Social = Dµ˜ −∇ F (µ˜ ,y˜ ) = −(∇ F (µ˜ ,y˜ )+∇ F (µ˜ ,y˜ ))
dt Social µ˜ Social L Social Social dt v L Social Social v L Target Target
dµ˜
Target
= Dµ˜ −∇ F (µ˜ ,y˜ ) (D.68)
dt
Target µ˜Target L Target Target
Where expanding the free energy gradients on the right equation leads to an expression
for the action update in terms of a precision-weighted sum of vectors, appearing in (18) in
the main text.
E Numerical methods
We used a forwards Euler-Maruyama scheme to the integrate a (Itô-style) stochastic differ-
ential equation for the positions of all agents over time:
dr = v dt+σ dW (E.69)
t t a t
where the variance of ‘action noise’ σ2 was set to 0.01 for all experiments unless explicitly
a
stated otherwise. We used a step size of ∆t = 0.01s in the integration. For the current
timestep τ in ‘simulation time’, we used a simple forwards Euler scheme to integrate the
differential equations used for belief updating (see (A.37)) and action (see (A.43)) for each
agent in parallel. We use the positions and heading vectors of all agents from the previous
integration timestep (τ −∆t) to generate the observations for the current timestep.
The collective information transfer experiments were performed using custom Julia code,
and all other simulations were implemented in JAX using custom code. To accelerate the
parameter scans over p , Γ , and Γ to create the results in Figure 3 in the main
inf z-Social z-Target
text, we used the high-performance computing clusters (Cobra and Draco) provided by the
Max Planck Computing and Data Facility.
55
Table E.1: Defaultparameterconfigurationusedinnumericalsimulations(unlessotherwise
stated). First column denotes the name of the parameter, second column denotes its default
value and third column indicates whether the parameter concerns the generative process (the
physics of the simulation environment), the generative model used for active inference, or a
hyperparameter (e.g., used in the active inference algorithm).
Parameter Value Type
∆t (Euler integration step, in seconds) 0.01 generative process
Number of sensory sectors 4 generative process
Sector angle (in degrees ◦) 60 generative process
R (interaction radius, in arbitrary units) 5 generative process
0
σ2 0.01 generative process
a
σ2 0.01 generative process
z,h
σ2 0.01 generative process
z′,h
Γ 1.0 generative model
z
Γ 1.0 generative model
ω
λ 1.0 generative model
z
λ 1.0 generative model
ω
α 0.5 generative model
α 0.5 generative model
target
η 1.0 generative model
Number of generalised coordinates (x) 3 hyperparameter
Number of generalised coordinates (y) 2 hyperparameter
κ 0.1 hyperparameter
µ
n 1 hyperparameter
InferIter
κ 0.1 hyperparameter
a
n 1 hyperparameter
ActionIter
κ 0.001 hyperparameter
θ
n 1 hyperparameter
LearnIter
56
Supplemental References
[1] Karl Friston, Klaas Stephan, Baojuan Li, and Jean Daunizeau. “Generalised filtering”.
In: Mathematical Problems in Engineering 2010 (2010).
[2] Karl Friston. “Hierarchical models in the brain”. In: PLoS computational biology 4.11
(2008).
[3] Bhashyam Balaji and Karl Friston. “Bayesian state estimation using generalized coor-
dinates”. In: Signal processing, sensor fusion, and target recognition XX 8050 (2011),
pp. 716–727.
[4] Karl J Friston. “Variational filtering”. In: NeuroImage 41.3 (2008), pp. 747–766.
[5] KarlJFriston,NTrujillo-Barreto,andJeanDaunizeau.“DEM:avariationaltreatment
of dynamic systems”. In: Neuroimage 41.3 (2008), pp. 849–885.
[6] Christopher L Buckley, Chang Sub Kim, Simon McGregor, and Anil K Seth. “The
free energy principle for action and perception: A mathematical review”. In: Journal
of Mathematical Psychology 81 (2017), pp. 55–79.
[7] Karl Friston, Lancelot Da Costa, Noor Sajid, Conor Heins, Kai Ueltzhöffer, Grigorios
A Pavliotis, and Thomas Parr. “The free energy principle made simpler but not too
simple”. In: Physics Reports 1024 (2023), pp. 1–29.
[8] Karl Friston. “A theory of cortical responses”. In: Philosophical transactions of the
Royal Society B: Biological sciences 360.1456 (2005), pp. 815–836.
[9] Karl Friston and Stefan Kiebel. “Predictive coding under the free-energy principle”. In:
Philosophical Transactions of the Royal Society B: Biological Sciences 364.1521 (2009),
pp. 1211–1221.
[10] Yanping Huang and Rajesh PN Rao. “Predictive coding”. In: Wiley Interdisciplinary
Reviews: Cognitive Science 2.5 (2011), pp. 580–593.
[11] Rick A Adams, Stewart Shipp, and Karl J Friston. “Predictions not commands: active
inferenceinthemotorsystem”.In:Brain Structure and Function 218.3(2013),pp.611–
643.
[12] Karl Friston. “What is optimal about motor control?” In: Neuron 72.3 (2011), pp. 488–
498.
[13] Thomas Parr, Giovanni Pezzulo, and Karl J Friston. Active inference: the free energy
principle in mind, brain, and behavior. MIT Press, 2022.
[14] Manuel Baltieri and Christopher L Buckley. “PID control as a process of active infer-
ence with linear generative models”. In: Entropy 21.3 (2019), p. 257.
[15] Iain D Couzin, Jens Krause, Richard James, Graeme D Ruxton, and Nigel R Franks.
“Collective memory and spatial sorting in animal groups”. In: Journal of theoretical
biology 218.1 (2002), pp. 1–12.
57
[16] Ichiro AOKI. “A Simulation Study on the Schooling Mechanism in Fish”. In: NIPPON
SUISAN GAKKAISHI 48.8 (1982), pp. 1081–1088. doi: 10.2331/suisan.48.1081.
[17] Craig W Reynolds. “Flocks, herds and schools: A distributed behavioral model”. In:
Proceedings of the 14th annual conference on Computer graphics and interactive tech-
niques. 1987, pp. 25–34.
[18] Tamás Vicsek, András Czirók, Eshel Ben-Jacob, Inon Cohen, and Ofer Shochet. “Novel
type of phase transition in a system of self-driven particles”. In: Physical review letters
75.6 (1995), p. 1226.
[19] Pawel Romanczuk, Iain D Couzin, and Lutz Schimansky-Geier. “Collective motion due
to individual escape and pursuit response”. In: Physical Review Letters 102.1 (2009),
p. 010602.
[20] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, Giovanni
Pezzulo, et al. “Active inference and learning”. In: Neuroscience & Biobehavioral Re-
views 68 (2016), pp. 862–879.
[21] Lancelot Da Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic, Victorita Neacsu,
and Karl Friston. “Active Inference on Discrete State-Spaces: A Synthesis”. In: Journal
of Mathematical Psychology 99 (Dec. 2020), p. 102447. issn: 0022-2496. doi: 10.1016/
j.jmp.2020.102447. (Visited on 01/27/2021).
Supplemental Movie Legends
Movie 1 Example of a simulation of N = 96 agents that includes a dynamic transition
from polarized to milling regime. Parameters: σ2 = 0.05; Sector angle = 80◦; R = 10
z′,h 0
units; κ = 0.2; λ = 0.5; λ = 2.0. Unless specified, all remaining parameters are as listed
a ω z
in Table E.1.
Movie 2 ExampleofapolarizedgroupofN = 64agents. Parameters: Sectorangle= 80◦;;
κ = 0.2; λ = 0.5; λ = 1.5.
a ω z
Movie 3 ExampleofamillingregimeobservedinN = 64agents. Parameters: σ2 = 0.04;
z′,h
Sector angle = 80◦; α = 1.0; κ = 0.2; λ = 0.8; λ = 1.8.
a ω z
Movie 4 Example of adisordered regime observed inN = 96agents. Parameters: Number
of sensory sectors = 2; Sector angle = 160◦; R = 10.0 units; α = 0.2; η = 0.5, κ = 0.2;
0 a
λ = 0.1; λ = 1.787.
ω z
Movie 5 Metastable ‘snaking’ configuration observed in N = 64 agents. Parameters:
σ2 = 0.04; Sector angle = 80◦; α = 0.1; κ = 0.2; λ = 0.5; λ = 2.2.
z′,h a ω z
58
Fragmentation probability
Figure E.1: Fragmentation probability as a function of the two precision parameters logΓ
z
and λ . Fragmentation probability was quantified as the proportion of trials (out of 500 inde-
z
pendenttrialspercondition)wherethegroupfragmented. Atrialwasconsideredfragmented
if least one individual was further than 2.0 dimensionless units from all other individuals for
at least 3 of the last 10 seconds of the 15-second trial. All other parameters are identical to
those used in Figure 2B in the main text.
59

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Collective behavior from surprise minimization"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
