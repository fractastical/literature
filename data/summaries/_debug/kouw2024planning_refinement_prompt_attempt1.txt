=== IMPORTANT: ISOLATE THIS PAPER ===
You are revising a summary for ONLY the paper below. Do NOT reference or use content from any other papers.
Paper Title: Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents
Citation Key: kouw2024planning
REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Issues to fix:
1. CRITICAL: The current summary has severe repetition issues. You MUST eliminate all repeated sentences, phrases, and paragraphs. Each idea should be expressed only once. If you find yourself repeating content, remove the duplicates entirely. Focus on variety and uniqueness in your wording.
2. Severe repetition detected: Same phrase appears 9 times (severe repetition)

Current draft (first 2000 chars):
Here's a summary of the paper "Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents" based on the provided text, adhering to all the specified instructions.### OverviewThis paper investigates a novel approach to active inference, where the agent’s planning behavior is influenced by the curvature of the measurement function. The core idea is that Gaussian approximations to non-linear sensors, particularly those employing second-order Taylor expansions, induce a state-dependent ambiguity term. This term effectively biases the agent towards states where the measurement function is less curved, leading to a preference for smoother trajectories. The research is conducted within the framework of active inference, utilizing a variational Bayesian approach to model sensory input and action. The key contribution is demonstrating that the ambiguity term is not constant, but rather depends on the curvature of the measurement function, and that this has a significant impact on the agent’s planning behavior. The paper tests this hypothesis through a robot navigation experiment.### MethodologyThe study employs a state-space model with linear dynamics and Gaussian noise (Eq.1) to represent the robot’s movement. The robot’s state is defined as its planar position and time derivatives. The robot does not directly sense its position but infers it from noisy measurements (y) produced by a non-linear sensor (g). The measurement function g is approximated using Gaussian approximations to ensure tractable inference. The authors explore three different Gaussian approximations: first-order Taylor, second-order Taylor, and the unscented transform. The model is implemented using a variational Bayesian approach, where the posterior distribution is approximated by a Gaussian distribution. The robot’s control input is optimized using a model predictive control objective (Eq.5), minimizing the free energy functional. The experiment i...

Key terms: avoid, ambiguous, agents, planning, state, states, linear, gaussian

=== FULL PAPER TEXT ===
Planning to avoid ambiguous states through
Gaussian approximations to non-linear sensors
in active inference agents
Wouter M. Kouw[0000−0002−0547−4817]
Bayesian Intelligent Autonomous Systems laboratory
TU Eindhoven, Eindhoven, Netherlands
w.m.kouw@tue.nl
Abstract. In nature, active inference agents must learn how observa-
tions of the world represent the state of the agent. In engineering, the
physics behind sensors is often known reasonably accurately and mea-
surement functions can be incorporated into generative models. When
a measurement function is non-linear, the transformed variable is typi-
cally approximated with a Gaussian distribution to ensure tractable in-
ference.WeshowthatGaussianapproximationsthataresensitivetothe
curvature of the measurement function, such as a second-order Taylor
approximation,produceastate-dependentambiguityterm.Thisinduces
a preference over states, based on how accurately the state can be in-
ferredfromtheobservation.Wedemonstratethispreferencewitharobot
navigation experiment where agents plan trajectories.
Keywords: Active inference · Free energy minimization · Bayesian fil-
tering · Non-linear sensing · Control systems · Planning · Navigation
1 Introduction
In nature, intelligent agents build a model to infer the causes of their sensations
[2]. In engineering, we are able to utilize knowledge of the relevant physics to
structuresuchamodel.Inparticular,weoftenknowhowsensorsmeasurestates
of the world. For example, we know how radar measures relative velocity and
distance[19].Measurementfunctionsthatarenon-lineartransformationsofstate
variables pose challenges to state estimation, which are often dealt with using
Gaussian approximations of the transformed variables [8,14]. We show that for
certain Gaussian approximations, an active inference agent will prefer to avoid
states because it already knows that state estimation will be difficult.
Active inference agents are based on free energy functionals that rank poli-
cies on explorative and goal-directed behaviour [5,7,6,16]. The expected free
energy functional can be understood through its decomposition into a cross-
entropy term between states and observations given action ("ambiguity"), and
a Kullback-Leibler divergence between the posterior predictive and a goal prior
distribution ("risk") [7,18,4]. We show that Gaussian approximations of a non-
linear observation function that are itself linear in the covariance matrix, e.g.,
4202
peS
81
]YS.ssee[
2v47910.9042:viXra
2 W.M. Kouw
first-order Taylor and the unscented transform [9], lead to ambiguity terms that
are constant over states. This echoes an earlier finding that agents with a linear
Gaussian state-space model exhibit a constant ambiguity term [10]. However,
utilizing a second-order Taylor approximation induces a non-constant ambigu-
ity term. Under this model, the agent will avoid states where the non-linear
measurement function curves strongly. Our contributions are:
– Analysisofambiguityinexpectedfreeenergyfunctionsunderthreedifferent
Gaussian approximations.
– An experiment where a robot must plan a trajectory and navigate to a goal
prior distribution, testing the effect of the ambiguity term.
2 Problem statement
We want to plan a trajectory for a robot across a plane. The robot’s state
at time k is its planar position and time derivatives, x
k
∈ RDx. The robot
does not sense position directly, but has to infer it from noisy measurements
y
k
∈ RDy, produced by a sensor through a non-linear mapping g : RDx → RDy
andmeasurementnoisev
k
∈RDy.Itacceptscontrolinputsu
k
∈RDu andmoves
according to linear dynamics with a transition matrix A ∈ RDx×Dx, control
matrix B ∈ RDx×Du and process noise e
k
∈ RDx. Overall, we consider robot
systems described with discrete-time state-space models of the form:
x =Ax +Bu +e , e ∼N(0,Q), (1)
k k−1 k k k
y =g(x )+v , v ∼N(0,R), (2)
k k k k
where Q,R are noise covariance matrices.
ThegoalistofindasequenceofT controlsu¯ =u ,...u thatproduces
k k+1 k+T
future states close to a desired state x . Agents must plan every time-step. The
∗
challenge is that errors in state estimation may cause drastic changes in the
planned trajectory, which can lead an agent astray.
Example Consider a robot with position and velocity states that must move
frompositionx =(0,−1)tox =(0,1).Itsstatetransition,controlandprocess
0 ∗
noise covariance matrices are given by:
 10∆t 0   0 0   σ2∆t3 0 σ2∆t2 0 
1 3 1 2
A=    0 0 1 0 0 1 ∆ 0 t   , B=   ∆ 0 t 0 0    , Q=     σ 1 2 0 ∆ 2 t2 σ 2 2 0 ∆ 3 t3 σ 1 2 0 ∆t σ 2 2 0 ∆ 2 t2    , (3)
00 0 1 0 ∆t 0 σ2∆t2 0 σ2∆t
2 2 2
for ∆t=0.5, σ =σ =0.1. Measurements are produced by a sensor station at
1 2
(0,0) that reports relative angle ϕ ∈ [−π π] and relative distance d ∈ [0,∞).
k k
The mapping and measurement noise covariance matrix are:
(cid:20) ϕ (cid:21) (cid:20) (cid:112) x2 +x2 (cid:21) (cid:20) ρ2 0 (cid:21)
g(x )= k = 1k 2k , R= 1 , (4)
k d arctan(x ,x ) 0 ρ2
k 1k 2k 2
Planning to avoid ambiguous states through Gaussian approximations 3
where ρ = ρ = 0.001. Suppose it uses an extended Kalman filter (first-order
1 2
Taylorapproximation)forstateestimationandafinite-horizonmodel-predictive
control objective of the form:
k+T
J (u¯ )= (cid:88) (cid:0) (Axˆ +Bu )−x (cid:1)⊺ C (cid:0) (Axˆ +Bu )−x (cid:1) +ηu2, (5)
k k t−1 t ∗ t−1 t ∗ t
t=k+1
where xˆ is the mean state, xˆ = Axˆ +Bu , C is a cost matrix (ones for
t t−1 t
position, zeros for velocity) and η a regularization parameter. Minimizing this
objectiveeverytime-stepproducesthecontrolsequenceu¯MPC =argminJ (u¯ ).
k k k
Suchanagentwillfirstplanatrajectorymovingdirectlyforward,asdescribedin
Figure 1 (left). However, as it approaches the sensor station, its state estimate
become progressively more inaccurate and it makes increasingly more drastic
adjustments to the control plan (see k =5 in Figure 1 middle). Figure 1 (right)
shows the executed trajectory over a trial of 10 steps, demonstrating that the
agent lost track of the robot’s state and did not successfully reach the target.
Fig.1. (Left) Planned trajectory at k =1, from start to goal directly over the sensor
station. (Middle) Planned trajectory at k = 5 showing a mismatch between true and
estimated state resulting in a strong adjustment to the planned trajectory. (Right)
Executed trajectoryover atrial of 10 steps demonstratesthe agent losing track of the
robot when it approaches the sensor station.
3 Agent specification
3.1 Probabilistic Model
Theagent’smodelwillhaveGaussianpriordistributionsoverstatesandcontrols,
p(x )=N(x |m ,S ), N(u |0,η−1I), (6)
0 0 0 0 k
with mean m , covariance matrix S , precision η and identity matrix I. The
0 0
agent’s state transition will also be expressed as a Gaussian distribution:
p(x |x ,u )=N(x |Ax +Bu ,Q). (7)
k k−1 k k k−1 k
4 W.M. Kouw
Let the marginal state x be Gaussian distributed, i.e., p(x )=N(x |m ,S ).
k k k k k
We restrict our attention to approximations of the nonlinear sensor g(x ) that
k
produce Gaussian joint distributions over states and observations [14], i.e.,
(cid:16)(cid:20)
x
(cid:21) (cid:20)
m
(cid:21) (cid:20)
S Γ
(cid:21)(cid:17)
p(y k ,x k )≈N y k | µ k , Γ k ⊺ Σ k . (8)
k k k k
Fromthejoint,weobtainaconditionaldistributionofobservationsgivenstates:
p(y |x )≈N (cid:0) y |µ +Γ ⊺ S−1(x −m ),Σ −Γ S−1Γ ⊺(cid:1) . (9)
k k k k k k k k k k k k
This distribution is linear in x , and will allow for exact Bayesian filtering.
k
But note that the parameters µ , Γ and Σ may be nonlinear functions of x ,
k k k k
dependingonthetypeofGaussianapproximation(specificstreatedinSection4),
and may thus capture more of the effect of g(x ).
k
3.2 Inferring states
Weassumethat,wheninferringstates,theagenthasobservedthesystemoutput
y =yˆ andinputu =uˆ .LetD ≜{yˆ,uˆ }k refertodataobservedthusfar.
k k k k k i i i=1
Giventheknownexecutedcontrol,stateestimationfollowsthegeneralBayesian
filtering equations [14]. Firstly, the prior predictive distribution is given by:
(cid:90)
p(x |uˆ ,D )= p(x |x ,uˆ )p(x |D )dx =N(x |m¯ ,S¯ ). (10)
k k k-1 k k-1 k k-1 k-1 k-1 k k k
with m¯ ≜Am +Buˆ and S¯ ≜AS A⊺+Q. This prediction is corrected
k k−1 k k k−1
by the observation through Bayes’ rule [14],
p(yˆ |x )
p(x |D )= k k p(x |uˆ ,D )=N(x |m ,S ), (11)
k k p(yˆ |D ) k k k-1 k k k
k k-1
with m =m¯ +Γ Σ−1(yˆ −µ ) and S =S¯ −Γ Σ−1Γ .
k k k k k k k k k k k
3.3 Inferring controls
Wewilldiscusstheinferenceprocedurefirstforasinglestepintothefuture,and
then generalize to a finite horizon of length T. Predictions for the future state
and observation are made by unrolling the generative model to t=k+1:
p(y ,x ,u |D )=p(y |x )p(x |u ;D )p(u ). (12)
t t t k t t t t k t
Wewilluseanexpectedfreeenergyfunctionaltoinferaposteriordistribution
over the control u [13]:
t
(cid:90) (cid:90) q(x ,u )
F [q]= q(y |x ) q(x ,u )ln t t d(u ,x )dy . (13)
k t t t t p(y ,x ,u |D ) t t t
t t t k
Planning to avoid ambiguous states through Gaussian approximations 5
The variational model is specified to be:
q(y |x )≜p(y |x ), q(x ,u )≜p(x |u ;D )q(u ). (14)
t t t t t t t t k t
Constraining q(y |x ) to the Gaussian approximation defined in Eq. 9 allows us
t t
to study deterministic approximations in an expected free energy minimization
context. Given this variational model, Eq. 13 may be re-arranged to:
(cid:90) (cid:90) p(x |u ;D )q(u )
F [q]= p(y |x ) p(x |u ;D )q(u )ln t t k t d(x ,u )dy (15)
k t t t t k t p(y ,x ,u ;D ) t t t
t t t k
= (cid:90) q(u ) (cid:0) (cid:90) p(y ,x |u ;D )ln p(x t |u t ;D k )q(u t ) d(y ,x ) (cid:1) du (16)
t t t t k p(y ,x |u ;D )p(u ) t t t
t t t k t
= (cid:90) q(u ) (cid:0) ln q(u t ) + (cid:90) p(y ,x |u ;D )ln p(x t |u t ;D k ) d(y ,x ) (cid:1) du . (17)
t p(u ) t t t k p(y ,x |u ;D ) t t t
t t t t k
(cid:124) (cid:123)(cid:122) (cid:125)
Jk(ut)
We refer to J (u ) as the expected free energy function as it depends on the
k t
value of u not on its distribution. Under J (u ) = ln(1/exp(−J (u ))), the
t k t k t
expected free energy functional can be concisely expressed as:
(cid:90) q(u )
F [q]= q(u )ln t du . (18)
k t p(u )exp(−J (u )) t
t k t
The above is a Kullback-Leibler divergence, which is minimal when
q∗(u )∝p(u )exp(−J (u )) . (19)
t t k t
Theproportionalityisduetotheimplicitconstraint1thatq∗(u )shouldintegrate
t
to 1. To work out the expectation in Eq. 17, we first decompose the joint over
states and observations into
p(y ,x |u ;D )=p(x |y ,u ;D )p(y ), (20)
t t t k t t t k t
and then intervene on the marginal distribution over y with a distribution re-
t
flecting desired future observations (a.k.a. goal prior) [11]:
p(y )→p(y |y )=N(y |µ ,Σ ). (21)
t t ∗ t ∗ ∗
The next step involves applying Bayes’ rule in the inverse direction:
1 p(y |u ;D )
= t t k , (22)
p(x |y ,u ;D ) p(y |x )p(x |u ;D )
t t t k t t t t k
1 A more rigorous treatment would define a Lagrangian with normalization and
marginalizationconstraints[17].However,suchatreatmentisinconsequentialwhen
resorting to MAP estimation, as will be pursued later in the paper.
6 W.M. Kouw
where the marginal prediction for the future observation is:
(cid:90)
p(y |u ;D )= p(y |x )p(x |u ;D )dx (23)
t t k t t t t k t
(cid:90) (cid:20) x (cid:21) (cid:20) m¯ (cid:21) (cid:20) S¯ Γ (cid:21)
= N( y t | µ t , Γ ⊺ t Σ t )dx t =N(y t |µ t ,Σ t ). (24)
t t t t
Note that µ and Σ depend on u through m¯ . Plugging Eqs. 21 and 22 into
t t t t
Eq. 20 yields:
(cid:90) p(x |u ;D ) p(y |u ;D )
J (u )= p(y ,x |u ;D )ln t t k t t k d(y ,x ) (25)
k t t t t k p(y |y ) p(y |x )p(x |u ;D ) t t
t ∗ t t t t k
(cid:90) (cid:104) p(y ,x |u ;D )(cid:105)
= p(y ,x |u ;D ) −ln t t t k d(y ,x )
t t t k p(x |u ;D ) t t
t t k
(cid:124) (cid:123)(cid:122) (cid:125)
ambiguity
(cid:90) (cid:104)(cid:90) (cid:105) p(y |u ;D )
+ p(y ,x |u ;D )dx ln t t k dy . (26)
t t t k t p(y |y ) t
t ∗
(cid:124) (cid:123)(cid:122) (cid:125)
risk
"Risk"referstotheKullback-Leibler(KL)divergencebetweenpredictedandde-
siredfutureobservations.TheinnerintegralintherisktermleadstoaGaussian
distribution (Eq. 24) and the KL divergence between Gaussians is [3]:
E (cid:104) ln p(y t |u t ;D k )(cid:105) = 1(cid:16) ln |Σ ∗ | −D +tr (cid:0) Σ−1(Σ +Ψ ) (cid:1)(cid:17) . (27)
p(yt|ut;Dk) p(y |y ) 2 |Σ | y ∗ t ∗
t ∗ t
where Ψ ≜(µ −µ (cid:1)(cid:0) µ −µ )⊺. "Ambiguity" refers to the conditional entropy
∗ ∗ t ∗ t
of the future observations given the future states.
Lemma 1. Ambiguity, as defined in Eq. 26, for a generative model described in
Eq. 12 and a variational distribution described in Eq. 14, is:
E (cid:2) −ln p(y t ,x t |u t ;D k )(cid:3) = D y ln(2πe)+ 1 ln|Σ −Γ ⊺ S¯-1Γ |. (28)
p(yt,xt|ut;Dk) p(x |u ;D ) 2 2 t t t t
t t k
The proof is in Appendix A. Note that the first term does not depend on the
statex .PluggingEqs.27and28intotheexpectedfreeenergyfunction(Eq.26)
t
produces:
J k (u t )= 1 2 (cid:16) ln | | Σ Σ ∗ | | +D y ln(2π)+tr (cid:0) Σ ∗ −1(Σ t +Ψ ∗ ) (cid:1) +ln (cid:12) (cid:12)Σ t −Γ t ⊺ S¯ t -1Γ t (cid:12) (cid:12) (cid:17) . (29)
t
Note that Γ , Σ and Ψ depend on u . The above steps can be generalized to a
t t ∗ t
longer time horizon t = k+1,...k+T. Because the prior is independent over
time, p(u¯) =
(cid:81)T
p(u ) (see Eq. 6), the function J (u¯) factorizes to a sum of
t=1 t k
recursive expected free energy functions
(cid:80)T
J (u ).
t=1 k t
Planning to avoid ambiguous states through Gaussian approximations 7
We are interested in the most probable value under the approximate control
posterior, i.e., the MAP estimate:
k+T
(cid:88)
uˆ=argmax q∗(u¯)=argmin J (u )−lnp(u ), (30)
t t t
u¯∈U u¯∈U
t=k+1
where U ⊂RT is the space of affordable controls over T steps. Constraints such
as motor force limits can be imposed during optimization.
4 Gaussian approximations
WediscussthethreemostpopularGaussianapproximationstonon-lineartrans-
formationsofGaussianrandomvariables:thefirstandsecond-orderTaylorseries
approximations (used in extended Kalman filters) and the unscented transform
(used in the unscented Kalman filter) [9,8][14, Ch. 5].
The first-order Taylor series approximation effectively linearizes the non-
linear observation function g(x ). Since ambiguity is known to be constant over
t
states under a linear observation function [10], it is no surprise that the first-
order Taylor also leads to an ambiguity term that is constant over states.
Theorem 1. Let G (m¯ ) be the Jacobian of g with respect to x , evaluated at
x t t
m¯ . Under a first-order Taylor approximation, the parameters Σ ,Γ are:
t t t
Σ =G (m¯ )S¯G (m¯ ) ⊺ +R, Γ =S¯G (m¯ ) ⊺ . (31)
t x t t x t t t x t
With these parameters, the ambiguity term does not depend on the state x :
t
E (cid:2) −ln p(y t ,x t |u t ;D k )(cid:3) = D y ln(2πe)+ 1 ln|R|. (32)
p(yt,xt|ut;Dk) p(x |u ;D ) 2 2
t t k
TheproofisinAppendixB.Perhapssurprisingly,underthesecond-orderTaylor
approximation, the ambiguity term varies as a function of the state x .
t
Theorem 2. Let G(i)(m¯ ) be the Hessian of the i-th element of the non-linear
xx t
observation function evaluated at m¯ and e be a canonical basis vector. The
t i
parameters Σ ,Γ computed through a second-order Taylor approximation are:
t t
Σ =G (m¯ )S¯G (m¯ ) ⊺ + 1(cid:88)
Dy
(cid:88)
Dy
e e ⊺ tr (cid:0) G(i)(m¯ )S¯G(j)(m¯ )S¯(cid:1) +R
t x t t x t 2 i j xx t t xx t t
i=1j=1
Γ =S¯G (m¯ ) ⊺ . (33)
t t x t
With these parameters, the ambiguity term depends on x through:
t
E (cid:2) −ln p(y t ,x t |u t ;D k )(cid:3) = (34)
p(yt,xt|ut;Dk) p(x |u ;D )
t t k
D y ln(2πe)+ 1 ln (cid:12) (cid:12) 1(cid:88)
Dy
(cid:88)
Dy
e e ⊺ tr (cid:0) G(i)(m¯ )S¯G(j)(m¯ )S¯(cid:1) +R (cid:12) (cid:12).
2 2 (cid:12)2 i j xx t t xx t t (cid:12)
i=1j=1
The proof is in Appendix C.
8 W.M. Kouw
Interestingly, the ambiguity is also constant for the unscented transform.
Theorem 3. Define 2D +1 sigma points as:
x
χ ≜m¯ , χ ≜m¯ + (cid:112) D +λ (cid:2)(cid:112) S¯(cid:3) , χ ≜m¯ − (cid:112) D +λ (cid:2)(cid:112) S¯(cid:3) , (35)
0 t i t x t i Dx+i t x t i
√
where i=1,...D , [·] denotes the i-th column of a matrix, and S denotes the
x i √ √
matrix square root such that S S =S. The parameter λ≜α2(D +κ)−D
x x
depends on free parameters α and κ. Define 2D +1 weights as:
x
λ 1
w ≜ +(1−α2+β) , w ≜ , (36)
0 D +λ i D +λ
x x
for i = 1,...2D and β as an additional free parameter. Under these sigma
x
points and weights, the parameters µ , Σ , Γ are [14, Eq. 5.89]:
t t t
λ
2
(cid:88)
Dx
1
2
(cid:88)
Dx
⊺
µ = g(χ )+ g(χ ), Γ = w (χ −m¯ )(g(χ )−µ ) ,
t D +λ 0 2(D +λ) i t i i t i t
x x
i=1 i=0
2
(cid:88)
Dx
⊺
Σ = w (g(χ )−µ )(g(χ )−µ ) +R. (37)
t i i t i t
i=0
Then, the ambiguity is independent of the state:
E (cid:2) −ln p(y t ,x t |u t ;D k )(cid:3) = D y ln(2πe)+ 1 ln|R|. (38)
p(yt,xt|ut;Dk) p(x |u ;D ) 2 2
t t k
TheproofcanbefoundintheAppendixD.Thisresultisconjecturedtoholdfor
otherGaussianapproximationsthatarelinearintheirestimateofthecovariance
matrix, for example the Gauss-Hermite approximation [14, Ch. 6].
5 Experiments
Our experiment is as described in Section 2, with the nonlinear observation
function g(·) measuring relative angle and distance to a base station. Examples
of sensors include Hall effect and ultrasound sensors. The robot starts at x =
0
[0 -1 0 0] and must reach x = [0 1 0 0]. The agent’s state prior distribution’s
∗
parameters were m = [0 -1 0 0] and S = 0.5I. Its control prior precision was
0 0
set to a tiny value, η = 1.0·10−8, so as to best study the effects of ambiguity
and risk. It was given a goal prior of m =g(x ) and S =0.5I.
∗ ∗ ∗
Wewillcomparethreeagents2:firstly,anagentthatusesthefirst-orderTay-
lor approximation, referred to as EFE1. Secondly, an agent with a second-order
Taylor approximation, referred to as EFE2. Thirdly, an agent with a second-
order Taylor approximation but with only the risk term included, referred to as
EFER. The difference between EFER and EFE2 reflects the effect of the ambi-
guity term, while the difference between EFE1 and EFE2 reflects the effect of
2 Details and code at: https://github.com/biaslab/IWAI2024-ambiguity
Planning to avoid ambiguous states through Gaussian approximations 9
the second-order Gaussian approximation. Figure 2 plots the value of the con-
trol objective function at every position in state-space, under a state covariance
matrix of S =I. States close to the sensor station are red and will lead to high
t
values under the control objective. Note that the area around the sensor sta-
tion increases from EFE1 to EFER due to the curvature of the relative distance
sensor. The white markers are the approximate minimizers for this choice of S
t
matrix. Comparing EFER and EFE2, we can see that ambiguity increases the
cost of being close to the sensor station.
Fig.2.ValueunderthreeEFEfunctionsoveraplane:EFE1isriskandambiguityun-
derafirst-orderTaylorapproximation,EFERisriskonlyunderasecond-orderTaylor
approximation and EFE2 is both risk and ambiguity under a second-order Taylor ap-
proximation.Whitemarkersindicateminimizers.NotethateachEFEfunctioninduces
a different preference over states.
We ran 100 Monte Carlo experiments. Figure 3 plots the average trajectory
of T =30 steps taken by the EFE1, EFER and EFE2 agents. Ribbons indicate
the standard error of the mean at every time-point. Note that all agents avoid
the sensor station, with EFE2 taking the widest curve (EFE1 and EFER turn
at x = 1.0 while EFE2 turns at x = 1.5). EFE1 and EFER lose track of the
1 1
robotinanumberofexperiments(likethemodelpredictivecontrollerinSec.2),
leading to a more volatile average trajectory. EFE2 has the smoothest average
trajectory, indicating that the ambiguity term helps planning.
Fig.3. Trajectories of agents under three EFE functions, averaged over 100 Monte
Carlo samples (ribbon is standard deviation of the mean). The robot starts at the
greenmarkerandmustreachtheredgoalmarker.Allagentsavoidthesensorstation,
with EFE2 taking the widest curve and having the smoothest average trajectory.
10 W.M. Kouw
6 Discussion
One could argue that our analysis is more about model selection than inference,
as each Gaussian approximation essentially constitutes a different generative
model. In that sense, the experiments only indicate that richer approximations
of nonlinear functions lead to better performance, which is not surprising. How-
ever, the result is more subtle than that since the unscented transform is richer
than the first-order Taylor (produces a more accurate mean estimate [8]) but
apparently still leads to constant ambiguity. No, the approximation must be
sensitive to how the covariance matrix of the joint distribution over states and
observations changes as a function of g’s curvature. It would be interesting to
extend this work with parameter estimation, such as inferring the process noise
covariance matrix using a Wishart distribution [15], or the state transition ma-
trix with a Matrix-Normal distribution [1,12].
7 Conclusion
We examined active inference agents with linear Gaussian distributed dynamics
and a non-linear measurement function. We found that the first-order Taylor
series and unscented transform approximations to the non-linearly transformed
states lead to expected free energy functions with ambiguity terms that are
constant over states. A second-order Taylor approximation leads to a state-
dependent ambiguity term, inducing a preference over states.
Acknowledgments. The author gratefully acknowledges financial support from the
Eindhoven Artificial Intelligence Systems Institute (EAISI) at TU Eindhoven.
Disclosure of Interests. The authors have no competing interests to declare that
are relevant to the content of this article.
A Appendix: proof of Lemma 1
Proof. The cross-entropy is split into two entropies that simplify according to:
E (cid:2) −ln p(y t ,x t |u t ;D k )(cid:3)
p(yt,xt|ut;Dk) p(x |u ;D )
t t k
=− (cid:90) N (cid:0) (cid:20) x y t (cid:21) | (cid:20) m µ ¯ t (cid:21) , (cid:20) Γ S¯ ⊺ t Σ Γ t (cid:21) (cid:1) lnN (cid:0) (cid:20) x y t (cid:21) | (cid:20) m µ ¯ t (cid:21) , (cid:20) Γ S¯ ⊺ t Σ Γ t (cid:21) (cid:1) d(y t ,x t )
t t t t t t t t
(cid:90)
+ N(x |m¯ ,S¯)lnN(x |m¯ ,S¯)dx (39)
t t t t t t t
= D x + 2 D y ln(2πe)+ 1 2 ln (cid:12) (cid:12) (cid:20) Γ S¯ t ⊺ t Σ Γ t t (cid:21) (cid:12) (cid:12)− (cid:16)D 2 x ln(2πe)+ 2 1 ln|S¯ t | (cid:17) (40)
= D y ln(2πe)+ 1 ln (cid:0) |S¯|·|Σ −Γ ⊺ S¯−1Γ | (cid:1) − 1 ln|S¯| (41)
2 2 t t t t t 2 t
D 1
= y ln(2πe)+ ln|Σ −Γ ⊺ S¯-1Γ |. (42)
2 2 t t t t
Planning to avoid ambiguous states through Gaussian approximations 11
B Appendix: proof of Theorem 1
Proof. Plugging Σ , Γ from (31) into the result from Lemma 1, yields:
t t
D 1
y ln(2πe)+ ln|Σ −Γ ⊺ S¯−1Γ| (43)
2 2 t t t
D 1
= y ln(2πe)+ ln|G (m¯ )S¯G (m¯ ) ⊺ +R−G (m¯ )S¯⊺ S¯−1S¯G (m¯ ) ⊺ |
2 2 x t t x t x t t t t x t
D 1
= y ln(2πe)+ ln|R|. (44)
2 2
The cancellation is due to S¯ being symmetric, i.e., S¯⊺ S¯−1 =S¯S¯−1 =I.
t t t t t
C Appendix: proof of Theorem 2
Proof. Plugging Σ , Γ from (33) into the result from Lemma 1, yields:
t t
D 1 (cid:12) (cid:12) D 1 (cid:12)
y ln(2πe)+ ln(cid:12)Σ −Γ ⊺ S¯−1Γ (cid:12)= y ln(2πe)+ ln(cid:12)G (m¯ )S¯G (m¯ ) ⊺ (45)
2 2 (cid:12) t t t (cid:12) 2 2 (cid:12) x t t x t
+ 1(cid:88)
Dy
(cid:88)
Dy
e e ⊺ tr (cid:0) G(i)(m¯ )S¯G(j)(m¯ )S¯(cid:1) +R−G (m¯ )S¯⊺ S¯−1S¯G (m¯ ) ⊺ (cid:12) (cid:12)
2 i j xx t t xx t t x t t t t x t (cid:12)
i=1j=1
= D y ln(2πe)+ 1 ln (cid:12) (cid:12) 1(cid:88)
Dy
(cid:88)
Dy
e e ⊺ tr (cid:0) G(i)(m¯ )S¯G(j)(m¯ )S¯(cid:1) +R (cid:12) (cid:12). (46)
2 2 (cid:12)2 i j xx t t xx t t (cid:12)
i=1j=1
The covariance matrix S¯ is symmetric, i.e., S¯⊺ S¯−1 = S¯S¯−1 = I. Note that
t t t t t
the Hessian G(i)(m¯ ) depends on the inferred mean of the predicted state m¯ ,
xx t t
meaning that ambiguity is not constant over state-space.
D Appendix: proof of Theorem 3
Proof. Plugging µ , Σ , Γ from (37) into the log-determinant term from the
t t t
result in Lemma 1, gives:
2
1 ln (cid:12) (cid:12)Σ
t
−Γ
t
⊺ S¯
t
−1Γ (cid:12) (cid:12)= 1
2
ln (cid:12) (cid:12)
(cid:12)
2 (cid:88) Dx w
i′
(g(χ
i′
)−µ
t
)(g(χ
i′
)−µ
t
) ⊺ +R
i′=0
− (cid:16) 2 (cid:88) Dx w (χ −m¯ )(g(χ )−µ ) ⊺ (cid:17)⊺ S¯−1 (cid:16) 2 (cid:88) Dx w (χ −m¯ )(g(χ )−µ ) ⊺ (cid:17)(cid:12) (cid:12). (47)
i i t i t t j j t j t (cid:12)
i=0 j=0
The second term can be re-arranged to:
(cid:16) 2 (cid:88) Dx w (χ −m¯ )(g(χ )−µ ) ⊺ (cid:17)⊺ S¯−1 (cid:16) 2 (cid:88) Dx w (χ −m¯ )(g(χ )−µ ) ⊺ (cid:17)
i i t i t t j j t j t
i=0 j=0
=
2
(cid:88)
Dx2
(cid:88)
Dx
w (g(χ )−µ )(χ −m¯ ) ⊺ S¯−1w (χ −m¯ )(g(χ )−µ ) ⊺ . (48)
i i t i t t j j t j t
i=0 j=0
12 W.M. Kouw
Note that for j =0, (χ −m¯ )=(m¯ −m¯ )=0. Let D =D +λ. For j ≥1:
j t t t λ x
(χ −m¯ ) ⊺ S¯−1w (χ −m¯ ) (49)
i t t j j t
=(m¯ +(−1)i (cid:112) D (cid:2)(cid:112) S¯(cid:3) −m¯ ) ⊺ S¯−1 1 (m¯ +(−1)j (cid:112) D (cid:2)(cid:112) S¯(cid:3) −m¯ )
t λ t i t t D t λ t j t
λ
=
1
(
(cid:112)
D
)2(−1)i+j(cid:2)(cid:112) S¯(cid:3)⊺ S¯−1(cid:2)(cid:112) S¯(cid:3)
(50)
D λ t i t t j
λ
=(−1)i+j(cid:2)(cid:112) S¯(cid:3)⊺ S¯−1(cid:2)(cid:112) S¯(cid:3)
. (51)
t i t t j
(cid:2) (cid:3)
Furthermore,notethatcolumnselection · isequivalenttoright-multiplication
i
with a canonical basis vector e ;
i
(cid:2)(cid:112) S¯(cid:3)⊺ S¯−1(cid:2)(cid:112) S¯(cid:3) = (cid:0)(cid:112) S¯e (cid:1)⊺ S¯−1(cid:0)(cid:112) S¯e (cid:1) =e ⊺(cid:112) S¯ ⊺ S¯−1 (cid:112) S¯e . (52)
t i t t j t i t t j i t t t j
Since S¯ is a normal matrix, the eigendecomposition S¯ =VΩV−1 generates an
t t
orthonormal eigenvector matrix V, implying V−1 =V⊤, and a diagonal matrix
of eigenvalues Ω. This means that (cid:112) S¯ =VΩ1/2V−1, and that:
t
(cid:112) S¯ ⊺ S¯−1 (cid:112) S¯ = (cid:0) VΩ1/2V−1(cid:1)⊺ VΩ−1V−1(cid:0) VΩ1/2V−1(cid:1) (53)
t t t
=VΩ1/2V−1VΩ−1V−1VΩ1/2V−1 (54)
=VV−1 =I. (55)
⊺
Therefore, e Ie will be 1 for all i=j and 0 for i̸=j. We can thus identify two
i j
cases in the double sum in (48), one of which is always 0:
2
(cid:88)
Dx2
(cid:88)
Dx
w (g(χ )−µ )(χ −m¯ ) ⊺ S¯−1w (χ −m¯ )(g(χ )−µ ) ⊺ (56)
i i t i t t j j t j t
i=0 j=0
=
2
(cid:88)
Dx(cid:88)
w (g(χ )−µ )(−1)(i+j)1(g(χ )−µ ) ⊺
i i t j t
i=0 j=i
+
2
(cid:88)
Dx(cid:88)
w (g(χ )−µ )(−1)(i+j)0(g(χ )−µ ) ⊺ (57)
i i t j t
i=0 j̸=i
2
(cid:88)
Dx
⊺
= w (g(χ )−µ )(g(χ )−µ ) , (58)
i i t i t
i=0
where the (−1)(i+j) drops out because for i=j, i+j will always be even. One
may now recognize that (47) has two terms that cancel each other:
1
2
(cid:88)
Dx
⊺
2
(cid:88)
Dx
⊺
ln| w (g(χ )−µ )(g(χ )−µ ) +R− w (g(χ )−µ )(g(χ )−µ ) |
2 i′ i′ t i′ t i i t i t
i′=0 i=0
1
= ln|R|. (59)
2
Using this result and Lemma 1, we have proven Theorem 3.
Planning to avoid ambiguous states through Gaussian approximations 13
References
1. Barber,D.,Chiappa,S.:UnifiedinferenceforvariationalBayesianlinearGaussian
state-spacemodels.AdvancesinNeuralInformationProcessingSystems19(2006)
2. Conant,R.C.,RossAshby,W.:Everygoodregulatorofasystemmustbeamodel
of that system. International Journal of Systems Science 1(2), 89–97 (1970)
3. Cover, T.M.: Elements of information theory. John Wiley & Sons (1999)
4. Da Costa, L., Parr, T., Sajid, N., Veselic, S., Neacsu, V., Friston, K.: Active in-
ferenceondiscretestate-spaces:Asynthesis.JournalofMathematicalPsychology
99, 102447 (2020)
5. Friston, K.: The free-energy principle: a unified brain theory? Nature Reviews
Neuroscience 11(2), 127–138 (2010)
6. Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., Pezzulo, G.: Active in-
ference: a process theory. Neural Computation 29(1), 1–49 (2017)
7. Friston,K.,Rigoli,F.,Ognibene,D.,Mathys,C.,Fitzgerald,T.,Pezzulo,G.:Active
inference and epistemic value. Cognitive Neuroscience 6(4), 187–214 (2015)
8. Gustafsson, F., Hendeby, G.: Some relations between extended and unscented
Kalman filters. IEEE Transactions on Signal Processing 60(2), 545–555 (2011)
9. Julier,S.J.,Uhlmann,J.K.:Unscentedfilteringandnonlinearestimation.Proceed-
ings of the IEEE 92(3), 401–422 (2004)
10. Koudahl, M.T., Kouw, W.M., de Vries, B.: On epistemics in expected free energy
for linear Gaussian state space models. Entropy 23(12), 1565 (2021)
11. van de Laar, T., Koudahl, M., van Erp, B., de Vries, B.: Active inference and
epistemicvalueingraphicalmodels.FrontiersinRoboticsandAI9,794464(2022)
12. Luttinen,J.:FastvariationalBayesianlinearstate-spacemodel.In:EuropeanCon-
ference on Machine Learning. pp. 305–320. Springer (2013)
13. Millidge,B.,Tschantz,A.,Buckley,C.L.:Whencetheexpectedfreeenergy?Neural
Computation 33(2), 447–482 (2021)
14. Särkkä, S.: Bayesian filtering and smoothing, vol. 3. Cambridge University Press
(2013)
15. Sarkka, S., Nummenmaa, A.: Recursive noise adaptive Kalman filtering by varia-
tional Bayesian approximations. IEEE Transactions on Automatic Control 54(3),
596–600 (2009)
16. Schwartenbeck, P., Passecker, J., Hauser, T.U., FitzGerald, T.H., Kronbichler,
M., Friston, K.J.: Computational mechanisms of curiosity and goal-directed ex-
ploration. eLife 8, e41703 (2019)
17. Şenöz, İ., van de Laar, T., Bagaev, D., de Vries, B.: Variational message passing
and local constraint manipulation in factor graphs. Entropy 23(7), 807 (2021)
18. Tschantz, A., Seth, A.K., Buckley, C.L.: Learning action-oriented models through
active inference. PLOS Computational Biology 16(4), e1007805 (2020)
19. Zamiri-Jafarian, Y., Plataniotis, K.N.: A Bayesian surprise approach in designing
cognitive radar for autonomous driving. Entropy 24(5), 672 (2022)

=== REVISE TO ===
PROFESSIONAL TONE: Begin directly with content - NO conversational openings like 'Okay, here's...'

1. Fix all issues above
2. Title: "Planning to avoid ambiguous states through Gaussian approximations to non-linear sensors in active inference agents"
3. Include 10-15 quotes from paper text
   - Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
   - Use consistent quote formatting: 'The authors state: "quote"' or vary attribution phrases
   - Vary attribution phrases to avoid repetition
   - CRITICAL: Only extract quotes that actually appear in the paper text
4. ELIMINATE ALL REPETITION - each sentence must be unique
   - Check before each sentence: 'Have I already said this?' If yes, write something new
   - Vary attribution phrases - do NOT repeat 'The authors state' multiple times
5. Extract methodology, results with numbers, key quotes
6. 1000-1500 words, structured with ### headers

Generate COMPLETE revised summary.