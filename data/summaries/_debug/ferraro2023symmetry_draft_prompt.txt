=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Symmetry and Complexity in Object-Centric Deep Active Inference Models
Citation Key: ferraro2023symmetry
Authors: Stefano Ferraro, Toon Van de Maele, Tim Verbelen

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Key Terms: model, object, agents, objects, centric, complexity, symmetries, models, deep, symmetry

=== FULL PAPER TEXT ===

Symmetry and Complexity in Object-Centric
Deep Active Inference Models
Stefano Ferraro, Toon Van de Maele, Tim Verbelen, and Bart Dhoedt
IDLab, Department of Information Technology
Ghent University - imec
Ghent, Belgium
stefano.ferraro@ugent.be
Abstract. Humansperceiveandinteractwithhundredsofobjectsevery
day.Indoingso,theyneedtoemploymentalmodelsoftheseobjectsand
often exploit symmetries in the object’s shape and appearance in order
to learn generalizable and transferable skills. Active inference is a first
principles approach to understanding and modeling sentient agents. It
states that agents entertain a generative model of their environment,
and learn and act by minimizing an upper bound on their surprisal, i.e.
their Free Energy. The Free Energy decomposes into an accuracy and
complexity term, meaning that agents favor the least complex model,
that can accurately explain their sensory observations.
In this paper, we investigate how inherent symmetries of particular ob-
jects also emerge as symmetries in the latent state space of the genera-
tivemodellearntunderdeepactiveinference.Inparticular,wefocuson
object-centric representations, which are trained from pixels to predict
novelobjectviewsastheagentmovesitsviewpoint.First,weinvestigate
therelationbetweenmodelcomplexityandsymmetryexploitationinthe
statespace.Second,wedoaprincipalcomponentanalysistodemonstrate
how the model encodes the principal axis of symmetry of the object in
the latent space. Finally, we also demonstrate how more symmetrical
representations can be exploited for better generalizationin the context
of manipulation.
Keywords: Active Inference · Representation Learning · Symmetries ·
Deep Learning
1 Introduction
Humans perceive and interact with hundreds of objects every day. In doing so,
they need to develop mental models of these objects, which represent the object
shape, color, affordances, etc. From early infancy, toddlers learn this by actively
engaging with objects, which makes that they effectively mainly sample the
world with close-up observations of objects in center view, often holding and
manipulating the object in their hands [22,21].
Whenrepresentingobjectsinourmind,weoftengeneratesimplerrepresenta-
tions than their real-world observations. These representations often exploit the
3202
rpA
41
]VC.sc[
1v39441.4032:viXra
2 S. Ferraro et al.
Fig.1:Inthebrainconceptcanberepresentedwithdifferentlevelsofcomplexity
by exploiting different levels of symmetry.
various symmetries that are ubiquitous in real-world objects. For example,if we
are asked to quickly sketch a tree or a face we would end up drawing something
reallysimilartotheonespresentedattheleftofFigure1.Intuitively,thisshows
how more symmetries arise in the representation as it becomes less complex.
Activeinferenceisafirstprinciplesapproachtounderstandingandmodeling
sentient agents [7]. It states that agents entertain a generative model of their
environment, and learn and act by minimizing an upper bound on their sur-
prisal, i.e. their Free Energy [8]. Free Energy decomposes into an accuracy and
complexity term, meaning that agents favor the least complex model, that can
accurately explain their sensory observations.
Recently, deep active inference models have been proposed, which parame-
terizethegenerativemodelusingdeepneuralnetworksandlearnthestatespace
structure using stochastic gradient descent on the variational free energy loss
function [30,18]. In this paper, we investigate if symmetries also emerge in the
latentstatespaceofthegenerativemodellearntunderdeepactiveinferenceand
whether this is related to lower complexity in the Free Energy. In particular, we
focus on object-centric representations, which are trained from pixels to predict
novel object views as the agent moves its viewpoint [17].
In summary, we will zoom in on the following aspects:
1. We investigate the relation between model complexity and symmetry ex-
ploitationinthestatespace,byquantifyingandcomparingbothondifferent
object-centric models.
2. Wedoaprincipalcomponentanalysistodemonstratehowthemodelencodes
the principal axis of symmetry of the object in the latent space.
3. Wedemonstratehowmoresymmetricalrepresentationscanbeexploitedfor
better generalization of action selection in the context of manipulation.
Indoingso,wewillfirstformallydefinetheconceptofsymmetriesusinggroup
theoryinSection2.NextinSection3,wesummarizeactiveinference,variational
Symmetry and Complexity in Object-Centric Deep Active Inference Models 3
Free Energy, and how this decomposes into model complexity and accuracy.
Section 4 then presents the object-centric deep active inference setup used in
this paper, after which we address the aforementioned items in the experiments
in Section 5. Finally, we end with a discussion in Section 6, and conclusion in
Section 7.
2 What is symmetry?
Symmetries area setof transformations that,when appliedto anobject,render
the object invariant. Mathematically, this can be formalized using group the-
ory [3,13]. A group G is defined as a set equipped with a composition operation
G×G → G, i.e. “·”, that, given two elements g and g of the set, produces a
1 2
third element of the set g :
3
(g ,g )→g ·g =g , (1)
1 2 1 2 3
g ,g ,g ∈G
1 2 3
given that:
1. g ·g is an associative operation
1 2
2. there exist an identity element e∈G such that e·g =g, ∀g ∈G
3. for any g ∈G there exist a g−1 ∈G such that g·g−1 =g−1·g =e
Given a group G and a set of objects X, a group action of G on X is a
mapping G×X →X, i.e. an action g of G on x of X produces an element x
1 2
of the set X:
(g,x )→g·x =x (2)
1 1 2
x ,x ∈X
1 2
such that:
1. g·x is an associative operation
1
2. there exist an identity element e∈G such that e·x=x, ∀x∈X
We can now define the concept of an invariant map. Given again a group G
thatactsonasetX,ifF: X →Y isamapbetweensetsX andY,F isinvariant
if F(g·x)=F(x),∀(g,x)∈G×X. If X is invariant under such a mapping, the
mapping is a symmetry of X. The group of all transformations under which the
object X is invariant is called the symmetry group of X.
Forexample,thesetofrotationsof0◦,+90◦ and-90◦ formsagroupandcan
be applied to a set of 2D shapes, which is then the group action. Consider X to
be the set of all square shapes, then these rotations are symmetries, but not for
the set of triangles.
4 S. Ferraro et al.
In addition to invariance, we can also define equivariance. Given a group
G acting on both spaces X and Y and given a map H: X → Y, X is to be
consideredequivariantifforanyg ∈Gandanyx∈X wehaveH(g·x)=g·H(x).
Simply put it does not matter the order we apply our group transformations. If
we consider now an equivariant map H and an invariant map F, then we will
haveF(H(g·x))=F((g·H(x)))=F(H(x))thatisagainaninvariantmapping.
3 Symmetry and Complexity in Active Inference
Activeinferenceprovidesaframeworktodescribethebehaviorofsentientagents
acting in a dynamic environment. This theory postulates that a sentient agent
entailsagenerativemodeloftheenvironment,andtheagentactsintheenviron-
ment with the imperative of minimizing an upper bound on surprisal, i.e. free
energy [8].
The generative model comprises the joint probability P(o ,a ,s )
0:T 0:T−1 0:T
over sequences of observations o , actions a and hidden or latent state
0:T 0:T−1
s over some time horizon T. Modeling this as a partially observable Markov
0:T
decision process (POMDP) as depicted in Figure 2.b, this joint probability can
be factorized as:
T
(cid:89)
P(o ,a ,s )=P(s )P(o |s ) P(a )P(s |s ,a ) P(o |s )
0:T 0:T−1 0:T 0 0 0 t−1 t t−1 t−1 t t
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
t=1
Transitionmodel Likelihoodmodel
Inordertoinferbeliefsaboutthehiddenstatevariables,anactiveagentneeds
to calculate a posterior belief provided an observation o , which is in general in-
t
tractable.Tosolvethisproblemtheagentresortstovariationalinference,which
approximates the true posterior P(s |o ) with an approximate posterior distri-
t t
bution Q(s |o ). The objective is then to maximize the evidence lower bound
t t
(ELBO) [15], or equivalently, to minimize variational Free Energy [8]:
(cid:88)
F = −logP(o )+D [Q(s |o )||P(s |o ,s ,a )]
t KL t t t t t−1 t−1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
t
Evidence Divergence
(3)
(cid:88)
= D [Q(s |o )||P(s |s ,a )]−E [logP(o |s )]
KL t t t t−1 t−1 Q(st|ot) t t
t (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Complexity Accuracy
Here, the first line shows that F is indeed an upper bound on the (negative)
log evidence, bounded by the KL divergence between the approximate and the
true posterior. The second line rewrites the variational Free Energy as a com-
plexity term and an accuracy term. Here, the complexity term is the divergence
betweenthevariationaldensity(i.e.posteriorbelief)andpriorbeliefsabouthid-
denstates.Inotherwords,theagentpreferstheleastcomplexmodelthatyields
accurate explanations.
Symmetry and Complexity in Object-Centric Deep Active Inference Models 5
In active inference, agents minimize Free Energy either by updating their
internal model or by acting on the environment. Actions are selected which
are expected to reduce Free Energy in the future. As agents can rely on their
generativemodeltoobtainexpectedobservationsinthefuture,theycanestimate
the expected Free Energy G for all considered actions [30]:
G(a )=D (cid:2) Q(s |a )||P(s ) (cid:3) +E (cid:2) H(P(o |s )) (cid:3) (4)
t KL t+1 t t+1 Q(st+1) t+1 t+1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Risk Ambiguity
Here,weusedthattheagenthaspriorpreferencesoverfuturestatesP(s ),
t+1
and hence searches for actions that bring it closer to preferred states while min-
imizing the expected ambiguity. Actions are then selected by sampling from
P(a )=σ(−γG(a )) with σ the softmax function and γ the temperature.
t t
Indeepactiveinference,thestatespacestructureisnotspecifiedupfrontbut
ratherlearnedfromdatabyinstantiatingthelikelihoodmodel,transitionmodel,
and approximate posterior by deep neural networks, and performing gradient
descent on the variational Free Energy [30]. Crucially, this enables the agent to
determine the latent state space structure, and potentially exploit symmetries.
To this end, the posterior model can be seen as a map from observations to
latentstatespace,andsymmetriescanarisefromtransformationsinobservation
space that render the latent state invariant. Moreover, we hypothesize that the
complexity term in the variational Free Energy minimization will encourage
the model to exploit symmetries in the state space, especially when there are
symmetries in the environment that the agent has to model.
4 Object-centric generative models
In order to investigate the level of symmetry that can be exploited through
learned generative models, we focus on an agent learning object-centric repre-
sentations as proposed by Van de Maele et al. [17]. This model considers ob-
servations from different viewpoints of a given object and learns a generative
model by minimizing the predicting error for novel views. The agent can move
the camera, simulating a robotic manipulator with an in-hand camera, allowing
it to sample informative views about the object, and move towards preferred
poses, for example where the agent is able to grasp the object.
This model is effectively implementing a part of a hierarchical generative
model of human vision [19], which entails that the brain uses retinal activations
tomakeinferencesaboutthephysicalscenecomposition,i.e.whichobjectswith
adistinctshapeandappearancearepresentintheenvironment.Moreover,learn-
ing distinct models for separate object categories by looking at objects from a
close distance is inspired by the hypothesized role of distinct cortical columns
in the brain, which “vote” for objects at a certain pose in order to infer a
consistent scene representation [10]. In this work, we particularly focus on these
object-centricgenerativemodels,astheyenableustoinvestigatethesymmetries
6 S. Ferraro et al.
(a) (b)
Fig.2: Visualization of the generative model adopted. (a) the object-centric
model adopted, an agent in the form of a pinhole camera is free of moving
around the environment while maintaining a focus at the center of mass of the
object. Agent move from viewpoint v to v through action a , at each step
t t+1 t
observationoisrendered.(b)BayesianNetworkdescribingthegenerativemodel
of the agent. Observation o is the output of the generative process steaming
t
from state s . Latent state s is dependent on the previous state s and ac-
t t t−1
tion a . observed variables are presented in grey while unobserved ones are in
t+1
white.
learnt by the model, and intuitively relate those to the symmetric properties of
the physical object at hand that is modeled.
Figure2showstheobject-centricactiveinferenceagentsetup,whichconsists
of a pinhole camera that renders views of a particular object. At every timestep
t, the camera moves to viewpoint v and produces an observation o . Transition
t t
to viewpoint v is the result of action a . This action represents the relative
t+1 t
translation and orientation that is applied to the camera pose to acquire a new
viewpoint. The action space is thus defined as the collection of transforms that
change the camera pose to a different object-centric observation. The resulting
observations are images that render the object from various poses, similar to
how toddlers focus on particular objects from a close distance in their early
infancy [23].
This way, learning a latent representation of a particular object is cast as
active inference, where the generative model is implemented using deep neural
networks. This results in a model consisting of three distinct neural networks:
1. an encoding network q as approximate posterior Q(s |o ) ;
φ t t
2. a transition network p as transition model P(s |s ,a );
χ t+1 t t
3. a decoding network p as likelihood model P(o |s ).
ψ t t
AgraphicalrepresentationispresentedinFigure3.Attimestept−1,obser-
vationo isencoded.Theresultoftheencodingprocessisabeliefdistribution
t−1
q (s |o ), of which a latent state s is sampled using the reparameteriza-
φ t−1 t−1 t−1
tiontrick.Thesampledlatent,pairedwithactionvectora istheinputofthe
t−1
Symmetry and Complexity in Object-Centric Deep Active Inference Models 7
Fig.3: Neural network architecture. From the top left: observation o is fed
t−1
through the encoding unit q , and the output is a belief over the state of the
φ
object. Sampling is performed on the latter distribution to obtain a state s ,
t−1
which is paired with action a and fed to the transition unit p . action a
t−1 χ t−1
is a relative pose transformation between viewpoint v and v . The produced
t−1 t
belief over the transitioned state undergoes sampling to obtain prediction sˆ.
t
transition network p . The action vector consists of a relative translation and
χ
rotation as a 6 DOF continuous rotation representation [29]. A belief over the
transitioned state is encoded in p (s ,a ). Again sampling will provide the
χ t−1 t−1
expect transitioned state sˆ. The latter is then decoded by network p to result
t ψ
in the sensory prediction oˆ. All the networks are jointly trained by minimizing
t
the variational Free Energy:
F =||o −oˆ||2+βD [Q(s |o )||P(s |s ,a )] (5)
t t t KL t t t t−1 t−1
The first term is the accuracy which is computed as the mean squared error
between the prediction oˆ and the ground truth o . The second term is the
t t
complexity term which we scale with a β coefficient to adapt the weight of the
modelcomplexity.Theresultinglossformulationishencesimilarasproposedby
the β-VAE [11]. By varying β we will assess to what extent model complexity
relates to emerging symmetries in the latent state space. Given the formulation
similarities with the β-VAE architecture, we expect the information bottleneck
imposed by the variation of β will result in a compression of the latent space
and further exploitation of symmetric features.
5 Experiments
We trained the presented model on a subset of the YCB dataset [28]. Objects
are shown in Figure 4. They have been selected based on the presence of axes
8 S. Ferraro et al.
Fig.4: Subset of YCB dataset considered for the experimentations.
of symmetry both for the texture and shape of the object (i.e. Master Chef can
andplate)andthepresenceofonlyshapesymmetry(i.e.crackerbox,dice,and
Rubik’s cube).
Foreachobject,asetof10000randomlysampledobservationsandtheircor-
responding viewpoints have been recorded. These observations are produced in
anobject-centricfashion,bysamplingtheazimuthandelevationfromaspherical
coordinate system, while the radius is kept at a fixed value.
WeusethemodelarchitectureillustratedinFigure3.Thetrainingprocedure
issimilartotheoneadoptedbyVandeMaeleetal.[17]andconsistsofprocessing
pairs of observation simultaneously.
Foreachobject,wetraineddifferentmodelswithβvaryinginarangebetween
0.25to100.Inthefollowingsubsections,wewillanalyzetheresultinglatentspace
structure. First, we evaluate how the resulting model complexity changes with
varying β, and how this results in invariants in the state space which reflects
the symmetry. Next, we do a principal component analysis and check whether
theamountofprincipalcomponentsrelatetothesymmetryaxesofthemodeled
object. Finally, we show how exploiting symmetry can help to generalize action
selection, i.e. to infer successful grasp poses from a demonstration.
5.1 Complexity and Symmetry exploitation
In order to evaluate model complexity, we consider a set of 900 evaluation pairs
consistingoftworandomlysampledobservationsandtheactionmovingthecam-
era viewpoint from one to the other. For each pair, we calculate the complexity
as the KL divergence between the posterior and the prior. The prior is obtained
by encoding the first observation with the posterior model, and then predicting
the state distribution using the transition model given the action. The posterior
distribution is calculated by encoding the second observation with the posterior
model. We evaluate the complexity term for the whole evaluation dataset and
report the median as an overall measure of complexity.
To evaluate the symmetry exploitation from the model, we analyze to what
extent the latent state is invariant for different object viewpoints. To this end,
we use the same evaluation dataset, but now encode both observations with the
posteriormodel,andmeasuretheKLdivergencebetweenthosetwo.Forasingle
pair of observations a and b the symmetry term is:
S =D [Q(s |o )||Q(s |o )] (6)
a−b KL a a b b
Symmetry and Complexity in Object-Centric Deep Active Inference Models 9
Fig.5: Complexity terms and symmetry exploitation. Evaluated on a subset of
the YCB dataset. For each object, multiple models have been trained adjusting
the beta factor. The symmetry exploitation term is expressed in percentage
terms.
WeconsiderthestatemappinginvariantwhenS isbelowacertainthreshold,
which we empirically set to 300. The symmetry exploitation term expresses the
percentage of objects’ observations that are considered symmetric.
Our results are shown on Figure 5. The top row shows the model complex-
ity for various objects and varying β factors. As expected, model complexity
decreases as β increases. Conversely, symmetry exploitation increases with in-
creasing β, until the model collapses for very high β. In this case, every obser-
vation is mapped to a single latent, and we get posterior collapse.
InFigure6weprovideavisualizationofthestatespacedistributionobtained
by applying t-SNE [16]. Notice how for a low beta value of 0.75 similar observa-
tions are encoded to unique regions of the embedding, with evident separation
from dissimilar observations. By increasing beta, we start to notice some degra-
dationinthequalityofthepartitioning.Theshapepropertiesoftheobjectsare
still encoded correctly, unlikely the texture ones. For example, for the cracker
box,thefrontandthebackoftheboxaremixedtogether,insteadfortheRubik’s
cubeorangefacesaremixedwiththeredones.Overall,wefindthatminimizing
model complexity results in invariants in the latent space, effectively mapping
different observations to the same latent representation. The observations that
get mapped to the same latent code also reflect the symmetries of the physical
object.
5.2 Principal Axes of Symmetry
In this section, we further investigate how the true axes of symmetry of the
objects are represented in the latent space. To perform such analysis we opted
for Principal Components Analysis (PCA). PCA is a technique often used for
dimensionality reduction [27,14], the output of such analysis is the eigenvectors
and eigenvalues of the input dataset. We composed a dataset with 900 rendered
10 S. Ferraro et al.
Fig.6: Visualization of the t-SNE mapping applied on the latent space for 100
uniformly distributed observations of cracker box and Rubik’s cube. Increasing
beta values are presented.
observations, obtained by sampling viewpoints with varying elevation and az-
imuthcoordinates,butatafixedrange.Allobservationsareencodedintolatent
states using the posterior model, which we stack into a matrix M .
l
We hypothesize that for objects that have physical axes of symmetry along
the elevation and azimuth dimensions, only two principal components would
resultfromtheanalysisofthecomponentsonM .Figure7showstheeigenvalues
l
for various objects and varying β. Indeed, for objects like the Master Chef can
andtheplate,whichhavestrongsymmetry,thereareonlytwocomponentsthat
have large eigenvalues. For objects where the symmetrical properties are not
exploited during the data collection, the trend is reflected by a more uniform
distribution of the information along all the latent elements.
Notethatoncethemodelcollapsesforhighβ values,mostoftheeigenvalues
become zero, since no more elements are any more relevant for the collapsed
representation. Also, for Master Chef can and the plate it is interesting to point
out how for increasing values of β the principal axes become more apparent.
Symmetry and Complexity in Object-Centric Deep Active Inference Models 11
Fig.7: Eigenvalues plots resulting from Principal Component Analysis (PCA).
Provided a dataset of 900 instances obtained from the variation along azimuth
andelevationwithrespecttosphericalcoordinates.PCAisappliedtothelatent
vectors encoded from each observation.
5.3 Generalizing graspable poses through symmetry exploitation
In this final experiment, we look at how the exploitation of symmetry in the
agent’s generative model can influence a practical task. To this end, we provide
the agent with the task to grasp an object, given an example observation. This
preferred observed view can be interpreted as a proxy for the target grasping
pose, i.e. as if the agent is a robotic manipulator with an in-hand camera.
To solve this task, the agent has to plan its action that will realize the pre-
ferredobservation.Theactiveinferenceagentdoesthisthroughtheminimization
of expected free energy as described in Section 2. The considered preference is
thus provided as an RGB image o from a randomly sampled viewpoint v .
t+1 t+1
The agent’s task is then to infer the correct action to move from initial obser-
vation o to the preference. For this experiment, again a dataset is created with
t
twoobservations,andthegoalistofindanactiona ,thatbringstheagentfrom
t
the first observation to an observation similar to the second.
For finding the action with the lowest expected free energy, a Monte Carlo
procedure is used. First, the approximate posterior over state Q(s |o ) is com-
t t
puted by encoding observation O using q . Then 900 actions are randomly
t φ
sampled to yield a uniform distribution of target viewpoints around the object.
For each of these actions, the transitioned belief is acquired through p . The
χ
expected free energy G is then evaluated by computing the negative log proba-
bilityofthemeanofthetransitionedstatebeliefwithrespecttotheapproximate
posterior over the state, given our preferred view Q(s |o ). We repeat this
t+1 t+1
process for all elements in the dataset.
Weextractthetenactionswiththelowestexpectedfreeenergyandvisualize
theminFig8asthecorrespondinggraspingposes.Thetargetpose,orpreference,
is shown in green while the selected poses are presented in dark gray. From this
visualization, it can be observed that by increasing the β parameter, the model
starts exploiting more symmetries in the system. The relaxation of β during the
optimization of the model yields behavior where the agent is more permissive
towards different -but similar- poses. While this also causes a detrimental effect
onreconstructionaccuracy,onecanseehowfindingmoreequallygraspableposes
foranobjectisadvantageous.Asaresult,enforcingthisexploitationofsymmetry
12 S. Ferraro et al.
Fig.8:Manipulativeactionsdrivenbyexpectedfreeenergyactionselection.Pro-
videdatargetpose,displayedingreen,possibleselectedmanipulationposesare
shown in black.
aidsinthegeneralizationtowardsothergraspableposes.Ifthemanipulationtask
requireshighprecision,wecanadoptamodelwithalowβ andthuslowvariance
over sampled poses, while in the opposite case where we don’t care about the
exact grasping location, a model with high β could be beneficial.
6 Discussion
6.1 Complexity-accuracy trade-off in view of preferences
From our experiment results, we conclude that penalizing the complexity of the
modelthroughtheweighingofthecomplexityterminthefreeenergyformulation
yieldsanincreasedamountofsymmetryrepresentations.Themodelhaslearned
different observations mapping to the same belief over the state. In our case, we
adapted the model complexity by varying weight β on the complexity term in
the loss function. In reality, however, the accuracy-complexity trade-off should
be governed by preferences. High precision preferences on particular outcomes
might require a more complex model (i.e. I want to grasp the object from one
specificviewpoint),whereaslowerprecisionpreferences(i.e.Ijustwanttograsp
the object) can be realized with a less complex model, i.e. one that exploits
symmetries.
In an analogous way, Battaglia et al. [2] studied the “intuitive physics” we
apply to the objects we observe or interact with. Battaglia et el. conclude that
humansperformthistypeofinferenceaboutobjectdynamicsinanapproximate
manner with respect to the exact properties of the objects. There is a trade
between precision for speed, generality, and the ability to make predictions that
prove to be “good enough” for the everyday activities of human beings, hence
that minimize Free Energy. In this type of scenario, the ”preference” would be
in the form of a computational constraint.
Symmetry and Complexity in Object-Centric Deep Active Inference Models 13
6.2 Symmetry in the brain
It is historically known that through visual processing the brain discards in-
formation about identity preserving transformations of objects [9,20]. While at
the V1 layer of the visual cortex, information is encoded in high-dimensional
“entangled” representations, transformation information is lost and results in
“exemplar” neurons [4]. Each “exemplar” neuron fires accordingly to a specific
sensory identity (e.g. a specific object), invariant to the object pose.
Only recently, along with the advancement in ML, a new point of view has
become more popular. This new take stems from the equivariant representation
of brain functionality. In the invariant representation, a transformed input is
mapped to the same intermediate representation. In the equivariant representa-
tion,thetransformationtotheinputobservationispreservedandcascadedinto
theintermediatespace.Equivariantrepresentationshavebeenhighlyadoptedin
the context of ML [12,25,6,26], and are considered crucial to achieving general-
ization features from the model at hand. The adoption of equivariant architec-
turesisfavoredintheresearchof”disentangled”systemsbytheMLcommunity
where they have demonstrated their efficiency in generalization, imagination,
and abstraction reasoning.
Considering now an object as a unique composition of features. The equiv-
ariant representation exploits the fact that a certain subset of features may be
invariant to certain transformations, but the overall representation is still likely
to preserve information about the applied transformation. As an example, con-
sider a red-colored mug, when applying a rotational transformation, the color
feature is independent of it, instead features like pose, and lighting conditions
will have a dependency on it. With respect to the disentangling property of the
brain,fromtheneuroscienceliterature,wehaveproofthatgoingalongthevisual
cortex, many primary IT neurons have specific activation with respect to some
of the generative factors they are exposed to[24,4,1].
6.3 Symmetry versus disentanglement
The type of experimentation performed in this work is similar to the one per-
formed in the disentanglement work by Higgins et al. [12], where they showed
how higher β results in better disentanglement in the latent space. The disen-
tanglementeffectisobtainedbytheuseofanisotropicunitGaussianN(0,I)as
a fixed prior. This specific distribution enforces disentanglement by exploiting
the isotropic nature of the distribution (i.e. diagonal covariance matrix).
Inourarchitecture,however,thepriorislearned,andourlatentstatespaces
do not show disentanglement features, even for high β factors. As future work,
wecouldalsoexperimentwithextraregularizationtermstoencouragedisentan-
glement, and investigate how this relates to model complexity and symmetries.
7 Conclusion
Inthispaper,weanalyzedtherelationbetweenmodelcomplexityandsymmetry
exploitationinthecontextofanobject-centricdeepactiveinferenceframework.
14 S. Ferraro et al.
We first showed how lower model complexity leads to an increase in exploiting
symmetriesinthelearnedlatentstatespace.Second,weinvestigatedinmorede-
tailhowthelearnedsymmetriesinlatentspacecapturethephysicalsymmetries
of the object modeled. Finally, we demonstrated how lower complexity models
can be exploited for inferring preference realizing actions, which immediately
generalize to symmetric configurations. In future work, we aim to investigate
further how agents can learn the optimal accuracy-complexity trade-off, in view
ofanagentthatneedstorealizeacertainsetofpreferences.Inthissetup,instead
of manually varying β in the loss function, the agent should ideally converge to
the least complex model that is able to realize the agent’s preferences. In their
work Falorsi et al. [5], proposed an ad-hoc reparameterization trick for distribu-
tionsontheSO(3)groupofrotationsin3D.Matchingthetopologyofthelatent
datamanifoldtotheoneofthelatentspace.Asanextensiontothecurrentwork,
we aim to investigate the impact of the optimizations introduced by Falorsi et
al. in the symmetry exploitation scenario.
Author Contributions
SF conceived and performed the experiments. SF, TVa, and TVe contributed
to the software implementation. SF and TVe took care of the writing of the
manuscript.TVa,TVeandBDcontributedtothereviewofthemanuscript.BD
supervisedthewholeproject.Allauthorscontributedtothearticleandapproved
the submitted version.
Funding
ThisresearchreceivedfundingfromtheFlemishGovernment(AIResearchPro-
gram).
Data Accessibility
Data are available as supplementary material. Training dataset, trained models
along with the code (for training routine and figures generation) are provided.
The authors remain available for any clarification on its use.
References
1. Arguin, M., Saumier, D.: Conjunction and linear non-separability effects in visual
shape encoding. Vision Research 40(22), 3099–3115 (2000)
2. Battaglia, P.W., Hamrick, J.B., Tenenbaum, J.B.: Simulation as an engine of
physical scene understanding. Proceedings of the National Academy of Sciences
110(45), 18327–18332 (2013). https://doi.org/10.1073/pnas.1306572110, https:
//www.pnas.org/doi/abs/10.1073/pnas.1306572110
Symmetry and Complexity in Object-Centric Deep Active Inference Models 15
3. Bronstein, M.M., Bruna, J., Cohen, T., Veliˇckovi´c, P.: Geometric
deep learning: Grids, groups, graphs, geodesics, and gauges (2021).
https://doi.org/10.48550/ARXIV.2104.13478, https://arxiv.org/abs/2104.
13478
4. Chang, L., Tsao, D.Y.: The code for facial identity in the primate brain.
Cell169(6),1013–1028.e14(Jun2017).https://doi.org/10.1016/j.cell.2017.05.011,
https://doi.org/10.1016/j.cell.2017.05.011
5. Falorsi, L., de Haan, P., Davidson, T.R., De Cao, N., Weiler, M., Forr´e,
P., Cohen, T.S.: Explorations in homeomorphic variational auto-encoding
(2018). https://doi.org/10.48550/ARXIV.1807.04689, https://arxiv.org/abs/
1807.04689
6. Ferraro, S., Van de Maele, T., Mazzaglia, P., Verbelen, T., Dhoedt, B.: Disentan-
gling shape and pose for object-centric deep active inference models (2022)
7. Friston,K.:ThehistoryofthefutureoftheBayesianbrain.Neuroimage62-248(2),
1230–1233(Aug2012).https://doi.org/10.1016/j.neuroimage.2011.10.004,https:
//www.ncbi.nlm.nih.gov/pmc/articles/PMC3480649/
8. Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., ODoherty, J., Pez-
zulo, G.: Active inference and learning. Neuroscience & Biobehavioral Reviews
68, 862–879 (Sep 2016). https://doi.org/10.1016/j.neubiorev.2016.06.022, https:
//linkinghub.elsevier.com/retrieve/pii/S0149763416301336
9. Fukushima,K.:Neocognitron:Aself-organizingneuralnetworkmodelforamech-
anismofpatternrecognitionunaffectedbyshiftinposition.BiologicalCybernetics
36, 193–202 (1980)
10. Hawkins, J., Lewis, M., Klukas, M., Purdy, S., Ahmad, S.: A framework for in-
telligence and cortical function based on grid cells in the neocortex. Frontiers
in Neural Circuits 12 (2019). https://doi.org/10.3389/fncir.2018.00121, https:
//www.frontiersin.org/articles/10.3389/fncir.2018.00121
11. Higgins,I.,Matthey,L.,Pal,A.,Burgess,C.,Glorot,X.,Botvinick,M.,Mohamed,
S., Lerchner, A.: beta-VAE: Learning basic visual concepts with a constrained
variational framework. In: International Conference on Learning Representations
(2017), https://openreview.net/forum?id=Sy2fzU9gl
12. Higgins, I., Matthey, L., Pal, A., Burgess, C.P., Glorot, X., Botvinick, M.M., Mo-
hamed, S., Lerchner, A.: beta-vae: Learning basic visual concepts with a con-
strainedvariationalframework.In:5thInternationalConferenceonLearningRep-
resentations,ICLR2017,Toulon,France,April24-26,2017,ConferenceTrackPro-
ceedings (2017)
13. Higgins, I., Racani`ere, S., Rezende, D.: Symmetry-based repre-
sentations for artificial and biological general intelligence (2022).
https://doi.org/10.48550/ARXIV.2203.09250, https://arxiv.org/abs/2203.
09250
14. Keerthi Vasan, K., Surendiran, B.: Dimensionality reduction using principal com-
ponentanalysisfornetworkintrusiondetection.PerspectivesinScience8,510–512
(2016), recent Trends in Engineering and Material Sciences
15. Kingma,D.P.,Welling,M.:Auto-EncodingVariationalBayes.arXiv:1312.6114[cs,
stat] (May 2014), http://arxiv.org/abs/1312.6114, arXiv: 1312.6114
16. van der Maaten, L., Hinton, G.: Visualizing data using t-SNE. Journal of Ma-
chine Learning Research 9, 2579–2605 (2008), http://www.jmlr.org/papers/v9/
vandermaaten08a.html
17. Van de Maele, T., Verbelen, T., C¸atal, O., Dhoedt, B.: Embodied ob-
ject representation learning and recognition. Frontiers in Neurorobotics 16
16 S. Ferraro et al.
(2022). https://doi.org/10.3389/fnbot.2022.840658, https://www.frontiersin.
org/articles/10.3389/fnbot.2022.840658
18. Mazzaglia, P., Verbelen, T., C¸atal, O., Dhoedt, B.: The free energy princi-
ple for perception and action: A deep learning perspective. Entropy 24(2)
(2022). https://doi.org/10.3390/e24020301, https://www.mdpi.com/1099-4300/
24/2/301
19. Parr, T., Sajid, N., Da Costa, L., Mirza, M.B., Friston, K.J.: Generative Models
for Active Vision. Frontiers in Neurorobotics 15, 651432 (Apr 2021)
20. Poggio, T., Bizzi, E.: Generalization in vision and motor control. Nature 431,
768–74 (11 2004). https://doi.org/10.1038/nature03014
21. Slone, L., Smith, L., Yu, C.: Self-generated variability in object im-
ages predicts vocabulary growth. Developmental Science 22 (02 2019).
https://doi.org/10.1111/desc.12816
22. Smith, L., Jayaraman, S., Clerkin, E., Yu, C.: The developing infant creates a
curriculum for statistical learning. Trends in Cognitive Sciences 22 (03 2018).
https://doi.org/10.1016/j.tics.2018.02.004
23. Smith,L.B.,Yu,C.,Pereira,A.F.:Notyourmother’sview:thedynamicsoftoddler
visual experience. Developmental science 14 1, 9–17 (2011)
24. Stankiewicz,B.:Empiricalevidenceforindependentdimensionsinthevisualrepre-
sentationofthree-dimensionalshape.Journalofexperimentalpsychology.Human
perception and performance 28, 913–32 (09 2002)
25. Steenbrugge, X., Leroux, S., Verbelen, T., Dhoedt, B.: Improving generalization
for abstract reasoning tasks using disentangled feature representations (2018)
26. van Steenkiste, S., Locatello, F., Schmidhuber, J., Bachem, O.: Are disentangled
representations helpful for abstract visual reasoning? In: Wallach, H., Larochelle,
H., Beygelzimer, A., d'Alch´e-Buc, F., Fox, E., Garnett, R. (eds.) Advances in
Neural Information Processing Systems. vol. 32. Curran Associates, Inc. (2019)
27. Wauthier, S., C¸atal, O., De Boom, C., Verbelen, T., Dhoedt, B.: Sleep: Model
reduction in deep active inference pp. 72–83 (12 2020)
28. Xiang,Y.,Schmidt,T.,Narayanan,V.,Fox,D.:PoseCNN:AConvolutionalNeural
Networkfor6DObjectPoseEstimationinClutteredScenes.arXiv:1711.00199[cs]
(May 2018), http://arxiv.org/abs/1711.00199, arXiv: 1711.00199
29. Zhou,Y.,Barnes,C.,Jingwan,L.,Jimei,Y.,Hao,L.:Onthecontinuityofrotation
representationsinneuralnetworks.In:TheIEEEConferenceonComputerVision
and Pattern Recognition (CVPR) (June 2019)
30. C¸atal, O., Wauthier, S., De Boom, C., Verbelen, T., Dhoedt, B.: Learning Gen-
erative State Space Models for Active Inference. Frontiers in Computational
Neuroscience14,574372(Nov2020).https://doi.org/10.3389/fncom.2020.574372,
https://www.frontiersin.org/articles/10.3389/fncom.2020.574372/full

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Symmetry and Complexity in Object-Centric Deep Active Inference Models"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
