=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Leading or Following? Dyadic Robot Imitative Interaction Using the Active Inference Framework
Citation Key: wirkuttis2021leading
Authors: Nadine Wirkuttis, Jun Tani

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2021

Key Terms: energy, action, belief, imitative, intention, robot, dyadic, active, inference, framework

=== FULL PAPER TEXT ===

1
Leading or Following? Dyadic Robot Imitative
Interaction Using the Active Inference Framework
Nadine Wirkuttis1 and Jun Tani2,∗
Abstract—Thisstudyinvestigatedhowsocialinteractionamong follower, who imitates this action, can be determined when
robotic agents changes dynamically depending on the individual multiple choices of actions are possible among a set of well-
belief of action intention. In a set of simulation studies, we ex-
habituated ones.
amine dyadic imitative interactions of robots using a variational
Recent theories on predictive coding (PC) and active in-
recurrent neural network model. The model is based on the
free energy principle such that a pair of interacting robots find ference (AIF) based on the free energy principle (FEP)
themselvesinaloop,attemptingtopredictandinfereachother’s [2], [15] show that ”action intention” and its ”belief” can
actions using active inference. We examined how regulating the be formulated as a predictive model. ”Action intention” is
complexitytermtominimizefreeenergydeterminesthedynamic
considered a top-down prediction of action outcomes and
characteristics of networks and interactions. When one robot
”belief” as an estimated precision of this prediction or the
trained with tighter regulation and another trained with looser
regulation interact, the latter tends to lead the interaction by strength of intention (as described in [2], [15]). Analogous to
exerting stronger action intention, while the former tends to PC and AIF, Ito and Tani showed that imitative interaction
follow by adapting to its observations. The study confirms that can be performed using an RNN model by minimizing the
the dyadic imitative interaction becomes successful by achieving
prediction error instead of free energy in order to update
a high synchronization rate when a leader and a follower are
deterministiclatentvariables[13].However,thisdeterministic
determined by developing action intentions with strong belief
and weak belief, respectively. model does not account for the belief of action intention
because the precision of prediction cannot be estimated. On
a related topic, Ahmadi and Tani developed predictive-coding
I. INTRODUCTION inspired variational RNN (PV-RNN) [16]. Their model was
used to investigate how the strength of top-down intention SOCIALinteractionisconsideredanessentialcognitivebe-
in predicting fluctuating temporal patterns was modulated,
havior. In both empirical studies and synthetic modeling,
dependingonlearningconditionsinthemodel.Inthelearning
researchershaveinvestigatedunderlyingcognitive,psycholog-
process, free energy represented by the weighted sum of the
ical, and neuronal mechanisms accounting for various aspects
accuracy term and the complexity term is minimized. Ahmadi
of social cognitive behaviors. This study investigates mech-
and Tani found that softer regulation of the complexity term
anisms underlying synchronized imitation as a representative
during network training develops strong top-down intention.
socialcognitiveact,byformulatingtheproblemusingthefree
Predictions are more deterministic by self-organizing deter-
energy principle (FEP) [1], [2]. In simulation experiments of
ministic dynamics with the initial sensitivity characteristics in
dyadic robot imitative interaction, we examine how a leader
the network. Likewise, tighter regulation of the complexity
and follower can be determined in conflicting situations by
term results in weaker intention and increased stochasticity.
investigating the underlying network dynamics.
Compared to other neural network models based on the FEP
Numerous robotic studies have investigated imitative inter-
[17], [18], [19], [20], PV-RNN has advantages when applied
action.Inthe90s,imitationwasidentifiedasanindispensable
to problems in robotics. It can cope with temporal structure
humancompetencyrequiredinearlydevelopmentofcognitive
by using recurrence associated with stochastic latent variables
behaviors [3], [4], [5], [6]. Rizzolatti and colleagues [7]
and by hierarchical abstraction through a multiple timescale
showed that the mirror neuron system uses observations of
structure [21].
an action to generate the same action. Arbib and Oztop [8],
Our research group further investigated human-robot imita-
[9] indicated that mirror neurons may participate in imitative
tive interaction using PV-RNN. Chame and Tani [22] showed
behaviors. Upon this development, several research groups
thatahumanoidrobotwithforcefeedbackcontroltendstolead
proposed computational mirror neuron models for imitation
or follow the human counterpart in imitative interaction when
usingHiddenMarkovModels[10]andneuralnetworkmodels
its PV-RNN is set to softer or tighter regulation, respectively.
[11], [12], [13], [14].
However, the result is preliminary, merely showing a one-
An essential unsolved question in modeling of imitative
shot experimental result without any quantitative analysis. In
interaction is how a leader, who initiates an action, and a
a similar experimental setup, Ohata and Tani [23] showed
that this tendency can be also observed when regulation
This work was sponsored by the Okinawa Institute of Science and Tech-
nologyGraduateUniversity,Okinawa,Japan904-0302. of the complexity term is modulated during the interaction
1TheauthorsarewiththeCognitiveNeuroroboticsResearchUnit,Okinawa phase, rather than during the prior learning phase. The study
InstituteofScienceandTechnologyGraduateUniversity,Okinawa,Japan904-
investigated pseudo-imitative interaction between a simulated
0302.{nadine.wirkuttis,jun.tani}@oist.jp
*Correspondingauthor. robot and a human counterpart. This study, however, lacks
1202
guA
03
]OR.sc[
2v73120.3012:viXra
2
genuine interaction between the simulated robot and the hu- z, X¯, p , and q denote the latent state, the observation, the
θ φ
man counterpart because the outputs of the counterpart were prior distribution, and the approximate posterior, respectively.
replaced with static output sequences prepared in advance. θ and φ are the parameters of the generative and inference
The main contribution of the current study is to clarify the model. In maximizing the lower bound, the interplay between
underlying mechanism of how a leader and a follower can be accuracyandcomplexitycharacterizesthemodelperformance
determined in dyadic synchronized imitative interaction using in learning, prediction, and inference.
the framework of AIF. This study is distinct from the au- Consistent with the AIF, actions are generated so that the
thor’saforementionedpaststudiesbecausegenuineinteraction error between the expected action outcome and the actual
between two robots using the same model is examined and outcome is minimized. In robotic applications, this is equiva-
results are analysed both quantitatively and qualitatively. An lent to determining how expected proprioception in terms of
advantage of performing a robot-robot interaction experiment robot joint angles can be achieved by generating adequate
isthattheinternaldynamicscanbeanalyzedinacomparative motor torque. A simple solution is to use a PID controller,
way between the two robots. in which adequate motor torque to minimize errors between
The interaction experiment considers two robotic agents expected joint angles and actual angles can be obtained by
that are trained to generate a set of movement primitive means of error feedback schemes. Finally, perception by
sequences. When movements are generated by following a predictive coding and action generation by active inference
probabilistic finite state machine, the transition probability aredeployedsimultaneously,therebyclosingtheloopofaction
differs, depending on each of the two robots. After each and perception.
robot learns the given probabilistic transition structure for a
sequence,theexperimentaldesignallowsustoinvestigatehow
B. Overview of PV-RNN
two robots generate movement primitives in the synchronised
The PV-RNN model is designed to predict future sensation
imitative interaction. In particular, we examine conflicting
by means of prior generation, while reflecting the past by
situations in which each robot prefers to generate different
means of posterior inference based on learning (see Fig. 1).
movement patterns, depending on its learned experience. Do
One essential element of the model is the introduction of a
they synchronize to generate the same movement pattern with
parameter w, the so-called meta-prior, which regulates the
one robot following the other or leading by adapting the
complexity term in free energy. Different w settings results
intention? Or do they desynchronize by generating different
in alternation of the estimated precision in predicting the
movement patterns, ignoring their counterparts by following
sensation, as described later as prior generation (see section
their own action intentions? The current study hypothesizes
III-C). The model is also characterised by employing an
that these dyadic interaction outcomes depend on the relative
architecture of multiple timescale RNN (MTRNN) [21]. The
strength of the intention between the robots as a result of
whole network comprises multiple layers of RNNs wherein
regulating FEP complexity.
the dynamics of each layer are governed by different time
constant parameters τ. This scheme supports development of
II. MODEL hierarchical information processing by adequately setting the
timescaleofeachlayer[21],[14].Thisapproachisconsidered
A. Predictive Coding and Active Inference
as analogous to [24], [25].
ThecurrentstudyappliestheconceptsofPCandAIFbased
The following briefly describes the two essential parts, a
on FEP [1]. PC considers perception as the interplay between
generative model which is used for prior generation to make
a prior expectation of a sensation and a posterior inference
future predictions, and an inference model, which is used for
about a sensory outcome. Expectation of the sensation can be
posterior inference about the past. For further details, refer to
modeledbyagenerativemodelthatmapsthepriorofthelatent
[16], [23].
statetotheexpectationofsensation.Theposteriorinferenceof
1) Generative Model: The stochastic generative model is
the observed sensation can be achieved by jointly minimizing
usedforpriorgeneration,asillustratedinthefutureprediction
the error computed between the expected sensation and its
part (after time step 4) in Fig. 1. PV-RNN is comprised
outcome, i.e. the accuracy, plus the Kullback-Leibler (KL)
of deterministic variables d and random variables z. An
Divergence between the posterior and the prior distributions,
approximate posterior distribution q is inferred based on
φ
i.e.thecomplexity.Posteriorandpriorarebothrepresentedby
the prior distribution p by means of error minimization on
θ
Gaussian probability distributions using means and variances.
the generated prediction X. The generative model can be
This is to minimize free energy or to maximize the lower
factorized as:
bound of the logarithm of marginal likelihood:
p (X¯ ,d ,z |d )=
(cid:90) p (X¯,z) θ 1:T 1:T 1:T 0
logp θ (X¯)≥ q φ (z|X¯)log q θ φ (z|X¯) dz (cid:89) T p (X¯ |d )p (d |d ,z )p (z |d ) (2)
(cid:124) (cid:123)(cid:122) (cid:125) θ X¯ t t θd t t−1 t θz t t−1
Evidence lower bound t=1
=E [logp (X¯|z)]−D [q (z|X¯)(cid:107)p (z)]
qφ(z|X¯) θ KL φ θ Although d is a deterministic variable, it can be considered
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) to have a Dirac delta distribution centered on d˜as σ(d−d˜).
Accuracy Complexity
(1) X¯ is conditioned directly on z through d˜. At the initial time
3
past: posterior inference now future: prior generation
erutcetihcra
:erugiF
3 reyal
2
reyal
1 reyal
zp zp 4 5
zp zp 4 5
zp zp 4 5
d1 d2 d3 d4 d5
Xp
1
r Xe
1
x
e2 x
Xp
2
r Xe
2
x Xp
3
r Xe
3
x Xp
4
r Xe
4
x Xp
5
r Xe
5
x
X¯e
2
x
e3 x
mean µp and standard deviation σp. The reparameterization
t t
A1 A2 A3 trick was introduced by Kingma and Welling [27] to make
zp 1 ≅ z q 1 zp 2 e ≅ w z 2 z q 2 zp 3 e ≅ w z 3 z q 3 r th an ro d u o g m h t v h a e ri n ab et l w es or d k if f f o e r re l n e t a ia rn b i l n e g. fo T r he ba s c a k m p e ro c p o a n g s a i t d in e g rati e o r n ror is s
taken for the posterior of z in the inference model as well
t
d1 d2 d3 d4 d5
(cf. below Eq. 7).
A1 A2 A3
2) Inference Model: Posterior inference is performed dur-
zp 1 ≅ z q 1 zp 2 e ≅ w z 2 z q 2 zp 3 e ≅ w z 3 z q 3 ing learning and afterward, during action and perception. Fig.
1 illustrates information flow in the posterior inference in a
d1 d2 d3 d4 d5 time window from time step 2 to time step 3. The inference
A1 A2 A3 model for the posterior is described as:
zp 1 ≅ z q 1 zp 2 e ≅ w z 2 z q 2 zp 3 e ≅ w z 3 z q 3 Q φ (z t |d˜ t−1 ,e t:T )=N(z t ;µq t ,σ t q) (6)
where e denotes the error between the target X¯ and the
t t
predictedoutputX .Likethepriorp ,theposteriorq isalso
t θ φ
a Gaussian distribution with mean µq and standard deviation t
σq. For z it is defined as:
t 1:T
X¯e
3
x
q
φ
(zt|et:T)=N(µq
t
,σ
t
q)
Fig. 1: Graphical representation of a hierarchical 3-layer µq =tanh(Aµ) (7)
t t
PV-RNN architecture. Layers are indicated on the left. Time σq =exp(Aσ)
t t
increasesfromlefttorightandisindicatedasasubscript.The
representation shows the network in t = 3 with a two-time- Since computing the true posterior is intractable, an approxi-
stepposteriorinferencewindow[2,3]andpriorgenerationfor mate posterior q φ is inferred by maximizing the lower bound,
t=[4,5]. In the posterior inference window, prediction error analogous to Eq. (1). Here, the adaptation variable A 1:T
ex and the w weighted KL Divergence ez are minimized. forces the parameters φ of the inference model to represent
meaningful information. The lower bound of PV-RNN can be
derived as:
step, d˜is set to 0. Otherwise, d˜is recursively computed, for
T
whichtheinternalstatebeforeactivationisdenotedbyh.This L(θ,φ)= (cid:88) ( 1 E [logp (X¯ |d˜)]−
internalstatehisavector,calculatedasthesumoftheinternal N
X
qφ(zt|d˜ t−1,et:T) θ X¯ t t
states of the current level l and its connecting layers of the t=1 (8)
previous time step t−1 plus the latent z in the same layer of (cid:88) L wl D [q (z |d˜ ,e )||p (z |d˜ )])
the current time step t: l N z l KL φ t t−1 t:T θz t t−1
d˜l t =tanh(hl t ) wherethefirsttermistheaccuracyandthesecondtermisthe
hl t = (cid:18) 1− τ 1 l (cid:19) hl t−1 + (3) c n o u m m p b l e e r xi o ty f s (f e o n r so d r e y ta d il i s m r e e n f s e i r o r n ed s a to nd [1 t 6 h ] e ). n N um x b a e n r d of N t z l he ar l e ate th n e t
1 (cid:16) (cid:17)
Wlld˜l +Wllzl+Wll+1d˜l+1+Wll−1d˜l−1 random variables at the lth layer, respectively. wl serves as a
τl dd t−1 zd t dd t−1 dd t−1
weighting parameter for the complexity term in layer l and is
τl denotes the layer-specific time constant. With larger value
referred to as the meta-prior [16]. The meta-prior represents
for τl, slower timescale dynamics develop, whereas with a
the strength for regulating the closeness between the posterior
smaller value set, faster timescale dynamics dominate. W and the prior distributions. In t=1, wl is set with 1.0. wl
represents connectivity weight matrices between layers and 1 2:T
is set to a specific value when the sequence prior [26] is used
their deterministic and stochastic units. The output with size
aftertimestep1.Intheposteriorinference,alllearning-related
N is computed as mapping from d˜1 as:
x network parameters of θ, φ, and the adaptive variable A are
Xt=W
X
ll
d
d˜1
t
+bX (4) updatedtomaximizethelowerboundbyback-propagatingthe
error from time step T back to t [28].
The prior distribution p (z ) is a Gaussian distribution rep- 1
θ t
resented with mean µp and standard deviation σp. The prior 3) PV-RNN in Dyadic Robot Interaction: Two robots
t t
depends on d˜ by following the idea of a sequence prior equipped with the PV-RNN model interact during synchro-
t−1
nized imitation. In the interaction, the robots predict proprio-
[26], except at t = 1 where it follows a unit Gaussian
ception Xpr and exteroception Xex for the next time step.
distribution. t+1 t+1
ThepredictedXpr regulatesjointanglemovementsofarobot
p
θ
(z1)=N(0,I)
by considering a
t+1
PID controller. This movement Xpr can
p
θ
(zt|d˜ t−1)=N(µp
t
,(σ
t
p)2)wheret>1
(5) then be sensed by the other robot in terms of extero
t
c
+
e
1
ption
µp t =tanh(W d ll µpd˜ t−1) X¯ex . This is provided through the kinematic transformation
t+1
σ t p=exp(W d ll σpd˜ t−1) of joint angles Xp t+ r 1 (cf. Fig. 2). While in the training phase,
Based on the work on variational autoencoders, we use the the error signal is taken from the proprioceptive X¯pr as well
reparameterization trick to formulate the latent prior of z as as the exteroceptive X¯ex target sequences, in the interaction
t
Figure: interaction
4
Robot 1 Robot 2
layer 3 e z error signal layer 3 e z
intention precision to modulate intention intention precision
intention
to express belief
layer 2 e z layer 2 e z
intermediate layer intermediate layer
arms up bend elbows arms outwards
layer 1 e z layer 1 e z
sensory precision sensory precision
x
e X ex X¯ex body kinematics X pr
x
e
X pr body kinematics X¯ex X ex Fig. 2: Schematic of dyadic robot interaction where robots
are equipped with the PV-RNN model.
phasetheerrorsignal foreachrobotistakenonly fromX¯ex1. !3
During interactions, prediction errors ex are generated and
propagated bottom-up throughout all layers, as well as time
steps in the posterior inference window, in terms of the latent
error ez. This updates posterior distributions in the network
and minimizes the variational free energy. In this phase, only
A is updated without updating network parameters θ and
1:T
φ.
III. ROBOTEXPERIMENTS
To investigate how the interaction of two robots changes
with tighter and looser regulation of complexity, each robot
wastrainedandtestedindividually,asdescribedinIII-Bandin !4
III-C, respectively. Finally, two robots were examined during
a dyadic interaction (III-D).
A. Task Design
Robotic agents are trained with three movement primitives
A, B, and C (Fig. 3 (a)). Each primitive is 40 time steps in
length. A human experimenter generated the primitive data
via a master control of a humanoid OP22. The experimenter
controlled six joints in the upper body of one humanoid X¯pr.
TheexteroceptivetrajectoryX¯ex isgeneratedbymirroringits
own movement X¯pr and transformed into X¯ex xy-coordinate
positionsofthelefthandandrighthandtipsoftherobot(Fig.
3b). X¯pr and X¯ex are six and four dimensions, respectively.
Individual movement primitives are sampled and combined to
form a continuous pattern of 400 time steps that follows a
probabilistic sequence (analogous to [23]). Two probabilistic
patterns were generated, A20%B80%C and A80%B20%C as
shown in the form of a probabilistic finite state machine (P-
FSM) (Fig. 3 (c)). The difference between these two prob-
abilistic patterns is that C is biased and comes more often
(80%) than B (20%) after A in the former, and vice versa for
the latter.
1Considering only X¯ex for the error term in interaction settings assumes
thatthePIDcontrollergeneratesonlynegligiblepositionerrorsforthejoints.
2Humanoid OP2 and its master controller are developed by Robotis:
www.robotis.us/robotis-op2-us/.
rp
xe
xe
X
rX
lX
A B C
arms up bend elbows arms outwards
(a) robot movements
A20%B80%C A80%B20%C
80%C 20%C
A A
20%B 80%B
!14
rp
X¯
xe rX¯
xe lX¯
A B C
arms up bend elbows arms outwards
(b) movement trajectories
A20%B80%C A80%B20%C
80%C 20%C
A A
20%B 80%B
!4
rp
xe
xe
X
rX
lX
A B C
A20%B80%C A80%B20%C
80%C 20%C
A A
20%B 80%B
(c) probabilistic transition
Fig. 3: Task design. Robot movement primitives A, B, and C
ofthetrainingdataset(a).ProprioceptivetrajectoriesX¯pr plus
exteroceptive trajectories X¯ex and X¯ex. Colors represent six
r l dimensionsofjointanglesforX¯pr andxy-coordinatepositions
of the right and left end effector X¯ex and X¯ex (b). Two
r l
P-FSMs representing different movement primitive transition
patterns of A20%B80%C and A80%B20%C (c).
A point of interest is the interaction phase after the learn-
ing phase. It is expected that both robots can generate A
synchronously, since it is a deterministic state. This could
be different from generating B or C as two robots learned
different preferences in terms of transition probabilities. One
robot may lead so as to generate B or C while the other may
just follow it. However, both robots may generate their own
biasedmovementsand,thus,desynchronizetheirbehavior.The
current study hypothesizes that whether B or C is generated
synchronized or desynchronized between the two robots de-
pends on the complexity regulation of each robot.
B. Robot Training
The PV-RNN was trained with 20 data samples on a
set of different parameters (TABLE I). All network specific
parameters were fixed during training. To explore the influ-
ence of the meta-prior, w, only this parameter changed for
different networks and was repeated with different random
seeds to ensure reproducibility. Networks were trained for
80,000 epochs, using Adam Optimizing and back-propagation
through time (BPTT) [28] with learning rate 0.001. After
training, network performance was first analysed in stand-
alone robot experiments (subsection III-C). Thereafter, dyadic
5
TABLE I: Network parameters for training PV-RNNs. 3) Summary of Preparatory Analysis: Loose regulation
of the complexity term results in noisier, less repeatable
d z τ w1 w2:T
prior generation performance. Also the learned probability for
layer1 40 4 2 1 w1=[0.0,0.001,...4.999,5.0]
layer2 20 2 4 1 w2=w1×10 transition to either B or C is not accurate. This observation
layer3 10 1 8 1 w3=w1×100 changes with increasing meta-prior. The larger w, the more
accuratethelearnedtransitionprobabilitybecomes.Also,prior
robot interaction was studied using networks trained with w generation becomes more repeatable by developing more de-
set for the two representatives of tight and loose regulation of terministic dynamics with the initial sensitivity characteristics
FEP complexity (subsection III-D). (i.e., the sequence is generated solely depending on the latent
state in the initial time step). For subsequent dyadic robot
interaction experiments, we empirically select the meta-prior
C. Preparatory Analysis of Training Results
settingw=0.005andw=3.4astworepresentativesoftight
To investigate how the model learns the probabilistic struc-
and loose regulation of the FEP complexity.
ture of the training data, we conducted a first analysis in the
form of prior regeneration. For prior regeneration we choose
one training sample and use two time steps of the adaption
variable AX¯ to initialize the prior distribution p(z ) in
1:2 1:2
the PV-RNN. Thereafter the future prediction X 3:400 for D. Dyadic Robot Interaction Experiments
the remaining training sample length can be calculated (cf.
prior generation in Fig. 1). Using this scheme, we generated
In the following experiments, robots are either trained with
20 sequences for each meta-prior w. This was repeated
w=0.005 or w=3.4. For readability, we will consider R1
for each network that was trained for that parameter for w
and R2 with subscripts of the respective meta-priors w. In
all random seeds. For brevity, training analysis is reported w
the dyadic interaction, we present the network of each robot
only for the network that was trained on the probabilistic with observations of movements of the counterpart robot X¯ex
sequence A20%B80%C. Training of A80%B20%C showed
as the target and perform posterior inference in a regression
comparable results. An Echo State Network for multivariate
window with size win =70. Inference is performed from
size
timeseriesclassification[29]withreservoirsizeN =45,25%
the current time step t back to t − win , or t in case
size 1
connectivity and leakage 60% was used for classification of
t−win ≤1.After200epochsofiterationtomaximizethe
size
movement primitives. Movement patterns were identified as
lowerbound,thetimewindowisshiftedonetimestepforward.
not classified below a 55% threshold.
Note,allexperimentswereconductedinsimulationduetothe
1) Analysis of Probabilistic Transition: A robot that is
difficulty of real-time posterior inference computation.
trainedwithA20%B80%CwillfirstgenerateanAmovement,
We investigated how two robots interact in three different
and then transition to B with 20 percent probability and
dyadic conditions (TABLE III). We then analysed whether
to C with 80 percentage probability. We found that smaller
the robots trained with A80%B20%C maintained the learned
w settings are less stable in reproducing the probabilistic
preference between B and C or adapted to their counterparts
structure of the training data. The BC-ratio was either greater
that were trained with A20%B80%C. We also calculated the
or less than 20% for B or greater or less than 80% for
so-called BC-synchronization rate during the interaction. If
C. Networks trained with larger meta-priors become more
at any time step t, one of the robots generated B or C
reliable in regenerating the probabilistic training sequence
and the other robot generated the same movement primitive,
(BC-ratio in Table II). In addition to the capacity of learning
the interaction was considered synchronized. Note that time
the probability distribution of the training data, we found
steps in which movement patterns were identified as not
thatsmallermeta-priorsshownoisierpatterngeneration.Non-
classified by the Echo State Network (cf. subsection III-C)
classifiedmovementswereashighas22%±4withw=0.01
were excluded from the computation.
and decreased to 6%±0.6 with w=3.4.
2) Divergence Analysis: Repeatability in generating se- TABLE III shows the summary of the analysis for all
quences in prior generation was examined by conducting a three experiments. To better understand effects of loose
divergence analysis. Sequences are considered diverged when and tight regulation of FEP complexity, exemplar plots of
a comparison per time step of Xpr exceeds a threshold3. Out robot movement patterns, as well as corresponding net-
of 20 regeneration sequences, we randomly select one as a work dynamics, are shown (cf. Fig. 4 and Fig. 5). We
reference and calculate the average divergence step of the provide supplementary movies of the experiments show-
other sequences to this the reference. Out of 400 time steps ing humanoid robot interaction and network dynamics here:
of prior generation, sequences diverged from the reference https://doi.org/10.6084/m9.figshare.14099537.
aroundtimestep43fornetworkstrainedwithsmallerw.With
1) Experiment1:R1 vs.R2 : InExperiment1,R1
increasing w, repeatability of the trajectories increased. Here 0.005 3.4 0.005
adapts to the probabilistic transition of R2 by increasing
the divergence step was around 139 (cf. divergence step t in 3.4
the probability of performing B from 22% in the stand-
Table II).
alone condition to 70% in the dyad (Table III Experiment
1). Both robots are performing more B than C with a BC-
3As the threshold for the divergence analysis, we use the mean squared
errorofjointangledata[−180,180]ofXpr.Thethresholdissetto55. synchronizationof56±23%whichissignificantlyhigherthan
6
TABLE II: Training performance of representative meta-prior w. The mean ± standard deviation represent three random
seeds and 20 repetitions of prior generation for each w.
w trainingsequenceA20%B80%C BC-ratio divergencestept
A B C notclassified
0.005 34±1 11±3 40±2 15±1 22±6B78±5C 43
0.01 35±2 13±0.2 30±2 22±4 30±5B70±5C 50
1.0 36±1 11±2 40±2 13±0.2 22±4B78±4C 91
2 41±0.7 10±0.5 39±0.7 10±0.3 21±8B79±8C 120
3.4 45±1 11±1 38±2 6±0.5 24±2B76±2C 139
TABLE III: Interaction performance of three experimental probability of 83%. R2 , which in a stand-alone condition
3.4
settings. would maintain its preferenceto B with a probability of 75%,
shows 61% percentage transition to B in the interaction. BC-
Experiment BC-ratio BC-sync
synchronization rate turns out to be low as 31±24%, which
ID robots stand-alone interaction
is almost equal to the chance rate. Examining the network
B C B C
dynamics of the prior and posterior distributions shows that
R1 22±6 78±5 70±11 30±10 the robots executed movements based upon their prior action
1 0.005 56±23
R2 75±2 25±3 73±10 27±10
3.4 intention without adapting their posteriors to observations of
R1 24±2 76±2 17±12 83±18 the other robot’s movement (cf. Fig. 4b and supplementary
2 3.4 31±24
R2 75±2 25±3 61±12 39±12
3.4 movie).
R1 22±6 78±5 52±13 48±9 3) Experiment3:R1 vs.R2 : Whentworobotswith
3 R 0 2 .005 44±11 56±11 20±7 80±8 42±20 0.005 0.005
0.005 tight regulation of complexity interact, both try to adapt their
own action to the one demonstrated by the other. Indeed,
the chance rate of 32%4.
Fig. 4c shows that the prior and posterior do not comply,
Fig. 5 shows an example of how prediction of the future
but deviate. Whether trained with the probabilistic transition
and posterior inference of the past proceed as time passes
of A20%B80%C or A80%B20%C, both robots significantly
from time step 199, 229, to 259 for both robots. We observe
reduce the tendency to perform their own intended behavior
that the intended future behavior (the prior generation) of
CorB,respectively.ThisisevidencedbychangesoftheBC-
R1 is not consistent with the actually performed actions
0.005 ratiofromstand-alonecomparedtothedyadicsetting(TABLE
after posterior inference. On the other hand, in the case of
IIIExperiment3).BC-synchronizationrateis42±20%which
R2 , the performed action complies with its prediction. This
3.4 is higher than the chance rate but not significantly. The inter-
behavior can be explained by looking at exemplar priors µlp
i action becomes noisier, compared to results of Experiments 1
andposteriorsµlq forlayerlandneuronibetweentworobots.
i and 2 (cf. Fig. 4c and supplementary movie), which indicate
In layer 1, selected posterior network dynamics µ1q and µ1q
1 2 that tight regulation makes robots more sensitive to temporal
are deviating from prior dynamics µ1p and µ1p for robot
1 2 fluctuations in observations of their counterparts.
R1 .WhereasthedynamicsofR2 aremostlyoverlapping
0.005 3.4
(cf. Fig. 4a and supplementary movie). More specifically,
IV. DISCUSSION
the average KL Divergence ez of R1 is larger for all
0.005
layers ((ez,1,ez,2,ez,3) = (109.1,1.4,0.06)) than for R2 Thecurrentstudyexaminedhowsocialinteractioninrobotic
3.4
((ez,1,ez,2,ez,3) = (0.4,0.0003,0.00001)). This means that agentsdynamicallychangesdependingonhowthecomplexity
R2 tends to behave as intended because the posterior is inthefreeenergyisregulated.Forthispurpose,weconducted
3.4
attracted by the prior. On the other hand, R1 tends to simulation experiments on dyadic imitative interactions using
0.005
adapt to R2 since the posterior is rather attracted by the humanoid robots equipped with PV-RNN architectures. PV-
3.4
RNN is a hierarchically organized variational RNN model
observation than by the weaker prior belief.
Note that µ3q and µ3p in layer 3 change only slowly with that employs a framework of predictive coding and active
1 1
inference based on the free energy principle. In a prepara-
time. This indicates that these latent variables represent how
tory analysis we showed that PV-RNNs trained with looser
movement primitives transit from deterministic states to non-
regulation of complexity develop stronger action intentions
deterministic states using their slower timescale properties
characterized by τ3. by self-organizing more deterministic dynamics with strong
2) Experiment 2: R1 vs. R2 : When two robots with initial sensitivity. Networks trained with tighter regulation
3.4 3.4
develop weaker intentions by self-organizing more stochastic
loosecomplexityregulationinteract,bothrobotsmaintaintheir
dynamics.
learnedpreferencesintermsofprobabilityingeneratingeither
B or C. R1 , which learns a 76% transition to C in a stand- Our experiments revealed different types of interactions
3.4
betweenrobots.Intheexperimentwherearobothavinglooser
alone situation, shows its preference to C in the dyad with
regulation interacts with a robot with tighter regulation, the
4We assume that B and C are independent probabilistic events. Then we formertendstoleadtheinteractionbyexertingactionintention
canconsidertheprobabilitiesforarobotRtoperformeitheraBmovementas with stronger belief, while the latter tends to follow the other.
PR(B)oraCmovementasPR(C).TheactualBC-synchronizationchance
The following robot adapts its posterior to its observations
level can then be calculated as: P1(B)×P2(B)+P1(C)×P2(C) =
0.8×0.2+0.8×0.2=0.16+0.16=0.32. of the leading robot. In this setting, the synchronization of
7
!10
rp
4.3=wX
μ1,p
1
rp
500.0=wX
layer
1
layer
3
μ1,q μ3,p μ3,q μ1,q μ1,p
1 1 1 2 2
(a) Experiment 1: R1 vs R2
0.005 3.4
• rs 2 and 5
• rs 1 and 1
!10
rp
rp
4.3=wX
4.3=wX
(b) Experiment 2: R1 vs R2
3.4 3.4
• rs 5 and 5
!11
rp
rp
500.0=wX
500.0=wX
rp
rp
500.0=wX
500.0=wX
FIGURE: dynamic interaction (future prediction)
!12
old
(c) Experim • en r t s 3 : 0 R a1nd 0 vs R2 0.005 0.005
Fig. 4: Movement trajectories and network dynamics of
dyadic robot interacticoonnfsoirdeErxepde rfoimr eannti1 (a), Experiment
2 (b) and Experiment 3 (c). Time steps t = [100,300] of
movements and selected neurons in layer 1 and 3 are shown.
rp
rp
X
X
500.0=w
4.3=w
rp
rp
X
X
500.0=w
4.3=w
old
Fig. 5: Posterior inference and prior generation in Exper-
iment 1. Interaction of R1 (upper) and R2 (lower) in
0.005 3.4
terms of Xpr. The first, the second, and the third row show
Xpr aftertheposteriorinferenceintheinferencewindowwith
size win =70, as well as its future prior generation with
size
current time steps of 199, 229, and 259, respectively.
movement B and C (BC-synchronization rate) between the
two robots was significantly higher than the chance rate.
When two robots with looser regulation, i.e. intentions with
stronger belief, interact, each robot tends to generate its
own intended movements. Finally, in case both robots have
tighter regulation, a fluctuating dyadic interaction develops
where each robot attempts to adapt to the counterpart with
an intention with weaker belief. In the last two cases, the
BC-synchronization rate was not significantly higher than the
chance rate. It can be summarized that the dyadic imitative
interaction, including situations where the other’s movements
areunpredictable,tendstobesynchronizedsuccessfullywhen
a dedicated leader and follower are determined; a leader de-
velops action intentions with strong belief whereas a follower
develops action intentions with weak belief.
Thereadersmayaskwhytighterorlooserregulationofthe
complexity term results in development of weaker or stronger
belief of action intention for each robot. Let us consider a
situation in which the PV-RNN learns to predict probabilistic
sequences X¯ with meta-prior w set either with a large
1:T
value (loose regulation) or a smaller one (tight regulation).
Thelearningprocessinferstheposteriormeanµq andstandard
t
deviationσq ateachtimestept.Inordertominimizetheerror
t
e in the accuracy term, µq is fitted with an arbitrary value,
t
whereσq willbeminimized,inbothcases.Notably,whenthe t
data X¯ is observed as random, the corresponding posterior t µq also becomes random.
t
Let us consider the two cases when the meta-prior w is
either set large or small. In case w is set large, the KL
8
Divergence between the posterior and the prior is strongly [9] E. Oztop, M. Kawato, and M. Arbib, “Mirror neurons and imitation:
minimized. Thus, µp and σp of the prior latent state become Acomputationallyguidedreview,”Neuralnetworks,vol.19,no.3,pp.
close to µq and σq t of the p t osterior. By this, σp in the prior 254–271,2006.
t t t [10] T.Inamura,Y.Nakamura,H.Ezaki,andI.Toshima,“Imitationandprim-
is forced to take a minimal value close to 0; therefore, the itivesymbolacquisitionofhumanoidsbytheintegratedmimesisloop,”
prior generation becomes deterministic. Since µp should inProceedingsof2001IEEEInternationalConferenceonRoboticsand
be reconstructed as close to the sequence µq inf 1 e :T rred with Automation,vol.4,2001,pp.4208–4213.
1:T [11] A. Billard and M. Mataric, “Learning human arm movements by imi-
randomness, the prior generative model is forced to develop tation:Evaluationofabiologically-inspiredconnectionistarchitecture,”
strongly nonlinear deterministic dynamics with the initial RoboticsandAutonomousSystems,vol.941,pp.1–16,2001.
[12] E. Oztop, T. Chaminade, G. Cheng, and M. Kawato, “Imitation boot-
sensitivitythroughlearning.Ontheotherhand,ifwissetwith
strapping:experimentsonarobotichand,”in5thIEEE-RASInt.Conf.
a small value, the KL Divergence is only weakly minimized. onHumanoidRobots,2005.,2005,pp.189–195.
In this case, prior µp and σp can diverge from the posterior [13] M.ItoandJ.Tani,“On-lineimitativeinteractionwithahumanoidrobot
t t using a dynamic neural network model of a mirror system,” Adaptive
ones; therefore, the learning becomes ”relaxed”. As a result,
Behavior,vol.12,no.2,pp.93–115,2004.
the prior generative model develops stochastic dynamics with [14] J. Hwang, J. Kim, A. Ahmadi, M. Choi, and J. Tani, “Dealing with
only weak non-linearity, wherein µp takes an average of µq large-scale spatio-temporal patterns in imitative interaction between a
over all occurrences and σp takes t their distribution at each t robot and a human by using the predictive coding framework,” IEEE
t TransactionsonSystems,Man,andCybernetics:Systems,vol.50,no.5,
time step. Consequently, with larger w, the generative model pp.1918–1931,2020.
developsactionintentionwithstrongerbelief(i.e.smallerσp) [15] A. Clark, Surfing uncertainty: Prediction, action, and the embodied
mind. OxfordUniversityPress,2015.
whereas in the case of tighter regulation using a smaller w,
[16] A.AhmadiandJ.Tani,“Anovelpredictive-coding-inspiredvariational
the generative model develops action intention with weaker rnn model for online prediction and recognition,” Neural computation,
belief (i.e. larger σp). vol.31,no.11,pp.2025–2074,2019.
[17] S. Murata, Y. Yamashita, H. Arie, T. Ogata, S. Sugano, and J. Tani,
The current experiments consider a fixed meta-prior setting
“Learningtoperceivetheworldasprobabilisticordeterministicviain-
only. Since the meta-prior is the essential network parameter teractionwithothers:Aneuro-roboticsexperiment,”IEEETransactions
to guide the strength of action intention in the proposed onNeuralNetworksandLearningSystems,vol.28,no.4,pp.830–848,
2017.
framework, future studies should target meta-learning of the
[18] P.LanillosandG.Cheng,“Adaptiverobotbodylearningandestimation
meta-priorindevelopmentalprocessesorthroughautonomous throughpredictivecoding,”CoRR,vol.abs/1805.03104,2018.
adaption within dyadic contexts. This could provide further [19] C. Lang, G. Schillaci, and V. Hafner, “A deep convolutional neural
network model for sense of agency and object permanence in robots,”
understandingofmorecomplexsocialinteractionphenomena,
2018 Joint IEEE 8th International Conference on Development and
including turn-taking in the context of adaptive regulation of LearningandEpigeneticRobotics(ICDL-EpiRob),pp.257–262,2018.
the complexity term in free energy. [20] A.PhilippsenandY.Nagai,“Deficitsinpredictionabilitytriggerasym-
metriesinbehaviorandinternalrepresentation,”FrontiersinPsychiatry,
vol.11,p.1253,2020.
ACKNOWLEDGMENT [21] Y. Yamashita and J. Tani, “Emergence of functional hierarchy in a
multipletimescaleneuralnetworkmodel:ahumanoidrobotexperiment,”
We thank all members of the Cognitive Neurorobotics PLoScomputationalbiology,vol.4,no.11,2008.
[22] H. F. Chame and J. Tani, “Cognitive and motor compliance in inten-
Research Unit. Special thanks goes to Fabien Benuerau and
tionalhuman-robotinteraction,”arXivpreprintarXiv:1911.01753,2019,
Jeffrey Queisser, for fruitful discussions about developing acceptedforpublicationinIEEEICRA2020.
the computational model. The authors also acknowledge the [23] W. Ohata and J. Tani, “Investigation of the sense of agency in social
cognition, based on frameworks of predictive coding and active infer-
support of the Scientific Computation and Data Analysis
ence:Asimulationstudyonmultimodalimitativeinteraction,”Frontiers
section of OIST to carry out the research presented here. inNeurorobotics,vol.14,p.61,2020.
[24] L.Pio-Lopez,A.Nizard,K.Friston,andG.Pezzulo,“Activeinference
androbotcontrol:acasestudy,”JournaloftheRoyalSocietyInterface,
REFERENCES vol.16,2016.
[25] G. Schillaci, A. Ciria, and B. Lara, “Tracking emotions: Intrinsic
[1] K.Friston,“Atheoryofcorticalresponses,”Philosophicaltransactions motivation grounded on multi-level prediction error dynamics,” 10th
of the Royal Society B: Biological sciences, vol. 360, no. 1456, pp. JointIEEEICDL-EPIROB,pp.1–8,2020.
815–836,2005. [26] J.Chung,K.Kastner,L.Dinh,K.Goel,A.C.Courville,andY.Bengio,
[2] K.Friston,J.Mattout,andJ.Kilner,“Actionunderstandingandactive “Arecurrentlatentvariablemodelforsequentialdata,”inAdvancesin
inference,”Biologicalcybernetics,vol.104,pp.137–160,2011. neuralinformationprocessingsystems,2015,pp.2980–2988.
[3] Y. Kuniyoshi, M. Inaba, and H. Inoue, “Learning by watching: ex- [27] D.P.KingmaandM.Welling,“Auto-encodingvariationalbayes,”2014.
tracting reusable task knowledge from visual observation of human [28] D.E.Rumelhart,G.E.Hinton,andR.J.Williams,“Learninginternal
performance,”IEEETransactionsonRoboticsandAutomation,vol.10, representations by error propagation,” California Univ San Diego La
no.6,pp.799–822,1994. JollaInstforCognitiveScience,Tech.Rep.,1985.
[4] G.HayesandY.Demiris,“Arobotcontrollerusinglearningbyimita- [29] F. M. Bianchi, S. Scardapane, S. Løkse, and R. Jenssen, “Reservoir
tion,”Citeseer,vol.676,1995. computingapproachesforrepresentationandclassificationofmultivari-
[5] K. Dautenhahn, “Getting to know each other - artificial social in- ate time series,” IEEE transactions on neural networks and learning
telligence for autonomous robots.” Robotics and Autonomous System, systems,2020.
vol.16,no.2–4,pp.333–356,1995.
[6] P. Gaussier, S. Moga, M. Quoy, and J. P. Banquet, “From perception-
actionloopstoimitationprocesses:Abottom-upapproachoflearningby
imitation,”AppliedArtificialIntelligence,vol.12,no.7-8,pp.701–727,
1998.
[7] G. Di Pellegrino, L. Fadiga, L. Fogassi, V. Gallese, and G. Rizzolatti,
“Understandingmotorevents:aneurophysiologicalstudy,”Experimental
brainresearch,vol.91,no.1,pp.176–180,1992.
[8] M.Arbib,“Themirrorsystem,imitation,andtheevolutionoflanguage.”
Imitationinanimalsandartefacts,pp.229–280,2002.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Leading or Following? Dyadic Robot Imitative Interaction Using the Active Inference Framework"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
