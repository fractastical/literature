=== IMPORTANT: ISOLATE THIS PAPER ===
You are revising a summary for ONLY the paper below. Do NOT reference or use content from any other papers.
Paper Title: Active inference on discrete state-spaces: a synthesis
Citation Key: costa2020active
REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Issues to fix:
1. CRITICAL: The current summary has severe repetition issues. You MUST eliminate all repeated sentences, phrases, and paragraphs. Each idea should be expressed only once. If you find yourself repeating content, remove the duplicates entirely. Focus on variety and uniqueness in your wording.
2. Severe repetition detected: Same sentence appears 19 times (severe repetition)

Current draft (first 2000 chars):
Active inference on discrete state-spaces: a synthesisThe authors state: “Active inference is a framework for understanding how the brain generates perceptions and actions by integrating sensory information with prior beliefs about the world.”The authors state: “Active inference provides a computational account of how the brain constructs its representations of the world.”The authors state: “The key idea is that the brain does not simply passively receive sensory information, but actively constructs its own representations of the world.”The authors state: “The core of active inference is the idea that the brain uses a generative model to produce its perceptions and actions.”The authors state: “The free energy principle provides a formal framework for understanding how the brain minimizes its uncertainty about the world.”The authors state: “The free energy principle is a measure of the discrepancy between the brain’s predictions and its sensory observations.”The authors state: “The free energy principle provides a formal framework for understanding how the brain generates perceptions and actions.”The authors state: “The free energy principle is a framework for understanding how the brain generates perceptions and actions by integrating sensory information with prior beliefs about the world.”The authors state: “The key idea is that the brain does not simply passively receive sensory information, but actively constructs its own representations of the world.”The authors state: “The core of active inference is the idea that the brain uses a generative model to produce its perceptions and actions.”The authors state: “The free energy principle provides a formal framework for understanding how the brain generates perceptions and actions.”The authors state: “The free energy principle is a framework for understanding how the brain generates perceptions and actions by integrating sensory information with prior beliefs about the world.”The authors state: “The key idea is that t...

Key terms: decision, synthesis, discrete, process, apreprint, state, spaces, theory

=== FULL PAPER TEXT ===
ACTIVE INFERENCE ON DISCRETE STATE-SPACES – A
SYNTHESIS
APREPRINT
LancelotDaCosta1,2,∗, ThomasParr2, NoorSajid2, SebastijanVeselic2, VictoritaNeacsu2, KarlFriston2
1DepartmentofMathematics,ImperialCollegeLondon
2WellcomeCentreforHumanNeuroimaging,UniversityCollegeLondon
March31,2020
ABSTRACT
Activeinferenceisanormativeprincipleunderwritingperception,action,planning,decision-making
andlearninginbiologicalorartificialagents. Fromitsinception, itsassociatedprocesstheoryhas
growntoincorporatecomplexgenerativemodels, enablingsimulationofawiderangeofcomplex
behaviours. Due to successive developments in active inference, it is often difficult to see how its
underlyingprinciplerelatestoprocesstheoriesandpracticalimplementation. Inthispaper,wetry
to bridge this gap by providing a complete mathematical synthesis of active inference on discrete
state-space models. This technical summary provides an overview of the theory, derives neuronal
dynamicsfromfirstprinciplesandrelatesthisdynamicstobiologicalprocesses. Furthermore,this
paperprovidesafundamentalbuildingblockneededtounderstandactiveinferenceformixedgener-
ativemodels;allowingcontinuoussensationstoinformdiscreterepresentations. Thispapermaybe
usedasfollows: toguideresearchtowardsoutstandingchallenges,apracticalguideonhowtoim-
plementactiveinferencetosimulateexperimentalbehaviour,orapointertowardsvariousin-silico
neurophysiologicalresponsesthatmaybeusedtomakeempiricalpredictions.
Keywords: active inference, free energy principle, process theory, variational Bayesian inference, Markov decision
process,explained.
Contents
1 Introduction 2
2 Activeinference 4
3 Discretestate-spacegenerativemodels 5
4 VariationalBayesianinference 7
4.1 Freeenergyandmodelevidence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
4.2 Onthefamilyofapproximateposteriors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
4.3 Computingthevariationalfreeenergy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
5 Perception 12
∗Authorcorrespondence:l.da-costa@imperial.ac.uk
0202
raM
82
]CN.oib-q[
2v30270.1002:viXra
5.1 Plausibilityofneuronaldynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
6 Planning,decision-makingandactionselection 13
6.1 Planninganddecision-making . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
6.2 Actionselection,policy-independentstate-estimation . . . . . . . . . . . . . . . . . . . . . . . . . . 14
6.3 Biologicalplausibility. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
6.4 Pruningofpolicytrees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
6.5 Discussionoftheaction-perceptioncycle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
7 Propertiesoftheexpectedfreeenergy 15
8 Learning 16
9 Structurelearning 19
9.1 Bayesianmodelreduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
9.2 Bayesianmodelexpansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
10 Discussion 22
11 Conclusion 23
A Morecomplexgenerativemodels 23
A.1 LearningBandD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
A.2 Complexifyingtheprioroverpolicies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
A.3 Multiplestateandoutcomemodalities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
A.4 Deeptemporalmodels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
B Expectedfreeenergy 25
C Computingexpectedfreeenergy 26
C.1 Ambiguity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
C.2 Risk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
C.3 Novelty . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
1 Introduction
Active inference is a normative principle underlying perception, action, planning, decision-making and learning in
biological or artificial agents. It postulates that these processes may all be seen as optimising two complementary
objective functions; namely, a variational free energy, which measures the fit between an internal model and (past)
sensory observations, and an expected free energy, which scores possible (future) courses of action in relation to
prior preferences. Active inference has been employed to simulate a wide range of complex behaviours, including
planningandnavigation[1],reading[2],curiosityandabstractrulelearning[3],saccadiceyemovements[4],visual
foraging[5,6],visualneglect[7],hallucinations[8],nicheconstruction[9,10],socialconformity[11],impulsivity[12],
imagerecognition[13],andthemountaincarproblem[14–16]. Thekeyideathatunderwritesthesesimulationsisthat
creaturesuseaninternalforward(generative)modeltopredicttheirsensoryinput,whichtheyusetoinferthecauses
ofthesedata.
2
Early formulations of active inference employed generative models expressed in continuous space and time (for an
introductionsee[17],forareviewsee[18]),withbehaviourmodelledasacontinuouslyevolvingrandomdynamical
system. However,weknowthatsomeprocessesinthebrainconformbettertodiscrete,hierarchical,representations,
compared to continuous representations (e.g., visual working memory [19,20], state estimation via place cells [21,
22], language, etc). Reflecting this, many of the paradigms studied in neuroscience are naturally framed as discrete
state-space problems. Decision-making tasks are a prime candidate for this, as they often entail a series of discrete
alternativesthatanagentneedstochooseamong(e.g.,multi-armbandittasks[23–25],multi-stepdecisiontasks[26]).
Thisexplainswhy–inactiveinference–agentbehaviourisoftenmodelledusingadiscretestate-spaceformulation:
the particular applications of which are summarised in Table 1. More recently, mixed generative models [27] –
combining discrete and continuous states – have been used to model behaviour involving discrete and continuous
representations(e.g.,decision-makingandmovement[28],speechproductionandrecognition[29],pharmacologically
inducedchangesineye-movementcontrol[30]orreading;involvingcontinuousvisualsamplinginforminginferences
aboutdiscretesemantics[27]).
Table1: Applicationsofactiveinference(discretestate-space).
Application Description References
Decision-makingunder Initialformulationofactiveinferenceonpartiallyobservable [31]
uncertainty Markovdecisionprocesses.
Optimalcontrol ApplicationofKLorrisksensitivecontrolinanengineering [14,16]
benchmark–themountaincarproblem.
Evidenceaccumulation Illustratingtheroleofevidenceaccumulationin [32,33]
decision-makingthroughanurnstask.
Psychopathology Simulationofaddictivechoicebehaviour. [34]
Dopamine Theprecisionofbeliefsaboutpoliciesprovidesaplausible [35,36]
descriptionofdopaminergicdischarges.
Functionalmagnetic Empiricalpredictionandvalidationofdopaminergic [37]
resonanceimaging discharges.
Maximalutilitytheory Evidenceinfavourofsurpriseminimizationasopposedto [38]
utilitymaximisationinhumandecision-making.
Socialcognition Examiningtheeffectofpriorpreferencesoninterpersonal [39]
inference.
Exploration-exploitation Castingbehaviourasexpectedfreeenergyminimising [40]
dilemma accountsforepistemicandpragmaticchoices.
Habitlearningandaction Formulatinglearningasaninferentialprocessandaction [41,42]
selection selectionasBayesianmodelaveraging.
Sceneconstructionand Mean-fieldapproximationformulti-factorialhiddenstates, [5,43]
anatomyoftime enablinghighdimensionalrepresentationsofthe
environment.
Electrophysiologicalresponses Synthesisingvariousin-siliconeurophysiologicalresponses [44]
viaagradientdescentonfreeenergy. E.g.,place-cellactivity,
mismatchnegativity,phase-precession,thetasequences,
theta-gammacouplinganddopaminergicdischarges.
Structurelearning,curiosity Simulationofartificialcuriosityandabstractrulelearning. [3]
andinsight StructurelearningviaBayesianmodelreduction.
Hierarchicaltemporal Generalisationtohierarchicalgenerativemodelswithdeep [2,45]
representations temporalstructureandsimulationofreading.
Computational Simulationofvisualneglect,hallucinations,andprefrontal [7,46–49]
neuropsychology syndromesunderalternativepathologicalpriors.
3
Neuromodulation Useofprecisionparameterstomanipulateexplorationduring [6,30,50,51]
saccadicsearches;associatinguncertaintywithcholinergic
andnoradrenergicsystems.
Decisionstomovements Mixedgenerativemodelscombiningdiscreteandcontinuous [27,28]
statestoimplementdecisionsthroughmovement.
Planning,navigationandniche Agentinducedchangesinenvironment(generativeprocess); [1,9,10]
construction decompositionofgoalsintosubgoals.
Atarigames Activeinferencecomparesfavourablytoreinforcement [52]
learninginthegameofDoom.
Machinelearning Scalingactiveinferencetomorecomplexmachinelearning [53]
problems.
Duetothepaceofrecenttheoreticaladvancesinactiveinference,itisoftendifficulttoretainacomprehensiveoverview
of its process theory and practical implementation. In this paper, we hope to provide a comprehensive (mathemati-
cal) synthesis of active inference on discrete state-space models. This technical summary provides an overview of
thetheory,derivestheassociated(neuronal)dynamicsfromfirstprinciplesandrelatesthesetoknownbiologicalpro-
cesses.Furthermore,thispaperand[18]providethebuildingblocksnecessarytounderstandactiveinferenceonmixed
generativemodels. Thispapercanbereadasapracticalguideonhowtoimplementactiveinferenceforsimulating
experimentalbehaviour,orapointertowardsvariousin-siliconeuro-andelectro-physiologicalresponsesthatcanbe
testedempirically.
This paper is structured as follows. Section 2 is a high-level overview of active inference. The following sections
elucidatetheformulationbyderivingtheentireprocesstheoryfromfirstprinciples;incorporatingperception,planning
anddecision-making. Thisformalisestheaction-perceptioncycle:1)anagentispresentedwithastimulus,2)itinfers
itslatentcauses,3)plansintothefutureand4)realisesitspreferredcourseofaction;andrepeat. Thisenactivecycle
allowsustoexplorethedynamicsofsynapticplasticity,whichmediatelearningofthecontingenciesoftheworldat
slowertimescales. Weconcludeinsection9withanoverviewofstructurelearninginactiveinference.
2 Activeinference
To survive in a changing environment, biological (and artificial) agents must maintain their sensations within a cer-
tainhospitablerange(i.e.,maintaininghomeostasisthroughallostasis). Inbrief,activeinferenceproposesthatagents
achieve this by optimising two complementary objective functions, a variational free energy and an expected free
energy. Inshort,theformermeasuresthefitbetweenaninternal(generative)modelofitssensationsandsensoryob-
servations,whilethelatterscoreseachpossiblecourseofactionintermsofitsabilitytoreachtherangeof“preferred”
statesofbeing.
Our first premise is that agents represent the world through an internal model. Through minimisation of variational
free energy, this model becomes a good model of the environment. In other words, this probabilistic model and the
probabilistic beliefs2 that it encodes are continuously updated to mirror the environment and its dynamics. Such a
world model is considered to be generative; in that it is able to generate predictions about sensations (e.g., during
planningordreaming),givenbeliefsaboutfuturestatesofbeing. Ifanagentsensesaheatsource(e.g.,anotheragent)
viasometemperaturereceptors,thesensationofwarmthrepresentsanobservedoutcomeandthetemperatureofthe
heatsourceahiddenstate;minimisationofvariationalfreeenergythenensuresthatbeliefsabouthiddenstatesclosely
match the true temperature. Formally, the generative model is a joint probability distribution over possible hidden
statesandsensoryconsequences–thatspecifieshowtheformercausethelatter–andminimisationofvariationalfree
energy enables to "invert" the model; i.e., determine the most likely hidden states given sensations. The variational
freeenergyisthenegativeevidencelowerboundthatisoptimisedinvariationalBayesinmachinelearning[54,55].
Technically–byminimisingvariationalfreeenergy–agentsperformapproximateBayesianinference[56,57],which
enables them to infer the causes of their sensations (e.g., perception). This is the point of contact between active
inferenceandtheBayesianbrain[58–60]. Crucially,agentsmayincorporateanoptimismbias[61,62]intheirmodel;
therebyscoringcertain“preferred”sensationsasmorelikely.Thislendsahigherplausibilitytothosecoursesofaction
2BybeliefswemeanBayesianbeliefs,i.e.,probabilitydistributionsoveravariableofinterest(e.g.,currentposition). Beliefs
arethereforeusedinthesenseofBayesianbeliefupdatingorbeliefpropagation–asopposedtopropositionalorfolkpsychology
beliefs.
4
thatrealisethesesensations. Inotherwords,apreferenceissimplysomethinganagent(believesit)islikelytowork
towards.
Tomaintainhomeostasis,andensuresurvival,agentsmustminimisesurprise3. Sincethegenerativemodelscorespre-
ferredoutcomesasmorelikely,minimisingsurprisecorrespondstomaximisingmodelevidence4).Inactiveinference,
thisisassuredbytheaforementionedprocesses;indeed,thevariationalfreeenergyturnsouttobeanupperboundon
surprise and minimising expected free energy ensures preferred outcomes are realised, thereby avoiding surprise on
average.
Active inference can thus be framed as the minimisation of surprise [63–66] by perception and action. In discrete
state models – of the sort discussed here – this means agents select from different possible courses of action (i.e.,
policies)inordertorealisetheirpreferencesandthusminimisethesurprisethattheyexpecttoencounterinthefuture.
This enables a Bayesian formulation of the perception-action cycle [67]: agents perceive the world by minimising
variationalfreeenergy,ensuringtheirmodelisconsistentwithpastobservations,andactbyminimisingexpectedfree
energy,tomakefuturesensationsconsistentwiththeirmodel. Thisaccountofbehaviourcanbeconciselyframedas
self-evidencing[68].
Incontrasttoothernormativemodelsofbehaviour, activeinferenceisa‘firstprinciple’account, whichisgrounded
instatisticalphysics[69,70]. Activeinferencedescribesthedynamicsofsystemsthatpersist(i.e., donotdissipate)
duringsometimescaleofinterest,andthatcanbestatisticallysegregatedfromtheirenvironment–conditionswhich
are satisfied by biological systems. Mathematically, the first condition means that the system is at non-equilibrium
steady-state(NESS).Thisimpliestheexistenceofasteady-stateprobabilitydensitytowhichthesystemself-organises
andreturnstoafterperturbation(i.e.,theagent’spreferences). Thestatisticalsegregationconditionisthepresenceof
aMarkovblanket(c.f.,Figure1)[71,72]: asetofvariablesthroughwhichstatesinternalandexternaltothesystem
interact (e.g., the skin is a Markov blanket for the human body). Under these assumptions it can be shown that the
statesinternaltothesystemparameteriseBayesianbeliefsaboutexternalstatesandcanbecastaprocessofvariational
freeenergyminimisation.Thiscoincideswithexistingapproachestoapproximateinference[54,73–75].Furthermore,
itcanbeshownthatthemostlikelycoursesofactiontakenbythosesystemsarethosewhichminimiseexpectedfree
energy–aquantitythatsubsumesmanyexistingconstructsinscienceandengineering(seesection7).
Bysubscribingtotheaboveassumptions,itispossibletodescribethebehaviourofviablelivingsystemsasperforming
active inference – the remaining challenge is to determine the computational and physiological processes that they
implement to do so. This paper aims to summarise a possible answers to this question, by reviewing the technical
detailsofaprocesstheoryforactiveinferenceondiscretestate-spacegenerativemodels,firstpresentedin[44]. Note
thatitisimportanttodistinguishbetweenactiveinferenceasaprinciple(presentedabove)fromactiveinferenceasa
process theory. The former is a consequence of fundamental assumptions about living systems, while the latter is a
hypothesisconcerningthecomputationalandbiologicalprocessesinthebrainthatmightimplementactiveinference.
Theensuingprocesstheoriestheorycanthenbeusedtopredictplausibleneuronaldynamicsandelectrophysiological
responsesthatareelicitedexperimentally.
3 Discretestate-spacegenerativemodels
Thegenerativemodel[54]expresseshowtheagentrepresentstheworld. Thisisajointprobabilitydistributionover
sensory data and the hidden (or latent) causes of these data. The sorts of discrete state-space generative models
usedinactiveinferencearespecificallysuitedtorepresentdiscretetimeseriesanddecision-makingtasks. Thesecan
be expressed as variants of partially observable Markov decision processes (POMDPs; [76]): from simple Markov
decisionprocesses[77–79]togeneralisationsintheformofdeepprobabilistic(hierarchical)models[2,80,81]. For
clarity,theprocesstheoryisderivedforthesimplestmodelthatfacilitatesunderstandingofsubsequentgeneralisations;
namely,aPOMDPwheretheagentholdsbeliefsabouttheprobabilityoftheinitialstate(specifiedasD),thetransition
probabilities from one state to the next (defined as matrix B) and the probability of states given outcomes (i.e., the
likelihoodmatrixA);seeFigure2.
3In information theory, the surprise (a.k.a., surprisal) associated with an outcome under a generative model is given by
−logp(o). This specifies the extent to which an observation is unusual and surprises the agent – but this does not mean that
theagentconsciouslyexperiencessurprise.Ininformationtheorythiskindofsurpriseisknownasself-information.
4InBayesianstatistics,themodelevidence(oftenreferredtoasmarginallikelihood)associatedwithagenerativemodelisp(o)
–theprobabilityofobservedoutcomesaccordingtothemodel(sometimesthisiswrittenasp(o|m),explicitlyconditioningupon
amodel).Themodelevidencescoresthegoodnessofthemodelasanexplanationofdatathataresampled,byrewardingaccuracy
andpenalisingcomplexity,whichavoidsoverfitting.
5
Table2: Glossaryoftermsandnotation.
Notation Meaning Type
S Setofallpossible(hidden)states. Finitesetofcardinalitym>0.
s (Hidden)stateattimeτ. Incomputations,ifs RandomvariableoverS.
τ τ
evaluatestotheithpossiblestate,theninterpretitas
theithunitvectorinRm.
s Sequenceofhiddenstatess ,...,s . RandomvariablesoverSt.
1:t 1 t
O Setofallpossibleoutcomes. Finitesetofcardinalityn>0.
o Outcomeattimeτ. Incomputations,ifo evaluates RandomvariableoverO.
τ τ
tothejthpossibleoutcome,theninterpretitasthejth
unitvectorinRn.
o Sequenceofoutcomeso ,...,o RandomvariablesoverOt.
1:t 1 t
T Numberoftimestepsinatrialofobservationepochs Positiveinteger.
underthegenerativemodel.
U Setofallpossibleactions. Finiteset.
Π Setofallallowablepolicies;i.e.,sequencesofactions. FinitesubsetofUT.
π Policy. RandomvariableoverΠ,orelementof
Πdependingoncontext.
Q Approximateposteriordistribution. Probabilitydistributionoverthelatent
variablesofthegenerativemodel.
F,F Variationalfreeenergyandvariationalfreeenergy FunctionalsofQ.
π
conditioneduponapolicy.
G Expectedfreeenergy. FunctiondefinedonΠ.
Cat Categoricaldistribution;probabilitydistributionover Probabilitydistributionoverafiniteset
afinitesetassigningstrictlypositiveprobabilities. ofcardinalitykwithparameterspace
{x∈Rk|x >0, (cid:80) x =1}
i i i
Dir Dirichletdistribution(conjugatepriorofthe Probabilitydistributionover
categoricaldistribution);probabilitydistributionover {x∈Rk|x >0, (cid:80) x =1},itself
i i i
theparameterspaceofthecategoricaldistribution, parameterisedbyanelementof(R )k.
>0
parameterisedbyavectorofpositivereals.
X ,X ithcolumnand(k,i)thelementofmatrixX. Matrixindexingconvention.
•i ki
·,⊗,(cid:12),(cid:12) Respectivelyinnerproduct,Kroneckerproduct, Operationonvectorsandmatrices.
element-wiseproductandelement-wisepower.
Followingexistingactiveinferenceliterature,we
adopttheconventionX·Y :=XTY formatrices.
A Likelihoodmatrix. Theprobabilityofthe Randomvariableoverthesubsetof
state-outcomepairo ,s isgivenbyo ·As . M (R)withcolumnsin
τ τ τ τ n×m
{x∈Rk|x >0, (cid:80) x =1}.
i i i
B Matrixoftransitionprobabilitiesfromonestatetothe MatrixinM (R)withcolumnsin
m×m
nextstategivenactionπ τ−1 . Theprobabilityof {x∈Rk|x i >0, (cid:80) i x i =1}.
possiblestates ,givens andactionπ is
τ τ−1 τ−1
s ·B s .
τ πτ−1 τ−1
a,a Parametersofpriorandapproximateposteriorbeliefs MatricesinM (R ).
n×m >0
aboutA.
6
a ,a Matricesofthesamesizeasa,a,withhomogeneous MatricesinM (R ).
0 0 n×m >0
columns;anyofitsithcolumnelementsaredenoted
bya ,a anddefinedby
i0 i0
a =
(cid:80)n
a ,a =
(cid:80)n
a .
i0 j=1 ji i0 j=1 ji
log,Γ,ψ Naturallogarithm,gammafunctionanddigamma Functions.
function. Byconventionthesefunctionsaretaken
component-wiseonvectorsandmatrices.
E [f(X)] Expectationofrandomvariablef(X)undera Real-valuedoperatoronrandom
P(X)
probabilitydensityP(X),takencomponent-wiseif variables.
f(X)isamatrix. E [f(X)]:= (cid:82) f(X)P(X)dX
P(X)
A A:=E [A]=a(cid:12)a(cid:12)(−1) MatrixinM (R ).
Q(A) 0 n×m >0
logA logA:=E [logA]=ψ(a)−ψ(a ). Notethat MatrixinM (R).
Q(A) 0 n×m
logA(cid:54)=logA!
σ Softmaxfunctionornormalisedexponential. Function
σ(x) k = (cid:80) e
i
x e k xi Rk →{x∈Rk|x i >0, (cid:80) i x i =1}
H[P] ShannonentropyofaprobabilitydistributionP. Functionaloverprobability
Explicitly,H[P]=E [−logP(x)] distributions.
P(x)
As mentioned above, a substantial body of work justifies describing certain neuronal representations with discrete
state-space generative models (e.g., [19,20,87]). Furthermore, it has been long known that – at the level of neu-
ronal populations – computations occur periodically (i.e., in distinct and sometimes nested oscillatory bands). Sim-
ilarly, there is evidence for sequential computation in a number of processes (e.g., attention [88–90], visual percep-
tion [91,92]) and at different levels of the neuronal hierarchy [2,93], in line with ideas from hierarchical predictive
processing[94,95]. Thisaccommodatesthefactthatvisualsaccadicsamplingofobservationsoccursatafrequency
ofapproximately4Hz[28]. Therelativelyslowpresentationofadiscretesequenceofobservationsenablesinferences
tobeperformedinperistimulustimeby(much)fasterneuronaldynamics.
Activeinference, implicitly, accountsforfastandslowneuronaldynamics. Ateachtime-steptheagentobservesan
outcome,fromwhichitinfersthepast,presentandfuture(hidden)statesthroughperception. Thisunderwritesaplan
intothefuture,byevaluating(theexpectedfreeenergyof)possiblepolicies. Theinferred(best)policiesspecifythe
mostlikelyaction,whichisexecuted. Ataslowertimescale,parametersencodingthecontingenciesoftheworld(e.g.,
A), are inferred. This is referred to as learning. Even more slowly, the structure of the generative model is updated
tobetteraccountforavailableobservations–thisiscalledstructurelearning. Thefollowingsectionselucidatethese
aspectsoftheactiveinferenceprocesstheory.
Thispaperwillbelargelyconcernedwithderivingandinterpretingtheinferentialdynamicsthatagentsmightimple-
mentusingthegenerativemodelinFigure2. WeleavethediscussionofmorecomplexmodelstoAppendixA,since
thederivationsareanalogousinthosecases.
4 VariationalBayesianinference
4.1 Freeenergyandmodelevidence
VariationalBayesianinferencerestsuponminimisationofaquantitycalled(variational)freeenergy,whichmeasures
the improbability (i.e., the surprise) of sensory observations, under a generative model. Simultaneously, variational
freeenergyminimisationisastatisticalinferencetechniquethatenablestheapproximationoftheposteriordistribution
inBayesrule. Inmachinelearning,thisisknownasvariationalBayes[54,73–75]. Activeinferenceagentsminimise
variationalfreeenergy, enablingconcomitantmaximisationoftheirmodelevidenceandinferenceofthelatentvari-
ablesoftheirgenerativemodel.Inthefollowing,weconsideraparticulartimepointtobegivent∈{1,...,T},whence
theagenthasobservedasequenceofoutcomeso . Theposterioraboutthelatentcausesofsensorydataisgivenby
1:t
Bayesrule:
7
Figure 1: Markov blankets in active inference. This figure illustrates the Markov blanket assumption of active
inference. A Markov blanket is a set of variables through which states internal and external to the system interact.
Specifically, the system must be such that we can partition it into a Bayesian network of internal states µ, external
states η, sensory states o and active states u, (µ, o and u are often referred together as particular states) with prob-
abilistic(causal)linksinthedirectionsspecifiedbythearrows. Allinteractionsbetweeninternalandexternalstates
are therefore mediated by the blanket states b. The sensory states represent the sensory information that the body
receives from the environment and the active states express how the body influences the environment. This blanket
assumption is quite generic, in that it can be reasonably assumed for a brain as well as elementary organisms. For
example, when considering a bacillus, the sensory states become the cell membrane and the active states comprise
theactinfilamentsofthecytoskeleton. UndertheMarkovblanketassumption–togetherwiththeassumptionthatthe
systempersistsovertime(i.e.,possessesanon-equilibriumsteadystate)–ageneralisedsynchronyappears,suchthat
the dynamics of the internal states can be cast as performing inference over the external states (and vice-versa) via
a minimisation of variational free energy [69,70]. This coincides with existing approaches to inference; i.e., varia-
tionalBayes[54,73–75]. Thiscanbeviewedastheinternalstatesmirroringexternalstates,viasensorystates(e.g.,
perception), and external states mirroring internal states via active states (e.g., a generalised form of self-assembly,
autopoiesis or niche construction). Furthermore, under these assumptions the most likely courses of actions can be
shown to minimise expected free energy. Note that external states beyond the system should not be confused with
thehiddenstatesoftheagent’sgenerativemodel(whichmodelexternalstates). Infact,theinternalstatesareexactly
theparameters(i.e.,sufficientstatistics)encodingbeliefsabouthiddenstatesandotherlatentvariables,whichmodel
external states in a process of variational free energy minimisation. Hidden and external states may or may not be
isomorphic. Inotherwords,anagentusesitsinternalstatestorepresenthiddenstatesthatmayormaynotexistinthe
externalworld.
8
Figure2: Exampleofadiscretestate-spacegenerativemodel. Panel2a,specifiestheformofthegenerativemodel,
which is how the agent represents the world. The generative model is a joint probability distribution over (hidden)
states, outcomes and other variables that cause outcomes. In this representation, states unfold in time causing an
observationateachtime-step. ThelikelihoodmatrixAencodestheprobabilitiesofstate-outcomepairs. Thepolicy
π specifies which action to perform at each time-step. Note that the agent’s preferences may be specified either in
termsofstatesoroutcomes. Itisimportanttodistinguishbetweenstates(resp. outcomes)thatarerandomvariables,
and the possible values that they can take in S (resp. in O), which we refer to as possible states (resp. possible
outcomes). Note that this type of representation comprises a finite number of timesteps, actions, policies, states,
outcomes, possible states and possible outcomes. In Panel 2b, the generative model is displayed as a probabilistic
graphical model [54,72,75,82] expressed in factor graph form [83]. The variables in circles are random variables,
whilesquaresrepresentfactors,whosespecificformaregiveninPanel2a. Thearrowsrepresentcausalrelationships
(i.e., conditional probability distributions). The variables highlighted in grey can be observed by the agent, while
the remaining variables are inferred through approximate Bayesian inference (see Section 4) and called hidden or
latentvariables. Activeinferenceagentsperforminferencebyoptimisingtheparametersofanapproximateposterior
distribution (see Section 4). Panel 2c specifies how this approximate posterior factorises under a particular mean-
fieldapproximation[84], althoughotherfactorisationsmaybeused[85,86]. Aglossaryoftermsusedinthisfigure
isavailableinTable2. ThemathematicalyogaofgenerativemodelsisheavilydependentonMarkovblankets. The
Markovblanketofarandomvariableinaprobabilisticgraphicalmodelarethosevariablesthatshareacommonfactor.
Crucially,avariableconditioneduponitsMarkovblanketisconditionallyindependentofallothervariables. Wewill
usethispropertyextensively(andimplicitly)inthetext.
9
P(o |s ,A,π)P(s ,A,π)
P(s ,A,π|o )= 1:t 1:T 1:T (1)
1:T 1:t P(o )
1:t
Computing the posterior distribution requires computing the model evidence P(o ) =
1:t
(cid:80) (cid:80) (cid:82)
P(o ,s ,A,π) dA, which is intractable for complex generative models embodied by
π∈Π s1:T∈ST 1:t 1:T
biological and artificial systems [93] – a well-known problem in Bayesian statistics. An alternative to computing
theexactposteriordistributionistooptimiseanapproximateposteriordistributionoverlatentcausesQ(s ,A,π),
1:T
byminimisingtheKullback-Leibler(KL)divergence[96](D )–anon-negativemeasureofdiscrepancybetween
KL
probability distributions. We can use the definition of the KL divergence and Bayes rule to arrive at the variational
freeenergyF,whichisafunctionalofapproximateposteriorbeliefs:
0≤D [Q(s ,A,π)||P(s ,A,π|o )]
KL 1:T 1:T 1:t
=E [logQ(s ,A,π)−logP(s ,A,π|o )]
Q(s1:T,A,π) 1:T 1:T 1:t
=E [logQ(s ,A,π)−logP(o ,s ,A,π)+logP(o )]
Q(s1:T,A,π) 1:T 1:t 1:T 1:t
(2)
=E [logQ(s ,A,π)−logP(o ,s ,A,π)]+logP(o )
Q(s1:T,A,π) 1:T 1:t 1:T 1:t
(cid:124) (cid:123)(cid:122) (cid:125)
F[Q(s1:T,A,π)]
⇒−logP(o )≤F[Q(s ,A,π)]
1:t 1:T
From (2), one can see that by varying Q to minimise the variational free energy enables us to approximate the true
posterior,whilesimultaneouslyensuringthatsurpriseremainslow.Thismeansthatvariationalfreeenergyminimising
agents, simultaneously, infer the latent causes of their observations and maximise the evidence for their generative
model. Toaidintuition,thevariationalfreeenergycanberearrangedintocomplexityandaccuracy:
F[Q(s ,A,π)]=D [Q(s ,A,π)||P(s ,A,π)]−E [logP(o |s ,A,π)] (3)
1:T KL 1:T 1:T Q(s1:T,A,π) 1:t 1:T
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Complexity Accuracy
The first term of (3) can be regarded as complexity: a simple explanation for observable data Q, which makes few
assumptionsoverandabovetheprior(i.e.,withKLdivergenceclosetozero),isagoodexplanation. Inotherwords,
a good explanation is an accurate account of some data that requires minimal movement for updating of prior to
posterior beliefs (c.f., Occam’s principle). The second term is accuracy; namely, the probability of the data given
posterior beliefs about model parameters Q. In other words, how well the generative model fits the observed data.
The idea that neural representations weigh complexity against accuracy underwrites the imperative to find the most
accurate explanation for sensory observations that is minimally complex, which has been leveraged by things like
HoraceBarlow’sprincipleofminimumredundancy[97]andsubsequentlysupportedempirically[98–101]. Figure3
illustratesthevariousimplicationsofminimisingfreeenergy.
4.2 Onthefamilyofapproximateposteriors
The goal is now to minimise variational free energy with respect to Q. To obtain a tractable expression for the
variational free energy, we need to assume a certain simplifying factorisation of the approximate posterior. There
are many possible forms [85,118,119] (e.g., mean-field, marginal, Bethe), each of which trades off the quality of
the inferences with the complexity of the computations involved. For the purpose of this paper we use a particular
(structured)mean-fieldapproximation(c.f.,Figure2):
T
(cid:89)
Q(s ,A,π)=Q(A)Q(π) Q(s |π) (4)
1:T τ
τ=1
This choice is driven by didactic purposes and since this factorisation has been used extensively in the active in-
ference literature (e.g., [2,27,44]). However, the most recent software implementation of active inference (i.e.,
spm_MDP_VB_X.m) employs a marginal approximation [85,120], which retains the simplicity and biological inter-
pretationoftheneuronaldynamicsaffordedbythemean-fieldapproximation,whileapproximatingthemoreaccurate
inferencesoftheBetheapproximation. Forthesereasons,themarginalfreeenergycurrentlystandsasthemostbio-
logicallyplausible.
10
Figure3: Markovblanketsandself-evidencing. Thisschematicillustratesthevariousinterpretationsofminimising
variational free energy. Recall that the existence of a Markov blanket implies a certain lack of influences among
internal,blanketandexternalstates. Theseindependencieshaveanimportantconsequence;internalandactivestates
aretheonlystatesthatarenotinfluencedbyexternalstates,whichmeanstheirdynamics(i.e.,perceptionandaction)
are a function of, and only of, particular states (i.e., internal, sensory and active states); here, the variational (free
energy) bound on surprise. This surprise has a number of interesting interpretations. Given it is the negative log
probability of finding a particle or creature in a particular state, minimising surprise corresponds to maximising the
value of a particle’s state. This interpretation is licensed by the fact that the states with a high probability are, by
definition, attracting states. On this view, one can then spin-off an interpretation in terms of reinforcement learning
[77],optimalcontroltheory[102]and,ineconomics,expectedutilitytheory[103]. Indeed,anyschemepredicatedon
theoptimisationofsomeobjectivefunctioncannowbecastintermsofminimisingsurprise–intermsofperception
and action (i.e., the dynamics of internal and active states) – by specifying these optimal values to be the agent’s
preferences. Theminimisationofsurprise(i.e.,self-information)leadstoaseriesofinfluentialaccountsofneuronal
dynamics;includingtheprincipleofmaximummutualinformation[104,105],theprinciplesofminimumredundancy
and maximum efficiency [106] and the free energy principle [66]. Crucially, the average or expected surprise (over
time or particular states of being) corresponds to entropy. This means that action and perception look as if they
are minimising entropy. This leads us to theories of self-organisation, such as synergetics in physics [107–109] or
homeostasis in physiology [110–112]. Finally, the probability of any blanket states given a Markov blanket (m) is,
onastatisticalview,modelevidence[113,114]. Thismeansthatalltheaboveformulationsareinternallyconsistent
with things like the Bayesian brain hypothesis, evidence accumulation and predictive coding; most of which inherit
fromHelmholtz’smotionofunconsciousinference[115],laterunpackedintermsofperceptionashypothesistesting
in20thcenturypsychology[116]andmachinelearning[117].
11
4.3 Computingthevariationalfreeenergy
Thenextsectionsfocusonproducingbiologicallyplausibleneuronaldynamicsthatperformperceptionandlearning
basedonvariationalfreeenergyminimisation. Toenablethis,wefirstcomputevariationalthefreeenergy,usingthe
factorisationsofthegenerativemodelandapproximateposterior(c.f.,Figure2):
F[Q(s ,A,π)]=E [logQ(s ,A,π)−logP(o ,s ,A,π)]
1:T Q(s1:T,A,π) 1:T 1:t 1:T
T
(cid:88)
=E [logQ(A)+logQ(π)+ logQ(s |π)
Q(s1:T,A,π) τ
τ=1
(5)
T t
(cid:88) (cid:88)
−logP(A)−logP(π)−logP(s )− logP(s |s ,π)− logP(o |s ,A)]
1 τ τ−1 τ τ
τ=2 τ=1
=D [Q(A)||P(A)]+D [Q(π)||P(π)]+E [F [Q(s |π)]]
KL KL Q(π) π 1:T
where
T t
(cid:88) (cid:88)
F [Q(s |π)]:= E [logQ(s |π)]− E [logP(o |s ,A)]
π 1:T Q(sτ|π) τ Q(sτ|π)Q(A) τ τ
τ=1 τ=1
(6)
T
(cid:88)
−E [logP(s )]− E [logP(s |s ,π)]
Q(s1|π) 1 Q(sτ|π)Q(sτ−1|π) τ τ−1
τ=2
is the variational free energy conditioned upon a policy. This is the same quantity that we would have obtained by
omittingAandconditioningallprobabilitydistributionsinthenumeratorsof(1)byπ. Inthenextsection,wewillsee
howperceptioncanbeframedintermsofvariationalfreeenergyminimisation.
5 Perception
Inactiveinference,perceptionisequatedwithstateestimation[44](e.g.,inferringthetemperaturefromthesensation
ofwarmth),consistentwiththeideathatperceptionsarehypotheses[116].Toinferthe(past,presentandfuture)states
oftheenvironment,anagentmustminimisethevariationalfreeenergywithrespecttoQ(s |π)foreachpolicyπ.
1:T
Thisprovidestheagent’sinferenceoverhiddenstates,contingentuponpursuingagivenpolicy. Sincetheonlypartof
thefreeenergythatdependsonQ(s |π)isF ,theagentmustsimplyminimiseF . SubstitutingQ(s |π)bytheir
1:T π π τ
sufficientstatistics(i.e.,parameterss ),F becomesafunctionofthoseparameters. Thisenablesustorewrite(6),
πτ π
convenientlyinmatrixform:
T t
(cid:88) (cid:88)
F (s ,...,s )= s ·logs − o ·logAs
π π1 πT πτ πτ τ πτ
τ=1 τ=1
(7)
T
(cid:88)
−s logD− s ·log(B )s
π1 πτ πτ−1 πτ−1
τ=2
Thisenablestocomputethevariationalfreeenergygradients[121]:

o ·logA+s ·log(B )+logD ifτ =1
 τ πτ+1 πτ
∇ F (s ,...,s )=(cid:126)1+logs − o ·logA+s ·log(B )+log(B )s if1<τ ≤t (8)
sπτ π π1 πT πτ τ πτ+1 πτ πτ−1 πτ−1
s ·log(B )+log(B )s ifτ >t
πτ+1 πτ πτ−1 πτ−1
The neuronal dynamics are given by a gradient descent on free energy [44], with state-estimation expressed as a
softmaxfunctionofaccumulated(negative)freeenergygradients. Theconstantterm(cid:126)1isgenerallyomittedsincethe
softmaxfunctionremovesitanyway. Thisenablesustoequatethegradientwithapredictionerror.
v˙(s ,...,s )=−∇ F (s ,...,s )
π1 πT sπτ π π1 πT
(9)
s =σ(v)
πτ
12
The softmax function – a generalisation of the sigmoid to vector inputs – is a natural choice as the variational free
energygradientisalogarithmandthecomponentsofs mustsumtoone.
πτ
5.1 Plausibilityofneuronaldynamics
Thetemporaldynamicsexpressedin(9)unfoldatamuchfastertimescalethanthesamplingofnewobservations(i.e.,
withintimesteps)andcorrespondtofastneuronalprocessinginperistimulustime. Thisisconsistentwithbehaviour-
relevant computations at frequencies that are higher than the rate of visual sampling (e.g., working memory [122],
visualstimulusperceptioninhumans[91]andmacaques[92]).
Furthermore, thesedynamicsareconsistentwithpredictiveprocessing[123,124]–sinceactiveinferenceprescribes
dynamicsthatminimisepredictionerror–althoughtheygeneraliseittoawiderangeofgenerativemodels. Notethat,
while also a variational free energy gradient, this sort of prediction error is not the same as that given by predictive
codingschemes(whichrelyuponadifferentsortofgenerativemodel)[17,18,125].
Justasneuronaldynamicsinvolvetranslationfrompost-synapticpotentialstofiringrates,(9)involvestranslatingfrom
a vector of real numbers (v), to a vector whose elements are bounded between zero and one (s ); via the softmax
πτ
function. Asaresult,itisnaturaltointerpretthecomponentsofvastheaveragemembranepotentialofdistinctneural
populations, ands astheaveragefiringrateofthosepopulations, whichisboundedthankstoneuronalrefractory
πτ
periods. Thisisconsistentwithmean-fieldformulationsofneuralpopulationdynamics,inthattheaveragefiringrate
of a neuronal population follows a sigmoid function of the average membrane potential [126–128]. Using the fact
thatasoftmaxfunctionisageneralisationofthesigmoidtovectorinputs–heretheaveragemembranepotentialsof
coupledneuronalpopulations–itfollowsthattheiraveragefiringfollowsasoftmaxfunctionoftheiraveragepotential.
Inthiscontext, thesoftmaxfunctionmaybeinterpretedasperforminglateralinhibition, whichcanbethoughtofas
leadingtonarrowertuningcurvesofindividualneuronsandtherebysharperinferences[129].Importantly,thistellsus
thatstate-estimationcanbeperformedinparallelbydifferentneuronalpopulations,andasimpleneuronalarchitecture
issufficienttoimplementthesedynamics(seeFigure6in[85]).
Lastly,interpretingthedynamicsinthiswayhasadegreeoffacevalidity,asitenablesustosynthesiseawide-rangeof
biologicallyplausibleelectrophysiologicalresponses;includingrepetitionsuppression,mismatchnegativity,violation
responses,place-cellactivity,phaseprecession,thetasequences,theta-gammacoupling,evidenceaccumulation,race-
to-bounddynamicsandtransferofdopamineresponses[37,44].
The neuronal dynamics for state estimation coincide with variational message passing [130,131]: a widely used
algorithm for approximate Bayesian inference. This is an important result, since it shows that variational message
passing emerges under active inference using a particular mean-field approximation. If one were to use the Bethe
approximation,thecorrespondingdynamicscoincidewithbeliefpropagation[54,83,85,86,118],anotherwidelyused
algorithmforapproximateinference. Thisoffersaformalconnectionbetweenactiveinferenceandmessagepassing
interpretationsofneuronaldynamics[27,132,133]. Inthenextsection, weexamineplanning, decision-makingand
actionselection.
6 Planning,decision-makingandactionselection
Sofar,wehavefocusedonoptimisingbeliefsabouthiddenstatesunderaparticularpolicybyminimisingavariational
freeenergyfunctionalofanapproximateposterioroverhiddenstates,undereachpolicy.
In this section, we explain how planning and decision-making arise as a minimisation of expected free energy – a
function scoring the goodness of each possible future course of action. We briefly motivate how the expected free
energyarisesfromfirst-principles. Thisallowsustoframedecision-makingandaction-selectionintermsofexpected
freeenergyminimisation. Finally,weconcludebydiscussingthecomputationalcostofplanningintothefuture.
6.1 Planninganddecision-making
Attheheartofactiveinference,isadescriptionofagentsthatstrivetoattainatargetdistributionspecifyingtherangeof
preferredstatesofbeing,givenasufficientamountoftime. Toworktowardsreachingthesepreferences,agentsselect
policiesQ(π),suchthattheirpredictedstatesQ(s ,A)atsomefuturetimepointτ > t(usually,thetimehorizonof
τ
a policy T) reach the preferred states P(s ,A), which are specified by the generative model. These considerations
τ
13
allowustoshowinAppendixBthattherequisiteapproximateposterioroverpoliciesQ(π)isasoftmaxfunctionof
thenegativeexpectedfreeenergyG5:
Q(π)=σ(−G(π))
G(π)=D KL [Q(s τ ,A|π)||P(s τ ,A)]−E Q(sτ,A|π)P(oτ|sτ,A) [logP(o τ |s τ ,A)] (10)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Risk Ambiguity
Thismeansthatthemostlikely(i.e.,best)policiesminimiseexpectedfreeenergy. Thisensuresthatfuturecoursesof
actionareexploitative(i.e.,riskminimising)andexplorative(i.e.,ambiguityminimising). Inparticular,theexpected
freeenergyspecifiestheoptimalbalancebetweengoal-seekinganditinerantnovelty-seekingbehaviour, givensome
priorpreferencesorgoals. Notethattheambiguitytermrestsonanexpectationoverfictive(i.e.,predicted)outcomes
under beliefs about future states. This means that optimising beliefs about future states during perception is crucial
toaccuratelypredictfutureoutcomesduringplanning. Insummary, planninganddecision-makingrespectivelycor-
respond to evaluating the expected free energy of different policies, which scores their goodness in relation to prior
preferencesandformingapproximateposteriorbeliefsaboutpolicies.
6.2 Actionselection,policy-independentstate-estimation
Approximate posterior beliefs about policies allows to obtain the most plausible action as the most likely under all
policies–thiscanbeexpressedasaBayesianmodelaverage
(cid:32) (cid:33)
(cid:88)
u =argmax δ Q(π) (11)
t
u∈U
u,πt
π∈Π
where δ is the Kronecker delta. In addition, we obtain a policy independent state-estimation at any time point τ ∈
{1,...,T},asaBayesianmodelaverageofapproximateposteriorbeliefsabouthiddenstatesunderpolicies:
(cid:88)
Q(s )= Q(s |π)Q(π)
τ τ
π∈Π
(12)
(cid:88)
⇐⇒ s = s Q(π)
τ πτ
π∈Π
NotethattheseBayesianmodelaveragesmaybeimplementedbyneuromodulatorymechanisms[42].
6.3 Biologicalplausibility
Winnertake-allarchitecturesofdecision-makingarealreadycommonplaceincomputationalneuroscience(e.g.,mod-
els of selective attention and recognition [134,135], hierarchical models of vision [136]). This is nice, since the
softmax function in (10) can be seen as providing a biologically plausible [126–128], smooth approximation to the
maximumoperation,whichisknownassoftwinnertake-all[137]. Infact,thegenerativemodel,presentedinFigure
2,canbenaturallyextendedsuchthattheapproximateposteriorcontainsan(inverse)temperatureparameterγ multi-
plyingtheexpectedfreeenergyinsidethesoftmaxfunction(seeAppendixA.2). Thistemperatureparameterregulates
howpreciselythesoftmaxapproximatesthemaximumfunction,thusrecoveringwinnertake-allarchitecturesforhigh
parametervalues(technically,thisconvertsBayesianmodelaveragingintoBayesianmodelselection,wherethepol-
icycorrespondstoamodelofwhattheagentisdoing). Thisparameter,regulatingprecisionofpolicyselection,hasa
clearbiologicalinterpretationintermsofconfidenceencodedindopaminergicfiring[35–37,44]. Interestingly,Daw
andcolleagues[23]uncoveredevidenceinfavourofasimilarmodelemployingasoftmaxfunctionandtemperature
parameterinhumandecision-making.
5Amorecompletetreatmentmayincludepriorsoverpolicies–usuallydenotedbyE–andtheevidenceforapolicyaffordedby
observedoutcomes(usuallydenotedbyF).Theseadditionaltermssupplementtheexpectedfreeenergy,leadingtoanapproximate
posterioroftheformσ(−logE−F−G)[2].
14
6.4 Pruningofpolicytrees
Fromacomputationalperspective,planning(i.e.,computingtheexpectedfreeenergy)foreachpossiblepolicycanbe
cost-prohibitive, due do the combinatorial explosion in the number of sequences of actions when looking deep into
thefuture. Therehasbeenworkinunderstandinghowthebrainfinessesthisproblem[138],whichsuggestsasimple
answer: duringmentalplanning, humansstopevaluatingapolicyassoonastheyencounteralargeloss(i.e., ahigh
valueoftheexpectedfreeenergythatrendersthepolicyhighlyimplausible). Inactiveinferencethiscorrespondsto
usinganOccamwindow; thatis, westopevaluatingtheexpectedfreeenergyofapolicyifitbecomesmuchhigher
thanthebest(smallestexpectedfreeenergy)policy–andsetitsapproximateposteriorprobabilitytoanarbitrarilylow
valueaccordingly. Thisbiologicallyplausiblepruningstrategydrasticallyreducesthenumberofpoliciesonehasto
evaluateexhaustively.
Althougheffectiveandbiologicallyplausible,theOccamwindowforpruningpolicytreescannotdealwithlargepolicy
spacesthatensuewithdeeppolicytreesandlongtemporalhorizons.Thismeansthatpruningcanonlypartiallyexplain
how biological organisms perform deep policy searches. Further research is needed to characterise the processes in
which biological agents reduce large policy spaces to tractable subspaces. One explanation – for the remarkable
capacityofbiologicalagentstoevaluatedeeppolicytrees–restsondeep(hierarchical)generativemodels,inwhich
policiesoperateateachlevel. Thesedeepmodelsenablelong-termpolicies,modellingslowtransitionsamonghidden
statesathigherlevelsinthehierarchy,tocontextualisefasterstatetransitionsatsubordinatelevels(seeAppendixA).
Theresulting(semiMarkovian)processcanthenbespecifiedintermsofahierarchyoflimitedhorizonpoliciesthat
arenestedovertemporalscales;c.f.,motorchunking[139–141].
6.5 Discussionoftheaction-perceptioncycle
Minimisingvariationalandexpectedfreeenergyarecomplementaryandmutuallybeneficialprocesses. Minimisation
ofvariationalfreeenergyensuresthatthegenerativemodelisagoodpredictorofitsenvironment;thisallowstheagent
toaccuratelyplanintothefuturebyevaluatingexpectedfreeenergy,whichinturnenablesittorealiseitspreferences.
Inotherwords,minimisationofvariationalfreeenergyisavehicleforeffectiveplanningandreachingpreferencesvia
theexpectedfreeenergy;inturn,reachingpreferencesminimisestheexpectedsurpriseoffuturestatesofbeing.
In conclusion, we have seen how agents plan into the future and make decisions about the best possible course of
action. Thisconcludesourdiscussionoftheaction-perceptioncycle. Inthenextsection, weexamineexpectedfree
energyingreaterdetail. Then,wewillseehowactiveagentscanlearnthecontingenciesoftheenvironmentandthe
structureoftheirgenerativemodelatslowertimescales.
7 Propertiesoftheexpectedfreeenergy
The expected free energy is a fundamental construct of interest. In this section, we unpack its main features and
highlightitsimportanceinrelationtomanyexistingtheoriesinneurosciencesandengineering.
Theexpectedfreeenergyofapolicycanbeunpackedinanumberofways. Perhapsthemostintuitiveisintermsof
riskandambiguity:
G(π)=D [Q(s ,A|π)||P(s ,A)]+E [H[P(o |s ,A)]] (13)
KL τ τ Q(sτ,A|π) τ τ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Risk Ambiguity
Thismeansthatpolicyselectionminimisesriskandambiguity. Risk,inthissetting,issimplythedifferencebetween
predictedandpriorbeliefsaboutfinalstates. Inotherwords,policieswillbedeemedmorelikelyiftheybringabout
statesthatconformtopriorpreferences. Intheoptimalcontrolliterature,thispartofexpectedfreeenergyunderwrites
KL control [142,143]. In economics, it leads to risk sensitive policies [144]. Ambiguity reflects the uncertainty
aboutfutureoutcomes,givenhiddenstates. Minimisingambiguitythereforecorrespondstochoosingfuturestatesthat
generateunambiguousandinformativeoutcomes(e.g.,switchingonalightinthedark).
Wecanexpresstheexpectedfreeenergyofapolicyasaboundoninformationgainandexpectedlog(model)evidence
(a.k.a.,Bayesianrisk):
15
G(π)=E [D [Q(s ,A|o ,π)||P(s ,A|o )]]− E [logP(o )]
Q KL τ τ τ τ Q τ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Expectedevidencebound Expectedlogevidence
−E [D [Q(s ,A|o ,π)||Q(s ,A|π)]]
Q KL τ τ τ
(cid:124) (cid:123)(cid:122) (cid:125) (14)
Expectedinformationgain
≥− E [logP(o )] −E [D [Q(s ,A|o ,π)||Q(s ,A|π)]]
Q τ Q KL τ τ τ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Expectedlogevidence Expectedinformationgain
Thefirsttermin(14)istheexpectationoflogevidenceunderbeliefsaboutfutureoutcomes,whilethesecondensures
thatthisexpectationismaximallyinformed,whenoutcomesareencountered.Collectively,thesetwotermsunderwrite
the resolution of uncertainty about hidden states (i.e., information gain) and outcomes (i.e., expected surprise) in
relationtopriorbeliefs.
Whentheagent’spreferencesareexpressedintermsofoutcomes(c.f.,Figure2),itisusefultoexpressriskintermsof
outcomes,asopposedtohiddenstates.Thisismostusefulwhenthegenerativemodelisnotknownorduringstructure
learning, when the state-space evolves over time. In these cases, the risk over hidden states can be replaced risk
overoutcomesbyassumingtheKLdivergencebetweenthepredictedandtrueposterior(underexpectedoutcomes)is
small:
D [Q(s ,A|π)||P(s ,A)]=D [Q(o |π)||P(o )]+E [D [Q(s ,A|o ,π)||P(s ,A|o )]]
KL τ τ KL τ τ Q(oτ|π) KL τ τ τ τ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Risk(states) Risk(outcomes) ≈0
(15)
≈D [Q(o |π)||P(o )]
KL τ τ
(cid:124) (cid:123)(cid:122) (cid:125)
Risk(outcomes)
Thisdivergenceconstitutesanexpectedevidenceboundthatalsoappearsifweexpressexpectedfreeenergyinterms
ofintrinsicandextrinsicvalue:
G(π)=−E [logP(o )]+E [D [Q(s ,A|o ,π)||P(s ,A|o )]]
Q(oτ|π) τ Q(oτ|π) KL τ τ τ τ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Extrinsicvalue Expectedevidencebound
(16)
−E [D [Q(s |o ,π)||Q(s |π)]]−E [D [Q(A|o ,s ,π)||Q(A)]]
Q(oτ|π) KL τ τ τ Q(oτ,sτ|π) KL τ τ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Intrinsicvalue(states)orsalience Intrinsicvalue(parameters)ornovelty
Extrinsic value is just the expected value of log evidence, which can be associated with reward and utility in be-
havioural psychology and economics, respectively [145–147]. In this setting, extrinsic value is the negative of
Bayesian risk [148], when reward is log evidence. The intrinsic value of a policy is its epistemic value or affor-
dance[40]. Thisisjusttheexpectedinformationgainaffordedbyaparticularpolicy,whichcanbeabouthiddenstates
(i.e.,salience)ormodelparameters(i.e.,novelty). Itisthistermthatunderwritesartificialcuriosity[149].
Intrinsicvalueisalsoknownasintrinsicmotivationinneurorobotics[145,150,151],thevalueofinformationineco-
nomics [152], salience in the visual neurosciences and (rather confusingly) Bayesian surprise in the visual search
literature [153–155]. In terms of information theory, intrinsic value is mathematically equivalent to the expected
mutualinformationbetweenhiddenstatesinthefutureandtheirconsequences–consistentwiththeprinciplesofmin-
imumredundancyormaximumefficiency[105,106,156]. Finally,fromastatisticalperspective,maximisingintrinsic
value (i.e., salience and novelty) corresponds to optimal Bayesian design [157] and machine learning derivatives,
suchasactivelearning[158]. Onthisview,activelearningisdrivenbynovelty;namely,theinformationgainafforded
modelparameters,givenfuturestatesandtheiroutcomes.Heuristically,thiscuriosityresolvesuncertaintyabout“what
wouldhappenifIdidthat”[147].Figure4illustratesthecompassofexpectedfreeenergy,intermsofitsspecialcases;
rangingfromoptimalBayesiandesignthroughtoBayesiandecisiontheory.
8 Learning
Inactiveinference,learningconcernsthedynamicsofsynapticplasticity,whicharethoughttoencodebeliefsaboutthe
contingenciesoftheenvironment[44](e.g.,beliefsaboutB,insomesettings,arethoughttobeencodedinrecurrent
16
Figure4:Expectedfreeenergy.Thisfigureillustratesthevariouswaysinwhichminimisingexpectedfreeenergycan
beunpacked(omittingmodelparametersforclarity). Theupperpanelcastsactionandperceptionastheminimisation
ofvariationalandexpectedfreeenergy, respectively. Crucially, activeinferenceintroducesbeliefsoverpoliciesthat
enableaformaldescriptionofplanningasinference[1,159,160]. Inbrief,posteriorbeliefsabouthiddenstatesofthe
world,underplausiblepolicies,areoptimisedbyminimisingavariational(freeenergy)boundonlogevidence. These
beliefsarethenusedtoevaluatetheexpectedfreeenergyofallowablepolicies,fromwhichactionscanbeselected[44].
Crucially,expectedfreeenergysubsumesseveralspecialcasesthatpredominateinthepsychological,machinelearning
andeconomicsliterature. Thesespecialcasesaredisclosedwhenoneremovesparticularsourcesofuncertaintyfrom
theimplicitoptimisationproblem. Forexample,ifweignorepriorpreferences,thentheexpectedfreeenergyreduces
to information gain [113,157] or intrinsic motivation [145,150,151]. This is mathematically the same as expected
Bayesian surprise and mutual information that underwrite salience in visual search [153,155] and the organisation
of our visual apparatus [104–106,156]. If we now remove risk but reinstate prior preferences, one can effectively
treathiddenandobserved(sensory)statesasisomorphic. Thisleadstorisksensitivepoliciesineconomics[144,161]
or KL control in engineering [143]. Here, minimising risk corresponds to aligning predicted outcomes to preferred
outcomes. If we then remove ambiguity and relative risk of action (i.e., intrinsic value), we are left with extrinsic
value or expected utility in economics [162] that underwrites reinforcement learning and behavioural psychology
[77]. Bayesian formulations of maximising expected utility under uncertainty is also known as Bayesian decision
theory[148]. Finally, ifwejustconsideracompletelyunambiguousworldwithuninformativepriors, expectedfree
energy reduces to the negative entropy of posterior beliefs about the causes of data; in accord with the maximum
entropyprinciple[163]. Theexpressionsforvariationalandexpectedfreeenergycorrespondtothosedescribedinthe
maintext(omittingmodelparametersforclarity). Theyarearrangedtoillustratetherelationshipbetweencomplexity
andaccuracy,whichbecomeriskandambiguity,whenconsideringtheconsequencesofaction. Thismeansthatrisk-
sensitivepolicyselectionminimisesexpectedcomplexityorcomputationalcost. Thecoloureddotsabovethetermsin
theequationscorrespondtothetermsthatconstitutethespecialcasesinthelowerpanels.
17
excitatoryconnectionsintheprefrontalcortex[47]). Thefactthatbeliefsaboutmatrices(e.g.,A,B)maybeencoded
in synaptic weights conforms to connectionist models of brain function, as it offers a convenient way to compute
probabilities, in the sense that the synaptic weights could be interpreted as performing matrix multiplication as in
artificialneuralnetworks,topredict;e.g.,outcomesfrombeliefsaboutstates,usingthelikelihoodmatrixA.
These synaptic dynamics (e.g., long-term potentiation and depression) evolve at a slower timescale than action and
perception, which is consistent with the fact that such inferences need evidence accumulation over multiple state-
outcomepairs. Forsimplicity, wewillassumetheonlyvariablethatislearnedisA, butwhatfollowsgeneralisesto
morecomplexgenerativemodels(c.f.,AppendixA.1. LearningAmeansthatapproximateposteriorbeliefsaboutA
follow a gradient descent on variational free energy. Seeing the variational free energy (5) as a function of a (the
sufficientstatisticofQ(A))wecanwrite:
t
(cid:88)
F(a)=D [Q(A)||P(A)]− E [o ·log(A)s ]+···
KL Q(π)Q(sτ|π)Q(A) τ τ
τ=1
(17)
t
(cid:88)
=D [Q(A)||P(A)]− o ·logAs +···
KL τ τ
τ=1
Here, we ignore the terms in (5) that do not depend on Q(A), as these will vanish when we take the gradient. The
KL-divergencebetweenDirichletdistributionsis[164,165]:
m
(cid:88)
D [Q(A)||P(A)]= D [Q(A )||P(A )]
KL KL ·i ·i
i=1
m (cid:32) n n (cid:33)
(cid:88) (cid:88) (cid:88)
= logΓ(a )− logΓ(a )−logΓ(a )+ logΓ(a )+(a −a )·(logA)
0i ki 0i ki •i •i •i
i=1 k=1 k=1
m (cid:32) n n (cid:33)
(cid:88) (cid:88) (cid:88)
= logΓ(a )− logΓ(a )−logΓ(a )+ logΓ(a ) +(a−a)·logA
0i ki 0i ki
i=1 k=1 k=1
(18)
Incorporating(18)in(17),wecantakethegradientofthevariationalfreeenergywithrespecttologA:
t
(cid:88)
∇ F(a)=a−a− o ⊗s (19)
logA τ τ
τ=1
where⊗istheKronecker(i.e., outer)product. Thismeansthatthedynamicsofsynapticplasticityfollowadescent
on(19):
ρ˙(a)=−∇ F(a)
logA
(cid:88) t (20)
=−a+a+ o ⊗s
τ τ
τ=1
In computational terms, these are the dynamics for evidence accumulation of Dirichlet parameters at time t. Since
synapticplasticitydynamicsoccuratamuchslowerpacethanperceptualinference,itiscomputationallymuchcheaper
–innumericalsimulations–todoaone-stepbeliefupdateattheendofeachtrialofobservationepochs. Explicitly,
settingthefreeenergygradienttozeroattheendofthetrialgivesthefollowingupdateforDirichletparameters:
T
(cid:88)
a=a+ o ⊗s (21)
τ τ
τ=1
After which, the prior beliefs P(A) are updated to the approximate posterior beliefs Q(A) for the subsequent trial.
Notethatinparticular,theupdatecountsthenumberoftimesaspecificmappingbetweenstatesandobservationshas
beenobserved. Interestingly,thisisformallyidenticaltoassociativeorHebbianplasticity.
18
As one can see, the learning rule concerning accumulation of Dirichlet parameters (c.f., (21)) means that the agent
becomes increasingly confident about its likelihood matrix by receiving new observations (since the matrix which
isaddedontoaateachtimestepisalwayspositive). Thisisfineaslongasthestructureoftheenvironmentremains
relativelyconstant.Inthenextsection,wewillseehowBayesianmodelreductioncanrevertthisprocess,toenablethe
agenttoadaptquicklytoachangingenvironment.Table3summarisesthebeliefupdatingentailedbyactiveinference,
andFigure5indicateswhereparticularcomputationsmightbeimplementedinthebrain.
Table3: Summaryofbeliefupdating.
Process Computation Equations
Perception s =σ(v),v˙ =−∇ F (8)
πτ sπτ π
Planning G(π) (43),(44)
Decision-making Q(π)=σ(−G(π)) (10)
(cid:0)(cid:80) (cid:1)
Actionselection u =argmax δ Q(π) (11)
t u∈U π∈Π u,πt
(cid:80)
Policy-independent s = s Q(π) (12)
τ π∈Π πτ
state-estimation
Learning(endoftrial) a=a+
(cid:80)T
o ⊗s (21)
τ=1 τ τ
9 Structurelearning
In the previous sections, we have addressed how an agent performs inference over different variables at different
timescalesinabiologicallyplausiblefashion,whichweequatedtoperception,planninganddecision-making. Inthis
section,weconsidertheproblemoflearningtheformorstructureofthegenerativemodel.
Theideahereisthatagentsareequipped(e.g.,born)withaninnategenerativemodelthatentailsfundamentalprefer-
ences(e.g.,essentialtosurvival),whicharenotupdated. Forinstance,humansarebornwithpriorpreferencesabout
their body temperature around 37◦C and O , CO , glucose etc concentrations within a certain range. Mathemati-
2 2
cally, this means that the parameters of these innate prior distributions – encoding the agent’s expectations as part
ofitsgenerativemodel–havehyperpriorsthatareinfinitelyprecise(e.g.,aDiracdeltadistribution)andthuscannot
be updated in anexperience dependent fashion. The agent’s generativemodel then naturally evolves by minimising
variational free energy to become a good model of the agent’s environment but is still constrained by the survival
preferenceshardcodedwithinit. Thisprocessoflearningthegenerativemodel(i.e.,thevariablesandtheirfunctional
dependencies)iscalledstructurelearning.
Structurelearninginactiveinferenceisanactiveareaofresearch.Activeinferenceproposesthattheagent’sgenerative
model evolves over time to maximise the evidence for its observations. However, a complete set of mechanisms
that biological agents use to do so has not yet been laid out. Nevertheless, we use this section to summarise two
complementary approaches; namely, Bayesian model reduction and Bayesian model expansion [3,172–174] – that
enabletosimplifyandcomplexifythemodel,respectively.
9.1 Bayesianmodelreduction
Toexplainthecausesoftheirsensations,agentsmustcomparedifferenthypothesesabouthowtheirsensorydataare
generated – and retain the hypothesis or model that is the most valid in relation to their observations (i.e., has the
greatestmodelevidence). InBayesianstatistics,theseprocessesarecalledBayesianmodelcomparisonandBayesian
model selection – these correspond to scoring the evidence for various generative models in relation to available
data and selecting the one with the highest evidence [175,176]. Bayesian model reduction (BMR) is a particular
instance of structure learning, which formalises post-hoc hypothesis testing to simplify the generative model. This
precludes redundant explanations of sensory data – and ensures the model generalises to new data. Technically, it
involvesestimatingtheevidenceforsimpler(reduced)priorsoverthelatentcausesandselectingthemodelwiththe
highest evidence. This process of simplifying the generative model – by removing certain states or parameters –
hasaclearbiologicalinterpretationintermsofsynapticdecayandswitchingoffcertainsynapticconnections,which
19
Figure5: Possiblefunctionalanatomy. Thisfiguresummarisesapossible(coarse-grained)functionalanatomythat
could implement belief updating in active inference. The arrows correspond to message passing between different
neuronalpopulations. Here,avisualobservationissampledbytheretina,aggregatedinfirst-ordersensorythalamic
nuclei and processed in the occipital (visual) cortex. The green arrows correspond to message passing of sensory
information. This signal is then propagated (via the ventral visual pathway) to inferior and medial temporal lobe
structures such as the hippocampus; this allows the agent to go from observed outcomes to beliefs about their most
likelycausesinstate-estimation(perception),whichisperformedlocally. Thevariationalfreeenergyiscomputedin
thestriatum. Theorangearrowsencodemessagepassingofbeliefs. PreferencesC areattributedtothedorsolateral
prefrontalcortex–whichisthoughttoencoderepresentationsoverprolongedtemporalscales[45]–consistentwith
thefactthatthesearelikelytobeencodedwithinhighercorticalareas[3]. Theexpectedfreeenergyiscomputedin
themedialprefrontalcortex[44]duringplanning,whichleadstoinferencesaboutmostplausiblepolicies(decision-
making) in the basal ganglia, consistent with the fact that the basal ganglia is thought to underwrite planning and
decision-making[166–171]. Themessageconcerningpolicyselectionissenttothemotorcortexviathalamocortical
loops. Themostplausibleaction,whichisselectedinthemotorcortexispassedonthroughthespinalcordtotrigger
a limb movement. Simultaneously, policy independent state-estimation is performed in the ventrolateral prefrontal
cortex,whichleadstosynapticplasticitydynamicsintheprefrontalcortex,wherethesynapticweightsencodebeliefs
aboutA.
20
is reminiscent of the synaptic mechanisms of sleep (e.g., REM sleep [177,178]), reflection and associated machine
learningalgorithms(e.g.,wake-sleep[179]).
Tokeepthingsconcise,letνrepresentahiddenvariableinthegenerativemodelthatisoptimisedduringlearning(e.g.
A),ando = o asequenceofobservations. ThecurrentmodelhasapriorP(ν)andwewouldliketotestwhether
1:t
a reduced prior (i.e., less complex) P˜(ν) can provide a more parsimonious explanation for the observed outcomes.
UsingBayesrule,wehavethefollowingidentities:
P(ν)P(o|ν)=P(ν|o)P(o) (22)
P˜(ν)P(o|ν)=P˜(ν|o)P˜(o) (23)
WhereP(o)= (cid:82) P(o|ν)P(ν)dν andP˜(o)= (cid:82) P(o|ν)P˜(ν). Dividing(22)by(23)yields
P(ν) P(ν|o)P(o)
= (24)
P˜(ν) P˜(ν|o)P˜(o)
Wecanthenuse(24)inordertoobtainthefollowingrelations:
(cid:34) (cid:35)
(cid:90) P(o)(cid:90) P˜(ν)P(ν|o) P(o) P˜(ν)
1= P˜(ν|o)dν = dν = E (25)
P˜(o) P(ν) P˜(o) P(ν|o) P(ν)
(cid:34) (cid:35)
P˜(ν)
⇒logP˜(o)−logP(o)=logE (26)
P(ν|o) P(ν)
Wecanapproximatetheposteriortermintheexpectationof(26)withthecorrespondingapproximateposteriorQ(ν),
whichsimplifiesthecomputation. Thisallowsustocomparetheevidenceofthetwomodels(reducedandfull)and
selectthebest. Ifthereducedmodelhasmoreevidence,itimpliesthecurrentmodelistoocomplex–andredundant
parameterscanberemovedbyadoptingthenewpriors.
Inconclusion,BMRallowsforcomputationallyefficientandbiologicallyplausiblehypothesistesting,tofindsimpler
explanations for the data at hand. It has been used to emulate sleep and reflection in abstract rule learning [3], by
simplifying the prior over A at the end of each trial – this has the additional benefit of preventing the agent from
becomingoverconfident.
9.2 Bayesianmodelexpansion
BayesianmodelexpansioniscomplementarytoBayesianmodelreduction. Itentailsadoptingamorecomplexgener-
ativemodel(byadding,e.g.,morestates);if,andonlyifthegaininaccuracyin(3)issufficientenoughtooutweighthe
increaseincomplexity. Thismodelexpansionallowsforgeneralisationandconceptlearninginactiveinference[173].
Notethatadditionalstatesneednotalwaysleadtoamorecomplexmodel.Itisinprinciplepossibletoexpandamodel
insuchawaythatcomplexitydecreases,asmanystateestimatesmightbeabletoremainclosetotheirpriorsinplace
ofasmallnumberofestimatesmovingalot. This‘sharedwork’bymanyparameterscouldleadtoasimplermodel.
Fromacomputationalperspective,conceptacquisitioncanbeseenasatypeofstructurelearning[180,181]–thatcan
beemulatedthroughBayesianmodelcomparison. Recentworkonconceptlearninginactiveinference[173],shows
thatagenerativemodelequippedwithextra(latent)hiddenstatescanengagethese‘unused’hiddenstates, whenan
agentispresentedwithnovelstimuliduringthelearningprocess.Initiallythecorrespondinglikelihoodmappings(i.e.,
thecorrespondingcolumnsofA)areuninformative,buttheseareupdatedwhentheagentencountersnewobservations
thatcannotbeaccountedbyitscurrentknowledge(e.g.,observingacatwhenithasonlybeenexposedtobirds). This
happens naturally, during the learning process, in an unsupervised way through free energy minimization. To allow
foreffectivegeneralization,thisapproachcanbecombinedwithBMR;inwhichanynewconceptcanbeaggregated
withsimilarconcepts,andtheassociatedlikelihoodmappingscanberesetforfurtherconceptacquisition,infavourof
asimplermodelwithhighermodelevidence. Thisapproachcanbefurtherextendedbyupdatingthenumberofextra
hiddenstatesthroughaprocessofBayesianmodelcomparison.
21
10 Discussion
Dueto thevarious recenttheoretical advancesin activeinference, itiseasy tolose sightof itsunderlying principle,
processtheoryandpracticalimplementation. Wehavetriedtoaddressthisbyrehearsing–inaclearandconciseway
– the assumptions underlying active inference as a principle, the technical details of the process theory for discrete
state-spacegenerativemodelsandthebiologicalinterpretationoftheaccompanyingneuronaldynamics. Itisuseful
toclarifytheseresults;asafirststeptoguidetowardsoutstandingtheoreticalresearchchallenges,apracticalguideto
implementactiveinferencetosimulateexperimentalbehaviourandapointertowardsvariouspredictionsthatmaybe
testedempirically.
Activeinferenceoffersadegreeofplausibilityasaprocesstheoryofbrainfunction. Fromatheoreticalperspective
itsrequisiteneuronaldynamicscorrespondtoknownempiricalphenomenaandextendearliertheorieslikepredictive
coding[64,123,124]. Furthermore,theprocesstheoryisconsistentwiththeunderlyingfreeenergyprinciple,which
biologicalsystemsarethoughttoabideby–namely,theavoidanceofsurprisingstates:thiscanbearticulatedformally
basedonfundamentalassumptionsaboutbiologicalsystems[69,70]. Lastly,theprocesstheoryhasadegreeofface
validityasitspredictedelectrophysiologicalresponsescloselyresembleempiricalmeasurements.
However, for a full endorsement of the process theory presented in this paper, rigorous empirical validation of the
syntheticelectrophysiologicalresponsesisneeded.Topursuethis,onewouldhavetospecifythegenerativemodelthat
abiologicalagentemploysforaparticulartask. ThiscanbedonethroughBayesianmodelcomparisonofalternative
generative models with respect to empirical (choice) behaviour being measured (e.g., [182]). Once the appropriate
generativemodelisformulated,evidenceforaplausiblebutdistinctimplementationsofactiveinferencewouldneed
to be compared, which come from various possible approximations to the free energy [85,86,118], each of which
yieldsdifferentbeliefupdatesandsimulatedelectrophysiologicalresponses. Notethatthemarginalapproximationto
the free energy currently stands as the most biologically plausible [85]. From this, the explanatory power of active
inferencecanbeassessedinrelationtoempiricalmeasurementsandcontrastedwithotherexistingtheories.
Thismeansthatthekeychallengeforactiveinference–andarguablydataanalysisingeneral–isfindingthegenerative
model that best explains observable data (i.e., evidence maximising). A solution to this problem would enable to
find the generative model – entailed by an agent – by observing its behaviour. In turn, this would enable one to
simulate its belief updating and behaviour accurately in-silico. It should be noted that these generative models can
bespecifiedmanuallyforthepurposesofreproducingsimplebehaviour(e.g.,agentsperformingsimpletasksneeded
for empirical validation discussed above). However, a generic solution to this problem is necessary to account for
complexdatasets;inparticular,complexbehaviouraldatafromagentsinarealenvironment. Moreover,abiologically
plausible solution to this problem could correspond to a complete structure learning roadmap; accounting for how
biological agents evolve their generative model to account for new observations. Evolution has solved this problem
by selecting phenotypes with a good model of their sensory data, therefore, understanding the processes that have
selectedgenerativemodelsthatarefitforpurposeforourenvironmentmightleadtoimportantadvancesinstructure
learninganddataanalysis.
Discovering new generative models corresponding to complex behavioural data, will demand to extend the current
process theory to these models, in order to provide testable predictions and reproduce the observed behaviour in-
silico. Examplesofgenerativemodelsthatdonotfallwithinthecurrentdiscretestate-space, continuousstate-space
[8,18,31,183–186]ormixed[27,28,30]models–currentlyimplementedinactiveinference–includeMarkovdecision
trees[75,187]andBoltzmannmachines[78,188,189].
Onechallengethatmayarise,whenscalingactiveinferencetocomplexmodelswithmanydegreesoffreedom,willbe
thesizeofthepolicytreesinconsideration. Althougheffectiveandbiologicallyplausible,thecurrentpruningstrategy
isunlikelytoreducethesearchspacesufficientlytoenabletractableinferenceinsuchcases. Asnotedabove,theissue
of scaling active inference may yield to the first principles of the variational free energy formulation. Specifically,
generative models with a high evidence are minimally complex. This suggests that ‘scaling up’, in and of itself, is
not the right strategy for reproducing more sophisticated or deep behaviour. A more principled approach would be
to explore the right kind of factorisations necessary to explain structured behaviour. A key candidate here are deep
temporalordiachronicgenerativemodelsthathaveaseparationoftimescales. Thisformoffactorisation(c.f.,mean
fieldapproximation)replacesdeepdecisiontreeswithshallowdecisiontreesthatarehierarchicallycomposed.
Tosummarise,wearguethatsomeimportantchallengesfortheoreticalneuroscienceincludefindingprocesstheories
ofbrainfunctionthatcomplywithactiveinferenceasaprinciple[69,70];namely,theavoidanceofsurprisingevents.
Theoutstandingchallengeisthentoexploreandfinegrainsuchprocesstheories,viaBayesianmodelcomparison(e.g.,
usingdynamiccausalmodelling[59,190])inrelationtoexperimentaldata.Fromastructurelearninganddataanalysis
perspective,themainchallengeisfindingthegenerativemodelwiththegreatestevidenceinrelationtoavailabledata.
Thismaybeachievedbyunderstandingtheprocessesevolutionhasselectedforcreatureswithagoodmodeloftheir
22
environment. Finally,toscaleactiveinferencetobehaviourwithmanydegreesoffreedom,oneneedstounderstand
howbiologicalagentseffectivelysearchdeeppolicytreeswhenplanningintothefuture,whenmanypossiblepolicies
maybeentertainedatseparabletimescales.
11 Conclusion
In conclusion, this paper aimed to summarise: the assumptions underlying active inference, the technical details
underwriting its process theory, and how the associated neuronal dynamics relate to known biological processes.
These processes underwrite action, perception, planning, decision-making, learning and structure learning; which
we have illustrated under discrete state-space generative models. We have discussed some important outstanding
challenges:fromabroadperspective,thechallengefortheoreticalneuroscienceistodevelopincreasinglyfine-grained
mechanisticmodelsofbrainfunctionthatcomplywiththecoretenetsofactiveinference[69,70]. Inregardstothe
processtheory,keychallengesrelatetoexperimentalvalidation,understandinghowbiologicalorganismsevolvetheir
generativemodeltoaccountfornewsensoryobservationsandhowtheyeffectivelysearchlargepolicyspaceswhen
planningintothefuture.
Softwareavailability
The belief updating scheme described in this article is generic and can be implemented using standard rou-
tines (e.g., spm_MDP_VB_X.m). These routines are available as Matlab code in the SPM academic software:
http://www.fil.ion.ucl.ac.uk/spm/. Examples of simulations using discrete state-space generative models
canbefoundviaagraphicaluserinterfacebytypingDEM.
Acknowledgements
LDissupportedbytheFondsNationaldelaRecherche,Luxembourg(Projectcode: 13568875). TPissupportedby
the Rosetrees Trust (Award number: 173346). NS is funded by the Medical Research Council (Ref: 2088828). SV
wasfundedbytheLeverhulmeDoctoralTrainingProgrammefortheEcologicalStudyoftheBrain(DS-2017-026).
KFisfundedbyaWellcomeTrustPrincipalResearchFellowship(Ref: 088130/Z/09/Z).
A Morecomplexgenerativemodels
InthisAppendix, webrieflypresent casesofmorecomplexdiscretestate-spacegenerativemodelsand explainhow
thebeliefupdatingcanbeextendedtothosecases.
A.1 LearningBandD
Inthispaper,wehaveonlyconsideredthecasewhereAislearned,whilebeliefsaboutB(i.e.,transitionprobabilities
fromonestatetothenext)andD(i.e.,beliefsabouttheinitialstate)remainedfixed. Ingeneral,B andDcanalsobe
learntovertime. Thiscallsuponanew(extended)expressionforthegenerativemodelwithpriorsoverBandD:
T T
(cid:89) (cid:89)
P(o ,s ,A,B,D,π)=P(π)P(A)P(B)P(D)P(s |D) P(s |s ,B,π) P(o |s ,A)
1:T 1:T 1 τ τ−1 τ τ
τ=2 τ=1
m (27)
(cid:89) (cid:89)
P(B)= P((B ) ) P((B ) )=Dir((b ) )
u •i u •i u •i
u∈Ui=1
P(D)=Dir(d)
Here,(B ) and(b ) denotetheith columnsofthematrixB encodingthetransitionprobabilitiesfromonestate
u •i u •i u
to the next state and its corresponding Dirichlet parameter b . Furthermore, one needs to define the corresponding
u
approximateposteriorsthatwillbeusedforlearning:
23
m
(cid:89) (cid:89)
Q(B)= Q((B ) ) Q((B ) )=Dir((b ) )
u •i u •i u •i
(28)
u∈Ui=1
Q(D)=Dir(d)
The variational free energy, after having observed o , is computed analogously as in equation (5). The process of
1:t
findingthebeliefdynamicsisthenakintosection8–werehearseitinthefollowing: selectingonlythosetermsinthe
variationalfreeenergy,whichdependonBandDyields:
F[Q(B,D)]=D [Q(B)||P(B)]+D [Q(D)||P(D)]−E [s ·logD]
KL KL Q(π)Q(s1|π)Q(D) 1
t
(cid:88)
− E [s ·logB s ]+···
Q(π)Q(sτ,sτ−1|π)Q(B) τ πτ τ−1
τ=2
t
(cid:88)
=D [Q(B)||P(B)]+D [Q(D)||P(D)]−s ·logD− E [s ·logB s ]+···
KL KL 1 Q(π) πτ πτ πτ−1
τ=2
(29)
UsingtheformoftheKLdivergenceforDirichletdistributions(18)andtakingthegradientsyields
t
(cid:88)(cid:88)
∇ F(b )=b −b − δ Q(π)(s ⊗s ) (30)
logBu u u u u,πt πτ πτ−1
τ=2π∈Π
∇ F(d)=d−d−s (31)
logD 1
where⊗denotestheKroneckerproduct. Finally,itispossibletospecifyneuronalplasticitydynamicsfollowingade-
scenton(30),(31),whichcorrespondtobiologicaldynamics. Alternatively,wehavebeliefupdaterulesimplemented
onceaftereachtrialofobservationepochsinin-silicoagents:
t
(cid:88)(cid:88)
b =b + δ Q(π)(s ⊗s ) (32)
u u u,πτ πτ πτ−1
τ=2π∈Π
d=d+s (33)
1
A.2 Complexifyingtheprioroverpolicies
In this paper, we have considered a simple prior approximate posterior over policies; namely, σ(−G(π)). This can
beextendedtoσ(−γG(π)),whereγ isan(inverse)temperatureparameterthatdenotestheconfidenceinselectinga
particularpolicy. Thisextensionisquitenaturalinthesensethatγ canbeinterpretedasthepostsynapticresponseto
dopaminergicinput[35,36]. Thiscorrespondenceissupportedbyempiricalevidence[37]andenablesonetosimulate
biologicallyplausibledopaminergicdischarges(c.f.,AppendixE[44]). Anatomically,thisparametermaybeencoded
within the substantia nigra, in nigrostriatal dopamine projection neurons [37], which maps well with our proposed
functional anatomy (c.f., Figure 5), since the substantia nigra is connected with the striatum. We refer the reader
to[44]foradiscussionoftheassociatedbeliefupdatingscheme.
A.3 Multiplestateandoutcomemodalities
Ingeneral, onedoesnotonlyneedonehiddenstateandoutcomefactortorepresenttheenvironment, butmany. In-
tuitively, this happens in the human brain as we integrate sensory stimuli from our five (or more) distinct senses.
Mathematically,wecanexpressthisviadifferentstreamsofhiddenstates(usuallyreferredtoashiddenfactors)that
evolveindependentlyofoneanotherthatinteracttogenerateoutcomesateachtimestep;e.g.,seeFigure9[75]fora
graphicalrepresentationofamulti-factorialhiddenMarkovmodel. ThismeansthatAbecomesamulti-dimensional
tensor that integrates information about the different hidden factors to cause outcomes. The belief updating is anal-
ogousinthiscase,contingentuponthefactthatoneassumesamean-fieldfactorisationoftheapproximateposterior
onthedifferenthiddenstatefactors(see,e.g.,[5,43]). Thismeansthatthebeliefsaboutstatesmaybeprocessedina
manneranalogoustoFigure5,invokingagreaternumberofneuralpopulations.
24
A.4 Deeptemporalmodels
A deep temporal model is a generative model with many layers that are nested hierarchically and act at different
timescales. Thesewerefirstintroducedwithinactiveinferencein[3]. OnecanpicturethemgraphicallyasaPOMDP
(c.f.,Figure2)atthehigherlevelwhereeachoutcomeisreplacedbyaPOMDPatthelowerlevel,andsoforth.
Thereisausefulmetaphorforunderstandingtheconceptunderlyingdeeptemporalmodels: eachlayerofthemodel
corresponds to the hand of a clock. In a two-layer hierarchical model, a ticking (resp. rotation) of the faster hand
correspondstoatimestep(resp. trialofobservationepochs)atthelowerlevel. Attheendofeachtrialatthelower
level,theslowerhandticksonce,whichcorrespondstoatime-stepatthehigherlevel,andtheprocessunfoldsagain.
Onecanconciselysummarisethisbysayingthatastateatthehigherlevelcorrespondstoatrialofobservationepochs
atthelowerlevel. Ofcourse,thereisnolimittothenumberoflayersonecanstackinahierarchicalmodel.
Toobtaintheassociatedbeliefupdating,onecomputesfreeenergyatthelowerlevelbyconditioningtheprobability
distributionsfromBayesrulebythevariablesfromthehigherlevels. Thismeansthatoneperformsbeliefupdatingat
thelowerlevelsindependentlyofthehigherlevels. Then,onecomputesthevariationalfreeenergyatthehigherlevels
bytreatingthelowerlevelsasoutcomes. Formoredetailsonthespecificitiesoftheschemesee[3].
B Expectedfreeenergy
Attheheartofactiveinferenceisadescriptionofacertainclassofsystemsatnon-equilibriumsteady-state(NESS)
[69,70]. AnimportantconsequenceofNESSistheexistenceofasteady-stateprobabilitydistributionP(s ,A)that
τ
theagentisguaranteedtoreachgivenasufficientamountoftime. Intuitively, thisdistributionshouldbethoughtas
theagent’spreferencesoverstatesandmodelparameters. Practically,thismeansthattheagentselectspolicies,such
that its predicted states Q(s ,A) at some future time point τ > t – usually, the time horizon of a policy T – reach
τ
itspreferencesP(s ,A),whicharespecifiedbythegenerativemodel. Inthefollowing,wewillshowhowaspecific
τ
familyofdistributionsQ(π)guaranteeanagenttoreachitspreferences. Then,wewillseehowNESSenablesinfact
toextractonesinglecanonicalmemberofthisfamily: the(softmaxnegative)expectedfreeenergy.
Objective: we seek distributions over policies that imply steady-state solutions; i.e., when the final distribution
does not depend upon initial observations. Such solutions ensure that, on average, stochastic policies lead to
a steady-state or target distribution specified by the generative model. These solutions exist in virtue of condi-
tional independencies, where the hidden states provide a Markov blanket that separates policies from outcomes.
In other words, policies cause final states that cause outcomes. In what follows, τ > t is a future time and
Q := Q(o ,s ,A,π) ≈ P(o ,s ,A,π|o ) is the corresponding approximate posterior distribution, given initial
τ τ τ τ 1:t
conditionso .
1:t
Lemma1(Steady-state). Thesurprisaloverpolicies−logQ(π)andtheGibbsenergy,
G(π;β)=D [Q(s ,A|π)||P(s ,A)]−E [βlogP(o |s ,A)] (34)
KL τ τ Q(oτ,sτ,A|π) τ τ
E [logQ(π|s ,A)]
β := Q τ ≥0 (35)
E [logP(o |s ,A)]
Q τ τ
areequalonaverageunderQifandonlyifthesystemreachessteady-state. Explicitly:
E [−logQ(π)]=E [G(π;β)] ⇐⇒ D [Q(s ,A)||P(s ,A)]=0 (36)
Q Q KL τ τ
Here, β ≥ 0 characterises the steady-state with the relative precision (i.e., negative entropy) of policies and final
outcomes, given final states. The generative model stipulates steady-state, in the sense that distribution over final
states (and outcomes) does not depend upon initial observations. Here, the generative and predictive distributions
simplyexpresstheconditionalindependencebetweenpoliciesandfinaloutcomes,givenfinalstates. Notethatwhen
β =1,Gibbsenergybecomesexpectedfreeenergy.
Proof. LetusunpacktheGibbsenergyexpectedunderQ:
E [G(π;β)]=E [D [Q(s ,A|π)||P(s ,A)]−E [βlogP(o |s ,A)]]
Q Q KL τ τ Q(oτ,sτ,A|π) τ τ
=E [D [Q(s ,A|π)||P(s ,A)]]
Q KL τ τ
E [logQ(π|s ,A)]
− Q τ E [E [logP(o |s ,A)]]
E [logP(o |s ,A)] Q Q(oτ,sτ,A|π) τ τ (37)
Q τ τ
=E [logQ(s ,A|π)−logP(s ,A)−logQ(π|s ,A)]
Q τ τ τ
=E [−logQ(π)−logP(s ,A)+logQ(s ,A)]
Q τ τ
=E [−logQ(π)]+D [Q(s ,A)||P(s ,A)]
Q KL τ τ
25
Andtheresultisimmediate.
AstraightforwardconsequenceofLemma1,isthateachdistribution
Q(π)=σ(−G(π;β)), β ≥0 (38)
describesacertainkindofsystemthatself-organisestosomesteady-statedistribution. Thisfamilyofdistributionshas
interestinginterpretations: forexample, thecaseβ = 0correspondstostandardstochasticcontrol, variouslyknown
asKLcontrolorrisk-sensitivecontrol[143]:
G(π;0)=D [Q(s ,A|π)||P(s ,A)]≥D [Q(s |π)||P(s )] (39)
KL τ τ KL τ τ
Inotherwords,onechoosespoliciesthatminimisetheKLdivergencebetweenthepredictiveandtargetdistribution.
Moregenerally, whenβ > 0, policiesaremorelikelywhentheysimultaneouslyminimisetheentropyofoutcomes,
givenstates. Inotherwords,β > 0ensuresthatthesystemexhibitsitinerantbehaviour. OnecanseethatKLcontrol
mayariseinthiscaseiftheentropyofthelikelihoodmappingremainsconstantwithrespecttopolicies.
Remark2. Itispossibletoextendthisframeworkbyconsideringsystemsthatreachtheirpreferencesatacollection
oftime-stepsintothefuture,sayτ ,...,τ >t. Inthiscase,onecanadapttheproofofLemma1toobtain:
1 n
(cid:34) n (cid:35) n
(cid:88) (cid:88)
E G(π,τ ;β) =E [−nlogQ(π)]+ D [Q(s ,A)||P(s ,A)] (40)
Q i Q KL τi τi
i=1 i=1
where G(π,τ ;β) is the Gibbs free energy of Lemma 1, replacing τ by τ . In this case, the canonical choice of
i i
approximateposterioroverpolicieswouldbe:
(cid:32) n (cid:33)
1 (cid:88)
Q(π)=σ G(π,τ ;β) (41)
n i
i=1
One perspective – on the distinction between simple and general steady-states – is in terms of uncertainty about
policies. Forexample,simplesteady-statesprecludeuncertaintyaboutwhichpolicyledtoafinalstate. Thiswouldbe
appropriatefordescribingclassicalsystems(thatfollowauniquepathofleastaction),whereitwouldbepossibleto
inferwhichpolicyhadbeenpursued,giventheinitialandfinaloutcomes. Conversely,ingeneralsteady-statesystems
(e.g., mice, Homosapiens), simplyknowingthat‘youarehere’doesnottellme‘howyougothere’, evenifIknew
whereyouwerethismorning. Putanotherway,therearelotsofpathsorpoliciesopentosystemsthatattainageneral
steadystate.
Inactiveinference,weareinterestedinacertainclassofsystemsthatself-organisetogeneralsteady-states;namely,
thosethatmovethroughalargenumberofprobabilisticconfigurationsfromtheirinitialstatetotheirfinalsteady-state.
Thetreatmentsin[69,70]effectivelyturnthesteady-statelemmaonitsheadbyassumingNESSisstipulativelytrue–
andthencharacterisetheensuingself-organisationintermsofBayesoptimalpolicies:
Corollary 3 (Active inference [70]). If a system attains a general steady-state, it will appear to behave in a Bayes
optimal fashion – both in terms of optimal Bayesian design (i.e., exploration) and Bayesian decision theory (i.e.,
exploitation). Crucially,thelossfunctiondefiningBayesianriskisthenegativelogevidenceforthegenerativemodel
entailedbyanagent.Inshort,systems(i.e.,agents)thatattaingeneralsteady-stateswilllookasiftheyareresponding
toepistemicaffordances[45].
Sofar,wehavededucedthedistributionoverpoliciesofsystemsthatreachsteady-state. However,recallthatreaching
steady-stateisonlyaconsequenceofNESS.In fact, NESSdynamicsunder aMarkovblanket(c.f., Figure1)imply
a slightly stronger statement: the most likely trajectories of systems described by active inference are those which
minimise expected free energy [69,70] – this is exactly the case β = 1 in (38). This is nice, since many existing
theoriesofcognitionandcontrolemergeunderthisspecificimperative(c.f.,Figure4).
C Computingexpectedfreeenergy
In this appendix, we present the derivations underlying the analytical expression of the expected free energy that is
usedinspm_MDP_VB_X.m. Following[120],wecanreexpresstheexpectedfreeenergyinthefollowingform:
26
G(π) = E [H[P(o |s )]]+D [Q(s |π)||P(s )]−E [D [Q(A|o ,s )||Q(A)]] (42)
Q(sτ|π) τ τ KL τ τ P(oτ|sτ)Q(sτ|π) KL τ τ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Ambiguity Risk(states) Novelty
Here, Q(A|o ,s ) denotes approximate posterior beliefs about A if we knew occurence of the state outcome pair
τ τ
(o ,s ). Inthefollowing,weshowthatwecancomputetheexpectedfreeenergyinthefollowingway
τ τ
G(π)≈H ·s +s ·(logs −logC)−As ·Ws
πτ πτ πτ πτ πτ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Ambiguity Risk(states) Novelty
H :=−diag[A·logA] (43)
1(cid:16) (cid:17)
W := a(cid:12)(−1)−a(cid:12)(−1)
2 0
whentheagent’spreferencesC areexpressedintermsofpreferencesoverstates. Whenpreferencesareexpressedin
termsofoutcomes(asiscurrentlyimplementedinspm_MDP_VB_X.m),theriskterminsteadbecomes
(As )·(log(As )−logC) (44)
πτ πτ
(cid:124) (cid:123)(cid:122) (cid:125)
Risk(outcomes)
C.1 Ambiguity
Theambiguitytermof(42)isE [H[P(o |s )]]. Bydefinition,theentropyinsidetheexpectationis:
Q(sτ|π) τ τ
(cid:88)
H[P(o |s )]=− P(o |s )logP(o |s ) (45)
τ τ τ τ τ τ
oτ∈O
Thefirstfactorinsidethesumcorrespondsto:
(cid:90)
P(o |s )= P(o ,A|s )dA
τ τ τ τ
(cid:90)
= P(o |s ,A)P(A)dA
τ τ
(cid:90)
= o τ ·As τ P(A)dA (46)
(cid:90)
≈ o ·As Q(A)dA
τ τ
=o ·E [A]s
τ Q(A) τ
=o ·As
τ τ
Here we have replaced the prior over model parameters P(A) by the approximate posterior Q(A). This is not nec-
essary, but in numerical simulations since learningoccurs once at the end of the trial the two can be interchanged –
furthermore, thisallowsustoreusepreviouslyintroducednotation. Inanycase, thistellsusthattheentropycanbe
re-expressedas:
(cid:88)
H[P(o |s )]=− (o ·As )(o ·log(A)s )
τ τ τ τ τ τ
oτ∈O
n
(cid:88)
=− (A s )(log(A )s )
•i τ •i τ
i=1
(47)
n
(cid:88)
=− (A (cid:12)log(A ))s
•i •i τ
i=1
=−(A(cid:12)logA)s
τ
=−diag[A·logA]·s
τ
27
Finally,
E [H[P(o |s )]]=H ·s
Q(sτ|π) τ τ πτ
(cid:124) (cid:123)(cid:122) (cid:125)
(48)
Ambiguity
H :=−diag[A·logA]
C.2 Risk
Therisktermof(42)istheKLdivergencebetweenpredictedstatesfollowingaparticularpolicyandpreferredstates.
Thiscanbeexpressedas:
D [Q(s |π)||P(s )]=s ·(s −logC) (49)
KL τ τ πτ πτ
(cid:124) (cid:123)(cid:122) (cid:125)
Risk(states)
Where the vector C ∈ Rm encodes preference over states P(s ) = Cat(C). However, it is also possible to
τ
approximate this risk term over states by a risk term over outcomes (c.f., (15)), as is currently implemented in
spm_MDP_VB_X.m. Inthiscase,ifC ∈RndenotesthepreferencesoveroutcomesP(o )=Cat(C):
τ
D [Q(o |π)||P(o )]=(As )·(log(As )−logC) (50)
KL τ τ πτ πτ
(cid:124) (cid:123)(cid:122) (cid:125)
Risk(outcomes)
C.3 Novelty
Thenoveltytermof(42)isE [D [Q(A|o ,s )||Q(A)]]where
P(oτ|sτ)Q(sτ|π) KL τ τ
m
(cid:89)
Q(A)= Q(A ), Q(A )=Dir(a ) (51)
•i •i •i
i=1
m
(cid:89)
Q(A|o ,s )= Q(A |o ,s ), Q(A |o ,s ):=Dir(a(cid:48) ) (52)
τ τ •i τ τ •i τ τ •i
i=1
TheKLdivergencebetweenbothdistributions(c.f.,(18))canbeexpressedas:
m n
(cid:88) (cid:88)
D [Q(A|o ,s )||Q(A)]= [logΓ(a(cid:48) )− logΓ(a(cid:48) )−logΓ(a )
KL τ τ 0i ki 0i
i=1 k=1
(53)
n
(cid:88)
+ logΓ(a )]+(a(cid:48)−a)·(ψ(a(cid:48))−ψ(a(cid:48)))
ki 0
k=1
where ψ is the digamma function. We now want to make sense of a(cid:48). Suppose that at time τ the agents knows the
possible outcome j and possible state k as in Q(A|o ,s ) (c.f., Table 2 for terminology). This means that in this
τ τ
case, beliefs about hidden states correspond to the true state; in other words, s = s . We can then use the rule of
τ τ
accumulationofDirichletparameterstodeducea(cid:48) =a+o ⊗s . Inotherwords,a(cid:48) =a +1andtheremaining
τ τ jk jk
componentsareidentical. Usingthewell-knownidentity:
Γ(x+1)=xΓ(x)⇒logΓ(x+1)=logx+logΓ(x) (54)
wecancompute(53):
D [Q(A|o ,s )||Q(A)]=logΓ(a +1)−logΓ(a )−logΓ(a +1)+logΓ(a )+ψ(a +1)−ψ(a
KL τ τ 0k 0k jk jk jk 0k
=loga −loga +ψ(a +1)−ψ(a +1)
0k jk jk 0k
(55)
28
Usingthedefinitionofthedigammafunctionψ(x)= d logΓ(x)weobtain:
dx
d d
D [Q(A|o ,s )||Q(A)]=loga −loga + (logΓ(a +1))− (logΓ(a +1))
KL τ τ 0k jk da jk da 0k
jk 0k
d d
=loga −loga + (logΓ(a +1))− (loga +logΓ(a )) (56)
0k jk da jk da 0k 0k
jk 0k
1 1
=loga −loga + − +ψ(a )−ψ(a )
0k jk a a jk 0k
jk 0k
Wecanuseanasymptoticexpansionofthedigammafunctiontosimplifytheexpression:
1
ψ(x)≈logx− +···
2x
(57)
1 1
⇒D [Q(A|o ,s )||Q(A)]≈ −
KL τ τ 2a 2a
jk 0k
Finally,theanalyticalexpressionofthenoveltyterm:
E [D [Q(A|o ,s )||Q(A)]]≈As ·Ws
P(oτ|sτ)Q(sτ|π) KL τ τ πτ πτ
W :=
1(cid:0) a(cid:12)−1−a(cid:12)−1(cid:1) (58)
2 0
References
[1] Raphael Kaplan and Karl J. Friston. Planning and navigation as active inference. Biological Cybernetics,
112(4):323–343,August2018.
[2] KarlJ.Friston, RichardRosch, ThomasParr, CathyPrice, andHowardBowman. Deeptemporalmodelsand
activeinference. Neuroscience&BiobehavioralReviews,90:486–501,July2018.
[3] Karl J. Friston, Marco Lin, Christopher D. Frith, Giovanni Pezzulo, J. Allan Hobson, and Sasha Ondobaka.
ActiveInference,CuriosityandInsight. NeuralComputation,29(10):2633–2683,October2017.
[4] Thomas Parr and Karl J. Friston. Active inference and the anatomy of oculomotion. Neuropsychologia,
111:334–343,March2018.
[5] M.BerkMirza,RickA.Adams,ChristophD.Mathys,andKarlJ.Friston.SceneConstruction,VisualForaging,
andActiveInference. FrontiersinComputationalNeuroscience,10,June2016.
[6] Thomas Parr and Karl J. Friston. Uncertainty, epistemics and active inference. Journal of the Royal Society
Interface,14(136),November2017.
[7] ThomasParrandKarlJ.Friston. TheComputationalAnatomyofVisualNeglect. CerebralCortex(NewYork,
N.Y.: 1991),28(2):777–790,January2018.
[8] RickA.Adams,KlaasEnnoStephan,HarrietR.Brown,ChristopherD.Frith,andKarlJ.Friston. TheCompu-
tationalAnatomyofPsychosis. FrontiersinPsychiatry,4,2013.
[9] Jelle Bruineberg, Erik Rietveld, Thomas Parr, Leendert van Maanen, and Karl J Friston. Free-energy mini-
mizationinjointagent-environmentsystems:Anicheconstructionperspective. JournalofTheoreticalBiology,
455:161–178,October2018.
[10] A Constant, M Ramstead, Samuel P. L. Veissière, J O Campbell, and K.J. Friston. A variational approach to
nicheconstruction. JournalofTheRoyalSocietyInterface,15(141):20170685,April2018.
[11] AxelConstant, MaxwellJ.D.Ramstead, SamuelP.L.Veissière, andKarlFriston. RegimesofExpectations:
AnActiveInferenceModelofSocialConformityandHumanDecisionMaking. FrontiersinPsychology,10,
2019.
[12] M.BerkMirza,RickA.Adams,ThomasParr,andKarlFriston. ImpulsivityandActiveInference. Journalof
CognitiveNeuroscience,31(2):202–220,February2019.
29
[13] Beren Millidge. Implementing Predictive Processing and Active Inference: Preliminary Steps and Results.
Preprint,PsyArXiv,March2019.
[14] OzanÇatal,JohannesNauta,TimVerbelen,PieterSimoens,andBartDhoedt. Bayesianpolicyselectionusing
activeinference. arXiv:1904.08149[cs],April2019.
[15] Karl J. Friston, Jean Daunizeau, and Stefan J. Kiebel. Reinforcement Learning or Active Inference? PLoS
ONE,4(7):e6421,July2009.
[16] KarlFriston,RickAdams,andReadMontague. Whatisvalue—accumulatedrewardorevidence? Frontiersin
Neurorobotics,6,2012.
[17] Rafal Bogacz. A tutorial on the free-energy framework for modelling perception and learning. Journal of
MathematicalPsychology,76:198–211,February2017.
[18] Christopher L. Buckley, Chang Sub Kim, Simon McGregor, and Anil K. Seth. The free energy principle for
action and perception: A mathematical review. Journal of Mathematical Psychology, 81:55–79, December
2017.
[19] S. J. Luck and E. K. Vogel. The capacity of visual working memory for features and conjunctions. Nature,
390(6657):279–281,November1997.
[20] Weiwei Zhang and Steven J. Luck. Discrete Fixed-Resolution Representations in Visual Working Memory.
Nature,453(7192):233–235,May2008.
[21] HowardEichenbaum,PaulDudchenko,EmmaWood,MatthewShapiro,andHeikkiTanila. TheHippocampus,
Memory,andPlaceCells: IsItSpatialMemoryoraMemorySpace? Neuron,23(2):209–226,June1999.
[22] J.O’KeefeandJ.Dostrovsky. Thehippocampusasaspatialmap.Preliminaryevidencefromunitactivityinthe
freely-movingrat. BrainResearch,34(1):171–175,November1971.
[23] NathanielD.Daw,JohnP.O’Doherty,PeterDayan,BenSeymour,andRaymondJ.Dolan. Corticalsubstrates
forexploratorydecisionsinhumans. Nature,441(7095):876–879,June2006.
[24] PaulReverdy,VaibhavSrivastava,andNaomiE.Leonard. ModelingHumanDecision-makinginGeneralized
GaussianMulti-armedBandits. arXiv:1307.6134[cs,math,stat],July2013.
[25] Charley M. Wu, Eric Schulz, Maarten Speekenbrink, Jonathan D. Nelson, and Björn Meder. Generalization
guideshumanexplorationinvastdecisionspaces. NatureHumanBehaviour,2(12):915–924,December2018.
[26] Nathaniel D. Daw, Samuel J. Gershman, Ben Seymour, Peter Dayan, and Raymond J. Dolan. Model-Based
InfluencesonHumans’ChoicesandStriatalPredictionErrors. Neuron,69(6):1204–1215,March2011.
[27] KarlJ.Friston,ThomasParr,andBertdeVries. Thegraphicalbrain: Beliefpropagationandactiveinference.
NetworkNeuroscience,1(4):381–414,December2017.
[28] Thomas Parr and Karl J. Friston. The Discrete and Continuous Brain: From Decisions to Movement—And
BackAgain. NeuralComputation,30(9):2319–2347,September2018.
[29] KarlJ.Friston,NoorSajid,DavidRicardoQuiroga-Martinez,ThomasParr,CathyJ.Price,andEmmaHolmes.
ActiveListening. bioRxiv,page2020.03.18.997122,March2020.
[30] Thomas Parr and Karl J. Friston. The computational pharmacology of oculomotion. Psychopharmacology,
April2019.
[31] KarlFriston,SpyridonSamothrakis,andReadMontague.Activeinferenceandagency:Optimalcontrolwithout
costfunctions. BiologicalCybernetics,106(8):523–541,October2012.
[32] ThomasH.B.FitzGerald,PhilippSchwartenbeck,MichaelMoutoussis,RaymondJ.Dolan,andKarlFriston.
Active inference, evidence accumulation, and the urn task. Neural Computation, 27(2):306–328, February
2015.
[33] ThomasH.B.FitzGerald, RosalynJ.Moran, KarlJ.Friston, andRaymondJ.Dolan. Precisionandneuronal
dynamics in the human posterior parietal cortex during evidence accumulation. NeuroImage, 107:219–228,
February2015.
[34] Philipp Schwartenbeck, Thomas H. B. FitzGerald, Christoph Mathys, Ray Dolan, Friedrich Wurst, Martin
Kronbichler, and Karl Friston. Optimal inference with suboptimal models: Addiction and active Bayesian
inference. MedicalHypotheses,84(2):109–117,February2015.
[35] ThomasH.B.FitzGerald,RaymondJ.Dolan,andKarlFriston. Dopamine,rewardlearning,andactiveinfer-
ence. FrontiersinComputationalNeuroscience,9,November2015.
30
[36] Karl Friston, Philipp Schwartenbeck, Thomas FitzGerald, Michael Moutoussis, Timothy Behrens, and Ray-
mond J. Dolan. The anatomy of choice: Dopamine and decision-making. Philosophical Transactions of the
RoyalSocietyB:BiologicalSciences,369(1655),November2014.
[37] Philipp Schwartenbeck, Thomas H. B. FitzGerald, Christoph Mathys, Ray Dolan, and Karl Friston. The
DopaminergicMidbrainEncodestheExpectedCertaintyaboutDesiredOutcomes. CerebralCortex(NewYork,
N.Y.: 1991),25(10):3434–3445,October2015.
[38] PhilippSchwartenbeck,ThomasH.B.FitzGerald,ChristophMathys,RayDolan,MartinKronbichler,andKarl
Friston. Evidence for surprise minimization over value maximization in choice behavior. Scientific Reports,
5:16575,November2015.
[39] Michael Moutoussis, Nelson J. Trujillo-Barreto, Wael El-Deredy, Raymond J. Dolan, and Karl J. Friston. A
formalmodelofinterpersonalinference. FrontiersinHumanNeuroscience,8,March2014.
[40] Karl Friston, Francesco Rigoli, Dimitri Ognibene, Christoph Mathys, Thomas Fitzgerald, and Giovanni Pez-
zulo. Activeinferenceandepistemicvalue. CognitiveNeuroscience,6(4):187–214,October2015.
[41] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, John O’Doherty, and Giovanni
Pezzulo. Activeinferenceandlearning. Neuroscience&BiobehavioralReviews,68:862–879,September2016.
[42] Thomas H. B. FitzGerald, Raymond J. Dolan, and Karl J. Friston. Model averaging, optimal inference, and
habitformation. FrontiersinHumanNeuroscience,8,2014.
[43] KarlFristonandGyorgyBuzsáki. TheFunctionalAnatomyofTime: WhatandWhenintheBrain. Trendsin
CognitiveSciences,20(7):500–511,July2016.
[44] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and Giovanni Pezzulo. Active
Inference: AProcessTheory. NeuralComputation,29(1):1–49,January2017.
[45] ThomasParrandKarlJFriston.Workingmemory,attention,andsalienceinactiveinference.ScientificReports,
7(1):14678,December2017.
[46] Thomas Parr, Geraint Rees, and Karl J. Friston. Computational Neuropsychology and Bayesian Inference.
FrontiersinHumanNeuroscience,12,2018.
[47] ThomasParr,RajeevVijayRikhye,MichaelMHalassa,andKarlJFriston. PrefrontalComputationasActive
Inference. CerebralCortex,pagebhz118e0190429e12112e37454,July2019.
[48] DavidBenrimoh,ThomasParr,PeterVincent,RickA.Adams,andKarlFriston.ActiveInferenceandAuditory
Hallucinations. ComputationalPsychiatry,2:183–204,November2018.
[49] ThomasParr,DavidA.Benrimoh,PeterVincent,andKarlJ.Friston. PrecisionandFalsePerceptualInference.
FrontiersinIntegrativeNeuroscience,12,2018.
[50] Anna C. Sales, Karl J. Friston, Matthew W. Jones, Anthony E. Pickering, and Rosalyn J. Moran. Locus
Coeruleus tracking of prediction errors optimises cognitive flexibility: An Active Inference model. bioRxiv,
page340620,June2018.
[51] Peter Vincent, Thomas Parr, David Benrimoh, and Karl J. Friston. With an eye on uncertainty: Modelling
pupillaryresponsestoenvironmentalvolatility. PLOSComputationalBiology,15(7):e1007126,05-Jul-2019.
[52] MaellCullen,BenDavey,KarlJ.Friston,andRosalynJ.Moran.ActiveInferenceinOpenAIGym:AParadigm
forComputationalInvestigationsIntoPsychiatricIllness. BiologicalPsychiatry: CognitiveNeuroscienceand
Neuroimaging,3(9):809–818,September2018.
[53] Alexander Tschantz, Manuel Baltieri, Anil K. Seth, and Christopher L. Buckley. Scaling active inference.
arXiv:1911.10601[cs,eess,math,stat],November2019.
[54] Christopher M. Bishop. Pattern Recognition and Machine Learning. Information Science and Statistics.
Springer,NewYork,2006.
[55] YangXitong. UnderstandingtheVariationalLowerBound. 2017.
[56] Biswa Sengupta and Karl Friston. Approximate Bayesian inference as a gauge theory. In Computational
BiologyWorkshop,volume14,pagee1002400,March2016.
[57] BiswaSengupta,ArturoTozzi,GeraldK.Cooray,PamelaK.Douglas,andKarlJ.Friston. TowardsaNeuronal
GaugeTheory. PLOSBiology,14(3):e1002400,08-Mar-2016.
[58] LaurenceAitchisonandMátéLengyel. Withorwithoutyou: PredictivecodingandBayesianinferenceinthe
brain. CurrentOpinioninNeurobiology,46:219–227,October2017.
[59] KarlFriston. ThehistoryofthefutureoftheBayesianbrain. NeuroImage,62(2):1230–1233,August2012.
31
[60] David C. Knill and Alexandre Pouget. The Bayesian brain: The role of uncertainty in neural coding and
computation. TrendsinNeurosciences,27(12):712–719,December2004.
[61] Ryan T. McKay and Daniel C. Dennett. The evolution of misbelief. The Behavioral and Brain Sciences,
32(6):493–510;discussion510–561,December2009.
[62] TaliSharot. Theoptimismbias. CurrentBiology,21(23):R941–R945,December2011.
[63] KarlFriston. Thefree-energyprinciple: Aroughguidetothebrain? TrendsinCognitiveSciences,13(7):293–
301,July2009.
[64] KarlFriston. Thefree-energyprinciple:Aunifiedbraintheory? NatureReviewsNeuroscience,11(2):127–138,
February2010.
[65] KarlJ.FristonandKlaasE.Stephan. Free-energyandthebrain. Synthese,159(3):417–458,November2007.
[66] KarlFriston,JamesKilner,andLeeHarrison.Afreeenergyprincipleforthebrain.JournalofPhysiology-Paris,
100(1-3):70–87,July2006.
[67] J.M.Fuster. Prefrontalcortexandthebridgingoftemporalgapsintheperception-actioncycle. Annalsofthe
NewYorkAcademyofSciences,608:318–329;discussion330–336,1990.
[68] JakobHohwy. TheSelf-EvidencingBrain. Noûs,50(2):259–285,June2016.
[69] Thomas Parr, Lancelot DaCosta, and Karl J. Friston. Markovblankets, information geometry and stochastic
thermodynamics. Phil.Trans.R.Soc.A.,2019.
[70] KarlFriston. Afreeenergyprincipleforaparticularphysics. BioArxiv,page148,2019.
[71] Michael Kirchhoff, Thomas Parr, Ensor Palacios, Karl Friston, and Julian Kiverstein. The Markov blankets
of life: Autonomy, active inference and the free energy principle. Journal of The Royal Society Interface,
15(138):20170792,January2018.
[72] JudeaPearl. GraphicalModelsforProbabilisticandCausalReasoning. InPhilippeSmets, editor, Quantified
RepresentationofUncertaintyandImprecision,HandbookofDefeasibleReasoningandUncertaintyManage-
mentSystems,pages367–389.SpringerNetherlands,Dordrecht,1998.
[73] MatthewJamesBeal. VariationalAlgorithmsforApproximateBayesianInference. page281,2003.
[74] David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational Inference: A Review for Statisticians.
JournaloftheAmericanStatisticalAssociation,112(518):859–877,April2017.
[75] MichaelI.Jordan, ZoubinGhahramani, TommiS.Jaakkola, andLawrenceK.Saul. AnIntroductiontoVari-
ational Methods for Graphical Models. In Michael I. Jordan, editor, Learning in Graphical Models, pages
105–161.SpringerNetherlands,Dordrecht,1998.
[76] KJAström.OptimalControlofMarkovProcesseswithIncompleteStateInformation.JournalofMathematical
AnalysisandApplications,10,1965.
[77] AndrewBartoandRichardSutton. ReinforcementLearning: AnIntroduction. 1992.
[78] JamesVStone. ArtificialIntelligenceEngines: ATutorialIntroductiontotheMathematicsofDeepLearning.
2019.
[79] C.C.White. Markovdecisionprocesses. InEncyclopediaofOperationsResearchandManagementScience,
pages484–486.SpringerUS,Boston,MA,2001.
[80] G E P Box and George C Tiao. Multiparameter problems from a Bayesian point of view. The Annals of
MathematicalStatistics,1965.
[81] GregMAllenby,PeterERossi,andRobertEMcCulloch. HierarchicalBayesModels: APractitionersGuide.
2005.
[82] JudeaPearl. ProbabilisticReasoninginIntelligentSystems. 1988.
[83] Hans-AndreaLoeliger. Anintroductiontofactorgraphs. IEEESignalProcessingMagazine,2004.
[84] ToshiyukiTanaka. ATheoryofMeanFieldApproximation. page10,1999.
[85] ThomasParr,DimitrijeMarkovic,StefanJ.Kiebel,andKarlJ.Friston. NeuronalmessagepassingusingMean-
field,Bethe,andMarginalapproximations. ScientificReports,9(1):1889,December2019.
[86] SarahSchwöbel,StefanKiebel,andDimitrijeMarkovic´. ActiveInference,BeliefPropagation,andtheBethe
Approximation. NeuralComputation,30(9):2530–2567,September2018.
[87] JamesTeeandDesmondP.Taylor. IsInformationintheBrainRepresentedinContinuousorDiscreteForm?
arXiv:1805.01631[cs,math,q-bio],May2018.
32
[88] TimothyJ.BuschmanandEarlK.Miller. ShiftingtheSpotlightofAttention: EvidenceforDiscreteComputa-
tionsinCognition. FrontiersinHumanNeuroscience,4,2010.
[89] J.Duncan, R.Ward, andK.Shapiro. Directmeasurementofattentionaldwelltimeinhumanvision. Nature,
369(6478):313–315,May1994.
[90] AyeletNinaLandauandPascalFries.AttentionSamplesStimuliRhythmically.CurrentBiology,22(11):1000–
1004,June2012.
[91] SimonHanslmayr, GregorVolberg, MariaWimber, SarangS.Dalal, andMarkW.Greenlee. PrestimulusOs-
cillatoryPhaseat7HzGatesCorticalInformationFlowandVisualPerception. CurrentBiology,23(22):2273–
2278,November2013.
[92] ETRollsandMJTovee. Processingspeedinthecerebralcortexandtheneurophysiologyofvisualmasking.
ProceedingsoftheRoyalSocietyofLondon.SeriesB:BiologicalSciences,257(1348):9–15,July1994.
[93] Karl Friston. Hierarchical Models in the Brain. PLoS Computational Biology, 4(11):e1000211, November
2008.
[94] Zenas C. Chao, Kana Takaura, Liping Wang, Naotaka Fujii, and Stanislas Dehaene. Large-Scale Cortical
NetworksforHierarchicalPredictionandPredictionErrorinthePrimateBrain. Neuron,100(5):1252–1266.e3,
May2018.
[95] Sandra Iglesias, Christoph Mathys, Kay H. Brodersen, Lars Kasper, Marco Piccirelli, Hanneke E. M. den
Ouden,andKlaasE.Stephan. HierarchicalPredictionErrorsinMidbrainandBasalForebrainduringSensory
Learning. Neuron,80(2):519–530,October2013.
[96] S. Kullback and R. A. Leibler. On Information and Sufficiency. The Annals of Mathematical Statistics,
22(1):79–86,March1951.
[97] HoraceBarlow. Redundancyreductionrevisited. Comput.NeuralSyst.,page13,2001.
[98] Yang Dan, Joseph J. Atick, and R. Clay Reid. Efficient Coding of Natural Scenes in the Lateral Geniculate
Nucleus: Experimental Test of a Computational Theory. Journal of Neuroscience, 16(10):3351–3362, May
1996.
[99] MichaelS.Lewicki. Efficientcodingofnaturalsounds. NatureNeuroscience,5(4):356–363,April2002.
[100] Bruno A Olshausen and David J Field. Sparse coding of sensory inputs. Current Opinion in Neurobiology,
14(4):481–487,August2004.
[101] BrunoA.OlshausenandKevinN.O’Connor. Anewwindowonsound. NatureNeuroscience,5(4):292–294,
April2002.
[102] EmanuelTodorovandMichaelI.Jordan. Optimalfeedbackcontrolasatheoryofmotorcoordination. Nature
Neuroscience,5(11):1226–1235,November2002.
[103] Peter Bossaerts and Carsten Murawski. From behavioural economics to neuroeconomics to decision neuro-
science:Theascentofbiologyinresearchonhumandecisionmaking.CurrentOpinioninBehavioralSciences,
5:37–42,October2015.
[104] L. M. Optican and B. J. Richmond. Temporal encoding of two-dimensional patterns by single units in pri-
mateinferiortemporalcortex.III.Informationtheoreticanalysis. JournalofNeurophysiology,57(1):162–178,
January1987.
[105] R Linsker. Perceptual Neural Organization: Some Approaches Based on Network Models and Information
Theory. AnnualReviewofNeuroscience,13(1):257–281,1990.
[106] H.B.Barlow. PossiblePrinciplesUnderlyingtheTransformationsofSensoryMessages. TheMITPress,1961.
[107] Hermann Haken. Synergetics: An Introduction Nonequilibrium Phase Transitions and Self-Organization in
Physics,ChemistryandBiology. SpringerSeriesinSynergetics.Springer-Verlag,BerlinHeidelberg,2edition,
1978.
[108] StuartA.Kauffman. TheOriginsofOrder: Self-OrganizationandSelectioninEvolution. OxfordUniversity
Press,1993.
[109] G. Nicolis and I. Prigogine. Self-Organization in Nonequilibrium Systems: From Dissipative Structures to
OrderThroughFluctuations. Wiley-Blackwell,NewYork,June1977.
[110] W. R. Ashby. Principles of the Self-Organizing Dynamic System. The Journal of General Psychology,
37(2):125–128,October1947.
[111] ClaudeBernard. LecturesonthePhenomenaofLifeCommontoAnimalsandPlants. Thomas,1974.
33
[112] Roger C Conant and W. R. Ashby. Every good regulator of a system must be a model of that system. Int. J.
SystemsSci.,1(2):89–97,1970.
[113] David J. C. MacKay. Information Theory, Inference and Learning Algorithms. Cambridge University Press,
Cambridge,UK;NewYork,sixthprinting2007editionedition,September2003.
[114] DavidMacKay. AFreeEnergyMinimizationAlgorithmforDecodingandCryptanalysis. InElectronicLetters,
1995.
[115] HermannvonHelmholtzandJamesP.CSouthall. Helmholtz’sTreatiseonPhysiologicalOptics. DoverPubli-
cations,NewYork,1962. OCLC:523553.
[116] R.L.Gregory. Perceptionsashypotheses. PhilosophicalTransactionsoftheRoyalSocietyofLondon.Series
B,BiologicalSciences,290(1038):181–197,July1980.
[117] PeterDayan, GeoffreyE.Hinton, RadfordM.Neal, andRichardS.Zemel. TheHelmholtzMachine. Neural
Computation,7(5):889–904,September1995.
[118] J.S.Yedidia,W.T.Freeman,andY.Weiss. ConstructingFree-EnergyApproximationsandGeneralizedBelief
PropagationAlgorithms. IEEETransactionsonInformationTheory,51(7):2282–2312,July2005.
[119] T.Heskes. ConvexityArgumentsforEfficientMinimizationoftheBetheandKikuchiFreeEnergies. Journal
ofArtificialIntelligenceResearch,26:153–190,June2006.
[120] Thomas Parr. The Computational Neurology of Active Vision. Ph.D., University College London, London,
2019.
[121] KaareBrandtPetersenandMichaelSyskindPedersen. TheMatrixCookbook. page72.
[122] Mikael Lundqvist, Jonas Rose, Pawel Herman, Scott L. Brincat, Timothy J. Buschman, and Earl K. Miller.
GammaandBetaBurstsUnderlieWorkingMemory. Neuron,90(1):152–164,April2016.
[123] Rajesh P. N. Rao and Dana H. Ballard. Predictive coding in the visual cortex: A functional interpretation of
someextra-classicalreceptive-fieldeffects. NatureNeuroscience,2(1):79–87,January1999.
[124] Andre M. Bastos, W. Martin Usrey, Rick A. Adams, George R. Mangun, Pascal Fries, and Karl J. Friston.
CanonicalMicrocircuitsforPredictiveCoding. Neuron,76(4):695–711,November2012.
[125] KarlFriston,JérémieMattout,NelsonTrujillo-Barreto,JohnAshburner,andWillPenny.Variationalfreeenergy
andtheLaplaceapproximation. NeuroImage,34(1):220–234,January2007.
[126] AndréC.Marreiros,JeanDaunizeau,StefanJ.Kiebel,andKarlJ.Friston. Populationdynamics: Varianceand
thesigmoidactivationfunction. NeuroImage,42(1):147–157,August2008.
[127] GustavoDeco,ViktorK.Jirsa,PeterA.Robinson,MichaelBreakspear,andKarlFriston. TheDynamicBrain:
From Spiking Neurons to Neural Masses and Cortical Fields. PLoS Computational Biology, 4(8):e1000092,
August2008.
[128] RosalynMoran,DimitrisA.Pinotsis,andKarlFriston. Neuralmassesandfieldsindynamiccausalmodeling.
FrontiersinComputationalNeuroscience,7,2013.
[129] GeorgVonBékésy. SensoryInhibition. PrincetonUniversityPress,1967.
[130] JohnWinnandChristopherMBishop. VariationalMessagePassing. JournalofMachineLearningResearch,
page34,2005.
[131] JustinDauwels. OnVariationalMessagePassingonFactorGraphs. In2007IEEEInternationalSymposiumon
InformationTheory,pages2546–2550,Nice,June2007.IEEE.
[132] JustinDauwels,FrançoisVialatte,TomaszRutkowski,andAndrzejCichocki. MeasuringNeuralSynchronyby
MessagePassing. InNIPS,2007.
[133] Dileep George. Belief Propagation and Wiring Length Optimization as Organizing Principles for Cortical
Microcircuits. 2005.
[134] GailA.CarpenterandStephenGrossberg. Amassivelyparallelarchitectureforaself-organizingneuralpattern
recognitionmachine. ComputerVision,Graphics,andImageProcessing,37(1):54–115,January1987.
[135] L. Itti, C. Koch, and E. Niebur. A model of saliency-based visual attention for rapid scene analysis. IEEE
TransactionsonPatternAnalysisandMachineIntelligence,20(11):1254–1259,November1998.
[136] Maximilian Riesenhuber and Tomaso Poggio. Hierarchical models of object recognition in cortex. Nature
Neuroscience,2(11):1019–1025,November1999.
[137] WolfgangMaass. OntheComputationalPowerofWinner-Take-All. NeuralComputation,12(11):2519–2535,
November2000.
34
[138] Quentin J. M. Huys, Neir Eshel, Elizabeth O’Nions, Luke Sheridan, Peter Dayan, and Jonathan P. Roiser.
Bonsai Trees in Your Head: How the Pavlovian System Sculpts Goal-Directed Choices by Pruning Decision
Trees. PLoSComputationalBiology,8(3):e1002410,March2012.
[139] Stanislas Dehaene, Florent Meyniel, Catherine Wacongne, Liping Wang, and Christophe Pallier. The Neural
RepresentationofSequences:FromTransitionProbabilitiestoAlgebraicPatternsandLinguisticTrees.Neuron,
88(1):2–19,October2015.
[140] Jordi Fonollosa, Emre Neftci, and Mikhail Rabinovich. Learning of Chunking Sequences in Cognition and
Behavior. PLOSComputationalBiology,11(11):e1004592,19-Nov-2015.
[141] Masahiko Haruno, Daniel Wolpert, and Mitsuo Kawato. Hierarchical MOSAIC for Movement Generation.
2003.
[142] Emanuel Todorov. General duality between optimal control and estimation. 2008 47th IEEE Conference on
DecisionandControl,pages4286–4292,2008.
[143] BartvandenBroek,WimWiegerinck,andBertKappen. Risksensitivepathintegralcontrol. UAI,2010.
[144] W.H.FlemingandS.J.Sheu.Risk-sensitivecontrolandanoptimalinvestmentmodelII.TheAnnalsofApplied
Probability,12(2):730–767,May2002.
[145] Andrew Barto, Marco Mirolli, and Gianluca Baldassarre. Novelty or Surprise? Frontiers in Psychology, 4,
2013.
[146] Emil Kauder. Genesis of the Marginal Utility Theory: From Aristotle to the End of the Eighteenth Century.
TheEconomicJournal,63(251):638–650,September1953.
[147] JürgenSchmidhuber. FormalTheoryofCreativity,Fun,andIntrinsicMotivation(1990–2010). IEEETransac-
tionsonAutonomousMentalDevelopment,2(3):230–247,September2010.
[148] James O. Berger. Statistical Decision Theory and Bayesian Analysis. Springer Series in Statistics. Springer-
Verlag,NewYork,2edition,1985.
[149] Jürgen Schmidhuber. Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts.
ConnectionScience,18(2):173–187,June2006.
[150] Pierre-Yves Oudeyer and Frederic Kaplan. What is intrinsic motivation? A typology of computational ap-
proaches. FrontiersinNeurorobotics,1,2009.
[151] EdwardDeciandRichardM.Ryan. IntrinsicMotivationandSelf-DeterminationinHumanBehavior. Perspec-
tivesinSocialPsychology.SpringerUS,1985.
[152] Ronald A. Howard. Information Value Theory. IEEE Transactions on Systems Science and Cybernetics,
2(1):22–26,August1966.
[153] LaurentIttiandPierreBaldi. Bayesiansurpriseattractshumanattention. Visionresearch,49(10):1295–1306,
May2009.
[154] Philipp Schwartenbeck, Thomas FitzGerald, Raymond J. Dolan, and Karl Friston. Exploration, novelty, sur-
prise,andfreeenergyminimization. FrontiersinPsychology,4,October2013.
[155] YiSun,FaustinoGomez,andJuergenSchmidhuber. PlanningtoBeSurprised: OptimalBayesianExploration
inDynamicEnvironments. arXiv:1103.5708[cs,stat],March2011.
[156] HBBarlow. InductiveInference,Coding,Perception,andLanguage. Perception,3(2):123–134,June1974.
[157] D. V. Lindley. On a Measure of the Information Provided by an Experiment. The Annals of Mathematical
Statistics,27(4):986–1005,1956.
[158] DavidJ.C.MacKay. Information-BasedObjectiveFunctionsforActiveDataSelection. NeuralComputation,
4(4):590–604,July1992.
[159] HagaiAttias. PlanningbyProbabilisticInference. In9thInt.WorkshoponArtificialIntelligenceandStatistics,
page8,2003.
[160] MatthewBotvinickandMarcToussaint. Planningasinference. TrendsinCognitiveSciences,16(10):485–488,
October2012.
[161] DanielKahnemanandAmosTversky. ProspectTheory: AnAnalysisofDecisionunderRisk. Decision,Proba-
bility,andUtility: SelectedReadings.CambridgeUniversityPress,NewYork,NY,US,1988.
[162] J. Von Neumann and O. Morgenstern. Theory of Games and Economic Behavior. Theory of Games and
EconomicBehavior.PrincetonUniversityPress,Princeton,NJ,US,1944.
35
[163] E.T.Jaynes. InformationTheoryandStatisticalMechanics. PhysicalReview,106(4):620–630,May1957.
[164] BarisKurt. Kullback-LeiblerDivergenceBetweenTwoDirichlet(andBeta)Distributions,2013.
[165] W.D.Penny. KL-divergenceofNormal,Gamma,DirichletandWishartdensitites. 2001.
[166] ThomasParrandKarlJ.Friston. TheAnatomyofInference: GenerativeModelsandBrainStructure. Frontiers
inComputationalNeuroscience,12,2018.
[167] MarjanJahanshahi,IgnacioObeso,JohnC.Rothwell,andJoséA.Obeso. Afronto-striato-subthalamic-pallidal
networkforgoal-directedandhabitualinhibition. NatureReviews.Neuroscience,16(12):719–732,December
2015.
[168] G. S. Berns and T. J. Sejnowski. How the Basal Ganglia Make Decisions. In A. R. Damasio, H. Damasio,
andY.Christen,editors,NeurobiologyofDecision-Making,ResearchandPerspectivesinNeurosciences,pages
101–113.SpringerBerlinHeidelberg,Berlin,Heidelberg,1996.
[169] Long Ding and Joshua I. Gold. The basal ganglia’s contributions to perceptual decision-making. Neuron,
79(4):640–649,August2013.
[170] Suzanne N. Haber. The primate basal ganglia: Parallel and integrative networks. Journal of Chemical Neu-
roanatomy,26(4):317–330,December2003.
[171] Florence Thibaut. Basal ganglia play a crucial role in decision making. Dialogues in Clinical Neuroscience,
18(1):3,March2016.
[172] KarlFristonandWillPenny. PosthocBayesianmodelselection. NeuroImage,56(4):2089–2099,June2011.
[173] RyanSmith,PhilippSchwartenbeck,ThomasParr,andKarlJ.Friston. Anactiveinferencemodelofconcept
learning. bioRxiv,page633677,May2019.
[174] KarlFriston,ThomasParr,andPeterZeidman.Bayesianmodelreduction.arXiv:1805.07092[stat],May2018.
[175] GerdaClaeskensandNilsLidHjort.ModelSelectionandModelAveraging.CambridgeUniversityPress,2006.
[176] KlaasEnnoStephan,WillD.Penny,JeanDaunizeau,RosalynJ.Moran,andKarlJ.Friston. Bayesianmodel
selectionforgroupstudies. NeuroImage,46(4):1004–1017,July2009.
[177] J.A.HobsonandK.J.Friston. Wakinganddreamingconsciousness: Neurobiologicalandfunctionalconsider-
ations. ProgressinNeurobiology,98(1):82–98,July2012.
[178] J. Allan Hobson, Charles C.-H. Hong, and Karl J. Friston. Virtual reality and consciousness inference in
dreaming. FrontiersinPsychology,5,2014.
[179] G. Hinton, P Dayan, B. Frey, and R. Neal. The "wake-sleep" algorithm for unsupervised neural networks.
Science,268(5214):1158–1161,May1995.
[180] SamuelJ.GershmanandYaelNiv. Learninglatentstructure: Carvingnatureatitsjoints. CurrentOpinionin
Neurobiology,20(2):251–256,April2010.
[181] D.GowanlockR.Tervo, JoshuaB.Tenenbaum, andSamuelJ.Gershman. Towardtheneuralimplementation
ofstructurelearning. CurrentOpinioninNeurobiology,37:99–105,April2016.
[182] M. Berk Mirza, Rick A. Adams, Christoph Mathys, and Karl J. Friston. Human visual exploration reduces
uncertaintyaboutthesensedworld. PLOSONE,13(1):e0190429,05-Jan-2018.
[183] Harriet Brown, Rick A. Adams, Isabel Parees, Mark Edwards, and Karl Friston. Active inference, sensory
attenuationandillusions. CognitiveProcessing,14(4):411–427,November2013.
[184] RickA.Adams,StewartShipp,andKarlJ.Friston. Predictionsnotcommands: Activeinferenceinthemotor
system. BrainStructure&Function,218(3):611–643,May2013.
[185] KarlFriston,RickAdams,LaurentPerrinet,andMichaelBreakspear. PerceptionsasHypotheses: Saccadesas
Experiments. FrontiersinPsychology,3,2012.
[186] HarrietBrownandKarlJ.Friston. Free-EnergyandIllusions: TheCornsweetEffect. FrontiersinPsychology,
3,2012.
[187] MichaelI.Jordan,ZoubinGhahramani,andLawrenceK.Saul. HiddenMarkovDecisionTrees. 1997.
[188] DavidH.Ackley,GeoffreyE.Hinton,andTerrenceJ.Sejnowski.Alearningalgorithmforboltzmannmachines.
CognitiveScience,9(1):147–169,January1985.
[189] Ruslan Salakhutdinov and Geoffrey Hinton. An efficient learning procedure for deep Boltzmann machines.
NeuralComputation,24(8):1967–2006,August2012.
[190] K.J.Friston, L.Harrison, andW.Penny. Dynamiccausalmodelling. NeuroImage, 19(4):1273–1302, August
2003.
36

=== REVISE TO ===
PROFESSIONAL TONE: Begin directly with content - NO conversational openings like 'Okay, here's...'

1. Fix all issues above
2. Title: "Active inference on discrete state-spaces: a synthesis"
3. Include 10-15 quotes from paper text
   - Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
   - Use consistent quote formatting: 'The authors state: "quote"' or vary attribution phrases
   - Vary attribution phrases to avoid repetition
   - CRITICAL: Only extract quotes that actually appear in the paper text
4. ELIMINATE ALL REPETITION - each sentence must be unique
   - Check before each sentence: 'Have I already said this?' If yes, write something new
   - Vary attribution phrases - do NOT repeat 'The authors state' multiple times
5. Extract methodology, results with numbers, key quotes
6. 1000-1500 words, structured with ### headers

Generate COMPLETE revised summary.