=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods
Citation Key: sedlak2025multidimensional
Authors: Boris Sedlak, Alireza Furutanpey, Zihang Wang

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: services, agents, processing, agent, computing, network, edge, deep, dimensional, comparison

=== FULL PAPER TEXT ===

5202
nuJ
21
]IA.sc[
1v02401.6052:viXra
Multi-dimensional Autoscaling of Processing
Services: A Comparison of Agent-based Methods
Boris Sedlak1,∗ , Alireza Furutanpey1 , Zihang Wang1 , Víctor Casamayor
Pujol2 , and Schahram Dustdar1,2
1 Distributed Systems Group, TU Wien, Vienna, Austria.
2 DISL, ICREA | Universitat Pompeu Fabra, Barcelona, Spain
* Corresponding author contact: b.sedlak@dsg.tuwien.ac.at
Abstract. Edge computing breaks with traditional autoscaling due to
strictresourceconstraints,thus,motivatingmoreflexiblescalingbehav-
iorsusingmultipleelasticitydimensions.Thisworkintroducesanagent-
based autoscaling framework that dynamically adjusts both hardware
resources and internal service configurations to maximize requirements
fulfillmentinconstrainedenvironments.Wecomparefourtypesofscaling
agents:ActiveInference,DeepQNetwork,AnalysisofStructuralKnowl-
edge,andDeepActiveInference,usingtworeal-worldprocessingservices
runninginparallel:YOLOv8forvisualrecognitionandOpenCVforQR
code detection. Results show all agents achieve acceptable SLO perfor-
mance with varying convergence patterns. While the Deep Q Network
benefitsfrompre-training,thestructuralanalysisconvergesquickly,and
the deep active inference agent combines theoretical foundations with
practical scalability advantages. Our findings provide evidence for the
viability of multi-dimensional agent-based autoscaling for edge environ-
ments and encourage future work in this research direction.
Keywords: InternetofThings·StreamProcessing·ActiveInference
· Autoscaling · Markov Decision Processes · Reinforcement Learning
1 Introduction
The rise of Edge Computing and the Computing Continuum (CC) addresses
thelimitationsoftraditionalCloudinfrastructures[4].Bybringingcomputation
closerto usersand data sources (e.g.,IoT devices)these paradigmssignificantly
reduce network latency, critical for applications that demand near real-time re-
sponses, such as autonomous driving, e-health, and virtual reality. A common
use case, as depicted in Figure 1, could be to detect entities in a video stream
(e.g., humans) or tracking objects that have a QR code attached. By running
these inference services locally, the overall network congestion is also mitigated
by minimizing long-distance data transfers.
However,EdgeandCCenvironmentsintroducenewchallenges[1]:Theyrely
on resource-constrained computing hardware, and thus break with traditional
Cloud-based autoscaling. In Cloud systems, autoscaling mechanisms elastically
2 Sedlak et al.
respond to increased user demand by allocating more resources to a service or
replicating it. This is infeasible at the Edge or in the CC, where computing re-
sourcesarestrictlylimited[9].Especiallywhenresourcesarescarce,applications
require a more flexible scaling behavior that uses a wider range of adaptations
– hence, operating in multiple elasticity dimensions [3]. On the one hand, this
protectstheserviceexecutionandpromiseshigherrequirementsfulfillment–cap-
tured through a set of Service Level Objectives (SLOs). On the other hand, this
increases the complexity for choosing optimal scaling actions. What is needed,
hence, are lightweight multi-dimensional scaling mechanisms that optimize the
service execution without obstructing existing workloads.
To fill this gap, we propose an agent-based autoscaling approach tailored for
Edge and CC systems, which adjusts processing services in multiple elasticity
dimensions. Our approach employs decentralized local agents that (1) observe
theserviceexecutionandtheirSLOfulfillmentwithoutcentralizedcontrol;thus,
we can monitor the resource allocation per service or the application through-
put. If SLOs are violated, the agents attempt to restore the desired state by (2)
adjusting the service execution; the exact scaling policy is learned by the agent
according to environmental feedback. Notably, our approach allows scaling poli-
cies tailored to the individual services, where one service could, for example,
scale down its machine learning (ML) model, while another service claim the
remaining resources. This allows building composite and customizable scaling
policies, which go further than existing approaches [13].
Toshowtheviabilityofourapproach,weimplementfourdifferentversionsof
our general agent and compare their performance in a processing environment,
where the agent needs to dynamically scale two processing services on an Edge
device.Inparticular,wecompareanActiveInferenceagent(AIF),aDeepActive
Inference agent (DACI), a Deep Q-Network agent (DQN), and an agent using a
numerical solver – called Analysis of Structural Knowledge (ASK). During our
experiments, a scaling agent manages two physically executed services: one for
video stream inference (Figure 1a) using the well-known Yolov8 model [15], and
another for QR code reading (Figure 1b), implemented with OpenCV2 [11].
On the short term, our work provides well-needed baselines for comparing
the performance of different agent-based approaches – particularly needed for
emerging solutions. On the long term, our evaluation environment is extensible
and allows incorporating other agents. We summarize our contributions as:
1. Introducinganagent-basedautoscalingapproachwithinamulti-dimensional
elasticity space thatdynamicallymaximizeSLOfulfillmentinIoTandEdge
environments by adjusting hardware and service configurations
2. Evaluating on real-world applications of four distinct scaling agent architec-
tures (Active Inference, Deep Active Inference, Deep Q-Network, and Anal-
ysis of Structural Knowledge) for real-time service orchestration.
3. Providing a benchmarking environment for future autonomous research and
demonstrating viability through agent-based resource allocation for parallel
processing services (YOLOv8 and OpenCV) on constrained hardware.
Multi-dimensional Autoscaling of Processing Services: Agent-based Methods 3
(a)CV(Yolov8) (b)QR(OpenCV)
Fig.1: Demo output of the results produced by the two processing services
2 Preliminaries
In the following, we provide a formal description of the problem, as well as how
researchers have addressed it so far with agent-based methods – including AIF.
2.1 Problem Definition
As depicted in Figure 2, multiple services are executed within one Edge device
– sharing the device’s processing resources between them. The execution of the
individualservicesisaffectedbytheamountofresourcesallocated(e.g.,CPU,or
RAM),andtheconfigurationoftheservice-internalparameters(e.g.,inputqual-
ity, or model size). Considering that both sets of parameters can be elastically
adjusted during runtime [3], we summarize them as elastic configurations.
The allocated resources and the service configuration influence the degree
to which the service outcome satisfies the client requirements (i.e., the SLOs).
However, and this is the core of the problem, it is not a priori known what
will be the resulting SLO fulfillment for a specific configuration. Hence, the
problem boils down to adjusting the elastic configurations in such a way, that
the SLO fulfillment is maximized. While the number of service configurations
and resource allocations is limited, it is not easily possible to brute-force the
problembyexhaustivelysearchingthesolutionspace.Thereasonisthatactions
taken on the environment require a considerable amount of time to show effect.
For instance, orchestration tools like Docker and Kubernetes usually consider a
cooldown period of several minutes after taking an action.
Formal Definition More formally, the problem domain and the physical pro-
cessing environment is defined as follows:
Processing Hardware An Edgedevice d is defined by its hardware constrains H,
e.g., the physical number of CPU cores c and RAM capacity r , and the
phy phy
set of processing services S that is executed there; hence d=⟨H,S⟩.
4 Sedlak et al.
Fig.2:Servicescompeteforlimiteddeviceresources;accordingtoSLOfulfillment,the
service execution is adjusted by elastically changing device and service configurations
Processing Services Each processing service (s ∈ S) is characterized through a
service type t, a set of SLOs Q, and a service-internal configuration K; hence
s = ⟨t,Q,K,c ⟩, where a service (s) has a number of cores (c ) allocated to it,
s s
forwhichc ≤c musthold.EachSLOsq ∈Qwithq =⟨v,t⟩tracksavariable
s phy
v and reflects whether its current assignment reaches a target (t).
ServiceMonitoring TotrackthesystemstateandtheSLOfulfillment,thedevice
d and its services s ∈ S continuously monitor the execution at different levels.
This provides a set of software- or application-related metrics (M ), and a set
s
of device-related metrics (M ) that capture the hardware state.
d
SLOFulfillment Usingthesemetrics,wecalculatethecontinuousSLOfulfillment
(ϕ) for a metrics (m∈M) and an SLO q as shown in Eq. (1).
(
m if m≤t
ϕ(q,m)= tq q (1)
1.0 if m>t
q
This means, that SLOs cannot be overfulfilled; for instance, if the target is
keeping the service throughput (tp) ≥ 30, both assignments for m = 40 and
tp
m =100 achieve the maximum SLO fulfillment of ϕ=1.0.
tp
2.2 Related Work
In the following, we identify competing approaches on autoscaling that do not
use AIF, and others that use AIF agents.
Mostnotably,competingapproachesandtraditionalautoscalingmethods[17,18]
struggleinenvironments,wheremulti-dimensionaladaptationiscrucialformain-
taining service quality. In particular, RL-based systems still find no productive
use by large providers despite over a decade of research. We argue that AIF-
based agents offer a promising alternative by enabling adaptive, efficient, and
Multi-dimensional Autoscaling of Processing Services: Agent-based Methods 5
decentralized control suited to the dynamic and uncertain nature of complex
multi-tier distributed systems. Hence, our focus is on further establishing AIF
for service adaptation on resource-restricted devices.
Amongexistingworks,Sedlaketal.[14]explorehowAIFcanbeusedtoop-
timize SLO fulfillment across various use cases. Danilenka et al. [2] demonstrate
how AIF agents can adapt to dynamic and heterogenous environments. Pujol et
al. [12] adopt a representation using Partially Observable Markov Decision Pro-
cesses (POMDPs) within a multi-agent system. Lapkovskis et al. [8] presented
a comparison of AIF agents with other methods for a CC application that com-
plements our work with a different set of algorithms. Vyas et al. [16] provide an
adaptation mechanism for active sensing on Edge devices, which dynamically
adjust perception by changing the camera orientation.
3 Methodology
In this section, we first present the general design of a scaling agent that maxi-
mizestheSLOfulfillmentforasetofservicesunderlimitedprocessingresources.
Afterward, we show four approaches of how this agent can be implemented.
Namely, we present a traditional RL agent using a Deep Q-Network (DQN),
an Bayesian agent using AIF, a Deep Active Inference (DACI) agent, and an
algebraic agent based on Analysis of Structural Knowledge (ASK).
3.1 Processing Environment
To evaluate our scaling agents for a real-world problem, we need a processing
environmentinwhichtooperate.Forthis,wefirstintroducethestructureofthe
two processing services and how they are monitored during runtime. Lastly, we
introduce our training environment for pretraining some of the agents.
ProcessingServices Inthefollowing,weintroducethetwoprocessingservices
thatwillbeexecutedinparallelonanEdgedevice.Bylimitingourselvestotwo
services,wedecreasethecomplexityoftheoptimizationproblem,whileretaining
the central issue of resource limitations.
Computer Vision (CV) The CV service processes a continuous stream of video
framestoperformobjectdetectiononthem.Forthis,itusesYolov8[15],aDNN
model developed by Ultralytics; Figure 1a showcases its output.
TheservicestateforCViscomposedbyfourfeatures,asdisplayedinTable1:
quality determines the ingested video resolution, model size describes the Yolo
model(e.g.,v8norv8m),andcoresdeterminesthemaximumresourcesallocated;
throughput describes the service output in terms of frames per second.
The action state for CV is a subset of these variables – as part of the service
configuration(K),itispossibletoadjustquality andmodel size,whilecores (c )
s
is another property of the service. The exception is throughout, which cannot be
directly set, but is statistically dependent on the three other features.
6 Sedlak et al.
variable type range actionable dependent SLO target
quality int [128, 320] ✓ (step=32) — ≥288
model size int [1, 5] ✓ (step=1) — ≥3
cores float (0, 8) ✓ (no step) — —
throughput int [0, 100] — all others ≥5
Table 1: Variables of the CV service used for sensing and acting on the environment
QR Code Reader (QR) The QR service scans a continuous video stream to
detectQRcodeswithintheindividualvideoframes.Forthis,itusesthePython
wrapper of OpenCV [6]; Figure 1b showcases the service output.
The service state for QR is composed by three features, as displayed in Ta-
ble 2. The three features are defined analog to the CV service; the exception is
that QR does not use a specific model size but a fixed algorithm.
variable type range actionable dependent SLO target
quality int [300, 1000] ✓ (step=100) — ≥900
cores float (0, 8) ✓ (no step) — —
throughput int [0, 100] — all others ≥60
Table 2: Variables of the QR service used for sensing and acting on the environment
To quantify the requirements and preferences on how the services should
operate,bothTable1&2containthepreciseSLOtargets.Despitethefactthat
both services operate on a video stream, they differ greatly in their input shape
and the expected throughput. Notably, QR has a high expected throughput of
60 frames per second, while the resource-heavy CV has a target of 5.
Service Monitoring The two processing services operate in batches of 1 sec-
ond: at the beginning of each iteration, 100 frames are ingested to the service;
whentheprocessingtimeframe(i.e.,1000ms)isexceeded,theservicecountsthe
number of processed frames – the throughput. This information, together with
the service properties, is then collected in a time-series DB.
Later, when a scaling agent wants to resolve the service states, it can query
this information through the time-series DB. A key advantage of this approach,
is that it allows computing sliding-windows over monitored variables; thus, it
stabilizes an agent’s perception against temporary perturbations, like momen-
tary drops in throughput. Stable states are most relevant for evaluating SLOs
and avoiding overhasty scaling decisions, e.g., the Kubernetes HPA3 considers
per default a time window of 30min; in our case, we will stick to 5 seconds.
Training Environment Changes to the processing environment need time to
show effect. This, however, is conflictive with contemporary ML training, which
often requires thousands of iteration to converge to a policy. Hence, sample-
efficient methods, like model-based algorithms (also evaluated in this paper)
3 https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
Multi-dimensional Autoscaling of Processing Services: Agent-based Methods 7
move into focus. However, to not exclude traditional RL algorithms, like DQN,
we supply a training environment based on the Gymnasium framework4.
To estimate the state transition probabilities for state-action pairs, we use
a part of the monitored metrics to train a Linear Gaussian Bayesian Network
(LGBN); this can be seen as a simplified replication of the real processing envi-
ronment. For an assignment of free (i.e., actionable) variables, the LGBN sam-
ples the remaining variables – in this case throughput. Training on the LGBN
environment, scaling agents can infer expected state and reward of actions.
3.2 General Agent Design
To optimize SLO fulfillment, we supervise the service execution through a ded-
icated scaling agent, executed locally on the processing device. Generally, our
agent follows a simple two-step scheme in which it first resolve the states of
services and hardware, and then acts on the processing environment. To react
to dynamic runtime behavior, our scaling agents iterate in cycles of 5 seconds –
thus adhering to the sliding window for service monitoring.
Perception At the beginning of each iteration, the agent queries the service
statesthroughthetime-seriesDB(cfr.Section3.1).Next,ititeratesthroughthe
services (s∈S) and evaluates their SLO fulfillment as in Eq. (1). This indicates
the degree to which requirements are currently fulfilled.
To determine the amount of unclaimed resources, the agent then resolves
the number of cores (c ) currently assigned to the individual services5and the
s
number of free cores (c ) on the device d as in Eq. (2).
free
X
c =c − c . (2)
free phy s
s∈S
Action After resolving the environmental state, the agent adjusts the process-
ingenvironmentaccordingtoitspreferencesbychangingactionableservicevari-
ables. However, the exact policy depends on the implementation of the scaling
agent and will be explained in the next section. For example, some agents will
try solving this by training an accurate world model, e.g., the AIF agent, while
the DQN will use simplified state-action networks. Most importantly, this also
determines how the different scaling agents explore the solution space.
3.3 Scaling Agent Implementations
Inthefollowing,wedescribefourdifferentimplementationsofthegeneralscaling
agent, using different agent-based approaches. The code for the agents, as well
as for the processing services, can be found in the following repository6.
4 https://gymnasium.farama.org/api/env/
5 Internally, the services are executed in a containerized environment – Docker; the
claimedcoresperservicecanbequeriedbyouragentrunningonthesamemachine.
6 Repository with implementations for scaling agents and processing services
8 Sedlak et al.
Active Inference (AIF) The AIF agent is defined following the same idea
as in [12], which leverages pymdp [7]. Hence, we model the agent as a Markov
Decision Process and specifying the transition model using Dynamic Bayesian
Networks and Conditional Probability Tables (CPTs). In particular, the influ-
ence of actions over certain state factors, such as throughput, whose transition
dynamics are unknown, is initially defined as a uniform probability distribu-
tion within the CPTs7. These uniform priors allow the agent to learn the true
dynamics through experience and improve SLO fulfillment.
The AIF agent simultaneously controls both services, which increases its
state and action spaces. To maintain practical computational times, the agent
can choose only one action per service: modifying data quality, model size, or
number of cores. This reduces computational demands but also restricts the
agent’s capacity for more dynamic and fine-grained interventions. Additionally,
compared to the other agents in this article, the state space factors for this AIF
agent are discretized into coarser bins. While this lowers computational cost, it
results in less precise action selection and coarser estimates of SLO fulfillment.
The final state space of the agent consists of 7 factors with 3,457,440 state
combinations, and an action space of 35 different combinations.
Using this setup, the pymdp implementation (using v0.0.7.1) remained pro-
hibitivelyslow,requiringapproximately20secondsperiterationforpolicyinfer-
enceandobservationmodelconstruction.Weaddressthesebottlenecksthrough
twoalgorithmicoptimizations:(1)vectorizedpolicyevaluationeliminatesnested
loops in expected free energy calculations, and (2) sparse matrix operations re-
duce overhead in belief updating. These improvements achieved 20-30x speedup
in inference routines, leading to the performance describing in Figure 3b.
Deep Active Inference (DACI) While traditional AIF implementations us-
ing graphical models provide excellent interpretability, they are challenging to
scale,limitingtheirpracticalityinreal-worldapplicationswithhigh-dimensional
input spaces. DACI addresses scalability in the CC by exploiting the abundant
availability of hardware acceleration (e.g., TPUs, NPUs) for Artificial Neural
Networks (ANNs). This work presents preliminary results on Deep Active Infer-
encefortheCCbasedontheworkbyFountasetal[5].Thebasicideaistolearn
non-linear transforms with ANNs to map the high-dimensional input space into
a compressed latent representation of the environment. Then, the agent may
operate efficiently in complex, multi-dimensional elasticity spaces that would
be intractable for discrete graphical models. Analogous to any active inference
agent,it1)samplestheenvironmentandcalibratesitsinternalgenerativemodel
toexplainsensoryobservationsand2)performsactionstoreducetheuncertainty
about the environment. We slightly simplify and adjust the original objective in
7 The interested reader can find the matrix definition in the following directory.
Multi-dimensional Autoscaling of Processing Services: Agent-based Methods 9
[5] to compute the variational free energy for each time-step t as:
F′ = E [logP (o |s )]
t Qϕs (st) θo t t
+D [Q (s )∥P (s |s ,a )]
KL ϕs t θs t t−1 t−1
+λ ·Var[fulfillment ]
eq services
(cid:16) ucores(cid:17)2
+λ · 1−
util tcores
WehaveomittedtheKLdivergenceinvolvingthehabitualnetworkandincluded
regularization terms to reduce the variance between service fulfillments and en-
courageresourceutilization.Ourintuitionistoregularizetheterm−E[logP(o |π)]
τ
that represents preferences about future observations by encoding the specifica-
tionforbalancedservicesandresourceefficiencytohaveahigherpriorprobabil-
ity. Lastly, we encode the objective to prioritize actions that reduce uncertainty
abouttheenvironmentbyminimizingtheEFEwithanexpressionthatisequiv-
alent to that in the original work [5].
Deep Q Networks (DQN) The DQN [10] agent approximates Q-values for
state-action pairs in the multi-dimensional autoscaling problem. We implement
separateDQNmodelsforeachprocessingservice(CVandQR),allowingservice-
specific policy learning while maintaining coordinated resource allocation when
competingforlimitedresources.Themodelsaretrainedjointlywithintheshared
processing environment to benefit from the pre-training in the simulated LGBN
environment,resultingintheDQNagentachievingstableperformancefromthe
initial deployment phase.
Analysis of Structural Knowledge (ASK) This agent solves the orchestra-
tionproblemthroughnumericaloptimization,usingSLSQP.Forthis,itconsider
the variables and their parameter boundaries from Table 1 & 2, the objective
function ϕ for calculating the SLO fulfillment of a parameter assignment, and
the SLOs (Q). Given that, it misses a continuous function that allows descend-
ing to the optimal solution. In a nutshell: how to estimate throughput, given the
assignments of all bounded parameters – including continuous-scale cores?
We address this, similarly to the LGBN training environment, through a
regression model that captures the dependencies between service variables (K)
and the allocated cores (c ). As the agent captures more metrics, the accuracy
k
of the regression and the inferred parameter assignment improves. To create an
accurate model, the ASK agent needs an initial exploration time (i.e., 20 itera-
tions in the experiments), during which the parameters are assigned randomly.
After this time, the ASK is ready for the numerical optimization.
For our two service s and s and all their variables x∈{K ∪c }, the ASK
1 2 s s
agent infers assignments that maximize the SLO fulfillment as in Eq. (3).
X X
max ϕ (x) subject to c ≤c , x ∈[xmin,xmax] (3)
s s phy i i i
x
s∈S s∈S
10 Sedlak et al.
Thispresentsacoupleofadvantages:First,thecontinuousactionspaceallows
agents to infer fine-grained elasticity strategies; in particular cores can be split
precisely between the devices. Also, it is possible to infer assignments for all
services and all their elasticity parameters in one operation.
4 Evaluation
4.1 Experimental Design
Toanalyzetheperformanceofthedifferentscalingagentsweevaluatethem,one
after the other, in the processing environment (i.e., the two processing services
executed in parallel). In each experiment we capture the following performance
metrics: (1) SLO fulfillment, as the average over the two services, and (2) com-
plexity of inference, as the duration for running one inference cycle.
Each experiment contains 50 iterations within the processing environment,
i.e., 50 times that the agent interacts with the environment by sensing its state
andactingonit.AsdescribedinSection3.2,theagentsoperatewithafrequency
of 5 seconds – every 5 seconds they orchestrate the services according to the
inferred policy. Thus, individual experiments take 5 × 50 = 250 seconds. To
stabilize the empirical results, we repeat each experiment 10 times.
During the experiments, agents must achieve the SLO targets specified in
Table1&2.TofulfilltheseSLOs,anagentneedstooptimallyadjusttheservices
and split the resources – in this case 8 physical cores (i.e., c =8).
phy
4.2 Experimental Results
Figure3ashowstheSLOfulfillmentrateofallagentsoverthe50stepsoftheex-
periment. The ASK agent requires approximately 20 iterations to train and sta-
bilize, reaching an average SLO fulfillment rate of 0.868 over the final 10 steps.
In contrast, the DQN agent, having been pre-trained in the simulation environ-
ment,maintainsstableperformancethroughouttheexperimentandachievesan
average of 0.753 in the last 10 iterations. Regarding the active inference-based
methods, the AIF agent takes around 10 steps to stabilize its performance, ul-
timately reaching an average fulfillment rate of 0.704 during the final 10 steps.
Lastly, although the DACI agent exhibits steady improvement, it only achieves
an average SLO fulfillment rate of 0.724 by the end of the experiment.
Intermsofcomputationalspeed(Figure3b)thereisaconsiderabledifference
between the agents – note that the y-axis is plotted in log10 scale. The DQN
agent remains the fastest with a mean of 60 milliseconds, benefiting from ma-
tureneuralnetworkoptimizations.OuroptimizedAIFagentachievesanaverage
timeof 1.7seconds,demonstratingsubstantialimprovementthroughvectorized
inference over the original implementation with roughly 20 seconds. The DACI
and ASK agents exhibit execution times of 2.8 seconds and 1.2 seconds re-
spectively, highlighting the computational trade-offs inherent in their respective
approaches. When merely exploring (expl) the ASK agent also took less time
Multi-dimensional Autoscaling of Processing Services: Agent-based Methods 11
(a)SLOfulfillmentofdifferentagents (b)Durationofcycles(log10)inmilliseconds
Fig.3:Scalingagentsoperatingontheprocessingenvironmentfor50iterations(=250
seconds); 10 experiment repetitions per agent type to stabilize results
than during the actual numerical inference (inf). Notably, all agents (incl. the
AIF) now operate within practical time constraints for the 5-second scaling in-
terval, enabling real-time performance comparison across all four methods.
5 Conclusion & Future Work
This article highlights a key need for orchestration under resource limitations:
multi-dimensionalelasticity.Byoptimizingresourceallocationandfindingqual-
ity trade-offs, it supports flexible scaling behavior that improve Service Level
Objectives (SLOs). To show the capabilities of different learning methods for
solving such problems, we developed a real-world processing environment where
twoservicescompeteforresources.Wecomparedfourdifferentagents:anActive
Inference (AIF) agent using pymdp, a Deep Q-Network (DQN), a Deep Active
Inference (DACI) agent, and an agent using Analysis of Structural Knowledge
(ASK). Our evaluation shows that ASK achieved the highest SLO fulfillment
(0.87),withAIF,DQNandDACIroughlytakingthesecondspottogether;AIF
and ASK, which learn online, took about 10 and 20 rounds to converge respec-
tively. In terms of execution time, agents must infer a scaling policy in less than
5 seconds – our orchestration interval. Our optimized AIF agent achieved an
average of 1.7 seconds per iteration, showcasing our improvement of the pymdp
library. However, it was the DQN agent that excelled with an average execution
under60ms.WhileDACIexhibitedthelongestexecutiontime,itisarguablythe
most promising approach as it combines theoretical foundations with practical
scalability, which are a necessity in large-scale distributed systems.
We emphasize that we only present early-stage results. Besides further im-
provementstotheneuralarchitectureandtheobjective,carefultheoreticalanal-
ysis,extensiveexperimentation,andoptimizationsthatcanexploitparallelpro-
cessing are works in progress. Moreover, future work will refine agents for dis-
tributed settings, explore service-hardware interaction, and develop tools for
easierconfiguration andorchestration. We also planto extendthe frameworkto
support a broader set of real-world use cases.
12 Sedlak et al.
References
1. Casamayor-Pujol, V., Morichetta, A., Murturi, I., Donta, P.K., Dustdar, S.: Fun-
damental Research Challenges for Distributed Computing Continuum Systems.
Information 14, 198 (Mar 2023). https://doi.org/10.3390/info14030198
2. Danilenka,A.,Furutanpey,A.,Pujol,V.C.,Sedlak,B.,Lackinger,A.,Ganzha,M.,
Paprzycki, M., Dustdar, S.: Adaptive Active Inference Agents for Heterogeneous
and Lifelong Federated Learning (Oct 2024)
3. Dustdar, S., Guo, Y., Satzger, B., Truong, H.L.: Principles of Elastic Processes.
Internet Computing, IEEE 15, 66–71 (Nov 2011)
4. Dustdar,S.,Pujol,V.C.,Donta,P.K.:OnDistributedComputingContinuumSys-
tems. IEEE Transactions on Knowledge and Data Engineering 35(4), 4092–4105
(Apr 2023). https://doi.org/10.1109/TKDE.2022.3142856
5. Fountas, Z., Sajid, N., Mediano, P., Friston, K.: Deep active inference agents us-
ing monte-carlo methods. Advances in neural information processing systems 33,
11662–11675 (2020)
6. Heinisuo, O.P.: opencv-python: Wrapper package for OpenCV python bindings.
(2021), https://github.com/skvark/opencv-python
7. Heins, C., Millidge, B., Demekas, D., Klein, B., Friston, K., Couzin, I., Tschantz,
A.: pymdp: A Python library for active inference in discrete state spaces. Journal
of Open Source Software (May 2022)
8. Lapkovskis,A.,Sedlak,B.,Magnússon,S.,Dustdar,S.,Donta,P.K.:Benchmarking
Dynamic SLO Compliance in Distributed Computing Continuum Systems (Mar
2025). https://doi.org/10.48550/arXiv.2503.03274
9. Manaouil,K.,Lebre,A.:KubernetesandtheEdge?report,InriaRennes-Bretagne
Atlantique (Oct 2020), https://inria.hal.science/hal-02972686
10. Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D.,
Riedmiller, M.: Playing atari with deep reinforcement learning (2013)
11. opencv: opencv at 4.9.0 (2024), https://github.com/opencv/opencv/tree/4.9.0
12. Pujol, V.C., Sedlak, B., Salvatori, T., Friston, K., Dustdar, S.: Distributed Intel-
ligence in the Computing Continuum with Active Inference (May 2025). https:
//doi.org/10.48550/arXiv.2505.24618
13. Sedlak, B., Morichetta, A., Raith, P., Pujol, V.C., Dustdar, S.: Towards Multi-
dimensionalElasticityforPervasiveStreamProcessingServices.In:2025IEEEIn-
ternational Conference on Pervasive Computing and Communications Workshops
and other Affiliated Events (PerCom Workshops) (2025)
14. Sedlak, B., Pujol, V.C., Donta, P.K., Dustdar, S.: Equilibrium in the Computing
Continuum through Active Inference. Future Generation Computer System 160,
92–108 (2024). https://doi.org/10.1016/j.future.2024.05.056
15. Varghese, R., M., S.: YOLOv8: A Novel Object Detection Algorithm with En-
hanced Performance and Robustness. In: ADICS (2024)
16. Vyas,D.,Prado,M.d.,Verbelen,T.:Towardssmartandadaptiveagentsforactive
sensing on edge devices (Jan 2025). https://doi.org/10.48550/arXiv.2501.06262
17. Wang, Z., Li, P., Liang, C.J.M., Wu, F., Yan, F.Y.: Autothrottle: A Practical Bi-
Level Approach to Resource Management for SLO-Targeted Microservices (2024)
18. Zhao,Y.,Uta,A.:TinyAutoscalersforTinyWorkloads:DynamicCPUAllocation
for Serverless Functions. IEEE Comp. Society (2022). https://doi.org/10.1109/
CCGrid54584.2022.00026

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
