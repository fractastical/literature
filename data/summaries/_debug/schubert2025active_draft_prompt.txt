=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions
Citation Key: schubert2025active
Authors: Johan Schubert, Farzad Kamrani, Tove Gustavi

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: probability, energy, intelligent, autonomous, agents, target, evidence, inference, reconnaissance, active

=== FULL PAPER TEXT ===

Active Inference for an Intelligent Agent in Autonomous
Reconnaissance Missions
Johan Schubert[0000-0002-0262-9908], Farzad Kamrani[0000-0001-9448-6803],
Tove Gustavi[0009-0003-1886-9265]
Swedish Defence Research Agency, SE-164 90 Stockholm, Sweden
{johan.schubert,farzad.kamrani,tove.gustavi}@foi.se
Abstractâ€”We develop an active inference route-planning method for the au-
tonomous control of intelligent agents. The aim is to reconnoiter a geographical
area to maintain a common operational picture. To achieve this, we construct an
evidence map that reflects our current understanding of the situation, incorporat-
ing both positive and â€œnegativeâ€ sensor observations of possible target objects
collected over time, and diffusing the evidence across the map as time progresses.
The generative model of active inference uses Dempster-Shafer theory and a
Gaussian sensor model, which provides input to the agent. The generative process
employs a Bayesian approach to update a posterior probability distribution. We
calculate the variational free energy for all positions within the area by assessing
the divergence between a pignistic probability distribution of the evidence map
and a posterior probability distribution of a target object based on the observa-
tions, including the level of surprise associated with receiving new observations.
Using the free energy, we direct the agentsâ€™ movements in a simulation by taking
an incremental step toward a position that minimizes the free energy. This ap-
proach addresses the challenge of exploration and exploitation, allowing agents
to balance searching extensive areas of the geographical map while tracking iden-
tified target objects.
Keywordsâ€”active inference, free energy principle, autonomous agents.
1 Introduction
This paper focuses on active inference [1, 2] for the autonomous control of an intelli-
gent agent (e.g., a reconnaissance Unmanned Aerial Vehicle (UAV)) aimed at achiev-
ing and maintaining the best possible situational awareness over time. Active inference
is a methodology for autonomous decision-making. This methodology is generic and
based on the concept that a system aims to minimize its surprise when receiving new
information. What is unique about active inference is that the method includes two par-
allel approaches for an agent to seek consistency between reality and the systemâ€™s de-
scription of the environment: either the systemâ€™s internal representation is updated as
new information is received, or actions are taken against the environment to change it
so that it is consistent with its perception.
Presented at the 6th International Workshop on Active Inference, 15â€“17 October 2025, Montreal,
Canada.
2 J. Schubert, F. Kamrani, and T. Gustavi
Minimizing surprise is inherently impossible. Instead, we aim for the best possible
action by choosing the one that minimizes free energy. Free energy is an information
theory concept that refers to the divergence between two probability distributions and
the element of surprise. One distribution reflects our perception of reality, often de-
scribed as a dynamic common operational picture, while the other is the probability
after a current observation. When these two distributions align closely, the free energy
is low. In active inference, the agent seeks to position itself so that its observations
correspond with its reality model.
Section 2 formulates the problem statement. Section 3 shows related works. Section
4 introduces the fundamentals of active inference and free energy. Section 5 provides a
brief overview of Dempster-Shafer theory, which updates the dynamic common oper-
ational picture. Section 6 describes the simulation environment and sensor model. In
Section 7, we mathematically describe how to control an agent using active inference
by minimizing free energy. Section 8 offers an overview of the implementation, and
finally, Section 9 presents the conclusions drawn from this work.
2 Problem Statement and Persistent Surveillance
2.1 Problem Statement
In the field of autonomous systems, the task of continuously monitoring a specific area
over an indefinite period is referred to as persistent surveillance. Real-world applica-
tions for persistent surveillance systems include surveillance of areas around critical
infrastructure and military facilities to detect potential intruders with malicious intent.
It can also be used for surveillance at popular beaches to prevent drowning incidents
and for monitoring wildlife in sensitive natural areas for preservation purposes. UAVs
are particularly well-suited for this type of surveillance task due to their wide-angle
views, speed, and the relative absence of obstacles in their operational environments,
which facilitates trajectory planning for the autonomous agents.
In this paper, we consider a scenario in which an autonomous agent is assigned the
task of continuously monitoring a designated area to maintain an accurate and up-to-
date dynamic common operational picture. The agent must be capable of detecting both
fixed and moving targets and should ideally be able to keep track of the approximate
locations of these targets, even when they are out of sensor range. Moving targets must
therefore be revisited as often as necessary to prevent losing track of them. Addition-
ally, it is requested that no part of the designated area should be left unobserved for
more than a specified time.
In persistent surveillance scenarios, the trajectory planning problem for autonomous
agents is usually defined by a set of specific goals and constraints, which may have
different priorities. Various methods can be employed to implement the actual trajec-
tory planning or motion control (as discussed in Section 7). This paper specifically aims
to investigate the feasibility of using active inference for trajectory planning and gen-
eration. The primary research question addressed in this paper can be formulated as
follows:
Active Inference for an Intelligent Agent 3
Can active inference be used to solve the motion control problem for a single UAV
conducting multi-objective persistent surveillance over a predefined 2D area?
2.2 An Active Inference Approach to Persistent Surveillance
To effectively implement the active inference framework for motion control in a per-
sistent surveillance context, several key components must be defined.
A generative model describes all possible states and their transitions to address these
considerations. Information about these states is derived from observations made over
time, allowing us to update our understanding of the current state. We express uncer-
tainty in the model using Dempster-Shafer theory [3, 4]. In this model, the states are
represented stochastically; each possible transition of target basic belief from one state
(e.g., position) to the next is specified by transition probabilities. The states are dynam-
ically updated at each time step using a diffusion algorithm. This model indicates the
current basic belief of the existence of at least one target object within each possible
state (see Section 7.1).
A generative process complements the generative model by managing new observa-
tions made with the agentâ€™s sensor. In the generative process, we use a Bayesian ap-
proach. This process updates the probabilities of all positions within the agentâ€™s sensor
radius. This update calculates a new probability for each position based on the current
sensor model while considering the existing probabilities (see Section 7.2).
Since we cannot directly minimize the surprise an agent experiences when receiving
new observations, we focus on minimizing the free energy, which serves as an upper
bound for that surprise. The free energy is defined as the sum of the divergence between
two probability distributions and the level of surprise, and is our objective function to
direct the agentsâ€™ movements. For each location within the sensor radius, we compare
the probability obtained from the generative model with the probability derived from
observations, striving to minimize the divergence between the two (see Section 7.3).
At each time step, we calculate the free energy for all locations within the sensorâ€™s
radius. The agent then takes a fixed-length step in the direction that minimizes free
energy. This approach enables the agent to control itself autonomously, ensuring it
achieves the best possible common operational picture. The agentâ€™s control is modeled
by a Multi-Agent Dynamic Simulator (MADS) developed in-house.
3 Related Works
3.1 Persistent Surveillance and Motion Control
Over the years, different methods for addressing the control problem in persistent sur-
veillance (also referred to as persistent monitoring) have been proposed. This section
briefly describes some examples.
Hari et al. [5] examine a persistent monitoring mission for a single UAV, tasked with
repeatedly visiting n targets of equal priority. Since the targets are fixed, the problem
simplifies to a classic traveling salesman problem. Brown and Anderson [6] explore a
4 J. Schubert, F. Kamrani, and T. Gustavi
more complex maritime surveillance scenario that includes constraints on UAV dynam-
ics and formulate a multi-objective optimization problem aimed at maximizing infor-
mation gain and minimizing fuel consumption. Feasible and optimal solutions are found
using a trajectory generation method combined with a particle swarm optimization al-
gorithm. Similar to the problem discussed here (in this paper), HÃ¼bel et al. [7] introduce
a dynamic â€œinformation mapâ€ subject to information decay and use it to derive a gradi-
ent-based control that drives a group of agents to continuously update their situational
awareness by surveilling an area. Additionally, the authors propose a time-varying den-
sity function that can be integrated into the control algorithm to model moving points
of interest. Another approach to increase the probability of autonomous agents observ-
ing moving targets during surveillance missions was proposed by Ramasamy and
Ghose [8]. Assuming that the probability of observing a target is non-uniformly distrib-
uted across a monitored area, Ramasamy and Ghose assign an â€œimportanceâ€ degree to
each grid point in a discretized map where the UAV in the scenario has detected a
target. The importance of a grid point depends on the number of detections made there
and increases the chances of the UAV revisiting that location. Lastly, there is additional
work documented in the literature that employs reinforcement learning for persistent
surveillance control. Chen et al. [9] use a multi-agent reinforcement learning approach
to learn policies for each agent in a team, tasked with continuously monitoring a 2D
environment with stationary obstacles. To accomplish this, the problem is modeled so
that a penalty is applied at every time step if a point in the environment is left unmoni-
tored. Mishra et al. [10] present another example of a reinforcement-learning-based
method for persistent surveillance.
3.2 Active Inference for Estimation and Control
Active inference connects perception and action through variational free energy. The-
oretical links to classical estimation and control show that minimizing variational free
energy yields objectives that combine information-theoretic surprise with control costs,
leading to linear-quadratic-Gaussian behavior in linear-Gaussian environments [11]. In
practical terms, active inference has been employed for state estimation of a quadcopter
using dynamic expectation maximization (DEM). DEM is a perception scheme inspired
by the brain, based on a data-driven model-learning algorithm [12]. Additionally, active
inference has been used for adaptive manipulation control in the absence of detailed
environment models in industrial robots. This method has proven to be scalable even
when the dynamics of the environment are not explicitly modeled [13]. Active infer-
ence has also been applied to the adaptive control of robot arms using multimodal per-
ception-action and variational autoencoder (VAE)-based state representations. This ap-
proach does not require a dynamic or kinematic model of the robot [14]. Furthermore,
active inference has been used to develop a torque controller that integrates raw vision
and proprioception in a streamlined design for a 7-degrees-of-freedom Franka Emika
Panda robot, capable of online adaptation to changes in dynamics and human interfer-
ence [15]. It has also been employed for fault-tolerant control under sensor faults, de-
livering unbiased state estimation and simplifying action specification [16]. These re-
sults support our use of free energy for closed-loop control with a soft sensor model.
Active Inference for an Intelligent Agent 5
3.3 Active Inference for Navigation, Exploration, and Bandit Problems
For mobile agents, active inference under hierarchical generative models enables
goalâ€‘oriented navigation with topologically consistent maps and practical robot deploy-
ments [17]. Modular active inference systems support flexible, goal-driven navigation,
avoiding obstacles and choosing high-confidence paths with strong zero-shot generali-
zation to new settings [18]. Curiosity-driven learning for robotic tasks, using the free
energy principle, employs Bayesian neural networks to represent epistemic uncertainty
and model complex behaviors [19]. Moreover, retrospective (residual) surprise has
been introduced as a computational element in active inference, serving as a lower
bound on the expected free energy [20]. In decision-making, contextual multi-armed
bandits (CMABs) extend the classical bandit problem by conditioning action selection
on observed contextual information. Recent active inference models of CMABs
[21, 22] use expected free energy to guide context-based action selection, balancing
exploration and exploitation under uncertaintyâ€”an effect we replicate in our approach
through minimizing a spatial free-energy field over the evidence map.
3.4 Multi-agent Active Inference, Organizational Adaptation, and Complex
Tasks
In multi-agent settings, active inference is used to design adaptive organizations, where
roles and structures change by minimizing team-level free energy [23â€“25]. For complex
robotic tasks, active inference combines with behavior trees to enable continuous plan-
ning and robust execution with fewer nodes [26]. Meanwhile, non-modular, cognitively
inspired active inference architectures are explored for robustness against unknown in-
puts [27]. Recent work extends active inference to autonomous driving by incorporat-
ing action-oriented priors that link perception and control, leading to more human-like,
collision-avoidant behavior [28]. In socially interactive and multi-agent scenarios, ac-
tive inference applies to human-robot kinesthetic interaction, where meta-priors adjust
compliance and counter-forces during physical contact [29], and to empathic, socially
compliant agents that adapt their movements to surrounding individuals and contextual
norms [30], demonstrating the flexibility of the free-energy framework for coordination
and interaction tasks. Active inference also applies to hierarchical, embodied percep-
tion-action loops, where multiple sensorimotor pathways associated with different body
parts are dynamically combined, enabling the robot to reconfigure control and activate
only the necessary joints for a given task [31]. Our method differs by operationalizing
free energy over a spatial Dempster-Shafer evidence map and a deterministic soft sen-
sor model, then guiding the agent to move in the direction that minimizes this per-cell
objective at each step.
3.5 Our Contribution
Compared to surveillance controllers [5â€“10], we introduce a Dempster-Shafer-based
evidence map with diffusion and a deterministic soft-output sensor model to generate
cell-wise evidential scores. Then, we steer the platform by minimizing a grid-based
6 J. Schubert, F. Kamrani, and T. Gustavi
free-energy objective that compares a pignistic distribution [32] to a posterior derived
from the latest observation, including observation surprisal. Compared to active infer-
ence controllers and expected free energy-planning methods [13â€“31], our contribution
is a computationally lightweight free-energy minimization over the grid map that (i)
separates observation and state evidence, (ii) avoids Monte Carlo sampling by using
deterministic soft observations, and (iii) provides an effective exploration-exploitation
balance for persistent reconnaissance.
4 Active Inference and Free Energy
The generative model and the generative process are stochastic in nature. Let the out-
come space over all possible states be Î˜=(cid:4668)ğ‘‡,ğ¹(cid:4669), where ğ‘‡ denotes the presence of at
least one target object, and ğ¹ represents the absence of a target object.
4.1 The Generative Model
The generative model outlines all possible states and transitions [1, 2]. In this context,
the states are represented by grid cells, indicating all possible positions on a map. The
agent and the target objects can transition between states, moving from any grid cell to
its nearest neighboring cells.
The probability in the generative model is denoted by ğ‘(cid:3047) (cid:4666)ğœ—(cid:4667), where ğœ— is the state
(cid:3051)(cid:3052)
and ğ‘(cid:3047) is the probability for a grid cell ğ‘ at time ğ‘¡. In each grid cell, we have
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
ğ‘(cid:3047) (cid:4666)ğœ—=ğ‘‡(cid:4667)+ğ‘(cid:3047) (cid:4666)ğœ—=ğ¹(cid:4667)=1. (cid:4666)1(cid:4667)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
We determine the probabilities ğ‘(cid:3047) for all grid cells ğ‘ in our stochastic common op-
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
erational picture based on all observations gathered throughout the scenario. These ob-
servations form our understanding of the situation. More about how ğ‘(cid:3047) is calculated
(cid:3051)(cid:3052)
when scouting with an agent can be found in Chapter 4.
4.2 The Generative Process
In the generative process, we handle new observations. At each time step, we have an
incoming a priori probability ğ‘(cid:3047) (cid:4666)ğœ—(cid:4667). This probability is equal to the posterior proba-
(cid:3051)(cid:3052)
bility at the previous time step.
We set
ğ‘(cid:3047) (cid:4666)ğœ—(cid:4667)=ğ‘(cid:3047)(cid:2879)(cid:2869)(cid:4666)ğœ—|ğœ‘(cid:4667). (cid:4666)2(cid:4667)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
In addition, we initialize the a priori probability for time 0 according to
ğ‘(cid:2868) (cid:4666)ğœ—(cid:4667)=ğœ€. (cid:4666)3(cid:4667)
(cid:3051)(cid:3052)
Using Bayes theorem, we can calculate the posterior probability ğ‘(cid:3047) (cid:4666)ğœ—|ğœ‘(cid:4667) in the grid
(cid:3051)(cid:3052)
cell ğ‘ for the current time step ğ‘¡ based on the a priori probability.
(cid:3051)(cid:3052)
Active Inference for an Intelligent Agent 7
We have
ğ‘(cid:3047) (cid:4666)ğœ‘|ğœ—(cid:4667)
ğ‘(cid:3047) (cid:4666)ğœ—|ğœ‘(cid:4667)= (cid:3051)(cid:3052) ğ‘(cid:3047) (cid:4666)ğœ—(cid:4667), (cid:4666)4(cid:4667)
(cid:3051)(cid:3052) ğ‘(cid:3047) (cid:4666)ğœ‘(cid:4667) (cid:3051)(cid:3052)
(cid:3051)(cid:3052)
where ğ‘(cid:3047) (cid:4666)ğœ‘|ğœ—(cid:4667) represents the likelihood, which indicates the detection probability for
(cid:3051)(cid:3052)
an observation ğœ‘=ğ‘‡, as determined by the sensor model, when we have a target object
ğœ— =ğ‘‡ in the grid cell ğ‘ at time ğ‘¡. In this context, ğ‘(cid:3047) (cid:4666)ğœ‘(cid:4667) represents the probability
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
of obtaining an observation. The probability can be calculated according to
ğ‘(cid:3047) (cid:4666)ğœ‘(cid:4667)= ğ‘(cid:3047) (cid:4666)ğœ‘|ğœ— =ğ‘‡(cid:4667)âˆ™ğ‘(cid:3047) (cid:4666)ğœ— =ğ‘‡(cid:4667)+ğ‘(cid:3047) (cid:4666)ğœ‘|ğœ— =ğ¹(cid:4667)âˆ™ğ‘(cid:3047) (cid:4666)ğœ— =ğ¹(cid:4667), (5)
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
where ğ‘(cid:3047) (ğœ— =ğ‘‡) denotes the a priori probability discussed earlier, and
(cid:3051)(cid:3052)
ğ‘(cid:3047) (ğœ— =ğ¹)=1âˆ’ğ‘(cid:3047) (ğœ— =ğ‘‡). (6)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
Additionally, ğ‘(cid:3047) (ğœ‘|ğœ— =ğ‘‡) represents the likelihood, which is the detection probabil-
(cid:3051)(cid:3052)
ity of the sensor model, with
ğ‘(cid:3047) (ğœ‘|ğœ—=ğ¹)=1âˆ’ğ‘(cid:3047) (ğœ‘|ğœ— =ğ‘‡). (7)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
4.3 The Free Energy
Based on the generative modelâ€™s ğ‘(cid:3047) (ğœ—) and the generative processâ€™s ğ‘(cid:3047) (ğœ—|ğœ‘), we
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
can now calculate the free energy ğ¹(cid:3047) for all grid cells ğ‘ at time ğ‘¡.
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
We have
ğ¹(cid:3047) =ğ· (cid:3427)ğ‘(cid:3047) (ğœ—)âˆ¥ğ‘(cid:3047) (ğœ—|ğœ‘)(cid:3431)âˆ’ğ‘™ğ‘›(cid:3427)ğ‘(cid:3047) (ğœ‘)(cid:3431)
(cid:3051)(cid:3052) (cid:3012)(cid:3013) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
ğ‘(cid:3047) (ğœ—)
=(cid:3429) (cid:3533) ğ‘(cid:3047) (ğœ—)âˆ™ğ‘™ğ‘›(cid:4678) (cid:3051)(cid:3052) (cid:4679)(cid:3433)âˆ’ğ‘™ğ‘›(cid:3427)ğ‘(cid:3047) (ğœ‘)(cid:3431) (8)
(cid:3051)(cid:3052) ğ‘(cid:3047) (ğœ—|ğœ‘) (cid:3051)(cid:3052)
(cid:3051)(cid:3052)
(cid:3107)âˆˆ(cid:4668)(cid:3021),(cid:3007)(cid:4669)
here ğ· is the Kullback-Leibler divergence [33]. The term âˆ’ğ‘™ğ‘›(cid:3427)ğ‘(cid:3047) (ğœ‘)(cid:3431) represents
(cid:3012)(cid:3013) (cid:3051)(cid:3052)
the degree of surprise from an observation, ğ‘(cid:3047) (ğœ—) is the probability according to the
(cid:3051)(cid:3052)
generative model, and ğ‘(cid:3047) (ğœ—|ğœ‘) is the posterior probability according to the generative
(cid:3051)(cid:3052)
process, calculated at each time point based on Bayes theorem. Finally, ğ‘(cid:3047) (ğœ‘) is the
(cid:3051)(cid:3052)
probability of an observation as derived in equation (5).
In active inference, the action that minimizes ğ¹(cid:3047) is chosen. This action may involve
(cid:3051)(cid:3052)
moving to ğ‘ or in its direction.
(cid:3051)(cid:3052)
5 Dempster-Shafer Theory
In Dempster-Shafer theory [3, 4], belief is assigned to a proposition through a basic
belief assignment. The proposition is represented by a subset ğ´ of an exhaustive set of
mutually exclusive possibilities, referred to as a sample space Î˜.
8 J. Schubert, F. Kamrani, and T. Gustavi
The basic belief function ğ‘š is defined as a function from the power set of Î˜ to the
interval (cid:4670)0,1(cid:4671)
ğ‘š:2(cid:2944) â†’(cid:4670)0,1(cid:4671) (9)
where ğ‘š(âˆ…)=0 and
(cid:3533)ğ‘š(ğ´)=1. (10)
(cid:3002)âŠ†(cid:2944)
Here, ğ‘š(ğ´) represents the basic belief assigned to ğ´.
If we receive additional information about the same hypothesis from a different
source, we combine the two basic belief functions to create a more comprehensive un-
derstanding. This is achieved by computing the orthogonal combination using Demp-
sterâ€™s rule. Let ğµ be a subset of ğ‘š and ğ¶ be a subset of ğ‘š . The combination of ğ‘š
(cid:2869) (cid:2870) (cid:2869)
and ğ‘š results in a new basic belief function ğ‘š âŠ•ğ‘š where
(cid:2870) (cid:2869) (cid:2870)
ğ‘š âŠ•ğ‘š (ğ´)=ğ¾âˆ™ (cid:3533) ğ‘š(ğµ)âˆ™ğ‘š(ğ¶), (11)
(cid:2869) (cid:2870)
(cid:3003)â‹‚(cid:3004)(cid:2880)(cid:3002)
where ğ¾ is a normalization constant.
6 Simulation Environment and Sensor Model
6.1 Simulation Environment
The world is represented as a 2D map of a designated reconnaissance area. This map is
divided into a grid of ğ‘šÃ—ğ‘› square cells indexed based on a coordinate system. Using
a 2D representation is a deliberate simplification justified by the fact that the scenario
being examined is much larger in its x and y dimensions compared to any variation in
its z dimension. Although the simulator can perform 3D movements, this feature was
disabled during the simulations conducted. The positions of both the agent and any
target objects are indicated using cell indices in the format ğ‘ , where ğ‘¥ and ğ‘¦ are inte-
(cid:3051)(cid:3052)
gers. Each cell is assumed to be large enough to contain the agent or a target object
within the reconnaissance area.
We conduct experiments using active inference for UAV control in MATLAB. The
previously mentioned 2D map is the foundation for the generative model describing the
environment. The simulation environment includes both fixed and moving target ob-
jects. Two predefined movement patterns are available for the moving target objects:
stationary (no movement) or movement along a straight line.
We represent uncertainty in the model using Dempster-Shafer theory [3, 4]. This
uncertainty, at the mapâ€™s cell level, provides two evidence-based likelihood values. The
first is a basic belief, denoted as ğ‘š(cid:3047) (ğœ—=ğ‘‡), which ranges from 0 to 1. It represents
(cid:3051)(cid:3052)
the basic belief at time t that the cell ğ‘ contains at least one target object. The second
(cid:3051)(cid:3052)
is an estimated likelihood value, also between 0 and 1, denoted as ğ‘š(cid:3047) (ğœ—=ğ¹). This
(cid:3051)(cid:3052)
Active Inference for an Intelligent Agent 9
indicates the basic belief that, at time t, the cell does not contain any target objects. The
formulas for diffusing basic belief to neighboring cells in the generative model are de-
signed to be independent of the gridâ€™s topology. For example, moving from a square
grid topology, used in this experiment, to a hexagonal topology only requires changing
the parameter N, which represents the number of neighboring cells in equations (12)
and (13) (see Section 7.1). This change adjusts N from eight to six.
6.2 Sensor Model
The sensor model serves as an intelligent image sensor designed for ground scouting.
Its detection radius lets it reliably identify and classify objects as targets or non-targets.
Each time an object is positively classified as a target, the method also provides a quan-
titative estimate, denoted as ğ‘š(cid:3047) (ğœ—=ğ‘‡), representing the basic belief that this classi-
(cid:3051)(cid:3052)
fication is correct. If an object is identified as a target, the sensor calculates an estimate
of its coordinates on a 2D map.
Since the sensor does not actively monitor or classify the absence of targets within
the search area, it is more challenging to quantify evidence for this condition. If an area
has been scanned without identified targets, it suggests no targets are present. In loca-
tions where no targets are detected, the sensor provides a default estimate, denoted as
ğ‘š(cid:3047) (ğœ—=ğ¹), for the basic belief of target absence. The terrain in the area can influence
(cid:3051)(cid:3052)
this estimate; for instance, the likelihood of detecting targets is generally lower in for-
ests compared to open fields.
We implement a simplified version of the sensor model used in the simulations to
mimic its behavior as described above. The detection probability for target objects is
set to 1, meaning that all target objects are detected. However, the probability that a
detected target object is correctly classified is set to 0.7. Additionally, we assume the
sensor does not generate false detections of target objects. Therefore, the uncertainties
in the simulated sensor output arise exclusively from the classification process.
The implementation is based on the premise that a real sensorâ€™s ability to classify
target objects primarily depends on the distance between the sensor and the potential
target object. The sensor operates most reliably when it is focused on objects directly
beneath the agent to which it is mounted. Consequently, the sensorâ€™s capability to de-
termine whether an area is free of target objects is expected to decline as the distance
from the sensor increases. In the implementation, the default values of ğ‘š(cid:3047) (ğœ— =ğ‘‡)=
(cid:3051)(cid:3052)
0.7 and ğ‘š(cid:3047) (ğœ—=ğ¹)=0.3 are applied. These values correspond to the maximum ex-
(cid:3051)(cid:3052)
pected levels of ğ‘š(cid:3047) (ğœ— =ğ‘‡) and ğ‘š(cid:3047) (ğœ— =ğ¹) in real-world scenarios. During the sim-
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
ulation, these default values generate realistic outputs for ğ‘š(cid:3047) (ğœ—=ğ‘‡) and
(cid:3051)(cid:3052)
ğ‘š(cid:3047) (ğœ—=ğ¹) as the simulated sensor moves across the 2D map. One-dimensional
(cid:3051)(cid:3052)
Gaussian functions are used to model how these values decrease with increasing dis-
tance from the sensor.
When the sensor model is utilized in a simulation, two matrices, with basic beliefs
ğ‘š(cid:3047) (ğœ—=ğ‘‡) and ğ‘š(cid:3047) (ğœ—=ğ¹), are generated for all grid cells ğ‘ within the sensor
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
radius using two Gaussian functions. The first Gaussian function, which produces
higher values, is multiplied by a factor to set its maximum value equal to
10 J. Schubert, F. Kamrani, and T. Gustavi
ğ‘š(cid:3031)(cid:3032)(cid:3033)(cid:3028)(cid:3048)(cid:3039)(cid:3047)(ğœ—=ğ‘‡)=0.7. This function generates ğ‘š(cid:3047) (ğœ— =ğ‘‡) for grid cells that contain
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
target objects, while for these cells, ğ‘š(cid:3047) (ğœ—=ğ¹) is set to 0. The second Gaussian func-
(cid:3051)(cid:3052)
tion is employed similarly to create ğ‘š(cid:3047) (ğœ—=ğ¹) for grid cells that do not contain target
(cid:3051)(cid:3052)
objects. This function is scaled so that its maximum value equals ğ‘š(cid:3031)(cid:3032)(cid:3033)(cid:3028)(cid:3048)(cid:3039)(cid:3047)(ğœ—=ğ¹)=
(cid:3051)(cid:3052)
0.3. In these grid cells, ğ‘š(cid:3047) (ğœ—=ğ‘‡) is set to 0. In other words, in the simulation, our
(cid:3051)(cid:3052)
sensor does not draw a stochastic categorical observation; instead, it produces a
deterministic soft output interpreted as the expected correctness of a positive detection
for each cell within the radius. We encode this soft observation as a score in [0, 1] and,
for brevity, we write it using the same ğ‘š(cid:3047) (â¦) symbols as our map-based evidence.
(cid:3051)(cid:3052)
Thus, when ğ‘š(cid:3047) (ğœ— =ğ‘‡) appears below in the context of the sensor, it should be read
(cid:3051)(cid:3052)
as a soft observation score produced by the sensor model, not as a posterior belief about
the state.
To enhance the sensor modelâ€™s realism, we introduce an assumed standard deviation,
referred to as ğœ , which represents the error in the sensorâ€™s position estimate for
(cid:3043)(cid:3042)(cid:3046)(cid:3036)(cid:3047)(cid:3036)(cid:3042)(cid:3041)
identified target objects. Considering the anticipated positioning uncertainty of a sen-
sor, the values for ğ‘š(cid:3047) (ğœ—=ğ‘‡) and ğ‘š(cid:3047) (ğœ—=ğ¹) in grid cells located within a distance
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
less than the sensorâ€™s radius ğ‘Ÿ(cid:3435)ğœ (cid:3439) are adjusted: ğ‘š(cid:3047) (ğœ—=ğ‘‡) is determined by
(cid:3043)(cid:3042)(cid:3046)(cid:3036)(cid:3047)(cid:3036)(cid:3042)(cid:3041) (cid:3051)(cid:3052)
the distance to the estimated target position. A Gaussian function, with an appropriate
standard deviation, is applied for this calculation; ğ‘š(cid:3047) (ğœ— =ğ¹) is set equal to 0.
(cid:3051)(cid:3052)
The Gaussian sensor model is utilized in the generative Dempster-Shafer model to
quantify the observation basic belief ğ‘š(cid:3047) (ğœ—) and in the generative Bayesian process as
(cid:3051)(cid:3052)
its likelihood ğ‘(cid:3047) (ğœ‘|ğœ—).
(cid:3051)(cid:3052)
7 Controlling an Intelligent Agent
7.1 The Generative Model
This work presents the common operational picture using an evidence map, denoted as
ğº. This evidence map is structured as a grid composed of multiple cells. Each cell cor-
responds to a specific segment of the geographical area being monitored, as a grid is
overlaid on the map of that area. Thus, each cell represents a distinct portion of the
surveillance zone.
Each cell ğ‘ in the evidence map is associated with two basic beliefs: ğ‘š(cid:3047) (ğœ— =ğ‘‡)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
and ğ‘š(cid:3047) (ğœ—=ğ¹). Here, ğ‘š(cid:3047) (ğœ—=ğ‘‡) indicates the basic belief that the cell at time ğ‘¡
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
contains at least one object of interest, while ğ‘š(cid:3047) (ğœ—=ğ¹) represents the basic belief
(cid:3051)(cid:3052)
that the cell is empty. The following conditions apply to the basic beliefs:
ğ‘š(cid:3047) (ğœ—=ğ‘‡),ğ‘š(cid:3047) (ğœ—=ğ¹)â‰¥0, and ğ‘š(cid:3047) (ğœ—=ğ‘‡)+ğ‘š(cid:3047) (ğœ— =ğ¹)â‰¤1 for all cells ğ‘
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
at all times ğ‘¡. The basic belief for cell ğ‘ at time ğ‘¡ is represented by the pair
(cid:3051)(cid:3052)
(cid:4672)ğ‘š(cid:3047) (ğœ—=ğ‘‡),ğ‘š(cid:3047) (ğœ—=ğ¹)(cid:4673), with uncertainty defined as 1âˆ’ğ‘š(cid:3047) (ğœ—=ğ‘‡)âˆ’
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
ğ‘š(cid:3047) (ğœ—=ğ¹).
(cid:3051)(cid:3052)
In Fig. 1, the green area represents ğ‘š(cid:3047) (ğœ— =ğ‘‡), the red area represents
(cid:3051)(cid:3052)
ğ‘š(cid:3047) (ğœ—=ğ¹), and the white area indicates the uncertainty.
(cid:3051)(cid:3052)
Active Inference for an Intelligent Agent 11
ğ‘š(cid:3047) (ğœ—=ğ‘‡) ğ‘š(cid:3047) (ğœ—=ğ¹)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
Fig 1. Illustration of evidence and uncertainty in cell ğ‘ . Green indicates ğ‘š(cid:3047) (ğœ—=ğ‘‡), red in-
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
dicates ğ‘š(cid:3047) (ğœ—=ğ¹), and white shows residual uncertainty 1âˆ’ğ‘š(cid:3047) (ğœ—=ğ‘‡)âˆ’ğ‘š(cid:3047) (ğœ—=ğ¹);
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
this per-cell Dempsterâ€“Shafer pair forms the basis of the evidence map G.
The uncertainty 1âˆ’ğ‘š(cid:3047) (ğœ—=ğ‘‡)âˆ’ğ‘š(cid:3047) (ğœ—=ğ¹) can be considered a genuine uncer-
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
tainty in cell ğ‘ that the agent should strive to minimize across all cells ğ‘ and at all
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
times to maintain a current common operational picture.
Instead of assigning a single piece of evidence for a positive detection to one specific
set of grid cells within the assumed detection radius of the sensors, we opt to assign
evidence to each grid cell individually within that radius. This approach offers a more
detailed representation, as each grid cell ğ‘ receives its value, while significantly re-
(cid:3051)(cid:3052)
ducing the computational complexity involved in updating these values with new sen-
sor measurements.
Our experiment utilizes a Gaussian distribution with a standard deviation equal to
the sensor radius, ensuring that the center cell is assigned the highest value. This method
results in a series of distinct basic belief distributions â€“ one for each grid cell. The
outcome provides a satisfactory resolution and a relevant spread in the evidence-based
common operational picture. The diffusion model outlined in equations (12) and (13)
achieves a dynamic evidence-based common operational picture.
Given that the observed environment is assumed to be dynamic, the value of older
information diminishes over time. In the evidence map, this decreasing certainty about
the locations of already detected objects is represented by the spread of basic belief to
adjacent cells.
Regardless of whether the agent observed the state of cell ğ‘ between times ğ‘¡ and
(cid:3051)(cid:3052)
ğ‘¡+1, the basic beliefs ğ‘š(cid:3047) (ğœ— =ğ‘‡) and ğ‘š(cid:3047) (ğœ— =ğ¹) in the cell are updated according
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
to equations (12) and (13). This is separate from fusion with new observations, which
is managed in equations (14) and (15). The update for the basic belief is given by:
ğ‘š(cid:3047) (ğœ— =ğ‘‡) ğ‘š(cid:3047) (ğœ— =ğ‘‡)
ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡)=1âˆ’(cid:4678)1âˆ’ (cid:3051)(cid:3052) (cid:4679)âˆ™ (cid:3537) (cid:4678)1âˆ’ (cid:3036)(cid:3037) (cid:4679)
(cid:3051)(cid:3052) ğ‘+1 ğ‘+1
((cid:3036)(cid:3037)) âˆˆ (cid:3419)(cid:3041)(cid:3032)(cid:3036)(cid:3034)(cid:3035)(cid:3029)(cid:3042)(cid:3045)(cid:3046) (cid:3042)(cid:3033) (cid:3030)(cid:3299)(cid:3300)(cid:3423)
(12)
where ğ‘ is the number of neighbors of the cell ğ‘ . This means that the basic belief
(cid:3051)(cid:3052)
ğ‘š(cid:3047) (ğœ—=ğ‘‡) of cell ğ‘ is shared among its neighbors and itself (i.e., among nine grid
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
cells in the case of a square grid) and then combined using Dempsterâ€™s rule. This causes
a diffusion of basic belief ğ‘š(cid:3047) (ğœ—=ğ‘‡)over an increasingly larger area over time (in a
(cid:3036)(cid:3037)
manner similar to an explosion).
12 J. Schubert, F. Kamrani, and T. Gustavi
Suppose ğ‘š(cid:3047) (ğœ—=ğ‘‡)>0 in cell ğ‘ , some of the basic belief ğ‘š(cid:3047) (ğœ—=ğ‘‡) will be
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
propagated to its ğ‘ neighbors. Conversely, if ğ‘š(cid:3047) (ğœ—=ğ‘‡)>0 in adjacent cells, some
(cid:3036)(cid:3037)
basic belief is propagated into cell ğ‘ .
(cid:3051)(cid:3052)
Furthermore, we have
(cid:2869) (cid:2869)
ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹)=ğ‘š(cid:3047) (cid:4672) (cid:3015)(cid:2878)(cid:2869) (cid:4673)(ğœ—=ğ¹)âˆ™ (cid:3537) ğ‘š(cid:3047) (cid:4672) (cid:3015)(cid:2878)(cid:2869) (cid:4673) (ğœ—=ğ¹)(13)
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3036)(cid:3037)
((cid:3036)(cid:3037)) âˆˆ (cid:3419)(cid:3041)(cid:3032)(cid:3036)(cid:3034)(cid:3035)(cid:3029)(cid:3042)(cid:3045)(cid:3046) (cid:3042)(cid:3033) (cid:3030)(cid:3299)(cid:3300)(cid:3423)
where ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹) indicates that cell ğ‘ is empty at time ğ‘¡+1. This suggests that if
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
cell ğ‘ will be empty at the next time step (i.e., ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹)), then both its neighbor-
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
ing cells and the cell itself must currently be empty, meaning ğ‘š(cid:3047) (ğœ—=ğ¹). Equation
(cid:3051)(cid:3052)
(13) contracts basic belief ğ‘š(cid:3047) (ğœ—=ğ¹) inward (in a manner similar to an implosion).
(cid:3051)(cid:3052)
A sensor on an agent gathers information about one or more cells in the evidence
map. This gathering is influenced by the sensorâ€™s detection radius and the agentâ€™s flight
altitude. As the flight altitude rises, the likelihood of detecting interesting objects on
the ground decreases. In our simulations, we keep a constant flight altitude since we
only model the problem in 2D.
A positive observation occurs when the sensor detects an object of interest in a spe-
cific cell ğ‘ at time ğ‘¡, represented as (cid:3435)ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ‘‡),0(cid:3439), where ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ‘‡) indicates
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
the basic belief that the positive detection is correct. Conversely, a â€œnegativeâ€ observa-
tion, where the sensor does not detect any object of interest in cell ğ‘ at time ğ‘¡, is
(cid:3051)(cid:3052)
represented as (cid:4672)0,ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ¹)(cid:4673). Here, ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ¹) represents the basic belief con-
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
firming that the negative result is accurate.
Both ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ‘‡) and ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ¹) fall within the range of (cid:4670)0,1(cid:4671). Sensor meas-
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
urements continuously update the evidence map according to equations (14) and (15)
below.
If we obtain a positive observation (cid:3435)ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ‘‡),0(cid:3439), it is combined with the exist-
(cid:3051)(cid:3052)
ing basic belief pair ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡) and ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹), which are derived using equa-
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
tions (13) and (14) with Dempsterâ€™s rule [3].
We have
ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡)=
(cid:3051)(cid:3052)
ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡)+ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ‘‡)âˆ™(cid:4672)1âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡)âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹)(cid:4673)
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
= (14)
1âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ‘‡)âˆ™ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
and
(cid:4672)1âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ‘‡)(cid:4673)âˆ™ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ¹)= . (15)
(cid:3051)(cid:3052) 1âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ‘‡)âˆ™ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ— =ğ¹)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
It is assumed that equations (14) and (15) are always applied after equations (12) and
(13), and at the same time, ğ‘¡. The basic beliefs ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡) and ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ— =ğ¹) on the
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
right-hand side represent the results from the diffusion update at time step ğ‘¡ + 1. In
Active Inference for an Intelligent Agent 13
contrast, the values ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡) and ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ¹) on the left-hand side, indicated
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
with an asterisk (*), are the combined results from the two updates at the same time
step ğ‘¡ + 1.
If a new â€œnegativeâ€ observation is received in grid cell ğ‘ , then (cid:4672)0,ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ¹)(cid:4673)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
is combined with ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡) and ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹) using Dempsterâ€™s rule.
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
We have
ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡)âˆ™(cid:4672)1âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ¹)(cid:4673)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡)= (16)
(cid:3051)(cid:3052) 1âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡)âˆ™ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ¹)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
and
ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ¹)=
(cid:3051)(cid:3052)
ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹)+ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ¹)âˆ™(cid:4672)1âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡)âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹)(cid:4673)
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
= . (17)
1âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡)âˆ™ğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ‘=ğ¹)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
A combined result of the two distributions ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡) and ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ¹) for ğœ— =
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
ğ‘‡ is shown in Fig. 2. Here, the fused result in the figure shows the remaining basic
belief from positive observations after taking into account â€œnegativeâ€ observations.
7.2 The Generative Process
In the generative process, we employ a Bayesian approach. When we receive a current
observation, our goal is to calculate the updated posterior distribution ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘). We
(cid:3051)(cid:3052)
must determine this probability distribution across all grid cells, ğ‘ , to achieve this.
(cid:3051)(cid:3052)
This requires a sensor model in the form of a likelihood distribution ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘|ğœ—) and an
(cid:3051)(cid:3052)
observation model ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘), as well as an a priori distribution ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—).
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
We begin with the a priori distribution. It is important to note that the a priori distri-
bution at each time step equals the posterior distribution from the previous time point.
We have
ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—)=ğ‘(cid:3047) (ğœ—|ğœ‘). (18)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
Initially, we have set
# ğ‘ğ‘ ğ‘ ğ‘¢ğ‘šğ‘’ğ‘‘ ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡ğ‘  ğ‘–ğ‘› ğ‘¡â„ğ‘’ ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ ğ‘ğ‘Ÿğ‘’ğ‘
ğ‘(cid:2868) (ğœ—)=ğœ€ = . (19)
(cid:3051)(cid:3052) # ğ‘”ğ‘Ÿğ‘–ğ‘‘ ğ‘ğ‘’ğ‘™ğ‘™ğ‘  ğ‘–ğ‘› ğ‘¡â„ğ‘’ ğ‘ğ‘¢ğ‘Ÿğ‘Ÿğ‘’ğ‘›ğ‘¡ ğ‘ğ‘Ÿğ‘’ğ‘
Using a likelihood distribution and our sensor model, we assign probabilities to each
grid cell ğ‘ within the sensorâ€™s radius based on two Gaussian distributions.
(cid:3051)(cid:3052)
To calculate the probability of an observation, denoted as ğ‘(cid:3047) (ğœ‘), we can express it
(cid:3051)(cid:3052)
as follows:
ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘)=ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘|ğœ— =ğ‘‡)âˆ™ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡)+ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘|ğœ— =ğ¹)âˆ™ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹),(20)
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
14 J. Schubert, F. Kamrani, and T. Gustavi
Fig. 2. Fused results, ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡) derived from the generative model in a simulation scenario
(cid:3051)(cid:3052)
at 50 seconds (2D on top and 3D below). Values reflect diffusion, equations (12)â€“(13), followed
by Dempsterâ€“Shafer fusion, equations (14)â€“(17); higher values indicate a stronger basic belief
that a cell contains â‰¥ 1 target (axes in meters; black â€œ+â€ marks show target locations).
where ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡) is the a priori probability derived earlier in (18) and
(cid:3051)(cid:3052)
ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ¹)=1âˆ’ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡). (21)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
Additionally, the likelihood distribution ğ‘(cid:3047) (ğœ‘|ğœ— =ğ‘‡) is calculated using a Gaussian
(cid:3051)(cid:3052)
distribution, similarly to the method described in Section 6.2, starting from
ğ‘š(cid:3031)(cid:3032)(cid:3033)(cid:3028)(cid:3048)(cid:3039)(cid:3047)(ğœ—=ğ‘‡).
(cid:3051)(cid:3052)
Active Inference for an Intelligent Agent 15
Since the sensor returns a deterministic score, we define the likelihood directly from
it. Hence, the identification in (22) is just shorthand rather than an inference about the
state,
ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘|ğœ— =ğ‘‡)â‰œğ‘š(cid:3047)(cid:2878)(cid:2869)(ğœ—=ğ‘‡),
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘|ğœ— =ğ¹)=1âˆ’ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘|ğœ—=ğ‘‡). (22)
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
Using the three probability distributions (a priori ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—), likelihood ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘|ğœ—), and
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
observation ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘)), we can calculate the desired posterior distribution using Bayes
(cid:3051)(cid:3052)
theorem.
We have
ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘|ğœ—)
ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘)= (cid:3051)(cid:3052) ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—). (23)
(cid:3051)(cid:3052) ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘) (cid:3051)(cid:3052)
(cid:3051)(cid:3052)
Fig. 3 displays the posterior distribution concurrently with Fig. 2.
7.3 The Free Energy
The basic belief distribution ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡) represents the distribution from the gener-
(cid:3051)(cid:3052)
ative model that we aim to compare with the posterior distribution derived from the
current observation ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘). Notably, ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡) encompasses values over all
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
subsets of the sample space Î˜, including Î˜ itself (where |2(cid:2944)|=3), while ğ‘(cid:3047) (ğœ—|ğœ‘) is
(cid:3051)(cid:3052)
limited to values associated with the elements of Î˜ (where |Î˜|=2). Therefore, we
must convert the basic belief distribution into a probability distribution to facilitate a
comparison between these two distributions. This conversion is achieved through a
pignistic transformation [32], defined as follows:
ğ‘š(ğ‘‹)
ğµğ‘’ğ‘¡ğ‘ƒ(ğœ”)= (cid:3533) (24)
|ğ‘‹|
(cid:3104)âˆˆ(cid:3025)
where ğœ”âˆˆÎ˜ and ğ‘‹ âŠ†Î˜.
We have
1
ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡)= (cid:3427)1+ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡)âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ¹)(cid:3431) (25)
(cid:3051)(cid:3052) 2 (cid:3051)(cid:3052) (cid:3051)(cid:3052)
and
1
ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ¹)= (cid:3427)1+ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ¹)âˆ’ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡)(cid:3431), (26)
(cid:3051)(cid:3052) 2 (cid:3051)(cid:3052) (cid:3051)(cid:3052)
where ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—) represents a pignistic probability derived from the pignistic transfor-
(cid:3051)(cid:3052)
mation of the basic belief distribution ğ‘š(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—).
(cid:3051)(cid:3052)
16 J. Schubert, F. Kamrani, and T. Gustavi
Fig. 3. The posterior distribution ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘), calculated after the most recent observation, using
(cid:3051)(cid:3052)
Bayes rule, equation (23), with the prior, equations (18)â€“(21), and Gaussian sensor likelihood,
equation (22), at the same timestep as Fig. 2, for comparison with the fused belief shown there.
We can now calculate the free energy of each grid cell ğ‘ within the sensor radius by
(cid:3051)(cid:3052)
measuring the divergence between ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—) and ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘), along with the degree of
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
surprise represented by ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘).
(cid:3051)(cid:3052)
Fig. 4 illustrates the divergence between the pignistic probability distribution
ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—) from the generative model and the posterior distribution ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘) from the
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
generative process.
Active Inference for an Intelligent Agent 17
Fig. 4. The divergence between the model and the actual observation. Cell-wise ğ· (cid:3427)ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=
(cid:3012)(cid:3013) (cid:3051)(cid:3052)
ğ‘‡)âˆ¥ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘)(cid:3431), which is the first term of equation (27) within the sensor footprint (r = 100
(cid:3051)(cid:3052)
meters), illustrating where the modelâ€™s belief and the posterior disagree.
Fig. 5 displays the degree of surprise, indicated as âˆ’ğ‘™ğ‘›(cid:3427)ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘)(cid:3431).
(cid:3051)(cid:3052)
We have
ğ¹ =ğ· (cid:3427)ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡)âˆ¥ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘)(cid:3431)âˆ’ğ‘™ğ‘›(cid:3427)ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘)(cid:3431)
(cid:3051)(cid:3052) (cid:3012)(cid:3013) (cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—)
=(cid:3429) (cid:3533) ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—)âˆ™ğ‘™ğ‘›(cid:4678) (cid:3051)(cid:3052) (cid:4679)(cid:3433)âˆ’ğ‘™ğ‘›(cid:3427)ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘)(cid:3431), (27)
(cid:3051)(cid:3052) ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘) (cid:3051)(cid:3052)
(cid:3051)(cid:3052)
(cid:3107)âˆˆ(cid:4668)(cid:3021),(cid:3007)(cid:4669)
where ğ· is the Kullback-Leibler divergence [33].
(cid:3012)(cid:3013)
18 J. Schubert, F. Kamrani, and T. Gustavi
Fig. 5. The level of surprise. Surprisal âˆ’ğ‘™ğ‘›(cid:3427)ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘)(cid:3431), which represents the second term of equa-
(cid:3051)(cid:3052)
tion (27), is shown inside the sensor footprint. Outside the footprint, ğ‘(ğœ‘)=0, so surprisal di-
verges and is omitted.
The free energy ğ¹ is calculated for all grid cells within the sensor radius and mini-
(cid:3051)(cid:3052)
mized across all grid cells. Finally, the variational free energy is presented in Fig. 6.
The agentâ€™s position is updated with steps smaller than the sensor radius. Thus, using
active inference, we gradually move the agentâ€™s position toward the grid cell, which
minimizes ğ¹ .
(cid:3051)(cid:3052)
Active Inference for an Intelligent Agent 19
Fig. 6. Free energy, denoted as ğ¹ , for all grid cells ğ‘ . ğ¹ is calculated using equation (27);
(cid:3051)(cid:3052) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
the green â€œÃ—â€ marks argmin F, which the agent uses to set the next waypoint.
8 Implementation and Results for an Intelligent Agent
Implementing agent control using the free energy principle and active inference in-
volves calculations, as outlined in Section 7. However, several essential implementa-
tion details and design choices must be considered.
The generative model and process are evaluated at each simulation time step. Im-
portantly, the free energy is calculated only for positions within the sensor radius; for
this simulation, we use a sensor radius of 100 meters. This limitation is not merely a
design choice but a fundamental aspect of the model. According to equation (27), free
20 J. Schubert, F. Kamrani, and T. Gustavi
energy is defined as the sum of the Kullback-Leibler divergence between two probabil-
ities, ğ· (cid:3427)ğ‘(cid:3047)(cid:2878)(cid:2869)âˆ—(ğœ—=ğ‘‡)âˆ¥ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ—|ğœ‘)(cid:3431), and the surprise, which is calculated as
(cid:3012)(cid:3013) (cid:3051)(cid:3052) (cid:3051)(cid:3052)
âˆ’ğ‘™ğ‘›(cid:3427)ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘)(cid:3431). Here, ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘) represents the probability of the observation. Outside the
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
sensor radius, ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘) equals zero, causing âˆ’ğ‘™ğ‘›(cid:3427)ğ‘(cid:3047)(cid:2878)(cid:2869)(ğœ‘)(cid:3431) to approach infinity. This
(cid:3051)(cid:3052) (cid:3051)(cid:3052)
observation highlights the notion that surprise becomes infinite when faced with im-
possibilities.
The computational complexity per step of our planner is
ğ‘‚(cid:3435)ğ‘(cid:2870) + ğ‘ ğ´ + ğ´ + ğ‘ (cid:2870)(cid:3439), (28)
(cid:3028)(cid:3034)(cid:3032)(cid:3041)(cid:3047)(cid:3046) (cid:3043)(cid:3042)(cid:3036) (cid:3034) (cid:3034) (cid:3045)
where ğ‘ is the number of agents in the swarm, ğ´ is the number of grid cells,
(cid:3028)(cid:3034)(cid:3032)(cid:3041)(cid:3047)(cid:3046) (cid:3034)
ğ‘ is the number of points of interest (POI), and ğ‘  is the sensing radius expressed in
(cid:3043)(cid:3042)(cid:3036) (cid:3045)
grid cells. In practice, for a 580Ã—380 grid with ten agents, six POI, and a sensing
radius of 100 cells (i.e., 100 meters), each simulation step took on average 0.12 sec-
onds, which amounts to 36 seconds for a 300-step rollout (one minute wall-clock time
at five simulation ticks per second, i.e., faster than real time) on a standard laptop
(MATLAB; Intel i7; 32 GB RAM).
Another design choice focuses on how to select the new waypoint. Once the position
with the lowest free energy has been identified, we calculate a vector from the agentâ€™s
current position to the minimum free energy position. The agent then takes an incre-
mental step toward that position. The next waypoint is placed at a fixed distance along
this vector, which in our simulation is set to half the sensor radius (i.e., a step length of
50 meters). This approach ensures a consistent distance between successive waypoints.
This section provides a qualitative analysis of the methodâ€™s behavior based on sim-
ulation observations. The findings indicate that the technique demonstrates favorable
behavior. After navigating the pre-programmed waypoints (the first three targets), the
agent continues to search the area in a balanced manner that integrates exploration and
exploitation.
An agentâ€™s trajectory (shown as a red line) over a 500-second scenario (Fig. 7) illus-
trates a dynamic balance between tracking various target goals (indicated by black â€œ+â€
symbols) and exploring new areas. Black trajectories represent three moving targets,
while four targets are stationary. The green â€œxâ€ indicates the minimum free energy at
the current time.
A qualitative analysis of the images using a stochastic model, along with probabil-
istic observations and their divergences, provides insights into the level of surprise ex-
perienced by the agent. This understanding and the concept of free energy help clarify
the reasons and timing behind the agentâ€™s decision to scout or pursue a target. When
examining the sequence of images throughout a scenario, a behavior that is intuitively
and analytically coherent emerges.
Active Inference for an Intelligent Agent 21
Fig. 7. The agentâ€™s path entails both reconnaissance and target tracking. The trajectory, way-
points, and position of minimum free energy are illustrated. The agents, represented by red
crosses, select a new waypoint along a vector that points towards the minimum free energy point,
indicated by the green cross. The black crosses depict the exact locations of the targets from a
global perspective; these locations remain unknown to the agents except through sensor obser-
vations. The black â€œ+â€ at the end of black trajectories indicates the final position of a target as it
exits the map and the simulation.
9 Conclusions
A simulation of an intelligent agent demonstrates its ability to autonomously decide
when to engage in scouting activities and when to track specific targets. This decision-
making process entirely depends on the data acquired through the agentâ€™s sensors. As
the agent operates, it navigates from its current location towards the designated grid
cell that minimizes free energy. Free energy quantifies the degree of alignment between
the agentâ€™s perception of reality and its current observations. The agentâ€™s minimizing
free energy enhances its comprehension and adaptability to the external environment.
Additionally, the planner operates efficiently: in our prototype, each step takes approx-
imately 0.12 seconds on average, resulting in 36 seconds for a 300-step rollout using
standard hardware, which demonstrates its potential for near real-time operation. A
qualitative analysis of the agentâ€™s behavior during the simulation reveals promising re-
sults. The agentâ€™s ability to balance exploration and exploitation indicates significant
operational autonomy and efficiency. A quantitative analysis of the active inference
approach to the persistent monitoring problem has not yet been performed. To achieve
this, some mission goals need to be formulated, and appropriate metrics for measuring
goal fulfillment must be defined. Examples of performance metrics for a combined
tracking and area coverage scenario, similar to the scenario discussed in this paper, can
be found, for instance, in [8]. The performance of the implemented active inference-
22 J. Schubert, F. Kamrani, and T. Gustavi
based control should be compared to that of a simple baseline control or, ideally, with
several other control algorithms from the literature, and for some different scenarios.
Disclosure of Interests. The authors have no competing interests to declare relevant to this arti-
cleâ€™s content.
References
1. Parr, T., Pezzulo, G., Friston, K. J.: Active inference: The free energy principle in mind,
brain, and behavior. The MIT Press, Cambridge, MA (2022). doi:10.7551/mitpress/
12441.001.0001
2. Buckley, C. L., Kim, C. S., McGregor, S., Seth, A. K.: The free energy principle for action
and perception: A mathematical review. Journal of Mathematical Psychology 81, 55â€“79
(2017). doi:10.1016/j.jmp.2017.09.004
3. Dempster, A. P.: A generalization of Bayesian inference. Journal of the Royal Statistical
Society. Series B 30(2), 205â€“247 (1968). doi:10.1111/j.2517-6161.1968.tb00722.x
4. Shafer, G.: A mathematical theory of evidence. Princeton University Press, Princeton, NJ
(1976)
5. Hari, S. K. K., Rathinam, S., Darbha, S., Kalyanam, K., Manyam, S. G., Casbeer, D.: Opti-
mal UAV route planning for persistent monitoring missions. IEEE Transactions on Robotics
37(2), 550â€“566 (2020). doi:10.1109/TRO.2020.3032171
6. Brown, A., Anderson, D.: Trajectory optimization for high-altitude long-endurance UAV
maritime radar surveillance. IEEE Transactions on Aerospace and Electronic Systems 56(3),
2406â€“2421 (2020). doi:10.1109/TAES.2019.2949384
7. HÃ¼bel, N., Hirche, S., Gusrialdi, A., Hatanaka, T., Fujita, M., Sawodny, O.: Coverage con-
trol with information decay in dynamic environments. IFAC Proceedings 41(2), 4180â€“4185
(2008). doi:10.3182/20080706-5-KR-1001.00703
8. Ramasamy, M., Ghose, D.: Learning-based preferential surveillance algorithm for persistent
surveillance by unmanned aerial vehicles. In: Proceedings of the 2016 International Confer-
ence on Unmanned Aircraft Systems, pp. 1032â€“1040. IEEE, Piscataway, NJ (2016).
doi:10.1109/ICUAS.2016.7502678
9. Chen, J., Baskaran, A., Zhang, Z., Tokekar, P.: Multi-agent reinforcement learning for visi-
bility-based persistent monitoring. In: Proceedings of the 2021 IEEE/RSJ International Con-
ference on Intelligent Robots and Systems, pp. 2563â€“2570. IEEE, Piscataway, NJ (2021).
doi:10.1109/IROS51168.2021.9635898
10. Mishra, M., Poddar, P., Agrawal, R., Chen, J., Tokekar, P., Sujit, P. B.: Multi-agent deep
reinforcement learning for persistent monitoring with sensing, communication, and locali-
zation constraints. IEEE Transactions on Automation Science and Engineering 22, 2831â€“
2843 (2025). doi:10.1109/TASE.2024.3385412
11. van de Laar, T., Ã–zÃ§elikkale, A., Wymeersch, H.: Application of the free energy principle
to estimation and control. IEEE Transactions on Signal Processing 69, 4234â€“4244, 2021.
doi:10.1109/TSP.2021.3095711
12. Bos, F., Meera, A. A., Benders, D., Wisse, M.: Free energy principle for state and input
estimation of a quadcopter flying in wind. In: Proceedings of the 2022 International Confer-
ence on Robotics and Automation, pp. 5389â€“5395. IEEE, Piscataway, NJ (2022).
doi:10.1109/ICRA46639.2022.9812415
Active Inference for an Intelligent Agent 23
13. Pezzato, C., Ferrari, R., HernÃ¡ndez Corbato, C.: A novel adaptive controller for robot ma-
nipulators based on active inference. IEEE Robotics and Automation Letters 5(2), 2973â€“
2980 (2020). doi:10.1109/LRA.2020.2974451
14. Meo, C., Lanillos, P.: Multimodal VAE active inference controller. In: Proceedings of the
2021 IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2693â€“
2699. IEEE, Piscataway, NJ (2021). doi:10.1109/IROS51168.2021.9636394
15. Meo, C., Franzese, G., Pezzato, C., Spahn, M., Lanillos, P.: Adaptation through prediction:
multisensory active inference torque control. IEEE Transactions on Cognitive and Develop-
mental Systems 15(1), 32â€“41 (2023). doi:10.1109/TCDS.2022.3156664
16. Baioumy, M., Pezzato, C., Ferrari, R., Corbato, C. H., Hawes, N.: Fault-tolerant control of
robot manipulators with sensory faults using unbiased active inference. In: Proceedings of
the 2021 European Control Conference, pp. 1119â€“1125. IEEE, Piscataway, NJ (2021).
doi:10.23919/ECC54610.2021.9654913
17. Ã‡atal, O., Verbelen, T., Van de Maele, T., Dhoedt, B., Safron, A.: Robot navigation as hier-
archical active inference. Neural Networks 142, 192â€“204 (2021). doi:10.1016/j.neunet.2021
.05.010
18. Scholz, F., Gumbsch, C., Otte, S., Butz, M. V.: Inference of affordances and active motor
control in simulated agents. Frontiers in Neurorobotics 16, 881673 (2022). doi:10.3389/
fnbot.2022.881673
19. Kawahara, D., Ozeki, S., Mizuuchi, I.: A curiosity algorithm for robots based on the free
energy principle. In: Proceedings of the 2022 IEEE/SICE International Symposium on Sys-
tem Integration, pp. 53â€“59. IEEE, Piscataway, NJ (2022). doi:10.1109/SII52469.2022
.9708819
20. Katahira, K., Kunisato, Y., Okimura, T., Yamashita, Y.: Retrospective surprise: A compu-
tational component for active inference. Journal of Mathematical Psychology 96, 102347
(2020). doi:10.1016/j.jmp.2020.102347
21. Wakayama, S., Ahmed, N.: Active Inference for autonomous decision-making with contex-
tual multi-armed bandits. In: Proceedings of the 2023 IEEE International Conference on
Robotics and Automation, pp. 7916â€“7922 (2023). doi: 10.1109/ICRA48891.2023.10160593
22. Wakayama, S., Candela, A., Hayne, P., Ahmed, N.: Active inference for bandit-based au-
tonomous robotic exploration with dynamic preferences. IEEE Transactions on Robotics
41:3841â€“3851 (2025). doi:10.1109/TRO.2025.3577041
23. Levchuk, G., Pattipati, K., Fouse, A., Serfaty, D.: Application of free energy minimization
to the design of adaptive multi-agent teams. In: Proceedings SPIE 10206, Disruptive Tech-
nologies in Sensors and Sensor Systems, 102060E (2017). doi:10.1117/12.2263542
24. Levchuk, G., Fouse, A., Pattipati, K., Serfaty, D., McCormack, R.: Active learning and
structure adaptation in teams of heterogeneous agents. In: Proceedings SPIE 10653, Next-
Generation Analyst VI, 1065305 (2018). doi:10.1117/12.2305875
25. Levchuk, G., Pattipati, K., Serfaty, D., Fouse, A., McCormack, R.: Active inference in mul-
tiagent systems: Context-driven collaboration and decentralized purpose-driven team adap-
tation. In: Artificial Intelligence for the Internet of Everything, pp. 67â€“85. Academic Press,
Cambridge, MA (2019). doi:10.1016/B978-0-12-817636-8.00004-1
26. Pezzato, C., Corbato, C. H., Bonhof, S., Wisse, M.: Active inference and behavior trees for
reactive action planning and execution in robotics. IEEE Transactions on Robotics 39(2),
1050â€“1069 (2023). doi:10.1109/TRO.2022.3226144
27. Baltieri, M., Buckley, C. L.: Nonmodular architectures of cognitive systems based on active
inference. In: Proceedings of the 2019 International Joint Conference on Neural Networks,
pp. 1â€“8 (2019). doi:10.1109/IJCNN.2019.8852048
24 J. Schubert, F. Kamrani, and T. Gustavi
28. Nozari, S., Krayani, A., Marin, P., Marcenaro, L., Gomez, D. M., Regazzoni, C.: Exploring
action-oriented models via active inference for autonomous vehicles. EURASIP Journal on
Advances in Signal Processing 2024, 92 (2024). doi:10.1186/s13634-024-01173-9
29. Sawada, H., Ohata, W., Tani, J.: Human-robot kinaesthetic interactions based on the free-
energy principle. IEEE Transactions on Systems, Man, and Cybernetics: Systems 55(1),
366â€“379 (2025). doi:10.1109/TSMC.2024.3481251
30. Matsumura, T., Esaki, K., Yang, S., Yoshimura, C., Mizuno, H.: Active inference with em-
pathy mechanism for socially behaved artificial agents in diverse situations. Artificial Life
30(2), 277â€“297 (2024). doi:10.1162/artl_a_00416
31. Esaki, K., Matsumura, T., Minusa, S., Shao, Y., Yoshimura, C., Mizuno, H., Dynamical
perception-action loop formation with developmental embodiment for hierarchical active
inference. In: Buckley, C. L., et al. Active Inference. IWAI 2023. Communications in Com-
puter and Information Science 1915, pp. 14â€“28. Springer, Cham (2023). doi:10.1007/978-
3-031-47958-8_2
32. Smets, P., Kennes, R.: The transferable belief model. Artificial Intelligence 66(2), 191â€“234
(1994). doi:10.1016/0004-3702(94)90026-4
33. Kullback, S., Leibler, R. A.: On information and sufficiency. The Annals of Mathematical
Statistics 22(1), 79â€“86 (1951). doi:10.1214/aoms/1177729694

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   âŒ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   âœ… GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   âŒ BAD: Repeating the same claim 3+ times with slight variations
   âœ… GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
