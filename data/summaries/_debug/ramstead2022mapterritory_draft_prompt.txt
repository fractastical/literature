=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: On the map-territory fallacy fallacy
Citation Key: ramstead2022mapterritory
Authors: Maxwell J D Ramstead, Dalton A R Sakthivadivel, Karl J Friston

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2022

Key Terms: brook, principle, fallacy, systems, stony, university, physical, physics, territory, modelling

=== FULL PAPER TEXT ===

5202
nuJ
32
]hp-tsih.scisyhp[
2v42960.8022:viXra
On the Map-Territory Fallacy Fallacy
Maxwell J D Ramstead,1,2,∗ Dalton A R Sakthivadivel,1,3,4,5,† and Karl J Friston1,2,‡
1VERSES Research Lab, Los Angeles, CA, 90016, USA
2Wellcome Centre for Human Neuroimaging, University College London, London, UK
3Department of Mathematics, Stony Brook University, Stony Brook, NY, USA
4Department of Physics and Astronomy, Stony Brook University, Stony Brook, NY, USA
5Department of Biomedical Engineering, Stony Brook University, Stony Brook, NY, USA
(Dated: 24th June 2025)
This paper presents a meta-theory of the usage of the free energy principle (FEP) and
examines its scope in the modelling of physical systems. We consider the so-called ‘map-
territoryfallacy’andthefallaciousreificationofmodelproperties. ByshowingthattheFEP
is a consistent, physics-inspired theory of inferences of inferences, we disprove the assertion
that the map-territory fallacy contradicts the principled usage of the FEP. As such, we
argue that deploying the map-territory fallacy to criticise the use of the FEP and Bayesian
mechanics itself constitutes a fallacy: what we call the map-territory fallacy fallacy. In so
doing, we emphasise a few key points: the uniqueness of the FEP as a model of particles
or agents that model their environments; the restoration of convention to the FEP via its
relation to the principle of constrained maximum entropy; the ‘Jaynes optimality’ of the
FEP under this relation; and finally, the way that this meta-theoretical approach to the
FEP clarifies its utility and scope as a formal modelling tool. Taken together, these features
make the FEP, uniquely, the ideal model of generic systems in statistical physics.
I. INTRODUCTION
Bayesian mechanics and the free energy principle (FEP) have been proposed as a universal
modelling methodology for physical things, and in particular, for self-organising systems [1–3].
The FEP is a mathematical statement (or indeed a physical principle) which provides a unifying
perspective on formal approaches to behaviour and dynamics [4]. Bayesian mechanics, a corollary
of the FEP, comprises a set of tools to write mechanical theories (i.e., laws of motion) that relate
the dynamics of states or paths of a physical system to the dynamics of probabilistic beliefs (or
conditional probability densities) that are encoded by some (so-called internal) subsets of the
∗ maxwell.ramstead@verses.io
† dalton.sakthivadivel@stonybrook.edu
‡ k.friston@ucl.ac.uk
2
states of the system [5]. These internal states (or their dynamics) are coupled to other (external)
subsets of the system in such a way that they can be read as parameters for probability densities
over the external subset. Bayesian mechanics unifies first-principles-based modelling efforts in
physics by integrating the FEP with one of the cornerstones of contemporary physics, namely,
the constrained maximum entropy principle (CMEP) [6]. As a consequence, these are tools that
allow us to model any particle, or ‘thing’—in the sense that it exists as a separable, identifiable
thing [7, 8]—as if it were inferring the causes of its sensory perturbations and (re)acting so as to
remain in system-like configurations. This inference proceeds by the minimisation of a free energy
functional of such beliefs as parameterised by internal states, which guarantees—or describes—the
minimisation of the surprisal of particular states. Using this approach, we can model the dynamics
(i.e., the observable behaviour) of things or particles as realising a path of least surprisal. Bayesian
mechanics formalises the truism in physics that, on average, systems will do what it is that they
do on average. Behind this truism lies a formal apparatus that enables us to write many of the
core formulations of contemporary physics in a parsimonious manner. The hope is that this will
allow one to take some first steps towards a mechanistic explanation of how self-organisation arises
in physical systems.
In this paper, we begin the development of a bona fide meta-theory, and philosophy for the
usage, of the FEP. A good starting point for this project would be the so-called map-territory
fallacy, which some have alleged is committed by the architects of the FEP [9, 10]. Indeed, some
scholars have argued that FEP-theoretic modelling conflates the metaphorical ‘map’ (i.e., the
scientific model that scientists use to make sense of some target phenomenon) and ‘territory’ (i.e.,
the actual natural system that is being modelled). See [11] and [5] for a related critical discussion
of such claims. On this view, using the technology of FEP (and Bayesian mechanics more broadly)
to claim that things or particles engage in inference constitutes a case of model reification. That is,
some have alleged that, in describing the dynamics of physical systems as inference, FEP theorists
mistakenly conflate their metaphorical ‘map’ of the territory (i.e., the scientific FEP-theoretic or
Bayesian mechanical model, which is a set of mathematical structures) with the territory or target
system itself, thereby reifying aspects of their model into what are now assumed to be real features
of the territory.
We will argue that deploying the map-territory fallacy to criticise the FEP and Bayesian mech-
anics in this manner itself constitutes a fallacy: what we will call the map-territory fallacy fallacy.
We believe that the map-territory fallacy is fallacious for two main reasons.
3
Firstly,wewillarguethattheFEPcommitsonetoanunproblematic1 nestedrepresentationalist
account of physical dynamics: mathematically, there simply is no conflation of map and territory,
i.e., of modelled system and scientific model (see also [5, 11, 15, 16]). Indeed, the technology of the
FEP may be used to write down a statistical (generative) model of the states of a system (or paths
of a system through its state space), which constitutes our scientific models of the target system
(as modellers). The model that we construct contains a partition of the states or paths of the
system (a ‘particular’ partition, i.e., into particles); this partition captures relations of conditional
independencerelationsamongstsubsetsofthesystem,whichtrackeachothers’statisticalstructure
dynamically. Thesesubsetsofstatesengageininferenceabout(orrepresentthestatisticalstructure
of) other subsets of states. Thus, we can think of the FEP, metaphorically, as a map of that part
of the territory that behaves as if it were a map. Crucially, at this level of analysis, there is
no conflation between our FEP-theoretic model and the statistical model that is embodied by a
particle in a self-organising system: under the assumption that systems model their environments,
we can understand their dynamics in virtue of the model they hold. As such, when we use the FEP
to model the way a system models its environment, we simultaneously model the system itself in a
high-fidelity manner. This duality is key to dismissing the map-territory fallacy and is an essential
feature of the success of the FEP. That this exists in the FEP by consequence of the fundamental
posits of the theory, in particular, a symmetric boundary across which bidirectional interactions
occur, is no accident.
Secondly, we will argue that, when deployed in the context of FEP-theoretic modelling, the
map-territory fallacy rests on some rather deep misunderstandings about the nature of modelling
in physics, and about the existence and nature of constraints in modelling physical systems in
general. Specifically,weleveragethemathematicalfactthat,viatheprincipleofmaximumentropy,
anFEP-theoreticmodelofbeliefupdatingisthe optimal model of systemic dynamics, toarguethat
theFEPprovidesultimateconstraintsonwhatitmeanstobeanoptimal(physical, i.e., embodied)
model of some target physical phenomenon.
Thisallowsforthefollowing: wecanleveragethisfacttoclaimthatthe‘thing’wearemodelling
can also be expected to use the principle of maximum entropy to model its environment; since the
FEPcanbereadastheapplicationoftheCMEPtomodelmaximumentropyagentsmodellingtheir
environment, then, referencing the first point, we can produce the high-fidelity model that we have
1 The story in this paper rests on a deflated and naturalised account of representation and semantics, which is
reviewed in [12–14]. As we detail below, any system that can be modelled as an estimator i.e., as engaging
in the statistical estimation of some quantity, is a representation of the estimated system. We are aware that
proponentsofanti-representationalistphilosophyofmindmightwanttoresistthisnotion. Below,weexplainwhy
this resistance is not justified, mathematically speaking.
4
indicated. All this means is that, under the assumption that systems model their environments
optimally given some constraints on that model, they will model their environment using the FEP
or CMEP. In turn, this entails that we can understand their dynamics in virtue of the model
they hold by ourselves using the FEP to reproduce that model. More particularly, we will always
reproduce a map of that part of the territory that makes maps.
Additionally, we argue that (in a metaphorical sense) the FEP and Bayesian mechanics also
provide a map of any possible map whatsoever of, or held by, a physical system. This undermines
any strict notion that maps and territories must always be held distinct conceptually; and thus
defeats the map-territory fallacy (at least as applied to the FEP). However, this is not to suggest
that the map and the territory are never conflated; they obviously are in cases of genuine model
reification [11]. Instead, we suggest that this leads, in a Kantian manner (in terms of logically
necessary preconditions for sense-making, and thus the parsing of communicated sensory streams
on which cognition is contingent [13]), to constraints on possible maps, which arise from what it
means to be a map or model of a physical process at all.
We first present a technical introduction to the FEP and Bayesian mechanics, and examine
the claim that the FEP is, metaphorically, a map of that part of the territory that behaves as if
it were a map. It turns out that most things behave, at some level of description, like maps in
this sense. We defuse the map-territory fallacy at a first level of analysis, showing that there is no
simplyambiguitybetweenmodelandmodelledsysteminthecoreFEPformalism. Wethendiscuss
the duality of the FEP and the CMEP, and examine the implications of this duality for modelling
physicalsystems. Wefurtherdefusethemap-territoryfallacyregardingtheFEPbynotingthatthe
FEP/CMEP duality entails constraints on what counts as an optimal model of a physical process.
Here, the very distinction between map and territory is blurred; and the metaphor itself is thereby
shown to be less useful than might have been hoped initially. Finally, we summarise our critical
discussion and open onto future research questions that ought to be taken up by philosophers of
the FEP.
Altogether, we present a thesis that modelling internal states modelling external states consti-
tutes the best possible model of the internal states of a ‘thing,’ by proving that
1. things with internal states model external states, and that this model-of-models is captured
by the FEP (Sections IIA and IIB),
2. the FEP is an optimal model at the particle-level (Section IIC),
3. we can achieve a relevant model of those internal states by leveraging particle-environment
5
symmetry (Section IIIA), and
4. abiding by this symmetry, the FEP-theoretic model of the beliefs of a particle is the optimal
model at the modeller-level (Section IIIB).
Together these justify the utilisation of the FEP at a semi-axiomatic level, and lay out a set of
schema driving its applicability.
II. THE FEP AND BAYESIAN MECHANICS
A. Introduction to the FEP
The FEP can be summarised as a principle of least surprisal [1, 5, 17] for systems that possess
a particular partition. A particular partition simply takes a system and separates it into a set of
internal states and external states by an intervening set of blanket states (also called a Markov
blanket). This separation will be central to what follows in two senses. Firstly, it is an existential
imperative for anything. In other words, if the states of something could not be individuated from
everythingelse, thethingwouldnotexist. Secondly, whentalkingaboutmaps—intheformalsense
of a function or morphism—we require the domain and codomain (i.e., the image) of the map to
exist. Therefore, the use of a map in this setting presupposes the existence of a partition.
Formulated most generally, the FEP says that the paths taken by a system through its state or
phase space are characterised by a Lyapunov function, a function that varies systematically with
its dynamics. The utility of Lyapunov functions is they allow us to understand those dynamics
varying with such a function as a gradient flow on the function—in other words, it is crucial to
understanding the ‘inference’ component of surprisal minimisation. Under the FEP, this Lyapunov
functionissurprisalorvariationalfreeenergy,dependingonthesetting. Surprisalissimplynegative
log probability. Variational free energy is a tractable (i.e., easily computed) upper bound on
surprisal. Minimising surprisal implies that the variational free energy is minimised, and likewise,
minimising the variational free energy places an upper bound on the surprisal. Though not a
minimum per se, minimising the variational free energy is a necessary first step, and a good
proxy, for surprisal minimisation.2 That the dynamics of a system encode an inference whenever
they minimise this quantity is the consequence of reading surprisal as a Lyapunov function for
2 In the limit of exact Bayesian inference, when the functional form of posterior beliefs encoded by internal states
coincides with the posterior density over external states, the variational free energy is just the surprisal. See e.g.
[6, Lemma 4.2].
6
those dynamics. This gradient flow is what we identify as actually being the process (i.e., the
performance) of inference.
Asstated,theFEPpartitionsa‘system’intothreesetsofstates: theparticularstatesofa‘thing’
or ‘particle’ (which is equipped with internal states µ), an environment (which possesses external
states η, relative to the thing in question), and an interface separating but coupling the two (the
so-called Markov blanket, b), which mediates the influence of η on µ and vice-versa. When we say
‘recognition model’ or ‘Bayesian belief’ we mean a parameterised probability density over external
states conditioned on particular states µ and b. The variational free energy is based on a relative
entropy,measuringthedivergencebetweenaparticle’srecognitionmodelofitsenvironmentandthe
true posterior conditional density over external states given blanket states. The recognition model
is parameterised by (the dynamics of) internal states in such a way that the particle synchronises
withtheenvironment. Morespecifically, supposethereexistsaparametricmodeloftheprobability
ofexternalstates,q(η;ηˆ ,Σ ),wherewehaveparameterisedtherecognitionmodelbytheaverage3
b η|b
state ηˆ and variance Σ of the environment.
b η|b
If there exists a boundary of the form of a Markov blanket, then there exists a function σ
relating (the dynamics of) internal states to the environment across the boundary [6, Lemma 4.3].
In that case, we can convert these parameters to σ(µˆ ) and [η−σ(µˆ )]2, meaning that the particle
b b
models its environment. Ultimately this simply means that, in virtue of being coupled (vicariously,
i.e., via blanket states) to its environment, the particle reflects data about its environment—or,
what it believes that its environment is like. Under the assumption that a particle which exists in
an environment models that environment, free energy is implicitly a measurement of coherence. If
the particle stops modelling its environment in a particular way (i.e., for a particular σ), it must
have ceased to exist with the mean that σ was constructed for; conversely, if a particle ceases to
exist, it will eventually stop modelling its environment. The variational free energy measures how
far this recognition model of what lies beyond the blanket is from the true probability density over
external states, given blanket states. If the recognition model is bad, and the free energy is high,
it is likely that the system will move into surprising (i.e., implausible or uncharacteristic) states;
this would render it non-existent, in the sense that it would be occupying states that were not
characteristic of the thing in question (e.g., a fish out of water). These statements tie together the
reasoning that things which exist in an environment reflect the statistics of their environment in a
particular way based on the way they are coupled to their environment, or, they do not exist that
3 In fact this is a conditional average, since the state of the environment is dependent on the state of the boundary
connectedtoit;hencewedenotethisasηˆ . Moregenerally,theparametercontrollingthepeakofthedensity—the
b
conditional maximum a posteriori estimate—will do.
7
way.
Mathematically, we can express this by observing the following: since the joint probability
p(η,b,µ)factorisesintop(η | b,µ)p(b,µ)(seetheprobabilisticchainrule)andlogarithmsdecompose
additively, we have
(cid:90) (cid:90)
q(η;σ(µˆ ),Σ )logq(η;σ(µˆ ),Σ )dη− q(η;σ(µˆ ),Σ )logp(η,b,µ)dη =
b η|b b η|b b η|b
(cid:90) (cid:90)
q(η;σ(µˆ ),Σ )logq(η;σ(µˆ ),Σ )dη− q(η;σ(µˆ ),Σ )logp(η | b,µ)dη−logp(µ,b) (1)
b η|b b η|b b η|b
where the left-hand side measures a divergence between q(η;σ(µˆ ),Σ ) and the true joint density;
b η|b
whilst on the right-hand side, the divergence between that recognition model and the true condi-
tional densityonexternalstatesboundsthesurprisalofinternalstatesfromabove. (Notethatthis
difference term, which we will denote F, is always non-negative, since it is a KL divergence—as
such, it is added to the surprisal in general. From that we deduce −logp(µ,b)+F ≥ −logp(µ,b).)
The FEP can be used to reformulate the least action principles that appear in both classical
and quantum physics, due to intimate connections between physical law and probability [2, 7]. In
contemporary physics, classical laws are actually the deterministic limit of underlying probabilistic
specifications of the behaviours of a system; indeed, we can quantify the degree of divergence from
the most probable path of a system by keeping track of quantum effects. The classical path of
least action is, definitionally, the most probable path a system will take, i.e., in the Gaussian
case, the average path, and thus classical physics is quantum physics modulo what one might call
randomness.4
WehaveknownsincePrigoginethatwecanalwaysreformulatethephysicallawsthatpertainto
systemic dynamics in terms of surprisal (and related metrics, such as entropy) [18, 19]. That is, we
can always take laws of physics formulated in terms of probability densities, as just described, and
reformulate them in terms of surprisal and entropy. In this setting, rather than speak of the most
probable path or state, one speaks of the least surprising one, where surprisal is parameterised
by some ‘attractor state.’ This is not specific to FEP-theoretic modelling; it is a hallmark of all
contemporary approaches to physics.
Bayesian mechanics explains why every physical thing looks as if it were performing inference
over the causes of its perturbations, forming (Bayes) optimal beliefs about the causes of those
perturbations [6]. The interesting thing about this is that surprisal is suited to act as a kind of
4 Whilst different approaches to quantum mechanics emphasise different aspects of the theory, this is especially
evidentinthepathintegralformulationofquantumphysics,whichisreflectedinthepathintegralformulationof
Bayesian mechanics, cf. [17].
8
‘ontological potential’ for the system, in the sense that the surprisal is equivalent to a constraint on
what states are accessible to the system; the trajectories of a system are curves on this surprisal,
which satisfy some equation of motion derived from the surprisal itself. As has been asserted in
recent literature [17], one reading of the FEP would hold that the crux of the ubiquity of the
FEP is that everything which is coupled to another thing holds a model of that thing in the
following very trivial sense: in virtue of this coupling, one system estimates the parameters of
the probability density over states of the other system (and vice-versa). Since the FEP regards
these systems as estimators, they are performing inference in the sense of parametric Bayesian
inference. Given that the term ‘belief’ is quite theoretically loaded (especially in philosophy),
we ought perhaps to say ‘estimator,’ instead. Once more, our contention is that anything which
estimates the parameters of a density is engaged in a form of Bayesian inference, by mathematical
definition; i.e., it is mathematically indisputable that systems that estimate statistics represent, or
encode, or otherwise hold probabilistic beliefs—whether the practitioner likes the word ‘beliefs’ or
not, and irrespective of what commitments one makes with encodings and representations.
There are two main ways to implement FEP-theoretic technology to model the dynamics of a
system; withtheformerbeingtheasymptoticlimitofthelatter(fordetaileddiscussion,see[5,17]).
First,wecanformulatetheprobabilitydensitydynamicsofasystem[2,6]. Inthissetting,surprisal
quantifies how unlikely it is that the system will visit some states, given the kind of thing that
it is. The least surprising states are those that are characteristic of the particle. Second, we can
formulatetheFEPintermsofpaths[1,17]. InthisformulationoftheFEP,thesurprisalquantifies
how far a path deviates from the expected path. For instance, under constraints that reproduce
the correspondence principle of quantum physics, the least surprising path is simply the classical
path; this is like saying that particles in quantum physics do inference over the forces acting on
them at a macroscopic level and act accordingly on average. That this higher-level inference is
generally conducive to self-organisation has been remarked on in [20].
B. A map of that part of the territory that behaves as if it were a map
We will now argue that the FEP evinces a ‘map’ of sorts: a map of that part of the territory
which behaves as if it were a map. In other words, the FEP provides us with tools to understand
mathematically the representational capacities of self-organising systems. Even more simply, it
gives us tools to model systems that look as if they are modelling the world, producing a map of
the mapmaker, as it were.
9
How does one get beliefs and inference from FEP-theoretic models? How does FEP-theoretic
technology allow us to model self-organising systems as themselves engaging in inference and belief
updating? The joint probability p(η,b,µ) plays a central role here. This generative model can be
read as a probabilistic specification of the states characteristically occupied by the joint particle-
environmentsystem. Inthissense, itprovidesconstraintsonthekindofstatesthejointsystemcan
be found in. In other words, it is the ‘territory’ that characterises the system. On another reading,
it can be regarded as a generative model that gives rise to the free energy in (1), and thereby the
free energy gradients that underwrite particular dynamics. On this view, it is a generative model
that is entailed by the recognition model, where we can read the recognition model as a map;
namely, a map from internal states to Bayesian beliefs about external states (i.e., the probabilistic
image of the mapping). If we now move to a meta-theoretical perspective and consider one particle
(e.g., a scientist or philosopher) observing another particle, we have the interesting situation where
the philosopher may impute a particular generative model that best explains the mechanics of the
observed particle. Is this meta-model a map or a territory?5
The meta-model is our scientific model of the system, as observers or modellers. We generally
assume that the system is its ‘own best model.’ In other words, our scientific model is just the
joint probability density that describes the state of the system (i.e., the territory). This can be
read as a new take on the nouvelle AI idea that physical systems are their own best models; or
as a new take on the good regulator theorem. For instance, in work on robotics following the
tradition of embodied cognition [23, 24], practitioners have eschewed the construction of agents
with internal representations of some environment. In these systems, the physics and geometry of
the situation were sufficient to endow these agents with the capacity to couple to an environment.
The world is, on this view, its own best representation. In our view, this approach dovetails nicely
with FEP-theoretic modelling, where the generative model in FEP-theoretic constructions is just
a joint probability density defined over all the states (or paths) of a system. In other words, the
generative model is just our representation of the world as we believe it to be; and this model
need not be encoded directly in the particle or agent. Given a generative model or Lagrangian
of the appropriate sort, we can show that the system evinces a particular partition (i.e., contains
particles); and we can show that subsets of the system track each other, where tracking means
inferring or becoming the sufficient statistics of probabilistic beliefs about their external states.
5 This meta-theoretical move is commonplace in practical applications of the FEP and is sometimes referred to
as meta-Bayesian inference or, more simply, observing the observer [21]. Practically, it involves optimising the
parametersofagenerativemodel,suchthatundertheFEP(theidealBayesianobserverassumption)theobservable
behaviouroftheparticleisrenderedthemostlikely. ThisapplicationoftheFEPisoftendescribedascomputational
phenotyping [22].
10
We interpret this tracking as a form of inference, namely, variational or approximate Bayesian
inference under a generative model (i.e., the map).
It is important to say explicitly that the sense in which a system is its own best model (qua
generative model) is not the same sense in which particles of the system are models (i.e., maps)
of their environment, or of themselves acting in their environments (qua recognition model); they
are of course connected, in the sense that the dynamics of internal states or paths (and thereby, of
particular recognition models) entail a generative model (via (1), for instance) [15].
Itisimportanttodefuseapossible(butinourviewna¨ıve)objection. Itisatruismthatphysical
systems need not explicitly calculate their trajectories of motion, to be modelled as pursuing such
trajectories. In developing a Bayesian mechanical account of the dynamics of systems, we need
not assume that the particle itself is literally performing inference.6 What is at stake is an ‘as
if’ description. We simply assume that there exists a quantity that varies systematically with the
dynamics of the system. It just so happens that, under the FEP, this quantity turns out to be
surprisal (or, equivalently, variational free energy); and that the minimisation of this quantity is
mathematically equivalent to inference, in the sense of being an estimator, as discussed above.
Thus, our map (as scientists and modellers) can be identified in an unproblematic way as the
generative model or Lagrangian of the system, which FEP-theoretic technology enables us to write
down. And it so happens that our model is a model of the representational capacities of subsets of
the target system: that is, our map is precisely a map of systems that behave as if they were maps,
allowing us to construct scientific models of the maps that are encoded by the internal subset of
the system considered.
In summary, our scientific model is, metaphorically, a map that allows us to say that some
(internal) subset of the system looks as if it possesses a map; which we interpret formally as
tracking the statistics of another (external) subset. This arguably defuses the first aspect of the
map-territory fallacy: namely, it shows that there is no conflation of the map and the territory, at
a first level of analysis.
6 Ways of defending stronger, increasingly literal versions of this positions are available as well. For a defence of
the claim that physical systems are quite literally in the business of inference, see [14, 25]. Related to this, it is
possible to articulate a version of the notion of notion of implementation, whereby a physical process implements
acomputationprovidedthataso-calledinterpretationmapexists,andcommutesintheappropriatemanner,such
thatthephysicalprocesscanbeinterpretedasimplementingacomputation; see[26]forthegeneralaccount,and
[7, 27] for its application to the FEP.
11
C. Maps that are optimal employ the CMEP; maps of maps that are optimal employ the
FEP
Mathematically,entropyistheuniquefunctionalofprobabilitydensitieswhichyieldsconsistent,
unbiased inferences [28, 29] and is sufficiently general to recover all of equilibrium thermodynamics
[29–31] and much of information and probability theory [32, 33]. Maximum entropy inference, in
which we find the probabilistic model that maximises entropy, given some specific constraints (e.g.,
somedata), isdesignedastheleastbiasedinferencewhichaccountsforknowninformation, making
it optimal in the sense of being neither overfitted nor incomplete for any given scenario. As a mod-
elling principle, the constrained maximum entropy principle (CMEP) is canonically the soundest
[31, 32]. For a complete review of the principles behind the CMEP, see [34]. For convenience,
we refer to this host of results as ‘Jaynes optimality.’ A model is Jaynes optimal if it is optimal
for a set of known unknowns, i.e., it produces the model which neither overfits those constraints
nor ignores them, by assigning probability in accord to the preference induced by constraints [6].
Contrast this with Bayes optimality, which is a model that provides a lower bound on classification
error: Bayesian updates can be derived from maximum entropy (see [35] and references therein, or
more recently, [36]), so we assume these are closely related. Under the assumption that particles
are Bayes optimal (perhaps justified by the complete class theorem that Bayes optimal agents do
exist), they are Jaynes optimal, and vice-versa. In the simpler case of conditional independence of
inputs, for instance, it is known that na¨ıve Bayes classifiers are CMEP models.
It stands to reason, then, that systems which model their environments use the principle of
maximum entropy. Recall the use case driving the FEP: we need to use a principled modelling
framework to form (scientific) models of things using principled modelling frameworks to form
(recognition)models. Inthissense,itwouldbeidealiftheFEPisanelegantshorthandforapplying
maximum entropy to model things using maximum entropy. Recent literature [6, Theorem 4.1]
has shown that this is precisely the case.
Let us assume that a particle models its environment, justified by the deflationary approach to
estimation-as-modelling discussed above. The FEP is what allows us to model this model; we want
to prove that it is equivalent to the sort of model that such a particle actually could be expected
to use. Take (1) and negate it once, then maximise it instead of minimising it. Grouping the last
two terms in the expression, we then have
(cid:90) (cid:18) (cid:90) (cid:19)
− q(η;σ(µˆ ),Σ )logq(η;σ(µˆ ),Σ )dη− − q(η;σ(µˆ ),Σ )logp(η | b,µ)dη−logp(µ,b) .
b η|b b η|b b η|b
Contrast this with maximising the entropy of the recognition model q subject to the constraint
12
that the surprisal of the environment given the particle is (on average) no greater than the intrinsic
surprisal of the particular states: −E [logq]−(E [J(η)]−C) where J(η) = −logp(η | b,µ) and
q q
C = −logp(µ,b), and this proves the claim. That is to say, since maximising a positive quantity
is the same as minimising a negative quantity, if things model their environments by using the
CMEP, then the FEP is an equivalent (scientific) model of that (scientific) model. As such, the
FEP is not merely a model of models, but is the model of the models that all such systems that
model their environments use, due to its relationship to the CMEP. The Jaynes optimality of the
chosen recognition density in the FEP rests precisely on using constrained maximum entropy to
choose that density.
The point of this section has ultimately been that, if particles use the CMEP to model their
environments(whichisreasonablegiventheyareoptimalinthesensediscussedabove)thenunder-
standing what our FEP-theoretic model does is like inhabiting the system and understanding what
the particle does. Recall that by constructing a model of the particle modelling its environment,
there exists an induced model of the states of the particle µ doing that modelling under σ. Next,
we will prove that the induced model on internal states is also optimal, for largely the same reason:
ourselves, as observers in an environment, also ought to employ the CMEP to model particles in
our environment—a symmetry which is brought to life by the FEP.
III. OF MAPS OF MAPS
A. The duality of FEP and CMEP
Therearetwowaystomodelaparticlemodellingitsenvironment: (i)tomodeltheenvironment
as though we are the particle modelling its environment (from its own first-person perspective),
or, (ii) to model the particle holding a model of the environment. These perspectives reduce to
‘forming a model of external states as if we were the particle’—what we have called a map of
the piece of the territory which behaves like a map, which allows us to understand the inference
performed by other particles, which is in turn the core of the FEP—and ‘forming a model of the
internal states which model external states,’ the actual application of the FEP, which allows us to
write down those inferences on paper. Paradoxically, these are equivalent statements, in that both
‘access’ the generative model enailed by the system. However, as methods they go about that goal
in radically different—even directly opposing—ways. Opposites that are equal in some sense are
known in mathematics as adjoint pairs.
13
It has long been remarked that the FEP-theoretic problems are equivalent to maximum en-
tropy problems with a constraint, where the constraint is a log-probability function supplied by a
generative model. Recent work has demonstrated that the FEP is, in a specific sense, mathemat-
ically equivalent to the CMEP. They are two sides of the same metaphorical coin. More precisely,
they are dual to each other [5, 6]; see in particular [6, Theorem 4.2]. The existence of a duality
relationship between two structures means (informally) that those two structures are dual to each
other, i.e., that they form an adjoint pair. Adjoint pairs are structures with identical ‘objects,’
but where things that act on those objects act in an opposite manner to each other. Here, the
adjunction is semi-obvious: the objects (internal and external states) are the same, but our model
either(i)looks‘outwards’,fromtheparticle’sfirst-personperspective,byformingamodelofbeliefs
and inferences about external states, or (ii) looks ‘inwards’ at the system from a scientific (second
person) perspective by forming a model of the dynamics of internal states in relation to external
states.
We can understand this as the following: suppose we have the recognition density q(η | µ),
a parameterised family of proposed recognition models held by the particle, each of which is
conditioned on the particular value of the internal state holding that belief. Then one value of µ
yields the optimal model, µ = µˆ = σ−1(ηˆ ). Our model of a thing which models its environment
b b
undermaximumentropycanthusbeformedbymaximisingtheentropyofourownscientificmodel
under the constraint that our model should model a system modelling its environment. This is the
meta-Bayesianapplicationoftheconstrainedmaximumentropyprinciple,wheretheconstraintsare
supplied by ideal Bayesian observer assumptions (i.e., that the behaviour of the observed observer
complieswiththeFEP[21]). Thissimplystatesthatourmodelofparticularstatesshouldconsider
that the particle as an observer or estimator, and reproduce our intended aim of modelling the
particle given our knowledge that the particle’s behaviour is contingent on its model. Thus, we
can maximise the following entropy functional:
−E [logp(µ | b)]−λ (cid:0)E J(µ)−Σ (cid:1) (2)
p(µ|b) p(µ|b) η|b
where J(µ) = [µ−k]2 and k = σ−1(ηˆ )—in other words, a model of a system that (on average,
b
though how often precisely is controlled by the Lagrange multiplier λ) holds an optimal model
of its environment. Note that this particle also matches the variance of the environment, not
just the mode, in order to model the full suite of environmental states. Notice also that we have
switched the locations of η’s and µ’s compared to (1), now maximising the entropy of the model of
internal states modelling external states, rather than the model of external states. This reflects the
14
duality referenced. Together, we implicitly have a maximum entropy model of the system holding
a maximum entropy or FEP-theoretic belief.7
This leads us to another, absolutely core, point—one which is central to the FEP itself, and
hence to any candidate philosophy of the FEP and Bayesian mechanics. The duality we have
leveraged arises from the fact that the boundaries of a particle are symmetrical. In turn, this
means the environment of a particle is also an agent that models the particle. More precisely, the
particle and environment each model the actions of the other on their mutually shared blanket
states. Nature is constantly dissipating organised structures in the world, and the inference that
is performed by the natural world is how best to dissipate the energy held in any such structure.
The only way to avoid this is to mirror nature herself; this is the point of us modelling ‘things’
as being unsurprising. This is the game that is characteristic of self-organisation, and only by
understanding both sides can we understand self-organisation; such an attitude has been referred
to as a relational approach to biological physics [37].
In the end, map and territory are simply dual perspectives; the fact that the FEP applies to us,
and that we articulate models from our perspective as external observers, may often blind us to
this duality. However, it underwrites the whole argument on offer: the FEP packages together an
optimal model of a thing and an optimal model of the thing’s model to achieve a new view on self-
organisation. This is also what we mean by the FEP being the application of maximum entropy to
thingsthatmaximiseentropy, againmakingituniqueamongstmodellingmethods. Bymodellinga
particle modelling its environment, we achieve a dual model of the particle automatically, induced
by the symmetry between external and internal states. However, a further uniqueness of the FEP
is that, by emphasising the viewpoint of internal states, it is uniquely suited modelling action and
cybernetic systems. The dual, CMEP-theoretic viewpoint is a good (i.e., Jaynes-optimal) account
of the dynamics of particles that stay together, in virtue of looking at an anomalous ‘thing’ that
organises (i.e., the viewpoint of some scientist or heat bath), but does not include an account of
action or policy explicitly [6]. As indicated, this agent-centred perspective is what the FEP brings
to the table.
That the FEP and the CMEP turn out to be two complementary perspectives on the physical
existence of systems with particular partitions has profound implications, which have not been
remarked upon previously in great detail (although see [5] for an exposition of the mathematical
7 For completeness, note that we often assume the synchronisation map applies to the conditional maximum a pos-
teriori estimate,suchthatthesysteminferstheparametercontrollingtheplacementofthepeakoftheprobability
density: themostlikelystateoftheenvironment. Ourmaximumentropymodelofthismodelassumestheparticle
isperformingaLaplaceapproximation[3]. Importantly,notethatthelog-probabilityconstraintin(1)isprecisely
the variance term in (2) under a Laplace approximation, meaning that (1) and (2) are identical up to dualisation
in that case. More general forms for (2) are possible which generalise beyond the Laplace assumption.
15
nature of this duality). FEP-theoretic models of complex physical systems, as we have seen, are
mechanical theories, which provide us with an explanation (i.e., laws of motion) of the observable
behaviour (or dynamics) of a system, from the point of view of a particle that self-organises (i.e.,
from the point of view of a ‘self’). Dually, the CMEP provides a description of self-organising
systems, this time from the point of view of an observer, located in the external environment.
Now, it is a mathematical fact that one can appeal to this duality to convert any FEP-theoretic
model into an equivalent CMEP-theoretic one. More precisely, an FEP-theoretic model of belief
updating (i.e., a model of the dynamics of beliefs, encoded by the internal states of a particle)
can always be converted to a dual CMEP-theoretic model of systemic dynamics (i.e., a model
of the dynamics of the states or paths of the system per se, as opposed to the beliefs that they
encode). Moreover if we have one, we implicitly have the other. This argument extends the
dual aspect information geometry of internal states—describing their thermodynamics [19]—and
the information geometry that arises when internal states are read as the sufficient statistics of
Bayesian beliefs about external states [12].
Besides being a well-appreciated and established theory in physics, as we will go on to discuss,
therelationshiptotheCMEPjustifiestheFEPasastatistical-mechanicallyoptimalmodelofsome
unknown data-generating process.
B. FEP-theoretic models of encoded beliefs are CMEP-theoretically optimal models of
systemic dynamics
The effectiveness of the CMEP in statistical physics and beyond is not to be taken lightly, and
the implications of this duality are far reaching. Some commentators have argued that the FEP is
not special [38]: on this view, the FEP is merely one formal approach to the dynamics of complex
systems, without any special epistemic status. The duality of FEP and CMEP negates this claim.
Indeed, as we have outlined, maximum entropy inference is a way of arriving at the best model
possible, mathematically, given our state of knowledge about the system being modelled. So, the
duality of FEP and CMEP has a dramatic and deeply significant implication: given the duality
of FEP and CMEP, we can state in full generality that a FEP-theoretic model of a particle’s
belief updating is the optimal model of systemic dynamics, from the point of view of an external
observer. We know that an FEP-theoretic model of a particle’s beliefs about a system simply is
a maximum entropy model of the states of the system, albeit seen from another perspective. We
know that maximum entropy inference enables us to arrive at the optimal model of that system,
16
given our state of knowledge. The implication is that, given some constraints, the FEP-theoretic
model is the optimal model of the physics of a system. This makes intuitive sense: due to the way
that the generative model or Lagrangian is defined (i.e., over all the subsets of the systems), the
FEP-theoretic model contains every ingredient needed to fully account for the manner in which
subsets coupled to each other.
Of course, practically, it does not suffice to write down a path of least surprisal. Minimally,
withoutsomeadditional specification, sucha scientific modelcannot be complete; since the bound-
ary conditions (e.g., initial conditions and constraints) have to be added. More directly relevant to
our present concerns, one must specify the form of the generative model or Lagrangian, which is
often far from a trivial exercise. It is always a model in context. Indeed, it is the model or energy
function which does most of the heavy lifting when it comes to modelling specific, empirical sys-
tems. We still need to find the appropriate set of constraints; what the technology of FEP/CMEP
enables is doing the best inference possible, given our state of knowledge. Indeed, given that they
are principles (i.e., mathematical structures with no empirical content), one cannot falsify the
FEP/CMEP directly [5, 39]. This would be like attempting to falsify calculus or group theory:
this constitutes a category error. One can only falsify specific models that have been derived from
FEP/CMEP-theoretic technologies. When we arrive at incorrect results using these methods, the
mistake usually lies in the application: the inference was optimal, given the non-optimal data set
that we were using to constrain our inference procedure. What counts, in some sense, then, is
the function that we put the model to use. Assuming we have adequate knowledge of the target
system, and have written that knowledge down adequately as a set of sensible constraints, then
the FEP-theoretic model is the optimal model; and if we have not done so, then we ought to be
preparedforourmodeltonotbeoptimal. ThesameproblemhasbeenknowninBayesianstatistics
for some time, and hence ought not to be particularly striking [40].
These considerations serve to decisively defuse the second horn of the map-territory fallacy,
which is that map and territory are always separate. Indeed, the FEP is not a mere model of
physical processes: it is the optimal model given our state of knowledge, and therefore, poses
absolute constraints on what it means to be a model of some physical process.
IV. TOWARDS A PHILOSOPHY OF THE FEP AND BAYESIAN MECHANICS
We now briefly summarise and elaborate on the points discussed above. We propose these few
points as the foundations of a philosophy of Bayesian mechanics, which has yet to be constructed.
17
A. A map of map-like territories, and a map of possible maps: Towards a dynamical,
nested representationalism
In summary, we have argued that the map-territory fallacy, as it has been leveraged against the
FEP (e.g., by [9, 10]) simply does not apply to FEP-theoretic modelling: it constitutes a fallacy,
which we have called the map-territory fallacy fallacy. Mathematically, there is no ambiguity
or conflation of map and territory in FEP-theoretic modelling. Although the language used to
narrate the mathematics of the FEP are at times ambiguous (which may have led to the confusion
of some segments of the philosophical commentary and reporting on the FEP), the mathematical
structureitselfisnot. Thatthetargetsystemitselfis agenerativemodelorLagrangianoughttobe
read as shorthand, to mean that the model that we deploy as scientists is meant to capture all the
dependenciesthatexistwithinthesystem. Theparticleitselfdeploysarecognition model, whichits
internalstatesencode; theirdynamicsaregiveninour generativemodel, whichismeanttocapture
the real dependence relations of the target system [15]. Applications of the FEP thus commit to
a kind of ‘nested representationalism,’ in the sense that it is a scientific model (implemented as a
generative model of states or Lagrangian of paths), the content of which is precisely a mechanistic
theory for the representational capacities of certain particular kinds of systems. Here, and in
subsequent publications, we argue that the correct interpretation of the FEP is a dynamical,
nested representationalist one.
Moreover, as we have seen, the FEP is not merely one possible way to model physical systems.
Instead, it is the optimal model of systemic dynamics, given our state of knowledge. Thereby,
the FEP/CMEP duality imposes ultimate constraints on what it means to be a physical model
of some target system. Thus, FEP/CMEP provides us with core mathematical constraints on the
optimalityofmodellingstrategies. Thisdeterminationofconstraintsonwhatitmeanstophysically
realise a model from within the formal constraints of the mathematics of physical modelling itself
is reminiscent of Kant’s attempt to arbitrate the limits of reason from within the system of reason
itself[41]; oragain,Wittgenstein’sattempttoformulatethestructureofanypropositioningeneral,
within the language of propositional calculus [42]: it is an attempt to provide constraints on any
possible meaningful maps, which arise from what it means to be a map or model of a physical
process.
What is unique about the FEP/CMEP approach is that it is ultimately a model that is apt
to model the modeller. Indeed, the Markov blanket is a symmetric boundary between particle
and environment. We see the world through our own Markov blanket; and any possible observer
18
constitutestheenvironmentfortheparticlethatwearemodelling. Fromthepointofviewfurnished
bytheFEP/CMEPduality,ourscientificmodelsareattemptstoinferwhatrevealsitselfvicariously
through our Markov blanket. What we, as modellers, call systems or particles ultimately reflect
what we, as modellers, can observe, and identify as persistent entities that sketch themselves out
on our Markov blanket.
This position can be illustrated by revisiting the map–territory fallacy through the lens of the
FEP. The foregoing argument suggests that one should not ask whether the FEP is subject to the
map-territory fallacy; rather, one should ask whether the map-territory fallacy subject to the FEP.
With a careful and formal definition of map and territory, the answer is yes, in the following sense.
One can associate the ‘territory’ with the generative model describing the joint probability over
causes and consequences, from the perspective of some ‘thing.’ The ‘map’ may be best ascribed to
the recognition model in the sense that a map denotes a mapping; here, a map from internal states
toBayesianbeliefsaboutexternalstates. Notethatfora‘map’toexistinthissense,therehastobe
a partition of states: in the absence of a Markov blanket—which distinguishes internal states from
external states—there can be no map, and therefore, no fallacy. With these definitions in place,
the map–territory fallacy reduces to a failure to distinguish between recognition and generative
models. This distinction is precluded by the FEP, whose core claim is that the map depends in
a lawful way on the territory—and that this mapping has existential implications, i.e., that there
exists a particular partition or something that holds a recognition model about external states [15].
So, can there be a map-territory fallacy in applications of the FEP to form scientific models?
Again, the answer is yes, with some interesting examples. In applications of the FEP, we are
building recognition models (i.e., maps) of generative models (i.e., territories) that best explain the
behaviour of something. To reify one of these maps is to falsely infer that our scientific recognition
model is the true generative model. Examples of this in statistics could include the fallacy of
classical inference [43]; in which the false inferences rest upon using the wrong kind of (point null)
hypotheses. Perhaps a more interesting example of false inference is psychopathology; namely,
the type I errors when we falsely infer something is there when it is not (e.g., hallucinations and
delusions)ortypeIIerrorswhenwefalselyinfersomethingisnottherewhenitis(e.g., dissociative
symptoms and neglect syndromes). In fact, there is a large literature in computational psychiatry
[44–49]thatcouldbereadasonekindofmap–territoryfallacy(i.e., conflatingone’sfalseinferences
with reality)—a very special kind of fallacy that inherits from applications of the FEP. Holding an
optimal map for the wrong territory is the same sort of failure to be a proper Bayesian that we
discussed in Section IIIB—not a failure of Bayesian inference per se, but a misapplication of such
19
an inference.
B. On the theoretical appropriation of the FEP in philosophy
The core publications on the FEP and Bayesian mechanics have mostly been in mathematical
biophysics [2, 6, 50] and computational or theoretical neuroscience [4, 51]. Since the middle of
the last decade, he FEP has also generated much interest in philosophy [52, 53]. Despite these
efforts,andwithafewexceptions(e.g,[12,39]),therehasbeenverylittleworkonthephilosophical
commitments of the FEP per se; and, given that it has only emerged self-consciously over the last
few years, there is only one publication to date discussing the philosophy of Bayesian mechanics
[5]. Indeed, arguably, most extant philosophical work on the FEP starts from a given set of
assumptions—for example, about the extended mind [54], the enactive approach to cognition [15],
or neo-Kantian, indirect accounts of perception [55]—and then proceeds to present a reading of
the FEP that fits as well as possible with those assumptions. This seems especially common in
scholarshipthatisindependentlycommittedtophilosophicalthesesthatare, inmanycrucialways,
contradictory to the core commitments of the FEP, such as staunch anti-representationalism and
the rejection of computational and information theoretic tools to study self-organising systems
[56, 57].
We do not think that this is conducive to understanding the theory and commitments of the
FEP and Bayesian mechanics themselves (although we have been guilty of this ourselves, in some
cases). Indeed, we believe that the variegated theoretical appropriation of the FEP is one central
reason why there seem to be several different interpretations or versions of the FEP—with wildly
conflicting theoretical assumptions and broader philosophical commitments. We urge researchers
in the tradition to pursue their examinations of the FEP on its own merits, setting aside questions
about its compatibility with specific, independent philosophical perspectives (or the lack thereof).
V. CONCLUSION
This paper has taken some first steps towards the development of a semi-axiomatic meta-
theory and philosophy of the free energy principle (FEP) and Bayesian mechanics, providing a
justificationofitsuseinthemodellingofphysicalsystems, andanexplanationofitsscopeinterms
of first principles. We argued that, in describing ‘things’ or ‘particles’ as estimators or (deflated)
representations of the systems to which they are coupled, the FEP-theoretic apparatus does not
20
commit the map territory fallacy, i.e., it is false that the FEP reifies aspects of the metaphorical
map (i.e., our scientific model), mistakenly taking them to be part of the territory (i.e., the target
system that we wish to model). We have argued that this allegation itself constitutes a map-
territory fallacy fallacy. We have argued that, in distinguishing the generative and recognition
models, FEP-theoretic modelling allows us to construct a map of that part of the territory that
behaves as if it were a map, without reification. Second, we have leveraged the duality of the FEP
and the CMEP to argue that, in a Kantian or Wittgensteinian manner, the FEP also provides us
withultimateconstraintsonwhatitmeanstobeanoptimalmodelofphysicalprocesses. TheFEP
us thus, metaphorically, a map of any possible map whatsoever of, or held by, a physical system.
We ought to celebrate the territory map mapping. The FEP is really, at its core, a principled
approach to the formalisation of this mapping. The FEP is utterly unique as a ‘Jaynes-optimal’
model of physical systems that model (i.e., are estimators of the statistics of) their environments.
This restores convention to the FEP, via its relation to the CMEP: the FEP is not a strange
theoretical beast residing in a faraway corner of theoretical biology, but rather, turns out to be a
core principle of physical science. Our meta-theoretical approach to the FEP clarifies its role and
scope as the uniquely ideal or optimal modelling tool for generic systems in statistical physics.
Acknowledgements
We are thankful to Mahault Albarracin, Mel Andrews, Lancelot Da Costa, Chris Fields, James
Glazebrook, Alex Kiefer, Gabriel Ren´e, and Adam Safron, as well as the regular attendees of the
Theoretical Neurobiology Group Meetings at University College London’s Wellcome Centre for
Human Neuroimaging, for fruitful discussions that helped to shape the content of this paper.
[1] Karl J Friston, Lancelot Da Costa, Noor Sajid, Conor Heins, Kai Ueltzh¨offer, Grigorios A Pavli-
otis, and Thomas Parr. The free energy principle made simpler but not too simple. 2022. Preprint
arXiv:2201.06387.
[2] Karl J Friston. A free energy principle for a particular physics. 2019. Preprint arXiv:1906.10184.
[3] Lancelot Da Costa, Karl J Friston, Conor Heins, and Grigorios A Pavliotis. Bayesian mechanics for
stationary processes. Proceedings of the Royal Society A, 477(2256), 2021.
[4] Karl J Friston. The free-energy principle: a unified brain theory? Nature Reviews Neuroscience,
11(2):127–138, 2010.
21
[5] Maxwell J D Ramstead, Dalton A R Sakthivadivel, Conor Heins, Magnus Koudahl, Beren Millidge,
Lancelot Da Costa, Brennan Klein, and Karl J Friston. On Bayesian mechanics: a physics of and by
beliefs. 2022. Preprint arXiv:2205.11543.
[6] Dalton A R Sakthivadivel. Towards a geometry and analysis for Bayesian mechanics. 2022. Preprint
arXiv:2204.11900.
[7] Chris Fields, Karl J Friston, James F Glazebrook, and Michael Levin. A free energy principle for
generic quantum systems. Progress in Biophysics and Molecular Biology, 173:36–59, 2022.
[8] Dalton A R Sakthivadivel. Weak Markov blankets in high-dimensional, sparsely-coupled random dy-
namical systems. 2022. Preprint arXiv:2207.07620.
[9] Jelle Bruineberg, Krzysztof Dolega, Joe Dewhurst, and Manuel Baltieri. The emperor’s new Markov
blankets. Behavioral and Brain Sciences, pages 1–63, 2020.
[10] Thomas van Es. Living models or life modelled? On the use of models in the free energy principle.
Adaptive Behavior, page 1059712320918678, 2020.
[11] Mel Andrews. Making reification concrete: a response to Bruineberg et al. 2022.
[12] Karl J Friston, Wanja Wiese, and J Allan Hobson. Sentience and the origins of consciousness: from
Cartesian duality to Markovian monism. Entropy, 22(5):516, 2020.
[13] Maxwell J D Ramstead, Karl J Friston, and Inˆes Hipo´lito. Is the free-energy principle a formal theory
of semantics? From variational density dynamics to neural and phenotypic representations. Entropy,
2020.
[14] Alex B Kiefer. Psychophysical identity and free energy. Journal of the Royal Society Interface,
17(169):20200370, 2020.
[15] Maxwell J D Ramstead, Michael D Kirchhoff, and Karl J Friston. A tale of two densities: active
inference is enactive inference. Adaptive Behavior, 28(4):225–239, 2020.
[16] Maxwell J D Ramstead. The empire strikes back: some responses to Bruineberg and colleagues, 2021.
Preprint arXiv:2112.15528.
[17] Dalton A R Sakthivadivel. A worked example of the Bayesian mechanics of classical objects. In The
Third International Workshop on Active Inference, 2022. Preprint arXiv:2206.12996. To appear.
[18] Ilya Prigogine. Time, structure, and fluctuations. Science, 201(4358):777–785, 1978.
[19] Gavin E Crooks. Measuring thermodynamic length. Physical Review Letters, 99(10):100602, 2007.
[20] Maxwell J D Ramstead, Casper Hesp, Alexander Tschantz, Ryan Smith, Axel Constant, and Karl J
Friston. Neural and phenotypic representation under the free-energy principle. Neuroscience & Biobe-
havioral Reviews, 120:109–122, 2021.
[21] Jean Daunizeau, Hanneke E M Den Ouden, Matthias Pessiglione, Stefan J Kiebel, Klaas E Stephan,
andKarlJFriston. Observingtheobserver(I):meta-Bayesianmodelsoflearninganddecision-making.
PLoS ONE, 5(12):e15554, 2010.
[22] Philipp Schwartenbeck and Karl J Friston. Computational phenotyping in psychiatry: a worked ex-
ample. eNeuro, 3(4), 2016.
22
[23] Randall D Beer. Computational and dynamical languages for autonomous agents. In Mind as Motion:
Explorations in the Dynamics of Cognition, pages 121–147. 1996.
[24] Rodney A Brooks. Intelligence without representation. Artificial Intelligence, 47(1-3):139–159, 1991.
[25] Alex B Kiefer. Literal perceptual inference. In Philosophy and Predictive Processing, 2017.
[26] Clare Horsman, Susan Stepney, Rob C Wagner, and Viv Kendon. When does a physical system
compute? Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences,
470(2169):20140182, 2014.
[27] Chris Fields, James F Glazebrook, and Michael Levin. Neurons as hierarchies of quantum reference
frames. Biosystems, 219:104714, 2022.
[28] John Shore and Rodney Johnson. Axiomatic derivation of the principle of maximum entropy and the
principle of minimum cross-entropy. IEEE Transactions on Information Theory, 26(1):26–37, 1980.
[29] Steve Press´e, Kingshuk Ghosh, Julian Lee, and Ken A Dill. Principles of maximum entropy and
maximum caliber in statistical physics. Reviews of Modern Physics, 85(3):1115, 2013.
[30] Edwin T Jaynes. Information theory and statistical mechanics. Physical Review, 106(4):620, 1957.
[31] Steve Press´e, Kingshuk Ghosh, Julian Lee, and Ken A Dill. Nonadditive entropies yield probability
distributions with biases not warranted by the data. Physical Review Letters, 111(18):180604, 2013.
[32] Edwin T Jaynes. Probability Theory: The Logic of Science. Cambridge University Press, 2003.
[33] Petr Jizba and Jan Korbel. When Shannon and Khinchin meet Shore and Johnson: equivalence of
information theory and statistical inference axiomatics. Physical Review E, 101(4):042126, 2020.
[34] Adom Giffin. Maximum entropy: the universal method for inference. 2009. Preprint arXiv:0901.2987.
Doctoral thesis.
[35] Edwin T Jaynes. The relation of Bayesian and maximum entropy methods. In Maximum-Entropy and
Bayesian Methods in Science and Engineering, pages 25–29. Springer, 1988.
[36] Ariel Caticha and Adom Giffin. Updating probabilities. In AIP Conference Proceedings, volume 872,
pages 31–42. American Institute of Physics, 2006.
[37] Robert Rosen. A relational theory of biological systems. The Bulletin of Mathematical Biophysics,
20(3):245–260, 1958.
[38] VicenteRaja,DineshValluri,EdwardBaggs,AnthonyChemero,andMichaelLAnderson. TheMarkov
blanket trick: on the scope of the free energy principle and active inference. Physics of Life Reviews,
39:49–72, 2021.
[39] MelAndrews. Themathisnottheterritory: navigatingthefreeenergyprinciple. Biology&Philosophy,
36(3):30, 2021.
[40] DavidHWolpert. ReconcilingBayesianandnon-Bayesiananalysis. InMaximumEntropyandBayesian
Methods, pages 79–86. Springer, 1996.
[41] Immanuel Kant. Critique of Pure Reason. 1781. 1908 edition, Houghton Mifflin.
[42] Ludwig Wittgenstein. Tractatus Logico-Philosophicus. 1922. 2013 edition, Routledge.
[43] Dennis V Lindley. A statistical paradox. Biometrika, 44(1/2):187–192, 1957.
23
[44] KarlJFriston. Precisionpsychiatry. Biological Psychiatry: Cognitive Neuroscience and Neuroimaging,
2(8):640–643, 2017.
[45] David Benrimoh, Thomas Parr, Rick A Adams, and Karl J Friston. Hallucinations both in and out of
context: an active inference account. PLoS ONE, 14(8):e0212379, 2019.
[46] Ryan Smith, Richard D Lane, Thomas Parr, and Karl J Friston. Neurocomputational mechanisms
underlying emotional awareness: insights afforded by deep active inference and their potential clinical
relevance. Neuroscience & Biobehavioral Reviews, 107:473–491, 2019.
[47] AdamLinson, ThomasParr, andKarlJFriston. Activeinference, stressors, andpsychologicaltrauma:
Aneuroethologicalmodelof(mal)adaptiveexplore-exploitdynamicsinecologicalcontext. Behavioural
Brain Research, 380:112421, 2020.
[48] Philipp Sterzer, Rick A Adams, Paul Fletcher, Chris Frith, Stephen M Lawrie, Lars Muckli, Predrag
Petrovic,PeterUhlhaas,MartinVoss,andPhilipRCorlett. Thepredictivecodingaccountofpsychosis.
Biological Psychiatry, 84(9):634–643, 2018.
[49] Vivien Ainley, Matthew A J Apps, Aikaterini Fotopoulou, and Manos Tsakiris. ‘Bodily precision’: a
predictivecodingaccountofindividualdifferencesininteroceptiveaccuracy. PhilosophicalTransactions
of the Royal Society B: Biological Sciences, 371(1708):20160003, 2016.
[50] Karl J Friston. A free energy principle for biological systems. Entropy, 14(11):2100–2121, 2012.
[51] Karl J Friston, Thomas Parr, and Bert de Vries. The graphical brain: belief propagation and active
inference. Network Neuroscience, 1(4):381–414, 2017.
[52] Andy Clark. Surfing Uncertainty: Prediction, Action, and the Embodied Mind. Oxford University
Press, 2015.
[53] Jakob Hohwy. The Predictive Mind. Oxford University Press, Oxford, 2014.
[54] Micheal D Kirchhoff and Julian Kiverstein. Extended Consciousness and Predictive Processing: A
Third-Wave View. Routledge, New York, 2019.
[55] Jakob Hohwy. How to entrain your evil demon. In Philosophy and Predictive Processing, 2017.
[56] Thomas van Es and Inˆes Hip´olito. Free-energy principle, computationalism and realism: a tragedy.
2020.
[57] Inˆes Hip´olito and Thomas van Es. Enactive-dynamic social cognition and active inference. Frontiers
in Psychology, 13, 2022.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "On the map-territory fallacy fallacy"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
