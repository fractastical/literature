=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Chance-Constrained Active Inference
Citation Key: laar2021chanceconstrained
Authors: Thijs van de Laar, Ismail Senoz, Ayça Özçelikkale

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2021

Abstract: Active Inference (ActInf) is anemerging theory thatexplains percep-
tion and action in biological agents, in terms of minimizing a free energy
bound on Bayesian surprise. Goal-directed behavior is elicited by intro-
ducing prior beliefs on the underlying generative model. In contrast to
priorbeliefs,whichconstrainallrealizationsofarandomvariable,wepro-
poseanalternativeapproachthroughchanceconstraints,whichallowfor
a (typically small) probability of constraint violation, and demonstrate
howsuchc...

Key Terms: actinf, passing, electrical, engineering, inference, dept, active, chance, message, constrained

=== FULL PAPER TEXT ===

Chance-Constrained Active Inference
Thijs van de Laar∗, I ˙ smail S¸eno¨z∗, Ay¸ca O ¨ z¸celikkale†, and Henk
Wymeersch‡
∗Dept. of Electrical Engineering, Eindhoven University of
Technology, The Netherlands
†Dept. of Electrical Engineering, Uppsala University, Sweden
‡Dept. of Electrical Engineering, Chalmers University of
Technology, Sweden
May 7, 2021
Abstract
Active Inference (ActInf) is anemerging theory thatexplains percep-
tion and action in biological agents, in terms of minimizing a free energy
bound on Bayesian surprise. Goal-directed behavior is elicited by intro-
ducing prior beliefs on the underlying generative model. In contrast to
priorbeliefs,whichconstrainallrealizationsofarandomvariable,wepro-
poseanalternativeapproachthroughchanceconstraints,whichallowfor
a (typically small) probability of constraint violation, and demonstrate
howsuchconstraintscanbeusedasintrinsicdriversforgoal-directedbe-
havior in ActInf. We illustrate how chance-constrained ActInf weights
allimposed(prior)constraintsonthegenerativemodel,allowinge.g.,for
a trade-off between robust control and empirical chance constraint vio-
lation. Secondly, we interpret the proposed solution within a message
passing framework. Interestingly, the message passing interpretation is
not only relevant to the context of ActInf, but also provides a general
purpose approach that can account for chance constraints on graphical
models. Thechanceconstraintmessageupdatescanthenbereadilycom-
bined with other pre-derived message update rules, without the need for
custom derivations. The proposed chance-constrained message passing
frameworkthusacceleratesthesearchforworkablemodelsingeneral,and
can be used to complement message-passing formulations on generative
neural models.
Index terms — Active Inference, Message Passing, Chance Constraints,
Variational Bayes
This is the author’s final version of the manuscript, as accepted for publica-
tion in MIT Neural Computation.
1
1202
yaM
6
]LM.tats[
2v29780.2012:viXra
1 Introduction
Similar to biological agents, learning to make decisions based on observations
andfeedbackfromtheenvironmentisalsoanessentialtaskforautonomousarti-
ficialagents. Traditionally,adaptivelinearcontrolandmodelpredictivecontrol
have been successfully applied in this area (Borrelli et al., 2017). Over the
past few years, reinforcement learning has become the predominant approach
(Recht, 2019). An emerging alternative perspective to decision making under
uncertaintyisactiveinference (ActInf)(Friston,2010). ActInfisaneuroscience-
based theory that has been used extensively to explain behavior of biological
agents in dynamic environments (Friston, 2010).
ActInf is based in the free energy principle (FEP), and postulates that per-
ceptionandactioninbiologicalagentsminimizeafreeenergyboundonBayesian
surprise. The free energy is an information-theoretic measure that bounds the
current and the future expected statistical surprise, i.e., how unpredictable are
the observations under a given generative model (GM). The free energy is as-
sociated with the Kullback-Leibler (KL) divergence (i.e., the distance) between
the approximate and the true posterior. In particular, according to the free en-
ergy principle, the agent acts in such a way as to minimize a free-energy bound
on the surprise, i.e., Bayesian surprise which, informally speaking, provides a
quantification of the difference between the agent’s predictions about the sys-
tem behavior and the observed system behavior. Minimization of free energy is
closelyrelatedtovariationalBayesianmethods, reinforcementlearning(Sallans
andHinton,2001;Tschantzetal.,2020;Sajidetal.,2021),anddeepgenerative
models (Ueltzh¨offer, 2018; Fountas et al., 2020), another set of popular ma-
chine learning approaches (Goodfellow et al., 2014). ActInf is closely related to
message passing on graphical models (de Vries and Friston, 2017; Friston et al.,
2017),andseveralwidelyusedmessagepassingalgorithms,including(loopy)be-
lief propagation, variational message passing and expectation propagation can
be derived as fixed-point equations of the (Bethe) free energy (Heskes, 2003;
Yedidia et al., 2005; Dauwels, 2007; Zhang et al., 2017). This relation has been
harnessed to develop elegant automated methods for ActInf (Schw¨obel et al.,
2018; van de Laar and de Vries, 2019).
In addition to investigation of motivating connections with the behavior
of the biological systems (Friston et al., 2006; Ramstead et al., 2018), ActInf
hasbeensuccessfullyutilizedinapplicationsinthetraditionalstochasticcontrol
scenarios,suchaslinearquadraticGaussian(LQG)controlandsimilarstandard
problems such as maze problems (Hoffmann and Rostalski, 2017; Ueltzh¨offer,
2018; Schw¨obel et al., 2018; Baltieri and Buckley, 2019; Millidge et al., 2020;
Imohiosen et al., 2020), and exploration-exploitation balancing in multi-armed
bandit problems (Markovic et al., 2021).
Despite these promising developments, the ActInf framework lacks certain
desirable features present in model predictive control. In particular, there is no
off-the-shelf standard ActInf formulation that allows inclusion of chance con-
straints in the problem setting. Chance constraints provide an attractive ap-
proach for on-line decision making for uncertain systems (Mesbah, 2016), i.e.,
2
systems where the dynamics are not fully known or the system contains certain
componentsthatarebestmodeledinastochasticmanner. Insuchsettings,con-
straintsonthesystembehavior,suchastheagentremaininginagivenregionof
the environment with a given probability, cannot directly be encoded in terms
of prior beliefs. In contrast to approaches that constrain all realizations of the
random variables, chance constraints allow for a (typically small) probability of
constraint violation, which can significantly improve performance since chance
constraints enable the decision maker trade performance with probability of
constraint violation (Blackmore et al., 2011).
Thispaperproposesacomputationallytractableapproachtochance-constrained
decision making, and applies it to an ActInf context. We include chance con-
straints in the ActInf objective (i.e., the free energy) by using the Lagrangian
formalism. We then solve the Lagrangian optimization problem by variational
calculus. Finally, we show that the proposed solution not only leads to a mod-
ularandscalablemessagepassingframeworkforActInfproblems, butalsopro-
videsageneralpurposemessagepassingframeworkthatcanaccountforchance
constraints on graphical models in general. We claim the following main con-
tributions:
1. We show that the analytic solution to the chance-constrained free energy
problem yields posterior beliefs in the form of truncated mixtures. (The-
orem 1)
2. Weshowhowthissolutioncanbeinterpretedintermsofmessagepassing
on a factor-graph representation of the generative model. (Theorem 2)
3. Consequently, our results provide a message passing framework that is
specifically designed to account for chance constraints.
Message passing is inherently modular, and (variational) message update
rules can be pre-derived and stored in a lookup table for later use (Korl, 2005;
vandeLaar,2019). Thechance-constrainedmessageupdatescanthenbereadily
combined with these pre-derived rules, without the need for laborious deriva-
tions. Our results illustrate that the proposed framework can successfully find
solutionssothattherateofconstraintviolationspecifiedintheoriginalproblem
andtheonethatisactuallyobservedduringtheclosed-loopoperationareclose.
Theresultsalsoillustratehowtobalancetheconstraintsontheactionsandthe
states through the usage of a tuning parameter, which enables exploration of
different trade-offs between immediate and delayed intervention.
2 Problem Statement
We start by defining a general factorized generative model f with respect to
an (arbitrary) collection of variables x. As a notational convention, individual
variables are indexed by i,j ∈ V, and factors by a,b,c ∈ F, unless stated
3
otherwise. The model then factorizes as
(cid:89)
f(x)= f (x ), (1)
a a
a∈F
withnon-negativerealfunctionsf ,andwherex ⊂xcollectstheargumentsof
a a
f . In a probabilistic generative model, the individual factors usually represent
a
conditional probability distributions. Probabilistic inference is then concerned
(cid:82)
with obtaining an (approximate) posterior belief q (x ) ∝ f(x)dx over a
j j \j
variable of interest x , where x indicates the integration over all model vari-
j \j
ables except x .
j
Wenowbrieflyrecaphowthecomputationofthesebeliefscanbeperformed
efficiently and automated over a factor graph (Loeliger et al., 2004), and how
this process can be interpreted as a Bethe free energy minimization problem
(Yedidia et al., 2005). With these concepts firmly in place, we move to chance
constraints and the formal problem statement in Sec. 2.4.
2.1 Factor Graphs for Marginal Belief Computation
A factor graph can be used to visually represent a factorized function. In this
paper we use the bi-partite factor graph representation. A bi-partite factor
graph
G =(F,V,E),
consistsofvariable-nodesV,factor-nodesF,andedgesE thatconnectvariable-
nodes with factor-nodes. A variable-node i ∈ V is connected to a factor-node
a∈F byanedge(i,a)∈E if(andonlyif)thevariablex isanargumentofthe
i
factor-function f . An example section of a graph is drawn in Fig.1, where the
a
circle and square represent a variable- and factor-node respectively. We write
. . . f b
µjb
← →
(xj)
x j . . .
µbj(xj)
Figure 1: Bi-partite subgraph of a model around a variable-node j (circle) and
factor-node b (square), with indicated messages. Ellipses represent a continua-
tion of the model.
the neighborhood of a variable-node i as F(i), which collects all factor-nodes in
F that are direct neighbors of i. Similarly, V(a) collects all variable-nodes in V
that are direct neighbors of a.
Suppose we are interested in obtaining a posterior belief q (x ). The belief
j j
propagation algorithm (Pearl, 1982) then prescribes we send messages from
4
the branches of the graph towards the variable-node of interest, following the
recursive application of the belief propagation update rules:
(cid:89)
µ (x )= µ (x ) (2a)
jb j aj j
a∈F(j)
a(cid:54)=b
(cid:90)
(cid:89)
µ (x )= f (x ) µ (x )dx , (2b)
bj j b b ib i b\j
i∈V(b)
i(cid:54)=j
where x collects all x with the exception of x . Here, µ (x ) represents the
b\j b j jb j
message from a variable-node j ∈V to a neighboring factor-node b∈F(j); and
reversely for µ (x ). These messages are illustrated in Fig. 1. The posterior
bj j
belief can then be expressed as
1
q (x )= µ (x )µ (x ), (3)
j j Z jb j bj j
j
(cid:82)
with Z = µ (x )µ (x )dx a normalizing constant.
j jb j bj j j
In practice, for numerical stability, messages are often re-normalized after
computation. Furthermore, messages are usually scheduled for computation,
andareoftenreferredtobytheirpositioninthescheduleinsteadoftheirlocation
in the graph. We will use a similar notation in Sec. 4. See (Bishop, 2006) for a
more detailed introduction to (approximate) inference on bi-partite graphs.
2.2 Bethe Free Energy Interpretation
The Bethe free energy for a factorized model of the form of (1) is defined as
(cid:88) (cid:88) (cid:88)
F[q]= U [q ]− H[q ]+(d −1) H[q ], (4)
a a a i i
a∈F a∈F i∈V
(cid:82)
whered representsthedegreeofvariablex . HereU [q ]=− q (x )logf (x )dx
i i a a a a a a a
(cid:82)
denotes the average energy for factor f , and H[q ]=− q (x )logq (x )dx
a a a a a a a
denotes the entropy. The Bethe free energy is optimized with imposed normal-
ization and marginalization constraints:
(cid:90)
q (x )dx =q (x ),∀a∈F,∀j ∈V(a) (5a)
a a a\j j j
(cid:90)
q (x )dx =1,∀a∈F (5b)
a a a
(cid:90)
q (x )dx =1,∀i∈V, (5c)
i i i
such that the q and q represent (approximate) posterior probability distribu-
a i
tions (beliefs).
5
2.3 Free Energy Minimization for Active Inference
Active Inference usually defines dynamic models that specialize variables into
parameters,states,observationandcontrolsequencesforpastandfuturetimes.
FreeenergyminimizationforActInfisthenpresentedasadualobjective,where
minimization of free energy for a model of past variables accounts for state
and parameter estimation (perception), and free energy minimization of free
energyforamodeloffuturevariablesaccountsforpolicyplanning(Baltieriand
Buckley, 2018; van de Laar et al., 2019).
In the present paper we assume that the current state is observed and that
model parameters are given. Therefore, this paper only concerns inference for
policyplanning. Extensionsforperceptionarehoweverstraightforward. Chance
constraintsonlyaffectinferenceforplanning,andthereforestandardtechniques
for state estimation and parameter learning can be employed (van de Laar and
de Vries, 2019).
Furthermore, the current paper employs the Bethe Free Energy (BFE) for-
mulation(4)forpolicyplanning(Schw¨obeletal.,2018;vandeLaaranddeVries,
2019) instead of the more traditional Expected Free Energy (EFE) (Friston
et al., 2015). The BFE is known to lack the epistemic qualities of the EFE
(Schw¨obel et al., 2018), which can be compensated for by introducing an addi-
tional mutual information term between the states and the observations to the
BFEobjective(ParrandFriston,2019). ThebenefitoftheuncompensatedBFE
however,isthattraditionalmessagepassingalgorithms,including(loopy)belief
propagation,variationalmessagepassing,expectationpropagationandgeneral-
izedbeliefpropagationalgorithmscanallbederivedasfixed-pointequationsof
thevariationalfreeenergybytheuseofvariationalcalculus, see(Yedidiaetal.,
2000; Heskes, 2003; Yedidia et al., 2005; Dauwels, 2007; Zhang et al., 2017).
2.4 Chance Constraints
A chance constraint imposes that the probability mass of a belief q (x ),j ∈V
j j
outside of a ‘safe’ region S ⊂ X cannot exceed a pre-set threshold (cid:15) ∈ [0,1].
j j
Formally, a chance constraint imposes the inequality
(cid:90)
1−(cid:15)≤ q (x )dx
j j j
Sj
(cid:90)
= q (x )g (x )dx , (6)
j j j j j
Xj
with
(cid:40)
1 if x ∈S
g (x )= j j
j j
0 otherwise.
Our problem statement then becomes two-fold, namely:
1. Find the stationary points of the Bethe free energy (4) under the normal-
ization and marginalization constraints of (5) and chance constraints of
the form (6) (Theorem 1);
6
2. Interprettheretrievalofstationarypointsofthechance-constrainedBethe
free energy as message passing on a factor graph (Theorem 2).
The simulations of Sec. 4 further specialize the model variables into state,
observation and control sequences and demonstrate the added value of chance
constraints in an ActInf setting. Crucially, with an interpretation of chance
constraintsintermsofmessagepassingonafactorgraph,chanceconstraintscan
bereadilyappliedtoanyfactorizedmodel. Formulatingchanceconstraintsasa
click-onmoduleforapproximateinferencethengreatlyimprovestheapplication
range of chance constraints.
3 Chance-Constrained Message Passing
Inthissectionweformulatethemethodofchance-constrainedmessagepassing.
We identify the stationary points of the chance-constrained Bethe free energy
and interpret the result in terms of message passing on a factor graph. We
work towards a practical message-passing update rule for chance-constrained
variables, as summarized in Algorithm 1. A brief introduction to variational
calculus is available in Appendix A. Proofs can be found in Appendix B.
3.1 Stationary Points
FromtheBethefreeenergy (4)andtheconstraintsof (5),(6),wecanconstruct
the Lagrangian
(cid:20)(cid:90) (cid:21) (cid:20)(cid:90) (cid:21)
(cid:88) (cid:88)
L[q]=F[q]+ γ q (x )dx −1 + γ q (x )dx −1
i i i i a a a a
i∈V a∈F
(cid:90) (cid:20) (cid:90) (cid:21)
(cid:88) (cid:88)
+ ζ (x ) q (x )− q (x )dx dx
ia i i i a a a\i i
a∈Fi∈V(a)
(cid:20)(cid:90) (cid:21)
(cid:88)
+ η q (x )g (x )dx −(1−(cid:15)) , (7)
i i i i i i
i∈V
where the Lagrange multipliers γ,ζ,η enforce the constraints of (5), (6).
Under strong duality, for the inequality constraint in (6) we have the com-
plementary slackness condition (Boyd and Vandenberghe, 2004, Ch. 5). This
(cid:2)(cid:82) (cid:3)
conditionstatesthatforoptimalitywehaveη q (x )g (x )dx −(1−(cid:15)) =0.
i i i i i i
Therefore, either η > 0, which implies that the chance constraint of (6) holds
i
with equality (active) or η = 0, which implies that the chance constraint may
i
hold without equality (inactive). In other words, the complementary slackness
condition requires us to consider two scenarios: i) (6) holds with equality for
η > 0 and ii) (6) is satisfied under η = 0. Hence, if η > 0, the chance
i i i
constraint is activated and enforced with equality.
In Lemmas 1, 2 we express the stationary points of L[q] in terms of the
beliefs. The proofs are presented in Appendix B.1 and Appendix B.2.
7
Lemma 1. Stationarypointsof (7)asafunctionalofq ,b∈F, areoftheform
b
1 (cid:89)
q∗(x )= f (x ) µ (x ), (8)
b b Z b b ib i
b
i∈V(b)
with
(cid:90)
(cid:89)
Z = f (x ) µ (x )dx
b b b ib i b
i∈V(b)
a normalizing constant.
Proof. See Appendix B.1.
Note that the µ have not yet been identified or interpreted as messages.
ib
We will explicitly make this connection in Sec. 3.3.
Lemma 2. Stationarypointsof (7)asafunctionalofq ,j ∈V, areoftheform
j
1 (cid:89)
q∗(x ;η )= exp(−η g (x )) µ (x ), (9)
j j j Z (η ) j j j aj j
j j
a∈F(j)
with
(cid:90)
(cid:89)
Z (η )= exp(−η g (x )) µ (x )dx
j j j j j aj j j
a∈F(j)
a normalizer that still depends on η .
j
Proof. See Appendix B.2.
Note that, in contrast to (3), this result incorporates an additional expo-
nential term for η . We will identify this multiplier in Sec. 3.2. However, we
j
already know that when the chance constraint for j is inactive, hence η = 0
j
as a consequence of the complementary slackness condition. In this case, (9)
reduces to (3).
3.2 Active Chance Constraint
Inthissection,weidentifythestationarypointsunderactivechanceconstraint.
The result is stated in Theorem 1.
Theorem 1. Under active chance constraint, stationary points of (7) as a
functional of q ,j ∈V are of the form
j
 1−(cid:15)q(0)(x ) if x ∈S
q∗(x ;η =η∗)=
 Φ(
j
0) j j j j
(10)
j j j j  1−Φ (cid:15) (0) q j (0)(x j ) otherwise,
j
8
with
q(0)(x )=q∗(x ;η =0), (11a)
j j j j j
(cid:90)
Φ(0) = q(0)(x )dx , (11b)
j j j j
Sj
η∗ =log((cid:15)Φ(0))−log(1−(cid:15))−log(1−Φ(0)). (11c)
j j j
Proof. See Appendix B.3.
This remarkable result tells us that the corrected belief q∗(x ;η = η∗) is
j j j j
obtained by scaling the probability mass of the uncorrected belief q(0)(x ) over
j j
the respective safe and unsafe regions. This defines the corrected belief as
a mixture of truncated beliefs. The optimal scaling of (10) ensures that the
overflow is equal to (cid:15).
The complementary slackness condition ensures that the chance constraint
isonlyenforcediftheprobabilitymassoftheunconstrained beliefoverflowsthe
‘safe’ region S by more than (cid:15); i.e., the uncorrected belief is ‘unsafe’ when
j
(cid:15)<1−Φ(0), (12)
j
where we refer to Φ(0) as the ‘safe mass’.
j
If (12) is satisfied, then the posterior density q(0)(x ) is corrected according
j j
to (10), which ‘pushes’ the probability mass (just) back inside the safe region.
3.3 Chance-Constrained Message Passing
In this section, we show that chance constraints (10) can be interpreted as
auxiliary factor-nodes (with a specific node-function), and can be enforced by
belief propagation in an augmented graph.
Theorem 2. Given a bipartite graph G =(F,V,E) with a variable node j ∈V,
andanassociatedBethefreeenergy (4)withachanceconstraint (6)onthebelief
q (x ). Then, stationary points of (7) can be obtained by belief propagation on
j j
an augmented graph G(cid:48) =(F(cid:48),V,E(cid:48)), where
F(cid:48) =F ∪g (13a)
E(cid:48) =E ∪(j,g), (13b)
and auxiliary node function

1−(cid:15) if x ∈S
 Φ(0) j j
f (x )= j (14)
g j  1−Φ (cid:15) (0) otherwise.
j
Proof. See Appendix B.4.
9
Theorem2showsthatchance-constrainedmessagepassingcanbeseamlessly
incorporated within the belief propagation framework. Chance constraints sim-
plyenterthemodeldefinitionasauxiliaryfactors,whosefactorfunctiondepends
upontheincomingmessage,seeFig.2. Becauseuncorrectedbelief (11a)isbeing
represented by the (re-normalized) incoming message µ (x ), this allows for a
jg j
modular application of chance constraints by augmenting the original graphical
model with auxiliary nodes.
f
g
µgj(xj)↓ ↑µjg(xj)
. . . f b
µjb
← →
(xj)
x j . . .
µbj(xj)
Figure 2: Bi-partite graph around a chance-constrained variable x , with indi-
j
cated auxiliary factor f (dashed square) and messages. Ellipses represent the
g
continued model by an arbitrary (possibly zero) number of connected edges.
3.4 Gaussian Approximation
Since the message µ (x ) introduces discontinuities, the computations for de-
gj j
pendent messages may grow prohibitively complex. For efficient computations,
it can be helpful to make a Gaussian approximation q˜(x ) to the corrected
j j
belief q∗(x ;η = η∗), e.g., by moment matching. The resulting (approximate)
j j j j
message then follows from
µ (x )=q˜(n)(x )/µ (x ).
gj j j j jg j
Ifthemessageµ (x )isalsoGaussian,thiscomputationiseasilyperformedby
jg j
subtractingthecanonicalstatistics. Thisprocedurethenresemblestheexpecta-
tionpropagationalgorithm(Minka,2001;CoxanddeVries,2018). Interestingly,
theexpectationpropagationalgorithmcanalsobederivedintermsofBethefree
energyoptimization,wherethemarginalizationconstraints(5a)arereplacedby
moment-matching constraints (Zhang et al., 2017). This makes the Gaussian
approximation consistent with the Lagrangian approach as presented in this
paper.
The approximated belief q˜(x ) however renders the chance constraint (6)
j j
inexact. Asaresult,theapproximatedbeliefneedstobeiterativelyre-corrected:
 1−(cid:15) q˜(n−1)(x ) if x ∈S
q(n)(x )=  Φ j (n−1) j j j j (15)
j j  1−Φ (cid:15) (n−1) q˜ j (n−1)(x j ) otherwise,
j
10
where n denotes an iteration counter. This leads to the procedure summarized
in Alg. 1, and depicted in Fig. 3.
Algorithm 1 Chance-constrained message passing with Gaussian approxima-
tion
Given a Gaussian inbound message µ (x )
jg j
Compute the uncorrected belief q(0)(x ) through (11a)
j j
Compute the safe mass Φ(0) through (11b)
j
Initialize the approximated belief q˜(0)(x )=q(0)(x )
j j j j
Initialize the iteration counter n=0
while (cid:15)+δ <1−Φ(n) do
j
% Chance constraint is violated with some tolerance δ
Increase the counter n←n+1
Compute the corrected belief q(n)(x ) through (15)
j j
Approximate q˜(n)(x )≈q(n)(x ) by Gaussian moment matching
j j j j
Compute Φ(n) = (cid:82) q˜(n)(x )dx , the safe mass of the approximated belief
j Sj j j j
end while
return The message µ (x )=q˜(n)(x )/µ (x )
gj j j j jg j
Withthisalgorithm,wehavederivedapracticalchance-constrainedmessage
update from the first principles. The message update can be readily applied to
any continuous variable that requires a chance constraint. Note however, that
when multiple chance constraints are imposed on the model, the message pass-
ing algorithm itself becomes an iterative procedure because of circular message
dependencies. For example, a message incoming to an auxiliary node g might
(indirectly) depend on a message that exits another auxiliary node h. In turn,
this exiting message depends on the incoming message to h (1), which depends
on the message exiting g, etcetera. In order to break this circular message
dependency, uninformative messages can be used to initialize the algorithm.
4 Simulations
Inthissectionwesimulateadronethataimstoelevateitselfaboveagivenheight
threshold with a preset probability, under the influence of a stochastic vertical
wind. Wedefinethedroneelevationlevelovertimebyx={x ,...,x ,...,x },x ∈
0 t L t
R, and actions (ascension velocity) a = {a ,...,a ,...,a },a ∈ R. A time-
0 t L t
dependent m defines the expected wind velocity that acts upon the agent.
w,t
The discrete-time stochastic system is defined as:
w ∼N(m ,v )
t w,t w
x =x +a +w ,
t+1 t t t
where v defines the wind velocity variance.
w
11
q˜(n−1)(x ) Φ(n−1)
j j j
x
j
S
j
q˜(n)(x )
j j
q(n)(x )
j j
(cid:15)
x
j
S
j
Figure 3: Example of beliefs as computed by Algorithm 1. The top figure
evaluatestheprobabilitymasswithinthe“safe”zone. Thebottomfigureapplies
the correction (solid curve) and approximates the corrected belief by Gaussian
moment matching (dashed curve).
We define an agent that directly observes its elevation level and has knowl-
edge of the statistical system properties m and v . The agent models future
w,t w
states of the system with a fixed time horizon T. As a shorthand notation,
we write the future (including current) states x = {x ,...,x } and control
t t t+T
variables u = {u ,...,u }. For notational convenience, we drop the t
t t t+T−1
subscript from these collections. The agent model at time t is defined as:
t+T−1
(cid:89)
f (x,u)= p (x |u ,x )p (u ), (16)
t x,k k+1 k k u k
k=t
with a respective state transition model and control prior
p (x |u ,x )=N(x |x +u +m ,v ) (17a)
x,k k+1 k k k+1 k k w,k w
p (u )=N
(cid:0)
u
|0,λ−1(cid:1)
. (17b)
u k k
We factorize and constrain the variational posterior distribution such that
(van de Laar and de Vries, 2019)
t+T−1
(cid:89)
q (x ,u)=q (x ) δ(u −a ), (18)
t \t t \t k k
k=t
12
where x indicates the collection of latent states (the state sequence x without
\t
the observed current state x ). The goal of the agent controller then becomes
t
to find the policy π ={a ,...,a } that minimizes the Bethe free energy
t t t+T−1
(cid:90) (cid:90) q (x ,u)
t \t
F[q ;x ,π ]= ··· q (x ,u)log dx du, (19)
t t t t \t f (x,u) \t
t
underthenormalizationandmarginalizationconstraintsof (5)andchancecon-
straints
(cid:90)
1−(cid:15)≤ q (x )dx , ∀k ∈{t+1,...,t+T},
x,k k k
S
wherethe saferegion S =(1,∞)and violationprobability (cid:15) areidenticalforall
future state variables.
4.1 Graphical Model and Schedule
As detailed in Sec. 3, Bethe free energy minimization under chance constraints
can be performed by message passing on an augmented model. The graphical
representation of the augmented model is depicted in Fig. 4.
λ
p
u
u
m k
w,k v
w
x
k+1
...
p
x x,k
t
f
x,k+1
k=t:t+T−1
Figure 4: Augmented graphical representation of the agent model (16). Circles
and squares indicate variable- and factor-nodes respectively. Auxiliary factor-
nodes (14) are dashed, and dark circles indicate observed variables or fixed
parameters. Ellipses indicate a continuation of the framed section until the
lookahead time horizon.
13
G
←
u k N λ
2 ↓ ↑ F
v
w
p
N x,k
3 ↓
1 E ↑ 4 D 5 x k+1 7
→ → ← → →
... + + ...
← ← ←
H C A
B ↓ ↑ 6
m w,k f x,k+1
Figure 5: Augmented agent model (16), with p expanded according to (17)
x,k
(dashed rectangle), and indicated forward (numbers) and backward (letters)
message passing schedules for optimization of (19). Circle and square nodes
indicate variable- and factor-nodes respectively. Dark nodes indicate observed
variables or fixed parameters, and auxiliary factor-nodes (14) are dashed. El-
lipsesindicateacontinuationofthemodel. Darkmessagesarecomputedbythe
variational update rule, see (Winn and Bishop, 2005; Dauwels, 2007).
The schedule comprises a forward-backward scheme, as illustrated in Fig. 5.
Four message updates in Fig. 5 are of particular interest. Firstly, since (18)
constrains the belief over controls to a point-mass, it follows that
µ(i)(u )=δ(u −a(i−1)),
2 k k k
where i counts the number of schedule (forward-backward) iterations. The
schedule is initialized with a(0) =0 for all k ≥t. Secondly, µ(i)(x ) takes on
k B k+1
the role of µ (x ) in Alg. 1. Because the noise in the model is Gaussian, this
jg j
message will be an (unnormalized) Gaussian as well. Therefore, by application
of Alg. 1, the third message of interest, µ(i)(x ) is computed. For the initial
6 k+1
forward pass, µ(0)(x ) = 1 is considered uninformative. Fourthly, µ(i)(u )
B k+1 F k
carries information upward to the control variables. Because the variational
posteriorischosentofactorizebetweenthestateandcontrolsequence(18), the
µ(i)(u ) message is computed by a variational update rule as detailed in (Winn
F k
and Bishop, 2005) and (Dauwels, 2007).
14
The action for the next iteration then follows from
q(i)(u )∝µ(i)(u )µ(i)(u )
u,k k F k G k
a(i) =modeq(i)(u ).
k u,k k
Iteratingtheschedulethencorrespondswithanexpectationmaximizationscheme.
Theexpectationstepofthisschemecomputestheµ(i)(u )messagefromtheac-
F k
tionsa(i−1). Themaximizationstepthenchoosestheupdatedactionsa(i) asthe
k k
currentMAP-estimateofu . Thescheduleisiterateduntilthepolicyconverges.
k
Message passing simulations1 are performed with the ForneyLab probabilis-
tic programming toolbox (Cox et al., 2019), version 0.11.3.
4.2 Control Law
NotethattheBethefreeenergyof (19)isstillafunctionoftheobservedcurrent
elevation x . We can then evaluate the optimal action a as a function of the
t t
currentelevationx (thecontrollaw),foragivenwindprofile,chanceconstraint
t
and model parameters. In order to gain an intuition for controller behavior, we
fix m = 0 for all t. We plot the control law in Fig. 6, for varying values of
w,t
the lookahead horizon T, chance constraint threshold (cid:15), wind variance v and
w
control prior precision λ.
The top-left diagram shows that with growing lookahead horizon T, the
agent starts intervening at higher elevation. With this anticipatory effect the
agentpreparesforeventsinthemoredistantfuture. Thetop-rightdiagramalso
shows that the agent intervenes at higher elevation with decreasing (cid:15). When
violation of the constraint grows less desirable, the agent must intervene earlier
in order to assure that sufficient probability mass is present in the safe region.
Also note that no further action is proposed beyond an intervention threshold.
Once the agent is sufficiently elevated, no corrections are proposed until the
agent wanders (or is forced) below the intervention threshold. The bottom-left
figure shows a similar effect for growing wind velocity variance v . When the
w
system grows more stochastic, chance constraint abidance is ensured by inter-
vening at higher elevations. Finally, the bottom-right figure illustrates what
happens when the chance constraint is combined with a Gaussian prior con-
straint on control. Increasing the control prior precision λ penalizes immediate
correction. For low precisions (low penalty on control magnitude), the slope of
thecontrollawbelowtheinterventionthresholdisequalto1,andcompensation
is immediate. Control grows more robust with growing precision, at the cost of
prolonged chance constraint violation.
4.3 Comparison Against a Goal-Driven Agent
In order to illustrate the difference in behavior between a chance- and a goal-
driven ActInf agent, we compare the results of Fig. 6 with an ActInf agent
1Sourcecodeforthesimulationsisavailablefordownloadathttp://biaslab.github.io/
materials/cc_simulations.zip
15
Figure 6: Slices of the control law for m = 0,S = (1,∞), varied around
w,t
reference setting T = 1,(cid:15) = 0.01,v = 0.2,λ = 10−12 (black curves). Dashed
w
vertical lines indicate the minimal safe elevation.
where the chance constraint is replaced by a goal prior. We use the graphical
model definition of Fig. 4 and define the auxiliary node function as a fixed
prior f (x ) = N(x |m ,ϑ ) for all t ≤ k ≤ t+T −1. We choose
x,k+1 k+1 k+1 x x
m =2,andthevarianceϑ =0.18478suchthattheoverflowofthesaferegion
x x
(cid:82)
1− f (x )dx ≈ 0.01 resembles the situation for (cid:15) = 0.01. The
S x,k+1 k+1 k+1
message passing schedule then follows the definition of Fig. 5, where µ(i)(x )
6 k+1
is no longer computed by Alg. 1 and propagates the fixed goal prior instead.
Fig.7showstheresultingcontrollawform =0,T =1,v =0.2andvarying
w,t w
λ.
The results of Fig. 7 show that the control for the goal-driven agent grows
morerobustwithincreasingλ–similartothecontrollawforthechance-driven
agent (Fig. 6, bottom right). For the smallest λ, the control law for the prior-
drivenagentresemblesthecorrespondingcontrollawforthechance-drivenagent
(dotted curve) only for elevations x < 2. For elevations x > 2, the goal-driven
agent proposes downward corrections, while the chance-driven agent proposes
no corrections. This comparison illustrates how a chance-driven agent avoids
unnecessary interventions.
16
Figure 7: Slices of the control law for a goal-driven agent with m = 0,T =
w,t
1,m = 2,ϑ = 0.18478,v = 0.2 with varying λ. The dashed vertical line
x x w
indicates the minimal safe elevation. The black dotted curve represents the
reference result (λ=10−12) for the chance-driven agent (Fig. 6, black curves).
4.4 Simulation Results
Inthissectionwestudyanactiveinferenceagentininteractionwithasimulated
environment. Theaction-perceptionloopisbasedon(vandeLaaranddeVries,
2019) and consists of four steps at every time t:
1. Observe the current agent elevation;
2. Infer a policy from the current elevation and the future expected wind
velocities by chance-constrained message passing;
3. Act by selecting the first (current) action from the inferred policy;
4. Execute the selected action in the system and advance the time index by
one.
The results for ten thousand independent runs are plotted in Fig. 8 for a
chance-driven agent (left) and a goal-driven agent (right). The first row of
diagrams plots the expected wind velocity over time, which is identical for each
run. Thesampledwindvelocitytrajectoriesw dovaryperrun,underinfluence
t
of the wind velocity variance v . For 5 ≤ t < 10 a downward draft attempts
w
to push the drone below the minimal safe elevation (dashed). The second row
plots the drone elevation trajectory for a randomly selected subset of runs.
Corresponding actions are plotted in the third row. The fourth row evaluates
the relative number of runs that violate the safe-zone over time.
It can be seen that both agents undertake corrective actions in order to
compensate for the downward wind. However, while the chance-driven agent
(left) only proposes upward corrections below the intervention threshold, the
goal-driven agent (right) proposes additional downward corrections above the
17
Figure 8: Results for ten thousand simulations with varying wind strength over
time, and T =1,v =0.2,λ=10−12, for a chance-driven agent ((cid:15)=0.01, left),
w
and a goal-driven agent (m =2,ϑ =0.18478, right).
x x
threshold. Furthermore, itcanbeseenthatthemaximalempiricalviolationfor
the chance-constrained agent mostly remains below the chance constraint tar-
get violation probability of (cid:15) = 0.01 (dashed), while the goal-driven agent sys-
tematically overshoots the target violation probability, i.e. violates the chance
constraint. Compared to the chance-driven agent, the maximal empirical viola-
tions for the goal-driven agent are also larger. This effect can be explained in
termsoftheconstrainedbeliefs. Namely,thechance-drivenagentconstrainsthe
posterior beliefs, while the goal-driven agent imposes prior constraints on the
model. Prior constraints may still be violated by the corresponding posterior
beliefs, leading to more pronounced empirical violations.
5 Conclusions
In this paper, we formulated chance-constrained optimization of the Bethe free
energy in terms of message passing on a factor graph. We showed that, in the
factor graph representation of the generative model, chance constraints can be
18
imposed by auxiliary factors that force (a specified portion of) the probability
mass of the chance-constrained beliefs inside a designated safe-zone. Message
passing on the augmented graph, with the auxiliary factor-nodes included in
the graph, then automatically balances the imposed chance constraints with
additional (prior) constraints on the generative model. Chance constraints can
thus be interpreted as modular click-on extensions to the generative model,
similar to conventional factor-nodes (Loeliger et al., 2004), and can thus be
used to complement message-passing formulations on generative neural models
(Friston et al., 2017; van de Laar et al., 2018).
However, because the analytical result for the chance-constrained update
includesaninherentdiscontinuity,directapplicationofthisrulemaystillleadto
messageupdatesthatgrowprohibitivelycomplex. Toremedythis,weproposed
an algorithm that approximates the resulting message with a Gaussian form.
This algorithm offers a tractable formulation of chance-constrained message
passing. Theproposedmessagepassinginterpretationofchanceconstraintsthen
vastly enhances the modularity and flexibility of chance-constrained inference,
and can accelerate the search for workable models (Blei, 2014).
We demonstrated chance-constrained message passing in the context of ac-
tive inference. We compared the simulated behavior of a chance-driven agent
with a goal-driven agent, where the chance constraints are replaced by tradi-
tionalpriorbeliefsonfutureoutcomes. Theresultsillustratehowthegoal-driven
agent continually proposes corrections, whereas the chance-driven agent seizes
interventions above a threshold. Chance-constrained ActInf may thus avoid
unnecessary interventions and reduce the cost of control.
The results for the chance-driven agent showed that, in the absence of addi-
tional prior constraints, the empirical chance constraint violation ratio mostly
remains below the pre-set target violation probability. An added prior con-
straintoncontrolsrobustifiescontrolatthecostofprolongedchanceconstraint
violation. Chance-constrained active inference thus weights all imposed con-
straints on the generative model, allowing e.g., for a trade-off between robust
control and empirical chance constraint violation.
Acknowledgments
Thisworkwassupported,inpart,byGNHearingA/SandtheSwedishResearch
Council (under Grants 2015-04011 and 2018-03701).
Appendix
A Calculus of Variations
The calculus of variations offers a principled method for optimizing functionals
(a function of a function that returns a scalar). We follow (Engel and Dreizler,
2013) and consider the impact of a variation in a function q(x),x ∈ X, on a
19
functional L[q]. We define an infinitesimal variation of q by
∆
δq =βφ,
where β →0, and φ(x) is a continuous and differentiable “test” function.
The functional derivative δL/δq relates a variation in q to a change in L, by
(Parr, 1980):
dL[q+βφ] (cid:12) (cid:12) (cid:90) δL
(cid:12) = (x)φ(x)dx. (20)
dβ (cid:12) δq
β=0
Theprocedurethenbecomestoapplytheoperationsonthel.h.s. toL,andbring
itintotheformofther.h.s.,whichallowsustoidentifythefunctionalderivative
δL/δq. The stationary points q∗ are then obtained by setting δL/δq = ! 0 and
solving for q.
B Proofs
B.1 Proof of Lemma 1
Application of (20) to (7) as a functional of q , yields
b
dL[q b d + β βφ b ] (cid:12) (cid:12) (cid:12) (cid:12) = (cid:90) φ b (x b ) (cid:20) log f q b ( ( x x b ) ) +1+γ b − (cid:88) ζ ib (x i ) (cid:21) dx b .
β=0 b b i∈V(b)
IdentifyingthefunctionalderivativeδL[q ]/δq andsettingittozero, weobtain
b b
(cid:20) (cid:21)
(cid:88)
q∗(x )=f (x )exp ζ (x )−γ −1 . (21)
b b b b ib i b
i∈V(b)
Wenowdefineµ(x )=expζ(x )andapplythenormalizationconstraint,which
j j
recovers (8).
B.2 Proof of Lemma 2
Application of (20) to (7) as a functional of q , yields
j
dL[q j d + β βφ j ] (cid:12) (cid:12) (cid:12) (cid:12) = (cid:90) φ j (x j ) (cid:20) −(d j −1)+γ j
β=0
(cid:21)
(cid:88)
−(d −1)logq (x )+ ζ (x )+η g (x ) dx .
j j j ja j j j j j
a∈F(j)
Identifying the functional derivative δL[q ]/δq and setting it to zero, yields
j j
(cid:20) (cid:18) (cid:19)(cid:21)
1 (cid:88)
q∗(x )=exp 1−d +γ + ζ (x )+η g (x ) , (22)
j j d −1 j j ja j j j j
j
a∈F(j)
20
which is the first expression for q∗.
j
We can obtain a second expression for q∗ by applying the marginalization
j
constraint to the result of Lemma 1. Substituting (8) in (5a),
(cid:90)
q∗(x )= q∗(x )dx
j j b b b\j
µbj(xj)
1
(cid:90)(cid:122)
(cid:89)
(cid:125)(cid:124) (cid:123)
= µ (x ) f (x ) µ (x )dx , (23)
Z jb j b b ib i b\j
b
i∈V(b)
i(cid:54)=j
where we identified a new quantity µ (x ) (note the reverse indexing).
bj j
Interestingly,themarginalizationresultof (23)notonlyholdsforthespecific
factor b, but for all factors that neighbor j. Therefore, by symmetry, we can
iterate the relation of (23) for all c∈F(j):
(cid:89) (cid:89) 1
q∗(x )= µ (x )µ (x ).
j j Z jc j cj j
c
c∈F(j) c∈F(j)
We choose to exclude b itself from the iteration on both sides, and obtain
(cid:89) (cid:89) 1
q∗(x )= µ (x )µ (x ). (24)
j j Z jc j cj j
c
c∈F(j) c∈F(j)
c(cid:54)=b c(cid:54)=b
We substitute (22) in the l.h.s. of (24), and note that the product on the
l.h.s. now has d −1 terms, and that neither of these terms depend on c. This
j
allows us to remove the d −1 terms from the exponent of (22), which yields
j
(cid:89) (cid:89) 1
exp(1−d +γ +η g (x )) µ (x )= µ (x )µ (x ).
j j j j j ja j Z jc j cj j
c
a∈F(j) c∈F(j)
c(cid:54)=b
Canceling duplicate terms and simplifying, we obtain an expression for µ
jb
as identified in (23):
(cid:89)
µ (x )∝exp(−η g (x )) µ (x ). (25)
jb j j j j aj j
a∈F(j)
a(cid:54)=b
Finally,substituting (25)backin(23)andre-normalizing,werecover(9).
B.3 Proof of Theorem 1
We start from (9), and use the definitions of (11) to obtain
(cid:90) Φ(0)exp(−η )
q∗(x ;η )dx = j j ,
Sj
j j j j Φ(
j
0)exp(−η
j
)−Φ(
j
0)+1
21
which leads to
(1−(cid:15))(1−Φ(0))
exp(−η∗)= j .
j (cid:15)Φ(0)
j
We have now identified the η multiplier. Substituting this result back in (9)
j
recovers (10), which expresses the corrected belief in terms of the uncorrected
belief.
B.4 Proof of Theorem 2
From (9), we express the uncorrected belief in terms of the messages
q(0)(x )= 1 (cid:89) µ (x ), (26)
j j Z(0) aj j
j a∈F(j)
with Z(0) =Z (η =0).
j j j
We now construct the augmented graph G(cid:48) = (F(cid:48),V,E(cid:48)) according to (13),
and define a message
µ (x )=f (x ), (27)
gj j g j
with f (x ) as defined by (14).
g j
Substituting (26) and (27) in (10) then yields the corrected belief in terms
of the messages
1
q∗(x ;η =η∗)= µ (x )µ (x ), (28)
j j j j Z(0) gj j jg j
j
with
(cid:89)
µ (x )= µ (x ). (29)
jg j aj j
a∈F(cid:48)(j)
a(cid:54)=g
The results of (27), (28) and (29) can be interpreted as belief propagation
(2), (3) on the augmented graph G(cid:48).
References
Baltieri,M.andBuckley,C.L.(2018). Themodularityofactionandperception
revisitedusingcontroltheoryandactiveinference. InArtificiallifeconference
proceedings, pages 121–128. MIT Press.
Baltieri, M. and Buckley, C. L. (2019). Active Inference: Computational Mod-
els of Motor Control without Efference Copy. In 2019 Conf. on Cognitive
Computational Neuroscience.
22
Bishop, C. M. (2006). Pattern recognition and machine learning. Springer.
Blackmore, L., Ono, M., and Williams, B. C. (2011). Chance-constrained
optimal path planning with obstacles. IEEE Transactions on Robotics,
27(6):1080–1094.
Blei, D. M. (2014). Build, compute, critique, repeat: Data analysis with latent
variable models. Annual Review of Statistics and Its Application, 1:203–232.
Borrelli, F., Bemporad, A., and Morari, M. (2017). Predictive control for linear
and hybrid systems. Cambridge University Press.
Boyd, S. and Vandenberghe, L. (2004). Convex Optimization. Cambridge Uni-
versity Press.
Cox, M. and de Vries, B. (2018). Robust expectation propagation in factor
graphsinvolvingbothcontinuousandbinaryvariables.In201826thEuropean
Signal Processing Conference (EUSIPCO), pages 2583–2587. IEEE.
Cox, M., van de Laar, T. W., and de Vries, B. (2019). A factor graph approach
to automated design of Bayesian signal processing algorithms. International
Journal of Approximate Reasoning, 104:185–204.
Dauwels,J.(2007). OnVariationalMessagePassingonFactorGraphs. InIEEE
Inter. Symp. on Information Theory, pages 2546–2550.
de Vries, B. and Friston, K. J. (2017). A factor graph description of deep
temporal active inference. Frontiers in computational neuroscience, 11:95.
Engel, E. and Dreizler, R. M. (2013). Density functional theory. Springer.
Fountas, Z., Sajid, N., Mediano, P. A., and Friston, K. (2020). Deep active in-
ference agents using monte-carlo methods. arXiv preprint arXiv:2006.04176.
Friston, K., Rigoli, F., Ognibene, D., Mathys, C., Fitzgerald, T., and Pezzulo,
G. (2015). Active inference and epistemic value. Cognitive Neuroscience,
6(4):187–214.
Friston, K.J.(2010). Thefree-energyprinciple: aunifiedbraintheory? Nature
Reviews Neuroscience, 11(2):127–138.
Friston, K. J., Kilner, J., and Harrison, L. (2006). A free energy principle for
the brain. Journal of Physiology, Paris, 100(1-3):70–87.
Friston, K. J., Parr, T., and de Vries, B. (2017). The graphical brain: belief
propagation and active inference. Network Neuroscience, 1(4):381–414.
Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
Ozair, S., Courville, A. C., and Bengio, Y. (2014). Generative adversarial
nets. In NIPS.
23
Heskes, T. (2003). Stable fixed points of loopy belief propagation are local
minimaofthebethefreeenergy. InAdvancesinneuralinformationprocessing
systems, pages 359–366.
Hoffmann, C. and Rostalski, P. (2017). Linear Optimal Control on Factor
Graphs - a Message Passing Perspective. In 20th IFAC World Congress,
Toulouse, France.
Imohiosen, A., Watson, J., and Peters, J. (2020). Active inference or control as
inference? a unifying view. In 1st International Workshop on Active Infer-
ence.
Korl, S. (2005). A factor graph approach to signal modelling, system identifica-
tion and filtering. ETH Zurich.
Loeliger,H.-A.,Dauwels,J.,Koch,V.M.,andKorl,S.(2004). Signalprocessing
with factor graphs: examples. In First International Symposium on Control,
Communications and Signal Processing, 2004., pages 571–574. IEEE.
Markovic, D., Stojic, H., Schwoebel, S., and Kiebel, S. J. (2021). An empir-
ical evaluation of active inference in multi-armed bandits. arXiv preprint
arXiv:2101.08699.
Mesbah, A. (2016). Stochastic model predictive control: An overview and per-
spectives for future research. IEEE Control Systems Magazine, 36(6):30–44.
Millidge, B., Tschantz, A., Seth, A. K., and Buckley, C. L. (2020). On the rela-
tionshipbetweenactiveinferenceandcontrolasinference.In1stInternational
Workshop on Active Inference.
Minka, T. P. (2001). Expectation propagation for approximate Bayesian infer-
ence. InProceedingsoftheSeventeenthconferenceonUncertaintyinartificial
intelligence, pages 362–369.
Parr, R. G. (1980). Density functional theory of atoms and molecules. In
Horizons of Quantum Chemistry, pages 5–15. Springer.
Parr,T.andFriston,K.J.(2019). Generalisedfreeenergyandactiveinference.
Biological cybernetics, 113(5):495–513.
Pearl,J.(1982). Reverendbayesoninferenceengines: Adistributedhierarchical
approach. In Proc. of the Second AAAI Conference on Artificial Intelligence,
AAAI’82, page 133–136.
Ramstead, M. J. D., Badcock, P. B., and Friston, K. J. (2018). Answering
Schr¨odinger’s question: A free-energy formulation. Physics of Life Reviews.
Recht, B. (2019). A tour of reinforcement learning: The view from continu-
ous control. Annual Review of Control, Robotics, and Autonomous Systems,
2:253–279.
24
Sajid, N., Ball, P. J., Parr, T., and Friston, K. J. (2021). Active inference:
demystified and compared. Neural Computation, 33(3):674–712.
Sallans, B. and Hinton, G. E. (2001). Using free energies to represent Q-values
in a multiagent reinforcement learning task. In Adv. in neural information
process. systems, pages 1075–1081.
Schw¨obel,S.,Kiebel,S.,andMarkovic,D.(2018). ActiveInference,BeliefProp-
agation, and the Bethe Approximation. Neural Computation, 30(9):2530–
2567.
Tschantz, A., Millidge, B., Seth, A. K., and Buckley, C. L. (2020). Reinforce-
ment learning through active inference. arXiv preprint arXiv:2002.12636.
Ueltzh¨offer, K. (2018). Deep Active Inference. Biological Cybernetics,
112(6):547–573.
van de Laar, T. W. (2019). Automated design of Bayesian signal processing
algorithms. Eindhoven University of Technology.
van de Laar, T. W., Cox, M., Senoz, I., Bocharov, I., and de Vries, B. (2018).
Forneylab: a toolbox for biologically plausible free energy minimization in
dynamic neural models. In Conference on Complex Systems.
van de Laar, T. W. and de Vries, B. (2019). Simulating Active Inference Pro-
cesses by Message Passing. Frontiers in Robotics and AI, 6:20.
van de Laar, T. W., O¨z¸celikkale, A., and Wymeersch, H. (2019). Applica-
tion of the free energy principle to estimation and control. arXiv preprint
arXiv:1910.09823.
Winn, J. and Bishop, C. M. (2005). Variational message passing. Journal of
Machine Learning Research, 6(Apr):661–694.
Yedidia, J. S., Freeman, W., and Weiss, Y. (2005). Constructing free-energy
approximations and generalized belief propagation algorithms. IEEE Trans-
actions on Information Theory, 51(7):2282–2312.
Yedidia, J. S., Freeman, W. T., Weiss, Y., et al. (2000). Generalized belief
propagation. In NIPS, volume 13, pages 689–695.
Zhang, D., Wang, W., Fettweis, G., and Gao, X. (2017). Unifying message
passing algorithms under the framework of constrained Bethe free energy
minimization. arXiv preprint arXiv:1703.10932.
25

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Chance-Constrained Active Inference"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
