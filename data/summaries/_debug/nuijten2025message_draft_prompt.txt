=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: A Message Passing Realization of Expected Free Energy Minimization
Citation Key: nuijten2025message
Authors: Wouter W. L. Nuijten, Mykola Lukashchuk, Thijs van de Laar

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: energy, approach, expected, passing, minimization, realization, inference, eindhoven, free, epistemic

=== FULL PAPER TEXT ===

A Message Passing Realization of
Expected Free Energy Minimization
Wouter W. L. Nuijten1, Mykola Lukashchuk1, Thijs van de Laar1, and Bert de
Vries1,2
1 Eindhoven University of Technology, 5612 AP Eindhoven, the Netherlands
2 GN Hearing, 5612 AB Eindhoven, The Netherlands
Abstract. We present a message passing approach to Expected Free
Energy (EFE) minimization on factor graphs, based on the theory intro-
duced in [37]. By reformulating EFE minimization as Variational Free
Energyminimizationwithepistemicpriors,wetransformacombinatorial
search problem into a tractable inference problem solvable through stan-
dard variational techniques. Applying our message passing method to
factorized state-space models enables efficient policy inference. We evalu-
ate our method on environments with epistemic uncertainty: a stochastic
gridworld and a partially observable Minigrid task. Agents using our
approach consistently outperform conventional KL-control agents on
thesetasks,showingmorerobustplanningandefficientexplorationunder
uncertainty. In the stochastic gridworld environment, EFE-minimizing
agents avoid risky paths, while in the partially observable minigrid set-
ting, they conduct more systematic information-seeking. This approach
bridges active inference theory with practical implementations, providing
empiricalevidencefortheefficiencyofepistemicpriorsinartificialagents.
Keywords: Active Inference · Epistemic Planning · Expected Free En-
ergy · Factor Graphs · Message Passing
1 Introduction
Expected Free Energy (EFE) minimization, rooted in the Free Energy Principle,
provides a framework for modeling intelligent behavior by unifying reward-
seeking (pragmatic) and information-seeking (epistemic) drives [16,18]. While
control-as-inference approaches have made significant advances in formulating
decision-making as probabilistic inference problems [20,1], EFE minimization
extends this paradigm by explicitly accounting for epistemic uncertainty [13],
though its practical application faces computational challenges for extended
planning horizons and high-dimensional state-spaces [30].
TraditionalapproachestocomputingEFEofteninvolveevaluatingallpossible
action sequences, which becomes intractable for non-trivial problems. While
various approximations have been developed to address this tractability issue,
traditionalapproachestypicallyuseEFEasacostfunctionforevaluatingpolicies,
rather than as an objective functional for variational optimization of beliefs
[29,8,19].
5202
guA
4
]IA.sc[
1v79120.8052:viXra
2 W. W. L. Nuijten et al.
This paper provides empirical validation of the theoretical foundation pre-
sented in [37], which reformulates EFE minimization directly as a variational
inference problem on factor graphs. By introducing appropriate epistemic priors,
we show that minimizing EFE can be achieved through standard Variational
Free Energy (VFE) minimization, making it consistent with the Free Energy
Principle’s core tenet that all processes are fundamentally based on variational
free energy minimization.
We implement this approach through an iterative message passing algorithm
on factorized state-space models. We evaluate its performance in environments
with different uncertainty characteristics: a stochastic gridworld with perilous
transitions and a partially observable Minigrid environment requiring active
exploration for successful completion. Our results confirm that agents using
our inference-based method exhibit the same characteristic advantages over KL-
control agents as direct EFE computation, particularly in handling epistemic
uncertainty. This validates our approach while providing a computationally
efficient framework for planning under uncertainty.
The remainder of this paper is organized as follows:
– Section 2 provides background on necessary materials.
– Section 3 discusses related work in control as inference and active inference.
– Section 4 presents our methodology for reformulating EFE minimization as
an inference problem.
– Section 5 describes our evaluation environments and experimental design.
2 Background
2.1 Variational Inference
Variational inference (VI) provides a principled framework for approximating
complex posterior distributions in Bayesian models [24,6,7,38]. The central chal-
lenge in Bayesian inference is computing the posterior distribution p(x|y) of
hidden state sequence x given an observed data sequence y, which requires eval-
uating the model evidence p(y) [11,21]. This normalization constant is typically
intractable for complex models.
VI reformulates inference as an optimization problem by approximating the
Bayesian posterior with a simpler, tractable distribution q(x) from a family of
distributionsQ[7].ThefunctionalwewillminimizeistheVariationalFreeEnergy
(VFE). The VFE is defined as F[q]=D (q(x)∥p(x|y))−logp(y), making it
KL
clear that minimizing the VFE is equivalent to minimizing the KL divergence
since logp(y) is constant with respect to q. The VFE also provides a tractable
upper bound on the negative log evidence, with F[q]≥−logp(y) [23].
2.2 Factor Graphs
Factor graphs are a specific type of probabilistic graphical model that explicitly
represents the factorization structure of the model, where factors represent
A Message Passing Realization of Expected Free Energy Minimization 3
s s s
1 2 4
f f f
a b d
→− ←−
µ(s ) µ(s )
2 2 s →−
3 µ(s )
3
f
c
Fig.1: A Forney-style factor graph representation of the factorization in (2).
(conditional) probability distributions. In our work, we employ Forney-style
factor graphs (FFGs) [15], which offer a specific representation approach with
notation following [26].
An FFG represents a factorized function f(s) as
(cid:89)
f(s)= f (s ), (1)
a a
a∈V
where s encompasses all variables in the model, and s ⊆s represents the subset
a
of variables that participate in factor f .
a
In the FFG representation, nodes (a∈V) correspond to factors in the model,
whileedges(E ⊆V×V)representvariables.Anedgeconnectstoanodeprecisely
whenthevariableappearsasanargumentinthecorrespondingfactor.Wedenote
the set of edges connected to node a∈V as E(a), and the nodes connected to
edge i∈E as V(i).
To illustrate, the FFG representation of the factorized function
f(s ,s ,s ,s )=f (s )f (s ,s )f (s )f (s ,s ,s ) (2)
1 2 3 4 a 1 b 1 2 c 3 d 2 3 4
in shown in Figure 1.
A common approach to realizing efficient variational inference on factor
graphsinvolvestheBetheassumption,whichpositsthattheposteriordistribution
factorizes as a product of local marginals associated with the nodes and edges of
the graph. This structural assumption on the posterior distributions enables the
formulation of message passing algorithms that seek out stationary points of the
Bethe free energy [39,40,14].
To illustrate the computational benefits of message passing, consider the
generative model in (2), and assume we are interested in computing p(s ). This
2
marginal distribution can be obtained by summing out all other variables from
the joint
(cid:88)(cid:88)(cid:88)
p(s )= f(s ,s ,s ,s ), (3)
2 1 2 3 4
s1 s3 s4
which,wheneachs cantake10values,containsaboutathousandterms.However,
i
taking into account the factorization of the generative model and the distributive
4 W. W. L. Nuijten et al.
law of the product, (3) can be rewritten as
→−
µ(s3)
(cid:18) (cid:19) (cid:18) (cid:122) (cid:125)(cid:124) (cid:123) (cid:19)
p(s )=
(cid:88)
f (s )f (s ,s ) ·
(cid:0)(cid:88)
f (s )
(cid:1)(cid:88)
f (s ,s ,s ) . (4)
2 a 1 b 1 2 c 3 d 2 3 4
s1 s3 s4
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
→− ←−
µ(s2) µ(s2)
Thecomputationin(4)requiresonlyafewhundredsummationsandispreferable
from a computational standpoint. In larger models, the number of computations
scale linearly with the number of factor nodes, instead of exponentially. The
intermediateresults→− µ(s )and← µ − (s )affordaninterpretationaslocalmessagein
i i
theFFGrepresentationofthemodel,seeFigure1.Forcomprehensivetreatments
offactorgraphsandassociated(variational)messagepassingalgorithms,werefer
readers to [26,27,39,14,40].
3 Related Work
Autonomous decision-making under uncertainty remains a central challenge in
control theory and artificial intelligence. This section reviews key developments
that contextualize our contribution.
3.1 Control as Inference
The pursuit of efficient and high-performing autonomous systems has driven
significant research in control theory. Optimal control [3,4,32] provides a mathe-
matical framework for determining the control inputs that minimize a predefined
cost function for a given system. Building upon these foundations, Model Pre-
dictive Control (MPC) algorithms address the challenges of real-time control by
incorporating a feedback loop and a receding horizon strategy [5,33,34,12]. This
approach allows for online adaptation to disturbances and constraints.
A significant paradigm shift in recent years involves viewing control as an in-
ference problem. This perspective allows the application of powerful probabilistic
tools to address control challenges, particularly in complex and uncertain envi-
ronments. Under deterministic dynamics, the sequential decision-making process
in closed-loop receding horizon MPC can be elegantly mapped to inference on a
factor graph [25,28].
When dealing with stochastic dynamics or the need for state estimation
under uncertainty, stochastic optimal control methods can be reformulated using
variational inference [22,20]. Here, the intractable posterior distribution over
states and/or controls is approximated by a tractable variational distribution.
Activeinference[13,10]addressescontrolunderuncertaintybyproposingthat
information gained about the system is also a form of reward. The framework
suggeststhatvariationalinferencenaturallybalancesexplorationandexploitation
by optimizing the Expected Free Energy [18], which elegantly combines the drive
to minimize uncertainty about the environment (information gain) with the need
A Message Passing Realization of Expected Free Energy Minimization 5
to achieve desired outcomes. However, a current limitation of active inference lies
in the computational cost associated with computing the Expected Free Energy
[18], which has spurred recent research into efficient algorithms [29,17,30,8].
Recently, [37] proposed an alternative approach to Expected Free Energy
minimization by framing EFE minimization as a regular variational free energy
minimization task. This approach is promising for scalable implementation of
EFE-minimizing planning algorithms, but offers a theoretical account, without
considering practical implementation or empirical validation. In the next section,
we will propose a message passing realization of this approach.
4 Methodology
Forthemaincontributionofthispaper,wewillelaborateonTheorem1from[37].
For convenience, we will repeat the theorem here, albeit without the inclusion of
model parameters θ:
Theorem 1 (Expected Free Energy Theorem). Consider an agent with
generative model p(y,x,u), and prior beliefs pˆ(x) about future desired states.
Consider the Variational Free Energy functional
posterior
(cid:122) (cid:125)(cid:124) (cid:123)
(cid:20) (cid:21)
q(y,x,u)
F[q]≜E log , (5)
q(y,x,u) p(y,x,u) pˆ(x) p˜(u)p˜(x)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124)(cid:123)(cid:122)(cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
generative preference epistemic
model prior priors
where the generative model in the denominator is augmented by both a preference
prior pˆ(·) and epistemic priors p˜(·).
If the epistemic priors are chosen as
p˜(u)∝exp(H[q(x|u)]) (6a)
p˜(x)∝exp(−H[q(y|x)]) (6b)
then F[q] decomposes as
(cid:20) (cid:21)
F[q]=E (cid:2) G(u) (cid:3) +E log q(y,x,u) +constant, (7)
q(u) q(y,x,u) p(y,x,u)
(cid:124) (cid:123)(cid:122) (cid:125)
expectedpolicy (cid:124) (cid:123)(cid:122) (cid:125)
costs complexity
where
(cid:20) (cid:18) (cid:19)(cid:21)
q(x|u) 1
G(u)=E log · (8)
q(y,x|u) pˆ(x) q(y|x)
is the expected free energy as defined in [13]. In (6),
(cid:90)
H[q(y|x)]=− q(y|x)logq(y|x)dy (9)
is the entropy functional.
6 W. W. L. Nuijten et al.
Proof. The proof of (7) is given in [37, Appendix A].
While (7) shows that minimization of the F[q] leads to minimization of
(expected) G(u), the proof of (7) is declarative and does not provide an explicit
algorithm for minimizing F[q].
In the following sections, we will describe a message passing algorithm on
factor graphs that can be used as a practical approach to search for stationary
points of the free energy functional.
4.1 Factorized models and factorized posteriors
Theorem 1 is a general result, however, in practice, we are often interested in
factorized state-space models of the form
T
(cid:89)
p(y,x,u)=p(x ) p(y |x )p(x |x ,u )p(u ) (10)
0 t t t t−1 t t
t=1
We can make an additional assumption that the posterior distribution factorizes
in the same way as the generative model:
T
(cid:89)
q(y,x,u)=q(x ) q(y |x )q(x |x ,u )q(u ). (11)
0 t t t t−1 t t
t=1
Note that this is consistent with making the Bethe assumption, which says that
the variational posterior distribution can be decomposed into local contributions:
(cid:89) (cid:89)
q(s)= q (s ) q (s )−1 (12)
a a i i
a∈V i∈E
for G = (V,E) the underlying FFG. Under this assumption, we can derive a
corollary to Theorem 1 that provides more specific expressions for the epistemic
priors.
Corollary 1. Consider an agent with Variational Free Energy functional as in
(5), comprising a generative model (10), a posterior distribution factorized as
in (11), and a preference prior pˆ(x) = (cid:81)T pˆ(x ). If the epistemic priors are
t=1 t
chosen as
p˜(u )∝exp(H[q(x ,x |u )]−H[q(x |u )]) (13a)
t t t−1 t t−1 t
p˜(x )∝exp(−H[q(y |x )]) (13b)
t t t
then the Variational Free Energy functional (5) decomposes as
(cid:20) (cid:21)
F[q]=E (cid:2) G(u) (cid:3) +E log q(y,x,u) +constant. (14)
q(u) q(y,x,u) p(y,x,u)
A Message Passing Realization of Expected Free Energy Minimization 7
While this corollary is a special case and a direct application of Theorem 1,
an elaboration of the proof is given in Appendix A. This corollary states that
the preference and epistemic priors can be reduced to local contributions. We
will implement the preference and epistemic priors as factor nodes that act as
prior distributions during the inference procedure. A timeslice of the augmented
factor graph is shown in Figure 2.
The benefit of this approach is that in-
ference on factor graphs is well-understood
and can be implemented efficiently using re-
active message passing [2]. Effectively, this
p˜(ut+1)
means that the computational complexity of ut+1
Expected Free Energy minimization is the
···
xt xt+1
···
same as the computational complexity of vari-
ational inference on a factor graph. p(xt+1|xt,ut+1)
p˜(xt+1) pˆ(xt+1)
4.2 Inferring a policy posterior
Fig.2: Slice of the factor graph
Corollary 1 introduces a circular dependency
representation of the augmented
in the model definition: to define the VFE
generative model. The original
functional with epistemic priors (13), we need
generative model (10) is aug-
access to the variational posterior distribution,
mented with epistemic priors
but the variational posterior can only be ob-
p˜(u ) and p˜(x ), and pref-
tainedbyminimizingtheVFEfunctionalgiven t+1 t+1
erence priors pˆ(x ) for future
the generative model. t+1
timesteps.
This circular dependency can be resolved
through an iterative variational inference pro-
cedureimplementedasmessagepassingonthe
factor graph. We first initialize the variational
posterior and then iteratively update both the
posterior beliefs and epistemic priors until convergence.
On a factor graph, we can implement variational inference using message
passing algorithms that iteratively updates posterior distributions [31].
Each message passing iteration τ refines both the posteriors and priors
simultaneously. To that extent, let q (·) be the variational posterior distribution
τ
at iteration τ, we then define the epistemic priors as
(cid:0) (cid:1)
p˜ (u )=σ H[q (x ,x |u )]−H[q (x |u )]
τ t τ−1 t t−1 t τ−1 t−1 t (15)
(cid:0) (cid:1)
p˜ (x )=σ −H[q (y |x )] .
τ t τ−1 t t
Here,σ isthesoftmaxfunction,whichguaranteesproportionalityasinEquations
13aand13b.AformaldescriptionofthealgorithmisgiveninAlgorithm1.While
this approach solves the initialization problem, there are some subtleties that
need to be addressed. Specifically, although the subtraction of entropies in line
Equation 21a results in a constant when using the same variational distribution
q for both the epistemic prior p˜and the optimization, this property no longer
holds when we use different distributions - namely, when we use q to define
τ−1
8 W. W. L. Nuijten et al.
p˜ but optimize with respect to q . While this is not a problem if the inference
τ τ
procedure converges, this convergence is not guaranteed.
Algorithm 1 EFE minimization as VFE minimization
1: Input:Factorizedgenerativemodelp(y,x,u),preferencepriorpˆ(x),number
of VI iterations τ
max
2: Output: Policy posterior q (u)
τmax
3: q (y,x,u)← Uninformative distribution
0
4: for τ ←1 to τ do ▷ Iterations of variational inference algorithm
max
5: for each time step t do
6: p˜ (u )←σ(H[q (x ,x |u )]−H[q (x |u )])
τ t τ−1 t t−1 t τ−1 t−1 t
7: p˜ (x )←σ(−H[q (y |x )])
τ t τ−1 t t
8: end for
9: q (y,x,u)←infer(p(y,x,u)) ▷ Message passing (4)
τ
10: end for
11: return q (u)
τmax
5 Evaluation
This section evaluates our EFE-minimizing policy inference method. In this
section, we will evaluate the performance of the proposed method. The addition
of preference priors is consistent with the literature on KL control [35,36], which
means the main point of interest is the influence of the epistemic priors on
the policy posterior. To this extent, we will execute the experiments both with
and without the epistemic priors, which will correspond to a KL-control and
an EFE-minimizing policy, respectively. KL-control is known to be prone to
optimistic planning in the face of stochasticity and uncertainty [28,25], so we
will explore partially observable Markov decision processes (POMDPs) with
stochastic dynamics and observation noise.
Forourexperimentalevaluation,weconsiderscenarioswheretheenvironment
dynamics are completely known to the agent, though they may be stochastic
or contain inherent uncertainty. This known-dynamics assumption allows us to
isolate and evaluate the specific effects of epistemic priors on decision-making,
without conflating them with model learning.
5.1 Experimental design
Wedesignedastochasticgridenvironmentthatspecificallychallengesagentswith
uncertainty in dynamics and observations. Additionally, we evaluate our method
on the Minigrid door-key environment [9], which tests how agents handle partial
observability. Both environments highlight the differences between KL-control
and EFE-minimizing policies in the presence of epistemic uncertainty.
A Message Passing Realization of Expected Free Energy Minimization 9
MazeElements
Sinkstate
Negativereward
Positivereward
Observationnoise
Stochastictransition
Agentposition
Fig.3: The stochastic grid environment. The agent should traverse the grid
with both stochastic transitions and observation noise. Cells with stochastic
transitions appear on the shortest path, creating a risk-reward tradeoff. Opacity
for observation noise is used to indicate the uncertainty in the environment.
Stochastic Grid Environment Forourfirstexperiment,wefocusonastochas-
tic grid environment. In this environment, the agent has to traverse the grid
from one end to the other, with hazards and stochastic transitions. The key
challenge is that on the shortest path from the start to the goal, there are cells
in which the transition matrix is stochastic, with the risk that the agent will end
up in a sink state. The stochasticity presents a direct test of how agents handle
uncertainty in dynamics: the KL-control agent is expected to plan optimistically
through these uncertain transitions, while the EFE-minimizing agent should
recognize the epistemic risk and avoid these cells. This environment also features
observation noise, adding another layer of uncertainty that forces the agent to
maintain beliefs over possible states rather than having full observability.
A longer but safer path exists that avoids all stochastic transitions. The
optimal policy for a risk-aware agent would be to take this safer path, despite it
requiring more steps. A visualization of the environment is shown in Figure 3.
The agent receives a reward of 1 for reaching the goal. When ending up in
a sink state, the agent receives a penalty of −1. The full specification of the
generative model can be found in Appendix B.
Minigrid Door-Key Environment The second environment we consider is a
Minigridenvironment,specificallya4x4door-keyenvironment.Thisenvironment
tests a different aspect of epistemic uncertainty, namely, partial observability.
The agent has a limited field of view, which means that the agent must actively
explore to reduce uncertainty about the environment state.
The task requires the agent to locate and pick up a key, find and open a
door, and finally reach the goal square. This multi-step process creates a natural
exploration challenge that tests how agents handle partial observability. The
agent location, key location, and door location are randomized in each episode,
10 W. W. L. Nuijten et al.
which means that the agent has epistemic uncertainty about the environment
state.
The EFE-minimizing agent should show more di-
rected exploration behavior, actively seeking to reduce
uncertainty about the key and door locations. In con-
trast, the KL-control agent (without epistemic priors)
might exhibit less efficient exploration patterns, as it
lacks the intrinsic drive to resolve uncertainty.
The Minigrid environment adds another layer of
complexity to the task, as the field of view means that
the observations are relative to the agent, while the
goals are formulated in an external frame of reference.
This means that the observation space of the agent
is much larger than the state space. The observation
Fig.4: An initial state
space is of size ≈ 549 , which makes algorithms like
of the Minigrid environ-
Sophisticated Inference [17] intractable. Furthermore,
ment. The agent has
the planning horizon of 22 timesteps makes standard
a limited field of view,
Expected Free Energy computation as policy evalu-
indicated by the high-
ation intractable. The computational complexity of
lighted cells.
the door-key environment is where the benefits of the
proposed method are most evident.
A visualization of the initial state of the Minigrid
environment is shown in Figure 4. The agent receives a reward when reaching
the goal, proportional to the number of steps taken. The full specification of
the used generative model can be found in Appendix C. The source code and
implementation details for all experiments presented in this paper are publicly
available in our online repository3.
5.2 Results
Stochastic Grid Environment We evaluated the performance of both agents
across 100 episodes, Table 1, left, summarizes the quantitative results.
This table suggests distincly different navigational patterns between both
agents. The EFE-minimizing agent consistently chooses the longer but safer path
around the stochastic transition cells, demonstrating risk-averse behavior that
alignswiththeoreticalpredictions.Incontrast,theKL-controlagentattemptsthe
shorter path through cells with stochastic transitions, exhibiting the optimistic
planning tendency typical of approaches that wrongly account for the system’s
aleatoric uncertainty. A more detailed visualization of the trajectories for both
agents, as well as an empirical convergence analysis of our algorithm, is provided
in Appendix D.
Minigrid Door-Key Environment We evaluated both agents across 200
experimentalepisodeswithaplanninghorizonof25steps.Table1,right,presents
3 https://github.com/biaslab/EFEasVFE
A Message Passing Realization of Expected Free Energy Minimization 11
Stochastic Grid Minigrid Door-Key
Metric KL EFE (ours) Metric KL EFE (ours)
Success Rate 21% 100% Success Rate 76.5% 88.0%
Avg. Reward 0.22 ± 0.77 1.00 ± 0 Avg. Reward 0.74 ± 0.410.85 ± 0.32
Avg. Time to
- - - 3.36 ± 6.291.34 ± 1.08
Key Visibility
Table1:Performancecomparisonacrossenvironments(100episodesforStochastic
Grid, 200 episodes for Minigrid).
the quantitative comparison between the EFE-minimizing and KL-control agents
in the Minigrid door-key environment.
The EFE-minimizing agent demonstrates more effective exploration patterns,
particularly in scenarios requiring active information seeking. This is especially
evident in the reduced time needed to locate the key, confirming that epis-
temic priors enable more directed information-seeking in partially observable
environments.
A more detailed visualization of the trajectories for both agents and an
empirical convergence analysis of our algorithm is provided in Appendix E.
6 Discussion
Our experimental results demonstrate that agents using the proposed message
passing approach for EFE minimization exhibit the characteristic behaviors
of active inference: risk-averse path selection in stochastic environments and
information-seeking exploration in partially observable settings. These behaviors
emerge naturally from the inclusion of epistemic priors in the variational free
energy objective, without requiring explicit computation of expected free energy.
The reformulation of EFE minimization as a variational inference problem
provides several advantages: it maintains theoretical consistency with the Free
Energy Principle’s core tenet; transforms a combinatorial search problem into
a tractable inference procedure using message passing on factor graphs; and
eliminates the need for ad hoc policy pruning, replacing it with principled
reactive processing where the agent minimizes VFE at each point in time. This
approachisparticularlyvaluableincomplexenvironmentswheretraditionalEFE
computation becomes intractable, as demonstrated in our Minigrid experiments.
Whileourimplementationshowspromisingresults,theconvergenceproperties
of our iterative approach to handling self-referential epistemic priors require
further theoretical investigation. Future research should investigate the inclusion
of additional parameters in the generative model, particularly those related to
environment dynamics. A natural extension of our work would be to incorporate
parameter learning within the epistemic priors. This would allow agents to infer
policiesthatfacilitatesample-efficientlearningofmodelparameters.Thisconcept
has already been introduced in [37]. However, the exact functional form of the
empirical prior has not yet been derived.
12 W. W. L. Nuijten et al.
7 Conclusion
In this paper, we presented a message passing implementation of Expected Free
Energyminimizationonfactorgraphs.OurapproachreframesEFEminimization
as a variational inference problem, allowing us to use standard message passing
algorithms for efficient policy inference. The key insight is that by introducing
appropriateepistemicpriors,wecantransformtheexpectedfreeenergyobjective
into a modified variational free energy objective that can be optimized through
standard inference techniques.
Our experimental results in both stochastic and partially observable environ-
ments demonstrate that this approach reproduces the characteristic behaviors of
active inference: risk aversion in environments with hazardous stochasticity and
information seeking in partially observable environments. The message passing
implementation shows significant advantages in computational efficiency com-
pared to traditional methods for computing expected free energy, particularly
in complex environments with high-dimensional observation spaces and long
planning horizons.
By reformulating EFE minimization as variational inference, our work con-
tributes to unifying the theoretical frameworks of the Free Energy Principle
and active inference with practical implementations for decision-making under
uncertainty. This bridges the gap between theoretical accounts of intelligent
behavior and efficient algorithms for artificial agents, offering a principled ap-
proachtobalancingpragmaticandepistemicobjectivesincomplexanduncertain
environments.
Acknowledgements
Thispublicationispartoftheproject"ROBUST:TrustworthyAI-basedSystems
for Sustainable Growth" with project number KICH3.LTP.20.006, which is
(partly) financed by the Dutch Research Council (NWO), GN Hearing, and the
DutchMinistryofEconomicAffairsandClimatePolicy(EZK)undertheprogram
LTP KIC 2020-2023.
References
1. Attias, H.: Planning by probabilistic inference. In: International workshop on
artificialintelligenceandstatistics.pp.9–16.PMLR(2003),https://proceedings.
mlr.press/r4/attias03a.html
2. Bagaev, D., de Vries, B.: Reactive Message Passing for Scalable Bayesian Inference
(Dec 2021). https://doi.org/10.48550/arXiv.2112.13251, http://arxiv.org/
abs/2112.13251, arXiv:2112.13251 [cs]
3. Bellman, R.: The theory of dynamic programming. Bulletin of the
American Mathematical Society 60(6), 503–515 (1954). https://doi.org/
10.1090/S0002-9904-1954-09848-8, https://www.ams.org/bull/1954-60-06/
S0002-9904-1954-09848-8/
A Message Passing Realization of Expected Free Energy Minimization 13
4. Bellman, R.: Dynamic Programming. Science 153(3731), 34–37 (1966), https:
//www.jstor.org/stable/1719695, publisher: American Association for the Ad-
vancement of Science
5. Bertsekas, D.: Dynamic programming and optimal control: Volume I,
vol. 4. Athena scientific (2012), https://books.google.com/books?hl=en&
lr=&id=qVBEEAAAQBAJ&oi=fnd&pg=PR1&dq=Dynamic+Programming+and+Optimal+
Control&ots=x0bAav0O5n&sig=s3UxthkdnzR2UpqCUsUsQ7zKgLc
6. Bishop, C.M., Nasrabadi, N.M.: Pattern recognition and machine learning, vol. 4.
Springer (2006), https://link.springer.com/book/9780387310732
7. Blei, D.M., Kucukelbir, A., McAuliffe, J.D.: Variational Inference: A Review
for Statisticians. Journal of the American Statistical Association 112(518), 859–
877 (Apr 2017). https://doi.org/10.1080/01621459.2017.1285773, https://
doi.org/10.1080/01621459.2017.1285773, publisher: Taylor & Francis _eprint:
https://doi.org/10.1080/01621459.2017.1285773
8. Champion, T., Da Costa, L., Bowman, H., Grześ, M.: Branching Time Ac-
tive Inference: The theory and its generality. Neural Networks 151, 295–
316 (Jul 2022). https://doi.org/10.1016/j.neunet.2022.03.036, https://www.
sciencedirect.com/science/article/pii/S0893608022001149
9. Chevalier-Boisvert, M., Dai, B., Towers, M., Perez-Vicente, R., Willems, L.,
Lahlou, S., Pal, S., Castro, P.S., Terry, J.: Minigrid & miniworld: Modu-
lar & customizable reinforcement learning environments for goal-oriented
tasks. Advances in Neural Information Processing Systems 36, 73383–73394
(2023), https://proceedings.neurips.cc/paper_files/paper/2023/hash/
e8916198466e8ef218a2185a491b49fa-Abstract-Datasets_and_Benchmarks.
html
10. Costa, L.D., Tenka, S., Zhao, D., Sajid, N.: Active Inference as a Model of Agency
(Jan 2024). https://doi.org/10.48550/arXiv.2401.12917, http://arxiv.org/
abs/2401.12917, arXiv:2401.12917 [cs]
11. Cox, R.T.: Probability, frequency and reasonable expectation. American journal
of physics 14(1), 1–13 (1946), http://www.cs.toronto.edu/~ilya/cox1946.pdf,
publisher: American Association of Physics Teachers
12. Cutler, R.R., Ramaker, B.L.: Dynamic Matrix Control-A Computer Control Algo-
rithm. Proc. Joint Automatic Control Conference, 1979 (1979), https://cir.nii.
ac.jp/crid/1570291225777284224
13. Da Costa, L., Parr, T., Sajid, N., Veselic, S., Neacsu, V., Friston, K.: Active
inferenceondiscretestate-spaces:Asynthesis.JournalofMathematicalPsychology
99, 102447 (Dec 2020). https://doi.org/10.1016/j.jmp.2020.102447, https:
//www.sciencedirect.com/science/article/pii/S0022249620300857
14. Dauwels, J.: On Variational Message Passing on Factor Graphs. In: IEEE Interna-
tional Symposium on Information Theory. pp. 2546–2550. Nice, France (Jun 2007).
https://doi.org/10.1109/ISIT.2007.4557602
15. Forney, G.D.: Codes on graphs: Normal realizations. IEEE Transactions on Infor-
mation Theory 47(2), 520–548 (2001), https://ieeexplore.ieee.org/abstract/
document/910573/, publisher: IEEE
16. Friston, K.: The free-energy principle: a unified brain theory? Nature Reviews
Neuroscience 11(2), 127–138 (Feb 2010). https://doi.org/10.1038/nrn2787,
https://www.nature.com/articles/nrn2787, number: 2 Publisher: Nature Pub-
lishing Group
17. Friston, K., Costa, L.D., Hafner, D., Hesp, C., Parr, T.: Sophisticated Inference
(Jun 2020). https://doi.org/10.48550/arXiv.2006.04120, http://arxiv.org/
abs/2006.04120, arXiv:2006.04120 [q-bio]
14 W. W. L. Nuijten et al.
18. Friston, K., Rigoli, F., Ognibene, D., Mathys, C., Fitzgerald, T., Pezzulo,
G.: Active inference and epistemic value. Cognitive Neuroscience 6(4), 187–
214(Oct2015).https://doi.org/10.1080/17588928.2015.1020053,http://www.
tandfonline.com/doi/full/10.1080/17588928.2015.1020053
19. Friston, K.J., Salvatori, T., Isomura, T., Tschantz, A., Kiefer, A., Verbelen, T.,
Koudahl, M., Paul, A., Parr, T., Razi, A., Kagan, B.J., Buckley, C.L., Ramstead,
M.J.D.:ActiveInferenceandIntentionalBehavior.NeuralComputation37(4),666–
700 (Mar 2025). https://doi.org/10.1162/neco_a_01738, https://doi.org/10.
1162/neco_a_01738
20. Ito,K.,,Kashima,K.:Kullback–Leiblercontrolfordiscrete-timenonlinearsystems
on continuous spaces. SICE Journal of Control, Measurement, and System In-
tegration 15(2), 119–129 (Jun 2022). https://doi.org/10.1080/18824889.2022.
2095827, https://doi.org/10.1080/18824889.2022.2095827, publisher: Taylor
& Francis _eprint: https://doi.org/10.1080/18824889.2022.2095827
21. Jaynes, E.T.: Probability Theory: The Logic of Science. Cambridge University
Press, 1 edn. (Apr 2003). https://doi.org/10.1017/CBO9780511790423, https:
//www.cambridge.org/core/product/identifier/9780511790423/type/book
22. Kappen,B.,Gomez,V.,Opper,M.:Optimalcontrolasagraphicalmodelinference
problem. Machine Learning 87(2), 159–182 (May 2012). https://doi.org/10.
1007/s10994-012-5278-7, http://arxiv.org/abs/0901.0633, arXiv:0901.0633
[math]
23. Kingma, D.P., Welling, M.: Auto-Encoding Variational Bayes (Dec 2022). https:
//doi.org/10.48550/arXiv.1312.6114, http://arxiv.org/abs/1312.6114,
arXiv:1312.6114 [cs, stat]
24. Koller,D.,Friedman,N.:ProbabilisticGraphicalModels:PrinciplesandTechniques.
MIT Press (Jul 2009), google-Books-ID: 7dzpHCHzNQ4C
25. Levine,S.:ReinforcementLearningandControlasProbabilisticInference:Tutorial
and Review (May 2018). https://doi.org/10.48550/arXiv.1805.00909, http:
//arxiv.org/abs/1805.00909, arXiv:1805.00909 [cs]
26. Loeliger,H.A.:Anintroductiontofactorgraphs.IEEESignalProcessingMagazine
21(1), 28–41 (Jan 2004). https://doi.org/10.1109/MSP.2004.1267047, confer-
ence Name: IEEE Signal Processing Magazine
27. Loeliger,H.A.,Dauwels,J.,Hu,J.,Korl,S.,Ping,L.,Kschischang,F.R.:TheFactor
GraphApproachtoModel-BasedSignalProcessing.ProceedingsoftheIEEE95(6),
1295–1322 (Jun 2007). https://doi.org/10.1109/JPROC.2007.896497
28. Lázaro-Gredilla, M., Ku, L.Y., Murphy, K.P., George, D.: What type of inference
is planning? (Nov 2024). https://doi.org/10.48550/arXiv.2406.17863, http:
//arxiv.org/abs/2406.17863, arXiv:2406.17863
29. Paul, A., Sajid, N., Costa, L.D., Razi, A.: On efficient computation
in active inference. Expert Systems with Applications 253, 124315 (Nov
2024). https://doi.org/10.1016/j.eswa.2024.124315, http://arxiv.org/abs/
2307.00504, arXiv:2307.00504 [cs]
30. Paul, A., Sajid, N., Gopalkrishnan, M., Razi, A.: Active Inference for Stochastic
Control. In: Kamp, M., Koprinska, I., Bibal, A., Bouadi, T., Frénay, B., Galárraga,
L., Oramas, J., Adilova, L., Krishnamurthy, Y., Kang, B., Largeron, C., Lijffijt, J.,
Viard, T., Welke, P., Ruocco, M., Aune, E., Gallicchio, C., Schiele, G., Pernkopf,
F., Blott, M., Fröning, H., Schindler, G., Guidotti, R., Monreale, A., Rinzivillo,
S., Biecek, P., Ntoutsi, E., Pechenizkiy, M., Rosenhahn, B., Buckley, C., Cialfi, D.,
Lanillos, P., Ramstead, M., Verbelen, T., Ferreira, P.M., Andresini, G., Malerba,
D., Medeiros, I., Fournier-Viger, P., Nawaz, M.S., Ventura, S., Sun, M., Zhou, M.,
A Message Passing Realization of Expected Free Energy Minimization 15
Bitetta, V., Bordino, I., Ferretti, A., Gullo, F., Ponti, G., Severini, L., Ribeiro,
R., Gama, J., Gavaldà, R., Cooper, L., Ghazaleh, N., Richiardi, J., Roqueiro,
D., Saldana Miranda, D., Sechidis, K., Graça, G. (eds.) Machine Learning and
PrinciplesandPracticeofKnowledgeDiscoveryinDatabases.pp.669–680.Springer
International Publishing, Cham (2021)
31. Pearl, J.: Reverend Bayes on Inference Engines: A Distributed Hierarchical
Approach. In: AAAI-82 Proceedings. pp. 133–136. AAAI Press, Carnegie
Mellon University, Pittsburgh PA (1982), https://books.google.com/books?
hl=nl&lr=&id=e59kEAAAQBAJ&oi=fnd&pg=PA129&ots=qrs53bNhtS&sig=auOq_
v4YW1fTTgNOvsmydDN6RPY, publisher: Morgan & Claypool
32. Pontryagin, L.S.: Mathematical Theory of Optimal Processes. Routledge, London
(May 2018). https://doi.org/10.1201/9780203749319
33. RICHALET,J.:Algorithmiccontrolofindustrialprocesses.Proc.ofthe4^thIFAC
Sympo. on Identification and System Parameter Estimation pp. 1119–1167 (1976),
https://cir.nii.ac.jp/crid/1570854174674016512
34. Richalet, J., Rault, A., Testud, J.L., Papon, J.: Model predictive heuristic control:
Applicationstoindustrialprocesses.Automatica14(5),413–428(Sep1978).https:
//doi.org/10.1016/0005-1098(78)90001-8, https://www.sciencedirect.com/
science/article/pii/0005109878900018
35. Todorov, E.: Linearly-solvable Markov decision problems. In: Ad-
vances in Neural Information Processing Systems. vol. 19. MIT Press
(2006), https://proceedings.neurips.cc/paper_files/paper/2006/hash/
d806ca13ca3449af72a1ea5aedbed26a-Abstract.html
36. Todorov,E.:Generaldualitybetweenoptimalcontrolandestimation.In:200847th
IEEE Conference on Decision and Control. pp. 4286–4292 (Dec 2008). https://
doi.org/10.1109/CDC.2008.4739438,https://ieeexplore.ieee.org/abstract/
document/4739438, iSSN: 0191-2216
37. Vries, B.d., Nuijten, W., Laar, T.v.d., Kouw, W., Adamiat, S., Nisslbeck,
T., Lukashchuk, M., Nguyen, H.M.H., Araya, M.H., Tresor, R., Jenneskens,
T., Nikoloska, I., Subramanian, R.G., Erp, B.v., Bagaev, D., Podusenko,
A.: Expected Free Energy-based Planning as Variational Inference (Apr
2025). https://doi.org/10.48550/arXiv.2504.14898, http://arxiv.org/abs/
2504.14898, arXiv:2504.14898 [stat]
38. Winn, J., Bishop, C.: Variational Message Passing. Journal of Machine Learning
Research 6, 661–694 (Apr 2005)
39. Yedidia, J.S., Freeman, W., Weiss, Y.: Constructing free-energy approximations
and generalized belief propagation algorithms. IEEE Transactions on Information
Theory51(7),2282–2312(Jul2005).https://doi.org/10.1109/TIT.2005.850085
40. Senöz, İ.: Message Passing Algorithms for Hierarchical Dynamical Models. Phd
,
Thesis1(ResearchTU/e/GraduationTU/e),EindhovenUniversityofTechnology,
Eindhoven (Jun 2022), iSBN: 9789038655321
16 W. W. L. Nuijten et al.
A Proof of Corollary 1
Proof. Proof of Corollary 1. This proof is an adjusted proof of the proof of
Theorem 1, which is given in [37].
(cid:20) (cid:21)
q(y,x,u)
F[q]=E log (16a)
q(y,x,u) p(y,x,u)pˆ(x)p˜(u)p˜(x)
(cid:20) (cid:21)
=E log q(u) +E (cid:2) log q(y,x|u) (cid:3) (16b)
q(u) p(u) q(y,x|u) p(y,x|u)pˆ(x)p˜(u)p˜(x)
(cid:124) (cid:123)(cid:122) (cid:125)
C(u)
(cid:20) (cid:21)
=E log q(u) +G(u)+E (cid:2) log q(y,x|u)(cid:3) +constant (16c)
q(u) p(u) q(y,x|u) p(y,x|u)
(cid:124) (cid:123)(cid:122) (cid:125)
C(u)if (13)holds
(cid:20) (cid:21)
=E (cid:2) G(u) (cid:3) +E log q(y,x,u) +constant if (13) holds
q(u) q(y,x,u) p(y,x,u)
(16d)
In the above derivation, we still need to prove the transition for C(u) from
(16b) to (16c), which we address next.
Lemma 1 (Proof of equivalence C(u) in (16b) and (16c)).
posterior
(cid:122) (cid:125)(cid:124) (cid:123)
(cid:20) (cid:21)
q(y,x|u)
C(u)=E log (17a)
q(y,x|u) p(y,x|u)pˆ(x) p˜(u)p˜(x)
(cid:124) (cid:123)(cid:122) (cid:125)(cid:124)(cid:123)(cid:122)(cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
predictive utilityepistemicpriors
(cid:20) (cid:18) (cid:19)(cid:21)
q(x|u) 1
=E log · + (17b)
q(y,x|u) pˆ(x) q(y|x)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
risk ambiguity
(cid:124) (cid:123)(cid:122) (cid:125)
G(u)=ExpectedFreeEnergy
(cid:20) (cid:18) (cid:19)(cid:21)
pˆ(x)q(y|x) q(y,x|u)
+E log ·
q(y,x|u) q(x|u) p(y,x|u)pˆ(x)p˜(u)p˜(x)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
inversefactorsfromG(u) factorsfrom(17a)
(cid:20) (cid:21) (cid:20) (cid:21)
q(y,x|u) q(y|x)
=G(u)+E log + E log
q(y,x|u) p(y,x|u) q(y,x|u) q(x|u)p˜(u)p˜(x)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
=B(u) chooseepistemicpriorstoletthisvanish
(17c)
(cid:20) (cid:21) (cid:20) (cid:21)
1 q(y|x)
=G(u)+B(u)+E log +E log
q(x|u) q(x|u)p˜(u) q(y|x) p˜(x)
A Message Passing Realization of Expected Free Energy Minimization 17
Now here we can replace the general q(y|x) and q(x|u) with the factorised
(cid:81) (cid:81)
q(y |x ) and q(x |x ,u ).
t t t t t t−1 t
(cid:20) (cid:21)
1
C(u)=G(u)+B(u)+E log +
q(x|u) (cid:81) q(x |x ,u )p˜(u )
t t t−1 t t
(cid:20) (cid:21)
+E logq(y |x )−logp˜(x ) (18a)
q(y|x) t t t
=G(u)+B(u)
(cid:20) (cid:21)
(cid:88)
+ E −logq(x |x ,u )−logp˜(u ) +
q(xt,xt−1|ut) t t−1 t t
x
(cid:20) (cid:21)
(cid:88)
+ E logq(y |x )−logp˜(x ) . (18b)
q(yt|xt) t t t
y
Now we can recognize the following:
(cid:20) (cid:21)
E −logq(x |x ,u ) (19a)
q(xt,xt−1|ut) t t−1 t
(cid:20) (cid:18) (cid:19)(cid:21)
=E − logq(x ,x |u )−logq(x |u ) (19b)
q(xt,xt−1|ut) t t−1 t t−1 t
=H[q(x ,x |u )]−H[q(x |u )], (19c)
t t−1 t t−1 t
and
E (cid:2) logq(y |x ) (cid:3) =−H[q(y |x )]. (20)
q(yt|xt) t t t t
Which, when substituted into (18b), together with the definitions of p˜(u ) and
t
p˜(x ), yields
t
=G(u)+B(u)
(cid:88)
+ H[q(x ,x |u )]−H[q(x |u )]−logp˜(u )+
t t−1 t t−1 t t
(cid:124) (cid:123)(cid:122) (cid:125)
x
=cx ifp˜(ut)∝exp(H[q(xt,xt−1|ut)]−H[q(xt−1|ut)])
(cid:88)
+ H[q(y |x )]−logp˜(x ) (21a)
t t t
(cid:124) (cid:123)(cid:122) (cid:125)
y
=cy ifp˜(xt)∝exp(−H[q(yt|xt)])
(cid:20) (cid:21)
q(y,x|u)
=G(u)+E log +c +c , if (13) holds. (21b)
q(y,x|u) p(y,x|u) x y
18 W. W. L. Nuijten et al.
B Generative Model for the Gridworld Environment
The generative model for the stochastic grid environment is defined as follows:
x ∼p(x ) (22a)
0 0
x ∼Cat(x |x ,u ,B) (22b)
t t t−1 t
y ∼Cat(y |x ,A) (22c)
t t t
x ∼pˆ(x ). (22d)
T T
Here, s represents the agent’s state at time t, y is the observation, and u is
t t t
the action. The transition dynamics are governed by B, and A represents the
observation model. The agent starts with a prior belief p(s ) and aims to reach
0
the goal state by the end of the planning horizon T.
In the case of the KL-control agent, the prior on the control is given by
u ∼Cat(u |1/4) for t=1,...,T . (23)
t t
The EFE-minimizing agent uses empirical priors on the control and the states,
given by
u ∼Cat(u |σ(H[q(x ,x |u )]−H[q(x |u )])) for t=1,...,T (24a)
t t t t−1 t t−1 t
x ∼Cat(x |σ(−H[q(y |x )])) for t=1,...,T . (24b)
t t t t
C Generative Model for the Minigrid Environment
The generative model for the Minigrid environment uses a factorized state and
observation space, which makes the model computationally tractable. Here, the
location of the agent is denoted by l, the orientation by o, the key-door state
by s, the door location by d, and the key location by k. The key-door state is a
categorical variable with three possible values: {0,1,2}, where 0 indicates that
the key is not picked up yet, 1 indicates that the key is picked up but the door is
not opened yet, and 2 indicates that the key is picked up and the door is opened.
For the observations, y is the observation at time t for cell (x,y) of the field
t,(x,y)
ofview.ThegenerativemodelfortheMinigridenvironmentisdefinedasfollows:
l ∼p(l ) (25a)
0 0
o ∼p(o ) (25b)
0 0
s ∼p(s ) (25c)
0 0
d∼p(d) (25d)
k ∼p(k) (25e)
l ∼Cat(l |l ,o ,k,d,s ,u ,Bl) (25f)
t t t−1 t−1 t−1 t
o ∼Cat(o |o ,Bo,u ) (25g)
t t t−1 t
s ∼Cat(s |s ,l ,o ,k,d,u ,Bs) (25h)
t t t−1 t−1 t−1 t−1
y ∼Cat(y |l ,o ,k,d,s ,A ) ∀(x,y)∈{1,...,7}2 (25i)
t,(x,y) t,(x,y) t t t (x,y)
A Message Passing Realization of Expected Free Energy Minimization 19
with terminal state goal priors
l ∼pˆ(l ) (26a)
T T
s ∼Cat(s |[0,0,1])=pˆ(s ), (26b)
T T T
where Bl is the location transition tensor, Bo is the orientation transition tensor,
Bs is the key-door state transition tensor, and A are the observation tensors
(x,y)
for each cell in the field of view.
In the case of the KL-control agent, the prior on the control is given by
u ∼Cat(u |1/5) for t=1,...,T . (27)
t t
The EFE-minimizing agent uses empirical priors on the control and the states,
given by
u ∼Cat(u |σ( (28a)
t t
H[q(l ,l ,o ,k,d,s |u )]−H[q(l ,o ,k,d,s |u )]+ (28b)
t t−1 t−1 t−1 t t−1 t−1 t−1 t
H[q(s ,s ,l ,o ,k,d|u )]−H[q(s ,l ,o ,k,d|u )]+ (28c)
t t−1 t t−1 t t−1 t t−1 t
H[q(o ,o |u )]−H[q(o |u )])) for t=1,...,T (28d)
t t−1 t t−1 t
(cid:18) (cid:18) (cid:19)(cid:19)
(cid:88)
l ∼Cat l |σ −H[q(y ,o ,s ,k,d,|l )]+H[o ,k,d,s |l ]
t t t,(x,y) t t t t t t
(x,y)
for t=1,...,T (28e)
(cid:18) (cid:18) (cid:19)(cid:19)
(cid:88)
o ∼Cat o |σ −H[q(y ,l ,s ,k,d,|o )]+H[l ,s ,k,d|o ]
t t t,(x,y) t t t t t t
(x,y)
for t=1,...,T (28f)
(cid:18) (cid:18) (cid:19)(cid:19)
(cid:88)
s ∼Cat s |σ −H[q(y ,l ,o ,k,d,|s )]+H[l ,o ,k,d|s ]
t t t,(x,y) t t t t t t
(x,y)
for t=1,...,T (28g)
(cid:18) (cid:18) (cid:19)(cid:19)
(cid:88) (cid:88)
k ∼Cat k|σ −H[q(y ,l ,o ,s ,d,|k)]+H[l ,o ,s ,d|k]
t,(x,y) t t t t t t
t (x,y)
(28h)
(cid:18) (cid:18) (cid:19)(cid:19)
(cid:88) (cid:88)
d∼Cat d|σ −H[q(y ,l ,o ,s ,k,|d)]+H[l ,o ,s ,k|d] .
t,(x,y) t t t t t t
t (x,y)
(28i)
20 W. W. L. Nuijten et al.
D Additional Results for the Stochastic Grid Environment
Experiments
In this section, we will provide further analysis of the results presented in
section 5.2. We will go into more detail on the convergence of the Bethe Free
Energy over different iterations of the variational inference procedure, and we
will elaborate on a trajectory in a specific episode.
D.1 Convergence Analysis
In Figure 5, we plot the Bethe Free Energy over the iterations of the message
passing procedure, along the state of the environment at which the inference
procedure is being called.
As we can see, even though we have not provided a proof of convergence,
in this specific example, the Bethe Free Energy converges to a constant value,
indicating that our inference procedure has converged.
Note that the Bethe Free Energy is an approximation of the true Variational
Free Energy, and can therefore not be used for model comparison [39]. Although
RxInfer minimizes the Bethe Free Energy, this explains the upwards trend in the
Bethe Free Energy curve, and we can only use the Bethe Free Energy as a sanity
check to check convergence of the inference procedure.
InitialState
26
25
24
23
22
0 10 20 30 40 50
Iteration
ygrenEeerFehteB
BetheFreeEnergyProgression
Fig.5: Visualization of the inference results for the stochastic grid environment.
On the left, the initial state of the environment is shown. On the right we show
the Bethe Free Energy curve over the iterations of message passing. Convergence
to a constant value indicates convergence of the inference procedure.
A Message Passing Realization of Expected Free Energy Minimization 21
D.2 Trajectory
Figure 6 provides a frame-by-frame comparison of the trajectories taken by the
EFE-minimizing agent (left) and the KL-control agent (right) in the stochastic
grid environment. This visualization clearly demonstrates the differences in
planning strategies between the two approaches.
(a) EFE-minimizing agent trajectory
(b) KL-control agent trajectory
Fig.6: Comparison of agent trajectories in a stochastic maze environment. Top:
EFE-minimizing agent with epistemic priors. Bottom: KL-control agent without
epistemic priors.
The EFE-minimizing agent immediately chooses the longer but safer path,
moving upward and around the cells with stochastic transitions. This risk-averse
behavior is a direct result of the epistemic priors that penalize uncertainty in
transitions. By frame t = 8, the agent has successfully reached the goal state
without encountering any hazardous transitions.
In contrast, the KL-control agent attempts to optimize for the shortest path,
movingdirectlythroughcellswithstochastictransitions.Thisoptimisticplanning
is characteristic of approaches that don’t account for aleatoric uncertainty. While
thisstrategywouldbeoptimalinadeterministicenvironment,itleadstopotential
failures in this stochastic setting because the agent cannot manipulate its own
luck.
The difference in trajectories directly translates to the performance gap
observed across the 100 trial episodes. The EFE-minimizing agent’s perfect
successrate(100%)comparedtotheKL-controlagent’slowerperformance(21%)
confirmsthetheoreticalpredictionthatincorporatingepistemicuncertaintyleads
to more robust planning in stochastic environments.
22 W. W. L. Nuijten et al.
E Additional Results for the Minigrid Environment
Experiments
E.1 Convergence Analysis
In Figure 8, we perform inference on the initial state of the Minigrid environment
shown in Figure 7. The figure displays the Bethe Free Energy progression during
the inference process, along with the agent’s final beliefs about its current
location, orientation, and the state of the key and door after the last iteration.
We observe that the BFE stabilizes to a constant value, indicating that our
inference procedure successfully converges.
Fig.7: Initial state of the Minigrid environment.
E.2 Trajectory
Figures9and10provideaframe-by-framecomparisonofthetrajectoriestakenby
theEFE-minimizingagentandtheKL-controlagentintheMinigridenvironment.
This visualization clearly demonstrates the differences in planning strategies
between the two approaches, and highlights the shortcomings of the KL-control
approach.
The EFE-minimizing agent is able to solve the task at hand, while the KL-
control agent stays in the corner of the grid facing the wall. As shown in Figure
9, the EFE-minimizing agent reaches the goal state, while the KL-control agent
does not.
The difference in trajectories directly translates to the performance gap ob-
servedacrossthetestepisodes.TheEFE-minimizingagent’ssuperiorperformance
confirmsourtheoreticalpredictionthatincorporatingepistemicuncertaintyleads
to more efficient planning in partially observable environments like Minigrid.
A Message Passing Realization of Expected Free Energy Minimization 23
2200
2100
2000
1900
1800
1700
1600
0 10 20 30 40
Iteration
ygrenEeerFehteB
BetheFreeEnergyProgression CurrentLocationBelief
1
4 (4,1) (4,2) (4,3) (4,4)
0.8
3 (3,1) (3,2) (3,3) (3,4) 0.6
2 (2,1) (2,2) (2,3) (2,4) 0.4
0.2
1 (1,1) (1,2) (1,3) (1,4)
1 2 3 4 0
OrientationBelief Key/DoorStateBelief
1.0 1.0
0.8 0.8
0.6 0.6
0.4 0.4
0.2 0.2
0.0 → ↓ ← ↑ 0.0 Nokey Haskey Dooropen
Fig.8: Visualization of the inference results for the Minigrid environment. Top
left: Bethe Free Energy curve over the iterations of message passing. Top right:
Agent’s belief of its current location after the last iteration. Bottom left: Agent’s
belief of its current orientation after the last iteration. Bottom right: Agent’s
belief of the state of the key and door after the last iteration.
24 W. W. L. Nuijten et al.
t=0 t=1 t=2 t=3 t=4
t=5 t=6 t=7 t=8 t=9
t=10 t=11 t=12 t=13 t=14
t=15 t=16 t=17 t=18 t=19
t=20 t=21 t=22 t=23 t=24
Fig.9: Visualization of the agent’s trajectory in the Minigrid environment using
EFE-based control. The 5×5 grid shows the sequential frames of the agent’s
movement.
A Message Passing Realization of Expected Free Energy Minimization 25
t=0 t=1 t=2 t=3 t=4
t=5 t=6 t=7 t=8 t=9
t=10 t=11 t=12 t=13 t=14
t=15 t=16 t=17 t=18 t=19
t=20 t=21 t=22 t=23 t=24
Fig.10: Visualization of the agent’s trajectory in the Minigrid environment using
KL control. The 5×5 grid shows the sequential frames of the agent’s movement
throughout the episode.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "A Message Passing Realization of Expected Free Energy Minimization"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
