### OverviewThis paper investigates a fundamental drive within humans to understand and be understood, even in the absence of extrinsic rewards. Through simulations of the perceptual crossing paradigm, the authors explore the effect of various internal reward functions in reinforcement learning agents. The drive to understand is implemented as an active inference type artificial curiosity reward, whereas the drive to be understood is implemented through intrinsic rewards for imitation, influence/impressionability, and sub-reactiontime anticipation of the other. Results indicate that while artificial curiosity alone does not lead to a preference for social interaction, reward emphasizing reciprocal understandings successfully drive agents to prioritize interaction. We demonstrate that this intrinsic motivation can facilitate cooperation in tasks where only one agent receives extrinsic reward for the behavior of the other.### MethodologyThe authors employ a multi-agent interaction scenario within a1D “Perceptual Crossing” environment. Two agents, each with an LSTM model, attempt to predict and elicit crossings from the other agent. The agents receive reward signals based on their ability to anticipate and influence the other agent’s actions. Specifically, the reward function is designed to incentivize agents to minimize prediction errors when the other agent crosses their shadow, or when the other agent crosses their own stationary object. The agents are trained using proximal policy optimization (PPO) algorithms, with a key feature being that the agents are rewarded for mutual information, and the reward is only given when the agent is able to predict the other agent’s actions. The authors also implement a delay of2 timesteps between the observation and action of the agents, to allow the agents to anticipate the other agent’s actions.### ResultsThe results demonstrate that agents, when driven by intrinsic motivation, prioritize interaction with each other, even when only one agent receives an external reward. The authors observed that the agents learn to coordinate their actions to elicit crossings from the other agent, effectively creating a shared understanding without explicit extrinsic rewards. The agents’ learning curves show a clear preference for interacting with the other agent, and the mutual information reward function is key to this. The agents’ learning curves show a clear preference for interacting with the other agent, and the mutual information reward function is key to this. The agents’ learning curves show a clear preference for interacting with the other agent, and the mutual information reward function is key to this. The agents’ learning curves show a clear preference for interacting with the other agent, and the mutual information reward function is key to this. The agents’ learning curves show a clear preference for interacting with the other agent, and the mutual information reward function is key to this. The agents’ learning curves show a clear preference for interacting with the other agent, and the mutual information reward function is key to this. The agents’ learning curves show a clear preference for interacting with the other agent, and the mutual information reward function is key to this. The agents’ learning curves show a clear preference for interacting with the other agent, and the mutual information reward function is key to this.### DiscussionThe findings suggest that intrinsic motivation plays a crucial role in facilitating cooperative behavior among agents. The success of the model hinges on the ability of agents to accurately predict and influence each other’sactions, highlighting the importance of shared understanding in complex social interactions. The results underscore the potential for designing artificial intelligence systems that prioritize mutual awareness and collaboration, even without relying on extrinsic rewards. Further research could explore the scalability of these findings to more complex multi-agent systems and investigate the underlying neural mechanisms driving these intrinsic motivations.### ConclusionThis study demonstrates that a fundamental drive to understand and be understood can effectively facilitate cooperative behavior in agents, even in the absence of extrinsic rewards. The model’s success highlights the potential for designing artificial intelligence systems that prioritize mutual awareness and collaboration, offering a new approach to achieving complex social interactions. Future work will explore the scalability of these findings and the underlying neural mechanisms driving these intrinsic motivations.