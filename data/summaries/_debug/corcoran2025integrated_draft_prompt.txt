=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Integrated information and predictive processing theories of consciousness: An adversarial collaborative review
Citation Key: corcoran2025integrated
Authors: Andrew W. Corcoran, Andrew M. Haun, Reinder Dorman

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Abstract: As neuroscientific theories of consciousness continue to proliferate, the need to assess their
similarities and differences – as well as their predictive and explanatory power – becomes
ever more pressing. Recently, a number of structured adversarial collaborations have been
devised to test the competing predictions of several candidate theories of consciousness. In
this review, we compare and contrast three theories being investigated in one such
adversarial collaboration: Integrated Informatio...

Key Terms: adversarial, review, processing, integrated, university, amsterdam, consciousness, collaborative, information, theories

=== FULL PAPER TEXT ===

Integrated information and predictive
processing theories of consciousness:
An adversarial collaborative review
Andrew W. Corcorana,1, Andrew M. Haunb, Reinder Dormanc, Giulio Tononib,
Karl J. Fristond, Cyriel M. A. Pennartzc,e, TWCF: INTREPID Consortium
a Monash Centre for Consciousness and Contemplative Studies, Monash University,
Melbourne, Australia
b Department of Psychiatry, University of Wisconsin, Madison, USA
c Swammerdam Institute for Life Sciences, Center for Neuroscience, University of
Amsterdam, Amsterdam, Netherlands
d Queen Square Institute of Neurology, University College London, London, UK
e Research Priority Program Brain and Cognition, University of Amsterdam, Amsterdam,
Netherlands
ORCID iDs and e-mail addresses
AWC: https://orcid.org/0000-0002-0449-4883; anco@nexs.ku.dk
AMH: https://orcid.org/0000-0001-9458-8957; andrew.haun@wisc.edu
RD: https://orcid.org/0000-0001-9596-7051; r.dorman@uva.nl
GT: https://orcid.org/0000-0002-3892-4087; gtononi@psychiatry.wisc.edu
KJF: https://orcid.org/0000-0001-7984-8909; k.friston@ucl.ac.uk
CMAP: https://orcid.org/0000-0001-8328-1175; c.m.a.pennartz@uva.nl
Corresponding author: Andrew W. Corcoran
1 Present address: Movement & Neuroscience, Department of Nutrition, Exercise and
Sports, Nørre Allé 51, DK-2200 Copenhagen N, Denmark
2
Abstract
As neuroscientific theories of consciousness continue to proliferate, the need to assess their
similarities and differences – as well as their predictive and explanatory power – becomes
ever more pressing. Recently, a number of structured adversarial collaborations have been
devised to test the competing predictions of several candidate theories of consciousness. In
this review, we compare and contrast three theories being investigated in one such
adversarial collaboration: Integrated Information Theory, Neurorepresentationalism, and
Active Inference. We begin by presenting the core claims of each theory, before comparing
them in terms of (1) the phenomena they seek to explain, (2) the sorts of explanations they
avail, and (3) the methodological strategies they endorse. We then consider some of the
inherent challenges of theory testing, and how adversarial collaboration addresses some of
these difficulties. More specifically, we outline the key hypotheses that will be tested in this
adversarial collaboration, and exemplify how contrasting empirical predictions may pertain to
core and auxiliary components of each theory. Finally, we discuss how the data harvested
across disparate experiments (and their replicates) may be formally integrated to provide a
quantitative measure of the evidential support accrued under each theory. We suggest this
approach to theory comparison may afford a useful metric for tracking the amount of
scientific progress being made in consciousness research.
Keywords: Active Inference; adversarial collaboration; consciousness; Integrated
Information Theory; meta-science; Neurorepresentationalism; predictive processing
3
1 Accelerating research on consciousness through
adversarial collaboration
There is perhaps no other field of neuroscience that generates more widespread interest,
disagreement, and controversy than the neuroscience of consciousness. Recent work has
highlighted both the proliferation of theories of consciousness and the remarkable diversity
of their conceptual foundations and explanatory targets (Kuhn, 2024; Mudrik et al., 2025;
Northoff & Lamme, 2020; Seth & Bayne, 2022). Indeed, there are now so many theories of
consciousness that an increasing number of researchers are turning their attention to the
meta-theoretical question of how they might be compared and evaluated (Chis-Ciure et al.,
2024; Del Pin et al., 2021; Doerig et al., 2021; Kirkeby-Hinrup, 2024; Negro et al., 2024;
Signorelli et al., 2021), with a view to advancing the field via the unification, integration, or
elimination of competing candidates (Evers et al., 2024; Storm et al., 2024; Wiese, 2020). It
is in this context that the Templeton World Charity Foundation launched their ‘Accelerating
Research on Consciousness’ (ARC) initiative (https://acceleratingresearch.org), an
ambitious attempt to progress consciousness science by pitting some of its leading theories
directly against one another in a series of structured adversarial collaborations (Melloni et
al., 2021; Reardon, 2019).
Adversarial collaboration is a unique approach to scientific inquiry in which proponents of
competing theories work together to identify genuine points of disagreement that can be
adjudicated by empirical investigation (Kahneman, 2003; Mellers et al., 2001). One or more
experiments are then jointly devised by members of each adversarial party to test the
contrasting predictions of their theories, with a commitment to publish their findings
irrespective of the outcome. While often challenging to implement (Melloni, 2022; Tetlock &
Mitchell, 2009b, 2009a; Vlasceanu et al., 2022), the adversarial model confers several
notable benefits, including (but not limited to): (1) complementing open science practices
with procedures designed to reduce bias and increase validity; (2) incentivising fair but
‘severe’ tests (Mayo, 2018; Popper, 2002) of competing hypotheses; (3) ensuring that
inconvenient findings cannot be easily dismissed due to differences in methodological
predilection (Ceci et al., 2024; Clark et al., 2022; Clark & Tetlock, 2023; Rakow, 2022). Such
advantages may be particularly apt for driving progress in a field such as consciousness
science (Corcoran et al., 2023), where there is widespread disagreement about the way
consciousness should be operationalised and the kinds of data relevant for driving theory
development and critique (Francken et al., 2022; Irvine, 2017; Yaron et al., 2022).
4
The first stage of the adversarial collaborative process calls for participants to work together
to form a clear understanding of one another’s theoretical commitments and disagreements
(Bateman et al., 2005; Cowan et al., 2020; Peters et al., 2025). Indeed, a core tenet of this
paradigm is the capacity to characterise the position of one’s adversary with accuracy and
precision, thereby establishing a firm foundation for the joint development of experiments
that are capable of arbitrating substantive theoretical differences (Clark et al., 2022;
Corcoran et al., 2023). The present ‘adversarial review’ documents the outcome of this
process for the INTREPID Consortium (https://arc-intrepid.com), an adversarial collaboration
funded under the ARC initiative to test competing predictions of the Integrated Information
Theory and two predictive processing theories of consciousness – Neurorepresentationalism
and Active Inference.
In what follows, we present a succinct overview of the three theories at hand, identify notable
points of commonality and disagreement amongst them, and examine how their distinctive
theoretical claims may be translated into hypotheses amenable to empirical investigation.
We further consider how the evidence generated by experimental tests of key hypotheses
may be used to inform (and hopefully progress) theoretical debate about the nature of
consciousness. We hope that this review will provide a useful and instructive resource not
only for those engaged in debates about theories of consciousness (and indeed other topics;
see, e.g., https://gac.ccneuro.org/; https://web.sas.upenn.edu/adcollabproject), but also for
those interested in the broader (meta-theoretical) question of how empirical evidence for
competing theoretical claims can be accrued, integrated, and evaluated over time.
2 Introducing the three theories
In this section, we begin by providing a very brief introduction to the core components of
each of the three theories represented within the INTREPID Consortium, referring to more
in-depth treatments along the way. We then highlight salient similarities and differences
amongst the theories, focusing in particular on (1) the phenomena they seek to explain
(explananda), (2) the sorts of explanation they proffer (explanans), and (3) the
methodological approaches used to develop and validate their claims.
5
2.1 Key tenets of each theory
2.1.1 Integrated Information Theory (IIT)
IIT originates from the hypothesis that conscious systems evince high degrees of functional
integration and differentiation, given the characteristically unified yet complex nature of
subjective experience (Tononi & Edelman, 1998). Since its inauguration more than two
decades ago (Tononi, 2004), IIT has undergone a number of refinements and elaborations
(Albantakis et al., 2023; Balduzzi & Tononi, 2008, 2009; Oizumi et al., 2014; Tononi, 2008,
2012); however, the key idea that consciousness comprises fully-integrated,
uniquely-specified states has remained at its core.
IIT begins by identifying the fundamental properties of consciousness – i.e., “those
[properties] that are immediate and irrefutably true of every conceivable experience”
(Albantakis et al., 2023, p. 2). These are distilled in the following set of ‘axioms’:
0. Existence. Experience exists; it is real.
1. Intrinsicality. Experience exists for itself; it is found from the experiencer’s own
intrinsic perspective (independent of external observers).
2. Information. Experience is the particular way it is; it is specific, not indeterminate or
generic.
3. Integration. Experience is unitary; it cannot be decomposed or reduced into separate
parts without something being lost.
4. Exclusion. Experience is definite; its contents are bounded (a content is either
included or not), and it unfolds at a particular spatiotemporal grain (neither finer nor
coarser).
5. Composition. Experience is structured; it is composed of many interrelated
phenomenological relations and distinctions that determine how it feels.
IIT then proposes a set of ‘postulates’ designed to explain how these phenomenal properties
may be physically realised. Each postulate aims to characterise the specific causal
properties a physical system would need to satisfy in order to support consciousness:
0. Existence. Physical existence is operationalised as cause-effect power; the physical
substrate of consciousness must be able to ‘take and make a difference’.
1. Intrinsicality. The physical substrate of consciousness must have intrinsic
cause-effect power; it must exert causal constraints on itself.
2. Information. The physical substrate of consciousness must specify a particular causal
state (which may be measured in information theoretic terms).
6
3. Integration. The intrinsic causal power of the physical substrate of consciousness
must be irreducible; parts of a partitioned substrate must, together, have less
cause-effect power than the whole.
4. Exclusion. The intrinsic, integrated cause-effect power of the physical substrate of
consciousness must be bounded; the bounds are those of the maximal substrate or
complex (where any super/sub/set has less cause-effect power).
5. Composition. The intrinsic cause-effect power of the physical substrate of
consciousness must be structured as a set of interrelated causal relations and
distinctions; these are the individual mechanisms (groups of system units) that exert
causes and effects within the substrate.
According to IIT, any entity that instantiates the physical properties specified by each of the
postulates is conscious. The subjective quality of its experience depends on the form of the
cause-effect structure or Φ-structure (“phi-structure”) derived from analysis (‘unfolding’) of
the maximal substrate’s composition in a given state. The amount of consciousness
expressed by the system is quantified by summing the integrated information φ (“phi”)
measured from each subset of units within the maximally irreducible cause-effect structure to
calculate Φ (“structure-phi” or “big-phi”), which corresponds to the amount of structure
integrated information. In this way, IIT provides a formal account of both the quality and the
quantity of conscious experience (for technical details, see Albantakis et al., 2023).
Applied to the paradigmatic case of wakefulness in healthy human adults, IIT identifies
temporal, parietal, and occipital regions of cerebral cortex – the so-called posterior ‘hot zone’
– as possessing the requisite organisational structure to instantiate consciousness in the
brain (i.e., for generating a maximum of irreducible, intrinsic cause-effect power; Tononi et
al., 2016). The initial findings of another ARC adversarial collaboration comparing IIT against
global neuronal workspace theory (Dehaene et al., 1998; Dehaene & Changeux, 2011;
Dehaene & Naccache, 2001; Mashour et al., 2020) have been evaluated with respect to this
claim (Cogitate Consortium et al., 2025; for discussion, see Negro, 2024), adding to
pre-existing evidence from the clinical and neuroimaging literature (Boly et al., 2017; Koch et
al., 2016; Storm et al., 2017; cf. Odegaard et al., 2017). The INTREPID Consortium aims to
go one step further by testing the hypothesis that regions of this substrate specify the
requisite cause-effect structure to explain both the quantity and quality of spatial experience
(discussed in Sections 3.2 and 3.3).
7
2.1.2 Neurorepresentationalism (NREP)
NREP provides a predictive processing inspired account of the way conscious experience
arises from hierarchically-organised neural computations in the brain (Pennartz, 2015,
2022). Although the predictive processing framework offers a generic approach for
understanding adaptive systems regardless of their conscious state (see, e.g., Clark, 2013,
2016; Friston, 2010; Hohwy, 2013, 2020; Piekarski, 2021), much work under the rubric of
predictive processing is founded on predictive coding models of visual perception (Bastos et
al., 2012; Bogacz, 2017; Lee & Mumford, 2003; Rao & Ballard, 1999; Srinivasan et al.,
1982). NREP seeks to combine the fundamental principles enshrined in such models
(namely, that the brain engages in a process of prediction error minimisation to infer the
causes of sensory states) with insights drawn from philosophical analysis and neuroscientific
data to elaborate a distinctive theory of consciousness.
NREP is rooted in the philosophical stance of ‘representationalism’, which aims to reconcile
the subjective experience of elementary phenomenal properties (so-called ‘qualia’; e.g., the
redness of a tomato) with its material substrate – the brain (Pennartz, 2015, ch. 11). Qualia –
and perceived properties in general – traditionally pose a problem for many materialist
theories of mind insofar as these theories struggle to account for the physical location of
such properties. For example, when we experience an illusion such as Kitaoka’s rotating
snakes (see Murakami et al., 2006), it would be incorrect to state that the apparent rotational
movement of snake-like shapes is physically happening in front of us. But it is equally
incorrect to say that rotating snakes are literally present inside our brain (which consists of
neurons, glial cells, blood vessels, etc.). So where is the quality of rotational motion to be
found? Representationalism solves this problem by regarding perceived qualities as
components of representations, which can be veridical or non-veridical (Lycan, 2023;
Pennartz, 2018). The perceived rotation is therefore a represented property of the
represented object – a property which in this case is illusory. The consequence of this
account is that all of our conscious experiences are ‘best-guess’ reconstructions of the
causes of sensory (or imagined) input – a notion going back to Kant (1787) and Von
Helmholtz (1962).
Similar to IIT, NREP deploys reflective analysis to identify the ‘inalienable features’
distinguishing conscious experience from nonconscious processing in healthy human adults
(Pennartz, 2015, ch. 8). These ‘hallmarks’ of consciousness – which differ from IIT’s axioms
– are summarised as follows (Pennartz, 2022; Pennartz et al., 2019):
8
1. Multimodal richness. Conscious experience consists of distinctive sensory qualities
derived from multiple modalities (e.g., vision, audition) and submodalities (e.g.,
colour, motion).
2. Situatedness and immersion. Conscious agents find themselves situated in a space
that is organised with certain objects in the foreground and others in the background
(context). One’s body is experienced as immersed in the situation, occupying a
central position relative to surroundings.
3. Unity and integration. Consciousness is characteristically unified such that the
contents of experience form part of a singular, integrated whole (however, this does
not imply that there is only one mechanism underlying integration).
4. Dynamics and stability. Static objects are experienced as stable elements in relation
to moving objects and other changing inputs from the environment; both static and
dynamic objects are distinguished from sensory changes brought about by bodily
self-motion.
5. Intentionality. Conscious experience is about objects that differ from the neural
substrates which instantiate them. Neural activity patterns lie at the basis of
conscious experience; however, this experience is not about these activity patterns
as such, but about the objects and situations the subject is aware of. These patterns
are localised at different positions in space than where the neurons involved in the
representation are located in the brain.
NREP interprets consciousness as furnishing the subject of experience with a unified,
dynamic, multimodal ‘survey’ (or ‘world-model’) of unfolding bodily and environmental
conditions (Pennartz, 2015, ch. 6). This inferential summary of the agent’s current situation
is argued to confer adaptive benefits, insofar as it underpins the ability to deliberate about
and engage in goal-directed behaviour (Pennartz, 2018, 2022). Consciousness as conceived
under NREP thus functions to inform on-the-fly, self-initiated decision-making and planned
action (as opposed to reflexive or habitual modes of behaviour), but does not involve motor
action per se (although it does involve ‘activity’ in the broader sense of generating top-down
expectations, imagery, predictions of future sensory input, etc.). NREP thus acknowledges
the importance of motor activity in shaping conscious experience, but does not consider
such activity necessary for consciousness itself.
Some further qualifications of NREP need to be mentioned, as they clarify how NREP
distinguishes itself from other theories of consciousness. To realise qualitative richness in
conscious experience, NREP posits that interactions between unimodal and multimodal
corticothalamic systems are required, both to segregate and integrate modalities (Pennartz,
9
2009). This integration takes place across multiple levels of representation, beginning with
low-level predictions and errors concerning simple features (such as small, oriented edges in
the visual field; i.e., local visual details), ascending to unimodal object representations (e.g.,
within the visual domain, but comprising different attributes such as colour, shape, texture,
etc.), to finally reach a stage of very large, multimodal networks of networks (meta-networks)
that perform a ‘superinference’ across multimodal inputs specified in space (Olcese et al.,
2018; Pennartz, 2022). In this account, many forms of integration are posited to contribute to
consciousness, including binding, grouping, binocular integration, scene synthesis by
integrating across eye and head movements, and multisensory integration. For example,
space perception critically hinges on the integration of retinotopic information with vestibular,
proprioceptive, and other sensorimotor sources (e.g., efference copy), explaining how visual
space perception transcends the level of retinotopic representation and thus realises
craniotopic and allocentric aspects of perception (Pennartz, 2015, 2022, 2024).
2.1.3 Active Inference
Unlike IIT and NREP – which were both explicitly developed as scientific theories of
consciousness – Active Inference explains the emergence of adaptive behaviour from ‘first
principles’ (Parr et al., 2022). While this more general framework can be applied to
conscious and nonconscious systems alike (Hohwy, 2022), an increasing number of
researchers are drawing on its conceptual and methodological resources to explain various
aspects of consciousness (e.g., Clark, 2019; Deane, 2021; Ramstead, Albarracin, et al.,
2023; Rudrauf et al., 2017; Sandved-Smith et al., 2021; Seth & Tsakiris, 2018; Solms, 2019;
Wiese, 2024; Williford et al., 2018; for helpful overviews, see Nikolova et al., 2022; Rorot,
2021; Vilas et al., 2022). We focus here on what has recently been dubbed ‘the minimal
theory of consciousness implicit in active inference’ (Whyte et al., 2024), which is primarily
concerned with the claim that active inference is necessary for a change in conscious
content. We shall use the acronym AI-C to distinguish this narrower theoretical account from
the broader (meta-theoretic) scope of the Active Inference framework at large.
Active Inference provides a normative account of sentient, self-organising behaviour (Friston
et al., 2020; Parr et al., 2022; Sajid et al., 2021), where ‘sentience’ here is understood in
terms of (approximately Bayes-optimal) belief-updating and decision-making (Friston, Da
Costa, Sakthivadivel, et al., 2023; Friston et al., 2025). This perspective is inspired by the
free energy principle (Friston, 2010; Friston, Da Costa, Sajid, et al., 2023), which provides a
formalism for describing self-organisation – i.e., the emergence of adaptive agency – in
random dynamical systems. Under this formalism, the internal states of the agent
10
parameterise probabilistic beliefs about the external dynamics causing its sensory inputs
under a generative or world model (Da Costa et al., 2021; Friston et al., 2020; Ramstead,
Sakthivadivel, et al., 2023). Sentient behaviour on this view is characterised by the agent’s
capacity to model the expected consequences of its actions, thus enabling it to select the
(approximately) Bayes-optimal course of action for a particular context (given the agent’s
prior preferences and beliefs; Friston et al., 2025; Pezzulo et al., 2024). Mathematically,
these inferential processes are underwritten by the minimisation of two objective functions:
(1) variational free energy, which scores the degree of belief updating compelled by the
observation of sensory data, and (2) expected free energy, which scores the probability of
alternative courses of action (i.e., policies) based on the sensory observations those actions
are expected to elicit.
In terms of computational and functional (biophysical) architectures – and attendant
information theoretic characterisations – the free energy principle is compatible with most
global brain theories, ranging from global neuronal workspace theories through to
hierarchical predictive coding that is also used in NREP (e.g., Friston, Da Costa,
Sakthivadivel, et al., 2023; Friston et al., 2012; Friston & Kiebel, 2009). However, the free
energy principle – in and of itself – makes no claims about subjective experience.
Since the optimisation of variational and expected free energy is not claimed to be a specific
feature or signature of subjective awareness, any theory of consciousness based on the
Active Inference framework needs to explain how these two objective functions relate to
conscious experience. Early work identified probabilistic beliefs encoded by the approximate
posterior over hidden states as the best candidate for explaining conscious content (Hohwy,
2012; Hohwy et al., 2008), with the important caveat that only a privileged subset of posterior
beliefs – namely, those spanning spatiotemporal scales relevant for embodied interaction
with the world – contribute to conscious experience (Marchi & Hohwy, 2022; see also Clark,
2018). This proposal meshes well with the independently developed idea that subjective
awareness is grounded in the ‘temporal thickness’ (or ‘counterfactual depth’) of the agent’s
generative model, which confers the capacity to select actions based on the inferred
consequences of various possible choices (Friston, 2018; see also Clark et al., 2019;
Corcoran et al., 2020; Friston et al., 2020, 2021; Hohwy, 2022).
After reviewing a variety of Active Inference models simulating the manipulation of conscious
states and contents in synthetic agents, Whyte and colleagues (2024) proposed a minimal
theory of consciousness (AI-C) reiterating the conceptual linkage between subjective
experience and posterior beliefs about hidden states. On this account, all changes in
11
conscious content – including the transition from unconscious to conscious experience and
vice versa – must be driven by a change in the inferred state of the world (where ‘world’ here
includes states within the brain and body, as well as the external environment). Moreover,
AI-C identifies the interface between continuous (sensorimotor) and discrete
(decision-making) levels of the processing hierarchy as the locus at which posterior beliefs
become conscious, in line with previous work explaining conscious experience in terms of
perceptual state inferences that function to inform policy selection (Hohwy, 2013; Marchi &
Hohwy, 2022; Whyte, 2019). The upshot of this view is the claim that active inference is
necessary (but may not be sufficient) for a change in conscious content (i.e., changes in
consciousness must be accompanied by changes in posterior beliefs, but changes in
posterior beliefs might occur without changes in awareness – e.g., belief-updates occurring
at spatiotemporal scales too fast or slow to guide policy selection).
It is important to be clear that AI-C associates changes in consciousness with the
deployment of a certain kind of inferential machinery to actively sample (or ‘probe’; see
Dołęga & Dewhurst, 2021) the sensorium – not the execution of an action per se. Under the
Active Inference framework, actions are hidden states that must be inferred by the agent,
and which are enacted as a consequence of some inferential process (e.g., the optimisation
of expected free energy in the service of policy selection; cf. ‘planning-as-inference’; Attias,
2003; Botvinick & Toussaint, 2012). It is also important to note that actions are conceived
here rather generically, in a way that extends beyond the domain of motor control or
voluntary behaviour. For instance, actions may pertain to cellular self-organisation,
autonomic reflex arcs, covert attentional dynamics, or overt behaviours such as saccadic
eye movements and subjective reports. What’s common across these diverse phenomena is
that they can all be understood as having been selected in accordance with beliefs about
their sensory consequences, with a view to realising sensory states that ultimately minimise
free energy. This means that AI-C can entertain changes in conscious experience that are
driven by belief updates in the absence of overt movement – as in the case of changes in
subjective awareness that are covertly entrained via the selection of attentional policies (i.e.,
‘mental actions’; Limanowski & Friston, 2018; Parr, Corcoran, et al., 2019).
2.2 Similarities and differences
Having briefly outlined the key claims of IIT, NREP, and AI-C, the remainder of this section
presents a focussed comparison of their similarities and differences. We organise our
discussion around three interrelated themes: (1) targets of explanation (explananda); (2)
kinds of explanation (explanans); and (3) methodological strategies.
12
2.2.1 Explananda: What do these theories attempt to explain?
Consciousness researchers disagree about the relevant phenomena any comprehensive
theory of consciousness ought to explain (Francken et al., 2022; Seth & Bayne, 2022) – a
situation Vilas and colleagues (2022) dub the ‘explanandum problem’. This lack of
consensus is perhaps somewhat surprising given our own intimate acquaintance with
conscious experience (Chalmers, 1996; Wiese, 2018), but likely a product of vastly divergent
intuitions about which features of mental life should be included within a scientific conception
of consciousness (and how they ought to be operationalised for scientific investigation;
Irvine, 2017; Phillips, 2018). In light of such diversity, it is important to be clear about the way
consciousness is conceptualised under competing theories in order to disambiguate whether
such theories make distinctive claims about the same target phenomenon, or whether they
offer explanations targeting distinctive phenomena. While the latter case might be construed
as a theoretical dispute about the fundamental nature of consciousness and the proper
explananda that any scientific theory of consciousness science ought to target, such
apparent disagreements might ultimately be resolved through subsumption under a broader,
unifying theory of consciousness (Storm et al., 2024).
As discussed in Section 2.1, IIT, NREP, and AI-C all make explicit statements about their
explanatory targets. IIT’s axioms aim to provide an exhaustive list of the essential properties
of consciousness, understood as the feeling of ‘what it is like’ to have an experience (Nagel,
1974). NREP’s hallmarks function in a similar fashion, aiming to capture the universal
features of healthy human conscious experience. Again, the main explanatory target here is
the qualitative character of perceptual experience, with an emphasis on its situatedness and
multimodal richness (Lee & Pennartz, 2025; Pennartz et al., 2019). While AI-C does not
currently distinguish certain properties as essential or fundamental elements of
consciousness, its focus on the content of awareness suggests a similar concern with the
phenomenal quality of experience. All three theories are thus broadly in agreement that a
scientific theory of consciousness should account for the qualitative properties of experience
– what is often referred to as ‘phenomenal consciousness’ (Block, 1995, 2011).
Beyond phenomenal consciousness, Active Inference has previously been deployed to
model features of ‘access consciousness’ (Whyte et al., 2022; Whyte & Smith, 2021) – those
elements in awareness that can be reported, thought about, and used to guide behaviour
(Block, 1995, 2011). Indeed, AI-C might prove particularly well-suited for characterising
aspects of access consciousness, given the emphasis it places on such executive processes
as attentional regulation, decision-making, and action planning. This may explain the
13
historical affinity between Active Inference based accounts of consciousness and Global
Workspace Theory (Hohwy, 2013; Whyte, 2019), which identifies access consciousness as
the primary (and perhaps exclusive) explanandum for the science of consciousness (Cohen
& Dennett, 2011; Dehaene et al., 2006; Naccache, 2018). In contrast, IIT and NREP both
associate access consciousness with cognitive and motor functions that operate on
phenomenally conscious content (rather than being constitutive of consciousness per se;
Ellia et al., 2021; Pennartz, 2015). This highlights a difference between IIT and NREP on the
one hand as theories that determine their explananda on pre-theoretical grounds (i.e.,
through reflective analysis of the essential features of conscious experience), versus AI-C on
the other as a theory that targets those phenomena that are paradigmatically studied in
consciousness science at large (see Section 2.2.3).
Leaving the distinction between access and phenomenal consciousness aside, one can also
ask how each of the three theories considered here relates to states of consciousness
(Chalmers, 1996; Seth & Bayne, 2022). From its inception, IIT has sought to address both
the quantity and quality of experience (Tononi, 2004, 2008) – thus aiming to provide a
comprehensive account of both the global and local properties of conscious states. On this
view, global states (e.g., wakefulness, dreaming, coma) are interpreted as ‘levels’ along a
unidimensional scale corresponding to Φ, where any system with Φ > 0 is conscious to
some degree (note that calculation of Φ is not feasible beyond very simple networks,
although a variety of proxy measures have been proposed; Mediano et al., 2019, 2022).
NREP and AI-C are not committed to the view that global states can be straightforwardly
ordered along a single scale as implied by IIT (cf. Bayne et al., 2016). Insofar as NREP
takes consciousness to subserve goal-directed behaviour, it focuses in the first instance on
explaining the neural underpinnings of perceptual content experienced in the context of
wakefulness (since these are the states most relevant for prospection and goal-directed
behaviour, which NREP construes as the targets subserved by consciousness). However,
NREP also aims to account for other forms of conscious experience that are less dependent
on external sensory processing, as in dream states and mental imagery (Pennartz et al.,
2019). For instance, dreaming is conceived of as a ‘virtual reality’ state characterised by
being less susceptible to cognitive control and less strongly coupled to output systems for
goal-directed behaviour (Pennartz, 2015). It is not however considered to be a ‘lower’ state
of consciousness than wakefulness, but rather to constitute a different mode. Nonetheless,
NREP recognizes that consciousness can be graded along several dimensions – intensity,
spatiotemporal resolution, and multimodal richness.
14
Although AI-C is principally concerned with local states insofar as it aims to account for
changes in the content of experience, its scope could conceivably be broadened to capture
different sorts of global states. Indeed, the transition from an unconscious to a conscious
state may be construed as a change from a state with no content to one with some content
(Whyte et al., 2024). Whyte and colleagues (2024) extend a previously reported hierarchical
model of auditory processing (Smith et al., 2022) to capture differences in evoked neural
responses to local and global regularities which have been empirically documented across
sleep and wake states. This model suggests that the loss of consciousness in deep sleep is
driven by the disconnection of hierarchical levels within the generative model, resulting in a
breakdown of message-passing that precludes belief-updating within temporally-deep levels.
This example illustrates how existing Active Inference models of sensory processing might
be elaborated to account for differences in the phenomenology and neural dynamics
associated with various global states of consciousness.
2.2.2 Explanans: How do these theories explain consciousness?
Having established the relevant explananda of IIT, NREP, and AI-C, we turn now to their
respective explanans – the kinds of explanation each theory proffers for their explanatory
targets. Again, we caution that differences in theoretical explanations of common
explananda may not necessarily entail a fundamental disagreement – one theory’s
explanans may be compatible with (or even equivalent to) another’s. This being said, one
explanatory approach may still be preferred over another, equally viable explanation for a
variety of reasons (e.g., theoretical virtues such as simplicity, fecundity, unification, etc.;
Kuhn, 1977; Quine, 1955). We focus here on the kinds of explanation availed by each
theory, deferring treatment of their implications for empirical testing to Section 3.
IIT proposes an explanatory identity between conscious experience and the cause-effect
structure ‘unfolded’ from its physical substrate (Albantakis et al., 2023; for discussion, see
Cea et al., 2023). This implies an isomorphic mapping between the phenomenal features of
a given experience and the causal configuration of the physical substrate instantiating it –
that is, the subjective quality of experience is fully explained by the cause-effect powers
observed in the conscious system. IIT thus renders explanations of conscious phenomena
expressed in terms of the causal relations embedded within their substrates. An important
implication of this approach is its rejection of functionalism: two systems may have
equivalent (or practically indistinguishable) input-output functions (i.e., respond to identical
stimuli in the same way), yet the degree and quality of conscious experience may differ
dramatically between systems depending on the cause-effect powers realised by their
15
architectures (Albantakis et al., 2023; Grasso et al., 2021; Oizumi et al., 2014). For this
reason, IIT does not regard functional (or behavioural) properties as reliable indicators or
satisfying explanations of consciousness (Ellia et al., 2021; Tononi & Koch, 2015; cf. Cohen
& Dennett, 2011).
In contrast to IIT’s focus on intrinsic causal structure, NREP and AI-C ground their
explanations of consciousness in information processing architectures that support
inferences (i.e., probabilistic beliefs) about external states of affairs. NREP claims conscious
experience is the product of ‘superinference’ on the causes of sensory input in which all
levels of the multimodal processing hierarchy participate (Pennartz, 2015, ch. 10, 2018,
2022). Although NREP subscribes to the predictive processing framework, it is not wedded
to any specific process-theoretic description of the computational architecture underpinning
such inferences (see, e.g., Brucklacher, Lee, et al., 2025; Salvatori et al., 2021; Spratling,
2017; Sprevak & Smith, 2023). NREP has provided computational network models based on
sensory cortical hierarchies, which illustrate several integrative processes operating at the
level of specific image representation, view-invariant object representation, figure-ground
segmentation during ego- and object-motion, and predictive cross-modal interactions
(Brucklacher et al., 2023; Brucklacher, Pezzulo, et al., 2025; Dora et al., 2021; Pearson et
al., 2021). These models provide mechanistic explanations of the low-to-medium levels of
representation (i.e., of single features and unimodal objects); however, NREP abstains from
attempting to precisely equate or map computational models to phenomenology, since this
transition from quantitative to qualitative properties is deemed unimaginable (Lee &
Pennartz, 2025; Pennartz, 2015).
AI-C can similarly be described as presenting a predictive processing account of conscious
experience; however, unlike NREP, it is specifically committed to the process theory
developed under the free energy principle (Friston et al., 2017; Parr et al., 2022) – with the
caveat that the precise implementational details described at the process theory level are
themselves subject to development (e.g., there are multiple message passing schemes
consistent with the free energy principle that could be used to implement an Active Inference
model; Parr, Markovic, et al., 2019). While AI-C proposes that the inferential (Bayesian)
mechanics underpinning changes in conscious contents must conform to the free energy
principle – and thus adduces the optimisation of free energy functionals as its primary
explanans – NREP emphasises the more classic and specific concept of prediction error
minimization (cf. Rao & Ballard, 1999). Instead, NREP posits that basic predictive coding
models take care of low-level computational operations, but do not present the appropriate
descriptors for phenomenology playing out at the highest representational levels.
16
The crucial role of policy selection in AI-C highlights a distinctive explanatory construct that
is absent from both IIT and NREP (and that is the focus of one set of experiments being
conducted by the INTREPID Consortium; see Section 3.4). As mentioned in Section 2.1.3,
active inference pertains to the optimisation of beliefs about precisions and policies; there is
no requirement for overt movement to be initiated in order for changes in awareness to occur
(consonant with IIT and NREP, both of which dissociate overt action from conscious
experience). However, the notion of mental action – in which covert attentional policies are
selected in a way analogous to those driving overt behaviour (Limanowski & Friston, 2018;
Parr, Corcoran, et al., 2019) – highlights the fundamental explanatory role of such executive
processes as attentional regulation (i.e., precision-optimisation) and decision-making (i.e.,
planning-as-inference) in AI-C. This formulation is reminiscent of certain action-oriented or
enactive approaches to consciousness, such as sensorimotor contingency theory (O’Regan,
2011; O’Regan & Noë, 2001; see also Seth, 2014). Arguably, AI-C benefits from a formalised
approach that grounds the “everyday-language” explanations afforded by sensorimotor
theory (O’Regan, 2023, p. 2) – e.g., the notion of being “poised” to act in a particular way
(O’Regan, 2022, p. 3) – in a computationally tractable account that speaks to underlying
neural dynamics (see Nave et al., 2022). In short, NREP considers representation sufficient
for ‘seeing’, while AI-C posits that representation is necessary but not sufficient, in the
enactivist sense that ‘to see is to look’ (overtly or covertly).
2.2.3 Methodology: How are these theories constructed and validated?
Finally, we consider the methodological approaches adopted to develop and validate each of
the theories addressed in this review. We briefly outline both the strategies used to construct
or derive core elements of each theory, and how these strategies guide the empirical
investigation of consciousness under each theoretical perspective.
IIT distinguishes itself from most other neuroscientific theories by adopting a
‘phenomenology-first’ approach that seeks to characterise the intrinsic structure of
consciousness (Ellia et al., 2021; Negro, 2020; Oizumi et al., 2014). Beginning with
introspection and reasoning, the essential, invariant properties of subjective experience are
derived to form the axiomatic foundations of the theory. These phenomenological properties
are then operationalised in terms of physical (causal) properties (i.e., postulates) that are
amenable to formal analysis (e.g., by quantifying the amount of integrated information
expressed by a causal network) and empirical investigation (e.g., by searching for neural
substrates capable of supporting particular cause-effect powers). The operationalisation of
axioms into their corresponding postulates is based on an ‘inference to a good explanation’
17
under the assumption there exists an observer-independent reality comprising reliable
causal relations that can be analysed in terms of their smallest constituents (Albantakis et
al., 2023; Chis-Ciure, 2022; Tononi et al., 2022; cf. Cea et al., 2023).
The mathematical framework provided by IIT enables one to quantify and evaluate the
various properties specified by the postulates for a candidate system, culminating in a formal
description of the qualitative structure of experience under a given state. In order to validate
this formalism, one may compare the kind of structure it prescribes for certain kinds of
conscious experience with the physical organisation of neural structures involved in
supporting such experience. For example, an IIT-based analysis of spatial extendedness
suggests a grid-like substrate would be required to instantiate this kind of experience, which
is consistent with the structure of posterior cortical regions implicated in visual processing
(Grasso et al., 2021; Haun & Tononi, 2019). This observation leads to the hypothesis that
perturbations of this grid-like neural structure should distort the phenomenal quality of visual
space in a predictable manner (Haun & Tononi, 2019; Tononi et al., 2016; see Section 3.3).
Analysis of the sort of structure instantiated by the cerebellum, on the other hand, is argued
to confirm its poor suitability for supporting consciousness (due to low levels of neural
integration; Tononi, 2008; Tononi et al., 2016). Once this formalism has been sufficiently
validated across various states of consciousness in healthy human adults, it may then be
extended to characterise the quality and quantity of experience in more challenging cases
(e.g., infants, unresponsive patients, non-human systems; Tononi & Koch, 2015).
Although NREP does not explicitly specify a single favoured strategy for theory development
and validation, it blends aspects of the philosophical stance of representationalism with
empirical and computational methods from neuroscience and robotics. NREP-inspired
research aims to complement the search for neural correlates of consciousness (Crick &
Koch, 1990, 2003) by investigating the impact of causal (e.g., optogenetic) manipulations of
neural substrates, and by developing predictive coding-inspired computational models
capturing the network dynamics hypothesised to underpin representational processes.
Following this strategy, researchers have demonstrated, for instance, the neurobiological
plausibility of predictive processing-based representational models in spiking neural
networks (Lee et al., 2024), and reproduced the increase in population sparsity and
single-neuron image selectivity observed when ascending the visual cortical hierarchy (Dora
et al., 2021).
Notably, NREP’s primary objective is to characterise the neural basis of representations
pertaining to externally- and internally-driven modes of experience as instantiated in healthy
18
human adults (Pennartz, 2018, 2022). While this objective may appear to hinder the
potential expansion of NREP’s explanatory scope to include other animal species and
artificial agents, this need not be the case. Indeed, it may be possible to abstract the
computational architecture underpinning human consciousness away from its neural
implementation and apply these insights in other domains (see, e.g., Pennartz, 2015, ch. 11;
Pennartz et al., 2019). For instance, the effectiveness of multisensory integration in
predictive coding driving place recognition in mobile rodent-like robots (Pearson et al., 2021)
exemplifies how this approach may help to define so-called ‘indicators of consciousness’ in
artificial agents (Lee & Pennartz, 2025; Pennartz et al., 2019).
In contrast to IIT’s ‘phenomenology-first’ approach and NREP’s unique blend of
philosophical, empirical, and computational analysis, AI-C might be characterised as
adopting a ‘model-first’ approach whereby core elements of AI-C are derived from the
interrogation of process-theoretic models. This approach is inspired by Hohwy and Seth’s
(2020) proposal to deploy insights from predictive processing in the service of
consciousness research and theory development. The key idea here is to exploit the
resources availed by a domain-general modelling framework such as Active Inference to
construct computational models of paradigmatic phenomena in consciousness science (e.g.,
binocular rivalry; Doerig et al., 2021), and to compare the properties of these models such
that salient commonalities and particularities may be identified (Vilas et al., 2022; Whyte et
al., 2024). Given a sufficiently diverse set of models, the hope is that systematic examination
of their properties will eventually yield meaningful insights into the computational differences
between conscious and unconscious states, and the content of those states (one might
conceive of this endeavour as a search for ‘computational correlates of consciousness’;
Cleeremans, 2005; Wiese & Friston, 2021).
A distinctive feature of the model-first approach used to develop AI-C is that it may help to
minimise the potential influence of background assumptions that constrain both the
phenomena targeted for explanation and the kinds of observation deemed relevant for
theory development and evaluation (cf. Yaron et al., 2022). Rather, a wide variety of
empirical phenomena and methodological paradigms can be exploited in pursuit of the
computational properties of consciousness, independent of prior beliefs or assumptions
about the nature of consciousness itself (as derived, e.g., via introspective reflection). While
it is currently unclear how well this strategy will perform when applied to more challenging or
controversial cases (e.g., artificial systems), the delineation of common computational
properties across a range of paradigmatic cases may provide a useful starting point for
inferring the existence and contents of conscious states within such systems.
19
3 From theoretical constructs to empirical
predictions
Having sketched out the key tenets of IIT, NREP, and AI-C – as well as some notable
similarities and differences between them – we turn next to the topic of their empirical
validation. The overarching premise of the Accelerating Research on Consciousness (ARC)
initiative is that theoretical disagreements about the nature of consciousness may be settled
by devising and implementing experiments that test distinctive hypotheses derived from
each theory (Melloni et al., 2021; Reardon, 2019). Inspired by the historical example of Sir
Arthur Eddington’s seminal experimentum crucis – in which competing predictions of
Newtonian mechanics and general relativity were pitted against one another on the occasion
of the 1919 solar eclipse (Dyson et al., 1920) – such experiments are designed to generate
data that will corroborate the predictions of one theory while simultaneously disconfirming
those of its competitors (Del Pin et al., 2021; Negro, 2024). Although the findings of a few
experiments are seldom sufficient to definitively refute an entire theory – perhaps no bad
thing considering the relative immaturity of consciousness science (Evers et al., 2024; Negro
et al., 2024; Wiese, 2018) – such data are expected to inform the debate (and future
research) by clarifying which theory enjoys the most empirical support (Corcoran et al.,
2023).
In this section, we begin by considering some of the important steps and challenges that
complicate attempts to test scientific theories, and the role of adversarial collaboration in
addressing (or at least mitigating) some of these issues. We then turn our attention to three
key hypotheses that will be investigated by the INTREPID Consortium. Our goal here is to
succinctly outline the theoretical motivation for each hypothesis and to anticipate the
potential implications of alternative empirical outcomes for each theory.
3.1 Bridging the gap between theory and observation
Before sketching out the distinctive hypotheses that will be tested by the INTREPID
Consortium, it is important to consider the inherent challenges posed by theory testing in
general – as well as those confronting neuroscientific theories of consciousness in particular.
On the first point, we note that theories generally consist of a set of more-or-less formalised
propositions that are not themselves amenable to direct empirical validation (e.g., the axioms
and postulates of IIT; conformity to the free energy principle). Rather, a number of additional
concepts and assumptions must be invoked to bridge the gap between the theoretical and
20
empirical realms (e.g., to compute the integrated information of a network of units; to
describe how predictive processing mechanisms are implemented in the brain). This
generally involves translating a set of theoretical propositions or principles into a formal
process theory that in turn generates predictions about target phenomena that may be
subjected to empirical validation (Devezer & Buzbas, 2023; for a philosophical overview, see
Vorms, 2018). If predictions are borne out by the data, this lends support to the theory from
which they were derived (at least to the extent the process theory embodies the relevant
theoretical constructs; see Negro et al., 2024). However, if predictions fail to adequately
capture the data, it is unclear whether the fault lies within the core of the theory itself, or
within the additional set of auxiliary hypotheses and background beliefs that were enlisted in
order to render the theory empirically tractable (Duhem, 1954; Quine, 1951). Such ambiguity
enables the resourceful theoretician to preserve their core theoretical commitments at the
expense of peripheral factors which can be cheaply sacrificed in the face of challenging data
(e.g., changing the mathematical formalism used to calculate integrated information;
updating the message passing scheme used to implement predictive coding or active
inference) – hence why such auxiliary components are sometimes said to form a ‘protective
belt’ around the core elements of one’s theory (Lakatos, 1976).
Given the nascent state of consciousness science – and the scientifically unusual situation
of seeking reliable empirical data about the quality of subjective experience – the gap
between theory and observation is often considerable. Theories of consciousness are in
general not formalised to the degree that predictions about target phenomena can be simply
and straightforwardly derived (i.e., in the way that Newtonian mechanics and general
relativity both entail precise predictions about the degree of gravitational lensing that ought
to be observed during a solar eclipse). The implications of a theory of consciousness for
specific phenomena may be ambiguous or underdetermined (see, e.g., Bayne, 2018).
Moreover, as discussed in Section 2.2, there is little consensus about the phenomena that
ought to be targeted for explanation by scientific theories of consciousness – or the
methodological procedures that ought to be deployed to study them (see also Mudrik et al.,
2025). This is akin to followers of Newton and Einstein disagreeing about the relevance of
light’s apparent deflection around celestial objects for explanations of gravity, or disputing
whether telescopes are an appropriate instrument for measuring the degree of gravitational
lensing caused by the sun.
Adversarial collaboration does not eliminate such fundamental difficulties. It does however
provide a mechanism for ensuring that the data to be collected in a planned study are
agreed to be informative for the dispute at hand, meaning its results will need to be taken
21
seriously by adherents of competing theoretical perspectives irrespective of the outcome.
This does not mean that co-designed experiments should be expected to definitively
arbitrate amongst rival views; one paradigm might prove more critical for one particular
theory, insofar as it tests predictions that lie closer to its core set of principles and
propositions than another’s (Negro, 2024). Neither does it prevent theoreticians from
ascribing unanticipated or unfavourable outcomes to faults within their auxiliary hypotheses
or background assumptions (rather than their theory’s core) – indeed, this is perfectly
rational behaviour which may precipitate important theoretical developments and empirical
discoveries (Chalmers, 2013; Corcoran et al., 2023; Lakatos, 1976). But collaborators should
agree from the outset that the questions to be addressed by their co-designed experiments
are capable in principle of generating the sort of data needed to progress the debate, and
that the methods used to obtain and analyse such data are sufficiently rigorous and reliable
to obviate facile dismissal.
These considerations led the INTREPID Consortium to develop a multi-experiment project
designed to jointly test unique combinations of predictions elicited from each of the three
theories under examination. In this approach, no single experiment is decisive for arbitrating
disagreements amongst proponents of IIT, NREP, and AI-C. However, certain experiments
are more heavily weighted towards testing a key prediction of one theory versus its
competitors; hence, when aggregated together, the outcome of these experiments will
indicate the relative performance of each theory across a variety of settings. In the
remainder of this section, we adumbrate the key hypotheses to be tested in this project, and
briefly illustrate how they may be related to core and auxiliary components of each theory.
For more detailed exposition of the full range of predictions, paradigms, and analysis plans
for each experiment, please refer to the Consortium’s preregistration document (available on
the OSF platform: https://osf.io/4rn85), and the experiment-specific Study Protocols
(Abbatecola et al., under review; Haun et al., in prep; Robinson et al., in press; Takahashi et
al., 2025).
3.2 Hypothesis #1: On the contribution of inactive neurons to
the specification of visuospatial awareness
According to IIT, the quality of any conscious experience is determined by the form of the
cause-effect structure corresponding to that experience. Since such structures are specified
by the cause-effect powers inherent within the organisation of their physical substrate, any
alteration of its architecture should be accompanied by a corresponding alteration of
22
experience. An intriguing consequence of this view is the claim that consciousness may be
sustained by a cerebral cortex which is silent in terms of neural activity (Oizumi et al., 2014;
Tononi et al., 2016). This follows from the premise that silent (i.e., quiescent or ‘inactive’)
neurons are just as important for specifying the cause-effect structure as are active neurons,
since silent neurons contribute to the exclusion of alternative neural configurations that
would otherwise have given rise to different conscious experiences. IIT thus posits that
intervening on inactive neurons such that their functional capacity for activation is disabled –
i.e., their potential ability to ‘take or make a difference’ is abolished – should alter subjective
experience on account of preventing these neurons from participating in the cause-effect
structure (Albantakis et al., 2023).
The notion that conscious experience may be manipulated by suppressing the potential
activation of already inactive neurons is a bold and perhaps counterintuitive claim – one that
distinguishes IIT from many other theories of consciousness, including NREP and AI-C.
While the latter two theories do not make positive claims about the specific role of inactive
neurons in awareness, the inactivation of already-inactive neurons should not be expected to
exert any significant effect on conscious experience under these accounts. This is because
inactive neurons are not expected to influence the rest of the network they are a part of;
hence, their ‘inactivation’ (where their capacity for activation is suppressed) should be
indistinguishable from their mere quiescence (where their capacity for activation remains
intact). In other words, an experimental manipulation that does not perturb neural dynamics
should not be expected to perturb subjective experience.
There is, however, an important distinction between NREP and AI-C that leads to divergent
predictions about the contribution of ‘background neuronal activity’ to spatial awareness.
Because NREP claims that consciousness arises from a multimodal, integrative
‘superinference’ on representations including object relations (Pennartz, 2009, 2015), this
implies that some degree of background neuronal activity is necessary for generating
consciousness (Pennartz, 2022; Pennartz et al., 2023). Hence, although the ‘inactivation’ of
already inactive neurons is not anticipated to affect conscious experience, suppression of
background activity is expected to have a disruptive effect (providing this activity is strong
enough to impact other neurons; Pennartz, 2015, 2022). AI-C does not entail this prediction,
although it is plausible that the suppression of background activity could alter precision
estimation in ways that impact visuospatial awareness and behaviour (Friston, 2018; Parr &
Friston, 2018).
23
Optogenetic techniques enabling the precise manipulation of neuronal activity afford the
tantalising prospect of investigating the impact of neuronal inactivation on visuospatial
perception in rodents and other animals. The INTREPID Consortium aims to exploit such
methodological advances in the service of testing the contrasting predictions of IIT, NREP,
and AI-C. Briefly, rodents will be trained to perform a discrimination task in which they must
indicate whether a target stimulus presented in the left and right fields of view falls within the
left or right (subjectively perceived) hemifield. In critical trials, regions of visual cortex in the
left hemisphere will be optogenetically hyperpolarised to investigate the impact of transient
bouts of neural inactivation on task performance. If silent neurons (or those evincing
background levels of activity) are indeed necessary for the conscious experience of space,
inactivating these populations should precipitate systematic changes in behavioural
performance that are consistent with perturbations of spatial awareness akin to hemineglect
or hemianopia (for further details, see Takahashi et al., 2025).
As is typically the case with sophisticated research designs, this experiment presents a
number of technical challenges that must be overcome if it is to generate meaningful data.
First, the animals must be capable of performing the task well enough such that (changes in)
spatial awareness can be reliably inferred from (changes in) their behaviour. Second,
inactive neurons must be reliably distinguished from active neurons, and the experimental
manipulation must be implemented with sufficient precision such that only the target subset
of neurons are inactivated as intended. This task is complicated by the fact that healthy
neurons typically express a certain degree of spontaneous activity, meaning that subsets of
inactive neurons may need to be classed according to a threshold level of quiescence that
does not correspond to absolute silence. Third, it must be ensured that the experimental
manipulation does not induce unintended side effects on downstream processes that might
confound the effect of neural inactivation on consciousness per se with (for example)
decision-making and behavioural processes bearing on the dependent variables being used
to infer (changes in) spatial awareness.
These three exemplary challenges serve to illustrate some of the methodological difficulties
involved in designing informative experiments capable of arbitrating theoretical disputes.
Failure to select an appropriate task for tracking changes in conscious experience would
undermine the experiment from the get-go, since the data generated through such
procedures may not pertain to the desired explanandum. Failure to accurately identify and
precisely manipulate neural activity may produce changes in conscious experience that can
be reliably measured but cannot be ascribed to the causal mechanism hypothesised under
the theories in question. The inferences licenced by a set of empirical observations thus
24
depend on a conjunction of hypotheses that pertain not only to core theoretical claims of
interest, but also to auxiliary assumptions about the adequacy of the interventions and
measures used to probe these claims. Importantly, adversarial collaboration may help to
reduce disagreements about certain auxiliary assumptions (e.g., about whether an
experimental paradigm is appropriate for testing hypotheses about conscious experience,
what level of activity constitutes a reasonable threshold for classing neurons as inactive,
etc.). However, the space of potential auxiliary hypotheses that may be implicitly tested by
any given experimental procedure is vast and seldom fully constrained prior to data
collection (Lakatos, 1976).
Before moving to the next hypothesis, it is worth noting that auxiliary hypotheses are not
exclusively concerned with methodological matters such as those identified in the examples
enumerated above. For example, assume that the optogenetic manipulation designed to test
the effect of inactivating neuronal circuitry is executed perfectly, yet no difference in task
performance is detected. Moreover, assume control manipulations reveal that the rodents
respond to task stimuli as expected, indicating that their behaviour yields a reliable indicator
of their subjective experience. This outcome would constitute evidence against IIT’s
prediction about the effect of neuronal inactivation, but it would not refute the more
fundamental idea that intervening on the physical substrate of the cause-effect structure in a
way that changes its repertoire of potential states will necessarily correspond to a change in
subjective awareness. This is because cause-effect structures are not assumed to be
specified at the neuronal level; manipulations of neuronal activity may not constitute
interventions on the correct spatiotemporal grain to influence the substrate’s cause-effect
powers. Thus, IIT could accommodate the failure to observe any effect of neuronal
inactivation, at the cost of finding a plausible alternative candidate substrate. That is, new
auxiliary hypotheses would be required to translate core principles of the theory into
empirically-tractable predictions.
3.3 Hypothesis #2: On the contribution of cortical structure to
the quality of spatial extendedness
A further implication of the identity IIT posits between the quality of experience and the
cause-effect structure is that fundamental properties of experience can be explained in terms
of the composition of the structure as specified by its physical substrate. Proponents of IIT
have identified the 2D grid-like organisation of posterior cortical networks as a prime
candidate for explaining the phenomenal character of spatial extendedness in the visual
25
modality (e.g., the subjectively perceived distance between two points in the visual field;
Grasso et al., 2021; Haun & Tononi, 2019). IIT predicts that changes in the connectivity of
primary visual cortex should cause systematic alterations in the way space is experienced
(Albantakis et al., 2023; Haun & Tononi, 2019). For example, lesions of primary visual cortex
are expected to result in a corresponding collapse of the experience of spatial extent, such
that objects spanning these regions appear closer together than they otherwise would if the
intervening cortical structure were intact (Haun & Tononi, 2019).
NREP and AI, by contrast, do not predict gross distortions of spatial experience as a
consequence of such structural alterations or lesions. Rather, predictive processing
mechanisms endorsed by these theories imply that regions of the visual field corresponding
to such areas should instead be ‘brushed-over’ or ‘filled in’ (as has been reported for
artificially-induced perceptual scotomas; Ramachandran & Gregory, 1991). Since NREP
argues that spatial experience arises from a large-scale inferential process involving multiple
modalities and underlying brain systems (e.g., visual input, vestibular and proprioceptive
inputs, etc.), estimates of spatial distances spanning damaged or missing cortex should
average out with estimates from trajectories through intact portions of the visual field. While
AI-C predicts that spatial estimates may be less accurate – due to loss of precise sensory
evidence – it predicts no systematic bias corresponding to a contraction or dilation of
perceived space (other than a regression to prior expectations).
The INTREPID Consortium aims to test these competing predictions through two
complementary experiments – one which treats the retinal blindspot as a naturally-occurring
lacuna within cortical space (Abbatecola et al., under review), and one examining the effect
of neurological insults resulting in a scotoma (Haun et al., in prep). The motivation for both
experiments is the same – to investigate whether target stimuli spanning or bordering the
blindspot/scotoma feel closer together (or further apart) compared to foils presented
elsewhere in the visual field. IIT predicts that the absence of functional neural tissue in these
regions of cortex translates to an altered cause-effect structure in which the region of space
that would have been represented as part of the visual scene is simply missing – hence
making target stimuli appear closer together (since there is less intervening phenomenal
space between stimuli). NREP predicts no (or only small) distortions of spatial
extendedness; AI-C predicts no bias but reduced accuracy.
IIT’s prediction of subjective spatial contraction is concordant with psychophysical evidence
from healthy adults (Song et al., 2017); however, other forms of distortion (e.g., spatial
dilation) may also be accommodated by the theory according to the analysis presented by
26
Haun and Tononi (2019). One lack of constraint pertaining to the nature of the anticipated
distortion concerns uncertainty over the precise structural connectivity evinced by the
hypothesised grid-like networks in primary visual cortex – a problem that may be
exacerbated by individual differences in the microstructure of these regions. It is also unclear
whether adaptive compensatory mechanisms, acting from birth onwards, may affect the way
visual experience is constructed for regions of space corresponding to the blindspot.
Moreover, testing this hypothesis in the context of scotoma introduces additional challenges;
psychophysical experiments with many trials are cognitively taxing and can be especially
difficult for older participants with neurological deficits. The heterogeneous nature of the
lesions that patients present with introduces additional variability beyond pre-existing
individual differences in cortical structure, which may further dilute subtle effects.
While these complications highlight various ways in which the data could be reconciled with
IIT – or could turn out to be equivocal due to various sources of error – these experiments
have the potential to significantly challenge the theory in two ways. First, and most obviously,
both experiments could deliver compelling evidence that spatial experience is not warped in
proximity to the blindspot or scotoma, despite the absence of particular neural architectures
in corresponding cortical regions (consistent with the predictions of NREP and AI-C).
Second, an inconsistent pattern of distortion might be observed for different kinds of task –
e.g., a distance estimation task might reveal evidence of a contraction of phenomenal space,
whereas an apparent motion task might suggest a dilation of phenomenal space (or
vice-versa). Such mixed results would be difficult to explain solely in terms of structural
connectivity (or predictive filling-in mechanisms). If this were to transpire, additional work
would be required to explain how the hypothesised impact of deviant cortical structure
interacts with other factors to produce task-specific effects.
3.4 Hypothesis #3: On the contribution of active sampling to
changes in conscious visual experience
The final hypothesis we consider switches focus from empirical predictions motivated by IIT
and NREP to the role of active sensory sampling as envisaged by AI-C. As discussed in
Section 2.1.3, AI-C implies that some kind of (active) inference is required for a change in
conscious experience to manifest – where action (i.e., the consequence of an inferred policy)
here may be realised overtly (e.g., via motor behaviour) or covertly (e.g., via the reallocation
of attention). This is in contrast to both IIT and NREP, neither of which accord any special
role to policy selection in their accounts of consciousness. Although evidence in favour of the
27
hypothesis that active sampling mediates changes in conscious content would not directly
threaten the core claims of IIT or NREP, it would challenge their proponents to offer a
satisfying explanation as to why such sampling should be expected to systematically
influence the way perceptual contents manifest in consciousness.
As with the hypotheses discussed in the previous two sections, the putative role of active
inference in conscious processing is difficult to test directly. Since active sampling is
understood as a pervasive feature of living organisms under the Active Inference framework,
it should not be possible to suppress all forms of such activity without rendering the
organism unconscious (and perhaps even dead). As such, the hypothesis that active
inference is necessary for a change in conscious content cannot simply be examined via the
thoroughgoing suppression of all forms of active inference. Nonetheless, it should still be
possible to shed light on this question by controlling the forms of action in which the human
participant can engage.
The INTREPID Consortium aims to test the role of active sampling in mediating changes in
consciousness via a modified version of the motion-induced blindness paradigm (Bonneh et
al., 2001). In this task, participants report the subjective disappearance of a target stimulus
presented in the visual periphery, as well as the subjective reappearance of the target after
saccading towards it. The amount of time it takes for the individual to report subjective
reappearance of the target stimulus during this active sampling condition will be compared to
the time taken during a passive ‘replay’ condition in which the target stimulus (and the
moving grid required to induce its disappearance) is moved to the centre of the visual field
while the participant maintains stable fixation (rather than moving their eyes towards the
peripheral location). In this way, the effect of active sampling (via saccade) on conscious
content should be isolated while other factors (visual input, attentional deployment, task
demands, etc.) remain constant (for further details, see Robinson et al., in press).
AI-C predicts that active sampling of the target location should promote faster resolution of
uncertainty about the latent causes of sensory states; hence, one should expect shorter
subjective reappearance times to be reported as compared to the passive condition (which
will still result in an eventual change in conscious content due to unresolved prediction errors
generated by the new target position). Failure to confirm this prediction would present a
significant challenge for AI-C, although it may not necessarily ‘falsify’ the theory outright.
Auxiliary hypotheses that might explain the absence of the predicted effect could include
(e.g.) technical difficulties (such as the inability to precisely match retinal input in the passive
replay condition with that driven by eye movements performed during the active condition),
28
measurement error or noise introduced by intervening processes between the onset of
stimulus reappearance in conscious awareness and behavioural reports of this event, or
some unanticipated confound that can be accommodated by the theoretical resources of the
Active Inference framework (e.g., earlier subjective reappearance in the passive condition
due to an increase in precision mediated by bottom-up attentional capture; later subjective
reappearance in the active condition due to a decrease in precision mediated by top-down
saccadic suppression). Of course, subsequent experiments could be devised with a view to
disambiguating some of these candidate hypotheses, but they would themselves rely on
further auxiliary hypotheses that could likewise be called upon to explain away evidence
contrary to the predictions entailed by AI-C. This being said, successive failures to accrue
evidence in favour of the theory would be indicative of a ‘degenerative’ research programme
– and reason to pursue alternative theories more vigorously (especially if they are accruing
evidential support in the meantime).
As mentioned above, behavioural evidence favouring the facilitatory effect of action on
changes in conscious contents would support AI-C, but would not necessarily constitute
counter-evidence against IIT and NREP per se. Proponents of IIT might explain such an
effect in terms of motor-induced changes in visual cortical state. Similarly, proponents of
NREP might ascribe the effect to motor-driven changes in attention, or motor/
reafference-related modulation of visual cortical dynamics (Oude Lohuis et al., 2024).
However, while IIT and NREP are capable of accommodating (or explaining away)
facilitatory effects of active sampling on conscious perception, they would do so by
appealing to auxiliary hypotheses about the consequences of motor activity that are not
straightforwardly derived from (or motivated by) their core claims. AI-C would by contrast
afford a more compelling theoretical explanation of this phenomenon, insofar as it furnishes
a principled, unifying account of the way changes in conscious experience are mediated by
overt actions – and why such actions are accompanied by covert fluctuations in arousal and
attention.
4 From empirical data to model comparison
Having implemented the experiments designed to test each of the hypotheses outlined in
Section 3, the final step of our collaborative endeavour will be to assess the evidence in
favour of each of the three theories of consciousness under examination. Although we are
not in a position to comment on the precise ways in which each set of experimental findings
will be analysed, some general remarks on the potential advances, pitfalls, and
29
controversies that may lie in wait can be made based on the state of the art of adversarial
collaboration.
One notable empirical feature of adversarial collaboration is that it often fails to completely
resolve scientific disputes amongst its protagonists (Mellers et al., 2001; Witkowski, 2020).
Adversarial experiments typically generate mixed results that do not fully confirm the
predictions of one theoretical position or another (as indeed was the case for the first ARC
study; Cogitate Consortium et al., 2025). Even in cases where the data appear to decisively
favour one set of predictions, proponents of the ‘disconfirmed’ hypothesis may ascribe
unfavourable results to various auxiliary factors rather than concede the deficiency of their
core theoretical claims (Cowan et al., 2020). As discussed in the previous section, this
phenomenon is characteristic of scientific practice in general (i.e., it is not a distinctive
feature of adversarial collaboration per se). Often, manuscripts reporting the results of an
adversarial collaboration provide the opportunity for protagonists to outline their own
interpretations of the results (Clark et al., 2022; Rakow, 2022). It is then up to the broader
scientific community to evaluate these interpretations in light of the evidence, much as an
impartial judge or jury must adjudicate the arguments presented by competing advocates in
the adversarial legal system (Corcoran et al., 2023).
While the potential for divergent interpretations of results may not be unusual in adversarial
collaboration, the multi-experiment structure of ARC projects such as INTREPID poses
additional challenges for the adjudication of competing theories. The inclusion of multiple
experiments raises the question of how the results of each experiment ought to be
aggregated in view of the consideration that different experiments pose more or less severe
tests of the theoretical predictions at stake. Since the ARC initiative stipulates that all
experiments must be performed by two independent labs, there is also the additional
question of how discrepancies in the results obtained by different labs performing ostensibly
the same experiment should be handled (e.g., in the event that a predicted effect is reported
by one lab but not the other, does this still constitute evidence in favour of the theory that
predicted this effect, or should effects that ‘fail to replicate’ be demoted or disqualified?).
Disagreements about the appropriate way to deal with such scenarios may engender further
controversy and confusion about the implications of the data for competing theories.
These are challenging meta-scientific issues that transcend the scope of the INTREPID
Consortium. However, since all ARC projects will ultimately need to contend with these
issues, we briefly highlight an analytic strategy that has recently been developed with a view
to integrating the evidence accumulated across disparate datasets in the context of
30
adversarial collaboration (Corcoran et al., 2023). The key idea of this approach – which
forms part of a broader framework for Bayesian adversarial collaboration – is to leverage
standard techniques of variational Bayesian inference such that the hypotheses of
competing theories can be formalised as generative models and fit to empirical data. The
quality of these model fits – which is quantified as the (log) marginal likelihood or model
evidence – can be obtained for each model and compared across theories (which may
themselves be assigned different prior probabilities – although for the purposes of this
Consortium the prior over each theory is assumed to be uniform). These quantities can be
aggregated across datasets irrespective of whether they were generated by the same
experiment, paradigm, or modality, meaning that the amount of evidence for each theory
over the course of the project can be additively accrued as data are accumulated across
different sites.
One advantage of this formal approach is that it encourages protagonists to specify their
adversarial predictions as clearly and precisely as possible, thereby mitigating the risk of
vague or ambiguous statements that can be retrospectively finessed to fit empirical results.
This approach also ensures that adversarial predictions are really predictions about the
same underlying data or putative effect, rather than related phenomena that are distinct but
not mutually exclusive. This helps to ensure that the adversarial collaborative setting is being
exploited to maximum effect (i.e., to drive an evidential wedge between theories by testing
contrastive predictions about the same target phenomenon), rather than merely combining
parallel investigations that do not directly engage with one another’s hypotheses.
A further advantage of the integrative approach proposed by Corcoran and colleagues is its
capacity to handle conflicting patterns of results (e.g., from different labs conducting the
same protocol) in a principled manner. For instance, two implementations of the same
experiment yielding equal amounts of evidence for and against the hypothesised effect
would simply cancel each other out; epistemically speaking, one is no better off than before
the experiments were run. However, if one lab produced strong evidence in favour of the
effect, whereas another produced inconclusive evidence (perhaps due to noisier
measurement), the data from the latter group would be down-weighted in accordance with its
lower evidential value. Notably, such calculations would all be handled under the normative
belief-updating scheme prescribed by Bayesian inference, thus obviating potentially
controversial decisions pertaining to the amount of information conferred by disparate
datasets (although decisions about which datasets ought to be included in the analysis
would still require careful deliberation; cf. Negro et al., 2024).
31
With this analysis strategy in mind, each theory lead involved in the INTREPID project
contributed their predictions for the effect of each critical manipulation on the key parameters
of each experiment being conducted by the Consortium. These predictions took the form of a
categorical ‘tickbox’ scheme, in which the predicted effect of an experimental manipulation
could be positive, negative, or neutral (i.e., no change), relative to a control condition (see
Table 1 for an example pertaining to Hypothesis #1). Theory leads were permitted to select
more than one option, thereby encoding more complex predictions corresponding to
directional or non-directional hypotheses, a hypothesis of no effect, or some combination of
these options. Additionally, theory leads were invited to assign a categorical confidence level
(low, medium, high) to each of their predictions. This information was solicited in recognition
of the fact that some experiments test predictions that are more proximal to one theory’s
core than another’s; theorists may be less confident about the outcome of a manipulation
involving factors that are more distal from or peripheral to the core claims of their theory.
One can construe this confidence rating as a way of weighting the evidence that will be
accrued (or lost, in the case of an unpredicted outcome) from particular experiments – where
evidence pertaining to high-confidence predictions is up-weighted and that pertaining to
low-confidence predictions is down-weighted.
The Bayesian approach to evidence accumulation and model comparison is not expected to
eliminate all sources of controversy from adversarial collaborative research; as indicated in
Section 3, there are various reasons a hypothesis might not turn out as anticipated – ranging
from unforeseen experimental complications to under-appreciated causal factors – that may
be elegantly integrated within an updated version of one’s theory (or at least accommodated
via the incorporation of auxiliary hypotheses). We see the strength of this analytic approach
in its power to formalise predictions and confidences, quantify the evidence accumulated for
competing theories, and integrate evidence over disparate paradigms and settings.
Importantly, this analysis is suggested to function as the starting point for discussion – it
does not supersede sensitive interpretation of the data generating process or the need for
carefully reasoned inferences to the best available explanation. We also acknowledge that
this novel approach may introduce its own pitfalls, which may become apparent when
deployed on real data. At the very least, it may be necessary to elaborate the scheme we
propose here in a way that augments model comparison with procedures that can
systematically account for the distance of a prediction from a theory’s core (e.g., by
weighting model evidences according to scores based on recently proposed metrics or
criteria; see Chis-Ciure et al., 2024; Negro, 2024). It might also be useful to specify families
of models permitted under competing theories, to account for subtle differences in
predictions that issue from uncertainties in auxiliary hypotheses. These considerations aside,
32
we are hopeful that this formal approach will complement and enrich the more informal
commentaries typically provided in the discussion sections of adversarial collaborative
research reports.
5 Concluding remarks
The Templeton World Charity Foundation’s ‘Accelerating Research on Consciousness’
initiative marks an ambitious and unprecedented attempt to progress the neuroscience of
consciousness through adversarial collaboration. Here, we have outlined the key tenets,
similarities, and distinguishing features of three theories of consciousness – Integrated
Information Theory, Neurorepresentationalism, and Active Inference – represented by one
such adversarial collaboration – the INTREPID Consortium. We have furthermore identified
key hypotheses that will be put to the test in a series of experiments designed to jointly
elucidate which of these three theories provides the best account for a variety of empirical
phenomena. Although we acknowledge that the adversarial model does not circumvent all of
the challenges that attend the empirical validation of neuroscientific theories of
consciousness, we suggest a Bayesian modelling framework may help to mitigate some of
these difficulties by formally quantifying the amount of evidence accumulated for each theory
across different experiments. We hope this strategy will be adopted and further developed in
future work, with a view to facilitating the evidence-based adjudication of competing theories
of consciousness in the community at large.
33
Manipulation: Optogenetic inactivation of ‘minimally active’ neurons in left visual
cortex
Biased towards No change in Biased towards Confidence
right hemifield performance left hemifield
IIT X High
NREP X High
AI-C X Medium
Manipulation: Optogenetic inactivation of ‘normal background activity’ in left visual
cortex
Biased towards No change in Biased towards Confidence
right hemifield performance left hemifield
IIT X High
NREP X Medium
AI-C X X Low
Table 1. Example of adversarial prediction tables for two experimental manipulations
designed to test the effect of neural inactivation on visuospatial awareness. IIT
predicts both manipulations will bias responses on critical trials of a visual location task
towards the intact (left) hemifield, consistent with the hypothesis that neural inactivation
should alter the cause-effect structure in such a way as to impose a functional hemineglect.
While NREP and AI-C agree that the inactivation of ‘minimally active’ neurons should not
influence task performance – thus entailing the prediction of no change in behaviour relative
to control trials in which the same task is performed in the absence of any optogenetic
perturbation – NREP predicts an increase in response bias when ‘normal background
activity’ is suppressed (see main text for definition of these activity levels). AI-C, by contrast,
is less-committal, offering a non-directional prediction about the consequence of this
manipulation. Taken together, this set of predictions enables each of the three theories to
accrue differing amounts of evidence according to the results of the experiment. Please
consult the INTREPID Consortium’s preregistration document and accompanying Study
Protocols for further details and examples. AI-C: Active Inference theory of consciousness;
IIT: Integrated Information Theory; NREP: Neurorepresentationalism.
34
Acknowledgements
The authors wish to thank Jakob Hohwy and Umberto Olcese for valuable feedback on a
previous version of this manuscript.
Funding
This research was supported by a grant from the Templeton World Charity Foundation
(TWCF#0646). The opinions expressed in this publication are those of the authors and do
not necessarily reflect the views of the Templeton World Charity Foundation. AWC
acknowledges the support of the Three Springs Foundation. KJF was supported by funding
for the Wellcome Centre for Human Neuroimaging (Ref: 205103/Z/16/Z), a Canada-UK
Artificial Intelligence Initiative (Ref: ES/T01279X/1) and the European Union’s Horizon 2020
Framework Programme for Research and Innovation under the Specific Grant Agreement
No. 945539 (Human Brain Project SGA3). CMAP was supported by the European Union’s
Horizon 2020 Framework Programme for Research and Innovation under the Specific Grant
Agreement No. 945539 (Human Brain Project SGA3) and by NWO grant OCENW.M20.285.
Competing interests
None.
35
References
Abbatecola, C., ’t Hart, B. M., Montabes de la Cruz, B. M., Petro, L. S., Pennartz, C. M. A.,
Tononi, G., Friston, K. J., Hohwy, J., Olcese, U., Boly, M., Haun, A. M., Tripathy, S. P.,
Cavanagh, P., Muckli, L. F., & TWCF: INTREPID Consortium. (under review).
Investigating the warping of spatial experience across the blind spot to contrast
predictions of the Integrated Information Theory and Predictive Processing accounts
of consciousness.
Albantakis, L., Barbosa, L., Findlay, G., Grasso, M., Haun, A. M., Marshall, W., Mayner, W.
G. P., Zaeemzadeh, A., Boly, M., Juel, B. E., Sasai, S., Fujii, K., David, I., Hendren,
J., Lang, J. P., & Tononi, G. (2023). Integrated information theory (IIT) 4.0:
Formulating the properties of phenomenal existence in physical terms. PLOS
Computational Biology, 19(10), e1011465.
https://doi.org/10.1371/journal.pcbi.1011465
Attias, H. (2003). Planning by probabilistic inference. In C. M. Bishop & B. J. Frey (Eds),
Proceedings of the Ninth International Conference on Artificial Intelligence and
Statistics. Society for Artificial Intelligence and Statistics.
Balduzzi, D., & Tononi, G. (2008). Integrated information in discrete dynamical systems:
Motivation and theoretical framework. PLoS Computational Biology, 4(6), e1000091.
https://doi.org/10.1371/journal.pcbi.1000091
Balduzzi, D., & Tononi, G. (2009). Qualia: The geometry of integrated information. PLoS
Computational Biology, 5(8), e1000462. https://doi.org/10.1371/journal.pcbi.1000462
Bastos, A. M., Usrey, W. M., Adams, R. A., Mangun, G. R., Fries, P., & Friston, K. J. (2012).
Canonical microcircuits for predictive coding. Neuron, 76(4), 695–711.
Bateman, I., Kahneman, D., Munro, A., Starmer, C., & Sugden, R. (2005). Testing competing
models of loss aversion: An adversarial collaboration. Journal of Public Economics,
89(8), 1561–1580. https://doi.org/10.1016/j.jpubeco.2004.06.013
36
Bayne, T. (2018). On the axiomatic foundations of the integrated information theory of
consciousness. Neuroscience of Consciousness, 2018(1).
https://doi.org/10.1093/nc/niy007
Bayne, T., Hohwy, J., & Owen, A. M. (2016). Are there levels of consciousness? Trends in
Cognitive Sciences, 20(6), 405–413.
Block, N. (1995). On a confusion about a function of consciousness. Behavioral and Brain
Sciences, 18(2), 227–247. https://doi.org/10.1017/S0140525X00038188
Block, N. (2011). Perceptual consciousness overflows cognitive access. Trends in Cognitive
Sciences, 15(12), 567–575. https://doi.org/10.1016/j.tics.2011.11.001
Bogacz, R. (2017). A tutorial on the free-energy framework for modelling perception and
learning. Journal of Mathematical Psychology, 76, 198–211.
Boly, M., Massimini, M., Tsuchiya, N., Postle, B. R., Koch, C., & Tononi, G. (2017). Are the
neural correlates of consciousness in the front or in the back of the cerebral cortex?
Clinical and neuroimaging evidence. The Journal of Neuroscience, 37(40),
9603–9613. https://doi.org/10.1523/JNEUROSCI.3218-16.2017
Bonneh, Y. S., Cooperman, A., & Sagi, D. (2001). Motion-induced blindness in normal
observers. Nature, 411(6839), 798–801. https://doi.org/10.1038/35081073
Botvinick, M., & Toussaint, M. (2012). Planning as inference. Trends in Cognitive Sciences,
16(10), 485–488.
Brucklacher, M., Bohté, S. M., Mejias, J. F., & Pennartz, C. M. A. (2023). Local minimization
of prediction errors drives learning of invariant object representations in a generative
network model of visual perception. Frontiers in Computational Neuroscience, 17,
1207361. https://doi.org/10.3389/fncom.2023.1207361
Brucklacher, M., Lee, K., Moreni, G., Mejías, J. F., Bohté, S. M., & Pennartz, C. M. A. (2025).
Predictive processing in neuroscience, computational modeling and psychology. In
Encyclopedia of the Human Brain (pp. 657–679). Elsevier.
https://doi.org/10.1016/B978-0-12-820480-1.00201-1
Brucklacher, M., Pezzulo, G., Mannella, F., Galati, G., & Pennartz, C. M. A. (2025). Learning
37
to segment self-generated from externally caused optic flow through sensorimotor
mismatch circuits. Neural Networks, 181, 106716.
https://doi.org/10.1016/j.neunet.2024.106716
Cea, I., Negro, N., & Signorelli, C. M. (2023). The fundamental tension in integrated
information theory 4.0’s realist idealism. Entropy, 25(10), 1453.
https://doi.org/10.3390/e25101453
Ceci, S. J., Clark, C. J., Jussim, L., & Williams, W. M. (2024). Adversarial collaboration: An
undervalued approach in behavioral science. American Psychologist.
https://doi.org/10.1037/amp0001391
Chalmers, A. F. (2013). What is this thing called science? (Fourth edition). Hackett
Publishing Company, Inc.
Chalmers, D. J. (1996). The conscious mind: In search of a fundamental theory. Oxford
University Press.
Chis-Ciure, R. (2022). The transcendental deduction of integrated information theory:
Connecting the axioms, postulates, and identity through categories. Synthese,
200(3), 236. https://doi.org/10.1007/s11229-022-03704-z
Chis-Ciure, R., Melloni, L., & Northoff, G. (2024). A measure centrality index for systematic
empirical comparison of consciousness theories. Neuroscience & Biobehavioral
Reviews, 161, 105670. https://doi.org/10.1016/j.neubiorev.2024.105670
Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of
cognitive science. Behavioral Brain Sciences, 36(3), 181–253.
Clark, A. (2016). Surfing uncertainty: Prediction, action, and the embodied mind. Oxford:
Oxford University Press.
Clark, A. (2018). Beyond the ‘Bayesian blur’: Predictive processing and the nature of
subjective experience. Journal of Consciousness Studies, 25(3–4), 71–87.
Clark, A. (2019). Consciousness as generative entanglement. The Journal of Philosophy,
116(12), 645–662. https://doi.org/10.5840/jphil20191161241
Clark, A., Friston, K. J., & Wilkinson, S. (2019). Bayesing qualia: Consciousness as
38
inference, not raw datum. Journal of Consciousness Studies, 26(9–10), 19–33.
Clark, C. J., Costello, T., Mitchell, G., & Tetlock, P. E. (2022). Keep your enemies close:
Adversarial collaborations will improve behavioral science. Journal of Applied
Research in Memory and Cognition, 11(1), 1–18.
https://doi.org/10.1037/mac0000004
Clark, C. J., & Tetlock, P. E. (2023). Adversarial collaboration: The next science reform. In C.
L. Frisby, R. E. Redding, W. T. O’Donohue, & S. O. Lilienfeld, Ideological and political
bias in psychology: Nature, scope, and solutions (pp. 905–927). Springer.
Cleeremans, A. (2005). Computational correlates of consciousness. In Progress in Brain
Research (Vol. 150, pp. 81–98). Elsevier.
https://doi.org/10.1016/S0079-6123(05)50007-4
Cogitate Consortium, Ferrante, O., Gorska-Klimowska, U., Henin, S., Hirschhorn, R., Khalaf,
A., Lepauvre, A., Liu, L., Richter, D., Vidal, Y., Bonacchi, N., Brown, T., Sripad, P.,
Armendariz, M., Bendtz, K., Ghafari, T., Hetenyi, D., Jeschke, J., Kozma, C., …
Melloni, L. (2025). Adversarial testing of global neuronal workspace and integrated
information theories of consciousness. Nature.
https://doi.org/10.1038/s41586-025-08888-1
Cohen, M. A., & Dennett, D. C. (2011). Consciousness cannot be separated from function.
Trends in Cognitive Sciences, 15(8), 358–364.
https://doi.org/10.1016/j.tics.2011.06.008
Corcoran, A. W., Hohwy, J., & Friston, K. J. (2023). Accelerating scientific progress through
Bayesian adversarial collaboration. Neuron, 111(22), 3505–3516.
https://doi.org/10.1016/j.neuron.2023.08.027
Corcoran, A. W., Pezzulo, G., & Hohwy, J. (2020). From allostatic agents to counterfactual
cognisers: Active inference, biological regulation, and the origins of cognition. Biology
& Philosophy, 35(32).
Cowan, N., Belletier, C., Doherty, J. M., Jaroslawska, A. J., Rhodes, S., Forsberg, A.,
Naveh-Benjamin, M., Barrouillet, P., Camos, V., & Logie, R. H. (2020). How do
39
scientific views change? Notes from an extended adversarial collaboration.
Perspectives on Psychological Science, 15(4), 1011–1025.
https://doi.org/10.1177/1745691620906415
Crick, F., & Koch, C. (1990). Towards a neurobiological theory of consciousness. Seminars
in the Neurosciences, 263–275.
Crick, F., & Koch, C. (2003). A framework for consciousness. Nature Neuroscience, 6(2),
119–126. https://doi.org/10.1038/nn0203-119
Da Costa, L., Friston, K., Heins, C., & Pavliotis, G. A. (2021). Bayesian mechanics for
stationary processes. Proceedings of the Royal Society A: Mathematical, Physical
and Engineering Sciences, 477(2256), 20210518.
https://doi.org/10.1098/rspa.2021.0518
Deane, G. (2021). Consciousness in active inference: Deep self-models, other minds, and
the challenge of psychedelic-induced ego-dissolution. Neuroscience of
Consciousness, 2021(2), niab024. https://doi.org/10.1093/nc/niab024
Dehaene, S., & Changeux, J.-P. (2011). Experimental and theoretical approaches to
conscious processing. Neuron, 70(2), 200–227.
https://doi.org/10.1016/j.neuron.2011.03.018
Dehaene, S., Changeux, J.-P., Naccache, L., Sackur, J., & Sergent, C. (2006). Conscious,
preconscious, and subliminal processing: A testable taxonomy. Trends in Cognitive
Sciences, 10(5), 204–211. https://doi.org/10.1016/j.tics.2006.03.007
Dehaene, S., Kerszberg, M., & Changeux, J.-P. (1998). A neuronal model of a global
workspace in effortful cognitive tasks. Proceedings of the National Academy of
Sciences, 95(24), 14529–14534. https://doi.org/10.1073/pnas.95.24.14529
Dehaene, S., & Naccache, L. (2001). Towards a cognitive neuroscience of consciousness:
Basic evidence and a workspace framework. Cognition, 79(1–2), 1–37.
https://doi.org/10.1016/S0010-0277(00)00123-2
Del Pin, S. H., Skóra, Z., Sandberg, K., Overgaard, M., & Wierzchoń, M. (2021). Comparing
theories of consciousness: Why it matters and how to do it. Neuroscience of
40
Consciousness, 2021(2), niab019. https://doi.org/10.1093/nc/niab019
Devezer, B., & Buzbas, E. O. (2023). Rigorous exploration in a model-centric science via
epistemic iteration. Journal of Applied Research in Memory and Cognition, 12(2),
189–194. https://doi.org/10.1037/mac0000121
Doerig, A., Schurger, A., & Herzog, M. H. (2021). Hard criteria for empirical theories of
consciousness. Cognitive Neuroscience, 12(2), 41–62.
https://doi.org/10.1080/17588928.2020.1772214
Dołęga, K., & Dewhurst, J. E. (2021). Fame in the predictive brain: A deflationary approach
to explaining consciousness in the prediction error minimization framework.
Synthese, 198(8), 7781–7806. https://doi.org/10.1007/s11229-020-02548-9
Dora, S., Bohte, S. M., & Pennartz, C. M. A. (2021). Deep gated Hebbian predictive coding
accounts for emergence of complex neural response properties along the visual
cortical hierarchy. Frontiers in Computational Neuroscience, 15, 666131.
https://doi.org/10.3389/fncom.2021.666131
Duhem, P. M. M. (1954). The Aim and Structure of Physical Theory. Princeton University
Press. https://doi.org/10.1515/9780691233857
Dyson, F. W., Eddington, A. S., & Davidson, C. (1920). IX. A determination of the deflection
of light by the sun’s gravitational field, from observations made at the total eclipse of
May 29, 1919. Philosophical Transactions of the Royal Society of London. Series A,
Containing Papers of a Mathematical or Physical Character, 220(571–581), 291–333.
https://doi.org/10.1098/rsta.1920.0009
Ellia, F., Hendren, J., Grasso, M., Kozma, C., Mindt, G., P. Lang, J., M. Haun, A., Albantakis,
L., Boly, M., & Tononi, G. (2021). Consciousness and the fallacy of misplaced
objectivity. Neuroscience of Consciousness, 2021(2), niab032.
https://doi.org/10.1093/nc/niab032
Evers, K., Farisco, M., & Pennartz, C. M. A. (2024). Assessing the commensurability of
theories of consciousness: On the usefulness of common denominators in
differentiating, integrating and testing hypotheses. Consciousness and Cognition,
41
119, 103668. https://doi.org/10.1016/j.concog.2024.103668
Francken, J. C., Beerendonk, L., Molenaar, D., Fahrenfort, J. J., Kiverstein, J. D., Seth, A.
K., & van Gaal, S. (2022). An academic survey on theoretical foundations, common
assumptions and the current state of consciousness science. Neuroscience of
Consciousness, 2022(1), niac011. https://doi.org/10.1093/nc/niac011
Friston, K. J. (2010). The free-energy principle: A unified brain theory? Nature Reviews
Neuroscience, 11(2), 127–138.
Friston, K. J. (2018). Am I self-conscious? (Or does self-organisation entail
self-consciousness?). Frontiers in Psychology, 9(579).
Friston, K. J., Breakspear, M., & Deco, G. (2012). Perception and self-organized instability.
Frontiers in Computational Neuroscience, 6(44), 1–19.
Friston, K. J., Da Costa, L., Hafner, D., Hesp, C., & Parr, T. (2021). Sophisticated inference.
Neural Computation, 33(3), 713–763. https://doi.org/10.1162/neco_a_01351
Friston, K. J., Da Costa, L., Sajid, N., Heins, C., Ueltzhöffer, K., Pavliotis, G. A., & Parr, T.
(2023). The free energy principle made simpler but not too simple. Physics Reports,
1024, 1–29. https://doi.org/10.1016/j.physrep.2023.07.001
Friston, K. J., Da Costa, L., Sakthivadivel, D. A. R., Heins, C., Pavliotis, G. A., Ramstead,
M., & Parr, T. (2023). Path integrals, particular kinds, and strange things. Physics of
Life Reviews, 47, 35–62. https://doi.org/10.1016/j.plrev.2023.08.016
Friston, K. J., FitzGerald, T., Rigoli, F., Schwartenbeck, P., & Pezzulo, G. (2017). Active
inference: A process theory. Neural Computation, 29(1), 1–49.
Friston, K. J., & Kiebel, S. (2009). Predictive coding under the free-energy principle.
Philosophical Transactions of the Royal Society B, 364(1521), 1211–1221.
Friston, K. J., Salvatori, T., Isomura, T., Tschantz, A., Kiefer, A., Verbelen, T., Koudahl, M.,
Paul, A., Parr, T., Razi, A., Kagan, B. J., Buckley, C. L., & Ramstead, M. J. D. (2025).
Active inference and intentional behavior. Neural Computation, 37(4), 666–700.
https://doi.org/10.1162/neco_a_01738
Friston, K. J., Wiese, W., & Hobson, J. A. (2020). Sentience and the origins of
42
consciousness: From Cartesian duality to Markovian monism. Entropy, 22(5), 516.
https://doi.org/10.3390/e22050516
Grasso, M., Haun, A. M., & Tononi, G. (2021). Of maps and grids. Neuroscience of
Consciousness, 2021(2), niab022. https://doi.org/10.1093/nc/niab022
Haun, A. M., Monai, E., Boly, M., Peli, E., Hwang, D., Lew, W. H., Reeves, A., Tononi, G.,
Pennartz, C. M. A., Friston, K. J., & TWCF: INTREPID Consortium. (in prep).
Measuring the effects of cortical scotoma on visual space.
Haun, A. M., & Tononi, G. (2019). Why does space feel the way it does? Towards a
principled account of spatial experience. Entropy, 21(12), 1160.
https://doi.org/10.3390/e21121160
Hohwy, J. (2012). Attention and conscious perception in the hypothesis testing brain.
Frontiers in Psychology, 3(96), 1–14.
Hohwy, J. (2013). The predictive mind. Oxford: Oxford University Press.
Hohwy, J. (2020). New directions in predictive processing. Mind & Language, 35(2),
209–223.
Hohwy, J. (2022). Conscious self-evidencing. Review of Philosophy and Psychology, 13(4),
809–828. https://doi.org/10.1007/s13164-021-00578-x
Hohwy, J., Roepstorff, A., & Friston, K. J. (2008). Predictive coding explains binocular rivalry:
An epistemological review. Cognition, 108(3), 687–701.
Hohwy, J., & Seth, A. (2020). Predictive processing as a systematic basis for identifying the
neural correlates of consciousness. Philosophy and the Mind Sciences, 1(II).
https://doi.org/10.33735/phimisci.2020.II.64
Irvine, E. (2017). Explaining what? Topoi, 36(1), 95–106.
https://doi.org/10.1007/s11245-014-9273-4
Kahneman, D. (2003). Experiences of collaborative research. American Psychologist, 58(9),
723–730. https://doi.org/10.1037/0003-066X.58.9.723
Kant, I. (1787). Kritik der reinen Vernunft. Felix Meiner Verlag.
Kirkeby-Hinrup, A. (2024). Quantifying empirical support for theories of consciousness: A
43
tentative methodological framework. Frontiers in Psychology, 15, 1341430.
https://doi.org/10.3389/fpsyg.2024.1341430
Koch, C., Massimini, M., Boly, M., & Tononi, G. (2016). Neural correlates of consciousness:
Progress and problems. Nature Reviews Neuroscience, 17(5), 307–321.
https://doi.org/10.1038/nrn.2016.22
Kuhn, R. L. (2024). A landscape of consciousness: Toward a taxonomy of explanations and
implications. Progress in Biophysics and Molecular Biology, 190, 28–169.
https://doi.org/10.1016/j.pbiomolbio.2023.12.003
Kuhn, T. S. (1977). Objectivity, value judgment, and theory choice. In The Essential Tension:
Selected Studies in Scientific Tradition and Change (pp. 320–339). University of
Chicago Press.
Lakatos, I. (1976). Falsification and the methodology of scientific research programmes. In
S. G. Harding (Ed.), Can Theories be Refuted? (pp. 205–259). Springer Netherlands.
https://doi.org/10.1007/978-94-010-1863-0_14
Lee, K., Dora, S., Mejias, J. F., Bohte, S. M., & Pennartz, C. M. A. (2024). Predictive coding
with spiking neurons and feedforward gist signaling. Frontiers in Computational
Neuroscience, 18, 1338280. https://doi.org/10.3389/fncom.2024.1338280
Lee, K., & Pennartz, C. M. A. (2025). Predictive processing, neurorepresentationalism and
the trouble with computational functionalism.
Lee, T. S., & Mumford, D. (2003). Hierarchical Bayesian inference in the visual cortex.
Journal of the Optical Society of America A, 20(7), 1434–1448.
Limanowski, J., & Friston, K. J. (2018). ‘Seeing the dark’: Grounding phenomenal
transparency and opacity in precision estimation for active inference. Frontiers in
Psychology, 9, 643.
Lycan, W. (2023). Representational theories of consciousness. In E. N. Zalta & U. Nodelman
(Eds), Stanford Encyclopedia of Philosophy.
https://plato.stanford.edu/archives/win2023/entries/consciousness-representational/
Marchi, F., & Hohwy, J. (2022). The intermediate scope of consciousness in the predictive
44
mind. Erkenntnis, 87(2), 891–912.
Mashour, G. A., Roelfsema, P., Changeux, J.-P., & Dehaene, S. (2020). Conscious
processing and the global neuronal workspace hypothesis. Neuron, 105(5), 776–798.
https://doi.org/10.1016/j.neuron.2020.01.026
Mayo, D. G. (2018). Statistical inference as severe testing: How to get beyond the statistics
wars (1st edn). Cambridge University Press. https://doi.org/10.1017/9781107286184
Mediano, P. A. M., Rosas, F. E., Bor, D., Seth, A. K., & Barrett, A. B. (2022). The strength of
weak integrated information theory. Trends in Cognitive Sciences, 26(8), 646–655.
https://doi.org/10.1016/j.tics.2022.04.008
Mediano, P. A. M., Seth, A. K., & Barrett, A. B. (2019). Measuring integrated information:
Comparison of candidate measures in theory and simulation. Entropy, 21(1), 17.
https://doi.org/10.3390/e21010017
Mellers, B., Hertwig, R., & Kahneman, D. (2001). Do frequency representations eliminate
conjunction effects? An exercise in adversarial collaboration. Psychological Science,
12(4), 269–275. https://doi.org/10.1111/1467-9280.00350
Melloni, L. (2022). On keeping our adversaries close, preventing collateral damage, and
changing our minds. Journal of Applied Research in Memory and Cognition, 11(1),
45–49. https://doi.org/10.1037/mac0000009
Melloni, L., Mudrik, L., Pitts, M., & Koch, C. (2021). Making the hard problem of
consciousness easier. Science, 372(6545), 911–912.
https://doi.org/10.1126/science.abj3259
Mudrik, L., Boly, M., Dehaene, S., Fleming, S. M., Lamme, V., Seth, A., & Melloni, L. (2025).
Unpacking the complexities of consciousness: Theories and reflections.
Neuroscience & Biobehavioral Reviews, 170, 106053.
https://doi.org/10.1016/j.neubiorev.2025.106053
Murakami, I., Kitaoka, A., & Ashida, H. (2006). A positive correlation between fixation
instability and the strength of illusory motion in a static display. Vision Research,
46(15), 2421–2431. https://doi.org/10.1016/j.visres.2006.01.030
45
Naccache, L. (2018). Why and how access consciousness can account for phenomenal
consciousness. Philosophical Transactions of the Royal Society B: Biological
Sciences, 373(1755), 20170357. https://doi.org/10.1098/rstb.2017.0357
Nagel, T. (1974). What is it like to be a bat? The Philosophical Review, 83(4), 435.
https://doi.org/10.2307/2183914
Nave, K., Deane, G., Miller, M., & Clark, A. (2022). Expecting some action: Predictive
processing and the construction of conscious experience. Review of Philosophy and
Psychology. https://doi.org/10.1007/s13164-022-00644-y
Negro, N. (2020). Phenomenology-first versus third-person approaches in the science of
consciousness: The case of the integrated information theory and the unfolding
argument. Phenomenology and the Cognitive Sciences, 19(5), 979–996.
https://doi.org/10.1007/s11097-020-09681-3
Negro, N. (2024). (Dis)confirming theories of consciousness and their predictions: Towards a
Lakatosian consciousness science. Neuroscience of Consciousness, 2024(1),
niae012. https://doi.org/10.1093/nc/niae012
Negro, N., Corcoran, A. W., Mudrik, L., & Hohwy, J. (2024). The philosophy of science of
consciousness science. PhilSci-Archive. https://philsci-archive.pitt.edu/23829/
Nikolova, N., Waade, P. T., Friston, K. J., & Allen, M. (2022). What might interoceptive
inference reveal about consciousness? Review of Philosophy and Psychology, 13(4),
879–906. https://doi.org/10.1007/s13164-021-00580-3
Northoff, G., & Lamme, V. (2020). Neural signs and mechanisms of consciousness: Is there
a potential convergence of theories of consciousness in sight? Neuroscience &
Biobehavioral Reviews, 118, 568–587.
https://doi.org/10.1016/j.neubiorev.2020.07.019
Odegaard, B., Knight, R. T., & Lau, H. (2017). Should a few null findings falsify prefrontal
theories of conscious perception? The Journal of Neuroscience, 37(40), 9593–9602.
https://doi.org/10.1523/JNEUROSCI.3217-16.2017
Oizumi, M., Albantakis, L., & Tononi, G. (2014). From the phenomenology to the
46
mechanisms of consciousness: Integrated Information Theory 3.0. PLoS
Computational Biology, 10(5), e1003588.
Olcese, U., Oude Lohuis, M. N., & Pennartz, C. M. A. (2018). Sensory processing across
conscious and nonconscious brain states: From single neurons to distributed
networks for inferential representation. Frontiers in Systems Neuroscience, 12, 49.
https://doi.org/10.3389/fnsys.2018.00049
O’Regan, J. K. (2011). Why red doesn’t sound like a bell: Understanding the feel of
consciousness. Oxford University Press.
O’Regan, J. K. (2022). A brief summary of the sensorimotor theory of phenomenal
consciousness [Preprint]. PsyArXiv. https://doi.org/10.31234/osf.io/xhukf
O’Regan, J. K. (2023). How voluntary control over information and body movements
determines “what it’s like” to have perceptual, bodily, emotional and mental
experiences. Frontiers in Psychology, 13, 1108279.
https://doi.org/10.3389/fpsyg.2022.1108279
O’Regan, J. K., & Noë, A. (2001). A sensorimotor account of vision and visual
consciousness. Behavioral & Brain Sciences, 24(5), 939–1031.
Oude Lohuis, M. N., Marchesi, P., Olcese, U., & Pennartz, C. M. A. (2024). Triple
dissociation of visual, auditory and motor processing in mouse primary visual cortex.
Nature Neuroscience, 27(4), 758–771. https://doi.org/10.1038/s41593-023-01564-5
Parr, T., Corcoran, A. W., Friston, K. J., & Hohwy, J. (2019). Perceptual awareness and
active inference. Neuroscience of Consciousness, 5(1), niz012.
Parr, T., & Friston, K. J. (2018). Active inference, novelty and neglect. In T. Hodgson (Ed.),
Processes of Visuospatial Attention and Working Memory (Vol. 41, pp. 115–128).
Springer International Publishing. https://doi.org/10.1007/7854_2018_61
Parr, T., Markovic, D., Kiebel, S. J., & Friston, K. J. (2019). Neuronal message passing using
Mean-field, Bethe, and Marginal approximations. Scientific Reports, 9(1), 1889.
Parr, T., Pezzulo, G., & Friston, K. J. (2022). Active inference: The free energy principle in
mind, brain, and behavior. The MIT Press.
47
Pearson, M. J., Dora, S., Struckmeier, O., Knowles, T. C., Mitchinson, B., Tiwari, K., Kyrki, V.,
Bohte, S., & Pennartz, C. M. A. (2021). Multimodal representation learning for place
recognition using deep Hebbian predictive coding. Frontiers in Robotics and AI, 8,
732023. https://doi.org/10.3389/frobt.2021.732023
Pennartz, C. M. A. (2009). Identification and integration of sensory modalities: Neural basis
and relation to consciousness. Consciousness and Cognition, 18(3), 718–739.
https://doi.org/10.1016/j.concog.2009.03.003
Pennartz, C. M. A. (2015). The brain’s representational power: On consciousness and the
integration of modalities. The MIT Press.
Pennartz, C. M. A. (2018). Consciousness, representation, action: The importance of being
goal-directed. Trends in Cognitive Sciences, 22(2), 137–153.
https://doi.org/10.1016/j.tics.2017.10.006
Pennartz, C. M. A. (2022). What is neurorepresentationalism? From neural activity and
predictive processing to multi-level representations and consciousness. Behavioural
Brain Research, 432, 113969. https://doi.org/10.1016/j.bbr.2022.113969
Pennartz, C. M. A., Farisco, M., & Evers, K. (2019). Indicators and criteria of consciousness
in animals and intelligent machines: An inside-out approach. Frontiers in Systems
Neuroscience, 13, 25. https://doi.org/10.3389/fnsys.2019.00025
Pennartz, C. M. A., Oude Lohuis, M. N., & Olcese, U. (2023). How ‘visual’ is the visual
cortex? The interactions between the visual cortex and other sensory, motivational
and motor systems as enabling factors for visual perception. Philosophical
Transactions of the Royal Society B: Biological Sciences, 378(1886), 20220336.
https://doi.org/10.1098/rstb.2022.0336
Peters, B., Blohm, G., Haefner, R., Isik, L., Kriegeskorte, N., Lieberman, J. S., Ponce, C. R.,
Roig, G., & Peters, M. A. K. (2025). Generative adversarial collaborations: A new
model of scientific discourse. Trends in Cognitive Sciences, 29(1), 1–4.
https://doi.org/10.1016/j.tics.2024.10.015
Pezzulo, G., Parr, T., & Friston, K. (2024). Active inference as a theory of sentient behavior.
48
Biological Psychology, 186, 108741. https://doi.org/10.1016/j.biopsycho.2023.108741
Phillips, I. (2018). The methodological puzzle of phenomenal consciousness. Philosophical
Transactions of the Royal Society B: Biological Sciences, 373(1755), 20170347.
https://doi.org/10.1098/rstb.2017.0347
Piekarski, M. (2021). Understanding predictive processing. A review. AVANT, 12(1), 1–48.
https://doi.org/10.26913/avant.2021.01.04
Popper, K. R. (2002). Conjectures and refutations: The growth of scientific knowledge.
Routledge.
Quine, W. V. O. (1951). Two dogmas of empiricism. The Philosophical Review, 60(1), 20.
https://doi.org/10.2307/2181906
Quine, W. V. O. (1955). Posits and reality. In The Ways of Paradox and Other Essays (2nd
edn, pp. 246–254). Harvard University Press.
Rakow, T. (2022). Adversarial collaboration. In W. O’Donohue, A. Masuda, & S. Lilienfeld
(Eds), Avoiding Questionable Research Practices in Applied Psychology (pp.
359–377). Springer International Publishing.
https://doi.org/10.1007/978-3-031-04968-2_16
Ramachandran, V. S., & Gregory, R. L. (1991). Perceptual filling in of artificially induced
scotomas in human vision. Nature, 350(6320), 699–702.
Ramstead, M. J. D., Albarracin, M., Kiefer, A., Klein, B., Fields, C., Friston, K., & Safron, A.
(2023). The inner screen model of consciousness: Applying the free energy principle
directly to the study of conscious experience. arXiv.
https://doi.org/10.31234/osf.io/6afs3
Ramstead, M. J. D., Sakthivadivel, D. A. R., Heins, C., Koudahl, M., Millidge, B., Da Costa,
L., Klein, B., & Friston, K. J. (2023). On Bayesian mechanics: A physics of and by
beliefs. Interface Focus, 13(3), 20220029. https://doi.org/10.1098/rsfs.2022.0029
Rao, R. P. N., & Ballard, D. H. (1999). Predictive coding in the visual cortex: A functional
interpretation of some extra-classical receptive-field effects. Nature Neuroscience,
2(1), 79–87.
49
Reardon, S. (2019). Rival theories face off over brain’s source of consciousness. Science,
366(6463), 293–293. https://doi.org/10.1126/science.366.6463.293
Robinson, J. E., Corcoran, A. W., Whyte, C. J., Sárközy, A., Seth, A. K., Kovács, G., Friston,
K. J., Pennartz, C. M. A., Tononi, G., Hohwy, J., & TWCF: INTREPID Consortium. (in
press). The role of active inference in conscious awareness. PLOS ONE.
Rorot, W. (2021). Bayesian theories of consciousness: A review in search for a minimal
unifying model. Neuroscience of Consciousness, 2021(2), niab038.
https://doi.org/10.1093/nc/niab038
Rudrauf, D., Bennequin, D., Granic, I., Landini, G., Friston, K., & Williford, K. (2017). A
mathematical model of embodied consciousness. Journal of Theoretical Biology,
428, 106–131.
Sajid, N., Ball, P. J., Parr, T., & Friston, K. J. (2021). Active inference: Demystified and
compared. Neural Computation, 33(3), 674–712.
https://doi.org/10.1162/neco_a_01357
Salvatori, T., Song, Y., Lukasiewicz, T., Bogacz, R., & Xu, Z. (2021). Predictive coding can do
exact backpropagation on convolutional and recurrent neural networks (Version 1).
arXiv. https://doi.org/10.48550/ARXIV.2103.03725
Sandved-Smith, L., Hesp, C., Mattout, J., Friston, K. J., Lutz, A., & Ramstead, M. J. D.
(2021). Towards a computational phenomenology of mental action: Modelling
meta-awareness and attentional control with deep parametric active inference.
Neuroscience of Consciousness, 2021(1), niab018.
https://doi.org/10.1093/nc/niab018
Seth, A. K. (2014). A predictive processing theory of sensorimotor contingencies: Explaining
the puzzle of perceptual presence and its absence in synesthesia. Cognitive
Neuroscience, 5(2), 97–118.
Seth, A. K., & Bayne, T. (2022). Theories of consciousness. Nature Reviews Neuroscience,
23(7), 439–452. https://doi.org/10.1038/s41583-022-00587-4
Seth, A. K., & Tsakiris, M. (2018). Being a beast machine: The somatic basis of selfhood.
50
Trends in Cognitive Sciences, 22(11), 969–981.
Signorelli, C. M., Szczotka, J., & Prentner, R. (2021). Explanatory profiles of models of
consciousness—Towards a systematic classification. Neuroscience of
Consciousness, 2021(2), niab021. https://doi.org/10.1093/nc/niab021
Smith, R., Friston, K. J., & Whyte, C. J. (2022). A step-by-step tutorial on active inference
and its application to empirical data. Journal of Mathematical Psychology, 107,
102632. https://doi.org/10.1016/j.jmp.2021.102632
Solms, M. (2019). The hard problem of consciousness and the free energy principle.
Frontiers in Psychology, 9, 2714. https://doi.org/10.3389/fpsyg.2018.02714
Song, C., Haun, A. M., & Tononi, G. (2017). Plasticity in the structure of visual space.
eNeuro, 4(3), ENEURO.0080-17.2017.
https://doi.org/10.1523/ENEURO.0080-17.2017
Spratling, M. W. (2017). A review of predictive coding algorithms. Brain & Cognition, 112,
92–97.
Sprevak, M., & Smith, R. (2023). An introduction to predictive processing models of
perception and decision‐making. Topics in Cognitive Science, tops.12704.
https://doi.org/10.1111/tops.12704
Srinivasan, M. V., Laughlin, S. B., & Dubs, A. (1982). Predictive coding: A fresh view of
inhibition in the retina. Proceedings of the Royal Society B, 216(1205), 427–459.
Storm, J. F., Boly, M., Casali, A. G., Massimini, M., Olcese, U., Pennartz, C. M. A., & Wilke,
M. (2017). Consciousness regained: Disentangling mechanisms, brain systems, and
behavioral responses. The Journal of Neuroscience, 37(45), 10882–10893.
https://doi.org/10.1523/JNEUROSCI.1838-17.2017
Storm, J. F., Klink, P. C., Aru, J., Senn, W., Goebel, R., Pigorini, A., Avanzini, P., Vanduffel,
W., Roelfsema, P. R., Massimini, M., Larkum, M. E., & Pennartz, C. M. A. (2024). An
integrative, multiscale view on neural theories of consciousness. Neuron, 112(10),
1531–1552. https://doi.org/10.1016/j.neuron.2024.02.004
Takahashi, K., Pontes Quero, S., Fiorilli, J., Benedetti, D., Yuste, R., Friston, K. J., Tononi,
51
G., Pennartz, C. M. A., Olcese, U., & TWCF: INTREPID Consortium. (2025). Testing
the role of spontaneous activity in visuospatial perception with patterned
optogenetics. PLOS ONE, 20(2), e0318863.
https://doi.org/10.1371/journal.pone.0318863
Tetlock, P. E., & Mitchell, G. (2009a). Adversarial collaboration aborted but our offer still
stands. Research in Organizational Behavior, 29, 77–79.
https://doi.org/10.1016/j.riob.2009.06.012
Tetlock, P. E., & Mitchell, G. (2009b). Implicit bias and accountability systems: What must
organizations do to prevent discrimination? Research in Organizational Behavior, 29,
3–38. https://doi.org/10.1016/j.riob.2009.10.002
Tononi, G. (2004). An information integration theory of consciousness. BMC Neuroscience,
5(1), 42. https://doi.org/10.1186/1471-2202-5-42
Tononi, G. (2008). Consciousness as integrated information: A provisional manifesto. The
Biological Bulletin, 215(3), 216–242. https://doi.org/10.2307/25470707
Tononi, G. (2012). Integrated information theory of consciousness: An updated account.
Archives Italiennes de Biologie, 150(4), 290–326.
Tononi, G., Albantakis, L., Boly, M., Cirelli, C., & Koch, C. (2022). Only what exists can
cause: An intrinsic view of free will (Version 3). arXiv.
https://doi.org/10.48550/ARXIV.2206.02069
Tononi, G., Boly, M., Massimini, M., & Koch, C. (2016). Integrated information theory: From
consciousness to its physical substrate. Nature Reviews Neuroscience, 17(7),
450–461. https://doi.org/10.1038/nrn.2016.44
Tononi, G., & Edelman, G. M. (1998). Consciousness and complexity. Science, 282(5395),
1846–1851. https://doi.org/10.1126/science.282.5395.1846
Tononi, G., & Koch, C. (2015). Consciousness: Here, there and everywhere? Philosophical
Transactions of the Royal Society B: Biological Sciences, 370(1668), 20140167.
https://doi.org/10.1098/rstb.2014.0167
Vilas, M. G., Auksztulewicz, R., & Melloni, L. (2022). Active inference as a computational
52
framework for consciousness. Review of Philosophy and Psychology, 13(4),
859–878. https://doi.org/10.1007/s13164-021-00579-w
Vlasceanu, M., Reinero, D. A., & Van Bavel, J. J. (2022). Adversarial collaborations in
behavioral science: Benefits and boundary conditions. Journal of Applied Research
in Memory and Cognition, 11(1), 23–26. https://doi.org/10.1037/mac0000002
von Helmholtz, H. (1962). Handbuch der physiologischen Optik (J. P. C. Southall, Ed. &
Trans.; Vol. 3). Dover Publications.
Vorms, M. (2018). Theories and models. In A. Baberousse, D. Bonnay, & M. Cozic (Eds),
The Philosophy of Science: A Companion (pp. 171–224). Oxford University Press.
Whyte, C. J. (2019). Integrating the global neuronal workspace into the framework of
predictive processing: Towards a working hypothesis. Consciousness and Cognition,
73, 102763. https://doi.org/10.1016/j.concog.2019.102763
Whyte, C. J., Corcoran, A. W., Robinson, J., Smith, R., Moran, R. J., Parr, T., Friston, K. J.,
Seth, A. K., & Hohwy, J. (2024). On the minimal theory of consciousness implicit in
active inference (Version 1). arXiv. https://doi.org/10.48550/ARXIV.2410.06633
Whyte, C. J., Hohwy, J., & Smith, R. (2022). An active inference model of conscious access:
How cognitive action selection reconciles the results of report and no-report
paradigms. Current Research in Neurobiology, 3, 100036.
https://doi.org/10.1016/j.crneur.2022.100036
Whyte, C. J., & Smith, R. (2021). The predictive global neuronal workspace: A formal active
inference model of visual consciousness. Progress in Neurobiology, 199, 101918.
https://doi.org/10.1016/j.pneurobio.2020.101918
Wiese, W. (2018). Toward a mature science of consciousness. Frontiers in Psychology, 9,
693. https://doi.org/10.3389/fpsyg.2018.00693
Wiese, W. (2020). The science of consciousness does not need another theory, it needs a
minimal unifying model. Neuroscience of Consciousness, 2020(1), niaa013.
https://doi.org/10.1093/nc/niaa013
Wiese, W. (2024). Artificial consciousness: A perspective from the free energy principle.
53
Philosophical Studies, 181(8), 1947–1970.
https://doi.org/10.1007/s11098-024-02182-y
Wiese, W., & Friston, K. J. (2021). The neural correlates of consciousness under the free
energy principle: From computational correlates to computational explanation.
Philosophy and the Mind Sciences, 2. https://doi.org/10.33735/phimisci.2021.81
Williford, K., Bennequin, D., Friston, K. J., & Rudrauf, D. (2018). The projective
consciousness model and phenomenal selfhood. Frontiers in Psychology, 9, 2571.
https://doi.org/10.3389/fpsyg.2018.02571
Witkowski, T. (2020). Daniel Kahneman: Decision making, adversarial collaboration and
hedonic psychology. In T. Witkowski, Shaping Psychology (pp. 289–303). Springer
International Publishing. https://doi.org/10.1007/978-3-030-50003-0_15
Yaron, I., Melloni, L., Pitts, M., & Mudrik, L. (2022). The ConTraSt database for analysing
and comparing empirical studies of consciousness theories. Nature Human
Behaviour, 6(4), 593–604. https://doi.org/10.1038/s41562-021-01284-5

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Integrated information and predictive processing theories of consciousness: An adversarial collaborative review"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
