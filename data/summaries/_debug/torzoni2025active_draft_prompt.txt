=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Active Digital Twins via Active Inference
Citation Key: torzoni2025active
Authors: Matteo Torzoni, Domenico Maisto, Andrea Manzoni

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Abstract: Digital twins are transforming engineering and applied sciences by enabling real-time monitoring,
simulation, and predictive analysis of physical systems and processes. However, conventional dig-
ital twins rely primarily on passive data assimilation, which limits their adaptability in uncertain
and dynamic environments. This paper introduces the active digital twin paradigm, based on
active inference. Active inference is a neuroscience-inspired, Bayesian framework for probabilistic
reasoning an...

Key Terms: milan, politecnico, predictive, milano, italy, engineering, inference, active, digital, twins

=== FULL PAPER TEXT ===

5202
nuJ
71
]EC.sc[
1v35441.6052:viXra
Active Digital Twins via Active Inference
Matteo Torzonia, Domenico Maistob, Andrea Manzonic, Francesco Donnarummab,
Giovanni Pezzulob, Alberto Coriglianoa
aDepartment of Civil and Environmental Engineering, Politecnico di Milano, Milan, 20133, Italy
bInstitute of Cognitive Sciences and Technologies, National Research Council, Rome, 00185, Italy
cMOX – Department of Mathematics, Politecnico di Milano, Milan, 20133, Italy
Abstract
Digital twins are transforming engineering and applied sciences by enabling real-time monitoring,
simulation, and predictive analysis of physical systems and processes. However, conventional dig-
ital twins rely primarily on passive data assimilation, which limits their adaptability in uncertain
and dynamic environments. This paper introduces the active digital twin paradigm, based on
active inference. Active inference is a neuroscience-inspired, Bayesian framework for probabilistic
reasoning and predictive modeling that unifies inference, decision-making, and learning under a
unique, freeenergyminimizationobjective. Byformulatingtheevolutionoftheactivedigitaltwin
asapartiallyobservableMarkovdecisionprocess,theactiveinferenceagentcontinuouslyrefinesits
generativemodelthroughBayesianupdatesandforecastsfuturestatesandobservations. Decision-
making emerges from an optimization process that balances pragmatic exploitation (maximizing
goal-directedutility)andepistemicexplorationorinformationgain(activelyresolvinguncertainty).
Actions are dynamically planned to minimize expected free energy, which quantifies both the di-
vergencebetweenpredictedandpreferredfutureobservations, andtheepistemicvalueofexpected
informationgainabouthiddenstates. Thisapproachenablesanewlevelofautonomyandresilience
in digital twins, offering superior spontaneous exploration capabilities. The proposed framework
is assessed on the health monitoring and predictive maintenance of a railway bridge.
Keywords: Digital twins, Active inference, Free energy principle, Structural health monitoring.
1. Introduction
Overthepastdecade,thedigitaltwin(DT)paradigmhasemergedasatransformativeapproach
for monitoring, control, and decision support, enabling diagnostic and predictive capabilities that
surpass those of traditional computational models. As outlined in the 2024 report by the National
Academies of Engineering, Science, and Medicine [1], DTs differ from both forward digital models
and digital shadows [2]. The former are designed to simulate how input parameters and internal
states influence system behavior to generate observable outputs, while the latter focus on data
assimilation and model updating. A DT is a tailored virtual representation that captures key
attributesofaphysicalsystemorprocess[3]. Thisdigitalrepresentationdynamicallysynchronizes
with its physical counterpart by continuously assimilating sensor data and providing predictive
capabilities. Specifically, DTs enable the simulation of what-if scenarios, supporting predictive
decision-making aimed at maximizing utility. This paper proposes active inference (AIF) [4] as
a new paradigm for DTs. By modeling the twin’s evolution as a partially observable Markov
decisionprocess(POMDP)[5],theAIFagentachievesintelligentautomationunderthefree-energy
principle [6, 7]. This results in a unified mathematical framework for a new class of active digital
twins (ADT), equipped with spontaneous exploration capabilities.
Email address: matteo.torzoni@polimi.it(MatteoTorzoni)
1
Emerging from aeronautical and aerospace engineering [8, 9], DT applications nowadays ex-
pand across several domains. These include structural health monitoring and predictive main-
tenance [10–12], additive manufacturing [13], smart cities [14], energy transition [15], urban sus-
tainability[16],geotechnicalengineering[17],subductionzonemodeling[18],railwayinfrastructure
management[19],aerialvehiclesmonitoringandcontrol[20,21],spacecraftoperationsinorbit[22],
personalizedmedicine[23,24], andclimate science[25]. DespitethegrowinginterestinDTs, their
implementation remains highly customized, typically tailored on the specific application, and of-
ten hard to deploy. The need for a widely accepted framework for DTs is therefore increasingly
recognizedinbothresearchandindustry. In[26], Kapteynetal. proposedanapplication-agnostic
formulation for describing coupled physical-digital systems that evolve dynamically over time and
interactviaobserveddataandcontrolinputs. Akeycontributionoftheirworkistheabstractionof
thecoupleddynamicalsystemintoageneralizedrepresentation,whichservesasthefoundationfor
amathematicaldescriptionofDTs. Thisabstractionisconsistentwithagent-basedrepresentations
in POMDPs, typically formalized using probabilistic graphical models [27].
We introduce ADTs with enhanced exploratory capabilities, employing AIF agents based on
discrete generative models to leverage and significantly extend the abstraction of physical-digital
systems by Kapteyn et al. [26]. Active inference is a theoretical framework integrating perception,
decision-making,andlearningwithintheunifiedobjectiveoffree energy minimization [4]. AnAIF
agentmaintainsaninternalgenerativemodelofitsenvironment,continuouslyupdatingitsbeliefsin
responsetosensoryinputs. Byminimizingvariationalfreeenergy,theagentsimultaneouslyfulfills
two objectives: reducing the divergence between predicted and preferred future observations, and
resolvingexpecteduncertaintyabouthiddenstatesthroughaction. Thisdualmechanismnaturally
balances exploitation of existing knowledge to achieve specific goals with exploration, i.e., the
acquisition of new information. These two imperatives can be referred to using interchangeable
terminology. Theexploitativeorpragmaticbehaviorisassociatedwithtermssuchasgoal-directed
behavior or utility maximization, while the exploratory or epistemic behavior is described using
termssuchasinformationseeking,informationgain,oruncertaintyresolution. TheAIFframework
has been applied in diverse domains, from neuroscience [28–32] – for modeling decision-making
underuncertainty–toreinforcementlearning[33,34],collectivebehavior[35,36],androbotics[37–
40], demonstrating its versatility in modeling dynamic systems.
The generative model of an AIF agent functions as a self-updating engine that unifies the key
aspects underpinning ADTs – namely, data assimilation, state estimation, prediction, planning,
and learning – under a Bayesian framework that generalizes across applications. Furthermore, as
demonstratedinthefollowingsections,AIFagentsnaturallyprovideamechanismforactiveinfor-
mation seeking, thereby unlocking the full potential of ADTs. When combined with goal-directed
(pragmatic) behavior and possibly enhanced with learning capabilities, this information-seeking
(epistemic) drive enables ADTs to engage in spontaneous exploration in response to (potentially
critical) uncertainty, ultimately maximizing pragmatic utility.
The limitations of conventional DTs, which are typically restricted to passive observation and
open-loopsimulation,havealreadybeenrecognizedin[41],althoughthechallengeofactivelyseek-
ing information to enhance perception or learning remains largely unaddressed. Similar problems
have long been studied in fields such as active vision, where perception is not limited to pas-
sively acquired images, but involves actively steering the sensing process to resolve uncertainty
abouttheenvironment[42,43]. Likewise,roboticsystemsdynamicallyadjusttheirsensingdevices
to enhance environmental exploration [44, 45], as seen in simultaneous localization and mapping
(SLAM) tasks [46]. Similar perception mechanisms are embedded in autonomous driving systems,
where view and sensor attention can be dynamically adjusted based on environmental conditions
and contextual priorities [47]. In the same spirit, pan-tilt-zoom cameras can actively track ob-
jects or events of interest in real time for surveillance purposes [48]. Active digital twins rely on
2
the analogous principle of closing the loop between perception and action, enabling them to au-
tonomouslyimprovesituationalawareness,refinetheirinternalmodelsthroughactiveexploration,
and proactively manage the environment evolution.
Compared to alternative approaches for developing DTs, AIF offers remarkable advantages.
Unlike reinforcement learning, which relies on trial-and-error exploration (often infeasible in real-
world applications) and typically requires extensive datasets, AIF enables ADTs to infer hidden
states and optimize future behavior using a compact generative model. Moreover, the free energy
minimization imperative of AIF balances information-seeking (epistemic) and goal-directed (prag-
matic) behaviors, without the need for manually tuned reward functions or random exploration.
These features make AIF particularly well-suited for adaptive and robust ADTs.
We present the ADT paradigm through an application in structural health monitoring and
predictive maintenance of engineering structures. Given the potentially high life-cycle costs – eco-
nomic, social, and safety – associated with such systems, adopting a DT perspective is crucial to
enablecondition-basedorpredictivemaintenancepractices,replacingtraditionallyemployedtime-
based methods [49, 50]. To this end, non-destructive tests and in-situ inspections are inadequate
for continuous and global monitoring. Conversely, by assimilating sensor data from permanent
datacollectionsystems,vibration-basedstructuralhealthmonitoringtechniquesenableautomated
damageidentificationandevolutiontracking[51,52]. Thisparadigmshifthasthepotentialtoun-
lockpersonalizedmonitoring, management, andmaintenanceprograms[53,54], offeringnumerous
benefits throughout the system life-cycle – including more informed structural safety assessments,
better resource allocation, and increased system availability [55].
A graphical abstraction of the computational flow is illustrated in Fig. 1. The end-to-end
loop spans from the physical to the digital domain through data assimilation and inference, and
then back to the asset through action and observation, while explicitly accounting for uncertainty
quantification, propagation, and resolution. We refer to the monitored asset, whose physical state
ishiddento theAIFagent andonlyindirectlyaccessiblevia thesensedstructuralresponse, asthe
external generative process. Theassetstateevolvesovertimeaccordingtophysicallawsinfluenced
by both its internal properties and external factors. These external factors might encompass long-
termdegradationmechanismscausedbychemical,physical,ormechanicalaging,aswellassudden
changes, such as discrete damage events or maintenance interventions [56].
The digital counterpart (AIF agent) is defined by an internal generative model, implemented
as a probabilistic graphical model in the form of a dynamic Bayesian network (DBN) [5, 27].
This factored representation provides a systematic way to maintain a posterior belief about latent
variables that characterize the (hidden) structural health of the asset, such as damage presence,
location, and severity, by continuously integrating new observations within a sequential Bayesian
inferencescheme. Beliefupdatingisachievedbyminimizingvariationalfreeenergy,whichmeasures
the discrepancy between the model’s predicted observations and the actual sensor data.
In parallel, the internal generative model supports the forward simulation of future. This
enables the ADT to evaluate “what-if” trajectories for structural health evolution, conditioned on
its current beliefs. This forecasting step involves modeling not only the asset’s physical dynamics
but also the agent’s control policies, represented as latent variables encoding sequences of future
actions, usually termed policies [57]. Policy selection is then framed as an optimization problem,
where the agent seeks to minimize the expected free energy – a quantity that balances (i) selecting
policies that align future observations with (pragmatic) goal-directed prior preferences, and (ii)
resolvinguncertaintyabouthiddenstatesthrough(epistemic)information-seeking. Thisformalism
unifies inference and control: posterior beliefs are updated via free energy minimization, while
actionsequencesareselectedtominimizeexpectedfreeenergy,convertingtheproblemofdecision-
making into a problem of inference under the generative model. Once an action is executed, the
generative process evolves, and the bidirectional perception-action cycle restarts.
3
onlinepolicyswitchinthecaseofrareevents.
Model-FormUncertainty. Furtherworkisneededtoaddress
concerns related to modeling assumptions. Despite efforts
to refine the structural model or employ more sophisticated
descriptionsforpotentialdamagepatterns,engineeringstruc-
turesmaybetoocomplexanduncertainsystemstobeperfectly
modeled. Uncertaintiesarisingfrommodelingchoices,envi-
ronmentalfactors,andoperationalvariabilitiesareamongthe
manyfactorsthatcanhinderthemodelcapabilitytofaithfully
describeareal-worldsystem. Intermsofmonitoring,properly
accounti8< n Mr r˙( ( 0 0gr) ) ¨r(= = t)W W + f> > Cd d˙ ro ( 0 0 µ , )r˙ r (t)+K mr(µ)r( o t)= d fr(t, e µ), l t -2f (0 o ,T) rm(2u3)ncertaintyiscrucialtoobtaina
reliaMbr⌘lWe>MWs :,oClru⌘Wt>Ci(µo)Wn, Ktro⌘W>Kt(µh)We, fpr(t,µa)⌘rW>af((t2,m4µ)). eteridentificationproblem. To
addressthiscu1(th) au2(lt)leu3n(t)gue4(t),latent(v25)ariablemodelsofferaninteresting
q(t) (26)
Activ p m c ae o n e i u r d s D s s l , d Ap 111 i 1234 012 56789 l :::: ::: ::::: g n o SS WF Ec r i e ao O N it ml R p h D v =g p o e m g j c C SS WSW l F f P e ao u O o = P O = µ ml ll j r O R v ll =n t D -e 2pe =[ o! D C c , W l tp r i f P e o t i o . i d u P e m O . S l p µe l l e l | O . l s a e W a r 1 v D ( - 1 , s t c r S D o m v N i= t a p tr o 1 ajt ms d o S er - ) i] a e[ e d d a e m me a j d r m e p e y t ( e ( =( i l m n D S t S r q a c0 so . ) O j d[ m , ddµ ) µ l i e( c e l 1 t ! u s 0 ) L , | e µ . µ s. j j . T ) e | | d a .i ( . to . n T n| t d , w µ (t e f1 T t ) s, ] µ l n j i i) y ] n i g t ,n f h v o o t s a r s f r m i i t n a h a b t t e o i l o e m t s n h , o c e a o n r n u i e t d l l o d ia e r b i b x n i a e l g m i l t e y p i v n r o e i o f r n c a g t e g h s t e e h s d . f e o i t r o r U w d a s i a c i s n r c t d o r g i u b m l n u a o t t t e i d f o n o e n r t l
via Avcartiiavbele FII Im ✓⇤ n::: === oFINno evfr uewd rrasa lerde npe ore top wbe olrera r lmk to a sr(pm(e p per a oarsx afum imrneeo amte tier o snntrs! t c o!I mdeseaosuugrahetmpeantrtasm)aeters)assi(27m) ilationpurposesPweorcuelpdtiroenq uoifr esensory inputs
theuseofapI✓p⇤=arr✓g 2 mo⇥in Xpjk(rI✓ iFa)(µtj)e µjkBayesia(28n) inferenceengines.Inthisregard,
Physical to digitathl:erecentadvancesinsimulation-basedinferencestandInafseraennce & belief updating:
Data assimilatioanppealingch ...oic ...e[ ...7]. ... Free ene 7. r C g r y an m me i r n et i a m l., i T z h a ef t r i o o nt n ierof
simulation-basedinference.2020
wFihgiulereb4lu:eSnchoedmeseroeffetrhetoNthNetLuFnfaubllley-pcaornanmeectteerds.model:rednodesdenotetheinput/outputquantities, 8 ExpeAcrknoiwmledgmeentsntal Data. A last aspect that should be explored
Physical space conc TfeohrisSwtrruocr n ktuirsals s uHpepaolrtt thedMh ionnpita eortribnyg”t u haetiPnos telirtdee icsnciipcoli o ndairMy f Pilha.nDoa ..Gr v ant“ a Phy i sic l s-I a nform b edD l e e epLea e rnin x g perimentalrecordingstoimprove Digitalspace
(generative proce t s h s e ) reliabilityofd8ataassimilationmodels. Tobridgethedata-to- (generative model)
methodologygapforsupervisedlearningtasks,weenvisionthe
applicationofmulti-fidelitymethodsatthefeaturelevelasan
opportunitytoadvancecurrentstrategiesinpopulation-based
[8,9] and domain adaptation [10,11,12] for structural health 8.Bulletal.,Foundationsof
population-basedSHM,PartI: monitoring. For example, experimental data from existing Homogeneouspopulationsand structurescouldbeintegratedwithsyntheticdatafromphysics- forms.2021
basedmodelsviamulti-fidelityinformationfusiontoestablish 9.Gardneretal.,Foundations ofpopulation-basedSHM,Part
sharedfeaturespacesunaffectedbylabelinconsistencies. III:Heterogeneouspopulations–
Policy selection for lowest surprise: Mappingandtransfer.2021 Digital to physical: Expected free energy minimization 10S.iGmiguliolnaiteetal.,Adomain
Action -Observation argmin ⌧   (1.1w) haadta-pitfat isocneapnparoraichotsodamage
( ) classificationwithanapplicationto   bridgemonitoring.2024
⌧   = Infogain Pragmaticvalue (1.2) 11.Wangetal.,Knowledgetransfer
( )     forstructuraldamagedetection
throughre-weightedadversarial
domainadaptation.2022
12.Pooleetal.,Onstatisticalign-
mentfordomainadaptationin
structuralhealthmonitoring.2023
8 1 C￿￿￿￿￿￿￿￿￿￿￿￿￿O￿￿￿￿￿￿
.................................................................. royalsocietypublishing.org/journal/rspaProcRSocA0000000
29
c
G
⇡
Ut 1 Ut
Dtc B Dt B Dtp
A A
Ot Otp
Figure3:DynamicBayesiannetworkencodingtheactiveinferencegenerativemodelusedto predictfuturedigitalstatesandobservationsundereachpolicy.Circularnodesrepresentrandom
variables,whilethediamond-shapednodedenotespriorpreferencesthatreflectapragmatic
objective.Graysquarenodesrepresentparametrizedoperatorsofthegenerativemodel.Directed edgesencodeconditionaldependenciesbetweenvariables.
policybyincorporatingbothgoal-directedanduncertainty-resolvingcomponents,asexplained
inSec.3(c).Finally,theinitialpriorp(Dtc; )istypicallyrepresentedbyanunconditionalCPT
denotedasd: [0,1]. D7!
Alsographically,thegenerativemodelillustratedinFig.3presentsseveraldifferences comparedtotheDBNinFig.2.Thisformulationfocusesonsampling(orgenerating)sequencesof
potentialobservationsOtc:tpandpredictingfuturedigitalstatesDtc:tpbasedontheprobabilistic
structureencodedinAandB,conditionedoncontrolactionsUtc:tpthathavenotyetbeen
executed.Accordingly,actionsUtaremodeledas(circular)randomvariablesratherthan(square) decisionnodes,astheyrepresenthypotheticalwhat-ifscenariosbeyonddataassimilation.
Moreover,sincecontrolstatesaredeterminedbyfeasiblepolicies⇡definedapriori,thesame colorisusedtorepresentbothdigitalstatesandcontrolpoliciesinthegraph,asbotharelatent
variablesofthegenerativemodel.Equippedwiththisgenerativemodel–specifiedbythefour-
tuple
h
A,B,c,d
i
–AIFinvolvesperforminginferenceoverDt,⇡,and ,asdescribedinthe
followingsections.
(b)Digitalstateinferenceviavariationalfreeenergyminimization
G po iv st e e n ri a o n rd ob is s t e r r ib v u at t i i o o n n O p( t D c t = c o | O E tc x t p c , = th o e E t u c x n p) d , e u r s ly in in g g B d a i y g e i s ta ’ l R s u ta le te : Dtccanbeinferredbyestimatinga
p(Dtc| Otc=oE tc xp)= p(o p E t ( c x o p E tc , x D p) tc) = p(oE tc xp p | ( D oE t t c x c p ) ) p(Dtc) , (3.2)
.................................................................. royalsocietypublishing.org/journal/rspa
ProcRSocA0000000
St Stc
Ot Exp Utc  1 Ot E c xp
Ot Otp
A A A A
Dtc  1 B Dtc B Dt B Dtp
Utc Utc+1
⇡
G
c
Digitalstateinference Policyinference
| {z }| {z }
ecapslacisyhP
ecapslatigiD
)ssecorpevitareneG(
)ledomevitareneG(
29
Figure7
70.AvciO,AbdeljaberO,KiranyazS,HusseinM,GabboujM,InmanD.2021Areviewof
vibration-baseddamagedetectionincivilstructures:FromtraditionalmethodstoMachine
LearningandDeepLearningapplications.MechanicalSystemsandSignalProcessing147,
107077.(10.1016/j.ymssp.2020.107077)
71.FinkO,WangQ,SvensenM,DersinP,LeeWJ,DucoffeM.2020Potential,Challengesand
FutureDirectionsforDeepLearninginPrognosticsandHealthManagementApplications.
EngineeringApplicationsofArtificialIntelligence92,103678.(10.1016/j.engappai.2020.103678) 72.CholletFetal..2015Keras.https://keras.io.
73.TorzoniM.2025DT-Active,github.https://github.com/MatteoTorzy/DT-Active.
.................................................................. royalsocietypublishing.org/journal/rspaProcRSocA0000000 St Stc
Ot Exp Utc  1 Ot E c xp
Ot Otp
A A A A
Dtc  1 B Dtc B Dt B Dtp
Utc Utc+1
⇡
G
c
Digitalstateinference Policyinference
| {z }| {z }
ecapslacisyhP
ecapslatigiD
)ssecorpevitareneG(
)ledomevitareneG(
29
Figure7
70.AvciO,AbdeljaberO,KiranyazS,HusseinM,GabboujM,InmanD.2021Areviewof
vibration-baseddamagedetectionincivilstructures:FromtraditionalmethodstoMachine
LearningandDeepLearningapplications.MechanicalSystemsandSignalProcessing147, 107077.(10.1016/j.ymssp.2020.107077)
71.FinkO,WangQ,SvensenM,DersinP,LeeWJ,DucoffeM.2020Potential,Challengesand
FutureDirectionsforDeepLearninginPrognosticsandHealthManagementApplications.
EngineeringApplicationsofArtificialIntelligence92,103678.(10.1016/j.engappai.2020.103678)
72.CholletFetal..2015Keras.https://keras.io.
73.TorzoniM.2025DT-Active,github.https://github.com/MatteoTorzy/DT-Active.
.................................................................. royalsocietypublishing.org/journal/rspaProcRSocA0000000
St Stc
Ot Exp Utc  1 Ot E c xp
Ot Otp
A A A A
Dtc  1 B Dtc B Dt B Dtp
Utc Utc+1
⇡
G
c
Digitalstateinference Policyinference
| {z }| {z }
ecapslacisyhP
ecapslatigiD
)ssecorpevitareneG(
)ledomevitareneG(
29
Figure7
70.AvciO,AbdeljaberO,KiranyazS,HusseinM,GabboujM,InmanD.2021Areviewof
vibration-baseddamagedetectionincivilstructures:FromtraditionalmethodstoMachine
LearningandDeepLearningapplications.MechanicalSystemsandSignalProcessing147,
107077.(10.1016/j.ymssp.2020.107077)
71.FinkO,WangQ,SvensenM,DersinP,LeeWJ,DucoffeM.2020Potential,Challengesand
FutureDirectionsforDeepLearninginPrognosticsandHealthManagementApplications.
EngineeringApplicationsofArtificialIntelligence92,103678.(10.1016/j.engappai.2020.103678)
72.CholletFetal..2015Keras.https://keras.io.
73.TorzoniM.2025DT-Active,github.https://github.com/MatteoTorzy/DT-Active.
.................................................................. royalsocietypublishing.org/journal/rspa
ProcRSocA0000000
St Stc
Ot Exp Utc  1 Ot E c xp
Ot Otp
A A A A
Dtc  1 B Dtc B Dt B Dtp
Utc Utc+1
⇡
G
c
Digitalstateinference Policyinference
| {z }| {z }
ecapslacisyhP
ecapslatigiD
)ssecorpevitareneG(
)ledomevitareneG(
Figure1: Activedigitaltwinsviaactiveinference–Graphicalabstractionoftheend-to-endinformationflow. The
dichotomybetweentheexternalphysicalprocessgeneratingobservationaldata(i.e.,thegenerativeprocess)andthe
agent’s internal model (i.e., the generative model) is evident by the symmetry along the vertical axis. Meanwhile,
thetwoformsofinference–digitalstateestimationandpolicyselection–exhibitasymmetryalongthehorizontal
axis. AdetailedschematicofgenerativemodelsforbothdigitalstateandpolicyinferenceispresentedinFig.4.
The paper is organized as follows. Section 2 describes the POMDP that encodes the coupled
dynamics of the physical-digital system. Section 3 illustrates the use of AIF agents to realize
ADTs. Section 4 assesses the proposed procedure on the simulated monitoring, management, and maintenance of a railway bridge, providing comparative results for different AIF agents featuring
increasingly rich behavior. CoFnigucrleu7sions and future developments are finally outlined in Sec. 5.
70.AvciO,AbdeljaberO,KiranyazS,HusseinM,GabboujM,InmanD.2021Areviewof
2. Pavribtraitaionl-lbyasedodbamseagrevdeatebctiloeninMcivailrstkruoctuvres:dFerocmitsraidoitinonaplmreothcodesstosMfacohrinedigital twins
LearningandDeepLearningapplications.MechanicalSystemsandSignalProcessing147,
107077.(10.1016/j.ymssp.2020.107077)
F71i.gFiunkreO,W2anigllQu,sSvternasetneMs,DtehrseinPp,rLeoebWaJ,bDiulciosftfeicM.g20r2a0pPohteinctiaal,lCmhalloendgeeslan–d adapted from [26] – that represents
FutureDirectionsforDeepLearninginPrognosticsandHealthManagementApplications.
the dyEnngainmeeriincgAipnplticeatrioanscotfAiortnificiablIenttewlligeenecne92t ,1 h 03 e 678 p .( h 10 y .1 s 0 i 1 c 6/ a j.e l ng a a n pp d ai.2 v 02 i 0 r .1 t 0 u 36 a 78 l ) domains. This abstraction is inspired
72.CholletFetal..2015Keras.https://keras.io.
73.TorzoniM.2025DT-Active,github.https://github.com/MatteoTorzy/DT-Active.
by classical POMDP formulations [5]. POMDPs are state-space models for decision-making in
stochastic, partially observable environments, where system dynamics are typically described by
Markov transition models. Unlike standard Markov decision processes, where a policy directly
maps observable states to actions, POMDPs define the policy as a mapping from belief states –
probabilistic representations of hidden states inferred from observations – to actions.
ThegraphinFig. 2isaDBN,inwhichcircularnodesrepresentrandomvariables,squarenodes
denote taken actions, and diamond-shaped nodes symbolize the objective function. All variables
are defined at discrete time steps. Each time the DT is updated through the assimilation of new
observationaldata,theDBNadvancesbyonetimestep,witht 0,...,T ,wheret=0marksthe
∈{ }
moment the DT enters operation, and t=T defines its lifetime horizon. Nodes with bold outlines
indicate observed quantities, while those with thin outlines correspond to latent variables that
must be inferred. The DBN is sparsely connected, with edges encoding conditional dependencies
amongthevariables. ForanoverviewofthefundamentalsofDBNs,thereaderisreferredto[5,27].
Capital letters denote random variables associated with the quantities in our abstraction, the
correspondinglowercaselettersrefertotheirspecificrealizations,andsubscriptsindicatetheirtime
4
S S S
0 1 2
O 0 Exp U 0 O 1 Exp U 1 O 2 Exp U 2
R R R
0 1 2
D D D
0 1 2
t=0 t=1 t=2
| | |
ecaps
lacisyhP
ecaps
latigiD
Figure2: DynamicBayesiannetworkencodingtheasset-twindynamicalsystem. Circularnodesrepresentrandom
variables, square nodes denote taken actions, and diamond-shaped nodes symbolize the objective function. Nodes
with bold outlines indicate observed quantities, while those with thin outlines represent latent variables to be
inferred. Directededgesencodeconditionaldependenciesbetweenvariables.
index. Calligraphiclettersdenotethesetofpossiblevalueseachquantitycanassume. Forinstance,
the hidden physical state is denoted as S p(s ), where s represents a particular realization at
t t t
∼
time t, and p(s ) defines the probability that S =s for any possible state s .
t t t t
∈S
ThedigitalstateD p(d )isdesignedtocapturetheessentialfeaturesofthe(hidden)physical
t t
∼
state that are relevant for diagnosis, prediction, and decision-making [3]. The digital state space
can represent a variety of information, including initial and/or boundary conditions, material
D
properties, and other key characteristics to describe the asset under consideration.
The physical-to-digital information flow from S to D is mediated by the assimilation of ob-
t t
servational data O p(o ), enabling the inference of D . The observation space may include
t t t
∼ O
sensor measurements, inspection results, or diagnostic reports. Since the physical state S is only
t
partially and indirectly observable, the digital state D encodes posterior beliefs over possible sys-
t
temconfigurationsattimet,reflectingtheevidenceprovidedbytheavailableobservations[58,59].
Thisperceptualprocessisrealizedthroughobservationmodels–oneforeachobservationmodality
– which relate digital states and observations in a probabilistic manner, such that O is modeled
t
as stochastically generated from D . Throughout the paper, we will use both O and OExp to
t t t
representobservations: O referstopredicted(expected)observationsunderthegenerativemodel,
t
while OExp denotes actual sensor data. Belief updates are driven by minimizing the discrepancy
t
between predicted and actual observations.
The updated digital state D informs the digital-to-physical information flow by guiding the
t
selection of control actions to influence future physical states. In Fig. 2, U p(u ) denotes a
t t
∼
decisionvariablerepresentingtheactiontaken. Theactionspace mayincludeinterventionsthat
U
directly modify the physical state, adjustments to the operational conditions, or modifications to
the observational process. Each action is associated with its own transition model – one for each
digital state factor – across the digital state space, which serves as a control-dependent predictor
that propagates the digital state beliefs forward in time.
Finally, the reward node R p(r ) quantifies the performance of the asset-twin system within
t t
∼
arewardspace . Theserewardsassesstheexpected“quality”ofDBNtrajectoriestoguideaction
R
selection toward optimal outcomes. In general, reward values may represent real costs associated
withstatesandactions,orabstractmetricstunedtosteerthesystemtowardthedesiredbehavior.
Formally, a POMDP can be defined as a seven-tuple , , , ,A,B,ϕ , where: denotes
⟨D O U R ⟩ D
the space of beliefs over hidden states; is the space of possible observations; is the space of
O U
5
available actions; : R defines the reward function, which assigns a numerical value
R D×U (cid:55)→
to beliefs-action pairs; A : [0,1] is the observation model, encoding the conditional
O ×D (cid:55)→
observation likelihood p(O D ;ϕ), which represents beliefs about how hidden states give rise to
t t
|
observations; B: [0,1] is the transition model, encoding the conditional probability
D×D×U (cid:55)→
p(D D ,U ;ϕ), which represents beliefs about the temporal evolution of hidden states
t t 1 t 1
| − −
conditioned on control actions; finally, ϕ is a vector of hyperparameters of the POMDP model.
In the following, we assume that digital states, observational data, and control actions are
defined over discrete and finite spaces. This implies that these variables can only take value on
a finite set of discrete levels. Consequently, categorical distributions give a natural choice for
representing the corresponding probability distributions. These latter assign a probability value
between 0 and 1 to each discrete outcome, under the constraint that probabilities across all levels
must sum to one, as they represent a complete and mutually exclusive set of realizations.
Thejointprobabilitydistributionp(O ,D ,U ,R ,ϕ)overthePOMDPfactorizes–accordingto
t t t t
the chain rule of probability – into a product of categorical distributions (representing conditional
likelihoods)andDirichletdistributions(servingaspriors). Numerically,thesediscretedistributions
are organized as multidimensional arrays known as conditional probability tables (CPTs). The
leading dimensions (rows) of a CPT correspond to the support of the random variable, while
the lagging dimensions (columns) represent the conditioning variables. Each column specifies the
probability distribution of a random variable given a particular configuration of its parent nodes,
and the entries within each column sum to one, as they represent a complete set of mutually
exclusive and exhaustive outcomes. If a node has no parents, its CPT reduces to a single column
representing the prior probabilities of its possible values. The contents of these CPTs can be
controlled through the hyperparameters included in ϕ.
The complete set of possible realizations of the unobserved variables – conditioned on observa-
tional data OExp =oExp and control actions U =u – from the initial time step t=0 up to
0:tc 0:tc 0:tc 0:tc
thecurrenttimet ,witht=0,...,t ,canbeextractedbyleveragingtheconditionalindependence
c c
assumptions implied by the graphstructure inFig. 2. The jointbeliefstate canthen befactorized
according to the following sequential Bayesian inference formulation:
p(D ,R ,ϕ OExp =oExp,U =u )=
0:tc 0:tc | 0:tc 0:tc 0:tc 0:tc
tc tc (1)
p(ϕ)p(D ;ϕ) p(D D ,u ;ϕ) p(oExp D ;ϕ)p(R D ,u ).
0 t | t − 1 t − 1 t | t t | t t
t=1 t=0
(cid:89) (cid:89)
In Eq. (1), the term p(ϕ) represents the prior distribution over the hyperparameters ϕ; inference
over them typically evolves on a slower timescale than the inference of hidden states and control
actions. p(D ;ϕ)denotesthepriorovertheinitialhiddenstates,representingthedigitalstatebelief
0
at t = 0, before any observation is incorporated. The term p(oExp D ;ϕ) represents the sensory
t | t
likelihood encoded in A. Similarly, p(D D ,u ;ϕ) defines the transition likelihood encoded
t t 1 t 1
| − −
inB. Finally,p(R D ,u )representsthelikelihoodofreceivingagivenreward,encapsulatingthe
t t t
|
objective function evaluation. Note that selecting actions U =u underpins solving the planning
t t
problem induced by the probabilistic graphical model. After forming a belief that measures the
desirabilityofactions,suchasp(U D ),theactualactioncanbeselectedeitherasthebest-point
t t
|
estimate or by sampling from this posterior, converting probabilistic control into a decision.
3. Active inference for digital twins
An attractive feature of AIF is that perception, learning, and action emerge as distinct man-
ifestations of variational Bayesian inference [4]. Perception, or state estimation, is accomplished
throughinferenceoverdynamicallyevolvinghiddenstates,conditionedonassimilatedobservations
and past actions. Learning corresponds to the gradual inference of hyperparameters that capture
6
the statistical regularities of the environment. Action, in turn, is realized by inferring a posterior
distribution over policies and sampling actions accordingly.
In the following, we describe the use of AIF agents to “navigate” the POMDP underlying
the DT problem, enabling the full potential of ADTs. Section 3.1 introduces the AIF generative
model,whichencodestheprobabilisticassumptionsabouttheunderlyingenvironment. Section3.2
addressesdigitalstateinference via variationalfreeenergyminimization. Section3.3covers policy
inferenceandactionselectionthroughexpectedfreeenergyminimization. Section3.4describesthe
slow-scale learning of the hyperparameters that define the AIF generative model. Finally, Sec. 3.5
discusses the active information-seeking (epistemic) behavior that characterizes ADTs.
3.1. Active inference generative model
InAIF,thesetofprobabilisticassumptionsabouthowtheenvironment(orgenerative process)
produces observations (via the observation model A) and how actions influence the environment
evolution(viathetransitionmodelB)isreferredtoasthePOMDPgenerativemodel. Thismodel
is used to represent the joint distribution in Eq. (1), from current time t to a prediction horizon
c
t > t . Specifically, for time- and space-discretized POMDPs, probabilistic estimates of future
p c
digital states and observations over the prediction time steps t=t ,...,t are computed as:
c p
tp tp
p(O ,D ,ϕ π)=p(ϕ)p(D ;ϕ) p(D D ,π;ϕ) p(O D ;ϕ), (2)
tc:tp tc:tp
|
tc t
|
t
−
1 t
|
t
t=
(cid:89)
tc+1 t
(cid:89)
=tc
whichreflectsunrollingtheAIFgenerativemodelofFig. 3overt=t ,...,t . ComparedtoEq. (1),
c p
the factorization in Eq. (2) introduces several modifications to align with the AIF framework.
First, the control variable U is replaced by a policy π, defined as a sequence of control states
π = u ,...,u . The generative model in Eq. (2) is conditioned on a fixed policy π, which is
{
tc tp}
how it is used for inference purposes. Policies are treated as latent variables to be inferred: the
posterior over policies represents the agent beliefs about its intended actions, while single actions
are realizations sampled from the posterior over control states. The policy-to-control mapping
p(U π) assigns the control state at each time-step based on the selected policy.
t
|
The second modification concerns the omission of the reward variable R. In AIF, utility-
maximization goals are encoded as a prior distribution p(O ) over future observations. These
tc:tp
preferencesarespecifiedthroughanunconditionalCPTc: [0,1]. Suchpriorpreferencesguide
O (cid:55)→
policyselectiontowardgoal-directed(pragmatic)behavio(cid:101)rbyfavoringactionsexpectedtoproduce
preferredobservations. Thisformalequivalencebetweenrewardsandpriorseliminatestheneedfor
explicit cost functions. Further, it enables optimal control to be cast as an inference problem: the
jointprobabilityofobservations, digitalstates, controlstates, andmodelparametersismaximized
when the system samples from preferred observations. The square node G in the graph represents
the expected free energy, which quantifies the desirability of each policy by incorporating both
pragmatic and information-seeking (epistemic) components, as explained in Sec. 3.3. Finally, the
initial prior p(D ;ϕ) is typically represented by an unconditional CPT denoted as d: [0,1].
tc
D (cid:55)→
Graphically,thegenerativemodelillustratedinFig. 3showsseveraldifferencescomparedtothe
DBNinFig. 2. ThisformulationfocusesonpredictingfuturedigitalstatesD andsampling(or
tc:tp
generating)sequencesofpotentialobservationsO basedontheprobabilisticstructureencoded
tc:tp
in A and B, conditioned on control actions U that have not yet been executed. Accordingly,
tc:tp
actions U are modeled as (circular) random variables rather than (square) decision nodes, since
t
they represent what-if scenarios beyond data assimilation. Moreover, the same color is used to
represent both digital states and control policies in the graph, as both are latent variables of the
generative model. Equipped with this generative model – specified by the four-tuple A,B,c,d
⟨ ⟩
– AIF supports the inference over D , π, and ϕ, as described in the following sections.
t
7
c
G
π
U U
t 1 t
−
D tc B D t B D tp
A A
O t O tp
Figure3: DynamicBayesiannetworkencodingtheactiveinferencegenerativemodelusedtopredictfuturedigital
states and observations under each policy. Circular nodes represent random variables, while the diamond-shaped
node denotes prior preferences that reflect a goal-directed (pragmatic) objective. Gray square nodes represent
parametrizedoperatorsofthegenerativemodel. Directededgesencodeconditionaldependenciesbetweenvariables.
3.2. Digital state inference via variational free energy minimization
GivenanobservationOExp =oExp,theunderlyingdigitalstateD canbeinferredbyestimat-
tc tc tc
ing a posterior distribution p(D OExp =oExp), using Bayes’ Rule:
tc | tc tc
p(oExp,D ) p(oExp D )p(D )
p(D OExp =oExp)= tc tc = tc | tc tc , (3)
tc | tc tc p(oExp) p(oExp,D =d )
tc dtc∈D tc tc tc
(cid:80)
where the (generative model) joint distribution p(oExp,D ) is factorized into a likelihood term
tc tc
p(oExp D ) and a prior p(D ). The denominator p(oExp) is the marginal likelihood or model
tc | tc tc tc
evidence, which captures the probability of observing OExp =oExp under the generative model.
tc tc
Since Bayesian inversion to estimate hidden states from observations is generally intractable,
AIF employs variational inference [60] as an approximate Bayesian method, trading exactness for
computational tractability. Specifically, we define a tractable variational distribution
Q(D ;θ): [0,1], parametrized by θ, and optimize this surrogate distribution to make it
tc
D (cid:55)→
as close as possible to the true posterior p(D OExp = oExp). In our discrete POMDP setting,
tc | tc tc
thevariationalparametersθ correspondtotherelativefrequenciesofeachcategoryinthesupport
of a random variable. This leads to the following optimization problem:
θ∗ =argmin D
KL
Q(D
tc
;θ)
||
p(D
tc |
oE
tc
xp) , (4)
θ
(cid:104) (cid:105)
where D [Q(X) P(X Y)] = E [lnQ(X) lnP(X Y)] denotes the Kullback-Leibler (KL)
KL Q
|| | − |
divergence between the approximate posterior Q(X) and the true posterior P(X Y), for two
|
generic random variables X and Y. Here, E denotes the expectation with respect to the vari-
Q
ational posterior. However, this objective remains intractable because it depends on the true
posterior p(D oExp) that we seek to approximate. To circumvent this, we reformulate the
tc | tc
8
objective as the variational free energy (VFE):
(θ)=D Q(D ;θ) p(D oExp) lnp(oExp)
F tc KL tc || tc | tc − tc
(cid:104) (cid:105)
Q(D ;θ)
= Q(D ;θ) ln tc lnp(oExp) (5)
(cid:88)D tc (cid:34) p(D tc | oE tc xp) − tc (cid:35)
=E lnQ(D ;θ) lnp(oExp,D ) ,
Q tc − tc tc
(cid:104) (cid:105)
which serves as an upper bound on the negative log marginal likelihood ( lnp(oExp)), also known
− tc
as the Bayesian surprise. Minimizing VFE thus brings the variational posterior closer to the true
posterior while simultaneously increasing the marginal likelihood of the observation. The VFE
objective leads to the following final form of the optimization problem:
θ∗ =argmin
F
tc
(θ). (6)
θ
Atconvergence,ifQ
∗
(D
tc
;θ∗)exactlymatchesthetrueposterior,theKLdivergencevanishes,i.e.,
D = 0, and the VFE equals surprise: = lnp(oExp). By further minimizing surprise, the
KL F tc − tc
VFE then provides a useful objective not only for inference but also for learning the parameters
of the generative model. The underlying rationale is that AIF agents aim to avoid surprising
observations, and minimizing surprise is equivalent to maximizing model evidence.
With reference to the generative model formulation (2), instantaneous inference over digital
states involves approximating the true posterior p(D OExp = oExp,D ,U = u ).
tc | tc tc tc− 1 tc− 1 tc− 1
This inference is conditioned on the current observation OExp = oExp, the previous (posterior)
tc tc
distribution over digital states D , and the previously executed action U =u , as:
tc− 1 tc− 1 tc− 1
θ∗ =argmin
F
tc
(θ)
θ
=arg
θ
min E Q lnQ(D tc ;θ) − lnp(oE tc xp,D tc | D tc− 1 ,u tc− 1 ;ϕ) (7)
(cid:104) (cid:105)
=argmin E lnQ(D ;θ) ln p(oExp D ;ϕ)p(D D ,u ;ϕ) .
θ
Q tc − tc | tc tc | tc− 1 tc− 1
(cid:104) (cid:16) (cid:17)(cid:105)
TheoptimizationprobleminEq. (7)issolvedusingfixed-pointiteration[61],undertheassump-
tionoftemporalfactorization,wherevariationalposteriorsatdifferenttimestepsareconditionally
independent. As a result, the full VFE across trajectories decomposes into a sum of single-time-
step free energies, enabling independent optimization at each time point. Moreover, the posterior
Q(D ;θ)atagiventimesteptcanbefurtherfactorizedacrossF independenthiddenstatefactors
t
D = D1,...,DF , following the mean-field approximation [62]:
{ }
F
Q(D ;θ)= Q(Df;θ), (8)
t t
f=1
(cid:89)
where Q(Df;θ) denotes the posterior over the fth hidden state factor, f =1,...,F.
t
These factors may represent distinct aspects of the generative process, potentially varying in
dimensionality, transition dynamics, and association with specific observation modalities. Simi-
larly, observations can be structured into M distinct modalities O = O1,...,OM , where each
{ }
Om,m=1,...,M,correspondstoaseparatesensorychannelusedbytheagentateachtimestep.
For example, in a DT application for the human health, one hidden state factor may represent a
patient’s metabolic state, while another factor could encode cardiovascular function. Correspond-
ingly, observation modalities may include blood glucose readings and heart rate measurements,
each providing information about different latent physiological processes.
Inthismulti-modal,multi-factorsetup,theobservationlikelihoodarrayAbecomesacollection
of M sub-arrays A = A1,...,AM , with each Am, m = 1,...,M, representing the observation
{ }
9
model for the mth modality. Each sub-array encodes the likelihood p(Om D1,...,DF;ϕ), cap-
|
turing the dependency of that observation modality on the hidden state factors. Similarly, the
transition model B is represented as a collection of F sub-arrays B = B1,...,BF , under the
{ }
assumption that hidden state factors evolve independently without influencing each other. Each
Bf, f = 1,...,F, encodes the dynamics p(Df Df ,uf ;ϕ), conditioned on the previous state
t | t − 1 t − 1
and action for that factor. Note that control states are factorized analogously to hidden states,
such that U = U1,...,UF . Each control factor Uf governs the transitions of the corresponding
{ }
digital state factor Df, with a dimensionality matching the number of possible control actions
applicable to that aspect of the system.
This factored structure enables the encoding of complex conditional dependencies while signif-
icantly reducing memory requirements. For instance, if the model employs two separate hidden
statefactorstorepresentthelocationandidentityofaphenomenon,thememoryrequirementsfor
thefactoredrepresentationscalelinearlywiththedimensionalityofthetwofactors. Anadditional
advantage of this factorization lies in its interpretability: by explicitly designing digital state fac-
tors to reflect intuitive features of the environment, the resulting generative model becomes more
transparentandmodular. Incontrast,explicitlyenumeratingallpossiblecombinationsof“where”
and “what” would incur polynomial memory complexity.
The marginal variational posteriors for each hidden state factor at the current time t are
c
computed analytically via mean-field fixed-point iteration [61]. The algorithm proceeds by setting
the gradient of the VFE (θ) to zero, and iteratively solving for each factorized component
F
tc
Q(Df ;θ), for f =1,...,F. A detailed derivation of this procedure can be found in [63].
tc
NotethatintheAIFframework,thereisnoneedtointroduceanexplicitnodeforrepresenting
quantities of interest, unlike the abstraction of physical-digital systems proposed in [26]. In their
probabilistic graphical model, these variables are represented by a dedicated node and predicted
fromtheupdateddigitalstateviathecomputationalmodelscomprisingtheDT.Incontrast,under
the AIF framework, such a node is redundant, as quantities of interest are naturally embedded
within the observational data node. When observational evidence is unavailable for a particular
modality, inference simply remains uninformed in that dimension of the observation space. Never-
theless,theupdateddigitalstatecanstillbeusedtopredictexpectedvaluesacrossanyobservation
channel–whetherobservedorunobserved–viathecorrespondingobservationmodel. Themodels
may, in principle, incorporate arbitrarily complex forward mappings, ranging from high-fidelity
physics-based simulators to purely data-driven surrogates or hybrid combinations of the two.
3.3. Policy inference-action selection via expected free energy minimization
Given the updated variational posterior over the digital state Q
∗
(D
tc
;θ∗), policy inference
involvesevaluatingthequalityofeachadmissiblepolicycomprisingfutureactionsoveraprediction
horizont=t ,...,t . InAIF,thedesirabilityof(orpreferencefor)eachpolicyisquantifiedthrough
c p
theexpectedfreeenergy(EFE).TheEFEisthecentralquantitydrivingthebehaviorofADTsand
is formulated to evaluate sequences of actions (or policies) both on goal-directed (pragmatic) and
information-seeking (epistemic) behaviors. Like the VFE, the EFE is a function of observations,
hidden states, and policies. However, different from the VFE, it pertains to sequences of future
actions, where no actual observations are yet available, and it includes expectations over future
digital states and future observations generated by the generative model.
The use of AIF generative models for digital state inference and policy inference is graphically
summarized in Fig. 4. Digital state inference integrates the prior belief at time t 1 with the
c
−
observational data assimilated at t . In contrast, policy inference entails predictive modeling over
c
the horizon t = t ,...,t , where the generative model operates without access to future sensory
c p
data or executed actions from the interfacing generative process.
10
S S
tc− 1 tc
O t E c x − p 1 U tc− 1 O t E c xp
O O
tc+1 tp
A A A A
D tc− 1 B D tc B D tc+1 B D tp
U U
tc tc+1
π
G
c
t=t c 1 t=t c t=t c +1 t=t p
−
| | | |
Digitalstateinference Policyinference
(cid:124) (cid:123)(cid:122) (cid:125)(cid:124) (cid:123)(cid:122) (cid:125)
ecaps
lacisyhP
ecaps
latigiD
)ssecorp
evitareneG(
)ledom
evitareneG(
Figure 4: A dynamic Bayesian network illustrating the use of active inference generative models to navigate the
partiallyobservableMarkovdecisionprocessunderlyingthedigitaltwinproblem. Circularnodesrepresentrandom
variables, red square nodes denote taken actions, gray square nodes represent parametrized operators of the gen-
erative model, and the diamond-shaped node symbolizes prior preferences that reflect a goal-directed (pragmatic)
objective. Nodes with bold outlines indicate observed quantities, while those with thin outlines represent latent
variablestobeinferred. Directededgesencodeconditionaldependenciesbetweenvariables. Theupperleft-to-right
pathrepresentstheevolutionofthephysicalspace,whilethelowerpathdepictstheevolutionofthedigitalspace.
Digitalstateinferenceisperformedatthecurrenttimetc,whereaspolicyinferenceinvolvespropagatingtheupdated
digitalstatefromtc tothepredictiontimetp.
The EFE associated to a generic policy π is defined as:
Gπ =E lnQ(D π) lnp(O ,D π) , (9)
Q(Otc:tp ,Dtc:tp| π) tc:tp
| −
tc:tp tc:tp
|
(cid:2) (cid:3)
where,forsimplicity,weomittheexplicitdependenceoftheva(cid:101)riationalposterioronthevariational
parameters θ, denoting it simply as Q(D ). Similarly, we omit the dependency of the generative
t
modelonthehyperparametersϕ. InEq. (9),p(O ,D π)=p(D O ,π)p(O )definesagenerative
t t t t t
| |
modelbiasedbythepredictiveprioroverobservationsp(O ). Thisconstructionintegratestheprior
t
preferences encoded in c into the inference p(cid:101)rocess (described below), en(cid:101)abling the AIF agent to
act in ways that maximize the likelihood of preferred(cid:101)outcomes.
Given the assumed conditional independence of variational posteriors across time, the EFE at
11
a generic time step t t ,...,t for policy π is given by:
c p
∈{ }
Gπ =E [lnQ(D π) lnp(O ,D π)]
t Q(Ot,Dt| π) t | − t t |
= E [D [Q(D O ,π) Q(D π)]] E [lnp(O )]
−
Q(Ot| π) KL t
|
t
(cid:101)||
t
| −
Q(Ot| π) t
(10)
Epistemicvalue(informationgain) Pragmaticvalue(utility)
(cid:101)
(cid:124) +E Q(Ot| π) [D(cid:123)K(cid:122)L [Q(D t
|
O t ,π)
||
p(cid:125)(D t
|
(cid:124)O t ,π)]](cid:123),(cid:122) (cid:125)
Expectedvariationalapproximationerror( 0)
≥
(cid:124) (cid:123)(cid:122) (cid:125)
withthecompletederivationprovidedinAppendix A,asadaptedtotheADTframeworkfrom[63].
In Eq. (10), the first term denotes the epistemic value [28], which promotes information-seeking
behavior. It favors policies under which the agent is expected to explore states that yield high
informationgainaboutthedigitalstate. Thisgainisquantifiedasthedivergencebetweenpredicted
digital states conditioned and unconditioned on observations under the same policy. The second
term corresponds to the pragmatic value, which reflects goal-directed behavior. It favors policies
that lead the agent to states expected to generate outcomes aligned with prior preferences p(O ).
t
Thefinaltermcapturestheexpectedapproximationerror–thedivergencebetweenthetruedigital
state posterior and its variational approximation – which is typically assumed to be negligib(cid:101)le.
The epistemic drive in Eq. (10) is a crucial component that enables ADTs to exhibit spon-
taneous exploratory behavior. Epistemic actions in ADTs encompass decisions that gather in-
formation or improve the digital state observability. These may include, for instance, installing
new sensors, scheduling targeted inspections, or testing model predictions. For example, in a
manufacturing ADT, the agent might deliberately vary process parameters within safe limits to
resolve uncertainty about machine wear dynamics. In a personalized medicine context, the ADT
mightrecommendalow-riskdiagnostictesttodisambiguatebetweencompetinghypothesesabout
a patient’s physiological condition. In both cases, the primary objective of these actions is not
immediate(pragmatic)utilitymaximization,butrathertorefinethegenerativemodelandenhance
the understanding of the environment.
The EFE of temporally deep policies is given by the sum of time step-specific contributions:
tp
Gπ = Gπ, (11)
t
t
(cid:88)
=tc
where each term is evaluated based on the agent’s predictive beliefs over future digital states
and observations. The computation begins from the current posterior belief Q (D ), which is
∗ tc
then propagated over the prediction horizon t = t ,...,t using the policy-specific transition and
c p
observation models. This process generates the posterior predictive densities Q(O ,D π),
tc:tp tc:tp
|
which are subsequently used to evaluate the goal-directed (pragmatic) and information-seeking
(epistemic) values at each time step.
Let Π= π ,...,π denote the set of P feasible policies, constructed through the combinato-
1 P
{ }
rialenumerationofsequencesofactionsfromtheactionspace overthetimehorizont=t ,...,t .
c p
U
The EFE vector G=[Gπ1,...,GπP]
⊤
RP, which assigns a scalar EFE to each policy, defines a
∈
prior over policies according to:
p(π)=σ( γG), (12)
−
where σ(x)= (cid:80) e x x e p x ( p x ( ) x) is the Softmax function, and γ ∈ R+ is an inverse temperature parameter
that modulates the precision over policies. Higher γ values yield more deterministic preferences.
Undertheprior(12),AIFagentsperformpolicyinferencebyoptimizingavariationalposterior
over policies Q(π) [63], to minimize the following VFE expansion over the prediction horizon
12
t=t ,...,t :
c p
=E lnQ(D ,π) lnp(O ,D ,π)
F
tc:tp Q(Dtc:tp ,π) tc:tp
−
tc:tp tc:tp
=E (cid:2)lnQ(D π)+lnQ(π) lnp(O (cid:3),D π) lnp(π)
Q(Dtc:tp ,π) tc:tp
| −
tc:tp tc:tp
| −
=E Q(π) [lnQ(π(cid:2)) lnp(π)] (cid:3) (13)
−
+E E lnQ(D π) lnp(O ,D π)
Q(π) Q(Dtc:tp| π) tc:tp
| −
tc:tp tc:tp
|
=D [Q(π) p(π) (cid:104) ]+E π(cid:2) , (cid:3)(cid:105)
KL || Q(π) Ftc:tp
(cid:104) (cid:105)
whichmeasurestheKLdivergencebetweentheapproximateposteriorQ(D ,π)andthegenera-
tc:tp
tivemodelp(O ,D ,π)asasumoftwocontributions. ThefirstistheKLdivergencebetween
tc:tp tc:tp
the variational posterior over policies and the corresponding prior (12), thereby incorporating the
EFE into the inference process. The second term is a policy-weighted average of the free energy
across all policies, where π denotes the free energy associated with a single policy π:
Ftc:tp
π = E lnp(O ,D π) lnQ(D π)
Ftc:tp − Q(Dtc:tp| π) tc:tp tc:tp | − tc:tp | (14)
= E (cid:2)lnp(O ,D π) H Q(D π(cid:3)) ,
−
Q(Dtc:tp| π) tc:tp tc:tp
| −
tc:tp
|
with H Q(D π) = E (cid:2) lnQ(D π) be (cid:3) ing th (cid:2) e variational (cid:3) posterior entropy,
tc:tp
|
Q(Dtc:tp| π)
−
tc:tp
|
which quantifies the uncertainty in the beliefs about future digital states under policy π.
(cid:2) (cid:3) (cid:2) (cid:3)
By evaluating each policy independently and computing its associated free energy, the opti-
mal posterior Q (π) is obtained by minimizing the total VFE with respect to Q(π). This
∗
F
tc:tp
is achieved by enforcing the stationarity of with respect to Q(π), leading to a Softmax
F
tc:tp
distribution through the following update rule:
Q (π)=argmin =σ(lnp(π) π ), (15)
∗ F tc:tp −Ftc:tp
Q(π)
assigning higher probability to policies with lower free energy while remaining close to the prior.
The posterior over policies can be further biased by incorporating a policy prior p(π ), which
0
encodes habitual tendencies. For example, p(π ) could represent the standard policy implemented
0
by decision-makers, such as state agencies and companies, depending on the context, or standard
protocols in medical settings. By expanding the prior (12) as:
p(π)=σ(lnp(π ) γG), (16)
0
−
the resulting update rule for belief estimation becomes:
Q (π)=argmin =σ(lnp(π ) γG π ). (17)
∗ F tc:tp 0 − −Ftc:tp
Q(π)
The posterior over control states Q (U ) is formed by marginalizing over policies as follows:
∗ t
Q (U )= p(U π)Q (π), (18)
∗ t t ∗
|
π Π
(cid:88)∈
where p(U π) defines a deterministic mapping from policies to control states. The actual action
t
|
U = u to be executed on the system can eventually be selected either as the maximum a-
tc tc
posteriori estimate or by sampling from Q (U ).
∗ tc
3.4. Learning of the generative model via parameter inference
In this section, we describe the learning of the parameters ϕ that define the AIF generative
model, based on the outcomes of inference. “Learning” ϕ is a generative model’s parameter
updating occurring at a slower timescale than the faster inference processes for digital states and
13
policies. Nevertheless, the update equations for ϕ follow the same variational principles of digital
state inference, where a variational posterior over ϕ is optimized through VFE minimization.
In our discrete setting, posterior inference over ϕ is performed by parametrizing the likelihood
and prior distributions of the generative model with Dirichlet distributions, following an approach
similar to [11, 21]. The choice to treat hyperparameters ϕ as the parameters of Dirichlet distri-
butions is motivated by their conjugacy to the categorical distribution. This formulation enables
online learning via closed-form Bayesian updates, allowing evidence about the system response to
actions to be incorporated efficiently, while ensuring that the posterior remains within the Dirich-
let family. The approach is computationally scalable and supports continual refinement of ADTs,
even when initialized with potentially inaccurate or uncertain priors and likelihoods.
In the following, we refer to the generative model (2) by decomposing ϕ into subsets corre-
sponding to the categorical and Dirichlet parameters associated with the arrays A, B, and d.
Specifically, we write ϕ = A,a,B,b,D,d to explicitly highlight the stochastic parametrization
{ }
of each likelihood and prior distribution, as defined below:
1. The observation model A R , which encodes the observation likelihood p(O D ;A),
|O|×|D| t t
∈ |
is parametrized by the matrix of categorical probabilities A R , as follows:
|O|×|D|
∈
O D ;A Cat(A), (19)
t t
| ∼
p(A)= p(A ), A Dir(a ), (20)
,d ,d ,d
• • ∼ •
d
(cid:89)∈D
where Ndenotesthecardinalityofagenericset ;Cat(X)andDir(X)denotecategorical
|X|∈ X
and Dirichlet distributions over a generic random variable X, respectively; the notation X
,j
•
referstothejthcolumnofamatrixX;anda R isthematrixof(positive)concentration
|O|×|D|
∈
parameters defining the Dirichlet prior over A. These parameters encode prior beliefs over
categorical probabilities and can be interpreted as pseudo-counts representing the expected
frequency of each possible realization – here, the frequency of each observation given a digital
state. For notational simplicity, we assume the generative model is not factorized into multiple
digitalstatefactorsorobservationmodalities. However,theformulationcanbeeasilyextended
to a multi-modal, multi-factor setup via additional parametrized dimensions.
2. ThetransitionmodelB R ,whichencodesthecontrol-dependentforward-timepre-
|D|×|D|×|U|
∈
dictor p(D D ,u ;B), is parametrized by the tensor of categorical parameters
t t 1 t 1
| − −
B R , as follows:
|D|×|D|×|U|
∈
D D ,u ;B Cat(B), (21)
t t 1 t 1
| − − ∼
p(B)= p(B ), B Dir(b ), (22)
,d,u ,d,u ,d,u
• • ∼ •
d u
(cid:89)∈D (cid:89)∈U
where b R is the tensor of parameters for the Dirichlet prior over B.
|D|×|D|×|U|
∈
3. the initial state model d R , which encodes the prior over initial digital states p(D ;D), is
|D| 0
∈
parametrized by the vector of categorical parameters d R , as follows:
|D|
∈
D ;D Cat(D), (23)
0
∼
D Dir(d), (24)
∼
where d R is the vector of parameters defining the Dirichlet prior over D.
|D|
∈
Given the split of ϕ into the individual parametrizations for A, B, and d, the generative
14
model (2) can be expressed as:
p(O ,D ,A,B,D,π)=
tc:tp tc:tp
tp tp (25)
p(A)p(B)p(D)p(π)p(D ;D) p(D D ,π;B) p(O D ;A).
tc t
|
t
−
1 t
|
t
t=
(cid:89)
tc+1 t
(cid:89)
=tc
Learning is thus formulated as the approximate inference of A, B, and D by minimizing the
VFE with respect to their corresponding approximate posteriors Q(A), Q(B), and Q(D). The full
variational posterior is assumed to factorize as:
tp
Q(D ,A,B,D,π)=Q(A)Q(B)Q(D)Q(π) Q(D π), (26)
tc:tp t
|
t
(cid:89)
=tc
where the variational distributions Q(A), Q(B), and Q(D) are modeled as Dirichlet distributions:
Q(A)= Q(A ), Q(A )=Dir(a ), (27)
,d ,d ,d
• • •
d
(cid:89)∈D
Q(B)= Q(B ), Q(B )=Dir((cid:98)b ), (28)
,d,u ,d,u ,d,u
• • •
d u
(cid:89)∈D (cid:89)∈U
Q(D)=Dir(d), (cid:98) (29)
where a R , b R , and d R serve the same role as a, b, and d in defining
∈
|O|×|D|
∈
|D(cid:98)|×|D|×|U|
∈
|D|
Dirichletdistributions,whilebeingtreatedasvariationalparameterstobeoptimized. Accordingly,
the full(cid:98)VFE objectiv (cid:98) e for the generative m (cid:98) odel (25) is given by:
=E lnQ(D ,A,B,D,π) lnp(O ,D ,A,B,D,π) , (30)
F
tc:tp Q(Dtc:tp ,A,B,D,π) tc:tp
−
tc:tp tc:tp
which, using Eq. (25) and Eq. ((cid:2)26), can be factorized as: (cid:3)
=E lnQ(A) lnp(A)+lnQ(B) lnp(B)+lnQ(D) lnp(D)
F
tc:tp Q(Dtc:tp ,A,B,D,π)
− − −
+lnQ(π(cid:2)) lnp(π) lnp(D ;D)+lnQ(D π) (31)
− −
tc tc:tp
|
lnp(D D ,π;B) lnp(O D ;A) .
−
tc+1:tp
|
tc:tp− 1
−
tc:tp
|
tc:tp
The update rules for the Dirichlet parameters a, b, and d are derived by i(cid:3)ndependently setting
the gradients of the VFE (31) to zero with respect to each parameter direction. Specifically, when
the ADT is being updated at the current time step t , learning proceeds as follows:
c
• A array: Given the Dirichlet prior parameters a over the generative model, the observation
OExp = oExp, and the digital state posterior Q (D ), the fixed-point update rule for the
tc tc ∗ tc
variational posterior Dirichlet parameters a over Q(A) is:
a =a+ηA(oExp Q (D )), (32)
∗ (cid:98) tc ⊗ ∗ tc
where denotestheouterproduct,andηA R,with0 ηA 1,isalearningrateparameter
⊗ (cid:98) ∈ ≤ ≤
that scales the update step.
• B array: Given the Dirichlet prior parameters b over the generative model, the digital state
posteriorQ (D ),thepreviousdigitalstateposteriorQ (D ),andtheactionU =u
∗ tc ∗ tc− 1 tc− 1 tc− 1
takenattheprevioustimestep,thefixed-pointupdateruleforthevariationalposteriorDirichlet
parameters b over Q(B) is:
b =b +ηB(Q (D ) Q (D )), (33)
(cid:98) ∗ • , • ,utc− 1 • , • ,utc− 1 ∗ tc ⊗ ∗ tc− 1
which corresponds to an update applied to the u th slice of b.
(cid:98) tc− 1
• d array: Given the Dirichlet prior parameters d and the digital state posterior Q (D ), the
(cid:98) ∗ tc
fixed-point update rule for the variational posterior Dirichlet parameters d over Q(D) is:
d =d+ηdQ (D ). (34)
∗ ∗ tc (cid:98)
(cid:98)
15
3.5. Epistemic behavior of active digital twins
If the agent also maintains a variational posterior over the model hyperparameters Q(ϕ), as
discussed in Sec. 3.4, the EFE expression (10) can be extended to capture the epistemic value
associated with the expected information gain not only over digital states but also over ϕ:
Gπ =E [lnQ(D ,ϕ π) lnp(O ,D ,ϕ π)]
t Q(Ot,Dt,ϕ | π) t | − t t |
= E [D [Q(D O ,π) Q(D π)]] E [D [Q(ϕ O ,π) Q(ϕ π)]]
−
Q(Ot| π) KL t
|
t
|| (cid:101)
t
| −
Q(Ot| π) KL
|
t
|| |
Epistemicvalue(digitalstateinformationgain) Epistemicvalue(modelparametersinformationgain)
(cid:124)
−
E Q(Ot| π) [l(cid:123)n(cid:122)p(O t )] +E Q(Ot| π) [(cid:125)D KL [(cid:124)Q(D t ,ϕ
|
O t ,π)
||
(cid:123)p(cid:122)(D t ,ϕ
|
O t ,π)]]. (cid:125)
Pragmaticvalue(utility) Expectedvariationalapproximationerror( 0)
≥
(cid:101)
(35)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
The full derivation is provided in Appendix A, adapted to the ADT framework from [63]. The
second epistemic term quantifies the value of resolving uncertainty over the Dirichlet parameters
that govern the prior and posterior distributions of the A, B, and d arrays. When the AIF agent
maintainsandupdatesbeliefsoverthesemodelparameters,thistermsteerspolicyinferencetoward
action-observation trajectories expected to yield informative updates to the generative model. We
pointoutthattheepistemicvalueoverϕisnotexploitedinthenumericaldemonstrationspresented
in Sec. 4. Nevertheless, it is retained in the formulation of the ADT framework, as this capability
may enable essential functionalities depending on the context and specific application objectives.
Epistemic actions aimed at refining the generative model can be regarded as forms of au-
tonomouscalibration,whereintheADTsteersitsoperationintounderexploredregimesorperturbs
its environment to test and improve its generative model. For instance, a sensor might be tem-
porarilyactivatedsolelytoevaluateitsreliabilitywhileupdatingalikelihoodmodeldeemedunreli-
able. This behavior underscores the distinction between passive and active learning: while passive
learning entails assimilating externally provided or randomly encountered data, active learning re-
flectsthestrategicinitiationofdataacquisitiontoacceleratemodelrefinementandenhancefuture
decision-making. The information-seeking (epistemic) behavior of ADTs thus emerges from their
capacity for self-adaptive inference and learning, pursued alongside goal-directed (pragmatic) ob-
jectives. ThisdualoptimizationisembeddedinpolicyinferencethroughEFEminimization,which
unifiesgoal-directedexplorationandutilitymaximizationwithinasinglecomputationalframework
that moves beyond the passive replication of physical systems.
3.6. Algorithmic description
AnalgorithmicdescriptionofasinglestepoftheAIFloopforADTsisprovidedinAlgorithm 1.
Giventhegenerativemodel,anobservationsampledfromthegenerativeprocess,theposteriorover
digitalstatesfromtheprevioustimestep, andtheactiontakenattheprevioustimestep, onestep
of the loop involves: (1) performing inference over digital states based on the new observation; (2)
using the posterior belief over digital states to perform policy inference and select the next action;
(3) updating the generative model through learning informed by inference results.
4. Numerical demonstrations
This section demonstrates the proposed methodology through the simulated monitoring, man-
agement,andmaintenanceplanningoftheH¨orneforsrailwaybridge[64]. Althoughthiscasestudy
focuses specifically on structural health monitoring (SHM), the underlying framework broadly
applies to a wide range of systems or domains.
Section4.1introducesthemonitoredphysicalasset. Section4.2describesthecompositionofthe
handledvibrationdataandthenumericalmodelsusedtogeneratelabeledexamplesundervarious
16
Algorithm 1 Active inference loop for active digital twins.
input: generative model A,B,c,d
⟨ ⟩
assimilated observation OExp =oExp
tc tc
digital state posterior Q (D ) at previous time step
∗ tc− 1
action U =u executed at previous time step
tc− 1 tc− 1
▷ digital state inference by minimizing variational free energy
F
tc
1: infer digital state posterior Q ∗ (D tc )
▷ policy inference and action selection by minimizing future variational free energy
F
tc:tp
2: compute posterior predictive distributions Q(O tc:tp ,D tc:tp
|
π)
3: evaluate epistemic and pragmatic values over t=t c ,...t p under each policy
4: infer control policies posterior Q ∗ (π)
5: select action U tc =u tc by taking the best-point estimate or sampling from Q ∗ (U tc )
▷ learning by minimizing variational free energy
F
tc
6: update observation model A by computing the variational posterior Dirichlet parameters a
7: update transition model B by computing the variational posterior Dirichlet parameters b
8: update initial prior d by computing the variational posterior Dirichlet parameters d (cid:98)
(cid:98)
(cid:98)
return updated generative model A,B,c,d
⟨ ⟩
updated posterior distribution over control policies Q (π)
∗
control action to be executed U =u
tc tc
posterior predictive density over digital states Q(D )
tc:tp
posterior predictive density over actions Q(U )
tc:tp
damage scenarios. Section 4.3 outlines the assimilation of observational data for structural health
identification using artificial neural networks. Section 4.4 details the step-by-step construction of
the AIF generative model, namely the four-tuple A,B,c,d . Section 4.5 presents the results of
⟨ ⟩
ADT simulations under purely goal-directed behavior, serving as a baseline for comparison with
the simulations involving mixed pragmatic-epistemic behavior, subsequently discussed in Sec. 4.6.
The AIF agents based on discrete, Markovian generative models have been simulated using
the open-source Python package pymdp library [63]. Compared to other AIF libraries, such as the
MATLABtoolboxDEM [65]andtheC++librarycpp-AIF[66],pymdpoffersnotableadvantagesinterms
ofuser-friendliness,flexibility,andcustomizability,althoughfeaturinglowerprocessrepresentation
(DEM)andlesscomputationalefficiency(cpp-AIF).ThesimulationshavebeenrunonaPCfeaturing
an Intel® CoreTM i9-14900KF CPU @ 3.2 GHz and 64 GB RAM.
4.1. Physical asset
The H¨ornefors railway bridge, shown in Fig. 5(a), is an integral reinforced concrete structure
along the Swedish Bothnia line. It spans 15.7 m, with a clearance height of 4.7 m and a width of
5.9m(excludingedgebeams). Themainstructuralelementshaveathicknessof0.5mforthedeck,
0.7mfortheframewalls,and0.8mforthewingwalls. Thefoundationsystemcomprisestwoslabs
connectedbystaybeams,supportedbypilegroups. TheconcreteisofgradeC35/45,characterized
by the following material properties: Young’s modulus E = 34 GPa, Poisson’s ratio ν = 0.2, and
density ρ = 2500 kg/m3. The bridge supports a single railway track with sleepers spaced at
0.65 m intervals, resting on a ballast layer that is 0.6 m deep and 4.3 m wide, with a density
of ρ = 1800 kg/m3. The structure is subjected to dynamic loading from Gr¨ona T˚aget trains
B
17
C
⌧
 
* * *
C 1 C C 1
  +
⇡ 0 B ⇡ C B ⇡ C 1 B
+
A A
$ $
C C 1
+
C =0 C =1 C =2
( ( (
0 1 2
| | |
Figure1.1
( 0 $ 0 ( 1 $ 1 ( 2
C
$ 0 *  1 ⇡ 0 NN $ 1 * 0 * 0   ⇡ 1 NN * 1 * 1  
 
⌧
*  ⇡NN * *  ⇡NN * * 
1 0 0 0 ⇡ 1 1 1 ⇡
  0 1
 
⇡ ⇡
0 1
& ' & '
0 0 1 1
* *
C 1 C
 
& ' C =0 & ' C =1 0 0 1 1
| | |
⇡ 0 B ⇡ C B ⇡ C 1
C =0 ( C C =1 ( 1 + ( 2
exp Figure8.2: Dynamicdeci-
| | C $ C | sionnetworkencodingthe
( ( A A( asset-twincoupleddynam-
C $ 1 $ 2
C Figure8.2: D1ynamicdeci- icalsystem. Circlenodes
sionnetworkencodingthe denoterandomvariables,
⌧
$ C *     1 ⇡ C NN $ 1* C $ C * C   a i d c s e a s n l e o s t- y t t e s w t r e a in m nd c . o o C u m i p ⇡$rc l v e l 1C N a e d +r N n1 i d a o y b d n l e e a s s m , * - 1 s a n q n o u d te a d r t e h i*a e n m 1 o o   o d b n j e e d s ct d n iv e o n e d o f e u t s e n d a c e c t - i t o io n n . s,
*  1 ⇡ C NN * C C =0 * C   ⇡   1 NCN=1 * 1 s a q n u d a d re i*a n m 1 o   o d n e d sd n C e o n = d o e t 2 s e d a e c - tions, N de o n d o e t s e w ob it s h er b v o e l d d q o u u a tl n in ti e ti s es,
  | ⇡ C | notetheobjectiv⇡e |1 function. whilenodeswiththinout-
Figure1.2 Nodeswithboldoutlines linesdenoteunobserved
* * denoteobs*ervedquantities,
C 1 C C 1 quantitiestobeestimated.
⇡ C   ⇡ 1 whilenodesw+iththinout- Directedsolidedgesrepre-
1.3 O￿￿￿￿￿￿￿￿￿￿￿￿￿￿ & ￿CF￿￿￿￿￿￿R￿￿￿￿￿￿￿ ' C linesdenoteuno&bs 1 erved 9 sentthe'v1ariables’dependen-
quantitiestobeestimated.
ciesencodedviaconditional
⇡ 0 & C B ' C ⇡ C C =0 & B 1 ⇡D s C e i n r t ec th te e' d v1 s a o r l i i a Bd bl e e d s’ g d es e C p r = e e p n r 1 d e e - n- w pr h o i b le ab d i i l r i e ty ct d ed ist d r a ib s u h t e i d on e s d , ges
ciesencodedviaconditional
representthevariables’de-
| p|robabilitydistributions, |
C =0 A C =1 A whiledirecteddashededges pendenciesencodedvia
deterministicfunctions.
representthevariables’de-
| and is governed|by the update frequency of the D|T via data Figure8.3: Dynamicdeci-
pendenciesencodedvia
assimilation,ensuringtheDTisupdatedodnecteermpeirnitsitmicefusntcetpio.ns. sionnetworkencodingthe
and is governed by the update frequency $ oCf the DT via data $ FCigure8.3: Dynamicdeci- asset-twincoupleddynam-
Inthegraph,circlenodesdenoterandomvariablesatdiscrete icalsystem. Circlenodes
assimilation,ensuringtheDTisupdatedoncepertimestep. sionnetworkencodingthe C =0 times,squarenode C s = de1noteactions,anddiaaC mss= oent2-dtwninodceosupdleendodtyenathme- denoterandomvariables,
Inthegraph,circleno o de b s je d c e t n iv o e te fu ra n n c d ti o o m n. v N ar o ia d b e le s s w at it d h is b c o r l e d te outlicinalessysdteemn.oCteircolebnseodrvesed squarenodesdenoteactions,
times,squaren|odesdenoteactions,anddiamo|ndnodesdenotethe den|oterandomvariables, anddiamondnodesde-
Figure1.1 quantities, while nodes with thin outline s s qu d a e re n n o o t d e es u d n e o n b ot s e e a r c v ti e o d ns, notetheobjectivefunction. objective function. Nodes with bold outlines denote observed
quantitiestobeestimated. ThePGMissapnadrsdeialymcoonndnneocdteesddwe-ith Nodeswithboldoutlines
quantities, while nodes with thin outlines denote unobserved notetheobjectivefunction. denoteobservedquantities,
edgesencodingknownorassumedconditionaldependencies. Solid
quantitiestobeestimated. ThePGMissparselyconnectedwith Nodeswithboldoutlines whilenodeswiththinout-
edgesrepresentthevariables’dependencideesnoetnecoobdseervdedviqauacnotnitdieis-, linesdenoteunobserved
edgesencodingknownorassumedconditionaldependencies. Solid whilenodeswiththinout- quantitiestobeestimated.
tionalprobabilitydistributions,modeledbyCPTsasthespaces
edgesrepresentthevariables’dependenciesencodedviacondi- linesdenoteunobserved Directedsolidedgesrepre-
ofunobservedvariablesarediscrete. Dashquedanetditgieesstroebpereesstiemnattetdh.e sentthevariables’dependen-
tionalprobabilitydistributions,modeledbyCPTsasthespaces
variables’ dependencies encoded via deDteirremcteidnsisotliidcefdugnesctrieopnres-. ciesencodedviaconditional
ofunobservedvariablesarediscrete. Dashededgesrepresentthe sentthevariables’dependen- probabilitydistributions,
Thanks to the modeled conditional dependencies, the graph
variables’ dependencies encoded via deterministic functions. ciesencodedviaconditional whiledirecteddashededges
topology is specified from the first two tpimroebasbliilicteysdiastnridbuctiaonnsb, e representthevariables’de- Thanks to the modeled conditional dependencies, the graph
whiledirecteddashededges pendenciesencodedvia
topology is specified from the first two time slices and can be representthevariables’de- deterministicfunctions.
pendenciesencodedvia
188 8 D￿￿￿￿￿￿T￿￿￿￿￿￿S￿￿￿￿￿￿￿￿￿￿￿￿P￿￿￿￿d￿e￿t￿e￿r￿m￿￿￿inGis￿ti￿c￿f￿u￿n￿￿ct￿ioMns￿.￿￿￿￿
188 8 D￿￿￿￿￿￿T￿￿￿￿￿￿S￿￿￿￿￿￿￿￿￿￿￿￿P￿￿￿￿￿￿￿￿￿￿￿￿G￿￿￿￿￿￿￿￿M￿￿￿￿￿
1.3 O￿￿￿￿￿￿￿￿￿￿￿￿￿￿￿F￿￿￿￿￿￿R￿￿￿￿￿￿￿ 9
ecaps
lacisyhP
ecaps
latigiD
(a)
(b) (c)
Figure 5: Physical asset and its digital twin. (a) The physical space corresponds to the H¨ornefors bridge. (b)
The digital space represents a structural health monitoring schematization, including details of synthetic record-
ings related to displacements u1(t),...,u10(t), and predefined damage regions Ω1,...,Ω6. (c) Exemplary vertical
displacementtimehistoryatmidspan,comparingfull-ordermodel(FOM),reduced-ordermodel(ROM),andnoisy
FOMapproximations.
operatingatspeedsbetweenv [160,215]km/h. Wespecificallyconsiderconfigurationsinvolving
∈
two-car trainsets, totaling eight axles, with each axle bearing a mass of ψ [16,22] ton. The
∈
geometrical and mechanical parameters, as well as the moving load model, are adapted from [67].
The physical state space represents the ground-truth variability in the bridge structural health.
S
4.2. Offline data assembly
The bridge monitoring system provides displacement data in the form of multivariate time
series, denotedasU(µ)=[u
1
(µ),...,u
Ns
(µ)]
∈
RL
×
Ns. TheseconsistofN
s
=10individualtime
series corresponding to the degrees of freedom (dofs) indicated in Fig. 5(b). Each series contains
L samples equally spaced over the time interval [0,1.5 s], acquired with a sampling frequency of
400 Hz. The vector µ RNpar collects N
par
control parameters, which are assumed to represent
∈
the operational and damage conditions. For the problem settings we consider, each observation
spans a relatively short time interval, within which these conditions are regarded as constant.
We simulate the monitored asset using a physics-based computational model. Specifically, the
structure is modeled as a linear-elastic continuum under the assumption of linearized kinematics,
and the equations of elasto-dynamics describe its dynamic response to train transits. The model
is spatially discretized using linear tetrahedral finite elements, and its solution is advanced in time
to generate synthetic observational data, controlled by the parameter vector µ.
The full-order model (FOM) is described in detail in [10]; here, we summarize its key features.
Thefiniteelementmeshconsistsofelementswithanominalsizeof0.8m,refinedto0.15malongthe
deck,resultinginatotalof17,292dofs. Theballastlayerisaccountedforbyincreasingthedensity
of the deck and edge beams to represent an equivalent mass. Embankment effects are captured
using distributed springs applied along the surfaces in contact with the ground, implemented via
a Robin-type boundary condition with an elastic coefficient of 108 N/m3. Structural damping
18
is introduced using Rayleigh damping, calibrated to yield a 5% damping ratio in the first two
vibrational modes. The dynamic response is computed over the time interval [0,1.5 s], uniformly
partitioned into L=600 time steps, using an implicit Newmark time integration scheme [68].
Damage-induced variations in the structural dynamic response are modeled as localized reduc-
tions in effective stiffness. Assuming that each observation spans a time window short enough
compared to the timescale of damage progression, the structural behavior can be treated as lin-
ear within that interval. This enables a separation of timescales between the slow evolution of
damage and the structural health assessment [69]. While the precise damage mechanisms are typ-
ically confirmed through on-site inspections following early detection, the degradation patterns in
integral bridges that can be described in this way include: cracking in concrete due to thermal
gradients, freeze-thaw cycles, or overloading; progressive deterioration from alkali-silica reactions,
whichmayleadtocrackingandspalling; crackingfromstressconcentrationscausedbydifferential
settlements; and surface erosion from prolonged environmental exposure.
The digital state space includes a set of predefined configurations of damage presence, lo-
D
cation, and severity. These are modeled by parametrizing the stiffness matrix using two variables
y N and δ R, both included in the parameter vector µ. The discrete variable y 0,...,6
∈ ∈ ∈{ }
designatesthedamageregion, withy =0denotingtheundamagedbaseline. Forthedamagecases
y =1,...,6, weconsiderN =6predefinedsubdomainsΩ , form=1,...,6, eachrepresentinga
Ω m
potential damage location as shown in Fig. 5. Within each subdomain, the material stiffness may
be reduced by a factor δ [30%,80%], which remains constant throughout the passage of a train.
∈
To reduce the computational cost of solving the FOM for arbitrary values of µ, we employ a
projection-basedreduced-ordermodel(ROM).ThereductionisperformedusingaGalerkinreduced
basismethod[70,71],relyingonalow-dimensionalsetofbasisfunctionscomputedthroughproper
orthogonal decomposition. Following the method of snapshots [72], the ROM is constructed upon
400 FOM solutions for different configurations of the input parameters µ = (v,ψ,y,δ) , which
⊤
are taken as uniformly distributed and sampled via the Latin hypercube rule. The dimension
of the reduced-order expansion is determined based on an energy retention criterion. By setting
a tolerance of 10 3 for the fraction of discarded energy, the number of dofs is reduced to 133.
−
Both the FOM and ROM have been implemented in the Matlab environment, using the redbKIT
library [73]. For a more detailed description, the reader is referred to [10].
A representative example of displacement time histories is reported in Fig. 5(c), showing the
verticaldisplacementatmidspanobtainedfromboththeFOMandROM.Toemulatemeasurement
noiseandassessitspotentialimpactonthehandledstructuralresponse,signalsarecorruptedwith
additive Gaussian noise, yielding a signal-to-noise ratio of 120.
4.3. Data assimilation via artificial neural networks
The vibration recordings are assimilated for structural health diagnostics by leveraging the
flexibility of deep learning (DL) models for SHM applications, as demonstrated in [74–76].
Data-driven approaches to SHM follow a pattern recognition paradigm [62], in which damage
is assessed by comparing measurements with data previously collected under known structural
conditions. This process relies on two key components: (i) feature selection and extraction, and
(ii) statistical modeling to associate these features with specific damage patterns [77]. A major
challengeliesinidentifyingdamage-sensitivefeaturesthatremainrobustundervaryingoperational
and environmental conditions. DL offers an automated alternative for selecting and extracting
optimized features by capturing temporal correlations within and across time series data [78, 79].
In our framework, each time a train crosses the bridge, the vibration recordings U are initially
processed by a DL classifier, which outputs confidence scores indicating the likelihood that U
correspondstoeachdamageclassdefinedbytheyparameter. Theclasswiththehighestconfidence
is selected as the best-point estimate for categorizing the measurements. Whenever damage is
19
detected and localized within a region Ω , m = 1,...,6, the vibration recordings U are further
m
processed by a dedicated regression model – one for each damageable region – to estimate the
severity of damage δ. These initial estimates are then incorporated into the AIF framework as
assimilated observation OExp =oExp, as detailed below.
tc tc
The DL architectures have been implemented through the Tensorflow-based Keras API [80],
andtrainedonasingleNvidia GeForce RTXTM 3080GPUcard. Thetraininghasbeenperformed
in a supervised fashion using 10,000 noisy data instances generated from ROM simulations. For a
comprehensive description the reader is referred to [10].
4.4. Active digital twin framework
The outcomes from the DL models are integrated into our POMDP framework by discretizing
the range of δ into N =6 intervals: [30%,35%], [35%,45%], [45%,55%], [55%,65%], [65%,75%],
δ
{
[75%,80%] . This discretization results in a total of N N +1 = 37 possible damage scenarios,
Ω δ
}
each specifying a combination of damage location and severity. By ordering them first by location
and then by severity, this post-processed output constitutes the first observation modality OΩδ.
The observation space is completed with a second observation modality Ou corresponding
O
to the action taken prior to data assimilation, such that O = OΩδ,Ou . Including this additional
{ }
perceptualchannelprovidestwokeybenefits. First,itenablespriorpreferences(viathecarray)to
account not only for the costs associated with structural health states but also for those linked to
actions. Second, as detailed below, it naturally supports the formulation of an action-conditioned
observation model, introducing an inductive bias that facilitates digital state identification.
The digital state space is structured into three factors D = DΩ,Dδ,DEpi , corresponding
D { }
to: thedamage location DΩ = Ω ,...,Ω ; thediscretizedpercentagereductioninmaterialstiff-
1 6
{ }
ness Dδ = 0%, [30%,35%], [35%,45%], [45%,55%], [55%,65%], [65%,75%], [75%,80%] ; and an
{ }
epistemicswitchDEpi = Epi,Non-Epi ,whichindicateswhethertheAIFagentislikelytoengage
{ }
in information-seeking (epistemic) behavior. This third factor allows the agent to autonomously
switchbetweenactingasanactiveinformationseekerorasautilitymaximizerthatisconfidentin
itsbeliefs. Itisworthnotingthatthisfactorizationisneithertheonlyviableoptionnornecessarily
the most appropriate. This reflects the inherent subjectivity involved in shaping the digital state
space. For example, DΩ and Dδ could have been merged into a single enumerated representa-
tion, similar to the one used for OΩδ, at the expense of increased computational complexity and
reduced interpretability. Alternatively, a more expressive but computationally demanding option
wouldinvolvedefiningsixseparateDδ factors,oneforeachoftheN damageableregions. Finally,
Ω
note that including DEpi is essential to enable epistemic behavior, as this factor leads to distinct
observation models associated with the Epi and Non-Epi states, as discussed further below.
The action space comprises four control actions, each producing specific effects:
U
1. Do nothing (DN): the structural health state evolves according to a stochastic deterioration
process, while regular revenue is maintained.
2. Maintenance (MA):ahigh-costmaintenanceinterventionisexecutedtomitigateexistingdam-
age. Althoughthisactionimprovesthestructuralcondition,itmaynotfullyrestorethesystem
to a pristine (damage-free) state.
3. Restrict operations (RO): traffic is limited to lightweight trains with axle load below 18 ton,
thereby reducing the rate of structural degradation. However, this also leads to a reduction in
the revenue generated by the infrastructure.
4. Read sensors (RE): a moderate-cost, high-fidelity sensing action is performed to resolve uncer-
tainty in the structural health state. This action provides high epistemic value by decreasing
theentropyofthedigitalstateposterior,thusincreasingthemutualinformationbetweenlatent
20
statesandexpectedobservations. Thiseffectreflectstheuseofhigh-qualitysensors, controlled
forced vibration tests, or in-situ inspection. From the perspective of the generative model,
performinganinspectionisequivalenttoreadingvibrationrecordingsfromsensors,albeitwith
significantly higher information content and a corresponding higher cost.
The observation likelihood array A = AΩδ,Au comprises two observations models:
{ }
AΩδ ROΩδ DΩ Dδ DEpi and Au ROu DΩ Dδ DEpi , respectively encoding the con-
| |×| |×| |×| | | |×| |×| |×| |
∈ ∈
ditional sensory likelihoods p(OΩδ DΩ,Dδ,DEpi) and p(Ou DΩ,Dδ,DEpi) for the first and
| |
second observation modalities. Conceptually, these tensors are designed to answer two distinct
questions: (i) what might the agent believe about the pre-classified signals? and (ii) what might
the agent infer about its previous action?
The slice of AΩδ for the epistemic state, i.e., p(OΩδ DΩ,Dδ,DEpi = Epi), is denoted by
|
AΩδ ROΩδ DΩ Dδ . Thisobservationmodelisderivedfromaconfusionmatrixthatquantifies
Epi ∈ | |×| |×| |
the offline (expected) performance of the DL models in identifying the digital state factors DΩ
and Dδ. The confusion matrix is interpreted as a CPT, where rows correspond to ground-truth
responses and columns to predicted outcomes. The offline evaluation has been performed using
4000 noisy FOM solutions, achieving a classification accuracy of 91.39%. To mitigate the risk
of inconsistencies due to zero-likelihood observations, i.e., evidence contradicting the confusion
matrix, a small positive perturbation 10 5 is added to all entries of AΩδ prior to normalization.
− Epi
AnexemplarysliceofAΩδ associatedwithp(OΩδ DΩ =Ω ,Dδ,DEpi =Epi)isshowninFig. 6a.
Epi | 4
While AΩδ serves as a relatively informative sensory likelihood, a higher-entropy likelihood is
Epi
usedtomodelthesliceofAΩδunderthenon-epistemicstate,i.e.,p(OΩδ DΩ,Dδ,DEpi =Non-Epi),
|
denotedbyAΩδ ROΩδ DΩ Dδ . Thisnon-epistemicmodelisobtainedviauniformrandom
Non-Epi ∈ | |×| |×| |
perturbation of AΩδ as the following linear combination:
Epi
AΩδ =(1 α)AΩδ +αAΩδ , (36)
Non-Epi − Epi Entropic
which is then properly renormalized. Here, AΩδ is a purely entropic observation model
Entropic
sampled from a uniform distribution over [0,1], and 0 α 1 is a weighting coefficient con-
≤ ≤
trolling the degree of entropy introduced. Figure 6b shows an exemplary slice corresponding to
p(OΩδ DΩ =Ω ,Dδ,DEpi =Non-Epi)forα=0.2. Itisworthnotingthatmodulatingαcanalso
4
|
be interpreted as a simple yet effective mechanism to account both for potential errors in, and for
the decision-maker confidence about, the use of DL models to assimilate real-world data.
ThesliceofAu fortheepistemicstate,i.e.,encodingp(Ou DΩ,Dδ,DEpi =Epi),isdenotedas
|
Au ROu DΩ Dδ . It is populated with Dirac delta distributions centered at the RE action
Epi ∈ | |×| |×| |
for all possible combinations of DΩ and Dδ (see also Fig. 6c). This design reflects the assumption
thatiftheagentisinthestateDEpi =Epi,itknowswithcertaintythatthepreviouslytakenaction
was the (epistemic) RE action, regardless of the values of the other digital state factors. From a
data assimilation point of view, receiving Ou =RE provides no informative cues for inferring DΩ
or Dδ, but it deterministically sets DEpi = Epi. In contrast, under the non-epistemic state, the
corresponding observation model Au ROu DΩ Dδ is filled with entries that reflect a
Non-Epi ∈ | |×| |×| |
plausible causality for what the agent can infer about the previous action given DΩ and Dδ. This
prior CPT (see also Fig. 6d) is modeled consistently across the DΩ factor, as follows:
0.08 0.3 0.45 0.4 0.3 0.2 0.1
0.9 0.4 0.3 0.1 0.15 0.2 0.25
p(Ou DΩ =Ω ,Dδ,DEpi =Non-Epi)= . (37)
1:6
| 0.02 0.3 0.25 0.5 0.55 0.6 0.65
 
 0 0 0 0 0 0 0 
 
 
For data assimilation, observing Ou = RE has two implications: first, it deterministically sets
̸
DEpi = Non-Epi; second, it introduces an inductive bias by leveraging the structure of Au
Non-Epi
to condition inference on the previous action, similar to the influence of the transition model.
21
Ω
1
Ω
2
Ω
3
Ω
4
Ω
5
Ω
6
0% 30% 40% 50% 60% 70% 80%
 ' L J L W D O  V W D W H  I D F W R U Dδ   3 U H G L F W H G  V W D W H 
 DΩ=Ω 4 , DEpi=Epi
  K W X U W  G Q X R U *  δΩO  Q R L W D Y U H V E R  G H W F H S [ ( 100%
Ω
1
Ω
2
Ω
3
50%
Ω
4
Ω
5
Ω
6
0%
0% 30% 40% 50% 60% 70% 80%
 ' L J L W D O  V W D W H  I D F W R U Dδ   3 U H G L F W H G  V W D W H 
 DΩ=Ω 4 , DEpi=Non Epi
(a)
  K W X U W  G Q X R U *  δΩO  Q R L W D Y U H V E R  G H W F H S [ ( 100%
50%
0%
(b)
 ' 1
 0 $
 5 2
 5 (
0% 30% 40% 50% 60% 70% 80%
 ' L J L W D O  V W D W H  I D F W R U Dδ
uO  Q R L W D Y U H V E R  G H W F H S [ (
100%
 ' 1
 0 $
50%
 5 2
 5 (
0%
0% 30% 40% 50% 60% 70% 80%
 ' L J L W D O  V W D W H  I D F W R U Dδ
(c)
uO  Q R L W D Y U H V E R  G H W F H S [ (
100%
50%
0%
(d)
Figure6: Visualizationoftheobservationmodels: Panels(a)and(b)showslicesofAΩδ,correspondingtothesensory
likelihoods (a) p(OΩδ | DΩ = Ω4,Dδ,DEpi = Epi) and (b) p(OΩδ | DΩ = Ω4,Dδ,DEpi = Non-Epi) for α = 0.2.
Panels(c)and(d)showslicesofAu,correspondingtothesensorylikelihoods(c)p(Ou|DΩ=Ω1:6,Dδ,DEpi=Epi)
and(d)p(Ou|DΩ=Ω1:6,Dδ,DEpi=Non-Epi).
The transition array B = BΩ,Bδ,BEpi comprises three sub-arrays Bf RDf Df Uf ,
| |×| |×| |
{ } ∈
each encoding the transition dynamics p(Df Df ,uf ;Bf) of a specific digital state fac-
t | t − 1 t − 1
tor Df DΩ,Dδ,DEpi , conditioned on its previous state and the corresponding control factor
∈{ }
uf uΩ,uδ,uEpi . Starting with initial priors over the transition probabilities defined by Bf,
∈{ }
these are iteratively refined by assimilating evidence from the system response to actions, as de-
scribed in Sec. 3.4. A graphical visualization of the initial transition models for each digital state
andcontrolfactorisshowninFig. 7. Notethattheseinternalmodelsdonotreplicatetheground-
truth evolution, which remains unknown to the ADT. Moreover, assuming digital state factors
evolve independently, the control space is factorized as U = UΩ = ∅,Uδ = U,UEpi = U . This
{ }
reflects that DΩ is an uncontrollable factor, with a control dimensionality of 1, while Dδ and DEpi
are both influenced by the same control variable U = DN,MA,RO,RE . The set of feasible
∈U { }
policiesΠisconstructedbycombinatoriallyenumeratingallpossiblesequencesofactionsfromthe
action space over the prediction horizon t=t
c
,...,t
p
, resulting in a total of 4tp− tc policies.
U
The initial Dirichlet parameters bΩ over the categorical distribution BΩ for the uncontrollable
BΩ are selected to yield a 0.8 probability that damage stays in the same subdomain Ω , for
m
m = 1,...,6. The remaining 0.2 probability is evenly distributed across the other subdomains,
reflecting a strong prior belief that damage is unlikely to move between different regions.
Fortheaction-conditionedBδ,eachaction-specificsliceencodestheprobabilityoftransitioning
betweendiscreteδintervals. Thediagonalentriesrepresenttheprobabilityofremaininginthesame
damagestate,whilethelower-leftandupper-righttrianglesdenotetheprobabilitiesofdeterioration
and improvement, respectively. Under the DN action, the initial Dirichlet parameters bδ for the
categorical distribution Bδ are configured to yield transition probabilities of 0.85, 0.1, and 0.05
22
Ω1
Ω2
Ω3
Ω4
Ω5
Ω6
Ω1 Ω2 Ω3 Ω4 Ω5 Ω6
 ' L J L W D O  V W D W H  I D F W R U D t Ω 1
−
Ω t D  U R W F D I  H W D W V  O D W L J L '
100%
0%
30%
40%
50%
50%
60%
70%
80%
0% 30% 40% 50% 60% 70% 80%
0%  ' L J L W D O  V W D W H  I D F W R U D t δ 1
 U t δ 1 =DN −
−
(a)
δ t D  U R W F D I  H W D W V  O D W L J L '
100%
50%
0%
(b)
0%
30%
40%
50%
60%
70%
80%
0% 30% 40% 50% 60% 70% 80%
 ' L J L W D O  V W D W H  I D F W R U D
t
δ
1
 U
t
δ
1
=MA −
−
δ t D  U R W F D I  H W D W V  O D W L J L '
100%
0%
30%
40%
50% 50%
60%
70%
80%
0%
0% 30% 40% 50% 60% 70% 80%
 ' L J L W D O  V W D W H  I D F W R U D
t
δ
1
 U
t
δ
1
=RO −
−
(c)
δ t D  U R W F D I  H W D W V  O D W L J L '
100%
50%
0%
(d)
0%
30%
40%
50%
60%
70%
80%
0% 30% 40% 50% 60% 70% 80%
 ' L J L W D O  V W D W H  I D F W R U D t δ 1  U t δ 1 =RE −
−
δ t D  U R W F D I  H W D W V  O D W L J L '
100%
50%
Epi
Non Epi
0% Non Epi Epi
 ' L J L W D O  V W D W H  I D F W R U D t Epi 1  U t Epi 1 = DN,MA,RO −
−
(e) ' “
ipE
t D  U R W F D I  H W D W V  O D W L J L '
100%
Epi
50%
Non Epi
0% Non Epi Epi
 ' L J L W D O  V W D W H  I D F W R U D t Epi 1  U t Epi 1 =RE −
−
(f)
ipE
t D  U R W F D I  H W D W V  O D W L J L '
100%
50%
0%
(g)
Figure 7: Visualization of the transition models: Panel (a) shows the uncontrollable BΩ, corresponding to the
transitionlikelihoodp(DΩ|DΩ ). Panels(b-e)showtheaction-specificslicesofBδ,correspondingtothetransition
t t−1
likelihoods (b) p(Dδ | Dδ ,Uδ = DN), (c) p(Dδ |Dδ ,Uδ =MA), (d) p(Dδ | Dδ ,Uδ = RO), and (e)
t t−1 t−1 t t−1 t−1 t t−1 t−1
p(Dδ |Dδ ,Uδ =RE). Panels(f)and(g)showstheaction-specificslicesofBEpi,correspondingtothetransition
t t−1 t−1
likelihoods(f)p(DEpi|DEpi,UEpi ={DN,MA,RO})and(g)p(DEpi|DEpi,UEpi =RE).
t t−1 t−1 t t−1 t−1
for degradation of zero, one, or two δ intervals, respectively. For the RO action, the corresponding
probabilities are set to 0.92, 0.05, and 0.03, reflecting a slower rate of deterioration due to reduced
structural load. The slice associated with the RE action is designed to reflect improved damage
tracking. Itassignsprobabilitiesof0.9and0.1fordegradationofzeroandoneδintervals,capturing
the higher confidence associated with epistemic control actions. In contrast, the MA action slice
is designed to support transitions across up to six δ intervals, with probabilities 0.05, 0.15, 0.20,
0.20, 0.20, and 0.20, for improvements of zero to five intervals, respectively. To mitigate the risk
ofnumericalinconsistenciescausedbyevidence thatcontradicts theassumed transitiondynamics,
a small perturbation of 10 3 is added to all entries of Bδ prior to normalization.
−
23
The sub-array BEpi serves as an epistemic switch, enabling deterministic transitions between
the states DEpi = Epi and DEpi = Non-Epi. This mechanism is implemented through Boolean
matricesthatenforceDEpi =Non-Epi–regardlessofitspreviousvalue–whenevertheADTselects
DN, MA, or RO actions. Conversely, selecting the RE action triggers a transition to the epistemic
state DEpi = Epi. This transition model is not subject to learning updates, as its structure is
predefined and not expected to benefit from interaction with the generative process.
At each time step, the ADT selects a control action u whose effects on the generative
t
∈ U
process are uncertain and may lead to unexpected outcomes. The costs associated with both
the structural health state and the control actions are modeled as prior preferences via the array
c= cΩδ,cu . The components cΩδ ROΩδ and cu ROu assign relative log-probabilities to
| | | |
{ } ∈ ∈
each outcome of the two observation modalities, respectively:
+5.5 if u = DN,
t
0 if y =0,
 5 if u = MA,
cΩδ
←
lnp(O
t
Ωδ)=
 −
1
e
0
xp(δ)
i
i
f
f 3
δ
0
=
%
8
<
0%
δ
,
<80%, cu
←
lnp(O
t
u)=
+
−
2.5 if u
t
t
= RO,
(38)
(cid:101) − (cid:101) 0.5 if u = RE.
These log-probability

vectors are passed through a Softmax function to
p −
roduce val
t
id probability
distributions p(OΩδ) and p(Ou), which are then used to compute the expected utility term in the
t t
EFE. The structural health preferences penalize deterioration in proportion to the exponential of
δ, with a stee(cid:101)p penalty fo(cid:101)r severely compromised states. The control action preferences reflect
trade-offsbetweenepistemicvalueofexpectedinformationgainandoperationalcost: DNandRO
actionsyieldpositiverewardsbutcarrytheriskofstructuraldeterioration; REsimilarlyallowsfor
deterioration, yet it is expected to reduce the entropy of the digital state posterior at the cost of a
moderatelynegativereward. MAmitigatesdeteriorationbutcarriesasignificantlynegativereward
due to its high cost. While these values are expressed in non-dimensional form, they represent
indicativecostschargedtothedecisionmaker. Actualvaluesmaybederivedfromserviceandcost
catalogs issued by governmental agencies or infrastructure operators. In particular, the health-
related preference distribution p(OΩδ) should reflect a prioritization analysis that accounts for
t
both the likelihood and consequences of different damage scenarios – such as loss of serviceability,
increased accident risk, or struct(cid:101)ural failure – as well as the risk tolerance of the decision-maker.
The array defining the initial state model d = dΩ,dδ,dEpi consists of three sub-arrays
{ }
df RDf , each specifying the initial prior distribution p(Df ) over a digital state factor
∈ | | tc
Df DΩ,Dδ,DEpi . Uniform probability distributions are adopted for DΩ and DEpi to re-
∈{ }
flect initial uncertainty. In contrast, Dδ is initialized as a Dirac delta distribution centered at 0%,
consistent with the assumption of undamaged structure when the ADT enters into operation.
The (unknown) ground-truth generative process evolves conditionally on the most recent con-
trol action. In particular, we assume that damage can develop in any predefined region, without
propagating across different damageable subdomains. The evolution follows the degradation (or
improvement) stochastic models described below. Under the DN, RO, and RE actions, structural
health is assumed to degrade monotonically. For the DN action, the damage class y is sampled
fromacategoricaldistributiony Cat(1, 1 , 1 , 1 , 1 , 1 , 1 ), whichassignshalfoftheprobabil-
∼ 2 12 12 12 12 12 12
itymasstotheundamagedstatey =0,anddistributestheremaininghalfuniformlyamongthesix
damage classes y =1,...,6. When damage first initiates, the magnitude δ is sampled uniformly
within the range of the first damage interval δ y =0,y =0 Uniform(0.3%,0.35%). Subse-
t t t 1
| ̸ − ∼
quent damage progression is modeled by sampling δ increments from a truncated normal distribu-
tioncenteredat1.5%withastandarddeviationof1%,δ δ y =0 Normal (1.5%,1%),
t t 1 t 1 0
− − | − ̸ ∼ ≥
with any increments below 0% rounded up to 0%. For the RO action, a similar model is em-
ployed, but with a lower probability of damage initiation and slower deterioration. In this case,
24
the damage class is sampled as y Cat(3, 1 , 1 , 1 , 1 , 1 , 1 ), and the damage magnitude
∼ 4 24 24 24 24 24 24
evolves as δ δ y =0 Normal (0.95%,0.5%). For the RE action, the generative pro-
t t 1 t 1 0
− − | − ̸ ∼ ≥
cess is the same as that under the DN or RO actions, respectively, depending on whether the
system was previously in a restricted or unrestricted condition before engaging in information-
seeking (epistemic) behavior. In contrast, the MA action is modeled as a healing process. If
y =0, the system remains undamaged. If y =0, the damage magnitude decreases according to
̸
δ δ y =0 Normal ( 25%,15%), withanydecrementbelow10%roundedupto10%.
t t 1 t 10%
− − | ̸ ∼ ≤ −
The system is assumed to return to an undamaged condition (y = 0) if the resulting damage
magnitude satisfies δ <30%, reflecting a minimal detectable deterioration threshold.
4.5. Results: Purely goal-directed behavior
In this section and the next, we present the results of several ADT simulations, each spanning
60 time steps. At every time step, new observational data are generated based on the (unknown)
ground-truthgenerativeprocess. TheADTassimilatesthesedatatoinferthevariationalposterior
Q (D ) over the current digital state, and performs policy inference by computing the posterior
∗ tc
Q (π) over policies. Control actions are subsequently selected as the best-point estimate from the
∗
posterior Q (U ) over control states, and the generative model is eventually learned by updating
∗ tc
the variational posterior Dirichlet parameters b .
∗
We adopt a policy horizon of t t =4 and begin by analyzing a baseline scenario where the
p c
− (cid:98)
ADT operates under a purely goal-directed (pragmatic) behavior. This is achieved by retaining
only the utility term associated with pragmatic value in the EFE formulation, excluding any
contributions from information-seeking (epistemic) value and removing the epistemic RE action
from the available action set. The entropy level in the observation model AΩδ is set using
Non-Epi
α=0.5. The inverse temperature parameter controlling the precision of policy selection is left to
its default value of γ =16. Furthermore, learning updates to the generative model are disabled in
this baseline setting.
Figure 8 illustrates a representative ADT simulation. Results are reported in terms of both
the ground-truth physical state and the corresponding ADT estimates obtained after assimilating
observational data. The evolution of the digital state is shown only for regions that experience
damage,althoughalldamageableregionsΩ ,...,Ω aresusceptibletodegradation. Initially,dam-
1 6
age develops in Ω , and the posterior Q (D ) reveals relatively high uncertainty, primarily due
1 ∗ tc
to the entropy in the observation model. Nevertheless, despite the severely corrupted observation
modelAΩδ ,theADTsuccessfullyfollowstheground-truthevolutionbyleveragingpriorinfor-
Non-Epi
mationfromtheforward-timepredictorB. Thecorrespondingsequenceofcontrolactionestimates
Q (U ) is shown in the penultimate panel. The ADT initially recommends DN actions, aligned
∗ tc
with the prior preferences over the two observation modalities encoded in c, i.e., to maximize
utility. Once a substantial probability mass in Q (D ) is assigned to Dδ 45%, RO actions
∗ tc
≥
begin to be selected, enabling the ADT to continue monitoring degradation, which now evolves at
a reduced rate. Eventually, an MA action is selected when the structural state becomes critically
compromised, as indicated by a consistent probability mass over Dδ 75% in Q (D ). A similar
≥
∗ tc
behavior is shown for the subsequent damage event in Ω .
6
For comparison, control actions under the ground-truth generative process are computed using
a second AIF agent that mirrors the ADT architecture but has access to the true physical state.
The ADT selects the appropriate control action from Q (U ) with a delay of at most five time
∗ tc
stepsrelativetotheground-truth-informedagent. Thisdelayismainlyattributedtothecontinued
use of a highly entropic observation model, which limits fast and accurate inference, along with
the need to recursively update prior beliefs from earlier time steps. Note that including the RE
action in the available action set would not affect the results in this case, as the ADT is driven
solelyby(pragmatic)utilitymaximizationanddoesnotengageininformation-seeking(epistemic)
25
80%
60%
30%
0%
 H J D P D '
 ' L J L W D O  W Z L Q  * U R X Q G  W U X W K
 ' D P D J H  S U R E D E L O L W \  L Q  U H J L R Q Ω
1
80%
60%
30%
0%
 H J D P D '
 ' D P D J H  S U R E D E L O L W \  L Q  U H J L R Q Ω
6
 5 2
 0 $
 ' 1
 V Q R L W F $
   
   
 $ F W L R Q  S U R E D E L O L W \
   
 ( [ S H F W H G  I U H H  H Q H U J \  G L V F U H S D Q F \   6 X P  R Y H U  S R O L F L H V
20%
10%
0%
                   
 7 L P H  V W H S
Figure8: Activedigitaltwinusingpurelygoal-directed(pragmatic)behavior. Probabilisticandbest-pointestimates
of: (toptwopanels)digitalstateevolutioncomparedtotheground-truthphysicalstate;(penultimatepanel)control
actions recommended by the digital twin versus the optimal action under the ground-truth generative process. In
the top panels, background colors represent the belief distribution over the digital state at each time step. In the
penultimate panel, background colors indicate the belief distribution over the control actions. The bottom panel
quantifiessimulationqualityintermsofthepercentageabsolutediscrepancybetweenthesumofthepolicy-specific
expectedfreeenergiescomputedbythedigitaltwinandthoseobtainedunderthegroundtruth.
behavior,i.e.,itdoesnotseektoreducetheentropyofQ(D )throughexploratoryactions. The
tc:tp
bottom panel of the figure assesses simulation quality by tracking the evolution of the percentage
absolutediscrepancybetweenthesumofthepolicy-specificEFEscomputedbytheADTandthose
obtained under the ground-truth-informed agent:
(Gπ Gπ)
∆G = π ∈ Π − 100, (39)
(cid:12) (cid:12) (cid:12) (cid:80) π ∈ Π Gπ (cid:98) (cid:12) (cid:12) (cid:12) ·
where Gπ denotes the EFE associated w (cid:12) (cid:12)ith p (cid:80) olicy π(cid:98)under (cid:12) (cid:12)the ground-truth-informed AIF agent.
A second representative ADT simulation is shown in Fig. 9, exemplifying the same purely
(cid:98)
goal-directed (pragmatic) behavior but with a different random seed. In this case, damage begins
to develop in region Ω , and the ADT initially behaves consistently with the previous results,
3
trackingthegenerativeprocesswithrelativelyhigh-entropyestimatespropagatedforwardintime.
However, starting from time step t = 33, the ADT begins to diverge from the ground truth,
and the digital state posterior Q (D ) progressively loses synchronization with the physical state.
∗ tc
The probability mass in Q (D ) gradually shifts from DΩ = Ω to DΩ = Ω , where Dδ is
∗ tc 3 6
consistently underestimated as lying within the range [65%,75%], while the actual value is in the
26
80%
60%
30%
0%
 H J D P D '
 ' L J L W D O  W Z L Q  * U R X Q G  W U X W K
 ' D P D J H  S U R E D E L O L W \  L Q  U H J L R Q Ω
3
80%
60%
30%
0%
 H J D P D '
 ' D P D J H  S U R E D E L O L W \  L Q  U H J L R Q Ω
6
 5 2
 0 $
 ' 1
 V Q R L W F $
   
   
 $ F W L R Q  S U R E D E L O L W \
   
 ( [ S H F W H G  I U H H  H Q H U J \  G L V F U H S D Q F \   6 X P  R Y H U  S R O L F L H V
20%
10%
0%
             
 7 L P H  V W H S
Figure 9: Failed active digital twin using purely goal-directed (pragmatic) behavior. Probabilistic and best-point
estimates of: (top two panels) digital state evolution compared to the ground-truth physical state; (penultimate
panel)controlactionsrecommendedbythedigitaltwinversustheoptimalactionundertheground-truthgenerative
process. In the top panels, background colors represent the belief distribution over the digital state at each time
step. In the penultimate panel, background colors indicate the belief distribution over the control actions. The
bottompanelquantifiessimulationqualityintermsofthepercentageabsolutediscrepancybetweenthesumofthe
policy-specificexpectedfreeenergiescomputedbythedigitaltwinandthoseobtainedunderthegroundtruth.
range [75%,80%]. As a result, the ADT fails to select an MA action for more than ten time steps,
despite its necessity. The simulation eventually terminates at time step t = 46, due to a digital
failure at t = 47, caused by Dδ > 80%, and symbolizing structural collapse. The ADT inability
to recover accurate tracking is attributed to the interplay between the poorly informative sensory
likelihood and the recursive propagation of outdated prior beliefs, which degrade over time.
By running a cluster of 100 simulations, each spanning 60 time steps and initialized with a
different random seed for both the observation model AΩδ and the ground-truth generative
Non-Epi
process, the ADT operating under a purely goal-directed (pragmatic) behavior fails in 47 out of
100 cases. In this baseline setting, the failure rate is strongly driven by the high level of entropy
introducedintheobservationmodelAΩδ . Althoughhighlycorruptedobservationsrealistically
Non-Epi
reflectmanyreal-worldconditions,theresultsinthefollowingsectionshowthatequippingtheADT
withbothgoal-directedandinformation-seeking(epistemic)componentsenablesactiveexploration
in response to critical uncertainty, resulting in a significant performance improvement over the
purely pragmatic baseline.
The behavior described above can also be illustrated using a simplified scenario in which the
ADT relies on two sensors, each providing partial observations to update its beliefs about the
27
evolvingdamagestate. Ifonesensorbecomesfaultybutthetransitionmodelcloselyapproximates
the actual dynamics of damage progression, the ADT may still track the system accurately, as
the predictive power of the prior compensates for the degraded sensory evidence. However, in the
more typical case where the transition model does not fully capture the actual system evolution,
outdatedpriorsdominatetheinferenceprocess,andthecompromisedlikelihoodisunabletocorrect
them. In such conditions, an information-seeking (epistemic) action should ideally be triggered
to resolve ambiguity and restore confidence in the likelihood model – for instance, by querying a
redundant sensor, activating a dormant one, or scheduling a targeted diagnostic procedure.
ItisinterestingtonotehowtheEFEdiscrepancyshowninthebottompanelofFig. 9doesnot
indicate any criticalissue. This isbecause the EFEis a subjective metric, reflecting how theADT
evaluatesitsownperformanceratherthanmeasuringthecorrectnessofthedigitalstateestimates.
Indeed, the ∆G indicator quantifies the misalignment in belief-driven action planning between the
ADT and an idealized agent with access to the true physical state. As a result, ∆G remains low
simply because the ADT is (mistakenly) confident in its estimated behavior, just as the ground-
truth-informed agent is confident in its own. However, the resulting control actions differ. To
address this limitation, one could instead employ objective performance indicators derived from
the generative process. Examples include utility scores evaluated on realized system outcomes, or
the survival time before reaching a critical condition.
4.6. Results: Combining goal-directed and information-seeking behaviors
Inthissection, wepresenttheresultsofADTsimulationscombininggoal-directed(pragmatic)
and information-seeking (epistemic) behaviors. For this, we adopt the complete EFE formulation
includingbothpragmaticandepistemicterms; furthermore,weincludetheepistemicREactionin
the available actions. All other settings remain unchanged from the simulations presented earlier.
Figure 10 illustrates a representative simulation. The ADT initially exhibits information-
seeking (epistemic) behavior, executing a sequence of RE actions to gather information about
damage onset. Once the posterior Q (D ) identifies evolving damage within Ω with relatively
∗ tc 1
low uncertainty, the ADT shifts to DN actions aimed at (pragmatic) utility maximization. When
a significant portion of Q (D ) supports Dδ 45%, RO actions begin to emerge. An MA action
∗ tc
≥
is eventually selected when the risk of structural failure becomes substantial, i.e., for a significant
probability mass over Dδ 65%. A similar pattern is observed during the subsequent damage
≥
event in Ω . In this case, sporadic RE actions are also triggered whenever the entropy of Q (D )
6 ∗ tc
increases, to prevent desynchronization from the physical state. These RE actions are interleaved
with extended sequences of DN and RO decisions, depending on the evolving health state and the
interaction between the sensory likelihood and the transition model. For instance, RE actions at
t =35 and t =51 are deployed to disambiguate the digital state just before executing costly MA
interventions. In contrast, the first MA action at t = 15 is not preceded by RE behavior, as the
ADT maintains a confident, low-entropy belief at that point. Note that the epistemic RE action
carries a lower prior preference p(Ou) than DN or RO actions and does not directly affect damage
progression. As a result, it is employed only under epistemic-driven behavior, where its role is
to support future goal-directed(cid:101)(pragmatic) decisions. Similarly, RE actions occurring immedi-
ately after MA interventions reflect the ADT effort to resolve uncertainty via active exploration
of maintenance outcomes. In contrast, under the ground-truth generative process, RE actions
are triggered exclusively to gather initial evidence about damage onset. Corrective inference is
unnecessary in this setting due to perfect, uncertainty-free access to the physical state.
Figure11showstheposteriorpredictivedensitiesforthefuturedigitalstatesQ (D )andthe
∗ tc:tp
corresponding control states Q (U ), starting at t = 60 and spanning four time steps. These
∗ tc:tp c
predictions capture the expected progression of structural health, conditioned on the posterior
over policies Q (π), thereby supporting the planning of preventive interventions. When belief
∗
28
80%
60%
30%
0%
 H J D P D '
 ' L J L W D O  W Z L Q  * U R X Q G  W U X W K
 ' D P D J H  S U R E D E L O L W \  L Q  U H J L R Q Ω
1
80%
60%
30%
0%
 H J D P D '
 ' D P D J H  S U R E D E L O L W \  L Q  U H J L R Q Ω
6
 5 (
 5 2
 0 $
 ' 1
 V Q R L W F $
   
   
 $ F W L R Q  S U R E D E L O L W \
   
 ( [ S H F W H G  I U H H  H Q H U J \  G L V F U H S D Q F \   6 X P  R Y H U  S R O L F L H V
20%
10%
0%
                   
 7 L P H  V W H S
Figure10: Activedigitaltwinusingacombinationofgoal-directed(pragmatic)andinformation-seeking(epistemic)
behaviors. Probabilisticandbest-pointestimatesof: (toptwopanels)digitalstateevolutioncomparedtotheground-
truthphysicalstate;(penultimatepanel)controlactionsrecommendedbythedigitaltwinversustheoptimalaction
under the ground-truth generative process. In the top panels, background colors represent the belief distribution
overthedigitalstateateachtimestep. Inthepenultimatepanel,backgroundcolorsindicatethebeliefdistribution
overthecontrolactions. Thebottompanelscoressimulationqualityintermsofthepercentageabsolutediscrepancy
betweenthesumofthepolicy-specificexpectedfreeenergiescomputedbythedigitaltwinandthoseobtainedunder
thegroundtruth.
propagation leads to an overly flat digital state distribution, the likelihood of selecting an RE
action increases, mitigating the risk of decisions based on unreliable or uncertain belief states.
By running a second cluster of 100 simulations, each initialized with a different random seed,
theADToperatingundercombinedgoal-directed(pragmatic)andinformation-seeking(epistemic)
behaviors consistently succeeds, with zero failures observed. This result underscores the potential
of fully equipped ADTs compared to the purely pragmatic baseline discussed in Sec. 4.5. In this
configuration,theADTisabletoautonomouslycopewithhighlycorruptedobservationsbyactively
exploring its environment in response to potentially critical uncertainty.
TheresultsofacompleteADTsimulation,combininggoal-directed(pragmatic)andinformation-
seeking (epistemic) behaviors and additionally incorporating learning updates to the generative
model, are shown in Fig. 12 for the same initialization seed as in Fig. 10. This scenario spans 80
time steps and introduces learning via updates to the transition model array B, with a learning
rate of ηB = 0.1. Learning demonstrates beneficial in several aspects. First, it reduces the fre-
quency of incorrect digital state inferences, thereby shortening the average response delay relative
totheground-truthagent. Second,asthetransitiondynamicsbecomeprogressivelytailoredtothe
29
80%
60%
30%
0%
 H J D P D '
 ' D P D J H  S U R E D E L O L W \  L Q  U H J L R Q Ω
6
 5 (
 5 2
 0 $
 ' 1
t t +3
c c
 7 L P H  V W H S
 V Q R L W F $
   
   
 $ F W L R Q  S U R E D E L O L W \
   
Figure11: Activedigitaltwinusingacombinationofgoal-directed(pragmatic)andinformation-seeking(epistemic)
behaviors. Posterior predictive densities beyond data assimilation over (future) digital states and control states,
starting at tc =60. In the top panel, background colors represent the belief distribution over the digital state at
eachtimestep. Inthebottompanel,backgroundcolorsindicatethebeliefdistributionoverthecontrolactions.
(unknown) generative process, the ADT gains confidence in its predictions, resulting in a reduced
need for (corrective) RE actions. Third, the gradual reduction of uncertainty in the transition
model enables the ADT to safely delay maintenance toward the end of the simulation. For ex-
ample, the third maintenance action, previously triggered at t = 52, is now postponed to t = 74.
Moreover, this intervention is no longer based on a maximum a-posteriori estimate of Dδ within
the [55%,65%] range, but instead within the higher [65%,75%] range – highlighting the potential
for resource savings across the system operational lifespan. The runtime for this simulation is
about 130 s, averaging 1.6 s per time slice.
5. Conclusions
This paper introduces active digital twins based on the active inference paradigm. By unifying
probabilistic modeling and inference with perception, learning, and decision-making under uncer-
tainty, the proposed approach enables digital twins to autonomously balance both goal-directed
(pragmatic or utility-maximization) and information-seeking (epistemic or uncertainty-resolving)
behaviors. This is because both factors are included in the variational free energy minimization
process that drives active inference agents [4, 6]. Active inference endows active digital twins with
the capacity to adaptively monitor, interact with, and learn from uncertain and dynamic envi-
ronments. We have presented a case study in the context of structural health monitoring for a
railway bridge, which demonstrates that active digital twins can achieve a new level of autonomy
and resilience, surpassing traditional (more passive) approaches.
The active digital twin paradigm has been realized by leveraging active inference agents [4] to
navigate the partially observable Markov decision process underlying the abstraction of physical-
digital systems proposed by Kapteyn et al. [26]. At the core of this framework lies a self-updating
generative model that enables intelligent automation through data assimilation, state estimation,
prediction, planning, and learning – all with quantified uncertainty. Digital state estimation is
performed via inference over dynamically evolving latent states, using variational free energy min-
imization. Action selection is framed as an inference process, wherein the agent infers a distribu-
tion over control policies that minimizes expected free energy, effectively closing the loop between
30
80%
60%
30%
0%
 H J D P D '
 ' L J L W D O  W Z L Q  * U R X Q G  W U X W K
 ' D P D J H  S U R E D E L O L W \  L Q  U H J L R Q Ω
1
80%
60%
30%
0%
 H J D P D '
 ' D P D J H  S U R E D E L O L W \  L Q  U H J L R Q Ω
6
 5 (
 5 2
 0 $
 ' 1
 V Q R L W F $
   
   
 $ F W L R Q  S U R E D E L O L W \
   
 ( [ S H F W H G  I U H H  H Q H U J \  G L V F U H S D Q F \   6 X P  R Y H U  S R O L F L H V
20%
10%
0%
                         
 7 L P H  V W H S
Figure12: Activedigitaltwinusingacombinationofgoal-directed(pragmatic)andinformation-seeking(epistemic)
behaviors and additionally incorporating learning updates to the generative model. Probabilistic and best-point
estimates of: (top two panels) digital state evolution compared to the ground-truth physical state; (penultimate
panel)controlactionsrecommendedbythedigitaltwinversustheoptimalactionundertheground-truthgenerative
process. In the top panels, background colors represent the belief distribution over the digital state at each time
step. In the penultimate panel, background colors indicate the belief distribution over the control actions. The
bottompanelquantifiessimulationqualityintermsofthepercentageabsolutediscrepancybetweenthesumofthe
policy-specificexpectedfreeenergiescomputedbythedigitaltwinandthoseobtainedunderthegroundtruth.
perception and action. Finally, learning emerges from the (slow-timescale) inference of hyperpa-
rameters that define the generative model itself.
The considered case study is among the few active inference applications in engineering, focus-
ingonthestep-by-stepconstructionofaphysics-basedgenerativemodelthatenablesbidirectional
perception-action interaction. Simulations of both purely goal-directed (pragmatic) and combined
goal-directedandinformation-seeking(pragmatic-epistemic)behaviorshavedemonstratedthatthe
proposed framework supports a wide range of adaptive responses, where actions emerge from in-
ternal beliefs and their entropy. By incorporating all components of the expected free energy,
the active twin effectively balances pragmatic goals and epistemic drives. Active exploration has
proven essential for maintaining synchronization between the digital and physical states, particu-
larly when the generative model must uncover key system features or when belief states become
outdated. Moreover, including learning updates has shown that personalized generative models
can improve inference accuracy, reduce the need for corrective epistemic actions, and enable the
safe postponement of costly interventions. Crucially, the behavior of the twin is not fixed but
remains customizable. There is no universally optimal behavior; rather, the performance and role
31
of an active digital twin should be assessed in light of the objectives encoded in its generative
model. For example, prior preferences on the structural health can be adjusted to reflect specific
operational or safety requirements, and even treated as sweep parameters to derive meta-decision
curves providing insight into how risk sensitivity can be modulated by the decision-maker.
Beyond the structural health monitoring application presented here, the proposed framework
offers a generalizable methodology applicable across a wide range of domains. Active digital twins
are envisioned as key enablers of autonomous agents in the development of smart structures and
systems, as well as in fields such as medicine and neuroscience [81]. Future extensions will target
self-healing structures and multi-agent physical systems capable of self-organization and continual
self-learning. In addition, future work will investigate the scalability of the approach to higher-
dimensional continuous state spaces, the multi-agent coordination of digital twin networks, and
onlinelearningfromreal-worlddata. Thisonlinelearningwillbecomplementedbyofflineupdates
via Bayesian model reduction [82], allowing the generative model to be periodically simplified
by pruning uninformative concentration parameters. This process will enable an optimal trade-
off between model complexity (quantifying the magnitude of belief updates required to maintain
predictive performance) and model accuracy (reflecting the model fit to observed data). Compet-
itive generative models will be compared to select the most parsimonious explanation of recent
experience, retaining only those latent causes that meaningfully contribute to accurate inference.
Data Accessibility: The implementation code used for the experiments presented in Sec. 4 is
available in the public repository ADT-code [83]. The code implements the proposed active digital
twin framework and can be used to simulate and generate the plots for digital state estimation,
future prediction, and policy inference, as reported in this paper. The observational data used to
runtheexperiments,alongwiththedeeplearningmodelstrainedaccordingtotheimplementation
details provided in the Appendix of [10], are also available in the same repository. The Matlab
library for finite element simulation and reduced-order modeling of partial differential equations
employed to generate these data is available in the repository Redbkit [73].
CompetingInterests: Theauthorsdeclarethattheyhavenoknowncompetingfinancialinterests
or personal relationships that could have appeared to influence the work reported in this paper.
Acknowledgments: The authors thank Dr. Luca Rosafalco (Politecnico di Milano) and Eng.
GiacomoMondello(PolitecnicodiMilano)fortheinsightsandcontributionsduringourdiscussions.
Funding: This work is supported by the ERC advanced grant IMMENSE (Grant Agreement
101140720), funded by the European Union. Views and opinions expressed are however those
of the authors only and do not necessarily reflect those of the European Union or the European
Research Council Executive Agency. Neither the European Union nor the granting authority
can be held responsible for them). Author AM also acknowledges the financial support from the
FIS starting grant DREAM (Grant Agreement FIS00003154), funded by the Italian Science Fund
(FIS) - Ministero dell’Universit`a e della Ricerca. Authors DM, FD, and GP acknowledge financial
support from the ERC consolidator grant ThinkAhead (Grant Agreement 820213), funded by the
European Union.
References
[1] National Academy of Engineering and National Academies of Sciences, Engineering, and Medicine, Founda-
tional Research Gaps and Future Directions for Digital Twins, The National Academies Press, Washington,
DC,2024. doi:10.17226/26894.
[2] W.Kritzinger,M.Karner,G.Traar,J.Henjes,W.Sihn,DigitalTwininmanufacturing: Acategoricalliterature
reviewandclassification,IFAC-PapersOnLine51(11)(2018)1016–1022,16thIFACSymposiumonInformation
ControlProblemsinManufacturingINCOM2018. doi:10.1016/j.ifacol.2018.08.474.
32
[3] A.Ferrari,K.Willcox,Digitaltwinsinmechanicalandaerospaceengineering,NatureComputationalScience
4(2024)178–183. doi:10.1038/s43588-024-00613-8.
[4] T.Parr,G.Pezzulo,K.J.Friston,ActiveInference: TheFreeEnergyPrincipleinMind,Brain,andBehavior,
MITPress,Cambridge,MA,2022. doi:10.7551/mitpress/12441.001.0001.
[5] S.J.Russell,ArtificialIntelligence: AModernApproach,PearsonEducation,London,UnitedKingdom,2020.
[6] K. Friston, The free-energy principle: a unified brain theory?, Nature Reviews Neuroscience 11 (2) (2010)
127–138. doi:10.1038/nrn2787.
[7] K. J. Friston, T. Parr, B. de Vries, The graphical brain: Belief propagation and active inference, Network
Neuroscience1(4)(2017)381–414. doi:10.1162/NETN\_a\_00018.
[8] Shafto,MikeandConroy,MikeandDoyle,RichandGlaessgen,EdandKemp,ChrisandLeMoigne,Jacqueline
andWang,Lui,TechnologyArea11: Modeling,Simulation,InformationTechnology&Processing,Tech.rep.,
National Aeronautics and Space Administration, Washington, District of Columbia (2020). doi:10.17226/
13354.
[9] DigitalTwin: Definition&Value—AnAIAAandAIAPositionPaper,AIAADigitalEngineeringIntegration
Committeeandothers,Tech.rep.,AIAA:Reston,Virginia(2020).
[10] M.Torzoni,M.Tezzele,S.Mariani,A.Manzoni,K.E.Willcox,Adigitaltwinframeworkforcivilengineering
structures,ComputerMethodsinAppliedMechanicsandEngineering418(2024)116584. doi:10.1016/j.cma.
2023.116584.
[11] E.Varetti,M.Torzoni,M.Tezzele,A.Manzoni,Adaptivedigitaltwinsforpredictivedecision-makingthrough
hierarchicalBayesianlearningoftransitiondynamics,na(2025). doi:na.
[12] C. Li, S. Mahadevan, Y. Ling, S. Choze, L. Wang, Dynamic Bayesian Network for Aircraft Wing Health
MonitoringDigitalTwin,AIAAJournal55(3)(2017)930–941. doi:10.2514/1.J055201.
[13] A. Phua, C. Davies, G. Delaney, A digital twin hierarchy for metal additive manufacturing, Computers in
Industry140(2022)103667. doi:10.1016/j.compind.2022.103667.
[14] M.Jans-Singh,K.Leeming,R.Choudhary,M.Girolami,Digitaltwinofanurban-integratedhydroponicfarm,
Data-CentricEngineering1(2020)20. doi:10.1017/dce.2020.21.
[15] A.L.Reis,A.Andrade-Campos,P.Matos,C.HenggelerAntunes,M.A.Lopes,Anenergyandcostefficiency
ModelPredictiveControlframeworktooptimizeWaterSupplySystemsoperation,AppliedEnergy384(2025)
125478. doi:10.1016/j.apenergy.2025.125478.
[16] A. Tzachor, S. Sabri, C. E. Richards, A. Rajabifard, M. Acuto, Potential and limitations of digital twins
to achieve the sustainable development goals, Nature Sustainability 5 (10) (2022) 822–829. doi:10.1038/
s41893-022-00923-7.
[17] D.Cotoarb˘a,D.Straub,I.F.Smith,Probabilisticdigitaltwinsforgeotechnicaldesignandconstruction,arXiv
preprintarXiv:2412.09432v1(2024). doi:10.48550/arXiv.2412.09432.
[18] S. Henneking, S. Venkat, O. Ghattas, Goal-Oriented Real-Time Bayesian Inference for Linear Autonomous
Dynamical Systems With Application to Digital Twins for Tsunami Early Warning, arXiv preprint
arXiv:2501.14911v1(2025). doi:10.48550/arXiv.2501.14911.
[19] G.Arcieri, C.Hoelzl, O.Schwery, D.Straub, K.Papakonstantinou, E.Chatzi, POMDPinferenceandrobust
solution via deep reinforcement learning: An application to railway optimal maintenance, Machine Learning
(2024). doi:10.1007/s10994-024-06559-2.
[20] A.McClellan,J.Lorenzetti,M.Pavone,C.Farhat,APhysics-BasedDigitalTwinforModelPredictiveControl
ofAutonomousUnmannedAerialVehicleLanding,PhilosophicalTransactionsoftheRoyalSocietyA:Math-
ematical,PhysicalandEngineeringSciences380(2229)(2022)20210204. doi:10.1098/rsta.2021.020417.
[21] M.Tezzele,S.Carr,U.Topcu,K.E.Willcox,Adaptiveplanningforrisk-awarepredictivedigitaltwins,arXiv
preprintarXiv:2407.20490v2(2024). doi:10.48550/arXiv.2407.20490.
[22] S. Henao-Garcia, M. Kapteyn, K. E. Willcox, M. Tezzele, M. Castroviejo-Fernandez, T. Kim, M. Ambrosino,
I.Kolmanovsky,H.Basu,P.Jirwankar,R.Sanfelice,Digital-Twin-EnabledMulti-SpacecraftOn-OrbitOpera-
tions,in: AIAASCITECH2025Forum,2025,p.1432. doi:10.2514/6.2025-1432.
33
[23] J. Corral-Acero, F. Margara, M. Marciniak, C. Rodero, F. Loncaric, Y. Feng, A. Gilbert, J. F. Fernandes,
H. A. Bukhari, A. Wajdan, et al., The ‘Digital Twin’ to enable the vision of precision cardiology, European
HeartJournal41(48)(2020)4556–4564. doi:10.1093/eurheartj/ehaa159.
[24] A.Chaudhuri,G.Pash,D.A.Hormuth,G.Lorenzo,M.Kapteyn,C.Wu,E.A.Lima,T.E.Yankeelov,K.Will-
cox, et al., Predictive digital twin for optimizing patient-specific radiotherapy regimens under uncertainty in
high-gradegliomas,FrontiersinArtificialIntelligence6(2023). doi:10.3389/frai.2023.1222612.
[25] P. Bauer, B. Stevens, W. Hazeleger, A digital twin of Earth for the green transition, Nature Climate Change
11(2)(2021)80–83. doi:10.1038/s41558-021-00986-y.
[26] M. G. Kapteyn, J. V. Pretorius, K. E. Willcox, A probabilistic graphical model foundation for enabling
predictive digital twins at scale, Nature Computational Science 1 (5) (2021) 337–347. doi:10.1038/
s43588-021-00069-0.
[27] D. Koller, N. Friedman, Probabilistic Graphical Models: Principles and Techniques, MIT Press, Cambridge,
Massachusetts,2009.
[28] K.Friston,F.Rigoli,D.Ognibene,C.Mathys,T.Fitzgerald,G.Pezzulo,Activeinferenceandepistemicvalue,
CognitiveNeuroscience6(4)(2015)187–214. doi:10.1080/17588928.2015.1020053.
[29] T. H. FitzGerald, R. J. Dolan, K. Friston, Dopamine, reward learning, and active inference, Frontiers in
ComputationalNeuroscience9(2015)136. doi:10.3389/fncom.2015.00136.
[30] T. Parr, K. J. Friston, Uncertainty, epistemics and active inference, Journal of the Royal Society Interface
14(136)(2027)20170376. doi:10.1098/rsif.2017.0376.
[31] G.Pezzulo,F.Rigoli,K.J.Friston,HierarchicalActiveInference: ATheoryofMotivatedControl,Trendsin
CognitiveSciences22(4)(2018)294–306. doi:10.1016/j.tics.2018.01.009.
[32] T.VandeMaele,B.Dhoedt,T.Verbelen,G.Pezzulo,Ahierarchicalactiveinferencemodelofspatialalternation
tasks and the hippocampal-prefrontal circuit, Nature Communications 15 (1) (2024) 9892. doi:10.1038/
s41467-024-54257-3.
[33] Z. Fountas, N. Sajid, P. Mediano, K. Friston, Deep active inference agents using Monte-Carlo methods, in:
Proceedingsofthe34thInternationalConferenceonNeuralInformationProcessingSystems,CurranAssociates
Inc.,RedHook,NewYork,2020,pp.11662–11675.
[34] P. Mazzaglia, T.Verbelen, B.Dhoedt, Contrastiveactiveinference, in: Proceedingsof the35thInternational
Conference on Neural Information Processing Systems, Curran Associates Inc., Red Hook, New York, 2021,
pp.13870–13882.
[35] D.Maisto,F.Donnarumma,G.Pezzulo,Interactiveinference: Amulti-agentmodelofcooperativejointactions,
IEEE Transactions on Systems, Man, and Cybernetics: Systems 54 (2) (2024) 704–715. doi:10.1109/TSMC.
2023.3312585.
[36] C.Heins,B.Millidge,L.DaCosta,R.P.Mann,K.J.Friston,I.D.Couzin,Collectivebehaviorfromsurprise
minimization, Proceedings of the National Academy of Sciences 121 (17) (2024) e2320239121. doi:10.1073/
pnas.2320239121.
[37] C. L. Buckley, C. S. Kim, S. McGregor, A. K. Seth, The free energy principle for action and perception: A
mathematicalreview,Journalofmathematicalpsychology81(2017)55–79. doi:10.1016/j.jmp.2017.09.004.
[38] P. Lanillos, C. Meo, C. Pezzato, A. A. Meera, M. Baioumy, W. Ohata, A. Tschantz, B. Millidge, M. Wisse,
C.L.Buckley,J.Tani,Activeinferenceinroboticsandartificialagents: Surveyandchallenges,arXivpreprint
arXiv:2112.01871(2021). doi:10.48550/arXiv.2112.01871.
[39] T. Taniguchi, S. Murata, M. Suzuki, D. Ognibene, P. Lanillos, E. Ugur, L. Jamone, T. Nakamura, A. Ciria,
B. Lara, et al., World models and predictive coding for cognitive and developmental robotics: frontiers and
challenges,AdvancedRobotics37(13)(2023)780–806. doi:10.1080/01691864.2023.2225232.
[40] P. Vijayaraghavan, J. F. Queißer, S. V. Flores, J. Tani, Development of compositionality through interac-
tive learning of language and action of robots, Science Robotics 10 (98) (2025) eadp0751. doi:10.1126/
scirobotics.adp0751.
[41] A. Bounceur, M. Kara, Intelligent Acting Digital Twins (IADT), IEEE Access 13 (2025) 15201–15214. doi:
10.1109/ACCESS.2025.3532545.
34
[42] R.Bajcsy,Activeperception,ProceedingsoftheIEEE76(8)(1988)966–1005. doi:10.1109/5.5968.
[43] J. Aloimonos, I. Weiss, A. Bandyopadhyay, Active vision, International Journal of Computer Vision 1 (4)
(1988)333–356. doi:10.1007/BF00133571.
[44] S. Thrun, W. Burgard, D. Fox, Probabilistic Robotics (Intelligent Robotics and Autonomous Agents), MIT
Press,Cambridge,MA,2005. doi:10.7551/mitpress/12441.001.0001.
[45] L. P. Kaelbling, M. L. Littman, A. R. Cassandra, Planning and acting in partially observable stochastic
domains,ArtificialIntelligence101(1-2)(1998)99–134. doi:10.1016/S0004-3702(98)00023-X.
[46] C.Cadena,L.Carlone,H.Carrillo,Y.Latif,D.Scaramuzza,J.Neira,I.Reid,J.J.Leonard,Past,Present,and
FutureofSimultaneousLocalizationandMapping: TowardtheRobust-PerceptionAge,IEEETransactionson
Robotics32(6)(2016)1309–1332. doi:10.1109/TRO.2016.2624754.
[47] S. Grigorescu, B. Trasnea, T. Cocias, G. Macesanu, A survey of deep learning techniques for autonomous
driving,JournalofFieldRobotics37(3)(2020)362–386. doi:10.1002/rob.21918.
[48] H.Niu,J.Liu,Z.Yu,D.Zheng,P.He,F.Wang,Real-timeobjecttrackingsystemusingPTZcamera,in: 2022
IEEE 4th International Conference on Civil Aviation Safety and Information Technology, 2022, pp. 471–478.
doi:10.1109/ICCASIT55263.2022.9986912.
[49] S.D.Glaser,A.Tolman,SenseofSensing: FromDatatoInformedDecisionsfortheBuiltEnvironment,Journal
ofInfrastructureSystems14(1)(2008)4–14. doi:10.1061/(ASCE)1076-0342(2008)14:1(4).
[50] J.D.Achenbach,Structuralhealthmonitoring–Whatistheprescription?,MechanicsResearchCommunica-
tions36(2)(2009)137–142. doi:10.1016/j.mechrescom.2008.08.011.
[51] M.Torzoni,A.Manzoni,S.Mariani,Structuralhealthmonitoringofcivilstructures: Adiagnosticframework
powered by deep metric learning, Computers & Structures 271 (2022) 106858. doi:10.1016/j.compstruc.
2022.106858.
[52] E.Garc´ıa-Mac´ıas,F.Ubertini,IntegratedSHMSystems: DamageDetectionThroughUnsupervisedLearning
and Data Fusion, in: A. Cury, D. Ribeiro, F. Ubertini, M. D. Todd (Eds.), Structural Health Monitoring
BasedonDataScienceTechniques,SpringerInternationalPublishing,Cham,Switzerland,2022,pp.247–268.
doi:10.1007/978-3-030-81716-9\_12.
[53] A. Thelen, X. Zhang, O. Fink, Y. Lu, S. Ghosh, B. D. Youn, M. D. Todd, S. Mahadevan, C. Hu, Z. Hu, A
comprehensive review of digital twin – part 1: modeling and twinning enabling technologies, Structural and
MultidisciplinaryOptimization65(2022)354. doi:10.1007/s00158-022-03425-4.
[54] M.Torzoni,A.Manzoni,S.Mariani,EnhancingBayesianmodelupdatinginstructuralhealthmonitoringvia
learnablemapping,arXivpreprintarXiv:2405.13648v1(2024). doi:10.48550/arXiv.2405.13648.
[55] Matteo Torzoni, Model-based and data-driven methodologies toward predictive digital twins of structures,
Ph.D.thesis,PolitecnicodiMilano(2024).
[56] B. Zaki´c, A. Ryzynski, C. Guo-Hong, J. Jokela, Classification of damage in concrete bridges, Materials and
Structures24(1991)268–275. doi:10.1007/BF02472082.
[57] K.Friston,S.Samothrakis,R.Montague,Activeinferenceandagency: optimalcontrolwithoutcostfunctions,
BiologicalCybernetics106(8)(2012)523–541. doi:10.1007/s00422-012-0512-8.
[58] A.Kamariotis,K.Vlachas,V.Ntertimanis,I.Koune,A.Cicirello,E.Chatzi,OntheConsistentClassification
and Treatment of Uncertainties in Structural Health Monitoring Applications, ASCE-ASME Journal of Risk
andUncertaintyinEngineeringSystems,PartB:MechanicalEngineering11(1)(2024)011108. doi:10.1115/
1.4067140.
[59] V. Narouie, H. Wessels, F. Cirak, U. R¨omer, Mechanical state estimation with a Polynomial-Chaos-Based
Statistical Finite Element Method, Computer Methods in Applied Mechanics and Engineering 441 (2025)
117970. doi:10.1016/j.cma.2025.117970.
[60] K.P.Murphy,Probabilisticmachinelearning: Advancedtopics,MITpress,Cambridge,MA,2023.
[61] M.J.Wainwright, M.I.Jordan, GraphicalModels, ExponentialFamilies, andVariationalInference, Founda-
tionsandTrends®inMachineLearning1(1–2)(2008)1–305. doi:10.1561/2200000001.
35
[62] C.M.Bishop, PatternRecognitionandMachineLearning, InformationScienceandStatistics, Springer, New
York,NewYork,2006.
[63] C. Heins, B. Millidge, D. Demekas, B. Klein, K. Friston, I. D. Couzin, A. Tschantz, pymdp: A Python
library for active inference in discrete state spaces, Journal of Open Source Software 7 (73) (2022) 4098.
doi:10.21105/joss.04098.
[64] M. U¨lker-Kaustell, Some aspects of the dynamic soil-structure interaction of a portal frame railway bridge,
Ph.D.thesis,KTHRoyalInstituteofTechnology(2009).
[65] R.Smith,K.J.Friston,C.J.Whyte,Astep-by-steptutorialonactiveinferenceanditsapplicationtoempirical
data,JournalofMathematicalPsychology107(2022)102632. doi:10.1016/j.jmp.2021.102632.
[66] F. Gregoretti, G. Pezzulo, D. Maisto, cpp-AIF: A multi-core C++ implementation of Active Inference for
PartiallyObservableMarkovDecisionProcesses,Neurocomputing568(2024)127065. doi:10.1016/j.neucom.
2023.127065.
[67] L.Rosafalco,M.Torzoni,A.Manzoni,S.Mariani,A.Corigliano,Onlinestructuralhealthmonitoringbymodel
order reduction and deep learning algorithms, Computers & Structures 255 (2021) 106604. doi:10.1016/j.
compstruc.2021.106604.
[68] T. J. Hughes, The Finite Element Method: Linear Static and Dynamic Finite Element Analysis, Dover Civil
andMechanicalEngineering,DoverPublications,2000.
[69] S.EftekharAzam,S.Mariani,Onlinedamagedetectioninstructuralsystemsviadynamicinverseanalysis: A
recursive Bayesian approach, Engineering Structures 159 (2018) 28–45. doi:10.1016/j.engstruct.2017.12.
031.
[70] A.Quarteroni,A.Manzoni,F.Negri,ReducedBasisMethodsforPartialDifferentialEquations: AnIntroduc-
tion,Vol.92,Springer,Cham,Switzerland,2015. doi:10.1007/978-3-319-15431-2.
[71] F.Chinesta,A.Huerta,G.Rozza,K.Willcox,ModelReductionMethods,in: E.Stein,R.deBorst,T.J.R.
Hughes(Eds.),EncyclopediaofComputationalMechanics,SecondEdition,JohnWiley&Sons,2017,pp.1–36.
[72] L.Sirovich,Turbulenceandthedynamicsofcoherentstructures.I.Coherentstructures,QuarterlyofApplied
Mathematics45(3)(1987)561–571. doi:10.1090/qam/910462.
[73] F.Negri,redbKIT,version2.2,http://redbkit.github.io/redbKIT(2016).
[74] M.Torzoni,A.Manzoni,S.Mariani,Amulti-fidelitysurrogatemodelforstructuralhealthmonitoringexploiting
model order reduction and artificial neural networks, Mechanical Systems and Signal Processing 197 (2023)
110376. doi:10.1016/j.ymssp.2023.110376.
[75] M.Torzoni,L.Rosafalco,A.Manzoni,S.Mariani,A.Corigliano,SHMundervaryingenvironmentalconditions:
Anapproachbasedonmodelorderreductionanddeeplearning,Computers&Structures266(2022)106790.
doi:10.1016/j.compstruc.2022.106790.
[76] M. Torzoni, A. Manzoni, S. Mariani, A Deep Neural Network, Multi-fidelity Surrogate Model Approach
for Bayesian Model Updating in SHM, in: P. Rizzo, A. Milazzo (Eds.), European Workshop on Struc-
tural Health Monitoring, Springer International Publishing, Cham, Switzerland, 2023, pp. 1076–1086. doi:
10.1007/978-3-031-07258-1\_108.
[77] C. R. Farrar, S. W. Doebling, D. A. Nix, Vibration–Based Structural Damage Identification, Philosophical
Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 359 (1778) (2001)
131–149. doi:10.1098/rsta.2000.0717.
[78] O.Avci,O.Abdeljaber,S.Kiranyaz,M.Hussein,M.Gabbouj,D.Inman,Areviewofvibration-baseddamage
detectionincivilstructures: FromtraditionalmethodstoMachineLearningandDeepLearningapplications,
MechanicalSystemsandSignalProcessing147(2021)107077. doi:10.1016/j.ymssp.2020.107077.
[79] O.Fink,Q.Wang,M.Svensen,P.Dersin,W.-J.Lee,M.Ducoffe,Potential,ChallengesandFutureDirections
forDeepLearninginPrognosticsandHealthManagementApplications,EngineeringApplicationsofArtificial
Intelligence92(2020)103678. doi:10.1016/j.engappai.2020.103678.
[80] F.Chollet,etal.,Keras,https://keras.io(2015).
36
[81] K. Amunts, M. Axer, S. Banerjee, L. Bitsch, J. G. Bjaalie, P. Brauner, A. Brovelli, N. Calarco, M. Carrere,
S.Caspers,etal.,Thecomingdecadeofdigitalbrainresearch: Avisionforneuroscienceattheintersectionof
technologyandcomputing,ImagingNeuroscience2(2024)1–35. doi:10.1162/imag\_a\_00137.
[82] K. J. Friston, M. Lin, C. D. Frith, G. Pezzulo, J. A. Hobson, S. Ondobaka, Active Inference, Curiosity and
Insight,NeuralComputation29(10)(2017)2633–2683. doi:10.1162/neco\_a\_00999.
[83] M.Torzoni,Adt-code,github,https://github.com/MatteoTorzy/DT-Active(2025).
Appendix A. Expected free energy derivations
In this Appendix, we provide the complete derivation of the expected free energy expressions
(10) and (35), as adapted to the adaptive digital twin framework from [63]:
Expected free energy.
Gπ =E [lnQ(D π) lnp(O ,D π)]
t Q(Ot,Dt| π) t | − t t |
=E [lnQ(D π) lnp(O ,D π)+lnQ(D O ,π) lnQ(D O ,π)]
Q(Ot,Dt| π) t
| − (cid:101)
t t
|
t
|
t
−
t
|
t
=0
=E [lnQ(D π) lnQ (cid:101) (D O ,π) lnp(O )
Q(Ot,Dt| π) t
| −
t
|
t
−
(cid:124) t (cid:123)(cid:122) (cid:125)
lnp(D O ,π)+lnQ(D O ,π)]
t t t t
− | | (cid:101)
= E [lnQ(D O ,π) lnQ(D π)] E [lnp(O )] (A.1)
−
Q(Ot,Dt| π) t
|
t
−
t
| −
Q(Ot,Dt| π) t
+E [lnQ(D O ,π) lnp(D O ,π)]
Q(Ot,Dt| π) t
|
t
−
t
|
t
(cid:101)
= E [D [Q(D O ,π) Q(D π)]] E [lnp(O )]
−
Q(Ot| π) KL t
|
t
||
t
| −
Q(Ot| π) t
Epistemicvalue(informationgain) Pragmaticvalue(utility)
(cid:101)
(cid:124) +E Q(Ot| π) [D(cid:123)K(cid:122)L [Q(D t
|
O t ,π)
||
p(cid:125)(D t
|
(cid:124)O t ,π)]](cid:123).(cid:122) (cid:125)
Expectedvariationalapproximationerror( 0)
≥
(cid:124) (cid:123)(cid:122) (cid:125)
Expected free energy with model parameters.
Gπ =E [lnQ(D ,ϕ π) lnp(O ,D ,ϕ π)]
t Q(Ot,Dt,ϕ | π) t | − t t |
=E [lnQ(D ,ϕ π) lnp(O ,D ,ϕ π)
Q(Ot,Dt,ϕ
|
π) t
| − (cid:101)
t t
|
+lnQ(D ,ϕ O ,π) lnQ(D ,ϕ O ,π)]
t t t t
| − (cid:101) |
=0
=E [lnQ(D π)+lnQ(ϕ π) lnp(O ) lnp(D ,ϕ O ,π)
Q(Ot,Dt,ϕ
|
π(cid:124)) t
|
(cid:123)(cid:122)
| −
t(cid:125)
−
t
|
t
+lnQ(D ,ϕ O ,π) lnQ(D ,ϕ O ,π)]
t t t t
| − |(cid:101)
=E [lnQ(D π) lnQ(D O ,π)+lnQ(ϕ π) lnQ(ϕ O ,π)
Q(Ot,Dt,ϕ
|
π) t
| −
t
|
t
| − |
t
lnp(O ) lnp(D ,ϕ O ,π)+lnQ(D ,ϕ O ,π)]
t t t t t
− − | |
= E [lnQ(D O ,π) lnQ(D π)]
−
Q(Ot,Dt,ϕ
|
π
(cid:101)
) t
|
t
−
t
|
E [lnQ(ϕ O ,π) lnQ(ϕ π)] E [lnp(O )]
−
Q(Ot,Dt,ϕ
|
π)
|
t
− | −
Q(Ot,Dt,ϕ
|
π) t
+E [lnQ(D ,ϕ O ,π) lnp(D ,ϕ O ,π)]
Q(Ot,Dt,ϕ
|
π) t
|
t
−
t
|
t
(cid:101)
= E [D [Q(D O ,π) Q(D π)]] E [D [Q(ϕ O ,π) Q(ϕ π)]]
−
Q(Ot| π) KL t
|
t
||
t
| −
Q(Ot| π) KL
|
t
|| |
Epistemicvalue(digitalstateinformationgain) Epistemicvalue(modelparametersinformationgain)
(cid:124)
−
E Q(Ot| π) [(cid:123)ln(cid:122)p(O t )] +E Q(Ot| π)(cid:125)[D KL [(cid:124)Q(D t ,ϕ
|
O t ,π)
||
(cid:123)p(cid:122)(D t ,ϕ
|
O t ,π)]]. (cid:125)
Pragmaticvalue(utility) Expectedvariationalapproximationerror( 0)
≥
(cid:101)
(A.2)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
37

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Active Digital Twins via Active Inference"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
