### OverviewThis paper investigates the formalization of agency by proposing a novel approach: interpreting systems as solving Partially Observable Markov Decision Processes (POMDPs). The authors argue that a system can be considered an agent if it exhibits behaviors consistent with an optimal policy within a POMDP framework. This approach moves beyond purely physical descriptions of agents and introduces a more abstract, computational perspective. The core idea is that a stochastic Moore machine – a system with an internal state, an input space, and a machine kernel – can be interpreted as solving a POMDP if its internal state parameterizes a belief state, and if the actions taken by the machine are consistent with an optimal policy within that belief state. This definition provides a formal framework for understanding agency.### MethodologyThe authors build upon existing work in Bayesian filtering and decision theory. They define a stochastic Moore machine as the core computational unit for this interpretation. A stochastic Moore machine is a system with an internal state space, an input space, and a machine kernel that maps inputs to the internal state. The machine kernel is a probability distribution that governs the transition between internal states. The authors then define a POMDP as a tuple consisting of a hidden state space, an action space, a transition kernel, and a reward function. The key insight is that a stochastic Moore machine can be interpreted as solving a POMDP if its internal state parameterizes a belief state, and if the actions taken by the machine are consistent with an optimal policy within that belief state. The authors provide a formal definition of this interpretation, which states that a system can be interpreted as solving a POMDP if it has a consistent Bayesian influenced filtering interpretation and outputs the optimal policy.### ResultsThe authors demonstrate that a stochastic Moore machine can be interpreted as solving a POMDP. They show that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state. They provide a formal definition of this interpretation, which states that a system can be interpreted as solving a POMDP if it has a consistent Bayesian influenced filtering interpretation. The authors show that the stochastic Moore machine can be interpreted as solving a POMDP, and that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state. The authors show that the stochastic Moore machine can be interpreted as solving a POMDP, and that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state. The authors show that the stochastic Moore machine can be interpreted as solving a POMDP, and that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state. The authors show that the stochastic Moore machine can be interpreted as solving a POMDP, and that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state. The authors show that the stochastic Moore machine can be interpreted as solving a POMDP, and that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state. The authors show that the stochastic Moore machine can be interpreted as solving a POMDP, and that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state. The authors show that the stochastic Moore machine can be interpreted as solving a POMDP, and that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state. The authors show that the stochastic Moore machine can be interpreted as solving a POMDP, and that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state. The authors show that the stochastic Moore machine can be interpreted as solving a POMDP, and that the internal state of the machine parameterizes a belief state, and that the actions taken by the machine are consistent with an optimal policy within that belief state.### DiscussionThe authors argue that this approach offers a more formal and rigorous way to understand agency, moving beyond purely physical descriptions. They highlight the importance of interpreting a system’s internal state as a belief state, and using this belief state to drive actions consistent with an optimal policy within a POMDP. They state that the convenient feature of POMDPs for their purpose is that the optimal policies are usually expressed as functions of probabilistic beliefs about the hidden state of the POMDP. For this to work, the probabilistic beliefs must be updated correctly according to Bayesian principles. It then turns out that these standard solutions for POMDPs can be turned into stochastic Moore machines whose states are the (correctly updated) probabilistic beliefs themselves and whose outputs are the optimal actions. This has two consequences. One is that it seems justified to interpret such stochastic Moore machines as rational agents that have beliefs and goals. Another is that there are stochastic Moore machines that solve POMDPs. Accordingly, our definition of stochastic Moore machines that solve POMDPs (definition5) applies to these machines.### Key TermsAgency · POMDP · Bayesian filtering · Bayesian inference