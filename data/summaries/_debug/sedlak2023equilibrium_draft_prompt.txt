=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Equilibrium in the Computing Continuum through Active Inference
Citation Key: sedlak2023equilibrium
Authors: Boris Sedlak, Victor Casamayor Pujol, Praveen Kumar Donta

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Abstract: ComputingContinuum(CC)systemsarechallengedtoensuretheintricaterequirementsofeachcomputational
tier. Given the system’s scale, the Service Level Objectives (SLOs) which are expressed as these requirements,
mustbebrokendownintosmallerpartsthatcanbedecentralized. Wepresentourframeworkforcollaborative
edgeintelligenceenablingindividualedgedevicesto(1)developacausalunderstandingofhowtoenforcetheir
SLOs,and(2)transferknowledgetospeeduptheonboardingofheterogeneousdevices. Throughcollaboration,
they (3)...

Key Terms: continuum, equilibrium, devices, computing, slos, edge, requirements, inference, active, scale

=== FULL PAPER TEXT ===

Equilibrium in the Computing Continuum through Active Inference
Boris Sedlak∗, Victor Casamayor Pujol, Praveen Kumar Donta, Schahram Dustdar
Distributed Systems Group, TU Wien, 1040 Vienna, Austria
Abstract
ComputingContinuum(CC)systemsarechallengedtoensuretheintricaterequirementsofeachcomputational
tier. Given the system’s scale, the Service Level Objectives (SLOs) which are expressed as these requirements,
mustbebrokendownintosmallerpartsthatcanbedecentralized. Wepresentourframeworkforcollaborative
edgeintelligenceenablingindividualedgedevicesto(1)developacausalunderstandingofhowtoenforcetheir
SLOs,and(2)transferknowledgetospeeduptheonboardingofheterogeneousdevices. Throughcollaboration,
they (3) increase the scope of SLO fulfillment. We implemented the framework and evaluated a use case in
which a CC system is responsible for ensuring Quality of Service (QoS) and Quality of Experience (QoE)
during video streaming. Our results showed that edge devices required only ten training rounds to ensure four
SLOs; furthermore, the underlying causal structures were also rationally explainable. The addition of new
types of devices can be done a posteriori, the framework allowed them to reuse existing models, even though
the device type had been unknown. Finally, rebalancing the load within a device cluster allowed individual
edge devices to recover their SLO compliance after a network failure from 22% to 89%.
Keywords: Active Inference, Computing Continuum, Scalability, Edge Intelligence, Transfer Learning,
Equilibrium
1. Introduction Given the scale of the CC, requirements must be
decentralized; this means, that the logic to evaluate
ComputingContinuum(CC)systemsasenvisioned requirements must be transferred to the component
in [1, 2, 3] are large-scale distributed systems com- that they concern. Cloud-level requirements, i.e.,
posed of multiple computational tiers. Each tier Service Level Objectives (SLOs), may thus be bro-
serves a unique purpose, e.g., providing latency- ken down into smaller parts that are ensured by the
sensitive services (i.e., Edge), or an abundance of vir- respective components. To contribute to high-level
tual, scalable resources (i.e., Cloud). However, the goals, each device optimizes its service according to
requirements that each tier must fulfill are equally its scope. This allows SLOs to span the entire CC,
diverse, as they span a wide variety of edge devices also called Deep SLOs [4]. While it is one challenge
and fog nodes. Assume that requirements would be to segregate and disseminate SLOs, ensuring them is
ensured in the cloud, e.g., by analyzing metrics and another. Requirements are versatile and may change
reconfiguring individual devices, massive amounts of over time, every component must itself discover how
data would have to be transferred. Also, if edge its SLOs are related to its actions. For this to hap-
devices fail to provide their service to a satisfying pen, the device could use Machine Learning (ML)
degree, the latency for detecting and resolving this techniquestodiscovercausalrelationsbetweenitsen-
would be high. vironmentandSLOfulfillment[5]. Thispromotesthe
usage of Active Inference (ACI) [6], a concept from
neuroscience that describes how the brain continu-
∗Corresponding author
ously predicts and evaluates sensory information to
Email addresses: boris.sedlak@dsg.tuwien.ac.at
(Boris Sedlak), v.casamayor@dsg.tuwien.ac.at (Victor model real-world processes. Given these causal mod-
Casamayor Pujol), pdonta@dsg.tuwien.ac.at (Praveen els, components could adjust their environment ac-
Kumar Donta), dustdar@dsg.tuwien.ac.at (Schahram cording to preferences (i.e., SLOs).
Dustdar)
1
3202
voN
82
]CD.sc[
1v96761.1132:viXra
Ensuring SLOs autonomously (i.e., evaluating the wideQoSandQoEbycounterbalancingenviron-
environment to infer adaptations) makes components mental factors.
intelligent [7]; any system (or subsystem) composed
entirelyofsuchintelligent,self-containedcomponents The remaining sections of this paper are organized
becomes more resilient and reliable. No central logic as follows: Section 2 introduces background knowl-
must be employed to ensure SLOs; thus, higher-level edge that is a prerequisite for presented concepts.
componentscanrelyonSLOfulfillmentofunderlying Section 3 presents our framework for collaborative
components. Ascendingfromintelligentedgedevices, edge intelligence. Section 4 contains the prototypical
the next level would be intelligent fog nodes; those implementation of the framework and the evaluation
we see in the ideal position to orchestrate the service methodology; the respective results are presented in
of edge devices. Thereby, edge devices in proximity Section 5. Section 6 provides an overview of exist-
are bundled into a device cluster, administered by a ing research in this field. Finally, we concluded our
fog node; whenever the Edge is scaled up with new paper with a future scope in Section 7. For readers’
devices (or device types), existing SLO-compliance convenience, frequently used notations and acronyms
models can be exchanged within the cluster. While are summarized in Section Nomenclature.
each tier has its own SLOs, their tools for adaptation
can have a different scale, e.g., fog nodes would be
2. Background
able to shift computations within clusters, from de-
vices that fail their SLOs. Such operations can con- Theframeworkpresentedinthispaperbuildsheav-
sider environmental impacts (e.g., network issues), ily on two existing concepts that we adapt for our
but also heterogeneous device characteristics. usage, namely causality and ACI. Although these
To realize this vision, we present our framework topics might be known to some readers, we provide
for collaborative edge intelligence. Guided by ACI, this section to ensure a solid understanding of their
individual edge devices gradually develop a causal core aspects and terminology. Furthermore, since
understanding to ensure their SLO. This knowledge both concepts are not native to computer science (or
is federated through a device cluster; edge devices distributed systems), we highlight intersections with
of arbitrary types reuse existing models to ensure these fields as far as possible.
their SLOs. Thus, the entire Edge becomes spanned
with SLO-compliant devices, which allows other CC 2.1. Causality and Causal Network Graphs
tiers to construct their service on top. By the same
Causalityallowsmodelingcausalrelationsbetween
method, cluster leaders (i.e., fog nodes) infer how to
events or variables. While spurious correlations can
adjust their environment; each tier may thus achieve
mislead and hide the true causes, causality answers
an equilibrium for offering compound service.
why a specific event happened. However, to identify
Hence, the contributions of this paper are:
causal relations, specific experiments and consider-
ation of expert knowledge are required. To define a
• An ACI-based ML technique that allows CC
general theory for causality, Pearl [8] proposed Struc-
componentstograduallyidentifycausalrelations
tural Causal Models (SCMs). Such a mathematical
between environmental metrics and SLO fulfill-
model can be expressed through causal graphs, e.g.,
ment. Components can thus evaluate SLOs de-
as Directed Acyclic Graph (DAG). Thus, variables in
centralized and update their beliefs according to
thegraphcanbearrangedfromcausetoconsequence.
new observations.
Causality is a hot topic in research because of
• The transfer and combination of ML mod- its ability to provide explanations for phenomena
through interpretable graphical models. This is why
els between heterogeneous devices to accelerate
many works link causality and machine learning;
their convergence towards SLO-fulfilling config-
see[9]foracomprehensivereview. Thereby,causality
urations. This simplifies the onboarding of new
can also be embedded into distributed systems, e.g.,
device types in the Edge.
for root cause detection [10]. As another instance,
• An offloading mechanism that redistributes load Lin et al. [11] use causal graphs in Cloud computing
within an edge-fog cluster according to devices’ to detect dependencies within a microservices-based
capabilities to fulfill SLOs. It improves cluster- architecture. For such use cases, DAGs are an ideal
2
modeling tool. Interestingly, they monitor SLOs to herplants. Thediscrepancy(oruncertainty)between
trigger causal inference over their causal graphs, be- the agent’s understanding of the process and the re-
ing able to detect the source of the SLO violation. ality is called Free Energy (FE). In simple terms: the
Another crucial concept for our work – or gener- lower the FE, the higher the prediction accuracy.
ally for scalability in the CC – is the Markov Blanket Moreformally,inEq.(1)&(2),thesurpriseℑ(o|m)
(MB).ConsideraBayesiannetwork(BN)represented of observation o given model m is the negative log-
as a DAG (e.g., Fig. 3): a random variable is condi- likelihood of the observation. The surprise itself is
tionally independent of all other variables, given its capped by the FE of the model – expressed as the
MB. In other words, the MB of a variable shields it Kullback-Leibler divergence (D ) between approx-
KL
from all external variables. In a DAG, the MB of imate posterior probability (Q) of the hidden states
a variable consists of its parents, children, and co- (x) and their exact posterior probability (P).
parents. Discovering the structure of BNs and ex-
ModelEvidence
tracting MBs through data is not a simple task, and (cid:122) (cid:125)(cid:124) (cid:123)
ℑ(o|m) = −ln P(o|m) (1)
many works are devoted to that; see [12] or [13] for
specific techniques, and [14] for a thorough survey
F[Q,o] = D [Q(x)||P(x|o,m)]+ℑ(o|m) ≥ ℑ(o|m)
KL
on the topic. Regardless of the system size, MBs can (cid:124) (cid:123)(cid:122) (cid:125)
(Variational)FreeEnergy
achievemodularity; thus,thesystemcanbemanaged
(2)
and controlled on a convenient scale.
Internally, agents organize generative models in hi-
Graph-based causal models promise to extend sys-
erarchical structures; each level interprets lower-level
tems with explainability. Inspired by that, our work
causes and, based on that, provides predictions to
stemsfrom[2,15]tobuildMBsaroundSLO-governed
higher levels. For example, suppose (1) it rains with
components. Thus, itbecomespossibletoisolatesys-
a certain probability, (2) I bring an umbrella. This
tem variables that affect SLO fulfillment. On the one
is commonly known as Bayesian inference and allows
hand, thisdrasticallyreducesthenumberofvariables
agents to use priors (i.e., existing beliefs) to calcu-
required for analysis thanks to conditional indepen-
late the probability of related events. Thus, deci-
dence; the system can thus be managed at scale. On
sion processes can be segregated into self-contained
the other hand, it is possible to leverage the BN to
causal structures (i.e., MBs) that share only a lim-
explain causal effects between variables in the MB
ited number of interface variables. For example, only
and the SLOs’ behavior (e.g., failure).
the weather state (rainy or sunny) is considered for
picking the umbrella; any lower-level observations
2.2. Active Inference
thatdeterminedtheagent’sperceptionoftheweather
In this work, we use ACI to provide devices with (e.g., humidity or illumination) are disregarded.
the capacity to build causal knowledge on how to To decrease their FE, ACI agents repeatedly en-
fulfill their SLOs. However, we consider ACI an gageinaction-perceptioncyclesby(1)predictingsen-
unknown concept for most readers outside of neu- sory inputs, (2) awaiting (or seeking) the outcome,
roscience; therefore, we use this section to summa- and (3) updating beliefs. This phase is widely known
rize core concepts of ACI according to Friston et as predictive coding. Afterward, they can actively
al. [16, 17, 18, 19, 20, 21]. This includes (1) free adjust the environment toward their beliefs. As the
energy minimization, (2) hierarchical organization of agent’sinternalmodelsbecomeincreasinglyaccurate,
beliefs, (3)action-perceptioncycles, and(4)Bayesian causal relationships between the environment and its
inference and belief updating. preferences (e.g., SLOs) are revealed. Agents’ ability
to discover causal relations, however, is very depen-
2.2.1. Core Concepts
dentonthenumberandaccuracyofobservations[22].
Tointerpretobservableprocesses, agentsinternally Luckily, the CC provides an infinite amount of oper-
generate models that resemble these processes, e.g., ational metrics.
a human could reason that it rains due to water
drops falling from the sky. However, if this gener- 2.2.2. Intersection with Distributed Systems
ative model and the real-world process diverge, the While ACI seems a fitting choice to achieve causal-
agentwilleventuallybe“surprised”,e.g.,becausewa- ity in the CC, there is only limited work on this in-
terdropswereactuallycausedbyaneighborwatering tersection. To date, most (non-theoretic) research on
3
uated to continuously train an ML model and adapt
Federate Transfer Model the service accordingly; this model is then federated
and combined at a (fog) node, which provides the
Evaluate SLOs Optimize SLOs model to an unknown device type (marked as red).
Improve Model The fog node analyzes the overall SLO fulfillment in
Adapt Service Prepare Model the cluster; if it appears beneficial to offload compu-
tation from one device to another one (e.g., from the
Stream Offloading blue to the red one), this is orchestrated by the fog
node. Logically, the model transfer and load balanc-
Figure 1: High-level overview of the collaborative edge intelli- ing rely on the SLO fulfillment in the Edge, which
gence framework that continuously improves model evidence, is why all three contributions are required to ensure
sharesthisknowledgebetweenedgedevices,andoptimizesSLO
SLOs on multiple tiers (or the entire CC).
fulfillment within this cluster.
3.1. Continuous Model Optimization
ACI has not been embedded and evaluated in op-
erative distributed systems (e.g., [19, 23]). To the Anaccurategenerativemodelallowsonetoexplain
best of our knowledge, our latest research [24] is thus a system’s behavior (e.g., why SLOs were violated),
among the few works that embedded ACI into dis- infer how to adapt the system to ensure SLOs, and
tributedsystems; anotherworkthatwewanttohigh- predict how changes will affect this. Further, predic-
light is Levchuk et al. [25], which created a decentral- tion errors are always propagated back to the agent
ized mechanism for team adaptation. so that the model can be improved according to the
For the remaining paper, our work in [24] pro- experienced deviations. In the following, we will first
vides valuable reference points; precisely, how ACI present the representation of the EOSC model and
agents can ensure SLO-compliant device configura- the applied training method. Afterward, this process
tions. Those agents operated parallel to ongoing pro- is integrated into an ACI agent, which uses this pro-
cessing and evaluated rational information (i.e., en- cess to continuously improve the model accuracy.
vironmental states) to adapt generative models ac-
cording to prediction errors. We call such a model 3.1.1. Static Model Training and Inference
– at its core a BN – an Equilibrium-Oriented SLO-
Within previous work [5], we presented the idea of
Compliance (EOSC) model. In the following, we will
obtainingagenerativemodelfromprocessingmetrics
extend these EOSC models to achieve equilibrium
and inferring system configurations that fulfill SLOs.
within the CC.
However, it lacked a formal implementation; this will
be the content of this section. Figure 2 summarizes
3. Collaborative Edge Intelligence our method to train the BN, which is required as a
causal structure for our framework:
To ensure SLOs throughout computational tiers, To report their current state, edge devices produce
we propose our framework for collaborative edge in- metrics throughout ongoing processing; this data
telligence that is constructed upon our three main can be used to create a generative model through
contributions: (1) The continuous model optimiza- Bayesian Network Learning (BNL) (#1). This re-
tion based on ACI, which ensures SLOs (locally) on veals(ideally)causaldependenciesbetweenvariables,
a device basis; (2) the federation and combination of including the impact of environmental changes (e.g.,
EOSC model between edge devices, which decreases increased incoming requests). To decrease the model
the overhead of training models for different device complexity, we identify a minimum number of vari-
types from scratch; and (3) the evaluation of SLOs ables that are relevant to fulfill system requirements
on a cluster-level, which can rebalance load within (i.e., SLOs); we call this subset the MB of the BN
the cluster according to environmental factors. (#2). Given the MB, we estimate the probability
These three contributions are described in the re- of SLO violations for different hypothetical scenar-
spectivesubsections(3.1to3.3);Figure1furthercon- ios and (#3) infer the device configuration with the
tains a high-level overview of the framework’s capa- highest statistical compliance level. In the following,
bilities. On the left, it is depicted how SLOs are eval- we elaborate on these substeps further.
4
Workload Service Level Objectives Algorithm 1 Hill-Climb search (HCS) algorithm
Energy INPUT: D, G , score and C
#2 Extract MB init
Delay OUTPUT: G // Learned Structure
final
1: G = G init , G final = G init
Metric [ ]
2: repeat
CPU utilization
Processing delay #1 BNL 3: score = Score(G,D)
Requests / Sec.
... 4: for each (X i ,X j ) ∈ G∀ i,j ≤ |G|,i ̸= j do
Ideal configuration Bayesian network Markov blanket 5: if !edge(X i ,X j ) then
Probability of SLO violations #3 Infer knowledge 6: G final = G final + edge(X i ,X j )
7: score′ = Score(G final ,D) using Eq. (3)
Figure2: TrainingaBayesianNetworkfromprocessingmetrics; 8: if score′ > score then
thisisusedtoextracttheminimumnumberofvariablesrelated 9: score = score′
to SLO fulfillment and a configuration that satisfies them.
10: else
11: G final = G final − edge(X i ,X j )
Bayesian Network Learning. BNL is an efficient way
12: end if
to generate the most accurate structure from given
13: end if
data; its two main parts are STRL – structural learn-
14: end for
ing of causal dependencies (i.e., DAG), and PARL –
15: until C is satisfied
parameter learning as quantification of variable de-
16: return G final
pendencies. Structure learning is categorized into
constraint-based (e.g., parent-child or grow-shrink)
and score-based approaches (e.g., Hill-Climb or ge- structure with the highest score. In this way, Algo-
netic algorithm) [26]. In this work, we consider a rithm 1 repeats Lines 2-15, until it reaches the max-
score-based Hill-Climb Search (HCS) algorithm be- imum score, and chooses the best DAG i.e., G .
final
cause of its rapid convergence, low complexity, and For a data set with 5 columns, the resulting graph
efficiency when considering limited attributes. The could look like Figure 3a. Afterward, as a second
goal of HCS is to identify the DAG G from given step in the BNL process, the variable relations are
final
data D, ∃! G = arg max score(G,D), where G∗ evaluated: For each node in G , the Conditional
final final
G∈G∗
Probability Distribution (CPD) is evaluated through
indicates the set of possible DAGs, and score(G,D)
Maximum Likelihood Estimation (MLE). The MLE
is calculated using Eq. (3) [27],
for BNL is calculated using Eq. (5),
score(S,D) = LL(G,D)±(ϕ(|D|)+||G||) (3)
MLE(θ|D) = sup LL(θ,D) (5)
θ
where LL(G,D) is computed using Eq. (4) ϕ(|D|)
is the Bayesian Information Criterion (BIC) which where θ ∈ G, and LL(θ,D) = P(D|θ). MLE esti-
can be computed as ϕ(|D|) = 1log(|D|), and ||G|| = mates the model parameters that maximize the like-
2
(cid:80) (|V|+|E|), where |V| and |E| denotes number of lihood of observed data. This determines the CPD of
vertices and edges in DAG G, each node given its parents in the network; the result
isstoredintherespectiveConditionalProbabilityTa-
|D|
(cid:88) ble (CPT). This concludes parameter learning.
LL(G,D) = |D|× ξ(x |Parent(x )) (4)
i i
i=1 Lemma 1: ThetimecomplexityofBNLisO(n×2ω)
where |D| denotes the number of rows in dataset Proof: Calculating time complexity for STRL and
D. ξ denotes entropy; it is calculated as PARL is NP-Hard, but there are also some positive
(cid:80)
Pr(x |Parent(x ))×log(Pr(x |Parent(x ))). tractability results under certain parameterizations
i i i i
[28, 29]. In general, the time complexity for BNL
The detailed pseudo-code for the HCS algorithm is is O(n×2ω log n), where n indicates the number of
presented in Algorithm 1. HCS starts with an empty nodes in resulting DAG, and ω denotes the width of
graph (G) and measures the score using Eq. (3). By the DAG. However, the algorithm runs similar recur-
adding or removing edges between variables, it cre- sive calls multiple times, and while avoiding identical
ates a set of neighboring structures and selects the recursive calls according to Darwiche[30], the BNL
5
Proof: MB of a target variable usually involve three
network streams network streams stages [33]. (i) Identify a parent-child (PC) set,
which takes more computation i.e., approximately
O(P ×2n+1), where n is the total number of nodes
consump consump
in DAG, and P denotes size of conditioned set while
searching PC. (ii) Identify spouses: worst case com-
bitrate CPU bitrate CPU plexity to identify spouses is O(C ×(n−C)), where
C is maximum size PC set for n. (iii) Extract MB: Fi-
(a)EntireDAG (b)MBfornetwork nally,toextractMBfrompreviousstepinworstcase,
it needs O(SK×C), where S, and K denotes number
Figure3: CausalvariablerelationsintheDAGofatrainedBN
ofspouses, andmaximumsizespousessetfromDAG,
respectively. Overall, O(P ×2n+1)+(C×(n−C))+
needs only O(n×2ω) for both structure and param- (SK×C), asymptotically O(P×2n) is the worst case
eter learning. time complexity for MB selection.
The ACI agent will use the presented BNL method Knowledge Extraction. There exist two main cate-
for constructing (and later updating) the EOSC gories of algorithms for extracting knowledge from
model: STRL trains a DAG through HCS; PARL eval- BNs,namelyApproximateInference(AxI)andExact
uates the conditional variable dependencies through Inference (EI). Given a BN and system requirements
MLE. Together, they can be used to create a BN (i.e., SLOs), we seek to extract probabilities of SLO
model from data D as model = PARL(STRL(D),D). violations under different environmental states. This
mechanism works equally for different CC tiers; an
Markov Blanket Selection. A BN contains by design edge device, for example, could use its BN to answer
directed relations and conditional dependencies of P(network > t), with t being a custom threshold.
random variables; however, to determine the state of For dynamic reconfiguration, we require inference to
anindividualnodex,onlyapartofthenetworknodes be (1) accurate, (2) converge reliably, and (3) fast for
are influential. This promotes the application of MB large networks. We argue that EI and, in particular,
[31, 32, 2], which shield a variable from all nodes that Variable Elimination (VE) [34] as an instance, fulfill
areconditionallyindependentofit. Supposewespec- these constraints. In the following, VE is explained:
ify an SLO according to device capabilities (e.g., net- For a BN with a node set {v ,v ,v ,v } ∈ V, VE
1 2 3 4
work throughput < t) and evaluate it using a single accepts a list of target variables T = {v ,v }, vari-
1 2
variable (e.g., network), we want to identify metrics able assignments A = [(v : a )], and an elimination
3 3
relatedtoSLOfulfillment. Namely, theseareallvari- order O = {v ,v }. The query provides the condi-
4 3
ables contained in the MB of network; the function tional probabilities of the variables T given assign-
MB(model,network) would thus return all blue nodes ments A. Each variable must either be eliminated or
in Figure 3b. within the target set, thus ∀v ∈ V,v ∈ T ⊕v ∈ O.
In this context, we distinguish between metrics VE iterates over O and eliminates variables from V
that statically reflect the system state (e.g., CPU), while updating the beliefs of the remaining nodes; V
and those that represent a parameterizable variable thus eventually contains only T. In the given case, v
4
(e.g., bitrate). However, we summarize both using is eliminated first and v second; the difference is the
3
the term ”metrics” from a BNL perspective. While assignment of v , which introduces evidence in the
3
static metrics are essential to explain why an SLO is form of P({v ,v }|v = a ). While the elimination
1 2 3 3
in its current state, only parameterizable ones can be order has no functional consequence, it is relevant for
dynamically reconfigured, i.e., they are the possible the efficiency of VE and thus its scalability.
action states of the ACI agent. Overall, the sum of For the following example, recall the DAGs from
metrics in the MB provides a clear understanding of Figure 3: We construct a QoS SLO that is ful-
why an SLO is in its current state. filled if network is below t and infer the proba-
bility of SLO violations for different variable as-
Lemma 2: The time complexity for MB selection is signments. To decrease the complexity, we execute
O(P ×2n) VE only on mb = MB(model,network), the node
6
list V thus equals {network,streams,bitrate}. For 3.1.2. Active Inference Cycle
laterusage,wecallVEthroughINFERENCE(m x ,T,A), The tools presented in the last section allowed cre-
where m x can be any subset of the BN. We exe- ating a BN from processing metrics, extracting an
cute INFERENCE with mb, T = {network}, A = MB, and inferring system configurations that fulfill
[(streams : 2),(bitrate : 720)], and arbitrary O. given SLOs. Supposed there is sufficient data avail-
The result contains all conditional probabilities of able, BNL can be a one-time process; however, there
network given the variable assignment; from which are two fundamental issues: (1) data shifts, which
we can extract P(network > t). likely occur after some time, will inevitably distort
the accuracy of the ML model, and (2) it is impracti-
cal to empirically evaluate how an exponential num-
This will be our central mechanism for identify-
ber of system configuration impacts SLO fulfillment.
ingtheprobabilitiesofSLOviolationsgivenasystem
Large and complex systems, such as the CC, require
state. If an SLO is violated due to an environmen-
a different approach, one that creates and updates a
tal change, e.g., higher streams and thus exceeded
model incrementally according to new observations,
network, wecancomparepossibleconfigurationsand
and at the same time draws conclusions for unknown
provide the one with the highest probability of ful-
parameter combinations from existing data.
filling the SLO. In the given example, only bitrate
To evaluate this parameter space of configurations,
can be parameterized (i.e., configured); to fulfill the
we extend the ACI agents from [5] to interpolate be-
network SLO, the corresponding measure could thus
tweenempiricallyevaluatedcombinations; further,to
be to decrease bitrate. This matches our envisioned
maintain the model’s FE low, the agent continuously
level of intelligence, i.e., ”understanding a situation
updates conditional probabilities of variable relation
and reacting according to needs”, and neatly fits the
according to new observations. In theory, our ACI
principles of elastic computing [35].
agents can be employed at any CC tier; neverthe-
less, the running example in this paper is focused on
Lemma 3: The time complexity for knowledge ex-
intelligent edge devices, which collaborate under the
traction is O(n×τν+1)
supervision of a fog node. Thus, we raise the granu-
Proof: The complexity of knowledge extraction is
larity of intelligence from the Edge to the Fog. The
primarily determined by the VE process, whereas
causality filter employed by our framework allows to
other stages are linear or constant. The VE requires
manage each layer alike – to ensure SLO fulfillment
O((𭟋+n)×τν) [36]. Here, 𭟋 is the number of fac-
on a higher scale, any upper layers can build upon
tors in the model m, n is the number of nodes in V,
the SLO compliance of lower levels. In the follow-
ν is the induced width of the elimination order i.e.
ing, we will present the different tasks and subtasks
|O| (for example, |O|=2 for our running case study),
executed by an Edge-based ACI agent; this includes
and k is the maximum cardinality of a variable in V.
training and updating the BN, as well as evaluating
Since m < n and m is chosen as small as possible, we
its scope of actions according to a set of behavioral
can consider VE’s complexity as O(n×τν+1). This
factors. Based on that, the agent decides if and how
equals the overall knowledge extraction.
to modify the system, which will again be reflected
through system metrics.
Theorem 1: The time complexity for Static Model
Training and Inference is O(n×τν+1) Agent and Operation. The ACI agent operates par-
Proof: The complexity of Static Model Training and allel to regular device tasks, e.g., serving clients. Al-
Inference dependsonBNL,MBselection, andknowl- though regular operation, model training, and infer-
edge extraction. The complexity of BNL, MB se- ence are logically separated, they take place on the
lection and knowledge extraction are O(n × 2ω), samephysicaldevice;Figure4containsavisualrepre-
O(P × 2n), and O(n × τν+1), respectively (accord- sentation of that: assume an edge device that contin-
ing to Lemma 1 – Lemma 3). So, the complexity for uouslyperformsaworkload,e.g.,processingdatapro-
Static Model Training and Inference isO(n×2ω+P× vided by clients. The agent observes the device state
2n+n×τν+1). We assume, k > 2, P < n and ν < n, and the environment through metrics; thus, it can
so the asymptotic complexity of Static Model Train- evaluatewhetherprocessingcomplieswithSLOs,e.g.,
ing and Inference can be concluded as O(n×τν+1). if a request was finished with delay < t. From that
7
Predict Sensory Input Suggest Changes Reconfigure
Compare to Event
Process Data
Update Beliefs
Provide Metrics
Energy
Delay
SStrtereaamm D Daatata
Causal Graph || Conditional Probabilities Service Level Objectives
Figure 4: Overview of the Active Inference cycle – learning how to fulfill SLOs by adapting the generative process
data, the agent creates a BN (as in Section 3.1.1), thatproducesitemsinbatchesof500ms,theACIcy-
where conditional probabilities reflect the SLO ful- cle (i.e., predicting, comparing, and updating beliefs)
fillment under a discrete environmental state. Then, must be completed within this timeframe. On the
the agent starts with predictive coding, i.e., forecast- other hand, large and complex BNs, i.e., hierarchi-
ingwhetherfutureeventswillfulfillSLOs, comparing cally deep ones, require higher computational effort
the expectation with actual observations, and updat- to execute inference queries, while sparse graphs may
ing the BN accordingly. failtocaptureallcausalrelations[14];predictionswill
After each iteration, the agent infers how to mod- thus be increasingly inaccurate because dependencies
ify the system configuration to optimize local SLO within the environment were not revealed. Neverthe-
fulfillment. Following that approach, the ACI agent less,executinginferencequeriesontheMBofatarget
can create a generative model from scratch or update variable (i.e., a subsection of the graph), is a viable
a BN according to new observations by following its way to decrease the query complexity.
sensing-acting loop. Thus, it is possible to cancel out Regardless of whether dense or sparse, the DAG
datashifts,whichmight,e.g.,betheresultofamodel and the CPTs, i.e., the main parts of the BN, are
transfer from one edge device type to another. ACI under constant optimization; they are the priors of
can therefore perform the fine-tuning that is required the model – the initial assumptions that will be up-
after such an operation. datedaccordingtopredictionerrorstoformposterior
beliefs. Forexample,assumeanedgedevicethatpro-
Model Boundaries. The trained model reflects the cesses video streams, for which the ACI agent trains
characteristics of the workload and the environment; a model (as presented in Figure 4); variables in the
in other words, the accuracy will be higher in pa- BN are related, as shown in Figure 3a. Whether
rameter spaces that are more exploited by the agent. the maximum network capacity (i.e., a QoS SLO) is
Environmental states that were not present during reached, is determined by the bitrate and the num-
modellearning, oronly toadegree thatdidnot allow ber of video streams; these, on the other hand, deter-
to identify causal relations, can thus only be treated minetheCPUutilizationofthedeviceandtheenergy
to a limited extent. This determines the boundaries consumption. While some variable relations can be
of the generative model, which manifest in terms of updatedatwill,e.g.,theimpactofCPU →consump-
temporal or hierarchical depth. In this context, Parr tion,othersaretiedtoenvironmentallimitations. For
et al. [21] provided a guideline for model design. example,whetherbitrate violatesanSLOconstructed
The temporal depth reflects the timely horizon of on network, is dependent on the device characteris-
predictions,e.g.,predictionsthatcoverashortperiod tics. In the latter case, network is not immutable
(i.e., a low number of observations) have lower preci- but only updated as the environment changes, e.g.,
sion than long-term averages. According to [5], it is because the network interface is upgraded.
a natural choice to align the length of the ACI cycle
to the frequency of new samples coming in. For ex- Free Energy Minimization. To create an accurate
ample, if an edge device controls a production engine model, the ACI agent operates in cycles; each cycle
8
processes a batch of observations that reflects the en- Algorithm 2 SURPRISE for model and batch
vironmental state, including the latest system config- Require: model, batch, V
SLO
uration. The agent continuously evaluates the batch, Ensure: ℑ // surprise over all observations
updates its model, and chooses which system con- 1: ℑ ← 0
figuration (c next ) to choose for the next iteration. 2: mb ← MB(model,V SLO )
Throughout these cycles, the ACI agent has one cen- 3: for each var in V SLO do
tral goal: decreasing the FE, or in other words, mini- 4: log likelihood ← 0
mizingsurpriseofpredictions. Therefore,wewillfirst 5: ev ← MB(model,var)
present how we calculate surprise and then embed it 6: for each row in batch do
into the high-level loop executed by the agent. 7: evidence ← row∩ev
For calculating the surprise for batch and model 8: p ← INFERENCE(mb,var,evidence)
we present Algorithm 2; this can be seen as an imple- 9: log likelihood ← log likelihood+log(p)
mentation of Eq. (1). To decrease the complexity, we 10: end for
limit the calculation to variables that directly reflect 11: cpt ← CPT(model,var)
SLO fulfillment (V SLO ), and execute INFERENCE only 12: k ← |cpt| // number of states in the CPT
on the MB of V SLO (Line 2). This node set is further 13: n ← |batch|
filtered(Line5)tocontainonlytheevidencevariables 14: bic ← (−2)×log likelihood+k×log(n)
(ev) that impact the outcome of var; afterward, in 15: ℑ ← ℑ+bic
Line 7, each row in the batch is filtered to contain 16: end for
only these variables. In Lines 8 & 9, the probabil- 17: return ℑ
ity of observing var, i.e., the state of the SLO, given
the environment (evidence) is first inferred and then
appended as log likelihood. For each var, the cpt
from model is considered, from which k – the num- Behavioral Factors. The behavior of the ACI agent,
ber of states – can be extracted as a representation of i.e., how it selects between possible system configura-
model complexity. CPT is as a helper function to get tions,isdeterminedbythreemajorfactors: Theprag-
the CPT for a var in model. Together with n – the matic value (pv) defines how well the device fulfilled
number of observations – the BIC is calculated (Line client expectations, e.g., if a streamed video’s res-
14). Aftercalculatingthesurpriseforeachvar×row, olution is satisfactory. The risk assigned (ra) deter-
this overall sum is returned. mineshowlikelythesystemwillfailitsservice,e.g.,if
The surprise has a special role within our ACI cy- the stream packets are delivered on time. Lastly, the
cle, as it determines when and how BNL takes place; information gain (ig) represents the agent’s expec-
considerthereforeAlgorithm3,whichshowsthehigh- tation of how much it can improve model accuracy.
level loop executed by the ACI agent. At the begin- The ig is directly related to surprise minimization,
ning of each iteration, the agent ensures that there whereas pv and ra reflect the agent’s capability to
exists a model, otherwise, it creates an initial struc- fulfill SLOs. To separate concerns, we divide SLOs
ture from batch (Lines 1 & 2). Notice, that STRL and according to their characteristics: pv represents QoE
PARL accept now another parameter – model – which requirements, while ra contains QoS requirements.
allows to update the DAG and CPTs of model ac- Combined, these three factors determine the behav-
cording to batch. Whether STRL or PARL is executed ior of the agent; in the following, we will calculate
(Lines 7-11) is determined by the surprise magnitude each of them.
(s). If s exceeds the median surprise of the last 10 To infer the optimal device configuration (i.e.,
rounds (m ) by a custom factor h, STRL is applied; the one with the highest SLO fulfillment), it would
10
otherwise, if s exceeds m , PARL is applied. This be necessary to evaluate a potentially exponential
10
distinction is necessary because STRL and PARL have amount of parameter combinations. As discussed be-
quitedifferentruntimes,aswewillrevealinSection5. fore, this is impractical. To that extent, the agent
Finally, in Lines 12 & 13, the agent evaluates possi- limits itself to finding the Bayes-optimal configura-
ble system configurations and determines which one tion [37], i.e., the optimal under current knowledge.
it will use for the following iteration. We will explain Therefore, the ACI agent first infers the assignment
these two functions in the next two paragraphs. for known parameter combinations (c ) that were
k
9
Algorithm 3 An Iteration in the ACI Cycle
Require: model, batch, ℑ, h, V
SLO
Ensure: c // Next configuration
next
1: if model = ∅ then
2: model ← PARL(STRL(∅,batch),batch)
3: end if
4: s ← SURPRISE(model, batch, V SLO )
5: ℑ ← ℑ∪{s}
6: m 10 ← median(ℑ 10 ) // over the last 10 values (a)Interpolationforpv (b)ig after1round
7: if s > (m 10 ×h) then
8: model ← STRL(model,batch) Figure5: MatricesofbehavioralfactorsusedbytheACIagent
9: else if s > m 10 then
10: model ← PARL(model,batch) arrangedina[fps×pixel]2Dmatrix. Aftercalculat-
11: end if ing K, the unknown spaces in the parameter matrix
12: K ← CALCULATE FACTORS(model) are filled by performing linear interpolation1. As a
13: c next ← BEST CONFIGURATION(K) resulting example, we provide the matrix depicted in
14: return c next Figure 5a. Later, in Section 4.2, the agent will inter-
polate within a 3D parameter space.
Contrarily to pv and ra, the agent does not ap-
empirically evaluated and then interpolates between
ply interpolation to estimate the ig of an unknown
these values to span the entire parameter space. Cal-
parameter configuration. Instead, in the absence of
culating pv and ra is similar to Algorithm 2 (Lines
observations for c, it assumes that ig(c) = max(ℑ).
5-8): It requires a subset V ⊆ V – either QoS or
Q SLO
Further, it remains to introduce a hyperparameter
QoE SLOs – which is used as ev ← MB(model,V ).
Q
fromEq.6,namelye. Toimprovetheinterpolationof
Foreachrowinc ,evidenceisconstructedequally,so
k
pv and ra, the agent initially focuses on key positions
that INFERENCE(mb,V ,evidence) provides the joint
Q
of the possible configurations. Figure 5b illustrates
probability of all QoS or QoE violations.
that tendency; the visually highlighted blocks are in-
(cid:32) ℑ˜ (cid:33) creased by e = 0.3. When calculating the behavioral
c
ig(c) = e+ ℑ¯ ×100 (6) factors, the ACI agent thus initially focuses on these
cornerstonestosetuptheinterpolation; aftervisiting
c, it subtracts e from ig(c).
In accordance with [24], high surprise indicates
To summarize the possible risks but also benefits
high information insight and, hence, possible im-
that emerge from a configuration c, we combine the
provement of the model precision. However, from an
three factors under a common one (u) that is cal-
agent’s perspective, is it worth abandoning a suppos-
culated as u = pv + ra + ig . The ACI agent
edlysatisfactoryconfiguration(intermsofpv andra) c c c c
compares the common factors of all possible config-
to search for a global optimal one? This presents a
urations and selects the highest-scoring one (Line 13
tradeoff between exploration of unknown areas and
of Algorithm 3). By repeating this cycle, the agent
the tendency to stick to exploited areas; multi-agent
gradually develops an understanding of which areas
systems commonly model this through hyperparam-
intheparameterspacearemorelikelytofulfillSLOs,
eters (e.g., [25]). In our case, we calculate the ig of
e.g., the left-bottom area in Figure 5a.
a configuration c ∈ c as presented in Eq. (6) [24]:
k
it compares the median surprise (ℑ˜ ) for c with the
c
overall mean surprise (ℑ¯). Configurations with high Theorem 2. The time complexity for Active Infer-
ℑ˜ will thus be preferred by the ACI agent. ence Cycle is O(n×2ω)
c
Proof. The time complexity for the Active In-
Parameter Space. By the presented means, the ACI ference Cycle is determined by combining the com-
agent calculates the behavioral factors for all entries
in c and summarizes them as K (Line 12 of Algo-
k 1In fact, this will be done using the Python scypy package,
rithm 3). For the next step, imagine two configura-
which triangulates the input data through a convex hull, and
tion parameters {fps,pixel} with their combinations performs on each triangle linear barycentric interpolation.
10
plexities of Agent and Operation, Model Boundaries,
Classify Devices
FE Minimization, Behavioral Factors, and Parame-
ter Space. Except for FE Minimization, all other
Prepare Model
stages are computed using constant i.e., O(1) or lin-
ear time i.e., O(n). FE minimization takes O(n3)
(accordingtoZuker’sRNApredictionapproach[38]).
Algorithm 2 makes a key role in FE minimization EOSC Model Device Char.
and it is mainly depends on number of V and
SLO
batch size i.e., |batch|. So, the asymptotic complex-
Cluster
ityforAlgorithm2isapproximatelyO(V ×batch)
SLO
(Note: Constant time excluded.). The complexity
of Algorithm 3 depends on three functions such as
Surprise calculation (SURPRISE), Structure learning
(STRL),andParameter(PARL)learning. Accordingto
Lemma 1 and Darwiche, we can conclude asymptotic
complexity for ACI cycle iteration when model = ∅
and s > (m × h) for all cases is determined as
10
O(2 × n × 2ω). In summary, the time complexity
Figure6: TransferlearningbetweendevicesinanEdgecluster
for active inference cycle through iteration will take according to hardware characteristics
≈ O(n3)+O(V ×batch)+O(n×2ω), and asymp-
SLO
totically i.e., ≈ O(n×2ω).
This concludes the agent’s continuous model op- processing hardware. For example, a multi-core de-
timization, which maintains an up-to-date model of vice is certainly capable of processing multiple video
a processing task (i.e., the generative process). The streams, while a single-core one is not. Furthermore,
high accuracy in the EOSC model allows the ACI the behavior of the ACI agent (i.e., which device con-
agent to infer (Bayes-)optimal device configurations, figurations it favors) and the workload patterns (e.g.,
which ensures QoS and QoE of ongoing operation. In highdemandbyclients)determinewhichareasofthe
the following, we will now focus on the collaboration parameter space are more or less exploited.
between the Edge-based agents.
Whenever a new device (type) joins a cluster, the
question is whether there exists a device within the
3.2. Knowledge Transfer within the Cluster
cluster whose environment and characteristics match
By now, we presented ACI agents that can create
the newly-joint device’s. Consider Figure 6, the yel-
generative models from scratch or update a model
low and green devices were already present in the
according to new observations. However, if we as-
cluster and shared their EOSC models and device
sume a cluster of nearby devices that process similar
characteristics(e.g.,hardwarespecsorenvironmental
workloads, training EOSC models for every device
factors) with the cluster leader (i.e., standing hierar-
seems redundant. Also, if we aim to extend the clus-
chically above the device cluster). As the red device
ter with more devices (i.e., scaling up horizontally),
joins the cluster, the characteristics are compared to
model training delays the time until devices operate
select a fitting model. In cases where the charac-
according to requirements. Instead, we envision the
teristics of multiple devices are similar, their models
federation of knowledge between these edge devices
are merged and provided to the newly-joint device.
by exchanging EOSC models within the device clus-
Thus, the red device builds its EOSC model on top
ter. Suchatransferlearningapproachappearstobea
of existing knowledge in the federation.
straightforward process if the models were trained in
the exact same environment [39]. However, the real- In the following, we will dive deeper into this
ityisthattheEdgeiscomposedofmultipleheteroge- transfer-learning process by answering (1) how mod-
neous device types; the resulting models thus reflect els are federated between devices, (2) how hardware
the characteristics of the device it was trained on, characteristics are compared to select a model, and
i.e., its capability to cope with SLOs depends on the (3) how models are combined to fit the target device.
11
3.2.1. Cluster-wide Model Exchange hands – we are unaware of the dynamics of the envi-
Exchanging EOSC models has two directions: (1) ronment in which the device is set. Due to that, we
receiving – when joining a device cluster it might be focus on the device characteristics when transferring
preferable to adopt an existing model rather than models between edge devices. To that extent, we get
training one, and (2) providing – any device might it- inspiration from the work of Casamayor et al. [40],
self share its model with devices that join the cluster. which allows classification of heterogeneous charac-
Theselectionofafittingmodel, however, canhappen teristicsofthedevicesfoundinacluster,namelytheir
on any trusted device; we assume for this task either CPU and GPU capacity. This means that we rel-
a cluster leader (i.e., an outstanding device that was atively classify the CPU capacity (p) of the devices
electedduetoitscapabilities)orapowerfulfognode. in the cluster in a range [p min ,p max ], and their GPU
To provide an estimation, these models are suppos- capacity (g) from [g min ,g max ]. Given that there are
edly smaller than 2 MB, as measured in [5, 24]. numerous edge devices without GPU, it is possible
When making the architectural decision (i.e., ei- to set g min = 0. To make this more tangible, in
ther cluster leader or fog node), there are various fac- Section 4.2, we present a list of edge devices whose
tors to consider, among them: network scale, cost, hardware is classified accordingly. Finally, we define
geographic location, and availability. In cases where each device’s capacities as dc = p+g. To estimate
the cluster would be small (e.g., 10 devices), an edge the similarity of device characteristics and to iden-
device (e.g., chosen from Table 3) could cope with tify a device with a matching model, the leader node
collecting and preparing EOSC models; however, for selects the device(s) with the closest integer dc.
larger clusters (e.g., 1000 devices), regular edge de- Indeed, there exist other methods to classify edge
vices might fail to do so. In any case, a strong factor devices’ capacities, as well as to build the proximity
for using fog nodes is their high availability, as fog or distance score between them. However, we are
nodes could reliably cache a high number of EOSC choosing the presented one because it is simple and
modelsfromvariousedgedevices. Eitherchoice,they can be computed quickly. This is important because
assumethesameresponsibilities,whichiswhywecall devices are categorized relative to each other; due to
them simply leader node. This leader node periodi- that, the leader node must perform the classification
cally collects the EOSC models of all devices regis- repeatedly whenever a new device joins the cluster.
tered in the cluster, as well as their hardware charac-
teristics. Based on this information, models will be 3.2.3. Combination and Preparation of Models
provided for new device types. Heterogeneous edge devices differ in terms of hard-
ware characteristics; therefore, we identified mod-
3.2.2. Model Comparison and Selection els that were trained on comparable devices. How-
TransferringaEOSCmodeltoanewly-jointdevice ever, with the presented mechanism, there would fre-
raises two questions: First, is the transfer of an ex- quently occur situations in which there is not ex-
isting model more efficient than learning the model actly one device that trumps all others. For ex-
from scratch? And second, how to choose the most ample, consider a device with type t that wants
x
convenient model for the new device? Of course, the to join a device cluster; there are already numer-
second question assumes that the device type is un- ous device types present, among them t and t .
a b
known and the cluster does not contain the respec- The leader node classifies the device capabilities as
tive trained models so far. The first question will be dc = 3,dc = 5, and dc = 4. Which EOSC model
a b x
answered and discussed as a result of this article; the shouldnowbeprovidedtot ,theonetrainedont or
x a
secondquestion,however,requiresbuildingahypoth- on t ? And in case dc = 2 and dc = 7; is choosing
b a b
esis around how to choose a model. dc really the smartest choice here?
a
The dynamism within the training environment What we envision for both cases is merging the
hasadecisiveimpactontheresultingmodel: applica- models from t and t , thus creating a new model
a b
tionswithastablenumberofuserrequestsdonotsuf- t that presents the intersection between these two.
ab
fermanydynamics,whileapplicationsthatarelinked In the second case, where dc does not exactly fall
x
to specific events (i.e., disaster management) can ex- between dc and dc , this is done proportionately.
a b
perience extremely different requirements. However, Therefore, what is required is a mechanism to com-
we assume that environmental factors are out of our bineEOSCmodels–stillBNsattheircores. Todate,
12
merging BNs is an ongoing research field that still 3.3. Stream Offloading in the Edge-Fog Cluster
presents various limitations [41, 42]; in most cases, it
Regardless of whether trained by an ACI agent or
is coupled to conditions that the models must fulfill.
transferred from another device, a EOSC model is a
Due to this, we limit our work to merging CPTs.
decisive step toward SLO fulfillment. Thus, edge de-
Aslongastwomodelsm andm containthesame
a b
vices are continuously reconfigured to achieve maxi-
structure (i.e., their DAGs are identical) and their
mum SLO compliance. However, despite our efforts,
CPTshavethesamecardinality(i.e.,variablestates),
edgedevicesarestillvulnerabletoenvironmentalfac-
this can be done as follows: For a random variable r
tors that cannot be controlled, e.g., irregular peaks
anditsCPT(m,r),eachtablecell’sexpectedvalue(P)
in client traffic. While a EOSC model can have a
is calculated as shown in Eq. (7); P and P repre-
a b
hard time finding an SLO-compromising device con-
sent the probabilities in the cells of m and m , the
a b
figuration, idle edge devices in close proximity might
coefficients w and w reflect the distribution of dc
a b x
be available for offloading computation. Again, to
between dc and dc . For example, in case dc is
a b x
match our desired level of intelligence, this can be
aligned centrally between them, they take the value
achieved through collaboration between the agents.
w = w = 0.5; otherwise, it is shifted proportionally,
a b
Given that the struggling edge device is part of a de-
but w +w = 1 must always remain true.
a b
vice cluster, it is possible to (1) compare the device’s
P = (w ×P )+(w ×P ) (7) capabilities to fulfill their SLOs within their environ-
x a a b b
ment, and (2) balance the load accordingly. Notice,
Lemma 4. The time complexity for model prepara-
that shifting the load within the cluster is a (local)
tion is O((q+v)k+1).
reconfiguration that follows the same rules as in Sec-
Proof. Although multiplying table cells is a simple
tion 3.1; this time, however, on a higher level.
process, it has to be done for every CPT in the BN.
In the following, we describe how to evaluate, ana-
Notice, CPTs are multidimensional arrays with k+1
lyze, and optimize the cluster-wide SLO compliance;
dimensions, where k represents the number of incom-
the overall process is visible in Figure 7: The edge
ing edges for r. So depending on the complexity of
devices in the cluster (red & blue) serve their respec-
the BN, which consists of v variables with each up to
tive clients, e.g., by processing data, which is subject
q states, this can take O((q +v)k+1) multiplications
to dynamic reconfiguration according to the EOSC
for a fully connected graph.
model. Throughout processing, the edge devices sup-
ply their SLO fulfillment to the leader node. Among
If m and m do not fulfill the requirements
a b that, they provide other factors (i.e., as metrics) that
for simple multiplication, they would have to un-
potentially impact the fulfillment. Environmental
dergo a transformation process. Nevertheless, in Sec-
factors (e.g., insufficient hardware, power shortage,
tion4.2.2,weapplyaworkaroundtomergeBNwhose
or client demand) can thus be contrasted with the
CPTs have different cardinalities. Solving this is-
devices’ capacity to fulfill SLOs. Based on that anal-
sue on a general level requires dedicating future work
ysis, the leader reconfigures the cluster (e.g., by re-
solely to this challenge.
distributingtheload)sothatQoSandQoESLOsare
After merging the EOSC models, the leader node
optimized within the cluster.
provides the resulting model to the newly-joint de-
vice; once received, we consider the transfer learn-
ing completed. Thereby, it allowed us to decrease 3.3.1. Cluster-wide Evaluation of SLOs
the time required for model training or even skip it To analyze SLO fulfillment on a cluster level, the
entirely. The big remaining question is now: how leadernodedoesnothavetoevaluatetheEdge-based
accurately does the resulting model match the char- SLOs again – this is already covered within the Edge
acteristics of the new device? This will be evalu- tier. Instead, the leader node merely collects the
ated, as it determines the device’s capability to en- SLO compliance rate per device as a combined factor
sure SLOs. Nevertheless, consider that any trans- f = pv×ra. Thesemetricsarecollectedattheleader
ferred EOSC model can again be supervised by an node; depending on the desired amount of historical
ACI agent. Hence, even though the model would not data, the high availability of the Fog would again be
match perfectly, the agent can perform the required beneficialforcollectingthedata. Thequestionisnow
fine-tuning to ensure model accuracy. how to transfer metrics: Considering the potential
13
Redistribution Optimize Assignment Redistribution
Analyze Performance
SLO Fulfillment SLO Fulfillment
Stream Data
Offloading Stream
Reconfigure
Figure 7: Evaluating SLOs within a cluster of nearby edge devices and reassigning tasks
size of a device cluster, we opt for a push-based ap- Section 3.2.2). Although we ascended from an Edge
proach, where devices periodically supply their data to a cluster level, we still use the same tool for an-
to the cluster. alyzing and adapting the environment – the EOSC
Apart from the SLO fulfillment, edge devices pro- model. However, to make a distinction, we call this
vide metrics that reflect their current environmen- new instance a EOSC-F (Fog) model. To make the
tal state. This includes any factors that the leader EOSC-F model training autonomous, it can again be
node should consider; what cannot be quantified can guided by ACI.
alsonotserveasabasisforcluster-wideoptimization. Given a trained EOSC-F model (or rather, its
If a battery-equipped device suffers occasional power DAG), it is evident which environmental factors
shortages, it can report this conditional to the leader (σ ) have a causal impact on SLO fulfillment. This
env
node, which adapts the network, e.g., by offloading can also help to improve the QoS in the long run,
computations to other devices to decrease its power e.g., by pinpointing issues within the infrastructure.
drain. However, in the event of an entire network However, we aim to ensure SLO fulfillment the mo-
outage, devices can be incapable of reporting their ment the QoS or QoE drops; the EOSC-F model can
state, and another node (e.g., leader) would have to therefore consider the devices’ environment and re-
detect this. Other frequent conditions can be general distribute client load to ensure maximum SLO ful-
network congestion, including poor latency, jitter, or fillment within the cluster. To that extent, we
packetloss,butalsodevices’geographiclocation,user present Algorithm 4, which distributes a number of
density, andpeakusagetimes. Giventheirimpacton streams (n ) between the devices (Λ) in the clus-
client
the devices’ capacity to fulfill SLOs, the leader node ter. Notice, that Inference is again executed only
will rebalance the environment. on the variables that relate to SLO fulfillment, i.e.,
MB(model,f), byfilteringthemodel (Line2&10). In
3.3.2. Analysis & Optimization per Device Lines 6-18, the agent then iteratively assigns clients
Optimizing the devices’ environments requires to the device, whose SLO fulfillment is the least im-
methods to draw conclusions between discrete envi- pacted by receiving another stream (ass[λ]+1). This
ronmental states and their consequential SLO fulfill- assumes, that both ass and σ env are part of ev, i.e.,
ment. To that extent, we aim – again – to iden- have an impact on SLO fulfillment. To that extent,
tify causal relations between metrics; however, this σ env [λ] can contain factors like device characteristics.
time on a cluster level. Given a metric set (i.e., re- After assigning all streams within the cluster, the as-
flecting the environmental state) and the respective signment can be orchestrated to the clients.
SLO rates per device, the leader node can construct
a BN and infer how environmental changes impact Lemma 5. The time complexity for client reassign-
the SLO fulfillment. To accelerate the construction ment (Algorithm 4) is O(n2).
of such a model, the leader node can combine met- Proof. According to the step count method, the al-
rics from devices of the same type, or even those that gorithm takes Λ interactions for initial assignments.
havecomparablehardwarecharacteristics(asdonein Then, it take n times of Λ. So, the time com-
clients
14
Algorithm 4 Client reassignment algorithm EOSC approach is O(n×τν+1)
Require: model, n ,σ Proof. The proposed EOSC consists of three stages
client env
Ensure: ass // assignment according to env. state including Static Model Training and Inference, Ac-
1: i ← 0 tive Inference Cycle, Knowledge Transfer within the
2: ev ← MB(model,f) Cluster,andStreamOffloadingintheEdge-FogClus-
3: for each λ ∈ Λ do ter. It is measured as (n×τν+1)+(n×2ω)+((q+
4: ass[λ] = 0 v)k+1)+(n2). So, the asymptotic complexity of the
5: end for proposed work can be concluded as O(n×τν+1).
6: while i < n clients do
7: δ best = −∞ This concluded the redistribution of client load,
8: for each λ ∈ Λ do which optimized the overall SLO fulfillment in the
9: evidence ← ev∩(σ env [λ]∪ass[λ]+1) cluster according to the EOSC-F model. To transfer
10: δ ← INFERENCE(ev,f,evidence) intelligence to the network edge, or even to the level
11: if δ > δ best then of a cluster or fog node, this section provided various
12: δ best = λ concepts that all had the same goal: ensure SLOs
13: end if in the respective system. To that extent, it remains
14: end for to provide a prototypical implementation of the pre-
15: ass[δ best ] ← ass[δ best ]+1 sentedideas,evaluateitaccordingtokeyaspects,and
16: i ← i+1 argue to what extent it is ready for wider adoption.
17: end while This will be the content of the next two sections.
18: return ass
4. Evaluation
plexity can be defined as O(Λ+(n ×Λ)), which
clients In the following, we describe (1) a CC scenario
is ≈ O((n ×Λ)). In worst case n = Λ = n,
clients clients that requires edge devices to continuously transform
then the asymptotic time complexity for the client
video streams; this use case poses various require-
reassignment algorithm is O(n2).
ments that must be ensured throughout processing.
Afterward, we outline (2) our prototype that ensures
3.3.3. Orchestration and Redistribution SLOs through collaborative edge intelligence. Essen-
As a last step, the new cluster configuration must tially, this is the implementation of the framework
be enforced; in this case, by informing the perti- presented in this paper. Lastly, we explain (3) the
nent devices of the new assignment. The leader node methodology according to which the prototype will
pushes this information to all edge devices that must be evaluated. Section 5 will contain the respective
alter their configuration. In accordance with Fig- results.
ure 7, this includes all devices that offload or receive
clients (red & blue); thus, the red device redirects 4.1. Use Case Description
clients to the blue device. The CC as a distributed system provides unprece-
To improve the SLO fulfillment rate within the dented opportunities for service providers and clients
cluster, the assignment considered each device’s en- alike, e.g., in terms of processing or requirements as-
vironment to provide an adequate configuration on a surance. As an example, consider a region with fre-
cluster level. Regardless of whether the QoS was im- quentnaturaldisasterswherethehumanitariansitua-
pacted by poor network conditions or by poor hard- tionshouldbedocumented. Therefore,reporterspro-
ware, if these conditions are packed as stateful in- vide video streams in which vulnerable groups, e.g.,
formation, the leader node can optimize the cluster minors of age, are detected. In the same step, indi-
accordingly. Thus, it covers heterogeneities between viduals can be counted or visually highlighted; their
edge devices, which themselves might fail to scale identities, however, must be preserved. The region
their service given the stress introduced by the en- suffersfromoccasionalnetworkbreakdowns(i.e., this
vironment. affectsaccesstoglobalresourceslikethecloudbutnot
internal connectivity); the reporting team thus pro-
Theorem 3. The time complexity for proposed vides ad hoc networking infrastructure in the form of
15
edge devices, which can be installed in close proxim- 4.2.1. Prototype
ity to the operation area. Reporters equipped with We provide the Python-based prototype of our
IoT cameras are now capturing their surroundings; framework in a GitHub repository2; it contains all
the video streams are transformed on edge devices, source code we used to implement the three contri-
where they can be cached as long as global internet butions, as well as the EOSC models for each device
services are unavailable. Once resumed, the videos type. The core logic is separated into two classes:
are streamed to a cloud platform that provides the Agent and FogNode. These are the high-level loops
content to worldwide consumers. executedinthemainthread; allotherprocesses(e.g.,
ACI or VideoProcessor) run in detached threads.
Envisioned Solution. Due to the nature of how such The central library that is applied for training and
disasters happen, it is impossible to fine-tune the updating BNs, as well as running inference queries, is
complete streaming architecture beforehand. There- pgmpy [46]. pgmpy offersamplesupportofBNLtech-
fore, the system is unaware of how to ensure its ser- niques; however our choice is also motivated by per-
vice (i.e., characterized by a set of SLOs) within this sonal preference – the framework’s performance must
highly dynamic environment. To that extent, we ad- be analyzed under different libraries (e.g., as done by
vertise our framework for collaborative edge intelli- [47]). To improve the portability of our framework
gence as the missing piece: Edge devices are super- and simplify distribution, we provide a docker im-
vised by ACI agents, which ensure QoS and QoE age3 that can be executed platform independently4.
through their EOSC model. Whenever the comput- The image exposes multiple env variables for config-
ing architecture is extended with new devices (i.e., uring the solution, e.g., forcing the Agent to create a
scaled horizontally), existing models can be trans- EOSC model from scratch or disabling ACI entirely.
ferred to this new device, regardless of whether its The source code also contains the framework for
device type is known. Therefore, both devices must privacy-preserving stream transformation and the
bepartofacluster,inwhichtheleadernodeidentifies MLmodelsforface[48]andagedetection[49]. Toim-
the device whose hardware characteristics are most prove the reproducibility of results, we cancel out ir-
similar. Apart from that, the leader node continu- regularities in the video streams by processing prere-
ously analyzes edge devices’ capacity to comply with corded videos; these are contained in the same repos-
SLOs; in case some devices are excessively loaded or itory. To simulate redirecting IoT devices within
sufferfromshort-termnetworkissues,theassignment the cluster, it thus suffices to open/close processing
between IoT cameras and edge devices is adapted to threads on the edge devices; this simplifies network-
optimize the cluster-wide SLO fulfillment. ing. The Agent can thus reconfigure the stream as-
signment immediately, at the end of every ACI itera-
4.2. Implementation tion. Becausetheusecaseisfocusedonvideostream-
ing and the number of frames per second (fps) that
While the last part of the use case outlined the
are transferred, each iteration lasts up to 1000ms.
envisioned solution, not all of these aspects are im-
plemented and evaluated; in this regard, we focus on
4.2.2. Practical Limitations
theideaspresentedinthispaper. Thisespeciallycon-
Merging BN, as presented in Section 3.2.3, is only
cerns the three contributions of the presented frame-
possible under the specified conditions, which are not
work, i.e., the ACI-based model training, the knowl-
always given during the ACI process. The number of
edge transfer between heterogeneous devices, and the
states in a CPT, for example, is highly dynamic and
rebalancing of load according to environmental fac-
extended as new batches of data are received. To
tors. Aspects such as the bootstrapping of IoT and
merge the EOSC models under such circumstances,
edge devices and the leader node election (e.g., fog or
we provided a workaround: Instead of merging two
edge) have already been covered, e.g., by Murturi et
BNs (m and m ), we extend one of them (e.g., m ).
al. [43, 44]. The same applies to the cloud-based dis- a b a
tribution of video streams. An exception, however,
is the privacy-preserving stream transformation; for
2https://github.com/borissedlak/workload/tree/main/FGCS
3https://hub.docker.com/repository/docker/basta55/workload/
this, we make use of previously evaluated work [45].
4In fact the docker image is restricted to daemons with a
To give our evaluation more rigor, we chose this tool
linux/arm64 architecture. This is the embedded architecture
oversimulatingtheworkloadanditsimpactonSLOs. for all device in Table 3, except for Laptop (x86 64).
16
Thedevicethattrainedm maintainsabackupofthe to success, whereas the cluster-based EOSC-F model
b
training data (d ); this we use to update the CPTs treats the lower part. Notice that the metric’s ori-
b
of m through PARL5, i.e., m = PARL(m ,d ). No- gin, i.e., if it was measured from system stats or the
a ab a b
tice, that this merges the conditional probabilities of application, does not determine where it is used as
the models, but not the structure; this remains an a variable. From these variables, we construct SLOs
open question. While the resulting models are valid, thatreflectthesystemstateintermsofQoSandQoE.
we cannot assume that the original training data is The ACI agent considers this classification when cal-
always maintained. culating pv and ra (recall Section 3.1.2). In Table 2,
Another limitation is that the DAG of the model we present four SLOs that must be ensured during
cannot be updated frivolously through STRL; this edge-based processing and one that is ensured by the
triggers numerous updates within the CPTs of the cluster’s leader node. To simplify the EOSC models,
BN, which are not supported by default in pgmpy. we include the SLO into BNL and remove the source
Although bnlearn [50] promises these features, we variable, i.e., distance instead of distance
require a package that can be embedded into our We consider the presented SLOs relevant because
Python environment. Therefore, we make use of (1) network ensures that the combined number of
the following workaround: Instead of updating the video streams does not exceed the networking capa-
DAG of model m according to new observations bilities, (2) in time makes sure that frames are com-
a
batch, we train a new BN with data = batch ∪ d , puted within the available time frame, (3) success
a
where d reflects again the backup data. So inter- guarantees maximal privacy preservation, and (4)
a
nally, the ACI agent executes STRL(model,batch) as distance ascertains a smooth trajectory for tracked
PARL(STRL(data),data), which likewise updates the objects. The maximum slo rate speaks for itself.
CPTs with every execution. We consider it out of
scope to solve this limitation within our work. 4.2.4. Device Classification
Video processing is very dependent on the avail-
4.2.3. Variables and SLOs ability of GPU acceleration [45]; therefore, we apply
For the given use case, the agents consider de- multiple edge devices – with and without GPUs. All
viceandapplication(i.e.,videoprocessing)metricsto devices applied for this work are listed in Table 3; in
construct EOSC models. Internally, BNL transforms the following, we call them by their ID. The other
metrics into model variables, which are used to eval- columns contain hardware characteristics and – com-
uate conditional probabilities. Table 1 contains an plementarily–theoriginalpriceofthedevice. Aspe-
overview of all captured metrics; each row contains a cial instance is Xavier : while its physical hard-
CPU
description, measuring unit, and if it can be used as ware is equal to Xavier , we disabled the GPU ac-
GPU
parameter. Notice, that only parameterizable vari- celeration(i.e.,NVIDIACUDA)tocreateanotherde-
ables can be adjusted by the ACI agent to optimize vice type. Overall, our devices differ greatly in terms
SLOfulfillment. Forexample, pixel andfps arevideo of computing capabilities (e.g., missing GPU support
stream properties of the IoT device, which are recon- orahighlysuperiorCPUwith16cores);nevertheless,
figured by the edge device according to the agent’s as a whole, these devices compose the heterogeneous
behavior. The leader node, on the other hand, can edge layer of the CC architecture.
only adjust the number of streams per device; this, As a prerequisite for transfer learning, we classify
however, was out of scope for an individual device. devices in a cluster according to their hardware char-
The EOSC (or EOSC-F) models can be applied acteristics. Although this process is dynamic, i.e.,
in different computational tiers to ensure each tier’s done repeatedly as devices join or leave or leave the
unique requirements; thus, their model variables cluster, we focus our evaluation on a scenario where
mightnotoverlap. Theedge-basedEOSCmodelcon- the cluster contains all devices from Table 3, exclud-
tains the upper part of the variables, i.e., from pixel ing Xavier ; the latter will be the device joining
GPU
the cluster. As discussed in Section 3.2.2, we classify
5Thisfunctionalityisnativelyofferedbypgmpy;bydefault, these devices relative to each other according to their
themodelsaremergedproportionallytothenumberofsamples CPU and GPU capabilities; the results are contained
that m and d contain. This can be fine-tuned by adjusting
a b
the n prev samples parameter; we use this to prioritize new
observations batch over existing conditional probabilities. 6PriceasofOctober11th2023fromhttps://sparkfun.com/
17
Table 1: List of metrics captured by the devices, which are turned into variables by ACI
Name Origin Unit Description Param
pixel IoT num number of pixel contained in a frame Edge
fps IoT num number of frames received per second Edge
bitrate IoT num number of pixels transferred per second No
cpu Edge % utilization of the device CPU No
memory Edge % utilization of the system memory No
streams Edge num number of IoT devices providing data Fog
consumption Edge W energy pulled by the device No
network Edge num data transferred over network interface No
delay App. ms processing time per video frame No
success App. T/F if a pattern (i.e., face) was detected No
distance App. num relative object distance between frames No
slo rate Edge % combined SLO Fulfillment rate (pv×ra) No
device type Edge enum physical device type No
congestion Edge num network congestion that increases latency No
Table 2: Extracted SLOs and their classification. and parameter learning are recurrent factors in the
evaluation, we will put emphasis on when they hap-
SLO Condition Tier Type
pen. Namely, our questions include:
network network < 1.6 MB/s Edge QoS
A-1: Do MBs reduce the complexity of inference?
in time delay < 1/fps Edge QoS
success success = True Edge QoE Increasingly large BNs require mechanisms to limit
distance distance < 50 Edge QoE the complexity of a system; otherwise, resource-
restricted edge devices may fail to execute the ACI
slo rate max(slo rate) Fog Both
cycle within an induced time frame. The MB, as a
potential remedy, could achieve this.
in Table 4. To achieve the desired distance between
A-2: What is ACI’s operational overhead?
the scalars, the CPU is aligned between [1 ≤ p ≤ 4]
and the GPU between [0 ≤ g ≤ 2]. TrainingandupdatingEOSCmodelsdirectlyonedge
devices allows them to adapt quickly to system dy-
4.3. Evaluation Methodology namics. However, any overhead introduced by ACI
The implementation of the use case is thus set must not disrupt regular device operation, e.g., data
up for evaluation. To ensure a solid foundation for processing.
our framework, we will target each of the three pil-
A-3: How long require ACI agents to ensure SLOs?
lars (i.e., the contributions) individually. The order
TooptimizeSLOfulfillment,theagentmustbeableto
in which they are evaluated resembles the one used
infer adequate system configuration. However, there
throughout the paper; this makes sense also from a
is no guarantee after how many ACI iterations the
logical point of view because transfer learning and
model will converge to the desired accuracy. Hence,
stream offloading rely on the underlying ACI mecha-
we must provide an estimate for this.
nism. In the three paragraphs below, we outline the
evaluated aspects and motivate each question. Com-
A-4-1: Are the produced Bayesian networks inter-
bined, this represents our evaluation methodology.
pretable?
Active Inference. Our main interest includes the Large-scale distributed systems, e.g., the CC, require
executability of the ACI agent on edge devices and trusted and reliable components as a solid founda-
the extent to which the EOSC model improves the tion. Given that ACI can provide structures that are
SLO fulfillment within the Edge. Because structure empirically verifiable, this promises to increase trust.
18
Table 3: List of devices used for implementing and evaluating the presented methodology
Full Device Name ID Price6 CPU RAM GPU
ThinkPad X1 Gen 10 Laptop 1800 € Intel i7-1260P (16 core) 32 GB Incompatible
Jetson Orin Nano Orin 500 € ARM Cortex A78 (6 core) 8 GB Volta (383 core)
Nvidia Jetson Nano Nano 150 € ARM Cortex A57 (4 core) 4 GB Incompatible
Jetson Xavier NX Xavier 300 € ARM Carmel v8.2 (6 core) 8 GB Disabled
CPU
Jetson Xavier NX Xavier 300 € ARM Carmel v8.2 (6 core) 8 GB Amp (1024 core)
GPU
Table 4: Classification of device hardware and assigned scalar Knowledge Transfer. After focusing on the train-
ing of EOSC models, we are mainly interested in how
Device ID CPU [1,4] GPU [0,2] Σ
well the created models can be exchanged with other
Laptop Very High (4) None (0) 4 edge devices, and if this promises to improve the
Orin High (3) High (2) 5 training time. Ideally, we would thus reuse existing
Nano Low (1) None (0) 1 knowledge instead of “rediscovering” it.
Xavier Medium (2) None (0) 2
CPU
K-1: How high is the SLO fulfillment of transferred
Xavier Medium (2) Low (1) 3
GPU models compared to ACI-trained ones?
Transfer learning can provide ML models (i.e., spe-
A-4-2: Is the behavior of ACI agents explainable? cific for one device) to other devices. However, it
is not guaranteed that a transferred model performs
Being able to understand an agent’s decisions allows
equally to a model specifically trained for a device.
to justify (or empirically debug) its behavior, e.g.,
For example, the transferred model might be more
why the agent chose a certain device configuration
likely to violate SLOs; hence, this must be examined
at a specific time. If agents follow patterns, this also
by comparing the produced results.
simplifies the configuration of hyperparameters.
K-2: Can knowledge transfer achieve any speedup?
A-5: WhatistheoperationalimpactofincludingBNL
Transferring a trained model removes computational
in the ACI cycle?
overhead (A-2) from the recipient; thus, it could de-
BNL was identified as the dominant factor for the
creasetheoverallenergydedicatedtomodeltraining,
complexityoftheACIcycle; therefore,wemustascer-
most beneficial for resource-restricted edge devices.
tain whether edge devices can perform BNL without
Furthermore, this could decrease the time required
limitations. Depending on the results, the two pro-
to ensure SLOs (A-3).
cesses could be broken up into a federated learning
approach, e.g., to execute sub-steps in the Fog. K-3: Can merged models decrease the FE compared
to choosing a single one?
A-6: Canchangesinvariabledistributionbehandled?
Models with low FE can infer SLO-fulfilling sys-
Real-world generative processes are not guaranteed
temconfigurationswithhigheraccuracy. Exchanging
to stay stable, a small environmental change (e.g., a
knowledge within the cluster can include the combi-
new client) might suffice to change the SLO outcome.
nationofmultipleeligiblemodels. However, cansuch
Nevertheless, these changes should be detected and
combinedmodelsinterpretobservationswithlesssur-
resolved through ACI-based model training.
prise compared to a single transferred model?
A-7: Can SLOs be modified during runtime?
Stream Offloading. To optimize their SLO fulfill-
In the CC, edge devices can be administered by en- ment,intelligentedgedevicecontinuouslyadapttheir
tities that stand hierarchically above them; these can environment. However, if there are environmental
change their role in the architecture, or more simply, factors that are out of their scope (e.g., network
their SLOs. If the device could not adapt its existing failures or hardware limitations), the device cluster
EOSC model, it would have to train from scratch. can be the remedy to compensate for these issues.
19
In this context, we want to determine whether the
SLO fulfillment of individual devices can be recov-
ered through collaboration.
S-1: How is the load distributed among resource-
constrained devices?
The Edge, as one CC tier, allows clients to request
services from nearby edge devices; however, this fos-
terssituationswhereloadishighlyunbalancedwithin
the system. This might cause resource-restricted de-
vices to fail their service; once this is detected, the
load must be rebalanced within the system.
S-2: Can the CC hierarchical structure optimize local
SLO fulfillment? Figure8: DurationoftheACIcycledependingontheapplica-
tion of an MB and the number of SLOs (A-1)
Depending on the scale of SLO failures, individual
devices may be incapable of recovering their service
through local reconfiguration. Nevertheless, higher Weobservetwothings: (1)applyinganMBreduces
entities in the CC (e.g., the device cluster) can eval- themedianexecutiontypesignificantly, i.e., from191
uate and resolve this by employing their own SLOs. ms (grey) to 159 ms (blue) for 4 SLOs, and (2) de-
creasing the number of SLOs gradually reduces the
execution time further. We thus conclude that MBs
5. Results and Discussion
can reduce the complexity of VE (A-1).
In the following, we will evaluate the prototype ac-
cording to the presented methodology. We structure A-2: What is ACI’s operational overhead?
our results according to the three contributions and
the evaluation order used in Section 4.3; based on To evaluate the operational overhead of ACI, we
the results, we pose derivative questions for future use pre-trained EOSC models for Xavier and
CPU
work. At the end of this section, we take a step back Xavier . Each device processes 6 video streams.
GPU
(i.e., not focusing on particular questions), look at WemeasuretheCPUload(%)ofthetwodeviceswith
the results as one coherent framework, and discuss oneofthesetwoconfigurations: (1)ACIenabled,and
the applicability of our approach. (2) ACI disabled. We capture the load over 10 min;
this produces 600 observations for each experiment.
5.1. Active Inference
In Figure 9, we show the CPU load of Xavier
CPU
and Xavier . The left bar of each device shows
A-1: Do MBs reduce the complexity of inference? GPU
the load when operating with ACI and the right one
without (i.e., disabled) ACI.
To show whether an MB can decrease the ACI cy-
cle duration, we focus on one of its subparts – the We observe: (1) the CPU load is clearly decreased
inference. This makes sense since INFERENCE poses when processing the videos on a GPU, Xavier GPU
the highest algorithmic complexity whenever STRL is with ACI enabled presented a 24% lower load than
not executed. We modify the implementation of Al- Xavier CPU , and (2) the ACI background process in-
gorithm 2 (Line 2 & 8) to execute INFERENCE either troduced a computational overhead of 3% for both
(1) on the entire BN including all 4 SLOs, (2) the devices (left vs. right bar). Overall, this provides
MB including 4 SLOs, (3) the MB with 2 SLOs, or an estimate of the general overhead (A-2); however,
(4) the MB with 1 SLO. Then, we execute the ACI whether this is acceptable depends on the use case.
cycleonLaptop andcapturetherunningtimeofeach
configurationoveradurationof10min; thisproduces A-3: How long require ACI agents to ensure SLOs?
600 observations for each experiment. Figure 8 visu-
alizes the time that Laptop requires for performing To evaluate the time to train a EOSC model, we
INFERENCE, given the different MB sizes. count(1)thenumberofACIiterationsthattheagent
20
Figure9: OverheadintroducedbytheACIbackgroundprocess
Figure10: SLOfulfillmentrate(splitupintopv andra)when
when operating on Xavier or Xavier (A-2)
CPU GPU operating on a blank Laptop client over 20 ACI cycles (A-3)
requires to arrive at a (nearly) optimal device con-
variables in blue. We observe: (1) all SLO variables
figuration, and (2) how often the agent changes the
are influenced by variables that the ACI agent can
configuration to get there. The model is trained from
control, and (2) memory was the only variable that
scratch; therefore, the ACI agent (i.e., executed on
could not be related to any other. After studying the
Laptop) trains the model over 20 cycles and reports
graphs carefully, we could not detect any edge that
after each cycle (3) the SLO fulfillment according to
appearscounterintuitivetous; however, thisdoesnot
the selected device configuration. We present the re-
prove that they are indeed causal. In total, we claim
sults in Figure 10: The green and red lines represent
that the created graph is coherent and the links are
the SLO fulfillment (pv & ra); whenever the agent
understandable (A-4-1), but it requires sophisticated
reconfigures the edge device, we print a blue dot for
experiments to prove causality for each edge.
both lines in the graph. We observe: (1) the agent
requires roughly 7 cycles to converge to a configura-
tion that satisfied SLOs with more than 90%, which A-4-2: Is the behavior of ACI agents interpretable?
it then maintains in the same range; (2) this state is
reached after 3 reconfigurations; and (3) pv and ra Complementarily, we were interested in how the
showed similar trends in this example. Thus, we an- behavior of the ACI agent could be interpreted. In
swered how long an ACI agent requires to provide an Figure 12 we present three matrices for each behav-
acceptable configuration (A-3), both in terms of ACI ioral factor (i.e., pv, ra, and ig). We executed the
cycles and the number of reconfigurations. ACIagentonLaptop andextractedthematricesafter
{1,5,50}iterations. Thefirstrowpresentstheagent’s
A-4-1: Are the produced causal graphs interpretable? initialassumptionsonhowtheparametersarerelated
to SLO fulfillment (pv & ra) and which rows provide
To discuss the interpretability of created causal the most insight (ig).
structures, we compare the DAGs produced by STRL We observe: (1) the ig is initially high at corner
and highlight at which stage the graph can be empir- points in the parameter space (as discussed in Sec-
icallyexplained. Wewillnotconsiderspecificmetrics tion 3.1.2), which are visited in the first ACI itera-
here but interpret the DAGs according to our expert tions–thisisevidentbecauseatround5onlyonecell
knowledge. On Laptop, we train a EOSC model from with e = 0.3 remains; (2) the interpolation improves
scratchandextracttheDAGsafter{1,3,5,10}rounds astransitionsintheheatmapbecomesmoother(from
of BNL. Thus, we want to show how the ACI agent top to bottom); (3) the highest SLO fulfillment is at
discovers (ideally) causal relations between model pixel = 300,fps = 14; and (4) the agent develops
variables. The results are visible in Figure 11: SLO clear preferences in terms of pv (i.e., bottom-left cor-
variables (see Table 2) are colored in green; regular ner), while the optimal ra is located in the center of
21
memory
in_time bitrate bitrate streams pixel success pixel success network
streams
success
consump
streams
CPU
fps distance
in_time streams
pixel pixel fps bitrate CPU bitrate
consump
CPU consump in_time
CPU consump
memory
network in_time
success memory distance network fps distance network fps distance memory
(a)DAGafter1round (b)DAGafter3round (c)DAGafter5rounds (d)DAGafter10rounds
Figure11: ProgressoftheDAGafter{1,3,5,10}roundsofparametertrainingwhencreatingamodelwithACIonLaptop (A-4-1)
the parameter space. Areas to avoid would be, e.g., handle this, we either (1) simulate a peek usage time
pixel = 120, because image detection requires more by increasing the number of processed video streams
detail, orfps > 22becausetheprocessingtimeframe from 1 to 6, or (2) distort the video content with a
shrinks. Overall, we argue that the visualizations al- Gaussian blur of 5px, which could resemble a foggy
low understanding the agent’s behavior (A-4-2). videosetting. WemeasuretheimpactontheSLOful-
fillment (pv & ra) over 20 ACI cycles and visualize to
A-5: What is the operational impact of including what extent the EOSC model is capable of restoring
BNL in the ACI cycle? satisfactory (i.e., close to original) SLO rates. Fig-
ure 14 shows in both subfigures the SLO fulfillment
rate of Laptop, when the disruptive factor was intro-
To answer whether BNL can be applied on regular
duced (i.e., after 3 iterations), and at which points
edge devices, we train a EOSC model on Xavier
GPU
the ACI agent reconfigured the system (blue dots).
and measure the execution time of STRL and PARL,
i.e., the BNL sub-steps from Algorithm 3. In Fig- We observe: (1) after the stream change, Laptop
ure 13 we visualize the execution time of STRL and took 11 ACI cycles (incl. 4 reconfigurations) to re-
PARL over 100 ACI iterations, respectively 1.5 min of cover the SLO fulfillment, and (2) the information
operation. We observe: (1) PARL runs with a stable loss introduced by the video manipulation could not
runtime of around 250ms, (2) the time required for be recovered, although SLO fulfillment was improved
STRL increases as more and more training data be- asfaraspossible. Hence,weconcludethatthesystem
comes available, and (3) running STRL after 100 ACI was able to adapt to changes in the variable distribu-
iterationstookmorethan20s. WeconcludethatPARL tion (A-6); however, only as long as the device can
might be run on the employed edge device because it compensate for this factor. In fact, the SLO fulfill-
can be completed within less than 1000ms (i.e., the ment could not be recovered after the video change
time frame for concluding the ACI cycle from Sec- becausetheagentdidnothaveanequivalentcounter-
tion 4.2.1). However, the runtime of STRL presents measure, e.g., increasing the resolution sufficiently.
an obstacle because the ACI agent might thus have
to skip iterations until the ongoing execution of STRL A-7: Can SLOs be modified during runtime?
is finished. Hence, it would be advisable to perform
STRL on another device (A-5) or find a way to de-
Requirements might change during operation; to
crease the runtime, e.g., by updating the DAG re-
simulate this, we modify the distance SLO from 50
gardless of existing CPTs.
to 20 (i.e., clearly stricter) and measure the SLO ful-
fillment rate before and after the modification. Ad-
A-6: Can changes in variable distribution be han- ditionally, we capture the surprise (Algorithm 2) to
dled? show if SLO outcomes reflected the expectations of
theagent. Figure15showsintheupperparttheSLO
Variable distributions can change due to various fulfillment rate over 40 ACI cycles; the SLO changes
external factors; to evaluate how well the system can after 3 iterations. The lower part shows the agent’s
22
(a)pv matrixafter1round (b)ramatrixafter1round (c)ig matrixafter1round
(d)pv matrixafter5rounds (e)ramatrixafter5rounds (f)ig matrixafter5rounds
(g)pv matrixafter50rounds (h)ramatrixafter50rounds (i)ig matrixafter50rounds
Figure12: Behavioralfactors(i.e.,pv,ra,andig)interpolatedbytheACIagenttoevaluatepossibledeviceconfigurations(A-4-2)
surprise at each round and when STRL or PARL hap- the decision between STRL and PARL (as envisioned
pen. in Algorithm 3). However, as known from Figure 13,
STRL can exceed the ACI time frame multiple times;
We observe: (1) after the SLO change, the agent
hence, the ACI agent is forced to wait for this pro-
experienced 9 rounds of high surprise, i.e., >> 35,
cesstofinish. Thiscouldbesolved,e.g.,byoffloading
(2) after 2 reconfigurations, the state prior to the
STRL. Nevertheless, we conclude that the system was
SLO change was recovered, although final SLO rates
able to handle SLO changes during runtime (A-7).
(mean 0.91) are slightly below previous (mean 0.94),
and(3)themagnitudeofthesurprisewasdecisivefor
23
20
15
10
5
0
)s(
emit
LRTS
0.30
0.15
0.00
0 20 40 60 80 100
ACI Cycle Iteration
)s(
emit
LRAP
Figure 13: Duration of structure and parameter learning on
the Xavier when training the BN from scratch (A-5)
GPU
Figure 15: Impact of changing the distance SLO during run-
time, combined with the respective surprise values measured
(A-7)
the combined model, and the grey one was trained
from scratch. Additionally, we indicate each time the
agents changed the configuration.
We observe: (1) the merged model does not face
anysubstantialimprovementsofitsinitiallyhighSLO
(a)Streamchanges (b)Videochanges
fulfillment; (2) the agent required 14 rounds to arrive
Figure 14: Changes in the variable distribution caused (a) by at a comparable SLO rate – this also matches our
higher number of video streams or (b) lower video quality (A- experience from Figure 10, where Laptop required 7
6)
to 16 ACI rounds for training; and (3) the final rates
are within the range [0.85,0.95]. From that, we con-
5.2. Knowledge Transfer clude that the results produced by the trained model
were comparable to the merged model (K-1), and
K-1: How high is the SLO fulfillment of transferred that KT could achieve a speedup of 14 rounds (K-2),
models compared to ACI-trained ones? assuming that the transferred model was ready for
usage. Nevertheless, this is only valid for the given
Transfer learning promises to accelerate model setup (i.e., these two devices); it is not possible yet
training,butwemustascertainthattransferredmod- to derive general implications of our approach.
els perform equally to trained ones. For this, we as-
sume that Xavier wants to join the device clus- K-3: Can merged models decrease the FE compared
GPU
ter. According to Table 4, Laptop and Xavier to choosing a single one?
CPU
are eligible for providing their model, i.e., their hard-
ware scalars (2 & 4) are the closest to Xavier As discussed in Section 2.2, it is hard to estimate
GPU
(3). Hence, we merge their EOSC models and trans- the FE of a model, but we consider the fact that sur-
fer the result to Xavier . Next, we compare the prise is bounded by FE. Although low surprise does
GPU
SLO fulfillment of the merged model with a separate not imply low FE, we use it as an indicator: We
run, where a model is trained from scratch. We place transfer a model to Xavier (merged from Laptop
GPU
both runs into Figure 16; the blue line represents and Xavier as above) and calculate the surprise
CPU
24
Figure16: DifferenceinSLOfulfillmentbetweenanagentusing
a transferred model or training from scratch (K-1 & K-2)
Figure 17: Overall surprise measured per batch when operat-
ing on the Xavier with existing models or one combined
GPU
especiallyforthisdevice. PairedwiththefrequencytheCPTs
throughout multiple ACI cycles. This we compare are updated through parameter learning (K-3)
againstalternativeruns,inwhichXavier usesone
GPU
of the EOSC models of the other devices (from Table
5.3. Stream Offloading
Table 3). Furthermore, we count the usage of PARL.
The results are presented in Figure 17; each of the S-1: How is the load distributed among resource-
colored lines represents one of the respective models, constrained devices
whichwerecopiedtoXavier . Theblueline, how-
GPU
ever, describes the combined model. The lower figure
To offload computations within the cluster, we aim
shows for each run when PARL was executed. to show how low-resource devices are relieved from
excessive load. For this, we assume 25 IoT devices
We observe: (1) the models trained on Orin and that are either assigned Equal to the edge devices or
Nano produced initially very high surprise (>> 50), Random. As an indicator for maximum SLO fulfill-
indicating that these models fit Xavier the least; ment, we added Single, where each device processes
GPU
(2) nevertheless, the agent was able to improve these one stream; Table 5 shows an overview of each sce-
models and converge to an area where all 5 models nario’s assignment. After operating with Equal or
provide similar surprise after 25 iterations; (3) the Random, the leader node starts to optimize the envi-
combinedmodelprovidedinitiallythebestvaluesand ronment, i.e., using the EOSC-F model to distribute
only performed PARL twice; and (4) interestingly, al- the 25 streams depending on the device capabilities
though close to each other, the combined model pro- (Infer). This new assignment is then provided to the
duces after 25 rounds the highest surprise (33), while edgedevices. Wethussimulatedanoffloadingorload
Xavier reached 17. This shows, that the frequent rebalancing, e.g., Nano dropped from 5 (or 3) to 1
CPU
retrainingperformedbytheotherdevices(coloredtri- stream. In Figure 19, we show each device’s SLO ful-
angles in the lower graph) allowed the other models fillmentrateperscenario. TheleftbarsofFigure19b
to surpass Xavier . This raises the question if it show the cluster-wide average of the SLO fulfillment
GPU
would be advisable to always run PARL, regardless of and the right bar the weighted average according to
the surprise magnitude – Are there even situations the number of streams (slo rate×stream). To get a
when the CPTs should be updated less frequently? feeling of the heterogeneous device capabilities, Fig-
Combined, we can answer that the merged model ure 18 provides a regression function that shows how
had initially less surprising values (K-3); however, the SLO fulfillment per device is impacted by the
frequent retraining may achieve even better results. number of streams.
25
Table5: Streamsassignedtoeachdeviceforevaluatedscenarios
Device ID Single Equal Rand Infer
Laptop 1 5 4 9
Xavier 1 5 8 5
GPU
Xavier 1 5 5 1
CPU
Orin 1 5 4 9
Nano 1 5 3 1
(a)SLOfulfillmentperdevice
Sum Σ 5 25 25 25
(b)Averageandweightedaverageperbatch
Figure 19: SLO fulfillment within the edge-fog cluster when
distributing load according to Infer, Random, or Equal. Single
is an upper bar for this device constellation (S-1)
Figure 18: Regression curves between environmental demand the DAG internal to the EOSC-F model: Blue nodes
foredgedevices(streams)andtheirrespectiveSLOfulfillment
are environmental factors, from which only stream
rates (pv×ra)
can be configured (recall Section 4.2.3); slo rate rep-
resents the common factor f = pv × ra. We simu-
Weobserve: (1)theaverageSLOfulfillmentclearly late network congestion7for Orin – which the leader
improved by using Infer (0.81) instead of Random node can evaluate through congestion – and redis-
(0.64) or Equal (0.60); (2) this is also reflected by the tributetheloadaccordingtotheEOSC-Fmodel, i.e.,
weighted average (right bars of Figure 19b), which Orin = 8,Laptop = 2. Then, we compare the overall
puts Laptop and Orin in focus that processed 9 SLO fulfillment before and after offloading; the re-
streamseach; (3)theweightedaverageofInfer comes sults are shown in Figure 21. The two lines show the
closetotheoneofSingle (0.89),eventhoughtheclus- SLO fulfillment (f) of Laptop (red) and Orin (blue)
terprocessed25insteadofonly5streams. Fromthat, over 50 ACI iterations; after 10 rounds, the network
weconcludethattheintelligentclusterwasabletoin- gets congested. In round 30, the cluster leader re-
corporaterestrictededgedevices(e.g.,Nano)intothe balanced the load according to its EOSC-F model;
architecture (S-1), and that the overall SLO compli- although it is possible to rebalance earlier, we de-
ance improved by following our approach. cided to observe the system behavior until manually
rebalancing in round 30.
S-2: Can the CC hierarchical structure optimize local Weobserve: (1)thenetworkissuecrushedtheSLO
SLO fulfillment? fulfillment of Laptop from around 0.9 to a minimum
of 0.2 at round 15; (2) the edge device was able to
To improve the SLO fulfillment whenever individ- improve the rate in the following 20 iterations by re-
ual devices lack the required scope, we will resolve configuration, until reaching a local optimum at 0.43.
such SLO failures within the cluster. Therefore, we Further, (3) the cluster-wide SLO compliance was
consideracondenseddeviceclusterconsistingofLap- clearly improved through rebalancing, i.e., at round
top andOrin. S-1 showedthattheyhavecomparable 15 the sum of f +f was 1.03, at round 30 it
Laptop Orin
processing capabilities; therefore, it is fair to split 10 was 1.33, while at round 45 it rose to 1.54. We con-
streams equally between them. Figure 20 provides clude that the intelligent cluster was able to resolve
26
device
type
streams congestion
slo_rate
Figure 20: DAG internal to the EOSC-F model
1.0
0.8
0.6
0.4
0.2
0 10 20 30 40 50
ACI Cycle Iteration
etar
tnemllifluf
OLS
devices took 9 rounds to interpret an unprecedented
increaseindemand, whileSLOfailuresintroducedby
poor video quality could not be fully recovered. Fur-
ther, (4) the causality filter based on MBs decreased
the complexity of inference and sped up SLO eval-
uation by 17%, and (5) our framework introduced
a negligible CPU overhead of 3%, which makes it a
suitable choice for resource-restricted devices.
It turned out that (6) BNL, or in particular struc-
ture learning, surpassed the given time frame for
continuous model adaptation; nevertheless, param-
eter learning alone took less than 250 ms. Thus,
(7) models transferred between nearby devices could
be continuously improved, even in cases where they
fit poorly; this improves the reusability of models in
the heterogeneous Edge, (8) the SLO fulfillment of
devices with transferred models equaled the one of
Laptop
self-trained models; this accelerated the distribution
Orin
of SLO-compliance models within one computational
Net. Issue
Rebalance tier by up to 16 rounds, (9) rebalancing the load af-
ter a network error increased the overall SLO fulfill-
ment from 1.03 to 1.54; this showed that collabora-
tion within this tier increased the scope of SLO fail-
Figure 21: Recovering network congestion by rebalancing the
loadwithinthedeviceclusteraccordingtotheEOSC-Fmodel; ures that could be covered. A closing observation is
both devices initially processed 5 streams, 3 are offloaded to that (10) shifts in the variable distribution showed
Orin (S-2)
the same effects on SLO fulfillment as low accuracy
aftertransferringamodeltoanunknowndevicetype.
the introduced network issue (S-2) by redistributing To our framework, they did not provide any funda-
the load according to the EOSC-F model. However, mental differences, which is why they could both be
to draw general conclusions, we aim to consider a resolved through continuous model training.
larger range of potential issues.
6. Related Work
5.4. Summary and Implications
This section provides recently published related
This section summarizes the presented results and
works that discuss (1) the training and application
highlights their implications for the applicability of
of causal ML models on the Edge, (2) transfer learn-
ourframework. Tothatextent,wecanreportthat(1)
ing approaches in the CC, and (3) methods of load
edge devices were gradually able to ensure local SLO
balancing and computation offloading that are pop-
compliance without prior knowledge; it took them
ular across the CC. Following that, we highlight for
16 rounds to identify factors that impact SLO fulfill-
each of these fields the research gap that our work
ment and adapt the environment accordingly, (2) the
aims to fill.
underlying causal structures and the transitions be-
tween device configuration were empirically explain-
6.1. Causal ML Training on the Edge
able; this increases traceability andtrust of ML mod-
els, and (3) shifted variable distributions were can- Sudharsan et al. [51] developed an Edge2Train
celed out through continuous model retraining; edge model to analyze real-time data on the fly. With
Edge2Train, Support Vector Machine (SVM) models
are trained offline in edge nodes using real-time IoT.
7Internally, we increase the processing delay according to
Adopting causality to Edge2Train can help converge
congestion; this increases the overall latency and causes the
the most efficient training models quickly. Diagnos-
in time SLO to fail more likely. The EOSC-F model can then
considercongestionasanenvironmentalfactorforAlgorithm4. ing the root cause of performance degradation in the
27
CC is a challenging issue, and Chen et al [10] use utilized on any mobile edge platform because of its
causal inference (CauseInfer) mechanisms to pin- ability to handle large, compute-intensive ML mod-
point the root causes within the system. CauseInfer els. In addition, systolic array-based edge acceler-
determines fault propagation paths that can be de- ators are introduced to prevent cloud interactions.
termined explicitly, without production systems be- Wu et al. present a novel approach to online trans-
ing instrumented. A similar approach (called Nazar) ferlearningforbothheterogeneousandhomogeneous
is designed by Hao et al. in [52], where they apply labels of multi-source domains [39]. This approach is
mobile devices to diagnose root causes in distributed very efficient in online classification, and the weights
systems. Further, thisapproachenhancesitstraining aredynamicallyadjusteddependingonthesourcedo-
models through cause-specific adaptive mechanisms. main. The work fits well into the CC due to the com-
Through experiments, Nazar confirmed that training plex heterogeneity of devices within the system. Hsu
models can be improved due to cause-specific adap- et al. provide a clustering mechanism that consid-
tation while monitoring a large number of devices. ers the similarity of domains and tasks for transfer
Lin et al. introduced Microscope in [11], a micro- learning [55]. They provided a similarity function for
service environment to diagnose the possible root cross-task transfer learning that is based on similari-
causes of abnormal services in distributed systems ties between domains.
through causal graphs. Lin et al. demonstrate that Xing et al. introducedamodelcalledRecycleMLin
Microscope can construct a service causal graph in [56] that enables multi-modality among edge devices,
real time and infer the root cause of abnormal ser- where knowledge is shared by transforming common
vices. Tariq et al. presenttheWhat-IfScenarioEval- latentfeaturesintotheirlowerlayers. Further,itpro-
uator (WISE) tool in [53], which predicts the effect vides task-specific knowledge transfer between mod-
of potential configuration and deployment changes els through the retraining of higher layers beyond the
on content delivery networks (CDN). WISE initially latent space shared by both models, thus reducing
learns causal relations among existing response time the need for labeled data. Sharma et al. proposed
distributions. Basedontheavailabledatasets, itesti- a knowledge transfer technique between edge devices
matespossiblefutureresponsetimedistributions. Fi- to lower computational intensity without losing ac-
nally, it allows network designers to express possible curacy and convergence speed [57]. In this, the stu-
deployment scenarios without knowing how variables dent network takes the knowledge from the teacher
will affect response time. network to achieve this goal. Using an IoT testbed,
Kolcun et al. [58] evaluated various machine learning
There evidently exists work that identifies and ap- classifiers’ convergence speed and accuracy. These
plies causal understanding to ensure system require- testbeds considered both data- and resource-specific
ments; however, with the exception of Nazar [52], constraints. The results of each local testbed’s train-
they treat model training as a one-time process. ing models are transmitted to the gateway to mini-
Hence, drifts (or shifts) in the variable distribution mize global training model overhead.
stay undetected. Further, it is impractical to assume
that sufficient training data is available to arrive at
Transferring ML models is an important measure
this causal understanding; this is also the shortcom-
forrelievingresource-restricteddevicesfromtraining;
ingofNazar. Contrarily, ourapproach, whichfocuses
teacher devices can therefore consider the context of
onACI,isabletograduallycreatecausalmodelsover
the student to provide a tailored model. This is an
multipleiterations(i.e.,asnewtrainingdatabecomes
important feature since edge devices have heteroge-
available), and continuously ensures model accuracy
neous characteristics; however, none of the presented
by updating beliefs according to prediction errors.
works considered low-level hardware characteristics
to identify potential teachers among nearby devices.
6.2. Transfer Learning in the CC
Further, while it is possible to combine models, the
Goyal et al. present MyML [54], a hardware-friendly presented techniques are not applicable to the causal
model transfer for edge nodes. MyML uses trans- structures that we require for decentralized SLO as-
fer learning to create small, lightweight, custom ML surance. To that extent, our framework uses hard-
models based on user preferences. This approach is ware classification to find adequate models within a
hardware-friendly, bottom-up pruning, which can be device cluster and creates a tailored model by merg-
28
ing the conditional probabilities of BNs. basic load-balancing schemes whose main difference
is the amount of information required for rearrange-
6.3. SLO-Induced Load Balancing and Offloading ment. In[67],Menino proposedefficientfailuredetec-
tion mechanisms for unstructured overlay networks.
Elasticity is one of the most effective ways to en-
Thisapproachaimstoidentifyefficientneighborhood
sure requirements of dynamic workloads by automat-
overlays, which dynamically identify and maintain
ically provisioning or de-provisioning resources based
each node in P2P networks.
on demand [35]. SLOC is a novel elastic framework
developed by Nastic et al. in [59], that allows users
SLOs are an efficient way for modeling and en-
to provide and consume cloud resources in an SLO-
forcing requirements; thus, high-level SLOs can be
native manner while guaranteeing performance. Its
segregated and enforced at the respective CC compo-
primary goal is to provide better support for SLOs
nent. Nevertheless,theremainingquestioniswhether
by exploiting and advancing current elasticity man-
the component has the required scope to recover
agement solutions. Further, Furst et al. bring elastic
SLO failures (e.g., by offloading computation), but
service principles from the cloud to edge computing
it is impractical to evaluate SLOs in the cloud (e.g.,
[60]. They evaluated elastic and non-elastic services
MHP2P).Hence,ad-hochierarchicalstructurescould
at the edge while processing images to latency SLOs,
provide a remedy, which Menino [67] are the only
and noticed improved service provisioning through
ones to use among the related work. However, they
elasticity.
all assume prior knowledge of which variables im-
Tran and Kim introduce an edge serverless auto-
pact SLO fulfillment. Contrarily, our approach (1)
scaling method based on traffic prediction that can
gradually increases the SLO scope by forming device
be used against a Kubernetes cluster [61]. In this
clusters that can span the entire CC, and (2) evalu-
work, system resource usage is optimized to ensure
ates causal relations among environmental variables
latency SLOs. No additional resources are required
to shift the load from impacted devices.
to perform this operation; this optimizes the amount
of available resources. Hazra et al. [62] proposed
efficient heuristic-based transmission scheduling and 7. Conclusion and Future Work
graph-basedcomputationaloffloading(TSCO)through
mixed linear programming to achieve energy effi- This paper presented a novel framework for collab-
ciencyandminimizelatency. Asingle-andmulti-task orative and distributed edge intelligence that ensures
loadbalancingwithaprioritizationapproachtocom- decentralized SLO fulfillment. It allows CC systems
puting Deep Neural Networks (DNNs) at the edge to break down high-level requirements and enforce
has been presented by Karjee et al. in [63]. In these them at the component that they concern; thereby,
approaches, prioritized tasks are distributed among we create self-adaptive devices that themselves en-
IoT and edge nodes to balance energy, lower latency, sure dynamic requirements. For each of its compo-
and continue task execution without restarting the nents, the framework is able to develop causal rea-
system. Lim and Lee proposed a load-balancing ap- soning between environmental factors and SLO ful-
proach for distributing mobile devices tasks within fillment. Resource-restricted devices that cannot cre-
a cloud-edge continuum using graph coloring [64]. ate this knowledge themselves were able to exchange
Through this process, computing resources are scaled and combine causal models according to their hard-
with increased edge resource utilization. ware characteristics. This accelerates the onboard-
A trilayer mobile hybrid hierarchical peer-to-peer ing of unknown device types and simplifies horizon-
(MHP2P) model was proposed by Duan et al. in tal scaling within the Edge. Contrarily, any attempt
[65] as a cloudlet for efficient load balancing strat- to achieve this centrally would struggle with hetero-
egy through mobile edge computing (MEC). MHP2P geneous device characteristics, the induced network
promises high reliability, scalability, and efficiency in latency, and the communication overhead. To cre-
service lookups. Moreover, there is a load-balancing ate advanced SLOs with an increased scope, devices
scheme to ensure that MHP2P loads are evenly dis- collaborated as clusters under the supervision of a
tributed between MEC servers and queries. Rao et Fog node; this forms higher-level components that
al. presentedanotherload-balancingstrategyforP2P can again supervise their own set of SLOs. As a con-
systems through virtual servers [66]; it presents three sequence, the cluster was able to use its extended en-
29
vironment to resolve SLO violations, e.g., by offload- Table 6: Frequently used notations.
ing computation among pertinent devices. Erecting
Notation Meaning
thesehierarchicalstructuresallowsustofulfillthein-
D Kullback-Leibler divergence
KL
tricate requirements of multiple computational tiers. x Hidden states of a model
Weprovidedaprototypeoftheframeworkforadis- P Exact posterior probability
Q Approximate posterior probability
tributed video transformation use case and evaluated
ℑ Surprise for observation
it according to twelve aspects; the results showed the
m Model
potentialofourapproachforensuringSLOsthrough- m Merged BN model m and m
ab a b
outCCtiers. Forfuturework, weaimtodynamically v Number of variables in a BN
o Observation
assemble hierarchical structures and evaluate limita-
D Datasets
tions regarding the number of SLOs and devices that
G Graph
can be managed. Further, this work builds heavily G∗ Set of possible DAGs for a G
on the analysis of causal relations between SLO ful- G final DAG
LL(G,D) Log-likelihood for G of D
fillment and environmental factors; however, to claim
ϕ(|D|) BIC
true causality, dedicated experiments must be inte-
V Vertex set of G
grated into the framework. Once this is established, E Edge set of G
our framework will provide the necessary causal links ξ Entropy
to tame requirements within the CC. MLE Maximum Likelihood Estimation
ω Width of DAG
n Number of nodes (V) in DAG
P Size of conditioned set while searching PC
Acknowledgement
C max(PC set) for n
S Number of Spouses from G
final
Funded by the European Union (TEADAL, K Maximum size Spouses from G
final
101070186). Views and opinions expressed are how- T Target variables
O Elimination order
everthoseoftheauthor(s)onlyanddonotnecessarily
mb Markov blanket
reflect those of the European Union. Neither the Eu-
t Threshold
ropean Union nor the granting authority can be held pv Pragmatic value
responsible for them. ra Risk assigned
ig Information gain
u Combined behavioral factors
Nomenclature f Combined SLO fulfillment
K Behavioral factors of known configurations
ev Evidence variable list
This section provide a summary of notations (6)
V SLO target variables list
SLO
and acronyms (7) used in this paper. V Subset of V , either QoS or QoE
Q SLO
e Constant for visiting state more frequently
h Factor for choosing between STRL and PARL
References ℑ˜ Median surprise for configuration c
c
ℑ¯ Mean overall surprise
[1] P. Beckman, et al., Harnessing the computing continuum c Configuration
forprogrammingourworld,in: FogComputing,JohnWi- q Number of states for a variable r in a BN
ley & Sons, Ltd, 2020, pp. 215–230. p CPU capacity
[2] S. Dustdar, V. C. Pujol, P. K. Donta, On Distributed g GPU capacity
Computing Continuum Systems, IEEE Transactions on dc Device capacity
KnowledgeandDataEngineering35(4)(2023)4092–4105. w Coefficient for relative device capacity
doi:10.1109/TKDE.2022.3142856. k r Incoming edges for a variable r in a BN
[3] W. Ta¨rneberg, et al., The 6G Computing Continuum r Random variable
(6GCC): Meeting the 6G computing challenges, in: In- σ env Environment factors
ternational Conference on 6G Networking, 2022. Λ Physical devices
[4] V. Casamayor-Pujol, A. Morichetta, I. Murturi, P. K. n clients Number of streams
Donta, S. Dustdar, Fundamental Research Challenges for d a backup data to create m a
Distributed Computing Continuum Systems, Information
14 (2023) 198. doi:10.3390/info14030198.
[5] B. Sedlak, V. C. Pujol, P. K. Donta, S. Dustdar, De- Z. Zheng, M. Mecella (Eds.), Service-Oriented Comput-
signing Reconfigurable Intelligent Systems with Markov ing, Lecture Notes in Computer Science, Springer Na-
Blankets, in: F. Monti, S. Rinderle-Ma, A. Ruiz Cort´es, ture Switzerland, Cham, 2023, pp. 42–50. doi:10.1007/
30
Table 7: Frequently used acronyms and their meaning
to-End Performance Diagnosis with Hierarchical Causal-
ity Graph in Cloud Environment, IEEE Transactions
Acronym Meaning
on Services Computing (2019). doi:10.1109/TSC.2016.
AxI Approximate Inference
2607739.
ACI Active Inference
[11] J. Lin, P. Chen, Z. Zheng, Microscope: Pinpoint Perfor-
BIC Bayesian Information Criterion
mance Issues with Causal Graphs in Micro-service Envi-
BN Bayesian Network
ronments, in: C. Pahl, M. Vukovic, J. Yin, Q. Yu (Eds.),
BNL Bayesian Network Learning
Service-Oriented Computing, Lecture Notes in Computer
CC Computing Continuum
Science, Springer International Publishing, Cham, 2018,
CDN Content Distribution Networks
pp. 3–20. doi:10.1007/978-3-030-03596-9_1.
CPTs Conditional Probability Tables
[12] I. Tsamardinos, C. F. Aliferis, A. Statnikov, Time and
CPU Central Processing Unit
sample efficient discovery of Markov blankets and direct
DAG Directed Acyclic Graph
causal relations, Association for Computing Machinery,
DL Deep Learning
New York, USA, 2003. doi:10.1145/956750.956838.
DNN Deep Neural Networks
[13] A. Niculescu-Mizil, R. Caruana, Inductive Transfer for
EI Exact Inference
Bayesian Network Structure Learning, in: Proceedings of
EOSC Equilibrium-Oriented SLO-Compliance
the Eleventh International Conference on Artificial Intel-
FE Free Energy
ligence and Statistics, PMLR, 2007, pp. 339–346, iSSN:
GPU Graphics Processing Unit
1938-7228.
HCS Hill-Climb Search
[14] M.J.Vowels,N.C.Camgoz,R.Bowden,D’yalikeDAGs?
IoT Internet of Things
A Survey on Structure Learning and Causal Discovery
KT Knowledge Transfer
(Mar. 2021). doi:10.48550/arXiv.2103.02582.
MB Markov Blanket
[15] V. C. Pujol, P. Raith, S. Dustdar, Towards a new
MEC Mobile Edge Computing
paradigm for managing computing continuum applica-
ML Machine Learning
tions, in: 2021 IEEE Third International Conference on
MLE Maximum Likelihood Estimation
Cognitive Machine Intelligence (CogMI), 2021, pp. 180–
P2P Peer-to-Peer
188. doi:10.1109/CogMI52975.2021.00032.
PC Parent-Child
[16] K. Friston, Life as we know it, Journal of The Royal So-
PERL Parameter Learning
ciety Interface 10 (86) (2013) 20130475. doi:10.1098/
QoE Quality of Experience
rsif.2013.0475.
QoS Quality of Service
[17] M. Kirchhoff, T. Parr, E. Palacios, K. Friston, J. Kiver-
TL Transfer Learning
stein,TheMarkovblanketsoflife: autonomy,activeinfer-
SCM Structural causal models
ence and the free energy principle, Journal of The Royal
SLOs Service Level Objectives
Society Interface (2018).
STRL Structure Learning
[18] K. J. Friston, J. Daunizeau, S. J. Kiebel, Reinforcement
SVM Support Vector Machine
Learning or Active Inference?, PLOS ONE 4 (7) (2009)
VE Variable Elimination
e6421. doi:10.1371/journal.pone.0006421.
WISE What-If Scenario Evaluator
[19] R. Smith, K. J. Friston, C. J. Whyte, A step-by-step tu-
torial on active inference and its application to empiri-
cal data, Journal of Mathematical Psychology 107 (2022)
978-3-031-48421-6_4. 102632. doi:10.1016/j.jmp.2021.102632.
[6] K.Friston,L.DaCosta,N.Sajid,C.Heins,K.Ueltzho¨ffer, [20] N. Sajid, P. J. Ball, T. Parr, K. J. Friston, Active in-
G. A. Pavliotis, T. Parr, The free energy principle made ference: demystified and compared, Neural Computation
simpler but not too simple (May 2023). doi:10.48550/ 33 (3) (2021) 674–712. doi:10.1162/neco_a_01357.
arXiv.2201.06387. [21] T. Parr, G. Pezzulo, K. J. Friston, Active Inference: The
[7] H.Kokkonen,L.Lov´en,N.H.Motlagh,A.Kumar,J.Par- Free Energy Principle in Mind, Brain, and Behavior, The
tala, T. Nguyen, V. C. Pujol, P. Kostakos, T. Leppa¨nen, MIT Press, 2022. doi:10.7551/mitpress/12441.001.
A.Gonza´lez-Gil,E.Sola,I.Angulo,M.Liyanage,M.Ben- 0001.
nis, S. Tarkoma, S. Dustdar, S. Pirttikangas, J. Riekki, [22] G. Camps-Valls, A. Gerhardus, U. Ninad, G. Varando,
AutonomyandIntelligenceintheComputingContinuum: G. Martius, E. Balaguer-Ballester, R. Vinuesa, E. Diaz,
Challenges, Enablers, and Future Directions for Orches- L. Zanna, J. Runge, Discovering causal relations and
tration (Feb. 2023). doi:10.48550/arXiv.2205.01423. equations from data, Physics Reports 1044 (2023) 1–68.
[8] J. Pearl, Causal inference in statistics: An overview, doi:10.1016/j.physrep.2023.10.005.
Statistics Surveys 3 (2009) 96–146, publisher: Amer. [23] C. Heins, B. Millidge, D. Demekas, B. Klein, K. Friston,
Statist.Assoc.,theBernoulliSoc.,theInst.Math.Statist., I. Couzin, A. Tschantz, pymdp: A Python library for ac-
and the Statist. Soc. Canada. doi:10.1214/09-SS057. tive inference in discrete state spaces, Journal of Open
[9] N.Ganguly,D.Fazlija,M.Badar,M.Fisichella,S.Sikdar, Source Software (May 2022). doi:10.21105/joss.04098.
J. Schrader, J. Wallat, K. Rudra, M. Koubarakis, G. K. [24] B. Sedlak, V. C. Pujol, P. K. Donta, S. Dustdar, Active
Patro, W. Z. E. Amri, W. Nejdl, A Review of the Role InferenceontheEdge: ADesignStudy(Nov.2023). doi:
ofCausalityinDevelopingTrustworthyAISystems(Feb. 10.48550/arXiv.2311.10607.
2023). doi:10.48550/arXiv.2302.06975. [25] G.Levchuk,K.Pattipati,D.Serfaty,A.Fouse,R.McCor-
[10] P. Chen, Y. Qi, D. Hou, CauseInfer: Automated End- mack, Active Inference in Multiagent Systems: Context-
31
Driven Collaboration and Decentralized Purpose-Driven tion in Construction 140 (2022) 104366. doi:10.1016/
Team Adaptation, in: Artificial Intelligence for the Inter- j.autcon.2022.104366.
net of Everything, Academic Press, 2019. [42] M. Vaniˇs, Z. Lokaj, M. Sˇroty´ˇr, A Novel Algorithm for
[26] M. Scanagatta, A. Salmero´n, F. Stella, A survey on Merging Bayesian Networks, Symmetry 15 (7) (2023)
bayesian network structure learning from data, Progress 1461. doi:10.3390/sym15071461.
in Artificial Intelligence 8 (2019) 425–439. [43] I.Murturi,S.Dustdar,ADecentralizedApproachforRe-
[27] P. K. Donta, B. Sedlak, V. Casamayor Pujol, S. Dustdar, sourceDiscoveryusingMetadataReplicationinEdgeNet-
Governance and sustainability of distributed continuum works, IEEE Transactions on Services Computing 15 (5)
systems: a big data approach, Journal of Big Data 10 (1) (2022) 2526–2537. doi:10.1109/TSC.2021.3082305.
(2023) 53. doi:10.1186/s40537-023-00737-0. [44] S. Dustdar, I. Murturi, Towards Distributed Edge-based
[28] J.Kwisthout,Mostprobableexplanationsinbayesiannet- Systems, in: 2020 IEEE Second International Confer-
works: Complexityandtractability,InternationalJournal ence on Cognitive Machine Intelligence (CogMI), IEEE,
of Approximate Reasoning 52 (9) (2011) 1452–1469. Atlanta, GA, USA, 2020, pp. 1–9. doi:10.1109/
[29] M. Scutari, C. Vitolo, A. Tucker, Learning bayesian net- CogMI50398.2020.00021.
works from big data with greedy search: computational [45] B.Sedlak,I.Murturi,P.K.Donta,S.Dustdar,APrivacy
complexity and efficient implementation, Statistics and Enforcing Framework for Transforming Data Streams on
Computing 29 (2019) 1095–1108. theEdge,IEEETransactionsonEmergingTopicsinCom-
[30] A. Darwiche, Bayesian networks, Foundations of Ar- puting (2023). doi:10.1109/TETC.2023.3315131.
tificial Intelligence 3 (2008) 467–509. doi:10.1016/ [46] A. Ankan, J. Textor, pgmpy: A Python Toolkit for
S1574-6526(07)03011-8. Bayesian Networks (Apr. 2023).
[31] C.Aliferis,etal.,LocalCausalandMarkovBlanketInduc- [47] Q. Zhang, X. Che, Y. Chen, X. Ma, M. Xu, S. Dust-
tion for Causal Discovery and Feature Selection for Clas- dar, X. Liu, S. Wang, A Comprehensive Deep Learn-
sification Part I: Algorithms and Empirical Evaluation, ing Library Benchmark and Optimal Library Selection,
JournalofMachineLearningResearch11(2010)171–234. IEEETransactionsonMobileComputing(2023)1–14doi:
[32] V. Casamayor Pujol, P. Raith, S. Dustdar, Towards a 10.1109/TMC.2023.3301973.
new paradigm for managing computing continuum appli- [48] Linzaer, Ultra-Light-Fast-Generic-Face-Detector-1MB,
cations,in: IEEE3rdInternationalConferenceonCogni- https://github.com/Linzaer/Ultra-Light-Fast-Generic-
tiveMachineIntelligence,CogMI2021,2021,pp.180–188. Face-Detector-1MB (Feb. 2022).
[33] T. Gao, Q. Ji, Efficient markov blanket discovery and [49] R. Rothe, R. Timofte, L. V. Gool, DEX: Deep EXpecta-
its application, IEEE transactions on Cybernetics 47 (5) tionofApparentAgefromaSingleImage,in: 2015IEEE
(2016) 1169–1179. doi:10.1109/TCYB.2016.2539338. International Conference on Computer Vision Workshop
[34] N. Zhang, D. Poole, A simple approach to Bayesian net- (ICCVW), IEEE, Santiago, Chile, 2015, pp. 252–257.
work computations, in: Engineering-Economic Systems, doi:10.1109/ICCVW.2015.41.
Stanford University, 1994. [50] M.Scutari,LearningBayesianNetworkswiththebnlearn
[35] S. Dustdar, Y. Guo, B. Satzger, H.-L. Truong, Principles RPackage,JournalofStatisticalSoftware35(2010)1–22.
ofElasticProcesses,InternetComputing,IEEE15(2011) doi:10.18637/jss.v035.i03.
66–71. doi:10.1109/MIC.2011.121. [51] B. Sudharsan, J. G. Breslin, M. I. Ali, Edge2Train: a
[36] D.Ren,J.Guo,X.Hao,Bayesiannetworkvariableelimi- framework to train machine learning models (SVMs) on
nationmethodoptimaleliminationorderconstruction,in: resource-constrained IoT edge devices, in: Proceedings
ITM Web of Conferences, Vol. 45, EDP Sciences, 2022. of the 10th International Conference on the Internet of
[37] D. Ghio, A. L. M. Aragon, I. Biazzo, L. Zdeborova´, Things, IoT ’20, Association for Computing Machinery,
Bayes-optimal inference for spreading processes on ran- New York, NY, USA, 2020, pp. 1–8. doi:10.1145/
dom networks, Physical Review E 108 (4) (2023) 044308. 3410992.3411014.
doi:10.1103/PhysRevE.108.044308. [52] W.Hao,Z.Wang,L.Hong,L.Li,N.Karayanni,C.Mao,
[38] G. Lei, Y. Dou, W. Wan, F. Xia, R. Li, M. Ma, D. Zou, J. Yang, A. Cidon, Monitoring and Adapting ML Mod-
Cpu-gpu hybrid accelerating the zuker algorithm for rna elsonMobileDevices(May2023). doi:10.48550/arXiv.
secondary structure prediction applications, in: BMC ge- 2305.07772.
nomics, Vol. 13, BioMed Central, 2012, pp. 1–11. [53] M.Tariq,A.Zeitoun,V.Valancius,N.Feamster,M.Am-
[39] Q.Wu,H.Wu,X.Zhou,M.Tan,Y.Xu,Y.Yan,T.Hao, mar, Answering what-if deployment and configuration
Online Transfer Learning with Multiple Homogeneous or questionswithwise,ACMSIGCOMMComputerCommu-
HeterogeneousSources,IEEETransactionsonKnowledge nication Review (2008). doi:10.1145/1402946.1402971.
and Data Engineering 29 (7) (2017) 1494–1507. doi:10. [54] V. Goyal, R. Das, V. Bertacco, Hardware-friendly User-
1109/TKDE.2017.2685597. specific Machine Learning for Edge Devices, ACM Trans-
[40] V. C. Pujol, A. Morichetta, S. Nastic, Intelligent Sam- actions on Embedded Computing Systems 21 (5) (2022)
pling: A Novel Approach to Optimize Workload Schedul- 62:1–62:29. doi:10.1145/3524125.
ing in Large-Scale Heterogeneous Computing Contin- [55] Y.-C. Hsu, Z. Lv, Z. Kira, Learning to cluster in order
uum, in: 2023 IEEE International Conference on Service- to transfer across domains and tasks, in: Sixth Inter-
OrientedSystemEngineering(SOSE),2023,pp.140–149, national Conference on Learning Representations (ICLR
iSSN: 2642-6587. doi:10.1109/SOSE58276.2023.00024. 2018), 2018. doi:10.48550/arXiv.1711.10125.
[41] M. Vagnoli, R. Remenyte-Prescott, Updating conditional [56] T. Xing, S. S. Sandha, B. Balaji, S. Chakraborty, M. Sri-
probabilities of Bayesian belief networks by merging ex- vastava, Enabling Edge Devices that Learn from Each
pert knowledge and system monitoring data, Automa- Other: CrossModalTrainingforActivityRecognition,in:
32
Proceedings of the 1st International Workshop on Edge
Systems, Analytics and Networking, ACM, Munich Ger-
many, 2018, pp. 37–42. doi:10.1145/3213344.3213351.
[57] R. Sharma, S. Biookaghazadeh, M. Zhao, Are Existing
KnowledgeTransferTechniquesEffectiveForDeepLearn-
ing on Edge Devices?, in: Proceedings of the 27th In-
ternationalSymposiumonHigh-PerformanceParalleland
DistributedComputing,HPDC’18,AssociationforCom-
puting Machinery, New York, NY, USA, 2018, pp. 15–16.
doi:10.1145/3220192.3220459.
[58] R. Kolcun, D. A. Popescu, V. Safronov, P. Yadav, A. M.
Mandalari, Y. Xie, R. Mortier, H. Haddadi, The Case for
Retraining of ML Models for IoT Device Identification at
theEdge(Nov.2020). doi:10.48550/arXiv.2011.08605.
[59] S.Nastic,A.Morichetta,T.Pusztai,S.Dustdar,X.Ding,
D.Vij,Y.Xiong,SLOC:ServiceLevelObjectivesforNext
Generation Cloud Computing, IEEE Internet Computing
24 (3) (May 2020). doi:10.1109/MIC.2020.2987739.
[60] J. Fu¨rst, M. Fadel Argerich, B. Cheng, A. Papageorgiou,
ElasticServicesforEdgeComputing,in: 201814thInter-
nationalConferenceonNetworkandServiceManagement
(CNSM), 2018, pp. 358–362.
[61] M.-N. Tran, Y. Kim, Optimized resource usage with hy-
brid auto-scaling system for knative serverless edge com-
puting, Future Generation Computer Systems 152 (2024)
304–316. doi:10.1016/j.future.2023.11.010.
[62] A. Hazra, P. K. Donta, T. Amgoth, S. Dustdar, Cooper-
ative transmission scheduling and computation offloading
with collaboration of fog and cloud for industrial iot ap-
plications,IEEEInternetofThingsJournal10(5)(2023)
3944–3953.
[63] J. Karjee, S. Praveen Naik, N. Srinidhi, Energy Pro-
filing based Load-Balancing Approach in IoT-Edge for
Split Computing, 2021 IEEE 18th India Council Inter-
nationalConference(INDICON)(2021)1–6doi:10.1109/
INDICON52576.2021.9691607.
[64] J. Lim, D. Lee, A Load Balancing Algorithm for
Mobile Devices in Edge Cloud Computing Environ-
ments, Electronics 9 (4) (2020) 686. doi:10.3390/
electronics9040686.
[65] Z. Duan, C. Tian, N. Zhang, M. Zhou, B. Yu, X. Wang,
J. Guo, Y. Wu, A novel load balancing scheme for mo-
bileedgecomputing,JournalofSystemsandSoftware186
(2022) 111195. doi:10.1016/j.jss.2021.111195.
[66] A.Rao,K.Lakshminarayanan,S.Surana,R.Karp,I.Sto-
ica,LoadBalancinginStructuredP2PSystems,Vol.2735,
2004, journal Abbreviation: Lecture Notes in Computer
SciencePublicationTitle: LectureNotesinComputerSci-
ence. doi:10.1007/978-3-540-45172-3_6.
[67] V. H. Menino, A Novel Approach to Load Balancing in
P2P Overlay Networks for Edge Systems, 2021.
33

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Equilibrium in the Computing Continuum through Active Inference"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
