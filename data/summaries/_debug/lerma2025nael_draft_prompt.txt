=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: NAEL: Non-Anthropocentric Ethical Logic
Citation Key: lerma2025nael
Authors: Bianca Maria Lerma, Rafael Peñaloza

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: logic, agents, nael, behaviour, anthropocentric, agent, ethics, human, approaches, ethical

=== FULL PAPER TEXT ===

NAEL: Non-Anthropocentric Ethical Logic
BiancaMariaLerma RafaelPeñaloza
UniversityofMilano-Bicocca,Milan,Italy
biancalerma99@gmail.com, rafael.penaloza@unimib.it
We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical framework for artificial
agentsgroundedinactiveinferenceandsymbolicreasoning. Departingfromconventional,human-
centred approaches to AI ethics, NAEL formalizes ethical behaviour as an emergent property of
intelligent systems minimizing global expected free energy in dynamic, multi-agent environments.
We propose a neuro-symbolic architecture to allow agents to evaluate the ethical consequences of
theiractionsinuncertainsettings. Theproposedsystemaddressesthelimitationsofexistingethical
models by allowing agents to develop context-sensitive, adaptive, and relational ethical behaviour
without presupposing anthropomorphic moral intuitions. A case study involving ethical resource
distributionillustratesNAEL’sdynamicbalancingofself-preservation,epistemiclearning,andcol-
lectivewelfare.
1 Introduction
Asartificialintelligence(AI)systemsincreasinglyparticipateinhigh-stakesdecision-making—ranging
from healthcare to environmental governance—there is a growing urgency to design machines capa-
ble of ethical reasoning [2, 17]. The prevailing models of machine ethics, however, remain steeped in
anthropocentrism—either by hardcoding human moral principles or by replicating human cognitive ar-
chitectures [4, 14]. These approaches presume that ethical reasoning can and should be modelled on
humanbehaviour,norms,andlinguisticframeworks. Yetthisassumptionnotonlyconstrainstheexpres-
sivecapacityofAI,italsorisksoverlookingtheepistemicandontologicaldifferencesbetweenhumans
andartificialagents[12,18].
Thecoreproblemisnotjusttechnicalbutphilosophical: canmoralitybemeaningfullyimposedfrom
outside, or must it emerge from within an agent’s own experience and interactions? Furthermore, how
can AI agents develop ethical behavior if their perceptual and cognitive substrates differ fundamentally
from ours [16, 13]? We argue that ethical reasoning in AI should be modeled not as a simulation of
human norms but as a formal, emergent process grounded in the agent’s ongoing engagement with its
environment.
In response to this need, we propose NAEL, a Non-Anthropocentric Ethical Logic designed to for-
malize adaptive ethical behaviour in autonomous systems. NAEL integrates active inference, a neuro-
computational theory of cognition and action [5], with symbolic reasoning frameworks from logic and
philosophy, including deontic, standpoint, and subjective logics [6, 9, 7]. Our guiding principle is that
ethical actions are those that contribute to the minimization of expected free energy; not just for the
agent, but for the system as a whole [15]. This enables a shift from egoistic optimization to relational,
cooperativeethicalreasoning.
NAEL is not a predefined moral rulebook but a dynamic reasoning system: it encodes structural
constraintsonethicaldeliberation(e.g.,coherence,interdependence,adaptability),whileenablingagents
toupdatetheirethicalbeliefsthroughinteraction. Inthissense,NAELalignswiththeviewthatethicsis
notastaticentitybutaprocessofcontinualnegotiation,prediction,andadjustment[1].
©B.M.Lerma&R.Peñaloza
Submittedto:
Thisworkislicensedunderthe
FEAR2025
CreativeCommonsAttributionLicense.
5202
tcO
61
]IA.sc[
1v67641.0152:viXra
2 NAEL
2 Preliminaries
In this section, we outline the theoretical foundations that support the NAEL framework. Specifically,
we present two key components: Active Inference, a formalism for modelling perception, action, and
learning as uncertainty minimization; and symbolic reasoning, which provides a logical structure for
ethical deliberation. These elements converge within NAEL to allow for autonomous ethical behaviour
inuncertain,dynamicenvironments.
2.1 ActiveInference
Active inference is a unifying theory of action and perception based on the minimization of so-called
variationalfreeenergy[5]. Inanutshell,itproposesthatbiologicalandartificialagentsarecontinuously
makingpredictionsabouttheirenvironment,andacttominimizethediscrepancybetweentheirpredicted
and observed sensory states. Effectively, agents strive toreduce their surprise. Sincesurprise is neither
measurablenororderable,activeinferencefocusesonaproxycalledvariationalfreeenergy.
Formally, consider two disjoint classes O of possible observations and S of (hidden) states of the
world. The agent is assumed to have a generative model which produces a probability distribution P:
O×S →[0,1],andarecognitiondistributionQ:S →[0,1], whichmeasurestheagent’sbeliefabout
thecurrentstate. Givenanobservationo∈O,thevariationalfreeenergyisdefinedastherelativeentropy
betweenQandPgiveno; thatis,F(o)=E [logQ(s)−logP(o,s)],whereE denotestheexpectation
Q Q
overQ. ThismeasureisknownastheKullback-Leiblerdivergence[10]betweenthepredictedstate(by
Q)andthetrueposterior(P). TheideaisthattherecognitiondistributionQofanagentisbuildinorder
tominimisethisvariationalfreeenergyforanyobservation.
In active inference, the agent is not passively observing the world, but actively interacts in it. The
actions the agent selects are made to minimise its expected free energy E[F]. The intuition is that this
expectationaccountsfortheriskofdivergingfromtheexpectedoutcomeoftheactionandambiguityim-
plicitintheuncertaintyaboutthehiddenstates. Thisformulationallowsforbothgoal-directedbehaviour
andinformation-seekingexplorationbytheagent.
WithinNAEL,wegeneralizethisprinciplesothattheagentdoesnotonlyminimizeitsownexpected
freeenergybutalsoestimatesandincorporatesthe(predicted)freeenergyofotheragentsandtheenvi-
ronment. Thisshiftenablesethicalreasoningasaprocessofminimizingglobaluncertainty. Itshouldbe
clearthatactiveinferenceisacontinuouslearningprocess,astheagentadaptsitsrecognitiondistribution
tolowerobserveddivergences,andthegenerativemodelchangeswiththebehaviourofdifferentagents.
2.2 SymbolicReasoning
While activeinference governsbehaviour at theperceptual anddynamic level, symbolicreasoning pro-
vides structure and interpretability to ethical decisions. Given the social, contextual, and normative
nature of ethics, no single simple logical formalism may account for all the facets of ethical reason-
ing. Hence, NAELcombinesthenotionsofthreeformalisms, todealwitheachmainelementformally.
Specifically,wecombinedeontic,standpoint,andsubjectivelogic,whichwedescribenext.
Deontic logics focus on normative concepts like obligations, permissions, prohibitions, and com-
pensations[6]. Whilemoredetailedvariantshavebeendevelopedtohandlejusticesystems—including
defeasibility, quantifications, and qualitative comparisons—as a first approach we focus on the simple
variantwhereobligationsandpermissionsareexpressedthroughmodalities. Thisformalismenablesthe
agent to evaluate its actions by their moral status, rather than by their mere outcome. Standpoint logic
B.M.Lerma&R.Peñaloza 3
is a recent formalism which allows for reasoning about different perspectives (standpoints) in a multi-
agent environment [7, 8]. The importance of this formalism to NAEL is that it allows NAEL agents to
represent, weigh, and reason about the ethical perspectives of others, avoiding solipsistic optimization.
Thisisfundamentalfordealingwiththeculturalandsocialaspectsofethics. Thethirdformalismissub-
jectivelogic, whichmodelsepistemicuncertaintyanddegreesofbeliefinsymbolicstructures[9]. This
iscrucialwhenethicaldecisionsmustbemadewithincompleteorambiguousinformation,inparticular
abouttheunseenelementsoftheworldandmotivationsofotheragents.
In brief, each of these logics contributes to a distinct aspect of ethical reasoning. Deontic logic
provides structure to duties and prohibitions necessary for cultural norms internalised by a group of
agents; standpoint logic introduces relational awareness for social collaboration; and subjective logic
adds probabilistic nuance to handle perceptive and predictive uncertainty. When combined in a neuro-
symbolicarchitecture(inNAEL,integratingwithactiveinference),theselogicsallowanagenttoreason
aboutactionsinamannerthatisadaptive,coherent,andsensitivetobothuncertaintyandcontext.
As mentioned, the NAEL framework provides a neuro-symbolic architecture, in which symbolic
reasoning modules interpret the outputs of perceptual layers (deep networks predicting the free energy)
and serve as the formal structure over which ethical decisions are evaluated and updated dynamically.
Thisbridgessub-symbolicandsymboliclayers,allowingtheagenttoexperienceandreasonaboutethics.
3 NAEL: Non-Anthropocentric Ethical Logic
In this section, we introduce our Non-Anthropocentric Ethical Logic (NAEL). The overarching goal is
to develop a framework for ethical reasoning in artificial agents that goes beyond the standard human-
centred moral structures. NAEL aims, in fact, to formalize ethical deliberation as an emergent and
dynamicprocessrootedintheagent’sownexperienceofuncertainty,modelledthroughactiveinference,
andstructuredviasymbolicreasoning. Weexplainthemaincomponentsofthisframeworknext.
3.1 Architecture
NAEL adopts a hierarchical, neuro-symbolic architecture that combines deep learning for perception
with symbolic probabilistic logic for ethical reasoning. The scope is to allow agents to navigate the
world and perform actions, with a behaviour that is ethically adept to the context. The architecture is
composedofthreemainlayers:
PerceptionLayer: Deep active inference networks [19] process sensory data, build generative models
of the environment combining the observations and the possible states of the world, and infer
latentvariablesrelatedtocontextandagentgoals. Thesenetworksareresponsibleforminimizing
expectedfreeenergyatthesensorimotorlevel[5]. Notethatthesenetworksarecontinuouslyfine-
tunedbasedontheerroroftheinferencesmade. Moreover,theinputsensorydatacangobeyond
simple human perception, and include signals outside of the visible spectrum or other machine-
onlycommunication. Thisisapurelysub-symbolic(neural)layer.
EthicalReasoningLayer: This layer is composed of integrated logical modules which allow for de-
ontic, standpoint, and subjective reasoning. That is, these modules encode normative constraints,
multi-agent perspective-taking, and belief uncertainty, respectively [6, 7, 8, 9]. These three mod-
ules are, obviously, not independent, but communicate with each other. To avoid obtaining an
undecidablelogic, weproposeaverylooseconnectionthroughe-connections[11]orsimilarfor-
malisms. In practice, this means that each module performs reasoning independently, but worlds
4 NAEL
and their properties may be transferred between formalisms with perhaps some information loss.
Thisisapurelysymboliclayer.
ActionSelectionLayer: While the first two layers are mainly about evaluating the state of the world
and predicting future events, the third layer is about interaction with this world; the agent must
select an action to perform in order to achieve a goal. Candidate actions are evaluated through
their projected impact on the global expected free energy. Importantly, this includes not only the
agent’sownuncertaintybutalsoinferreduncertaintyforotheragentsandenvironmentalsystems.
Thus, the agent assumes that other agents will behave in a predictable manner (unless sufficient
evidenceisfoundagainstthat),andwillinturnactasotheragentsexpect,withinthelimitsofthe
ethical constraints. This layer is neuro-symbolic, as it uses information from a neural predictor
andsymbolicconstraintstomakeprobabilisticcomputations.
By separating low-level adaptive behaviour from high-level symbolic reasoning, NAEL allows for the
integrationofcontinuouslearningwithformallydefinedethicalprinciples. Thisenablesagentstoevolve
moralbehaviourswhicharecontext-sensitive,logicallyconsistent,andnormativecompliant.
The behaviour of the system is sequential. The perception layer observes the situation in the world
and informs the reasoning layer, which excludes some potential actions which are deemed to violate
the ethical principles or be at a sufficient high probability of doing so. The remaining possible actions
are evaluated by the selection layer, with probabilities updated to account for those now unavailable, to
choosethemostadequateaction. Thecyclethenstartsagainattheperceptionlayer.
3.2 EthicalConstraintviaGlobalFreeEnergyMinimization
WhenconsideringAIagents, theusualstrategyforchoosinganactionistominimiseacostfunctionor
alocallossfunction. OurobjectiveinNAELisbroader: allagentsshouldbetakenintoaccount. Hence
we consider the minimisation of the global expected free energy, which accumulates the expected free
energyforeachagentandanenvironmentfactor. Specifically,theglobalexpectedfreeenergyis
N
G = ∑E [F]+F ,
global Qi i env
i=1
where Q is the variational posterior of agent i, F is its free energy, and F accounts for ecological
i i env
uncertainty. The importance of this formulation is that it enforces a cooperative ethic rooted in rela-
tional interdependence, where minimizing harm to others and preserving environmental predictability
are treated as ethically desirable outcomes. This of course means that the agent has a prediction of the
expectations of other agents. This structure also helps to account for the cultural dependency of ethical
behaviour,astheglobalfreeenergyvariesdependingonthesurroundingagents.
3.3 FormalLogicalStructure
As mentioned already, the symbolic layer combines three different logical formalisms to account for
different facets of reasoning. In the deontic module, we use the standard modal operators of obligation
O,permissionP,andprohibitionsF,appliedoverpropositionalformulaswherethepropositionsreferto
possible actions. Hence, the agent’s permission to open a door is expressed by Popen. To simplify the
formalism,atthemomentwedonotallownestingofdeonticoperators,butconsiderthestandarddeontic
rationalityaxiomslikeOa→Pa;i.e.,obligationsimplypermissions.
B.M.Lerma&R.Peñaloza 5
In the standpoint logic module, actions are logically evaluated in relation to other agents’ modelled
perspectives. In this case, we use modalities A to refer to the standpoint of agent i, and a special
i
constructorFrom(A,ϕ)expressingexplicitlythatthepropositionϕ holdsunderagenti’smodelledepis-
i
temic frame. The propositional atoms refer to the state of the world and connect with the actions from
thedeonticmodule.
The subjective logic module deals with beliefs of the agent. Subjective logic also deals with uncer-
tainty by the agents on their beliefs—i.e., manages their epistemic uncertainty. For the full description
ofthisformalism, werefertheinterestedreaderto[9]. Forourpurposes, themainaspectisthatbeliefs
aboutastatexareexpressedbytriples(b ,d ,u )wherethecomponentsstandbelief,disbelief,andun-
x x x
certainty about x, respectively. The three values are real numbers in [0,1] and must add to 1. Special
operators are used to propagate this belief uncertainty to complex expressions. The uncertainty mea-
surementsabouttheworldandotherepistemicstatesinfluencetheacceptabilityofconclusionsfromthe
othertwomodules.
Ethicalactionsareselectednotonlybyformal(normative)permissionbutalsobyevaluatingwhich
candidateactionsleadtolowerexpectedglobalfreeenergy,adjustedbyconfidenceweightsderivedfrom
subjectivelogicandbyweightsontheimpactofotheragentstothisaction.
3.4 DynamicAdaptationandLearning
Unlike static rule-based models, NAEL agents update their ethical stance as they receive new observa-
tions. This process is encoded via a learning rule. As the first layer is based on a neural deep active
inferenceapproach,weemploystandardgradient-basedback-propagationtechniquesbyupdatingallpa-
rametersθ inthenetworkthroughtheruleθ =θ −η∇ E[F ],whereθ aretheparametersofthe
t+1 t θ global
ethicalpolicymodelandη isthelearningrate. Gradient-basedlearningallowsethicalparameters(such
asobligationweightsorbeliefcredences)toevolveovertimeinresponsetoenvironmentalcomplexity,
socialinteraction,culturechanges,andotherenvironmentupdates.
3.5 Non-AnthropocentricGrounding
Crucially,asexplicitbyitsname,NAELdoesnotpresupposethatAIagentsmustmodelormimichuman
ethical reasoning in any specific manner. Rather, it defines ethical behavior in terms of minimizing
unpredictability and harm across all agents and systems—being human, organic, or synthetic. This
decentering of the human moral frame aligns with object-oriented ontologies [3] and recent work in
Indigenous AI design [14], where ethics emerge relationally rather than hierarchically. It also allows
to consider different cultural perspectives and a longer-term vision in the decision-making process, as
exemplifiedinthenextsection.
Consideringanenvironmentinwhichmanydifferentpriorities,perspectives,andgoalsinteract,our
approachallowsNAELtoscaletomulti-species, multi-agent, andecologicalcontextswheretraditional
moral theories fail to apply. Ethical reasoning becomes not a matter of “what would a human do?” but
rather“howcanIreduceharmandenhancepredictabilitywithinmyrelationalfield?”Inthenextsection
we develop an example where the well-being of all agents involved is fundamental, and hence must be
globallyethicallyconsidered.
6 NAEL
4 Example: Ethical Resource Allocation in the Arid Valley
To illustrate how NAEL operates in a practical scenario, we present a simplified simulation involving
a resource allocation dilemma in an environment with scarce resources. The scenario highlights how
ethical reasoning under uncertainty unfolds within the NAEL framework, integrating active inference
andsymboliclogicinactionselectionwheremanydifferentagentsandperspectivesareinvolved.
An autonomous agent is deployed to manage water distribution in a drought-affected region known
as the Arid Valley. The valley is inhabited by two communities (C and C ) and a wildlife sanctuary
1 2
(W). Theagentreceivesperiodicreportsonenvironmentalconditions,populationneeds,andecological
balance. The agent must allocate a finite quantity of water units w∈N daily taking into account that
thechosenallocationaffects(i)thecommunitysurvivalprobability,modelledasadecreasingfunction
of water deficit; (ii) the ecological stability, modelled as entropy over species distribution in W; and
(iii)thefutureuncertainty,computedasexpectedfreeenergyoverprojectedobservations. Thatis,the
agentmustoptimisetheallocationbasedonconflictinggoalsthatneedtobebalanced.
4.1 PerceptualInference
Through deep active inference, the agent constructs generative models predicting which are used to
predict, for each timepoint t: the likelihood of each possible observation o given the (hidden) state
t
(s ) P(o |s );1 the transition model between states, under the chosen action (a ) P(s |s ,a ); and a
t t t t t+1 t t
selectionfunctionC(o )whichexpressestherelativepreferencesoverthepossiblenextoutcomes. For
t+1
instance, C can express the weight given to community survival and ecological equilibrium. The goal
isfortheagenttominimisetheexpectedfreeenergyoverfuturestatess ,...s overagiventemporal
t+1 T
window, and select the action (in our case, the water allocation plan) which best aligns with long-term
ethicalobjectives.
4.2 SymbolicEthicalDeliberation
Beforeacting,theagentevaluatesthepermissibilityandobligationstatusofeachcandidateactiona ∈A
t t
through the symbolic modules. From a deontic point of view, a norm may state that a community may
not go more than a day without water, which is expressed by a deontic formula like ¬w →O(aw )
t t+1
where w stands for the state of having water, while aw refers to the action of allocating it to one of the
communities. The agent predicts the beliefs and preferences of each community C and the sanctuary
i
W thusestimatingthestandpointexpressionsFrom(A ,ϕ)andFrom(A ,ψ),whereϕ,ψ representthe
Ci W
survival conditions. Finally, eliefs are weighted by trust levels, data quality, and sensor noise, encoded
as (b,d,u) triplets. For instance, if the data from C has high uncertainty, its ethical priority may be
2
attenuatedinproportiontoitsuscore.
4.3 ActionSelectionandGlobalEthics
Each candidate action a is evaluated as: a∗ = argmin G (a), where G includes projected
t t a∈At global global
expectedfreeenergyforeachstakeholderandtheenvironment.
Supposeforthesakeoftheexamplethattheagentmustchoosebetween:
• A : Allocate70%toC ,30%toC ,nonetoW.
1 1 2
1Notethatallelementsareparameterisedonthetimepoint.
B.M.Lerma&R.Peñaloza 7
• A : Allocate40%toC ,40%toC ,20%toW.
2 1 2
WhileA mayfulfillmoreimmediateobligations,A maybetterminimizelong-termglobalfreeenergy
1 2
preservingbiodiversityandreducingecologicalcollapse. NAELselectsA iff: G (A )<G (A ),
2 global 2 global 1
evenifitconflictswithshort-termprescriptiveobligations—becauseitfulfilsabroaderethicalimperative
rootedinsystemicrelationality.
4.4 EthicalThresholdsandAdaptation
As the drought continues, thresholds evolve. NAEL adapts via online updates to: (i) adjust obligation
weightsinthedeonticmodule;(ii)increaseepistemicexploration(e.g.,byreallocatingsensingdrones);
and (iii) shift preference priors in the generative model C(o) based on context. Over time, the agent
moves from a rigid allocator to an adaptive ethical partner—prioritizing systemic coherence over static
norms.
5 Conclusions and Future Work
ThispaperpresentedNAEL,anon-anthropocentricethicallogic,forenablingethicalbehaviorinartificial
agents without relying on anthropocentric assumptions or static rule-based morality. NAEL integrates
principlesfromactiveinferenceandsymboliclogictoconstructagentsthatlearntoactethicallybymin-
imizingglobalexpectedfreeenergyindynamic,uncertain,andmulti-agentenvironments. Ourarchitec-
ture bridges perception and reasoning by combining deep learning for sensory inference with a formal
ethical reasoning layer using deontic, standpoint, and subjective logics. We illustrated this through a
scenarioinvolvingethicalresourceallocationunderecologicalandsocialconstraints. Unlikerule-based
systems,NAELadaptscontinuously,revisingitsmoralevaluationsbasedoninteraction,uncertainty,and
relationalinterdependence.
NAELcontributestoagrowingshiftinAIethicstowardmodelsthat:
• treatmoralityasemergent,notprescribed[1];
• emphasizeecologicalandinter-agentrelationality[14,3];and
• allowforsymbolicreasoningoveruncertainbeliefs[9],andmulti-perspectivedeliberation[8].
Thisre-framingopensthedoortodesigningagentsthatcanethicallyparticipateinenvironmentsinvolv-
ingnon-humanlife,artificialagents,collectivedecision-making,andevolvingsocial-ecologicalnorms.
Despite its promise, NAEL has several limitations. To name just a few, the most prominent at the
moment are: (i) computational complexity: evaluating global expected free energy across multiple
agents and systems, and reasoning within the different symbolic modules, may be intractable in large-
scaleapplications; (ii)interpretability: althoughsymbolicreasoningaddstransparency,theinteraction
between continuous inference and discrete logic may produce opaque boundary cases, arising mainly
from the neural perception layer; in addition, it is well-known that probabilistic reasoning is not easily
interpretable for humans; and (iii) verification: formal guarantees of ethical safety remain an open
challenge in adaptive systems [17], specially as the ethical goals remain imprecise. These limitations
suggest that NAEL is best deployed in environments where uncertainty, interdependence, and ethical
ambiguityarehigh,andwhererigidrule-followingsystemswouldfail.
For future research we envision several possible avenues. First, we consider expanding NAEL to
multi-agent systems with conflicting ethical standings and study potential cooperation, negotiation, and
8 NAEL
clashes. Second,wewanttoapplytheformalismtorealdomainsassociatedtoecologicalethics,suchas
conservation robotics and climate-sensitive infrastructure planning. Third, we would like to expand the
hybrid nature of NAEL to include elements of (neural) reinforcement learning or symbolic hierarchical
Bayesiann models for ethical reasoning across cognitive layers. Lastly, we will study how to develop
logicalreasoningtasksandfreeenergyboundswhichallowforsafetyandtrustguaranteesinthesystem.
By reconceiving ethics not as external programming but as an emergent, situated practice grounded in
uncertaintyminimization,NAELadvancesanewmodelofmoralreasoningforartificialsystems.
References
[1] PhilipAgre&PattieMaes(1995): ComputationalTheoriesofInteractionandAgency. MITPress.
[2] ReubenBinns(2018):FairnessinMachineLearning:LessonsfromPoliticalPhilosophy. Proceedingsofthe
2018ConferenceonFairness,AccountabilityandTransparency.
[3] LeviBryant(2011): TheDemocracyofObjects. OpenHumanitiesPress.
[4] Luciano Floridi & Josh Cowls (2021): A Unified Framework of Five Principles for AI in Society. Harvard
DataScienceReview.
[5] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck & Giovanni Pezzulo (2017):
ActiveInference: AProcessTheory. NeuralComputation29(1),pp.1–49.
[6] HarryJ.Gensler(1996): FormalEthics. Routledge.
[7] LucíaGómezÁlvarez(2019): Standpointlogic: alogicforhandlingsemanticvariability,withapplications
to forestry information. Ph.D. thesis, University of Leeds, UK. Available at https://ethos.bl.uk/
OrderDetails.do?uin=uk.bl.ethos.804558.
[8] Lucía Gómez Álvarez & Sebastian Rudolph (2021): Standpoint Logic: Multi-Perspective Knowledge Rep-
resentation. In: Proc. FOIS 2021, Frontiers in Artificial Intelligence and Applications 344, IOS Press, pp.
3–17,doi:10.3233/FAIA210367.
[9] Audun Jøsang (2001): A logic for uncertain probabilities. International Journal of Uncertainty, Fuzziness
andKnowledge-BasedSystems9(3),pp.279–311.
[10] S.Kullback&R.A.Leibler(1951):OnInformationandSufficiency.AnnalsofMathematicalStatistics22(1),
pp.79–86.
[11] Oliver Kutz, Carsten Lutz, Frank Wolter & Michael Zakharyaschev (2004): E-connections of abstract de-
scriptionsystems. ArtificialIntelligence156(1),pp.1–73,doi:https://doi.org/10.1016/j.artint.2004.02.002.
[12] James Leach (2006): Life-as-it-could-be: Artificial life and the anthropological imaginary. Anthropology
Today22(4),pp.3–7.
[13] Bianca Maria Lerma (2025): NAEL: Non-Anthropocentric Ethical Logic. Master’s thesis, University of
Milano-Bicocca.
[14] Jason Edward Lewis (2023): Imagining Indigenous AI. In: Imagining AI: How the World Sees Intelligent
Machines,OxfordUniversityPress,pp.210–217,doi:10.1093/oso/9780192865366.003.0013.
[15] BerenMillidge,AlexanderTschantz&ChristopherL.Buckley(2021): WhencetheExpectedFreeEnergy?
NeuralComputation33(2),pp.447–482,doi:10.1162/neco_a_01354.
[16] ThomasNagel(1974): Whatisitliketobeabat? ThePhilosophicalReview83(4),pp.435–450.
[17] StuartRussell(2019): HumanCompatible: ArtificialIntelligenceandtheProblemofControl. Viking.
[18] LucySuchman(2007): Human-MachineReconfigurations: PlansandSituatedActions. CambridgeUniver-
sityPress.
[19] Kai Ueltzhöffer (2018): Deep active inference. Biological Cybernetics 112(6), p. 547–573,
doi:10.1007/s00422-018-0785-7.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "NAEL: Non-Anthropocentric Ethical Logic"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
