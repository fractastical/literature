=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Meta-Representational Predictive Coding: Biomimetic Self-Supervised Learning
Citation Key: ororbia2025metarepresentational
Authors: Alexander Ororbia, Karl Friston, Rajesh P. N. Rao

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Abstract: Self-supervised learning has become an increasingly important paradigm in the domain of
machineintelligence. Furthermore,evidenceforself-supervisedadaptation,suchascontrastive
formulations,hasemergedinrecentcomputationalneuroscienceandbrain-inspiredresearch.
Nevertheless,currentworkonself-supervisedlearningreliesonbiologicallyimplausiblecredit
assignment–intheformofbackpropagationoferrors–andfeedforwardinference,typicallya
forward-lockedpass. Predictivecoding,initsmechanisticform,offersabiologic...

Key Terms: biomimetic, meta, input, representational, washington, learning, supervised, predictive, coding, self

=== FULL PAPER TEXT ===

META-REPRESENTATIONAL PREDICTIVE CODING:
BIOMIMETIC SELF-SUPERVISED LEARNING
AlexanderG.Ororbia KarlFriston RajeshP.N.Rao
RochesterInstituteofTechnology VERSESAIResearchLab UniversityofWashington
Rochester,NewYork,USA LosAngeles,California,USA Seattle,Washington,USA
ago@cs.rit.edu karl.friston@verses.ai rao@cs.washington.edu
ABSTRACT
Self-supervised learning has become an increasingly important paradigm in the domain of
machineintelligence. Furthermore,evidenceforself-supervisedadaptation,suchascontrastive
formulations,hasemergedinrecentcomputationalneuroscienceandbrain-inspiredresearch.
Nevertheless,currentworkonself-supervisedlearningreliesonbiologicallyimplausiblecredit
assignment–intheformofbackpropagationoferrors–andfeedforwardinference,typicallya
forward-lockedpass. Predictivecoding,initsmechanisticform,offersabiologicallyplausible
meanstosidestepthesebackprop-specificlimitations. However,unsupervisedpredictivecoding
restsonlearningagenerativemodelofrawpixelinput(akinto“generativeAI”approaches),
which entails predicting a potentially high dimensional input; on the other hand, supervised
predictive coding, which learns a mapping between inputs to target labels, requires human
annotation,andthusincursthedrawbacksofsupervisedlearning. Inthiswork,wepresenta
schemeforself-supervisedlearningwithinaneurobiologicallyplausibleframeworkthatappeals
to the freeenergy principle, constructing a new form ofpredictive coding that wecall meta-
representationalpredictivecoding(MPC).MPCsidestepstheneedforlearningagenerative
model of sensory input (e.g., pixel-level features) by learning to predict representations of
sensoryinputacrossparallelstreams,resultinginanencoder-onlylearningandinferencescheme.
Thisformulationrestsonactiveinference(intheformofsensoryglimpsing)todrivethelearning
ofrepresentations,i.e.,therepresentationaldynamicsaredrivenbysequencesofdecisionsmade
bythemodeltosampleinformativeportionsofitssensorium.
Keywords Self-supervised learning · Predictive coding · Free energy optimization ·
Brain-inspiredcomputing·Biologicalcreditassignment·Biomimeticintelligence
1 Introduction
Self-supervisedlearninghasbecomeanincreasinglyimportantparadigminthedomainofmachineintelligence
[21, 35]. Furthermore, some forms of self-supervised adaptation, such as contrastive formulations — which
learnhowtoinverttheprocessgeneratingdatasamples[120]—haveemergedincomputationalneuroscience
andbrain-inspiredcomputing[81,90]. Nevertheless,currentworkonself-supervisedlearning(SSL)relieson
biologically-implausiblecreditassignment–intheformofbackpropagationoferrors(backprop)–andinference
–typicallyaforward-lockedfeedforwardpass[46,80]. Aschemethatcouldconductthiskindoflearningina
neurobiologically-plausiblemanner,i.e.,inabackprop-freemanner,wouldbevaluable.However,currentimportant
computationalandmechanisticframeworks,includingmostpredictivecodingschemes[92,94,75,100],—which
provideviableaccountsofneurobiologicalinferenceschemes(viamessagepassing)andcreditassignment(via
localplasticityrules)—areprimarilyformulatedforlearningcomplexgenerativemodelsofrawsensoryinputor
mappingfunctionsbetweeninputandsupervisorysignals. Theseunsupervisedandsupervisedformsofpredictive
coding,however,donotspeaktoareverseperspectiveofneuronalinferenceandlearning: whatmightpredictive
codinglookifitonlylearnedageneratoroflatentstates(anencoderonly),asopposedtoageneratorofsensory
states(agenerativedecoder)? Thiscouldopenthedoortoaformofself-supervisedpredictivecodingfocusedon
learningdistributedrepresentationsofsensorystimuliwithoutexplicitlymodelinghighdimensionalinputs.
5202
raM
22
]EN.sc[
1v69712.3052:viXra
Preprint
In this work, we invert the premise of predictive processing [20, 107, 26, 15, 105] from top-down generative
learningtobottom-uprepresentationacquisition,castingthegoaloffreeenergy[32,27]minimizationasprediction
inlatentdistributedrepresentationspaces. Todoso,wedrawinspirationfromhowthevisualsystem[23,55,69]
processesstimulithroughcentralandperipheralstreamsandeyemovementssuchassaccades(i.e.,activevision).
Concretely,weframeinferenceandlearninginthecontextofapredictivecoding(PC)schemethatcomprises
an architecture of neuronal streams, some of which process central (high-resolution) views of the input while
othersprocessperipheral(low-resolution)ones. Thesecentralandperipheralstreamsinteractbypredictingthe
dynamics/behaviorofoneanother. Asaresult,weproposeageneralizationofpredictivecodingthatconductsa
formofencoder-onlyself-supervisedlearningthatwecallmeta-representationalpredictivecoding(MPC).Our
workmakesthefollowingcontributionstobiomimeticintelligenceandself-supervisedlearning:
• Wepresentandformulateaframeworkforbiologically-plausibleinferenceandcreditassignmentthat
restsonlearningdistributedrepresentationsofsensoryinputinaself-supervisedmanner.
• Castingself-supervisedneuralcomputationandcreditassignmentwithinandbetweenstreamsresults
in synaptic plasticity based on local neural statistics and inference conducted in a layer-wise parallel
fashion. Thisshowsthatagenerativemodelcanbelearnedwithoutpredictingrawsensoryinput(asin
machinelearningimplementationsofpredictiveprocessing)byinsteadpredicitnglatentactivityacross
visualstreams;thisfurtherobviatestheneedforcommonSSLmechanismssuchastheproductionof
positive/negativeexamplesasincontrastivelearning.
• WedemonstratethatMPCproducesaglobalencodingofasensorystimulusthroughaniterativesampling
andprocessingofportions(subsetsofvariables)ofrawinput,inspiredbythesaccadesthatbiological
eyesenact,yieldingascalableschemethatisagnostictothedimensionalityofsensorydata–themodel’s
representationsareshowntobehighlyeffectiveinseveraldownstreamsupervisedtasks.
• Thiskindof(biomimetic)PCincorporatesanenactiveperspectiveonprediction: thecoordinatesofwhere
anMPCcircuitislookinginformthedynamicsofitsconstituentneuronalunits,offeringasteppingstone
towardsmodelsofactivevisionandinferencesuchasactivepredictivecoding[93,91].
2 RepresentationalPredictiveCoding: Cross-CircuitLatentDynamicsandLearning
Notation. Inthiswork,weuse⊙toindicatetheHadamardproduct(orelement-wisemultiplication)and·to
denotematrix/vectormultiplication. (v)T isthetransposeofv. Matrices/vectorsaredepictedinboldfont,e.g.,
matrixMorvectorv(scalarsshowninitalics).z willrefertothejthelementofvectorz.<a,b>denotesvector
j
concatenationalongthecolumndimension;i.e.,thedotorinnerproduct. Finally,||v|| denotestheEuclidean
2
normofvectorv. Sensoryinputhasshapex∈RJ0×1(J
0
isthenumberofinputfeatures),andaneurallayerhas
shapezℓ ∈RJℓ×1(J
ℓ
isthenumberofneuronsforlayerℓ). Matrixflattening(toacolumnvectoroflengthequal
totheproductofthematrix’snumberofcolumnandrows)isdenotedasFlat().
2.1 SensoryStimuliProcessing: EyeStructureandMovements
Asastartingpointforhowwestructuretherequisiteneuronalmodel,weformulateitsabilitytoselectivelysample
itssensorium. Intermsofthemodelstructure,wedrawinspirationfromthefunctionalanatomy[118](ofanimals
andhumans)intermsofcentralandperipheralvision[108,112].1 Invisualprocessing[96],centralandperipheral
visionbothplayanimportantrole. Centralvision,furtherdecomposedintofoveal(extendingtoonedegreeof
eccentricityfromthevisualfield’scentercontainingthehighestdensityofconereceptorswithhighestresolution
[89, 16, 56]) and parafoveal (extending 4-5 degrees of eccentricity yet containing a high density of slightly
lower-resolution rod receptors [95, 111]) vision reports higher-resolution, detailed sensory information while
peripheralvisionfocusesonencodingcoarser-grained,lower-resolutiondatafeatures.Duetoitshigherdensity(and
smallerreceptivefieldsize)ofrodsandcones,centralvisionisthoughttobeimportantforhighspatialfrequency
recognitiontasks[104,68](suchasrecognizinganobjectorface). Ontheotherhand,peripheralvision,withthe
highestproportionofrodsatthelowestspatialresolution,isgenerallyviewedasimportantforlowspatialfrequency
tasksthatrequireobtainingaglobalgistofascene[103,60,57](orthe“biggerpicture”view). Whileitisthecase
thatvisiontendstocalloncentralandperipheralvisiondifferently,dependingonthetask[112],itisclearthat
thesetwovisualstreamsarecomplementaryinconstructingacompleterepresentationofthestimulibeingobserved
1Weregardthismorphologicalseparationunderlyingcentral/peripheralcorticalanatomyasausefulbiologicalmean-field
approximation(MFA).TherearemanyMFAsthatemergeinbiologicalself-organizationandthegeneralideabehindbiological
manifestationsofinference-and-learningthatleveragethemisthatthebiologicalsystemwillworkto“repair”thefalsehood(s)
inducedbysuchMFAs.Thus,aneuralsystem,liketheoneweproposeinthiswork,mustworktocompensateforthestatistical
independenceassumptionsbetweencentralandperipheralstructuresthusrequiringmechanismsforpassingsignalsbetween
thesespecializedregions.Thismotivatedour(later-described)message-passingschemethatlinksthesestructures.
2
Preprint
atanyinstant. Neuroscientificevidence,intheformofbrain-imagingstudies,furtherdemonstratesthatorderly
peripheralandcentralrepresentationsform/emergeinbothlow-levelretinotopicvisualareas,i.e.,V1toV4,aswell
inhigherareas/regionsthatcharacterizetheventraltemporalcortex[53,58,40,38,2]asaresultoftheinference
andlearning,evincedasvisualperceptionorrecognition(offaces,objects,orscenes). Wedrawinspirationfrom
thestructuralorganizationunderwritingvisualperception–thevisualprocessingaffordedbyfoveal,parafoveal,
andperipheralviewing–inconstructinganeuronalcircuitthat(loosely)emulatesthiscomputationalarchitecture.
Furthermore,wepresentapredictivecodingperspective[27,100]ontheaccompanyingneuronalcircuit’smessage
passingandplasticity–ourneuronalmodel’sinferenceandsynapticadjustmentsaredrivenbythepredictions
inducedacrossfoveal,parafoveal,andperipheralstreams/systems(inserviceofoptimizingfreeenergy[27]).
Inadditiontostructure, wedrawinspirationfrom
the oculomotor system that underwrites active vi-
sion[117,115,87,72]. Theensuingvisualpalpa-
tion (and implicit epistemic foraging) [41] can be
roughlybrokendownintofourkeymovements: sac-
cades,smoothpursuitmovements,andvergenceand
vestibulo-ocularmovements. Saccades[54,50,24]
arerapid,ballistic(jumpy/jerky)movementswhich
changetheeye’sfixationpoint,themovement/shift
ofwhichrangesfromsmaller(intaskssuchasread-
ing) to larger saccades (examining a scene). Sac-
cadesaregenerallymoreinvoluntary(unconscious)
Figure 1: Illustration of two consecutive observations
thanvoluntarilyandcan,fromamodelingperspec-
ofanimage. Shownisoneofthedigitsprocessedbythe
tive,appeartobemoreitinerantinnature. Smooth
MPCschemeoverthecourseoftwoconsecutivesaccade-
pursuit movement [98] entails slower movements
producedglimpses. Ontheleftisthefullsourceimagewith
thatfocusonkeepingamovingstimulusonthefovea
areddashedboxshowingtheapproximatesubspacesam-
andaremorevoluntaryinnature. Vergencemove-
pledbytheglimpse. Therightpanels,withintheexpanded
ment[88]workstowardaligningthefoveaofeach
dot-dashedrectangle,showhowthesampleddatawithinthe
eyewithtargetsatdifferentdistances(fromtheob-
dashedboxontheleftisconvertedintosixinputrepresen-
server)whereasvestibulo-ocularmovements[113]
tations,i.e.,fouroverlapping“foveapatches”,a“parafovea
servetostabilizetheeyesrelativetotheobserver’s
patch”,anda“peripheralpatch”.
niche(workingtocompensateforheadmovement,
preventingtheslippageofvisualstimuliontheretina’ssurfaceastheheadmoves).
Forthepurposesofthisstudy,wefocusonsaccadesasthedriverofourmodel’sinformationforaging,sincethe
saccadeisamongthemostcommoneyemovementsinhumans(duringwakinghours)[19,54]. Infutureresearch,
wewillextendourmodeltoincorporatecontextualcontrol[99]todrivevoluntarysaccadesandsmoothpursuit.
Usinginvoluntarysaccadesmeansthatourself-supervisedmodelsuseanapproximateofthequick,jumpysaccadic
movementsofbiologicaleyestoextractpartialinformation(“glimpses”)fromthevisualscene,e.g.,apixelimage.
Formally,wetreatanobservationattimet ,i.e.,o(t )(asinglestaticimageoraframesampledfromavideo;t
g g g
marksglobaltimeinmilliseconds),asasmalltemporaryenvironmentfromwhichourneuralmodelsextractafixed-
lengthtrajectoryofglimpsesproducedastheresultofrandomlygeneratedsaccades(or,infuturework,amotor-
(cid:110)(cid:0) (cid:1) (cid:0) (cid:1) (cid:0) (cid:1) (cid:0) (cid:1)(cid:111)
controlpolicy[93]),yieldingthesequenceS = g(0),a(0) , g(1),a(1) ,..., g(k),a(k) ,..., g(K),a(K)
whereg(k)isthek-thsaccade-driven“glimpse”ofthesensoryinput,a(k)∈[−1,1]2×1 isasaccadicactionor
x-ycoordinatevectorrecordingthechosencenterofthefixation-pointofglimpseg(k),andK isthemaximum
numberofstepstaken.
Each glimpse vector g(k) is made up of several groups (pixel patches) sampled from the observation o(t ).
g
Specifically: acombinationofC “foveal”views(8×8pixelpatches),F “parafoveal”views(16×16patches),
andP “peripheral”views(24×24patches). WechooseC = 4(fouroverlappingfovealviews,arrangedina
2×2grid),F =1(oneparafovealview),andP =1(oneperipheralview).2 Figure1illustratestheresultofa
two-step(K =2)saccadesequenceoveranimage(ofthedigitzero,extractedfromtheMNISTdatabase): thered
dot-dashedboxshowsthefourfovealandthesingleparafovealandperipheralpatchesusedtocreateg(k).
Toobtainthefinalglimpsevector,allfoveal,parafoveal,andperipheralviews(centeredaroundthesamecenter-
point)arefirstaveragepooledtoalwaysbetheshapeofS×S pixels,vectorized(i.e.,flattened),andconcatenated
2Intheappendix,wepresenttheresultsofpreliminaryexperimentationjustifyingthisparticulararrangementofstreams.
3
Preprint
toobtaing(k)∈R((C+F+P)∗(S∗S))×1. Thismeansthatthevectorg(k)producedbythek-thsaccadeis:
g(k)=(<g1(k),g2(k),...,gv(k),...,gV(k)>)T (1)
whereV =C+F +P,brackets<·>denotevectorconcatenation,and,specifically,indicesv =1,2,3,4would
correspondtoflattenedfovealviewsindexv =5wouldcorrespondtoaflattenedparafovealviewandindexv =6
wouldcorrespondtoaflattenedperipheralview. Seesupplementfortechnicaldetailsonconstructingg(k).
Theaboveprocessmeansthatanyg(k)isacollectionofsampledsub-spacesoftheobservationo(t ),represented
g
intermsofseveralhigher-resolution(smaller/close-up)viewsandseverallower-resolution(larger/zoomedout)
features. Although this scheme was designed for visual perception, a similar patch extraction process could
beconsideredforothersensorydomains,e.g.,rawaudiowaveformrepresentations,whererelevantanatomical
knowledge,e.g.,theear,spiralganglionneuronsinthecochlea,couldbeusedtomotivatethesamplingscheme.
2.2 DynamicPredictionofLatentSpaceCharacteristics
TodescribetheMPCcircuitmodel, westartwiththeobjectivethatitseekstooptimize. Ineffect, werequire
predictionstobemadewithrespecttoonly“parts”ofitsinternalrepresentations,i.e.,predictionsaremadein
portionsoflatentrepresentationspace. Todecidewhatmakespredictions(andwhatthetargetsofthesewillbe),we
treatthecircuitasanarchitectureoffoveal,parafoveal,andperipheralstreamswhereeachstreamisspecializedto
receiveandencodeonlyonefoveal,parafoveal,orperipheralinput. Crucially,thisarchitectureofstreams,further
inspiredbythemulti/dual-streamshypothesis[65,36]3,mustlearntopredicttheactivitydynamicsofoneanother;
thismeansthateachstreamiscontinuallyguessingwhattheotherstreamsareencoding(andeachmustadjustits
ownactivitiesbasedonhowwrongitsguessesare). Thisguessinggameresultsinalateral,cross-streamprediction
scheme,ofwhichtherearemanyvariationsthatcouldbestudied(onlyfourareconsideredinthiswork). Thistype
ofpredictionschemeenablesneuronalcircuitstopredictthestatisticalpropertiesofalatentspacewithoutmaking
“downward”(decoder-oriented)predictionsofrawsensoryinput. Fromthisperspective,asuccessfularchitectureof
streamswouldbeonethatseeksconsistencyorcoherenceamongdistributedrepresentations.
Within an MPC architecture, each individual stream, arranged in a heterarchical or hierarchical structure, fol-
lows a variational free energy (VFE) [25, 26, 27] gradient flow that is driven by at least one other stream.
In this work, we take this to mean that one stream, driven by a particular view of the sensory stimulus (at
one scale/resolution, e.g., a foveal view), seeks to predict the activity values of another stream that is driven
by a different yet complementary view of the same stimulus (e.g., another view but possibly at a different
scale/resolution,e.g.,aperipheralview). BasedonthesensoryviewsproducedbythesaccadesinSection2.1,
theMPCarchitecturewillconsistofseveral“foveal”neuronalstreams,“parafoveal”streams,and“peripheral”
streamsthatseektopredictoneanother,resultinginamessagepassingschemecombiningintra-streammessage
passing (internally-communicated mismatch signals) and inter-stream message passing (mismatches between
streams). ForageneralarchitecturemadeofV = C +F +P streams(allareassumedtohavethesamenum-
berofLlayersandℓ = 0indexesthesensoryinputlayer),withv-thstreamcomposedofsynapticparameters
Θv ={Wℓ,v,Σℓ,v,Aℓ,v,1,Rℓ,v,1,Σℓ,v,1,...,Aℓ,v,V,Rℓ,v,V,Σℓ,v,V}L ,theresultingfreeenergyfunctionalfor
C C ℓ=1
thev-thstream—whichtriestopredictthelatentrepresentationsofanyotherstream(q ̸=v)aswellaspossibly
itself(v =q)—isgivenby:
L L
F (Θv)= (cid:88)(cid:88) N (cid:16) zℓ,q(t);µℓ,v,q,Σℓ,v,q (cid:17) + (cid:88) N (cid:0) zℓ,v(t);µℓ,v,Σℓ,v(cid:1) + Ω (cid:16) Θv (cid:17) (2)
v C C
ℓ=1 q ℓ=1 (cid:124) (cid:123)(cid:122) (cid:125)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) Synapticprior
Cross-RepresentationTerm ResidualEnergy
L
= (cid:88)(cid:88) N (cid:16) zℓ,q(t);µ (cid:0) zℓ,v(t),Rℓ,v,q,Aℓ,v,q(cid:1) ,Σℓ,v,q (cid:17)
C C
ℓ=1 q
L
+ (cid:88) N (cid:16) zℓ,v(t);µ (cid:0) zℓ−1,v(t);Wℓ,v(cid:1) ,Σℓ,v (cid:17) + (cid:88) N (cid:16) Θv[p] ;0,λ (cid:17)
ij w
ℓ=1 p,i,j
3Notethatthetwo-streamshypothesisspecificallyreferstospecializedcircuitryrelatedto“what”(ventral)and“where”(dor-
sal)pathways.Althoughourarchitecturedoesnotspecificallyimplementthedorsalandventralpathwaysinaneuroanatomically
faithful manner, it does embody the spirit of the what-where distinction and implicit factorisation or mean-field approxi-
mation. Specifically,ourmodel’sfovealstreamsacquirefine-grainedinformation(high-resolutionstroke/arccomponents)
whereastheparafovealandperipheralstreamsacquirecoarse-grainedinformation(low-resolution,object/partchunks)within
whichthefiner-grainedinformationissituated,i.e.,thefovealvisualprimitivesindicatewhatisbeingdetectedwhereasthe
parafoveal/peripheralstreamsindicatewheretheprimitivescanbefoundinthecontextofthe“biggerpicture”.
4
Preprint
(a)Flowofpredictions(solidbluearrows). (b)Messagepassing(dashedblackarcs)flow.
Figure 2: Illustration of the message passing in MPC. For generative predictive coding (GPC) and meta-
representationalpredictivecoding(MPC),depictedis: (a)theflow/directionalpatternofpredictionsmade(solid
blue arrows, which indicate neuronal populations that produce a prediction) in GPC versus MPC, and (b) the
flow/directionofmessagepassing(dashedblackarcs, whichindicatefeedbackpathwaysthatcarryprediction
errors)thatresultfromGPCversusMPCpredictionpatterns(insub-figurea). Solidgrayboxesindicateneuronal
populationsencodinglatentstates,whilegreendiamondsindicatepopulationsoferrorneurons. BothtypesofPC
representthesamenumberoflatentstates;theMPCshownisanarchitectureoftwostreamswherestream“A”is
shownprocessingfovealsensoryinformationandstream”B”processesperipheralsensoryinformation.
wherethethreetermscanbeunderstoodasfollows. Thecross-representationtermdictatesthat,attimet,any
non-sensorylayerℓ>0withactivityzℓ,v(t)inthev-thstreampredictstheactivityvalueszℓ,qofthecorresponding
q-thtargetstream–thepredictionconnectionsfromstreamv’slayerℓconveythemeanµℓ,v,q andcovariance
C
Σℓ,v,q ofthatlayer’spredictionofzℓ,q. Theresidualenergytermcapturesthefactthateachindividualstreamis
C
hierarchicallystructured,whereeverylayerℓofneuronalunitsattempttominimizethepredictionerrorbetweenits
activityandthepredictionofthisactivitybylayerℓ+1. Thesynapticpriortermissynapticdecayor,inother
words,azero-meanGaussianprior(withstandarddeviationλ )placedoverthev-thstream’splasticsynapses
w
representedbytheparametersΘv.4 Finally,fortheentireMPCarchitecture,the“ensemblefreeenergy”wouldbe
thecombinationofalloftheindividualstream’sVFEs: F(Θ)= (cid:80)V F (Θv).
v=1 v
Neuronalarchitectureanddynamics. Wenextprovideamechanisticdescription(seeFigure2foradepiction)
oftheV streams(v ∈{1,2,...,v,...,V})thatcomposeanMPCarchitecture,whichoptimizetheVFEF. Each
layerofthev-thstreamencodesexpectations(meanvalues)thatareparameterizedasneuronal(population)activity:
µℓ,v =µ (cid:0) zℓ−1,v(t);Wℓ,v(cid:1) =Wℓ,v·ϕℓ−1(cid:0) zℓ−1,v(t) (cid:1) (3)
whereϕℓ−1()denotestheelement-wisenonlinearityappliedtotheℓ−11-thlayer’sstatevalueszℓ−1,v(t).5 Wℓ,v
isamatrixthatcontainsthe(intra-stream)predictivesynapticefficaciesforthev-thstream. Notethatthebottom
(sensory)layerℓ=0ofanMPCstreamhasnononlinearity,i.e.,ϕ0(z0,v)=z0,v (theidentity),andisclampedto
therelevantportionofthesensoryinputglimpse,i.e.,thismeansthatz0,v(t)=gv(k),wherethev-thstreamis
providedwiththev-thviewoftheglimpsevectorg(k). Wefurthermoresettheintra-streamcovarianceparameters
tobescaledidentitymatricesΣℓ,v =σIℓ,v (whereσ >0),whichsimplifiesVFEoptimization.6
4Θvisatuplecontainingallofsynapticefficacymatricesforthev-thMPCstream;pretrievesthep-thsynapticparameter
matrixfromΘv,whereasiandjindexaparticularsynapsewithinthep-thmatrix,i.e.,Θv[p] returnsascalarvalue.
ij
5Neurobiologically,inthiswork,werefertovaluesaspre-andpost-synapticdependingontheirrelationshiptothefollowing
linearalgebraictransformation:a=W·b;acontainsthepost-synapticvalues,bcontainsthepre-synapticvalues,andW
containsthesynapticefficaciesthemselves.
6Weremarkthatincorporatingdynamicsinherenttoneuronalimplementationsofprecision-weighting,e.g.,suchasthe
precisionimplementationin[109],wouldbeusefulformorecomplex(modeling)tasks.
5
Preprint
Inorderforthev-thstreamtomakepredictionsoftheq-thstream,eachlayerℓ>0ofneuronsisfurtherequipped
withlateralsynapticconnections. Thismeansthatthecross-representationmeanµℓ,v,q emittedbythev-thstream
C
isparameterizedasfollows:
µℓ,v,q =µ (cid:0) zℓ,v(t);Rℓ,v,q,Aℓ,v,q(cid:1) =Rℓ,v,q·ϕℓ (cid:16) zℓ,v(t) (cid:17) +Aℓ,v,q·a(t) (4)
C C
where Rℓ,v,q contains the cross-stream prediction synapses (emitting from stream v to stream q) and Aℓ,v,q
containstheactionconditional,afferentsynapses. a(t)∈[−1,1]2istheactiontakenbytheMPCmodelattime
t,specificallyatwo-dimensionalvectorencodingthechosencoordinates(positionalcoordinatesofthesensory
inputrelativetotheMPCscheme,asdescribedinSection2.1andthesupplement). Furthermore,foradditional
simplicity,wesetinter-streamcovariancestobescaledidentitymatrices,i.e.,Σℓ,v =σIℓ,v whereσ >0. Inspired
C
by[75]—whichdemonstratedthatlateralcompetitionisusefulforlearninggenerativemodels—theactivation
functionϕ()thatwechoseinducesafastformoflateralcompetition(withoutrequiringphysicallateralsynapses)
intheinternallayers. Specifically,wechoseϕ()topromotehighlevelsofsparsitywithineachstream,similarin
spirittothepart-wholespikingmodelproposedin[34];givenneuronalactivitieszℓ,v asitsargument,theactivation
ϕ(zℓ,v)canbewrittenoutasfollows:
(cid:40)
zℓ,v zℓ,v ∈{N largestelementsofzℓ,v}
NWTA(zℓ,v)= j j w (5)
0 otherwise
whichistheN-winners-take-all(NWTA)function[1]whereonlythe N neuronswithhighestvalueswithin
w
thelayer/groupzℓ,v emitanon-zerofiringrate(therestthatlosethiscross-neuroncompetitionwillemitazero).
Althoughthiswinner-take-allfunctionworkedwellfortheexperimentscarriedoutinthisstudy,futureworkwould
benefitbyconsideringextensions,suchasincorporatingaduty-cycle[1]topromotecooperationandthesharingof
firingresponsibilitiesamongneuronswithinagroup.
Crucially,embeddedwithineachlayerℓ>0ofanMPCstreamisasetofpredictionerrorneuronsthatcomputethe
mismatchsignalsreportinghowfaroffeachlayer’spredictionsarefromtheircorrespondingtargets. Therearetwo
kindsoferrorneurons,whichresultfromthefreeenergyfunctionalofEquation2,foreverylayer–intra-stream
errorunitseℓ,v andinter-streamerrorunitseℓ,v,q. Thesetwokindsoferrorneuronscanbewrittendownas:
C
eℓ,v =zℓ,v(t)−µℓ,v, //Intra-streammismatchsignals (6)
eℓ,v,q =zℓ,q(t)−µℓ,v,q //Inter-streammismatchsignals (7)
C C
wherewenoticethatmismatchsignalswillbeproducedasaresultofeitherlocalpredictionsofintra-streamactivity
(withinv),i.e.,µℓ,v attemptingtoguesszℓ,v(t),orinter-streamactivitybetweenvandq,i.e.,µℓ,v,q attemptingto
C
guesszℓ,q(t). DrivenbytheerrorneuronsofEquations6and7,thedynamicsoftheneuronalcellswithineach
layerofanMPCstreamfollowthegradientflowoffreeenergy;thisflowispresentedbythefollowing(vectorized)
ordinarydifferentialequation(ODE):
∂F(Θ) =τ ∂zℓ,v(t) =−eℓ,v+ (cid:16) Eℓ,v·eℓ+1,v+Eℓ,v,q·eℓ,v,q (cid:17) ⊙ ∂ϕ (cid:0) zℓ,v(t) (cid:1) (8)
∂zℓ(t) z ∂t W R C ∂zℓ,v(t)
whereτ istheneuralcellmembranetimeconstant(inmilliseconds; ms)and
∂ϕ(zℓ,v)
isthepartialderivative
z ∂zℓ,v
of the activation function with respect to the neural state activities at t. Eℓ,v contains the v-th stream’s intra-
W
streammessage-passingsynapseswhereasEℓ,v,q containitsinter-streammessage-passingsynapses. Onemore
R
simplification—thatcouldbeappliedtoanyMPCstream—istosetitsfeedbackconnectionmatricestoEℓ,v =
W
(Wℓ,v)T andEℓ,v,q =(Rℓ,v,q)T;notethatthesecan,alternatively,belearnedwithHebbianrules,asin[94,75].
R
Synapticplasticity. LearninginanMPCstreamfollowsthegradientflowofEquation2andsynapticconnection
strengthsareupdatedaccordingtoHebbianplasticityrules. Theintra-streamsynapsesWℓ,v, theinter-stream
synapsesRℓ,v,q,andtheaction-conditionalafferentsynapsesAℓ,v,q ofanyMPCstreamareupdatedasfollows:
τ
∂Wℓ,v
=−λ Wℓ,v+eℓ,v· (cid:0) ϕ(zℓ−1,v) (cid:1)T , (9)
w ∂t w
τ
∂Rℓ,v,q
=−λ Rℓ,v,q+eℓ,v,q· (cid:0) ϕ(zℓ,v) (cid:1)T , (10)
w ∂t w C
τ
∂Aℓ,v,q
=−λ Aℓ,v,q+eℓ,v,q· (cid:0) aℓ,v(cid:1)T (11)
w ∂t w C
whereτ isasynapticplasticitytimeconstant(inms)andλ isasynapticdecaymodulationcoefficient. The
w w
inferenceandlearningstepsinanMPCschemearescheduledaccordingtoanexpectation-maximization[17](EM)
likeprocess: 1)inference(E-step)iscarriedoutinanMPCstreambyapplyingEquation8usingEulerintegration,
6
Preprint
a
a t+1
t
z
t+2 Peripheral Foveal/Parafoveal
z Representation Stream Representation Stream
t+2
z z z 3 ,1 (t) z 3 ,2 (t)
t t+1
Cross-stream Neural states driven by
predictive synapses glimpse decisions (and
possibly prior states)
Figure3: Graphicaldepictionofasimpledualstream,MPCarchitecture. Ameta-representationalpredictive
coding(MPC)architectureworksbyprocessinginputsviatwoormorefeaturesofthesensoryinput,generallyat
differentresolutionswhichmimicthecoarseness(acuity)ofthespatialfeaturesextractedbythefoveal/parafoveal
and the peripheral streams of the human eye. In this image, we depict a two stream architecture, where one
MPCstreamproducesafoveal/centralrepresentationz3,1(t)(initsthirdlayer)ofitsinputattimetwhileanother
circuitproducesaperipheralrepresentationz3,2(t)oftheinput(alsoatt). ThefovealMPCstreamattemptsto
predicttheactivitiesoftheperipheralMPCcircuitandviceversa(forthek-thglimpseatanimage). Noticethat
allMPCstreamsareconditionedbytheactions,i.e.,normalizedx-ycoordinatesofthefixationpointofallof
thefoveal/parafoveal/peripheralviews,takenbyasaccadeoverthesensoryinputaswellaspossiblytheirprior
expectation(attimet−1). I
z
n1thiswork,afixedK-lengt
z
hsaccadesequenceisproducedbyrandomlyjumping
acrossthesensoryspace,resulttinginaperceptualinputsamplingpolicy. Greendiamondsindicateerrorneuron
populations,light-grayororangecircleswithslightlydarkercolorswithindenotestatecellpopulations,lightgray
arrowsrepresentsynapticconnections,dashedblackcirculararcsdepictrecurrentsynapses,andbluedash-dotted
arcsdenotelateralcross-circuitpredictionsynapses(notshown,toimprovevisualclarity,arefeedbacksynapses).
foralllayersℓ>0,overastimuluswindowlengthE =T/∆t7;2)thensynapticlearning(M-step)isperformed
byapplying,viaEulerintegration,Equations9,10,and11foralllayersℓ>0once. AftertheM-stepisperformed,
updatedsynapticmatricesareconstrainedtohaveunitcolumnEuclideannorms.
InFigure3,weillustratewhatasimpleMPCarchitecturewithV =2twostreams(eachwithL=4layers)would
looklike;inthisexample,asinglefovealstreampredictstheactivities(ateachlayer)ofasingleparafovealstream
andviceversa;hencethe’meta’aspectoftheensuingrepresentations. Noticethat,ourfreeenergyframework
complementsself-supervisedrepresentationlearning[21]schemes,suchasthosethatworktoavoid(dimensional)
collapse8 includinginformation-maximization[22,116,5]andregularizationapproaches[3,18]. Specifically,
MPC espouses a meta-representational narrative for self-supervised learning; representations of data features
shouldbeabletopredictoneanotherinaninternallyconsistentfashion. Insomesense,theMPCarchitecture
speakstothenotionthatcomplementaryviewsofinputpatternsshouldyieldembeddingsthatare’close’toone
another,asinsomeformsofmaskedprediction[12,85]. However,insteadoffocusingoninputdata,MPCoperates
7T isthelengthofstimuluspresentationtimeforexamininganinputviewz0,v(t)=gv(k)and∆tistheintegrationtime
constant;bothareinmilliseconds(ms).
8Dimensionalcollapsereferstothecasewherethetwobranchesofadual-embeddingarchitecture(suchasaSiameseneural
network[8])degeneratetoproducingidenticalandconstantoutputvectors.Thisisadegenerateoutcomeindicatingthatthe
modelendsuplearningtosimplyignoretheinputdata.
7
Preprint
(a)GPC-fov. (b)MPC.
Figure4: Structuresofgenerativeandmeta-representationalpredictivecodingschemes. Depictedaretwo
proposedvariantsofpredictivecoding–a“field-of-view”formofgenerativepredictivecoding(GPC-fov)and
meta-representationalpredictivecoding(MPC)–thatprocessthesamevisualscene. Inthisgraphicalexample,two
portionsofvisualinputataparticularpointintimeareextracted(yieldingadualview,possiblycontainingfoveal,
parafoveal,orperipheralpatchpixelinformation)byaneyemovementprocess(representedbythepalegreen
fatarrows),suchastheinvoluntarysaccadesdescribedinSection2.1. Specifically,weshow: (a)theproposed
GPC-fov(withtwoneuralcolumns)processingadualviewofthesensoryinput,i.e.,avariantofGPCthatusesthe
sameinformationasourMPCmodels;and(b)theproposedMPC(withtwoneuralcolumnsorstreams)processing
adualviewofthesensoryinput. Notethatsolid(black)arrowswithopencirclesdenoteinhibitory(predictive)
synapses,dashed(black)arrowswithsolidsquaresdenoteapopulationofexcitatory(message-passing)synapses,
purpleboxesindicateapopulationofneuronsencodinglatentstatesandgreendiamondsdenoteagroupoferror
neuronsforaspecificlayer. Inthezoomed-ininsetforsub-Figure4b,weshowtheincomingandoutgoingwired
connectionstoasingleneuronwithinapopulation.
exclusivelyinlatentspace,whereparallelstreamsencodinginputeffectivelylearntoresonatewithoneanotheras
aresultofcontinuouspredictionandmessagepassing.
Generativepredictivecoding. TocontrasttheproposedMPCframeworkwithstandardPC[92,75,100](which
wewillrefertoasgenerativePC9;GPC),weprovideabriefexplicationofGPC’srequisitefreeenergyfunctional
anditsresultantdynamics. Specifically,whenprocessingaclampedsensoryinputz0(t)=o(t ),aGPCcircuit
g
works—underadynamicexpectation-maximizationscheme—tooptimizethefollowingVFE:
L−1
(cid:88) (cid:16) (cid:17) (cid:88)
F(Θ)= N zℓ(t);µℓ,Σℓ + N(Θ[p] ;0,λ ) (12)
ij w
ℓ=0 p,i,j
where,dependingonthedistributionthatoneassumesoversensoryinputs,onecanmodifytheabovefunctionalto
useotherlikelihoodsatspecificlayers,e.g.,amultivariateBernoullidistributionforℓ = 0aswasdonein[75].
NotethattheaboveVFEhasbeenexpressedsuchthatitalsoincludesthesamesynapticpriorusedintheMPC
circuitinEquation2. Givenitsgoaltolearnhowtosynthesizesensoryinputs,aGPCschemeusuallyfocuseson
processingandpredictingtheentiresensoryinputo(t ). MuchasintheMPCcircuit,theexpectationµℓateach
g
layerisproducedviaalineartransformation,i.e.,µℓ(t)=Wℓ·ϕ(zℓ+1(t)). Thecovarianceparameters,asinthe
MPCmodel,aresimplifiedtothescaledidentitymatrixΣℓ =σIℓ(σ >0).
IntheaboveVFE(Equation12)andstructureforGPC,errorneuronscanberepresentedasasubtractivedifference,
i.e.,eℓ =zℓ(t)−µℓ(t),andmessagepassingemergesasaconsequenceofusingfeedbacksynapticconnectionsin
tandemwiththeseerrorunits. Specifically,thefreeenergygradientflow—thattheneuronalunitsadhereto—isthe
followingODE:
∂F(Θ) ∂zℓ(t) (cid:16) (cid:17) ∂ϕ (cid:0) zℓ(t) (cid:1)
=τ =−eℓ+ Eℓ·eℓ−1 ⊙ (13)
∂zℓ(t) z ∂t ∂zℓ(t)
whereEℓ =(Wℓ)T . NotethatEquation13(andtheVFEofEquation12)canbefurthermodifiedtoincorporate
additionalconstraintssuchaskurtoticpriorsthatencouragesparsityinthelatentstates(weuseaLaplacianpriorin
9Eventhoughallfreeenergy-centricmodelslearnprobabilisticgenerativemodels,weemphasizetheword“generative”to
emphasizethedecoder-centricnatureofmoststandardPCmodels.
8
Preprint
(a)MPCpredictionpattern‘-st2’. (b)MPCpredictionpattern‘-st3’. (c)MPCpredictionpattern‘-st4’.
Figure5: VisualizationofdifferentMPCcross-circuitpredictionpatternsexperimentedwith. Aboveare
shownthreepossiblepredictionschemesforhowtheindividualstreamsinteractwithoneanother;dashedblue
arrowsindicateapredictiondirection(bluearrowheadendsonpredictiontarget)fromwhicherrormessagesflow
backwards. Notethateach“Fovea”,“Parafovea”,and“Peripheral”boxcorrespondstoaparticularMPCstream
(fromatop-downview).
theGPCmodelsstudiedinSection3,torecoverthemodelingsetupsof[92]and[73]). AftersolvingEquation13
forT/∆tsteps(examininganobservationz0 =o(t )),Hebbianadjustmentsmaybemadetothesynapticweight
g
matricesasfollows:
τ
∂Wℓ
=−λ Wℓ+eℓ· (cid:0) zℓ−1(cid:1)T (14)
w ∂t w
wherethefirstterm(right-handsideoftheequality)constitutesthecontrollableweightdecaythatemergesfrom
thesynapticpriorintroducedinEquation12;thisrecoverstheGaussianprioroversynapsesin[92]).
Notethat,inthiswork,wefurthermodifiedtheaboveGPCmodel—whichwenamedthe“GPC-fov”(field-of-view
GPC)model—to(iteratively)processglimpsesasinMPC.Inordertodoso,wechangedtheinputthattheGPC
modelpredictstobez0 = g(k)andconvertedtheGPCmodel’sbottommatrixW1 (ormatricesW1,W2,...
up to but not including WL) closest to the input, to a block matrix with a number of blocks set equal to the
numberoffoveal/parafoveal/peripheralstreams. Thismeansthat,aftereverysynapticupdate(Equation14),we
wouldconstrainthisblockstructurethroughapplicationofabinarymask. ThisvariationofGPC,the“GPC-fov”
model,issimilartothefullpatch-levelmodelof[92]but,inthiswork,isanewvariantthatlearnstogenerate
dynamically-extractedpatchesofdifferentresolutions. InFigure4,wedepictthestructureofvariouskindsof
predictivecodingmodelswestudyinthiswork,includingtheclassicalGPCaswellastheGPC-fovandMPC(both
shown,forsimplicity,justprocessingtwostreamsoftheinput).
3 Experiments
Simulationsetup. TodemonstratetheefficacyofourMPCframework,wesimulatepredictivecodingoftwo
datasetsofincreasingcomplexity: 1)theMNISTdigitrecognitiondatabase[52],and2)theKuzushiji-MNIST
(K-MNIST)characterrecognitiondatabase[14]. MNISTandK-MNISTcontaingray-scale28×28imagesfrom
10categories. MNISTcontainsimagesofhandwrittendigitswhileKuzushiji-MNISTisachallengingdrop-in
replacementforMNIST,containingimagesdepictinghand-drawnJapaneseKanjicharacters;inK-MNIST,each
class(outof10classes)correspondstothecharacter’smodernhiraganacounterpart. Theonlypre-processing
appliedtotheimagesinthesedatasetswastonormalizethepixelintensitiestolieintherangeof[0,1];notethat,
wheneveranimagepatchisextractedforapatch-levelmodels(GPC-fovandMPCcircuits),weonlycenterit(i.e.,
subtractthemeanvalueofpatchfromthepatchgroupofpixels). Fortherelevantmodels(GPC-fovandanyMPC
circuit),weprocesseachsamplepatternaccordingtothesaccadeprocessschemedescribedinsub-Section2.1.
Simulatedmodelsandbaselines. Wecompareseveralcircuitmodels(withL=3layers)inourexperimental
simulations: 1)generativepredictivecoding(GPC)circuitsthatprocesstheentireinputimage(themoretraditional
PC model), including a full-image version of the classical model in [92], a variant of this model using ReLU
activationsGPC-relu),andavariantofthisGPCmodelusinganNWTAactivationwiththenumberofwinners
scaledtomatchthetotalnumberofwinnersacrossallneuralcolumnsintheGPC-fovandMPCmodels(GPC-nwta);
2)theGPC-fovdescribedearlier,whichprocessesthesamesensoryinformationasourMPCarchitecture,and;3)
variantsofourproposedMPCcircuit. Specifically,westudyfourvariantsofourMPCmodel(V =6views),each
withadifferenttopologicalstructurethatdictateshowthepredictionsaremadeandhowthemessagepassingis
9
Preprint
MNIST K-MNIST
ACC(%) Dec-MSE(nats) ACC(%) Dec-MSE(nats)
BP-FNN 98.04±0.03 – 90.57±0.11 –
JEPA[33] 95.40±0.23 – 79.65±0.87 –
GPC[92,75] 91.97±0.03 1.230±1.088 71.09±0.98 4.8005±1.099
GPC-relu 93.78±0.05 3.409±0.982 78.83±0.32 12.003±1.332
GPC-nwta 95.60±0.08 5.908±1.002 81.99±0.03 17.288±1.411
GPC-fov 96.83±0.03 7.105±0.113 79.95±0.09 22.679±0.617
MPC-st1 97.50±0.15 6.200±0.987 82.22±0.16 19.988±0.050
MPC-st2 97.81±0.02 5.761±1.222 85.68±0.18 20.867±0.154
MPC-st3 97.74±0.04 3.937±0.189 85.05±0.13 20.618±0.021
MPC-st4 97.80±0.05 4.093±0.059 85.48±0.02 20.706±0.053
Table1: Generalizationofdifferentpredictivecodingcircuits. Measurementsofgeneralizationaccuracy(ACC,
intermsof%)andreconstructiondecodermeansquarederror(Dec-MSE,intermsofnats)ofdifferenttypes
ofpredictivecoding(PC)schemes(mean±standarddeviationreportedfor10trials). BP-FFNisasupervised
referencemodel,i.e.,abackprop-trainedsparsefeedforwardneuralnetwork(withhiddenReLUactivations)that
directlylearnedamappingbetweeninputsandlabels. GPCisagenerativePCnetwork,GPC-fovisgenerativePC
reformulatedtoworkwithoursaccadesensoryprocessingscheme,andMPCisourproposedrepresentationalPC
model(MPC).Adashedsuffixtagreferstoaparticularstyleofcross-circuitprediction: ‘-st1’referstoallunits
predicteachotherwhile‘-st2’,‘-st3’,and‘-st4’refertovariantsoflocal,cross-streampredictionschemes(see
Figure5forvisualizationofthestructureofthelastthreepredictionschemes). JEPAistheencoder-onlybackprop
modelproposedin[33]adaptedtoourstudy(tofollowthesametrainingprocessaswellashavethesamenumber
ofparameterstoensurefaircomparison).
drivenacrossstreams. Whileweremarkthatmanyothersarepossible,thefourcross-circuitpredictionpatterns
thatwestudied(threeofwhichareshownin5)included:
• ‘-s1’:thisisthesimplest—anall-to-allstructure(everycolumnpredictsallothercolumnsandthemselves);
• ‘-s2’: asinglechainoflocalone-to-onefovealcolumnpredictions(andallparafoveal/peripheralstreams
predictallfovealstreamsaswellasthemselves),asinFigure5a;
• ‘-s3’: alocaltwo-neighbor(neighboraboveorbelowandneighbortotherightorleft)fovealcolumn
predictionscheme(andallparafoveal/peripheralstreamspredictallfovealstreamsaswellasthemselves),
asinFigure5b;
• ‘-s4’: allfovealstreamspredictallfovealstreams(whereasallparafoveal/peripheralstreamspredictall
fovealstreamsandthemselves),asinFigure5c.
EventhoughtheGPCmodelsworkinanunsupervisedfashion,theyareall“decoder-centric”whereasallMPC
circuitsare“encoder-centric”. OurinterestistoseeifourMPCschemeoffersrepresentationsasusefulasthese
generativePCmodels, demonstratingthat wecaneffectively constructencoder-centricbiologicalmodelsthat
acquire useful distributed representations of sensory input data without having to predict raw, low-level data
features(e.g.,pixelvalues).
Wetrainallmodelsoneachdatabasefor5epochswithgradientascent(usingmini-batchesoflength100). The
learningrateofthegradientascentoptimizationofparameterswastunedforeachmodelusingthevalidationsubset
ofeachdatabase(wegenerallyfoundthesaccade-drivenmodelspreferredhigherrates,whilewhole-imagemodels
workedbetterwithlowerrates). ForanymodelthatusedtheNWTAactivation—theGPC-nwta,theGPC-fov,and
allMPCcircuits-wetuned—foreachdatabaseforeachmodel(usingdevelopmentdata)—thenumberofwinners
intherangeofN =[10,20](oftenfindingthatthevalueofN =15yieldedgoodresultsingeneral). Unless
w w
statedotherwise,allsaccade-drivenmodels,i.e.,GPC-fovandallMPCmodels,usedK =10saccades.
To assess each model’s efficacy, we train each under the same experimental conditions and data. Since every
modelisunsupervisedorself-supervised,wealloweachtoprocessthedataforamaximumnumberofepochsand
adaptparametersaccordingtotheirspecificdynamicsandplasticitymechanisms. Onceamodelhascompleted
itsunsupervised/self-supervisedphase,wefixitssynapticconnectionstrengths(disableitsplasticity)andthen
allowittoprocessthetrainingdata,validationdata,andtestdataonce,extractingitslatentrepresentationforeach
datasample. Ifamodeliterativelyprocessesoneinput,weconcatenatedthesub-representationsitproducesacross
theK-lengthsaccadetrajectory. Theresultingrepresentationsofdatasamplesarethenusedinthetwofollowing
down-streamanalyses:
10
Preprint
(a)t-SNEofMPCMNISTlatents. (b)t-SNEofMPCK-MNISTlatents.
Figure 6: Visualization of MPC-acquired latent activity codes. t-SNE plots of the latent space induced by
meta-representationalpredictivecoding(MPC).Ratecodesareshownfor: (A)MPConMNIST,and(B)MPC
K-MNIST.Note: t-SNEcoordinateunitsaredimensionlessandarethusdenotedas“tSNEunits”).
• A log-linear classifier is fit to the latent codes of the training set (with validation latent codes used
forhyperparameter-tuning)andthenevaluatedonthetest-setlatentcodes. Wereportthetest-seterror
measurementsinTable1andcompareperformanceagainstareferencebackprop-trainedMLP(BF-FNN).
• Asinglehidden-layerMLPdecoder(with1024linearrectifierneuronsinthehiddenlayer,trainedwith
gradientdescentandTikhonovregularization)wasretro-fittothetraining-setlatentcodesofourMPC
scheme(theMLPwasalsotunedusingvalidation-setlatentcodes). Thisdecoder’sreconstructionefficacy
was evaluated using test-set latent codes. We report mean squared error and compare the decoder’s
down-streamreconstructionagainstthenaturalreconstructionabilityofthefull-imageGPCcircuits.
3.1 ResultsandAnalysis
DownstreamusageofMPClatentcodes Asdescribedbefore,weexaminedtheutilityofthedistributedrepre-
sentationsacquiredbyourMPCmodelsinthecontextofdownstreamclassificationanddecoding/reconstruction.
TheempiricalresultsgatheredfromtheseexperimentsaresummarizedinTable1. Specifically, wereportthe
meanandstandarddeviation(over10uniquely-seededexperimentaltrials)ofthetest-setaccuracy(ACC;higher
isbetter)forthedownstreamclassificationprobeandthetest-setmeansquarederror(Dec-MSE;lowerisbet-
ter) for the downstream decoder/reconstruction probe for all models on both MNIST and K-MNIST. Observe
that,althoughalloftheself-supervisedmodels(gen-
erativeandencoder-centric)donotexceedtheperfor-
mance of the purely discriminative, fully-supervised
BP-FNN,ourproposedencoder-onlyMPCschemegets
quiteclose,withtheMPC-st4andMPC-st2modelspro-
ducinggeneralizationaccuraciesthatareonlylowerby
0.21-0.23percentagepoints.Intermsofreconstruction,
weobservethatourMPCschemesfacilitatetheeffec-
tivelearningofaseparatedecoder, yieldingdecoder
MSE (Dec-MSE) scores that are comparable to the
powerfulwhole-imagegenerativemodels(theGPCcir-
cuits),whichthemselvesaretrainedtopredictallofthe
pixelsoftheimages(whichareexpected,inmostcases,
toyieldthebestreconstructionerrorsduetobeingspe-
cializedforreconstruction). ThefactthattheMPCcir-
cuitsproducerepresentationsthatfacilitatedownstream Figure7: SampleEfficiencyontheMNISTDatabase.
decodersthatarewithinafewnatsofthespecialized Here, we plot test-set classification accuracy (10-trial
GPCmodelsispromising. Inessence,Table1shows meanvalues)ofourbestMPCagainstthereferenceBP-
thatMPCschemeslearn,inaself-supervisedfashion, FNN(MLP)asafunctionofthenumberofsamplesused
distributed representations that can prove useful for totraineachmodel. Note: x-axiswasplottedonaloga-
bothdownstreamclassificationorreconstruction. For rithmicscaletohelpvisualisethegeneralizationcurve.
reference,adecodermodeltrainedwithpurelyrandom
11
Preprint
(a)MPCMNISTreceptivefields.
(b)MPCK-MNISTreceptivefields.
Figure8: Bottom-layerreceptivefieldsacquiredbyanMPCscheme. Thefoveal,parafoveal,andperipheral
receptive fields of the bottom-most neuronal units closest to the sensory input (i.e., layer ℓ = 1) of a meta-
representationalpredictivecoding(MPC)model,trainedonMNISTpatterns. Shownarethereceptivefieldsfor
eachofthesixneuralstreamsthatmakeupanMPCencodercircuit.
encodings(weassigneduniquerandomvectorstodatapointsthatwerethesamedimensionastheconcatenatedset
ofMPC/GPC-fovrepresentations)yieldsanMSEof55.433nats.
InFigure7,weshowtheresultsofasmalltestweconductedtoexamineMPC’ssampleefficiencyonMNIST.
Specifically,were-fitMPC-st4andthereferenceBP-FNNondifferently-sizedtrainingdatasets—datasetsizes10
included{100,200,500,1000,5000,10000,25000,50000}—andre-evaluatedtheirgeneralizationaccuracyon
thefulltest-set(meanvaluesover10trialsareplotted). Noticethatasthenumberofavailablesamplesdeclines
towards100,thesupervisedBP-FNN’sgeneralizationdegradessignificantly(asexpectedforalearningscheme
thatrequireslabels)whereasMPC’sdownstreamperformanceremainsrelativelyconsistent(onlydecliningby
aboutatmost2percentagepoints). WehypothesizethatMPC’ssampleefficiencylikelycomesfromthefactthatit
treatseachdatapointasasortof“minisensorium”viaitssaccade-drivensamplingprocess. ThismeansMPC
modelsworktoextractreusablesimplerfeatures(suchasstrokes/arcsandobjectchunks)thatappeartomore
readily/easilygeneralize(inMPC,thelowerlayerscapturetheseatomicfeatureswhereastheupperlayersproduce
weightedcombinationsoflower-levelatomicfeatures).
Qualitatively,weexaminedthereceptivefieldsacquiredbytheneuronalunitsofoneofourbest-performingMPC
circuits,theMPC-st4,byvisualizingthemintermsof2Dimages;theresultsofthisexamination/visualization
areshowninFigure8. Notehowthefovealreceptivefields(thefirstfoursquaresof12×12fields)lookvery
similartothoseacquiredbyclassicalGPCmodels; suchastheoneof[92], representingavarietyofdifferent
possiblestrokes. Thesestrokesareaggregatedbyhigher-levellayersoftheschemeasitassembleshigher-level
representationsofsensoryinput. Theparafovealandperipheralreceptivefields,i.e.,thelasttwo12×12squares
ofreceptivefieldstotheright,appeartoencodeeitherlarger,morezoomed-outversionsofstrokesorpossibly
low-resolutionobjects/chunksofobjects(digitsorKanjicharacters).
Beyondexaminingreceptivefields,wevisualizedtherelationshipbetweenthelatentcodesthatatrainedMPC
circuit(MPC-st4)producedonbothMNISTandK-MNIST’stest-sets. Theresultsofthisqualitativeanalysisused
t-SNE[110]tovisualizethelatentcodesformedwithrespecttothetest-setsamplesandispresentedinFigure6.
Noticethat,despiteneverhavingaccesstothelabelsnorusinganykindofsupervisorysignal,theMPCcodesfor
MNISTtendtoclusterratherwell(albeitabitnoisilyinsomespots),yieldingtendistinctmajorrepresentational
groupingswitheachcorrespondingtoadifferentdigit(labelswereonlyusedtocolorthet-SNEmappedlatent
codepointsinthet-SNEfigure). ForK-MNIST,weseethatMPClatentcodesformgroupingsaswellbutthere
manymoregroups/clustersor“sub-groupings”thanthetenidentifiedKanjicharactercategories;thisbehavior
makessense,giventhattheKanjicharactersaremorecomplexandexhibitahigherdegreeofvarietythanthe
handwrittendigitsintheMNISTdatabase.
10Samplesselectedfromtheoriginallytrainingdatabasewererandomlysampledwithoutreplacement.
12
Preprint
AssemblingrepresentationsthroughMPC AninterestingfeatureoftheMPCmodelisthatitrepresentsstimuli
byencodingportionsofinputacrosssaccades.Thismeansatleastseveralglimpsesoftheinputareneededtoobtain
adecent“biggerpicture”encoding. ToinvestigatehowthenumberofglimpsesaffectsanMPCscheme’sabilityto
formusefulrepresentations,wemeasuretheperformanceofthemodel—intermsofclassificationaccuracy—in
responsetothenumberofsaccadesallowed. InFigure9,weexaminethegeneralizationofMPC(asmeasured
intermsofdownstream,test-setclassificationaccuracy)asafunctionofthenumberofglimpsesitisallowedto
take(uptoamaximumof12glimpses)whenprocessingsensoryinput. Empirically,wenoticethatgeneralization
improvesasmoreglimpsesaretaken,uptoaboutalittleabove97.8%onaverage(with10glimpses). Thereis,
however,alawofdiminishingreturnseffectbeyond8-10glimpses. Thissaturationmightbeduetothefactthat
enoughof thesensoryinputwasexaminedby theMPCcircuitin ordertocrafta usefulglobalrepresentation
and further glimpses added no further information. It is likely that, for more complex sensory input (natural
images),moreglimpsesmightberequiredtoformeffectiveglobalencodings. Thiseffectmotivatesfuturework
todevelopacomplementarymotorcircuittodrivetheselectionoftheMPCsamplingoftheinput(withabias
towardspoliciesthatentailtheminimumnumberofsaccadesandthatconsiderabetterbalanceofrepresentational
efficiency-efficacy). Thiswouldbringourmodelfromanaction-conditionedonetoaself-drivenmodel,muchin
thespiritofactiveperception[66,106]andselectionthroughtheframeworkofplanning-as-inference[7,31,30].
GivenMPC’siterativenature,whensamplingsensory
input over the course of several saccades, in Figure
10, we asked what an MPC scheme is doing as it
processes a sensory stimulus throughout the course
ofnineglimpses. Specifically,weexaminedtwodif-
ferent digit patterns, i.e., a seven (in the top of Fig-
ure 10) and a zero (in the bottom of Figure 10). In
addition to depicting the raw sensory glances pro-
duced by our sensory glimpsing scheme, we show
the topfour mostactivated receptivefields thateach
neuronal stream yields in response to the observa-
tion of a glimpse (at each time step). Notice that,
for the sensory glimpse produced by each saccade,
themosthighly-activatedfovealreceptivefieldscap-
Figure9: AnalysisofNumberofSaccadesandDown-
ture particular, essential characteristics of the exam-
streamMNISTAccuracy. Here,weplotourbestMPC
inedinput,e.g.,therotation/orientationofstroke/edge
andourGPC-fovmodels’performance(intermsofdown-
of the overall digit pattern, while the most highly-
stream test-set classification accuracy) as a function of
activated parafoveal/peripheral fields correspond to
thenumberofinvoluntarysaccadesusedtoconstructtheir
either: 1) capturing broader feature shapes/profiles
globalrepresentationsofsensoryinputs.
(lower-resolution strokes and their orientations), or,
2)engaginginaformoftemplatematchingtothemostrelevantlow-resolutionobject“chunk”. Insomeinstances,
suchasforthefovealstreams,seeminglynon-relatedfeaturescanappearamongthemorehighly-activatedfields,
suchasastrokeoredgepiecethatjusthappenstofit“within”thestimulusareaofthegeneralfeature.
Limitations: AspromisingasourproposedMPCframeworkforSSLis, thereareseverallimitationswhich
affordavenuesforfutureresearchanddevelopment. Fromacomputationalneuroscienceperspective,whileour
MPCmodeldesignswerebiomimetic, leadingustoacomputationalarchitecturewithfoveal, parafoveal, and
peripheralstreams,MPCisstillalooseinspirationanddoesnotfaithfullymodelthebio-circuitrythatunderlievisual
hierarchiesandtheoculomotorsystem.FutureeffortthatmodifiestheMPCarchitecturetobetteremulatebiological
details(e.g.,craftingconstrainedlayeredstructuresthatdirectlyadheretoknownneuroanatomy,operatingwith
spikesasopposedtorate-codes,etc.) mayfurtherbenefitthegeneralizationabilityofmodelsconstructedwithin
ourframing. Furthermore,itcouldprovefruitfultocarryoutneurobiologicalstudiesthataskifacross-circuit-like
prediction/messagepassingschemelikethatofMPCaffordsausefulexplanationofempiricalneuronalresponses.
Fromamachineintelligencepoint-of-view,whilethisworkdemonstratesthatMPCcanextractrepresentationsthat
facilitatepromisingdownstreamperformance—demonstratingtheviabilityofourbiomimeticscheme—further
experimentalstudieswillbeneeded,e.g.,thosecarriedoutonmorecomplexdata;includingnaturalimagesand
video databases. These efforts may help determine what extensions/mechanisms might be required to ensure
generalizationacrossagreatervarietyof(visual)sensoria/niches. ItisnoteworthythatourMPCframeworkdoes
notrelyonlargebatches11orbatchstatistics/normalization[37,13]ornegativesamplesasmanyofthemoderndeep
learning[74,47,12]andneuro-mimeticschemes[44,43,78,81]do. ThismeansMPCmayofferaregularization-
11Weusedabatchsizegreaterthanonesolelytospeedupsimulation;MPCisinherentlyanonlinelearningframework.
13
Preprint
1 2 3
4 5 6
7 8 9
1 2 3
4 5 6
7 8 9
Figure10: AtrainedMPCschemeprocessingsensoryinputsthroughasaccadesequence. Shownisatrained
MPCschemeiterativelyprocessingasensorystimulus,e.g.,animageofadigitseven(topgroupoffourrows)ora
zero(bottomgroupoffourrows),throughaseriesof(randomlyselected)saccades. Withineachgroupofrows,
whichpertaintoaparticularsensoryinputdigit,thefirstrowshowsaglobalviewoftheoriginalinputforreference,
whiletheotherthreerowsshowthesaccadesequencetakenbytheMPCscheme(theboldnumberindicatesthe
saccadestepk,outofninetotaltaken,correspondingtoaparticularsaccade-sampledview). Withineachsaccade
view,thefirsthalfoftheimageshowsthesensory-levelglimpses(atstepk)whilethebottomhalfcontainsthetop
fourmosthighlyactivatedreceptivefieldsextractedfromtheMPCcircuitinresponsetotheinputstimulus.
based[33,4]SSLmethodthatperformsbiologically-plausibleinferenceandcreditassignment. However,the
failurecasesofMPC—aswellasthemissingheuristicsneededtoscaleittobecompetitivewithmodern-day
generativeAI—willneedtobedeveloped. Itwillfurtherbecrucialtoadaptandapplytheanalyticalapparatusof
self-supervisedandrepresentationallearning[35],suchascharacterizingproblemssuchasdimensionalitycollapse
[48]. ItisourhopethatourMPCframeworkencouragesexplorationofbrain-inspiredandneuroscience-motivated
intelligence[80,79]inthecontextofSSL,aspacewelabelbiomimeticself-supervisedlearning.
14
Preprint
Anotherkeyaspectthatismissingfromourframeworkisamechanismforcontext-drivenmotorcontrol12 further
inspiredbymachineintelligenceworksuchas[66,106],asitwell-knownthatcontextualtaskknowledgeplays
animportantroleindeterminingwhereabiologicalvisionsystemlooks[99]. Thisnextgeneralizationisfurther
relatedtoanimplementationofthefreeenergyprincipleknownasactiveinference[31]and,sinceourMPCmodel
isalreadyaction-conditional(i.e.,itsrepresentationsare“aware”ofactionstaken),ourframeworkcouldyield
togeneralizationsunderactiveinference. Inotherwords,itcoulddeploysaccadiceyemovementstomaximize
expectedinformationgain—orepistemicaffordance—ofvisualsamples. See[28,84,82,83]forworkedexamples.
4 RelatedWork
Self-supervised learning and representations. Self-supervised learning (SSL), specifically self-supervised
representationlearning[21](SSRL),whichcanbeviewedasaspecialcaseofunsupervisedlearning,strivestolearn
featuresor(abstract)representationsofdatawithoutusingsupervisoryannotation,e.g.,labelsofsemanticcategories.
Asopposedtounsupervisedlearningwhichcentersarounddensityestimationor(inputdata)reconstruction,SSRL
reliesonwhatareknownas“pretexttasks”orartificialtasksthatexploitknowledgerelatedtoaparticularinput
modality (or modalities). Pretext SSL tasks can take a wide variety of forms, ranging from counting visual
primitivesinascene[71]toin-painting[119]onepartof(maskedout)inputusingother(non-masked)portions
of the input. SSRL methodology in machine intelligence research seeks to develop approaches that acquire
representations(orthosethatlearngeneralfeatures)ofdatathatfacilitatestrongdownstreamsupervisedlearning
performancewithoutrequiringtime-consumingeffortfromhumanannotators(toproducethelabelsrequiredby
supervisedlearning). Thechosenpretexttask(s)tendtobebelesscomplexthanfull,rawdatagenerativemodeling,
possiblyyieldingrepresentationsofinputthatareless“distracted”bynoiseorirrelevantdatadetails,withmany
motivatingcasescomingfromreinforcementlearningresearch[9,51,59,70].
Inlearningusefulrepresentations[6]orlatentembeddingsofinputdata,awidevarietyofSSL/SSRLmethodshave
beenstudiedanddeveloped[35]. Recentapproaches,particularlythosethatcanbelabeledas“joint-embedding
architectures”[5],canbebrokendownroughlyintoafewgeneralcategories: contrastiveapproaches,information-
maximizing/regularizationapproaches,orthosewhicharedrivenbyparticularheuristics[37,97,13]. Contrastive
methodsfocusonconstructingobjectivesthatpull/attractembeddingsofsimilarinputs(e.g.,images)closertoone
anotherandpushembeddingsofdissimilarinputsawayfromeachother. Theseschemesstronglyrelyoneither:
• 1)aneffectiveminingprocessforuncoveringdissimilarimageswithinabatch[12]ormemorybank[42];
• 2) the design of a useful synthetic process that creates out-of-distribution or negative data examples
[43,78];or,
• 3)aquantization/clusteringscheme[10]thatassignsembeddingsofdissimilardatapatternstodifferent
clusterswithinaunitsphere.
Information-maximization SSL methods use objective functions that decorrelate and orthogonalise vari-
able/dimension pairs within an joint-embedding of latent vectors; this is argued to (indirectly) maximize the
information content of embedding vectors [5, 35]. Generally, these methods focus on either: 1) driving the
normalized cross-correlation matrix of the two embeddings (of two different, yet complementary inputs, e.g.,
twotransformationsofanimage)producedbythearchitecturetowardstheidentity[116,5],or2)whiteningand
spreadingoutembeddingvectors(ofinput)acrosstheunitsphere[22]. AlthoughMPCdoesnotencodeexplicit
objectivesthatdirectlymaximizeinformation,itsfocusonencouraging“resonant”,predictivesub-representations
ofdifferent,dynamically-selected(temporallyandspatiallyadjacent)subsetsofinputviaacross-streammessage
passingpassingschemebringsitclosesttoregularization-basedSSLapproaches,e.g.,theJEPAfamily[33,4].
Biomimeticself-supervised(representation)learning. Withrespecttobiomimeticintelligence,therehavebeen
severalapproachestoconstructschemesthatare(essentially)encoder-centric. SomeapproachesfocusonHebbian
plasticity[39,63,67]; whilethesemodelshavethebenefitofoperatingwithonlylocalpre-andpost-synaptic
statistics—todrivevariousformsofassociativelearning—itisdifficulttowritedownthecost/energyfunctionals
thattheyareoptimizing,resultinginanobscureoptimization-successtrackingexperience.13 See[45]foraworked
example with recurrent neural networks. More recent efforts include approaches that fall under the banner of
forward-onlylearning[49,79],withparticularapproachessuchas(theunsupervisedformsof)forward-forward
[43]andpredictiveforward-forward[78]learningofferingwaysofconductingSSRL.Scientificinquiryalongthis
directionhasledtoinsightsintohowsystemsofspikingneuronalcellscouldengageinself-supervisedforward-
onlylearning[81,62],buildingstrongconnectionsbetweenmachinelearning,computationalneuroscience,and
12Suchmechanismswouldproveusefulforincorporatingvoluntaryocularmotorcontrolaswellasfacilitateothertypesof
eyemovement,suchassmoothpursuitorvergence.
13Workisongoingforuncoveringtheimplicitobjectivesthattheseformsofplasticitymightbeapproximating[86,61].
15
Preprint
neuromorphicengineering. Nevertheless,theseformsofneuro-mimeticlearninginheritthesamelimitationsas
relatedmachinelearningSSLcontrastivemethodology, i.e., theyrequirethegenerationorminingofnegative
samplestofacilitatetheproperorganizationoflatentembeddings.
Predictivecoding(PC),whichisapromisingbiomimeticlearning-and-inferenceschemethathasemergedfrom
theoretical/computationalneuroscience[20,73,92]andbeencontinuouslydevelopedinneuroscience-inspired
machinelearningresearch[100,80],primarilytakesontheformofanauto-associativememory[102]structure
(thusdecoder-focused)inmodelingsensoria. ThegoalofanyunsupervisedPCmodelistooptimizeits(variational)
freeenergy(VFE)[32,27],leadingtoneuronaldynamicsandmessagepassingthatfollowthe(gradient)flow
ofthisVFE,wheresynapticconnectionstrengthsminimizethesameVFEobjective, resultinginerror-guided
Hebbian plasticity. Most PC models are formulated as unsupervised associative memory engines (such as
this work’s GPC baseline models), which predict raw sensory inputs. These models acquire their distributed
representations, which constitute their underlying models-of-the-world, as a consequence of optimizing VFE
[92, 27, 11, 102, 75, 101, 100]. Beyond unsupervised reconstruction, PC has been formulated for supervised
learning,e.g.,classification[114,101,76,64],andforreinforcementlearning/activeinference[77];althoughthese
PCformatsoftendonottakeonadecoder/associativememoryformat,theygenerallyrequireannotation/human
supervision to provide desired target signals or priors. This work directly recasts PC in terms of a non-auto-
associative,self-supervisedlearningframing—meta-representationalPC(MPC)—showingthatitispossible,from
a free energy principle perspective, to learn distributed representations of a sensorium without reconstructing
rawsensoryinputs. Inessence,MPCentailsakindofgenerativelearningoflatentcauses,guidedbyafferent
synapticconnectionsthatsupplymotor-actioninformationtothecircuit’sneuronalunits(actions,inourcase,being
thecoordinatesofsaccades),furtherelaboratedbyleveragingconditionalindependencies[29]toreproducethe
computationalarchitecturefoundinthevisualsystem,e.g.,central(fovealandparafoveal)andperipheralsensing,
andassociatedparvocellularandmagnocellularstreamsinthevisualcorticalhierarchy.
Activepredictivecoding: ArecentvariantofPCcalledactivepredictivecoding(APC)[91,93],whichisinspired
bytheprimacyofactionsintheneocortex,utilizesahierarchyofcoupledsensorypredictionandactionpolicy
modulesforsolvingavarietyofsensory-motortaskssuchasactiveperception,learningpart-wholehierarchies
and spatial navigation. In APC, higher level latent sensory states and abstract actions change the lower-level
statepredictionfunctionandpolicyfunctionrespectivelyaccordingtothecurrenttaskusinghypernetworksor
top-downmodulationoflower-levelnetworks. MPCshareswithAPCtheemphasisonusingactions(saccadic
eye movements) to generate a sequence of glimpses, which are then used for self-supervised learning. While
APClearnsaneyemovementpolicytointelligentlysamplethesceneaccordingtothetaskathand,thecurrent
implementationofMPCusesrandomlygeneratedmovements. Ontheotherhand,APCreliesonpredictionerrors
frompredictingrawinputsforlearningwhileMPCavoidsinputpredictionandreliesonpredictionerrorsfrom
predictinglatentstatesacrossmultiplevisualstreams. Anobviousdirectionforfutureresearchistocombinethe
strengthsofAPCandMPCbylearninghierarchicalpolicynetworksforintelligentlysamplingthesensoriumwhile
learningtask-specificandhierarchicallatentstaterepresentationsviapredictionsacrossvisualormorebroadly,
multimodalsensorystreams.
5 Conclusions
Inthisstudy,weproposedanewformulationofpredictivecoding,meta-representationalpredictivecoding(MPC),
whichisabiologically-motivatedformofself-supervisedinferenceandlearninginserviceofacquiringdistributed
representations of sensory input. Our framework, grounded in the free energy principle, inverts the standard
premiseofpredictiveprocessingfromoneofadaptingagenerativemodeltoexplainrawsensoryinputstoone
ofanencoder-centricschemewhererepresentationsofdistinctdatafeaturespredicteachother. Empirically,our
resultsdemonstratethatcastingneuronaldynamicsandsynapticplasticityasmessagepassing—inducedbywithin
andbetweenstreamprediction—offersamechanisticexplanationofhowrepresentationsofsensorystimulimight
emerge. In the context of visual perception, MPC is instantiated by an architecture of visual streams that are
eachconcernedwithprocessingfoveal/parafoveal(high-resolution)orperipheral(low-resolution)sensorydata
features. Theresultingneuronaldynamicsaredrivenbyintra-andinter-streammessagepassingofpredictionsand
predictionerrors.
Notetheresultingframeworkengageswiththerelativelychallengingproblemofself-supervisedlearning(SSL)
ofrepresentations,side-steppingtheneedforpositiveandnegativedatasamples(asincontrastiveSSLschemes)
through cross visual stream prediction, showing how abstract encodings might emerge using only predictions
andpredictionerroralone(asopposedtoschemesthatusesimilaritymetricsandcomplementaryviewsofdata
throughrandomtransformations). Ourexperimentalsimulationsshowthatself-supervisedMPCwascapableof
learningrepresentationsthatwereusefulfornotonlydownstreamdiscriminativelearningbutalsofordownstream
16
Preprint
reconstruction. SimulationresultsdemonstratedthatMPCwascompetitivewithstandardstate-of-the-artpredictive
codingandbackprop-trainedsupervisedlearning,eventhoughtheframeworkneveruseslabelinformationnor
doesitneedtopredicthighdimensionalsensorydata(e.g.,pixels).
Acknowledgements
WewouldliketothankVietNguyenforwritingthecustomJEPAbaselineusedfortheexperimentsinthispaper.
Thisresearchwasfundedinwhole, orinpart, bytheCiscoResearchGiftAward#26224(AO).Thisresearch
wasfundedinwhole,orinpart,bytheWellcomeTrust[203147/Z/16/Z](KF),theNationalScienceFoundation
(NSF)(EFRIgrantno.2223495)(RPNR),andaFrameworksgrantfromtheTempletonWorldCharityFoundation
(RPNR).ForthepurposeofOpenAccess,theauthorshaveappliedaCCBYpubliccopyrightlicensetoanyAuthor
AcceptedManuscriptversionarisingfromthissubmission.
References
[1] AHMAD, S., AND SCHEINKMAN, L. How can we be so dense? the benefits of using highly sparse
representations. arXivpreprintarXiv:1903.11257(2019).
[2] ARCARO, M. J., MCMAINS, S. A., SINGER, B. D., AND KASTNER, S. Retinotopic organization of
humanventralvisualcortex. Journalofneuroscience29,34(2009),10638–10652.
[3] ASSRAN, M.,DUVAL, Q.,MISRA, I.,BOJANOWSKI, P., VINCENT, P., RABBAT, M.,LECUN, Y.,AND
BALLAS, N. Self-supervised learning from images with a joint-embedding predictive architecture. In
ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition(2023),pp.15619–
15629.
[4] BARDES, A., GARRIDO, Q., PONCE, J., CHEN, X., RABBAT, M., LECUN, Y., ASSRAN, M., AND
BALLAS,N. Revisitingfeaturepredictionforlearningvisualrepresentationsfromvideo. arXivpreprint
arXiv:2404.08471(2024).
[5] BARDES, A., PONCE, J., AND LECUN, Y. Vicreg: Variance-invariance-covariance regularization for
self-supervisedlearning. arXivpreprintarXiv:2105.04906(2021).
[6] BENGIO,Y.,COURVILLE,A.,ANDVINCENT,P. Representationlearning: Areviewandnewperspectives.
IEEEtransactionsonpatternanalysisandmachineintelligence35,8(2013),1798–1828.
[7] BOTVINICK,M.,ANDTOUSSAINT,M. Planningasinference. Trendsincognitivesciences16,10(2012),
485–488.
[8] BROMLEY,J.,GUYON,I.,LECUN,Y.,SÄCKINGER,E., ANDSHAH,R. Signatureverificationusinga"
siamese"timedelayneuralnetwork. Advancesinneuralinformationprocessingsystems6(1993).
[9] BURDA, Y., EDWARDS, H., STORKEY, A., ANDKLIMOV, O. Explorationbyrandomnetworkdistillation.
arXivpreprintarXiv:1810.12894(2018).
[10] CARON,M.,BOJANOWSKI,P.,JOULIN,A.,ANDDOUZE,M. Deepclusteringforunsupervisedlearningof
visualfeatures. InProceedingsoftheEuropeanconferenceoncomputervision(ECCV)(2018),pp.132–149.
[11] CHALASANI,R.,ANDPRINCIPE,J.C. Deeppredictivecodingnetworks. arXivpreprintarXiv:1301.3541
(2013).
[12] CHEN,T.,KORNBLITH,S.,NOROUZI,M.,ANDHINTON,G. Asimpleframeworkforcontrastivelearning
ofvisualrepresentations. InInternationalconferenceonmachinelearning(2020),PMLR,pp.1597–1607.
[13] CHEN,X.,ANDHE,K. Exploringsimplesiameserepresentationlearning. InProceedingsoftheIEEE/CVF
conferenceoncomputervisionandpatternrecognition(2021),pp.15750–15758.
[14] CLANUWAT,T.,BOBER-IRIZAR,M.,KITAMOTO,A.,LAMB,A.,YAMAMOTO,K.,ANDHA,D. Deep
learningforclassicaljapaneseliterature,2018.
[15] CLARK,A. Surfinguncertainty: Prediction,action,andtheembodiedmind. OxfordUniversityPress,2015.
[16] CURCIO, C. A., SLOAN, K. R., KALINA, R. E., AND HENDRICKSON, A. E. Human photoreceptor
topography. Journalofcomparativeneurology292,4(1990),497–523.
[17] DEMPSTER,A. P.,LAIRD,N. M.,ANDRUBIN,D. B. Maximumlikelihoodfromincompletedataviathe
emalgorithm. Journaloftheroyalstatisticalsociety: seriesB(methodological)39,1(1977),1–22.
[18] DROZDOV,K.,SHWARTZ-ZIV,R.,ANDLECUN,Y. Videorepresentationlearningwithjoint-embedding
predictivearchitectures. arXivpreprintarXiv:2412.10925(2024).
17
Preprint
[19] EFRON, N. 5-lidwiperepitheliopathy. InContactLensComplications(FourthEdition),N.Efron,Ed.,
fourtheditioned.Elsevier,Philadelphia,2019,pp.53–68.
[20] ELIAS,P. Predictivecoding–i. IREtransactionsoninformationtheory1,1(1955),16–24.
[21] ERICSSON,L.,GOUK,H.,LOY,C.C.,ANDHOSPEDALES,T.M. Self-supervisedrepresentationlearning:
Introduction,advances,andchallenges. IEEESignalProcessingMagazine39,3(2022),42–62.
[22] ERMOLOV,A.,SIAROHIN,A.,SANGINETO,E.,ANDSEBE,N. Whiteningforself-supervisedrepresenta-
tionlearning. InInternationalconferenceonmachinelearning(2021),PMLR,pp.3015–3024.
[23] FELLEMAN, D. J., AND VAN ESSEN, D. C. Distributedhierarchicalprocessingintheprimatecerebral
cortex. Cerebralcortex(NewYork,NY:1991)1,1(1991),1–47.
[24] FINDLAY, J. M. Saccadiceyemovementprogramming: Sensoryandattentionalfactors. Psychological
research73,2(2009),127–135.
[25] FRISTON,K. Atheoryofcorticalresponses. PhilosophicalTransactionsoftheRoyalSocietyB:Biological
Sciences360,1456(2005).
[26] FRISTON,K. Hierarchicalmodelsinthebrain. PLoScomputationalbiology4,11(2008),e1000211.
[27] FRISTON,K. Thefree-energyprinciple: aunifiedbraintheory? Naturereviewsneuroscience11,2(2010),
127–138.
[28] FRISTON,K.,ADAMS,R.A.,PERRINET,L.,ANDBREAKSPEAR,M. Perceptionsashypotheses:saccades
asexperiments. Frontiersinpsychology3(2012),151.
[29] FRISTON,K.,ANDBUZSÁKI,G. Thefunctionalanatomyoftime: whatandwheninthebrain. Trendsin
cognitivesciences20,7(2016),500–511.
[30] FRISTON,K.,FITZGERALD,T.,RIGOLI,F.,SCHWARTENBECK,P.,ANDPEZZULO,G. Activeinference:
aprocesstheory. Neuralcomputation29,1(2017),1–49.
[31] FRISTON, K., FITZGERALD, T., RIGOLI, F., SCHWARTENBECK, P., PEZZULO, G., ET AL. Active
inferenceandlearning. Neuroscience&BiobehavioralReviews68(2016),862–879.
[32] FRISTON,K.,ANDKIEBEL,S. Predictivecodingunderthefree-energyprinciple. Philosophicaltransac-
tionsoftheRoyalSocietyB:Biologicalsciences364,1521(2009),1211–1221.
[33] GARRIDO, Q., ASSRAN, M., BALLAS, N., BARDES, A., NAJMAN, L., ANDLECUN, Y. Learningand
leveragingworldmodelsinvisualrepresentationlearning. arXivpreprintarXiv:2403.00504(2024).
[34] GEBHARDT,W.,ANDORORBIA,A.G. Time-integratedspike-timing-dependent-plasticity. arXivpreprint
arXiv:2407.10028(2024).
[35] GEIPING, J.,GARRIDO, Q.,FERNANDEZ, P., BAR, A.,PIRSIAVASH, H.,LECUN, Y., ANDGOLDBLUM,
M. Acookbookofself-supervisedlearning. arXivpreprintarXiv:2304.12210(2023).
[36] GOODALE, M. A., AND MILNER, A. D. Separatevisualpathwaysforperceptionandaction. Trendsin
neurosciences15,1(1992),20–25.
[37] GRILL,J.-B.,STRUB,F.,ALTCHÉ,F.,TALLEC,C.,RICHEMOND,P.,BUCHATSKAYA,E.,DOERSCH,C.,
AVILAPIRES,B.,GUO,Z.,GHESHLAGHIAZAR,M.,ETAL. Bootstrapyourownlatent-anewapproach
toself-supervisedlearning. Advancesinneuralinformationprocessingsystems33(2020),21271–21284.
[38] GRILL-SPECTOR, K., AND MALACH, R. Thehumanvisualcortex. Annu.Rev.Neurosci.27,1(2004),
649–677.
[39] GRINBERG,L.,HOPFIELD,J.,ANDKROTOV,D. Localunsupervisedlearningforimageanalysis. arXiv
preprintarXiv:1908.08993(2019).
[40] HASSON, U., HAREL, M., LEVY, I., AND MALACH, R. Large-scalemirror-symmetryorganizationof
humanoccipito-temporalobjectareas. Neuron37,6(2003),1027–1041.
[41] HAYHOE,M.,ANDBALLARD,D. Eyemovementsinnaturalbehavior. Trendsincognitivesciences9,4
(2005),188–194.
[42] HE, K., FAN, H., WU, Y., XIE, S., AND GIRSHICK, R. Momentumcontrastforunsupervisedvisual
representation learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition(2020),pp.9729–9738.
[43] HINTON, G. The forward-forward algorithm: Some preliminary investigations. arXiv preprint
arXiv:2212.13345(2022).
18
Preprint
[44] HINTON,G.E. Trainingproductsofexpertsbyminimizingcontrastivedivergence. Neuralcomputation14,
8(2002),1771–1800.
[45] ISOMURA, T.,ANDFRISTON,K. Reverse-engineeringneuralnetworkstocharacterizetheircostfunctions.
Neuralcomputation32,11(2020),2085–2121.
[46] JADERBERG,M.,CZARNECKI,W.M.,OSINDERO,S.,VINYALS,O.,GRAVES,A.,SILVER,D.,AND
KAVUKCUOGLU,K. Decoupledneuralinterfacesusingsyntheticgradients. InInternationalconferenceon
machinelearning(2017),PMLR,pp.1627–1635.
[47] JAISWAL,A.,BABU,A.R.,ZADEH,M.Z.,BANERJEE,D.,ANDMAKEDON,F. Asurveyoncontrastive
self-supervisedlearning. Technologies9,1(2020),2.
[48] JING, L., VINCENT, P., LECUN, Y., AND TIAN, Y. Understandingdimensionalcollapseincontrastive
self-supervisedlearning. arXivpreprintarXiv:2110.09348(2021).
[49] KOHAN,A.,RIETMAN,E.A.,ANDSIEGELMANN,H.T. Signalpropagation: Theframeworkforlearning
andinferenceinaforwardpass. IEEETransactionsonNeuralNetworksandLearningSystems(2023).
[50] KRAUZLIS, R. J. Thecontrolofvoluntaryeyemovements: newperspectives. TheNeuroscientist11,2
(2005),124–137.
[51] LASKIN, M., SRINIVAS, A., AND ABBEEL, P. Curl: Contrastive unsupervised representations for
reinforcementlearning. InInternationalconferenceonmachinelearning(2020),PMLR,pp.5639–5650.
[52] LECUN,Y. Themnistdatabaseofhandwrittendigits. http://yann.lecun.com/exdb/mnist/ (1998).
[53] LEVY,I.,HASSON,U.,AVIDAN,G.,HENDLER,T.,ANDMALACH,R. Center–peripheryorganizationof
humanobjectareas. Natureneuroscience4,5(2001),533–539.
[54] LIVERSEDGE, S. P., AND FINDLAY, J. M. Saccadiceyemovementsandcognition. Trendsincognitive
sciences4,1(2000),6–14.
[55] LIVINGSTONE,M.,ANDHUBEL,D. Segregationofform,color,movement,anddepth: anatomy,physiol-
ogy,andperception. Science240,4853(1988),740–749.
[56] LOSCHKY, L., MCCONKIE, G., YANG, J., AND MILLER, M. Thelimitsofvisualresolutioninnatural
sceneviewing. VisualCognition12,6(2005),1057–1092.
[57] LOSCHKY, L. C., SETHI, A., SIMONS, D. J., PYDIMARRI, T. N., OCHS, D., AND CORBEILLE, J. L.
Theimportanceofinformationlocalizationinscenegistrecognition. JournalofExperimentalPsychology:
HumanPerceptionandPerformance33,6(2007),1431.
[58] MALACH,R.,LEVY,I.,ANDHASSON,U. Thetopographyofhigh-orderhumanobjectareas. Trendsin
cognitivesciences6,4(2002),176–184.
[59] MAZZAGLIA, P., VERBELEN, T., AND DHOEDT, B. Contrastiveactiveinference. Advancesinneural
informationprocessingsystems34(2021),13870–13882.
[60] MCCOTTER,M.,GOSSELIN,F.,SOWDEN,P.,ANDSCHYNS,P. Theuseofvisualinformationinnatural
scenes. VisualCognition12,6(2005),938–953.
[61] MELCHIOR,J.,ANDWISKOTT,L. Hebbian-descent. arXivpreprintarXiv:1905.10585(2019).
[62] MERKEL,C.,ANDORORBIA,A.G. Contrastivelearninginmemristor-basedneuromorphicsystems. In
2024IEEEWorkshoponSignalProcessingSystems(SiPS)(2024),IEEE,pp.171–176.
[63] MICONI,T. Hebbianlearningwithgradients: Hebbianconvolutionalneuralnetworkswithmoderndeep
learningframeworks. arXivpreprintarXiv:2107.01729(2021).
[64] MILLIDGE,B.,TSCHANTZ,A.,ANDBUCKLEY,C.L. Predictivecodingapproximatesbackpropalong
arbitrarycomputationgraphs. NeuralComputation34,6(2022),1329–1368.
[65] MISHKIN,M.,ANDUNGERLEIDER,L.G. Contributionofstriateinputstothevisuospatialfunctionsof
parieto-preoccipitalcortexinmonkeys. Behaviouralbrainresearch6,1(1982),57–77.
[66] MNIH, V., HEESS, N., GRAVES, A., ET AL. Recurrentmodelsofvisualattention. Advancesinneural
informationprocessingsystems27(2014).
[67] MORAITIS, T., TOICHKIN, D., JOURNÉ, A., CHUA, Y., AND GUO, Q. Softhebb: Bayesianinference
inunsupervisedhebbiansoftwinner-take-allnetworks. NeuromorphicComputingandEngineering2,4
(2022),044017.
19
Preprint
[68] MUSEL, B., BORDIER, C., DOJAT, M., PICHAT, C., CHOKRON, S., LE BAS, J.-F., AND PEYRIN,
C. Retinotopic and lateralized processing of spatial frequencies in human visual cortex during scene
categorization. JournalofCognitiveNeuroscience25,8(2013),1315–1331.
[69] NEALEY, T. A., AND MAUNSELL, J. Magnocellularandparvocellularcontributionstotheresponsesof
neuronsinmacaquestriatecortex. JournalofNeuroscience14,4(1994),2069–2079.
[70] NGUYEN,V.D.,YANG,Z.,BUCKLEY,C.L.,ANDORORBIA,A. R-aif: Solvingsparse-rewardrobotic
tasksfrompixelswithactiveinferenceandworldmodels. arXivpreprintarXiv:2409.14216(2024).
[71] NOROOZI, M., PIRSIAVASH, H., AND FAVARO, P. Representation learning by learning to count. In
ProceedingsoftheIEEEinternationalconferenceoncomputervision(2017),pp.5898–5906.
[72] OGNIBENE, D., ANDBALDASSARE, G. Ecologicalactivevision: fourbioinspiredprinciplestointegrate
bottom–upandadaptivetop–downattentiontestedwithasimplecamera-armrobot. IEEEtransactionson
autonomousmentaldevelopment7,1(2014),3–25.
[73] OLSHAUSEN,B.A.,ANDFIELD,D.J. Sparsecodingwithanovercompletebasisset: Astrategyemployed
byv1? Visionresearch37,23(1997),3311–3325.
[74] OORD, A. V. D., LI, Y., AND VINYALS, O. Representationlearningwithcontrastivepredictivecoding.
arXivpreprintarXiv:1807.03748(2018).
[75] ORORBIA, A., AND KIFER, D. The neural coding framework for learning generative models. Nature
communications13,1(2022),2064.
[76] ORORBIA,A.,ANDMALI,A. Convolutionalneuralgenerativecoding: Scalingpredictivecodingtonatural
images. arXivpreprintarXiv:2211.12047(2022).
[77] ORORBIA,A., ANDMALI,A. Activepredictivecoding: Brain-inspiredreinforcementlearningforsparse
reward robotic control problems. In 2023 IEEE International Conference on Robotics and Automation
(ICRA)(2023),IEEE,pp.3015–3021.
[78] ORORBIA,A.,ANDMALI,A. Thepredictiveforward-forwardalgorithm. arXivpreprintarXiv:2301.01452
(2023).
[79] ORORBIA,A.,MALI,A.,KOHAN,A.,MILLIDGE,B.,ANDSALVATORI,T. Areviewofneuroscience-
inspiredmachinelearning. arXivpreprintarXiv:2403.18929(2024).
[80] ORORBIA, A. G. Brain-inspired machine intelligence: A survey of neurobiologically-plausible credit
assignment. arXivpreprintarXiv:2312.09257(2023).
[81] ORORBIA,A.G. Contrastivesignal–dependentplasticity:Self-supervisedlearninginspikingneuralcircuits.
ScienceAdvances10,43(2024),eadn6076.
[82] PARR,T.,ANDFRISTON,K.J. Theactiveconstructionofthevisualworld. Neuropsychologia104(2017),
92–101.
[83] PARR,T.,ANDFRISTON,K.J. Uncertainty,epistemicsandactiveinference. JournaloftheRoyalSociety
Interface14,136(2017),20170376.
[84] PARR, T., AND FRISTON, K. J. Workingmemory,attention,andsalienceinactiveinference. Scientific
reports7,1(2017),14678.
[85] PATHAK, D., KRAHENBUHL, P., DONAHUE, J., DARRELL, T., AND EFROS, A. A. Contextencoders:
Featurelearningbyinpainting. InProceedingsoftheIEEEconferenceoncomputervisionandpattern
recognition(2016),pp.2536–2544.
[86] PEHLEVAN,C.,SENGUPTA,A.M.,ANDCHKLOVSKII,D.B. Whydosimilaritymatchingobjectiveslead
tohebbian/anti-hebbiannetworks? Neuralcomputation30,1(2017),84–124.
[87] PERRINET,L.U.,ADAMS,R.A.,ANDFRISTON,K.J. Activeinference,eyemovementsandoculomotor
delays. Biologicalcybernetics108(2014),777–801.
[88] PIERROT-DESEILLIGNY,C.,MILEA,D.,ANDMÜRI,R.M. Eyemovementcontrolbythecerebralcortex.
Currentopinioninneurology17,1(2004),17–25.
[89] POLYAK,S.L. Theretina. Univ.ChicagoPress,1941.
[90] PRINCE, J. S., ALVAREZ, G. A., AND KONKLE, T. Contrastive learning explains the emergence and
functionofvisualcategory-selectiveregions. ScienceAdvances10,39(2024),eadl1776.
[91] RAO,R.P. Asensory–motortheoryoftheneocortex. Natureneuroscience27,7(2024),1221–1235.
20
Preprint
[92] RAO, R. P., AND BALLARD, D. H. Predictivecodinginthevisualcortex: afunctionalinterpretationof
someextra-classicalreceptive-fieldeffects. NatureNeuroscience(1999).
[93] RAO,R.P.,GKLEZAKOS,D.C.,ANDSATHISH,V. Activepredictivecoding: Aunifyingneuralmodel
foractiveperception,compositionallearning,andhierarchicalplanning. NeuralComputation36,1(2023),
1–32.
[94] RAO,R.P.N. Anoptimalestimationapproachtovisualperceptionandlearning. VisionResearch39,11
(1999),1963–1989.
[95] RAYNER,K.,INHOFF,A.W.,MORRISON,R.E.,SLOWIACZEK,M.L.,ANDBERTERA,J.H. Masking
offovealandparafovealvisionduringeyefixationsinreading. JournalofExperimentalPsychology:Human
perceptionandperformance7,1(1981),167.
[96] RENSINK,R.A. Thedynamicrepresentationofscenes. Visualcognition7,1-3(2000),17–42.
[97] RICHEMOND,P.H.,GRILL,J.-B.,ALTCHÉ,F.,TALLEC,C.,STRUB,F.,BROCK,A.,SMITH,S.,DE,S.,
PASCANU,R.,PIOT,B.,ETAL. Byolworksevenwithoutbatchstatistics. arXivpreprintarXiv:2010.10241
(2020).
[98] ROBINSON,D.A. Themechanicsofhumansmoothpursuiteyemovement. TheJournalofPhysiology180,
3(1965),569.
[99] ROTHKOPF,C.A.,BALLARD,D.H.,ANDHAYHOE,M.M. Taskandcontextdeterminewhereyoulook.
Journalofvision7,14(2007),16–16.
[100] SALVATORI,T.,MALI,A., BUCKLEY,C.L., LUKASIEWICZ,T.,RAO,R.P., FRISTON,K.,ANDOROR-
BIA,A. Brain-inspiredcomputationalintelligenceviapredictivecoding. arXivpreprintarXiv:2308.07870
(2023).
[101] SALVATORI,T.,PINCHETTI,L.,MILLIDGE,B.,SONG,Y.,BAO,T.,BOGACZ,R.,ANDLUKASIEWICZ,
T. Learningonarbitrarygraphtopologiesviapredictivecoding. Advancesinneuralinformationprocessing
systems35(2022),38232–38244.
[102] SALVATORI,T.,SONG,Y.,HONG,Y.,SHA,L.,FRIEDER,S.,XU,Z.,BOGACZ,R.,ANDLUKASIEWICZ,
T. Associativememoriesviapredictivecoding. AdvancesinNeuralInformationProcessingSystems34
(2021),3874–3886.
[103] SANOCKI,T. Representationandperceptionofsceniclayout. CognitivePsychology47,1(2003),43–86.
[104] SASAKI, Y., HADJIKHANI, N., FISCHL, B., LIU, A. K., MARRET, S., DALE, A. M., AND TOOTELL,
R.B. Localandglobalattentionaremappedretinotopicallyinhumanoccipitalcortex. Proceedingsofthe
NationalAcademyofSciences98,4(2001),2077–2082.
[105] SETH, A. K., AND HOHWY, J. Predictiveprocessingasanempiricaltheoryforconsciousnessscience.
CognitiveNeuroscience12,2(2021),89–90.
[106] SHARAFELDIN, A., IMAM, N., AND CHOI, H. Activesensingwithpredictivecodinganduncertainty
minimization. Patterns(2024).
[107] SRINIVASAN,M.V.,LAUGHLIN,S.B.,ANDDUBS,A. Predictivecoding: afreshviewofinhibitionin
theretina. ProceedingsoftheRoyalSocietyofLondon.SeriesB.BiologicalSciences216,1205(1982),
427–459.
[108] STRASBURGER,H.,RENTSCHLER,I.,ANDJÜTTNER,M. Peripheralvisionandpatternrecognition: A
review. Journalofvision11,5(2011),13–13.
[109] TANG,M.,SALVATORI,T.,MILLIDGE,B.,SONG,Y.,LUKASIEWICZ,T.,ANDBOGACZ,R. Recurrent
predictive coding models for associative memory employing covariance learning. PLoS computational
biology19,4(2023),e1010719.
[110] VAN DER MAATEN, L., AND HINTON, G. Visualizing data using t-sne. Journal of machine learning
research9,11(2008).
[111] VAN DIEPEN, P. M., WAMPERS, M., AND D’YDEWALLE, G. Functional division of the visual field:
Movingmasksandmovingwindows. InEyeguidanceinreadingandsceneperception.Elsevier,1998,
pp.337–355.
[112] WANG,P.,ANDCOTTRELL,G.W. Centralandperipheralvisionforscenerecognition: Aneurocomputa-
tionalmodelingexploration. Journalofvision17,4(2017),9–9.
[113] WESTHEIMER,G.,ANDMCKEE,S.P. Visualacuityinthepresenceofretinal-imagemotion. JOSA65,7
(1975),847–850.
21
Preprint
[114] WHITTINGTON, J. C., AND BOGACZ, R. An approximation of the error backpropagation algorithm
inapredictivecodingnetworkwithlocalhebbiansynapticplasticity. Neuralcomputation29,5(2017),
1229–1262.
[115] WURTZ,R.H.,MCALONAN,K.,CAVANAUGH,J.,ANDBERMAN,R.A. Thalamicpathwaysforactive
vision. Trendsincognitivesciences15,4(2011),177–184.
[116] ZBONTAR,J.,JING,L.,MISRA,I.,LECUN,Y.,ANDDENY,S. Barlowtwins:Self-supervisedlearningvia
redundancyreduction. InInternationalconferenceonmachinelearning(2021),PMLR,pp.12310–12320.
[117] ZEKI,S. Theferrierlecture1995behindtheseen: thefunctionalspecializationofthebraininspaceand
time. PhilosophicalTransactionsoftheRoyalSocietyB:BiologicalSciences360,1458(2005),1145–1183.
[118] ZEKI,S.,ANDSHIPP,S. Thefunctionallogicofcorticalconnections. Nature335,6188(1988),311–317.
[119] ZHANG, L., DU, W., ZHOU, S., WANG, J., AND SHI, J. Inpaint2learn: Aself-supervisedframework
foraffordancelearning. InProceedingsoftheIEEE/CVFWinterConferenceonApplicationsofComputer
Vision(2022),pp.2665–2674.
[120] ZIMMERMANN, R. S., SHARMA, Y., SCHNEIDER, S., BETHGE, M., AND BRENDEL, W. Contrastive
learninginvertsthedatageneratingprocess. InInternationalConferenceonMachineLearning(2021),
PMLR,pp.12979–12990.
22
Preprint
Appendix/SupplementaryMaterial
GlimpseVectorCreation: AdditionalDetails
Each glimpse-action pair within a K-length (random/involuntary) saccade trajectory or sequence
{(g(0),a(0)),(g(1),a(1)),...,(g(k),a(k)),...(g(K),a(K))}iscreatedbyfirstgeneratinga2Dvectorcontain
Cartesianx-ycoordinates(inthiswork,arandompolicyisusedtoselecteachsetofcoordinatesateachstepwithin
thetrajectory),extractingtherelevantglimpsevectorg(k)containingthefoveal/parafoveal/peripheralpatchesat
thechosencoordinates,andthenfinallynormalizingthecoordinatevectortocreatetherequisiteactionvector
a(k). Specifically,the2Dx-ycoordinateactionvectoriscreatedbynormalizingtheoriginalrawx-yCartesian
(cid:16) (cid:17)
coordinatestotherangeof[−1,1],i.e.,a(k)=2 [x,y]T /D−1foraD×Dpixelimagewherexandyarethe
originalCartesiancoordinatesoftheglimpsecenter-point.
Eachglimpsevectorg(k)itselfisaconcatenationofseveralviews(pixelpatches)sampledfromtheobservation
o(t ). Specifically,itisacombinationofseveraltypesofviews,eachofwhichcanbeexpressedintermsofthe
g
followingpiecewisefunction:
pv ∈RSc×Sc v ∈{Setoffovealpatchindices}
p c
v ∈RSf×Sf v ∈{Setofparafovealpatchindices}
pv = f (15)

pv
p
∈RSp×Sp v ∈{Setofperipheralpatchindices}
∅ otherwise.
To produce the final glimpse vector, all C foveal, F parafoveal, and P peripheral views (centered around the
glimpse/gaze’s center-point) are first average pooled to always be the same final shape of S ×S pixels, then
flattenedtovectors,andfinallyconcatenatedtoobtaing(k)∈R((C+F+P)∗(S∗S))×1. Alloftheabovemeansthat
thefinalglimpsevectorproducedasaresultofthek-thsaccadeis:
g(k)=(<g1(k),g2(k),...,gv(k),...,gV(k)>)T (16)
where V = C +F +P, brackets < · > denote vector concatenation, and gv(k) = Flat (cid:0) Pool(pv) (cid:1) . For the
mainmodelusedinthepaper,thesetoffovealpatchindiceswas{1,2,3,4}whilethesetofparafovealindices
was{5}andtheperipheralwas{6}. Thischoicewasmadebasedonpreliminaryexperimentation(thestream
configurationthatresultedinthebestperformingMPCmodelwaschosen),theresultsofwhicharepresentedin
thenextappendixsection.
Uponcreation,thefoveal,parafoveal,andperipheralviewsareallalignedaroundaglimpsecenter-point(thex-y
coordinatesofthecenter-pointofourmodel’sgaze)withallviewsarrangedaroundthecenter-pointinaparticular
topology(suchasagrid). FovealviewsaregenerallyshapedsuchthatS = S whereasparafovealviewsare
C
shapedsuchthatS >S andperipheralviewsareshapedsuchthatS >S >S;inthiswork,wespecifically
C P C
choose for foveal views S = S = 8 pixels, for parafoveal views S = 16 pixels, and for peripheral views
C F
S =24pixels. Asmentionedabove,weuseC =4fovealviewswhicharearrangedina2×2grid(suchthatthe
P
fovealviewsoverlapwithoneanotherby1-2pixels)centeredaroundthewholeglimpse/gazecenter-point;weonly
useone(F =1)parafovealviewandone(P =1)peripheralviews,whicharebothdirectlycenteredaroundthe
glimpse/gazecenter-point.
AnalysisofViewExtractionSchemes
Inthissupplementarysection,weprovidesomeexperimentalresultsforasmallsetofconfigurationsoftheinput
streampatchextractionschemethatweutilizefortheMPCandGPC-fovmodels. Table2presentstheresults
oftheseparticularexperimentalresults. Concretely,undereachparticularconfigurationoftheinputstream,we
fitanMPCtothetrainingdataasinthemainpaper,thenprobethequalityoftheembeddingswith: 1)alinear
probe/classifier,2)anonlinearattentiveprobe/classifier(setupinthesamewayasin[18]),and3)anonlinear
MLPdecoder(forinputreconstruction). ThetrainingdetailsforthelinearprobeandMLPdecoderarethesame
asdescribedinthemainpaper;thenonlinearattentionprobewastrainedundersimilarconditionstothelinear
probe(exceptitwastrainedusingtheAdamoptimizer,useddrop-outforregularization,andemployedadecaying
adaptivelearningrate).
Specifically, we analyze the performance of an MPC model on MNIST under a small set of several possible
streamconfigurations;concretely,weinvestigatethevalueofhavingonlyonecoarsergrainedview(i.e.,justthe
peripheral)ortwo(i.e.,theparafovealpatchandtheperipheralpatch)aswellashavingonlyasinglefovealor
multiple(twoorfourfovealpatches). Asaresult,theinputstreamconfigurationsthatwepreliminarilyinvestigated
includedthefollowing:
23
Preprint
F-PF-P Lin-ACC(%) Attn-ACC(%) Dec-MSE(nats)
C =1 96.20±0.07 98.00±0.03 9.283±0.137
C =2 96.40±0.08 98.30±0.08 10.869±0.933
C =4 97.81±0.05 98.80±0.05 5.761±1.222
F-P Lin-ACC(%) Attn-ACC(%) Dec-MSE(nats)
C =1 95.08±0.06 97.71±0.03 9.942±0.763
C =2 96.66±0.04 98.25±0.02 7.481±0.889
C =4 97.56±0.05 98.68±0.04 4.971±0.616
Table2: GeneralizationonMNISTofmeta-representationalpredictivecodingunderdifferentglimpsing
structures. We examine MPC generalization ability under different formulations of its sensory input stream
structure–‘F-PF-P‘denotesfoveal-parafoveal-peripheralwhereas‘F-P‘denotesfoveal-peripheral;C ={1,2,4}
controlstheamountoffovealstreamsarrangedforthestructure(whileonlyoneparafovealorperipheralview
areused). Wespecificallymeasuregeneralizationintermsofdownstreamclassificationability(intermsof%),
asmeasuredbyalinearprobe(Lin-ACC)andanonlinearattentiveprobe(Attn-ACC),aswellasdownstream
decodingabilityintermsofmeansquarederror(Dec-MSE,intermsofnats).
• Foveal,parafoveal,peripheral(F-PF-P):
– Onefoveal(C =1)+parafoveal+peripheral
– Twofoveal(C =2)+parafoveal+peripheral
– Fourfoveal(C =4)+parafoveal+periperhal
• Fovealandonlyperipheral(F-P):
– Onefoveal(C =1)+peripheral
– Twofoveal(C =2)+peripheral
– Fourfoveal(C =4)+periperhal
InTable2,weobservethatthebestclassificationperformance(intermsofboththelinearandnonlinearattentive
probes) is obtained with C = 4, F = 1, and P = 1; however, slightly better reconstruction comes from just
C =4andP =1(noparafoveal;F =0). Itisimportanttonotethatmorefovealstreamsresultedinimproved
performanceineitheroftheseoverallsettings(withC =4givingthebestinthesetofconfigurationsexplored). It
wouldprovebeneficialiffutureworkweretoexploreotherconfigurationsoftheinputstreams(includingboththe
quantityaswellasthespatialarrangement).
24

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Meta-Representational Predictive Coding: Biomimetic Self-Supervised Learning"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
