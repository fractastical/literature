=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: An Active Inference Strategy for Prompting Reliable Responses from Large Language Models in Medical Practice
Citation Key: shusterman2024active
Authors: Roma Shusterman, Allison C. Waters, Shannon O`Neill

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2024

Abstract: crafted by experienced CBT-I therapists.
Continuing advances in Large Language
Results showed that LLM responses
Models (LLMs) in artificial intelligence
received high ratings from the CBT-I
offer important capacities in intuitively
therapists, often exceeding those of
accessing and using medical knowledge in
therapist-generated appropriate responses.
many contexts, including education and
This structured approach aims to integrate
training as well as assessment and treatment.
advanced LLM techn...

Key Terms: phan, large, language, knowledge, medicine, strategy, models, medical, roma, practice

=== FULL PAPER TEXT ===

An Active Inference Strategy for Prompting Reliable Responses from
Large Language Models in Medical Practice
Roma Shusterman1,2, Allison C. Waters3, Shannon O’Neill3, Phan Luu1,2, and Don M. Tucker 1,2
1Brain Electrophysiology Laboratory Company, Eugene OR, USA
2Neurosom, Inc. Eugene OR, USA
3 Icahn School of Medicine at Mount Sinai, New York, NY, USA.
{roma.shusterman, phan.luu, don.tucker}@bel.company
appropriate and inappropriate responses
Abstract
crafted by experienced CBT-I therapists.
Continuing advances in Large Language
Results showed that LLM responses
Models (LLMs) in artificial intelligence
received high ratings from the CBT-I
offer important capacities in intuitively
therapists, often exceeding those of
accessing and using medical knowledge in
therapist-generated appropriate responses.
many contexts, including education and
This structured approach aims to integrate
training as well as assessment and treatment.
advanced LLM technology into medical
Most of the initial literature on LLMs in
applications, meeting regulatory
medicine has emphasized that LLMs are
requirements for establishing the safe and
unsuitable for medical use because they are
effective use of special purpose validated
non-deterministic, may provide incorrect or
LLMs in medicine.
harmful responses, and cannot be regulated
to assure quality control. If these issues
1. Introduction
could be corrected, optimizing LLM
technology could benefit patients and Given the remarkable capacity of
physicians by providing affordable, point- current generation large language models to
of-care medical knowledge. Our proposed access knowledge relevant to a wide range
framework refines LLM responses by of user queries, there is considerable interest
restricting their primary knowledge base to in using chatbots for medical applications,
domain-specific datasets containing which presents both opportunities and
validated medical information. Additionally, concerns. The medical literature at the time
we introduce an actor-critic LLM prompting of this writing primarily expresses concerns
protocol based on active inference principles for the use of LLMs. Gilbert and associates
of human cognition, where a Therapist agent (Gilbert, Harvey, Melvin, Vollebregt, &
initially responds to patient queries, and a Wicks, 2023) emphasize that chatbots must
Supervisor agent evaluates and adjusts be regulated like any other medical device to
responses to ensure accuracy and reliability. be safe and effective. However, they
We conducted a validation study where conclude that current chatbots cannot be
expert cognitive behaviour therapy for effectively regulated because of their near-
insomnia (CBT-I) therapists evaluated infinite range of possible inputs and outputs
responses from the LLM in a blind format. and because there is no proven method to
Experienced human CBT-I therapists limit harmful responses.
assessed responses to 100 patient queries, In a similar analysis, Mesko and Topol
comparing LLM-generated responses with (Meskó & Topol, 2023) review the diverse
1
applications in medicine that LLM chatbots, advanced technology into medical
such as GPT4, could support, and they applications more effectively. This includes
review the range of potential problems with restricting the LLM chatbot’s primary
their use, from determining the liability for knowledge base to domain-specific datasets
harmful responses to monitoring validity containing validated information essential
when the chatbot is updated through for generating accurate responses to medical
continuous learning. Minssen and associates queries, alongside methods to enhance
(Minssen, Vayena, & Cohen, 2023) domain-specific document processing for
summarized a similar list of challenges to accurate model inputs. Additionally, we
regulating chatbots in medicine, and they introduce an actor-critic LLM prompting
emphasized that the uniqueness of the protocol reflecting active inference
technology poses difficulties for the principles in human reasoning, where a
agencies in the US and Europe that are Therapist agent initially responds to patient
attempting to develop a rational regulatory queries, and a Supervisor agent evaluates
strategy. and adjusts responses to ensure
Recognizing these obvious concerns, appropriateness and reliability.
we think it is important to consider that
1.1 Using LLMs for Improving Access to
successfully addressing the limitations of
Medical Knowledge
LLM technology would significantly benefit
patients and physicians needing affordable, Developers interested in utilizing LLMs
point-of-care access to medical knowledge, for medical device and service applications
thereby improving widespread access to face three main options for integrating
effective medical care, particularly by LLMs: (1) develop custom LLMs, (2) fine-
underserved populations. In this paper, we tune general-purpose LLMs, or (3) restrict
review strategies to optimize the application general-purpose LLMs to provide accurate
of LLMs for medical devices and services. and domain-relevant responses using prompt
The inherent non-deterministic nature of the engineering and restriction base knowledge
LLM requires a careful strategy of utilizing for response generation to domain-specific
the inherently variable output for patient knowledge.
assessment and treatment. The LLMs can The first option, custom LLMs, is
produce confabulations (factually incorrect tailored for specific tasks and requires
responses presented as accurate information) significant AI expertise and computational
as well as hallucinations (inappropriate or infrastructure, making them appropriate for
even bizarre responses). Such errors become large organizations with advanced
more common when the LLMs rely on information technology capabilities. This
unverified information or when they approach is still evolving, with a growing
struggle with processing complex and interest in developing domain-specific
ambiguous queries. Even when optimally LLMs in medicine.
constructed and prompted, LLMs require The second option, fine-tuning general-
careful management, given that their purpose LLMs, involves adjusting existing
response generation process is inherently models with specific datasets, requiring
non-deterministic and may provide some AI knowledge and considerable
somewhat different responses with repeated resource investment. This area is witnessing
presentations of the same question. developments, such as Low-Rank
We propose a structured framework for Adaptation, that facilitate the tuning process
refining LLM responses, aiming to integrate without requiring regeneration of the full
2
LLM. In Low-Rank Adaptation, the LLM’s actor-critic LLM programming architecture,
weights are frozen, and low-rank trainable including a Therapist agent (actor) that
decomposition matrices are inserted in each generates responses and a Supervisor agent
layer of the Transformer architecture, (critic) that evaluates the Therapist agent’s
thereby reducing the training demands for response and proposes an alternative
domain-specific applications (Hu et al., response if the original response is found
2021). lacking. We emphasize that the current
The third approach, prompting general- neuropsychological theory of how human
purpose LLMs, provides a major advantage verbal associations are organized may
when considered within structured provide insight into how LLMs can be
application boundaries because of the instructed to generate appropriate, valid
emphasis on the integration of verified responses that are at the same time
domain-specific databases into the LLM’s considerate of the user’s perspective that is
retrieval process, which also facilitates often implicit (not explicitly stated) by their
validation processes that test retrievals query. Remarkably, by reviewing the
against the domain-specific databases. Supervisor agent responses, we find that
Additionally, incorporating Retrieval- improved sensitivity to the patient’s
Augmented Generation (RAG) can enhance concerns (an important factor in patient
this approach by allowing the model to interactions in the medical setting) is readily
retrieve and integrate relevant information engaged by a simple Supervisor
from a large corpus of documents, thus programming (prompting) instruction.
providing more accurate and contextually Further, we performed a validation
relevant responses. For certain applications, study to test our approach by incorporating
this approach can be completely adequate, expert human oversight in validating AI
offering a balance between flexibility and outputs effectively. Expert CBT-I therapists
resource investment. evaluated the LLM responses in a blind
The present manuscript emphasizes this format in which the CBT-I therapist did not
third approach of using Application know whether the response was generated
Programming Interfaces (APIs) to prompt by a human or the LLM. The findings
general-purpose LLMs. This method indicated that LLM responses were rated
involves transforming data into vectors and highly, frequently surpassing the ratings of
creating specialized embeddings, which therapist-generated appropriate responses.
primarily requires straightforward This structured approach is encouraging for
programming in Python. Although this efforts to integrate advanced LLM
approach still utilizes some organizational technology into medical applications safely.
resources, it is less resource-intensive
compared to custom LLM training or fine-
2. Approach
tuning generic models.
We first provide a brief review of
2.1 Overview of LLM Prompting with RAG
existing methods for improving the
Architecture Using a Knowledge Domain-
contextual knowledge base for a domain-
Specific Database
specific application, for optimizing the use
of the domain-specific knowledge base, and The RAG architecture enhances LLMs
for optimizing the question-and-answer by restricting the response generation to a
process so that the LLM’s behavior remains limited knowledge base (such as provided
predictable and reliable. We then propose an by a set of PDFs summarizing that
3
knowledge), thereby enabling more chapters, sections, or paragraphs. The goal is
accurate, contextually relevant, and to create chunks that are sufficiently
Fig 1. LLM with RAG. Various document types in domain-specific knowledge databases are converted into a
uniform format (e.g., JSON). Next, split the documents into manageable segments, tag them with metadata, and
transform these segments into vector representations using techniques like TF-IDF or neural embeddings. When
a query is received from the user, the implementation converts it into a vector, performs a similarity search with
the document vectors, retrieves the most relevant segments, and uses the LLM to generate a contextually
relevant response.
verifiable outputs than would be obtained by informative but not overly long, ensuring
generating responses from the large corpus that the retrieval process remains efficient
of the LLM itself (Lewis et al., 2020). This and focused. Each segment is tagged with
architecture is particularly useful in medical metadata to assist in the identification and
question-answering systems where the LLM later retrieval process.
can be restricted to drawing on knowledge After splitting, each document segment
from a known and validated private database is transformed into a vector representation.
to retrieve and generate responses based on These vectors are typically created using
the stored information. As with LLM embeddings—dense representations that
queries generally, the process involves capture the semantic meaning of the text.
prompting the LLM with user queries, Techniques such as TF-IDF (Term
which the model uses to identify and Frequency - Inverse Document Frequency)
retrieve relevant data before generating an determine the relevance of specific terms in
answer (Figure 1). relation to the document’s general
The initial step in integrating RAG with semantics. More advanced neural
a private, domain-specific knowledge embeddings like those from BERT or
database involves loading documents into a RoBERTa can be used (Lui et al 2019). The
manageable format. This typically includes resulting vectors are stored in a vector
converting various data types (e.g., PDFs, database or vector index, facilitating
text files, databases) into a uniform format efficient similarity searches and retrieval.
such as JSON or plain text. These The retrieval component is critical in
documents are then pre-processed to ensure the RAG architecture. When a query is
clarity and uniformity, which helps optimize received, it is converted into a vector using
the LLM’s retrieval and understanding the same embedding method used for
processes. document vectors. The system then performs
Once documents are loaded and pre- a similarity search between the query vector
processed, they are split into segments that and the document vectors stored in the
are manageable by the encoding process. index. The most relevant documents or
This splitting could be based on natural document segments are then retrieved based
divisions within the documents, such as on semantic closeness to the query.
4
In the final step, the retrieved functionality, demonstrating the models'
documents are used by the LLM to limitations in handling varied document
understand the context and generate a formats.
response. The LLM integrates the For most moderate-size applications, a
information from these documents into its manual parsing procedure is adequate to
response generation process, ensuring that assure the specialized domain documents;
the answer is accurate and contextually alternatively, a dedicated parsing engine
relevant to the query. The integration of may be developed for large document
RAG allows the LLM to not only generate inventories. The goal is to convert the
answers based on a fixed knowledge base documents into a simpler, separated format
but also to dynamically incorporate new and that is easily parsed by a specialized Domain
relevant information from the private AI retrieval system.
knowledge database.
Context Retention in Text Chunks
In the following section we review the
nature of each processing step and then When the LLM processes large
illustrate the overall process with a specific documents, the text is typically broken into
application. smaller chunks, risking loss of context. This
can be particularly problematic in medical
documentation, where specific details of the
2.2. Preparing LLMs and Domain- Specific
contextual information are often crucial.
Knowledge Bases for Reliable Use
Labelling data during chunking will add to
each segment a metadata wrapper detailing
Document Parsing and Simplification
its context—ensuring that even when
LLMs require inputs to be in
segments are reviewed in isolation, their
straightforward text formats. Certain types
significance and connection to the larger
of documents pose significant challenges for
document are preserved.
LLMs. For instance, scientific papers, which
Text chunking is a crucial aspect of
often include detailed figures and equations,
retrieval in natural language processing,
can be problematic (Figure 2). On the first
dictating how information is organized and
page of such papers, standard PDF parsers
stored for efficient retrieval. The choice of
may struggle with 1) relating author names
chunk size presents a challenge, with no
to email addresses, 2) understanding that the
one-size-fits-all solution. However, various
DOI and publishing date, when printed
methods exist to enhance retrieval, including
vertically, are not related to the manuscript's
improved chunking strategies.
subject, 3) correctly positioning text
Fixed Size Chunking represents a
associated with figures or tables within the
widely adopted method in text segmentation,
manuscript's content, 4) interpreting a two-
where the chunk size is predetermined based
column text, and 5) excluding publisher
on the number of tokens. Optionally, some
details from the content for further analysis.
overlap between chunks is maintained to
Corporate filings, dense with financial data
preserve semantic coherence. This approach
and tables, are interpreted as indecipherable
is often preferred due to its computational
noise. Moreover, even seemingly
efficiency and simplicity, and it does not
straightforward texts, such as technical
rely on specialized Natural Language
manuals with intricate formatting and
Processing (NLP) libraries.
diagrams, can disrupt both optical character
Recursive Chunking, on the other hand,
recognition processes and LLM
employs an iterative hierarchical process to
divide text into smaller segments using
5
designated separators. If the
initial splitting fails to
produce chunks of the desired
size or structure, the method
iteratively refines the process
until the desired outcome is
achieved. While chunks may
not be uniform in size, this
method retains the essence of
fixed size chunking while
accommodating more flexible
variations.
Document Specific
Chunking takes into account
the inherent structure of the
document, aligning chunk
boundaries with logical
sections such as paragraphs or
subsections. This preserves
the author's organizational
framework, enhancing
coherence and relevance in
retrieved information,
especially in structured
documents like Markdown or
HTML formats.
Semantic Chunking
focuses on the semantic
relationships within the text,
dividing it into semantically
meaningful segments.
Although slower than other
methods, semantic chunking
ensures information integrity
Figure 2. Example of challenges in parsing a PDF page. Numbers
during retrieval, resulting in
1-5 highlight the problematic pieces of text for off-the-shelf parsers.
more accurate and
contextually appropriate
outcomes.
Both Document Specific Chunking and By aligning document ingestion with
Semantic Chunking approaches are proving metadata and vector embedding generation,
to be particularly promising approaches for the search mechanism can retrieve relevant
improving the domain-specific knowledge text blocks and their contextual metadata.
base pipeline. This enhances the accuracy of responses
from Domain AI applications, providing
Enhanced Search and Retrieval
precise information retrieval in medical
Effective search and retrieval are vital service and device management.
for managing extensive medical databases.
6
LLMs can produce incorrect answers verifier, questioning the effectiveness of this
because their knowledge relies solely on approach.
parametric memory. Retrieval-augmented Conversely, CritiqueLLM introduces a
LLMs (Borgeaud et al., 2022; Izacard et al., critique generation model for evaluating
2023; Shi et al., 2023) address this LLM-generated texts, using dialogue-based
shortcoming by integrating non-parametric prompting to gather high-quality data.
knowledge with additional retrieval Employing supervised fine-tuning and
modules. Early work focused on single-hop various decoding strategies, CritiqueLLM
queries (Lazaridou et al., 2022; Ram et al., achieves performance comparable to GPT-4
2023), involving retrieving a relevant and outperforms it in certain tasks,
document and integrating this into Question- especially in reference-free settings,
and-Answer models. However, multistep providing scalable feedback to enhance
queries require connecting multiple LLM quality (Ke et al., 2023).
documents, demanding iterative access to Reflexion, a reinforcement learning
LLMs and retrievers, introducing high framework, integrates Actor, Evaluator, and
computational costs (Press et al., 2023; Self-Reflection models for iterative learning.
Trivedi et al., 2023). The Actor generates actions, the Evaluator
Recent advancements in RAG aim to assesses them, and the Self-Reflection
further enhance LLM performance. model provides feedback. This process aims
Corrective-RAG (CRAG) uses a retrieval to solve complex tasks, advancing AI agents'
evaluator to address hallucinations (Yan et problem-solving abilities through memory
al., 2024). Self-RAG adjusts query handling mechanisms (Shinn et al., 2023).
based on complexity (Asai et al., 2023), SelfCheck presents a zero-shot, step-by-
while Adaptive-RAG routes queries between step checker for identifying errors in LLM
different RAG approaches (Jeong et al., reasoning chains, leveraging LLMs'
2024). MIGRES guides LLMs to fill generative abilities and de-correlating errors
knowledge gaps through iterative retrieval between generation and checking. It
(Wang, 2024), and DRAGIN dynamically improves final answer accuracy through
decides on retrieval needs during text weighted voting without requiring fine-
generation (Su et al., 2024). These tuning, making it versatile across various
approaches improve the efficiency, reasoning tasks (Miao et al., 2023).
accuracy, and adaptability of LLMs in These studies collectively enhance
retrieval-augmented text generation, LLMs' question-answering capabilities by
advancing natural language processing in addressing self-critiquing reliability, critique
specific information domains. generation, reinforcement learning with self-
reflection, and error identification, paving
Refining Question-Answering Capabilities
the way for robust AI systems capable of
A recent focus in LLMs emphasizes tackling complex tasks across domains.
their question-answering abilities through
self-reflection, verification, and error-
2.3. LLM Generation and LLM Critical
correction mechanisms. One approach by
Monitoring: Analogy to Active Inference in
Bai and associates (Bai et al., 2022) explores
Human Cognition
LLMs' self-critiquing in planning tasks. It
uses a generator LLM to create plans and a A powerful technique in deep learning
verifier LLM to assess them. Results is the Generative Adversarial Network, in
indicate self-critiquing diminishes which the generative capacity of a deep
performance due to false positives from the learning network is trained by attempting to
7
overcome the critical capacity of a second active inference proceeds through error-
network that uses the same network statistics correction of the initial prediction by the
to evaluate the output of the generative evidence in order to align with the adaptive
network (Creswell et al., 2018). In the context.
development of domain-specific LLMs for The theory of active inference has
medical knowledge access, we propose the proven very powerful in both elementary
use of a second (Supervisor) LLM network neuroscience, aligning closely with the
to critically evaluate the responses of the functions of cortical networks (Adams,
primary (Therapist) generative LLM. The Shipp, & Friston, 2013; Bastos et al., 2012),
power of LLMs, in fact, is that a massive and also neuropsychology, aligning with the
array of human linguistic associations can be dual motivational controls on generative
accessed and then organized coherently by feedforward expectancy and critical
the LLM architecture. By building on the feedback error-correction in natural human
intrinsic mechanisms of active inference in cognition (Luu & Tucker, 2023; Luu et al.,
the human brain (Luu, Tucker, & Friston, 2023; Tucker & Luu, 2021, 2023). Given the
2023), we propose that the LLM explanatory value of active inference in
applications prompting can provide describing the mechanisms for forming
instructions consistent with the dual associations (neural connection strengths) in
generative (actor or therapist) and corrective the human cortex, we can hypothesize that
(critic or supervisor) roles that reflect the similar (generative feedforward and critical,
implicit human understanding of language error-correcting feedback) processes underly
roles reflected in the LLM associative the implicit associative semantics of LLMs.
matrix. Importantly, because LLMs By designing the applications programming
naturally process the semantics of human (instruction and prompting) of dual actor
language, the prompting of LLMs can be (generative) and critic (error-correcting)
achieved with natural language instructions, LLMs in ways that align with these intrinsic
which are readily interpreted by the LLM as natural biases of human associations, it may
the appropriate context for its responses. be possible to optimize both the creative
Active inference is the generic theory generative capacities of LLMs (when
that originated with the computational instructed to emphasize this creative
neuroscience model of predictive coding generation) and the critical error-correction
(Friston, 2008; Rao & Ballard, 1999). In the capacities (when these are explicitly
network architecture of the human cerebral instructed).
cortex, this model proposes that the process Furthermore, the theory of active
of perception begins not with sensory input inference, when elaborated in relation to the
but rather with the brain’s prediction or adaptive mechanisms of human motivational
expectancy of this sensory input (Bastos et control (Luu & Tucker, 2023; Luu et al.,
al., 2012). This is the active part of active 2023; Tucker & Luu, 2021, 2023) explains
inference, in which the generation of why actor (generative) functions are
predictions presents an implicit hypothesis intrinsically separated from critic (error-
(a set of Bayesian priors) for what is to be correcting) functions. These functions have
perceived. The sensory data, processed from inherently different forms of motive control
receptors initially in the primary sensory in the human brain. The generative actor
cortex, then presents the evidence from the function operates under a feedforward (loose
external world that matches or does not the and impulsive) control bias, proceeding
initial expectant prediction. The process of from limbic regions at the core of the
8
hemisphere through limbifugal (from- they are deeply implicit in the semantic
limbic) connections through the association associations of each of the large language
cortex toward primary sensory and motor corpuses that form the basis of LLMs.
cortices. This is a very useful form of
motive control for creative generation, but it
3. Methods
is likely to be over-inclusive and error-prone
3.1. LLM Architecture and Implementation
(Tucker & Luu, 2023).
In contrast, the error-correcting critic
function in the active inference within Content extraction from PDF files was
cortical networks operates under feedback done with the PdfReader class from the
control (constraint), which is inherently PyPDF2 library. Post extraction, the
suited to the constraint that sensory data extracted text undergoes a chunking process
imposes on expectant predictions, thereby to divide the large text into manageable
achieving effective-error correction. In more pieces. This is implemented using the
general cognition, this form of motive RecursiveCharacterTextSplitter from
control is integral to critical thinking the langchain.text_splitter module.
(Tucker & Luu, 2023). It is, therefore, well- The splitter was configured to segment the
suited to an evaluative LLM that is critical text into chunks of approximately 1000
of responses that are not well-constrained by characters, allowing for an overlap of 200
the domain-specific knowledge base. characters between consecutive chunks. The
In a Bayesian analysis, these dual forms text chunks were then embedded into vector
of control are optimized for the variational representations using the locally-run
Bayes adjustments: holding the priors LLaMA 2 model, which provides state-of-
(feedforward) constant while the evidence the-art language understanding capabilities.
(feedback) is adjusted, then holding the These embeddings were stored in Chroma
feedback mechanism constant while the DB, a high-performance vector database
errors in the prediction are adjusted. designed for efficient storage, retrieval, and
Although the underlying network similarity searches among large sets of
architecture of LLMs is an engineering vectors. This enables rapid retrieval and
construction, and not particularly analysis of text data.
neuromorphic, the intrinsic associations of The actor-critic architecture for LLM
the human language corpus were indeed programming of the Virtual Sleep Coach is
generated by human brains. We propose shown in Figure 3. The LLM for each
these inherent adaptive biases are implicit condition was the Meta LLaMa 2. At left is
within the language corpus, and thus the the Therapist agent (actor) that generates the
LLMs, and are therefore best engaged initial response to the patient, with simple
separately for semantic generation (with the instructions to organize the response from
actor or Therapist prompting) and semantic the CBT-I manual (or manuals). An
constraint (with the critic or Supervisor additional specification of the context may
prompting). be a focus on the specific session of the
Our theoretical model is that these CBT-I training, but for this illustration and
instructional biases are able to optimize the validation experiment we will not segment
performance of the dual actor (here, the context into specific sessions.
Therapist) and critic (here, Supervisor) LLM At right is the Supervisor agent, which
instructions because these roles are integral uses the same LLM but with prompting
to the way people think. We propose that instructions to act as a supervisor, to review
9
the Therapist agent’s response and decide if now widely available, patient compliance is
Figure 3. Proposed Therapist-Supervisor Framework. The Therapist agent drafts a response and sends it to
the Supervisor agent for verification. The Supervisor agent checks the response for correctness. If the
response is deemed correct, it is sent to the patient. If the response is incorrect, the Supervisor generates the
correct response, which is then sent to the patient.
it is appropriate to both the context often poor due to the considerable discipline
knowledge base and the intent of the required to understand and follow the often
patient’s query. challenging treatment regimen. In contrast
with a passive software application, the VSC
3.2. Instructing Patients in Cognitive interacts with the patient through natural
Behavioral Therapy for Insomnia language, with an engaging and
interpersonally sensitive conversation that
To provide a use case to show how
provides immediate answers to questions
these general principles might be
and concerns that arise during the therapy
implemented, we apply the proposed
process. These features offer important
framework to an education and training
advantages in improving patient compliance.
chatbot, the Virtual Sleep Coach (VSC), for
For example, a key behavioral principle
improving sleep through Cognitive Behavior
of CBT-I is stimulus control (Perlis et al.,
Therapy for Insomnia (CBT-I). Like other
2005), in which the experience of being in
behaviour therapies, CBT-I is highly
bed must be limited to sleeping (and/or sex).
structured, such that the therapist follows an
Instead, those with insomnia often learn to
evidence-based manual, which outlines a
associate being in bed with anxiety,
prescribed protocol for training the patient
including worrying about being awake. The
to improve sleep habits and practices.
discipline to get out of bed when not
Although it is typically administered by a
sleeping is very challenging. It often
clinical psychologist, the principles are
requires the CBT-I therapist to work
easily understood by physicians and
carefully with the patient to understand and
healthcare professionals in general, so an
commit to difficult behaviour changes.
LLM-based CBT-I chatbot can become a
Whereas a phone app is not suited to this
cost-effective method for teaching patients
kind of structured yet compassionate
about the therapy principles as well as
interpersonal interaction, we propose that
instructing them on the sequential training
well-programmed LLMs can be highly
goals. Although CBT-I software apps are
successful with the necessary therapeutic
10
interaction to improve patient understanding insensitive, or harmful. To ensure unbiased
and compliance, thus achieving real and evaluation, a second independent expert
perceptible therapeutic progress. CBT-I therapist rated all three responses on
a 1-5 scale to assess the proportion of VSC
3.3. Human Expert Validation Study of the responses that were appropriate versus
Virtual Sleep Coach inappropriate. Each of the two CBT-I
therapists evaluated 50 queries and rated a
Once the Therapist-Supervisor
total of 150 responses (50 VSC-generated,
prompting protocol for the VSC was
50 appropriate CBT-I therapist responses,
established, we designed a validation study
and 50 inappropriate CBT-I therapist
in which expert CBT-I therapists evaluated
responses), with the order of the responses
the VSC responses in a blind format in
randomized for each query (Supplementary
which the CBT-I therapist did not know
Table 1).
whether the response was generated by a
human or the VSC. The experienced CBT-I
4. Results
therapists rated each response on a 1-to-5
Lykert scale (1 = potentially harmful, 2 = Consistent with the literature on LLM
inappropriate or irrelevant, 3 = adequate but prompt engineering, we have observed that
inexpert, 4 = adequate to the therapeutic the LLM’s responses are highly sensitive to
context, and 5 = consistent with expert the context for the communication conveyed
therapy). Patient queries (N = 100) were by the prompt. Thus, simply assigning the
generated by two clinical psychologists Supervisor role to the LLM’s responses,
experienced with patient interactions in without any specific prompt to be sensitive
psychotherapy and behavior therapy to the patient’s intentions, resulted in the
settings. The queries were based on typical Supervisor agent making a more careful,
patient queries illustrated in this study's two accurate interpretation of the patient’s
CBT-I therapist manuals (Perlis, Jungquist, intended meaning than was initially
Smith, & Posner, 2005; Taylor et al., 2019). provided by the Therapist agent. The
Ten queries were generated relevant to the following example (also Supplementary
introduction of CBT-I, and fifteen were Table 2) illustrates this sensitivity the LLM
generated for each of the six typical CBT-I showed to the context of the patient’s
sessions, resulting in 100 representative response implied by taking the Supervisor
patient queries. The typical CBT-I sessions role.
deal with the sleep diary and sleep baseline
recording, stimulus control (using the bed Patient Query: "I often
only for sleep or sex), sleep restriction, have something on my
relaxation training, and cognitive mind that I worry about.
restructuring for worry and concerns that How can I stop
interfere with sleep. worrying?”
For each query, three responses were
generated: one by the VSC, monitored and Therapist agent
corrected by the Supervisor agent before Response: "To stop
presentation to the patient; a second worrying, try not to fall
appropriate response by an experienced asleep while worrying as
CBT-I therapist; and a third inappropriate it can interfere with
response also by a CBT-I therapist, which sleep. Turn on the light,
could be irrelevant, non-therapeutic, leave the bedroom, and
11
engage in a different address your worries,
activity like reading a and setting aside specific
book to distract yourself. 'worry time' during the
Avoid stimulating day. Additionally,
activities before bed. Put practicing mindfulness
the clock under the bed and grounding
or out of sight to prevent techniques can help you
clock watching, which stay present and reduce
can lead to frustration anxious thoughts. It's
and interfere with sleep. important to address
Avoid taking naps worrying during daytime
during the day to help hours to prevent it from
you fall asleep at night. interfering with your
Practicing relaxation sleep at night.”
techniques may also help
alleviate worrying and The Therapist agent's initial response in
promote better sleep.” this instance focused on improving sleep
hygiene, which indirectly addresses
Supervisor agent worrying but does not directly offer
feedback: "Therapist's strategies for managing or halting worrying
RESPONSE seems to be thoughts during waking hours. In contrast,
wrong. The response the Supervisor agent provided a revised
provided information on response emphasizing cognitive
how to improve sleep restructuring, problem-solving, designated
hygiene and address 'worry time,' mindfulness, and grounding
insomnia, rather than techniques. This feedback aimed to ensure
directly addressing the the response directly addressed the patient's
issue of how to stop query on how to stop worrying, aligning
worrying. While more closely with the patient's needs for
improving sleep can managing daytime anxiety.
indirectly help reduce The results in Figure 4A present the 1-5
worrying, it does not Likert scale ratings for responses to 100
directly address patient queries: “Appropriate” CBT-I
techniques for managing therapist-generated responses (mean ± std:
or stopping worrying 4.071 ± 0.828), VSC-generated responses
thoughts.” (4.327 ± 0.883), and “Inappropriate” CBT-I
therapist-generated responses (1.847 ±
Supervisor agent 0.923). As anticipated, most “Appropriate”
Response: “To stop CBT-I therapist responses were rated 4 or 5
worrying during the day, by another CBT-I therapist (Figure 4A, left).
you can try cognitive Unexpectedly, the VSC-generated
restructuring techniques appropriate responses received even higher
like identifying and ratings from the blind CBT-I therapist
challenging negative (Figure 4A, middle), with very few
thoughts, engaging in inappropriate ratings, indicating a
problem-solving to statistically significant difference from
12
“Appropriate” responses (two-tailed t-test, p observed in Figure 4B, with VSC responses
= 0.044). Consistent with expectations, the being rated more favorably overall.
CBT-I therapist-generated “Inappropriate” The higher ratings of the VSC
responses mainly were rated as responses might be attributed to the length
inappropriate (Figure 4A, right). of the responses. On average, the VSC-
Figure 4B shows the cumulative generated responses were longer than the
distribution of difference scores between human therapists (419.58 ± 136.59 vs
VSC-generated and CBT-I therapist- 243.51±81.98 characters; t-test p=0.0038).
generated appropriate responses, reflecting These longer responses could have been
the distributions seen in Figure 4A, with a perceived as more comprehensive or
greater number of positive scores (indicating enhanced, contributing to the higher ratings.
higher ratings for VSC responses). Figure To control for the effect of the response
4C similarly displays the distribution of length, we performed an analysis of
difference scores, corroborating the trend covariance. The main effect of response type
(‘Appropriate’ vs. VSC) on therapist ratings
Figure 4. A. Number of responses (total = 100) rated (1 = potentially harmful, 2 = inappropriate or
irrelevant, 3 = adequate but inexpert, 4 = adequate to the therapeutic context, and 5 = consistent with
expert therapy) for each of the sources (CBT-I therapist generated to be appropriate, VSC generated,
and CBT-I therapist generated to be inappropriate). B. Cumulative distribution of the difference
between VSC responses and therapist appropriate responses. C. Difference between ratings of CBT-I
therapist appropriate and VSC responses.
13
was not statistically significant after reasoning, which evolves from cumulative,
controlling for response length (p-value = Bayesian experiences rather than formal
0.895). The covariate, response length, was rules. This is analogous to statistical
found to be a significant predictor of learning in developmental psychology,
therapist ratings, indicating that the length of where predictive concepts are formed from
the response has a significant impact on the concrete experiences (Posner & Keele,
ratings. 1968; Rosch, 1975; Saffran & Kirkham,
2018).
Drawing from active inference
5. Discussion
principles, programming LLMs with distinct
The extensive information within
actor and critic roles aligns with natural
general-purpose LLMs can provide relevant
human linguistic associations. The actor role
and useful medical information but may also
in human cognition operates in a
produce meaningless, inappropriate, or
feedforward manner, generating
harmful responses due to the inclusion of
expectations, while the critic role corrects
inaccurate data. A simple strategy to
errors through feedback (Friston, 2008; Luu,
mitigate this risk is the RAG method, which
Tucker, & Friston, 2023; Tucker & Luu,
restricts the knowledge base to verified
2021). This structured approach harnesses
medical information. In our study, the VSC
the creative potential of LLMs while
generated responses based on well-known
limiting inappropriate responses in medical
CBT-I manuals (Perlis et al., 2005; Taylor et
contexts.
al., 2019), ensuring the responses were
The inherent sensitivity of the LLM to
aligned with typical CBT-I therapist
the implicit interpersonal perspective of a
guidance.
supervisor illustrates the complex implicit
To further ensure the appropriateness of
human psycholinguistic information that is
VSC responses, we implemented an actor-
integral to the LLM corpus and is therefore
critic architecture. The Therapist role
reflected by the simple associational
generated the initial response, which was
adjacency of human language captured by
then reviewed by the Supervisor role for
the LLM. Humans do not restrict their
accuracy and relevance. This dual-pass
interpretations to the explicit statements in
system adds a layer of redundancy and
conversations, but they rather infer the
quality control. Literature on active
intention of the speaker. This is a well-
inference suggests human reasoning
known capacity of human linguistic
involves a creative generation phase
inference described as Gricean implicature
balanced by error correction through
(Grice, 1957). The fact that an LLM
environmental feedback (Bastos et al., 2012;
recognizes that a therapist Supervisor agent
Friston, 2008; Tucker & Luu, 2023). We
must be sensitive to the patient’s intention,
propose that the separation of actor
and not only their explicit utterance, points
(Therapist) and critic (Supervisor) roles in
to the complexity of human linguistic
LLMs mirrors this cognitive process,
reasoning that can — with appropriate
optimizing response generation while
prompting — be coaxed from the LLM.
minimizing errors.
This observation may be consistent
The rationale behind this strategy is
with our general interpretation that the
rooted in neuropsychological theories of
structure of active inference, differentiating
human learning. LLMs, developed from vast
the roles of generating responses versus
linguistic associations, exhibit a form of
critically validating them, is inherent to
inferential reasoning similar to human
14
natural human linguistic reasoning. 2012. Canonical microcircuits for predictive
Separating the roles of the responding coding. Neuron, 76(4), 695-711.
Therapist and the critical Supervisor, and
Chen, X., Lin, M., Schärli, N., & Zhou, D.
then integrating them within the response
(2023). Teaching Large Language Models to
given to the person (patient or physician) by
Self-Debug. ArXiv, abs/2304.05128. Gilbert, S.,
the VSC leads to well-formed and accurate
Harvey, H., Melvin, T., Vollebregt, E., & Wicks,
responses to the patient’s queries. The
P.2023. Large language model AI chatbots
patient sees only the final responses, but
require approval as medical devices. Nature
both Therapist and Supervisor responses are medicine, 1-3.
logged for each session and can be reviewed
by the human responsible for the accurate Creswell, A., White, T., Dumoulin, V.,
performance of the VSC. Arulkumaran, K., Sengupta, B., & Bharath, A.
Our study tested this approach using A.2018. Generative adversarial networks: An
overview. IEEE signal processing magazine,
Meta LLaMa 2, generating responses to
35(1), 53-65.
queries typical of CBT-I sessions. Blind
ratings by trained CBT-I therapists indicated
Friston, K. 2008. Hierarchical models in
that LLM responses were consistently
the brain. PLoS Comput Biol, 4(11), e1000211.
appropriate, often more so than those of
human therapists. This may be attributed to Gilbert, S., Harvey, H., Melvin, T.,
the LLM responses being longer and closely Vollebregt, E., & Wicks, P. 2023. Large
aligned with the CBT-I manuals. language model AI chatbots require approval as
The key finding is that restricting LLM medical devices. Nature medicine, 1-3.
responses to a specific knowledge domain
Grice, P. 1957. Meaning. Philosophical
and implementing a secondary evaluation
Review, 66, 377-388.
layer ensures relevance and appropriateness
in medical applications. While further
Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu,
research is needed to refine LLM design and
Z., Li, Y., Wang, S., . . . Chen, W. 2021. Lora:
prompting strategies for medical domains, Low-rank adaptation of large language models.
our results suggest that even basic arXiv preprint arXiv:2106.09685.
precautions can enable powerful, validated
knowledge delivery technologies, potentially Ke, P., Wen, B., Feng, Z., Liu, X., Lei, X.,
supporting FDA and other regulatory Cheng, J., Wang, S., Zeng, A., Dong, Y., Wang,
H., Tang, J., & Huang, M. (2023). CritiqueLLM:
approvals for routine medical use.
Scaling LLM-as-Critic for Effective and
Explainable Evaluation of Large Language
References Model Generation.
Adams, R. A., Shipp, S., & Friston, K. J. http://arxiv.org/abs/2311.18702
2013. Predictions not commands: active
inference in the motor system. Brain Structure Lewis, P., Perez, E., Piktus, A., Petroni, F.,
and Function, 218(3), 611-643. Karpukhin, V., Goyal, N., Küttler, H., Lewis,
M., Yih, W., Rocktäschel, T., Riedel, S., &
Asai, A., Wu, Z., Wang, Y., Sil, A., & Kiela, D. (2020). Retrieval-Augmented
Hajishirzi, H. (2023). Self-RAG: Learning to Generation for Knowledge-Intensive NLP Tasks.
Retrieve, Generate, and Critique through Self- https://doi.org/https://doi.org/10.48550/arXiv.20
Reflection. ArXiv, abs/2310.11511. 05.11401
Bastos, A. M., Usrey, W. M., Adams, R. Liu, Y., Ott, M., Goyal, N., Du, J., Joshi,
A., Mangun, G. R., Fries, P., & Friston, K. J. M., Chen, D., Levy, O., Lewis, M., Zettlemoyer,
15
L., & Stoyanov, V. (2019). RoBERTa: A Rao, R. P., & Ballard, D. H. 1999.
Robustly Optimized BERT Pretraining Predictive coding in the visual cortex: a
Approach. http://arxiv.org/abs/1907.11692 functional interpretation of some extra-classical
receptive-field effects. Nature Neuroscience,
Luu, P., & Tucker, D. M. 2023. Continuity 2(1), 79-87.
and change in neural plasticity through
embryonic morphogenesis, fetal activity- Shinn, N., Labash, B., & Gopinath, A.
dependent synaptogenesis, and infant memory (2023). Reflexion: an autonomous agent with
consolidation. Developmental Psychobiology, dynamic memory and self-reflection. ArXiv,
65(8), e22439. abs/2303.11366.
Luu, P., Tucker, D. M., & Friston, K. 2023. Su, W., Tang, Y., Ai, Q., Wu, Z., & Liu, Y.
Vertical Integration of Motivational Control (2024). DRAGIN: Dynamic Retrieval
Across the Evolved Levels of the Human Augmented Generation based on the Real-time
Neuraxis. Cerebral Cortex. Information Needs of Large Language
Models. ArXiv, abs/2403.10081.
Miao, N., Teh, Y. W., & Rainforth, T.
(2023). SelfCheck: Using LLMs to Zero-Shot Taylor, D., Peterson, A., Goodie, J.,
Check Their Own Step-by-Step Reasoning. Grieser, E., Hryshko-Mullen, A., Rowan, A., . . .
http://arxiv.org/abs/2308.00436 Hall-Clark, B. (2019). Cognitive-behavioral
therapy for insomnia in the military: Therapist
Madaan, A., Tandon, N., Gupta, P., guide. In: University of Arizona, Tucson, AZ.
Hallinan, S., Gao, L., Wiegreffe, S., Alon, U.,
Dziri, N., Prabhumoye, S., Yang, Y., Welleck, Tucker, D. M., & Luu, P. 2021. Motive
S., Majumder, B., Gupta, S., Yazdanbakhsh, A., control of unconscious inference: The limbic
& Clark, P. (2023). Self-Refine: Iterative base of adaptive Bayes. Neuroscience &
Refinement with Self-Feedback. ArXiv, Biobehavioral Reviews, 128, 328-345.
abs/2303.17651.
Tucker, D. M., & Luu, P. 2023. Adaptive
Meskó, B., & Topol, E. J. 2023. The control of functional connectivity: dorsal and
imperative for regulatory oversight of large ventral limbic divisions regulate the dorsal and
language models (or generative AI) in ventral neocortical networks. Cerebral Cortex,
healthcare. npj Digital Medicine, 6(1), 120. 1-26.
Minssen, T., Vayena, E., & Cohen, I. G. Trivedi, T., Balasubramanian, N., Khot, T.,
2023. The Challenges for Regulating Medical & Sabharwal, A. 2023. Interleaving retrieval
Use of ChatGPT and Other Large Language with chain-of-thought reasoning for knowledge
Models. Jama. intensive multi-step questions. Proceedings of
the 61st Annual Meeting of the Association for
Perlis, M. L., Jungquist, C., Smith, M. T., Computational Linguistics 1, 10014-10037
& Posner, D. 2005. Cognitive behavioral
treatment of insomnia: A session-by-session Weng, Y., Zhu, M., Li, B., He, S., Liu, K.,
guide (Vol. 1): Springer Science & Business & Zhao, J. (2022). Large Language Models are
Media. reasoners with Self-Verification. ArXiv,
abs/2212.09561.
Press, O., Zhang M., Min, S., Schmidt, L.,
Smith, N. A., and Lewis, M. 2023. Measuring Yan, S., Gu, J., Zhu, Y., & Ling, Z. (2024).
and narrowing the compositionality gap in Corrective Retrieval Augmented
language models. Findings of the Association Generation. ArXiv, abs/2401.15884
for Computational Linguistics: EMNLP.
16
Supplemental Materials
Table 1: Examples of ten generated queries, “Appropriate” and “Inappropriate” responses
generated by one clinical therapist, “VSC” generated response and 3 ratings of the three
responses by the second therapist.
Q: What is the evidence that following Good Sleep Practices
really works?
A1: CBT-I can be so impactful that it is actually the first line of Appropriate 3
treatment recommended by the National Sleep Foundation.
A2 : Following good sleep practices, such as those outlined in sleep VSC 5
hygiene instructions, has been supported by evidence in improving
sleep quality. These practices help consolidate and deepen sleep,
regulate sleep onset, and maintain a regular sleep schedule.
Creating a comfortable sleep environment and avoiding disruptive
behaviors like napping can positively impact sleep quality. Exercise
and proper nutrition also contribute to better sleep. Additionally,
stimulus control techniques, like leaving the bedroom when awake,
have shown to influence the sleep homeostat and improve sleep
through classical conditioning
A3 : It`s a shot in the dark, we aren`t really sure if it work. Inappropriate 1
Q: My sleep problem bothers me because it makes me tired and not
feel good, but it doesn`t affect my work or relationship. Do I have
insomnia?
A1: Based on the information provided, insomnia is typically VSC 5
associated with complaints such as fatigue, irritability, problems
with attention and concentration, and distress related to sleep
difficulties. While your sleep problem may not impact your work or
relationships, if you are experiencing these symptoms, it may still
be worth addressing with a healthcare provider to determine the
best course of action for improving your sleep quality
A2 : That`s great to hear that it is not impacting important areas of Appropriate 5
your life. However, if your sleep issues are still causing you
distress, you may still have insomnia. The DSM defines insomnia
as followings: a sleep disturbance that occurs at least three times a
week for at least three months, and causes significant distress or
interference with personal functioning.
A3 : Nope! Insomnia must cause functional impairment for it to be Inappropriate 1
considered a disorder.
17
Q: I`ve found I sleep better if I have a glass of wine before bedtime.
Is that allowed under this program?
A1: Avoiding alcohol, especially in the evening, is recommended VSC 5
as it can cause awakenings later in the night, ultimately disrupting
your sleep. While alcohol may help some people fall asleep more
easily, it can negatively impact the quality of your sleep overall. It's
best to find alternative ways to wind down before bedtime that do
not involve alcohol to improve your sleep hygiene. If you struggle
with falling asleep, there are other strategies we can explore to help
you achieve better sleep quality.
A2 : It is typically recommended that alcohol be consumed more Appropriate 3
than 3 hours before your prescribed bedtime.
A3 : Sure! Some find a bottle of wine to work even better. Inappropriate 1
Q: How important is it for me to complete the sleep diary daily?
A1: It`s okay if you miss a few days a week. As long as there is a Inappropriate 3
general reflection of your sleep patterns across 3 days then
treatment will still work.
A2 : Adherence to the sleep diary is essential. This data is used and Appropriate 4
analyzed to offer individualized treatment recommendations for
quality sleep.
A3 : Completing the sleep diary daily is essential to track patterns VSC 5
and behaviors accurately. It helps in collecting data for analysis,
identifying factors affecting sleep, and guiding treatment decisions.
Consistent daily entries enable clinicians to assess progress and
make necessary adjustments. Missing entries may lead to
incomplete information and hinder the effectiveness of therapy.
Your commitment to daily diary completion enhances the success
of your treatment.
18
Q: I currently have a viral infection. Should I delay my CBTI?
A1: It would be best if you pushed through the infection and Inappropriate 1
continued with the program.
A2: A novel infection might not be the best time to start CBT-i. It Appropriate 4
would be most helpful to capture a typical sleep routine that is
reflective of your usual sleep patterns.
A3: It's important to consider delaying CBTI if you have a viral VSC 4
infection as your body needs rest to recover. It would be best to
consult with your healthcare provider to determine the best course
of action.
Q: Do I have to quit taking Ambien in order to try CBT-I?
A1: I recommend consulting with your healthcare provider VSC 3
regarding medication adjustments before starting CBT-I. It's
essential to discuss any changes in medication, including Ambien,
to ensure a safe and effective treatment plan. Your healthcare
provider can provide guidance on how to incorporate CBT-I while
considering your current medication regimen. If you have concerns
about medication adjustments, your healthcare provider can address
them during your consultation.
A2 : Not necessarily. You can implement behavioral sleep Appropriate 4
strategies while also taking a sleep medication simultaneously. We
can work together to assure there is no psychological dependence
on this sleep aid.
A3 : Yes, CBT-I is not compatible with any sleep aide. Inappropriate 2
19
Q: Will my anxiety get worse if I start sleep restriction?
A1: Possibly, some have a belief that sleep restriction equates to Appropriate 4
sleep deprivation. This anxiety is natural concern if you are already
not getting enough sleep. However, keep in mind that sleep
restriction is allotting you a prescribed set of hours you are already
receiving.
A2: It's understandable to have concerns about how sleep VSC 3
restriction may affect your anxiety. While sleep restriction therapy
is designed to improve sleep efficiency, it's important to discuss
any potential worsening of anxiety symptoms with your therapist.
They can help address these concerns and tailor the therapy to
ensure it supports your overall well-being.
A3: Increased anxiety with sleep restriction has never occurred Inappropriate 2
within this treatment.
Q: I find it really hard to go to bed at the prescribed time. What
should I do?
A1: If you find it hard to go to bed at the prescribed time, try VSC 5
establishing a relaxing bedtime routine to signal your body it's time
to sleep. Avoid stimulating activities close to bedtime, such as
using electronic devices. Consider relaxation techniques like deep
breathing or meditation to help calm your mind before bed. Ensure
your bedroom is conducive to sleep by keeping it dark, quiet, and at
a comfortable temperature. If you're still having trouble falling
asleep, get out of bed and do something calming until you feel
sleepy, then return to bed.
A2 : Your prescribed bedtime is the earliest suggested time you can Appropriate 5
enter bed. If you are still not sleepy, it is recommended you stay out
of bed until this cues appear. (e.g., heavy eyes, yawning, etc)
A3 : I know it`s hard, but please try to stay in bed and force sleep Inappropriate 1
upon you.
20
Q: It`s hard for me to understand why I have to restrict my sleep
time more when I have problem sleeping.
A1: The importance of sleep restriction is first address quality. Appropriate 4
When compressing sleep with sleep restriction, it offers the body
the chance to go through a natural sleep cycle and receive the
deeper stages. If quality sleep improves, the next step is to add time
back to your earliest bedtime for sleep quantity to improve.
A2: Sleep restriction therapy aims to consolidate your sleep by VSC 5
limiting the time you spend in bed to match your actual sleep time.
By restricting your time in bed, you can improve sleep efficiency
and reduce the time spent awake in bed. Initially, this may lead to
mild sleep loss, but it can help enhance your sleep drive and
strengthen the association between being in bed and sleeping. The
goal is to improve the quality and efficiency of your sleep so that
you can experience better restorative sleep in the long run. It's a
structured approach to help regulate your sleep patterns and
improve overall sleep quality.
A3: We need to induce sleep deprivation so that you eventually Inappropriate 1
break.
Q: At this point, is a sleep study, with EEG, a good thing for me?
A1: It is recommended that a sleep study be pursued after Appropriate 3
attempting CBT-i. If you notice insomnia symptoms are improving,
but you continue have significant daytime fatigue, it may be time to
schedule that appointment.
A2 : EEGs are very dangerous and should not be scheduled to Inappropriate 1
protect your brain health.
A3 : A sleep study, specifically polysomnography (PSG) with VSC 3
EEG, can be beneficial for you at this point. It provides detailed
information on different sleep stages, including deep sleep and
dream sleep, which can help in understanding your sleep patterns
and potential issues like insomnia. By objectively measuring brain
activity during sleep, PSG can identify any underlying sleep
disorders. It is considered the 'gold standard' in sleep research and
can provide valuable insights for developing an effective treatment
plan. However, the decision to undergo a sleep study should be
made in consultation with a healthcare provider who can assess
your individual needs and recommend the most appropriate course
of action.
21
Table 2: Examples of the « Therapist » agent responses to patient queries and « Supervisor »
agent correction when needed.
Query 1: I often have something on my mind that I worry about. How can I stop
worrying?
Therapist Response: To stop worrying, try not to fall asleep while worrying
as it can interfere with sleep. Turn on the light, leave the bedroom, and
engage in a different activity like reading a book to distract yourself. Avoid
stimulating activities before bed. Put the clock under the bed or out of sight to
prevent clock watching, which can lead to frustration and interfere with sleep.
Avoid taking naps during the day to help you fall asleep at night. Practicing
relaxation techniques may also help alleviate worrying and promote better
sleep.
Supervisor feedback: Therapist's RESPONSE seems to be wrong. The response
provided information on how to improve sleep hygiene and address insomnia, rather
than directly addressing the issue of how to stop worrying. While improving sleep
can indirectly help reduce worrying, it does not directly address techniques for
managing or stopping worrying thoughts.
Supervisor Response: “To stop worrying during the day, you can
try cognitive restructuring techniques like identifying and
challenging negative thoughts, engaging in problem-solving to
address your worries, and setting aside specific 'worry time' during
the day. Additionally, practicing mindfulness and grounding
techniques can help you stay present and reduce anxious thoughts.
It's important to address worrying during daytime hours to prevent it
from interfering with your sleep at night.”
Query 2: Is it ok for me to lay in bed, say during the day, and just scroll on my
tablet and relax?
Therapist Response: It's not recommended to engage in non-sleep activities
in bed, even during the day. It's best to reserve the bed for sleep and intimacy
only. Stimulus control instructions suggest leaving the bed if you're awake for
more than 15 minutes. Relaxing activities like scrolling on your tablet can
hinder the association between bed and sleep. It's advised to find a different
spot for activities like reading or using electronic devices to help improve
sleep quality.
Supervisor feedback: The therapist`s RESPONSE is not exactly what I would
expect. The provided response does not directly address the patient's question about
whether it's okay to scroll on a tablet in bed during the day. The response should
22
focus more on the importance of maintaining the association between bed and sleep
by avoiding non-sleep activities in bed.
Supervisor Response: It's not recommended to engage in non-sleep
activities in bed, even during the day. It's best to reserve the bed for
sleep and intimacy only. Stimulus control instructions suggest
leaving the bed if you're awake for more than 15 minutes. To
improve sleep quality, it's advised to find a different spot for
activities like reading or using electronic devices.
Query 3: Have you ever had sleep problems yourself?
Therapist Response: I am trained to answer questions related to behavioral
therapy for insomnia.
Supervisor feedback: The therapist`s RESPONSE is not exactly what I would
expect. The trainee's response does not directly address the patient's question about
personal experience with sleep problems
Supervisor Response: While I haven't personally experienced sleep
problems myself, I have extensive training and knowledge in
helping individuals with insomnia through behavioral therapy.
Query 4: How much exercise should I get to help me sleep?
Therapist Response: You should aim to exercise regularly, but avoid doing
so within 3 hours of bedtime. Regular exercise can help make it easier to
initiate sleep and deepen your sleep. It's important to schedule your exercise
times earlier in the day to avoid interfering with your sleep onset. Remember
that consistency is key in establishing a healthy sleep routine.
Supervisor feedback: The therapist`s RESPONSE is good.
Query 5: Can I rely on data from my apple watch to log entries in my diary?
Therapist Response: I'm trained to answer only questions related to
behavioral therapy.
23
Supervisor feedback: The therapist`s RESPONSE is not exactly what I would
expect. The trainee's response does not directly address the patient's question about
relying on data from an Apple Watch to log entries in a diary.
Supervisor Response: While technology like Apple Watches can
track sleep-related data, it may not always be accurate or
comprehensive for logging entries in a sleep diary. It's
recommended to use a combination of technology and traditional
methods to ensure thorough tracking of sleep patterns.
Query 6: Is it OK to take a nap during the day?
Therapist Response: Avoiding naps during the day can help improve
nighttime sleep quality. Napping may lead to longer sleep latency at night. It's
recommended to stay awake during the day to facilitate falling asleep at night.
Napping behavior may need to be modified or eliminated to address insomnia
symptoms. Consider adjusting your daytime activities to support better
nighttime sleep.
Supervisor feedback: The therapist`s RESPONSE is good
Query 7: This week I tried to stay up like you suggested but I just fell asleep
watching TV and then woke up at 3 am. What am I supposed to do?
Therapist Response: It sounds like staying up didn't work as planned. If you
find yourself falling asleep unintentionally, it's best to try a different
approach. Instead of trying to stay up, focus on establishing a relaxing
bedtime routine. Avoid stimulating activities before bed, such as watching
TV. Try reading a book or listening to calming music to help you wind down.
If you wake up in the middle of the night, avoid looking at the clock and try
some relaxation techniques to help you drift back to sleep. Remember,
consistency is key in improving your sleep patterns.
Supervisor feedback: The therapist`s RESPONSE is good
Query 8: I read that traffic accidents are often caused by people who fall asleep.
Aren`t I at risk of a crash when I`m restricting sleep in this therapy?
Therapist Response: It's understandable to have concerns about sleep
restriction therapy and its impact on your safety. However, the therapy is
24
carefully structured to ensure that you still get a safe amount of sleep. By
limiting your time in bed to match your average total sleep time, you're likely
to experience improved sleep quality and reduced daytime sleepiness,
decreasing the risk of accidents due to drowsiness. If you have specific
concerns about safety or driving, it's important to discuss them with your
therapist for personalized guidance.
Supervisor feedback: The therapist`s RESPONSE seems to be wrong because it
doesn't directly address the patient's concern about the risk of traffic accidents due to
sleep restriction in therapy.
Supervisor Response: It's important to acknowledge your concerns about the
risk of traffic accidents due to sleep restriction in therapy. While sleep restriction
therapy is carefully structured to ensure you still get a safe amount of sleep, it's
essential to prioritize safety. Discussing any specific concerns you have about
safety or driving with your therapist can help tailor the therapy to address these
issues and ensure your well-being.
Query 9: Of all the patients you`ve seen, how many fail the therapy completely?
Am I the only one who has such a problem?
Therapist Response: I don't have access to individual patient data or records,
so I can't provide specific numbers on therapy outcomes. Each individual's
response to therapy can vary. It's common for some patients to face
challenges during therapy, and you are not alone in experiencing difficulties.
It's important to remember that progress in therapy can fluctuate, and setbacks
are a normal part of the process. If you're finding therapy challenging, it
might be helpful to discuss your concerns with your therapist.
Supervisor feedback: The therapist`s RESPONSE is good.
Query 10: Now that I`m sleeping better, can I stay up late sometimes on the
weekend?
Therapist Response: It's essential to maintain a consistent sleep schedule,
including on weekends, to support your circadian rhythm. Staying up late can
disrupt your progress in improving your sleep patterns. Consistency in sleep
timing is crucial for long-term benefits. It's advisable to stick to your regular
sleep schedule to continue experiencing better sleep.
Supervisor feedback: The therapist`s RESPONSE is good.
25

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "An Active Inference Strategy for Prompting Reliable Responses from Large Language Models in Medical Practice"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
