=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics
Citation Key: tinguy2025bioinspired
Authors: Daria de Tinguy, Tim Verbelen, Emilio Gamba

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: navigation, fully, autonomous, adaptability, mapping, training, localisation, existing, inference, topological

=== FULL PAPER TEXT ===

Bio-InspiredTopologicalAutonomousNavigationwithActiveInferenceinRobotics
DariadeTinguy1∗,TimVerbelen2,EmilioGamba3,BartDhoedt1
1GhentUniversity,Ghent,Belgium
(daria.detinguyatugent.be
2Verses,LosAngeles,California,USA,
3FlandersMake,Leuven,Belgium,
∗Correspondingauthor
Abstract: Achieving fully autonomous exploration and navigation remains a critical challenge in robotics, requiring
integrated solutions for localisation, mapping, decision-making and motion planning. Existing approaches either rely
on strict navigation rules lacking adaptability or on pre-training, which requires large datasets. These AI methods are
often computationally intensive or based on static assumptions, limiting their adaptability in dynamic or unknown en-
vironments. This paper introduces a bio-inspired agent based on the Active Inference Framework (AIF), which unifies
mapping,localisation,andadaptivedecision-makingforautonomousnavigation,includingexplorationandgoal-reaching.
Ourmodelcreatesandupdatesatopologicalmapoftheenvironmentinreal-time,planninggoal-directedtrajectoriesto
exploreorreachobjectiveswithoutrequiringpre-training. Keycontributionsincludeaprobabilisticreasoningframework
forinterpretablenavigation, robustadaptabilitytodynamicchanges, andamodularROS2architecturecompatiblewith
existing navigation systems. Our method was tested in simulated and real-world environments. The agent successfully
exploreslarge-scalesimulatedenvironmentsandadaptstodynamicobstaclesanddrift,provingtobecomparabletoother
explorationstrategiessuchasGbplanner,FAELandFrontiers. Thisapproachoffersascalableandtransparentapproach
fornavigatingcomplex,unstructuredenvironments.
Keywords: autonomousnavigation,bio-inspired,activeinference,exploration,zero-shotlearning,cognitivemap
1. INTRODUCTION tations: they either depend heavily on prior knowledge,
require substantial training, or struggle to adapt in real
The transition toward fully automated factories re-
timetounexpectedchanges. Thismotivatestheneedfor
quires robots capable of autonomously exploring and
frameworksthatarebothadaptiveanddata-efficient,ca-
navigating their environments, a key challenge in
pable of operating without pre-training, and resilient in
robotics.
partiallyobservable,dynamicenvironments.
To navigate effectively, an agent must gather and in-
terpret sensory data (e.g., LiDAR, cameras) to perceive TheActiveInferenceFramework(AIF),rootedinneu-
its surroundings, adapt to environmental changes, and roscience,offersapromisingalternativebyframingnav-
optimise its motion strategy to minimise computational igation as a predictive inference process. Our model,
power and maximise coverage efficiency. Addressing inspired by AIF principles, operates in a zero-shot, on-
these challenges is essential for achieving robust, scal- line fashion, continuously learning from incoming sen-
able, and adaptive robotic navigation in large, dynamic sorydatawithoutrequiringpriortraining. Thisallowsit
environments. tolocalise,map,andplanefficientlyinenvironmentsthat
arenew,visuallyambiguous,anddynamic.
Therearemanyapproachestotacklethechallengesof
autonomous navigation. Hard-coded or heuristic-based
Ourcontributionsareasfollows.
methods [1], [2] are easily interpretable and computa-
tionally cheap but often struggle with dynamic or un-
structured environments due to their rigidity. Classi- • Novel Perspective in Robotics: We present an inte-
cal SLAM-based approaches [3], [4] provide high ac- grated model that combines mapping, localisation, and
curacy in static settings, yet are sensitive to drift and decision-makingusingActiveInference,enablingrobots
mayscalepoorlyinlargerenvironments. Learning-based tonavigatewithoutpre-training.
methods [5], [6], [7] perform well in familiar and struc- • Dynamic Adaptability: The model continuously up-
tured scenarios, but require extensive pre-training and dates its internal map and beliefs. The agent adapts to
tend to generalise poorly to novel or unexpected condi- changeswithoutrequiringpreprogrammedrules.
tions. Bioinspired approaches [8], [9], [10] aim to im- • Goal-Oriented Learning: It contains a goal-directed
proveadaptabilityinuncertainsettingsbymodellingnav- learningmechanismthatallowstherobottoprioritiseex-
igationthroughcognitiveortopologicalmaps. However, plorationorgoalreaching,giveninternalsettings.
thesemethodsoftensufferfromcomputationalcomplex- • Modulable Architecture: The system is developed as
ity and have limited deployment in real-world applica- asetofmodulesinROS2,allowingseamlessintegration
tions. withexistingroboticplatformsandenablingadaptability
tovarioussensorconfigurations.
Despite their strengths, these approaches share limi-
5202
guA
01
]OR.sc[
1v76270.8052:viXra
2. RELATEDWORKS probabilisticgenerativemodel. InspiredbyActiveInfer-
ence, thesystemcontinuouslyupdatesitsinternalrepre-
Autonomousnavigationhasbeenaddressedthrougha
sentationbasedonpartialsensoryobservations, inferred
range of methods, each targeting aspects like mapping,
beliefs, and expected outcomes of future actions. This
localisation, and path or motion planning. Traditional
sectiondescribesthecorecomponentsofourmodel, in-
methods often rely on hard-coded heuristics or well-
cludingenvironmentmapping,mapexpansion,decision-
establishedalgorithmssuchastheDynamicWindowAp-
making, and obstacle handling. We also detail the sys-
proach or frontier-based exploration [1], [11], offering
tem’s architecture and implementation within the ROS2
computational efficiency and interpretability but lacking
framework, highlighting how its modular structure sup-
adaptabilityindynamicorunstructuredsettings[2].
ports generalisation across different robotic platforms
Metric SLAM-based systems [3], [4], [12] remain a
andsensorconfigurations.
cornerstoneinrobotics;theyprovidepreciselocalisation
and mapping, particularly in static environments. How- 3.1MappingtheEnvironment
ever,theyarepronetodriftandmayscalepoorlywithen- Acognitivemapreferstoaninternalrepresentationof
vironmental complexity. To overcome these limitations, spatialknowledge,enablingagentstonavigateandinter-
bio-inspiredtopologicalmethodslikeRatSLAM[8]and prettheirsurroundings[20],[21],[22],[23]. Inrobotics,
G-SLAM[9]usegraph-basedrepresentations,whichare this concept aligns with topological graphs. Our model
memory-efficient and robust to perceptual aliasing. De- buildssucharepresentationasagraph,whereeachnode
spite this, they often struggle in dynamic environments correspondstoapossiblestatedefinedbytheagent’sbe-
due to their reactive nature. Learning-based techniques lievedposeandsensoryobservations. Statecertaintyde-
such as Neural-SLAM [5], RECON [7], and BYOL- pendsonhowwellcurrentobservationsmatchtheagent’s
Explore [6] perform well in structured, familiar settings belief. This topological structure allows for memory-
butrequireextensivepre-trainingandlargedatasets,lim- efficient scalability to large environments. To manage
iting generalisability. These systems often act as black the computational cost of long-term action prediction,
boxes, complicating interpretability and online adapta- we combine Active Inference with a Monte Carlo Tree
tion. Meanwhile, model-based control strategies using Searchalgorithm[24].
ModelPredictivePathIntegral(MPPI)[13], [14]enable Toimprovetheinternalmapoftheagent,representing
accurate planning but are computationally intensive and how the robot can navigate the environment, our model
reliant on precise models. Hybrid methods combining adjustsitsparameterstominimiseFreeEnergy,aconcept
planningwithlearnedpriors[15]showpromisebutface in Active Inference (AIF) [16]. AIF posits that action
challenges in real-time, general-purpose navigation. To and perception aim to minimise an agent’s Free Energy,
address these limitations, we propose a model based on acting as an upper limit to surprise. Generative mod-
the Active Inference Framework (AIF) [16], which uni- els are central to active inference, as they encapsulate
fies mapping, localisation, and planning through predic- causal relationships among observable outcomes, agent
tive belief updating. Active inference treats navigation actions,andhiddenenvironmentalstatesinalatentspace.
asacontinualprocessofpredictionandbeliefupdating, These environmental states remain ’hidden’ as they are
minimisingsurpriseabouttheenvironment. Thisleadsto shielded from the agent’s internal states by a Markov
agentsthatarebothreactiveandanticipatory,capableof blanket [25]. Leveraging partial observations, the agent
adaptinginrealtimetoambiguousconditions. Although constructs its own beliefs regarding hidden states, en-
AIF has been applied conceptually to navigation [17], ablingactionselectionandsubsequentobservationtore-
[18],therearefewimplementationsinrobotics[19],[9]. fineitsbeliefsrelyingonthePartiallyObservableMarkov
These typically depend on past observations and/or pre- Decision Model (POMDP) [26]. Our POMDP is pre-
training,makingthemsensitivetoenvironmentalchanges sentedFigure1.
andlesssuitedforexploringunknownareas. The active inference framework also defines how to
Our model extends this by constructing a topological updatemodelparametersinresponsetonewevidencein
map that combines past experiences with forward pre- a changing environment. The generative model of our
dictions of unexplored regions [10]. It can infer possi- modelisdefinedinEquation(1),wherethecurrentstate
ble navigable spaces (e.g., behind doorways) and plan s andpositionp areinferredbasedonthepreviousstate
t t
accordingly without prior training. With its zero-shot, s ,positionp andactiona leadingtothecurrent
t−1 t−1 t−1
online learning design, the model continuously updates observationo . ThejointprobabilitydistributionP isde-
t
itsinternalrepresentationbasedonreal-timesensoryin- finedovertimesequencesofstates,observations,andac-
put. This compositional and interpretable structure al- tionswithTildes(˜)denotingsequencesovertime.
lows robust navigation in dynamic, partially observable
P(o˜,s˜,p˜,a˜)=P(o |s )P(s )P(p )
environmentswhilesupportingmodularityandrealworld 0 0 0 0
deployment. (cid:89) τ
P(o |s )P(s ,p |s ,p ,a )
t t t t t−1 t−1 t−1
3. METHOD t=1
(1)
Our method enables an autonomous agent to build Our model works with the following essential distri-
andnavigateacognitivemapofitsenvironmentusinga butions:
(a)5m2ofrealenvironment (b)280m2simulatedwarehouse
Fig. 2.: Final map of exploration in a) a real-world en-
vironment, b) Amazon simulated warehouse. Coloured
points signify visited locations, where the same colour
Fig. 1.: Factor graph of the POMDP in our generative attributionsmeanthesameobservation. Thethicknessof
model, showing transitions from the past to the present thelinesdepictstheagent’sbelievedprobabilityoftran-
(up to time-step t) and extending into the future (time- sitioningbetweentwostatesgivenanaction.
stept+1).Pastobservationsaremarkedingreen,indicat-
ingtheyareknown. Inthefuturesteps,actionsfollowa
Torecogniselocations,inthisspecificarchitecture,the
policyπinfluencingthenewstatesandpositioninyellow
agent builds a 360° panorama from stitched images and
and new predictions in grey. The position at time t, p ,
t
compares it to stored memories using a Structural Sim-
is determined by the policy and the prior position p ,
t−1
ilarity (SSIM) threshold. If no match is found, it may
whilethecurrentstates isinferredfromtheobservation
t
either indicate a new place or an environmental change.
o , the position p , and the previous state s . Transi-
t t t−1
The agent uses its believed state s, inferred from esti-
tions between states are ruled by the B matrices, which
matedpositionpandcurrentobservationo,todetermine
definehowpriorconditionscontributetothecurrentone,
howtoupdatethemodel; theconfidenceinsisverified.
consideringtakenactions. Amatricesrepresenttheprob-
Supposeconfidenceinsexceedsasetthreshold. Inthat
abilitiesofanobservationcorrespondingtoastate.
case, it assumes correct localisation and the likelihood
matrixA growstoreceivethisobservationandassociate
o
• Statetransitions(B s ): Likelihoodoftheagentmoving it with the present state, which makes it resistant to vi-
betweenstates. sualchangessuchaslightingandperceptualaliasing(two
• Positiontransitions(B p ): Likelihoodtomovebetween similarimagesatdifferentlocations). Iflocalisationcon-
positions. fidence is lower than the set threshold, the agent priori-
• Observation likelihoods (A o ): How likely certain ob- tises re-localising by searching for familiar consecutive
servationsareateachstate. viewsbeforerecordingchangesandupdatingthemodel.
• Positionlikelihoods(A p ): Thelikelihoodofbeingina For planning, the agent uses its current pose and ob-
particularpositionateachstate. stacle data (e.g., LiDAR) to predict the outcome of ac-
Thestatesandpositionsareinferredateachtime-step tionsandupdatesitsinternalmapaccordingly. Newun-
t, while the agent perceives the observations. Those el- explored regions are added as hypothetical nodes (posi-
ementsare definedasMarkovmatrices intheagent, ex- tionp,observationounknownuntilvisited). EFEguides
cept for B , which is a tensor containing poses (tuples actionselectionviaasoftmaxoverthemodellikelihood
p
containing believed x and y coordinates) incrementally A p ,basedon:
increasingasnewonesareadded. B p isakeyelementto • Expected information gain: how well pose p explains
mapextension,aswewillexplainlater. theenvironment,consideringcollisionlikelihoodcfrom
Our model maps according to a given influence ra- o.
dius (the minimum acceptable distance between two lo- • Expectedvalue: probabilityofgettingadesiredoand
cations), which the user can freely define depending on encounteringacollisionc.
their environment. Figure 2 presents the agent’s gen- Thesefactorsjointlydrivedecision-makingunderAc-
erated map in a small real maze of 5m2and over a fully tiveInference.Locationswithuncertainobservationsnat-
mappedsimulatedwarehouseof280m2[27]. urally attract exploration, as they maximise information
gain.
3.2ExpandingtheMap
3.3DecisionMaking
The agent continuously updates its topological map
andvisualmemorybyintegratingnewsensoryinputsand Theagentnavigatesbyselectingamongdiscreteorien-
motion predictions. At each new motion, it expands the tationrangesspanningthefull360degyaw(e.g.,[0–30],
setoflocationsinB byidentifyingaccessibleareas(cur- [30–60],etc.). Thedefinitionoftheseangularsegments,
p
rentlybasedontheLiDARrange,althoughthiscouldbe as well as the inclusion of a ”STAY” action, is user-
replaced by visual cues such as door recognition [28]). configurable.ThemodelusesEFEtoguideitsnavigation
This process dynamically expands relevant matrices ac- decisions. EFE minimises expected surprise by favour-
cording to the computed Expected Free Energy (EFE) ingpoliciesincreasingthelikelihoodofencounteringpre-
overpolicies. ferredstates.Thosepreferencescanbegivenasaspecific
observation(utilityterm)orthecuriositytocomprehend
theenvironment’sstructure[18](informationgainterm).
Thisapproachfacilitatesactivelearningbyrapidlyreduc-
ing uncertainty about model parameters and enhancing
knowledgeacquisitionaboutunknowncontingencies.
At the heart of decision-making and adaptive be-
haviour lies a delicate balance between exploitation and
exploration[18].Exploitationinvolvesselectingthemost
valuableoptionbasedonexistingbeliefsabouttheworld,
while exploration entails choosing options to learn and
understandtheenvironment[29].
When the agent predicts new states and updates its (a)Agentmapwithanobstacle (b)Obstaclemovedatposition
initiallyplacedatposition(-1,0) (-1,-1).After20moresteps,the
map, depending on our agent’s objective and the weight
beforemovingitafterapartial failuretoreachthecoveredstate
between exploitation (reaching a desired objective) and exploration. reducestransitionprobabilities,
exploration(learnabouttheenvironment),theagentwill representedbythinnerlines.
prioritise locations that provide the most interesting in-
Fig.3.: Obstaclemovementanditsimpactontheagent’s
formation. Forarigorousmathematicaltreatmentofthe
internalmapduringexploration.
AIF model used here, we refer the reader to [10]. The
presentpaperfocusingmoreontheapplicationofanAIF
modeltorobotics. (state1insteadof3)becausetheagentcannotcorrectits
beliefbymovingtothatlocation. Anewstate(state20)
3.4Handlingdynamicobstacles iscreatedattheformerpositionoftheobstacle,andnew
Theagentalsodealswithobstaclesduringnavigation. transitions are established. This change does not affect
Whenanobstacleisdetectedbythelidar(likeawallor anyoftheotherexistingstates.
box)orexperimented(theagentcannotmovetowardthe
3.5AgentArchitecture
objective) the model updates its transition probabilities
betweentwostates, decreasingthelikelihoodofmoving Withourmethodestablished,wenowturntoitsimple-
into that blocked space using a Dirichlet pseudo-count mentationandevaluation. Toassessourmodel’sperfor-
updatedefinedinequation(2),withapositiveornegative manceinrealisticscenarios,weintegrateitintotheRobot
learning rate λ depending on the situation presented on OperatingSystem(ROS2)[30]. Thesystemisimagined
table1. sothateachmoduleisindependentandcanbeimproved
orreplacedindependently. Assuch,thisworkfocuseson
the model map generation and planning capacity rather
B =B +Q(s |s ,π)Q(s )∗B ∗λ (2) thanthevisualmoduleefficiencyormotionplanningflex-
π π t t−1 t−1 π
ibility. Our model is robot and sensor agnostic and was
adapted to several robots (turtlebot, turtlebot3 [31] and
Table 1.: Transition learning rate (λ) depending on the
rosbotxl [32]) with forward or 360deg lidars of various
situation
ranges,withsingle,severalcamerasora360degcamera.
Predicted Predicted Our system comprises four modules (Figure 4, grey
Transitions Possible Impossible Possible Impossible modules are meant to be replaced by any ROS-
Forward 7 -7 5 -5
compatible modules): the model, odometry, sensor pro-
Reverse 5 -5 3 -3
cessing,andmotioncontrol. Themodel’splanningrelies
Thus, our model can predict obstacles, and if an ob- onbelievedodometry(estimatedinternallybythemodel)
staclewasnotdetected(e.g.,theLiDARfailedtopickit rather than sensor-based data, avoiding issues like drift
up),itcanstillrecoverfromafailedmotion.Thelearning butresultinginapproximatepositioning. Theagentnavi-
rate of the transition matrix between two states depends gatesnottoprecisecoordinates,buttolocationsexpected
onthesituation,whetherthemodelispredictingablock- toproducedesiredobservations. Motioncontrolusesei-
age or experiencing one. Predicted motions (feasible or therNav2[33]orapotentialfield[34]tomovebetween
not) have a lower impact on the learning rate of transi- locations defined by the model. The observation mod-
tionscomparedtotransitionsthatthemodelhasdirectly ule captures panoramic views at specific locations and
experimented through motion. Figure 3 exemplifies this matchesthemtopastexperiencesbeforesendingabelief-
processwithanobstacle(e.g. abox)movedbetweentwo basedobservationtothemodel. Whilecurrentlysimple,
positions(fromposition(-1,0)to(-1,-1)overthevisited this sensor module is designed for future upgrades, par-
statenumber3)whiletheagentexploredaclusteredenvi- ticularlyinobservationandplacerecognition.
ronmentof36m2[27]with8actionrangestochosefrom.
Astheagentfailstoreachstatenumber3afterthebox
4. RESULTS
coversit,themodeladjustsitsinternalmaptoreflectthis
new reality. The transition probabilities to that location Having outlined the architecture and design of our
reduce,andthestateIDatthispositionbecomesincorrect model,wenowmovetoevaluateitsperformanceinvari-
a 3D map using UFOMap [38], and a topological graph
tonavigate;and(4)Gbplanner[39],anenhancedversion
ofthe2021DARPASubTChallengewinner[40],which
leverages a Voxblox-based [41] 3D map for topological
planning.
Sensorsetupsvariedacrossmethods: bothourmodel
and Frontiers used a 12 m-range 2D 360° LiDAR and
asinglecamera, whereasGbplanneroperatedwiththree
cameras and two 12 m-range 3D LiDARs. All experi-
mentswereperformedusingaTurtlebot3Wafflerobot.
Figure 5 shows the exploration efficiency of each
model to fully scout the environment (averaged over 5
runs). Frontiers, lacking optimised navigation, required
Fig.4.: Overviewofthesystemarchitecture. Ingrey,we
multiple passes over the same areas. Especially when
have modules that any ROS-compatible solution can re-
some small, unreachable areas have unexplored zones
place. Modules interact through belief propagation, In-
without a clear frontier. In contrast, our model and Gb-
ferring and planning (localisation, mapping and action
plannerfollowamoreefficienttrajectory(seeanexample
selection) rely on the AIF framework. The perceptual
ofourtrajectoryinFigure6). Thisdisplaysthatourbio-
andmotionplanningstillusetraditionalapproaches. Be-
inspired approach is on par with optimised exploration
lievedodometrytakesprecedenceoversensorodometry.
strategies.
Preferences(goal)areexpectedfromtheuserifwewant
toreachatargetobservation.
4.1.1Obstaclerobustness
ousenvironmentswithdiversefeaturesanddimensions. Gbplanner and our model both support dynamic re-
planning, though our approach reacts immediately to
4.1Exploringvariousenvironments
changes,eventhoseoccurringdirectlyaheadoftheagent.
We evaluate our model in four simulated environ- Gbplanner only replans after a few steps toward its ob-
ments: a mini (36m2), small (80m2) and large (280m2) jective,soitmightnotbeabletoreacttoanobstacleap-
warehouse, inspired by the Amazon Gazebo environ- pearingrightinfrontofit. Frontierstheoreticallyadapts
ment [27], featuring aisles, boxes, and industrial obsta- through its use of Nav2 SLAM, but it often struggles in
cles like forklifts; and a 156m2 home environment [35] practiceduetorelianceonfeature-basedlocalisationand
without doors, including a kitchen-living area, sports a static mapplanner. Itresults in our model beingmore
and play rooms, and a bedroom. Both settings include apt to recover from encountering a surprising or unde-
challenging objects for LiDAR-based detection, such as tectable obstacle (e.g., a curved chair base or aforklift).
curvedchairsorforklifts. Insuchcases,othermodelsfailedtoaccountforthesta-
In each scenario, the agent begins exploration from tionary motion and require an external intervention. Ta-
randominitialpositions. Sinceourmodeldoesnotcon- ble2summarisesthenumberofhumaninterventionsre-
structametricmap,werelyonLiDARrangereadingsto quiredperenvironmentoverallruns. Inallcases,thein-
associateobservationswiththeagent’sinternalrepresen- terventionsforouragentwereduetophysicallimitations
tationofnewstatelocations. (e.g.,thetworobotwheelsliftedoffthegroundafterhit-
tinganobstacle),whileothermodelsalsorequiredinter-
ventions due to an inability to consider the obstacle and
replan. FAELalsogotstuckinopenareasandrequireda
littlepushtocorrectlyconsiderLidardata.
Table 2.: Number of times the robot got stuck and re-
quiredinterventionperenvironmentoverallruns.
External
ours Gbplanner Frontiers FAEL
intervention
Miniware 0 2 3 3
Fig.5.: Explorationefficiencyindistanceoverthewhole Smallware 1 4 2 2
areaofthewarehousebyourmodel,Frontiers,FAELand Bigware 0 2 0 5
Gbplanner. Home 2 2 5 5
The agent explored the 280m2 warehouse from five Overall,bothourmodelandGbplannerdemonstrated
starting points using four different approaches: (1) our efficient exploration strategies, covering a 280m2 envi-
proposed method combining mapping, localisation, and ronment in approximately 100m travelled. Our model
planningwithNav2formotioncontrol; (2)theFrontier- exhibitedgreatrobustnessbymaintainingexplorationef-
basedexplorationalgorithm[1],implementedwithNav2 ficiency across different starting points and recovering
SLAM[36]; (3)FAEL[37]basedonFrontiers, creating fromundetectableobstacles.
4.1.2Driftrobustness
Inoneofthehomeruns,depictedinfigure6,theagent
driftedbetweentherealodometryandthebelievedodom-
etryoftheagentduetogettingstuckonfurnitureandap-
proximatingitslocalisation. Withourmodel, theexplo-
ration and goal-reaching ability is not impacted by this
shift, showing the robustness of the model to drift and
explorationefficiency. Frontiershadasimilarexperience
withanobjectthatthelidarcouldnotdetect,theodome-
tryshifted,andnav2SLAMwasnotabletorecoverfrom
this.TheusedFrontiersalgorithm[1]andGbplanner[39]
donotproposeanalternativeobjectivetoreachifnaviga-
Fig. 7.: Euclidean distance and navigated distance from
tionfails.
thestartingpositiontothegoalthroughallenvironments.
ronmentwithnohumanintervention,successfullyadapt-
ing to changes and efficiently mapping their surround-
ings. These results indicate that our approach has the
potential to be applied to industrial scenarios. By hav-
ing adaptive agents following principles inspired by an-
imal navigation, robots could learn and explore in envi-
ronments where rigid, hard-coded strategies would fail.
We envision that such robots could autonomously oper-
ateinlargereal-worldenvironments,suchaswarehouses,
Fig.6.:Driftbetweentherealodometry(dashedred)and where conditions are often variable without pre-training
the agent-believed odometry (continuous blue) during a orstrictlydefinednavigationrules.
homeexploration. Thedriftisduetoafurniturecollision
5. DISCUSSION
andlocationapproximation.
Our model uses Active Inference (AIF) to build a
4.2Reachinggivenobjective cognitive map by integrating visual observations and
The model can be given goals either as positions or estimated body position into a generative topological
RGBobservations. Itfirstdetermineswhetherthegoalis graph[45]. UnlikeexistingAIFsystemsthatrelysolely
familiar,theneitherexploresornavigatesdirectlytoit.In on past observations [46], [47], our approach predicts
these trials, RGB observations were used, and the agent possiblefuturestates,enablingproactiveandadaptiveex-
hadalreadyexploredtheenvironment,allowingcompar- ploration[48].Thisresultsinarobust,self-organisingin-
isonbetweentheagent’spathandtheidealtrajectory. ternalmapthatguidesdecision-makingwithoutrequiring
Ateachstep,theagentestimatesitspositionandisal- prior training, offering zero-shot, online learning capa-
lowedtoimaginetrajectoriesuptoaround14mtoselect bilities. Theframeworkismodular,basedonROS2[30]
the optimal action. To prioritise reaching the goal, the and fully interpretable, with decision-making grounded
explorationtermwassetto0, andthepreferenceforthe in the minimisation of expected free energy [17]. This
targetobservationwasweightedat5.Thisencouragesef- explainabilityallowsuserstotracehownavigationdeci-
ficient, goal-directed behaviour without distraction from sionsaremadeandhowpredictionsshapeexplorationor
unexplored areas. Results show that the agent reliably goal-reaching.
followsnear-optimalpaths,withminimaldeviationupto Ourmodelprovestobeasreliableinexplorationtasks
14meters. Beyonditsimaginationhorizon(i.e. therange asstate-of-the-art(GBplanner[39],FAEL[37])topolog-
withinwhichitpredictstheconsequencesofitsactions), icalplanningandmoreefficientthantraditionalmethods
itmaybrieflyexplorebeforerecalculatingadirectroute. suchasFrontiers[1],evenindynamicenvironments. Fu-
ThisisillustratedinFigure7. tureenhancementslikesemanticperception[49]orhier-
This limitation can be mitigated by applying strate- archical planning [50] could improve generalisation and
giessuchas[42]or[43],whereaweakerpreferenceora efficiency, and are meant to be integrated. More tests
statepreferenceispropagatedfromthegoaltoconnected shouldbeconductedinalargerreal-worldwarehousefor
nodes,guidingtheagentwhenthegoalisoverthepredic- exploration and goal-reaching to fully confirm those re-
tionrange. Wecouldalsodevelopsub-goalsas[44]pro- sults. Moreover, we still have to formally demonstrate
pose in their deep learning navigation model. Addition- thatourmethodiscomputationallyaffordableinrobotics
ally,theRGBobservationcouldbeassociatedwithaspe- platforms. Despitetheselimitations,ourmethoddemon-
cificposition,allowingtheagenttoassignweighttoboth strated that a biologically inspired, modular, and adapt-
the preferred position and the observation. The robots able navigation system is possible using AIF, which is
equipped with our growing cognitive map and an active promisingforreal-worldroboticapplicationsinuncertain
inferencenavigationschemecanexploreadynamicenvi- andchangingenvironments.
ACKNOWLEDGEMENT [13] I. S. Mohamed, K. Yin, and L. Liu, “Autonomous
navigation of agvs in unknown cluttered environ-
ThisresearchreceivedfundingfromtheFlemishGov-
ments: Log-mppi control strategy,” IEEE Robotics
ernment under the “Onder-zoeksprogramma Artificie¨le
and Automation Letters, vol. 7, no. 4, pp. 10240–
Intelligentie(AI)Vlaanderen”programme.
10247,2022.
[14] I. S. Mohamed, J. Xu, G. S. Sukhatme, and
L. Liu, “Towards efficient mppi trajectory genera-
REFERENCES tionwithunscentedguidance:U-mppicontrolstrat-
egy,”2024.
[1] A. Topiwala, P. Inani, and A. Kathpal, “Frontier
[15] D. An, H. Wang, W. Wang, Z. Wang, Y. Huang,
basedexplorationforautonomousrobot,”2018.
K.He,andL.Wang,“Etpnav:Evolvingtopological
[2] H. S. Hewawasam, M. Y. Ibrahim, and G. K. Ap-
planningforvision-languagenavigationincontinu-
puhamillage, “Past, present and future of path-
ousenvironments,”2024.
planningalgorithmsformobilerobotnavigationin
[16] T. Parr, G. Pezzulo, and K. Friston, Active Infer-
dynamicenvironments,”IEEEOpenJournalofthe
ence: The Free Energy Principle in Mind, Brain,
IndustrialElectronicsSociety,vol.3,pp.353–365,
andBehavior. TheMITPress,032022.
2022.
[17] R.KaplanandK.Friston,“Planningandnavigation
[3] C.Campos, R.Elvira, J.J.Gomez, J.M.M.Mon-
asactiveinference,”bioRxiv,122017.
tiel,andJ.D.Tardos,“ORB-SLAM3: Anaccurate
open-source library for visual, visual-inertial and [18] P.Schwartenbeck,J.Passecker,T.U.Hauser,T.H.
multi-mapSLAM,”IEEETransactionsonRobotics, FitzGerald, M. Kronbichler, and K. J. Friston,
vol.37,no.6,pp.1874–1890,2021. “Computationalmechanismsofcuriosityandgoal-
directedexploration,”eLife,vol.8,p.e41703,may
[4] H.Matsuki,R.Murai,P.H.J.Kelly,andA.J.Davi-
2019.
son,“Gaussiansplattingslam,”2024.
[5] D.S.Chaplot,D.Gandhi,S.Gupta,A.Gupta,and [19] O.C¸atal,T.Verbelen,T.VandeMaele,B.Dhoedt,
R.Salakhutdinov,“Learningtoexploreusingactive andA.Safron,“Robotnavigationashierarchicalac-
neuralslam,”inInternationalConferenceonLearn- tiveinference,”NeuralNetworks,vol.142,pp.192–
ingRepresentations(ICLR),2020. 204,2021.
[6] Z. D. Guo, S. Thakoor, M. Pˆıslar, B. A. Pires, [20] D. George, R. Rikhye, N. Gothoskar, J. S. Guntu-
F. Altche´, C. Tallec, A. Saade, D. Calandriello, J.- palli, A. Dedieu, and M. La´zaro-Gredilla, “Clone-
B.Grill,Y.Tang,M.Valko,R.Munos,M.G.Azar, structured graph representations enable flexible
and B. Piot, “Byol-explore: Exploration by boot- learning and vicarious evaluation of cognitive
strappedprediction,”2022. maps,”NatureCommunications,vol.12,042021.
[7] D.Shah,B.Eysenbach,G.Kahn,N.Rhinehart,and [21] M. Peer, I. K. Brunec, N. S. Newcombe, and
S.Levine,“Rapidexplorationforopen-worldnavi- R.A.Epstein, “Structuringknowledgewithcogni-
gationwithlatentgoalmodels,”2023. tive maps and cognitive graphs,” Trends in Cogni-
[8] M. Milford, G. Wyeth, and D. Prasser, “Ratslam: tiveSciences,vol.25,no.1,pp.37–54,2021.
ahippocampalmodelforsimultaneouslocalization [22] P. Foo, W. Warren, A. Duchon, and M. Tarr, “Do
andmapping,”inIEEEInternationalConferenceon humansintegrateroutesintoacognitivemap?map-
RoboticsandAutomation,2004.Proceedings.ICRA versus landmark-based navigation of novel short-
’04.2004,vol.1,pp.403–408Vol.1,2004. cuts.,” Journal of experimental psychology. Learn-
[9] A.Safron,O.C¸atal,andT.Verbelen,“Generalized ing, memory, and cognition, vol. 31, pp. 195–215,
simultaneouslocalizationandmapping(g-slam)as 042005.
unification framework for natural and artificial in- [23] R.Epstein,E.Z.Patai,J.Julian,andH.Spiers,“The
telligences: towards reverse engineering the hip- cognitive map in humans: Spatial navigation and
pocampal/entorhinalsystemandprinciplesofhigh- beyond,” Nature Neuroscience, vol. 20, pp. 1504–
levelcognition,”FrontiersinSystemsNeuroscience, 1513,102017.
vol.Volume16-2022,2022. [24] C. B. Browne, E. Powley, D. Whitehouse, S. M.
[10] D.deTinguy, T.Verbelen, andB.Dhoedt, “Learn- Lucas, P. I. Cowling, P. Rohlfshagen, S. Tavener,
ing dynamic cognitive map with autonomous nav- D.Perez,S.Samothrakis,andS.Colton,“Asurvey
igation,”FrontiersinComputationalNeuroscience, of monte carlo tree search methods,” IEEE Trans-
vol.18,Dec.2024. actions on Computational Intelligence and AI in
[11] D. Fox, W. Burgard, and S. Thrun, “The dynamic Games,vol.4,no.1,pp.1–43,2012.
window approach to collision avoidance,” IEEE [25] D.HaandJ.Schmidhuber,“Worldmodels,”CoRR,
Robotics and Automation Magazine, vol. 4, no. 1, vol.abs/1803.10122,2018.
pp.23–33,1997. [26] K. Friston, T. FitzGerald, F. Rigoli, P. Schwarten-
[12] W.Xu,Y.Cai,D.He,J.Lin,andF.Zhang,“FAST- beck, J. O. Doherty, and G. Pezzulo, “Active in-
LIO2: fast direct lidar-inertial odometry,” CoRR, ferenceandlearning,”NeuroscienceandBiobehav-
vol.abs/2107.06829,2021. ioralReviews,vol.68,pp.862–879,2016.
[27] aws-robotics, “aws-robomaker-small-warehouse- planningbasedongridcells,”EuropeanJournalof
world,”2020. Accessed: 2024-08-01. Neuroscience,vol.35,no.6,pp.916–931,2012.
[28] D. S. Chaplot, R. Salakhutdinov, A. Gupta, and [43] K.J.Friston,T.Salvatori,T.Isomura,A.Tschantz,
S. Gupta, “Neural topological SLAM for visual A.Kiefer,T.Verbelen,M.Koudahl,A.Paul,T.Parr,
navigation,”CoRR,vol.abs/2005.12256,2020. A. Razi, B. Kagan, C. L. Buckley, and M. J. D.
Ramstead, “Active inference and intentional be-
[29] K. Friston, R. J. Moran, Y. Nagai, T. Taniguchi,
haviour,”2023.
H.Gomi,andJ.Tenenbaum,“Worldmodellearning
andinference,”NeuralNetworks,vol.144,pp.573– [44] M. Cai, E. Aasi, C. Belta, and C.-I. Vasile, “Over-
coming exploration: Deep reinforcement learning
590,2021.
for continuous control in cluttered environments
[30] ROS2, “Ros2humble,” 2022. Accessed: 2025-05-
fromtemporallogicspecifications,”IEEERobotics
21.
and Automation Letters, vol. 8, no. 4, pp. 2158–
[31] Turtlebot, “Turtlebot versions,” 2024. Accessed:
2165,2023.
2024-12-16.
[45] J.C.R.Whittington,D.McCaffary,J.J.W.Baker-
[32] Husarion,“rosbotxl,”2025. Accessed: 2025-05-21.
mans,andT.E.J.Behrens,“Howtobuildacogni-
[33] nav2,“nav2,”2021. Accessed: 2024-12-01. tivemap,”NatureNeuroscience,vol.25,pp.1257–
[34] Y. Koren and J. Borenstein, “Potential field meth- 1272,October2022. Epub2022Sep26.
ods and their inherent limitations for mobile robot [46] R. Smith, P. Schwartenbeck, T. Parr, and K. J.
navigation,”vol.2,pp.1398–1404vol.2,051991. Friston, “An active inference approach to model-
[35] aws-robotics, “aws-robomaker-small-house- ing structure learning: Concept learning as an ex-
world,”2021. Accessed: 2024-10-01. ample case,” Frontiers in Computational Neuro-
[36] P. Gyanani, M. Agarwal, R. Osari, et al., “Au- science,vol.14,2020.
tonomous mobile vehicle using ros2 and 2d- [47] K. Friston, T. Parr, and P. Zeidman, “Bayesian
lidar and slam navigation,” Research Square, modelreduction,”2019.
vol. Preprint (Version 1), May 2024. Available at [48] D. de Tinguy, T. Verbelen, and B. Dhoedt, “Ex-
ResearchSquare. ploringandlearningstructure: Activeinferenceap-
proachinnavigationalagents,”2024.
[37] J. Huang, B. Zhou, Z. Fan, Y. Zhu, Y. Jie, L. Li,
[49] D. S. Chaplot, D. Gandhi, A. Gupta, and
andH.Cheng,“Fael: Fastautonomousexploration
R. Salakhutdinov, “Object goal navigation using
for large-scale environments with a mobile robot,”
goal-orientedsemanticexploration,”2020.
IEEE Robotics and Automation Letters, vol. 8,
[50] deTinguy,DariaandVandeMaele,ToonandVer-
pp.1667–1674,2023.
belen, Tim and Dhoedt, Bart, “Spatial and tempo-
[38] D.DubergandP.Jensfelt, “UFOMap: Anefficient
ral hierarchy for autonomous navigation using ac-
probabilistic3Dmappingframeworkthatembraces
tiveinferenceinminigridenvironment,”ENTROPY,
theunknown,”IEEERoboticsandAutomationLet-
vol.26,no.1,p.32,2024.
ters,vol.5,no.4,pp.6411–6418,2020.
[39] T. Dang, M. Tranzatto, S. Khattak, F. Mascarich,
K. Alexis, and M. Hutter, “Graph-based subter-
ranean exploration path planning using aerial and
legged robots,” Journal of Field Robotics, vol. 37,
no.8,pp.1363–1388,2020. WileyOnlineLibrary.
[40] M. Tranzatto, M. Dharmadhikari, L. Bernreiter,
M. Camurri, S. Khattak, F. Mascarich, P. Pfre-
undschuh, D. Wisth, S. Zimmermann, M. Kulka-
rni, V. Reijgwart, B. Casseau, T. Homberger,
P. D. Petris, L. Ott, W. Tubby, G. Waibel,
H. Nguyen, C. Cadena, R. Buchanan, L. Well-
hausen, N. Khedekar, O. Andersson, L. Zhang,
T. Miki, T. Dang, M. Mattamala, M. Montenegro,
K.Meyer,X.Wu,A.Briod,M.Mueller,M.Fallon,
R. Siegwart, M. Hutter, and K. Alexis, “Team cer-
beruswinsthedarpasubterraneanchallenge: Tech-
nicaloverviewandlessonslearned,”2022.
[41] H. Oleynikova, Z. Taylor, M. Fehr, J. I. Nieto, and
R.Siegwart,“Voxblox:Building3dsigneddistance
fields for planning,” CoRR, vol. abs/1611.03631,
2016.
[42] U. M. Erdem and M. Hasselmo, “A goal-directed
spatial navigation model using forward trajectory

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Bio-Inspired Topological Autonomous Navigation with Active Inference in Robotics"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
