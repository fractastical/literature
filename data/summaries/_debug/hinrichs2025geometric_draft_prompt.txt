=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Geometric Hyperscanning of Affect under Active Inference
Citation Key: hinrichs2025geometric
Authors: Nicolas Hinrichs, Mahault Albarracin, Dimitris Bolis

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: geometric, institute, university, affect, affective, okinawa, inference, germany, active, brain

=== FULL PAPER TEXT ===

Geometric Hyperscanning of Affect
under Active Inference
Nicolás Hinrichs1,2 , Mahault Albarracin3,4 , Dimitris Bolis5 , Yuyue
Jiang6,7 , Leonardo Christov-Moore8,9 , and Leonhard Schilbach10,11
1 Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany
2 Okinawa Institute of Science and Technology, Okinawa, Japan
3 VERSES AI Research Lab, Los Angeles, USA
4 Université du Québec à Montréal, Montréal (Québec), Canada
5 Instituto Italiano di Tecnologia, Rovereto, Italy
6 University of California, Santa Barbara, USA
7 University of California, Irvine, USA
8 Institute for Advanced Consciousness Studies, Santa Monica, USA
9 SENSORIA Research, San Francisco, CA
10 Ludwig Maximilians Universität, Munich, Germany
11 LVR-Klinikum Düsseldorf / Heinrich Heine University, Düsseldorf, Germany
hinrichsn@cbs.mpg.de nicolas.hinrichs@oist.jp
Abstract. Second-person neuroscience holds social cognition as em-
bodied meaning co-regulation through reciprocal interaction, modeled
here as coupled active inference with affect emerging as inference over
identity-relevantsurprise.Eachagentmaintainsaself-modelthattracks
violationsinitspredictivecoherencewhilerecursivelymodelingtheother.
Valence is computed from self-model prediction error, weighted by self-
relevance,and modulated byprior affective states and by whatweterm
temporal aiming, which captures affective appraisal over time. This ac-
commodatesshiftsintheself-otherboundary,allowingaffecttoemergeat
individualanddyadiclevels.Weproposeanovelmethodtermedgeomet-
richyperscanning,basedontheForman-Riccicurvature,tooperational-
ize these processes empirically: it tracks topological reconfigurations in
inter-brain networks, with its entropy serving as a proxy for affective
phase transitions such as rupture, co-regulation, and re-attunement.
Keywords: Active inference · Hyperscanning · Second-person neuro-
science · Dyadic coupling · Forman-Ricci curvature · Phase transitions.
1 Introduction
How do agents come to feel ‘together’? How do they navigate the sharing of be-
liefsabouttheworldandthemselves,andthefragileterrainofaffectivemeaning?
Traditional models of social cognition often approach this question through the
lens of mental state attribution: one agent models another’s beliefs, intentions,
and emotions. Adopting a third-person stance towards someone has dominated
5202
peS
42
]CN.oib-q[
4v99580.6052:viXra
2 Hinrichs, Albarracin, Bolis, et al.
theoretical and empirical social cognition research [8]. However, such models ig-
nore a crucial fact: social understanding, in most of its ecologically valid forms,
does not unfold in detached observation but in active, embodied engagement
with others. As Schilbach et al. [36] argue, social interaction is not simply the
backdropagainstwhichinferenceoccurs;instead,itisthemediumthroughwhich
meaning is constituted. This shift, often captured under the rubric of ‘second-
personneuroscience’[34,37],reframestheunitofanalysisfromtheisolatedagent
tothedyadasagenerativesysteminitsownright,bytakingmutualengagement
in social interaction, rather than social observation, as its central explanandum.
Recentformalizationsofthisframeworkthroughthelensofactiveinference[28]
have provided the missing computational scaffolding: they model interacting
agents as mutually coupled generative systems that co-regulate meaning via re-
cursivebeliefupdating.Inthisview,socialunderstandingisnotcomputedabout
another agent, but emerges while in social interaction with another through on-
goingcyclesofexpectation,violation,andrealignment.Thedyadbecomesaunit
ofanalysisinitsownrightandcanberegardedasasharedgenerativemanifold,
which can be modeled as a coupled system of intra- and interpersonal processes
across multiple modalities [4,5].
1.1 The Affective Gap
Weextendsecond-personactiveinferencetothedomainofaffect,modelingitas
recursiveinferenceovertwotypesofprediction error:mismatchbetweenpredic-
tionsandoutcomesrelevanttotheworld,andthoserelevanttoidentity.Drawing
onJiangandLuo’s[25,24]model,valencereflectsaninferenceovertheintegrity
of the self-model, embedded in the dyadic generative manifold. Because both
agents maintain self-models while recursively modeling each other, affective dy-
namics become entangled, shaping belief updating and action selection. This
recursive process promotes interpersonal attunement and stabilization [5,41,38],
whileaffectiverupturetriggerscognitivelycostlyrecalibration[9,1].Wepropose
geometric hyperscanning to link these formal dynamics to neural signatures,
expanding the framework of second-person active inference and its formal dy-
namics of belief and affect to empirical research.
This paper makes three contributions. First, we formalize affect as recursive
inference over self-model coherence. We model valence as identity-relevant pre-
diction error weighted by self-relevance, modulated by affective memory, and
shaped by temporal aiming — the agent’s orientation across past and future af-
fectivestates(Section2.1).Weshowhowrecursivemodelingoftheotherdynam-
ically shifts self–other boundaries (Section 2.2). Second, we introduce geometric
hyperscanning, an empirical method based on Forman-Ricci curvature (FRc),
to track topological reconfigurations in inter-brain networks and infer affective
phase transitions (Section 2.3). Third, we integrate this formal-empirical frame-
work within second-person neuroscience and active inference. We offer a scal-
ablearchitectureformodelingrecursiveaffectivedynamicsacrosspsychotherapy,
Geometric Hyperscanning of Affect under Active Inference 3
development, and naturalistic interaction, and outline its broader implications
(Section 3).
2 Second-Person Neuroscience and Dyadic Active
Inference
Second-person neuroscience [36] holds that social understanding is constituted
through real-time mutual engagement, as opposed to detached or post-hoc at-
tribution. From a computational standpoint, this view is well-expressed in the
active inference framework, in which agents minimize variational free energy to
maintain a coherent embodied model of the world and their role within it. In
second-person settings, this framework must be extended [6,28,40]: agents not
only predict external states, but also the inferred generative models of others.
These recursive beliefs form a shared generative manifold, wherein action and
perception are jointly coordinated. We can conceive of each agent maintaining
a generative model:
M =p(o ,a ,s ,s |π ) (1)
i j i j i
where:
– o = observations available to agent i,
i
– a = inferred actions of agent j,
j
– s ,s = hidden states of agents i and j,
i j
– π = current policy or sequence of expected actions for agent i.
i
The recursive nature of this system (wherein both agents model each other,
modelingthem)doesnotleadtoaninfiniteregress.Instead,asFristonandFrith
(2015) demonstrated, it dissolves into a shared dynamic narrative, where both
agents come to predict and enact the same process. In other words, both agents
use the same model and the dyad, thus, becomes the minimal unit of inference.
In contrast, traditional third-person approaches to social cognition, such as
Theory of Mind or mindreading paradigms, cast social understanding as an ob-
serverinferringanother’shiddenmentalstates.Classicexperiments,forinstance,
might have a participant watch a video or read a story and then guess what an-
otherpersonbelievesorintends.Theseparadigms,whilevalid,involveaone-way
attribution process, often in non-interactive settings. Neuroscientifically, third-
person “mentalizing” tasks reliably engage a network including the dorsomedial
prefrontal cortex (dmPFC), ventromedial prefrontal cortex (vmPFC), and tem-
poroparietal junction (TPJ), which is often called the mentalizing or theory-
of-mind network [18]. However, in a live interaction, one’s brain is modeling
the other and responding to them in real time, creating a feedback loop. This
form of social connectedness has measurable two-brain dynamics: an engaged
“I–Thou” exchange produces alignment of neural rhythms that does not occur
in a one-directional “I observe him” situation (see [13,37] for a recent review).
[19] refers to these coupled networks as mutual social attention systems,
proposing that when two people directly attend to each other, their brains tem-
porarily form an integrated system. The second-person emphasis on real-time
4 Hinrichs, Albarracin, Bolis, et al.
mutualengagementdovetailswithactiveinference,becausebothparadigmsrec-
ognizethatunderstandingothersisanactive,dynamical,andbidirectionalalign-
ment process.
2.1 Valence as Inference over the Self-Model
Within this coupled generative architecture, affect is conceptualized as dynamic
regulatory processes guiding cognition and behavior based on the integrity and
coherence of an agent’s predictive self-model [25,24]. Central to this approach
is the idea that emotional valence signals the alignment or mismatch between
predicted and observed outcomes, particularly those relevant to identity and
social expectations [1].
Priorworkhasmodeledvalenceasaderivativeoffreeenergy[26],ametacog-
nitivesignal[20],interoceptiveinference[39],shiftsinprocessingmodes[45],and
recursive affective dynamics linked to self-relevance and identity [2,25,1]. Build-
ing on these insights, and drawing on [25], we propose an extended model of
emotionalvalenceasacontinuousinferenceovertheintegrityoftheagent’sself-
model. Emotional states emerge from prediction errors tied to identity-relevant
expectations.Valenceoperationalizestheemotionalappraisalofinteractionsvia
two primary factors: (1) the magnitude of self-model prediction error, and (2)
the self-relevance assigned to that error. We further incorporate a temporal pa-
rameter into this model, reflecting the directionality and velocity of affective
processing.Buildingon[26]and[45],weintroducetemporal aiming (seeFig.1),
encompassing both the velocity of affective evaluation (fast learning rates vs.
slow enduring states) and its temporal direction (retrospective vs. prospective
appraisal).
This modulation adds an essential dimension to affective inference: agents
may respond differently to the same interaction depending on whether they are
prospectively anxious, retrospectively regretful, or temporally stable. Temporal
aiming thus complements self-relevance and prediction error as core variables
in our valence model. We conceptualize emotions as functions of valence (align-
ment of identity-relevant predictions) and arousal (uncertainty and intensity of
self-relevant evaluations), with both dimensions anchored in the evolving self-
concept,shapedbyreflection,comparison,andinternalizedideals.Inthisframe-
work, valence reflects the agent’s appraisal of ongoing interaction or how “good”
or “bad” the current moment feels to the agent, computed as a weighted func-
tion of self-model prediction error and self-relevance, and modulated by prior
affective memory [24]:
V =α·PE ·SR +β·V (2)
t self,t t SR,t
where:
– PE is the prediction error between expected and actual self-state, cap-
self,t
turing the “surprise” the agent experiences about itself
– SR is a dynamic scalar indexing the self-relevance of the context, reflecting
t
how much the situation matters for the agent’s identity
Geometric Hyperscanning of Affect under Active Inference 5
Fig.1. Temporal aiming in affective inference. The figure illustrates how agents eval-
uateself-modelpredictionerrorovertimeaccordingtodifferenttemporalorientations.
Affectisshapednotonlybythemagnitudeandrelevanceofpredictionerror,butalsoby
theagent’stemporalaim,i.e.,whetherinferenceisdirectedtowardanticipatedfutures
or prior experiences, and whether updates occur rapidly or gradually. This temporal
structuring of affect modulates the stability and flexibility of policy selection within
dyadic interaction.
– V isretrievedfromsimilarpriorcontexts,representingthelingeringemo-
SR,t
tional tone (mood) shaped by related past experiences,
– α,βareprecision-modulatingweights,thatdeterminehowstronglytheagent
reacts to immediate surprises versus how much past mood carries over..
Itfollowsthatwhenevertheagentexperiencesaself-relatedpredictionerror,
it generates an affective response proportional to that error and to how self-
relevantitis.Thefirstterm,α·PE ·SR ,encodestheinstantaneousemotional
self,t t
impact: large, self-relevant surprises cause large valence shifts. The parameter α
scales the impact of immediate prediction error on valence. An agent i with a
larger α will exhibit heightened emotional sensitivity to surprises, particularly
negative ones, which yield more negative valence. The second term, β ·V
SR,t
with 0 < β < 1, he second term, β · V , introduces emotional inertia: it
SR,t
blends in past affective states, so that current mood is partly a continuation of
recent emotional history, it makes valence a leaky integrator: it carries forward
some fraction of previous valence (mood) into the current moment. The term
PE includes both the agent’s previous valence V(t−1) and contributions
self,t
from past episodes that had similar self-relevance or context as the current one.
We can treat V as an exponentially decaying sum of past valences, with
SR,t
greaterweightassignedtomorerecenttimesandtoeventswithcomparableself-
relevance(SR).Inthenotationoftheoriginalmodel,self-modelpredictionerror
and self-relevance map onto PE and SR, respectively, where the last term of
self
V helps to maintain the affective experience as iterative and continuous.
SR,t
6 Hinrichs, Albarracin, Bolis, et al.
Valence under the Dyadic Inference Framework In dyadic active infer-
ence, each agent’s self-model is treated as a dynamic function of its internal
world model,whichincludesa simulated model of the other agentand incoming
interactional feedback. At time t, agent i’s self-model is conditioned on beliefs
about the other agent’s state, actions, and observations:
Pi =f(Si,Aj,Oj) (3)
t t t t
This reflects that one’s self-concept in a social setting is co-constructed by
self-generatedandsociallyobservedinformation.Agenti’sfullgenerativemodel
factorizes as:
P(O ,A ,S ,S )=P(O |S ,A )·P(A |S ,S )·P(S |S ) (4)
i i i j i i i i i j i j
This expresses that (1) the agent’s observations depend on its state and
actions, (2) its actions depend on both its own and the other’s state, and (3) its
own state is partly inferred from the other’s state. Valence (V ,t) measures how
i
emotionally coherent the agent’s self-model feels over time. It is computed from
the prediction error in the self-model, modulated by both SR and V . The
t SR,t
expected valence is defined as:
E(Vt)=α·PE ·SR +β·V (5)
i self,t t SR,t
where PEi is the prediction error between expected and actual self-state,
self,t
and alpha and beta are precision-modulating weights. The realized valence re-
flects how well observed outcomes under the current policypit align with these
i
expectations; it is given by:
Vt =E (cid:2) logP (cid:0) ot |E(Vt) (cid:1)(cid:3)
i P(ot|πt) i
(cid:104) (cid:16) (cid:12) (cid:12) (cid:17)(cid:105)
=E logP ot |α(cid:12)Pt−Pˆt(cid:12)SRt+βVt (6)
P(ot|πt) (cid:12) i i(cid:12) i i,SR
This means that valence is the expectation, over possible outcomes, of how
well those outcomes will sustain the agent’s internalized social narrative, given
its evolving model of the partner and the feedback from ongoing interaction.
Affective Valence as a Prior Over Policy in Planning-as-Inference By
design, valence serves as an internal reward/safety signal: high positive valence
indicates that the interaction is proceeding smoothly, with strong affective syn-
chrony, while negative valence signals a breakdown in synchrony, prompting
either a new attempt to restore alignment or a withdrawal from the interac-
tion, depending on individual differences in valence construction and perception
(modeled by the parameters α and β). Which path the agent takes depends on
individual differences in emotional sensitivity and persistence, captured by the
parameters α and β Though we do not explicitly model all downstream effects
Geometric Hyperscanning of Affect under Active Inference 7
here, valence functions as a feedback loop, a readout of the self-model’s perfor-
mance and modulating subsequent perception and action. In practical terms,
this means that affect shapes the space of possible future actions by making
certain policies feel “more natural” or “safer” than others. In our model, affect
modulates the posterior over policies, effectively serving as a soft prior that bi-
asesaction selectiontowardmoreaffectivelycoherent trajectories.Following Da
Costa’s (2020) [12] planning-as-inference paradigm, we express policy selection
as:
P(π |V )∝eλ·g(Vt,πt) (7)
i t
where:
– λ is an inverse temperature parameter controlling affective precision or con-
fidence in the valence signal (high λ = more deterministic choice; low λ =
more exploratory choice), and
– g(V ,π ) is a compatibility function mapping affective coherence to policy
t t
likelihood (higher compatibility = higher policy probability).
This captures the recursive and value-sensitive nature of planning in social
contexts. The agent is more likely to choose plans consistent with positive va-
lence (i.e., minimal surprise and maximal narrative alignment), while negative
valence reduces the likelihood of maintaining the current trajectory. When both
agents are engaged in this recursive affective inference, the system forms a dy-
namically coupled manifold —a shared generative space in which each agent’s
self-coherence is entangled with the other’s behavior. Moments of affective rup-
ture mark local minima in joint narrative alignment and correspond to dyadic
expected free energy peaks. Repairing these ruptures requires coordinated ad-
justments in beliefs and policies across both agents. This framework completes
a recursive loop: expected valence, derived from self-model integrity and antic-
ipated partner behavior, acts as a prior over policy selection, guiding the agent
towardactionsexpectedtopreserveorrestoreaffectivecoherence.Thesechosen
policiesleadtonewinteractionsandobservations,whichupdatetheagent’sself-
model and generate realized valence. In turn, the mismatch between expected
and realized valence yields an affective prediction error that shapes the next in-
ferencecycle.Thisrecursiveloop(Fig.2)summarizeshowaffectivelymodulated
policies guide dyadic interaction through cycles of prediction error, self-model
update, and realignment.
2.2 Recursive Coupling and Shared Surprise
Inexploringthedynamicsofaffectiveinteractions,itishelpfultodrawuponthe
concept of intra-action from neo-materialist philosophy [3]. Intra-action empha-
sizes that interacting entities do not preexist independently but emerge through
mutual entanglement. Under this lens, the dyadic interaction is not simply a
transfer of emotional states between two separate agents; instead, it represents
a continual co-construction of affective experiences and identities [32]. From
this perspective, affective states are inherently recursive and relational, arising
8 Hinrichs, Albarracin, Bolis, et al.
Fig.2. Recursive Affective Inference Framework for Dyadic Social Interaction. Il-
lustrates a recursive framework wherein affect dynamically regulates social behavior
between two agents via cycles of inference, prediction error, and adaptive policy up-
dates grounded in self-model coherence.
from the iterative feedback loops between agents. Affective ruptures, moments
of misalignment or increased prediction error, serve as significant informational
signals indicating points of divergence in the shared expectations of interacting
agents. These affective evaluations modulate the posterior over policies, biasing
action selection toward trajectories that restore narrative alignment and reduce
identity-relevant surprise. Such an entanglement of affect and policy selection
turns the dyad into a dynamic field of co-regulated affective inference, where
both agents are simultaneously minimizing joint expected free energy:
G=E [logq(s)−logp(o,s)] (8)
q(s)
Then, in a dyadic setting, we can express the joint free energy as:
(cid:20) (cid:21)
q(s ,s )
G =G +G =E log i j (9)
joint i j q(si,sj) p(o ,o ,s ,s )
i j i j
Here, G quantifies the shared divergence between the dyad’s joint beliefs
joint
and its joint generative model. High joint valence corresponds to low joint free
energy (smooth alignment), whereas affective ruptures correspond to spikes in
joint free energy (misalignment and uncertainty). At the dyadic level, recursive
coupling of valence creates a shared attractor structure: higher valence biases
policyselectiontowardtrajectoriesthatpreservenarrativecoherenceandreduce
expectedfuturefreeenergy.Conversely,negativevalencecantriggerexploratory
Geometric Hyperscanning of Affect under Active Inference 9
policies to restore alignment or withdraw from destabilizing interactional tra-
jectories. This way, valence modulates immediate affective dynamics and the
agent’s future epistemic and instrumental uncertainty.
Critically,momentsofaffectiverupture—sharpdropsinvalence—correspondto
increasesinjointfreeenergy,typicallyarisingfrommismatchesintheagents’self-
model priors. These transitions are not noise but informative inflection points
in the dyadic generative process. Mismatches in self-model coherence directly
elevate free energy, as valence encodes deviations between observed interaction
outcomes and expected self-relevant predictions. Because valence reflects each
agent’s affective confidence in their internal model, it serves as both a readout
of local free energy minimization and a control signal that shapes future joint
free energy via policy adaptation. This recursive structure is central to how
dyadic affective inference maintains, destabilizes, or reconstructs interpersonal
synchrony over time.
2.3 Geometric Hyperscanning as Second-Person Method
To empirically access the internal dynamics of dyadic affective inference, we in-
troduce geometric hyperscanning based on the Forman-Ricci curvature (FRc)
[21,22], which captures phase transitions in inter-brain network topology us-
ing geometric markers derived from EEG hyperscanning data. This method en-
ablesoperationalizationoflatentaffectiveandnarrativecoherenceasmeasurable
transformationsinthetopologyofinter-brainnetworks.Importantly,FRcisnot
treated as a post hoc readout; we propose it as a data-derived proxy for latent
generativestatesinthedyadicactiveinferencemodel.Traditionalhyperscanning
methodsfocusonnode-levelsynchrony,typicallycorrelatinghomologousregions
across two brains. While informative about temporal alignment, these methods
fail to detect topological reconfigurations in inter-brain structure. FRc, by con-
trast, is an edge-centric geometric measure that quantifies the local expansion
or contraction of topological flow within a network [44], and has been shown to
characterize network robustness, signal routing, and functional reorganization.
GivenanetworkG=(V,E)withedgee connectingnodesv andv ,theFRc
ij i j
is computed as:
(cid:18) (cid:19) (cid:32) (cid:33)
FRc(e )=w(e ) 1 + 1 − (cid:88) w(e ij ) (10)
ij ij w(v i ) w(v j ) e∼eij (cid:112) w(e ij )·w(e)
where we interpret w(·) as node and edge weights (e.g., derived from functional
connectivity matrices), to track the evolution of inter-brain topology over time,
we calculate the entropy of the FRc distribution within a sliding window.
(cid:88)
H (t)=− p(e)logp(e) (11)
FRc
e∈Et
10 Hinrichs, Albarracin, Bolis, et al.
This scalar quantity acts as a proxy for interactional volatility. Peaks or dis-
continuities in FRc entropy correspond to phase transitions in the shared gen-
erative manifold and reflect affective rupture, repair, or co-regulation dynamics.
FRc(e)
p(e)= (12)
(cid:80) FRc(e′)
e′
FRc entropy is not simply an output variable but can be formalized as an
observationmodeloverlatentaffectivepredictionerror.Curvaturedynamicscan
infer or constrain internal state variables such as valence or identity coherence.
This closes the loop between model and measurement, as the generative model
predictschangesinself-modelcoherenceanddyadicfreeenergy,andtheFRcen-
tropy serves as an empirical signal that can be used to update model beliefs via
Bayesian inference. To make these transitions tractable and interpretable, we
propose a multi-level operationalization of rupture, repair, and reattunement,
linking neural signatures to behavioral and psychological indicators. Neurally,
rupture corresponds to abrupt drops in network integration (low FRc), high
curvature entropy, or rapid shifts in entropy gradients; repair and reattunement
reflect a return to more stable topologies. Behaviorally, rupture may manifest
as disengagement, disrupted synchrony, or confusion (e.g., gaze aversion, vocal
interruptions), while repair involves re-engagement cues such as gesture mirror-
ing, prosodic modulation, or turn-taking; reattunement is evidenced by fluent,
coordinatedinteractionandmutualresponsiveness.Psychologically,rupturecan
be self-reported as disconnection or emotional distancing, repair as subjective
efforts to reconnect, and reattunement as restored mutual understanding or re-
lational safety. These experiences can be measured via self-reports (affective
sliders, post-session interviews, validated instruments), annotated through mul-
timodal behavioral data (gaze, prosody, synchrony), and aligned with curvature
dynamics in the inter-brain manifold. Treated as latent categorical states (e.g.,
within a hidden Markov model), these phases can serve as points of annotation,
classification, or real-time feedback in both experimental and clinical contexts.
Importantly, embedding these events within the recursive generative model of
dyadic inference allows rupture–repair cycles to function as outcomes and as
endogenousfeaturesof interactionaldynamics.Affectivecoherencedrivespolicy
selection, while behavioral and neural feedback recursively update each agent’s
self-model. This recursive structure enables in situ inference over dynamic in-
terpersonal states, validation of model predictions across modalities, and fine-
grained adaptation to moment-by-moment shifts in relational coherence. Inte-
gratinggeometric hyperscanning intothegenerativemodelthereforeboundsthe
model with an additional objective: not only minimising identity-relevant pre-
diction error, but implicitly driving the system toward maximal interpersonal
attunement—an intrinsically rewarding state even in the absence of overt in-
strumental gain [34,6]. Curvature-induced surprises can surface to awareness,
prompting explicit attempts at repair.
Geometric Hyperscanning of Affect under Active Inference 11
Insum,FRc-basedgeometrichyperscanning offersascalable,multimodalmethod
fordetectingandinterpretingrecursiveaffectiveinference.Bytriangulatingneu-
ralentropy,behavioraldynamics,andpsychologicalexperience,wegainaninte-
grated empirical handle on how dyads co-regulate meaning, affect, and identity
over time. This framework advances a formal, testable architecture for second-
person neuroscience and lays the groundwork for modeling recursive emotional
entanglement, the subject of the following section.
3 Future Directions and Conclusions
This paper proposed that affect is best understood as recursive inference over
self-model coherence within coupled generative systems. Modeling the dyad via
activeinference,weformalizedaffectasavaluationofidentity-relevantsurprise,
driving and modulating recursive loops of belief updating, policy selection, and
behavioral adaptation during social interaction. We introduced a novel method
based on the FRc, termed geometric hyperscanning [22], which tracks dynamic
reconfigurationsininter-brainnetworks,providinganempiricalwindowontomo-
mentsofrupture,repair,andre-attunement.Byunifyingformalmodelsofbelief
dynamics,affectiveevaluation,andnetworkgeometry,weadvanceascalableand
interpretable framework for operationalizing second-person active inference.
3.1 Future Directions
The proposed theoretical formulation invites several concrete avenues for em-
pirical investigation and computational development. Foremost among these is
the simulation of agent-based models in which curvature entropy is treated as a
streamed sensory input—continuously informing belief updates about narrative
alignment. Such models would allow us to test whether the architecture, under
active inference, spontaneously reproduces the rupture–repair cycles observed
in real dyadic interaction. In doing so, they provide a crucial bridge between
formalism, neurophysiology, and phenomenology. Beyond dyads, the framework
naturally extends to hierarchically structured systems. By introducing group-
level alignment variables, one can model small-group coherence as an emergent
property of multiple interacting pairwise dynamics. This multiscale extension
opens the door to collective behaviour, organisational synchrony, and crowd
psychology applications, where relational inference is distributed across agents
and temporal scales. Furthermore, the curvature-informed likelihood may be
productively integrated with other sensorimotor channels. Prosodic variation,
gaze dynamics, and even facial microexpressions can all be incorporated within
a deep generative model, allowing heterogeneous evidence streams to converge
on shared latent variables. This multimodal fusion enriches the inferential land-
scape and supports more robust decoding of the intersubjective field. Yet the
prospect of real-time inference over relational states is not without ethical con-
sequences. As structural priors become actionable in applied contexts—be it
psychotherapy, education, or social robotics—the issues of privacy, autonomy,
12 Hinrichs, Albarracin, Bolis, et al.
and interpretability move to the fore. Any translational implementation must
therefore be grounded in transparent consent procedures and designed to yield
intelligible feedback to clinicians and researchers and to the individuals whose
relational trajectories it purports to track.
3.2 Sociomarkers for Interpersonalized Psychiatry
Geometric hyperscanning offers a promising foundation for sociomarkers: real-
time, measurable signatures of dynamic interpersonal coordination [5], analo-
goustobiomarkersofindividualphysiology.Affectiveco-regulation—vitalforso-
cial bonding across species [11,15,7,35]—is foundational to human development,
shaping cognition, emotion, and relational selfhood through early caregiver-
infant interactions [6,14,42,16,23]. Misattunement and repair cycles scaffold re-
silience and relational growth [5,6], with fluctuations in curvature entropy po-
tentially indexing key developmental processes [36,10,43]. Such signatures could
informpersonalized[30,29]andinterpersonalizedpsychiatry[5],whichviewspsy-
chopathologyasadisruptioninco-regulationandnarrativerepair[4,31].Inpsy-
chotherapy, real-time dyadic metrics [4,27] can track attunement, rupture, and
repair [33], helping both therapists and clients navigate the relational dynamics
of change. Crucially, synchrony is neither inherently good nor constant: transi-
tions into and out of synchrony may reflect autonomy, resistance, or meaningful
differentiation, not dysfunction. Modeling these dynamics as recursive affective
inferenceprovidesaprincipledlensforbasicscienceandrelationalmentalhealth
care.
3.3 Conclusions
Building on these formal and empirical insights, this approach carries several
keyimplications.First,itinvitesarethinkingofaffectinsocialinteraction—not
merely as a byproduct of inference, but as a primary regulatory signal that
modulatesthestabilityandflexibilityofgenerativecouplingitself.Onthisview,
affectbecomesthesenseofcoherenceorincoherencewithinthedyadicnarrative,
indicating when beliefs must be renegotiated or when interactional roles require
repair. Second, by shifting emphasis from synchrony per se to the topology of
inter-brain networks, our method aligns with a broader movement in second-
person neuroscience toward characterizing interaction structure. In this respect,
FRc extends Friston and Frith’s (2015) [17] notion of generalized synchrony by
capturingthereconfigurationsinnetworkstructurethataccompanyrecursiveaf-
fective inference. Third, by embedding affect into the posterior over policies, we
extend da Costa’s (2020) planning-as-inference formalism into the affective do-
main. Crucially, the affective signal can operate implicitly, as a precision-weight
on policy beliefs that never reaches phenomenal awareness, or explicitly, as a
consciously accessible feeling that furnishes the agent with propositional knowl-
edge about its own relational stance. In either guise, policy selection is driven
notonlybyepistemicorinstrumentalimperatives,butalsobytheimperativeto
Geometric Hyperscanning of Affect under Active Inference 13
preserve narrative and relational coherence. Affect thereby becomes an intrin-
sic dimension of social planning, covertly biasing action when tacit and overtly
guiding behaviour when made conscious—steering agents through moments of
ambiguity toward restored interactional alignment. These considerations open a
range of empirical and computational possibilities. In psychotherapy, curvature
entropy may serve as a real-time sociomarker of rupture and repair; in early
development, FRc could illuminate how co-regulatory patterns emerge between
infants and caregivers. Simulations of affective agents equipped with recursive
self- and other-models offer a formal means to investigate relational resilience
and breakdown. In particular, such models allow us to test the dialectical mis-
attunement hypothesis (Bolis et al., 2017), which posits that psychiatric risk
arises not from individual deficits alone but from persistent mismatches in com-
municative expectations or learning rates. Simulating these mismatches under
controlled conditions reveals how dyads adapt—or fail to—over developmental
time, providing insight into vulnerability and repair mechanisms. The theoret-
ical landscape also invites expansion. How does this framework scale to group
interactions,whererecursivegenerativecouplinginvolvesmultipleagents?What
ethicalsafeguardsareneededwhenautomatingthedetectionofaffectiverupture
and repair—especially in sensitive contexts like therapy or education? And how
might shared belief geometry interact with linguistic, prosodic, and bodily cues
to form a rich, multimodal map of affective inference? Together, these questions
point toward a broader scientific project: one that integrates formal modeling,
empirical measurement, and philosophical reflection into a unified account of
relational meaning. In this view, the dynamics of belief, affect, and participa-
tion are not peripheral but fundamental to the fabric of social cognition. By
reframing affect as recursive inference within coupled generative systems—and
rendering those dynamics tractable via network geometry—we move closer to
the vision of interaction as the basic unit of social neuroscience. Our proposal
thusoffersbothaconceptualframeworkandmethodologicaltoolkitforstudying
human interaction’s structural and affective choreography.
Contributions. NHandYJjointlyconceivedanddraftedtheinitialmanuscript.MA
and DB contributed core conceptual ideas and critically revised the text. LCM and
LS provided additional feedback and editorial refinement. All authors reviewed and
approved the final version of the manuscript.
Acknowledgments. NH and YJ would like to thank Danielle J. Williams and the
inauguralmeetingoftheSocietyforNeuroscienceandPhilosophy,atwhichtheauthors
contributedpapersanddiscussedintegratingtheirpresentedapproaches.NHwouldlike
to thank Lancelot Da Costa and Sebastian Sosa for their insightful feedback.
Disclosure of Interests. NH was funded by CNPq, MPI-CBS, and OIST. DB re-
ceives funding from the IIT. LS receives funding from the DFG.
14 Hinrichs, Albarracin, Bolis, et al.
A A Simulation-Ready Implementation (MBSR +
Valence–HMM)
Goal. We instantiate the manuscript’s account with two coupled but distinct
components: (i) an autobiographical memory-based self-relevance, (ii) a valence
HMM that carries the temporal dependence of affect. The HMM framework is
motivatedbythetemporalpersistenceofvalenceexhibitingstatecontinuitywith
gradual, experience-driven change (for review: affective spillover/carryover ef-
fect).HMMtransitionmatricescapturethisthroughhighdiagonalprobabilities
while permitting off-diagonal transitions. Standard moment-by-moment compu-
tations lack this persistence; HMMs provide it via probabilistic state evolution.
A.1 Setup and notation
Foragentiandstept,theinternalmodelM maintainsaself–stateprior/posterior
i
Pt,Pˆt, observations ot, inferred partner actions at, and the identity prediction
i i i j
error
PEt =Pˆt−Pt.
self,i i i
The projected/predicted valence, by definition, uses a scalar self-relevance
SRi ∈[0,1] and the identity prediction error PEt to weight identity-relevant
t self,i
surprise:
E(Vt)=α·PE ·SR +β·V (13)
i self,t t SR,t
Hereα,βareprecision-modulatinggainsbalancinginstantaneousidentity-relevant
surprise and affective carryover Vi .
t,SR
The agent’s current policy πt is enacted based on the valence state:
i
P(π |V )∝eλ·g(Vt,πt) (14)
i t
where ϕ(·) may include linear terms and selected interactions; its purpose is
to summarize, per trial, the stimulus and self-context the agent brings to the
exchange.
After one carries out an action policy, the results from the action will be
made available as new observations to compute the realized valence Vt. By
i
comparingexpectedoutcomesunderthecurrentpolicytotheexpectationE(Vt),
i
this item formalizes the felt value of the present exchange as the log-likelihood
of observations given the agent’s valence-weighted model (Eq. 15).
V i t =E P(ot|πt) (cid:2) logP (cid:0) ot(cid:12) (cid:12) E(V i t) (cid:1)(cid:3) . (15)
i
Inthefollowingimplementation,wediscretizebothself-relevanceandvalence
into three ordered HMM states:
– Self–relevance (SR): Rt ∈{r , r , r }.
i low med high
– Valence (S): St ∈{s , s , s }.
i neg neu pos
Geometric Hyperscanning of Affect under Active Inference 15
A.2 Memory-based Self–Relevance Chain
For each interaction, agents encode the present exchange in an interaction de-
scriptor
zt = (cid:0) ot, at, Pt(cid:1) ∈Rd (16)
i i j i
Each agent maintains an autobiographical store LTM = {(x ,I ,τ )}K
i k k k k=1
where each memory m has a descriptor x (context features), an impact tag
k k
I ∈ [0,1] (how strongly the episode affected the agent), and a timestamp τ .
k k
Giventhecurrentcontextzt,wecomputehowsimilaritistoeachstoredmemory.
i
Thesesimilaritiesarethennormalizedsothattheyadduptoone,turningthem
into attention weights over memory:
Simt
Simt =sim(zt,x ), S˜imt = k ,
k i k k (cid:80) Simt
j j
Foreachmemorym stored,thecontextztwillbecomethex ,thetimebecomes
k i k
τ , and they are accompanied by an impact tag which represents (1) how large
k
the self-prediction error was, and (2) how much the policy distribution reorga-
nized. Both are normalized to [0,1] for comparability. Impact tags are written
from the realized change at step t using a bounded, divergence-free score:
It =norm (cid:0) ∥PEt ∥ (cid:1) × TVt, (17)
self,i π
TVt = 1 (cid:88) (cid:12) (cid:12)pt (π)−pt (π) (cid:12) (cid:12)∈[0,1], (18)
π 2 post prior
π∈Πi
where pt /pt are policy distributions (softmax over scores) before/after as-
prior post
similating step t; norm(·) maps magnitudes to [0,1].
A memory-derived relevance score is then obtained as a similarity-weighted
average of impact tags:
K
S(cid:102)R i
t
= (cid:88) S˜imt
k
I
k
∈[0,1]. (19)
k=1
A.3 Expected Valence HMM Chain
Expected valence. We first compute the expected valence as a product of the
previous step’s identity prediction error and self-relevance (Eq. 13).
Integration into the valence HMM. Thisexpectedvalencethendrivesthetransi-
tiondynamicsofthelatentvalencestateSt ∈{Neg,Neu,Pos}withordinalmap
i
s(Neg) = −1, s(Neu) = 0, s(Pos) = 1. Three behavioral factors shape the dy-
namics:(i)baselinebiasesω (howlikelyeachshiftisbydefault),(ii)sensitivity
kℓ
η (howstronglyexpectedvalencepushestransitions),and(iii)penaltyρ (how
k k
costlybigjumpsare,e.g.fromnegativetopositiveinonestep).Weparameterize
transitions by expected valence, with stickiness and large–jump penalty:
exp (cid:8) ω + η E(Vt)s(ℓ) − ρ |s(ℓ)−s(k)| (cid:9)
Tt (k →ℓ) = kℓ k i k , (20)
S,i (cid:80) exp (cid:8) ω + η E(Vt)s(j) − ρ |s(j)−s(k)| (cid:9)
j kj k i k
16 Hinrichs, Albarracin, Bolis, et al.
with baselines ω , sensitivity η >0, and penalty ρ ≥0.
kℓ k k
Filtering and readout. The HMM updates the probability of each valence level,
using both the previous distribution and the transition dynamics. This yields a
smooth trajectory of affective states. The belief state over valence evolves as
(cid:88)
γt ∝(Tt )⊤γt−1, γt (ℓ)=1.
S,i S,i S,i S,i
ℓ
We can obtain a scalar valence readout in two ways:
vt =ν⊤γt , ν =(−1,0,1)⊤, (21)
i S,i
Here,valenceisreadoutasaweightedaverageacrossstateprobabilities,yielding
a single continuous score in [−1,1].
A.4 (Expected) Valence-guided Policy selection
Wedefineavalence–compatibleprioroverpolicies(Eq.14)withinversetemper-
ature λ controlling decisiveness. The compatibility function
g(E(V i t),π)=E P(ot|π) (cid:104) logP (cid:0) ot(cid:12) (cid:12) E(V i t) (cid:1)(cid:105) (22)
scores each candidate policy by how well its expected outcomes align with the
agent’s current valence state. In other words, policies are preferred if they make
the world more consistent with the agent’s affective expectations.
A.5 (Realized) Valence-guided Model Updating
After enacting the policy, agents would get an actual outcome of the chosen
policy and have an actual emotional response (realized valence (Eq. 15)). Con-
ceptually, this provides a feedback signal for updating.
Whenoutcomesunderpolicyπt matchexpectations,realizedvalenceishigh,
i
reinforcing both the policy and the current self-model. When outcomes diverge,
realized valence is low (or negative), signaling a need to adjust the model’s pa-
rameters,updatememorywithanewimpacttag,andreconsiderfuturepolicies.
This update propagates across all latent states and parameters:
– Self-state posteriors: priors Pt are corrected to posteriors Pˆt using the new
i i
observation (ot,ot).
i j
– Valence HMM: beliefs γt are updated using expected valence E(Vt) as in-
S,i i
put, ensuring temporal persistence of affect.
– Policy posterior: the distribution over policies P(πt | Vt) is recalculated
i i
given the new affective state.
– Impact encoding: the realized impact It is computed via Eqs. (17)–(18),
summarizing prediction error and policy reorganization.
– Memory write:thetuple(zt,It,t)isappendedtotheautobiographicalstore
i
LTM , allowing subsequent self-relevance estimates to remain personalized
i
and history-dependent.
This way, realized valence serves as a model-updating drive that keeps affec-
tive inference aligned with lived experience.
Geometric Hyperscanning of Affect under Active Inference 17
A.6 Table.1
Symbol Type Definition / Role
M model Agent i’s generative model (self + simulated other).
i
ot,ot obs Observations at step t (self / partner).
i j
Pt,Pˆt state Self-state prior / posterior after observing (ot,ot).
i i i j
PEt vec Identity prediction error; we use ∥PEt ∥.
self,i self,i
at act (inf.)Inferred partner action represented in M .
j i
zt feat Descriptor ϕ(ot,at,Pt); ψ(z)=z by default.
i i j i
LTM memory Autobiographical store of (x ,I ,τ ).
i k k k
It impact norm(∥PEt ∥)·TVt.
self,i π
TVt scalar Total variation between pre/post policy distributions at t.
π
S(z,x) sim Similarity kernel; S˜ is its normalization over k.
S(cid:102)R i
t
scalar Memory-derived self–relevance, Eq. (19).
E(Vt) scalar Expected valence, Eq. (13).
i
St,γt HMM Valence state / belief; transition Tt in Eq. (20).
i S,i S,i
ω ,η ,ρ params Valence baselines, sensitivity, jump penalty.
kℓ k k
πt,λ policy Action policy; inverse temperature in (14).
i
g(V,π) score Compatibility in (14).
Table 1. Symbols used in the simulation-ready HMM implementation.
18 Hinrichs, Albarracin, Bolis, et al.
A.7 Appendix illustration
Encode exchange Memory retrieval
z
i
t−1 =ϕ(ot
i
−1,at
j
−1,P
i
t−1) S˜(z,x),I
k
⇒S(cid:102)R
t−1
Identity surprise
∥PEt−1∥=∥Pˆt−1−Pt−1∥
self
Expected valence
E(Vt)=α∥PE
s
t
e
−
lf
1∥S(cid:102)R
t−1
Valence HMM
Tt(E(Vt))⇒γt, Vt
S S
Policy selection
P(πt |Vt)∝eλg(Vt,πt)
Act & update M
i
observe ot, update states
Write memory
It =norm(∥PEt ∥)·TVt; add (zt,It,t)
self π
Fig.3. Execution cycle for one agent at step t. Self–relevance is derived purely from
autobiographicalmemory(S(cid:102)R),whichmodulatesexpectedvalence.TheHMMhandles
valence dynamics, while memory ensures personalization and history dependence.
B Curvature-Based Geometric Entropy Channel
Goal. This appendix mirrors Appendix A but focuses on the geometric obser-
vation channel used in the main text: the edge-centric Forman–Ricci curvature
(FRc) and its entropy as a compact, simulation-ready observable of dyadic net-
work reconfiguration (rupture, repair, re-attunement).
Geometric Hyperscanning of Affect under Active Inference 19
Table 2. Symbols for the curvature-based entropy channel (Appendix B).
Symbol TypeDefinition / Role
G =(V,E )graph Inter-brain network at time t (nodes V, edges E ).
t t t
w(e ) scalar Edge weight for connectivity between v and v .
ij i j
w(v ) scalar Node weight (e.g., strength: sum of incident edge weights).
i
FRc(e ) scalar Forman–Ricci curvature of edge e (local geometry).
ij ij
p(e ) prob. Curvature-proportional mass: FRc(e )/ (cid:80) FRc(e′).
H
ij
(t) scalar Curvature entropy at t: − (cid:80) p(e
i
)
j
logp(
e
e
′
)
∈
.
Et
O FRc obs. Geometric observation chann e e ∈ l E (twe set O =H (t)).
κ,t κ,t FRc
S latent Dyad-level hidden state (e.g., alignment / rupture).
t
B.1 Setup and Notation
Let G =(V,E ) be a time-varying inter-brain graph at step t, where V indexes
t t
neuralsourcesacrossthetwoagentsandE containsinter-brain edgescomputed
t
fromaslidingwindowoverthedual-braindata(e.g.,cross-brainEEGcoherence).
Each edge e ∈E carries a connectivity weight w(e ), while each node v ∈V
ij t ij i
may be assigned a weight w(v ) (e.g., node strength).
i
B.2 Forman–Ricci Curvature (FRc)
For each edge e =(v ,v )∈E , the FRc for weighted graphs is:
ij i j t
(cid:18) (cid:19)
FRc(e ) = w(e ) 1 + 1 − (cid:88) w(e ij ) . (23)
ij ij w(v i ) w(v j ) e∼eij (cid:112) w(e ij )w(e)
e̸=eij
The first term grows when e dominates the load of its endpoints; the second
ij
termreducescurvaturewhenmanystrongneighbor edgese∼e createparallel
ij
routes, flattening local geometry. Positive FRc typically marks edges in dense,
redundant neighborhoods; strongly negative FRc highlights bridge-like edges
stitching otherwise separate modules.
B.3 Curvature-Based Entropy
Wecompressthenetwork’sgeometryattimetintoasinglevolatilitymarkervia
the Shannon entropy of the FRc distribution:
FRc(e )
p(e )= ij (curvature-proportional mass), (24)
ij (cid:80) FRc(e′)
e′∈Et
(cid:88)
H (t)= − p(e) logp(e). (25)
FRc
e∈Et
High H indicates dispersed curvature (topological disorder/volatility), while
FRc
low H indicates concentration on a stable backbone (topological order).
FRc
Abrupt rises in H (t) signal phase transitions in inter-brain topology and op-
FRc
erationalize affective rupture; subsequent drops track repair and re-attunement.
20 Hinrichs, Albarracin, Bolis, et al.
Practical note. In practice, some FRc(e) can be negative. To use Eq. (24), one
may (i) apply a positive shift before normalization, or (ii) work with a nonneg-
ative transform (e.g., |FRc|) when the analysis targets dispersion rather than
signed geometry. Either choice should be fixed a priori and reported.
B.4 Embedding Curvature in Active Inference
WetreatthecurvatureentropyH (t)asadyad-levelobservationchannel O
FRc κ,t
in the generative model:
(cid:0) (cid:1)
P O |S with O ≡H (t). (26)
κ,t t κ,t FRc
Hidden states S encode dyadic alignment (e.g., attunement ↔ low H ,
t FRc
rupture ↔ high H ). The agent inverts this likelihood online to infer P(S |
FRc t
O ,other cues).Curvature-inducedsurprises(unexpectedH spikes)increase
κ,t FRc
the posterior probability of rupture and drive policy adaptation toward repair;
sustained low H reinforces attuned policies.
FRc
B.5 Execution Cycle (Geometry Channel)
Figure 4 mirrors Appendix A’s execution loop, substituting the geometric chan-
nel for valence-specific computations. Here, O continuously constrains belief
κ,t
updates and policy selection.
Geometric Hyperscanning of Affect under Active Inference 21
Dual-brain signals Inter-brain network G
t
x ,x (window [t−W,t]) build w(e ) from FC
1 2 ij
Compute FRc on E
t
Eq. (23)
Observation channel Entropy H (t)
FRc
O =H (t) Eqs. (24)–(25)
κ,t FRc
Update beliefs P(S |O ,...)
t κ,t
Select policy (repair/maintain)
min. expected free energy
Act & couple
(behavior ↔ coupling)
Fig.4.Curvature-entropy observation loop (Appendix B).AslidingwindowyieldsG ,
t
FRc is computed per edge, and H (t) feeds an observation channel O for online
FRc κ,t
inference and policy selection.
B.6 Algorithmic Skeleton (Simulation-Ready)
B.7 Notes on Design Choices
– Windowing&FC.ThewindowW shouldbalancetemporalsensitivityand
estimator stability; FC choices (e.g., correlation/coherence) should match
modality and frequency-band of interest.
– Node weights.w(v )canbenodestrengthorconstant1(unweightednode
i
case); choices impact the sign/scale of FRc and should be reported.
– Normalization. If signed FRc complicates Eq. (24), adopt a fixed nonneg-
ative mapping (shift or magnitude) chosen a priori.
– Observation model. Calibrate P(O | S ) by aligning H transitions
κ,t t FRc
withbehavioral/phenomenologicalmarkers(rupture/repairannotations)for
the paradigm at hand.
22 Hinrichs, Albarracin, Bolis, et al.
Algorithm 1 Curvature-Entropy Driven Inference Cycle (mirror of Ap-
pendix A)
1: Inputs: window W; initial P(S ); coupling/likelihood params for P(O | S );
0 κ,t t
dual-brain stream or simulator.
2: for t=1,2,... do
3: Signals: extract x [t−W :t], x [t−W :t].
1 2
4: Network: compute FC across brains ⇒ weights w(e ); form G =(V,E ).
ij t t
5: Curvature: for each e ∈E , compute FRc(e ) via Eq. (23).
ij t ij
6: Entropy: compute p(e) by Eq. (24) and H (t) by Eq. (25).
FRc
7: Observation: set O ←H (t); combine with other cues.
κ,t FRc
8: Inference: update P(S |O ,...) (variational or filtering).
t κ,t
9: Policy: select action/policy minimizing expected free energy (repair if rupture
likely).
10: Act: enact behavior; update coupling/state dynamics for next step.
11: end for
Geometric Hyperscanning of Affect under Active Inference 23
References
1. Albarracin, M., Bouchard-Joly, G., Sheikhbahaee, Z., Miller, M., Pitliya, R.,
Poirier, P.: Feeling our place in the world: an active inference account of self-
esteem. Neuroscience of Consciousness 2024(1), niae007 (2024)
2. Albarracin, M., Pitliya, R., Ramstead, M.: Mapping husserlian phenomenology.
In: Friston, K., Ramstead, M., Constant, A. (eds.) Active Inference: Third Inter-
national Workshop, IWAI 2022, Grenoble, France, September 19, 2022, Revised
Selected Papers. p. 99. Springer, Heidelberg (2023)
3. Barad,K.:MeetingtheUniverseHalfway:QuantumPhysicsandtheEntanglement
of Matter and Meaning. Duke University Press, Durham (2007)
4. Bolis, D., Balsters, J., Wenderoth, N., Becchio, C., Schilbach, L.: Beyond autism:
Introducing the dialectical misattunement hypothesis and a bayesian account of
intersubjectivity. Psychopathology 50(6), 355–372 (2017)
5. Bolis, D., Dumas, G., Schilbach, L.: Interpersonal attunement in social interac-
tions: from collective psychophysiology to inter-personalized psychiatry and be-
yond. Philosophical Transactions of the Royal Society B 378(1870), 20210365
(2023)
6. Bolis, D., Schilbach, L.: ’i interact therefore i am’: the self as a historical product
of dialectical attunement. Topoi 39, 521–534 (2020)
7. Brosnan,S.,deWaal,F.:Monkeysrejectunequalpay.Nature425(6955),297–299
(2003)
8. Çatal, O., Van de Maele, T., Pitliya, R., Albarracin, M., Pattisapu, C., Verbelen,
T.: Belief sharing: a blessing or a curse. In: International Workshop on Active
Inference. pp. 121–133. Springer, Cham (2024)
9. Christov-Moore, L., Schoeller, F., von Guttenberg, M., Durinski, T., Jain, F., Ia-
coboni,M.,Reggente,N.:Usingachills-inducingscoretoaugmentlovingkindness
meditation:Effectsonself-transcendence,emotionalbreakthrough,andpsycholog-
ical insight. OSF Preprints (2025)
10. Cittern, D., Nolte, T., Friston, K., Edalat, A.: Intrinsic and extrinsic motivators
of attachment under active inference. PloS One 13(4), e0193955 (2018)
11. Coleman, M., et al.: Neurophysiological coordination of duet singing. PNAS
118(24), e2023035118 (2021)
12. Da Costa, L., Parr, T., Sajid, N., Veselic, S., Neacsu, V., Friston, K.: Active in-
ferenceondiscretestate-spaces:Asynthesis.JournalofMathematicalPsychology
99, 102447 (2020)
13. Dumas,G.,Nadel,J.,Soussignan,R.,Martinerie,J.,Garnero,L.:Inter-brainsyn-
chronization during social interaction. PLoS ONE 5(8), e12166 (2010). https:
//doi.org/10.1371/journal.pone.0012166
14. Fini, C., Bardi, L., Bolis, D., Fusaro, M., Lisi, M., Michalland, A., Era, V.: The
social roots of self development: from a bodily to an intellectual interpersonal
dialogue. Psychological Research 87(6), 1683–1695 (2023)
15. Fortune, E., et al.: Neural mechanisms for the coordination of duet singing in
wrens. Science 334(6056), 666–670 (2011)
16. Fotopoulou, A., Tsakiris, M.: Mentalizing homeostasis: The social origins of inte-
roceptive inference. Neuropsychoanalysis 19(1), 3–28 (2017)
17. Friston, K., Frith, C.: A duet for one. Consciousness and Cognition 36, 390–405
(2015). https://doi.org/10.1016/j.concog.2014.12.003
18. Gvirts,H.Z.,Perobolovski,A.:Commentary:Usingsecond-personneuroscienceto
elucidate the mechanisms of reciprocal social interaction. Frontiers in Behavioral
Neuroscience 14, 13 (2020). https://doi.org/10.3389/fnbeh.2020.00013
24 Hinrichs, Albarracin, Bolis, et al.
19. Gvirts, H.Z., Perlmutter, R.: What guides us to neurally and behaviorally align
withanyonespecific?aneurobiologicalmodelbasedonfnirshyperscanningstudies.
The Neuroscientist (2019). https://doi.org/10.1177/1073858419861912
20. Hesp, C., Smith, R., Parr, T., Allen, M., Friston, K., Ramstead, M.: Deeply felt
affect: The emergence of valence in deep active inference. Neural Computation
33(2), 398–446 (2021)
21. Hinrichs, N., Hartwigsen, G., Guzman, N.: Detecting phase transitions in eeg hy-
perscanning networks using geometric markers (2025)
22. Hinrichs,N.,Guzmán,N.,Weber,M.:Onageometryofinterbrainnetworks.arXiv
preprint arXiv:2509.10650 (2025)
23. Hoehl,S.,Markova,G.:Movingdevelopmentalsocialneurosciencetowardasecond-
person approach. PLOS Biology 16(12), e3000055 (2018)
24. Jiang, F., Luo, D.: Implementing self models through joint-embedding predictive
architecture. In: Proceedings of the Annual Meeting of the Cognitive Science So-
ciety. vol. 46 (2024)
25. Jiang, Y., Luo, D.: Valence computation as higher-order inference via conceptual
self-processing (April 2025). https://doi.org/10.31234/osf.io/nsfq5
26. Joffily, M., Coricelli, G.: Emotional valence and the free-energy principle. PLoS
Computational Biology 9(6), e1003094 (2013)
27. Lahnakoski, J.M., Forbes, P.A., McCall, C., Schilbach, L.: Unobtrusive tracking
of interpersonal orienting and distance predicts the subjective quality of social
interactions. Royal Society Open Science 7(8), 191815 (2020)
28. Lehmann, K., Bolis, D., Friston, K.J., Schilbach, L., Ramstead, M.J.D., Kanske,
P.: An active-inference approach to second-person neuroscience. Perspectives on
Psychological Science 19(6), 931–951 (2023)
29. Lombardo,M.V.,Lai,M.C.,Baron-Cohen,S.:Bigdataapproachestodecomposing
heterogeneityacrosstheautismspectrum.MolecularPsychiatry24(10),1435–1450
(2019)
30. Mandelli,V.,Landi,I.,Busuoli,E.M.,Courchesne,E.,Pierce,K.,Lombardo,M.V.:
Prognostic early snapshot stratification of autism based on adaptive functioning.
Nature Mental Health 1(5), 327–336 (2023)
31. Milton,D.E.:Ontheontologicalstatusofautism:The‘doubleempathyproblem’.
Disability & Society 27(6), 883–887 (2012)
32. Rahmjoo, A., Albarracin, M.: Intra-active inference i: Fundamentals (2023),
preprint
33. Ramseyer,F.,Tschacher,W.:Nonverbalsynchronyinpsychotherapy:coordinated
body movement reflects relationship quality and outcome. Journal of Consulting
and Clinical Psychology 79(3), 284 (2011)
34. Redcay,E.,Schilbach,L.:Usingsecond-personneurosciencetoelucidatethemech-
anisms of social interaction. Nature Reviews Neuroscience 20(8), 495–505 (2019)
35. Roma, P.G., Silberberg, A., Ruggiero, A.M., Suomi, S.J.: Capuchin monkeys, in-
equity aversion, and the frustration effect. Journal of Comparative Psychology
120(1), 67–73 (2006)
36. Schilbach, L., Timmermans, B., Reddy, V., Costall, A., Bente, G., Schlicht, T.,
Vogeley, K.: Toward a second-person neuroscience. Behavioral and Brain Sciences
36(4), 393–414 (2013)
37. Schilbach, L., Redcay, E.: Synchrony across brains. Annual Review
of Psychology 76(1), 883–911 (2025). https://doi.org/10.1146/
annurev-psych-080123-101149
Geometric Hyperscanning of Affect under Active Inference 25
38. Scholtes, C.M., Poppelaars, E.S., van Berkel, S.R., van IJzendoorn, M.H.: Dyadic
synchrony, rupture, and repair in mother–child interaction: Implications for emo-
tional and behavioral development. Development and Psychopathology 32(4),
1519–1533 (2020)
39. Smith,R.,Parr,T.,Friston,K.J.:Simulatingemotions:Anactiveinferencemodel
ofemotionalstateinferenceandemotionconceptlearning.FrontiersinPsychology
10, 2844 (2019)
40. Veissière,S.P.,Constant,A.,Ramstead,M.J.,Friston,K.J.,Kirmayer,L.J.:Think-
ingthroughotherminds:Avariationalapproachtocognitionandculture.Behav-
ioral and Brain Sciences 43, e90 (2020)
41. van Vugt, M.K., Lu, Z., Zhang, Z.: Inter-brain synchronization during agreement
versus disagreement in debate. Mindfulness 11(5), 1103–1112 (2020)
42. Vygotsky,L.S.:Mindinsociety:Thedevelopmentofhigherpsychologicalprocesses,
vol.86.HarvardUniversityPress,Cambridge,MA(1978),(Originalworkpublished
1935)
43. Wass, S.V., Whitehorn, M., Haresign, I.M., Phillips, E., Leong, V.: Interpersonal
neural entrainment during early social interaction. Trends in Cognitive Sciences
24(4), 329–342 (2020)
44. Weber, M., Saucan, E., Jost, J.: Characterizing complex networks with forman-
riccicurvatureandassociatedgeometricflows.JournalofComplexNetworks5(4),
527–550 (2017)
45. Yanagisawa, H., Wu, X., Ueda, K., Kato, T.: Free energy model of emotional
valence in dual-process perceptions. Neural Networks 157, 422–436 (2023)

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Geometric Hyperscanning of Affect under Active Inference"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
