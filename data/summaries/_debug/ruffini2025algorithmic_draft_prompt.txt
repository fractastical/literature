=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: The Algorithmic Regulator
Citation Key: ruffini2025algorithmic
Authors: Giulio Ruffini

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Abstract: The regulator theorem states that, under certain conditions, any optimal con-
troller must embody a model of the system it regulates, grounding the idea that
controllers embed, explicitly or implicitly, internal models of the controlled. This
principle underpins neuroscience and predictive brain theories like the Free-Energy
Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only
proven in limited settings. Here, we treat the deterministic, closed, coupled world-
regulator...

Key Terms: giulio, system, principle, world, complexity, algorithmic, ruffini, theorem, model, regulator

=== FULL PAPER TEXT ===

The Algorithmic Regulator
∗
Giulio Ruffini
Oct 14, 2025
Abstract
The regulator theorem states that, under certain conditions, any optimal con-
troller must embody a model of the system it regulates, grounding the idea that
controllers embed, explicitly or implicitly, internal models of the controlled. This
principle underpins neuroscience and predictive brain theories like the Free-Energy
Principle or Kolmogorov/Algorithmic Agent theory. However, the theorem is only
proven in limited settings. Here, we treat the deterministic, closed, coupled world-
regulator system (W,R) as a single self-delimiting program p via a constant-size
wrapper that produces the world output string x fed to the regulator. We ana-
lyze regulation from the viewpoint of the algorithmic complexity of the output,
K(x) (regulation as compression). We define R to be a good algorithmic regu-
lator if it reduces the algorithmic complexity of the readout relative to a null
(unregulated) baseline ∅, i.e., ∆ = K (cid:0) O W,∅ (cid:1) − K (cid:0) O W,R (cid:1) > 0. We then prove
that the larger ∆ is, the more world-regulator pairs with high mutual algorith-
mic information are favored. More precisely, a complexity gap ∆ > 0 yields
Pr((W,R) | x) ≤ C2M(W:R)2−∆, making low M(W:R) exponentially unlikely as
∆ grows. This is an AIT version of the idea that “the regulator contains a model
of the world.” The framework is distribution-free, applies to individual sequences,
and complements the Internal Model Principle. Beyond this necessity claim, the
same coding-theorem calculus singles out a canonical scalar objective and impli-
cates a planner. On the realized episode, a regulator behaves as if it minimized
the conditional description length of the readout.
∗giulio.ruffini@bcom.one, giulio.ruffini@neuroelectrics.com
1
5202
tcO
51
]CC.sc[
3v00301.0152:viXra
Contents
1 Introduction 3
2 Setting 5
2.1 The Coupled World-Regulator System . . . . . . . . . . . . . . . . . . . 6
3 Probabilistic Regulator Theorems 7
3.1 Posterior form, given the observed x . . . . . . . . . . . . . . . . . . . . 7
3.2 The Good Algorithmic Regulator and Posterior with Contrast . . . . . . 8
3.3 Inferring the Objective Function and Planner (As-If Agent) . . . . . . . . 10
4 Discussion 11
5 Conclusion 18
A Appendix 26
A.1 Setting and core definitions . . . . . . . . . . . . . . . . . . . . . . . . . 26
A.2 Three-Tape Turing Machine . . . . . . . . . . . . . . . . . . . . . . . . . 27
A.3 Prefix-free programs vs. stop-symbol delimiters (and why it matters) . . 27
A.4 Coding Theorems (unconditional and conditional) . . . . . . . . . . . . . 28
A.5 Why many long descriptions imply compressibility, and why long genera-
tors are unlikely . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
A.6 Single-episode compressibility is non-diagnostic . . . . . . . . . . . . . . 32
2
1 Introduction
In the Kolmogorov Theory (KT) of consciousness, an algorithmic agent is a system that
maintains (tele)homeostasis (persistence of self or kind) by learning and running succinct
generative models of its world coupled to an objective function and a action planner [41,
45, 44]. Closely related, Active Inference (AIF) models biological agents as minimizing
variational free energy under a generative model [20, 39]. These frameworks suggest
that “agents with world-modeling engines, objective functions, and planners” are natural
minimal models of homeostasis (goal-conditioned setpoint control). But for the kinds of
homeostaticsystemsweactuallyencounterinnature(cells,organisms,engineeredservos),
how can we tell—operationally—whether they are algorithmic agents in this sense?
The classical cybernetics statement that “every good regulator of a system must be
a model of that system” originates with Conant and Ashby’s 1970 paper (the Good
Regulator Theorem, GRT) [12]. While influential, the GRT has been criticized for the
loosenessofitsdefinitionsof“model”and“goodness”,andforaproofthatdoesnotclearly
deliver the headline claim [5]. In modern control theory, the rigorous statement that
fills a similar conceptual niche is the Internal Model Principle (IMP): under appropriate
hypotheses, perfect regulation or disturbance rejection for a given signal class requires
that the controller embed a dynamical copy of the signal generator [17, 18, 51]. The
IMP is precise (and falsifiable) within its scope, and is now a standard backbone for
robust control; see [8] for a contemporary review across control, bioengineering, and
neuroscience. However, the classical IMP is a linear result: for finite-dimensional LTI
plants ( linear, time-invariant meaning the system matrices do not change with time) and
exogenous signals generated by a finite-dimensional LTI exosystem, robust asymptotic
tracking/disturbance rejection requires that the controller embed a copy of the exosystem
dynamics [19]. For nonlinear systems, the appropriate generalization is the nonlinear
output-regulation framework: if the regulator equations admit smooth solutions and
the plant’s zero dynamics on the regulated manifold are (locally) stable, together with
suitable immersion/detectability assumptions, then one can construct dynamic output-
feedback regulators that embed a (possibly adaptive) internal model and achieve local or
semiglobal robust regulation [29, 26, 40]. However, absent these structural hypotheses, a
complete nonlinear analogue of the IMP with the same necessity/robustness guarantees
asintheLTIcaseisnotgenerallyavailable. Table2providesacomparisonofthedifferent
regulator theorem statements, which can be compared with the one presented here.
In this paper, we recast the modeling requirement in a setting independent of linearity,
probability, exact regulation or specific signal classes, by using algorithmic information
theory (AIT). We model a world W and a regulator R as deterministic causal Turing
machines that interact over interface tapes. We denote the world output by x = O
W
(over some temporal horizon of length N). Our main technical claim is that regulation in
the algorithmic sense, i.e., simplicity, forces algorithmic dependence between W and R.
Definition of model
A model in the present context is a program capable of compressing (or generating)
data. Similarly, “the regulator contains a model of the world” is interpreted in an
algorithmic-information sense: the regulator R carries nontrivial information about W,
quantified by positive mutual algorithmic information M(W:R) > 0 (up to the standard
O(log) slack). Equivalently, knowing R makes the shortest description of W strictly
3
shorter, K(W | R) < K(W). This notion does not require R to embed a dynamical copy
of W; rather, it formalizes “model content” as mutual algorithmic information.
We formalize this with the following definition:
Definition 1.1 (Algorithmic“internalmodel”). GivenafixedhorizonN (implicitly
conditioned),wesaythatRcontains an internal model of W in the algorithmic sense
if M(W:R) > 0 (up to O(log)), equivalently K(W | R) < K(W). The magnitude of
M(W:R) quantifies the amount of computable structure in W that R carries.
The definition ground on mutual algorithmic information M is further motivated by
the following: (i) Machine invariance: M is invariant up to O(1) under changes of
universal machine. (ii) Distribution-free: M is defined for individual objects (programs),
not probabilistic models. (iii) Operational meaning: M(W:R) is precisely the codelength
reduction in describing W when R is known, aligning with MDL/Occam reasoning via
the Coding Theorem [50, 65, 33].
This is the appropriate lens for our contrastive results, and it complements the Internal
Model Principle, where “model” means a dynamical replica of the Exosystem (a part of
the World in our framework, see Figure 2) under stated structural hypotheses [19, 29, 26,
40]. Conceptually, our AIT result is complementary to the IMP: whereas the IMP states
what structural content must be present in a controller to achieve perfect regulation for
a given signal class [17, 18, 51], our results quantify how much algorithmic information
the regulator must carry about the world whenever it succeeds in making the measured
outcome compressible.
Regulation as compression
We score regulation by how compressible a task-weighted error stream is. Let x be the
t
weighted error and x the T-sample string. Fix a prefix-free lossless code (e.g., a univer-
1:T
sal compressor) and define the per-sample codelength L := 1L (x ). A regulator R is
T T C 1:T
better on horizon T when it makes L smaller than a null baseline ∅, i.e., when the con-
T
trastive gap ∆ := L (x;∅)−L (x;R) is positive. This choice is natural: for stationary
T T
ergodic data, normalized universal codelengths converge (a.s.1) to the Shannon entropy
rate h(x), and (under standard computability assumptions) K(x )/T = h(x)+o(1) al-
1:T
most surely; thus the Kolmogorov-based criterion reduces to the Shannon criterion when
those stochastic assumptions hold—while remaining meaningful outside them [63, 13, 33].
To see the connection between regulation and compression in more detail, let h (α) :=
x1:T
min log|S|denotetheKolmogorovstructurefunction [57]. Regulationamounts
S∋x1:T,K(S)≤α
to moving down this curve: as the regulator invests model bits (larger α), more regularity
in x is captured and the residual randomness h (α) drops, approaching 0 at perfect
1:T x1:T
regulation. The notion of robability emerges along this path. Replacing set-models by
probabilistic models {P } turns the two-part description into the standard MDL form
M
T
(cid:88)
L(x ;M) ≈ K(M) − logP (x ),
1:T M t
t=1
1“Almost surely”: with probability 1.
4
where the second term is the ideal codelength under P (Shannon coding: −logP )
M M
[13, 33, 22]. If the regulator must hedge over multiple models, the mixture/Bayes code
¯ (cid:80)
with prior π uses P(x ) = π(M)P (x ) and assigns
1:T M M 1:T
(cid:88)
¯
L (x ) = −logP(x ) = −log π(M)P (x ),
mix 1:T 1:T M 1:T
M
a valid prefix code whose regret relative to the best single model M⋆ is bounded by
−logπ(M⋆); with π(M)∝2−K(M) (Solomonoff/Occam), the penalty matches the model
description length [7, 22, 49, 50, 33]. Thus, probabilistic/Bayesian regulation is the
coding-optimal way to descend h (α), aligning with the multi-model argument in [43].
x1:T
Finally, we can treat the regulator input as an error signal quantized at fixed sensor
resolution; the per-sample codelength of x under a universal compressor converges to
1:T
the entropy rate for stationary sources. For Gaussian processes,
1 (cid:90) π
(cid:0) (cid:1)
h(x) = log 2πeS (ω) dω,
xx
4π
−π
where S is the input power spectral density [63, 21] of the error signal x, so attenuating
xx
in-band sensitivity (reducing S where it matters) reduces codelength [21]. In the scalar
xx
white-Gaussian case with variance σ2, h = 1 log(2πeσ2), so smaller-amplitude fluctua-
2
tions (smaller σ) mean lower entropy and better compressibility. In short, “compressible
error” matches the classical view: good regulation removes variability/uncertainty in the
task band and accords with the IMP [4, 19].
In the next sections, we first provide an overview of the AIT setting and of the results,
followed by the analysis of the single episode scenario. The next section provides a formal
definition of the algorithmic regulator and the corresponding theorem.
2 Setting
Unless stated otherwise, U is the standard three–tape universal prefix Turing machine:
a read-only input tape holding a self-delimiting program p, a work tape (private scratch
memory), and a write-only output tape. When we write U(p) = x we mean that, upon
halting, the contents of the output tape equal x; the work tape is never part of the scored
output. Thedomainofhaltingprogramsisprefix-free, soKraft–McMillanappliesandthe
universal a priori semimeasure m(x) = (cid:80) 2−|p| is well defined. By the invariance
U(p)=x
theorem,replacingU byanyotheruniversalprefixmachine(single-ormulti-tape)changes
all complexities only by an additive O(1); all Coding-Theorem statements we use depend
only on prefix-freeness and therefore remain valid up to these constants (see, e.g., [33]).
The (prefix) Kolmogorov complexity of x is the length of its shortest description,
K(x) := min{|p| : U(p) = x}.
Intuitively, K(x) is the best achievable compressed size of x on U. If K(x) ≪ |x|, then
x has a short generative regularity; if K(x) ≈ |x|, x is (algorithmically) random. By the
invariance theorem, K is machine-independent up to an additive constant O(1) [33]. A
fundamental limitation is that K(·) is not computable: no algorithm can output K(x) for
all x [10, 33]. However, algorithms for upper bounds of K(x) exist, as we discuss below.
5
Given auxiliary data y on a read-only auxiliary tape, the conditional complexity
K(x | y) := min{|p| : U(p,y) = x}
is the shortest description of x given y. It operationalizes how much new information is
needed to reconstruct x once y is known (e.g., “world given regulator,” or “output given
model”).
The mutual algorithmic information (up to the usual O(log) slack) is
M(x:y) := K(x)+K(y)−K(x,y) = K(x)−K(x | y) = K(y)−K(y | x) ±O(log).
M(x:y) measures the algorithmically shared structure between x and y: how many bits
we save when describing one with the help of the other. In our setting, “the regulator
contains a model of the world” means M(W:R) > 0 (information-theoretic dependence),
not necessarily a dynamical replica.
Intuitively, strings produced by shorter programs are more likely. Solomonoff–Levin’s
universal a priori semimeasure m(x) and the Coding Theorem link probability and de-
scription length:
−log m(x) = K(x) ±O(1), (1)
2
providing a universal Occam calculus over individual strings. [50, 49, 64, 33].
In what follows, a finite temporal horizon N is fixed throughout; unless stated other-
wise, we implicitly condition on N (e.g., write K(x) for K(x | N)). All O(1) constants
depend only on the choice of U (and the fixed constant-overhead wrapper that decodes
(W,R) and simulates their coupling to print the readout), never on particular strings; see
Appendix A.2.
2.1 The Coupled World-Regulator System
We work with 3-tape Turing machines W and R (see Figure 1 and Appendix A.2). We
identify each machine with its minimal self–delimiting program (|W| = K(W), |R| =
K(R)) [33]. A horizon N ∈ N is fixed and all complexities are conditioned on N unless
otherwise stated. W and R interact causally for N steps, producing a deterministic
readout O(N) ∈ {0,1}N. The dynamical equations are
W,R
O = W(O ), O = R(O ). (2)
W R R W
The performance of the regulator is evaluated from the complexity of the output, K(x).
Intuitively, a good regulator produces outputs of lower complexity than the unregulated
case. Since x = O(N) is computable from (W,R,N),
W,R
K(x) ≤ K(W,R)+O(1) = K(W)+K(R)−M(W:R)+O(1). (3)
To disentangle the role of R from the coarse event “K(O(N)) is small,” we fix a null
regulator ∅ (where R’s output is set to zero). We compare the events
ER : K(O(N)) = a vs E ∅ : K(O(N)) = b, (4)
a W,R b W,∅
6
Figure 1: Regulation scenario. A) A good regulator R interacts with the world W so that
the readout x = O of the world’s output is clamped to a simple, highly compressible
W
sequence (e.g., almost all zeros). B) When the regulator is turned off, the output is more
complex.
∅
with b > a. Event E rules out worlds that produce a simple output without regulation;
b
the intersection ER ∧E ∅ isolates R’s contribution.
a b
For notational simplicity, the on–case and off–case readouts are also expressed as
x := O(N), y := O(N).
W,R W,∅
For a fixed time horizon, we write O for the full output produced by W when coupled
W
to R.
In the next sections, we provide our main results regarding mutual information between
world and regulator, and implications for inferring agent-like behavior in the regulator.
3 Probabilistic Regulator Theorems
3.1 Posterior form, given the observed x
Lemma 3.1 (Program posterior given x). With prefix prior P(p) = 2−|p| and de-
terministic likelihood P(x | p) = 1{U(p) = x},
2−|p|
P(p | x) = .
m(x)
Consequently, by (5),
1 1
2K(x)−|p| ≤ P(p | x) ≤ 2K(x)−|p|.
c c
2 1
Proof. For any finite string x,
(cid:88)
K(x) := min{|p| : U(p) = x}, m(x) := 2−|p|.
p:U(p)=x
7
(recall Eq. 1). The Coding Theorem gives machine-dependent constants c ,c > 0 with
1 2
c 2−K(x) ≤ m(x) ≤ c 2−K(x). (5)
1 2
Now, briefly, Bayes’ rule yields Pr{p | x} = 2−|p|/m(x); apply (5). In more detail,
place the prefix prior P(p) = 2−|p| on programs p and use the deterministic likelihood
P(x | p) = 1{U(p) = x}. Then the evidence is P(x) = m(x) and the posterior is
 2−|p|
P(x | p)P(p)  , U(p) = x,
P(p | x) = = m(x)
P(x)
0, otherwise.
Then, for any p with U(p) = x,
1 2−|p| 1
2K(x)−|p| ≤ P(p | x) = ≤ 2K(x)−|p|.
c m(x) c
2 1
The relation between K(x) and m(x) holds only up to an additive O(1) term in K, which
becomes a multiplicative constant on m(x). This O(1) ambiguity is unavoidable and
depends on the choice of universal prefix machine U; c ,c absorb exactly this machine-
1 2
dependent slack.
Now, in our setting the world W and regulator R are programs that interact for N steps,
producing the on-case readout x := O(N). A fixed, constant-overhead wrapper decodes a
W,R
shortest description of (W,R) and simulates the coupling to print x (decode+simulate);
if p denotes this canonical code, then
W,R
(cid:104) (cid:105)
(cid:0) (cid:1)
|p | = K(W,R)+O(1), P (W,R) | x ∈ 1, 1 ·2K(x)−K(W,R), (6)
W,R c˜2 c˜1
for constants c˜ := 2O(1)c .
i i
Now we can use the definition of mutual algorithmic information (up to the usual O(log)
slack) to write
M(W:R) = K(W)+K(R)−K(W,R)
and derive our first result:
Theorem 3.1.
(cid:104) (cid:105) 1
(cid:0) (cid:1)
P (W,R) | x ∈ 1, 1 ·2K(x)−K(W)−K(R)+M(W:R) < 2M(W:R) (7)
c˜2 c˜1 c˜
3.2 The Good Algorithmic Regulator and Posterior with Con-
trast
For our second result, we first define the Good Algorithmic Regulator (GAR).
8
Definition 3.1 (Good Algorithmic Regulator, contrastive). Given the on/off com-
plexities and gap
a := K(O(N)), b := K(O(N)), ∆ := b−a.
W,R W,∅
we say that R is a good algorithmic regulator of gap ∆ for W at horizon N if ∆ > 0.
Lemma 3.2 (OFF run lower-bounds the world). There exists c = O(1) such that
0
K
(cid:0) O(N)(cid:1)
≤ K(W)+c ⇒ K(W) ≥ b−c .
W,∅ 0 0
Proof. Given (W,∅,N), the wrapper simulates the OFF dynamics and prints O(N) with
W,∅
O(1) overhead.
With this definition we can now state and prove our main theorem.
Theorem 3.2 (Probabilistic regulator theorem). Let O(N) and ER be observed and
W,R b
let ∆ := K(O(N))−K(O(N)). Then there exists C > 0 such that
W,∅ W,R
P (cid:0) (W,R) | O(N),ER (cid:1) ≤ C · 2M(W:R) 2−∆.
W,R b
Equivalently, every bit by which M(W:R) falls short of ∆ costs a factor ≈ 2−1 in
posterior support.
Proof. (i) Posterior via wrapper. From Eq. (6), log P((W,R) | x) ≤ K(x)−K(W,R)+
2
O(1) = a−K(W,R)+O(1).
(ii) Decompose K(W,R). We use the exact mutual information M(W:R) := K(W) +
K(R)−K(W,R), K(W,R) = K(W)+K(R)−M(W:R), hence
K(x)−K(W,R) = a−K(W)−K(R)+M(W:R).
(iii) Insert OFF bound (where b enters). By Lemma 3.2, K(W) ≥ b−c , so
0
K(x)−K(W,R) ≤ M(W:R)−(b−a)−K(R)+c = M(W:R)−∆−K(R)+c .
0 0
(iv) Exponentiate and absorb constants. Exponentiating and using 2−K(R) ≤ 1 gives
P((W,R) | x,ER) ≤ C2M(W:R)2−∆ for a constant C absorbing 2c0 and the wrapper
b
Coding-Theorem constants.
Clarifications. (i) Where does b appear? Only via Lemma 3.2, which says the OFF
run lower-bounds K(W). We never need to compute b explicitly. (ii) Why can we drop
2−K(R)? A slightly sharper bound is P((W,R) | x,ER) ≤ C2M(W:R)2−∆2−K(R). Since
b
K(R) ≥ 0, dropping 2−K(R) ≤ 1 keeps the focus on the two interpretable scalars M and
∆ without changing the exponential scaling. (iii) Architecture-agnostic. The proof only
uses the computable wrapper (W,R,N) (cid:55)→ x. Whether R is open- or closed-loop does not
9
affect the posterior algebra. iv) The posterior on the left of Theorem 3.2 is conditioned on
the on-case observation x only. The off-case run is used solely to supply a numeric lower
bound b := K(O(N)), which implies K(W) ≥ b−O(1) by simulation. Formally, wephrase
W,∅
the result as a bound on Pr((W,R) | x,ER), where ER is the side-event “K(O(N)) = b”.
b b W,∅
AsaconsequenceofTheorem3.2,onecanboundindividualposteriormassesbyO(2K(x)−K(W,R)).
This implies an exponential tail: PrM(W : R) ≤ ∆−k = O(2−k). In other words,
M(W : R) is concentrated within O(1) of its maximum ∆. I.e., there exists C′ > 0
(machine/wrapper dependent only) such that for all integers k ≥ 0,
(cid:110) (cid:12) (cid:111)
Pr M(W:R) ≤ ∆−k (cid:12) x, ER ≤ C′2−k.
(cid:12) b
How to read (and use) Theorem 3.2.
1. What we measure: compute the on/off complexities a = K(O(N)) and b =
W,R
K(O(N)) (in practice: fixed MDL code lengths); their difference ∆ = b − a is
W,∅
the compressibility advantage.
2. What the bound says: for any explanation (W,R) of the observed x, the univer-
sal posterior weight is penalized as 2−∆ unless the pair shares structure: larger
M(W:R) compensates the penalty.
3. Practical rule of thumb: sustained large ∆ across tasks makes low M(W:R) ex-
ponentially unlikely. If off-case b is already small, ∆ will be small—choose a
diagnostic readout so the null is not trivially simple.
3.3 Inferring the Objective Function and Planner (As-If Agent)
We next provide a simple theorem regarding the role of complexity as an objective func-
tion.
Theorem 3.3 (On/Off evidence equals unconditioned complexity gap). Under the
universal a priori semimeasure,
m(O(N))
log W,R = K(O(N)) − K(O(N)) ±O(1). (8)
2 m(O(N)) W,∅ W,R
W,∅
Equivalently, writing the on/off gap as ∆ := K(O(N)) − K(O(N)), we have
W,∅ W,R
m(O(N))/m(O(N)) = Θ (cid:0) 2∆ (cid:1) . Hence, on the realized pair (O(N),O(N)), maxi-
W,R W,∅ W,R W,∅
mizing the likelihood of “ON over OFF” is equivalent (up to a constant factor) to
minimizing K(O(N)) or, equivalently, maximizing the gap ∆.
W,R
Proof. By the Coding Theorem there exist machine-dependent constants c ,c > 0 such
1 2
that c 2−K(z) ≤ m(z) ≤ c 2−K(z) for any string z. Apply this to x and O(N), take base-2
1 2 W,∅
logs, and subtract:
−log m(O(N)) = K(O(N))±O(1), −log m(O(N)) = K(O(N))±O(1),
2 W,R W,R 2 W,∅ W,∅
10
so log m(O W (N ,R )) = K(y)−K(O(N))±O(1).
2 m(O(N)) W,R
W,∅
This statement compares two different strings (the realized ON and OFF outputs) and
aligns with the contrastive quantities used elsewhere. The log universal Bayes factor for
“ON vs. OFF” is seen to equal the complexity gap ∆±O(1). Thus, on each episode, a reg-
ulator behaves as if it were maximizing the scalar ∆, equivalently minimizing K
(cid:0) O(N)(cid:1)
.
W,R
Thus, given a regulator R that persistently reduces the readout’s complexity relative to
a null baseline ∅ (the GAR setting of Def. 3.1), we can justify—on purely observational
grounds—thatR behavesas if it were minimizing a scalar objective. Theobjectiveshould
be canonical (not post hoc) and usable across episodes/tasks.
4 Discussion
We can summarize now our results:
First regulator result: posterior form, given the observed x (Th. 3.1). By
Solomonoff induction and the Coding Theorem [50, 49, 65, 58, 27], we showed that
2−K(W,R)+O(1) 1
(cid:0) (cid:1)
Pr (W,R) | x = ∼ 2K(x)−K(W,R) < 2M(W:R) (9)
m(x) c˜
Thus shorter joint generators are exponentially preferred; every extra bit in K(W,R)
halves the posterior weight. Decomposing
K(W,R) = K(W)+K(R) − M(W:R) ±O(log) (10)
shows that, at fixed marginals K(W),K(R), the posterior is exponentially tilted in the
algorithmic mutual information M(W:R): each extra bit of M(W:R) multiplies posterior
odds by ≈ 2.
Second regulator result: posterior with contrast (Th. 3.2). Without contrast,
thestoryispureOccam: (9)anchorstheposteriornearK(W,R) ≈ K(x)withageometric
excess-length tail; for fixed K(W),K(R), this yields a high-probability lower bound on
M(W:R) roughly K(W)+K(R)−K(x). With contrast, if turning the regulator on yields
K(O(N)) = a while the off case has K(O(N)) = b with b > a, then any explaining (W,R)
W,R W,∅
obeys
Pr((W,R) | x) ≤ C2M(W:R)2−∆,
so low mutual information is exponentially disfavored as the gap ∆ = b−a grows. In both
regimes, the operational slogan holds: see a simple string (K(x) small), suspect a simple
generator (K(W,R) small), and at fixed marginals this means suspect larger M(W:R).
The inutition behind these results is that seeing a simple string suggests its generation
by a simple program. Formally, for the coupled hypothesis P = (W,R) (wrapped as
a single self-delimiting program), observing x = O(N) yields the Solomonoff posterior
W
Pr(P | x) ∼ 2K(x)−K(P), by the Coding Theorem [50, 49, 65, 58, 27]. Every extra bit
of joint description K(P) = K(W,R) halves posterior weight. This is the quantitative
Occam tilt that operationalizes the slogan above.
11
The posterior mass of joint programs longer than K(x)+k decays geometrically:
Pr{K(W,R) ≥ K(x)+k | x} ≤ 2C2−k.
HencethetypicaljointlengthisnearK(x). IfK(W)andK(R)areexternallyconstrained
(e.g., by design or prior knowledge), this tail translates directly into a lower posterior
bound on M(W:R) of the form M(W:R) ≳ K(W)+K(R)−K(x)−O(log(1/δ)) with
posterior confidence 1−δ.
Our results are most informative when the observed readout O(N) is simple. If K(O(N))
W W
is large, the posterior constraints on joint complexity and on mutual information are
inherently weak. From the geometric tail, for any δ ∈ (0,1) there exists k = ⌈log (2C/δ)⌉
2
such that, with posterior probability at least 1−δ,
K(W,R) ≤ K(O(N))+k.
W
At fixed marginals K(W) and K(R) this yields
M(W:R) ≥ K(W)+K(R)−K(O(N))−k −O(log) with probability ≥ 1−δ.
W
Hence, if K(O(N)) is large (comparable to K(W)+K(R)), the lower bound on M(W:R)
W
may be trivial (near 0 up to logs). Intuitively, a complex output does not force shared
structure. It is compatible with a complex joint generator even when W and R share
little algorithmic information.
On the other hand, the strength of the conclusion depends on the gap ∆ = b−a:
Pr (cid:0) (W,R) | O(N),ER (cid:1) ≤ C2M(W:R)2−∆, Pr (cid:8) M(W:R) ≤ ∆−k (cid:12) (cid:12)O(N),ER (cid:9) ≤ C′2−k.
W b W b
Thus even if a = K(O(N)) is not very small, a large off/on gap still enforces a large
W,R
posterior M(W:R). In other words, contrast rescues identifiability of shared structure:
the evidence scales exponentially in ∆.
In the same universal calculus, regulation carries a canonical scalar interpretation: run-
time behavior is as if minimizing K(O(N)) (i.e., maximizing the on/off gap ∆), and
W
design-time comparison across explanations favors larger M(W:R) − ∆ via the GAR
posterior tilt. This supplies an MDL/Occam objective grounded in the coding theorem
(not an ad hoc utility) and complements the IMP’s structural requirements.
WenotethatalowK(O(N))alone doesnotprovehighM(W:R); itconcentratesposterior
W
mass on short joint generators P. High M(W:R) follows (i) when K(W) and K(R) are
fixed/known, or (ii) when contrast pins K(W) high via the off case. Without such
constraints, short P could also arise from individually simple W and R.
Third regulator result: as-if Objective-function minimization (Th 3.3). On
the realized O(N), the conditional Coding Theorem gives log (cid:0) m(O(N))/m(O(N)) (cid:1) =
W 2 W W,∅
K(O(N))−K(O(N)). Thus, the runtime scalar to minimize is K(O(N)). Together with
W,∅ W W
the above, this implies that the regulator is acting (as-if) like an algorithmic agent (with
a model of the world, objective function and planner).
Theorem 8 is a representation statement— not a mechanism: R need not compute K, but
persistent large ∆ is exactly what maximizes universal evidence for “ON”, and it simulta-
neously makes low M(W:R) exponentially unlikely. For a mechanistic objective beyond
12
theMinimumDescriptionLength(MDL)evidence, threeconstructiveroutesarestandard
and complementary. First, in Linear Time-Invariant (LTI) plants the Internal Model
Principle makes a structural claim—perfect robust regulation for a specified signal class
requires embedding a dynamical copy of the exosystem in the controller—and optimal
stabilizing designs arise from explicit quadratic/convex costs (e.g., the Linear Quadratic
Regulator, LQR); in the nonlinear case, output-regulation theory yields constructive reg-
ulators under solvable regulator equations together with immersion/detectability and (lo-
cal) zero-dynamics stability [17, 18, 51, 29, 26, 40, 3]. Second, in inverse optimal control
and inverse reinforcement learning (IRL), trajectories that satisfy Karush–Kuhn–Tucker
(KKT) regularity allow identification of a cost J (up to equivalences) whose minimizers
reproduce the behavior; in discrete settings, IRL recovers reward functions consistent
with observed policies [38, 1, 62]. Third, in revealed-preference analysis, if cross-episode
choices satisfy the Generalized Axiom of Revealed Preference (GARP), Afriat and Var-
ian guarantee the existence of a strictly increasing, concave utility that rationalizes the
data, while Debreu’s representation and the Savage/Karni–Schmeidler frameworks pro-
vide (state-dependent) expected-utility forms under their axioms [2, 56, 14, 46, 30].
Planner/policy representation (as-if agent). Any deterministic causal regulator R
induces a computable policy π : H →A mapping the coupled history h (past interface
R t t
I/O up to time t) to the next actuator symbol. This is simply the operational semantics
of R viewed as a function of histories.
The coding-theorem Bayes-factor identity (Thm. 3.3) supplies a canonical scalar such
that, on the realized episode, the sequence of actions produced by π is as if chosen
R
to maximize J subject to the world dynamics. Together with the algorithmic “internal
model” conclusion M(W:R) > 0 (i.e., K(W | R) < K(W)), this yields the standard
agent triad:
(model) M(W:R) > 0, (objective) J(x) = K(y)−K(x), (policy/planner) π .
R
Interpretation. This is a representation statement, not a claim that R explicitly solves an
optimization problem or contains a modular planner. The existence of π is tautological
R
for any deterministic R; the “as-if” objective follows from the universal evidence identity
above. Across tasks/episodes, if the induced choices satisfy standard consistency axioms
(e.g., GARP), classical revealed-preference theorems guarantee the existence of a (mono-
tone, concave) utility that rationalizes the behavior [2, 56]; and in dynamical settings,
inverse optimal control / inverse RL constructs a cost for which the observed policy is
(near-)optimal [38, 1]. Thus, given (i) algorithmic model content M(W:R) > 0 and (ii)
the canonical scalar J from the coding-theorem calculus, interpreting the regulator as
carrying a policy/planner is both natural and technically justified.
Why AIT is needed
Our results are single-episode and distribution-free: they make statements about an indi-
vidual realized readout x and about the pair (W,R) as concrete programs, without posit-
ing a stochastic source. Classical (Shannon) information theory quantifies expected code
lengths and mutual information with respect to a specified probability law; entropy H(X)
and mutual information I(X;Y) are undefined without a distribution, and asymptotic
statements (AEP/typical sets) further require ergodicity/mixing assumptions [13]. In our
13
setting, there is no given probabilistic model over worlds, regulators, or outputs—indeed,
the point is to infer model content from a single realized x.
AITsuppliesexactlythemissingcalculus. First,itprovidesacanonical,machine-invariant
complexity for individual strings, K(x), and a universal a priori semimeasure m(x)
(Solomonoff–Levin), connected by the Coding Theorem: −logm(x) = K(x) ± O(1)
(cid:0) (cid:1)
[50,49,64]. ThisyieldsauniversalOccamposterioroverprograms, Pr p | x ≍ 2K(x)−|p|,
from which (i) the geometric excess-length tail and (ii) our contrastive tilt bounds fol-
low. No analogue exists in Shannon’s framework without positing an external prior over
programs; there is no “canonical” Pr(p) or Pr(x) in Shannon theory.
Second, AIT lets us formalize “the regulator contains a model of the world” as algorith-
mic dependence, i.e. positive mutual algorithmic information M(W:R) > 0 (equivalently
K(W | R) < K(W)), a notion defined for individual objects and invariant up to O(1)
([33]). By contrast, Shannon’s I(W;R) requires a joint distribution over (W,R), which
is neither given nor natural here.
Third, our key inequalities explicitly use m(·) and prefix complexity: the posterior tilt
2K(x)−K(W,R), the OFF-run lower bound on K(W) by simulation, and the contrastive
penalty 2−∆ all rely on the Coding Theorem and Kraft–McMillan properties of prefix
programs—again, objects absent from Shannon’s ensemble-level calculus.
Finally, while one can approximate K(·) with MDL/codelengths in practice, MDL’s jus-
tification itself rests on the AIT view that shorter descriptions are better and on the
coding-theorem linkage between description length and (universal) probability [22]. In
short: AIT provides the universal prior (m), object-level complexities (K), and mutual
algorithmic information (M) needed to turn the informal slogan “see a simple string,
suspect a simple generator” into posterior and contrastive theorems—none of which can
be stated in Shannon’s framework without ad hoc model classes and priors.
Relation to the Internal Model Principle (IMP)
In the IMP, the closed loop is (E,C,P): an autonomous exosystem E (no inputs and no
explicit time dependence, e.g. w˙ = Sw), a controller C (the regulator), and a plant P.
The regulated error is e = r−y, where the reference r and disturbances are generated by
E and y is measured from P [17, 18]. In our notation, we group the World as W = (E,P)
and take the Regulator as R ≡ C (see Figure 2 and Table 1 for the comparison of the
two frameworks in the case of a thermostat).
The assumptions in IMP theorems are: (i) Classical necessity is sharpest for finite-
dimensional LTI plants (linear, time-invariant) with exogenous signals generated by a
finite-dimensional, neutrally stable LTI E; stabilizability/detectability and robustness
(one fixed C works for a plant neighborhood) are standard [17, 18]. (ii) The structural
conclusion is internal-model necessity: perfect robust regulation for the specified signal
class requires that C embed a dynamical copy of E (e.g., integrators for steps, oscillators
for sinusoids); in MIMO, a p-copy is needed. (iii) Nonlinear generalizations (output reg-
ulation) require solvability of the regulator equations, suitable immersion/detectability,
and (local) stability of the zero dynamics; guarantees are typically local/semiglobal, and
necessity is not universal [29, 26, 40]. (iv) Infinite-dimensional/distributed settings and
periodic signals may require infinite-dimensional internal models; technicalities arise with
unbounded I/O operators [8].
14
World (W) Regulator (R)
Forcing
Control
Ref Measurement
Exosystem
Plant
Error
Figure 2: To connect the IMP and the AIT formulation used here, we view the World
W as a box containing E and P; the Regulator/Controller R (or C) is a separate box.
Arrows depict Forcing (E →P), Ref (E → sum), the Error path (sum ↓ to the world
boundary and → R), and Control (R→P).
In the AIT formulation (here), we assume: (i) Architecture-agnostic: no required split
into E vs. P, and no specified place where R enters the causal path; we only assume a
computable wrapper mapping (W,R,N) (cid:55)→ O for a fixed horizon N. (ii) Deterministic,
W
closed coupling of world and regulator (no stochastic noise sources into W); statements
are distribution-free and about the realized sequence. (iii) “Model” means algorithmic
dependence: M(W : R) > 0 (equivalently K(W|R) < K(W)), not a literal dynamical
replica. (iv) The main necessity is probabilistic: a positive on/off complexity gap ∆ =
K(O )−K(O ) exponentially tilts the universal posterior against explanations with
W,∅ W,R
small M(W :R); no linearity, smoothness, or regulator-equation conditions are imposed.
See Secs. 2–6 of this work.
IMP yields a structural necessity (internal model in C of E) under explicit dynami-
cal hypotheses; the AIT formulation yields an information-theoretic necessity (positive
M(W:R) favored by the data) without assuming linearity, an E/P split, or a particular
causal insertion point for R. The two are complementary: IMP is the backbone for con-
structive regulation in structured classes; the AIT view covers unstructured architectures
and single episodes with a universal Occam calculus [17, 18, 51, 29, 26, 8].
The home thermostat. As an example, consider a home thermostat as regulator/-
controller. Let P be the living room+heater dynamics (thermal capacitance, heat loss,
delays) and E the exogenous processes (setpoint schedule, outdoor weather/solar, occu-
pancy). The Internal Model Principle (IMP) states that exact output regulation for a
specified signal class is possible only if the controller embeds a copy of the exosystem E
that generates those signals (e.g., an integrator for steps, an oscillator for a fixed sinu-
soid); plant knowledge is used for stabilization/shaping, but the IMP necessity targets
E itself [19, 9]. In our AIT view, a regulator R is “good” when it makes the realized
readout more compressible than a null baseline; a sustained compressibility gap implies
that R shares computable structure with the whole world W=(P,E):
(cid:0) (cid:1)
M(W:R) = M (P,E) : R = M(P:R) + M(E:R | P) ±O(log).
15
Role IMP language AIT language (this work) Thermostat instantiation
Exogenous generator ExosystemE: autonomous FoldintotheWorldW;no Referencer(t): setpoint
generatorof architecturalsplitisrequired schedule(oftenclock-driven).
references/disturbances(no (butmaystillconceptually Disturbances: outdoor
feedbackfromC);exact identifythissubpart). temperature,solarload,
regulationisdefinedw.r.t.a occupancyheatgains.
signalclassU.
Plant PlantP: roomthermal AlsoinsideWorldW. R–C (thermal)model,heater
dynamics+actuator/sensor; actuation,heatlosses,sensor
usedfor dynamics/delay.
stabilization/shaping.
Controller / ControllerC (theregulator RegulatorR. Thermostatlogic: bang-bang
Regulator inIMP). withhysteresis,PI/TPI,or
scheduledcontrol.
Measured output y. Worldreadoutxextracted IndoortemperatureTin (ora
fromthetranscript(often weightederrorsignal).
x=y ortheerrorstringe1:T).
Error / objective e=r−y;IMPconcerns Scoreregulationby Goodthermostat⇒xon
asymptotic e→0forallr,d compressibility ofthechosen (e.g.,temperatureorerror)
intheclassU (internalmodel readoutxwithRON vs.an staysneararegular
mustmatchE). OFF baseline(R=∅). Define deadbandpattern⇒shorter
thegap codethanthenull/open-loop
∆ = K(x
off
) − K(xon) case(heaterOFForfixed
(practically,useafixedMDL duty).
codeLC inplaceofK).
Table 1: Mapping the IMP triple (E,C,P) and the AIT (W,R) view to a simple ther-
mostat. IMP emphasizes an internal model of the exosystem E for exact regulation over
a signal class; AIT treats W=(P,E) jointly and assesses regulation by a compressibility
advantage ∆.
A simple on/off thermostat with a deadband tuned to the room time constant typically
yields a bounded limit cycle (not zero steady-state error); under IMP it lacks the needed
internal model of constants (no embedded integrator), hence it does not achieve exact
regulation of the “constant” class [19, 4]. Nevertheless, in the AIT sense it still qualifies
as a regulator: its policy encodes a very compressed model spanning P (heating raises
T, room inertia) and weak regularities in E (quasi-constant setpoint, slowly varying
weather), giving M(W:R) > 0 [12]. PI/PID or predictive thermostats remedy the IMP
shortfall by embedding the appropriate internal model (and often explicit models of P
and aspects of E) [4].
The AIT regulator framework (as well as the original GRT) is therefore more general
than IMP: the regulator must carry a model of the world W = E ∪ P, where P is the
plant (house/HVAC thermodynamics) and E the exogenous processes (setpoint sched-
ule, weather/solar/occupancy), and IMP is recovered as a special case when the per-
formance target is exact output regulation over a specified signal class. Under IMP, a
controller qualifies for exact regulation only if it embeds a dynamical copy of the exosys-
tem that generates the reference/disturbances (e.g., an integrator for steps, oscillators for
sinusoids)—no model of P is required beyond stabilizability/detectability [19]; nonlinear
output-regulation extends this under additional immersion/detectability and regulator-
equation solvability assumptions [9].
Ourstatementsarethuscomplementaryanddistinct: inAIT,weworkinadistribution-free,
program-level setting and make no linearity or smoothness assumptions. We remain ag-
nostic about what the regulator needs to model and do not demand exact regulation.
16
We do not assert the existence of a dynamical replica inside R. Instead, we show that
sustained contrastive compressibility (∆ > 0) tilts the universal posterior toward pairs
(W,R) with larger mutual algorithmic information M(W:R), i.e., R carries algorith-
mic structure about W. Thus, “the regulator contains a model” is made precise as
M(W:R) > 0 (information-theoretic dependence), not as an embedded exosystem. The
IMP supplies structural necessity for perfect regulation within specified signal classes;
our AIT results supply information-theoretic necessity for observed compressibility ad-
vantages, beyond linearity or probabilistic assumptions [51].
Practical estimation of K and the gap ∆
Our theorems are stated in terms of prefix Kolmogorov complexity, which is not com-
putable. In practice, one can fix a reference prefix code C and estimate upper bounds,
a := L
(cid:0) O(N)(cid:1)
, (cid:98)b := L
(cid:0) O(N)(cid:1)
, ∆(cid:98) =(cid:98)b−a,
(cid:98) C W,R C W,∅ (cid:98)
with the same compressor C used across all conditions. Persistent ∆(cid:98) > 0 across tasks
is cumulative evidence that explanations with low M(W:R) are exponentially unlikely;
maximizing ∆(cid:98) is the natural scalar objective the regulator appears to optimize on the
observed data.
SomestandardchoicesforprovidingupperboundstoKolmogorovcomplexityareLempel-
Ziv compressors (LZ77/LZ78/LZW). LZ-type compressors are universal in a weak sense
for stationary ergodic sources and are widely available. Implementations (gzip, lz4, etc.)
are practical proxies for L (·) [63, 42]. If both ON and OFF strings are available and a
C
scale-free sanity check of contrast is needed, we can compute
C(xy)−min{C(x),C(y)}
NCD(x,y) := ,
max{C(x),C(y)}
where C(·) is the chosen code length and xy is concatenation [32, 11]. NCD is heuristic
but can reveal whether x is “closer” to trivial baselines than y.
The Block Decomposition Method (BDM) estimates K by tiling a string (or array) into
small blocks whose complexities are looked up from Coding-Theorem-Method (CTM) ta-
bles(exhaustiveoutputfrequencystatisticsofsmallmachines), plusalogarithmicpenalty
(cid:80)
for multiplicities, K(cid:98) (x) ≈ K (b ) + logm , where b are distinct blocks and
BDM i CTM i i i
m their multiplicities (see [48, 61]). This is sensitive to small-scale algorithmic regular-
i
ities beyond LZ’s parse statistics; it works on 1D/2D data (but depends on the chosen
CTM table — size and machine model — and it suffers from boundary/tiling effects and
additive constants that can be sizable for short N).
Finally, alternatives include learned compressors based on neural networks. Autoen-
coder/variational–autoencoder codecs optimize a rate–distortion (thus MDL) objective,
withanexplicitcodelengthviewviaELBOandpracticallosslesscodingthroughbits-back
[22, 24, 31, 54, 25]. In images and video, end-to-end trained autoencoders, hyperpriors,
and autoregressive priors are now standard [6, 37, 23]. Transformer-based compressors
are competitive and rapidly improving—both for images via transformer or hybrid Trans-
former–CNN codecs [36, 35] and for general lossless compression using language-model
predictors and specialized transformer compressors [15, 55]; see also cross-modal results
17
reported with large models [34] and neural codecs for audio [60]. From an MDL per-
spective, these models implement universal codes whose lengths upper-bound the negative
log-likelihood under the learned generative model.
To improve discrimination, we can i) use paired ON/OFF measurements on the same
horizon N; report ∆(cid:98) and its sampling variability across repeats/seeds; ii) include triv-
ial controls (e.g. all-zero regulator and randomized regulator) to sanity-check that ∆(cid:98)
responds in the expected direction; iii) for finite N, complement point estimates with
nonparametric tests (paired permutations on ∆(cid:98) across episodes); iv) when outputs are
multivariate/real-valued, discretize with a fixed, reported quantization and alphabet be-
fore compression.
5 Conclusion
We developed a contrastive, algorithmic formulation of regulation: a regulator R is good
for a world W at horizon N when it yields a compressible readout that is strictly more
compressible than under a null baseline ∅. This places the GRT claim (“good regulators
are models”) on an AIT footing.
If switching a regulator on makes a system’s measured output much simpler to describe
(i.e., more compressible) than when the regulator is off, then the regulator is very likely
to carry non-trivial information about the world it controls—in the precise Algorithmic
Information Theory sense of positive mutual algorithmic information between world and
regulator. Thestrengthofthisevidencegrowsexponentiallywiththecompressibilitygap:
large ∆ makes explanations with little shared structure vanishingly likely. Practically,
this turns the old cybernetics slogan “every good regulator is a model of the system” into
aquantitative, testableclaimthatdoesnotassumelinearity, stochasticmodels, orspecific
architectures. On each run, the theorem also singles out a canonical scalar objective: the
regulator behaves as if it were minimizing the description length of the realized readout
(equivalently, maximizing ∆).
Probabilistically, if W and R are independently sampled minimal programs (no mutual
information), then low readout complexity—and especially the contrastive event “low
under R, high under ∅”—is exponentially unlikely in |W| and |R|. Thus, sustained com-
pressibility relative to baseline is strong evidence that R shares non-trivial algorithmic
structure with W (M(W :R) > 0). This is the AIT face of the Good Regulator idea
and complements the Internal Model Principle’s structural necessity results for classical
regulation: the IMP identifies structural necessities for perfect/robust regulation in clas-
sical settings, whereas our AIT view applies beyond linearity and probability and turns
regulation into a statement about description length. This bridge clarifies in what limited
(yet precise) sense the cybernetics aphorism “good regulators must model” can be made
rigorous [12, 5]: successful regulation implies positive mutual algorithmic information
between world and regulator.
The result supplies: (i) a distribution-free, single-episode diagnostic for “does the con-
troller contain a model?”, (ii) a complement to the IMP (which requires embedding a
copy of the signal generator under more restrictive and structured assumptions), and (iii)
a simple experimental recipe—fix a lossless compressor, quantize the readout, compute
two code lengths (ON vs. OFF), and use their difference ∆ as evidence of model content
18
in the controller.
Finally, the coding-theorem view identifies a canonical scalar and implicates a planner:
runtime minimization of K(x) (equivalently, maximization of ∆).
Alltogether,theseresultsprovidethegroundstojustifythatifasystemisseentoregulate
another in the algorithmic sense (reducing the complexity of an output of the regulated
system compared to no regulation), we can reasonably infer it is likely that the regulator
uses a model of the regulated system and an associated scalar objective function.
Acknowledgments
The author thanks Francesca Castaldo for discussions and reviewing the manuscript.
The author thanks David Wolpert (SFI) for highilighting open questions regarding the
classical regulator theorem.
References
[1] Pieter Abbeel and Andrew Y. Ng. Apprenticeship learning via inverse reinforcement
learning. In Proceedings of the 21st International Conference on Machine Learning
(ICML), pages 1–8, 2004.
[2] Sidney N. Afriat. The construction of a utility function from expenditure data.
Econometrica, 35(1):67–77, 1967.
[3] Brian D. O. Anderson and John B. Moore. Optimal Control: Linear Quadratic
Methods. Prentice Hall, Englewood Cliffs, NJ, 1990.
[4] Karl J. ˚Astro¨m and Richard M. Murray. Feedback Systems: An Intro-
duction for Scientists and Engineers. Princeton University Press, Prince-
ton, NJ, 2008. URL: https://www.cds.caltech.edu/~murray/books/AM08/pdf/
fbs-public_24Jul2020.pdf.
[5] John C. Baez. The good regulator theorem. Azimuth Blog, January 2016.
Informal critique and discussion; included here to reflect debates surround-
ing the GRT. URL: https://johncarlosbaez.wordpress.com/2016/01/27/
the-good-regulator-theorem/.
[6] JohannesBall´e, DavidMinnen, SaurabhSingh, SungJinHwang, andNickJohnston.
Variational image compression with a scale hyperprior. In Proceedings of the 6th
International Conference on Learning Representations (ICLR 2018), 2018. URL:
https://arxiv.org/abs/1802.01436.
[7] Andrew R. Barron, Jorma Rissanen, and Bin Yu. The minimum description length
principle in coding and modeling. IEEE Transactions on Information Theory,
44(6):2743–2760, 1998. doi:10.1109/18.720544.
[8] Michelangelo Bin, Jie Huang, Alberto Isidori, Lorenzo Marconi, Matteo Mischiati,
andEduardoD.Sontag. Internalmodelsincontrol,bioengineering,andneuroscience.
Annual Review of Control, Robotics, and Autonomous Systems, 5:55–79, 2022. doi:
10.1146/annurev-control-042920-102205.
19
[9] Christopher I. Byrnes and Alberto Isidori. Output regulation of nonlinear systems.
IEEE Transactions on Automatic Control, 35(2):131–140, 1990. doi:10.1109/9.
45168.
[10] Gregory J. Chaitin. A Theory of Program Size Formally Identical to Information
Theory. 22(3):329–340. URL: https://dl.acm.org/doi/10.1145/321892.321894,
doi:10.1145/321892.321894.
[11] Rudi Cilibrasi and Paul Vitanyi. Clustering by compression. URL: http://arxiv.
org/abs/cs/0312044, arXiv:cs/0312044, doi:10.48550/arXiv.cs/0312044.
[12] Roger C. Conant and W. Ross Ashby. Every good regulator of a system must be a
model of that system. International Journal of Systems Science, 1(2):89–97, 1970.
doi:10.1080/00207727008920220.
[13] Thomas M. Cover and Joy A. Thomas. Elements of Information Theory. Wiley-
Interscience, Hoboken, NJ, 2 edition, 2006. URL: https://onlinelibrary.wiley.
com/doi/book/10.1002/047174882X, doi:10.1002/047174882X.
[14] G´erard Debreu. Representation of a preference ordering by a numerical function.
In R. M. Thrall, C. H. Coombs, and R. L. Davis, editors, Decision Processes, pages
159–165. John Wiley & Sons, New York, 1954.
[15] Gr´egoire Del´etang, Anian Ruoss, Paul-Ambroise Duquenne, Elliot Catt, Tim Ge-
newein, Christopher Mattern, Jordi Grau-Moya, Li Kevin Wenliang, Matthew
Aitchison, Laurent Orseau, Marcus Hutter, and Joel Veness. Language modeling
is compression. In Proceedings of the Twelfth International Conference on Learning
Representations (ICLR 2024), 2024. URL: https://arxiv.org/abs/2309.10668.
[16] Lance Fortnow. Kolmogorov complexity. In Rod Downey and Denis Hirschfeldt,
editors, Aspects of Complexity: Minicourses in Algorithmics, Complexity and Com-
putational Algebra, volume 4 of de Gruyter Series in Logic and Its Applications,
pages 73–86. de Gruyter, Berlin, New York, 2001. URL: https://lance.fortnow.
com/papers/files/kaikoura.pdf, doi:10.1515/9783110889178.73.
[17] B. A. Francis and W. M. Wonham. The internal model principle for linear mul-
tivariable regulators. Applied Mathematics and Optimization, 2:170–194, 1975.
doi:10.1007/BF01447855.
[18] B. A. Francis and W. M. Wonham. The internal model principle of control theory.
Automatica, 12(5):457–465, 1976. doi:10.1016/0005-1098(76)90006-6.
[19] Bruce A. Francis and W. Murray Wonham. The internal model principle of control
theory. Automatica, 12(5):457–465, 1976. doi:10.1016/0005-1098(76)90006-6.
[20] Karl Friston. A Free Energy Principle for Biological Systems. 14(11):2100–
2121. URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3510653/,
arXiv:23204829, doi:10.3390/e14112100.
[21] Robert M. Gray. Entropy and Information Theory. Springer, New York,
NY, 2 edition, 2011. URL: https://link.springer.com/book/10.1007/
978-1-4419-7970-4, doi:10.1007/978-1-4419-7970-4.
20
[22] Peter D. Gru¨nwald. The Minimum Description Length Principle. MIT
Press, Cambridge, MA, 2007. URL: https://direct.mit.edu/books/
monograph/3813/The-Minimum-Description-Length-Principle, doi:10.7551/
mitpress/4643.001.0001.
[23] Amirhossein Habibian, Ties van Rozendaal, Jakub M. Tomczak, and Taco S.
Cohen. Video compression with rate-distortion autoencoders. In Proceedings
of the IEEE/CVF International Conference on Computer Vision (ICCV), pages
7032–7041, 2019. URL: https://openaccess.thecvf.com/content_ICCV_2019/
papers/Habibian_Video_Compression_With_Rate-Distortion_Autoencoders_
ICCV_2019_paper.pdf, doi:10.1109/ICCV.2019.00713.
[24] Geoffrey E. Hinton and Richard S. Zemel. Autoencoders, minimum descrip-
tion length and helmholtz free energy. In Advances in Neural Information
Processing Systems 6 (NIPS 1993), pages 3–10, San Mateo, CA, 1993. Mor-
gan Kaufmann. URL: https://proceedings.neurips.cc/paper/1993/file/
9e3cfc48eccf81a0d57663e129aef3cb-Paper.pdf.
[25] Jonathan Ho, Evan Lohn, and Pieter Abbeel. Compression with flows via local bits-
back coding. In Advances in Neural Information Processing Systems 32 (NeurIPS
2019), 2019. URL: https://arxiv.org/abs/1905.08500.
[26] Jie Huang. Nonlinear Output Regulation: Theory and Applications. Number 8 in
Advances in Design and Control. Society for Industrial and Applied Mathematics.
doi:10.1137/1.9780898718683.
[27] Marcus Hutter. On universal prediction and Bayesian confirmation. Theoretical
Computer Science, 384(1):33–48, 2007. URL: https://arxiv.org/abs/0709.1516,
doi:10.1016/j.tcs.2007.05.016.
[28] Marcus Hutter, Shane Legg, and Paul M. B. Vita´nyi. Algorithmic probability.
Scholarpedia, 2(8):2572, 2007. URL: https://www.scholarpedia.org/article/
Algorithmic_probability, doi:10.4249/scholarpedia.2572.
[29] A. Isidori and C.I. Byrnes. Output regulation of nonlinear systems. IEEE Transac-
tions on Automatic Control, 35(2):131–140, 1990. doi:10.1109/9.45168.
[30] Edi Karni and David Schmeidler. Foundations of state-dependent utility theory.
Theory and Decision, 81(4):615–636, 2016.
[31] Diederik P. Kingma and Max Welling. An introduction to variational autoencoders.
Foundations and Trends in Machine Learning, 12(4):307–392, 2019. URL: https:
//arxiv.org/abs/1906.02691, doi:10.1561/2200000056.
[32] Ming Li, Xin Chen, Xin Li, Bin Ma, and Paul Vitanyi. The similarity metric. URL:
http://arxiv.org/abs/cs/0111054, arXiv:cs/0111054, doi:10.48550/arXiv.
cs/0111054.
[33] Ming Li and Paul M. B. Vit´anyi. An Introduction to Kolmogorov Complexity and
Its Applications. Texts in Computer Science. Springer, Cham, 4 edition, 2019. URL:
https://link.springer.com/book/10.1007/978-3-030-11298-1, doi:10.1007/
978-3-030-11298-1.
21
[34] Ziguang Li, Chao Huang, Xuliang Wang, Haibo Hu, Cole Wyeth, Dongbo Bu, Quan
Yu, Wen Gao, Xingwu Liu, and Ming Li. Lossless data compression by large models.
7(5):794–799. URL: https://www.nature.com/articles/s42256-025-01033-7,
doi:10.1038/s42256-025-01033-7.
[35] Jinming Liu, Heming Sun, and Jiro Katto. Learned image compression with
mixed transformer-cnn architectures. In Proceedings of the IEEE/CVF Confer-
ence on Computer Vision and Pattern Recognition (CVPR), pages 14388–14397,
2023. URL: https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_
Learned_Image_Compression_With_Mixed_Transformer-CNN_Architectures_
CVPR_2023_paper.pdf.
[36] Ming Lu, Peiyao Guo, Huiqing Shi, Chuntong Cao, and Zhan Ma. Transformer-
based image compression. arXiv preprint arXiv:2111.06707, 2021. URL: https:
//arxiv.org/abs/2111.06707.
[37] David Minnen, Johannes Ball´e, and George Toderici. Joint autoregressive and hi-
erarchical priors for learned image compression. In Advances in Neural Informa-
tion Processing Systems 31 (NeurIPS 2018), 2018. URL: https://arxiv.org/abs/
1809.02736.
[38] Andrew Y. Ng and Stuart J. Russell. Algorithms for inverse reinforcement learning.
In Proceedings of the 17th International Conference on Machine Learning (ICML),
pages 663–670, 2000.
[39] Thomas Parr. Active Inference : The Free Energy Principle in Mind, Brain, and
Behavior. The MIT Press.
[40] F. Delli Priscoli, L. Marconi, and A. Isidori. Adaptive observers as nonlinear in-
ternal models. 55(8):640–649. URL: https://www.sciencedirect.com/science/
article/pii/S0167691106000363, doi:10.1016/j.sysconle.2005.09.016.
[41] Giulio Ruffini. An algorithmic information theory of consciousness. 2017(1):nix019.
arXiv:30042851, doi:10.1093/nc/nix019.
[42] Giulio Ruffini. Lempel-Zip Complexity Reference. URL: http://arxiv.org/abs/
1707.09848, arXiv:1707.09848, doi:10.48550/arXiv.1707.09848.
[43] Giulio Ruffini. Navigating complexity: How resource-limited agents derive prob-
ability and generate emergence. OSF Preprints, 2024. v2, Sept 16, 2024. URL:
https://osf.io/preprints/psyarxiv/3xy5d.
[44] GiulioRuffini,FrancescaCastaldo,andJakubVohryzek. StructuredDynamicsinthe
Algorithmic Agent. 27(1):90. URL: https://www.mdpi.com/1099-4300/27/1/90,
doi:10.3390/e27010090.
[45] Giulio Ruffini and Edmundo Lopez-Sola. AIT foundations of structured experience.
9(2):153–191.
[46] Leonard J. Savage. The Foundations of Statistics. John Wiley & Sons, New York,
1954.
22
[47] Aarti Singh. Lecture 7: Prefix codes, kraft–mcmillan inequality. Course notes, 10-
704 Machine Learning, 2016. Accessed 2025-09-29. URL: http://www.cs.cmu.edu/
~aarti/Class/10704_Fall16/lectures/lec10-prefix_trees_and_coding.pdf.
[48] Fernando Soler-Toscano, Hector Zenil, Jean-Paul Delahaye, and Nicolas Gauvrit.
Calculating kolmogorov complexity from the output frequency distributions of small
turing machines. 9(5).
[49] R. J. Solomonoff. A formal theory of inductive inference. Part II.
7(2):224–254. URL: https://www.sciencedirect.com/science/article/pii/
S0019995864901317, doi:10.1016/S0019-9958(64)90131-7.
[50] Ray J. Solomonoff. A formal theory of inductive inference. Part I. Information
and Control, 7(1):1–22, 1964. URL: https://raysolomonoff.com/publications/
1964pt1.pdf, doi:10.1016/S0019-9958(64)90223-2.
[51] Eduardo D. Sontag. Adaptation and regulation with signal detection implies in-
ternal model. Systems & Control Letters, 50(2):119–126, 2003. doi:10.1016/
S0167-6911(03)00136-1.
[52] Tom F. Sterkenburg. Solomonoff prediction and occam’s razor. Philosophy of Sci-
ence, 84(3):459–479, 2017. URL: https://www.journals.uchicago.edu/doi/10.
1086/691970, doi:10.1086/691970.
[53] Kohtaro Tadaki. A statistical mechanical interpretation of algorithmic information
theory. Journal of Physics: Conference Series, 201:012006, 2010. doi:10.1088/
1742-6596/201/1/012006.
[54] James Townsend, Tom Bird, and David Barber. Practical lossless compression with
latentvariablesusingbitsbackcoding. arXiv preprint arXiv:1901.04866, 2019. URL:
https://arxiv.org/abs/1901.04866.
[55] Chandra Shekhara Kaushik Valmeekam, Krishna Narayanan, Dileep Kalathil, Jean-
Francois Chamberland, and Srinivas Shakkottai. LLMZip: Lossless Text Compres-
sion using Large Language Models. URL: http://arxiv.org/abs/2306.04050,
arXiv:2306.04050, doi:10.48550/arXiv.2306.04050.
[56] Hal R. Varian. The nonparametric approach to demand analysis. Econometrica,
50(4):945–973, 1982.
[57] Nikolai Vereshchagin and Paul M. B. Vit´anyi. Kolmogorov’s structure functions
and model selection. IEEE Transactions on Information Theory, 50(12):3265–3290,
2004. URL: https://dl.acm.org/doi/10.1109/TIT.2004.838346, doi:10.1109/
TIT.2004.838346.
[58] Paul M. B. Vita´nyi. Conditional kolmogorov complexity and universal probability.
Theoretical Computer Science, 501:93–100, 2013. URL: https://arxiv.org/abs/
1206.0983, doi:10.1016/j.tcs.2013.07.009.
[59] Yao Xie. Source coding and kraft inequality. Lecture notes, ECE 587, 2012.
Accessed 2025-09-29. URL: https://www2.isye.gatech.edu/~yxie77/ece587/1_
SourceCoding.pdf.
23
[60] Neil Zeghidour, Alejandro Luebs, Ahmed Omran, Jan Skoglund, and Marco
Tagliasacchi. Soundstream: An end-to-end neural audio codec. IEEE/ACM Trans-
actions on Audio, Speech, and Language Processing, 30:495–507, 2022. URL:
https://arxiv.org/abs/2107.03312, doi:10.1109/TASLP.2021.3129994.
[61] Hector Zenil, Santiago Hern´andez-Orozco, Narsis A. Kiani, Fernando Soler-Toscano,
and Antonio Rueda-Toicen. A decomposition method for global evaluation of
shannon entropy and local estimations of algorithmic complexity. URL: https:
//arxiv.org/abs/1609.00110, doi:10.48550/ARXIV.1609.00110.
[62] Brian D. Ziebart, Andrew Maas, J. Andrew Bagnell, and Anind K. Dey. Maximum
entropy inverse reinforcement learning. In Proceedings of the 23rd AAAI Conference
on Artificial Intelligence, pages 1433–1438, 2008.
[63] Jacob Ziv and Abraham Lempel. A universal algorithm for sequential data com-
pression. IEEE Transactions on Information Theory, 23(3):337–343, 1977. doi:
10.1109/TIT.1977.1055714.
[64] A. K. Zvonkin and L. A. Levin. THE COMPLEXITY OF FINITE OB-
JECTS AND THE DEVELOPMENT OF THE CONCEPTS OF INFORMA-
TION AND RANDOMNESS BY MEANS OF THE THEORY OF ALGO-
RITHMS. 25(6):83. URL: https://iopscience.iop.org/article/10.1070/
RM1970v025n06ABEH001269/meta, doi:10.1070/RM1970v025n06ABEH001269.
[65] A. K. Zvonkin and L. A. Levin. The complexity of finite objects and
the development of the concepts of information and randomness by means
of the theory of algorithms. Russian Mathematical Surveys, 25(6):83–124,
1970. URL: https://www.its.caltech.edu/~matilde/ZvonkinLevin.pdf, doi:
10.1070/RM1970v025n06ABEH001269.
24
Aspect GRT (Conant–Ashby, 1970) IMP (Francis–Wonham, 1975/76; Sontag, A-GRT (Algorithmic, this work)
2003)
Setting / Objects System S, Regulator R, Disturbances/Inputs D, Plant P in feedback with Controller C; exogenous WorldW andRegulatorRaredeterministiccausal
Outcomes Z. Mapping ψ : (S,R)(cid:55)→Z; compare signals from an exosystem E; regulated output y prefix programs (3-tape UTM) that interact over
regulatorsbyentropyofZ. anderrore=r−y. interfacetapesforhorizonN;readoutx=O(N).
W,R
Symbols (explicit) S (system), R (regulator), D (disturbance/input), P (plant),E (exosystem/signalgenerator),C (con- W (shortestworldprogram),R (shortestregulator
Z (outcome),H(·)(Shannonentropy). troller), y (regulated output), signal class U (e.g., program), x := O(N) (ON readout), y := O(N)
steps/sinusoids/polynomials). W,R W,∅
(OFF readout), K(·) (prefix complexity), M(·:·)
(mutualalgorithmicinformation).
Definition of Deterministic mapping/homomorphism h : S→R Internal model: a dynamical subsystem embedded Algorithmicmodel(program): Rsharescomputable
“model” that preserves task-relevant structure so outcomes inC thatreproducesE (controllercontainsacopy structure with W—formally M(W:R)>0 (equiv-
havelowentropy. of E’s dynamics; in LTI, matching poles such as alently K(W | R)<K(W)); no need for a literal
integrators/resonators). dynamicalreplica.
Notion of “Maximallysuccessfulandsimple”: minimizeH(Z) Perfect regulation for a specified class U (exact Compressibilityofrealizedreadout: goodifK(x)is
“goodness” and avoid unnecessary regulator randomness/com- asymptotic tracking/disturbance rejection, robust- small at the chosen N; use contrastive gap ∆ :=
plexity. nessinclass). K(O(N))−K(O(N))>0.
W,∅ W,R
Core Theorem AmongregulatorsthatminimizeH(Z)andaresim- Necessity: perfect regulation for class U requires Algorithmic necessity: with ON x and OFF
Statement plest,thereisadeterministich:S→R;informally: C toembedacopyofE (aninternalmodel). complexity K(O(N)) = b, the universal posterior “every good regulator is (contains) a model of the W,∅
obeysPr((W,R)|x,ER) ≤ C2M(W:R)2−∆. Thus
system.” b
sustained∆>0makeslowM(W:R)exponentially
unlikely; on the realized episode, maximizing ON
over OFF likelihood is equivalent (up to O(1)) to
minimizingK(x)(i.e.,maximizing∆).
Assumptions Z iswell-definedfrom(S,R)anddisturbances;reg- Typically finite-dimensional LTI; stabilizable/de- Deterministic closed coupling; fixed universal pre-
ulatorscomparedbyH(Z)andsimplicity. Ref: Co- tectable;E autonomousandneutrallystable;exact fix machine and horizon N; W,R are minimal
nant&Ashby(1970). asymptotic tracking/rejection for U; robustness in self-delimiting programs; constant-overhead wrap-
a plant neighborhood. Refs: Francis & Wonham perfor(W,R,N)(cid:55)→O(N);diagnosticreadout(con-
W,R
(1975),Francis&Wonham(1976),Sontag(2003).
trastusable). Inpractice,estimateK(·)withfixed
MDLcodelengths.
Restrictions / “Model” notion is weak (mapping); success tied to Sharpest for LTI; nonlinear/output-regulation Information-theoretic (not structural) neces-
Limitations entropy of Z (can reward trivial predictable out- extensions add local sity; strength depends on diagnostic ∆; K(·)
comes);noexplicitstabilityclaims. solvability/detectability/zero-dynamics stabil- uncomputable (use fixed compressor/MDL);
ity;necessitygenerallylocal/structural. single-episodestatements(withprobabilistictilt).
Scope / Use Conceptual cybernetics link: regulation ⇒ repre- Designbackboneforrobustregulation(integralac- Distribution-free,single-episodediagnostics;empir-
sentation(model-building is compulsory). tion,embeddedoscillators);concretesynthesiscon- icalrecipe: fixalosslesscompressor,quantizeread-
straints. out, compute ON/OFF code lengths, use ∆ as ev-
idence of model content; complements IMP with
universal Occam calculus. AIT refs: Li & Vit´anyi
(2019).
Table 2:
Side-by-side comparison of the classical Good Regulator Theorem (GRT), the Internal Model Principle (IMP), and an Algorithmic-Information-Theoretic Good Regulator
Theorem(A-GRT).Primarysources(hyperlinked): Conant&Ashby(1970),Francis&Wonham(1975),Francis&Wonham(1976),Sontag(2003),andLi&Vit´anyi(2019).
25
A Appendix
A.1 Setting and core definitions
Universal machine and prefix complexity. Fix a universal prefix Turing machine
U. For any finite binary string x,
(cid:88)
K(x) := min{|p| : U(p) = x}, m(x) := 2−|p|.
p:U(p)=x
By the Coding Theorem there exist machine–dependent c ,c > 0 with c 2−K(x) ≤
1 2 1
m(x) ≤ c 2−K(x) [49, 64, 33, 58].
2
Conditioning convention. A finite horizon N ∈ N is fixed throughout; unless stated
otherwise, all complexities are implicitly conditioned on N, e.g. K(x) := K(x | N) and
m(x) := m(x | N).
Machines and transcripts. A world W and regulator R are deterministic causal
prefixprogramsthatinteractforN stepsviainterfacetapes. Theirclosed-loopinteraction
produces a binary readout x = O(N) ∈ {0,1}N. The off/null regulator, denoted ∅, is
W,R
the coupling where the regulator’s interface outputs a fixed quiescent symbol (e.g. 0) at
all steps, yielding y = O(N).
W,∅
Joint description and wrapper. Afixedconstant-overheadwrapper decodesshortest
descriptions of (W,R) and simulates the coupling to print O(N). Denote by K(W,R) the
W,R
length of a shortest self-delimiting code for the pair. We use standard chain rules (e.g.
K(W,R) = K(W)+K(R | W)±O(1)).
Mutual algorithmic information. For finite strings x,y,
M(x:y) := K(x)+K(y)−K(x,y) ±O(log(K(x)+K(y))).
Equivalently, M(x:y) = K(x)−K(x | y)±O(log) [33].
Good Algorithmic Regulator (contrastive). Let a := K(O(N)) and b := K(O(N)).
W,R W,∅
Define the gap
∆ := b−a.
We say that R is a good algorithmic regulator for W at horizon N if ∆ > 0. (In practice,
a and b are estimated by fixed MDL codelengths; see §4.)
Deterministic upper bound. Since the wrapper simulates the coupling, one always
has
K
(cid:0) O(N)(cid:1)
≤ K(W,R) ≤ K(W)+K(R)−M(W:R)+O(1).
W,R
26
A.2 Three-Tape Turing Machine
Definition A.1 (Three-Tape Turing Machine Algorithm). A three-tape Turing ma-
chine algorithm is represented by a Turing machine T with three tapes, and consists
of the following components:
1. A finite set of states Q, including a designated start state q and one or more
0
halting states.
2. A finite alphabet Σ, including a blank symbol, used for the input, output, and
private tapes.
3. Three finite tapes, divided into cells, where each cell can contain a symbol
from Σ. These tapes are designated as the input tape, the output tape, and
the non-erase private tape.
4. A transition function δ : Q×Σ3 → Q×Σ3×{L,R}3, defining how the machine
moves between states, writes symbols on the three tapes, and moves the tape
heads left (L) or right (R) on each tape.
We further identify the state of the private and output states with a set of variables
V = {v ,v ,...,v }, withsubsetsV andV . Thetimeevolutionofvariables
1 2 n private output
in V is governed by the operation of the Turing machine, as it processes the input,
modifies the private tape V , and writes to the output tape V , according
private output
to δ. So we can also see an algorithm as a specification of the evolution of a set of
variables.
The Turing machine begins in the start state with the input written on the input
tape and the other tapes blank. It proceeds according to the transition function,
writing into the output and private tapes. The private tape can be written to but
not erased. When the machine reaches a halting state, the output is read from the
output tape.
A.3 Prefix-free programs vs. stop-symbol delimiters (and why
it matters)
Setup. Let U be a universal prefix machine: the domain of its halting programs is
prefix-free, so no valid program is a prefix of another. The associated (prefix/self-
delimiting) Kolmogorov complexity is
K (x) = min{|p| : U(p) = x and p is in a prefix-free domain}.
U
Working with prefix-free domains aligns program lengths with instantaneous (prefix)
codes and invokes Kraft–McMillan inequality, the coding-theoretic backbone that under-
lies many AIT results, including Levin’s universal distribution and the coding theorem
[33,53,16]. (SeealsostandardITreferencesforKraft–McMillanandprefixcodes[59,47].)
Why prefix-freeness is not a mere technicality.
1. Instantaneous decodability and Kraft sums. If the halting programs form
a prefix code, then for the multiset of program lengths {|p| : U(p) ↓} we have
(cid:80) 2−|p| ≤ 1 by Kraft–McMillan. This lets us interpret 2−|p| as a valid “budget”
p
of probability mass per description and leads to semimeasures like Levin’s universal
distribution m (x) = (cid:80) 2−|p| with (cid:80) m (x) ≤ 1. This construction is central
U U(p)=x x U
27
to algorithmic probability and to the coding theorem (roughly K(x) ≈ −logm(x))
[33, 52, 28, 53].
2. Clean invariance and chaining inequalities. The invariance theorem (machine-
independence of K up to O(1)) and standard chain rules (e.g. K(x,y) ≤ K(x)+K(y |
x) + O(1)) are most naturally proved for prefix machines because self-delimitation
removesend-of-programambiguityincompositionsandconditionalencodings[33,16].
“Why not just add a stop symbol?” Suppose we try to avoid the prefix constraint
by allowing programs of the form p#, where # is an end marker.
• If the interpreter ignores any trailing bits after #, then any extension p#q yields the
same computation as p#. To keep the domain of halting programs unambiguous, you
must reject all extensions p#q ̸= p#. But rejecting all such extensions is exactly the
prefix-freeconditionindisguise: novalidcodewordisaprefixofanother. Thus, awell-
implemented “stop-symbol” machine reduces to a prefix-free machine up to a fixed
additive overhead for encoding #. Consequently, all asymptotic theorems (invariance,
coding theorem, bounds using Kraft) remain unchanged up to O(1) [33, 16, 53].
• If extensions after # are allowed as distinct valid programs, then the set of halting
inputs is not prefix-free, Kraft–McMillan can fail, and the sum (cid:80) 2−|p| need
U(p)=x
not be bounded by 1. This breaks the semimeasure property essential to Levin’s
universal distribution and derails the clean link between probability and description
length [52, 28]. In short: allowing arbitrary padding after a nominal “stop” symbol
undermines the probability calculus that AIT relies on.
Implications for our results All conclusions in this paper that rely on (i) the coding-
theoretic view of programs, (ii) semimeasures like m , or (iii) standard chain/invariance
U
bounds continue to hold if one uses a stop-symbol formalism implemented so that de-
scriptions are self-delimiting in the sense above. That formalism is equivalent to the
prefix-free setting up to O(1) and thus does not change the substance of our arguments
or their asymptotic constants. If, however, the stop-symbol scheme admits padded ex-
tensions as distinct valid programs, key lemmas using Kraft (and hence bounds derived
via m or coding-theorem arguments) may fail or require nonstandard fixes.
U
Takeaway. The “prefix business” is not a dispensable technicality; it encodes self-
delimitation that makes programs behave like instantaneous codewords. You can im-
plement self-delimitation via explicit markers, but only if you simultaneously forbid any
valid extension after the marker—i.e. you recover a prefix-free domain. With that in
place, none of the conclusions elsewhere in the paper need to change (beyond harmless
O(1) shifts). Without it, several probability/complexity identifications break.
A.4 Coding Theorems (unconditional and conditional)
Setup and notation. Fix a universal prefix Turing machine U. All logarithms are
base 2. For a finite string x, let K(x) be its (prefix) Kolmogorov complexity: K(x) :=
min{|p| : U(p) = x}. The universal a priori semimeasure is
(cid:88)
m(x) := 2−|p|.
p:U(p)=x
28
Sincethehaltingprogramsofaprefixmachineformaprefixcode,Kraft–McMillanimplies
(cid:80)
m(x) ≤ 1.
x
For conditional versions, we equip U with a read-only auxiliary input tape that holds
side information y. Define
(cid:88)
K(x | y) := min{|p| : U(p,y) = x}, m(x | y) := 2−|p|.
p:U(p,y)=x
All O(1) terms and constants below depend only on the choice of U, never on x or y.
Theorem A.1 (Coding Theorem (unconditional)). There exist machine-dependent
constants c ,c > 0 such that for all finite strings x,
1 2
c 2−K(x) ≤ m(x) ≤ c 2−K(x).
1 2
Equivalently,
−logm(x) = K(x) ±O(1).
Proof sketch. Lower bound. Let p⋆ be a shortest program for x, so |p⋆| = K(x) and
U(p⋆) = x. Then m(x) ≥ 2−|p⋆| = 2−K(x) (the constant c absorbs harmless machine
1
choices).
Upper bound. Because m(·) is a semimeasure, there exists a prefix code with lengths
ℓ(x) ≤ ⌈−logm(x)⌉ (Shannon–Fano/Kraft–McMillan). A fixed decoder transforms the
codeword for x into x, so K(x) ≤ ℓ(x)+O(1) ≤ −logm(x)+O(1). Rearranging gives
m(x) ≤ c 2−K(x).
2
Theorem A.2 (Coding Theorem (conditional)). There exist machine-dependent
constants c′,c′ > 0 such that for all finite strings x,y,
1 2
c′ 2−K(x|y) ≤ m(x | y) ≤ c′ 2−K(x|y).
1 2
Equivalently,
−logm(x | y) = K(x | y) ±O(1).
Proof sketch. Lower bound. With p⋆ a shortest conditional program for x given y, we
have U(p⋆,y) = x, hence m(x | y) ≥ 2−|p⋆| = 2−K(x|y).
Upper bound. For fixed y, m(· | y) is a semimeasure, so there is a prefix code (depending
on y) with ℓ(x | y) ≤ ⌈−logm(x | y)⌉ and a fixed decoder (shared across all y) that maps
codewords plus y to x. Therefore K(x | y) ≤ −logm(x | y)+O(1), which rearranges to
the stated upper bound.
Remarks.
• The constants c ,c ,c′,c′ (and all O(1) slacks) depend only on the choice of the uni-
1 2 1 2
versal prefix machine U; changing U shifts K(·) by at most an additive constant
(invariance theorem), which becomes a multiplicative constant on m(·).
29
• Theorems A.1–A.2 are often summarized as m(x) ≍ 2−K(x) and m(x | y) ≍ 2−K(x|y),
read “within constant factors”.
• Immediate corollaries used in the main text include the posterior under the universal
prior: for any program p with U(p) = x,
2−|p| (cid:104) (cid:105)
Pr{p | x} = ∈ 1, 1 ·2K(x)−|p|,
m(x) c2 c1
and the geometric excess-length tail: Pr{|p| ≥ K(x)+k | x} ≤ C2−k for some constant
C > 0.
References. Original sources and standard expositions: [50, 49, 65, 33, 58, 27].
A.5 Why many long descriptions imply compressibility, and
why long generators are unlikely
Fix a universal prefix Turing machine U. For a finite binary string x,
K(x) := min |p|
p:U(p)=x
is (prefix) Kolmogorov complexity, and the Solomonoff–Levin a priori semimeasure is
(cid:88)
m(x) = 2−|p|.
p:U(p)=x
The coding theorem (a.k.a. Levin’s theorem) states that there exist machine-dependent
constants c ,c > 0 such that
1 2
c 2−K(x) ≤ m(x) ≤ c 2−K(x). (11)
1 2
(Background: Solomonoff,1964a,1964b; Zvonkin–Levin,1970; pedagogicalsurvey: Vita´nyi,
2013; overview: Hutter, 2007.)
Multiplicity ⇒ compression (indexing among outputs)
For L ∈ N let N (x) be the number of programs of length ≤ L that output x.
≤L
Lemma A.1 (Multiplicity compression). If N (x) ≥ 2r, then
≤L
K(x) ≤ L−r + O(logL).
Proof idea (pedagogical). Enumerate all programs of length ≤ L in dovetailing fashion
and record each distinct output when first seen; this yields a computable list A =
L
(x ,x ,...). Define the high-multiplicity set B := {x ∈ A : N (x) ≥ 2r}. Each
1 2 L,r L ≤L
x ∈ B “uses” at least 2r programs, and the total number of prefix programs of length
L,r
≤ L is < 2L+1 (Kraft inequality). Hence
2L+1
|B | ≤ = 2L−r+1.
L,r 2r
Therefore x ∈ B is specified by: (i) a self-delimiting code for (L,r) costing O(logL)
L,r
bits, and (ii) its index in B costing ≤ L−r +1 bits. A fixed decoder reconstructs x
L,r
from these data, yielding the stated bound on K(x).
30
One-line “weight counting” variant. Sinceeveryprogramoflength≤ Lcontributes
at least 2−L to m(x),
m(x) ≥ N (x)2−L ⇒ N (x) ≤ m(x)2L ≤ c 2L−K(x) by (11).
≤L ≤L 2
Rearranging gives Lemma A.1 with the O(1) hidden in constants.
Consequences for posterior over program lengths
Let N (x) be the number of exactly b-bit programs with output x. Under the universal
b
prior over programs, Pr{p} = 2−|p|, observing x induces the posterior
(cid:80) 2−|p| N (x)2−b
p:U(p)=x,|p|=b b
Pr{|p| = b | x} = = .
m(x) m(x)
Bounding N (x) via m(x) ≥ N (x)2−b and (11) gives N (x) ≤ c 2b−K(x). Combining
b b b 2
with the lower bound m(x) ≥ c 2−K(x) yields the geometric decay with excess length:
1
Theorem A.3 (Excess-length posterior decay). For all b ≥ K(x),
c
Pr{|p| = b | x} ≤ 2 2−(b−K(x)).
c
1
Equivalently, writing b = K(x)+k with k ≥ 1,
Pr{|p| = K(x)+k | x} ≤ C2−k and Pr{|p| ≥ K(x)+k | x} ≤ 2C2−k,
for a machine-dependent constant C > 0.
Interpretation. Every extra bit beyond K(x) halves the posterior mass (up to a con-
stant factor). Thus an observed output O with K(O) = a is a priori very unlikely to
have been produced by a program b ≫ a: the posterior probability falls like 2−(b−a).
Why indexing becomes shorter when there are many programs
The key to Lemma A.1 is that we index outputs with many descriptions, not the descrip-
tions themselves. As the multiplicity N (x) grows by a factor of 2r, the set of such
≤L
outputs shrinks by the same factor, so the index shortens by r bits; this directly yields
the L−r bound. (See also exercises and discussion in Li–Vita´nyi, 4th ed., Chs. 2–3 and
an accessible column by Vereshchagin, 2008.)
Remarks
(i) Prefix complexity is essential: the domain of U is prefix-free, giving Kraft’s inequality
and the well-defined prior m(·). (ii) Conditional variants follow verbatim: replace K(·)
by K(· | y) and m(·) by m(· | y) (see Vita´nyi, 2013). (iii) There is no uniform lower
bound in k: for some x there may be no programs of some intermediate lengths due to
prefix-freeness; Theorem A.3 gives an essentially tight upper bound on the posterior mass
at/above length K(x)+k.
Primary sources with links: Solomonoff (1964a), Solomonoff (1964b), Zvonkin &
Levin (1970), Vit´anyi (2013), Hutter (2007), Li & Vita´nyi (4th ed.), Vereshchagin (2008).
31
A.6 Single-episode compressibility is non-diagnostic
Intuitively, knowing that the regulator-world coupled system produces a low-complexity
world output x reduces the set of possible worlds to select from. In turn, this allows
for a shorter description of the world using R and the complexity bound of the output.
The program may say: “To specify W, run the dynamics for all possible W-R pairs and
delete all world model candidates with complex outputs (above the set complexity bound
K(x) < a). Then use a reduced index to identify W”. This means that K(W|R,“K(x) <
a”) < K(W), which implies M(W;R|“K(x) < a”) > 0.
Theorem A.4. (low complexity output ⇒ strict but tiny shrinkage) Fix a universal
prefix machine. Let m := |W| and r := |R| denote minimal code lengths, and let
N ≥ m. For a fixed regulator R and horizon N, consider the class P of all minimal
m
m-bit world programs. Assume we only know that the closed-loop transcript has low
complexity,
E : K (cid:0) O(N) | R,N (cid:1) ≤ a,
a W,R
for some threshold a < m − c, where c = O(1) is a machine-dependent constant.
Claim. The set of candidates consistent with E is a strict subset of P :
a m
(cid:110) (cid:111)
S (m) := W ∈ P : K (cid:0) O(N) | R,N (cid:1) ≤ a ⊊ P .
R,N,a m W,R m
Consequently,
(cid:0) (cid:1) (cid:0) (cid:1)
K W | R,E ≤ log |P |−1 < log |P | = m ±O(1),
a 2 m 2 m
i.e., strictly K(W | R,E ) < K(W) (by a vanishingly small amount).
a
Proof. By Kleene’s recursion theorem (quines), there exists a program W⋆ ∈ P that
m
prints its own source asthefirstmoutputbitsandthenhalts(orpads). HenceK (cid:0) O(N) |
W⋆,R
R,N (cid:1) ≥ K(W⋆)−O(1) = m−O(1) > a, so W⋆ ∈/ S (m). Therefore S (m) ⊊ P ,
R,N,a R,N,a m
implying log|S (m)| < log|P | = m±O(1). □
R,N,a m
To see how small the information gained can be, consider a world program W whose last
line is “print u × O ,” where u is some computed world variable. If R simply outputs
R
0, the world output becomes the all-zeros string, hence very compressible. Knowing that
R outputs 0 and that the world output is 0N does restrict the structure of the world
program (it must include the final multiplication by the regulator output, or something
similar on the realized trace), but that restriction can be tiny—the calculation of u may
still be arbitrarily complex.
Although we have shown that R and E together share information with W, it may be
a
very small for any given case, and, in any case, this does not imply that R and W share
information. The chain rule gives
(cid:0) (cid:1)
M W : (R,E) = K(W)+K(R,E)−K(W,R,E)
(cid:2) (cid:3) (cid:2) (cid:3)
= K(W)+ K(R)+K(E | R) − K(R)+K(W,E | R) ±O(log)
= K(W)+K(R)−K(W,R) + K(W | R)+K(E | R)−K(W,E | R) ±O(log).
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
M(W:R) M(W:E|R)
32
Thus, knowing that the coupled (W,R) system produces a low-complexity readout x in a
single run strictly prunes the set of candidate worlds, but in the worst case this shrinkage
is only O(1) and—critically—does not by itself imply M(W:R) > 0; it certifies at most
(cid:0) (cid:1)
M W : (R,E ) > 0 via the chain rule.
a
Does contrast fix the non-probabilistic identifiability? Let E be the (contrastive) event
a,b
E : K
(cid:0) O(N)(cid:1)
≤ a and K
(cid:0) O(N)(cid:1)
≥ b (b > a).
a,b W,R W,∅
The deterministic shrinkage equals
(cid:0) (cid:1) (cid:0) (cid:1)
K(W)−K W | R,E = M W : (R,E ) ±O(log),
a,b a,b
and by the chain rule this splits as
(cid:0) (cid:1) (cid:0) (cid:1)
M W : (R,E ) = M(W:R) + M W:E | R ±O(log). (12)
a,b a,b
(cid:0) (cid:1)
Thus, from single-episode ON/OFF facts we can certify at most M W : (R,E ) > 0; in
a,b
general this does not imply M(W:R) > 0, because the conditional term M(W:E | R)
a,b
can carry (almost) all the gain or because of synergy.
Furthermore, even if the mutual algorithmic information between world and regulator is
null, it may be the case that coupling them leads to a reduction of complexity in the
world output by chance.
These caveats motivate the probabilistic analysis in the paper.
We discuss in more detail the case of synergy, and also show that a decrease of complexity
cannot certify mutual information in a particular case.
Chain rule and a synergy counterexample.
By the chain rule for mutual information,
(cid:0) (cid:1) (cid:0) (cid:1)
M W : (R,E ) = M(W:R) + M W:E | R + O(logn), (13)
a,b a,b
where R is a shortest description of R (drop R and the O(logn) term in the Shannon
(cid:0) (cid:1)
case).2 Thus, observing that M W : (R,E ) > 0 does not imply M(W:R) > 0, because
a,b
(cid:0) (cid:1)
the conditional term M W:E | R can carry (almost) all of the gain.
a,b
Example (XOR/synergy). Let R,E ∈ {0,1}n be independent, incompressible strings,
a,b
and set W = R⊕E (bitwise XOR). Then:
a,b
+
M(W:R) = K(W)+K(R)−K(W,R)
+
≤ K(W)−K(W | R)
+
= K(W)−K(E | R)
a,b
+
≤ O(logn), (14)
2Algorithmic version: Li & Vit´anyi, An Introduction to Kolmogorov Complexity and Its Applications,
4th ed., Springer, 2019. Shannon version: Cover & Thomas, Elements of Information Theory, 2nd ed.,
Wiley, 2006.
33
+
because E (cid:55)→ W is a bijection given R and independence gives K(E | R) ≥ n. In
a,b a,b
contrast,
(cid:0) (cid:1) + (cid:0) (cid:1)
M W : (R,E ) = K(W)−K W | R,E
a,b a,b
+
≥ n−O(logn), (15)
+ +
since K(W | R,E ) = O(1) and K(W) ≥ K(W | R) ≥ n. Hence the conditional
a,b
(cid:0) (cid:1)
term M W:E | R carries essentially all the information. For the Shannon ana-
a,b
logue, take R,E ∼ Ber(1) i.i.d.; then I(W;R) = 0, I(W;E | R) = H(W) = n,
(cid:0) (cid:1) a,b 2 a,b
so I W;(R,E ) = n.3
a,b
Chance simplification with M(W:R) ≈ 0 is possible.
Fix a universal prefix Turing machine U and a finite horizon N. All complexities are im-
plicitlyconditionedonN (wewriteK(·)forK(·|N)). IdentifyTuringmachineswiththeir
shortest prefix codes and write |W| = K(W), |R| = K(R). The coupled world–regulator
system produces a deterministic readout
x := O(N) ∈ {0,1}N.
W,R
There is no auxiliary map: a fixed, constant-overhead wrapper decodes (W,R) and sim-
ulates the interaction to print x (decode+simulate). Consequently
K(x) ≤ K(W,R)+O(1) = K(W)+K(R)−M(W:R)±O(logN), (16)
and we use the standard identity M(X:Y) = K(X)−K(X | Y )±O(log). (See eq. (1)
and the chain-rule algebra in §2–3 of the WP.)4
For concreteness in the examples below we take |W| = |R| = n and set N = n; this is
only for clarity (all statements have the obvious adjustments if N ̸= n).
Claim (It can happen that K(x) is small while M(W:R) ≈ 0). There exist pairs
(W,R) with M(W:R) = O(logn) such that the coupled output x = O(N) has very small
W,R
complexity (e.g. K(x) = O(logN)).
Construction (existence, uses only the W+R coupling). Fix a threshold ∆ ∈ {1,...,N}.
Define a world program W that monitors the first ∆ symbols emitted by the regulator
∆
on the interface and then latches:
if O [1:∆] = 0∆ then output x = 0N; else output a fixed incompressible z ∈ {0,1}N.
R
+ +
Herez ishard-codedinW (soK(z) = N andK(W ) = |W| = n). Chooseanyregulator
∆ ∆
R(∆) whose first ∆ interface outputs are 0∆ and whose remaining behavior is generated
+
by a shortest program of length = n independent of W . Then
∆
M(W :R(∆)) = O(logn) but x = 0N ⇒ K(x) = O(logN).
∆
Thus, even with M(W:R) ≈ 0 (up to the usual O(log) slack), the coupled program can,
on the realized episode, yield a low-complexity output.
3XOR–synergy as a canonical case in multivariate information: Williams & Beer (2010). For the
identity M(x:y)=K(x)−K(x|y)+O(log) used above, see Bennett, G´acs, Li, Vit´anyi & Zurek, IEEE
Trans. Inf. Theory, 1998.
4Fortextbookbackgroundonprefixcomplexity,chainrules,andM(x:y)=K(x)−K(x|y)±O(log),
see Li & Vit´anyi (2019), and Bennett etal. (1998).
34
“Rare but possible” bound (balanced couplings). Suppose the world implements
a balanced dependence on the regulator’s interface in the sense that, for fixed W, the map
u (cid:55)→ x is a permutation of {0,1}N when we view u := O [1:N] as the regulator’s output
R
sequence (e.g., the world computes x = z ⊕u with a fixed z = z(W)). If R is sampled
independently and its interface sequence u is (close to) uniform on {0,1}N (e.g., drawn
from a family with pseudorandom outputs), then by the standard Kolmogorov counting
bound (at most 2k+1 N-bit strings have K ≤ k),
(cid:2) (cid:3)
Pr K(x) ≤ k ≤ 2k+1−N.
Equivalently, the probability of a ∆-bit drop (K(x) ≤ N −∆) is ≤ 21−∆. Thus, a very
simplexcanoccurby chance, butonlywithexponentiallysmallprobabilityintheamount
of simplification.5
Ex-post constraint when R is invertible from (W,x). If the coupled architecture
allowsrecoveryofRfrom(W,x)viaacomputableinverse(i.e., thereexistsafixeddecoder
such that R = G(W,x)), then
K(x) ≥ K(R | W)−O(1) = K(R)−M(W:R)−O(logn).
+
Hence, with K(R) = n and M(W:R) ≈ 0, a large drop in K(x) cannot occur under
such invertible (in R) couplings. When a very small x is observed in this case, it forces
M(W:R) to be large. (Identity used: M(X:Y) = K(X)−K(X | Y )±O(log).)
5Counting bound: at most 2k+1 strings of length N have complexity ≤k; see Li & Vit´anyi (2019).
35

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "The Algorithmic Regulator"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
