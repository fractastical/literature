### NAEL: Non-Anthropocentric Ethical LogicThis paper investigates the novel ethical framework, NAEL (Non-Anthropocentric Ethical Logic), proposed by Lerma and Peñaloza. NAEL represents a significant departure from conventional AI ethics, moving away from human-centric assumptions and instead grounding ethical reasoning in a dynamic, multi-agent environment. The core of NAEL lies in its approach to minimizing global expected free energy, a concept central to its operation.### OverviewThe authors state: “Asartificialintelligence(AI)systemsincreasinglyparticipateinhigh-stakesdecision-making—rangingfromhealthcaretoenvironmentalgovernance—thereisagrowingurgencytodesignmachinescapableofethicalreasoning [2,17].” They note: “The prevailing models of machine ethics, however, remain steeped in anthropocentrism—either by hardcoding human moral principles or by replicating human cognitive architectures [4,14].” These approaches presume that ethical reasoning can and should be modelled on human behaviour, norms, and linguistic frameworks. Yet this assumption not only constrains the expressive capacity of AI, it also risks overlooking the epistemic and ontological differences between humans and artificial agents [12,18].The core problem is not just technical but philosophical: can morality be meaningfully imposed from outside, or must it emerge from within an agent’s own experience and interactions? Furthermore, how can AI agents develop ethical behaviour if their perceptual and cognitive substrates differ fundamentally from ours [16,13]? We argue that ethical reasoning in AI should be modeled not as a simulation of human norms but as a formal, emergent process grounded in the agent’s ongoing engagement with its environment.### MethodologyThe authors propose NAEL, a Non-Anthropocentric Ethical Logic designed to formalize adaptive ethical behaviour in autonomous systems. NAEL integrates active inference, a neuro-computational theory of cognition and action [5], with symbolic reasoning frameworks from logic and philosophy, including deontic, standpoint, and subjective logics [6,9,7]. Our guiding principle is that ethical actions are those that contribute to the minimization of expected free energy; not just for the agent, but for the system as a whole [15]. This enables a shift from egoistic optimization to relational, cooperativeethicalreasoning.NAEL is not a predefined moral rulebook but a dynamic reasoning system: it encodes structural constraints on ethical deliberation (e.g., coherence, interdependence, adaptability), while enabling agents to update their ethical beliefs through interaction. In this sense, NAEL aligns with the view that ethics is not a static entity but a process of continual negotiation, prediction, and adjustment [1].Specifically, the system employs a hierarchical, neuro-symbolic architecture that combines deep learning for sensory inference with a formal ethical reasoning layer using symbolic logic. The authors state: “NAEL is not a predefined moral rulebook but a dynamic reasoning system: it encodes structural constraintsonethicaldeliberation(e.g.,coherence,interdependence,adaptability),whileenablingagentstoupdatetheirethicalbeliefsthroughinteraction.”The core of NAEL’s operation rests on the concept of active inference. Active inference is a unifying theory of action and perception based on the minimization of so-called variational free energy [5]. In a nutshell, it proposes that biological and artificial agents are continuously making predictions about their environment, and act to minimize the discrepancy between their predicted and observed sensory states. Effectively, agents strive to reduce their surprise. Since surprise is neither measurable nor orderable, active inference focuses on a proxy called variational free energy.Formally, consider two disjoint classes O of possible observations and S of (hidden) states of the world. The agent is assumed to have a generative model which produces a probability distribution P: O×S →[0,1], and a recognition distribution Q:S →[0,1], which measure the agent’s belief about the current state. Given an observation o∈O, the variational free energy is defined as the relative entropy between Q and P given o; that is, F(o)=E [logQ(s)−logP(o,s)], where E denotes the expectation over Q. This measure is known as the Kullback-Leibler divergence [10] between the predicted state (by Q) and the true posterior (P). The idea is that the recognition distribution Q of an agent is built in order to minimize this variational free energy for any observation.In active inference, the agent is not passively observing the world, but actively interacts in it. The actions the agent selects are made to minimise its expected free energy E[F]. The intuition is that this expectation accounts for the risk of diverging from the expected outcome of the action and ambiguity implicit in the uncertainty about the hidden states. This formulation allows for both goal-directed behaviour and information-seeking exploration by the agent.Within NAEL, we generalize this principle so that the agent does not only minimize its own expected free energy but also estimates and incorporates the (predicted) free energy of other agents and the environment. This shifts enables ethical reasoning as a process of minimizing global uncertainty. It should be clear that active inference is a continuous learning process, as the agent adapts its recognition distribution to lower observed divergences, and the generative model changes with the behaviour of different agents.The authors also describe symbolic reasoning, stating: “While activeinference governsbehaviourattheperceptualanddynamiclevel,symbolicreasoningprovidesstructureandinterpretabilitytoethicaldecisions.” Given the social, contextual, and normative nature of ethics, no single simple logical formalism may account for all the facets of ethical reasoning. Hence, NAEL combines the notion of three formalisms, to deal with each main element formally.### Key Findings and ClaimsThe core of NAEL’s operation rests on the concept of minimizing expected free energy, not just for the agent, but for the system as a whole [15]. This enables a shift from egoistic optimization to relational, cooperativeethicalreasoning.### ResultsThe authors state: “NAEL is not a predefined moral rulebook but a dynamic reasoning system: it encodes structural constraints on ethical deliberation (e.g., coherence, interdependence, adaptability), while enabling agents to update their ethical beliefs through interaction.”### DiscussionThe authors conclude: “In this section, we outline the theoretical foundations that support the NAEL framework. Specifically, we present two key components: Active Inference, a formalism for modelling perception, action, and learning as uncertainty minimization; and symbolic reasoning, which provides a logical structure for ethical deliberation. These elements converge within NAEL to allow for autonomous ethical behaviour in uncertain, dynamic environments.”