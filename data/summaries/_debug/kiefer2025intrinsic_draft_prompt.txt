=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Intrinsic motivation as constrained entropy maximization
Citation Key: kiefer2025intrinsic
Authors: Alex B. Kiefer

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: empowerment, article, motivation, alexb, entropy, intrinsic, maximization, verses, intrinsicmotivation, constrained

=== FULL PAPER TEXT ===

Article
Intrinsic motivation as constrained entropy
maximization
AlexB.Kiefer1,2*
1 VERSES,LosAngeles,California,USA
2 MonashCentreforConsciousnessandContemplativeStudies,MonashUniversity,Melbourne,VIC3800,Australia
* Correspondence:alex.kiefer@monash.edu
Abstract: “Intrinsicmotivation”referstothecapacityforintelligentsystemstobemotivatedendoge-
nously,i.e. byfeaturesofagentialarchitectureitselfratherthanbylearnedassociationsbetweenaction
andreward. Thispaperviewsactiveinference,empowerment,andotherformalaccountsofintrinsic
motivationasvariationsonthethemeofconstrainedmaximumentropyinference,providingageneral
perspectiveonintrinsicmotivationcomplementarytoexistingframeworks. Theconnectionbetween
freeenergyandempowermentnotedinpreviousliteratureisfurtherexplored,anditisarguedthat
themaximum-occupancyapproachinpracticeincorporatesanimplicitmodel-evidenceconstraint.
Keywords: intrinsicmotivation;activeinference;empowerment;entropy
1. Introduction
Inpsychology,“intrinsicmotivation”referstothetendencyforintelligentcreaturestobemoti-
vatedtodocertainthings(suchasexplore,learn,andgrow)evenintheabsenceofspecificexternal
rewardsignals[1]. Thisparadigmhasincreasinglygainedtractioninmachinelearning,whereitis
operationalized as the idea that policies for action may be optimized based on structural features
ofagentsandagent-environmentinteractions,asagainsttraditionalapproacheslikereinforcement
learning,whichoptimizepoliciesbasedonadhocrewardfunctions.
Anearly,andincreasinglyinfluential,formalaccountofintrinsicmotivationisbasedonempower-
ment,definedasthecapacityofthechannellinkingagents’actions(actuatorstates)tosensoryfeedback
(observations)[2,3]. Oneinterpretationofthisobjectiveisthatempoweredagents“keeptheiroptions
open”,aswideaction-conditionedchannelcapacityentailsthatagentsareabletorealizeavarietyof
states(forwhichobservationsareaproxy).
Theactiveinferenceframework[4]sharessimilarmotivations,andprovidesaBayesianmethod
for combining a general form of intrinsic motivation (i.e. curiosity or “epistemic drive”) [5] with
agent-specific prior distributions over states or outcomes [6], which model homeostatic set points
and can function like explicit rewards. The expected (variational) free energy (EFE), as discussed
below,guidespolicyselectioninthisframeworkbysupplyinganempiricalprioroverpolicies,given
observations.
Morerecently,theobjectiveofmaximumpathoccupancyhasbeenproposedasaframeworkfor
intrinsicmotivation[7]. Onthisaccount,agentsaremotivatedtomaximizefutureaction-statepath
occupancy, whichcanbemeasuredintermsofboththeentropyoftheactiondistributionandthe
entropyoftheensuingstatedistribution,givenaninitialstate.Thissomewhatmoreradicalperspective
explicitlyinvertstheperhapsnaturalassumptionthatdrivesforexplorationandcuriosityhaveevolved
asameanstoachievingreward,andineffectviewsrewardingstatesasinstrumentallyvaluablein
enablingfutureexploration,i.e. avoidingabsorbingstatesthataffordlittleornoactionvariability(e.g.
death).
There are many other formal treatments of intrinsic motivation in the literature on machine
learning,somecloselyrelatedtothosejustdiscussed,suchaspioneeringworkonartificialcuriosity
(seee.g. [8,9])andtreatmentsintermsofBayesiansurprise[10,11]. Here,thefocusismainlyonthe
5202
beF
31
]CN.oib-q[
3v26920.2052:viXra
2of13
relationshipbetweenactiveinferenceandempowerment,andontherelationshipofbothtomaximum
occupancywhichhasrecentlybeenproposedexplicitlyasanalternative.
While[12]conductsacomparativeempiricalstudyofthesethreeframeworksforintrinsicmoti-
vationonatoyproblemand[13]considershowactiveinferencemaybeformallyrelatedtobroader
schemesforintrinsicmotivation,comparativelylittleworkexistsontheformalandconceptualrela-
tionsamongtheseframeworks. Here,Ihighlightthefactthatallthreecanbeunderstoodasvariations
on the theme of constrained entropy maximization, a principle with deep connections to the free
energyprincipleandactiveinference[14]. Iexploretheconnectionbetweenempowermentandactive
inference[15]bycastingtheempowermentobjectiveitselfexplicitlyasaformofvariationalinference.
Ialsoarguethattheabilityofoccupancy-maximizingagentstoexhibitapparentlygoal-directedbe-
haviordependsona“survivalinstinct”ormodel-evidenceconstraintimplicitinthefactorizationof
theoverallsystemintoactionsandstates. Theseconsiderationsframeentropymaximization,under
localconstraints,asthekernelofintelligenceandagency,withparticularfacetsofthisprocesssuchas
empowerment,perception,curiosityandthe“willtolive”ascorollaries.
Thefirstsectionbelowunpacksthethreeframeworksforintrinsicmotivationmentionedabove
(empowerment,activeinference,andmaximumoccupancy)insomedetail,bothformallyandinterms
ofconceptualmotivation,andarticulatestheirtiestoconstrainedentropymaximization. Sectiontwo
lookscloselyatsomeconnectionsamongthesetheories,thendistillsafewgeneralconclusions.
2. Threeformalaccountsofintrinsicmotivation
2.1. Empowerment
Theempowermentobjectiveforintrinsicmotivation,originallyproposedin[2],isdefinedasthe
capacityoftheinformationchannellinkinganagent’sactionstoitsobservationoftheeffectsofthose
actions. That is, given aspaceofpossibleobservationsO atfuturetimestep T anda sequence of
T
actions A fromthepresenttimestepttothefuture,thereissomedistributionP(O |A )capturing
t:T T t:T
theprobabilisticdependenceofthefutureobservationontheactionstaken,andtheempowerment
E ofanagentismeasuredasthecapacityCoftheinformationtransmissionchanneldefinedbythis
distribution:
(cid:16) (cid:17)
E =C P(O |A ) =maxI(A ;O )
t T t:T t:T T
P(A)
Inthiscase,Cisdefinedasthemaximummutualinformationbetweenactionsandfutureobservations,
I(A ),whentheconditionaldistributionP(O |A )isheldfixedandthedistributionoveractions,
t:T;OT T t:T
P(A),isallowedtovary.
It is worth taking a moment to unpack this, as a detailed understanding will be useful for
comparisonsbelow. Themutualinformationisstandardlydefined,fortworandomvariablesXandY,
asadoublesumequivalenttotheKLdivergencefromthejointdensityP(X,Y)totheproductofthe
marginalsoverXandY:
∑ ∑
(cid:16) P(x,y) (cid:17)
I = P(x,y)log
P(x)P(y)
y∈Yx∈X
(cid:16) (cid:17)
= D P(X,Y)||P(X)P(Y)
KL
Intuitively,thisexpressionmeasureshowdifferenttheactualjointdistributionisfromwhatit
wouldbewerethetwovariablesindependent,i.e. howmuchinformationthevariablescarryabout
oneanother. Whilethismeasureissymmetric(i.e. thesameforXandY),itcanbebrokendownin
termsofconditionalprobabilitiesineitherdirection. Sincethejointdensitycanbefactorizedintoa
priorandaconditionaldensity,i.e. P(X,Y) = P(X)P(Y|X) = P(Y)P(X|Y),themutualinformation
3of13
canalsobeexpressedasanexpectedKLdivergencefromaconditionaldensityP(Y|X)tothemarginal
overY:
∑ ∑
(cid:16)P(x)P(y|x)(cid:17)
I = P(x)P(y|x)log Factorizejointdistribution
P(x)P(y)
y∈Yx∈X
(cid:34) (cid:35)
∑ ∑
(cid:16)P(y|x)(cid:17)
= P(x) P(y|x)log CanceloutP(x)sandrearrange
P(y)
x∈X y∈Y
(cid:34) (cid:35)
(cid:16) (cid:17)
=E D P(Y|X)||P(Y)
P(X) KL
(cid:104) (cid:105)
GivenafixedP(Y|X)(channel),thechannelcapacityC P(Y|X) isthenthemaximumvaluethismutual
informationcantake,givenafreechoiceofP(X).
The empowerment objective is just this channel capacity, with respect to the channel linking
actionsovertimestepst...T withobservationsat T.1 Intuitively,themutualinformationterm(i.e.
informationgainexpectedundertheactiondistribution)measuresboththecontrollabilityofoutcomes
(the influence of action selection on such outcomes) and the variety of achievable outcomes (i.e.
“keepingone’soptionsopen”)[2]. Thiscombinationofcontrollabilityandvarietyischaracteristicof
constrainedentropymaximization,acommonthemeinmanyframeworksforintrinsicmotivation
[7,16,17],andisrelatedtoAshby’s“lawofrequisitevariety”[18].
The“variety”aspectofempowermentcanbemademoreexplicitbyconsideringtherelationof
mutualinformationtoentropy. Anymutualinformation I(X;Y)canbeexpressedintermsofentropy
inseveralways:
I(X;Y) = H(X)−H(X|Y)
= H(Y)−H(Y|X)
= H(X)+H(Y)−H(X,Y)
(cid:0) (cid:1)
ThusempowermentcanbeseenasmaximizingtheentropyoftheactiondistributionH P(A) while
ensuringthatactionsare“rational”inthesenseofbeingreliablyrelatedtoobservations,i.e.minimizing
(cid:0) (cid:1)
H P(A|O) . Atthesametime,itcanbeviewedasmaximizingthevarietyofobservationsOwhile
(cid:0) (cid:1)
ensuringthattheyremaincontrollable,i.e. minimizingH P(O|A) .2
Thisobjectivemaybereadasasignalguidingmodelevolutionorselection,asintheworkjust
cited(i.e. choosingagenerativemodelofactionsandoutcomesP(A)P(O|A)). Givenafixedmodel,
agents may also choose policies (actions) so as to maximize the time-dependent empowerment E
t
byseekingthepositioninthestate-spaceoftheoverallsystem(whereexternalstatesareimplicitly
representedherebyobservations)inwhichthechannelcapacityishighest,sinceP(O |A )implicitly
T t:T
dependsonthestatesatt...T.
Beforemovingontoconsiderothertreatmentsofintrinsicmotivation,wenotethatin[16]itis
shown(inthesettingofcontinuousstate-spaces)thatgeneralizingtheempowermentobjectivejust
discussed,byvaryingthelengthofactionandobservationsequencesandthetimeintervalseparating
actions from target observations, allows one to recover various extant descriptions of control in
dynamicalsystems. Salientlyforpresentpurposes,ageneralizedempowermentobjectiveinwhich
1 Forsimplicitythediscussionherefocusesontheoriginalformulationin[2],butobviouslymanyvariationsonthisthemeare
possible,e.g.usingdifferenttimeindices(asexploredin[16])orswappingoutobservationsforlatentstates.
2 Thereisaprimafacieconflictherewiththereasonableobjectiveofmaximizingmodelevidence(i.e.minimizingthesurprisal
ofobservations),asinactiveinference.Thismatterisdiscussedfurtherbelow,butnotethatinactiveinferencetreatments
themodelevidence(marginallikelihood)isusuallytreatedasfixedatthetimescaleofinference,andagentssimplyactsoas
tofurnishevidenceforthismodel.
4of13
actionsaretakenonlyatthefirsttime-stepcorrespondstoa“kicked”(controlled)versionofCausal
EntropicForcing[17],amoregeneralframeworkthatmodelsintelligentbehaviorintermsofentropy
maximization.
2.2. Activeinferenceandexpectedfreeenergy
AmongthemostpromisingapproachestointrinsicmotivationarethosethatleverageBayesian
Advancesincognitive(neuro)scienceoverthepastdecadeorsohaveseentherisetoprominence
oftheideathatmost(ifnotall)intelligentactioncanbeunderstoodintermsofBayesianinference
[19]. Thisparadigmencompassesquitespecificmodelsofneuronalinformationprocessingsuchas
predictive coding [20,21], which has been invoked to explain perceptual inference [22], as well as
moreabstractandgeneralframeworks,mostysalientlythefreeenergyprinciple[23,24],anaccountof
self-organizationintermsofvariationalBayesianinference,andactiveinference[4,25],whichderives
aschemeforaction(i.e. planningorpolicyselection)fromtheassumptionthatagentsselectactions
thatareexpectedtominimizevariationalfreeenergyinthefuture.3
Agents governed by active inference implement a specific form of planning as inference [27],
“reasoning backward” from preferred outcomes (cast in this context as observations that furnish
evidenceforapriorgenerativemodel[28])tothepoliciesmostlikelytobringthemabout. Inbrief,this
involvesinferringa(variational)posteriordistributionQ(π)overpoliciesπinwhichtheprobability
assignedtoeachpolicyisproportionaltoitsassociatedmodelevidence. Actionsarethensampled
at each timestep based on a Bayesian model average of the policies, each of which entails distinct
action-conditionedstatetransitionprobabilities.
The core quantity driving policy selection in the active inference framework is the expected
freeenergy(EFE,denotedGinequations),whichisthecumulativevariationalfreeenergythatthe
agentexpectstobeincurredbychoosingapolicy(actionsequence),givenitsgenerativemodel. The
generativemodelthatfiguresinpolicyinferenceincludesastate-independentdistributionP(o)over
outcomes(observationso)thattheagent“prefers”tosee,whichcanbecastasthemarginallikelihood
ofobservations[6]andmodelsthecharacteristicattractingsetofstatesthathomeostaticsystemsmust
remainwithininordertopersist[23]. Thiscanbethoughtofasakindofintrinsicmotivation,since
itis“builtin”totheagentratherthanlearned,thoughinpractice(i.e. incomputationalmodels)it
functionssimilarlytoanadhocrewardfunction. Crucially, however, theEFEalsoimplementsthe
model-independentinductivebiasthatactionswillminimizevariationalfreeenergyinthefuture,and
thussubservesamoregeneralformofintrinsicmotivation.
TheEFEassociatedwithapolicyG isdefinedastheexpectationofthevariationalfreeenergy,
π
giventhestate-transitionprobabilitiesinducedbyfollowingthatpolicy[5]. Thisdependsonpossible
futureobservations,whichareassumedtobegeneratedindependentlybystatesateachtimestep,so
thatG canbecomputedasasumovertimestep-specifictermsGt . Selectionofactionsorcontrol
π π
statesucanthenbesummarizedasfollows,whereP(u = u |π )is1ifpolicy jbeginswithcontrol
t i j
stateu and0otherwise,andF isthevariationalfreeenergy(VFE)incurredbypolicyπ:4
i π
3 Accountsofmotorcontrolintermsofhigh-precisionkinestheticpredictions[26]arecloselyrelatedtoactiveinference,but
herethelattertermisreservedtodenotetheideathatpoliciesforactionareselectedonthebasisofexpected(variational)
freeenergy.
4 Iomitseveralfeaturesofactiveinferencemodelsthatareinessentialforpresentpurposes,suchasthebaselinepolicy
or“habit”priorandthetemperatureparameterusedinactionselection. Pleasesee[4,25,29]forfurtherdetails. Insome
treatments,Fisomittedaswell.
5of13
∑
u ∼ Q(u ) = P(u |π)Q(π) Controlstatesampledfrommarginal
t t t
π
(cid:16) (cid:17)
Q(π) = σ −G−F Posterioroverpolicies
T
F =
∑E (cid:2)
−logP(s ,o |π)
(cid:3)
−H
(cid:2)
Q(s |π)
(cid:3)
VFEofpolicyπ
π Q(st |π) t t t
t=0(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Energy Entropy
T
G = ∑ Gt EFEofpolicyπ
π π
t=0
(cid:104) (cid:105)
Gt =E logQ(s |π)−logP(s ,o |π)
π Q(st,ot |π) t t t
(cid:104) (cid:105)
≈E logQ(s |π)−logQ(s |o ,π)−logP(o )
Q(st,ot |π) t t t t
(cid:104) (cid:105) (cid:104) (cid:105)
= −E −logP(o ) −D Q(s |o ,π)||Q(s |π)
Q(st,ot |π) t KL t t t
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Expectedutility Informationgain
GiventhattheEFEisdefinedastheVFEexpectedundervariouspolicies,itseemsatfirstglance
thatconsideringbothFandGwhencomputingQ(π)involvesdouble-counting. Thecrucialdifference
(cid:0) (cid:1)
isthattheEFEisusedtocomputeabelief P(π) = σ −G aboutpolicies,whichisusedasapriorin
thefullvariationalpolicyinferencescheme[29]:
Q ∗(π) =argminF
Q(π)
(cid:34) (cid:35)
(cid:16) (cid:17) (cid:104) (cid:105)
F = D P(π)||Q(π) +E F
KL Q(π) π
whereF isthetotalvariationalfreeenergyandQ∗(π)istheoptimalvariationalposterioroverpolicies.
TheroleoftheEFEasapriorisunderwrittenbytwodifferenceswithrespecttotheVFE.First,as
discussedin[30],thevariationaldistributionoverstatesintheEFE,Q(s |π),isavariationalempirical
t
prior—computedbyconditioningonthemostrecentlyinferredstatedistributionQ(s )androllingthe
t
generativemodeloutintothefuture—asopposedtothevariationalposteriorQ(s )overstates,which
t
invertsthelikelihoodwhileincorporatingtheprioroverstates. TheappearanceofQ(s |π)intheEFE
t
(togetherwiththeuseofQ(s |o ,π)toapproximateP(s |o ))underwritestheEFE’sinformationgain
t t t t
term.
A second difference is that the marginal over observations P(o ), rather than the likelihood
t
P(o |s ),appearsintheEFE,inaccordwiththeEFE’sroleasapriorbeliefaboutwhichpoliciesshould
t t
be(i.e. willbe,inaplanning-as-inferencescheme)pursued.5 Theper-policyvariationalfreeenergy
F,ontheotherhand,takesintoconsiderationtheentropyoftheposteriorstatedistributionaswell
astheexpectedenergyofobservationsunderthelikelihood,insuchawaythattheentropyofthe
posteriorismaximizedundertheenergy(modelevidence)constraint,inaccordancewiththeprinciple
ofconstrainedmaximum-entropyinference[14,23,31,32].
5 Importantly,whilesomeformulations(e.g. [30])aswellasmanysimulationsemploya“preferencedistribution”P˜(ot )
specifiedindependentlyofthepredictive(generative)modeloftheworld,thisisnotadeepfeatureofactiveinference.In[6]
forexampletheEFEobjectiveisformulatedsolelyintermsofthedifferencebetweenP(o,s)andP(o,s|a),i.e.the“reward“
orpreferencemodelisthesamegenerativemodelusedforprediction,withactionsmarginalizedout.
6of13
2.3. Maximumoccupancy
TheMaximumOccupancyPrinciple(MOP)[7]carriesthethemeofintrinsicmotivationtoits
logicalconclusion,proposingthatatraditionalpictureofrationalagency,inwhichcuriosityandother
intrinsic drives have evolved in order to serve reward maximization, should be inverted: we can
insteadunderstandrewardingstatesasameanstotheendofcontinuingtolive,i.e. toexplore(thus
maximallyoccupy)action-statepathspace.
Formally,theoccupancyobjectiveisdefinedintermsofastate-conditionedpolicydistribution
π(A|S)andtransitiondynamicsP(S′|S,A),whichcanbealternatelysampledfromtogenerateaction-
statepathsτ. TherewardfunctionR(τ)foragiventrajectoryisthenspecifiedas:
∞
(cid:104) (cid:105)
R(τ) = − ∑ γtlog πα(a t |s t )Pβ(s t+1 |s t ,a t )
t=0
whereγt isthestandardtemporalrewarddiscountinreinforcementlearningandαandβareweights
modulatingtheinfluenceofactionandstatepathoccupancy. Agentsselectpoliciessoastomaximize
theexpectedrewardor“value”ofstatess,V (s):
π
(cid:104) (cid:105)
V π (s) =E π(A|S)P(S′|S,A) R(τ)|s 0 = s
(cid:34) ∞ (cid:35)
(cid:16) (cid:17)
=E π(A|S)P(S′|S,A) ∑ γt αH(A|s t )+βH(S ′|s t ,a t ) |s 0 = s
t=0
Here,therealizationofτdependsontheinitialstates,andH(A|s )andH(S′|s ,a )denotethe
t t t
conditionalentropyoftheactiondistributiongiventhecurrentstate,andofthedistributionofthenext
stategiventhecurrentstateandaction,respectively.6 Thus,agentsthatmaximizeV (s)maximizean
π
expectationoverthe(summedstep-wiseconditional)entropyofbothactionandstatepaths,subjectto
theweightsandinitialcondition.7
In[12],empiricalstudiesarepresentedinwhichMOPagentsaggressivelyexplorestateandaction
spacewhilestillexhibitingapparentlygoal-directedbehavior. Theformerisperhapstobeexpected,
giventhepurelyintrinsic,surprisal-maximizingrewardfunction,thankstowhichagentswilldirectly
seekoutimprobableactionsthatleadtoimprobablestates. Presumably,theabilityofMOPagents
to behave in goal-oriented ways despite the absence of explicit tasks, rewards, or even preference
distributions, isunderwrittenbytheimperativetomaximizelonger-termpathoccupancy,8 which
balances the tendency to greedily maximize entropy at each timestep. This implicit constraint on
short-termentropymaximizationintheserviceofincreasingentropyinthelongrunisevocativeof
theargumentin[34]accordingtowhichthestructured,relativelylow-entropystatescharacteristicof
complexformsoflifearefavoredfortheirabilitytoacceleratethedissipationoffreeenergywithinthe
broaderuniverse.
3. Aunifiedviewofintrinsicmotivation
Thissectionbeginsbyanalyzingtherelationshipbetweenactiveinferenceandempowerment,
thenconsidersthemaximum-occupancyperspectiveinrelationtobothofthese. Itthenconcludes
withadiscussionofsomethemescommonacrosstheseframeworks,andasynthesisthatallowsusto
resolvesomeapparentdichotomiesfromamulti-scaleorscale-freeperspective.
6 Notethat,whiletheexpectationoverconditionedvariablesisabsorbedintheentropytermsinthethirdline,theexpectation
overtheconditioningvariablesstandatremains.
7 Negativeweightscangiverisetoentropy-minimizingbehavioraswell,asdiscussedbelow.
8 Notably,similaremergenttask-orientedbehaviorisdemonstratedinagentsgovernedbyanempowermentobjectivein[33].
7of13
3.1. Empowermentandactiveinference
Maximizingtheempowermentobjectiveiscloselyrelatedtominimizingexpectedfreeenergy.
Most straightforwardly, in the absence of a constraint (expected utility term), the expected free
(cid:16) (cid:17)
energydescribedabovereducestothenegativeinformationgainD Q(s |o ,π)||Q(s |π) ,sothat
KL t t t
minimizingEFEmaximizesthemutualinformationbetweenstatesandobservations[35].9
While the original empowerment objective [2] leaves the mediation of the action-sensation
channelP(O |A )byhiddenstatesimplicit,theactiveinferenceobjectivesimplymakesthisexplicit:
T t:T
inchoosingactions,agentseffectivelychoosethetransitiondynamicsforcontrollablestates(intypical
implementations, discrete actions index slices of transition tensors), such that they are rendered
informativeaboutobservations. Thuseffectively,statesare(probabilistically)chosensoastomaximize
themutualinformationbetweenactionsandobservations,asintheempowermentobjective.
In[15](Appendix),itisclaimedthat“empowermentisaspecialcaseofactiveinference,whenwe
canignorerisk(i.e.,whenallpoliciesareequallyrisky)”. Here,riskisatermoccurringinthefollowing
alternativebreakdownoftheEFE(see[25],AppendixAforaderivation):
(cid:16) (cid:17) (cid:104) (cid:105)
Gt = D Q(o |π)||P(o ) +E H(P(o |s ))
π KL t t Q(st |π) t t
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Risk Ambiguity
Intuitively,riskissimplyameasureofexpectednegativereward,whichinthiscontextishow
different predicted outcomes are from those expected a priori (i.e. preferred). The entropy of the
likelihoodmappingfromstatestoobservationsexpectedunderagivenpolicy(“Ambiguity”)quantifies
howuncertaintheagentwillbeaboutoutcomesifthatpolicyispursued. Thus,minimizingexpected
freeenergyencouragesagentstochoosepolicies(actions)thatrenderoutcomespredictable,subjectto
theconstraintthatriskisminimized.
Wecanrunasimilarargumentbyconsideringtheempowermentobjectivedescribedin[2]aspart
ofavariationalinferenceprocess. Intermsofthenotationusedforactiveinference,thegoalwouldbe
tomaximize I (π;o ),whereasaboveπisasequenceofcontrolstates[u ,u ,...,u ]. Thisobjective
t T 0 1 T
canbeexpressedintermsoftheentropiesofposteriorobservationandpolicydistributions,andalso
asaKLdivergence:
(cid:16) (cid:17) (cid:16) (cid:17)
I (π;o ) = H Q(π) −H Q(o |π)
t T T
(cid:16) (cid:17)
= D Q(π,o )||Q(π)Q(o )
KL T T
Thedivergencesimplystatesthatagentsmaximizingempowermentshouldselectpoliciesthat
provideinformationaboutthetargetobservation,whichinthiscontextamountstotheformeraffording
control over the latter. The subscript in I indicates that, like the original empowerment objective
t
E , this termisimplicitly time-dependent. More specifically, inthe presentsetting, the variational
t
posteriorsQattdependontheobservationo viathestateposteriorQ(s ).
t t
9 Again,eventhoughthismutualinformationcanbeinterpretedasmaximizingtheentropyofobservations(constrainedby
theircontrollability),optimizationofQinvariationalinferenceisalwaysconstrainedbythegenerativemodelPsothere
isnoconflictwiththeimperativetomaximizemodelevidence.Thatsaid,inamulti-scalesettingonemayalsoconsider
learningtheparametersofPasdiscussedbelow.
8of13
Interestingly,definingaconditional“energy”termasthenegativelogprobabilityoftheobserva-
tionatTgivenpolicies,theexpressionofthemutualinformationintermsofentropiescanbewritten
inaformanalogoustoafreeenergyF(π,o )simplybyflippingthesignandrearrangingterms:
t T
(cid:104) (cid:16) (cid:17) (cid:16) (cid:17)(cid:105)
F(π,o ) = − H Q(π) −H Q(o |π)
t T T
(cid:104) (cid:105) (cid:16) (cid:17)
=E −logQ(o |π) −H Q(π)
Q(oT |π) T
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
“Energy” Entropy
(cid:104) (cid:105) (cid:16) (cid:17) (cid:16) (cid:17)
=E −logP(o |s ) + H Q(s |π) − H Q(π)
Q(oT |π) T T T
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Energyoffinalobservation Conditionalstateentropy Policyentropy
(cid:104) (cid:16) (cid:17)(cid:105)
=E H P(o |s ) − I (π;s )
Q(sT |π) T T t T
(cid:124) (cid:123)(cid:122) (cid:125)
(cid:124) (cid:123)(cid:122) (cid:125)
Stateinformationgain
Ambiguity
(cid:104)T−1 (cid:105)
∑ ∑ ∏
Q(s
T
|π) = ··· P(s
t+1
|s
t
,π)Q(s
0
)
s0 ∈S sT−1 ∈S t=0
Maximizing I (π;o )isthenequivalenttominimizingthisenergy. Thesecondlinelackstheform
t T
ofaproper(variational)freeenergybecausethe“energy”termisjusttheentropyofavariational
densityQ(o |π),ratherthanajointprobability(generativemodel)P(o,s). However,Q(o |π)factors
T T
intoseveraltermssomeofwhicharedistributionsofthegenerativemodel. Takingthisintoaccount,
wearriveattheexpressioninthepenultimaterow,whichissimilartoaHelmholtzfreeenergywithan
additionalentropytermtobeminimized: underthisobjective,agentswillseeklow-energy(predictable)
observations,whilemaximizingtheentropyofpolicies(“keepingoptionsopen”)andalsoseeking
policiesthatminimizetheentropyofthefinalstate,i.e. seekingpathsthatresultincontrollablestates.
Finally(lastline),theexpectedenergy(negativelogprobabilityunderthegenerativemodel)ofo
T
isequivalenttotheambiguitytermintheEFEmentionedabove(withrespecttothefinalobservation
inatrajectory),whilethetwoentropytermscanbecombinedintoastateinformationgainterm.10
Thusfromtheempowermentobjectivealone(andignoringadditional“preference”constraints)wecan
derivedrivesforbothepistemicvalue(minimizingambiguity)andcontrol(maximizingstateinfogain).
Activeinferenceagentsarethus“empowered”inthattheymaximizetheentropyoffuturestate
distributions,undertheconstraintthatthesestatesortheensuingobservationsbecontrollable. Cru-
cially,inactiveinference,agentsarealsoconstrainedtomaximizemodelevidence(oritstractablelower
bound,variationalfreeenergy)[28]. Infact,thelatter(approximatelymaximizingmodelevidence)is
thecentralconceptintheFEPandactiveinference,where(constrained)entropymaximizationfalls
outofvariationalfreeenergyminimization,andspecificallyexploratorybehavioremergesthanksto
thedistribution-matching(KL-divergence)termintheEFEobjective[37].
3.2. Constrainedmaximumoccupancy
Primafacie,itisdifficulttosquarethemaximumoccupancyobjectivewiththosejustconsidered
inpreciseterms,sinceitsobjectiveinvolvesonlymaximizing(expected)entropy,withoutconstraints.
Infact,theMOPobjectivedescribedaboveisgeneralenoughtoencodeanapproximationtoempow-
erment, ifthe β termissettoanegativevalue[7], whichencouragesagentstochooseactionsthat
minimizetheentropyofthestatetransitiondistribution,whilestillmaximizingtheentropyofactions.
Thisisclearlycloselyrelatedtotheempowermentobjectivesdiscussedaboveoncethedistinction
betweenstatesandobservationsisaccommodated(i.e.,itresultsinagentsthat“keepoptionsopen”
whileensuringcontrollablestatesandthusobservations). However,whileofpracticalinterest,this
reallyamountstoadeparturefromthespiritofMOP.
10 Asimilarformulationofempowermentintermsoffreeenergyisreachedbyconsideringaction-stateempowermentinthe
contextofthegeneralizedfreeenergyfunctional[36],in[15].
9of13
Itisarguedin[7]onbothconceptualandexperimentalgroundsthatMOPagentsexhibitmore
robustexploratorybehavior,andvarietyinpolicyselection,thanagentsgovernedbyempowermentor
EFEobjectives. Theexperimentsreportedinthatworkandin[12],however,involvefullobservation
ofthestate-space,sothattheambiguitytermintheEFEdoesnowork(andmoregenerally,theusual
motivationsfortheFEPandactiveinference,inwhichagentsareassumedtoinferunknownstatesof
theenvironment,donotapply). Moreover,theexperimentsreportedin[7]useasettingofβ =0by
default,thuseffectivelymaximizingtheentropyofonlytheactiondistribution. Forthesereasonsthe
ensuingdiscussionfocusesontheconceptualargumentssurroundingentropymaximizationandthe
roleofconstraints,ratherthanontheseexperimentalresults.
Onconceptualgrounds,theMOPobjectivemay(itisarguedin[7])beexpectedtoproducea
greater variety of actions than active inference for two reasons: (a) the EFE objective contains an
explicit“preference”termwhichMOPlacks,andwhichbiasesactioninfavorofcertainoutcomes(thus
reducingtheentropyofaction-statepaths);and(b)whiletheEFEobjectivemaximizestheentropyof
thestate-transitiondistributionateachtimestep11,itcontainsnotermtomaximizetheentropyofthe
actiondistribution.
Themaximizationofaction(policy)entropydoesseemtofalloutoftheempowermentframework.
Thus,giventheequivalencesoutlinedabove,thesameshouldbetrueofactiveinference. [7]arguethat
theEFEdeterministicallyselectsasinglepolicy. However,inthecontextofafullvariationalinference
treatment(i.e. planning-as-inference),theentropyofthepolicydistributionshouldalsobemaximized
(underrelevantconstraints).
Conceptually,πisalatentvariable,andceterisparibusitsentropyshouldbemaximizedduring
variationalinferencejustastheentropyofQ(s),thevariationaldensityoverhiddencauses,ismax-
imized. Thisiscapturedformallyinworkonactiveinferenceexploringaformulationofexpected
variationalfreeenergythatisinsomewaysmoreparsimoniousthantheEFE,calledthegeneralized
freeenergy[36]. Asshownin[15],thisobjectivecan(asisusualinvariationalinference)bewritten
asaHelmholtzfreeenergy,whereinthiscasetheenergytermistheexpectedEFEunderthepolicy
posterior,andtheentropyofthepolicydistributionisexplicitlymaximizedasfreeenergyisminimized:
(cid:104) (cid:105) (cid:104) (cid:105) (cid:16) (cid:17)
F Q(s,π) =E G − H Q(π)
Q(π) π
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Generalizedfreeenergy ExpectedEFE Policyentropy
Itisthegeneralizedfreeenergywhichin[15]isshowntobeequivalenttoempowermentcon-
strainedbyrisk. Relatedly,the“freeenergyofempowerment”F(π,o )definedabovealsocontains
t T
thispolicyentropyterm. Thus,whileafocusexclusivelyontheEFEisnotsufficienttoshowthis,the
maindifferencebetweenactiveinference(viewedbroadlysoastoincludemaximum-entropypolicy
inference)andMOPseemstobethepresenceorabsenceofexplicitmodelevidenceconstraints.
ThecoreconceptinMOPisthatmaximizingpathoccupancyisan“intrinsic”value,fromwhich
rewardisderivative. ThecoreclaimoftheFEPandactiveinference(whichwehaveseentoentail
empowerment) is that maximizing model evidence is an “intrinsic” value, and that rewards as well
asinformation-seekingbehaviorderivefromthisimperative. Atfirstglance,theseframeworksmay
appeardifficulttoreconcile,sincetheformermaximizessurprisalwhilethelatterminimizesit(atleast
withrespecttosensoryobservations).
11 MinimizingthevariationalfreeenergyFinthefullvariationalpolicyinferenceschememaximizestheentropyofthestate
distributionateachstepunderanevidenceconstraint.TheEFEattimetcanbewrittenasaHelmholtzfreeenergy,showing
thatthesameistrueforthepolicy-conditionedempiricalprioroverstatesQ(st |π):
(cid:104) (cid:105) (cid:16) (cid:17)
Gt
π
=E
Q(st,ot|π)
−logP(st,ot |π) −H Q(st |π)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Energy Entropy
10of13
Oneofthecentralclaimsof[7]isthatintelligent,goal-directedactionemergesnaturallyfromthe
MOPobjective,inthepresenceofabsorbingstatestogetherwiththemeansto(foreseeably)avoidthem
givencertaincoursesofaction. ItmaybewonderedwhetherpureMOPagentswouldbeassuccessful
inlesspredictableenvironmentsinwhichrisk-aversionmaybemoreimportant,butindependentlyof
this,therearedeepreasonstosupposethatMOPagentswouldnotproducerichlyintelligentbehavior
withoutanimplicitmodel-evidenceconstraint.
Occupancy-maximizingagentsseekcontrolonlyinordertoremainalive,agoalthatisargued
toflowelegantlyfromthedesiretomaximizeentropyinthedistantfuture. However,thisargument
assumesthatbeingdeadcorrespondstoan“absorbing”state,whichintheexperimentsismodeled
as entailing zero entropy for the rest of time. In a more physically realistic model, dying would
correspond to a breakdown of the agent-environment boundary, and so to a much higher-entropy
state(withthedissolutionofindividualagentscorrespondingtoanunconstrainedmaximum-entropy
state,orinphysicalterms,thermalequilibrium). Relatedly,the“survivalinstinct”isencodedinactive
inferenceagentsinthefactthatdeparturesfromhomeostaticsetpoints(definedbythegenerative
modelor“preferencedistribution”)scorehighinfreeenergyandsoareaversive.
Thus,identifyingalackofactionavailabilitywithalow-entropystateisplausibleonlyintoy
scenariosinwhichtheentropyincreaseinducedwithintheoverallsystembythedissolutionofthe
agentisignored. DeathoughttobeattractivetoMOPagentsunlesstheypossessanaprioridistinction
between agent and environment, i.e. a “sense of self”. The upshot is that the implicit constraint
enablingtheemergenceofgoal-directedbehaviorinsuchagentsis,inthegeneralcase,notsimply
long-termentropymaximizationbutalsotheexistenceofanagentwitharepertoireofactions,encoded
in the very partitioning of the space into action and state variables. Effectively, this amounts to a
versionofthe“controllability”constraintsthatappearexplicitlyinactiveinferenceandempowerment,
astheagentmustexertcontrolsufficienttoenablehomeostasis(i.e. themaintenanceofinternalstates
againstdissipativeforces).12
3.3. Modelevidenceandthewilltolive
Despitetheargumentsjustgiven,theinversionoftraditionalassumptionsabouttherelationship
betweenexplorationandrewardhighlightedbytheMOPisappealing,asentropymaximization(albeit
underconstraints)appearstobeanessentialfeatureofintelligenceandlife[14,17,38,39],moreconstant
acrossdistinctformsoflifethananyparticularreward-seekingbehavior. Theideathatfuturepath
occupancy,asmeasuredbyentropy[7],istantamounttoremainingaliveisonewayofunderstanding
theplaceofentropymaximizationattheheartofaccountsofintrinsicmotivation.
Wehaveseenhoweverthatinordertoreproducethegoal-orientedbehaviorcharacteristicof
complex biological intelligence, it is necessary to maximize entropy under the constraint that the
agent’sexistence,operationalizedasaconditionalindependencebetweeninternalandexternalstates
[23](whichappearsinsimplemodelsasanaction-statepartition),ismaintained. Takingapagefrom
Schopenhauer[40],intrinsicmotivationmaythenbecastassimplythe“willtolive”,i.e. topersist
asaliving(moving,changing)thing,abasalimpulsethattakesdifferentparticularformsdepending
onlocalconstraints(generativemodels). Theseconstraintsshapetheprimarymotivationalforceof
entropyproduction,suchthatconditionalindependencestructuresaremaintained.
In simpler models of intelligence, the relevant partitioning of the entire (agent-environment)
systemisassumedtobefixed,butinmoresophisticatedtreatmentssuchasmulti-scaleorscale-free
activeinference[41,42], modelstructureitselfmayevolve, typicallyatslowertimescales. Wemay
then view the life of an agent at any given instant as seeking not only observational evidence for
thecurrentlyparameterizedmodel,butalsoevidencefortheparametersthemselves,aswellasfor
12 Wemaynotethattheabilitytopredicttheentropyoffuturestatessoastocomputestatevalue—howeverthisisimplemented—
alsocorrespondstosomelocaldisequilibriumandthusimposesadefactoconstraintonentropy(here,weareexplicitly
consideringtheentropyassociatedwiththeinternalstatesoftheagent).
11of13
hyperparameters(orpriorsoverparameters,includingstructuralpriors). Thisstructuralevolutioncan
beunderstoodintermsofBayesianmodelselection[35].
Fromthisperspective,thereisnodeepcontradictionbetweenscale-freeself-evidencing(i.e. the
seekingofmodelevidence)[28]andmaximumoccupancy. Onceconstraints(parametersandmodel
structure)arethemselvestreatedasrandomvariables,theprocessofself-evidencingisseentobedata-
orobservation-driventhroughandthrough,anditappearstobeapropertyofouruniverse(insofaras
itisaccuratelymodeledasaclosedsystem)thattheentropyofdata-generatingprocessesasawhole
canonlyincrease. Fromthisperspective,maximum-entropyinferenceisaubiquitousself-fulfilling
prophecyinvirtueofwhichtheuniverseevolvestowardthermalequilibrium.13 Thusallagentsindeed
maximizeoccupancyonthelongesttimescale,thoughinaratherselflessway,i.e. theygatherevidence
foramaximum-entropymodeloftheuniverseatlarge,inwhichboundariesbetweenagents(Markov
blankets)andtheircorrespondingenergeticconstraintshavedisappeared.
Theideathatentropyismaximized“foritsownsake”doesnot,ofcourse,precludeinterpretations
ofthisphenomenonintermsofepistemicvalue[5],curiosity[9],andsoon,invariouscontexts. What
theprecedingdiscussiondoessuggestisthatexploratorybehaviorisbynomeans“merely”anevolved
mechanismforsecuringoutcomeshighinutility,butisatleastasfundamentalanaspectofagencyas
thelattertendency,withthetwoplausiblyparticipatinginadanceofcircularcausality. Thepresence
ofbothgoal-seekingandinformation-seekingdrivesintheexpectedfreeenergyfunctional,regardless
oftheparticulargenerativemodel,pointstothissameconclusion[44].
4. Conclusion
Seeking common themes across contemporary accounts of intrinsic motivation has surfaced
the inevitability of constrained entropy maximization as a core principle describing motivation in
biologicalsystems. Thisinsightishardlynovelatafundamentallevel,asentropymaximizationhas
longbeenrecognizedasacrucialprinciplebothinphysicsgenerally[31]andforthephysicsoflife
andintelligencespecifically[17,23,34],andhasplayedanexplicitroleinseveralaccountsofintrinsic
motivation[9,16]. Here,thegoalhasbeenprimarilytoexploreindetailhowthreeaccountsofintrinsic
motivationthathavepreviouslybeenjuxtaposedintheliterature[12]maynonethelessbeunderstood
asvariantsofthisgeneralperspective.
Acknowledgments: TheauthorwouldliketothankinparticularKarlFriston,JacquelineHynes,andDalton
Sakthivadivelforconversationsdirectlyrelevanttothiswork,aswellasMahaultAlbarracin,RiddhiJ.Pitliya,
MaxwellRamstead,TimVerbelen,andRanWeiforinspiringdiscussions.
References
1. Domenico, S.I.D.; Ryan, R.M. The Emerging Neuroscience of Intrinsic Motivation: A New Frontier in
Self-DeterminationResearch. FrontiersinHumanNeuroscience2017,11.
2. Klyubin,A.S.;Polani,D.;Nehaniv,C.L. Empowerment:auniversalagent-centricmeasureofcontrol. 2005
IEEECongressonEvolutionaryComputation2005,1,128–135Vol.1.
3. Salge,C.;Glackin,C.;Polani,D. Empowerment-anIntroduction. ArXiv2013,abs/1310.1863.
4. Friston,K.J.;FitzGerald,T.H.B.;Rigoli,F.;Schwartenbeck,P.;Pezzulo,G. ActiveInference:AProcessTheory.
NeuralComputation2017,29,1–49.
5. Friston,K.J.;Rigoli,F.;Ognibene,D.;Mathys,C.D.;FitzGerald,T.H.B.;Pezzulo,G. Activeinferenceand
epistemicvalue. CognitiveNeuroscience2015,6,187–214.
6. DaCosta, L.; Tenka, S.; Zhao, D.; Sajid, N. Active Inference as a Model of Agency, 2024,
[arXiv:cs.AI/2401.12917].
7. Ramirez-Ruiz,J.;Grytskyy,D.;Mastrogiuseppe,C.;Habib,Y.;Moreno-Bote,R. Complexbehaviorfrom
intrinsicmotivationtooccupyfutureaction-statepathspace. NatureCommunications2022,15.
8. Schmidhuber,J. Adaptiveconfidenceandadaptivecuriosity. Forschungsberichte,TUMunich1991,FKI149
91,1–9.
13 Thedistinctionbetweenthermodynamicandmerelyinformation-theoreticorvariationalfreeenergy[32,43]needn’tconcern
ushere,astheentropyofobservationsissufficienttodrivethisprocess.
12of13
9. Schmidhuber,J. FormalTheoryofCreativity,Fun,andIntrinsicMotivation(1990–2010). IEEETransactions
onAutonomousMentalDevelopment2010,2,230–247.
10. Itti,L.;Baldi,P. Bayesiansurpriseattractshumanattention. VisionResearch2009,49,1295–1306. Visual
Attention:Psychophysics,electrophysiologyandneuroimaging,https://doi.org/https://doi.org/10.1016/j.
visres.2008.09.007.
11. Mazzaglia,P.;Çatal,O.;Verbelen,T.;Dhoedt,B. Curiosity-DrivenExplorationviaLatentBayesianSurprise.
InProceedingsoftheAAAIConferenceonArtificialIntelligence,2021.
12. Moreno-Bote,R.;Ramírez-Ruiz,J.Empowerment,FreeEnergyPrincipleandMaximumOccupancyPrinciple
Compared. InProceedingsoftheNeurIPS2023workshop:Information-TheoreticPrinciplesinCognitive
Systems,2023.
13. Biehl,M.;Guckelsberger,C.;Salge,C.;Smith,S.C.;Polani,D. ExpandingtheActiveInferenceLandscape:
MoreIntrinsicMotivationsinthePerception-ActionLoop. FrontiersinNeurorobotics2018,12.
14. Sakthivadivel, D.A.R. Towards a Geometry and Analysis for Bayesian Mechanics, 2022, [arXiv:math-
ph/2204.11900].
15. Friston,K.;DaCosta,L.;Hafner,D.;Hesp,C.;Parr,T. SophisticatedInference. NeuralComputation2021,
33,713–763.
16. Tiomkin,S.;Nemenman,I.;Polani,D.;Tishby,N. IntrinsicMotivationinDynamicalControlSystems. PRX
Life2024,2,033009.
17. Wissner-Gross, A.D.; Freer, C.E. Causal Entropic Forces. Phys. Rev. Lett. 2013, 110, 168702. https:
//doi.org/10.1103/PhysRevLett.110.168702.
18. Ashby,W.R.,RequisiteVarietyandItsImplicationsfortheControlofComplexSystems. InFacetsofSystems
Science;SpringerUS:Boston,MA,1991;pp.405–417. https://doi.org/10.1007/978-1-4899-0718-9_28.
19. Hohwy,J. ThePredictiveMind;OxfordUniversityPressUK:Oxford,GB,2013.
20. Rao, R.P.N.; Ballard, D.H. Predictive coding in the visual cortex: a functional interpretation of some
extra-classicalreceptive-fieldeffects. NatureNeuroscience1999,2,79–87.
21. Salvatori,T.;Song,Y.;Yordanov,Y.;Millidge,B.;Sha,L.;Emde,C.;Xu,Z.;Bogacz,R.;Lukasiewicz,T. A
Stable,Fast,andFullyAutomaticLearningAlgorithmforPredictiveCodingNetworks. InProceedingsof
theTheTwelfthInternationalConferenceonLearningRepresentations,2024.
22. Helmholtz,H.v.;Southall,J.P.C.J.P.C. Helmholtz’sTreatiseonphysiologicaloptics;DoverPublications: New
York,1962.
23. Friston,K.J. Afreeenergyprincipleforaparticularphysics. arXiv:NeuronsandCognition2019.
24. Friston,K.;DaCosta,L.;Sakthivadivel,D.A.;Heins,C.;Pavliotis,G.A.;Ramstead,M.;Parr,T. Pathintegrals,
particularkinds,andstrangethings. PhysicsofLifeReviews2023,47,35–62.
25. Smith,R.;Friston,K.J.;Whyte,C.J.Astep-by-steptutorialonactiveinferenceanditsapplicationtoempirical
data. JournalofMathematicalPsychology2022,107,102632. https://doi.org/https://doi.org/10.1016/j.jmp.
2021.102632.
26. Brown,H.R.;Friston,K.J.;Bestmann,S. ActiveInference,Attention,andMotorPreparation. Frontiersin
Psychology2011,2.
27. Botvinick,M.;Toussaint,M. Planningasinference. TrendsinCognitiveSciences2012,16,485–488. https:
//doi.org/https://doi.org/10.1016/j.tics.2012.08.006.
28. Hohwy,J. TheSelf-EvidencingBrain. Noûs2014,50,259–285. https://doi.org/10.1111/nous.12062.
29. Heins,C.;Millidge,B.;Demekas,D.;Klein,B.;Friston,K.;Couzin,I.D.;Tschantz,A. pymdp: APython
libraryforactiveinferenceindiscretestatespaces. JournalofOpenSourceSoftware2022,7,4098. https:
//doi.org/10.21105/joss.04098.
30. Millidge, B.; Tschantz, A.; Buckley, C.L. WhencetheExpectedFreeEnergy? NeuralComputation2021,
33,447–482. https://doi.org/10.1162/neco_a_01354.
31. Jaynes,E.T. InformationTheoryandStatisticalMechanics. Phys.Rev.1957,106,620–630.
32. Kiefer,A. PsychophysicalIdentityandFreeEnergy. JournaloftheRoyalSocietyInterface2020,17.
33. Ringstrom,T.J. RewardisnotNecessary:HowtoCreateaModular&CompositionalSelf-PreservingAgent
forLife-LongLearning,2023,[arXiv:cs.AI/2211.10851].
34. Ueltzhöffer,K. Onthethermodynamicsofpredictionunderdissipativeadaptation. arXiv: Neuronsand
Cognition2020.
35. Friston, K.J.; Da Costa, L.; Tschantz, A.; Kiefer, A.; Salvatori, T.; Neacsu, V.; Koudahl, M.; Heins, C.;
Sajid, N.; Markovic, D.; et al. Supervised structure learning. Biological Psychology 2024, 193, 108891.
https://doi.org/https://doi.org/10.1016/j.biopsycho.2024.108891.
13of13
36. Parr,T.;Friston,K.J. Generalisedfreeenergyandactiveinference. BiologicalCybernetics2018,113,495–513.
37. Millidge, B.; Tschantz, A.; Seth, A.K.; Buckley, C.L. Understanding the origin of information-seeking
explorationinprobabilisticobjectivesforcontrol. ArXiv2021,abs/2103.06859.
38. England,J.L. Statisticalphysicsofself-replication. TheJournalofChemicalPhysics2013,139,121923.
39. Costa,L.D. ProbabilisticPrinciplesforBiophysicsandNeuroscience:EntropyProduction,BayesianMechan-
ics&theFree-EnergyPrinciple,2024,[arXiv:math-ph/2410.11735].
40. Schopenhauer,A.;Payne,E.F.J. TheWorldasWillandRepresentation;DoverPublications:NewYork„1958.
41. Hesp,C.;Ramstead,M.;Constant,A.;Badcock,P.;Kirchhoff,M.;Friston,K. AMulti-scaleViewofthe
EmergentComplexityofLife:AFree-EnergyProposal. InProceedingsoftheEvolution,Developmentand
Complexity;Georgiev,G.Y.;Smart,J.M.;FloresMartinez,C.L.;Price,M.E.,Eds.,Cham,2019;pp.195–227.
42. Friston, K.; Heins, C.; Verbelen, T.; Costa, L.D.; Salvatori, T.; Markovic, D.; Tschantz, A.; Koudahl, M.;
Buckley,C.;Parr,T. Frompixelstoplanning:scale-freeactiveinference,2024,[arXiv:cs.LG/2407.20292].
43. Fields,C.;Goldstein,A.;Sandved-Smith,L. MakingtheThermodynamicCostofActiveInferenceExplicit.
Entropy2024,26. https://doi.org/10.3390/e26080622.
44. Smith,R.;Ramstead,M.J.D.;Kiefer,A.ActiveInferenceModelsDoNotContradictFolkPsychology. Synthese
2022,200,1–37. https://doi.org/10.1007/s11229-022-03480-w.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Intrinsic motivation as constrained entropy maximization"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
