Fix these issues in your summary:
- Too short: 182 words (minimum 200)

Current summary:
Okay, here’s a revised summary of the paper “Finding Similar Objects and Active Inference for Surprise in Numenta Neocortex Model” incorporating your feedback and instructions.**Finding Similar Objects and Active Inference for Surprise in Numenta Neocortex Model**The Numenta team has developed a model of the neocortex that proposes a mechanism for recognizing objects and dealing with surprise. This model, centered around the concept of “active inference,” suggests that the brain doesn’t passively receive sensory input but actively constructs its perception of the world by predicting and correcting sensory data. The core idea is that the brain seeks to minimize surprise by generating predictions that match incoming sensory information. This approach contrasts with traditional models that assume the brain simply receives and interprets sensory data. The model proposes that the brain actively seeks to minimize surprise by generating predictions that match incoming sensory data.The model is based on the principle that the brain doesn’t passively receive sensory input but actively constructs its perception of the world by predicting and correcting sensory data. The model proposes that the brain actively seeks to minimize surprise by

Paper text:
5202
nuJ
11
]CN.oib-q[
1v45512.6052:viXra
Finding Similar Objects and Active Inference for Surprise
in Numenta Neocortex Model
Hajime Kawakami
Akita University, Akita, 010-8502, Japan
kawakami@math.akita-u.ac.jp, hjm.kwkm.07091210@gmail.com
June 11, 2025
Abstract
Jeff Hawkins and his colleagues in Numenta have proposed the thousand-brains system. This is
amodelofthestructureandoperationoftheneocortexandisunderinvestigationasanewform
of artificial intelligence. In their study, learning and inference algorithms running on the system
are proposed, where the prediction is an important function. The author believes that one of
the most important capabilities of the neocortex in addition to prediction is the ability to make
association,thatis,tofindtherelationshipsbetweenobjects. Similarityisanimportantexample
of such relationships. In our study, algorithms that run on the thousand-brains system to find
similarities are proposed. Although the setting for these algorithms is restricted, the author
believes that the case it covers is fundamental. Karl Friston and his colleagues have studied the
free-energy principle that explains how the brain actively infers the cause of a Shannon surprise.
In our study, an algorithm is proposed for the thousand-brains system to make this inference.
The problem of inferring what is being observed from the sensory data is a type of inverse
problem, and the inference algorithms of the thousand-brains system and free-energy principle
solve this problem in a Bayesian manner. Our inference algorithms can also be interpreted as
Bayesian or non-Bayesian updating processes.
Keywords Neocortex · Thousand Brains · Similarity · Active Inference · Bayesian Inference ·
non-Bayesian Inference · Inverse Problem
1 Introduction
Conventionally, scientists state that the neocortex of the brain vertically comprises six layers.
Thus, the layers run parallel to the surface of the neocortex. The neocortex is horizontally
divided into several regions such as the visual and touch regions. For instance, the visual region
comprises several areas such as V1, V2, and V3. The neocortex, each region, and each area
comprise numerous cortical columns that penetrate the six layers. Numerous feedforward and
feedback connections exist between neurons in these cortical columns.
On pages 24 and 25 of [7], citing [15], Hawkins states:
Mountcastle is proposing that all the things we associate with intelligence, which on
the surface appear to be different, are, in reality, manifestations of the same under-
lying cortical algorithm. ... So, what was Mountcastle’s proposal for the location of
the cortical algorithm ? He said that the fundamental unit of the neocortex, the unit
of intelligence, was a “cortical column.”
1
However, Mountcastle did not propose any algorithm: how a cortical column does all the things
weassociatewithintelligence. Thus,Hawkinsetal. inNumentaproposedsuchalgorithmsin[6],
[7],[9],[11],and[14]. WerefertothesealgorithmscollectivelyastheNumenta(neocortex)model.
In these studies, prediction is considered as the most important capability of the neocortex,
and algorithms in the cortical columns for learning and inference, including prediction, have
been proposed (see Algorithms 3.1 and 3.2 described below). The cortical columns learn the
structure of objects using this learning algorithm, and infer the object under observation using
this inference algorithm with the sensory input. Hawkins named the system they created, which
included the Numenta model, the thousand-brains system. While writing this manuscript, the
paper [1] by Hawkins et al. was published. In this paper, Monty, the first instantiation of
the thousand-brains system, is proposed. Our study is based primarily on [9] and [14], which
explicitly describe the Numenta model algorithms, and it also refers to [1].
Whataretheotherimportantcapabilitiesoftheneocortexinadditiontoprediction? Section
2.4 of [1] lists the expected functions of a model of the neocortex. Related to this list, the
author believes that one of the important capabilities is making “association,” that is, finding
the relationships between objects. Similarity between objects is an important example of such
relationships. Theimportanceof“association”hasbeenhighlightedbynumerousscientists. For
instance, Polya [20] states the following on the list entitled “How to Solve it”:
Find the connection between the data and the unknown.
and
Have you seen it before ? Or have you seen the same problem in a slightly different
form ?
P. A. M. Dirac states that:
With the mathematical procedure there are two main methods that one may follow,
(i) to remove inconsistencies and (ii) to unite theories that were previously disjoint.
on page 58 of [19]. Hawkins emphasizes the importance of similarities with respect to Mount-
castle’s idea (see Chapter 3 of [6] and Chapter 2 of [7]). He also states that:
When mathematicians see a new equation, they recognize it as similar to previous
equations they have worked with.
on page 82 of [7]. In this study, we propose algorithms (Algorithms 4.1 and 4.2) that run on
the Numenta model to find similarities. These algorithms are based on the Numenta inference
algorithm (Algorithm 3.2). The setting for these algorithms is restricted, and for more general
“associations,” this setting is significantly limited. However, the author believes that the case
it covers is fundamental.
Friston et al. have studied the free-energy principle, for instance, [4], [5], and [18]. The free-
energy principle explains how the brain infers the cause for a Shannon surprise (informational
surprise). Inourstudy, analgorithm(Algorithm5.1)basedonAlgorithm3.2isproposedforthe
Numenta model to obtain this inference. A relationship between the thousand-brains system
and free-energy principle has been investigated in studies such as [22]. Friston’s theory is based
on probability theory, specifically the Bayesian inference theory. Inference in the Numenta
model is refined by reducing the ambiguity based on successive observations. Therefore, this
inference can be considered to be Bayesian. The problem of inferring what is being observed
from the sensory data is a type of inverse problem, and the inference algorithms of the Numenta
model and free-energy principle solve this problem in a Bayesian manner. We also consider our
inference algorithms from the perspective of Bayesian inference.
2
The remainder of this manuscript is organized as follows: In §2 and §3, the Numenta neocor-
texmodelandlearningandinferencealgorithms(Algorithms3.1and3.2)arereviewed. However,
these algorithms are slightly changed, primarily for simplicity. In §4 and §5, by slightly chang-
ing the Numenta inference algorithm, algorithms to find objects that are similar to a given
object (Algorithms 4.1 and 4.2) and an algorithm to actively infers surprise (Algorithm 5.1) are
proposed.
Although the proposed algorithms of this study are limited and are not based on brain
experimental results, the author hopes that they will contribute to future studies on the brain
or artificial intelligence. Real systems almost always encounter errors, and in the following,
the equations contain few of such errors, unless otherwise noted. It is believed that not only
neurons but also glial cells are important for the transmission of information in the brain (cf.
[3]). However, only neurons are considered in the Numenta model and this study.
2 Object, observation, learning, inference, and recognition
The Numenta model learns, infers, and recognizes objects. Figure 2.1 (A) shows an example of
such an object (see Figure 2 of [9] and Figure 5 of [14]). This object O comprises ten pairs of
locations and features, (location, feature), where ⋆, (cid:50), and ◦ are the features. (Several cases of
more general objects are considered in [1]. In §3.1 of [1], it is stated that “an object is a discrete
entity composed of a collection of one or more other objects.” Habitat objects, YCB object
dataset, and other datasets are listed in §6 as objects for simulation.) In the Numenta model,
time t is a discrete variable, t = 0,1,2,..., and each cortical column of the model observes and
senses one pair of (location, feature) at each time step. Figure 2.1 (B) illustrates an example of
an observation of O. The first observation location is the starting point of the red arrow, and
the sensory feature is ⋆ at this location. The next observation location is the end point of the
arrow, and the sensory feature is (cid:50) at this location. Such an arrow is called a movement vector
in[9]and[14]. Thus, acorticalcolumnoftheNumentamodellearnsO byobservingandsensing
pairs (location, feature) individually (by Algorithm 3.1).
Figure 2.1: An object and a movement vector
(A) (B)
⋆ ⋆
⋆ (cid:50) (cid:50) ⋆ ⋆ (cid:50) (cid:50) ⋆
(cid:1)(cid:21)
(cid:50) ◦ ◦ (cid:50) (cid:1) ◦ ◦
(cid:1)
(cid:1)
⋆ ◦ ⋆ ◦
O O
As described below, the inference is also performed by observing and sensing pairs (location,
feature) individually (by Algorithm 3.2). Assume that the model has already learned objects
O, O′, and O′′ of Figure 2.2, and then begins observing and inferring object O. In Figure 2.3
(A), the red arrow represents the first real movement vector. Then, both the first and second
sensory features are ◦, and this movement can not be distinguished from the other movements
3
Figure 2.2: Example of objects
⋆ ⋆ •
⋆ (cid:50) (cid:50) ⋆ ⋆ ◦ ◦ ⋆ • ◦ (cid:50) •
(cid:50) ◦ ◦ ◦ (cid:50) (cid:50) (cid:50) ◦ (cid:50)
⋆ ◦ (cid:50) • ◦
O O′ O′′
Figure 2.3: Convergence onto a representation for O
(A)
⋆ ⋆ •
(cid:45)
⋆ (cid:50) (cid:50) ⋆ ⋆ ◦(cid:27) ◦ ⋆ • ◦ (cid:50) •
(cid:54)
(cid:45)
(cid:50) ◦(cid:27) ◦ (cid:63)◦ (cid:50) (cid:50) (cid:50) ◦ (cid:50)
(cid:54) (cid:54)
⋆ (cid:63)◦ (cid:50) • ◦(cid:63)
O O′ O′′
(B)
⋆ ⋆ •
⋆ (cid:50) (cid:50) ⋆ ⋆ (cid:27) ◦ ◦ ⋆ • ◦ (cid:50) •
(cid:54) (cid:54)
(cid:50) ◦ (cid:45) ◦ ◦ (cid:50) (cid:50) (cid:50) ◦ (cid:50)
⋆ ◦ (cid:50) • ◦
O O′ O′′
(C)
⋆ ⋆ •
⋆ (cid:50) (cid:50)(cid:27) ⋆ ⋆ ◦ ◦ ⋆ • ◦ (cid:50) •
(cid:54)
(cid:50) ◦ (cid:45) ◦ ◦ (cid:50) (cid:50) (cid:50) ◦ (cid:50)
⋆ ◦ (cid:50) • ◦
O O′ O′′
4
represented by the blue vectors on O, O′, and O′′. Therefore, the model can not identify the
object that it has observed. In Figure 2.3 (B), the red arrows represent the first and second
real movement vectors. Then, these movements can not be distinguished from the movements
represented by the blue vectors on O′. Therefore, although the model is aware that it did not
observe O′′, it is unaware whether it has observed object O or O′. In Figure 2.3 (C), the red
arrows represent the first, second, and third real movement vectors. Then, the model is aware
that it has observed O, that is, it recognizes O. When this is the case, it is said that the
inference has converged onto a representation for the object O. The convergence property has
been investigated in detail in [9] and [14].
The inference by the Numenta model converges to an object, as the ambiguity regarding the
object under observation decreases. The problem of inferring an object using observed data is
an inverse problem. One of the well-known methods for solving inverse problems is successive
approximation such as gradient descent. By contrast, the inference of the Numenta model can
be considered as a Bayesian updating inference (see §5).
3 Numenta model of the neocortex
ThissectionreviewstheNumentamodelofthestructureofneocortexandlearningandinference
algorithms operating on the neocortex, based on [9] and [14]. However, it is slightly changed,
mainly for simplicity (see Remarks 3.1 and 3.3). The neocortex comprises numerous cortical
columns that are stacked vertically next to each other. All the cortical columns have the same
structure and Figure 3.1 shows one of the cortical columns. Although each cortical column is
said to comprise six horizontal layers, the cortical column of Figure 3.1 comprises the following
three layers: the output, sensory, and location layers corresponding to layers 2/3, 4, and 6a,
respectively. The sensory layer is also called the input layer in [9]. The model depicted in Figure
3.1 is obtained by combining the models in [9] and [14]. The model in [9] comprises only the
output and sensory layers, and that in [14] comprises only the sensory and location layers. The
model of Figure 3.1 also corresponds to the learning module in [1] (see Figure 3 in [1]).
EachbluebulletinFigure3.1isanhierarchicaltemporalmemory(HTM)neuron(see[8]and
[16]). HTM neurons are also called cells. Each cell can be in one of the following three states:
active, predictive, or inactive. The location layer comprises several grid cell modules, and each
module comprises several cells arranged in a triangular lattice. In Figure 3.1, only one module
is depicted. The number of modules in the location layer of each cortical column is denoted by
Nloc and the number of cells in each module by Mloc. In some simulations run in [14], Nloc = 10
and Mloc = 30 × 30 – 40 × 40. The sensory layer comprises several mini-columns, and each
mini-column comprises several cells arranged in a line. In Figure 3.1, only one mini-column is
depicted. The number of mini-columns in the sensory layer of each cortical column is denoted
by Nin and the number of cells in each mini-column by Min. In the simulations run in [9] and
[14], Nin = 150 and Min = 16. The output layer has no internal structure such as modules or
mini-columns. In Figure 3.1, only seven cells are depicted. The number of cells in the output
layer of each cortical column is denoted by Nout. In the simulations run in [9], Nout = 4096.
The Numenta model is a discrete time model. The arrows in Figure 3.1 represents the flow
of information between the cells. In the inference, the one cycle of the ordered flow is ⃝1 → ⃝2
→ ⃝3 → ⃝5 → ⃝6 → ⃝7 → ⃝4 → ⃝1 . In the model proposed by [14], it is ⃝1 → ⃝2 → ⃝3 → ⃝4 →
⃝1 , and in the model proposed by [9], it is ⃝2 → ⃝3 → ⃝5 → ⃝6 → ⃝7 → ⃝2 . These two flows are
sub-flows of the flow shown in Figure 3.1. The information flows in learning are similar to the
above. Steps ⃝1 to ⃝4 correspond to the stages 1 to 4 in [14]. Arrow ⃝1 is called the motor input
in [14], and ⃝3 is called the sensory input in [9] and [14]. These inputs originate from outside
5
the cortical column, and the motor input is either conscious or unconscious. Arrow ⃝6 shows the
internal flow of the output layer of a cortical column and the flow between the output layers of
cortical columns. Figure 3.2 illustrates three cortical columns. Different cortical columns may
receive the same type of sensory inputs, and they may also receive different types of sensory
inputs, suchasshapeandcolorinvision. Therefore, theNumentamodelcanhandlemultimodal
sensory inputs.
Figure 3.1: Numenta cortical column
⃝6 ⃝6
(cid:0) (cid:64) Dout • Dout (cid:0) (cid:64)
(cid:64) (cid:0) k,d • k,d (cid:64) (cid:0)
•
•
output •
layer •
f •
ijk
(cid:0)(cid:64)
⃝7
⃝5
sensory (cid:64)(cid:0)
layer f
ijk •
(input •
layer) •
•
(cid:64) Win •
⃝3 (cid:0) t •
•
Din •
c,d
(cid:0)(cid:64)
mini-column
⃝4
⃝2
(cid:64)(cid:0)
Dloc
γ,d
location
layer
• • • •
(cid:64) • • • • module
⃝1 (cid:0) • • • •
• • • •
Let v be a vector or tensor. If each component of v is either 0 or 1, we refer to v as a binary
vector or tensor. For a binary vector or tensor v, the number of 1s in the components of v is
denoted by ♮v. The inner product of vectors u and v of the same dimension is denoted by u•v.
Let Nc be the number of the considered cortical columns. We assume that the values of Nloc,
Mloc, Nin, Min, and Nout are equal for all considered cortical columns. Let Din, Dloc, and
c,d γ,d
Dout be binary vectors, and F = (f ) a binary tensor, where
k,d ijk
dimDin = NlocMloc, dimDloc = NinMin, dimDout = NcNout, dimF = NinMinNout.
c,d γ,d k,d
6
Vector Din represents a dendritic segment d of a cell c in the sensory layer, Dloc represents a
c,d γ,d
dendritic segment d of a cell γ in the location layer, Dout represents a dendritic segment d of a
k,d
cell k in the output layer, and f represents the pair of a cell j in mini-column i of the sensory
ijk
layer and a cell k in the output layer. The components of Din correspond to all the cells in
c,d
the location layer of the cortical column containing c, those of Dloc correspond to all the cells
γ,d
in the sensory layer of the cortical column containing γ, and those of F correspond to all the
pairs of the cells in the sensory and output layers in the same cortical column. The components
of Dout correspond to all the cells in the output layers of all considered cortical columns. Each
k,d
component of Din, Dloc, Dout, and F represents the connections between specified cells; for
c,d γ,d k,d
instance, if and only if a component of Din is 1, a connection exists between the cell in the
c,d
location layer represented by this component and the segment d of cell c. All the capabilities of
the Numenta model are realized by these connections.
Figure 3.2: Numenta cortical columns
(cid:63) (cid:63)
(cid:27) (cid:27) (cid:27) (cid:27)
(cid:45) (cid:45) (cid:45) (cid:45)
(cid:54) (cid:63) (cid:54) (cid:63) (cid:54) (cid:63)
(cid:45) (cid:45) (cid:45)
(cid:54) (cid:63) (cid:54) (cid:63) (cid:54) (cid:63)
(cid:45) (cid:45) (cid:45)
In §3.1 and §3.2, we consider learning and inference/recognition algorithms for objects. Fig-
ure 2.1 shows an example of such an object. This object O comprises ten pairs of (location,
feature). When a cortical column observes or recalls O, the location is specified by active cells
in the location layer, and the feature is specified by active cells in the sensory layer. Each
module in the location layer acts as a reference frame (or coordinate frame) of the locations
on the object under consideration. This is emphasized in [7] and [14]. According to [7] and
[14], the information flow in the model proposed by [14] is fundamentally sufficient for learning,
inferring, and recognizing any (simple) object. If an object is complex to be recognized by only
one cortical column, the connections ⃝6 between the output layers of the cortical columns assist
in recognizing this object. According to [1], each learning module can recognize objects, and
multiple learning modules can recognize more complex objects at a faster rate through voting
and a hierarchical structure.
Algorithm 3.1 is a learning algorithm and Algorithm 3.2 is an inference algorithm, based
on [9] and [14]. In the author’s opinion, some steps omitted in the algorithms of [9] and [14]
are added to Algorithms 3.1 and 3.2, and some steps are changed, mainly for simplicity. In
7
Algorithms 3.1 and 3.2, Aloc and Ain are binary vectors such that
t t
dimAloc = NlocMloc, dimAin = NinMin,
t t
and the components of Aloc and Ain correspond to the cells in the location and sensory layers
t t
of the considered cortical column at time t, respectively. If and only if a component of Aloc or
t
Ain is 1, the corresponding cell is active. In the following, Aloc and Ain are identified with the
t t t
sets of all cells in the location and sensory layers, respectively. When a location on an object is
observed, the feature f at this location provides a sensory input to the sensory layer, some mini-
columns in the sensory layer are selected, and some cells in these mini-columns are activated.
The set of such selected mini-columns is denoted by Win(f). Note that Win(f) is sparse, that
is, ♯Win(f) is significantly lower than Nin, where ♯S for a set S is the number of elements of
S. In [16], Win(f) is called the sparse distributed representation (SDR) of f. In Algorithms 3.1
and 3.2, Win(f) at time t is denoted by Win = Win(f).
t t
3.1 Learning
Algorithm 3.1 is a learning algorithm obtained by combining such algorithms of [9] and [14].
Algorithm 3.1 learns an object O by observing and sensing pairs (location, feature) on O indi-
vidually.
Algorithm 3.1 (Numenta learning algorithm)
This algorithm runs on each cortical column. In this algorithm, steps 6 to 12 are repeated
from the second round onwards. If πin = 0 for every c in (3.4), steps 11 and 12 are the same
c,t
as step 5. The positive constant θin in (3.4) is a threshold. The symbol “|” in (3.1), (3.2), and
b
(3.3) is designated as bitwise OR.
1. Set Din = 0 for every (c,d), Dloc = 0 for every (γ,d), Dout = 0 for every (k,d), and
c,d γ,d k,d
f = 0 for every (i,j,k).
ijk
2. For the object O, select a binary vector Aout of dimension Nout at random, that is, the
O
values of the components of Aout are determined at random. However, Aout must be
O O
sparse, that is, ♮Aout must be much less than dimAout. This Aout is fixed throughout
O O O
this algorithm. Denote by A out the NcNout dimensional vector obtained by concatenating
O
Aouts of all considered cortical columns.
O
The components of Aout correspond to all cells of the output layer. If and only if a
O
component of Aout is 1, the corresponding cell is active. In the following, Aout is identified
O O
with the set of all cells in the output layer.
3. For every active cell k ∈ Aout, select a dendritic segment d of k at random and set Dout =
O k,d
A out . Vector Dout is fixed throughout this algorithm.
O k,d
4. Set t = 0 and start observing O. From each module i in the location layer, randomly select
one cell and make it active. Thus, the initial value of the vector of Aloc is set.
t
The active cell in module i at time t represents a position vector ϕ⃗ in the reference frame
i,t
(cid:110) (cid:111)
given by module i. The set of vectors Φ := ϕ⃗ corresponds to the current observation
t i,t
location on O.
8
5. This step is stage ⃝3 in Figure 3.1. Sense the feature of O at the location in step 4. For the
sensory input from the feature, select a set of mini-columns Win of the sensory layer as
t
follows. Iftheinputhasbeenobservedinapreviouslearning, letWin bethemini-columns
t
selected then. If not, randomly select Win such that ♯Win ≪ Nin. Select one cell from
t t
each mini-column of Win at random and make this cell active. Thus, the initial value of
t
the vector of Ain is set.
t
6. Thisstepisstage⃝2. Foreveryactivecellcinthesensorylayer, selectadendriticsegment
d of c at random. It is fixed throughout this algorithm. For every such pair (c,d), update
Din by
c,d
(cid:12)
Din := Din (cid:12)Aloc . (3.1)
c,d c,d (cid:12) t
This is equation (9) of [14].
7. This step is stages ⃝5 and ⃝7 . For every active cell k ∈ Aout, randomly select some active
O
cells {c } in the sensory layer such that ♯{c } < ♯Win. Set γ = 1 and update f by
ij ij t ijk ijk
f := f |γ . (3.2)
ijk ijk ijk
8. Thisstepisstage⃝4. Foreveryactivecellγ inthelocationlayer,selectadendriticsegment
d of γ at random. It is fixed throughout this algorithm. For every such pair (γ,d), update
Dloc by
γ,d
Dloc := Dloc (cid:12) (cid:12)Ain . (3.3)
γ,d γ,d t
This is equation (8) of [14].
9. If the observation of O is finished, stop this algorithm. Otherwise, set t := t+1 and go to
the next step.
10. This step is stage ⃝1 . Change the observation location on O by motor input. This motor
input is represented by a vector ⃗δ in each module i of the location layer, and we obtain
i,t
(cid:110) (cid:111)
Φ = ϕ⃗ := ϕ⃗ +⃗δ ,
t i,t i,t−1 i,t
where the addition ϕ⃗ +⃗δ is considered on the torus made from the lattice of module
i,t−1 i,t
i. Make all cells in Φ active and the other cells inactive. Thus, Aloc is updated.
t t
The active cell in module i represents a position vector ϕ⃗ . The set Φ corresponds to the
i,t t
current observation location on O.
Notonlyavectorthatrepresentsamovementonanobject, suchastheredarrowinFigure
2.1, but also a vector in the location layer that represents a motor input, such as ⃗δ , is
i,t
also called a movement vector.
11. This step is stage ⃝2 . For every cell c in the sensory layer, calculate
(cid:40)
πin :=
1 ∃d : D
c
in
,d
•Al
t
oc ≥ θ
b
in
(3.4)
c,t
0 otherwise.
If and only if πin = 1, the cell c is predictive. If the current location is a location that has
c,t
not been visited before, then πin = 0 for almost all cells c.
c,t
9
12. This step is stage ⃝3 . Sense the feature of O at the location in step 10, get sensory input,
and select Win as in step 5. For every cell c = (ij) in the sensory layer (the j-th cell in
t
the i-th mini-column), calculate the activity of c:
 1 if i ∈ Win and πin = 1
 t ij,t

ain := ∗ if i ∈ Win and ∀k ∈ mini-column i,πin = 0
ij,t t ik,t


0 otherwise,
where ∗ = 1 for only one cell j that is randomly selected from the i-th mini-column and
∗ = 0 for the other every cell j. If and only if ain = 1, the cell c = (ij) is active. Thus,
ij,t
Ain is updated. Then, go back to step 6.
t
Remark 3.1 Compared with the learning algorithms in [9] and [14], Algorithm 3.1 is simpli-
fied as follows:
• In the learning algorithm of [9], the synaptic permanence values are used for Din, Dout,
c,d k,d
and f based on Hebbian-style adaptation (see (6), (7), and (8) in [9]). In contrast,
ijk
in the learning algorithm of [14], they are not used for Din and Dloc as shown in (3.1)
c,d γ,d
and (3.3), respectively. For simplicity, Algorithm 3.1 does not use synaptic permanence
values for Din, Dout, and f either. In particular, learning Dout is performed only once,
c,d k,d ijk k,d
at step 3. Note that, on page 5 in [9], the following is stated: “The output layer learns
representations corresponding to objects. When the network first encounters a new object,
a sparse set of cells in the output layer is selected to represent the new object. These cells
remain active while the system senses the object at different locations.” Based on this, we
maintain Aout fixed throughout learning.
O
• In [14], the activity in the location layer is considered for not a cell but a bump of cells,
and the structure of the reference frame and the lengths and angles of movement vectors
are precisely defined. In the present study, the activity is considered only for a cell and
movement vector ⃗δ is used for simplicity. The important ideas of the modules acting as
i,t
reference frames are explained in [7], [11], [13], and [14].
Remark 3.2 We make some remarks regarding Algorithm 3.1.
• The Numenta model can handle multimodal information through connections between
cortical columns via {Dout}. Connections {Dout} and {f } realize associative memory.
k,d k,d ijk
• For an object O, vector Aout is an SDR of O. Therefore, if O and O′ are different objects,
O
Ao
O
ut •Ao
O
u
′
t is expected to be approximately zero. Additionally, learning a new object is
expected not to result in catastrophic forgetting.
• In [9], ♮Aout in step 2 typically satisfies 40 ≤ ♮Aout ≪ dimAout = 4096. In [9] and [10],
O O O
♯Win in steps 5 and 12 and ♯{c } in step 7 are constants throughout learning, and their
t ij
typical values are 10 = ♯Win ≪ Nin = 150 and ♯{c } = 5 – 8. In the present study, the
t ij
values of ♮Aout, ♯Win, and ♯{c } are assumed to be equal for all objects, features, and
O t ij
times.
• In Algorithm 3.1, overlaps of the learned cells corresponding to different objects probably
exist because of random selections. In real learning, some noises that interfere with it
probably exist. See [9], [10], and [14] for the capacity for representing locations and
features, and noise robustness.
10
Figure 3.3: Learned connections between cells
totally connected
• • •• •
(cid:8)(cid:8)
(cid:74) (cid:10) (cid:8)
Aout in (cid:74) (cid:10) (cid:8)
O ······ (cid:8)
(cid:74) (cid:10) (cid:8)
output (cid:8)
(cid:74)(cid:10)(cid:8)
layer • =⇒ • • •
(cid:2) (cid:66)
(cid:2) (cid:66)
3 4
(cid:2) (cid:66)
(cid:2) (cid:66)
randomly selected (cid:2) (cid:66) ⇑ (cid:65)(cid:65) (cid:66)(cid:66) (cid:2)(cid:2) (cid:1)(cid:1) ⇓
(cid:2) (cid:66)
(cid:65) (cid:66) (cid:2) (cid:1)
(cid:2) (cid:66)
(cid:65) (cid:66) (cid:2) (cid:1)
(cid:2) (cid:66)
(cid:65)(cid:66) (cid:2)(cid:1)
(cid:2) (cid:66)
(cid:65)(cid:66) (cid:2)(cid:1)
(cid:2) (cid:66)
(cid:65)(cid:66) (cid:2)(cid:1)
(cid:2) (cid:66)
(cid:2) (cid:66) (cid:65)(cid:66)(cid:1)(cid:2)
Win in • • • • • • • • • •
t
sensory (cid:1)(cid:2)(cid:65)(cid:66)
(cid:1)(cid:2) (cid:66)(cid:65)
layer
(cid:1)(cid:2) (cid:66)(cid:65)
(cid:1)(cid:2) (cid:66)(cid:65)
2 5
(cid:1) (cid:2) (cid:66) (cid:65)
(cid:1) (cid:2)(cid:2) (cid:66)(cid:66) (cid:65)
totally connected
⇑ ⇓
totally connected
(cid:65) (cid:2)(cid:2) (cid:1) (cid:10)(cid:10)
(cid:65) (cid:2) (cid:1)(cid:10)
(cid:65) (cid:2)(cid:1)(cid:10)
(cid:65) (cid:2)(cid:1)(cid:10)
(cid:65) (cid:2)(cid:1)(cid:10)
location • • • • ⇐= • (cid:65) • (cid:2)(cid:1)(cid:10) • •
layer
1 6
An example of the connections between cells obtained using the learning algorithm 3.1 is
illustrated in Figure 3.3. The figures of two cortical columns in Figure 3.3 represent the same
cortical column: on the left, information flows upwards, whereas on the right, information flows
downwards. In 1 and 6 , the four rectangles represent the modules, and the four red points
represent the cells corresponding to a location. The five rectangles in 2 and 5 represent the
mini-columns in Win for the feature sensed at the location of 1 and 6 . The five red points
t
represent the cells selected from each mini-column in Win. For each cell in Aout, three cells were
t O
randomly selected from five active cells in Win. Algorithm 3.1 creates total connections between
t
all the cells representing the current location and all the cells representing the corresponding
feature. This algorithm also creates connections between all the cells in the output layer that
represent the same object. However, these connections are not required to be total connections
11
and probabilistic connections are also possible.
3.2 Inference, prediction and recognition
Algorithm 3.2 is an inference algorithm for objects learned by Algorithm 3.1. It is obtained
by combining such algorithms of [9] and [14]. Algorithm 3.2 makes inference by observing and
sensingpairs(location, feature)onanobjectO individually, inthesamemannerasinAlgorithm
3.1. (In§2.2of[1],itisstatedthat“thereisnocleardistinctionbetweenlearningandinference.”)
Let Aout be an Nout-dimensional bina

Rewrite the summary fixing the issues. Use exact title: Finding Similar Objects and Active Inference for Surprise in Numenta Neocortex Model
PROFESSIONAL TONE: Begin directly with content - NO conversational openings.
NO REPETITION. Each sentence must be unique. Vary attribution phrases.
Extract quotes VERBATIM from paper text - do NOT modify or "correct" them.