=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Navigating Autonomous Vehicle on Unmarked Roads with Diffusion-Based Motion Prediction and Active Inference
Citation Key: huang2024navigating
Authors: Yufei Huang, Yulin Li, Andrea Matta

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2024

Key Terms: unmarked, vehicle, prediction, autonomous, control, motion, navigating, active, traffic, inference

=== FULL PAPER TEXT ===

1
Navigating Uncertainties with Probabilistic Diffusion-
Based Motion Prediction and Active Inference
Yufei Huang, Yulin Li, Andrea Matta and Mohsen Jafari
Abstractâ€” This paper presents a novel approach to improving decision-making under uncertainty through predictive
autonomous vehicle control in environments lacking clear road reasoning [3].
markings by integrating a diffusion-based motion predictor within Uncertainties, such as missing roadway markings and mixed
an Active Inference Framework (AIF). Using a simulated parking
traffic, set a higher demand for a robust perception model in
lot environment as a parallel to unmarked roads, we develop and
autonomous navigation. Human drivers utilize their inner
test our model to predict and guide vehicle movements effectively.
The diffusion-based motion predictor forecasts vehicle actions by predictive mind [4] capability to predict and minimize
leveraging probabilistic dynamics, while AIF aids in decision- consequential errors by properly acting according to their
making under uncertainty. Unlike traditional methods such as perception of the roadway conditions. By anticipating and
Model Predictive Control (MPC) and Reinforcement Learning predictive reasoning, human drivers can handle poor road
(RL), our approach reduces computational demands and requires
conditions and avoid random moving traffic and parked
less extensive training, enhancing navigation safety and efficiency.
vehicles.
Our results demonstrate the model's capability to navigate
complex scenarios, marking significant progress in autonomous Navigating through traffic safely and efficiently remains a
driving technology. paramount concern for autonomous navigation, especially in
environments where traditional road markings are not clear.
Index Termsâ€” Diffusion-Based Motion Prediction, Active This challenge becomes even more pronounced in mixed flow
Inference Framework (AIF), Autonomous Control Systems traffic environments, where autonomous vehicles must coexist
with human-driven vehicles, all navigating without the
guidance of clear lane markings. Traditional navigation systems,
I. INTRODUCTION
which rely heavily on well-defined road infrastructures, often
In tackling the challenge of autonomous navigation under fall short under these conditions. The problem at hand focuses
uncertain and opposing circumstances, our research adopts a on enabling autonomous vehicles to find safe and efficient paths
novel approach by utilizing new advances in Generative AI, to their destinations in such unmarked road segments, hence, an
namely Probabilistic Diffusion (PD), and Active Inference
ability to adapt to less structured environments.
(AIF). PD reverse engineers a motion predictor and AIF safely Our approach sets itself apart from traditional methods such
guides vehicles to their intended destinations. We conjecture as Model Predictive Control (MPC) and Reinforcement
that the proposed approach can be generically applied to many Learning (RL), by leveraging the strengths of diffusion models
engineering applications involving predictions and control. In and the AIF. MPC relies heavily on precise vehicle modeling
this article, however, we demonstrate the main ideas for vehicle and the resolution of complex optimization challenges. Unlike
navigation in a parking lot setting, where vehicles are expected RL, which necessitates extensive training, our model offers a
to park at some designated spots. Lacking clear navigational direct, structured method for predicting vehicle trajectories,
cues and given random interactions between vehicles, parking incorporating safety considerations through its handling of
lots can serve as a building block for mirroring some of the predictive uncertainty. This unique combination of diffusion
complexities of autonomous navigation in more complex models and AIF, with its ability to make informed decisions
settings, such as unmarked roadways. We propose basic ideas
under uncertain conditions, positions our model as a pioneering
for extending our parking lot model to the unmarked roadway (the first of its kind) solution in the realm of autonomous
scenarios but leave the details to a future manuscript. Our navigation.
approach is pioneering, particularly in the utilization of PD for This paper is structured as follows: Section II reviews related
its novel application in the realm of autonomous navigation, works in the field; Section III details the methodology behind
beyond its traditional use in image processing where it excels our diffusion-based motion predictor and the AIF controller;
in generative AI tasks and reverse engineering complex systems Section IV presents the results from our simulation studies, and
[1]. Notably, this research marks one of the first instances of Section V concludes the paper with a discussion on the
PD being adapted for reverse engineering applications, a implications of our findings and directions for future research.
testament to its versatility and robust generative capabilities [2].
Similarly, AIF is employed not just as a control strategy but as II. RELATED WORKS
a cognitive model that mimics the Predictive Mind, enhancing
Y. Huang, Y. Li, and M. Jafari are with the Department of Industrial and A. Matta is with the Department of Mechanical Engineering of Politecnico
Systems Engineering, Rutgers University â€“ New Brunswick, Piscataway, NJ di Milano â€“ Via La Masa 1 20156, Milano, ITALY (e-mail:
08854, USA (e-mails: yh639@scarletmail.rutgers.edu; yl959@soe.rutgers.edu ; andrea.matta@polimi.it).
jafari@soe.rutgers.edu).
2
Navigating unmarked road environments poses unique existing literature provides a foundation for autonomous
challenges for autonomous vehicles, as traditional cues used for vehicle navigation, there is a distinct lack of research focused
lane following and distance keeping are not available. Model on mixed flow environments with unclear or no road markings.
Predictive Control (MPC) has been extensively applied in Furthermore, the potential of diffusion models and AIF in this
autonomous vehicle navigation due to its ability to handle context has not been fully explored, underscoring the novelty
dynamic constraints and predict future vehicle states [5]. For and significance of our approach.
instance, [6] demonstrated MPC's efficacy in lane-keeping and
obstacle avoidance by incorporating real-time traffic data into III. VEHICLE CONTROL IN UNMARKED PARKING AREAS
the control strategy. However, MPC's performance heavily
The goal of the control framework is to replicate a road
relies on the accuracy of the vehicle model and the
segment devoid of lane markings. To mimic the scenario, we
computational complexity of solving optimization problems in
break down the control system to aid vehicle navigation in a
real-time [7]. In scenarios with undefined road markings, the
simulated parking lot environment, where vehicles need to
absence of structured environmental data can limit MPC's
drive in unmarked corridors and avoid collision with other
predictive accuracy, making it less adaptable to unforeseen
parked and moving vehicles. The explanation is split into three
changes in traffic flow or road conditions. Recent studies
main parts. To begin with, we elaborate on the transformation
primarily focus on the development of robust machine learning
of a conventional road structure into a parking lot configuration.
models that can interpret complex environments where
This step is crucial in simulating a scenario where vehicles,
traditional sensor-based systems falter. Reinforcement
starting from random positions, velocities, and directions, need
Learning (RL) has been praised for its adaptability and ability
to navigate towards their designated parking spots. This
to improve over time, as highlighted by [8], who successfully
scenario represents a transition from a state of chaos to one of
applied deep reinforcement learning for trajectory planning in
order, which requires skillful maneuvering by the vehicles to
automated parking systems. But RL requires extensive training
avoid stationary and mobile obstacles. Next, we introduce an
data and significant computational resources, especially in
innovative diffusion-based motion predictor. This predictor is
complex and dynamic environments.
engineered to calculate the probability distribution of a vehicle's
Diffusion models have been predominantly utilized in image
imminent actions that will lead to its successful parking. The
processing and generation fields, as detailed by [9]. Our work
model is developed using diffusion model methodologies,
extends the application of diffusion models to the domain of
which include a forward training process and a reverse
reverse engineering; The diffusion model is used as a generative
application process. This dual-phase approach ensures a robust
model for next state prediction in AIF. AIF integrates
predictive framework capable of accurately forecasting
perception, action, and cognition into a cohesive framework,
vehicular movement within the parking lot. Lastly, we elucidate
emphasizing the role of uncertainty and the agent's internal
the application of the diffusion model within an active inference
model in guiding its behavior. The AIF has been used in
framework. Here, the diffusion model's generative capabilities
robotics and cognitive science to model decision-making
are used to help vehicles choose the most optimal action at each
processes under uncertainty [10]. Unlike Reinforcement
junction based on the principle of expected free energy.
Learning, which aims to maximize a numerical reward signal
Additionally, the model is continuously refined via variational
through actions, AIF takes actions as a means to minimize the
free energy adjustments, enhancing navigational efficacy.
expected free energy. This fundamental difference shifts the
Finally, the detailed workflow of the diffusion-based active
focus from seeking rewards to reducing uncertainty and
inference framework for autonomous vehicle navigation is
achieving a state of least surprise [11]. In RL, decisions are
illustrated.
driven by the potential for reward maximization, often defined
A. Adapting Parking Lot Dynamics to Simulate Unmarked
in terms of explicit rewards linked to specific outcomes.
Road Navigation
However, AIF embeds a preference-based approach where no
explicit reward signal is necessary; instead, it operates under a Within the context of autonomous navigation each vehicle
model where rewards are integrated as preferences over sensory must not only determine a path that avoids collisions but also
states, known as free energy. By minimizing free energy, AIF progress toward its destination amongst a dynamic and
inherently balances exploration and exploitation [12], adapting unpredictable setting. To tackle this, the concept of
its strategy based on both current understanding and new discretization becomes valuable. If we imagine breaking down
observations. This holistic approach allows agents to not only the continuous road into smaller, manageable pieces, akin to
respond to their environment but also anticipate changes, segments on a game board, the problem becomes less daunting.
making decisions that are informed by both past experiences As is shown in Fig.1 (a) and (b), within each of these discrete
and potential future states. segments, the vehicle's immediate task is to determine a safe
While AIF's application to autonomous vehicles is nascent, and viable route to the edge of the segment. This step-by-step
preliminary studies, such as those by [13] [14], indicate its approach, where the road is segmented into pieces, lays the
promise for enhancing adaptive decision-making in dynamic groundwork for drawing parallels with a parking lot scenario.
environments. Our research contributes to this emerging field In a parking lot, vehicles navigate through aisles to reach a
by integrating AIF with a diffusion-based motion predictor for specific parking spot without the guidance of painted lines.
improved navigation in mixed flow traffic environments. While Each aisle can be thought of as a segment of the road. The
3
vehicles must maneuver with care, negotiating their way around demonstrates the potential to reconstruct the original image
other cars and obstacles, all while making progress toward their from a state of maximal entropy through a systematic removal
allocated parking space. Both scenarios share fundamental of the introduced noises. In practice, a neural network can be
similarities: they require the vehicles to create order from introduced to learn the probability distribution to iteratively
disorder, forming structured outcomesâ€”whether it be a neatly denoise the image during the generative phase, with ğœ‘
parked car or a vehicle successfully reaching the end of a road representing the learned parameters of the model. The model
segmentâ€”out of initially unstructured situations. for the reverse process can be represented as:
ğ‘ (ğ‘¥ |ğ‘¥ )=ğ’©(ğ‘¥ ;ğœ‡ (ğ‘¥ ,ğ‘¡),ğœ2(ğ‘¥ ,ğ‘¡)ğ‘°) (2)
ğœ‘ ğ‘¡âˆ’1 ğ‘¡ ğ‘¡âˆ’1 ğœ‘ ğ‘¡ ğœ‘ ğ‘¡
Drawing on this established framework, the development of
the motion diffusion predictor adapts these principles to the
realm of vehicular movement. Instead of transitioning between
visual pixels, the motion diffusion predictor applies a similar
iterative process to the kinematic variables of a vehicle during
navigation.
a. Forward process of the diffusion-based motion predictor
In contrast to the image generation approach, where clarity is
Fig.1 (a) - Road segment for the controlled green car at timestep ğ‘› progressively diminished by overlaying Gaussian noise, the
motion diffusion predictor simulates the real-world conditions
that a vehicle starts from its parking spot, note the state as ğ‘† ,
0
and take random actions to drive away from the initial position
The final state ğ‘† is determined when a collision happens,
ğ‘‡
whether the vehicle hit the boundary of the parking area, or a
collision happen with other vehicles.
Fig. 1 (b) - Road segment for the controlled green car at timestep ğ‘›+1.
B. Path prediction: the diffusion-based motion predictor
(a) (b)
Fig. 3. Forward process for automated parking.
Illustrated in Fig.3 (a), the path of two actively moving
vehicles is traced (indicated in green). Initially positioned in
designated spots alongside four stationary vehicles, these two
green vehicles perform random throttle and steering
adjustments. Meanwhile, the yellow and red vehicles remain
Fig. 2. Diffusion process for image generation. stationary. The depicted sequence concludes with one green
The stable probabilistic diffusion [15] for image processing vehicle making contact with the red vehicle. Fig.3 (b) provides
commonly contains two phases as is shown in Fig.3. The an alternative depiction, where the roles are assumed by two
forward process begins with an original image, labeled as ğ‘‹ , yellow stationary cars and two green mobile cars. The green
0
that is fully observable. Through a sequence of transformations, cars persist in random movements until an eventual collision
random perturbation (noise) is incrementally introduced to this with the parking area's boundary, represented by a red wall.
image, leading to a progression of states where the original This forward process effectively emulates the journey from a
image becomes less recognizable, reaching a point of maximum state of complete organization to one of disorder, analogous to
randomness at ğ‘‹ . Denote ğ›½ as the variance of the Gaussian the method by which noise is added in image processing.
ğ‘‡ ğ‘¡
noise to be added at timestep ğ‘¡, which is increasing over time, Assuming that every aspect of the setting is visible and
trackable, the model processes time in fixed, uniform segments.
and the mean is defined as a scaled version of the previous state
Within these segments, the system monitors all vehicles'
ğ‘¥ , which is âˆš1âˆ’ğ›½ ğ‘¥ . The probability distribution of the
ğ‘¡âˆ’1 ğ‘¡ ğ‘¡âˆ’1
conditions. Each vehicle's condition is characterized by its
image at time ğ‘¡ can be represented as:
location, marked by coordinates (ğ‘¥,ğ‘¦), its speed in the direction
ğ‘(ğ‘¥ |ğ‘¥ )=ğ’©(ğ‘¥ ;âˆš1âˆ’ğ›½ ğ‘¥ ,ğ›½ ğ‘°) (1)
ğ‘¡ ğ‘¡âˆ’1 ğ‘¡ ğ‘¡ ğ‘¡âˆ’1 ğ‘¡ of both coordinates (ğ‘£ ,ğ‘£ ), and the direction it's facing, noted
ğ‘¥ ğ‘¦
In the subsequent reverse phase, the process methodically
as â„. The state of each vehicle at a certain timestamp ğ‘¡ can be
retracts the randomness, incrementally reinstating structure and
represented as a vector of 5 elements ğ‘† =
clarity. While the graph concludes with an image that is ğ‘¡
[ğ‘¥ ğ‘¦ ğ‘£ğ‘¡ ğ‘£ğ‘¡ ğ‘¡ ]. To aid in navigation, two extra pieces
partially clarified at ğ‘‹ , the aim is to recover a clear image, ğ‘¡ ğ‘¡ ğ‘¥ ğ‘¦ ğ‘¡
ğ‘¡âˆ’1 of information are provided for each vehicle at time ğ‘¡: ğœƒ shows
closely resembling the initial state ğ‘‹ . This process ğ‘¡
0
4
the direction to the vehicle's starting parking spot, and ğ‘™ actions that would logically return the vehicle to its prior state
ğ‘¡
measures how far the vehicle is from this spot. ğ‘†â€² based on the current state and navigational aids ğœƒ and ğ‘™ .
ğ‘¡âˆ’1 ğ‘¡ ğ‘¡
During each discrete interval of time in the simulation, the The aim here is mathematically modeled by seeking a
vehicles under control undergo random changes in speed and distribution for actions that reconcile with the earlier state,
direction. This is analogous to how, in the image diffusion given the existing conditions and guidance parameters. This
process, the amount of Gaussian noise is increased over time to approach endeavors to map out a backward trajectory,
gradually obscure the image. In a similar vein, the range within identifying actions that could have preceded the current
which these random driving decisions are made becomes wider vehicular state, hence facilitating a methodical backtracking to
as time progresses. The sequence of random driving decisions the initial position. The objective function, Kullback-Leibler
made throughout this process is represented by ğ‘ ,â‹¯,ğ‘ . (KL) Divergence [16], quantifies how one probability
1 ğ‘‡âˆ’1
Each action ğ‘ , where ğ‘– ranges from 1 to ğ‘‡âˆ’1, is drawn from distribution diverges from a second, expected probability
ğ‘–
a Gaussian distribution that is truncated. To avoid dramatic distribution. In this context, minimizing KL divergence helps in
movement change, the previous action is the mean of the adjusting the parameters of the predictive model ğ‘„ so that it
current action, the actions are chosen based on the previous closely approximates the true distribution ğ‘ƒ, leading to more
action ğ‘ but with added variability defined by ğœ2 . accurate predictions of the previous actions based on the given
ğ‘–âˆ’1 ğ‘–
Mathematically, this is written as: state and guidance features.
ğ‘ ~ğ’©(ğ‘ ,ğœ2ğœ¤) (3) minKL(ğ‘ƒ(ğ‘â€² |ğ‘†â€²,ğœƒâ€²,ğ‘™â€²)||ğ‘„(ğ‘â€² |ğ‘†â€²,ğœƒâ€²,ğ‘™â€²)) (8)
ğ‘ = ğ‘– ğ‘ğ‘™ğ‘–ğ‘(ğ‘ ğ‘–âˆ’1 , ğ‘™ğ‘ ğ‘– , ğ‘¢ğ‘) (4) ğ‘ğ‘¡ â€² âˆ’1 ğ‘¡âˆ’1 ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡âˆ’1 ğ‘¡ ğ‘¡ ğ‘¡
ğ‘– ğ‘– To effectively reduce the difference between what our model
The clip function applied here ensures that each action ğ‘
ğ‘– predicts and what actually happens, the goal is to closely match
stays within a specific range, denoted by the lower and upper
the state that our model predicts for the next step in the reverse
bounds (ğ‘™ğ‘ and ğ‘¢ğ‘). This range reflects the real-world physical
process, ğ‘†â€² (which corresponds to the state just before the
constraints on how much a vehicle can accelerate or decelerate ğ‘¡âˆ’1
current state ğ‘†â€² in the forward process), with the actual previous
(throttle) and turn (steering) at any given moment. ğ‘¡
state from the forward process. By doing so, we aim to refine
To manage the growing variability in the actions over time,
our model's ability to accurately forecast the results of its
a straightforward method increases ğœ linearly from a starting
ğ‘– suggested actions, ensuring the transitions it predicts align well
low point to a peak. This increment allows the range of potential
with real-world transitions.
actions to widen as the simulation progresses, facilitating a
gradual intensification of action diversity. The formula to
calculate ğœ reflects this linear growth, ensuring that with each
ğ‘–
step from the first to the last, the variance expands smoothly
from its minimum to its maximum value:
ğ‘– (5)
ğœ =ğœ +(ğœ âˆ’ğœ )Ã—
ğ‘– ğ‘šğ‘–ğ‘› ğ‘šğ‘ğ‘¥ ğ‘šğ‘–ğ‘› ğ‘‡âˆ’1
In Equation (5), ğœ and ğœ define the bounds of Fig. 4. Kinematic bicycle model.
ğ‘šğ‘–ğ‘› ğ‘šğ‘ğ‘¥
variance, while ğ‘– represents the current step, and ğ‘‡âˆ’1 Given the current state ğ‘†â€² and predicted action ğ‘â€² , the next
ğ‘¡ ğ‘¡âˆ’1
signifies the total number of steps. This approach guarantees a state ğ‘†â€² can be estimated using the kinematic bicycle model
ğ‘¡âˆ’1
controlled and predictable escalation in action variability,
[17] as shown in Fig.4. Define the vehicleâ€™s position as (ğ‘¥,ğ‘¦),
mirroring the real-world scenario where decision-making might
vehicleâ€™s forward speed as ğ‘£, vehicle's heading as ğœ“, the
become increasingly bold or cautious as conditions evolve.
vehicle's acceleration as ğ‘, vehicle's slip angle at the center of
gravity ğ›½, and ğ›¿ as the front wheel angle used as a steering
b. Reverse process of the diffusion-based motion predictor
command. The traditional bicycle model does not account for
In the reverse process, akin to the denoising steps in
uncertainties in state transitions that occur due to factors such
traditional diffusion models, a vehicle starts at random positions
as slippery roads and tires. To address this, the model is
inside the parking area with an initial speed and direction. The
enhanced by incorporating stochastic elements into its dynamic
motion diffusion predictor employs learned parameters to infer
equations. Specifically, noise terms are introduced, assumed to
the most probable previous action distribution of a vehicle -
follow a normal distribution, ğœ–~ğ’©(0,Î£), where Î£ represents a
essentially 'denoising' the vehicleâ€™s trajectory to yield a diagonal covariance matrix. The variances ğœ2, ğœ2, ğœ2 , ğœ2 ,
predicted path back to its parking state. The predictor is trained
ğ‘¥ ğ‘¦ ğ‘£ğ‘¥ ğ‘£ğ‘¦
and ğœ2 correspond to the respective state variables in ğ‘†â€². These
on reversed state-action sequences: ğ›¿ ğ‘¡
modifications enable the model to generate the next state by
ğ‘â€² ğ‘â€² ğ‘â€² ğ‘â€² (6)
ğ‘†â€²â†’ ğ‘¡âˆ’ 1ğ‘†â€² â†’ ğ‘¡âˆ’ 2â‹¯â†’1ğ‘†â€²â†’0ğ‘†â€² integrating the impact of environmental and vehicular
ğ‘¡ ğ‘¡âˆ’1 1 0
where ğ‘†â€² is the reverse of ğ‘† defined as: variabilities more realistically. The extended dynamic
ğ‘¡ ğ‘¡
ğ‘†â€²=[ğ‘¥ ğ‘¦ âˆ’ğ‘£ğ‘¥ âˆ’ğ‘£ ğ‘¦ ğœ‹âˆ’â„ ] (7) equations to get the next state can be written as:
ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡
Due to the dynamics of a vehicle's axles, the sequence of ğ‘¥ =ğ‘¥ +ğ‘£ âˆ™ğ‘ğ‘œğ‘ (ğ›¿ +ğ›½ )âˆ™âˆ†ğ‘¡+ğœ– (9)
ğ‘¡+1 ğ‘¡ ğ‘¥ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¥
actions taken during the forward phase may differ from those in ğ‘¦ =ğ‘¦ +ğ‘£ âˆ™ğ‘ ğ‘–ğ‘›(ğ›¿ +ğ›½ )âˆ™âˆ†ğ‘¡+ğœ– (10)
ğ‘¡+1 ğ‘¡ ğ‘¦ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¦
the reverse phase, implying that the reversed action ğ‘â€² â‰ ğ‘ . In ğ‘£ âˆ™ğ‘ ğ‘–ğ‘›â¡(ğ›½ ) (11)
ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡
ğ›¿ =ğ›¿ + âˆ™âˆ†ğ‘¡+ğœ–
the reverse process, the goal is to uncover the range of possible ğ‘¡+1 ğ‘¡ ğ¿/2 ğ›¿
5
ğ‘£ğ‘¥ =ğ‘£ âˆ™ğ‘ğ‘œğ‘ (ğ›¿ )+ğœ– (12) equation holds when ğ´ is within the boundaries:
ğ‘£
ğ‘¡
ğ‘¦
+1
=ğ‘£
ğ‘¡
âˆ™ğ‘ ğ‘–ğ‘›(ğ›¿
ğ‘¡+1
)+ğœ–
ğ‘£ğ‘¥
(13)
ğ‘¡
(ğ‘† ğ‘¡ âˆ’ğ›¾ ğ‘¡ ğ‘† 0 )2 (19)
where âˆ†ğ‘¡ is th ğ‘¡+ e 1 time ğ‘¡ step, ğ¿ is ğ‘¡ + th 1 e leng ğ‘£ t ğ‘¦ h of the vehicle, ğ›½ ğ‘¡ = ğ›» ğ‘†ğ‘¡ logğ‘ ğ‘¡ (ğ‘† ğ‘¡ |ğ‘† 0 )=âˆ’ğ›» ğ‘†ğ‘¡ 2ğœ ğ‘¡ 2
arctanâ¡( 1 âˆ™tanâ¡(ğ›¿ )) is the steering angle at the mass center, =âˆ’ ğ‘† ğ‘¡ âˆ’ğ›¾ ğ‘¡ ğ‘† 0
ğ‘¡
2 ğœ2
ğ‘¡
ğ‘£
ğ‘¡
=âˆšğ‘£
ğ‘¥
2
ğ‘¡
+ğ‘£
ğ‘¦
2
ğ‘¡
is the speed of the vehicle. ğœ–
ğ‘¥
, ğœ–
ğ‘¦
, ğœ–
ğ‘£ğ‘¥
, ğœ–
ğ‘£ğ‘¦
,
=âˆ’
ğ›¾
ğ‘¡
ğ‘†
0
+ğœ
ğ‘¡
ğ‘¨ âˆ’ğ›¾
ğ‘¡
ğ‘†
0
ğœ2
and ğœ– represents the noise on each state variable. ğ‘¡
ğ›¿ ğ‘¨
In the context of autonomous vehicle navigation using =âˆ’
ğœ
probabilistic methods, the application of Probabilistic Diffusion ğ‘¡
Therefore
(PD) through score matching [18] offers an innovative way to
ğ´ (ğ‘¥ ,ğ‘¡), (20)
handle the inherent randomness in vehicle dynamics. This ğ‘  (ğ‘¥ ,ğ‘¡)â‰”âˆ’ ğœƒ ğ‘¡
approach utilizes a stochastic differential equation framework ğœ‘ ğ‘¡ ğœ ğ‘¡
to model the dynamics of vehicle states, which is particularly For the timestep ğ‘¡ approaching a large number, we can use
useful in environments where precise control and prediction of the reparameterization trick because ğ‘  ğœ‘ (ğ‘¥ ğ‘¡ ,ğ‘¡) would also
vehicle behavior are critical due to unpredictable road follow Gaussian distribution based on the central limit theory.
conditions. The probabilistic state transition dynamics of a The objective of estimating the score function can be simplified
vehicle, represented by the bicycle model ğ‘† =ğ¹(ğ‘† ,ğ´ ) as:
ğ‘¡ ğ‘¡âˆ’1 ğ‘¡âˆ’1
ğ‘†(ğ‘¡ +âˆ†ğ‘¡)â‰…ğ‘† ğ‘¡ +ğ‘“(ğ‘† ğ‘¡ ,ğ´ ğ‘¡ )âˆ™ğ‘‘ğ‘¡+ğœ(ğ´(ğ‘¡),ğ‘¡) (14) ğ‘š ğœƒ ğ‘–ğ‘›ğ”¼ ğ‘¡~ ğ“Š(0,ğ‘‡) ğ”¼ ğ‘¥0~ğ‘0(ğ‘¥0) ğ”¼ ğ´ğ‘¡~ğ’©(ğ´ğ‘¡âˆ’1,ğœ ğ‘¡ 2ğ¼,ğ‘™ğ‘,ğ‘¢ğ‘) â€–ğ´ ğ‘¡ (21)
âˆ™âˆšâˆ†ğ‘¡ğ’©(ğ´ ,ğœ2ğ¼,ğ‘™ğ‘,ğ‘¢ğ‘) 2
ğ‘¡âˆ’1 ğ‘¡ âˆ’ğ´ (ğ‘¥ ,ğ‘¡)â€–
ğ‘‘ğ‘† =ğ‘“(ğ‘† ,ğ´ )âˆ™ğ‘‘ğ‘¡+ğ‘”(ğ´ ,ğ‘¡)ğ‘‘ğœ”Ì‚ (15) ğœ‘ ğ‘¡ 2
ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡
However, the total timestep in the proposed forward process
Here, ğ‘“(ğ‘† ,ğ´ ) denotes the deterministic evolution of the
ğ‘¡ ğ‘¡
would have a limited length and the reparameterization trick is
state, reflecting predictable changes based on the current state
not applicable. In this case, a rolling back method is introduced
ğ‘† , action ğ´ , and the bicycle model ğ‘“(âˆ™). The function ğ‘”(ğ´ ,ğ‘¡)
ğ‘¡ ğ‘¡ ğ‘¡ to learn ğ›» logğ‘ (ğ‘† |ğ‘† ).
represents the diffusion term, introducing randomness into the ğ‘†ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡+ğ‘‘ğ‘¡
As illustrated in Fig. 5, the process demonstrates how a
process to account for environmental uncertainties and the
ğ‘ğ‘¡âˆ’1
inherent variability in vehicle responses. The term ğ‘‘ğœ”Ì‚ denotes specific segment of state-action transitions from ğ‘† â†’ ğ‘† in
ğ‘¡ ğ‘¡âˆ’1 ğ‘¡
the increment of a Wiener process, encapsulating the random the forward phase is mirrored. In this reversal, the current state
fluctuations that affect the vehicle's trajectory. To address the ğ‘† becomes ğ‘†â€², following the method outlined in Equation (7).
ğ‘¡ ğ‘¡
challenge of modeling the reverse process, where one aims to A neural network model then predicts the probability
infer past states from current observations, a score matching ğ‘ƒ(ğ‘â€² |ğ‘†â€²,ğœƒâ€²,ğ‘™â€²) using the reversed state ğ‘†â€² in stage â‘  as is
ğ‘¡âˆ’1 ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡
technique is integrated into the dynamics: illustrated in Fig. 5. By employing the mean and variance
ğ‘‘ğ‘† (16) derived from ğ‘ƒ(ğ‘â€² |ğ‘†â€²,ğœƒâ€²,ğ‘™â€²), a reparametrized action ğ‘§â€² is
ğ‘¡ ğ‘¡âˆ’1 ğ‘¡ ğ‘¡ ğ‘¡ ğ‘¡âˆ’1
=[ğ‘“(ğ‘† ,ğ´ )âˆ’ğ‘”(ğ´ ,ğ‘¡)2ğ›» ğ‘™ğ‘œğ‘”ğ‘ (ğ‘† |ğ‘† )]ğ‘‘ selected. Subsequently, a physical model, referred to as the
ğ‘¡ ğ‘¡ ğ‘¡ ğ‘†ğ‘¡ ğ‘¡ ğ‘¡ 0 ğ‘¡
+ğ‘”(ğ´ ,ğ‘¡)ğ‘‘ğœ”Ì‚ bicycle model, is used to estimate the preceding state ğ‘†â€² from
ğ‘¡ ğ‘¡ ğ‘¡âˆ’1
In this setup, ğ´ adheres to a truncated Gaussian distribution, ğ‘†â€² and ğ‘§â€² in stage â‘¡ as is shown in Fig. 5. The discrepancy
ğ‘¡ ğ‘¡ ğ‘¡âˆ’1
ğ´ ~ğ’©(ğ´ ,ğœ2ğ¼,ğ‘™ğ‘,ğ‘¢ğ‘), ensuring that the actions remain between this estimated state ğ‘†â€² and the actual prior state, once
ğ‘¡ ğ‘¡âˆ’1 ğ‘¡ ğ‘¡âˆ’1
within plausible limits defined by physical and operational reversed to ğ‘† , is quantified using the mean squared error
ğ‘¡âˆ’1
constraints of the vehicle. The term ğ›» ğ‘™ğ‘œğ‘”ğ‘ (ğ‘† |ğ‘† ) (MSE). This rollback technique is pivotal in ensuring that the
ğ‘†ğ‘¡ ğ‘¡ ğ‘¡ 0
represents the score function, crucial for the score matching actions predicted by the model effectively guide the vehicle
approach. This gradient, which needs to be estimated via a closer to its initial parking spot, thereby reversing its trajectory
neural network ğ‘  (ğ‘¥ ,ğ‘¡), guides the correction of the forward in a manner that approximates the original state transitions.
ğœ‘ ğ‘¡
model by quantifying how the probability density function of
the state transitions should be adjusted to better fit the observed
data.
This refined modeling through score matching not only
enhances the accuracy of state prediction in backward time but
also improves the robustness and adaptability of the navigation
system under diverse and challenging driving conditions. The
objective function can be written as:
ğ‘šğ‘–ğ‘›ğ”¼ ğ”¼ ğ”¼ â€–ğ‘  (ğ‘¥ ,ğ‘¡) (17)
ğœƒ
ğ‘¡~ ğ“Š(0,ğ‘‡) ğ‘¥0~ğ‘0(ğ‘¥0) ğ´ğ‘¡~ğ’©(ğ´ğ‘¡âˆ’1,ğœ
ğ‘¡
2ğ¼,ğ‘™ğ‘,ğ‘¢ğ‘) ğœ‘ ğ‘¡
2 Fig. 5. Rolling back process.
âˆ’ğ›» ğ‘™ğ‘œğ‘”ğ‘ (ğ‘† )â€–
ğ‘†ğ‘¡ ğ‘¡ ğ‘¡
2 This neural network model architecture, rooted in the
where
principles of physics, utilizes a physics-informed variational
ğ‘† =ğ›¾ ğ‘† +ğœ ğ‘¨ (18)
ğ‘¡ ğ‘¡ 0 ğ‘¡ autoencoder (VAE) approach to carry out two key stages of
Since ğ´ follows truncated normal distribution, the following
ğ‘¡ prediction, as is shown in Fig. 6. At its core, the model inputs
6
the current reversed state ğ‘†â€². The initial phase involves an regularization term designed to refine the model's estimate of
ğ‘¡
encoder, structured as a fully connected neural network, which action variance at each timestep. It is expressed as the negative
predicts the likelihood of the previous action, ğ‘â€² based on ğ‘†â€². average over all timesteps ğ‘‡ of the logarithm of the variance ğœ
ğ‘¡âˆ’1 ğ‘¡ ğ‘–
This previous action is modeled to follow a Gaussian adjusted by a small constant ğœ– to maintain numerical stability.
distribution, with the neural network providing the mean Specifically, ğœ€ prevents the logarithm from diverging to
ğœ‡ and variance ğœ2 as outputs. Next, an action ğ‘§â€² negative infinity in cases where the variance ğœ approaches zero.
ğ‘ ğ‘¡ â€² âˆ’1 |ğ‘¥ğ‘¡ ğ‘ ğ‘¡ â€² âˆ’1 |ğ‘¥ğ‘¡ ğ‘¡âˆ’1 ğ‘‡ ğ‘– (23)
is chosen using a technique known as reparameterization, which 1
ğ‘… (ğœ2 )=âˆ’ âˆ‘[ğ‘™ğ‘œğ‘”(ğœ +ğœ€)
aids in drawing a sample from the predicted distribution. The ğ‘ ğ‘ ğ‘¡ â€² âˆ’1 |ğ‘¥ğ‘¡ ğ‘‡ ğ‘–
next part of the model, which acts as a decoder, incorporates a ğ‘¡=1
+ğ‘™ğ‘œğ‘”(1âˆ’ğœ âˆ’ğœ€)]
physics-based framework to estimate the earlier state, ğ‘†â€² . ğ‘–
ğ‘¡âˆ’1 This regularization term comprises two components: the log
informed by the chosen action ğ‘§â€² and the current modified
ğ‘¡âˆ’1 of ğœ plus ğœ€, and the log of 1âˆ’ğœ âˆ’ğœ€, which together
state ğ‘†â€². The process culminates with a comparison between the ğ‘– ğ‘–
ğ‘¡ encourage the model not to be overly confident (by avoiding
estimated previous state ğ‘†â€² and the actual previous state
ğ‘¡âˆ’1 too small variance) or overly uncertain (by avoiding too large
known from the data, referred to as ğ‘†âˆ—â€² . This final step verifies
ğ‘¡âˆ’1 variance) about its action predictions. The balance achieved by
the accuracy of the model's predictions, ensuring that the
this term is crucial for a model that needs to have a reasonable
chosen actions are effectively guiding the vehicle back toward
level of uncertainty to be robust yet confident enough to make
a state that aligns with the known trajectory leading up to the
accurate predictions. The noise loss term ğ‘… (Î£) defined in
original parking position. ğœ–
Equation (24) measures how likely the true next state is, given
the model's predictions, scaled by the model's own uncertainty
about its predictions (expressed through Î£).
ğ‘€ğ‘†ğ¸(ğ‘†â€² ,ğ‘†âˆ—â€² ) (24)
ğ‘… (Î£)= ğ‘¡âˆ’1 ğ‘¡âˆ’1
ğœ– 2âˆ™Î£2
The function is fundamentally derived from the log-
likelihood of a Gaussian distribution, which is a common
approach in statistical modeling to handle errors or noise that
follows a normal distribution. the log-likelihood of observing
Fig. 6. Physics-informed VAE. the next state ğ‘†â€² from a Gaussian distribution with the mean
ğ‘¡âˆ’1
(true next state) ğ‘†âˆ—â€² and variance Î£2 is given by Equation (25):
ğ‘¡âˆ’1
The loss function designed for the physics-informed VAE is (ğ‘†â€² âˆ’ğ‘†âˆ—â€² ) 2 (25)
threefold: Firstly, it accounts for the state prediction error, log(ğ‘(ğ‘†â€² |ğ‘†âˆ—â€² ,Î£2))=âˆ’ ğ‘¡âˆ’1 ğ‘¡âˆ’1 âˆ’
quantifying the difference between predicted states and true
ğ‘¡âˆ’1 ğ‘¡âˆ’1 2âˆ™Î£2
log(Î£âˆš2ğœ‹)
states. Secondly, it incorporates a regularization component for
the variance ğœ2 . This regularization ensures that the model We can drop the constant term logâ¡(Î£âˆš2ğœ‹) for optimization
ğ‘ ğ‘¡ â€² âˆ’1 |ğ‘¥ğ‘¡ since it does not affect the relative evaluations of the model
does not overly concentrate on minimizing the prediction error
parameters. This formulation leverages the properties of the
linked to the mean ğœ‡ , but also accurately gauges the level
ğ‘
ğ‘¡
â€²
âˆ’1
|ğ‘¥ğ‘¡ Gaussian distribution to model uncertainty in state transitions
of uncertainty in the variance. The third term accounts for and incorporate it into the loss function.
model uncertainty in predictions of the next state. It regulates
C. Decisions on the move: Active Inference with the diffusion
the variance of state transition noise ğœ–~ğ’©(0,Î£). The structure
model
of this loss function is intended to maintain a balance between
Active Inference (AIF) offers a framework for understanding
precise state estimation and a reliable measure of prediction
and predicting the behavior of autonomous agents in dynamic
confidence.
and uncertain environments. This approach uses the principle
â„’=ğ‘€ğ‘†ğ¸(ğ‘†â€² ,ğ‘†âˆ—â€² )+ğœ† ğ‘… (ğœ2 )+ğœ† ğ‘… (Î£) (22)
ğ‘¡âˆ’1 ğ‘¡âˆ’1 1 ğ‘ ğ‘
ğ‘¡
â€²
âˆ’1
|ğ‘¥ğ‘¡ 2 ğœ– of minimizing expected free energy and variational free energy
where ğœ† 1 and ğœ† 2 serve as scaling factors that dictate the to guide decision-making [19]. Variational free energy deals
relative weight of the regularization term and the noise term in with the present (how well the agent's model predicts what it
the overall loss function. By adjusting ğœ† and ğœ† , one can currently observes), while expected free energy is concerned
1 2
control how much emphasis is placed on the regularization with the future (choosing actions that minimize future surprise
aspect, which governs the precision of the uncertainty captured and maximize goal fulfillment) [20]. Together, these concepts
by ğ‘… (ğœ2 ) and ğ‘… (Î£), compared to the emphasis on help an agent continuously adapt and make informed decisions
ğ‘ ğ‘
ğ‘¡
â€²
âˆ’1
|ğ‘¥ğ‘¡ ğœ–
in a changing world, aiming for a coherent and accurate
minimizing the mean squared error (MSE) between the
predicted state ğ‘†â€² and the true previous state ğ‘†âˆ—â€² . The value understanding of its environment and effective interaction with
ğ‘¡âˆ’1 ğ‘¡âˆ’1
it.
of ğœ† and ğœ† are chosen to balance the trade-off between
1 2
Variational free energy is a concept derived from statistical
accuracy of state prediction and reliability of the model's
physics but adapted in the realm of cognitive science to measure
confidence in its predictions.
how well an agent's internal model predicts sensory inputs it
The function ğ‘… (ğœ2 ) defined in Equation (23) is a
ğ‘ ğ‘
ğ‘¡
â€²
âˆ’1
|ğ‘¥ğ‘¡ observes. It is a discrepancy measure between what the agent
7
expects to see and what it observes. Minimizing variational free In the AIF framework, Variational Free Energy (VFE) serves
energy means the agent is improving its model of the world to as a measure of the divergence between the predicted and actual
better predict incoming sensory data. In simpler terms, itâ€™s like future states. In this work, VFE is used to quantify the
an error signal that tells the agent how wrong its predictions discrepancy between the outcomes predicted by the diffusion
were; by reducing this error, the agentâ€™s model becomes more model (DP model) and the observed true states. The VFE is
accurate. Expected free energy, on the other hand, is more formally represented by the equation:
forward-looking. It measures not just the "fit" or accuracy of the ğ‘‰ğ¹ğ¸=ğ· [ğ‘(ğœ‘|ğ‘† ,ğ‘)||ğ‘(ğœ‘)] (28)
ğ¾ğ¿ ğ‘›
agent's model against current observations but also considers âˆ’ğ¸ [ğ‘™ğ‘œğ‘”ğ‘(ğ‘†âƒ—âƒ—âƒ— â€²|ğ‘† ,ğ‘,ğœ‘)]
ğ‘ ğ‘›
the future states the agent might experience. Expected free
In equation (28), the first term is the KL divergence, which
energy considers the uncertainty or surprise that those future
calculates the difference between the current belief about the
states could hold and how valuable they might be in terms of model parameters ğ‘(ğœ‘|ğ‘† ,ğ‘) and the prior beliefs ğ‘(ğœ‘). The
ğ‘›
the agent's goals. By minimizing expected free energy, the
second term is the expected log probability of the observed
agent doesnâ€™t just seek to reduce surprise in the present but also
states given the current state, actions, and model parameters,
acts in ways that are expected to reduce surprise in the future
which serves to anchor the model's predictions to the actual
while maximizing its goals [21].
observations. To optimize the diffusion model, VFE is
Here, AIF is an approach that conceptualizes the way
minimized by continuously adjusting the model parameters,
autonomous vehicles navigate and interact with the world. The
denoted as ğœ‘ using the data collected during operation. This
automated parking is modeled as a finite horizon Markov
optimization is typically performed using gradient descent on
decision process (MDP) [22]. The key to applying AIF is the
the physics-informed VAE, as is discussed in section III part b,
balance between being true to vehicleâ€™s model of the parking
where ğœ‘ =ğœ‘ âˆ’ğœ‚ğ›» ğ‘‰ğ¹ğ¸, with ğœ‚ is the learning rate.
ğ‘›ğ‘’ğ‘¤ ğ‘œğ‘™ğ‘‘ ğœ‘
environment while taking actions that are most likely to result
b. Navigating Towards Goals with the Free Energy of the
in preferred outcomes, which are states that lead the vehicle
Future
back to its desired parking spot. The diffusion-based motion
In the exploration of preferred states within the AIF
predictor operates as a generative model for a vehicle's
framework, a preference distribution ğ¶ is defined over the
interactions within its environment. This model, parameterized ğ›½
state space ğ•Š. This distribution is weighted by a parameter ğ›½,
by ğœ‘ , projects the likelihood of potential actions ğ‘(ğ‘ |ğ‘† ;ğœ‘),
ğ‘› ğ‘› which is greater than zero, to prioritize states that the agent finds
each action being one that could revert the vehicle to a position
rewarding. Mathematically, preferred states are derived from
progressively nearer to its designated parking location.
the Boltzmann distribution expressed as in logarithmic form by:
Complementing this predictive layer is the physical
âˆ’ğ‘™ğ‘œğ‘”ğ¶ (ğ‘†)=âˆ’âˆ’ğ›½ğ‘…(ğ‘†)âˆ’ğ‘(ğ›½),âˆ€ğ‘† (29)
probabilistic bicycle model, symbolized as ğ‘“(âˆ™), which serves ğ›½
âˆˆğ•Š,for some ğ‘(ğ›½)
to estimate the vehicle's subsequent state as a consequence of
âˆˆâ„ constant w.r.t s.
the selected actions. This physical model follows the dynamics
The parameter ğ›½ , known as the inverse temperature,
encapsulated in the predefined Equations (9) â€“ (13), providing
quantifies the agentâ€™s motivation level: a higher ğ›½ corresponds
the trajectory that a vehicle would trace given a set of
to a stronger preference for states yielding higher rewards.
maneuvers. The interplay between the generative model and the
Agents are therefore inclined to select states that maximize the
physical model creates a cohesive framework for understanding
reward function ğ‘…(ğ‘†), thus maximizing ğ¶ (ğ‘†) and minimizing
and guiding a vehicle's movements towards its goal state. ğ›½
ğ‘†â€² =ğ‘“(ğ‘† ,ğ‘ ) (26) âˆ’ğ‘™ğ‘œğ‘”ğ¶ (ğ‘†) for any given ğ›½ greater than zero. This
ğ‘›+1 ğ‘› ğ‘› ğ›½
Incorporating the realities of dynamic environments into the foundational preference structure underpins the agent's
predictive model, the likelihood of future states and actions can decision-making process, steering it toward states that it deems
now be represented with a probability distribution that allows preferable or beneficial in the context of its environment and
for environmental uncertainties such as slippery road conditions. objectives. The reward function ğ‘…(ğ‘†) captures the criteria for
This predictive distribution is described by: these desired states, integrating goals such as reaching a parking
ğ‘„(ğ‘†âƒ—âƒ—âƒ— â€²,ğ‘ |ğ‘† )â‰” (27) spot ğ‘† , maintaining safety by avoiding collisions with
ğ‘› ğ‘”ğ‘œğ‘ğ‘™
ğ‘âˆ’1 surrounding vehicles ğ‘†ğ‘£âˆ’ at time step ğ‘›+1, and ensuring
âˆ ğ’©(ğ‘† ;ğ‘“(ğ‘† ,ğ‘ ),Î£)ğ‘(ğ‘ |ğ‘† ;ğœ‘) ğ‘›+1
ğœ+1 ğœ ğœ ğœ ğœ smoothness in the control actions. Mathematically, the reward
ğœ=ğ‘›
In Equation (27), ğ‘„(ğ‘†âƒ—âƒ—âƒ— â€²,ğ‘ |ğ‘† ) denotes the estimated future function is characterized by:
ğ‘› ğ‘…(ğ‘†)=âˆ’ğœ† âˆ™â€–ğ‘†â€² âˆ’ğ‘† â€–+ğœ† (30)
states and actions, assuming the agent is in state ğ‘† . Instead of ğ‘”ğ‘œğ‘ğ‘™ ğ‘›+1 ğ‘”ğ‘œğ‘ğ‘™ ğ‘ ğ‘ğ‘“ğ‘’ğ‘¡ğ‘¦
ğ‘›
asserting that actions lead to a single specific state, the Gaussian âˆ™âˆ‘â€–ğ‘†â€² âˆ’ğ‘†ğ‘£âˆ’ â€–
ğ‘›+1 ğ‘›+1
distribution ğ’© introduces a scope of possible next states ğ‘† ,
ğœ+1 âˆ’ğœ† âˆ™â€–ğ‘â€² âˆ’ğ‘ â€–
with ğ‘“(ğ‘† ,ğ‘ ) providing the mean or most likely next state and ğ‘ ğ‘šğ‘œğ‘œğ‘¡â„ ğ‘› ğ‘›âˆ’1
ğœ ğœ where ğœ† , ğœ† , and ğœ† are the weighting
Î£ encapsulating the uncertainty in this transition. The term ğ‘”ğ‘œğ‘ğ‘™ ğ‘ ğ‘ğ‘“ğ‘’ğ‘¡ğ‘¦ ğ‘ ğ‘šğ‘œğ‘œğ‘¡â„
parameters that balance the importance of each aspect in the
ğ‘(ğ‘ |ğ‘† ;ğœ‘) captures the conditional probability of an action ğ‘ ,
ğœ ğœ ğœ
reward function. Extending the preference distribution ğ¶ over
given the current state ğ‘† , and influenced by the model's ğ›½
ğœ
parameters ğœ‘. trajectories ğ‘† â‰”(ğ‘† ,ğ‘† ,â‹¯,ğ‘† )âˆˆğ•Šğ‘, we apply the additive
1 2 ğ‘
a. Refining the Predictive Model via Variational Free Energy property of the reward function to evaluate entire paths:
8
distribution as encoded by ğ¶ (ğ‘† ). This divergence aims to
ğ›½
âˆ’ğ‘™ğ‘œğ‘”ğ¶ (ğ‘† )=âˆ’ğ›½ğ‘…(ğ‘† )âˆ’ğ‘â€²(ğ›½) (31) penalize decisions leading to future states that are less preferred
ğ›½
ğ‘ according to the cost function. Essentially, it encourages the
=âˆ’âˆ‘ ğ›½ğ‘…(ğ‘† )âˆ’ğ‘â€²(ğ›½),âˆ€ğ‘†
ğœ selection of actions that not only minimize surprise but also
ğœ=1
âˆˆğ‘†ğ‘ align future states closely with those that are considered
The inverse temperature parameter ğ›½ remains a measure of preferable or beneficial.
how strongly the agent prefers certain trajectories, favoring Given a MDP process, the EFE for a sequence of actions,
those that accumulate greater rewards. Through this framework, denoted as ğº(ğ‘ |ğ‘  ), can be expressed as an aggregate of
ğ‘¡
the active inference process not only seeks individual states but individual free energies at each time step:
also entire trajectories that are aligned with the agent's ğ‘ (34)
preferences and the dynamics of the vehicle's environment. ğº(ğ‘ |ğ‘  ğ‘¡ )â‰ˆ âˆ‘ ğº(ğ‘ ğœ |ğ‘  ğœ )
Vehicles aim to minimize a quantity known as Expected Free ğœ=ğ‘›+1
This simplification allows the agent to plan by evaluating
Energy (EFE) in the framework of active inference, which
each future time point separately, significantly streamlining the
guides them in making decisions that align with their
planning process without the need for an exhaustive evaluation
preferences. This aims at balancing the exploration-exploitation
of all possible future trajectories. It is an efficient method to
trade-off by minimizing surprise (or uncertainty) and
guide the agent toward preferred states while considering the
maximizing the likelihood of achieving preferred outcomes
inherent uncertainties and computational constraints.
[20]. The general formula for EFE is:
ğº(ğ‘ ,ğ‘)=ğ”¼ ğ‘„(ğ‘ â€² |ğ‘ ,ğ‘) [logğ‘„(ğ‘ â€²|ğ‘ ,ğ‘) (32) D. Comprehensive Workflow of the Diffusion-Based Active
âˆ’logğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘)] Inference Framework
whereâ¡â¡ğ‘  represents the current state, ğ‘ represents the action The following algorithm outlines the entire workflow of the
taken by the agent, ğ‘ â€² represents the subsequent state resulting Diffusion-Based Active Inference Framework (AIF). It is
from action ğ‘, and ğ‘œ is the observation or outcome associated structured into three interlinked phases: Forward Diffusion
with state ğ‘ â€². ğ‘„(ğ‘ â€²|ğ‘ ,ğ‘) is the approximate posterior or the Process, Reversed Diffusion Process, and Active Inference
agentâ€™s belief about the next state given the current state and Control. Using simulation for training, vehicles exit parking
action. ğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘) is the generative model that links states and spots under a variety of initial conditions, performing random
observations, providing the likelihood of observing ğ‘œ in state ğ‘ â€² maneuvers such as steering and throttle adjustments. The
after taking action ğ‘. The term logğ‘„(ğ‘ â€²|ğ‘ ,ğ‘) refers to the process continues until the vehicle either collides or reaches the
boundary of the parking area. The reversed Diffusion process
entropy of the agent's beliefs, which measures uncertainty or
surprise about the next state. The term logğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘) captures utilizes the data generated in the forward Diffusion process and
employs a physics informed Variational Autoencoder (VAE)
the accuracy of the predictions under the model, quantifying
model to reverse the sequence of the collected data. The model
how probable the outcomes are given the agentâ€™s model of the
predicts previous states and actions from current states,
world. In practice, this formula guides agents to choose actions
enabling the vehicle to reverse-engineer its movements. The
that are expected to provide the most informative (reducing
reverse model is refined through VFE when it fails to properly
uncertainty) and rewarding outcomes according to their internal
predict. The refined reverse model and AIF then decide the
model of the world.
most probable action(s) that minimize expected free energy. the
Equation (33) can be approximated and split into an energy
vehicle toward its intended destination, dynamically adapting
and an entropy or an accuracy and complexity term [20], which
to new data and making necessary course corrections.
corresponds to the extrinsic and epistemic action terms in the
Algorithm 1: Algorithm for Diffusion-Based Active
EFE:
Inference Framework
ğº(ğ‘ ,ğ‘) (33)
DP-Forward: Data Collection
â‰ˆâˆ’ğ”¼ ğ‘„(ğ‘ â€² |ğ‘ ,ğ‘) [logğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘)] Input: Number of trials, vehicle dynamics.
+ğ”¼ ğ‘„(ğ‘ â€² |ğ‘ ,ğ‘) ğ· ğ¾ğ¿ [ğ‘„(ğ‘† âƒ—âƒ—âƒ—â€²âƒ—âƒ— |ğ‘ ,ğ‘† ğ‘› )|ğ¶ ğ›½ (ğ‘† )] 1 O Fo u r tp e u a t c : h V t e r h ia ic l l : e trajectory dataset.
where the first term ğ”¼ ğ‘„(ğ‘ â€² |ğ‘ ,ğ‘) [logğ‘ƒ(ğ‘œ,ğ‘ â€²|ğ‘ ,ğ‘)] is the 2 Initialize parking lot with vehicles at random
spots.
extrinsic value. It quantifies the surprise or improbability of
3 Simulate vehicle movement until a collision or
observing ğ‘œ and the next state ğ‘ â€² given the current state ğ‘ â¡and
boundary is reached:
the current action ğ‘, thereby estimating how unexpected or 4 Apply random actions (throttle, steering)
unlikely these observations and transitions are under the current and introduce Gaussian noise to model
policy. The second term ğ”¼ ğ‘„(ğ‘ â€² |ğ‘ ,ğ‘) ğ· ğ¾ğ¿ [ğ‘„(ğ‘† âƒ—âƒ—âƒ—â€²âƒ—âƒ— |ğ‘ ,ğ‘† ğ‘› )|ğ¶ ğ›½ (ğ‘† )] is uncertainty.
5 Record state transitions and actions until
the intrinsic value, which incorporates the cost function ğ¶ (ğ‘† ) the end condition is met.
ğ›½
and quantifies how the distribution of predicted future states DP-Reverse: Model Training
ğ‘„(ğ‘†
âƒ—âƒ—âƒ—â€²âƒ—âƒ—
|ğ‘ ,ğ‘† ) diverges from a desired or preferred state
Input: Collected vehicle trajectories.
ğ‘› Output: Trained physics-informed VAE model for
9
motion prediction. remaining pair are static and parked. In the second, more
6 Reverse the state-action sequences from the complex scenario, the environment is expanded to include ten
trajectory dataset. parking spots and six cars, with half of the vehicles being under
7 Initialize the VAE model. our control, as is shown in figure 7(b).
8 For each training epoch:
9 Predict action distributions to reverse states.
10 Sample actions using reparameterization.
11 Predict previous states using the probabilistic
bicycle model.
12 Compute loss and update model parameters.
Active Inference Control: Implementation and
(a) (b)
Execution
Fig. 7. Randomly generated starting points for the forward process.
Input: Pretrained VAE model, vehicleâ€™s current
state, and destination. For training phase, the starting positions of the vehicles are
Output: Vehicle actions (throttle, steering). randomized in different parking spots in each trial, ensuring a
13 Continuously predict and apply actions that diverse range of initial conditions for model training.
minimize EFE until the vehicle reaches the desired b. Customizing the Simulation for AIF-Controlled Driving
spot.
14 Monitor state prediction error:
15 If error exceeds a threshold, fine-tune the model
with recent state-action data.
The algorithm is inherently cyclic and adaptive, featuring
feedback mechanisms within the Active Inference Control
phase that can trigger additional data collection and model (a) (b)
retraining as needed. This adaptive cycle ensures that the Fig. 8. Randomly generated starting points for the reverse process.
navigation system continuously evolves, enhancing its capacity For the application phase, the parking environment is again
to handle increasingly complex environments and improving
customized for scenarios with four and six cars as is shown in
accuracy over time.
Fig. 8. Parked cars are placed in predetermined spots, while the
controllable vehicles are placed at random locations within the
IV. SIMULATION AND VALIDATION RESULTS parking area, each with an assigned destination spot. The
In this section, we delve into the validation results from controllable cars, equipped with initial velocities and
simulations conducted within a custom-designed parking orientations, utilize AIF for navigation, driving towards their
environment created using the â€˜highway-envâ€™ simulation designated parking spots while avoiding collisions. This two-
package. The purpose of these simulations is to assess the real- tiered simulation approach serves a dual purpose: training the
world applicability and robustness of the proposed Framework. model to understand vehicle dynamics and control strategies in
The validation is divided into three segments. The initial part a constrained environment and validating the model's capability
describes the simulation environment set up within 'highway- to navigate complex scenarios with multiple agents. The results
env'. This setup provides the foundational context for from these simulations are expected to provide insightful data
subsequent testing and analysis. In the second segment, a on the potential of AIF in the field of autonomous vehicle
detailed analysis of the diffusion model's performance is navigation, particularly in unstructured environments where
presented. Finally, we examine the simulation outcomes where traditional driving guidelines may be absent.
the model's practical efficacy is showcased through its
B. Assessing the performance of the diffusion motion
application in controlling vehicles. These simulations
predictor
underscore the model's potential contributions to autonomous
Fig. 9 illustrates the loss plot of the diffusion motion
navigation under uncertainty.
predictor throughout its training and validation phases. Initially,
A. Simulation Setup a precipitous decline in the training loss is observed, indicative
a. Setup for training the diffusion motion predictor of the model's rapid acclimatization to the structure within the
For the motion prediction model, the highway-env training data. Concurrently, the validation loss mirrors the
simulation package was tailored to create two specific parking downward trend of the training loss, suggesting a consistent
scenarios, shown in figure 7, with the aim of training and learning pattern that generalizes beyond the training set. As the
validating a diffusion-based motion predictor. In the simulation epochs advance, both losses stabilize and exhibit minimal
setup, green vehicles are designated for autonomous control, variance, which implies that the model has potentially reached
whereas the yellow vehicles remain stationary. The parking its learning capacity given the current architecture and dataset.
area is outlined by yellow lines, denoting its boundaries. The The absence of a significant gap between the training and
first scenario is structured with six parking spots and four cars validation losses towards the end of the training suggests that
within the simulated environment shown in figure 7(a). Two of the model is not overfitting and is well-calibrated to the
these vehicles are designated as controllable, while the complexity of the data it aims to model.
10
shows the cases with three controlled vehicles. They depict the
routes taken from the vehiclesâ€™ starting points to their parking
spots, highlighting the adaptive maneuvers made to avoid
obstacles and achieve their parking goals. Through these plots,
we can demonstrate AIF's capacity for spatial reasoning and its
application in complex navigation tasks, validating its use in
autonomous parking systems.
Fig. 9. Loss plot for training the reverse process.
Table I presents some prediction examples that illustrates the
diffusion-based motion predictor's performance. The table (a) (b)
compares the positions of the controlled vehicles after applying
the reparametrized action selected from the predicted action
distribution against their actual positions. These examples
indicate the model's adeptness in tracking and predicting
vehicle motion with a high degree of accuracy, as reflected by
the minor discrepancies between predicted and true states.
(c) (d)
TABLE I
PREDICTION EXAMPLES OF THE DIFFUSION-BASED MOTION PREDICTOR Fig. 10. Vehicle trajectories controlled by diffusion-based AIF.
# Next State ğ’™ ğ’š ğ’— ğ’— ğ’‰
ğ’™ ğ’š
1 True next state 3.96 -19.46 -0.86 1.59 -1.08 V. CONCLUSION AND FUTURE WORK
Predicted next state 3.92 -19.55 -0.73 1.65 -1.15
In this paper, we have explored a novel approach to guiding
2 True next state -11.36 -8.30 9.80 9.73 -2.36
autonomous vehicles in scenarios where the usual road
Predicted next state -11.61 -7.58 8.67 10.76 -2.25
3 True next state 6.16 14.55 -0.08 -1.41 1.51 markings are absent. This exploration was grounded in the
Predicted next state 6.32 14.47 -0.11 -1.78 1.51 development of a diffusion-based motion predictor,
implemented within an Active Inference Framework (AIF), and
Table II enumerates more key metrics used to evaluate the
tested within a specially designed parking lot simulation. Our
diffusion-based motion predictor. The Mean Squared Error
goal was to closely mimic the challenges vehicles face on
(MSE) for the model's predictions, which evaluates the average
unmarked roads, using the parking lot as a stand-in for such
squared difference across all elements in the vehicle state
environments. We started by transforming a traditional road
(ğ‘¥,ğ‘¦,ğ‘£ ,ğ‘£ ,â¡andâ¡â„), is 0.2296. indicating the average squared
ğ‘¥ ğ‘¦ scenario into a parking lot setup, a crucial step in creating a
difference between the predicted and actual next states.
realistic yet controlled environment for our simulations. This
Furthermore, the model demonstrates a probabilistic
environment, characterized by its lack of lane markings,
confidence in its predictions, with the true next state falling
required vehicles to navigate from their starting points to
within one standard deviation (1 sigma) of the predicted
designated parking spots while avoiding collisions. This
distribution 43.05% of the time, within two standard deviations
scenario was meticulously designed to transition vehicles from
(2 sigma) 68.22% of the time, and within three standard
a disordered state, where their positions and velocities were
deviations (3 sigma) 86.27% of the time. These statistics not
randomized, to an orderly state, mirroring the structured
only affirm the model's predictive strength but also suggest a
outcome of successful parking. The introduction of the
well-calibrated understanding of the uncertainty inherent in
diffusion-based motion predictor was a pivotal part of our
vehicle movements.
exploration. This tool, developed through a nuanced
TABLE II
understanding of diffusion model methodologies, was adept at
PERFORMANCE METRICS FOR THE DIFFUSION-BASED MOTION PREDICTOR
forecasting the future movements of vehicles within the parking
Metric Description Value
lot. By predicting a range of possible actions for each vehicle
MSE between reparametrized next state and true next state 0.2296
True next state within 1 ğœ¹ of predicted next state distribution 43.05% and selecting the optimal path based on expected free energy,
True next state within 2 ğœ¹ of predicted next state distribution 68.22% the model demonstrated its ability to effectively navigate
True next state within 3 ğœ¹ of predicted next state distribution 86.27% vehicles to their intended destinations.
Our simulations offered concrete evidence of the model's
effectiveness. Through a series of tests in environments with
C. Active Inference Framework: Guiding Autonomous
varying degrees of complexity, from four to six cars navigating
Vehicles to Precision Parking
towards six to ten parking spots, we showcased the model's
The trajectory plots shown in Fig. 10 illustrates the behaviors
robust capability to ensure safe and efficient vehicle parking.
of the vehicles under the guidance of AIF. Fig. 10 (a) and (b)
These tests not only affirmed the model's practical applicability
shows the trajectories for two controlled vehicles, (c) and (d)
but also its potential to significantly improve traffic safety and
11
vehicle navigation in real-world scenarios devoid of lane Learning Representations, Latent-space Models, and
markings. Looking forward, we aim to extend the scope of our Policies with One Objective," in ICLR, Kigali, 2023.
research to encompass larger and more complex driving [12] N. Sajid, P. J. Ball, T. Parr and K. J. Friston, "Active
environments. The next steps involve refining the model to inference: demystified and compared," The Wellcome
enhance its predictive accuracy and adaptability to the Centre for Human Neuroimaging, UCLQueen Square
unpredictability inherent in real-world driving conditions. The Institute of Neurology, London, 2020.
scalability of the proposed system will also be tested in urban
[13] C. Pezzato, C. H. Corbato, S. Bonhof and M. Wisse,
driving environments, pushing the boundaries of whatâ€™s "Active Inference and Behavior Trees for Reactive
currently achievable in autonomous vehicle navigation. Action Planning and Execution in Robotics," IEEE
Transactions on Robotics, vol. 39, no. 2, pp. 1050-
REFERENCES 1069, 2023.
[14] C. Pezzato, R. Ferrari and H. C. Corbato, "A Novel
[1] H. Cao, C. Tan, Z. Gao, Y. Xu, G. Chen, P.-A. Heng Adaptive Controller for Robot Manipulators Based on
and S. Z. Li, "A Survey on Generative Diffusion Active Inference," IEEE Robotics and Automation
Models," IEEE Transactions on Knowledge and Data Letters, vol. 5, no. 2, pp. 2973-2980, 2020.
Engineering, pp. 1-20, 2024. [15] R. Rombach, A. Blattmann, D. Lorenz, P. Esser and
[2] Z. Zhong, D. Rempe, D. Xu, Y. Chen, S. Veer, T. B. Ommer, "High-Resolution Image Synthesis with
Che, B. Ray and M. Pavone, "Guided Conditional Latent Diffusion Models," arXiv, 2022.
Diffusion for Controllable Traffic Simulation," in [16] S. Kullback and R. A. Leibler, "On Information and
IEEE International Conference on Robotics and Sufficiency," The Annals of mathematical statistics,
Automation (ICRA), London, 2023. vol. 22, no. 1, pp. 79-86, 1951.
[3] G. Pezzulo, F. Rigoli and K. Friston, "Active [17] P. Polack, F. AltchÃ©, B. d'AndrÃ©a-Novel and A. d. L.
Inference, homeostatic regulation and adaptive Fortelle, "The kinematic bicycle model: A consistent
behavioural control," Progress in Neurobiology, vol. model for planning feasible trajectories for
134, pp. 17-35, 2015. autonomous vehicles?," in IEEE Intelligent Vehicles
[4] K. Friston and S. Kiebel, "Predictive coding under the Symposium (IV), Redondo Beach, California, US,
free-energy principle," Philosophical transactions of 2017.
the Royal Society of London Series B Biological [18] Y. Song, C. Durkan, I. Murray and S. Ermon,
sciences, vol. 364, no. 1521, pp. 1211-1221, 2009. "Maximum Likelihood Training of Score-Based
[5] F. Mohseni, E. Frisk and L. Nielsen, "Distributed Diffusion Models," in Conference on Neural
Cooperative MPC for Autonomous Driving in Information Processing Systems (NeurIPS), Online,
Different Traffic Scenarios," IEEE Transactions on 2021.
Intelligent Vehicles, vol. 6, no. 2, pp. 299-309, 2021. [19] J. Kulveit and R. Hadshar, "Why Simulator AIs want
[6] W. Y. Choi, S.-H. Lee and C. C. Chung, "Horizonwise to be Active Inference AIs," 10 April 2023. [Online].
Model-Predictive Control With Application to Available:
Autonomous Driving Vehicle," IEEE Transactions on https://www.lesswrong.com/posts/YEioD8YLgxih3yd
Industrial Informatics, vol. 18, no. 10, pp. 6940-6949, xP/why-simulator-ais-want-to-be-active-inference-ais.
2021. [20] T. Parr, G. Pezzulo and K. J. Friston, Active Inference
[7] A. Muraleedharan, H. Okuda and T. Suzuki, "Real- The Free Energy Principe in Mind, Brain, and
Time Implementation of Randomized Model Behavior, MIT Press, 2022.
Predictive Control for Autonomous Driving," IEEE [21] K. Friston, "The free-energy principle: a unified brain
Transactions on Intelligent Vehicles, vol. 7, no. 1, pp. theory?," Nature Reviews Neuroscience, vol. 11, pp.
11-20, 2022. 127-138, 2010.
[8] Z. Du, Q. Miao and C. Zong, "Trajectory Planning for [22] O. V. D. Himst and P. Lanillos, "Deep Active
Automated Parking Systems Using Deep Inference for Partially Observable MDPs," in IWAI
Reinforcement Learning," International Journal of 2020 : International Workshop on Active Inference,
Automotive Technology, vol. 21, pp. 881-887, 2020. Ghent, 2020.
[9] R. Rombach, A. Blattmann, D. Lorenz, P. Esser and
B. Ommer, "High-Resolution Image Synthesis with
Latent Diffusion Models," in arXiv, 2021.
[10] O. Ã‡atal, T. Verbelen, T. V. d. Maele, B. Dhoedt and
A. Safron, "Robot navigation as hierarchical active
inference," Neural Networks, vol. 142, pp. 192-204,
2021.
[11] R. Ghugare, H. Bharadhwaj, B. Eysenbach, S. Levine
and R. Salakhutdinov, "Simplifying Model-based RL:
12
Yufei Huang received a B.Eng. degree in
Automation from Xiâ€™an Jiaotong
University in 2016. Also, he received an
M.S. degree in Systems Engineering from
the University of Maryland, College Park
in 2018. He is currently a Ph.D. student at
Rutgers, the State University of New Jersey,
studying Industrial and Systems
Engineering, and a Research Assistant at
the Center for Advanced Infrastructure and Transportation
(CAIT). His research interests are in multi-agent systems,
autonomous systems, robotics, and reinforcement learning.
Yulin Li received his B.S. degree in
industrial and systems engineering from
Rutgers University in 2019 and an M.S.
degree in systems engineering from Cornell
University in 2021. He is currently working
towards a Ph.D. degree in industrial
engineering at Rutgers University. His
research interests include generative
models and the use of active inference for
decision-making in dynamic environments.
Andrea Matta is Full Professor at
Politecnico di Milano, where he currently
teaches integrated manufacturing systems
and manufacturing processes. His
research area includes analysis, design,
and management of manufacturing and
healthcare systems. He is Editor in Chief
of the Flexible Services and
Manufacturing Journal.
Mohsen Jafari (Mâ€™97) received a Ph.D.
degree from Syracuse University in 1985.
He has directed or co-directed a total of
over 23 million U.S. dollars in funding
from various government agencies,
including the National Science Foundation,
the Department of Energy, the Office of
Naval Research, the Defense Logistics
Agency, the NJ Department of Transportation, FHWA, and
industry in automation, system optimization, data modeling,
information systems, and cyber risk analysis. He actively
collaborates with universities and research institutes abroad. He
has also been a Consultant to several Fortune 500 companies as
well as local and state government agencies. He is currently a
Professor and the Chair of Industrial & Systems Engineering at
Rutgers University-New Brunswick. His research applications
extend to manufacturing, transportation, healthcare, and energy
systems. He is a member of the IIE. He received the IEEE
Excellence Award in service and research.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Navigating Autonomous Vehicle on Unmarked Roads with Diffusion-Based Motion Prediction and Active Inference"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   âŒ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   âœ… GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   âŒ BAD: Repeating the same claim 3+ times with slight variations
   âœ… GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
