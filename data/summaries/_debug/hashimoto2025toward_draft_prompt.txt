=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model
Citation Key: hashimoto2025toward
Authors: Saki Hashimoto, Shoichi Hasegawa, Tomochika Ishikawa

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: generation, understanding, ritsumeikanuniversity, objects, toward, question, large, language, ownership, probabilistic

=== FULL PAPER TEXT ===

Toward Ownership Understanding of Objects: Active Question Generation
with Large Language Model and Probabilistic Generative Model
SakiHashimoto1‚Ä† ,ShoichiHasegawa1,TomochikaIshikawa1,AkiraTaniguchi2,
YoshinobuHagiwara3,4,LotfiElHafi4,andTadahiroTaniguchi4,5
1GraduateSchoolofInformationScienceandEngineering,RitsumeikanUniversity,Osaka,Japan
(E-mail: {hashimoto.saki,hasegawa.shoichi,ishikawa.tomochika}@em.ci.ritsumei.ac.jp)
2CollegeofInformationScienceandEngineering,RitsumeikanUniversity,Osaka,Japan
(E-mail: a.taniguchi@em.ci.ritsumei.ac.jp)
3FacultyofScienceandEngineering,SokaUniversity,Tokyo,Japan
(E-mail: hagiwara@soka.ac.jp)
4ResearchOrganizationofScienceandTechnology,RitsumeikanUniversity,Shiga,Japan
(E-mail: lotfi.elhafi@em.ci.ritsumei.ac.jp)
5GraduateSchoolofInformatics,KyotoUniversity,Kyoto,Japan
(E-mail: taniguchi@i.kyoto-u.ac.jp)
Abstract: Robots operating in domestic and office environments must understand object ownership to correctly execute
instructions such as ‚ÄúBring me my cup.‚Äù However, ownership cannot be reliably inferred from visual features alone. To
address this gap, we propose Active Ownership Learning (ActOwL), a framework that enables robots to actively generate and
ask ownership-related questions to users. ActOwL employs a probabilistic generative model to select questions that maximize
informationgain,therebyacquiringownershipknowledgeefficientlytoimprovelearningefficiency. Additionally,byleveraging
commonsense knowledge from Large Language Models (LLM), objects are pre-classified as either shared or owned, and only
ownedobjectsaretargetedforquestioning. Throughexperimentsinasimulatedhomeenvironmentandareal-worldlaboratory
setting,ActOwLachievedsignificantlyhigherownershipclusteringaccuracywithfewerquestionsthanbaselinemethods. These
findingsdemonstratetheeffectivenessofcombiningactiveinferencewithLLM-guidedcommonsensereasoning,advancingthe
capabilityofrobotstoacquireownershipknowledgeforpracticalandsociallyappropriatetaskexecution.
Keywords: Object Ownership Inference, Active Inference, Information Gain, Large Language Models, Question Generation,
ProbabilisticGenerativeModels
1. INTRODUCTION
(a) (b)
Bring me
Robots operating in daily life environments must under- Whose cup is this?
my cup.
stand object ownership to carry out instructions naturally
Bob It‚Äôs Mine.
given by users, such as ‚ÄúBring me my cup.‚Äù Without own-
ershipknowledge, arobotcannotdeterminewhichobjectis
Which one is owned
being referred to when multiple similar objects exist. This Owner1 (c)
problemisespeciallyevidentinkitchens, offices, orlabora- by the Bob? Owner 2
Shared
tories, where objects with similar appearances may belong
to different individuals. Relying solely on perceptual fea- Owner1
Owner 2
tures such as location or appearance is insufficient because
Shared
ownership is inherently context-dependent and often deter-
Owner1
mined by social conventions. Therefore, enabling robots to
Owner 2
acquireownershipknowledgeisacrucialsteptowardsocially
Shared
appropriatehuman-robotinteraction.
Fig. 1. Overview of this study: (a) Without ownership
Toenablerobotstolearnobjectownershipindailylifeen-
knowledge,therobotcannotfollowinstructionscontain-
vironments,itisessentialtoimplementaquestion-generation
ingownernames. (b)Therobotgeneratesquestionsfor
mechanism that efficiently acquires necessary information.
the user, and (c) The probabilistic generative model is
However, inreal-worldenvironmentswithlargenumbersof
updated to predict object ownership based on the user‚Äôs
objects, this is impractical and imposes a heavy burden on
answers,enablingownershiplearning
users. Although robots can explore the environment to col-
lect visual features of objects, it remains difficult to obtain
ownership knowledge because it depends on users and con-
edgethroughinteractionwithusers.
text. Therefore,allowingrobotstoaskquestionsbasedonthe
Efficiency can be improved by first distinguishing shared
current situation enables them to acquire ownership knowl-
from owned objects. In real-world environments, many ob-
‚Ä† SakiHashimotoisthepresenterofthispaper. jects, such as tissue boxes, are typically shared rather than
5202
peS
61
]OR.sc[
1v45721.9052:viXra
individuallyowned. Askingaboutsuchobjectsincreasescog- teringaccuracywithfewerquestions.
nitiveloadandlowerslearningefficiency. Bypre-classifying Thestructureofthispaperisasfollows. Section2clarifies
objectsassharedorownedandexcludingsharedobjectsfrom the problem setting and key challenges of this study. Sec-
questioning,therobotcanminimizeinteractionsandacquire tion 3 reviews related work. Section 4 describes the details
ownershipknowledgemoreeffectively. of the ActOwL. Sections 5, 6, and 7 present experimental
In learning ownership knowledge, it is important for the results that evaluate ownership learning from the perspec-
robot to integrate perceptual features‚Äîsuch as object loca- tivesofclusteringaccuracy,quantifiedbyARI,andlearning
tion and visual attributes‚Äîwith ownership labels provided efficiency,assessedbythenumberofquestionsrequired. Sec-
by users, and to store this information as structured, linked tion8presentsthelimitationsofthisstudy. Finally,Section9
knowledge. Inthisstudy,wehypothesizethatobjectsowned concludesthepaperanddiscussesfuturedirections.
bythesamepersontendtobeplacedincloseproximityand
sharesimilarattributes. Basedonthishypothesis,weassume
2. PROBLEMSTATEMENT
thattherobotcanachievemoreaccurateownershipestimation
byassociatingspatialandvisualfeatureswithowneridenti- Thisstudyfocusesonthefollowingtwokeyapproaches:
ties. Forexample,byassociatingspatialandvisualcharacter- 1. Improving ownership learning by constructing a proba-
istics(e.g.,‚Äúasmall,round,browncuplocatedatcoordinates bilistic generative model that integrates object location, at-
(1,2)‚Äù)withthecorrespondingowner(e.g.,‚ÄúownedbyTaro‚Äù), tributes,anduseranswers.
therobotcanaccuratelylearnobjectownershiprelationships. 2. Enhancing ownership learning efficiency by actively se-
Ourchallengeinthisstudyistoimprovetheefficiencyof lectingobjectsforquestioningbasedonIG.
learning object ownership knowledge in daily life environ-
ments through robot-generated questions. To overcome this 2.1. ChallengesinHandlingownershipknowledge
challenge, this study introduces Active Ownership Learn- For robots to behave appropriately in daily life environ-
ing(ActOwL),aframeworkthatenablesrobotstoefficiently ments, they must accurately understand object ownership.
learn ownership knowledge through active question genera- However,learningownershipknowledgebasedsolelyonspa-
tion. AnoverviewofthisstudyisshowninFig.2. ActOwLin- tiallocationorvisualattributeshasinherentlimitations. For
tegratesaprobabilisticgenerativemodelwithcommonsense instance, in real-world settings, even objects owned by the
reasoningfromLargeLanguageModels(LLM).First,objects samepersonmaybeplacedindifferentlocationsduetotheir
arepre-classifiedassharedorownedbasedonLLM-guided intendeduseorstorageconvenience,leadingtoinconsisten-
commonsenseknowledge,allowingtherobottoavoidasking cies in spatial placement. As such, observable information
questions about shared objects. Then, for candidate-owned such as location and appearance alone is often insufficient
objects, ActOwL strategically selects the most informative to uniquely identify the owner of an object. Therefore, in
questionbymaximizinginformationgain(IG)andgenerates additiontoexploringtheenvironment,robotsmustengagein
human-likequestionsviaLLM.Byincorporatingtheprinci- interaction with users to obtain supplementary information,
pleofactiveexplorationintothequestiongenerationprocess therebyaccuratelyacquiringownershipknowledge.
andselectingobjectsthatmaximizeIG[1‚Äì3],ActOwLeffec-
tivelyreducesmodeluncertaintyduringownershiplearning. 2.2. ChallengesinAcquiringInformationthroughQues-
The user‚Äôs answers are subsequently incorporated into the tioning
probabilistic generative model, enabling the robot to incre- Tolearnobjectownershipindailylifeenvironments,itis
mentallyrefineitsownershipknowledge. effectiveforarobottoobtainnecessaryinformationthrough
ToevaluatetheeffectivenessoftheActOwL,weconducted interaction with users. However, asking users to manually
experiments in simulated and real-world environments that provideownershipknowledgeforeveryobjectintheenviron-
mimic home and laboratory settings. In addition, we quan- mentimposesasignificantburdenandisimpracticalinreal-
titatively compared ownership clustering accuracy and the worldsettings. Moreover,iftherobotgeneratesquestionsran-
number of questions required, and further performed abla- domly, theefficiencyoflearningownershipknowledgemay
tionstudiesontheprobabilisticgenerativemodeltoanalyze be substantially reduced. Therefore, a strategic approach is
theimpactofmultimodalattributesonlearningefficiency. required,inwhichtherobotselectivelyasksquestionsabout
Themaincontributionsofthisstudyareasfollows: objects that are likely to yield informative answers, while
1. Weshow aprobabilisticgenerativemodel thatintegrates minimizingthenumberofinteractions.
object location, attribute information, and user answers to
learnownershipdistributions,demonstratingthatcombining 3. RELATEDWORK
thesemultimodalinputsiseffectiveforacquiringownership
knowledge. 3.1. LearningObjectOwnership
2. WeshowanactiveobjectselectionmethodbasedonIG, Understanding object ownership is essential for assistive
andclarifyhowtheselectionstrategyinfluencestheefficiency robots,andseveralapproacheshavebeenproposedtoaddress
ofownershiplearning. thischallenge. Priorworkhasestimatedownershipfromob-
3. Weshowthroughcomparativeexperimentswithbaseline ject attributes, spatial features, or user interactions [4‚Äì6].
andablationmethodsinbothsimulationandreal-worldenvi- Whilethesemethodsprovideusefulcues,theytypicallylack
ronments that the ActOwL achieves higher ownership clus- integration of multimodal information and do not address
efficientquestiongeneration,commonsensereasoning,orau- 4. PROPOSEDMETHOD
tonomousdecision-makinginreal-worldenvironments.
Inthisstudy,weproposeActiveOwnershipLearning(Ac-
Incontrast,ourapproachenablesrobotstoautonomously tOwL),amethodthatenablesrobotstoefficientlylearnobject
acquireownershipknowledgethroughinteractionwithusers. ownershipindailylifeenvironments. ActOwLselectsobjects
By leveraging commonsense knowledge from LLM and a with the highest IG and asks targeted ownership questions,
probabilisticgenerativemodelthatintegratesobjectlocation, reducingtheneedforextensivemanualinstruction. Owner-
attributes,anduseranswers,ourmethodselectsinformative shipknowledgeisthenacquiredatthecategorylevelthrough
questionsefficiently. Thisallowsrobotstominimizeuserbur- a probabilistic generative model that integrates multimodal
denwhileacquiringownershipknowledgedirectlyapplicable information, including object location, attributes, and user
totaskexecutionindailyenvironments. answers.
An overview of the proposed method is shown in Fig. 2.
Theprocedureconsistsofthefollowingsteps:
3.2. KnowledgeAcquisitionthroughActiveExploration
1. Trainaprobabilisticgenerativemodelofownershipusing
Beyondpassiveobservation,robotsmustactivelyexplore thepositionandattributeinformationofeachobjectobtained
their environments to reduce uncertainty and acquire useful throughpriorexploration(Fig.2(a)).
knowledge under real-world constraints. Prior studies have 2. Classify each object as owned or shared based on com-
introducedIG-basedexplorationstrategies, includingmulti- monsenseknowledgefromtheLLM(Fig.2(b)).
modalperceptionwiththeMultimodalHierarchicalDirichlet 3. Treattheclassificationresultsaspseudo-useranswersand
Process (MHDP) [7,8] and spatial concept learning frame- usethemtoupdatethegenerativemodel(Fig.2(c)).
works [2,3]. These approaches integrate multimodal infor- 4. Forobjectspredictedasowned,computetheIGregarding
mationandexploitIGtoguideefficientexploration,yetthey ownershipandidentifytheobjectexpectedtoreduceuncer-
primarily aim to understand the environment from observ- taintymosteffectively(Fig.2(d)).
ablecuessuchasappearance,sound,andlocation. However, 5. Generateanaturalquestionabouttheselectedobjectusing
they do not consider ownership relations between users and theLLMandasktheuser(Fig.2(d)).
objects, which are crucial for executing user-specific com- 6. Update the generative model with the user‚Äôs answer
mands. (Fig.2(c)).
7. RecalculateIGbasedontheupdatedmodelandselectthe
Incontrast, ourstudyincorporatestheuncertaintyreduc-
nextobjectforquestioning(Fig.2(d)).
tionprincipleofactiveexplorationintothequestiongenera-
These steps are repeated until the ownership of all objects
tionprocess,applyingIG-basedselectiontoidentifythemost
is identified. Details of the prior environmental exploration
informative objects. By combining this with a probabilistic
are described in Section 4.1, the classification of objects as
generative model that integrates object position, attributes,
sharedorownedinSection4.2,thelearningofownershipdis-
and user answers, our approach enables robots to minimize
tributionsinSection4.3,andtheobjectselectionandquestion
user burden while acquiring ownership knowledge directly
generationprocessinSection4.4.
applicabletotaskexecution.
4.1. Pre-explorationofObjectsintheEnvironment
3.3. ResolvingUncertaintyduringTaskExecution Inthisstudy,weassumethattherobothaspriorknowledge
ofthespatiallayoutandcategoriesofobjectsintheenviron-
Recent work has explored methods for resolving uncer-
menttoefficientlylearnownershipknowledge. Therobotis
tainty in task execution from natural language instructions.
provided with an environment map and object-related data,
Systemspromptclarificationquestionstodisambiguatecom-
includingclassnames,2Dcoordinates,visualattributes,and
mands [9,10], while other approaches combine perceptual
a list of candidate owners. Object positions are represented
cues,contextualreasoning,orlanguagemodelstoidentifytar-
as coordinates on the robot‚Äôs 2D map, and visual attributes
getsunderuncertainty[11‚Äì15]. Anotherlineofworkfurther
areencodedasfeaturevectorsthatrepresenttheappearance.
incorporatesuserpreferencesthroughactivequestioning[16].
Suchrepresentationscanbeobtainedusingvision‚Äìlanguage
These methods demonstrate that robots can flexibly address
models, such as CLIP [17], while spatial and attribute in-
ambiguitythroughinteractionandinference,enablingrobust
formationcanbeembeddedthroughsemanticmappingtech-
taskexecutionincomplexenvironments.
niques,suchasNLMap[18]. Thecandidateownerlistspec-
However,ownershiprelationsaretypicallytreatedastem- ifies potential owners with concrete user names. Using this
poraryandtask-specific,withoutbeingstructuredorretained information,therobotstrategicallygeneratesquestionsbased
asreusableknowledge. Asaresult,repeatedinstructionsre- onspatialconfigurationandinter-objectrelationshipstoeffi-
quirethere-acquisitionofthesameinformation,andsequen- cientlyacquireownershipknowledge.
tialquestioningoftenincreasestheuser‚Äôsburden. Incontrast,
ourstudyenablesrobotstoautonomouslyacquireandretain 4.2. ClassificationofObjectsasOwnedorSharedusing
structured ownership knowledge by integrating object loca- CommonsenseKnowledgefromLLM
tion,attributes,anduseranswersinaprobabilisticgenerative Toimprovetheefficiencyofownershiplearning,weintro-
model. Thisallowsefficientinterpretationofambiguousin- duceafilteringmechanismthatpre-selectsobjectsforques-
structionswhileminimizingredundantuserinteractions. tioning. Objects are classified as either owned or shared
(a) Pre-exploration of Objects in the Environment (b) Classification of Objects asOwnedor Shared
using Commonsense Knowledge from LLM
Considered as the User's answer ùë§
ùëõ
ObjectList
„ÉªClass name Shared ObjectList
„ÉªPositionùë• Class name „ÉªPhone
ùëõ
„ÉªAttributes ùëú „ÉªPhone Classify
ùëõ
„ÉªBottle prompt OwnedObjectList
„ÉªCup „ÉªBottle
„ÉªCup
(c) Learning a Probabilistic Model of Object Ownership (d) Acquiring ownership knowledge
via User-Directed Question Generation
ùê∂ 1 ùê∂ 2 ùê∂ 3 ùê∂ 4 Next step
ùúè ‚Üêùúè+1
Whose red cup is it?
Estimate the latent
variables in the
owner‚Äòs indexùê∂ Mine
ùëõ
User‚Äôs
answer ùë§ Calculate IG
ùëõ
Fig. 2. Overview of the proposed method: (a) The robot explores the environment to obtain object positions and attributes,
traininganinitialownershipmodel. (b)Objectsareclassifiedasownedorsharedusingcommonsenseknowledgefromthe
LLM.(c)Classificationresultsaretreatedaspseudo-answerstoupdatetheownershipdistribution. (d)Forownedobjects,
therobotcomputesIG,selectsthemostinformativeone,generatesaquestionviaLLM,andupdatesthemodelbasedonthe
user‚Äôsanswer.
Prompt.4.1.ObjectOwnershipClassification 4.3. LearningaprobabilisticgenerativemodelofObject
Ownership
1:Youareanexcellenthouseholdrobot.
2: Pleaseclassifythelistofobjectsthatwegiveyouaseither‚Äúowned‚Äùor The robot learns a probabilistic generative model to esti-
‚Äúshared‚Äùbysomeoneinthelivingenvironment. mateobjectownershipfromthepositionandattributeinfor-
3:Let‚Äôsthinkstepbystep.
4: mationobtainedduringpriorexploration. Anoverviewofthe
5:Alistoftheobjectsyouobservedinahomeenvironment: modelisillustratedinFig.3,andthevariablesaredefinedin
6:existing_object=[OBJECT_LIST]
7: Table1. Thegenerativeprocessisformalizedasfollows.
8:However,theenvironmentisafamilyhousehold.
9:
10:Outputonlythoseobjectsthatarepropertyasaresultofclassification.
11: œÄ ‚àºDir(Œ≥) (1)
12:Followtheinstructionsbelowtoanswerthequestions.
13:Donotoutputanythingotherthantheanswer. Œ£ ‚àºIW(V ,ŒΩ ) k =1,2,...,K (2)
14: k 0 0
15:Example:Ifthelistofobjectsis ¬µ ‚àºN(m ,Œ£ /Œ∫ ) (3)
k 0 k 0
16:[book,pen,desk,window].
17: œï ‚àºDP(Œª) l=1,2,...,L (4)
l
18:Answer:
19:Owned_object=[book,pen] œÜ l ‚àºDir(Œ±) (5)
Œ∑ ‚àºDir(Œ≤) (6)
l
OTHER_OBJECT_LIST:ListofObjectsintheEnvironment
C ‚àºCat(œÄ) n=1,2,...,N (7)
(Class,Attribute,Point.X,Point.Y,ObservedUser) n
i ‚àºCat(œï ) (8)
n Cn
x ‚àºN(¬µ ,Œ£ ) (9)
n in in
o ‚àºMult(œÜ ) (10)
n Cn
w ‚àºMult(Œ∑ ) (11)
n Cn
Dir()denotestheDirichletdistribution,DP()theDirichlet
usingcommonsenseknowledgefromanLLM.Asillustrated process,Mult()themultinomialdistribution,andCat()the
inPrompt.4.1,therobotprovidestheobject‚Äôsclassnameas categorical distribution. IW() denotes the inverse-Wishart
input to the LLM, which determines whether the object is distribution,andN()denotesthemultivariateGaussiandis-
typicallysharedorindividuallyowned. Objectsclassifiedas tribution.
sharedareassumednottohaveaspecificownerandareex- Thepositiondistributionassumesthataperson‚Äôsbelong-
cludedfromquestiongenerationandprobabilisticmodeling, ingsaremorelikelytobefoundintheirownroom. Tohandle
whereasobjectsclassifiedasownedareretainedascandidates sharedspacessuchaskitchensandlivingroomsusedbymul-
forownershipidentification. tiple individuals, it is modeled as a Gaussian mixture. The
answerasmultimodalobservationsandperformssequential
Index of
Ownership Concepts ùúá ùëö ,ùúÖ inferenceoftheposteriordistributionoverownership.
ùëò 0 0
Thejointposteriordistributionofallparametersestimated
1 2 ùë•
ùëõ
Œ£
ùëò
ùëâ0,ùúà0 during ownership learning is factorized using Bayes‚Äô theo-
ùêæ Position distribution rem. FollowingthederivationpresentedinSpCoAE[2],the
3 4
particleweightupdateequationcanbeexpressedasfollows:
ùëñ ùúô ùúÜ
ùëõ ùëô
Object Attributes
ùõæ ùúã ùê∂ ùëõ ùëú ùëõ ùúë ùëô ùõº {classÔºåcolorÔºåsizeÔºåshape} p(x n ,o n ,w n |C 1:n‚àí1 ,i 1:n‚àí1 ,x 1:n‚àí1 ,o 1:n‚àí1 ,w 1:n‚àí1 ,h)
(cid:88)(cid:88)
User's Answer = p(x |x ,i ,h)p(o |o ,C ,Œ±)
n 1:n‚àí1 1:n n 1:n‚àí1 1:n
ùëÅ ùë§ ùëõ ùúÇ ùëô ùêø ùõΩ It's mine. Cn in
√óp(w |w ,C ,Œ≤)
Fig.3. Graphicalmodeloftheproposedmethod n 1:n‚àí1 1:n
√óp(C ,i |C ,i ,Œ≥,Œª)
1:n 1:n 1:n‚àí1 1:n‚àí1
(12)
attribute vector includes not only the object‚Äôs class but also
featuressuchascolor,size,andshape,allowingthemodelto Basedonthisequation,particlesareresampledaccordingto
capture individual user preferences. For example, if a user their weights œâ . During the initial exploration phase, the
n
typicallyprefersredobjects,redobjectsaremorelikelytobe robotdoesnotaskanyquestions; therefore,w istreatedas
n
inferredasbelongingtothatperson. uninformative. After question generation begins, the prob-
abilistic generative model is updated by incorporating the
User answers obtained through question generation do
not always correspond directly to predefined owner indices.
user‚Äôsanswerw
n
,enablingthelearningofownershipknowl-
edge.
For instance, instead of explicitly naming an owner (e.g.,
‚ÄúTaro‚Äôs‚Äù), usersmayreplywithpronounssuchas‚Äúmine‚Äùor
4.4. Acquiring ownership knowledge via User-Directed
expressions like ‚Äúmy father‚Äôs.‚Äù To address this variability,
QuestionGeneration
thesystemmapsuserresponsestoownershipindicesthrough
Toefficientlyacquireownershipknowledge,theproposed
semanticinterpretation.
methodcalculatesIGforeachobjectandselectstheoneex-
To incrementally update the ownership distribution in
pectedtomosteffectivelyreduceuncertainty. Fortheselected
answer to sequential observations, we adopt an online
object,anaturallanguagequestionisgeneratedusingLLM,
learning approach using a Rao-Blackwellized Particle Fil-
andananswerisobtainedfromtheuser.
ter (RBPF) [19], following the framework of SpCoAE [2].
Therobottreatstheobject‚Äôsposition,attributes,andtheuser‚Äôs
4.4.1. ObjectSelectionBasedonIG
Forobjectsidentifiedasownedbelongings,thenextobject
Table1. Definitionsofvariablesusedinthegraphical toqueryisselectedbasedonitsexpectedIG.Theoverallalgo-
modeloftheproposedmethod rithm for the proposed method is presented in Algorithm 1.
Here, UPDATE-MODEL denotes the RBPF-based update
C n Latentvariableindicatingtheownership step,whichtakesthecurrentsetofobservations(x ,o ,w )
index n n n
andsequentiallyupdatestheposteriordistributionofowner-
x n 2Dcoordinatesoftheobject shipconceptsandmodelparameters.
o n Attributevectoroftheobject In this study, the full set of parameters related to owner-
w n Useranswertotherobot‚Äôsquestion ship is denoted by Œò = {{¬µ },{Œ£ },{œï },{œÜ },{Œ∑ },œÄ},
i n Latent variable indicating the index of and the set of hyperparam k eters k is de l noted l by l h =
thepositiondistribution
{Œ±,Œ≤,Œ≥,Œª,m ,Œ∫ ,V ,ŒΩ }. The latent variables are repre-
œÄ,œÜ l ,Œ∑ l ,œï l Parametersofmultinomialdistributions sentedasZ = 0 {C 0 , 0 i 0 ,Œò},andSetofobservedinforma-
Œ£ k ,¬µ k Mean vector and covariance matrix of tionisW ={x 1:N ,o 1:N ,w ,h}. Here,a‚àà{1:N}\n
thepositiondistribution n0 1:N 1:N n0 0
denotestheindexofacandidateobjectforthenextquestion,
Œ≥,m
0
,Œ∫
0
,V
0
,
whilen representsthesetofindicescorrespondingtoobjects
ŒΩ 0 ,Œª,Œ±,Œ≤ Hyperparametersofthemodel thathav 0 ealreadybeenobserved.
n Indexofanobject
IG is defined to reduce the uncertainty in the ownership
N Totalnumberofobjectsobtainedduring distributionbeforeandafteraquestionisasked.
priorexploration
l Indexofanownershipconcept
L Totalnumberofownershipconcepts a‚àó =argmaxIG(Z;W a |W n0 ) (13)
a
k Index of a position distribution compo-
nent IGisapproximatedusingtheparticlesZ[r]andtheircorre-
K Total number of position distribution spondingweightsœâ[r]obtainedfromtheRBPF,asexpressed
components n0
bythefollowingequation:
Algorithm 1 Active Exploration Algorithm for Ownership Prompt.4.2.ObjectOwnershipQuestionGeneration
Acquisition
1:Youareanexcellenthouseholdrobot.
1: Z ‚àí1 =UPDATE-MODEL(cid:0) {w a =unknown|‚àÄa} (cid:1) 2 3 : : G In en a e d r d a i t t e io a n q , u p e r s o t v io id n e a i s n k f i o n r g m t a h t e io o n w a n b e o r u o t f o th th e e o r b o je b c je t c w ts e o p b ro se v r id ve e d . inthehome
2: IdentifysharedobjectsviaLLM;setw =Shared environment.
3: Z 0 = UPDATE-MODEL(cid:0) {w a ‚àà {unk a nown,Shared} | 4 w : it N h o a t k e n t o h w at n s o im w i n la e r rm ob a j y ec s t h s a m re a t y he ha s v a e m b e e o e w n n p e l r a . cednearby,orobjectsnearone
‚àÄa} (cid:1) 5: Insteadofsimplyasking‚ÄúWhoseisthis?‚Äù,addbriefobjectinformationto
helpthelistenerunderstandthequestion.
4: n 0 ={a|w a =Shared}, W n0 ={w a |a‚ààn 0 } 6:Let‚Äôsconsidertheminthisorder.
5: forœÑ =1toT do 7:
8:Belowisinformationabouteachobject.Usethefollowingformattodescribe
6: foralldetectedobjectsx a ,o a ‚ààRDdo it:
7: forr =1toRdo 9:[class,attribute,point.x,point.y,observeduser]
10:Thedescriptionofeachvariableisasfollows
8: forj =1toJ do 11:class:Classnameoftheobject
9: W[r,j] ‚àºMultinomial(p=pÀÜ(w |Z[r],W )) 12:attribute:Featurevectorofanobject
a a n0 13:Thevectorconcatenates:Objectlabel(18D)+
10: endfor 14:Attribute[color:red,blue,yellow,green,black,white](6D)+
15:Attribute[size:large,medium,small](3D)+
11: endfor
16:Attribute[shape:round,square,triangle](3D).
12: Compute IG a using sampled W a [r,j] and particle 17:Theobjectlabelsare:
weightsœâ[r] 18: [Backpack,Bed,Book,Bottle,Chair,Clock,Cup,Desk,DiningTable,
n0 Handbag/Satchel, Laptop, Monitor/TV,Mouse, Pillow, PottedPlant, Printer,
13: endfor Refrigerator,TrashbinCan].
19:answer:ownernameoftheobject
14: a‚ãÜ ‚Üêargmax IG
a a 20:point.x:x-coordinateofobject
15: q =QUESTION-GENERATION(W ) 21:point.y:y-coordinateofobject
a‚àó a‚àó
16: w ‚ÜêUNDERSTAND-ANSWER(a‚ãÜ) 22:observeduser:Nameoftheowneroftheobject(or‚Äúunknown‚Äùifunknown)
a‚ãÜ 23:
17: n ‚Üên ‚à™{a‚ãÜ}, W ‚ÜêW ‚à™{w } 24:Pleasealsoconsiderthefollowinginformationonotherobjects.
18: Z 0 ‚ÜêU 0 PDATE-MOD n E 0 L(W n ) 0 a‚ãÜ 25:Useonlyotherinformationrelatedtotheobjectbeingpresented.
œÑ n0 26:
19: endfor 27:otherobject:[OTHER_OBJECT_LIST]
28:
29:Donotoutputanythingotherthanthequestion.Keepyourquestionbrief.
30:Donotincludecoordinateinformationinthequestiontext.
31:
32:objectinquestion:[TARGET_OBJECT_LIST]
IG(Z;W |W )
a n0 OTHER_OBJECT_LIST:ListofObjectsintheEnvironment
‚âà (cid:88) R (cid:88) J (cid:34) œâ[r]log p(W a [j]|Z[r],W n0 ) (cid:35) ( T C A la R s G s, E A T tt _ ri O bu B t J e E ,P C o T in _ t L .X I , S P T o : i L nt i . s Y t , o O fO bs b e j r e v c e t d sT U a s r e g r e ) tedforQuestioning
n0 (cid:80)R [p(W[j]|Z[r‚Ä≤],W )]œâ[r‚Ä≤]] (Class,Attribute,Point.X,Point.Y,ObservedUser)
r=1j=1 r‚Ä≤=1 a n0 n0
(14) ExampleofOTHER_OBJECT_LISTandTARGET_OBJECT_LIST
-Refrigerator,[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,0,0,0,1,0],
0.736902236,3.799175403,unknown
-Backpack,[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1,0],
W[j] ‚àºp(W |Z[r],W ) (15) 6.325937769,2.471300272,hashimoto
a a n0 -Book,[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,1,0],
6.517469798,2.656295813,unknown
W[j] denotesapseudo-observation(i.e.,asimulateduser
a
answerw )forobjectaobtainedfromthenextpossibleques-
a
tion,andJrepresentsthenumberofpseudo-observationsam- onmaskingportionsofobjectdatasetstoelicitanswers[20].
ples. The term p(W[j] | Z[r],W ) is sampled from the However,thesemethodsareofteninflexibleinnovelenviron-
a n0
predictive distribution based on particle r, and is computed mentswithunknownobjectconfigurations,andtheresulting
usingthefollowingequation: questionstendtobeoverlyformalandrestrictive,limitingthe
naturalnessanddiversityofuserresponses.
Toaddressthisissue,ourapproachemploysanLLM,asin
W[j] =(w |x ,o )‚àºp(w |Z[r],x ,o ,w ,a,h)
a a a a a a a n0 priorstudies[9,10,13],togeneratequestionsinamorenatu-
(cid:88)
= p(w |C ,w ,h)p(C ,i |Z[r],x ,o ,a,h) ralandconversationalmanner. Thisenablesflexiblequestion
a a n0 a a a a
Ca,ia generation and intuitive interaction with users. When gen-
(16) erating questions, the LLM receives not only the attributes
of the target object but also its coordinates, features, and
The position x and attribute o of the object are held
a a ownershipknowledgealreadylearnedforotherobjectsinthe
fixed, and sampling is performed only over the user answer
environment. The prompt used for this process is shown in
w . Byleveragingtheparticlesandweightsobtainedthrough
a Prompt. 4.2, which allows the model to incorporate spatial
onlinelearning,IGcanbeefficientlyapproximated.
relationships and prior knowledge to produce contextually
4.4.2. QuestionGenerationusingLLM appropriatequestions.
For the object with the highest IG, the robot generates a Additionally,wheninterpretinguseranswers,thenameof
questionaboutownership. Conventionalapproachestoques- the respondent is included in the prompt. The prompt used
tion generation have relied on predefined templates [12] or for this process is shown in Prompt. 4.3, which enables the
Prompt.4.3.OwnershipIdentification
1:Youareanexcellenthouseholdrobot. Computer
2:Askthefollowingquestionabouttheownerofanobject.
3:
4:Questiontext:‚ÄúQUESTION_TEXT‚Äù
Phone
5:Tothisquestion,theusergivesthefollowinganswer. Chair
6:Useranswer:‚ÄúUSER_ANSWER‚Äù Table
7: Bag
8:Identifythenameoftheowneroftheobjectfromthiscontent.
9: However,iftheuser‚Äôsanswerindicatesthattheobjectissharedbymultiple Shoes
people,ratherthanaspecificperson,pleaseoutput‚ÄúShared‚Äù. Phone
10: Toy Chair
Bag
11:Thelistofusersisasfollows:
12:user_list=USER_LIST.
Book Cup
13:
14:However,thenameoftheuserwhoisrespondingisshownbelow. Fig.4. Objectlayout(Experiment1): Classname,color,size,
15:Respondinguser:‚ÄúRESPONDING_USER‚Äù shape,andpositiondistributionofobjectsareshown
16:
17:Extracttheansweraccordingtotheuser‚Äôsinputandoutputtheowner‚Äôsname
asfollows.
18:
Object positions were represented in a local two-
19:Example
20:answer_output=‚Äúhashimoto‚Äù dimensional coordinate system (x,y). Each object was de-
21:
scribedbya21-dimensionalattributevectorconstructedfrom
22: Useranswersaresubjecttotypos,inwhichcasepleasechoosetheclosest
match. fourtypesoffeatures:
23:
Class: one-hotvectorcorrespondingtothenumberofob-
24:Donotoutputanythingotherthan‚Äúanswer_output‚Äù. ‚Ä¢
25:Let‚Äôsconsidertheminthisorder. jecttypes(9classesinthisexperiment).
Color: 6-dimensional vector (red, blue, yellow, green,
‚Ä¢
QUESTION_TEXT:Thequestionaskedbytherobot. black,white).
USER_ANSWER:Thenaturallanguageanswerprovidedbytheuser.
USER_LIST:Thelistofownersintheenvironment. ‚Ä¢ Size: 3-dimensionalvector(large,medium,small).
RESPONDING_USER:Theowner‚Äôsnameasreceivedfromtheuser‚Äôsanswer, Shape: 3-dimensionalvector(circle,square,triangle).
includingthesharedlabel‚ÄúShared‚Äù. ‚Ä¢
Attributes were manually assigned to each object. User
answers were collected in textual form. This included ex-
plicitownernames(e.g.,‚ÄúTaro‚Äôs‚Äù),possessivepronouns(e.g.,
modeltocorrectlyhandlebothpossessiveexpressions(e.g.,
‚Äúmine‚Äù),andreferentialexpressions(e.g.,‚Äúmyfather‚Äôs‚Äù).
‚ÄúIt‚Äôsmine‚Äù)andexplicitreferencestoindividuals(e.g.,‚ÄúIt‚Äôs
Duringthelearningprocess, thenumberofparticleswas
Taro‚Äôs‚Äù).
setto100, andthenumberofpseudo-observations(i.e., an-
swersamplesperquestion)wassetto10. Thehyperparam-
5. EXPERIMENT 1: OWNERSHIP LEARN-
eters were set as follows: Attribute distribution parameter:
ING UNDER SIMPLIFIED SIMULATION
Œ± = 1.0, User answer distribution parameter: Œ≤ = 0.01,
CONDITIONS
Ownership concept prior: Œ≥ = 5.0, Precision parameter for
5.1. Objective the position distribution: Œ∫ 0 = 1.0, Prior mean vector for
Theobjectiveofthisexperimentistoevaluatewhetherthe thepositiondistribution: m 0 = [0,0,0,0], Priorcovariance
proposedmethodcanefficientlylearnobjectownershipina matrix: V 0 = diag(0.1,0.1)Degreesoffreedomforthepo-
simple simulated environment. In addition, we conduct an sitiondistribution: ŒΩ 0 =5.0. Wealsosetthetotalnumberof
ablationstudytoassessthecontributionofeachfeature‚Äîsuch
ownershipconcepts: L=4andthetotalnumberofposition
asobjectpositionandattributes‚Äîtotheaccuracyofowner- distributions: K =4Tostabilizeestimation,thetrueposition
distributionindexcorrespondingtoeachobservedcoordinate
shipestimation.
x wasfixed.
n
5.2. Conditions When integrating multimodal information‚Äîobject posi-
TheexperimentswereconductedinaGazebosimulation tion, attributes, and user answers‚Äîwe treated user answers
environment using the aws-robomaker-small-house-world 1. as the most reliable modality. A weighting coefficient
We set up an environment with three users and 12 objects, œâanswer =5.0wasappliedtouseranswers,whileothermodal-
each assigned an ownership label. The robot was assumed ities were equally weighted. For the LLM, we used GPT-4
to have prior knowledge of all objects‚Äô 2D coordinates and (gpt-4-0613)[21].
categorylabels. TheobjectlayoutisshowninFig.4. Shared
5.3. ComparisonMethods
objects were labeled as ‚ÄúShared,‚Äù while objects belonging
To evaluate the performance of our approach (ActOwL),
to the same user were given consistent color attributes and
wecompareitwiththefollowingbaselinemethods:
placed in close proximity. To simulate realistic conditions,
theenvironmentincludedbothownedandsharedobjects,as
1. IG-min: Amethodthatselectstheobjectwiththelowest
IG for question generation and learns ownership knowledge
well as categories with multiple instances and those with a
basedontheuser‚Äôsanswer.
singleinstance.
2. Random: A method that randomly selects an object for
1https://github.com/aws-robotics/aws-robomaker-small-house-world question generation and learns ownership knowledge based
ontheuser‚Äôsanswer.
3. No-LLM:Amethodthatselectsobjectsforquestiongen-
eration based solely on the probabilistic generative model
and IG, without using LLM, and learns ownership knowl- 1.0
edgefromtheuser‚Äôsanswers.
0.8
4. LLM-only: Amethodthatpredictsownershipknowledge
bypromptingLLMwithoutusinganyprobabilisticgenerative 0.6
model. 0.4
In addition, to examine the contribution of each feature
0.2
to ownership learning, we conducted the following ablation
0.0
studies:
1. Onlycolorinformationfromtheobject‚Äôsattributesisused.
1 0 1 2 3 4 5 6 7 8 9 10 11 12
2. Onlytheobject‚Äôspositionalcoordinatesareusedforlearn- Step
ing,withoutincorporatingattributeinformation.
3. Onlytheobject‚Äôsattributeinformationisusedforlearning,
withoutincorporatingpositionalcoordinates.
5.4. EvaluationMetrics
Thisstudyevaluates(1)theaccuracyofownershiplearn-
ingand(2)theefficiencyoflearningintermsofthenumber
of user questions required. The latter focuses on how ac-
tiveexplorationbasedonIGmaximizationimproveslearning
efficiencyintheprobabilisticgenerativemodel.
5.4.1. AdjustedRandIndex
Ownership clustering accuracy was measured using the
Adjusted Rand Index (ARI), a standard metric for cluster-
ing performance. ARI quantifies the agreement between
predicted ownership clusters and ground-truth labels, with
highervaluesindicatingmoreaccurateownershipconcepts.
5.4.2. NumberofQuestions
Learningefficiencywasevaluatedbythenumberofques-
tions posed by the robot to the user until a given ARI was
achieved. Thismeasuredirectlyindicateshoweffectivelythe
proposed method acquires ownership knowledge compared
tobaselinemethods.
5.5. Results
Fig.5showsARIanditsstandarddeviationforC across
n
20 trials at each step. The proposed method consistently
achieved the highest ARI values, indicating that the robot
accurately learned ownership knowledge at an early step.
ThisimprovementstemsfromIG-basedselectionofinforma-
tiveobjects,whichenabledefficientacquisitionofownership
knowledge. The No-LLM method also improved steadily
butrequiredmorequestionstoreachsimilaraccuracy,high-
lightingthebenefitofexcludingsharedobjectsinadvance. In
contrast,theLLM-onlymethodshowedlimitedARIimprove-
ment,despiteaskingfewerquestions,suggestingthatreliance
oncommonsensereasoningalonecanleadtoovergeneraliza-
tionmisalignedwithactualownership. ByintegratingLLM-
basedcommonsenseknowledgewithprobabilisticgenerative
modeling, the proposed method achieved more robust and
efficientownershiplearning.
Fig.6showsthetransitionofIGvaluesforselectedobjects
ateachstepacross20trials. Intheearlysteps, objectswith
highIGvalueswereconsistentlychosen,demonstratingthat
questiongenerationwasstrategicandefficient. FromStep6
C
xedni
fo
IRA
egarevA
Proposed Method Random LLM-only
IG-min No-LLM
Fig.5. ARIofC perstep(Experiment1): Step‚àí1shows
n
thepost-explorationbaseline,andStep0showsresultsaf-
terLLM-basedshared/ownedclassification. Subsequent
stepsindicateperformanceaftereachadditionalquestion.
Sincesharedobjectsareexcludedfromquerying(except
inNo-LLM),learningtypicallyconvergesbyStep9
2.5
2.0
1.5
1.0
0.5
0.0
1 2 3 4 5 6 7 8 9
Step
niaG
noitamrofnI
Mean of Each Step IG
Std of Each Step IG
Max IG
Min IG
Fig.6. TrendsinIGvaluesperstep(Experiment1)
onward,IGvariationdecreased,suggestingthattheremaining
candidatescontributedlessnewinformation. Thisindicates
that the robot had already acquired sufficient knowledge by
thispointandcouldmaintainhighownershippredictionper-
formancewithoutadditionalquestions.
Fig.7showstheaverageARIforC ateachstepacross20
n
trialsintheablationexperiments, witherrorbarsindicating
standarddeviation. Amongtheablationsettings,usingonly
colorinformationyieldedthehighestARI,reflectingconsis-
tentcolorpreferencesamongownersinthesimulatedenviron-
ment. However, since real-world owners do not necessarily
use objects of uniform color, relying solely on color lacks
generalizability. In contrast, the proposed method, which
integratesmultipleattributetypes, showsgreaterrobustness
andadaptabilitytodiverseenvironments. Settingsthatused
onlypositionalinformationoronlyattributeinformationpro-
ducedlowerARIthantheproposedmethod,indicatingthata
singlemodalityisinsufficientandthatcombiningpositional
andattributeinformationisessentialforaccurateownership
inference.
1.0
0.8
0.6
0.4
0.2
0.0
1 0 1 2 3 4 5 6 7 8 9
Step
C
xedni
fo
IRA
egarevA
Proposed Method Proposed Method w/o Attributes
Proposed Method(Color Attributes) Proposed Method w/o Position
1.0
0.8
0.6
0.4
0.2
0.0
1 0 1 2 3 4 5 6 7 8 9 1011121314151617181920
Step
Fig.7. ARIofC perstep(Experiment1: ablationstudy)
n
Computer
Shoes
Phone Box
Cup Chair
Table
Bag Box
Box
Cup Shoes Chair
Phone
Toy
Bag Chair
Toy
Book Cup
Fig.8. Objectlayout(Experiment2): Classname,color,size,
shape,andpositiondistributionofobjectsareshown
6. EXPERIMENT 2: OWNERSHIP LEARN-
INGINACOMPLEXSIMULATEDENVI-
RONMENT
6.1. Objective
The objective of this experiment is to evaluate the effec-
tivenessoftheproposedmethodinamorecomplexenviron-
ment. Inparticular,weexaminewhetheritremainseffective
forownershiplearningwhenboththenumberofobjectsand
users are increased, simulating a more realistic household
setting.
6.2. Conditions
TheexperimentwasconductedinthesameGazebosimula-
tionenvironmentasExperiment1,usingtheaws-robomaker-
small-house-world. We set up an environment with three
usersand20objects,eachassignedanownershiplabel. The
robotwasassumedtohavepriorknowledgeofallobjects‚Äô2D
coordinates and category labels through prior exploration.
TheobjectlayoutisshowninFig.8. AsinExperiment1,the
environment included both owned and shared objects, with
categoriesappearingmultipletimesaswellasonlyonce. To
evaluate robustness, most objects owned by the same user
were grouped by consistent color attributes, while a subset
was intentionally assigned inconsistent color patterns to in-
troducecontradictorycuesforownership.
In this experiment, the number of object categories was
setto10,resultingina22-dimensionalattributevectorcon-
C
xedni
fo
IRA
egarevA
Proposed Method Random LLM-only
IG-min No-LLM
Fig.9. ARIofC perstep(Experiment2): Step‚àí1shows
n
thepost-explorationbaseline,andStep0showsresultsaf-
terLLM-basedshared/ownedclassification. Subsequent
stepsindicateperformanceaftereachadditionalquestion.
Sincesharedobjectsareexcludedfromquerying(except
inNo-LLM),learningtypicallyconvergesbyStep16
structedinthesamemannerasinExperiment1. Therepre-
sentationofobjectpositionsandtheformatofuseranswers
werealsothesameasinExperiment1. Allotherexperimental
settings,includinghyperparameters,multimodalintegration,
andLLM-basedprocessing,wereidenticaltothosedescribed
inSection5.2.
To evaluate performance, we employed the same com-
parison methods as in Experiment 1. The same evaluation
metricswerealsousedtoassessownershiplearningaccuracy
andlearningefficiency.
6.3. Results
Fig. 9 shows the average ARI and standard deviation of
C over 20 trials at each step. In this experiment, the pro- n
posed method underperformed compared to No-LLM. This
wasmainlybecausetheobjectclass‚ÄúBox,‚Äùalthoughowned,
was incorrectly categorized as shared and excluded from
questioning,whichresultedinmissinginformation. Thisre-
vealsalimitationoftheproposedstrategy: relianceoninitial
classificationcancausecriticalinformationlossandsuppress
learning performance. By contrast, No-LLM, which relies
solely on the probabilistic generative model, achieved high
ARI, indicating the robustness of the model even when po-
sitional and attribute consistency across owners is limited.
Nevertheless, the proposed method outperformed the other
baselines such as Random and IG-min, confirming that IG-
based question selection contributes to efficient ownership
learning.
7. EXPERIMENT 3: EFFECTIVENESS IN A
COMPLEXREALENVIRONMENT
7.1. Objective
The objective of this experiment is to evaluate whether
the proposed method can efficiently learn object ownership
in a complex real-world environment. In particular, labora-
torysettingsareoftensharedbymultipleuserswithsimilar
workspaces,andobjectattributesarenotalwaysclearlydis-
Refrigerator Backpack
Dining
Trash Table Chair
bin Bottle
Can Book
Bottle
Monitor/ Desk
TV
Pillow
Mouse Clock
Bed
Bottle
Chair
Book Laptop
Trash
bin
Chair
Cup Can
Desk
Printer
Fig.11. Positiondistribution(Experiment3): Largegreen
Bottle
circles on left show the distribution of shared objects,
Potted Handbag Monitor whereastheothersshowthedistributionsofownedob-
Plant /Satchel /TV jects
Fig. 10. Object layout (Experiment 3): Class name, color, Prompt.7.1.PromptaddedinExperiment3.
sizeandshapeofobjectsareshown
InPrompt.4.1
8:However,theenvironmentshallbeauniversitylaboratory.
9:Eachstudenthashisorherowndeskinoneroom,andthereisasharedspace
tinguishable. Thisexperimentexamineswhetherthemethod formeetings.
canstillacquireownershipknowledgeeffectivelyundersuch
challengingconditions.
othermodalitieswereequallyweighted.
7.2. Conditions
ForLLM-basedprocessing,weusedGPT-4(gpt-4-0613),
The experiment was conducted in a real laboratory at asinthepreviousexperiments. Thepromptusedforclassi-
Ritsumeikan University using the Human Support Robot fying objects as shared orowned (Prompt. 4.1) was slightly
(HSR) [22]. We set up a scenario with seven users and 48 modifiedtoreflectthecontextualcharacteristicsofthelabo-
objects,eachassignedanownershiplabel. Therobotwasas- ratoryenvironment,asshowninPrompt.7.1.
sumedtohavepriorknowledgeofallobjects‚Äô2Dcoordinates To evaluate performance, we employed the same com-
and category labels through prior exploration. The object parison methods as in Experiment 1. The same evaluation
layout is shown in Fig. 10, and the corresponding position metricswerealsousedtoassessownershiplearningaccuracy
distributioninFig.11. andlearningefficiency.
Inthisreal-worldenvironment,itiscommonformultiple
userstosharethesameworkspace,andobjectsusedbydiffer- 7.3. Preparationbeforeexperiment
entindividualsoftenlackdistinguishingvisualfeatures. Asa Inthisexperiment,therobotfirstconstructedamapofthe
result,objectattributesarelesseffectivecuesforownership, domestic environment using gmapping, a ROS-based map-
making spatial location and user answers more critical. To pingpackage. Forobjectdetection,itemployedDetic[23]to
ensurerealisticevaluation,weusedactuallaboratoryobjects recognizeobjectsandobtaintheircategorylabels.
withknownownershipassignments.
The number of object categories was set to 18, resulting 7.4. Results
ina30-dimensionalattributevectorconstructedinthesame 7.4.1. Qualitativeevaluation
mannerasdescribedinSection5.2forExperiment1. Object Table 2 presents examples of object classes classified as
positionsanduseranswerswerehandledinthesamewayas shared or owned by the LLM. Incorporating the laboratory
inExperiment1. context into the prompt enabled appropriate classification
Most hyperparameter settings were identical to those in based on usage and placement, showing that the LLM‚Äôs
Experiment1,exceptthatthetotalnumberofownershipcon- commonsense knowledge functioned effectively. By pre-
cepts was set to L = 8 and the total number of position classifying shared objects, the robot excluded them from
distributionstoK =8. Asbefore,theindexi ofthespatial question generation, avoiding unnecessary queries. Conse-
n
distribution corresponding to each observed coordinate x quently, ownership knowledge was learned more efficiently
n
wasfixedforstability, andmultimodalintegrationapplieda withfeweruserquestions.
weightofœâanswer = 5.0touseranswers. Furthermore,since Fig. 12 presents examples of questions generated in this
no significant differences were observed in object attributes experiment. Theproposedmethodproducedclearandflexi-
intheexperimentalenvironment,theattributemodalitywas blequestionsbyleveragingspatialrelationshipswithnearby
down-weightedwithacoefficientofœâattribute =0.1,whilethe objects. However, in some cases, objects not actually close
Table2. ExamplesofobjectclassesclassifiedasShared
andOwnedobjects(Experiment3)
ObjectType Examples 1.0
Shared Clock,DiningTable,Printer,Potted
0.8
Plant,Refrigerator,TrashbinCan
Owned Backpack, Bed, Book, Bot- 0.6
tle, Chair, Cup, Desk, Hand-
0.4
bag/Satchel, Laptop, Monitor/TV,
Mouse,Pillow 0.2
0.0
1 3 5 7 911131517192123252729313335373941434547
Step
Who does this small, square,
black handbag belong to?
It‚Äôs User B‚Äôs.
User answer = ‚ÄúUser B‚Äú
Learning a Probabilistic Generative Model of Ownership
Is this black, middle, square-shaped laptop
yours, considering there is a similar one
nearby with an unknown owner?
It‚Äôs Mine.
User answer = ‚ÄúUser A‚Äú
Learning a Probabilistic Generative Model of Ownership
Fig.12. SamplequestionsgeneratedbyLLM
were incorrectly described as ‚Äúnearby,‚Äù indicating that the
LLMcouldnotfullycapturespatialrelationships. Thishigh-
lightsaremainingchallengeinprecisespatialreasoning.
7.4.2. Quantitativeevaluation
Fig. 13 shows the average ARI and standard deviation
of C over 10 trials at each step. In the laboratory envi- n
ronment, where object types and appearances were highly
similaracrossusers,thediscriminativepowerofattributein-
formation was limited, making IG-based question selection
less effective. Even so, by lowering the weight of the at-
tribute modality, our method achieved slightly higher ARI
thanIG-minandRandom,suggestingthatadjustingmodality
contributions can improve adaptability in challenging envi-
ronments. Moreover, the proposed method outperformed
bothNo-LLMandLLM-onlyinclusteringconsistency,indi-
cating that the combination of strategic question generation
and the probabilistic generative model remained effective.
It also achieved accuracy comparable to or higher than No-
LLMwithfewerquestions,showingthatpre-classifyingob-
jectsintosharedandindividuallyownedcategoriesenhances
learningefficiencybeyondconventionalapproaches. Overall,
theseresultsdemonstrateboththepotentialofourapproach
andtheinherentchallengesofownershiplearningincomplex
real-worldsettings,whereusersoftenpossessvisuallysimilar
objectsandownershipboundariesareambiguous.
C
xedni
fo
IRA
egarevA
Proposed Method Random LLM-only
IG-min No-LLM
Fig.13. ARIofC perstep(Experiment3): Step‚àí1shows
n
the post-exploration baseline, and Step 0 shows results
after LLM-based shared/owned classification. Subse-
quent steps indicate performance after each additional
question. Sincesharedobjectsareexcludedfromquery-
ing(exceptinNo-LLM),learningtypicallyconvergesby
Step40
8. LIMITATIONS
Themethodemployedcommonsense-basedclassification
ofobjectsintosharedandownedcategoriesusingLLM;how-
ever,suchinterpretationscanvaryacrossenvironments,cul-
tures,andcontexts,leavingariskofmisclassification. Amore
flexibleclassificationframeworkisneededthataccountsfor
uncertaintyinsharedness.
Thesystemassumedthatuserresponseswerealwaysaccu-
rateandconsistent;however,itwasunabletohandleambigu-
ous expressions or subjective variability. To ensure robust
dialogue in real-world scenarios, response processing must
incorporateuncertaintyinuserutterances.
Objectlocation,class,andattributeinformationwereen-
tirely annotated by hand, and the robot was not able to au-
tonomouslyexploreorperceivetheenvironment. Inaddition,
featureweightsweremanuallyset;therefore,amechanismis
necessary that allows the robot to autonomously select and
utilizerelevantfeaturesbasedoncontext.
Ownershipwastreatedasabinaryrelation‚Äîeitherindivid-
uallyownedorsharedbyall‚Äîandpartialorgroupownership
couldnotberepresented. Toreflectrealisticsocialcontexts,
a more flexible framework is needed for representing and
inferringcomplexownershiprelationships.
9. CONCLUSION
9.1. Summary
Inthisstudy,weproposedActOwL,whichenablesrobots
to efficiently learn object ownership in domestic environ-
ments. The approach selects objects based on IG and gen-
erates targeted questions to acquire ownership knowledge.
By leveraging commonsense reasoning from an LLM, the
robotcandistinguishsharedfromownedobjects,reducingthe
scopeofuserinteraction. WeevaluatedActOwLinbothsim-
ulatedandreal-worldsettings,whereitoutperformedbaseline
approaches by achieving higher ownership clustering accu-
racy with fewer interactions. These results suggest that ef- tional Conference on Intelligent Robots and Systems
ficientacquisitionofownershipknowledgethroughquestion (IROS),pp.1520‚Äì1525(2011)
generation can enhance a robot‚Äôs ability to perform flexible [9] Ren, A.Z., et al.: Robots That Ask For Help: Uncer-
andsociallyappropriatetasksindailylifeenvironments. tainty Alignment for Large Language Model Planners.
In: TheConferenceonRobotLearning(CoRL)(2023)
9.2. FutureWork [10] Park,J.,etal.: CLARA:ClassifyingandDisambiguat-
Byleveragingbackgroundinformationaboutusersinthe ing User Commands for Reliable Interactive Robotic
environment,suchastheirrolesandoccupations,itbecomes Agents. IEEE Robot. Autom. Lett. 9(2), 1059‚Äì1066
possible to narrow down candidate objects that are likely to (2023)
belong to them. This can improve the precision of ques- [11] Majumdar,A.,etal.: FindThis: Language-DrivenOb-
tion generation by the LLM and is expected to enhance the ject Disambiguation in Indoor Environments. In: The
efficiencyofownershiplearning. ConferenceonRobotLearning(CoRL)(2023)
Thefutureframeworkwillincorporatetemporaryowner- [12] Pramanick, P., et al.: Talk-to-Resolve: Combining
shipordynamicchangesinownershipovertime. Byintegrat- Scene Understanding and Spatial Dialogue to Resolve
ingobservationsofuserbehaviorandactivitypatternswithin GranularTaskAmbiguityforaCollocatedRobot.Robot
the environment, robots will be able to update ownership Auton.Syst.155,104,183(2022)
knowledgemoreflexiblyandadaptively. [13] Dai, Y., et al.: Think, Act, and Ask: Open-World
Once a robot understands ownership knowledge, it can Interactive Personalized Robot Navigation. In: IEEE
immediately identify the target object when the user gives International Conference on Robotics and Automation
acommand, enablingprompt andappropriateactions. This (ICRA),pp.3296‚Äì3303(2024)
capabilitycansupportpersonalizedandsociallyappropriate [14] Kuang, Y., et al.: OpenFMNav: Towards Open-
assistanceineverydaytaskssuchastidyingupandmanaging Set Zero-Shot Object Navigation via Vision-Language
personalbelongings. FoundationModels. In: AnnualConferenceoftheNa-
tions of the Americas Chapter of the Association for
ACKNOWLEDGMENTS ComputationalLinguistics(NAACL)(2024)
[15] Oyama, A., et al.: Take That for Me: Multimodal
ThisworkwassupportedbyJSPSKAKENHIGrants-in-
Exophora Resolution with Interactive Questioning for
Aid for Scientific Research (Grant Numbers JP23K16975,
Ambiguous Out-of-View Instructions. In: IEEE Inter-
JP25K15292) and JST Moonshot Research & Development
national Conference on Robot and Human Interactive
Program(GrantNumberJPMJMS2011).
Communication(RO-MAN)(2025)
[16] Wang,H.,etal.: APRICOT:ActivePreferenceLearning
REFERENCES
and Constraint-Aware Task Planning with LLMs. In:
[1] Friston, K.: The Free-Energy Principle: A Unified TheConferenceonRobotLearning(CoRL)(2024)
Brain Theory? Nat. Rev. Neurosci. 11(2), 127‚Äì138 [17] Radford,A.,etal.: LearningTransferableVisualMod-
(2010) els from Natural Language Supervision. In: Interna-
[2] Taniguchi,A.,etal.: ActiveExplorationbasedonInfor- tional Conference on Machine Learning (ICML), pp.
mationGainbyParticleFilterforEfficientSpatialCon- 8748‚Äì8763(2021)
ceptFormation. Adv.Robot.37(13),840‚Äì870(2023) [18] Chen, B., et al.: Open-Vocabulary Queryable Scene
[3] Ishikawa, T., et al.: Active Semantic Mapping for Representations for Real World Planning. In: IEEE
Household Robots: Rapid Indoor Adaptation and Re- International Conference on Robotics and Automation
ducedUserBurden. In: IEEEInternationalConference (ICRA),pp.11,509‚Äì11,522(2023)
on Systems, Man, and Cybernetics (SMC), pp. 3116‚Äì [19] Murphy, K., et al.: Rao-Blackwellised Particle Fil-
3123(2023) tering for Dynamic Bayesian Networks. In: Sequen-
[4] Tan, Z.X., et al.: That‚Äôs Mine! Learning Ownership tial Monte Carlo Methods in Practice, pp. 499‚Äì515.
Relations and Norms for Robots. In: The Association Springer(2001)
for the Advancement of Artificial Intelligence (AAAI) [20] Uehara, K., et al.: K-VQG: Knowledge-Aware Visual
onArtificialIntelligence,vol.33,pp.8058‚Äì8065(2019) Question Generation for Common-Sense Acquisition.
[5] Wu,H.,etal.: ItemOwnershipRelationshipSemantic In: IEEE/CVF Winter Conference on Applications of
LearningStrategyforPersonalizedServiceRobot. Int. ComputerVision(WACV),pp.4401‚Äì4409(2023)
J.Autom.Comput.17(3),390‚Äì402(2020) [21] Achiam, J., et al.: GPT-4 Technical Report. arXiv
[6] Hu, Y., et al.: An Interactive Learning Framework for preprintarXiv:2303.08774(2023)
ItemOwnershipRelationshipinServiceRobots. Hum. [22] Yamamoto,T.,etal.: DevelopmentofHumanSupport
FactorsRobotsDronesUnmannedSyst.p.29(2023) Robot as the Research Platform of a Domestic Mobile
[7] Taniguchi,T.,etal.: MultimodalHierarchicalDirichlet Manipulator. ROBOMECHJ.6(1),1‚Äì15(2019)
Process-based Active Perception by a Robot. Front. [23] Zhou, X., et al.: Detecting Twenty-Thousand Classes
Neurorobot.12,22(2018) usingImage-LevelSupervision. In: EuropeanConfer-
[8] Nakamura, T., et al.: Multimodal Categorization by enceonComputerVision(ECCV),pp.350‚Äì368(2022)
Hierarchical Dirichlet Process. In: IEEE/RSJ Interna-

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ‚ùå BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ‚úÖ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ‚ùå BAD: Repeating the same claim 3+ times with slight variations
   ‚úÖ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
