=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Structured Active Inference (Extended Abstract)
Citation Key: smithe2024structured
Authors: Toby St Clere Smithe

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2024

Key Terms: structured, systems, abstract, categorical, agents, models, verses, extended, formal, inference

=== FULL PAPER TEXT ===

4202
nuJ
7
]IA.sc[
1v77570.6042:viXra
Structured Active Inference
Toby St Clere Smither0000´0002´8317´8722s
VERSES Research Lab
toby.smithe@verses.ai
Abstract. We introduce structured active inference, a large generaliza-
tion and formalization of active inference using the tools of categorical
systems theory. We cast generative models formally as systems “on
an interface”, with the latter being a compositional abstraction of the
usual notion of Markov blanket; agents are then ‘controllers’ for their
generativemodels,formallydualtothem.Thisopenstheactiveinference
landscape to new horizons, such as: agents with structured interfaces
(e.g. with ‘mode-dependence’, or that interact with computer APIs);
agentsthatcan manageotheragents;and‘meta-agents’, thatuseactive
inferencetochangetheir(internalorexternal)structure.Withstructured
interfaces,wealsogainstructured(‘typed’)policies,whichareamenable
to formal verification, an important step towards safe artificial agents.
Moreover,wecanmakeuseofcategoricallogictodescribeexpressagents’
goals as formal predicates, whose satisfaction may be dependent on the
interactioncontext.Thispointstowardspowerfulcompositional toolsto
constrain and control self-organizing ensembles of agents.
Keywords: Activeinference·Categorical systemstheory·Cybernetics
· Multi-agent · Formal methods · Safe AI.
As active inference develops beyond toy models and early explorations, and
becomes a fully-fledged account of the form and function of complex living
systems at all scales, the necessity of a compositional organizing framework
becomesapparent:withoutthis,the complexityofveridicalmulti-agentsystems
in realistic environments is impossible to handle. To see this necessity, one need
only ponder the question,how wouldyoumodelanagentas it getson a bicycle,
orstartstodriveacar?Evenincasesasmundaneasthese,currentpresentations
of active inference do not yield a canonical answer. More generally, it is not at
all clear how to describe, in general, an agent that can change its ‘interface’.
This is an argument that we must move beyond the current paradigm
of partially observable Markov decision problems (and their continuous-time
cousins), which are most suitable for the description of individual agents with
unchangingMarkovblanketsandstaticenvironments,andadoptanewparadigm
withchangeatitsheart,andthatmakesthemostofthecompositionalstructure
of our world. It is such a paradigm that we propose here: structured active
inference,inwhicheveryagent’sgenerativemodelhasanexplicitinterface,vastly
generalizing the existing notion of Markov blanket. This new paradigmexploits
2 T. St Clere Smithe
the new mathematics of categorical systems theory (CST) [1], which organizes
interacting dynamical systems into a coherent compositional framework.
Being based on category theory, change and composition are at the heart of
structured active inference: patterns of interaction among systems constitute
morphisms of interfaces, as do changes-of-interface; and changes-of-structure
are morphisms of systems (over interfaces). Category theory is moreover the
mathematics of structure, meaning that agents’ interfaces may exhibit substan-
tially richer structures than merely a fixed pair of sets (of possible actions
and observations).In particular,agents may now exhibit mode-dependence: the
availableactionsmaydependoncontextualdata(encodedintheircurrentstate).
Being a mathematical lingua franca, category theory allows us to import ideas
from computer science, yielding agents that correctly interact with computer
APIs, or whose policies may be interpreted as programs and thus type-checked
(a step towards formal verification), or that (recursively) manage other agents,
or (‘corecursively’)use active inference to change their own structure.
Additionally,categoricalsystemstheoryisitselfamenabletocategoricallogic
[2],whichexplainsthestructuralfundamentsoflogicandtypetheoryandwhich
maybeinstantiatedinanysufficientlystructuredcontext.Inthisway,structured
active inference permits not only typed policies, but also a rigorous analysis of
agents’ goals as formal predicates (possibly in a fuzzy, quantitative, temporal
logic),whosesatisfactionmaybejudgedinrelationtotheirinteractioncontexts:
thanks to its compositionality, the logic of systems is itself ‘covariant’ with
their patterns of interaction. This promises a further important step towards
safe artificial agents, as agents’ goals may be gated behind the certification
(within bounds) of their safety [3, 4], and their policies judged accordingly. In
combination with structurally nested (‘manager’) agents, it becomes possible
to pass formal specifications of high-level goals down to low-level agents which
actually implement them.
This extended abstract is an announcement of work in progress. A full
expositorypaperwillfollowsoon.Meanwhile,wesupplyappendicesbelowwhich
sketch the key structures and exemplify the corresponding possibilities.
Acknowledgments. The author thanks VERSES for financial support during the
development of this work.
Disclosure of Interests. The author has no competing interests to declare that are
relevant to thecontent of this article.
References
[1] David Jaz Myers. Categorical Systems Theory (Draft). 2022. url:
http://davidjaz.com/Papers/DynamicalBook.pdf.
[2] Bart Jacobs. Categorical Logic and Type Theory. Vol. 141. Studies in
Logic and the Foundations of Mathematics. North-Holland Publishing
Co., Amsterdam, 1999, pp. xviii+760.isbn: 0-444-50170-3.
Structured ActiveInference 3
[3] David "davidad"Dalrymple.Safeguarded AI: Constructing Guaranteed
Safety.Tech.rep.AdvancedResearchandInnovationAgency,2024.url:
https://www.aria.org.uk/wp-content/uploads/2024/01/ARIA-Safeguarded-AI-Programme-Thes
[4] David "davidad" Dalrymple et al. Towards Guaranteed Safe AI: A
Framework for Ensuring Robust and Reliable AI Systems. 05/17/2024.
arXiv: 2405.06624 [cs]. url: http://arxiv.org/abs/2405.06624
(visited on 06/07/2024).preprint.
[5] NelsonNiuandDavidI.Spivak.Polynomial Functors: A Mathematical
Theory of Interaction. arXiv, 12/01/2023. arXiv: 2312.00990 [math].
url: http://arxiv.org/abs/2312.00990(visited on 04/05/2024).
[6] Bart Jacobs. “A Recipe for State-and-Effect Triangles”. In: Logical
Methods in Computer Science 13.2 (2017-05-17, 2017), pp. 1860–5974.
doi: 10.23638/LMCS-13(2:6)2017.arXiv: 1703.09034[cs.LO].
[7] Dylan Braithwaite, Jules Hedges, and Toby St Clere Smithe. The
Compositional Structure of Bayesian Inference. 05/10/2023. arXiv:
2305.06112 [cs, math]. url: http://arxiv.org/abs/2305.06112
(visited on 05/11/2023).preprint.
[8] Karl J. Friston et al. “Deep Temporal Models and Active Inference”.
In: Neuroscience & Biobehavioral Reviews 77 (06/2017), pp. 388–402.
issn: 01497634. doi: 10.1016/j.neubiorev.2017.04.009. url:
https://linkinghub.elsevier.com/retrieve/pii/S0149763416307096
(visited on 05/31/2024).
[9] Toby St Clere Smithe. Animating Categories. 11/16/2023. url:
https://tsmithe.net/p/animating-cats.html.
[10] JoachimKock.“PolynomialFunctorsandTrees”.In:Int.Math.Res.No-
tices 2011 (2011), 609-673 (07/17/2008).arXiv:0807.2874[math.CT].
[11] Nathanael Arkor and Marcelo Fiore. “Algebraic Models of Simple
Type Theories: A Polynomial Approach”. In: Proceedings of the
35th Annual ACM/IEEE Symposium on Logic in Computer Science.
LICS ’20: 35th Annual ACM/IEEE Symposium on Logic in Com-
puter Science. Saarbrücken Germany: ACM, 07/08/2020, pp. 88–101.
isbn: 978-1-4503-7104-9. doi: 10 . 1145/ 3373718. 3394771. url:
https://dl.acm.org/doi/10.1145/3373718.3394771 (visited on
04/05/2024).
[12] Matteo Capucci et al. “Towards Foundations of Categorical Cybernet-
ics”. In: Electronic Proceedings in Theoretical Computer Science. Ap-
4 T. St Clere Smithe
pliedCategoryTheory2021.Vol.372.Cambridge,UK:OpenPublishing
Association, 11/03/2022, pp. 235–248. doi: 10.4204/EPTCS.372.17.
url: http://arxiv.org/abs/2105.06332v2(visited on 09/29/2023).
[13] MatteoCapucci.“DiegeticRepresentationofFeedbackinOpenGames”.
In: Electronic Proceedings in Theoretical Computer Science. Applied
Category Theory 2022. Vol. 380. Glasgow, UK: Open Publishing
Association, 08/07/2023, pp. 145–158. doi: 10.4204/EPTCS.380.9.
url: http://arxiv.org/abs/2206.12338v3(visited on 09/29/2023).
[14] Toby St Clere Smithe. “Cyber Kittens, or Some First Steps Towards
Categorical Cybernetics”. In: Electronic Proceedings in Theoretical
ComputerScience.AppliedCategoryTheory2020.Vol.333.Cambridge,
MA: Open Publishing Association, 02/08/2021, pp. 108–124. doi:
10.4204/EPTCS.333.8.url: http://arxiv.org/abs/2101.10483v1
(visited on 09/29/2023).
[15] David I Spivak. “The Steady States of Coupled Dynamical Sys-
tems Compose According to Matrix Arithmetic”. 12/02/2015. arXiv:
1512.00802[math.DS].
Structured ActiveInference 5
A Categorical systems theory for active inference
A.1 Systems indexed by interfaces
A systems theory is a family of categories of systems, covariantly indexed by a
categoryofinterfaces.Moreformally,thisisa(pseudo)functorSys:IntÑCat,
where Cat is the 2-categoryofcategories,functors and naturaltransformations.
ThecategoryIntisusuallyunderstoodtohave‘interfaces’(ofsometype)for
objects,and“patternsofinteraction” or“wiringdiagrams” for morphisms.Thus,
if p and q are two interfaces (objects in Int), then a morphism p Ñ q encodes
“how to wire a p-shaped system into a q-shaped system”.
A standard example category of interfaces is the category LenspSetq of
‘lenses’ in Set (the latter being the category of sets and functions between
them). In this case, the objects of LenspSetq are pairs pO,Iq of sets; we think
of O as representing the output type of some system, and I as representing its
input type. and a morphism (a so-called ‘lens’) ϕ : pO,Iq Ñ pP,Jq is a pair
of functions ϕ : O Ñ P,ϕ7 : OˆJ Ñ I . We typically understand the map
1
ϕ as representing how an O ‘output’ is mapped to a P output, and the map
1
` ˘
ϕ7 as representing how an I ‘input’ may be obtained from an O output and a
J input. That is, ϕ encodes how an inner system with output-input interface
pO,Iq may be ‘nested’ inside an outer system with interface pP,Jq: the outer
outputs are obtained as a transformation of the inner outputs, and the inner
inputs are obtained as a transformation of the inner outputs and outer inputs,
thereby enabling feedback.
AsimpleexampleofasystemstheoryoverLenspSetqisthatofdeterministic
automata, or Moore machines, Moore : LenspSetq Ñ Cat. A Moore machine
withinterfacepO,IqisatriplepS,ϑ ,ϑuqofastatespaceS :Set,anoutputmap
o
ϑ :S ÑO,andanupdatemapϑu :SˆI ÑS.Amorphismf :pS,ϑqÑpS1,ϑ1q
o
ofMooremachinesoverpO,Iq is afunction f :S ÑS1 that“commuteswith the
dynamics”: i.e., satisfying f ˝ϑu “ ϑ1u ˝pf ˆid q. The category MoorepO,Iq is
I
thus constituted by Moore machines with interface pO,Iq and their morphisms,
which compose simply as functions.
Given a lens ϕ : pO,Iq Ñ pP,Jq, Moore must define a functor Moorepϕq :
MoorepO,Iq Ñ MoorepP,Jq which ‘rewires’ machines over pO,Iq so that they
becomemachinesoverpP,Jq. NotethataMooremachinepS,ϑqoverpO,Iq may
equivalently be presented as a lens pϑ ,ϑuq : pS,Sq Ñ pO,Iq, and so Moorepϕq
o
maybe definedsimplybycomposingϕafterϑ,thusmappingpS,ϑqtopS,ϕ˝ϑq.
It is easy to check that this maps morphisms of Moore machines over pO,Iq to
morphisms of Moore machines over pP,Jq (and does so functorially); and since
composition is functorial, this definition yields a valid pseudo functor.
A.2 Placing systems side-by-side
In order to understand morphisms of interfaces as wiring systems together, we
need to be able to place systems side-by-side, so that we can make sense of
the plural ‘systems’. This demands that we can first compose interfaces “in
6 T. St Clere Smithe
parallel”, and second that our systems theories are such that we can take a
system over one interface and a system over another, and form a system over
the corresponding parallel composite interface. Formally, this means we require
Int to be a monoidalcategorypInt,y,bqwith parallelcomposition (‘tensor’)b
and unit (trivial) interface y, and that our systems theories are (lax) monoidal
with respect to this parallelcomposition.The latter requirementmeans that we
need a natural transformation SysppqˆSyspqq Ñ Syspp bqq (satisfying some
standard coherence conditions). The laxness of this structure means that this
transformation is not invertible: that is, not every system over a composite
interfacepbq maybe decomposableintosystemsoverthecomponentinterfaces
p,q.
LenspSetq is monoidal, with tensor pO,IqbpA,Bq “ pOˆA,I ˆBq and
unit p1,1q. Moore is similarly lax monoidal, with the laxator MoorepO,Iq ˆ
MoorepA,Bq Ñ Moore pO,Iq b pA,Bq defined by mapping pS,ϑq,pT,ψq to
pSˆT,ϑbψq.
` ˘
A.3 Dynamic wiring
We will see below that it can be useful to define systems with “dynamic wiring”.
Recalling that ‘wiring’ corresponds to a morphism in a category of interfaces
Int, a system that can change some wiring would need an interface type that
encapsulates morphisms of interfaces; that is, given interfaces q,r to be wired
together, we need an object in Int that ‘internalizes’ the set of morphisms
Intpq,rq. Such an object is called an internal hom, and we will denote it by
rq,rs.
For rq,rs to behave like an internalization of Intpq,rq, it needs to exhibit a
‘currying’1relationshipwithb.Thatis,morphismspbqÑrmustbeinbijection
with morphisms p Ñ rq,rs. In other words, we need a natural isomorphism
Intppbq,rq – Intpp,rq,rsq. (This makes rq,´s right adjoint to ´bq.) From
this natural isomorphism we can obtain2 ‘evaluation’ morphisms rq,rsbq Ñ r
whichsaythat,givenarq,rs-systemandaq-system,wecanwiretheformerinto
thelattertoobtainanr-system.Thusrq,rs-systemsdynamicallywireq-systems
into r-systems.
We will use this structure to describe agents that manage other agents,
generalizing hierarchical(‘deep’) active inference.
A.4 Polynomial interfaces
A lens interface is a fixed pair of sets, much as in classical active inference. To
capturesystemswhoseinterfacesmaybe mode-orcontext-dependent3,weneed
1 The currying of a function f :AˆB Ñ C is the function f7 :A ÑrB,Cs defined
by themapping aÞÑfpa,´q.
2 Set p“rq,rs and then transport the identity morphism id :rq,rsÑrq,rs from
rq,rs
theright-hand side to theleft-hand side.
3 For example, when I close my eyes, the sense-data that I receive (my ‘inputs’) are
different from when I open them.
Structured ActiveInference 7
the possible inputs to a system to be able to depend on the system’s state,
as revealed by its output. To encode such dependence, we may use polynomial
functors, whose morphisms are sometimes known as dependent lenses.
A polynomial p in one variable, denoted y, is an expression of the form
ypris. We call I the indexing set and, for each i : I, pris is the exponent at
i:I
i. In high-school algebra, the variable y takes numerical values, the exponents
ř
pris are all numbers, and the whole expressionmay be evaluated into a number,
thus defining a function. Here, we allow the variable y and exponents pris to
be valued in sets, noting that each natural number n may be understood as a
finite setrns with n-manyelements. An exponentialBA of sets is understoodto
denote the set SetpA,Bq of functions A Ñ B, so that each term ypris denotes
the ‘hom’ functor X ÞÑ Xpris, and the sum denotes the disjoint union of sets.
In this way, each polynomial p does indeed denote a functor Set Ñ Set. If we
evaluate this functor at the singleton set 1, we find
pp1q“ 1pris – 1–I .
i:I i:I
ÿ ÿ
For this reason, we will often write a polynomial p as ypris.
i:pp1q
Each polynomial p also corresponds to a (discrete) bundle of sets, given by
projecting from the disjoint union of the
exponents4ř
back to the indexing set.
That is, each p corresponds to a function
prisÑpp1q
i:pp1q
ÿ
pi,xqÞÑi.
Note that, if the exponents do not vary with the index, e.g. q “ yQ, then
j:J
the bundle corresponds to a product projection Q – J ˆQ Ñ J. Such
j:J ř
‘non-dependent’ polynomials are called monomials and can be written as JyQ.
ř
A morphism ϕ : p Ñ q of polynomial functors is a natural transformation.
One can show (using the Yoneda Lemma) that these natural transformations
correspondtopairsoffunctionspϕ ,ϕ7qasinthefollowingcommutativediagram,
1
where the square on the right is a pullback square:
ϕ7
pris qrϕ piqs qrjs
i:pp1q i:pp1q 1 j:qp1q
{
ř ř ř
p
ϕ˚ 1q q
pp1q ϕ1 qp1q
Alternatively, ϕ7 may be understood as a pp1q-indexed family of functions
tϕ7 : qrϕ piqs Ñ prisu . Thus we have a ‘forwards’ function ϕ and a pp1q-
i 1 i:pp1q 1
dependent ‘backwards’function ϕ7.
4 The elements of pris are pairs pi,xq of iPpp1q and xPpris.
i:pp1q
ř
8 T. St Clere Smithe
Polynomial functors and their morphisms constitute a category Poly. The
composition of ϕ:pÑq and ψ :q Ñr is given by pψ ˝ϕ ,ϕ7˝ϕ˚ψ7q. Written
1 1 1
in indexed form, the backwards components are
rrψ pϕ piqqsÝ ψ Ýϕ 7 Ý1ÝpÑiq qrϕ piqsÝ ϕ Ñ 7 i pris.
1 1 1
We mentioned above that morphisms between polynomial functors may
be understood as ‘dependent’ lenses. To make this perspective clearer, we
observe that LenspSetq embeds into Poly. Each lens object pO,Iq corresponds
(bijectively) to a monomial OyI. Each lens pO,Iq Ñ pP,Jq is then exactly a
morphismOyI ÑPyJ.Wecanthereforethinkoftheexponentsofapolynomial
as ‘mode-dependent’ input types, and the indexing sets as possible outputs.
Alternatively, we may understand pp1q as the set of “possible configurations”
that a p-shapedsystem may adopt; andeach pris is the set of possible incoming
signals in configuration i, or the “i-context-dependent sensorium”.
A.5 Tensor and internal hom of polynomials
Poly has a ‘parallel’ tensor product b with unit y. p b q is defined as the
polynomial yprisˆqrjs; likewise, one takes products on morphisms.
pi,jq:pp1qˆqp1q
It is easy to verify that ybp – p – pby, and that this product is symmetric,
ř
pbq –qbp.
This tensor structure py,bq has a corresponding internal hom r´,“s. On
objects, the internal hom may be defined by
rp,qs“ y i:pp1q qrϕ1piqs .
ϕ:pÑq ř
ÿ
(Given morphisms ϕ : p1 Ñ p and ψ : q Ñ q1, we leave the definition of rϕ,ψs :
rp,qsÑrp1,q1s as an exercise for the reader.)
We therefore think of the configurations of rp,qs as encoding wirings from
p to q; and, for each such configuration ϕ, the inputs rp,qsrϕs are the inputs
demandedbyϕ7 —thus,thedatarequiredtopassinputstoanyp-systemwired
by ϕ into q.
For much more onpolynomialfunctors, we refer the reader to the wonderful
book by Niu and Spivak [5].
A.6 Generative models as stochastic Moore machines
Above (§A.1), we introduced the theory of Moore machines over LenspSetq,
wherewesawthataMooremachineonpO,IqisachoiceofstatespaceS andlens
pS,SqÑpO,Iq. We havejustseenthatLenspSetqisthemonomialsubcategory
of Poly, so a (non-dependent) Moore machine over pO,Iq may alternatively be
defined as a Poly morphism SyS Ñ OyI for some set S. This yields a first
generalization:adependent Mooremachinewithpolynomialinterfacepis apair
Structured ActiveInference 9
pS,ϑqwhereS isasetandϑamorphismSyS ÑpinPoly.Bysimilarreasoning
to that in §A.1, this yields a systems theory DMoore:PolyÑCat.
The reader may have noticed a similarity between the data of a Moore
machine ϑ : SyS Ñ OyA — consisting of an output map (or ‘likelihood’)
ϑ : S Ñ O and an update map (or “transition function”) ϑu : S ˆA Ñ S
o
— and a (discrete-time) generative model with state space S, observations O,
and actions A. There are two key differences: a generative model is a stochastic
transition system; and it is usually understood as being equipped with a ‘prior’
distribution (a stochastic initial condition) on the state space S.
Let us address the first difference first, defining a systems theory Gen :
PolyÑCatofstochasticdependentMooremachines,whichwetakeasamode-
dependent generalization of classical generative models. To keep the exposition
simple,wewillrestrictourselvestodiscreteprobabilitydistributions,whichmay
be defined over any set. If X is any set, we will write DX to denote the set of
such distributions over X. That is,
DX “ p:X Ñr0,1s ppxq“1 .
# ˇ +
ˇx
ÿ
:X
ˇ
For the sum over X to be well-defined, p ˇ ˇP DX may only be supported on a
countable subset of X.
Given any function f :X ÑY, we have a function Df :DX ÑDY defined
by ‘pushforward’: if p P DX, then Dpfqppq is the distribution mapping y P
Y to ppxq. (The pushforward distribution Dpfqppq is sometimes also
xPf´1tyu
denoted by f p.) This makes D into a functor SetÑSet.
ř ˚
A conditional probability distribution qpy|xq then corresponds to a function
X Ñ DY; note that, by currying, this is equivalent to a stochastic matrix
X ˆY Ñ r0,1s. If q : X Ñ DY and r : Y Ñ DZ are two stochastic matrices,
then they may be composed by matrix multiplication to yield a conditional
distribution r‚q : X Ñ DZ defined by pr‚qqpz|xq “ rpz|yqqpy|zq. Thus
y:Y
conditional distributions form the morphisms of a category, FinStoch. These
ř
morphisms are also known as stochastic maps or channels. We will denote a
channel X Ñ DY by X ù Y The identity channel X ù X is defined by
mapping x to the Dirac delta distribution at x; this mapping is sometimes
denoted η . Every function f : X Ñ Y yields a channel δ : X ù Y defined
X f
by X ÝÑ f Y Ý η ÝÑY DY.
A(discrete-time,discrete-space)Markovchainthuscorrespondstoachannel
X ùX,for some state space X. We will use this correspondenceto define the
systems theory Gen.
Givenapolynomialp,wedefinetheobjectsofGenppqtobetriplespS,ϑ ,ϑuq
o
whereS isaset,ϑ isafunctionS Ñpp1qandϑu isachannel prϑ psqsù
o s:S o
S. We will call these generative models or stochastic dependent Moore machines
with interface p. A morphism f : pS,ϑq Ñ pS1,ϑ1q in Genppq ř is a channel f :
S ù S1 such that f ‚ϑu “ ϑ1u ‚pf ˆidq. Morphisms of generative models
compose by channel composition.
10 T. St Clere Smithe
Given a dependent lens ϕ : p Ñ q, we obtain a functor Genpϕq : Genppq Ñ
Genpqqbypost-composition,almostexactlyasforMooremachines.Thus,Genpϕq
maps a model pS,ϑ ,ϑuq over p to the model pS,ϕ ˝ ϑ ,ϑu ‚ δ q. More
o 1 o ϑ˚ oϕ7
explicitly, the update channel is here given by the composite
qrϕ pϑ psqqs
δ ùϑ˚ oϕ7
prϑ
psqsùϑu
S
1 o o
s:S s:S
ÿ ÿ
whosefirstcomponentisthedeterministicchannelinducedbythefunctionϑ˚ϕ7.
o
It is easy to check that this definition preserves morphisms of models and thus
yields a valid pseudo functor Gen:PolyÑCat.
It will be important in the sequel that Gen is monoidal, so that we can
place generative models in parallel. Thus, we need a family of functors λ :
p,q
GenppqˆGenpqqÑGenppbqqnaturalinthe polynomialsp,q.These aredefined
as follows.
First, note that there is a family of functions DX ˆ DY Ñ DpX ˆ Yq,
naturalinthe setsX andY,givenbymappingαPDX andβ PDY to thejoint
distribution αbβ whose independent marginals are α and β. That is, αbβ is
defined by mapping px,yqPXˆY to the probability αpxqβpyq. (Note that this
b is not the same as the tensor on Poly; it is rather the tensor on FinStoch.)
Next, we define λ using these functions. If ϑ “ pS,ϑ ,ϑuq is a model
p,q o
over p and χ “ pT,χ ,χuq is a model over q, then λ pϑ,χq is defined by
o p,q
pSˆT,ϑ ˆχ ,ϑubχuq. In turn, ϑubχu is defined by the function
o o
prϑ psqsˆqrχ ptqsÝ ϑ Ý u Ý ˆ Ý χ Ñ u DSˆDT ÝÑ b DpSˆTq.
o o
ps,tq:SˆT
ÿ
Iff :pS,ϑ ,ϑuqÑpS1,ϑ1,ϑ1u qandg :pT,χ ,χuqÑpT1,χ1,χ1u qaremorphisms
o o o o
in Genppq and Genpqq respectively, then λ pf,gq is the morphism λ pϑ,χqÑ
p,q p,q
λ pϑ1,χ1q defined by the function
p,q
SˆT Ý f Ý ˆ ÝÑ g DS1ˆDT1 Ý b ÑDpS1ˆT1q.
One maythencheckthatthis makesλ intoa functor,andthatthis definition
p,q
is natural in p and q (i.e., that it respects morphisms on both interfaces).
Remark. To check that Gen really does correspond to classical (discrete time
and space) generative models means checking how it behaves over monomials
OyA.TheobjectsofGenpOyAqaretriplespS :Set,ϑ :S ÑO,ϑu :SˆAùSq.
o
Thus they are almost, but not quite, exactly classical generative models: the
output maps are still deterministic by this definition.
The reason for this is technical: in general, it is so that the pullback set
prϑ psqs is well defined. In the monomial case, there is no problem having
s:S o
stochasticity in ϑ , because the defining expression should evaluate to SˆA in
o
ř
anycase.Butitislesssimpletomakesenseoftheexpression prϑ psqswhen
s:S o
ϑ is a stochastic map (although there are ways to do so).
o
ř
Structured ActiveInference 11
Nonetheless,thisisnotintheendaproblem,becauseifwewantastochastic
‘likelihood’, we can fold it into the update channel. That is, we can let the state
space be S ˆ pp1q, the output map be the projection S ˆ pp1q Ñ pp1q, and
the update channel be defined by pris pϑù u,ϑlq S ˆ pp1q, where ϑu
ps,iq:Sˆpp1q
is a ‘transition’ channel pris ù S and ϑ is a ‘likelihood’ channel
ps,iq:Sˆpp1řq l
S ùpp1q, so that pϑu,ϑ q maps ps,i,xq to ϑups,i,xqbϑpsq.
l l
ř
Alternatively,wecouldmakeanalternativedefinitionofGensothatamodel
over p consists of a quintuple pS,O,ϑ ,ϑ ,ϑuq where S and O are sets, ϑ is a
l o l
likelihood channel S ù O, ϑ is an output function O Ñ pp1q, and ϑu is an
o
update channel prϑ poqs ù S. We made the definition we did because it
o:O o
keeps the amount of data to a minimum and maintains a close analogy with
ř
deterministic Moore machines.
We end this section by noting that priors over states are simply additional
dataattachedtoagenerativemodel.ThuswecandefineavariantofGen,denoted
Gen , where the objects of each Gen ppq are be tuples pS,ϑ,πq where pS,ϑq is
˚ ˚
an object of Genppq and π : 1 ù S is a distribution over S. We may similarly
extend the definitionof morphismso thata morphism f :pS,ϑ,πqÑpS1,ϑ1,π1q
inGen ppqisamorphismf :pS,ϑqÑpS1,ϑ1qinGenppqsatisfyingtheadditional
˚
condition that π1 “ δ ‚π. With this definition, there is a canonical indexed
f
functor Gen ñ Gen that simply forgets the data of the priors. We will see
˚
below (§B.5) that this is a basic example of a logical structure over Gen.
A.7 Agents’ control systems are dual to their generative models
The preceding section introduced structured generative models, but an active
inference agent is more than just a generative model: it is a model along with
a system for ‘controlling’ the model, supplying inputs (actions) that minimize
expectedfreeenergy,inanattempttominimizethedivergencebetweenhowthe
worldis inferredto be (fromthe observations)andhowthe worldis expectedto
be (from the transition model).
In active inference, an important distinction is made between the generative
model, which forms part of an agent, and the generative process, which may be
quitedifferentfromthegenerativemodel,butwhichisunderstoodasthe“ground
truth” generatorof the agent’s observations(and which is the ‘true’ recipient of
the agent’s actions). The generative model is used by the agent to predict how
the generative process (i.e., how the ‘environment’) will respond to its actions.
Inordertomakesuchaprediction—inorderto‘unroll’thegenerativemodel
intime—theagentmustsupplyitwithactions,whicharechosenbytheagent’s
control system. Formally, this means that the generative model along with the
control system must form a closed system (a system on the trivial interface y),
because closed systems are those that can be evolved autonomously, without
external input.
If the generative model has interface p, then this means that the control
system should have interface rp,ys, because (as we saw in §A.3) there is a
12 T. St Clere Smithe
canonicalmorphismrp,ysbpÑy.Thus any p-system(any p-generativemodel)
maybecanonicallycoupledtoarp,ys-system(ap-controller)toproduceaclosed
system (with interface y), which may be unrolled.
Letusverifythatthisabstractreasoningcapturesthestructureofaclassical
active inference agent with interface OyA. We have already seen that its
generative model comprises a state space S, a stochastic transition function
SˆA ùS, and a ‘likelihood’ S Ñ O. The dual5 of OyA is rOyA,ys“ AOyO.
A Moore machine on this interface comprises a state space T, an output map
T Ñ AO, and an update map T ˆO Ñ T. By currying, we can equivalently
writetheoutputmapasTˆOÑA.IfweletthestatespaceT beDS,thenour
two maps finally have the types DSˆO ÑA and DSˆO ÑDS. The latter is
the type signature of Bayesian inversion [7], so this map may be understood as
performing state inference (‘perception’). The former may then be understood
as performingactionselection,andwe may callit the policy; in active inference,
this is achieved by the minimization of expected free energy.
By inspection, we can therefore see that the pair of a generative model over
OyA and a Moore machine over rOyA,ys captures all the data of a classsical
active inference agent. This licenses the following important definition.
DefinitionA1. Anagent withpolynomialinterfacepandstatespaceS consists
of a generative model over p with state space S, along with a controller for the
generativemodel: a Moore machine overrp,yswith state space DS. The output
mapofthecontrolleristheagent’spolicy,performingactionselection;theupdate
map of the controller performs inference.
We emphasize again that the agent’s interface p generalizes the classical
notion of the Markov blanket of its generative model.
A.8 Animated categories: generative Poly
The preceding exposition has discussed individual agents, and justified the
constructions using ‘shallow’ generative models with interface OyA. But active
inference purports to model agents in complex contexts, interacting with other
agents; and even a single agent is often supposed to have some ‘deep’ or
hierarchicalstructure [8].
Wecanincorporatesuchsituationseasilyintothestructuredactiveinference
framework, by noticing that p – ry,ps. Thus, we can equivalently define a
‘simple’ agent with interface p as a model over ry,ps coupled to a controller
over rp,ys. If an agent is embedded into a more complex context, we can model
this by replacing the trivial interface y with an interface q describing the “outer
boundary” of the interaction context. Thus a ‘complex’ agent with interface p
in context q may be defined as a model over rq,ps along with a controller over
rp,qs.
5 Mathematically, many dualities are obtained by “homming into a unit object” [6],
which is precisely the situation we havehere.
Structured ActiveInference 13
This situation may be rendered fully compositional using the monoidal
structure of Gen andMoore, formalizedin the frameworkof animated categories
[9]. The key observation here is that the internal hom structure r´,“s induces
an“internalcomposition” operationinthecategoryofinterfacesPoly:thereare
morphisms rp,qsbrq,rs Ñrp,rs which act to “compose along q”, and these are
natural in p,q,r. This is to say that Poly is enriched in itself.
In general, whenever we have a category C enriched in a category V, and
a monoidal functor F : V Ñ V1, we can “change the enrichment of C along
F”, to produce a category F C enriched in V1. Here, we have a category Poly
˚
enriched in Poly, and a (pseudo) functor Gen : Poly Ñ Cat. Thus we can
produce a category Gen Poly enriched in Cat — that is, a bicategory. We call
˚
Gen Poly generative Poly. (This is animation: change of enrichment along a
˚
systems theory.)
The objects of Gen Poly are polynomials, and the hom-category from p
˚
to q is Genprp,qsq. Thus a 1-morphism p Ñ q is a generative model on rp,qs
and a 2-morphism is a corresponding morphism of systems. If we have a model
pÑq and a model q Ñr, we cancompose them using the internal composition
structure. We will see below (§B.3) that this is a precise generalization of what
happens in deep/hierarchical active inference that allows for richer situations
like “agents that manage agents”.
B Exemplification
B.1 APIs as polynomial interfaces
Polynomial functors are closely related to trees [10] and tree-structured data,
like typed syntax [11]: the allowed inputs to a formal operation depend on the
operationinquestion,anditsoutputmaybepassedasaninputtoasubsequent
operation, so long as the types match. Thus, a formal grammar corresponds to
a polynomial functor p, and the set of p-terms with inputs in a set X is the
set ppXq; an interpretation of the syntax in a set Y is then given by a function
ppXqÑY.
In this way, if we have a computer application programming interface (API)
or domain-specific language (DSL), we can encode its interaction pattern as
a polynomial functor p; and if we wish to construct an artificial agent that
interacts with the corresponding computer system, we can equip it with an
interface derived from p.
As a simple example, we might consider a ‘calculator’ language with two
binaryoperationst`,ˆu,oneunaryoperationt´u,andR-manyconstants.This
wouldcorrespondtothepolynomialfunctorp“t`,ˆuy2`t´uy`R.Amachine
thattakesanexpressionwithinputsinX andoutputs arealnumbercouldthen
have the interface RypX; and a model of such a machine with
We note that this interface is, in the end, monomial. But if we had a more
complex language with different possible output types, we could encode these
as a family of polynomials tp
j
u, yielding a machine with interface
j
O
j
ypjXj,
where O is the output type for p .
j j
ř
14 T. St Clere Smithe
Finally, let us note that this short section only scratches the surface of the
the connection between polynomial interfaces and typed languages.
B.2 Typed policies, structured spaces: actions as morphisms
Inclassicalactiveinference,apolicyisasequenceofactions.Becauseallactions
arevalidinallstates(asnecessitatedbythemonomialformalism),anysequence
ofactionsisavalidpolicy.Instructuredactiveinference,onlycertainactionsare
valid at eachstate,so only certainsequences constitute valid policies.Following
the link between polynomial functors and typed languages sketched in the
preceding section, one could say that, in structured active inference, policies
are typed: they are sequences of composable actions.
Insomesituations,this resultcanbe strengthened:everycategoryC yieldsa
polynomial c“
x:C0
y y:C0 Cpx,yq whose configurations are the objects of C and
whose actions at each ořbject x are the morphisms out of x. We can think of a
ř
categoryasanabstractstructuredspace:morphismsoutofxcorrespondtopaths
awayfromx. Alternatively,we canthink ofa categoryasa (non-deterministic 6 )
automaton,whosestatesaretheobjects,andwhosetransitionsoutofeachstate
x are the morphisms out of x. In such a setting, a policy really is a composable
sequence of morphisms.
We emphasize that this is a powerful strengthening of the classicalnotion of
policy.
Onthepracticalside,thisstrengtheningallowsustoapplyactiveinferenceto
manipulatestructuredcontextsinaprincipledway.Anysuchstructuredcontext
may usually be expressed in a categorical way, and using this homoiconicity,
we may attach a structured active inference agent to it. In this way, structured
agentsmaymanipulatetheirown(orotheragents’)structure,therebyanswering
the question posed at the opening of this extended abstract. We will consider
this ability in more detail below (§B.4).
On the ethical side, the strengthened notion of policy constitutes a step
towards safer artificial agents, first because policies may be type-checked,
and second because categories often come with an “internal logic”, in which
propositionsmay be formulated,and againstwhichpolicies may be verified.We
will sketch more in this area below (§B.5).
B.3 Hierarchical agents: systems that manage systems
In §A.8, we indicated that structured active inference extends naturally to
‘nested’ systems of agents, including to the special case of individual agents
witha‘deep’orhierarchicalstructure,byextendingtheinterfaceofagenerative
model from p – ry,ps to rq,ps for some polynomial q. Here, we sketch how this
plays out.
6 If we work with categories enriched in weighted sets, meaning each morphism is
equipped with a weight, then we can think of such a category as representing a
stochastic automaton; or as havingpaths equippedwith a length.
Structured ActiveInference 15
The basic idea is to see q as encoding the interface(s) of systems that may
be nested within p, just as a dependent lens q Ñp encodes the wiring of q into
p.Thepolynomialq mightitselfbe composedasthe tensorofanumberofother
polynomials,suchasq “q bq bq .ThenasysteminGen Polypq bq bq ,pq
1 2 3 ˚ 1 2 3
couldbeunderstoodasonethatbuildsahigh-levelagentoutofthreelower-level
ones. We could think of such a system as a ‘manager’ for the tq u systems,
i
bringing them together to form a ‘collective’ with interface p. Then, if we had
three lower-levelsystems ty Ñq u, we could tensor them together and compose
i
them with the manager q bq bq Ñp to instantiate the collective y Ñp.
1 2 3
Of course, an active inference agent is composed of a system and its dual
(§A.7), so to achieve a compositional description of nested agents, we need to
incorporate both parts of the structure. This is easily done.
Definition B1. Let the bicategory Agent be the ‘diagonal’ sub-bicategory of
Gen PolyˆpDMoore Polyqop whose objects are pairs pp,pq of two copies of a
˚ ˚
polynomial p; we will write these objects simply as p. Additionally, restrict the
statespacesofthe1-cellstobepairspS,DSqwhereSisaset.Thusa1-morphism
q Ñ p is a pair of a model in Gen Polypq,pq and a corresponding controller in
˚
DMoore Polypp,qq.
˚
Let us consider then a ‘manager’ agent ByC b DyE Ñ OyA; recall that
ByC bDyE –pBˆDqyCˆE. Such an agent consists of:
(a) a state space S;
(b) three output maps (‘likelihoods’):
(i) S ˆB ˆD Ñ O, predicting a high-level observation in O, on the basis
of the state and the low-level predictions/observations in B and D;
(ii) S ˆ B ˆ D ˆ A Ñ C, returning a low-level action in C (for the left
low-level agent), on the basis of the state, the low-level observations,
and the high-level action in A;
(iii) S ˆB ˆD ˆA Ñ E, returning a low-level action in E (for the right
low-levelagent),onthebasisofthestate,thelow-levelobservations,and
the high-level action in A;
(c) atransition channel SˆBˆDˆAùS,updatingthestate,givenlow-level
observations and high-level action;
(d) generative processes for both low-level agents’ observations, on the basis of
the state and the high-level observation;
(i) DSˆO ÑB, for the left low-level agent;
(ii) DSˆO ÑD, for the right low-level agent;
(e) a high-level policy, DSˆOˆCˆE ÑA, possibly depending on all of: the
state, the high-level observation, and the low-level actions;
(f) an inference process, DS ˆO ˆC ˆE Ñ DS, inferring the current state
given a prior, a high-level observation, and low-levelactions (which we take
to be observed).
As we have seen above (§A.7), an agent with interface ByC is constituted by
(a) a state space T,
16 T. St Clere Smithe
(b) an output map T Ñ B (yielding the low-level agent’s prediction of the
high-level agent’s generative process),
(c) a transition channel T ˆC ùT,
(d) a policy DT ˆB ùC, and
(e) an inference process DT ˆB ùDT.
A similar structure is of course obtained for the other low-level agent (on CyE).
Then the composition of the low-level agents to the manager agent proceeds by
passing:
(a) the manager’s low-level action outputs to the low-level agents’ transition
models;
(b) the low-level agents’ predicted observations to the manager’s transition
model;
(c) the manager’s generated observations to the low-level agent’s policies and
inference processes; and
(d) the low-level agents’ actions (selected by their policies) to the high-level
agent’s policy and inference process.
Put together, this composite agent has the interface OyA; the internal composi-
tion is hidden within this “generalized Markov blanket”.
We emphasize that all of this compositional structure is obtained from the
rulesoftheAgentconstruction;inprinciple,itisfullyautomatable.Moreover,it
extendsgracefullytoarbitrarylevelsofnesting,withcomplexinternalstructure.
Deep active inference is a special case. We end this section by sketching
how the Agent construction captures deep active inference, in the sense of
Friston et al. [8].
A deep active inference agent has a hierarchy of generative models: the
outputs (the ‘predictions’) at one level act on the level below, where they are
takenasa‘control’or‘policy’input.(Itmayalsobethecasethateachlevelalso
produces predictions of other observations, but these are effectively extraneous,
in that they have no direct effect on the evolution of the model.)
This pattern is easily captured by a sequence of 1-cells
y ÑyA1¨¨¨ÑyAi ÑyAi`1¨¨¨
in Agent, where the increasing index i corresponds to increasingly high levels
in the hierarchy. We leave it to the reader to write out the details and check
the correspondence. (One may simply recapitulate the example above, taking
B “ D “ E “ O “ 1 and letting C,E correspond to two levels A ,A of the
i i`1
action hierarchy.)
B.4 Meta-agents: changing internal and external structure
In §B.2, we explained that categorical structures can be encoded in polynomial
interfaces. Because structured active inference collects agents, and their struc-
ture, into categories,this makes it able to act on itself.
Structured ActiveInference 17
Crucially, the models Genppq over each interface p form a category, whose
morphismsrepresentchangesofinternalstructure.And the morphismsbetween
interfaces (of course) represent changes of interface.
These two types of change can be bundled together by applying the
Grothendieck construction to Gen. This yields a category Gen whose objects
are triples pp,S,ϑq where p is an interface in Poly and pS,ϑq is a model in
ş
Genppq.A morphismpp,S,ϑqÑpp1,S1,ϑ1q in Gen is thenapair ofa dependent
lens ϕ : p Ñ p1 and a morphism of systems GenpϕqpS,ϑq Ñ pS1,ϑ1q. Thus
ş
the morphisms of Gen are morphisms of interfaces along with compatible
morphisms of systems.
ş
One could then consider an agent whose interface combines the polynomial
induced by Gen with observations on “the current interface”, as in
ş
pp1qy pp1,S1,ϑ1q Gen pp,S,ϑq,pp1,S1,ϑ1q .
pp,S,ϑq: Gen ř ş ` ˘
ÿ
ş
Such an agent would predict both a structure for an agent along with the
observations that that agent should expect, and its policy would be a sequence
ofchanges-of-structure(whichincludestandardoperationslikemodelexpansion
and model reduction). By minimizing free energy, one might imagine that such
anagentwouldseekastructurethatbestexplainsitsobservations:itwouldbea
structure-learningagent.Planning(policysearch)forsuchanagentwouldinvolve
exploring different potential structures, which we can interpret as explanations
for the observed data.
This approachcan be extended to hierarchicalagents,turning Agent into a
double category7. But we will not expand on this here, except to note that
this brings structured active inference even closer to other developments in
categoricalcybernetics [12–14]. We leave this confluence to future work.
B.5 The logic of systems: goals, constraints, and safety
Let us end this tour of structured active inference with a note on the logic of
systems. We indicated in §A.6 that agents’ state priors can be understood as
a basic example of a logical structure. This is due to the (indexed) forgetful
functor U : Gen Ñ Gen. All that is required to bring logic into a categorical
˚
situation is the ability to define a notion of fibration in that setting; and indeed
the setting of categorical systems theory is sufficiently rich to do so (because
systems theories collect into a 2-category).
TheforgetfulfunctorU isasimpleinstanceofafibrationofsystemstheories.
In a logical context, one thinks of the fibre U over an object ϑ as a category
ϑ
of ‘predicates’ over ϑ. The reindexing operation entailed by the fibration may
be interpreted as substitution of terms inside the formal expressions of these
7 Thehorizontalmorphismswouldbeagents;theverticalmorphismswouldbechanges-
of-interface; and the squares would be changes-of-structure compatible with the
corresponding changes-of-interface.
18 T. St Clere Smithe
predicates. When the situation is sufficiently rich, these substitution functors
have left and right adjoints which correspond to existential and universal
quantification in these predicates.
We will not elaborate the details of the categorical logic of systems further
here, referring the interested or intrepid reader instead to Jacobs [2] (and the
task of translating that workto the systems-theoreticsetting). But we will note
that it is of course possible to produce more interesting fibrations of predicates
than U, with more expressive capability; and we will be able to use these to
specify notonly goalsfor systems,but alsoconstraintsontheir behaviour(their
policies). Moreover, because these logics are indexed by the systems’ patterns
of interaction, we will be able to judge the extent to which such constraints are
satisfied in different interactioncontexts8. We expect that these abilities will be
useful for distributing shared goals amongst collectives of agents, and crucial in
the development of verifiably safe (‘safeguarded’ [3]) AI systems.
8 This is formally much like the situation with fixed points: the fixed points of a
compositedynamicalsystemmaybecomputedfromthefixedpointsofthecomposite
systems, plus knowledge of their pattern of interaction [15]

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Structured Active Inference (Extended Abstract)"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
