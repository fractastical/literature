=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Active Inference in String Diagrams: A Categorical Account of Predictive Processing and Free Energy
Citation Key: tull2023active
Authors: Sean Tull, Johannes Kleiner, Toby St Clere Smithe

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Abstract: We present a categorical formulation of the cognitive frameworks of Predictive Processing (PP) and
Active Inference, expressed in terms of string diagrams interpreted in a monoidal category with copying
and discarding. This includes diagrammatic accounts of generative models, Bayesian updating, percep-
tion, planning, active inference, and free energy. In particular we present a diagrammatic derivation of
the formula for active inference via free energy minimisation, and establish a compositiona...

Key Terms: string, categorical, energy, processing, observations, inference, framework, active, predictive, free

=== FULL PAPER TEXT ===

Active Inference in String Diagrams: A Categorical
Account of Predictive Processing and Free Energy
Sean Tull1,2, Johannes Kleiner2,3,4, and Toby St Clere Smithe5,6
1Quantinuum
2Association for Mathematical Consciousness Science
3Ludwig Maximilian University of Munich
4University of Bamberg
5Topos Institute
6VERSES Research
Abstract
We present a categorical formulation of the cognitive frameworks of Predictive Processing (PP) and
Active Inference, expressed in terms of string diagrams interpreted in a monoidal category with copying
and discarding. This includes diagrammatic accounts of generative models, Bayesian updating, percep-
tion, planning, active inference, and free energy. In particular we present a diagrammatic derivation of
the formula for active inference via free energy minimisation, and establish a compositionality property
forfreeenergy,allowingfreeenergytobeappliedatalllevelsofanagent’sgenerativemodel. Asidefrom
aimingtoprovideahelpfulgraphicallanguageforthosefamiliarwithactiveinference,weconverselyhope
that this article may provide a concise formulation and introduction to the framework.
1 Introduction
Predictive processing (PP) is a framework for modelling cognition and adaptive behaviour in both biolog-
ical and artificial systems [WM17, Hoh20]. A prominent sub-field is the programme of Active Inference,
developedbyFristonandcollaborators[SFW22,PPF22,FFR+17,SBPF21], whichaimstoprovideaunified
understandingofcognitionandactionwhichcanbeappliedatmanylevels, fromasingleneurontoanentire
brain or organism. More specifically, active inference gives a proposal for how a cognitive agent represents
its own beliefs about the world, how it updates these beliefs in light of new observations, and how it chooses
the actions it takes, with the latter ultimately leading to new observations.
Central to the framework is that an agent possesses a generative model which explains its observations
causally in terms of both hidden states of the world and its own actions. Note that this model is internal to
the agent, and typically distinct from the ‘true’ causal process in the world which produces the observations.
After receiving an observation, the agent may update this generative model to determine likely hidden states
which caused the observation (the process of perception) and choose its actions (the process of planning). In
active inference, both forms of updating are carried out together through a form of approximate Bayesian
inference, by minimising a quantity known as free energy [FKH06, Fri10].
Whileactiveinferenceseeksaprincipledaccountofcognition, atpresentitsformalisationcanseemfairly
complex, andtherearevariousaspectswhichdonotfollowimmediatelyfromsimplyapplyingthedefinitions
to a given generative model. Conceptually clear formal accounts of the framework would be desirable to
simplify the theory and address these issues, as well as for applications within AI.
One hope for such a formal account would be for it to be both compositional and graphical. Indeed the
generative models in PP are highly structured, often given as ‘hierarchical models’ [DVF17] which are best
represented diagrammatically in terms of probabilistic graphical models such as Bayesian networks. While
there has been support for, and steps towards, a graphical account of active inference [FPdV17], so far the
graphical aspects only formally describe the structure of a generative model, while other aspects such as
1
3202
guA
1
]TC.htam[
1v16800.8032:viXra
updating and free energy are still treated through traditional probabilistic calculations, and only informally
in diagrams.
Recently however, fully formal diagrammatic methods have been developed for both describing Bayesian
networks and carrying out probabilistic reasoning about them. These approaches are based on (monoidal)
category theory and its associated graphical language of string diagrams [PZ23]. Category theory has been
applied across the sciences as a general mathematics of interacting processes, including within probability
theory [CS12, CJ19], causality [JKZ19, FK23, LT23], game theory [GHWZ18], machine learning [FST19,
SGW21],quantumcomputing[AC04]andnaturallanguageprocessing[CCS08]. Inparticularamajorongoing
development is in the study of probabilistic processes in terms of cd-categories (and ‘Markov categories’),
which allow one to carry out probabilistic reasoning entirely through string diagrams [Fri20].
In this work we give a full categorical account of predictive processing and active inference in terms of
string diagrams, interpreted in cd-categories. In doing so we aim to give a conceptually clear account of the
main features of the framework: generative models, Bayesian updating (including with soft observations),
perception, action planning, and their combination in active inference, and both variational and expected
free energy.
A highlight is a fully graphical derivation of the well-known formula for active inference in terms of
minimisationoffreeenergy. Whilethisisacentralresultwithinactiveinference,itsusualjustificationismore
heuristic in nature. Here we instead derive the free energy formula purely graphically from a diagrammatic
account of active inference itself, providing what we argue is the most transparent account of this result
known so far.
The categorical perspective also naturally leads us to consider more novel aspects of active inference.
These include the definition of open generative models (essentially from [LT23]) which are generative models
coming with ‘inputs’, allowing them to serve as the building blocks of an overall generative model.
We also introduce a notion of variational free energy for open models which allows us to establish the
desirable property that free energy is compositional. Namely, a system with an overall generative model
composed from sub-models may minimise global VFE by minimising VFE locally within each component.
This is a crucial fact in order to apply free energy as proposed to all levels of a system, say from a whole
brain down to its individual neurons.
Overall, we hope that our diagrammatic accounts of PP can provide a conceptually clear view of the
framework, and also a natural language for reasoning within it. Indeed, as argued for example in [LT23]
and elsewhere[JKZ19] diagramsin cd-categories provide anatural way toboth representcausal (generative)
models, aswellasreasonaboutthem. Aswedemonstrateheretheyarealsonaturalfordescribingthestruc-
ture of active inference, including free energy. Aside from aiming to provide a helpful graphical language for
those familiar with active inference, we conversely hope that this article may provide a succinct introduction
to PP for those already familiar with string diagrams and categorical reasoning.
Further motivations Though primarily a framework for cognition, various proposals have been put for-
ward for how predictive processing may be related to consciousness [WM17]. In previous work, two of the
authors developed a categorical account of the Integrated Information Theory of consciousness, again essen-
tially using cd-categories [TK21, KT21] and based on the work here we hope to give a categorical account of
how consciousness may be accounted for within PP [Dea21, HS20]. We also see this work as a piece of the
programme of Compositional Intelligence, which explores how categorically structured models and processes
can be applied to (artificial) intelligence. Specifically, PP may be seen as a proposal for how compositional
intelligence manifests in biology; that is, how biological systems may employ compositionality to carry out
intelligent and adaptive behaviour.
Active inference can also be understood as an alternate proposal to reinforcement learning (RL) for how
agents can learn adaptive behaviour, and shares similar features including the role of probabliistic models
and inference [TMSB20]. It differs from conventional RL by replacing an explicit reward function with the
aim of maximizing evidence for a probabilistic model, where the agent’s preferences are now encoded in the
model’s prior distribution [FDK09].
Related work This work can be seen as a part of the growing field of ‘categorical cybernetics’ [Smi21b,
CGHR21], including previous work from one of the authors on compositional accounts of Bayesian updating
[Smi20] and of active inference in terms of ‘statistical games’ [Smi21a, Smi22]. It differs from previous
2
Ot+1
A
Ot
St+1
A
B
Ot−1 St
A
B
St−1
P
E
D
Figure 1:
A generative model diagram from the recent book Active Inference by Parr, Pezzulo and Friston [PPF22]
(left) and the equivalent string diagram representation (right) (though replacing the informal EFE term G
with the prior E).
works by directly formalising the active inference framework itself, and by working explicitly graphically
within the simple string-diagrammatic setting of cd-categories, with the aim of supplying a simple abstract
characterization of active inference agents.
In this way the work is a part of a general movement in applying string diagrams in cd-categories to
probability theory and causal reasoning. A categorical account of Bayesian inversion was first given by
Coecke and Spekkens in [CS12], and then within cd-categories by Cho and Jacobs [CJ19], with further
developments in categorical probability by Fritz [Fri20]. Our diagrammatic account of generative models is
precisely that given for causal models in part by one of the authors in [LT23], which builds on the earlier
categorical treatments of (causal) Bayesian networks by Fong [Fon13], Jacobs et al [JKZ19] and others e.g.
[FK23]. Indeed, as an agent’s explanation for the observations it receives from the world, a generative model
is ultimately a causal model [Pea09], though this is not often stressed in the literature.
The two forms of soft Bayesian updating treated here we first studied by Jacobs in [Jac19]. The specific
treatment of conditioning in cd-categories used here is from [LT23]. Cd-categories with (non-unique) condi-
tionals have also been recently studied as ‘partial Markov categories’ in [DLR23], along with both notions
of updating. Our treatment of free energy refers to the KL divergence of distributions; we note that an
axiomatic treatment of Markov categories coming with divergences on their morphisms has recently been
given by Perrone in [Per22].
Within active inference itself, graphical aspects have been increasingly prominent, with discussion of the
‘graphical brain’ in [FPdV17]. In such works it is argued that one may describe models as (non-directed)
Forney Factor Graphs (FFGs) [DVF17]. However, generative models are inherently directed, going from
states to observations with the other direction being intractable to compute exactly. Thus it is more natural
totreatmodelsusing(generalisationsof)directedBayesiannetworks. NonethelesswenotethoughthatFFGs
derived from a model still have a role when minimising VFE via ‘message passing’ algorithms [PMKF19].
Interestingly, while a Bayesian network is typically depicted as a DAG (with only the variables labelled),
onemayarguethediagramsinactiveinferencehavebeennaturally‘converging’ontheirstringdiagrammatic
representation, which also includes labels on the channels; see Figure 1. We claim that the advantage of
string diagrams beyond DAGs is in allowing one to both represent and reason about the model in the same
formalism.
We note that the diagrams in PP are at times only semi-formal, including aspects such as the free energy
which are not strictly part of the generative model. One may see this work as a step towards the shared goal
of representing formally all aspects of PP within one language of diagrams.
Structure of the article We begin in Section 2 by introducing cd-categories and their diagrammatic
accountofprobabilitytheory. WethenapplythesetointroducefromscratchthekeyaspectsofPP:generative
modelsasBayesiannetworks,andtheirgeneralisationtoopengenerativemodelsinacd-category(Section3),
3
(Bayesian) updating of generative models from observations (Section 4 ), perception and planning (Section
5) and their combination in exact active inference (Section 6). We then discuss free energy (Section 7) and
give a graphical derivation of active inference via free energy minimisation (Section 8). In Section 9 we then
introduce free energy for open models using a graphical formalism of ‘log-boxes’ and use this to establish the
compositionality property of free energy. Finally we discuss future work in Section 10.
Acknowledgements We thank Robin Lorenz for helpful discussions and development of the treatment
of causal models used here. This research was supported by grant number FQXi-RFP-CPW-2018 from
the Foundational Questions Institute and Fetzer Franklin Fund, a donor advised fund of the Silicon Valley
Community Foundation. Sean Tull would also like to thank Quantinuum for their generous support in this
research. Johannes Kleiner would like to thank the Mathematical Institute of the University of Oxford for
hosting him while working on this research.
2 Categorical Setup
Let us begin by introducing the graphical treatment of probabilistic processes in terms of string diagrams,
developed by numerous authors [CS12, CJ19, Fri20]. Formally, these correspond to working in a ‘monoidal
category’ormorespecificallya‘cd-category’,butinpracticeonemayavoidmathematicaldetailsandsimply
work with the diagrams themselves. Though cd-categories are very general, in this article it suffices to
consider the category MatR+ of R+ valued finite matrices, introduced shortly in Example 1.
A category C consists of a collection of objects X,Y,... and morphisms or processes f: X →Y between
them,whichwecancomposeinsequence. InstringdiagramswedepictanobjectX asawireandamorphism
f: X →Y as a box with lower input wire X and upper output wire Y, read from bottom to top.
Y
f
X
Given another morphism g: Y →Z we can compose them to yield a morphism g◦f: X →Z, depicted as:
Z
Z g
g◦f = Y
f
X
X
Each object X also comes with an identity morphism id : X →X depicted as a blank wire:
X
X X
id =
X
X X
The identity leaves any morphism alone under composition, that is id ◦f =f =f◦id for any f: X →Y.
Y X
Formally, a symmetric monoidal category (C,⊗,I) is a category C with a functor ⊗: C×C → C, and
natural transformations which express that ⊗ is suitably associative and symmetric, with a distinguished
unit object I [Coe06]. All of these aspects however are expressed most simply in diagrams.
Firstly, the tensor ⊗ allows us to compose any pair of objects X,Y into an object X ⊗Y, depicted by
placing wires side-by-side.
X⊗Y X Y
=
X⊗Y X Y
4
Givenmorphismsf: X →W andg: Y →Z wecansimilarlyformtheir‘parallelcomposite’f⊗g: X⊗Y →
W ⊗Z as below.
W ⊗Z
W Z
f ⊗g = f g
X⊗Y X Y
In text we will at times omit the tensor symbols and write e.g. ‘f from X to Y,Z’ or f: X →Y,Z in place
of f: X →Y ⊗Z.
Thetensorissymmetricsowecan‘swap’pairsofwirespasteachother,suchthatswappingtwicereturns
the identity, and boxes carry along the swaps as below.
W Z W Z
f g
=
g f
Y X Y X
We also have a distinguished unit object I whose identity morphism we depict simply as empty space, and
denote by 1.
I
= = 1 (1)
I
Intuitively, tensoring any object by the unit simply leaves it invariant. The unit allows us to consider
morphisms with ‘no inputs’ and/or ‘no outputs’ in diagrams. A morphism ω: I → X is called a state of X,
depicted with no input. An effect on X is a morphism e: X → I, depicted with no output. A morphism
r: I→I, drawn with no input or output, is called a scalar.
X
e
ω r
X
In particular the ‘empty space’ diagram (1) is the scalar 1=id.
I
Thecompositions◦,⊗satisfyaxiomswhichmustbeconsideredwhenworkingsymbolicallybutaretrivial
inthegraphicallanguage. Anexampleisassociativityofcomposition(h◦g)◦f =h◦(g◦f),whichisautomatic
fromsimplydrawingthreeboxesinsequenceonthesamewire. Similarlytherule(f⊗g)◦(f′⊗g′)=(f◦f′)⊗
(g◦g′),displayedintheleftidentitybelow,andthe‘interchangelaw’(f⊗id)◦(id⊗g)=f⊗g =(id⊗g)◦(f⊗id),
displayed in the right identity below, amount to letting us freely slide boxes along wires.
f g f g
f g
= = f g =
g f
f′ g′ f′ g′
Let us now introduce our primary example category in this article.
Example 1. In the category MatR+ of positive valued matrices, the objects are finite sets X,Y,... and the
morphisms M: X → Y are functions M: X ×Y → R+ where R+ := {r ∈ R | r ≥ 0}. Equivalently such a
function is given by an ‘X×Y matrix’ with entries M(y |x):=M(x,y)∈R+ for x∈X, y ∈Y.
Y
M :: (x,y) (cid:55)→ M(y |x)
X
5
Composition of M: X →Y and N: Y →Z is given by summation over Y:
Z
N
(cid:88)
Y :: (x,z) (cid:55)→ N(z |y)M(y |x)
M y∈Y
X
The tensor ⊗ is given on objects by the Cartesian product X ⊗ Y = X × Y, and on morphisms by the
Kronecker product, i.e. the usual tensor product of matrices:
W Z
M N :: ((x,y),(w,z)) (cid:55)→ M(w |x)N(z |y)
X Y
The symmetry is simply the isomorphism X ×Y ≃ Y ×X. The unit object I = {⋆} is the singleton set. A
state of X is then equivalent to a positive function on X:
X
:: x (cid:55)→ ω(x)
ω
where ω(x) := ω(x | ⋆). Similarly, an effect e on X is also equivalent to a positive function on X via
e(x):=e(⋆|x).
e
:: x (cid:55)→ e(x)
X
Finally, a scalar is precisely a positive real r ∈R+.
2.1 Cd-categories
Many aspects of probability theory can be treated entirely diagrammatically, by noting that categories such
as MatR+ come with the following further structure.
Definition 2. [CJ19] A cd-category (copy-discard category) is a symmetric monoidal category in which
each object comes with a specified pair of morphisms
called copying and discarding, respectively, which satisfy the following:
= = = =
The choice of these morphisms is moreover ‘natural’ in that the following hold for all objects X,Y.
= = = 1 (2)
X⊗Y X Y X⊗Y X Y I
6
Thanks to these axioms for copying, we can unambiguously define a copying morphism with n output
legs, for any n≥1, via:
...
...
:=
with the n=0 case defined to be discarding .
The presence of discarding allows us to identify the truly ‘probabilistic’ processes in a cd-category. We
say that a morphism f is a channel when it preserves discarding, as below.
f =
In particular, we call a state ω normalised when the following holds. For an explanation of why this gives
the usual definition, cf. Example 3 below.
= 1
ω
Here we will often call a normalised state ω of X a distribution of X, even when working in a general
cd-category 1. We also call a normalised state of X⊗Y a joint distribution over X,Y.
A cd-category in which every morphism is a channel, or equivalently is the unique effect on any object,
is called a Markov category [Fri20]. Given any cd-category C, its subcategory C of channels always
channel
forms a Markov category.
Discarding allows us to ‘ignore’ certain outputs of a process. Given any morphism f from X to Y,Z, its
marginal X →Y is the following morphism:
Y
Z
f
X
Let us see how these features describe discrete probability theory within our example category.
Example 3. MatR+ is a cd-category. Copying on X is given (y,z |x)=δ
x,y,z
with value 1 iff x=y =z
and 0 otherwise. Discarding on X is given by the function with x (cid:55)→ 1 for all x ∈ X. Hence a state ω is
normalised, i.e. forms a distribution on X, precisely when it forms a probability distribution over X in the
usual sense, i.e. its values sum to 1.
X = (cid:88) ω(x) = 1
ω
x∈X
More generally, a process M: X → Y is a channel iff it forms a probability channel, or equivalently a
stochastic matrix, meaning that it sends each x ∈ X to a normalised distribution M(y | x) over Y. Indeed
we have that:
Y
(cid:88)
M :: x (cid:55)→ M(y |x)
y
X
1Thisistoavoidconfusionwiththeusualuseoftheterm(hidden)‘state’inPP.
7
Hence M is a channel iff this effect is constant at 1, i.e. for all x we have
(cid:88)
M(y |x)=1
y∈Y
In typical probability theory, such a channel is also often called a ‘conditional probability distribution’
P(Y |X) with values denoted P(y |x):=P(Y =y |X =x) for x∈X, y ∈Y. The subcategory of channels
in MatR+ is the Markov category FStoch of finite Stochastic matrices.
Letusseehowafewfeaturesofprobabilitytheoryappearindiagrams. Firstly, foranyX,Y, adistribution
ω on X ⊗Y corresponds to a joint distribution over X,Y (left-hand below). In particular given a pair of
distributions ϕ,σ over X,Y, the distribution ϕ ⊗ σ corresponds to the resulting product distribution over
X×Y, with X and Y independent from each-other (right-hand below).
X Y
X Y
ω ϕ σ
A general channel as below represents a probability channel P(Y ,...,Y |X ,...,X ).
1 m 1 n
Y Y
1 m
...
P
...
X X
1 n
Marginalisation of any morphism corresponds to the usual notion in probability theory, given by summation
over the discarded object.
Y
X
Z
Y
(cid:88) (cid:88)
::x(cid:55)→ ω(x,y) M ::(x,y)(cid:55)→ M(y,z |x)
ω
y∈Y z∈Z
X
Finally we observe that for any effect e: X → R+ and distribution ω the scalar e◦ω corresponds to the
expectation value of the function e according to the probability distribution ω.
e
(cid:88)
E e(x) = X = e(x)ω(x)
x∼ω
ω x∈X
2.2 Sharp states and caps
The copying morphisms in a cd-category allow us to identify those states which are really ‘deterministic’
[Fri20]. We call a state x sharp, and depict it with a triangle as below, when it is copied by , that is:
X X
X X
= (3)
x x
x
In many categories there is a corresponding effect for each state, playing an important role for sharp states,
thanks to the following feature. We say that C has caps when each object comes with a distinguished effect
8
on X⊗X depicted and satisfying:
= = = (4)
and such that the following holds for all objects X,Y:
=
X⊗Y X⊗Y X Y X Y
Intuitively, the cap is an effect which checks if its two input wires are ‘in the same state’. The first equation
in(4)expressesthatthiscomparisonissymmetric,andtheremainingtwothatitiscompatiblewithcopying;
for example the second says that each input when copied is equal to its copy.
Practically, caps allow us to ‘turn outputs into inputs’. In particular, for each state ω we can define a
corresponding effect by ‘flipping ω upside-down’:
ω
= ω (5)
When ω = x is a sharp state, we call this effect sharp also. One may verify that it is the unique effect
satisfying the following.
x
x x
= 1 = (6)
x x
Caps are particularly useful in diagrammatic reasoning when they are cancellative, meaning that:
f = g =⇒ f = g
for all morphisms f,g.
Example 4. MatR+ has cancellative caps. Each point x∈X corresponds to a normalised sharp state on X
which we again denote by x, given by the point probability distribution δ at X.
x
X (cid:40)
1 x=y
:: y (cid:55)→
x 0 otherwise
The corresponding effect is given by the function δ also. Each cap is given by (x,y) = δ . We note a
x x,y
useful fact that for any morphism M: X →Y its values M(y |x) can be given diagrammatically as below.
y
M(y |x) = M
x
Every sharp state on X is of the above form for some x ∈ X, or else given by the zero state 0 defined
by 0(x) = 0 for all x ∈ X. The only sharp scalars are 0 and 1. Note that a general state ω, even when
normalised, is not copyable.
X X
X X
̸=
ω ω
ω
9
Indeed the left-hand side is the distribution (x,y) (cid:55)→ ω(x)δ , while the right is (x,y) (cid:55)→ ω(x)ω(y), which
x,y
differ unless ω is zero or ω =δ for some x∈X.
x
2.3 Normalisation
Ingraphicalprobabilisticreasoningitisalsousefultobeabletonormalisestatesandprocesses. Wesaythat
a cd-category C has normalisation when it comes with a rule assigning each morphism f: X → Y a new
morphism called the normalisation of f, depicted by drawing a dashed blue box:
f (7)
such that these normalisations satisfy various axioms, of which we sketch a few here. For a full definition see
[LT23]. Firstly, a general state ω is equal to a scalar multiple of its normalisation. In particular in MatR+
when the state is non-zero, this means that its normalisation is indeed normalised in our above sense, i.e. a
distribution.
ω = ω ω (8)
For a general morphism f its normalisation is given on each sharp state x by normalising f ◦x.
f = f (9)
x
x
These two rules combine to give the following equation without explicit reference to states.
f = f f (10)
Notethatiff wealreadyachannelthenitwouldbeequaltoitsnormalisation,asinthiscasewecanpassing
the discarding through f and then the copy map above. In general normalisations satisfy a few graphical
conditions including the following.
f f
f g = f g = (11)
Further, for all morphisms f and channels g we have:
g g
= (12)
f f
10
and for all sharp states x and morphisms f we have the following.
f = f
x
x
For a full account of the properties of normalisation see [LT23]. We note that for a general morphism f,
itsnormalisationisnotnecessarilyachannelbutonlya‘partialchannel’2. Intermsofstates,thisisbecause
its sends each sharp state x either to a normalised state, or else to 0 if f ◦x=0. However in MatR+ it will
be a channel provided f has ‘full support’, so that f ◦x is non-zero for all non-zero sharp states x.
Throughout the article, the following notation will be useful. For any set X and function f: X →R+ let
us write
f(x)
Normf(x):=
x (cid:80) f(x′)
x′∈X
whenever this is well-defined, i.e. the denominator is finite and non-zero.
Example 5. MatR+ has normalisation. On each object X the zero state 0, given by 0(x)=0 for all x∈X,
is defined to have normalisation 0. For any non-zero state ω we indeed have
X
ω :: x (cid:55)→Normω(x)
x
For a general morphism M: X →Y the normalisation is given by:
Y
(cid:40) (cid:80)
Norm M(y |x) if M(y |x)̸=0
M :: (x,y)(cid:55)→ y y∈Y
0 otherwise
X
As a result if M has full support, so that M(y | x) ̸= 0 for some y, for all x, then its normalisation is a
probability channel.
2.4 Further cd-categories
Though we will not need them here, we note that the notion of a cd-category is much more general than
MatR+ , and give a few examples for those familiar with them. The category Rel whose objects are sets and
morphismsarerelationsisacd-category, asareitssubcategoriesPFunofsetsandpartialfunctionsandSet
of sets and functions, with the latter forming the channels in PFun.
There are also many more cd-categories of a ‘probabilistic’ nature, see for instance [Pan98, CJ19, Fri20].
In particular to treat general probability spaces (including ‘continuous probability channels’) one may work
in the category Kl(G) of measurable spaces X =(X,Σ ) and Markov (sub-)kernels f: X →Y, which send
X
each x ∈ X to a (sub-)probability measure f(x) over Y. Roughly, this means replacing all instances of
(cid:82)
summation Σ in MatR+ above with integration . Of particular interest in PP is the following subcategory,
though we will not work with it in detail in this article.
Example 6. [Fri20, Section 6] In the category Gauss the objects are spaces X = Rn and morphisms
M: X → Y are Markov kernels f: X → Y with densities of the form f(y | x) = η(y−Mx) for some fixed
Gaussian noise distribution η (independent of x) and linear map M: X → Y. This category models linear
processes with Gaussian noise. More general non-linear Gaussian processes are studied in PP under the
so-called ‘Laplace assumption’.
2Suchmorphismsarecalled’quasi-total’in[DLR23],wheremorphismssatisfying(10)arealsocalled‘normalisations’,though
arenotuniquelychosenunlikeourdefinition.
11
3 Generative Models
AcentralfeatureinPPisthateachcognitiveagentpossessesagenerativemodelwhichdescribestheirinternal
beliefs about how the observations they receives arise from hidden states of the world3. In its simplest form,
a generative model consists of a channel c: S →O describing how likely c(o|s) a given observation o∈O is
for each hidden state s∈S, along with a distribution σ over S describing prior beliefs about how likely each
state is.
However, generative models typically come with further compositional structure, relating various spaces
of observations and hidden states, as formalised by a Bayesian network (or more precisely a causal Bayesian
network, see later discussion), a probabilistic graphical model based on a directed acyclic graph (DAG).
There is in fact a close correspondence between DAGs and cd-categories, allowing us to describe and study
such models entirely in terms of string diagrams. This view also leads one to consider more general ‘open
generativemodels’,whichmaycomewith‘input’variables. Theseopenmodelscanbeusedtowhichdescribe
theindividualcomponentsofanoverallgenerativemodelintheusualsense. Formoredetailsontheapproach
used here, see [LT23].
We begin by relating DAGs with the following class of string diagrams.
Definition 7. [LT23] A network diagram is a string diagram D built from single-output boxes, copy maps
and discarding:
...
with labellings on the wires, such that any wires not connected by a sequence of copy maps are given distinct
labels, and each label appears as an output at most once and as an input to any given box at most once.
Such diagrams are best understood by examples, which we come to shortly. Before this, we note that
network diagrams are in fact equivalent to DAGs in the following sense. By an open DAG we mean a
finite DAG G with vertices V = {X ,...,X }, along with subsets I,O ⊆ V of input and output vertices,
1 n
respectively, such that each input vertex has no parents in G.
GivenanyopenDAGG,wemayconstructanequivalentnetworkdiagramfeaturingaboxc withoutput
i
X for each non-input vertex X . The box c itself has an input wire for each parent of X in G. In the
i i i i
diagram we copy the output of this box and pass it to each of the children of X , as well as an extra time if
i
X ∈O i.e. X is an output vertex of the DAG.
i i
...
...
Xi
Xi (cid:55)→ c
i
...
...
Y1 Y
k
Y1 Y
k
By construction, this yields a network diagram D from the inputs I to the outputs O of the DAG.
G
Conversely, given any such network diagram D we define an open DAG G =(G,I,O) with a vertex X ∈V
D
for each wire X in D, and with X ∈I,O iff it is an input (resp. output) to the diagram.
Inpracticethelabellingsoftheboxesarearbitrary,andweconsideranytwonetworkdiagramsequivalent
when they are the same up to the equations of a cd-category and box re-labellings. Then the above yields a
one-to-one correspondence between open DAGs and network diagrams [LT23, Sections 3,5].
Example 8. Consider the open DAG G over {X ,X ,X ,X } below, with output vertices O = {X ,X }
1 2 3 4 2 3
circled, and with no input vertices. The equivalent network diagram D is shown to the right. Note that the
G
3Notethatisdistinctfromwhatever‘true’externalprocessproducestheobservationsinreality,withthelatteroftencalled
the‘generativeprocess’todistinguishitfromtheagent’sown‘generativemodel’[PPF22].
12
labels of the boxes are arbitrary.
X3
X2
d
X
3
X4
c
X ⇐⇒
2
X1
X X a b
1 4
Example 9. The following depicts an open DAG over V = {X ,...,X } with outputs O = {X ,X } and
1 5 3 5
with inputs I = {X ,X } highlighted with special incoming arrows. To the right we show the corresponding
2 3
network diagram with the same inputs and outputs.
X5
X
5
c
X4
X
4
⇐⇒ b X3
X
1
X
2
X
3
X1
a
X2 X3
Wemaynowdefinegenerativemodelsthemselves,whichinvolvespecifyingactualchannelscorresponding
to the boxes in the network diagram.
An interpretation − of a network diagram D in a cd-category C consists of specifying an object X
i
for each wire X and c(cid:74)han(cid:75)nel f : X ⊗···⊗ X → X for each box f in D with inputs X ,...,X (cid:74)and(cid:75)
i 1 k 1 k
output X. (cid:74) (cid:75) (cid:74) (cid:75) (cid:74) (cid:75) (cid:74) (cid:75)
Definition10. [LT23]LetCbeacd-category. An opengenerativemodelinCisgivenbyanetworkdiagram
D along with an interpretation − in C. We call the objects corresponding to output wires observed and the
rest hidden. We call such a mo(cid:74)del(cid:75)closed when it has no inputs.
Note that an object of an open model may be both an input and output. In practice, we omit the −
symbols and for each wire X in the network diagram of a model denote the corresponding object X in(cid:74) C(cid:75)
also by X. Similarly for each box c in the diagram with output X we also write c for the corre(cid:74)spo(cid:75)nding
channel c .
(cid:74) (cid:75)
Remark 11. Formally, an open generative model in our sense is the same as an open causal model in the
sense of [LT23]; that is, both have the same mathematical definition. However a ‘generative model’ typically
refers to a causal model with the extra interpretation of being possessed by a cognitive agent.
Indeed, though not often stressed in the literature, a typical generative model in PP may be seen as a
causal Bayesian network, i.e. a causal model in the sense of Pearl [Pea09]. This means that the probability
channelswhichconstitutethenetworkdonotrepresentarbitraryrelationshipsbutinfact(beliefsabout)causal
ones, such as how observations are caused by (rather than merely correlated with) hidden states of the world.
For more discussion see Section 10.
Given any open generative model M we obtain an overall channel from its inputs to its outputs by
composing the channels of the model, i.e. viewing the (interpreted) network diagram as a single channel in
C. Often it is useful to also consider the following related channel.
Definition 12. Let M = (D, − ) be an open generative model in C with inputs Iand outputs O. Let S
denote the non-input hidden (n(cid:74)on(cid:75)-output) objects of the model. The total channel M of the model is the
13
channel from I to S,O:
S O
... ...
M (13)
...
I
given by interpreting the network diagram D′ in which we modify D by adding an extra copy morphism to
each object in S, to make it an output.
Conversely, the usual channel from inputs to outputs is then simply the marginal over S:
S
O O
... ...
M = M (14)
...
I I
In particular for a closed generative model, with no inputs, we call the total channel the total distribution of
the model. It is a joint distribution over the hidden objects S and observed objects O:
S O
... ...
M (15)
with the original distribution over the observed objects as its marginal.
S
O O
... ... ...
M = M (16)
Let us now consider generative models in our main example category.
Example 13. A closed generative model M in MatR+ is precisely a Causal Bayesian Network (CBN). This
consists of specifying:
• a finite DAG Gwith a subset O ⊆V of ‘observed’ vertices and the remaining S =V \O being ‘hidden’;
• for each vertex X an associated variable with a finite set of values also denoted X , and a mechanism
i i
c given by a probability channel with density:
i
P(X |Pa(X )) (17)
i i
The term ‘causal’ refers to the fact each such mechanism has a causal interpretation.
Indeed, as we have seen, such a DAG G with outputs O is equivalent to a network diagram D with no inputs.
Specifying an interpretation of D is then the same as choosing the sets X of values and channels (17) for
i
each box in the diagram. A CBN defines a joint distribution4 over all the variables V = {X ,...,X } with
1 n
density
n
(cid:89)
P(V):= P(X |Pa(X )) (18)
i i
i=1
which is precisely (15). The output distribution of the CBN is given by the marginal P(O) over only the
observed variables, corresponding to (16).
4Often a Bayesian network is instead defined as a distribution P(V) satisfying the Markov condition (18) in terms of its
conditionals. Since these conditionals may not be unique, and the channels ci are an important component of the model, we
insteadincludethelatterexplicitly;formorediscussionsee[LT23].
14
Example 14. An open generative model M in MatR+ is an ‘open CBN’, where now for the input variables
no channel (17) is specified. This induces via (13) the total channel
P(S,O |I)
from the inputs to the non-input hidden variables S and output variables O, which here we would denote (the
entries of) by M(s,o|i). Its marginal P(O |I) on the observed variables O yields the channel M(o|i) from
(14).
In short, a (closed) generative model in MatR+ specifies the internal structure of an output distribution
P(O) in terms of further variables and channels (17), while an open generative model similarly specifies the
internal structure of a channel P(O |I) from inputs I to outputs O.
For the remainder of this section we will describe some of the common forms of (open) generative models
which appear in PP.
3.1 Simple generative models
By a generative model S →O we mean a generative model M with network diagram:
O
c
S
σ
Thus M consists of objects S,O with O observed and S hidden, a channel c: S → O, called the likelihood,
and a distribution σ on S, called the prior. As alluded to earlier, we call S the hidden states and O the
observations of the model. The total distribution of the model is given by
S O
S O c
= (19)
M
σ
More generally, we can consider an open variant of such a generative model which now comes with a
hidden object I of inputs, with the following network diagram:
O
c (20)
S
σ
I
Hence both the prior and likelihood now take an additional I input. The total channel is given by
S O
S O
c
M = (21)
σ
I
I
15
Intuitively, such an open model M consists of specifying a particular generative model S →O for each input
in I.
Example 15. A generative model S → O in MatR+ consists of a finite set S of hidden states, O of
observations, a likelihood channel c(o | s) and prior distribution σ(s). Often would often write c(o | s) as
simply P(o | s) and σ(s) as P(s). We interpret c(o | s) as the probability of observing o when in the hidden
state s. Then the total state (19) is the joint distribution over S,O given by
M(s,o)=c(o|s)σ(s)
and typically simply denoted P(s,o). As the notation suggests P(o | s) is the conditional and P(s) the
marginal of the joint distribution P(s,o).
When the generative model is open as in (20) it now comes with a finite set I of input values, with
likelihood c(o|i,s) and prior σ(s|i). The total channel (21) is then given by
M(s,o|i)=c(o|i,s)σ(s|i)
Thus for each input i we obtain a generative model M(i) of the form S →O and an induced joint distribution
M(i) over S,O.
3.2 Discrete time models
For a given n∈N, a discrete time generative model is a closed generative model M of the form
O1 O2 On
A A A
S1 S2 Sn
B
...
...
B
D
Thus it consists of observed objects O ,...,O , hidden objects S ,...,S , a prior distribution D over S ,
1 n 1 n 1
observation channels {A: S →O }n and transition channels {B: S →S }n−1. Typically we mean that
t t t=1 t t+1 t=1
there are fixed objects S,O such that S =S,O =O for all j, and similarly as our notation suggests all the
j j
A and B channels for each time step are taken to be identical.
WeinterpretthemodelMasdescribingtheevolutionofasystemoverdiscretetimestepsfromt=1,...,n.
ThesystembeginsinitsinitialstatewithpriordistributionDandthenevolvesovereachtimestepaccording
tothetransitionchannelsB. Independently,weobservethesystemateachtimetviathechannelAtoproduce
an observation in O .
t
Example 16. AdiscretetimegenerativemodelinMatR+ isalsocalleda HiddenMarkovModelor partially
observable Markov decision process (POMDP) [PPF22].
3.3 Policy models
We now introduce an explicit ingredient whereby the agent can model its own actions. As in reinforcement
learning [TMSB20], a choice of actions or behaviour is called a policy. In a discrete time setting, a policy
can be thought of as determining likely sequences of actions over the time steps, which in turn influence the
evolution of the states over time.
16
An n-time step model with policies is a generative model M of the form:
On
A
Sn
B
Sn−1
O2
...
A
O1
S2
A
B
S1
B
...
S0
D P
E
Thus it now includes a hidden object P of policies which forms an input to each transition channel B from
S ,P to S , for t≤n−1. The model also comes with a prior distribution E over P, which are called the
t t+1
habits of the system. Note that here the policy the system is undertaking is considered hidden.
AgainwetypicallytakeS =S andO =O forsomefixedobjectsS,O, withallchannelsAidenticaland
j j
all B channels identical.
Example 17. Models of this form, within MatR+ , are the central examples used in the active inference
tutorial [SFW22] and book [PPF22].
3.4 Hierarchical models
Central to much of PP is the study of hierarchical generative models [DVF17, PPF22], which have a natural
graphical description. These are generative models given by composing various open generative models in
layers, where the outputs of the open models in one layer match the inputs of the models in the next layer,
such as in the example below.
S(3)
M M M M
3 3 3 3
S(2)
(22)
M M
2 2
S(1)
M
1
S(0)
M
0
HereitisunderstoodthateachboxM representsanopengenerativemodel,whichwemaydecomposefurther
j
in terms of its own network diagram with inputs and outputs as shown. The right-hand labels indicate that
the input wire to M has type S(0), the output wires from M both have type S(1) etc 5.
1 1
5ItisalsocommontointroducealabellingconventionforthewiressuchasS(0,1,2)wheretheindicesrepresentwirenumbers
in each layer as we read up the diagram. However this quickly becomes unwieldy, and in most cases the graphical description
ofthenetworkisthemostconvenient.
17
We interpret the inputs to each (box within a) layer as a ‘control’ signal from the layer below. Note
that because we read diagrams bottom to top, the layers further down the diagram are in fact those usually
referred to as more ‘high-level’ or ‘higher’ in the hierarchy.
The structure of the model tells us that the ‘high-level’ features cause the generation of the ‘lower-level’
features. For example S(0) could describe an overall action policy while the S(3) control more fine-grained
motor actions. Another common example explored in [DVF17] is where the output wires from each box
denote individual time steps. In this case time runs faster in the lower-level layers (higher in the diagram).
For example in the diagram above six time steps occur in layer S(3) for every time step in layer S(1).
Plugging in the network diagrams for each open model corresponding to M yields a composite network
j
diagram for the whole hierarchical model. For example in the following hierarchical model, the network
diagrams for M and M are shown in the highlighted boxes below and compose to yield the diagram on the
1 2
right-hand side.
S(2)
B B
2 2
A A
S(2) 2 2
M M =
2 2
S(1)
S(1)
B
M 1
1
P
M
0 A
1
P
M
0
Much of the PP literature concerns such hierarchical models and the passing of these ‘top-down predictions’
(the flow of information up the diagram in this case) are adjusted by ‘bottom-up errors’ passed back down
the model. The latter takes place when a model is updated, which we address next.
4 Updating Models
ConsideranagentwithbeasimplegenerativemodelMoftheformS →O asinSection3.1. Recallthatthis
induces a joint distribution M over S,O as in (15), whose marginal on S is the prior σ describing ‘beliefs’
about how likely each state in S is to occur.
S
S
O
=
σ M
Now suppose the agent receives an observation, which in general may be ‘soft’, given by an distribution o
overO. Theagentwouldliketoupdate thesebeliefstoobtainanewposterior distributionoverS,describing
how likely each s∈S now is given the observation.
S O O S
, (cid:55)→
M o update(M,o)
How then should the agent update the marginal on S to yield this posterior? For a general soft observation
with distribution o over O there are at least two distinct but natural ways to carry out Bayesian-style
18
updating, as pointed out by Jacobs in [Jac19], which we describe in this section. When the observation o
is sharp, however, corresponding to a single element o ∈ O, there is a canonical way to carry out this belief
updating, usually simply referred to as Bayesian updating, which we introduce first.
4.1 Sharp Updating
Let us begin by describing updates with respect to a sharp observation, given by (a point distribution at)
an element o ∈ O. Such Bayesian updating is closely related to the notion of conditional probabilities,
whichhaveanicecharacterisationincd-categories. Herewefollowtheapproachtoconditioningfrom[LT23],
building on earlier treatments [CS12, CJ19, Fri20]; see also [DLR23].
Definition 18. Let C be a cd-category, and ω a joint distribution over X,Y. Then a conditional of ω by Y
is a morphism ω| : Y →X such that the following holds:
Y
X Y
X Y
ω|
Y
= (23)
ω
σ
where σ is the marginal of ω on Y. If C has normalisation and cancellative caps, we define the (minimal)
conditional to be the morphism:
X
X
ω| = ω
Y
Y
Y
Each minimal conditional is indeed a conditional as shown in the Appendix of [LT23]. As we saw for
normalisations, a conditional is only a partial channel in general, being a channel only when ω has ‘full
support’.
Example 19. In MatR+ the minimal conditional ω|
Y
is given by
ω(x,y)
ω| (x|y):=Normω(x,y)=
Y x (cid:80) ω(x′,y)
x′
whenever the sum in the denominator is non-zero, and ω| (x | y) = 0 for all x otherwise. Thus when ω is
Y
normalised with density denoted P(X,Y) this is the usual conditional P(X |Y). The condition (23) amounts
to the usual ‘chain rule’ P(x,y)=P(x|y)P(y) for the probability distribution P(x,y)=ω(x,y), since σ(y)
is the marginal P(y) and we have:
x y
x y x y
ω|
Y
ω(x,y) = = = ω| = ω| (x|y)σ(y)
ω Y σ Y
y
σ
For a generative model M of the form S → O with joint distribution M over S,O we call the minimal
conditional M| : O → S the Bayesian inverse of the model. It specifies how to update beliefs about S for
O
19
each specific sharp observation o ∈ O. Explicitly, given a sharp distribution o = δ over O for some o ∈ O
o
the updated beliefs are given by the posterior:
S
S S
S o
O
update(M,o) = M = M O = M (24)
o
O
o
Example 20. In MatR+ , for a sharp observation δ
o
for some o ∈ O, the posterior is the distribution over
S given by the usual Bayesian update:
M(s,o)
M(s|o)= (25)
(cid:80) M(s′,o)
s′
4.2 Pearl and Jeffrey Updating
There are two distinct ways to generalise updating to the case of a soft observation given by a distribution
o over O, described in [Jac19]. Diagrammatically these correspond to generalising from either the former or
latter diagrams in (24). For more on both forms of updating in cd-categories see also the treatment by Di
Lavore and Rom´an [DLR23].
Definition 21. Let C be a cd-category with normalisation and cancellative caps, and M a joint distribution
over S,O. Given a distribution o over O, the Jeffrey update denoted M or M| is given by the composite
J o
M| ◦o, i.e.:
O
S
S
M| o := M
O
o
whenever this is normalised, and more generally is given by the normalisation of the above state. The
Pearl update denoted M or M|o is instead given by the normalisation:
P
S
S
o
=
M|o O
M
recalling that the effect o is given by composing o with a cap as in (5).
Example 22. For a generative model M from S to O in MatR+ , with joint distribution M over S,O, the
Jeffrey update is given by
(cid:88) M(s,o)o(o)
M (s)= E NormM(s,o)= (26)
J o∼o s o (cid:80) s′ M(s′,o)
while the Pearl update is
(cid:80)
M(s,o)o(o)
M (s)=Norm E M(s,o)= o (27)
P s o∼o (cid:80) s′,o′ M(s′,o′)o(o′)
20
The distinction between both update procedures is not always considered in the literature since for sharp
observations they coincide with the usual Bayesian update. Indeed the following is immediate from (24).
Lemma 23. Let C be a cd-category with normalisation and cancellative caps. Then for each sharp state o
on O the updates coincide: M =M =M| ◦o.
J P O
In contrast, for a general observation o the two updates differ in the way they apply normalisation,
amounting to whether one normalises with respect to (or separately from) the observation itself.
S S
M ̸= M
O
O o
o
The Jeffrey update simply composes the observation o with the Bayesian inverse (partial) channel M| . If
O
M| isonlyapartialchanneltheresultmaynotbenormalised(suchaswhenofallsoutsidethesupport),in
O
which case the update is then further normalised. The Pearl update instead involves a single normalisation,
taking place after composing with the observation, so that o is inside the normalisation box.
Remark 24. Jacobs has compared the two forms of updating within MatR+ in detail, noting that their in-
ferences can differ considerably, but that both can be considered rational notions of updating [Jac19]. One
differencebetweentheupdatesisthatbydefinitionJeffreyupdatingformsaprobabilitychannelinO(whenever
M| is a channel, i.e. M has full support over O). In contrast, the normalisation over o in Pearl updating
O
means that it does not form a channel in O. The two update procedures can also be characterised by the fol-
lowing respective properties. For a generative model M over S,O with likelihood c, Jeffrey updating minimises
the KL-divergence between o and the marginal on O of the updated model in which we replace the prior with
the posterior (left-hand below). Pearl updating instead has the property that it maximizes the expected value
of the function o (right-hand below).
 
O o
 
 O  O
 
M
J
minimises: D KL

c ,
o


M
P
maximises: c ∈R+
 S  S
 
M M
J P
The PP literature has mostly focused on updating with respect to sharp observations, in which the two notions
coincide. It is an interesting question for the future to determine which (if either) form of updating is most
natural in Bayesian models of cognition.
4.3 Updating Open Models
SinceatypicalgenerativemodelinPPiscomposedofvariousopen generativemodelsM,itisalsoimportant
todescribehowanagentmayupdatesuchopenmodelsM,nowcomingwithinputsI. Inthiscaseweconsider
theinducedchannelM: I →S,O. ThepriorbeliefsaboutS arenowgivenbythemarginalσ: I →S,which
we can think of specifying beliefs over S for each input i∈I. Given an observation o over O the agent now
wishes to update this to a posterior channel of the same kind.
S
S S
O
σ = M (cid:55)→ update(M,o)
I I I
21
All of the treatment of updating above generalises straightforwardly to such open models, amounting to
updating the corresponding closed model M(i) over S,O for each input i∈I.
Explicitly,foranymorphismf: X →Y ⊗Z inacd-category,aconditional isanymorphismf| satisfying
Z
the left-hand equation below, where σ is the corresponding marginal of f. In the presence of normalisation
and cancellative caps, the (minimal) conditional is that given on the right below, as in [LT23].
Y Z
Y
Y Z f| Z Y
f = f| = f
Z
σ
X X Z
X Z
X
Definition 25. Let M: I →S,O be the channel induced by an open model M, and o a distribution over O,
in a cd-category with normalisation and cancellative caps. The Jeffrey update denoted M or M| is given
J o
by composing M| with o as left-hand below (or more generally by its normalisation if the result is not a
O
partial channel). The Pearl update denoted M or M|o is instead given as on the right-hand side.
P
S
S
S o
S
O
M| o := M M|o = M
O
I o I I
I
By the defining property of normalisations (10) the Pearl update M| satisfies the following, which will
o
be useful later.
S o S o
O O
M = M|o M (28)
I
I
Example 26. In MatR+ the minimal conditional of f by Z is given by
f| (y |x,z)=Normf(y,z |x)
Z
y
and for a probability channel P(Y,Z | X) corresponds to the usual conditional P(Y | X,Z). The formulae
for both updates M (s | i),M (s | i) are the same as (26), (27) simply replacing each M(s,o) term with
J P
M(s,o|i), i.e.
M (s|i)= E NormM(s,o|i)
J
o∼o s
M (s|i)=Norm E M(s,o|i)
P
s o∼o
Again both update procedures coincide with M(s|o,i) for sharp observations i∈I and all inputs i∈I.
22
Remark 27. Di Lavore and Rom´an also study both forms of updating in cd-categories in which (non-chosen)
conditionalsexistin[DLR23],callingthem‘partialMarkovcategories’. Thereupdatingisdefinedviaarbitrary
(non-minimal) conditionals, meaning that M| can be arbitrarily defined outside the support on O of M.
O
However since this arbitrary choice can impact the result of a Jeffrey update M| ◦o when o is also non-zero
O
outside this support, we instead define updating via the minimal conditional M| .
O
5 Perception and Planning
Let us now see how the notion of updating is applied by an agent to govern its behaviour in PP. Two
fundamental uses of updating are the following.
Perception Firstly, as already alluded to, we can consider the case of an agent with a generative model
M from S to O, interpreted as accounting for observations O in terms of hidden states of the world S. For
example, O may be the space of pixel-level descriptions of images while S is a compressed representational
space of possible objects which the images portray.
Given an observation encoded by a (soft or sharp) distribution o over O, the agent can update its prior
over hidden states S to obtain a posterior describing how likely each hidden state is to have caused the
observation. We refer to this general process of updating as perception and view the resulting distribution
as the agent’s specific perception of the observation o. Intuitively perception takes the ‘raw data’ of the
observation o and returns (a distribution over) representations S.
S O O S S
M , o (cid:55)→ perception = update(M,o)
Intuitively, the update answers the question ‘Given that I have received this observation, how likely is each
possibleworldstate?’. Intheliteraturethisisoftenreferredtoasinference,inreferencetoBayesianinference.
Planning A second application of updating by an agent is in planning its behaviours. Here an agent
possesses a generative model M of the same formal structure but with objects labelled P,F and interpreted
differently. Now P encodes the action policies, or behaviours, the agent may carry out, while F represents
observations (or states) it may receive in the future. The model M includes a prior over policies which we
can think of as the agent’s habits or typical behaviours.
Here the agent possesses some preferences about which future observations (or states) are most desir-
able, encoded by a distribution C over F. Intuitively, the distribution will have highest density on the
most desirable outcomes. The agent can then plan its actions by updating its habits with respect to these
preferences:
P F F P P
M , C (cid:55)→ plan = update(M,C)
The process of deriving this distribution can intuitively be called ‘planning’. We can think of this update
as answering the question ‘Given that I will obtain my preferences in the future, how likely is each policy to
have led to this outcome?’.
The resulting ‘plan’ distribution over P can be used to guide the agent’s future behaviour. For example,
an agent may then sample an policy to pursue from this distribution, so that the more probable policies
according to the distribution are more likely to be carried out.
6 Exact Active Inference
Bothusesofupdatingbyanagent,planningandperception,cometogetherintheconceptofactiveinference,
of which we are now able to present a fully formal diagrammatic account.
Consider an agent possessing a generative model describing how its actions, in the form of action policies
P, bring about changes in its observations. These consist of both observations for the present time (and
23
previous times) O and for future time steps F. Thus the agent has a closed generative model M of the
following form.
observations O F
action = M (29)
P
policies
E
habits
Here (abusing notation slightly) we denote by M also the channel from policies to observations induced by
the model, and E is the prior over policies describing the agent’s habits.
Suppose further that the agent’s model explains the observations at each of these time steps through
hidden states, where S denotes the hidden states in the present time and S′ in the future, so that we have:
O F
A A′
S S′
O F B′
M = (30)
B
P
P
for ‘observation’ channels A,A′ and ‘transition’ channels B,B′. The induced distribution on P,O,F is then
given by:
P O F
P O F
M
M = (31)
E
The goal of active inference is then the following. The agent receives a current observation given by a
distribution o over O, and also carries a distribution C describing its preferences for future observations F.
The agent then wishes to update its prior E over policies to yield a posterior which describes its plan of
action6:
O F P P
o C (cid:55)→ plan = update(M,o,C) (32)
Intuitively,theposterioroverpoliciescanbethoughtofasansweringthequestion‘Given that I have received
this observation o now, and will attain my preferences C in the future, which action policy am I pursuing?’.
Note that, perhaps surprisingly, the agent’s own action policy is thus treated as hidden from itself, and
something that it must infer.
Now, typically the objects above all decompose into further structure, as in the following example.
Example 28. A common application of active inference is to the discrete-time models with policies given
in Section 3.3, which we may view as instances of (30) as follows. Consider such a model featuring N
time-steps, where n<<N is considered the current time, and all times m with n≤m≤N as in the future.
6Ultimately,havingderivedtheir‘plan’distributiontheagentmaythensampleasingleactionpolicyπ∈P asinSection5,
andactaccordingly. Weimaginethatviathetrue‘generativeprocess’intheworld(distinctfromtheagent’smodel)thisleads
tofurtherobservationsinthefuture,towhichtheagentcarriesoutfurtherplanningsteps,andsoon. Ourfocusissimplyona
singlestepofhowtheagentderivestheir‘plan’fromoandC.
24
The spaces of ‘current’ hidden states and observations S,O are the products over all previous time-steps
t=1,...,n up to and including the current time, while the future hidden states and observations S′,F take
the product over all future time-steps t=n+1,...,N.
S :=S ⊗···⊗S S′ :=S ⊗···⊗S
1 n n+1 N
O :=O ⊗···⊗O F :=O ⊗···⊗O
1 n n+1 N
The observation channels in the overall model (30) would then be given by:
O O1 On F On+1 ON
A := A ... A A′ := A ... A
S S1 Sn S′ Sn+1 SN
while the transition channels are as follows:
SN
Sn
B
B
Sn+1
S1 ...
S ... S′
B := B′ :=
B
B ...
...
P
S P ...
S1 Sn−1 Sn
P
P
so that the composite (31) yields the network diagram for the overall model for times t=1,...,N.
An agent may employ various update procedures, such as those discussed in Section 4, to calculate its
plan of action (32). Though both forms of updating coincide for sharp inputs, and the observations o in the
active inference literature are typically taken to be sharp, the preferences C are often not; that is, there may
be multiple desirable future observations in F. Thus Pearl and Jeffrey updating can be expected to differ.
Here we will describe an exact active inference procedure based on Pearl updating, allowing both obser-
vations o and preferences C to be soft. We leave the exploration of Jeffrey updating in active inference for
future work.
Now let us consider how the agent can in the ideal case compute its plan (32) via an exact update
procedure. Firstly, let us rewrite the channel in (30) as follows.
F
S′
A′
F
S′
B′ O M
O 2
O F
S S
M
A 1
M = =
B
P P
P
25
Here the channels M , M are the compositions indicated by the highlighted boxes7. Now applying the
1 2
property of Pearl updates (28) to M we have the following:
1
C C
F F
M P o M
P 2 2
o O S P o C
P o C
O S M 1 M 1 |o O F
O F
M M M|o
1 1
M = = = (33)
P P P
E E
E
Here we have again denoted by M ,M their respective marginals on O,F, given by discarding S,S′ respec-
1 2
tively. In the last step we used associativity of copying and the following argument:
F
F
M
F M 2 F
2
o
o
o M
F S S 2
O
O
O M S P
M 1
M|o = M = 1 = = M 1 |o
P
P
P P
P
whereinthemiddlestepweused(11)and(12)toslidethechannelM andcopyingoutofthenormalisation
2
box, respectively.
Thus we obtain an exact expression for active inference.
Proposition 29. The plan over policies in Pearl-style exact active inference is given by:
P
P
o C
P o C
O F
O F M M|o
1
plan = M = (34)
P
E
In MatR+ the plan has density over policies π ∈P given by:
plan(π):=Norm(E(π)(o◦M (π))(C◦M|o(π))) (35)
1
π
o
C
π A
=Norm M|o (36)
π
B
E π
π
7WhilewecoulddefineM2 withoutS′ asanoutput,theappearanceofS′ willbeusefullaterintreatingapproximateactive
inference. Notealsothatthedashedboxesinthiscasedonotdenotenormalisation.
26
Proof. The first equality holds by definition, so plan(π)=Norm f(π) where f is the density of the state in
π
(33). But this is given by:
o C
o C
π o C π O F
O F M M|o
P O F P 1
M M|o
1 P P
M = = π π
π
P
P
E
E
using that π is sharp, where the three right-hand scalars are precisely the terms in (35). The last line comes
from noting that the given marginal M : P →A is precisely B◦A.
1
There is only one problem with this form of active inference: the quantity (35) is completely intractable
to calculate. Along with the normalisation in calculating M|o, calculating the terms in (35) would involve
summation (or integration) over S,O and S′,F respectively, requiring us to respectively calculate:
(cid:88) (cid:88)
o(o)A(o|s)B(s|π) C(o′)M|o(o′ |π)
s∈S,o∈O o′∈F
To make the calculation of these updates tractable, an agent in active inference is understood to instead
use a special form of approximation scheme, to which we now turn.
7 Free Energy
WehaveseenthatforanagenttoperformexactBayesianupdatingiscomputationallyintractable. Inactive
inference, an agent instead carries out approximate updating by minimising a quantity known as free energy
[FKH06,Fri10,PPF22]. InthissectionforsimplicityweworkconcretelyinthecategoryC=MatR+ ,though
the same notions should be similarly defined in continuous settings.
The extra mathematical ingredient8 needed to define free energy will be the following .
Definition 30. For any distribution σ over X and x ∈ X we define the surprise as S(σ)(x) := −logσ(x).
For another distribution ω on X we define the overall surprise of σ relative to ω as the expectation value:
(cid:18) (cid:19)
S , := − E logσ(x)
ω σ
x∼ω
The entropy H(ω) of ω is its self-surprise:
(cid:18) (cid:19) (cid:18) (cid:19)
H :=S ,
ω ω ω
while the Kullback-Liebler (KL) divergence D(ω,σ) from σ to ω is the difference between these quantities:
(cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)
D , :=S , −H
ω σ ω σ ω
The KL divergence is a commonly used similarity measure on distributions, with D(ω,σ) ≥ 0 and
D(ω,ω)=0 for all distributions ω,σ.
Wemaynowdefinethefollowinggeneralnotionoffreeenergy. ThroughoutweconsideradistributionM
over S,O, which we imagine to be induced by a generative model from S to O. In this section for simplicity
givenanysuchdistributionwedenoteitsmarginalsonS,O andconditionalchannelsM| ,M| againsimply
S O
by M.
8Tostudyfreeenergywewillmovebeyondapurelydiagrammaticapproachandmakeuseofsomeprobabilisticcalculations,
mostnotablytodefine‘surprise’. HoweverlaterinSection9wewillseehowtorepresentsurpriseindiagrams(via‘log-boxes’).
Infutureworkitwouldbeinterestingtorepresentallofthecalculationsinthissectionusingsuchdiagrams.
27
Definition 31 (Free Energy). The Free Energy of a distribution Q over S,O relative to M is defined as:
 S O S O   S O S O   
S
FE   ,   := S   ,   − H  (37)
 Q M   Q M   Q 
Explicitly then we can re-write the free energy in the following useful form.
FE(Q,M)= E [log(Q(s))−log(M(s,o))] (38)
(s,o)∼Q
= E [log(Q(s)−log(M(s|o))−logM(o)] (39)
(s,o)∼Q
 
S S
   
  O O S
= E S   Q , M  +S , −H  (40)
o∼Q    Q M   Q 
 o o 
We now turn to two specific variants of this quantity commonly considered in active inference.
7.1 Variational Free Energy
SupposeanagentreceivesanobservationgivenbyadistributionooverO,andwishestoperformanapprox-
imate Bayesian update of its prior beliefs about S as encoded by the marginal of M on S. It may do so by
finding the distribution q over S which minimises the following quantity.
Definition 32 (Variational Free Energy). Given a distribution M over S,O and distribution o over O, the
Variational Free Energy (VFE) of a distribution q over S is defined as:
   
S S O S O
   
F :=FE , 
 q   q o M 
AnimportantfeatureoftheVFEisthefollowing. Usingtheexpression(40)andpullingtheentropyterm
inside the expectation we see that
 
S S  
O O
 
F(q) = E D , M  + S ,  (41)
o∼o   q    o M 
o
 
S S  
O O
 
≥ D , M  + S ,  (42)
  q    o M 
o
TheinequalityfollowsfromconcavityoftheKLdivergenceandJensen’sinequality,whichstatesthatforany
probability measure ω on X, measurable function f: X →R and concave function ϕ on R we have
E [ϕ(f(x))]≤ϕ( E [f(x)]) (43)
x∼ω x∼ω
In particular we see that the inequality (42) will be a strict equality whenever o=δ is given by a sharp
o
observation o ∈ O. In this case the minimum VFE value is given by the exact Bayesian inverse M| , with
o
value F = −logM(o). Hence for a sharp observation o, minimising the VFE minimises the KL-divergence
between q and the Bayesian inverse M| , achieving approximate inversion q ≈ M| . Moreover F(q) is an
o o
upper bound on the surprise of the observation o, and when q ≈M| we have F(q)≈S(o,M).
o
28
VFE Updating This process of minimising VFE to compute an approximate Bayesian update is central
in active inference, but typically only considered for such sharp observations. Here we can now consider the
more general minimisation of VFE for a soft observation given by a distribution o. In fact we may view this
as another notion of updating for a prior over S, in addition to the two forms of updating met in Section 4.
Firstly, observe that in the expression (41) since the surprise term is constant, the distribution q which
minimisesF(q)willbethatwhichminimisestheleft-handexpectedKLterm,whichisequaltothefollowing.
(cid:20) (cid:21)
E logq(s)− E logM(s|o)
s∼q o∼o
This quantity will in turn be minimised when this expression over S is equal to a constant K, so that:
logq(s)= E [logM(s|o)]+K
o∼o
Thedistributionqwillbegivenbynormalisingq(s)intheaboveexpression,allowingustoignoretheconstant
and yielding the following notion of updating motivated by the VFE. Recall that the softmax of a function
f: X →R+ is defined by σ(f)(x)=Norm ef(x).
x
Definition 33 (VFE Update). Given a joint distribution M over S,O and distribution o over O the VFE
update is the posterior
M
F
(s)=NormeE o∼ologM(s|o) (44)
s
=σ( E logM(s|o)) (45)
o∼o
where σ denotes a softmax over S.
Similarly, foranychannelM fromP toS,O wedefinethe VFEupdateofitsmarginalP →S point-wise,
by M (s|π)=M(π) (s) for each π ∈P.
F F
From the derivation above we see that q = M is the distribution which minimises F(q). Note that, as
F
for our other forms of updating, for a sharp observation o=δ we have M (s)=M(s|o).
o F
TorelategeneralVFEminimisationforasoftobservationtoexpectationvalues, wewillusethefollowing
form of approximation. Firstly, note that by Jensen’s inequality, for any probability measure ω and real
function f over X we have:
eE x∼ω[logf(x)] ≤ E [f(x)] (46)
x∼ω
Whenever we take both sides of such an inequality to be approximately equal, let us say we are using a log
approximation. In particular for any distributions ω,σ on X the follow holds log-approximately:
σ
(cid:18) (cid:19)
e−S ω , σ ⪅ X (47)
ω
Indeed this states precisely (46) for the case f(x) = σ(x). Such approximations can be used to relate free
energy to exact expectation values, as follows.
Proposition 34. Let M be the VFE update of M relative to a distribution o over O, and F its VFE value.
F
Then the following holds log-approximately:
S S o
O
e−F ≈
M M
F
Proof. Define f(s):=eE o∼ologM(s|o) and the normalisation constant K = (cid:80)
s
f(s), so that KM
F
(s)=f(s).
Then we have:
F =S(o,M)+ E [logM (s)− E logM(s|o)] (48)
F
s∼q o∼o
29
=S(o,M)−logK
e−FM (s)=e−S(o,M)KM (s)
F F
=e−E o∼o[logM(o)+logM(s|o)]
=e−E o∼o[logM(s,o)] ≈ E M(s,o)
o∼o
where in the last step we used a log-approximation.
Remark 35. Compare the formula for VFE update to the Jeffrey and Pearl updates (26), (27). While the
JeffreyupdatecomposestheconditionalO →S withoexactly,theVFEupdateinsteadminimisestheexpected
KL below.
S S  
S S
 
M J = M while M F minimises o E ∼o D   M F , M   
O o
o
7.2 Expected Free Energy
Asecondformoffreeenergyemployedinactiveinferenceisusedbyanagentwithamodelfeaturingaspace
O describing observations in the future. It then has a distribution C over O modelling preferences for these
future observations. Rather than updating its beliefs about future states, the agent simply want to assess
how well the marginal of the model on O will fit these preferences, via the following approximation.
Definition 36. Given a distribution M over S,O and distribution C over O, the Expected Free Energy
(EFE) is defined as
 
  S O
S O S O
O  
G   ,   := FE   , M   (49)
 M C   M 
 
C
The EFE compares the given model M to the right hand generative model which perfectly attains the
preferences, via its marginal C over O, whilst making use of the same inverse channel O → S. Writing the
EFE explicitly, and then rewriting in terms of the typically more readily computable channel S → O, we
have
G(M,C)= E [log(M(s))−log(M(s|o))]− E [logC(o)]
(s,o)∼M o∼M
= E [−log(M(o|s)]+ E [logM(o)−logC(o)]
s∼M o∼M
o∼M◦s
  
O
 
   O O
= E  H   M    +D , 
s∼M    M C 
  
s
ThefinallineexpressestheEFEintermsofaright-handrisk term,whichassesseshowwellthepredicted
state over O matches the preferences C, and a left-hand uncertainty term given by the expected entropy in
the observations. Thus minimising EFE requires both matching preferences and reducing uncertainty. For
more interpretations of EFE see [PPF22].
Now using Jensen’s inequality and the concavity of entropy, one may show that for any distribution ω
and channel c we always have:
   
c c
E H ≤H 
   
x∼ω x
ω
30
Hence the EFE is bounded above by the surprise of the preferences:
 S O       
O O O O O O
G   ,   ≤ H  + D ,  = S ,  (50)
 M C   M   M C   M C 
Thus minimising the EFE results in reducing the surprise of the preferences, making them more likely to be
obtained according to the model. Taking the inequality to be an approximation and applying exponentials
to both side along with a log-approximation then gives the following.
Proposition 37. The EFE is bounded above and approximately equal to the expectation value:
 
S O
O
C
e−G  ,   ⪅ O
 M C 
M
7.3 Free Energy in Active Inference
Weconcludethissectionbynotingtwousesoffreeenergyinapproximateactiveinference,treatedinthenext
section. For these we now consider a channel M from P to S,O, typically induced by an open model. For
eachπ ∈P thisspecifiesajointdistributionM(π)overS,O,towhichwemayapplyfreeenergycalculations.
Corollary 38. Let o and C be distributions over O. Let M : P → S be the VFE update of M by o,
F
and for each π ∈ P set F(π) := F(M(π) ) to the corresponding VFE value. Similarly for each π ∈ P let
F
G(π)=G(M(π),C). Then we have the following approximations:
S S o
C
O S O
e−F M
F
≈ M e−G ≈ M
P P
P
P
In the above the effect e−F is given by π (cid:55)→e−F(π), for π ∈P, and e−G is defined similarly.
Proof. Forthefirstapproximation,pluggingina(sharpstategivenby)anelementπ ∈P tobothsidesshows
that this is equivalent to Proposition 34 holding for each joint distribution M(π) over S,O with respect to
the observation o. For the second approximation, apply Proposition 37 to the joint distribution M(π) over
S,O for each π ∈P.
8 Active Inference via Free Energy
Let us now return to the situation of an agent carrying out active inference as in Section 6. As before the
agent’sgenerativemodelMin(29)consistsofitshabitsE overpoliciesP andachannelM fromP tocurrent
and future observations O,F, factoring via current and future hidden states S,S′. Given its observation o
and future preferences C it can now use free energy to give a viable approximation of its updated plan of
31
behaviour from Proposition 29, proceeding in two steps. We saw already in (33) that:
C
F
P o M
2
O S
P o C
M M |o
1 1
O F
M =
P
E
‘Perception’ step In the first step, the agent approximately updates the part of the model pertaining to
the current time, M , in light of the observation o. For each policy π it computes a distribution q(π) with
1
(approximately) minimal VFE F(q(π)), thus obtaining a channel q: P → S which approximates the VFE
update of M by o. For each π ∈P denote the corresponding VFE value by F(π). Explicitly:
1
 
S O
 
S S O
 
F(π)=F   q(π)    :=FE     q(π) o , M 1 P    
 
π
‘Prediction’ step In the second step, the agent uses this approximation channel q, to obtain a channel
M which approximates the model over future states and observations, defined as follows:
q
S′ F
S′ F M
2
S P
M q = q
P
P
For each policy π this induces a distribution M (π) over S′,F, for which the agent can compute the EFE
q
with respect to the preferences:
 S′ F 
F
 
 
G(π):=G M q , C  (51)
 
 
π
Using these free energy quantities, the agent may carry out approximate active inference. The following
formula is central in the active inference literature.
Theorem 39. The agent can carry out approximate active inference given observation o and preferences C
by setting its plan to have density
plan(π):=σ(logE(π)−F(π)−G(π)) (52)
where σ denotes a softmax over π ∈P.
32
Proof. We have:
C C
F F
P M P M
o 2
P o C S S
O
O F
e−F q
M
1
M = ≈
P P
E E
C
P P
F
e−F M q e−F e−G
= ≈
E E
where we used Corollary 38 in both approximation steps. Thus defining our plan as on the left-hand below
yields an approximate update:
P P
P
e−F e−G o C
O F
:= ≈
plan
M
E
Butfinally,notethattheleft-handdistributionispreciselygivenby(52). Indeedforeachπ ∈P,correspond-
ing to a sharp effect on P, we have:
π
e−F e−G
e−F e−G
P
= π π = E(π) e−F(π) e−G(π)
π
E E
Hence the normalisation of the above is precisely the softmax expression (52).
This formula for active inference via free energy, though frequently used, is usually only justified in a
fairly heuristic manner [PPF22]. Previous accounts rely on the less clear notion of treating EFE as a ‘prior’
to updating9. Here we have instead seen how the expression can be derived from a direct diagrammatic
argument, directly from the structure of the generative model.
9 Compositionality of Free Energy
A crucial aspect of active inference is the idea that an agent can be understood to minimise free energy at
all levels, so that it may be seen to globally minimise free energy in its generative model by minimising free
energy within each component.
To formalise this idea we must first introduce a notion of free energy for open models. For this we will
make use of the following graphical notation for the surprise.
9Despite the fact EFE is not straightforwardly a component of the generative model, and requires inference over present
statesS tobecalculatedfirst,ratherthanpriortothem
33
Definition 40. Given any effect e on X in MatR+ , corresponding to a function e: X →R+, we denote by
e
X
the function −loge(x): X →(−∞,∞].
Remark 41. Note that a log-box is no longer an effect within MatR+ , since when e(x) = 0 we will have
−loge(x)=∞. Herewewillinterpretanydiagraminvolvinglog-boxeswithinputsX ,...,X andnooutputs
1 n
as a (formula specifying a) function X ×···×X →(−∞,∞]. Composing boxes in the diagram amounts to
1 n
summation over wires, as for MatR+ . Given two such diagrams D
1
,D
2
we write D
1
+D
2
for the function
given by their point-wise sum as functions. In future it would be interesting to explore a formal categorical
semantics for log-boxes.
In particular we can apply a log box to any distribution ω in MatR+ by first turning it into an effect,
yielding the surprise S(ω)(x)=−logω(x).
X ω
ω
(cid:55)→ ω = (cid:55)→
ω
X X X
Similarly for a pair of distributions ω,σ we have
σ
(cid:18) (cid:19)
S , = . (53)
ω σ
ω
From the properties of the logarithm, one may verify that log-boxes then satisfy the following composi-
tional properties.
Lemma 42. For all effects d,e and sharp states x the following hold.
1.
d e
= d + e
2.
= 0
3.
d e = d + e
4.
d = d
x
x
34
Proof. Plugging inputs x,y into each equation they reduce to the following respective properties of the
logarithm. (1): log(d(x)e(x))=log(d(x))+log(e(x)). (2): log(1)=0. (3): log(d(x)e(y))=logd(x)+loge(y).
(4) holds by definition, since both diagrams are given by y (cid:55)→logd(x,y).
The following properties then follow from diagrammatic reasoning, using the relation between caps and
copying.
Proposition 43.
1. For all effects d,e and normalised states σ,ω:
d e d e
= +
σ ω σ ω
In particular, entropy is additive across parallel composition: H(σ⊗ω)=H(σ)+H(ω).
2. For all effects d,e:
d e d e
= +
3. For all morphisms f,g:
g
+
=
f f g
Proof. (1) follows from Lemma 42 (3) since:
d e d e d e
= + = +
σ ω σ ω σ ω σ ω
(2) follows from Lemma 42 (1), 2 and 3 since:
d e d e
=
= d + e
= d + e
35
(3) is a special case of (2) where we define the effects d,e by composing f,g with caps on their output,
respectively, since using the relation between caps and copying we see that:
g
= f g
f
Now, by construction, for any joint distributions M,Q over S,O the free energy is given by:
 
S O S O
M Q
 
FE ,  = −
 Q M  S
Q
Q
Hence for any joint distribution M over S,O and distributions q,o over S,O respectively, the VFE is given
by:
 
S
M q
 
F  = −
 q  S
S O
q
q o
We can use this to define a generalisation of VFE for (the channels induced by) open generative models.
Definition 44 (Open VFE). Given a channel M: I →S,O, distribution q over I,S and distribution o over
O, we define the open Variational Free Energy as
S O
 
S O S I O q
 
F   M , q , o   := M − (54)
  S I
 
I
I q
q o
In the special case where I is trivial, the open VFE coincides with the usual VFE.
Wecanusethecompositionalpropertiesoflogboxestoshowthatthisformoffreeenergyiscompositional,
in an appropriate sense. First consider the following two ways in which we may compose open models.
Consider a pair of open models M ,M with inputs I ,I , outputs O ,O and hidden states S ,S ,
1 2 1 2 1 2 1 2
respectively, such that O = I . We can compose these in sequence into a single open model M from I to
1 2 1
O , with S ,S ,O as its hidden states, with induced total channel M from I to the remaining variables
2 1 2 1 1
given as below.
S2 O2
O1
O2
O2 S1 O1 S2 O2
S1
M
2
M
2
M := O1 with total channel M = (55)
M M
1 1
I1 I1
I1
I1
36
Formally, the left-hand diagram is a composition in the category of open causal models; see [LT23, Sec. 5].
We can also compose open models in parallel. Given two open models M with inputs I , outputs O and
i i i
hidden states S , for i = 1,2 we can define an open model M with both sets of inputs, outputs and hidden
i
states with induced induced total channel M from I ,I to the remaining variables given as below.
1 2
O1 O2 O1 O2 S1 O1 S2 O2 S1 O1 S2 O2
M := M M with total channel M = M M (56)
1 2 1 2
I1 I2
I1 I2 I1 I2 I1 I1
Foreachoftheseformsofcompositionofopenmodels, wewishtoestablishthatfreeenergyiscompositional
in that the VFE of the open model M is determined from the VFE of its constituents. This ensures that
locally minimising VFE (within each of sub-component) can achieve global VFE minimisation also.
Theorem 45. For the sequential composite model M in (55) with O = I , with total channel M, and any
1 2
distribution o over O and distributions q ,q , the following holds:
2 1 2
     
S1 O1 S2 O2 I1 S1 I2 S2 O2 S1 O1 I1 S1 O1 S2 O2 I2 S2 O2
     
     
F M , q 1 q 2 , o  = F M 1 , q 1 , o 1  + F M 2 , q 2 , o 
     
     
I1 I1 I2
(57)
where
O1 I1
S2
o 1 = q 2 (58)
Intuitively, (58) expresses the way in which the beliefs about inputs I in M are passed down to the
2 2
model M as observations in O =I .
1 1 2
Proof. After rearranging some wires, we have that
M
2 q q
1 2
F(M,q,o) = −
M
1
S1 I1 S2 I2
q q
I1 S1 I2 S2 O2 1 2
q 1 q 2 o
q q
1 2
= + − −
M M
1 2
S1 I1 S2 I2
I1 S1 I2 S2 I2 S2 O2
q q
1 2
q 1 q 2 q 2 o
where for the first two terms we apply Proposition 43 with f = M and g = M , along with the fact that
1 2
o and q are normalised, and the second two terms are from Proposition 43 (1). But this is precisely the
1
right-hand side of (57).
Next let us turn to the parallel composite of open models.
37
Theorem 46. For any channels and distributions M ,q ,o for i=1,2, the following holds.
i i i

S1 O1 S2 O2 I1 S1 I2 S2 O1 O2
 
S1 O1 I1 S1 O1
 
S2 O2 I2 S2
O2 
F     M 1 M 2 , q 1 q 2 , o 1 o 2     = F     M 1 , q 1 , o 1     + F      M 2 , q 2 , o 2     
     
I1 I2 I1 I2
(59)
Proof. The left-hand side is given by
S1 O1 S2 O2
q q
− 1 2
M M
F(M,q,o) = 1 2
S1 I1 S2 I2
I1 I2
q q
1 2
q o q o
1 1 2 2
S1 O1 S2 O2
q q
1 2
= M + M − −
1 2
I1 I2
S1 I1 S2 I2
q q
q o q o 1 2
1 1 2 2
which is precisely the right-hand side, where we applied Proposition 43 (1).
TheaboveresultstellusthatanagentwithanoverallgenerativemodelmayminimiseVFEbyminimising
VFE locally within each sub-model, an important property underlying the application of the free energy to
all levels of a system.
10 Outlook
In this article we have aimed to give a concise formulation of active inference in terms of string diagrams
interpreted in a cd-category C, focusing on the case of finite discrete systems as described by C = MatR+ .
In particular we were able to derive the formula for approximate active inference via free energy minimisa-
tion purely from the high-level structure of a generative model undertaking active inference, and derived a
compositionality property for free energy.
However these are just the first steps towards a fully compositional account of intelligent behaviour
according to predictive processing, and there are many directions for future work.
Message passing So far we only studied active inference at a high-level, saying that an agent must, for
eachobservation,arriveatanupdateddistributionqbyfreeenergyminimisation,withoutdiscussinghowthis
istobecarriedout. InPPthisminimisationisnormallyachievedviaso-called‘messagepassing’algorithms,
such as ‘variational’ and ‘marginal’ message passing [PMKF19]. These are defined on undirected graphical
models described by Forney factor graphs, induced by a generative model. In future it would be interesting
to include a categorical account of message passing within our framework, to complete our description of
active inference.
Continuous settings Another technical matter would be to extend the treatment of PP beyond the
finite case to further cd-categories describing continuous settings, such as a suitable category of Gaussian
probabilistic processes, which are widely employed in PP under the ‘Laplace assumption’. One issue is
38
in extending our treatment of minimal conditionals to such continuous settings, where they are not as
straightforwardly defined.
Causal reasoning We have here pointed out that an generative model may be seen precisely as a causal
model [Pea09]. In future it would be interesting to explore how an agent may carry out causal reasoning on
its model using concepts from the causal model framework such as ‘interventions’, as treated graphically in
[LT23], and how such reasoning relates to active inference.
Approximations The treatment of active inference via free energy in Section 8 relied on applying various
approximation steps from Section 7 to parts of the diagram. Certainly more could be done to set bounds
on how well these approximations hold, including how they extend from part of a diagram to the whole
generative model.
Updating within PP The categorical perspective led us to naturally consider soft observations (given
by distributions) rather than the usual sharp ones (given by points), which come with distinct notions of
Jeffrey and Pearl updating (Section 4), as well our new notion of VFE updating (Section 7). While we were
able to describe active inference via the latter two forms of updating, it would be interesting to compare
against Jeffrey updating and establish which form of exact updating is most naturally considered (and
approximated) in PP. That is, given that both forms of updating have different goals [Jac19], which one (if
either) is approximately carried out by the brain? This question was also raised in [DLR23].
We note that Pearl updating can be more generally defined with respect to any effect (see e.g. [DLR23]),
i.e. any (not necessarily normalised) function. There is disagreement between active inference and rein-
forcement learning (RL) in whether an agent’s preferences should, rather than as a distribution as in active
inference, be simply modelled by a function C: F → R+ assigning a ‘value’ in R+ to each possible future
observation,i.e. asaneffectC onF [FDK09,TMSB20]. InthiscasePearlupdatingmaybethemostnatural
to treat planning. In contrast, Jeffrey updating may be most fitting for perception, with an observation o
naturally encoded as a distribution i.e. a ‘fuzzy point’ in O.
Consciousness in PP Various proposals have been put forward for how PP and active inference can be
related to consciousness. Continuing from previous work from two of the authors on IIT [KT21, TK21], in
future we hope to account for these proposals within our graphical account of active inference.
Categorical modifications of PP BeyondsimplyrecastingpreviousresultsinPPcategorically,infuture
one may also study what new insights the compositional perspective may bring to PP and active inference,
and to connect the work to ongoing research within categorical cybernetics [Smi21b, CGHR21] and more
broadly to the research programme of compositional intelligence.
References
[AC04] SamsonAbramskyandBobCoecke.Acategoricalsemanticsofquantumprotocols.InProceedings
ofthe19thAnnualIEEESymposiumonLogicinComputerScience, 2004.,pages415–425.IEEE,
2004.
[CCS08] Stephen Clark, Bob Coecke, and Mehrnoosh Sadrzadeh. A compositional distributional model
of meaning. In Proceedings of the Second Quantum Interaction Symposium (QI-2008), pages
133–140. Citeseer, 2008.
[CGHR21] Matteo Capucci, Bruno Gavranovi´c, Jules Hedges, and Eigil Fjeldgren Rischel. Towards founda-
tions of categorical cybernetics. arXiv preprint arXiv:2105.06332, 2021.
[CJ19] Kenta Cho and Bart Jacobs. Disintegration and bayesian inversion via string diagrams. Mathe-
matical Structures in Computer Science, 29(7):938–971, 2019.
[Coe06] BobCoecke. Introducingcategoriestothepracticingphysicist. InWhat is category theory,pages
45–74. Polimetrica Monza, 2006.
39
[CS12] Bob Coecke and Robert W Spekkens. Picturing classical and quantum bayesian inference. Syn-
these, 186:651–696, 2012.
[Dea21] George Deane. Consciousness in active inference: Deep self-models, other minds, and the chal-
lenge of psychedelic-induced ego-dissolution. Neuroscience of Consciousness, 2021(2):niab024,
2021.
[DLR23] Elena Di Lavore and Mario Rom´an. Evidential decision theory via partial markov categories.
arXiv preprint arXiv:2301.12989, 2023.
[DVF17] Bert De Vries and Karl J Friston. A factor graph description of deep temporal active inference.
Frontiers in computational neuroscience, 11:95, 2017.
[FDK09] KarlJFriston,JeanDaunizeau,andStefanJKiebel. Reinforcementlearningoractiveinference?
PloS one, 4(7):e6421, 2009.
[FFR+17] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and Giovanni Pez-
zulo. Active inference: a process theory. Neural computation, 29(1):1–49, 2017.
[FK23] TobiasFritzandAndreasKlingler. Thed-separationcriterionincategoricalprobability. J.Mach.
Learn. Res, 24(46):1–49, 2023.
[FKH06] Karl Friston, James Kilner, and Lee Harrison. A free energy principle for the brain. Journal of
physiology-Paris, 100(1-3):70–87, 2006.
[Fon13] Brendan Fong. Causal theories: A categorical perspective on bayesian networks. arXiv preprint
arXiv:1301.6201, 2013.
[FPdV17] Karl J Friston, Thomas Parr, and Bert de Vries. The graphical brain: belief propagation and
active inference. Network neuroscience, 1(4):381–414, 2017.
[Fri10] Karl Friston. The free-energy principle: a unified brain theory? Nature reviews neuroscience,
11(2):127–138, 2010.
[Fri20] Tobias Fritz. A synthetic approach to markov kernels, conditional independence and theorems
on sufficient statistics. Advances in Mathematics, 370:107239, 2020.
[FST19] BrendanFong,DavidSpivak,andR´emyTuy´eras. Backpropasfunctor: Acompositionalperspec-
tive on supervised learning. In 2019 34th Annual ACM/IEEE Symposium on Logic in Computer
Science (LICS), pages 1–13. IEEE, 2019.
[GHWZ18] Neil Ghani, Jules Hedges, Viktor Winschel, and Philipp Zahn. Compositional game theory.
In Proceedings of the 33rd annual ACM/IEEE symposium on logic in computer science, pages
472–481, 2018.
[Hoh20] Jakob Hohwy. New directions in predictive processing. Mind & Language, 35(2):209–223, 2020.
[HS20] JakobHohwyandAnilSeth. Predictiveprocessingasasystematicbasisforidentifyingtheneural
correlates of consciousness. Philosophy and the Mind Sciences, 1(II), 2020.
[Jac19] Bart Jacobs. The mathematics of changing one’s mind, via jeffrey’s or via pearl’s update rule.
Journal of Artificial Intelligence Research, 65:783–806, 2019.
[JKZ19] Bart Jacobs, Aleks Kissinger, and Fabio Zanasi. Causal inference by string diagram surgery. In
Foundations of Software Science and Computation Structures: 22nd International Conference,
FOSSACS 2019, Held as Part of the European Joint Conferences on Theory and Practice of
Software, ETAPS 2019, Prague, Czech Republic, April 6–11, 2019, Proceedings 22, pages 313–
329. Springer, 2019.
[KT21] Johannes Kleiner and Sean Tull. The mathematical structure of integrated information theory.
Frontiers in Applied Mathematics and Statistics, 6:602973, 2021.
40
[LT23] RobinLorenzandSeanTull. Causalmodelsinstringdiagrams. arXivpreprintarXiv:2304.07638,
2023.
[Pan98] Prakash Panangaden. Probabilistic relations. School of Computer Science Research Reports-
University of Birmingham CSR, pages 59–74, 1998.
[Pea09] Judea Pearl. Causality. Cambridge university press, 2009.
[Per22] Paolo Perrone. Markov categories and entropy. arXiv preprint arXiv:2212.11719, 2022.
[PMKF19] ThomasParr,DimitrijeMarkovic,StefanJKiebel,andKarlJFriston. Neuronalmessagepassing
using mean-field, bethe, and marginal approximations. Scientific reports, 9(1):1889, 2019.
[PPF22] Thomas Parr, Giovanni Pezzulo, and Karl J Friston. Active inference: the free energy principle
in mind, brain, and behavior. MIT Press, 2022.
[PZ23] Robin Piedeleu and Fabio Zanasi. An introduction to string diagrams for computer scientists.
arXiv preprint arXiv:2305.08768, 2023.
[SBPF21] Noor Sajid, Philip J Ball, Thomas Parr, and Karl J Friston. Active inference: demystified and
compared. Neural computation, 33(3):674–712, 2021.
[SFW22] RyanSmith,KarlJFriston,andChristopherJWhyte. Astep-by-steptutorialonactiveinference
and its application to empirical data. Journal of mathematical psychology, 107:102632, 2022.
[SGW21] Dan Shiebler, Bruno Gavranovi´c, and Paul Wilson. Category theory in machine learning. arXiv
preprint arXiv:2106.07032, 2021.
[Smi20] Toby St Clere Smithe. Bayesian updates compose optically. arXiv preprint arXiv:2006.01631,
2020.
[Smi21a] TobyStClereSmithe. Compositionalactiveinferencei: Bayesianlenses.statisticalgames. arXiv
preprint arXiv:2109.04461, 2021.
[Smi21b] Toby St Clere Smithe. Cyber kittens, or some first steps towards categorical cybernetics. arXiv
preprint arXiv:2101.10483, 2021.
[Smi22] Toby St Clere Smithe. Compositional active inference ii: Polynomial dynamics. approximate
inference doctrines. arXiv preprint arXiv:2208.12173, 2022.
[TK21] SeanTullandJohannesKleiner. Integratedinformationinprocesstheories. Journal of Cognitive
Science, 2021.
[TMSB20] Alexander Tschantz, Beren Millidge, Anil K Seth, and Christopher L Buckley. Reinforcement
learning through active inference. arXiv preprint arXiv:2002.12636, 2020.
[WM17] Wanja Wiese and Thomas Metzinger. Vanilla pp for philosophers: A primer on predictive pro-
cessing. 2017.
41

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Active Inference in String Diagrams: A Categorical Account of Predictive Processing and Free Energy"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
