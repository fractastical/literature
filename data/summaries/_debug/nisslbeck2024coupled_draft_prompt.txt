=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Coupled autoregressive active inference agents for control of multi-joint dynamical systems
Citation Key: nisslbeck2024coupled
Authors: Tim N. Nisslbeck, Wouter M. Kouw

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2024

Key Terms: systems, joint, energy, agents, filtering, control, terms, autoregressive, inference, dynamical

=== FULL PAPER TEXT ===

Coupled autoregressive active inference agents
for control of multi-joint dynamical systems
Tim N. Nisslbeck1[0009−0007−3114−812X] and
Wouter M. Kouw1[0000−0002−0547−4817]
Bayesian Intelligent Autonomous Systems lab, TU Eindhoven, Netherlands
t.n.nisslbeck@tue.nl((cid:0)), w.m.kouw@tue.nl
Abstract. Weproposeanactiveinferenceagenttoidentifyandcontrol
amechanicalsystemwithmultiplebodiesconnectedbyjoints.Thisagent
is constructed from multiple scalar autoregressive model-based agents,
coupled together by virtue of sharing memories. Each subagent infers
parameters through Bayesian filtering and controls by minimizing ex-
pected free energy over a finite time horizon. We demonstrate that a
coupled agent of this kind is able to learn the dynamics of a double
mass-spring-damper system, and drive it to a desired position through
abalanceofexplorativeandexploitativeactions.Itoutperformstheun-
coupled subagents in terms of surprise and goal alignment.
Keywords: Activeinference·Expectedfreeenergyminimization·Au-
toregressive models · Bayesian filtering · Adaptive control.
1 Introduction
Our society relies heavily on mechatronic systems for manufacturing, energy,
transport, logistics and healthcare. These systems are still largely designed us-
ingphysics-drivenmodels,offlinesystemidentificationandoptimalcontroltech-
niques. However, this design framework leads to systems that tend to be sen-
sitive to "noise", i.e., sensor and actuator imperfections, external disturbances,
and unmodeled physics (e.g., heat, vibrations). Robustness requires adaptation
toachangingenvironmentbyupdatingamodelrapidly,continuouslyanddata-
efficiently. This is exactly what embodied artificial intelligence and cognitive
robotics strive to achieve [17,14]. Reinforcement learning is a prime candidate
framework, but it tends to be costly in terms of computational resources and
trainingtime[3].Amoreappropriateframeworkforresource-constrainedmecha-
tronicsystemsisactiveinference,whichcharacterizesitselfbyincludingoptimal
information gain in its data acquisition protocol [22,21]. Here we present scalar
activeinferenceagentsthatarecoupledtogethertojointlycontrolamechatronic
system with multiple inputs and multiple outputs [20].
Active inference draws its roots from cognitive science where it is a pro-
cess theory for intelligent behaviour [8]. Many agents with discrete state and
action spaces have been proposed as models of learning, exploration and cu-
riosity [7,5,26,4]. The engineering community wants to use active inference as a
4202
tcO
41
]LM.tats[
1v51401.0142:viXra
2 T.N. Nisslbeck & W.M. Kouw
framework for designing intelligent autonomous systems with continuous state
and action spaces [23,16,1,2,12]. A major challenge in designing such agents are
thecalculationsofthedifferentialentropiesinvolved.Manymodelsassumesome
formofGaussianstatetransitionorlikelihood,oftenwithparametersshapedby
neuralnetworks[28,10,11].Webuildonrecentworkusingautoregressivemodels
fitforresource-constrainedmechatronicsystems[13].Ourcontributionsinclude:
– The formulation of a coupled active inference agent consisting of two scalar
agents that share memories (Sec. 3.3).
– An empirical evaluation of coupled versus uncoupled agents on a double
mass-spring-damper system (Sec. 4).
2 Problem statement
We study the class of multi-joint dynamical systems, characterized by simple
mechanical systems connected in sequence. For example, a double mass-spring-
damper system consists of one mass attached to a base through a spring and an
accompanying damper, with a second mass connected to the first mass through
anotherspringanddamper(Figure1left).Similarly,adoublependulumconsists
ofasinglependulumattachedtoabaseandanothersinglependulumattachedto
theendofthefirstpendulum(Figure1right).Thetaskistofindcontrolpolicies
for each motor such that the multi-joint dynamical system moves to a desired
position. We expect that coupling agents together lets them more accurately
predict joint motion and infer an appropriate control policy sooner.
k 1 c 1
l
• 1
m 1 m 1 g
l
k 2 c 2 g • 2
m g
2
m
2
Fig.1: (Left) A double mass-spring-damper system where block 1 is attached
to a stationary frame and block 2 is attached to the first block. The dynamics
of the system are determined by the masses m of the blocks, the stiffness of
i
the springs k , the amount of friction c the dampeners provide and gravity g.
i i
(Right)Adoublecompoundpendulumsystemconsistingoftwosinglecompound
pendulums joined end-to-end. The dynamics of the system are determined by
the masses m and lengths l of the poles.
i i
Coupling autoregressive active inference agents 3
3 Agent specification
Consider an agent, operating in discrete time, that sends inputs u ∈ R (a.k.a.
k
controls, actions) to a system and measures its output y ∈R. The agent must
k
drivethesystemtoadesiredoutputy withoutknowledgeofitsdynamics.Since
∗
this active inference agent minimizes expected free energy (EFE) based on an
autoregressive exogenous (ARX) model, we refer to it as an ARX-EFE agent.
3.1 Probabilistic model
We specify a likelihood function of the form:
p(y |θ,τ,u ,u¯ ,y¯ )=N
(cid:0)
y |θ
⊺(cid:2)
u u¯ y¯
(cid:3) ,τ−1(cid:1)
, (1)
k k k k k k k k
where the vectors y¯
k
∈ RMy and u¯
k
∈ RMu are buffers containing previous
observationsofthesystemoutputsandinputs,whereM andM arethelengths
y u
of the output and input buffers, respectively. This defines the above likelihood
as an autoregressive model. θ ∈ RD, where D = M +M +1, are coefficients
y u
and τ ∈R+ represents a precision parameter.
The prior distribution on the parameters is a multivariate Gaussian - uni-
variate Gamma distribution [27, ID: D5]:
p(θ,τ)≜NG (cid:0) θ,τ |µ ,Λ ,α ,β (cid:1) =N(θ|µ ,(τΛ )−1(cid:1) G (cid:0) τ |α ,β (cid:1) . (2)
0 0 0 0 0 0 0 0
The prior distributions over inputs are assumed to be independent over time:
p(u )≜N(u |0,η−1), (3)
k k
with precision parameter η. This choice has a regularizing effect on the inferred
controls (Sec. 3.2).
3.2 Inference
Our inference procedure is separated into a parameter belief update procedure
given observed data, and control estimation given parameters.
Parameters First,notethat,attimek,thecontrolu hasbeenexecutedandis
k
knowntotheagent.Henceforth,weshalluseuˆ andyˆ todifferentiateobserved
k k
variables from unobserved ones. Furthermore, let
(cid:2) (cid:3)
x = u u¯ y¯ . (4)
k k k k
The parameter posterior distribution is obtained by Bayesian filtering [25]:
likelihood
(cid:122) (cid:125)(cid:124) (cid:123)
(cid:0) (cid:1)
p yˆ |θ,τ,uˆ ,u¯ ,y¯
(cid:0) (cid:1) k k k k (cid:0) (cid:1)
p θ,τ |D = p θ,τ |D . (5)
k (cid:0) (cid:1) k-1
p yˆ |uˆ ,D
(cid:124) (cid:123)(cid:122) (cid:125) k k k-1 (cid:124) (cid:123)(cid:122) (cid:125)
posterior (cid:124) (cid:123)(cid:122) (cid:125) prior
evidence
4 T.N. Nisslbeck & W.M. Kouw
where D = {yˆ,uˆ }k is the data up to time k. The evidence (a.k.a. marginal
k i i i=1
likelihood) is
(cid:90)
(cid:0) (cid:1) (cid:0) (cid:1) (cid:0) (cid:1)
p yˆ |uˆ ,D = p yˆ |θ,τ,uˆ ,u¯ ,y¯ p θ,τ |D d(θ,τ). (6)
k k k-1 k k k k k-1
We obtain an exact posterior distribution using the multivariate Gaussian -
univariate Gamma prior distribution specified in Eq. 2 [13]:
p(θ,τ |D )=NG(θ,τ |µ ,Λ ,α ,β ). (7)
k k k k k
where
(cid:0) ⊺ (cid:1)−1(cid:0) (cid:1) ⊺
µ = x x +Λ x yˆ +Λ µ , Λ =x x +Λ , (8)
k k k k-1 k k k-1 k-1 k k k k-1
α =α + 1 , β =β + 1(cid:0) yˆ2−µ ⊺ Λ µ +µ ⊺ Λ µ (cid:1) . (9)
k k-1 2 k k-1 2 k k k k k-1 k-1 k-1
The marginal posterior distributions are Gamma distributed and multivariate
location-scale T-distributed [27, ID: P36]:
(cid:90)
p(τ |D )= p(θ,τ |D )dθ =G(τ |α ,β ), (10)
k k k k
p(θ|D )=
(cid:90)
p(θ,τ |D )dτ =T
(cid:0)
θ|µ ,
β kΛ-1(cid:1)
. (11)
k k 2αk k α k
k
The 2α subscript refers to the T-distribution’s degrees of freedom parameter.
k
Controls In order to effectively drive the system to the goal, the agent must
make accurate predictions for future outputs. The predictive probability of the
input, output and parameters at time t=k+1 is:
p(y ,θ,τ,u |D )=p(y |θ,τ,u ,u¯ ,y¯)p(θ,τ |D )p(u ). (12)
t t k t t t t k t
Notethatattimet=k+1,thebuffersy¯ =[yˆ yˆ ...]andu¯ =[uˆ uˆ ...]
t k k−1 t k k−1
contain only observed variables (i.e., there are no products between random
variables).Toincorporatethegoaloutput,weinvert(seeEq.21)theconditional
dependency in the predictive probability for the output and parameters:
p(y |θ,τ,u ,u¯ ,y¯)p(θ,τ |D )=p(y ,θ,τ |u ;D ) (13)
t t t t k t t k
=p(θ,τ |y ,u ;D )p(y ). (14)
t t k t
We intervene on the marginal prior distribution over future output, p(y ), with
t
our chosen goal prior parameters:
p(y )→p(y |y )≜N(y |m ,v ). (15)
t t ∗ t ∗ ∗
Now, to infer a posterior distribution for the control variable u , we introduce
t
an expected free energy functional [7,15],
(cid:104) p(θ,τ |D )q(u ) (cid:105)
F [q]≜E ln k t , (16)
k q(yt,θ,τ,ut) p(θ,τ |y ,u ;D )p(y |y )p(u )
t t k t ∗ t
Coupling autoregressive active inference agents 5
with a variational model of the form:
q(y ,θ,τ,u )≜p(y ,θ,τ |u ;D )q(u ). (17)
t t t t k t
Inferringtheoptimalcontrolattimetreferstominimizingthefreeenergyfunc-
tional with respect to the variational distribution q(u ):
t
q∗(u )=argmin F [q]. (18)
t k
q∈Q
where Q represents the space of candidate distributions. We can re-arrange the
free energy functional to simplify the variational minimization problem:
(cid:104) p(θ,τ |D )q(u ) (cid:105)
E ln k t = (19)
q(yt,ut,θ,τ) p(θ,τ |y ,u ;D )p(y |y )p(u )
t t k t ∗ t
E (cid:104) E (cid:2) ln p(θ,τ |D k ) (cid:3) +ln q(u t )(cid:105) .
q(ut) p(yt,θ,τ|ut;Dk) p(θ,τ |y ,u ;D )p(y |y ) p(u )
t t k t ∗ t
(cid:124) (cid:123)(cid:122) (cid:125)
Jk(ut)
Using J (u )=ln(1/exp(−J (u ))), the expected free energy functional can be
k t k t
expressed as a Kullback-Leibler divergence
(cid:104) q(u ) (cid:105)
F [q]=E ln t , (20)
k q(ut)
exp
(cid:0)
−J (u )
(cid:1)
p(u )
k t t
which is minimal when q∗(u ) = exp (cid:0) −J (u ) (cid:1) p(u ) [19]. Thus, we have an
t k t t
optimal approximate posterior distribution over controls.
The only unknown distribution in J (u ) is the distribution over parameters
k t
given the future output and control (see Eq. 13). It can be related to known
distributions through Bayes’ rule:
p(y |θ,τ,u ,u¯ ,y¯) p(θ,τ |D )
p(θ,τ |y t ,u t ;D k )= (cid:82) t t t t k . (21)
p(y |θ,τ,u ,u¯ ,y¯)p(θ,τ |D )d(θ,τ)
t t t t k
Thedistributionthatresultsfromthemarginalizationinthedenominatoristhe
posterior predictive distribution p(y |u ;D ) and can be derived analytically
t t k
within our model specification [13]:
(cid:90)
p(y |u ;D )≜ p(y |θ,τ,u ,u¯ ,y¯)p(θ,τ |D )d(θ,τ) (22)
t t k t t t t k
=T (cid:16) y |µ ⊺ x , β k(cid:0) x ⊺ Λ−1x +1 (cid:1)(cid:17) , (23)
2αk t k t α t k t
k
(cid:2) (cid:3)
forx = u u¯ y¯ .Ifwereplacep(θ,τ|y ,u )intheexpectedfreeenergyfunction
t t t t t t
with the right-hand side of Eq. 21 and use Eq. 12, then it can be split into two
components:
(cid:104) (cid:105)
J (u )=E −lnp(y |y ) (24)
k t p(yt|ut;Dk) t ∗
(cid:104) p(y ,θ,τ |u ;D ) (cid:105)
−E ln t t k .
p(yt,θ,τ|ut;Dk) p(θ,τ |D )p(y |u ;D )
k t t k
6 T.N. Nisslbeck & W.M. Kouw
One may recognize the first term as a cross-entropy, describing the dissimilarity
betweentheposteriorpredictivedistributionandthegoalpriordistribution[19].
Thesecondtermisthemutualinformationbetweentheparameterposteriorand
the predictive distribution, describing how much information is gained on the
parametersuponmeasuringasystemoutput[19].Solvingtheexpectationsyields
J (u )=C+ 1 (cid:0) (µ ⊺ x −m )2+ β k (x ⊺ Λ−1x +1) (cid:1) − 1 ln(x ⊺ Λ−1x +1), (25)
k t 2v k t ∗ α -1 t k t 2 t k t
∗ k
where C are constants that do not depend on u [13].
t
Unfortunately,thefunctionalformofq∗(u )doesnotappeartobeamember
t
of a known parametric family. This means we do not have access to analytic
solutions of the moments of this distribution. If only its most probable value
is of interest, then the most straightforward approach is maximum a posteriori
(MAP) estimation. The MAP estimator can be written as a minimization over
a negative logarithmic transformation of q∗(u ):
t
uˆ =argmaxq∗(u ) (26)
t t
ut∈U
=argmin J (u )−lnp(u ), (27)
k t t
ut∈U
where U ={u∈R|u ≤u≤u } refers to the space of affordable controls.
min max
It can be used to incorporate practical constraints such as torque limits. If an
approximate uncertainty over the controls is required, then the above MAP
estimate can be extended to a Laplace approximation [6].
3.3 Coupling
TheaboveARX-EFEagentisscalarandcanonlyoperateonsingle-inputsingle-
output systems. We can of course naively group multiple such agents together
to operate on a multi-input multi-output system, as is sometimes done with
Gaussian processes [29, Sec. 9.1]. But that ignores correlations between outputs
which is important for prediction of motion in mechanical systems. We propose
to couple agents together by virtue of incorporating additional signals into the
autoregressive data buffers (i.e., memories) x . For agent j ̸= i, sharing the
t
output buffer between agents would take the form of:
p(y |θ ,τ ,u ,u¯ ,y¯ ,y¯ )=N
(cid:0)
y |θ
⊺(cid:2)
u u¯ y¯ , y¯
(cid:3) ,τ−1(cid:1)
. (28)
i,k i i i,k i,k i,k j,k i,k i i,k i,k i,k j,k
Through sharing data buffers, the prediction for one system component will
dependexplicitlyonanothercomponent.However,thissolutionposesaproblem
forwhentheagentwantstoextenditstimehorizontot>k+1.Inprinciple,due
to the independence assumptions on the prior p(u ) and the variational control
t
posteriors q(u ), the joint control posterior distribution can be formed as:
t
T
q∗(u ,...,u )= (cid:89) p(u ) exp (cid:0) −J (u ) (cid:1) . (29)
t t+T t k t
t=1
Coupling autoregressive active inference agents 7
Forasingleagent,theoutputbufferfort>k+2canbefilledwiththemaximum
aposteriorivalueofitspredictionatt=k+1[13].Thissolutioncanbeapplied
recursively so the time horizon can be extended arbitrarily far. However, in a
coupled setting, agent 1 has to use agent 2’s prediction for k+1. But agent 2’s
prediction depends on agent 1’s action. Thus, the coupled agents must solve a
nested optimization procedure, iteratively alternating between two scalar opti-
mization procedures. This means coupling becomes computationally expensive
for time horizons t>k+1.
3.4 Optimization
The optimization problem in Eq. 27 can be solved in a number of ways. Firstly,
using modern automatic or algorithmic differentiation tools, the gradient and
Hessianwithrespecttou canbeobtained.Iterativeproceduressuchasgradient
t
descent or (quasi-)Newton methods, will then return approximate minimizers.
The most straightforward way to enforce control space constraints is to utilize
an interior-point method [9]. Such a method imposes a log-barrier function,
which increases an objective function drastically as it approaches the constraint
boundary.
Alternatively, one could quantize the control space U, calculate Eq. 27 for
everypossiblevalueandselecttheminimizer.Forasingletime-stepandascalar
control, this procedure may actually be computationally cheaper as it does not
require iteration. It does come at the cost of a quantization error for the esti-
mated uˆ , and, of course, it does not scale well for longer time horizons due to
t
the curse of dimensionality (the discretization interval becomes a tensor).
4 Experiments
4.1 System description
We perform an experiment1 on a double mass-spring-damper system. Its equa-
tion of motions are the following second-order ordinary differential equations
(ODE) [18]:
(cid:20) (cid:21)(cid:20) (cid:21) (cid:20) (cid:21)(cid:20) (cid:21) (cid:20) (cid:21)(cid:20) (cid:21) (cid:20) (cid:21)
m 0 z¨ −(c +c ) c z˙ −(k +k ) k z u
1 1 = 1 2 2 1 + 1 2 2 1 + 1 , (30)
0 m z¨ c −c z˙ k −k z u
2 2 2 2 2 2 2 2 2
whereeachblockihasdisplacement(orposition)z ,velocityz˙,accelerationz¨,
i i i
mass i, damping coefficient c , spring coefficient k , and external force (control)
i i
u . In our experiments, we choose c =c =0.1, k =k =1.0, and m =m =
i 1 2 1 2 1 2
1.0. To update the state of the system, we numerically solve the ODE using
the second-order Størmer-Verlet integration method [24]. This method involves
updating the displacement of the mass as follows:
1
z =z +∆tz˙ + ∆t2z¨, (31)
t+1 t t 2 t
1 Code found at https://github.com/biaslab/IWAI2024-CARXEFE
8 T.N. Nisslbeck & W.M. Kouw
where z¨ is calculated from the equations of motion in Eq. 30. The initial state
t
of the system is the fixed point z = [0.0,0.0,0.0,0.0]. By reducing the step
0
size ∆t and correspondingly increasing the number of updates n , we can
iter
reduce the risk of numerical instabilities. In our experiments, we choose ∆t =
0.01 and n = 120. The observed measurement y at time t of the system
iter t
is the position z plus measurement noise ε ∼ N(0,σ2I ), where I is an
t ε My My
identity matrix of size M ×M , and σ2 is the variance of the noise. We use
y y ε
σ2 =1×10−5.WediscretizethecontrolspaceU inton =999discretecontrols,
ε U
U ={u + k(umax−umin) |k =0,1,2,...,n −1}, using control limits u =
min nU−1 U min
−1.0,u
max
= 1.0. A multi-joint dynamical system has control space UDu and
observation space RDy with dimensions D
y
>1 and D
u
>1, respectively. Since
we couple ARX-EFE agents with single input and single output, we require
D = D agents to control and observe the system. In the case of a double
y u
mass-spring-damper system, D =D =2.
y u
4.2 Comparisons
WecompareasetofcoupledARX-EFEagents,referredtoasCARX-EFEagents,
withasetofuncoupledARX-EFEagents.CARX-EFEanduncoupledARX-EFE
agents differ in the size M of the history vector x . For each buffer type, we use
k
a history size of 2. Thus, an uncoupled ARX-EFE agent has a memory size
M = 4 (2 each for a history of its own observations and controls). CARX-EFE
hasamemorysizeofM =6,asweadditionallyincludeahistoryofobservations
of the other agent. Each agent has a set of parameters (µ ,Λ ,α ,β ,η ). By
0 0 0 0 0
initializing µ as a zero matrix and Λ as an identity matrix (each of size M),
0 0
we ensure initial conditions for optimization that give each element in x equal
t
importance to calculate the control objective in Eq. 25. We further choose α =
0
2.0, β = 3.0, and η = 0.001. The parameters of the goal priors for each agent
0 0
are (m ,v )=(1.0,1.0) and (m ,v )=(2.0,1.0).
1,∗ 1,∗ 2,∗ 2,∗
4.3 Results
Figure 2a shows the displacements of the two masses (z for mass m on the
1 1
left and z for mass m on the right) as a function of time for the coupled
2 2
agents (top row) compared to the uncoupled agents (bottom row). The black
scatterpointsshowtheobservationsthatthesystemgenerated,whiletheagent’s
one-step ahead predictions are shown as purple lines, accompanied by ribbons
indicating one standard deviation of the prediction variance. The goal prior,
indicating the desired displacement over time, is shown in green with a ribbon
reflecting one standard deviation of the goal prior variance. The CARX-EFE
agentsdemonstraterapidstabilizationaroundthegoalprior,withdisplacements
converging towards the goal prior within the first 20 time steps. After reaching
the goal prior, oscillations around it diminish over time, resulting in a stable
state where both displacements remain within a narrow range of the desired
values, as indicated by the low prediction variance. In contrast, the uncoupled
Coupling autoregressive active inference agents 9
(a) Observations (scatter points) and predictions of displacements of the two blocks
(left = displacement z of mass m , right = displacement z of mass m , in purple),
1 1 2 2
plotted over time. Goal prior distributions plotted in green. Both the prediction and
goal prior variance are indicated by a shaded ribbon corresponding to one standard
deviation.Comparedtoitsuncoupledcounterpart,CARX-EFEachieveslowerpredic-
tion uncertainty, as indicated by lower prediction variance.
(b)Controlsplottedovertime.Allagentsexhibitashortinactivityphaseinthebegin-
ning,beforechoosingnon-zerocontrols.Thecontrolsignalsforboththecoupledagent
controlling mass m and the uncoupled agent controlling mass m have an initial pe-
1 2
riodoflargeoscillations,whichgraduallydiminishinamplitude,eventuallyconverging
tospecificvalues(0.0forthecoupledagent,0.4fortheuncoupledagent)withnarrower
oscillations.
Fig.2:ComparisonofpredictionsandcontrolsofasetofCARX-EFEagents(top
rows) versus a set of uncoupled ARX-EFE agents (bottom rows). Each column
represents an agent controlling the first and second mass, respectively.
10 T.N. Nisslbeck & W.M. Kouw
ARX-EFEagentsoscillatemorewildly(untilaroundtimestep45)andhavemore
difficultymaintainingcloseadherencetothegoalprior.Theyexhibitaprolonged
oscillatory phase, where oscillations are more persistent and take significantly
longertodampen.Thehigherpredictionvariancefurtherhighlightstheincreased
uncertainty and instability in the performance of uncoupled ARX-EFE agents
compared to CARX-EFE. The control signals (Fig. 2b) provide further insight
into the observed differences in stabilization performance. Both sets of agents
start with a brief initial phase of inactivity, during which the control signals
remain at zero, keeping the system in its initial, stable state. Following this
inactivityphase,bothsetsofagentsapplynon-zerocontrolinputscharacterized
by relatively large oscillations where they learn the input-output relationship
before moving to the goal prior. After reaching the goal prior, the control pulse
width of one agent in each set gradually converges to specific values (0.0 for the
coupled agent, 0.4 for the uncoupled agent), while the other agent in the set
alternates between a high and a low control value of the control space U. These
oscillations are more narrow for the agent in control of mass m , compared to
2
the uncoupled ARX-EFE agent controlling mass m .
1
Figure 3 compares the model performance of both agent sets over time, di-
vided into two subplots: goal alignment (Fig. 3a) and surprise (Fig. 3b). Each
subplot is further split into two rows, showing the performance of agents con-
trolling the first and second mass, respectively. Goal alignment, quantified as
−logp(y |y ), measures how closely the agent’s predictions align with the de-
t ∗
sired outcome (goal prior). As illustrated in Figure 3a, the CARX-EFE agents
consistently achieve better goal alignment over time, compared to the uncou-
pled ARX-EFE agents. Both agent sets exhibit initial peaks in the alignment
error, reflecting difficulty in achieving goal alignment during the early stages of
control. For the uncoupled agents, these peaks are notably larger and more fre-
quent,reflectinggreaterinitialinstabilityandlesseffectivegoaladherence.Over
time, the CARX-EFE agents maintain more stable and lower error values, sug-
gestingamorerobustalignmentwiththedesiredsystemstate.Predictionerror,
measured by −logp(y |u ), reflects the agent’s ability to minimize surprise by
t t
accuratelypredictingsystembehaviorbasedoncontrolinputs.Figure3bdemon-
stratesthattheCARX-EFEagentsoutperformtheuncoupledARX-EFEagents
by consistently achieving lower surprise values. This suggests that CARX-EFE
agents are more effective in learning the system dynamics and predicting the
outcomeoftheiractions,whichinturnhelpsmaintainbettergoaladherence.In
contrast, the uncoupled agents, initially struggling with higher surprise values,
demonstrate less accurate predictions over time.
Overall, CARX-EFE agents exhibit superior performance by improving sta-
bilization, lower prediction variance, and more efficient control strategies com-
pared to their uncoupled counterparts. These findings underscore the efficacy
of the coupled approach in improving both the accuracy and stability of the
controlsystem,makingCARX-EFEamorerobustchoiceformanagingcomplex
dynamical systems.
Coupling autoregressive active inference agents 11
(a)Goalalignment,measuredby−logp(y |y ),plottedovertime.Coupledagentshave
t ∗
better overall goal alignment, with less fluctuations compared to uncoupled agents.
(b)Predictionerror(surprise),measuredbythenegativelog-likelihood−logp(y |u ),
t t
plotted over time. CARX-EFE agents achieve better performance by minimizing sur-
prise more effectively.
Fig.3: Comparison of model performance of a set of CARX-EFE agents versus
asetofuncoupledARX-EFEagents.Eachsubplotevaluatesaspecificaspectof
performance:(a)goalalignmentand(b)predictionerror(surprise).Lowervalues
indicate better performance. The top and bottom row in each subplot show the
performance of agents controlling the first and second mass, respectively.
12 T.N. Nisslbeck & W.M. Kouw
5 Discussion
Improved ability to stabilize and lower prediction variance demonstrated by
CARX-EFE suggest a significant advantage in scenarios requiring reliable con-
vergence,suchasroboticcontrolandadaptivesystemsinunpredictableenviron-
ments.However,thecurrentfindingsarebasedonasinglesimulationrun,neces-
sitating further validation. Conducting Monte Carlo experiments would confirm
therobustnessofCARX-EFE’sadvantagesacrossvariedconditions.Futurework
shouldalsoevaluatetheCARX-EFEagentsonnonlinearandunderactuatedsys-
tems, like a double pendulum or acrobot, to assess their ability to generalize.
Additionally,benchmarkingagainstothercontrolmethodscouldprovideinsights
into the relative strength of CARX-EFE agents. The current implementation of
CARX-EFE agents relies on a one-step ahead prediction, making their perfor-
mance sensitive to the system update step size (∆t). Addressing this limitation
by extending the prediction capability could reduce the dependence on these
parameters, and possibly improve the efficiency of the coupled approach.
6 Conclusion
Weinvestigatedthecontrolofamulti-jointmechanicalsystembycouplingmulti-
pleautoregressiveactiveinferenceagentsthatminimizeexpectedfreeenergy.We
evaluate the effect of sharing data buffers (i.e., memories) in the autoregressive
models of the agents. Our experiments demonstrate that coupling significantly
improves the agent’s ability to achieve both better goal alignment and lower
prediction error. CARX-EFE agents consistently outperformed their uncoupled
counterparts, showing lower prediction uncertainty with higher prediction accu-
racy(lowersurprise),andgreater long-term stabilityaroundthe goalprior.Itis
importanttonotethattheagentislimitedtoone-stepaheadpredictions.Future
researchshouldfocusonextendingthehorizonoftheagents,andimprovingthe
optimization procedure in MAP estimation.
Acknowledgments. The authors gratefully acknowledge support by the Eindhoven
Artificial Intelligence Systems Institute and the Ministry of Education, Culture and
Science of the Government of the Netherlands.
Disclosure of Interests. The authors have no competing interests to declare that
are relevant to the content of this article.
References
1. Baioumy, M., Duckworth, P., Lacerda, B., Hawes, N.: Active inference for inte-
grated state-estimation, control, and learning. In: IEEE International Conference
on Robotics and Automation. pp. 4665–4671 (2021)
2. Baltieri,M.,Buckley,C.L.:Pidcontrolasaprocessofactiveinferencewithlinear
generative models. Entropy 21(3), 257 (2019)
Coupling autoregressive active inference agents 13
3. Bucak, I.O., Zohdy, M.A.: Reinforcement learning control of nonlinear multi-link
system. Engineering Applications of Artificial Intelligence 14(5), 563–575 (2001)
4. Da Costa, L., Parr, T., Sajid, N., Veselic, S., Neacsu, V., Friston, K.: Active in-
ferenceondiscretestate-spaces:Asynthesis.JournalofMathematicalPsychology
99, 102447 (2020)
5. Friston,K.,FitzGerald,T.,Rigoli,F.,Schwartenbeck,P.,Pezzulo,G.,etal.:Active
inferenceandlearning.Neuroscience&BiobehavioralReviews68,862–879(2016)
6. Friston,K.,Mattout,J.,Trujillo-Barreto,N.,Ashburner,J.,Penny,W.:Variational
free energy and the Laplace approximation. Neuroimage 34(1), 220–234 (2007)
7. Friston,K.,Rigoli,F.,Ognibene,D.,Mathys,C.,Fitzgerald,T.,Pezzulo,G.:Active
inference and epistemic value. Cognitive neuroscience 6(4), 187–214 (2015)
8. Friston, K.J., Daunizeau, J., Kilner, J., Kiebel, S.J.: Action and behavior: a free-
energy formulation. Biological Cybernetics 102(3), 227–260 (2010)
9. Gill, P.E., Murray, W., Wright, M.H.: Practical optimization. SIAM (2019)
10. van der Himst, O., Lanillos, P.: Deep active inference for partially observable
MDPs. In: International Workshop on Active Inference. pp. 61–71 (2020)
11. Huebotter,J.,Thill,S.,Gerven,M.v.,Lanillos,P.:Learningpoliciesforcontinuous
controlviatransitionmodels.In:InternationalWorkshoponActiveInference.pp.
162–178. Springer (2023)
12. Imohiosen, A., Watson, J., Peters, J.: Active inference or control as inference? A
unifyingview.In:InternationalWorkshoponActiveInference.pp.12–19.Springer
(2020)
13. Kouw, W.M.: Information-seeking polynomial NARX model-predictive control
throughexpectedfreeenergyminimization.IEEEControlSystemsLetters(2023)
14. Krichmar, J.L.: Neurorobotics—a thriving community and a promising pathway
toward intelligent cognitive robots. Frontiers in Neurorobotics 12, 42 (2018)
15. van de Laar, T., Koudahl, M., van Erp, B., de Vries, B.: Active inference and
epistemicvalueingraphicalmodels.FrontiersinRoboticsandAI9,794464(2022)
16. Lanillos,P.,Meo,C.,Pezzato,C.,Meera,A.A.,Baioumy,M.,Ohata,W.,Tschantz,
A., Millidge, B., Wisse, M., Buckley, C.L., et al.: Active inference in robotics and
artificial agents: Survey and challenges. arXiv:2112.01871 (2021)
17. Liagkou, V., Stylios, C., Pappa, L., Petunin, A.: Challenges and opportunities in
industry 4.0 for mechatronics, artificial intelligence and cybernetics. Electronics
10(16), 2001 (2021)
18. Lopes, M.T., Castello, D.A., Matt, C.F.T.: A bayesian inference approach to esti-
mate elastic and damping parameters of a structure subjected to vibration tests.
In:ProceedingsofInverseProblems,DesignandOptimizationSymposium(2010)
19. MacKay, D.J.: Information theory, inference and learning algorithms. Cambridge
University Press (2003)
20. Massioni,P.,Verhaegen,M.:Distributedcontrolforidenticaldynamicallycoupled
systems: A decomposition approach. IEEE Transactions on Automatic Control
54(1), 124–135 (2009)
21. Parr, T., Friston, K., Zeidman, P.: Active data selection and information seeking.
Algorithms 17(3), 118 (2024)
22. Parr, T., Pezzulo, G., Friston, K.J.: Active inference: the free energy principle in
mind, brain, and behavior. MIT Press (2022)
23. Pio-Lopez, L., Nizard, A., Friston, K., Pezzulo, G.: Active inference and robot
control: a case study. Journal of The Royal Society Interface 13(122), 20160616
(2016)
24. Press, W.H.: Numerical recipes: The art of scientific computing. Cambridge Uni-
versity Press (2007)
14 T.N. Nisslbeck & W.M. Kouw
25. Särkkä, S.: Bayesian filtering and smoothing, vol. 3. Cambridge University Press
(2013)
26. Schwartenbeck, P., Passecker, J., Hauser, T.U., FitzGerald, T.H., Kronbichler,
M., Friston, K.J.: Computational mechanisms of curiosity and goal-directed ex-
ploration. eLife 8, e41703 (2019)
27. Soch, J., Faulkenberry, T.J., Petrykowski, K., Allefeld, C.: The book of statistical
proofs (2024). https://doi.org/10.5281/zenodo.4305949
28. Ueltzhöffer, K.: Deep active inference. Biological Cybernetics 112(6), 547–573
(2018)
29. Williams,C.K.,Rasmussen,C.E.:GaussianProcessesforMachineLearning.MIT
Press (2006)

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Coupled autoregressive active inference agents for control of multi-joint dynamical systems"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
