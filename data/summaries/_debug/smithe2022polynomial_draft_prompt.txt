=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Polynomial Life: the Structure of Adaptive Systems
Citation Key: smithe2022polynomial
Authors: Toby St Clere Smithe

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2022

Key Terms: systems, indexed, world, category, adjusting, structure, adaptive, life, polynomial, inference

=== FULL PAPER TEXT ===

Polynomial Life: the Structure of Adaptive Systems
Toby St. ClereSmithe
ToposInstitute
toby@topos.institute
Weextendourearlierworkonthecompositionalstructureofcyberneticsystemsinordertoaccount
fortheembodimentofsuchsystems. Alltheirinteractionsproceedthroughtheirbodies’boundaries:
sensationsimpingeontheirsurfaces,andactionscorrespondtochangesintheirconfigurations. We
formalize this morphological perspective using polynomial functors. The ‘internal universes’ of
systems are shown to constitute an indexed category of statistical games over polynomials; their
dynamics form an indexed category of behaviours. We characterize active inference doctrines as
indexedfunctorsbetweensuchcategories,resolvinganumberofopenproblemsinourearlierwork,
andpointingtoaformalizationofthefreeenergyprincipleasadjointtosuchdoctrines.Weillustrate
ourframeworkthroughfundamentalexamplesfrombiology,includinghomeostasis,morphogenesis,
andautopoiesis,andsuggestaformalconnectionbetweenspatialnavigationandtheprocessofproof.
1 Introduction
In asubmission toACT2020 [15], wepresented somefirststeps towards atheory of categorical cyber-
netics, motivated byconcerns about whatgivesphysical systems life. Weexplained that perception and
action could both be described as processes of Bayesian inference: on the one hand, adjusting beliefs
about the world on the basis of observational evidence; on the other, adjusting the world itself in order
better to match beliefs. In each case, the system must instantiate a number of structures: a choice of
‘prior’ belief about the state of the world; a mechanism to generate predictions about sense-data on the
basis of that belief, called a ‘stochastic channel’; and a (typically approximate) Bayesian inversion of
thatchannel, bywhichtoupdatethosebeliefs, inlightofsensory observations.
The pairing ofa prior witha stochastic channel corresponds to whatis called in the informal litera-
tureagenerative model,anditiscommontosuppose thatthesemodels arehierarchical: thatis,thatthe
stochastic channel factors as some composite; one imagines that each factor corresponds to predictions
at some level of detail, cascading for example down from high-level abstractions to individual photore-
ceptors. In our earlier submission, we formalized this compositional structure using the bidirectional
‘lens’pattern1 —sincepredictionsandinversionsareoppositelydirected—andcharacterized anumber
of approximate inference processes using a novel category of statistical games, whose best responses
correspond to optimal inferences. A cybernetic system wasthen defined as a‘dynamical realisation’ of
suchagame.
This formalism left some things to be desired: our notion of dynamical realisation was ill-defined,
and the notion of‘action’ wasoverly abstract. In this submission, weresolve these issues, substantially
simplifying ourpresentation alongtheway. Weexplainthatvariousrecipesforperformingapproximate
inference, corresponding toourearlierinformalnotionofdynamicalrealisation, formfunctorialapprox-
imate inference doctrines, between appropriate categories of statistical games and dynamical systems.
Then,toformalizeasatisfactorynotionofaction,wenotethatanyactivesystemhasaboundarydefining
1See[14]forapedagogicalpresentationofthefundamentalstructures.
K.Kishida(Ed.):FourthInternationalConference ©T.St.ClereSmithe
onAppliedCategoryTheory(ACT2021). ThisworkislicensedundertheCreativeCommons
EPTCS372,2022,pp.133–148,doi:10.4204/EPTCS.372.10 Attribution-ShareAlikeLicense.
134 PolynomialLife
itsmorphology,andthatitactsbychangingtheshapeofthisboundary;inordertoactonanothersystem,
itcouplespartofthisboundary tothatothersystem,soastochangethecomposite shape.
Toformalize theshapes ofsystemsandtheirinteractions, weadoptpolynomial functors: eachpoly-
nomial will encode the ‘phenotype’ (possible shapes or configurations) of a system, and the sensorium
possible in each configuration. To give such systems life, we construct categories of statistical games
and dynamical behaviours indexed by polynomials. An active inference doctrine is then an indexed
functor between such categories. This framework enables a number of possibilities: we can construct
a generative model for a corporation on the basis of models for its employees; we give compositional
descriptionsoffundamentalprocessesoflifesuchashomeostasisandmorphogenesis, andpointtowards
anaccountofautopoiesis;andwesketchtheprocessbywhichlivingsystemsinternalizethestructuresof
theirenvironments, andnavigate accordingly, notingthatsuchnavigation inabstractspacescorresponds
precisely totheprocess ofproof.
The work presented here iswork in progress, and owing to constraints of space and time, it has not
been possible to elaborate everything that we would have liked; this means that we defer proofs of the
mainresultstosubsequentelaborationsofthisextendedabstract. Twosuchelaborationsareourseriesof
papersoncompositionalactiveinference,beginningwith[16],andourworkonopendynamicalsystems
withpolynomial interfaces [18]. Notwithstanding theselimitations, webelieve theresults heregosome
ofthewaytoansweringtheopenquestions,ofeleganceandinteraction,sketchedattheendofourearlier
submission. Weseethisworkasmakingbabystepstowardsatheoryofembodied cybernetics.
Acknowledgements WethankthemembersoftheToposInstituteforstimulating discussions, andthe
Foundational Questions InstituteandToposInstitute forfinancialsupport.
2 Simpler Statistical Games
Webeginbysketchingarefinementofthestatisticalgamesformalismdevelopedin[15]. Formuchmore
detail, wereferthereaderto[16]. First,werecallthebidirectional structure ofBayesianinversion.
2.1 BayesianLenses
Definition 2.1 ([11, Def. 3.3]). The category GrLens of Grothendieck lenses for a pseudofunctor F :
F
C op→CatisthetotalcategoryoftheGrothendieck construction forthepointwiseopposite ofF.
Proposition 2.2 (GrLens is a category). The objects (GrLens ) of GrLens are (dependent) pairs
F F 0 F
(C,X)withC:C andX :F(C),anditshom-setsGrLens (C,X),(C′,X′) aredependent sums
F
(cid:0) (cid:1)
GrLens (C,X),(C′,X′) = ∑ F(C) F(f)(X′),X
F
(cid:0) (cid:1) f:C(C,C′) (cid:0) (cid:1)
so that a morphism (C,X)→7 (C′,X′) is a pair (f,f†) of f :C(C,C′) and f† :F(C) F(f)(X′),X . We
callsuchpairsGrothendieck lensesforF orF-lenses. (cid:0) (cid:1)
Proofsketch. The identity Grothendieck lens on (C,X) is id =(id ,id ). Sequential composition
(C,X) C X
is as follows. Given (f,f†):(C,X)→7 (C′,X′) and (g,g†):(C′,X′)→7 (D,Y), their composite (g,g†)◦
|
(f,f†) is defined to be the lens g◦ f,f†◦F(f)(g†) :(C,X)→7 (D,Y). Associativity and unitality of
composition followfromthefun(cid:0)ctoriality ofF. (cid:1)
T.St.ClereSmithe 135
Definition 2.3. Suppose F(C) =C , with F :C op →Cat a pseudofunctor. Define SimpGrLens to
0 0 F
be thefull subcategory of GrLens whoseobjects are duplicate pairs (C,C) ofobjectsC inC. Wecall
F
SimpGrLens the category of simple F-lenses. More generally, any lens between such duplicate pairs
F
willbecalled asimple lens. Sinceduplicating theobjects inthe pairs (C,C)isredundant, wewillwrite
theobjectssimplyasC.
Definition 2.4. Let(C,⊗,I)beamonoidal category enriched inaCartesian closed category V. Define
theC-state-indexed category Stat:C op→V-Catasfollows.
Stat : Cop → V-Cat
Stat(X) := C
0 0
 Stat(X)(A,B) := V(C(I,X),C(A,B)) 
X 7→Stat(X):= (1)
id :C(I,X)→C(A,A)
  id A : Stat(X)(A,A) := (cid:26) A ρ 7→ id A  
 
Stat(f) : Stat(X) → Stat(Y)
 
Stat(X) = Stat(Y)
f :C(Y,X)7→ 0 0
  V(C(I,X),C(A,B)) → V(C(I,Y),C(A,B))  
  α 7→ f∗α: σ:C(I,Y) 7→ α(f•σ):C(A,B)  
 
(cid:0) (cid:1) (cid:0) (cid:1)
Composition in each fibre Stat(X) is as in C. Explicitly, indicating morphisms C(I,X) → C(A,B)
X X X X
in Stat(X) by A−→• B, and given α:A−→• B and β:B−→• C, their composite is β◦α:A−→• C :=ρ7→
β(ρ)•α(ρ),wherehereweindicatecomposition inC by•andcomposition inthefibresStat(X)by◦.
Given f :Y →• X inC,theinduced functorStat(f):Stat(X)→Stat(Y)actsbypullback.
Example2.5. Typically,achoiceofC abovewillbetheKleislicategoryKℓ(P)ofaprobabilitymonad,
such as the Giry monad G :Meas→Meas on measurable spaces; and V will either be Set or (better)
some ‘nice’ category of measurable spaces. However, the category Meas of general measurable spaces
is not Cartesian closed, as there is no general way to make the evaluation maps Meas(X,Y)×X →
Y measurable, meaning that if we take C = Kℓ(G) above, then we are forced to take V = Set. In
turn, this makes the inversion maps c† : Kℓ(G)(1,X) → Kℓ(G)(Y,X) into mere functions. We can
salvage measurability by working instead with Kℓ(Q), where Q:QBS→QBSis the analogue of the
Giry monad for quasi-Borel spaces [10]. The category QBS is indeed Cartesian closed, and Kℓ(Q)
is enriched in QBS, so that we can instantiate Stat there, and the corresponding inversion maps are
accordingly measurable.
WedefinethecategoryofBayesianlensesinC tobethecategory ofStat-lenses.
Definition 2.6. The category BayesLens
C
of Bayesian lenses in C is the category GrLensStat of
Grothendieck lenses for the functor Stat. A Bayesian lens is a morphism in BayesLens . Where the
C
category C isevidentfromthecontext, wewilljustwriteBayesLens.
Unpacking this definition, we find that the objects of BayesLens are pairs (X,A) of objects of
C
C. Morphisms (that is, Bayesian lenses) (X,A)→7 (Y,B) are pairs (c,c†) of a channel c:X→• Y and a
“generalized Bayesianinversion” c†:B−→ X • A;thatis,elementsofthehomobjects
BayesLens
C
(X,A),(Y,B) :=GrLensStat (X,A),(Y,B)
(cid:0) (cid:1) ∼ =C(X,Y)×V(cid:0) C(I,X),C(B(cid:1),A) .
(cid:0) (cid:1)
136 PolynomialLife
TheidentityBayesianlenson(X,A)is(id ,id ),wherebyabuseofnotation id :C(I,Y)→C(A,A)is
X A A
theconstant mapid definedinequation (1)thattakesanystateonY totheidentity onA.
A
The sequential composite (d,d†)◦(c,c†) of (c,c†):(X,A)→7 (Y,B) and (d,d†):(Y,B)→7 (Z,C) is
|
theBayesianlens (d•c),(c†◦c∗d†) :(X,A)→7 (Z,C)where(c†◦c∗d†):C−→ X • Atakesastateπ:I→• X
tothechannelc
π
† •(cid:0)d†
c•π
:C→• A. (cid:1)
Definition 2.7. Given a Bayesian lens (c,c′):(X,A)→7 (Y,B), wewill call c its forwards or prediction
channel andc′ itsbackwardsorupdatechannel(eventhough c′ isreallyafamilyofchannels).
Definition 2.8 (Bayesian inversion). We say that a channel c:X→• Y admits Bayesian inversion with
respect toπ:I→• X ifthere exists achannel c
π
† :Y →• X,called the Bayesian inversion of cwithrespect
toπ,satisfying thefollowingequation [6,eq. 5]inthegraphical calculus ofC:
X Y X Y
c c†
π
= (2)
c
π π
WesaythatcadmitsBayesianinversiontoutcourtifcadmitsBayesianinversionwithrespecttoallstates
π:I→• X suchthat c•πhasnon-empty support. Wesaythatacategory C admitsBayesian inversion if
allitsmorphismsadmitBayesianinversion toutcourt.
Definition2.9. Wecallthepairing(π,c)ofastateπ:I→• X withachannelc:X→• Y agenerativemodel
X→• Y. Itinduces ajointdistributionω
(π,c)
:=(id
X
⊗c)•
X
•π:I→• X⊗Y.
Definition2.10. Let(c,c†):(X,X)→7 (Y,Y)beaBayesian lens. Wesaythat(c,c†)isexact ifcadmits
Bayesian inversion and, for each π: I→• X such that c•π has non-empty support, c and c
π
† together
satisfyequation (2). Bayesianlensesthatarenotexactaresaidtobeapproximate.
Definition2.11(Almost-equality). Givenastateπ:I→• X,wesaythattwoparallelchannelsc,d:X→• Y
π
areπ-almost-equal,denotedc∼d,ifthejointdistributionsofthetwogenerativemodels(π,c)and(π,d)
areequal;thatis,if(id⊗c)• •π=(id⊗d)• •π.
Theorem 2.12 ([14]). Let (c,c†) and (d,d†) be sequentially composable exact Bayesian lenses. Then
the contravariant component of the composite lens (d,d†)◦(c,c†)=(d•c,c†◦c∗d†)is, up to d•c•π-
|
almost-equality, theBayesian inversion of d•c withrespect to anystateπon thedomain ofcsuch that
c•πhasnon-empty support.
2.2 Statistical Games
Theperformance ofastatistical orcybernetic system depends upon itsinteraction withitsenvironment,
andthepriorbeliefs thatitstartedwith. Wewilltherefore defineastatistical gametobeaBayesianlens
pairedwithafitnessfunctionmeasuringperformanceincontext;andforthisweneedanotionofcontext.
Forthisnotion, wetakeinspiration fromcompositional gametheory[2].
T.St.ClereSmithe 137
Definition2.13. Acontext foraBayesianlensisanelementoftheprofunctor BayesLens definedby
C
BayesLens × BayesLens op → V
C C
− × = 7→ BayesLens ((I,I),−)×BayesLens (=,(I,I))
C C
where I is the monoidal unit in C, BayesLens ((I,I),−) : BayesLens → V is the representable
C C
copresheaf on (I,I), and BayesLens (=,(I,I)) : BayesLens op → V is the representable presheaf.
C C
Henceacontextforalens(X,A)→7 (Y,B)isanelementof
BayesLens (X,A),(Y,B) :=BayesLens (I,I),(X,A))×BayesLens ((Y,B),(I,I) .
C C C
(cid:0) (cid:1) (cid:0) (cid:1)
Proposition 2.14. WhenI isterminalinC andthebaseVofenrichment ofC iswellpointed (aswhen
V=Set),wehaveBayesLens
C
(X,A),(Y,B) ∼ =C(I,X)×V C(I,B),C(I,Y) .
(cid:0) (cid:1) (cid:0) (cid:1)
c ! !
Proof. Astraightforwardcalculationwhichweomit: usethatX−→Y −→I=X−→Iforanyc:X→Y.
f
Proposition 2.15. Given a context (π,k):BayesLens (X,A),(Z,C) for a composite lens (X,A)→7
C
(Y,B)→ g 7 (Z,C),weobtaincontexts forthefactors: (cid:0) (cid:1)
BayesLens (X,A),g (π,k)=(π,k◦g):BayesLens (X,A),(Y,B) ,
C | C
BayesLens (cid:0)f,(Z,C) (cid:1) (π,k)=(f ◦π,k):BayesLens (cid:0) (Y,B),(Z,C) (cid:1) .
C | C
(cid:0) (cid:1) (cid:0) (cid:1)
Wearenowinaposition todefinethecategory ofstatistical gamesoverC.
Proposition 2.16. Let C be a V-category admitting Bayesian inversion and let (R,+,0) be a monoid
in V. Then there is a category SGameR]C whose objects are the objects of BayesLens and whose
[ C
morphisms (X,A)→(Y,B) are statistical games: pairs (f,φ) of a lens f :BayesLens
C
(X,A),(Y,B)
and a fitness function φ:BayesLens
C
(X,A),(Y,B) →R. When R is the monoid of re(cid:0)als R, then w(cid:1)e
justdenotethecategory bySGameC. (cid:0) (cid:1)
Proof. Suppose given statistical games (f,φ):(X,A)→(Y,B) and (g,ψ):(Y,B)→(Z,C). We seek a
composite game(g,ψ)◦(f,φ):=(gf,ψφ):(X,A)→(Z,C). Wehavegf =g◦ f bylenscomposition.
|
Propositon 2.15givesusafamilyoffunctions localCtxwithsignature
BayesLens (X,A),(Z,C) ×BayesLens (X,A),(Y,B) ×BayesLens (Y,B),(Z,C)
C C C
→BayesLen(cid:0)s (X,A),(Y, (cid:1)B) ×BayesLen(cid:0)s (Y,B),(Z, (cid:1)C) . (cid:0) (cid:1)
C C
(cid:0) (cid:1) (cid:0) (cid:1)
Wetherefore identifythecompositefitnessfunctionψφas
ψφ:=+◦(φ,ψ)◦localCtx(−,f,g)
where +:R×R→R is the monoid operation. The identity game (X,A)→(X,A) is given by (id,0),
thepairing oftheidentity lenson(X,A)withtheunit0ofthemonoidR. Associativity andunitality are
immediatefromlenscomposition andthemonoidlaws.
Definition2.17. WewillwriteSimpSGame
C
֒→SGameC forthefullsubcategoryofSGameC defined
on simple Bayesian lenses (X,X)→7 (Y,Y). As in the case of simple lenses (Definition 2.3), we will
eschewredundancy bywritingtheobjects (X,X)simplyasX.
Wenowpresentsomekeyexamplesofstatistical games.
138 PolynomialLife
Example2.18(Bayesianinference). LetD:C(I,X)×C(I,X)→Rbeameasureofdivergencebetween
statesonX. Thena(simple)D-Bayesianinferencegameisastatisticalgame(X,X)→(Y,Y)withfitness
function φ:BayesLens (X,X),(Y,Y) → R given by φ(π,k) =E D c′ (y),c†(y) , where
C y∼k•c•π π π
h (cid:16) (cid:17)i
(c,c′)constitutes thelens (cid:0) partofthegam (cid:1) eandc† istheexactinversion ofcwithrespecttoπ.
π
Note that we say that D is a “measure of divergence between states on X”. By this we mean any
function ofthegiventypewiththesemantical interpretation thatitactslikeadistance measure between
states. ButthisisnottosaythatDisametricorevenpseudometric. OneusuallyrequiresthatD(π,π′)=
0 ⇐⇒ π=π′, but typical choices do not also satisfy symmetry nor subadditivity. An important such
typicalchoiceistherelativeentropyorKullback-Leibler divergence, denotedD .
KL
Definition2.19. TheKullback-Leibler divergence D :C(I,X)×C(I,X)→Risdefinedby
KL
D (α,β):= E [logp(x)]− E [logq(x)]
KL
x∼α x∼α
where pandqaredensityfunctions corresponding tothestatesαandβ.
Typically, computing D (c′ (x),c†(x)) iscomputationally difficult, soone resorts tooptimizing an
KL π π
upperbound;aprominent choiceisthefreeenergy[8].
Definition2.20(D-free energy). Let(π,c) beagenerative model withc:X→• Y. Let p
c
:Y ×X →R
+
and p : X → R be density functions corresponding to c and π. Let p :Y → R be a density
π + c•π +
function for the composite c•π. Letc
π
′ be achannelY →• X that wetake to be an approximation of the
Bayesianinversion ofcwithrespecttoπandthatadmitsadensityfunction q:X×Y →R . Finally,let
+
D:C(I,X)×C(I,X)→Rbe ameasure ofdivergence between states onX. Then the D-freeenergy of
c′ withrespecttothegenerative modelgivenanobservation y:Y isthequantity
π
F (c′ ,c,π,y):= E [−logp (y|x)]+D c′ (y),π . (3)
D π c π
x∼c′(y)
π (cid:0) (cid:1)
Wewillelidethedependence onthemodelwhenitisclearfromthecontext, writingonlyF (y).
D
TheD-freeenergy isanupperboundonDwhenDistherelativeentropy D .
KL
Proposition 2.21(Evidenceupperbound). TheD -freeenergysatisfiesthefollowingequality:
KL
q(x|y)
F (y)=D c′ (y),c†(y) −logp (y)= E log
DKL KL (cid:2) π π (cid:3) c•π x∼c π ′(y)(cid:20) p c (y|x)·p π (x)(cid:21)
Sincelogp (y)isalways negative, the freeenergy isanupper bound onD c′ (y),c†(y) ,wherec†
c•π KL π π π
h i
istheexact Bayesian inversion ofthechannel cwithrespect tothepriorπ. Similarly, the freeenergy is
anupperboundonthenegativelog-likelihood−logp (y). Thinkingofthislatterquantityasameasure
c•π
ofthe“modelevidence” givesusthealternative nameevidenceupperbound fortheD -freeenergy.
KL
Any system that performs (approximate) Bayesian inversion can thus be seen as minimizing some
free energy. The free energy principle says that all it means to be an adaptive system is to embody a
process ofapproximate inference inthisway. Wetherefore definefreeenergygames:
Example2.22(Freeenergygame). LetD:C(I,X)×C(I,X)→Rbeameasureofdivergence between
states on X. Then a simple D-free energy game is a simple statistical game (X,X)→ (Y,Y) with fit-
nessfunctionφ:BayesLens (X,X),(Y,Y) →Rgivenbyφ(π,k)=E [F (c′ ,c,π,y)]where
C y∼k•c•π D π
(c,c′):(X,X)→7 (Y,Y)constit(cid:0)utes thelensp(cid:1)artofthegame.
T.St.ClereSmithe 139
Remark 2.23. Itis also often of interest to consider parameterized channels, for which we can use the
Para construction [13]. This acts by adjoining an object of parameters to the domain of the category
at hand (such as the category of Bayesian lenses), and tensoring parameters of composite morphisms.
Formally, this corresponds to a generalization of the indexed category of state-dependent morphisms,
and forms the subject of another paper in these proceedings [4]. The parameters might represent the
‘weights’ of a neural network, or encode some structure about the possible predictions. Lacking the
spacetodojusticetothisstructure here,wenonetheless leaveitatthat,andreferthereadertoourpaper
[16]formoredetails.
3 Systems Within Interfaces; Worlds Within Worlds
In this section, we develop the structures required for extending the formalism of statistical games to
embodied systems.
3.1 PolynomialsforEmbodiment andInteraction
Each system in our universe inhabits some interface or boundary. It receives signals from its environ-
ments through this boundary, and can act by changing its shape (and, as we will see later, its position).
Asasystemchangesitsshape, thesetofpossibleimmanentsignalsmightchangeaccordingly: consider
a hedgehog rolling itself into a ball, thereby protecting its soft underbelly from harm (amongst other
immanentsignals). Asystemmayalsochangeitsshapebycouplingitselftosomeothersystem,suchas
whenwepickupchalktoworkthrough aproblem. Andshapescanbeabstract: wechangeour‘shapes’
when we enter an online video conference, or move within a virtual reality. We describe all of these
interactions formallyusingpolynomial functors, drawingontheworkof[12].
Definition 3.1. Let E be a locally Cartesian closed category, and denote by yA the representable co-
presheaf yA:=E(A,−):E →E. Apolynomial functor pisacoproduct ofrepresentable functors, writ-
ten p:=∑ ypi,where p(1):E istheindexingobject. ThecategoryofpolynomialfunctorsinE isthe
i:p(1)
fullsubcategoryPoly
E
֒→[E,E]oftheE-copresheafcategoryspannedbycoproductsofrepresentables.
Amorphismofpolynomials istherefore anaturaltransformation.
Remark 3.2. Every polynomial functor P:E →E corresponds to a bundle p:E →B in E, for which
B=P(1) and for each i:P(1), the fibre p is P(i). We will henceforth elide the distinction between a
i
copresheaf P and its corresponding bundle p, writing p(1) :=B and p[i]:= p, where E =∑ p[i]. A
i i
naturaltransformation f :p→qbetweencopresheavesthereforecorrespondstoamapofbundles. Inthe
caseofpolynomials, bytheYonedalemma,thismapisgivenbya‘forwards’ map f : p(1)→q(1)and
1
a family of ‘backwards’ maps f# :q[f (-)]→ p[-] indexed by p(1), as in the left diagram below. Given
1
f : p→qandg:q→r,theircompositeg◦ f : p→risasintherightdiagrambelow.
f# (gf)#
E f∗F F E f∗g∗G G
y y
p q p r
B B
f1
C B B
g1◦f1
D
Here,(gf)# isgivenbythe p(1)-indexed familyofcomposite mapsr[g (f (-))]− f − ∗g → # q[f (-)]−→ f# p[-].
1 1 1
In our morphological semantics, we will call a polynomial p a phenotype, its base type p(1) its
morphology andthetotalspace∑ p[i]itssensorium. Wewillcallelementsofthemorphology shapesor
i
configurations, andelementsofthesensorium immanentsignals.
140 PolynomialLife
Proposition3.3([12]). Thereisamonoidalstructure(Poly ,⊗,y)thatweinterpretas“puttingsystems
E
inparallel”. Given p:∑ p[i]→ p(1)andq:∑ q[j]→q(1),wehave p⊗q=∑ ∑ p[i]×q[j]→ p(1)×
i j i j
q(1). y:1→1isthenclearlyunital.
Proposition3.4([12]). Themonoidalstructure(Poly ,⊗,y)isclosed,withcorresponding internalhom
E
denoted [−,−].
Weinterpret morphisms (f ,f#)ofpolynomials asencoding interaction patterns; inparticular, such
1
morphismsencodehowcompositesystemsactasunities. Forexample,amorphism f : p⊗q→rspeci-
fieshowthesystems pandqcometogethertoformasystemr: themap f encodeshowr-configurations
1
areconstructed fromconfigurations of pandq;andthemap f# encodeshowimmanentsignalson pand
qresultfromsignalsonrorfromtheinteraction of pandq. Forintuition, considertwopeopleengaging
inahandshake, oranenzymeactingonaprotein toformacomplex. Theinternal hom[o,p]encodes all
thepossible waysthatano-phenotype systemcan“pluginto”a p-phenotype system.
Remark 3.5. In the literature on active inference and the free energy principle, there is much debate
abouttheconceptandroleof‘Markovblankets’,whicharesometimesconceivedtorepresentthebound-
ary of an adaptive system. We believe that the algebra of polynomials will help to make such thinking
precise, whereitdepartsfromtheestablished usageofMarkovblankets inBayesiannetworks.
3.2 Dynamical Systems onPolynomialInterfaces
Although some dynamical systems can be modelled within Poly itself, we prefer to take a fibrational
E
perspective, following the idea that polynomials represent the boundaries of systems, separating ‘inter-
nal’ states from ‘external’. We will therefore adopt a pattern of indexing categories by polynomials: in
thecaseofdynamics, thefibreoverapolynomial willbeacategory ofpossible internal systems, whose
projection forgets the internal structure. We can only sketch the relevant structures here, and so refer
the reader to our subsequent paper [18]where wegive ageneral account of open dynamical systems as
coalgebras forpolynomial functors.
Definition 3.6. Let P : E → E be a probability monad on the category E, and let p : Poly E be a
polynomial inE. Let(T,+,0)beamonoid inE,representing time. ThenanopenMarkovprocess on
theinterface pwithtimeTconsistsinatripleϑ:=(S,ϑo,ϑu)ofastatespaceS:E andtwomorphisms
ϑo :T×S→ p(1)andϑu :∑ t:T∑ s:S p[ϑo(t,s)]→PS,suchthatforanysectionσ: p(1)→∑ i:p(1) p[i]
of p,themapsϑσ:T×S→PSgivenby
∑S− ϑ − o − (− − ) − ∗ → σ ∑∑p[ϑo(−,s)]− ϑ → u PS
t:T t:Ts:S
constitute an object in the functor category Cat BT,Kℓ(P) , where BT is the delooping of T and
Kℓ(P)istheKleislicategory ofP. Wecallϑσ(cid:0)theclosureo(cid:1)fϑbyσ.
Proposition 3.7. OpenMarkov processes over pwithtimeTform acategory, denoted MrkProc T (p).
P
Its morphisms are defined as follows. Letϑ:=(X,ϑo,ϑu) and ψ:=(Y,ψo,ψu) be two Markov pro-
cesses over p. A morphism f :ϑ→ψconsists in a morphism f :X →Y such that, for any time t :T
and global section σ: p(1)→ ∑ p[i] of p, we have a natural transformation ϑσ →ψσ between the
i:p(1)
closures. The identity morphism id on the open Markov process ϑis given by the identity morphism
ϑ
id onitsstatespace X. Composition ofmorphisms ofopenMarkov processes isgivenbycomposition
X
ofthemorphismsofthestatespaces.
T.St.ClereSmithe 141
T T
Proposition 3.8. MrkProc extends to an indexed category, MrkProc : Poly → Cat. Suppose
P P E
T T
ϕ: p → q is a morphism of polynomials. We define the functor MrkProc (ϕ) : MrkProc (p) →
P P
MrkProc T (q) as follows. Suppose (X,ϑo,ϑu) is an object (open Markov process) in MrkProc T (p).
P P
Then MrkProc T (ϕ)(X,ϑo,ϑu) is defined as the triple (X,ϕ ◦ϑo,ϑu◦ϑo∗ϕ#):MrkProc T (q). On
P 1 P
morphisms, MrkProc T (ϕ)(f) : MrkProc T (ϕ)(X,ϑo,ϑu) → MrkProc T (ϕ)(Y,ψo,ψu) is given by
P P P
thesameunderlying map f :X →Y ofstatespaces.
Remark 3.9 (Closed Markov chains and Markov processes). A closed Markov chain is given by a
map X → PX, where P : E → E is a probability monad on E; this is equivalently an object in
MrkProc T (y), and (again equivalently) an object in Cat BN,Kℓ(P) . With more general time T,
P
one obtains closed Markov processes: objects in Cat BT,(cid:0) Kℓ(P) . Mo(cid:1)re explicitly, a closed Markov
processisatime-indexedfamilyofMarkovkernels;th(cid:0)atis,amorph(cid:1)ismϑ:T×X →PX suchthat,for
alltimess,t :T,ϑ =ϑ •ϑ asamorphism inKℓ(P). Notethatcomposition •inKℓ(P)isgiven
s+t s t
bytheChapman-Kolmogorov equation, sothismeansthat
ϑ (y|x)= ϑ(y|x′)ϑ(dx′|x).
s+t s t
Zx′:X
We will need to convert our fibration of Markov processes into an ordinary category, in order to
supply ‘dynamical semantics’ for statistical games. We can do so, with objects being appropriately
typed pairs and morphisms representing appropriately ‘bidirectional’ dynamical systems, by using the
followingstructure.
Proposition 3.10. Let D : Poly → Cat be an indexed category over polynomials. Then there is a
E
category ofhierarchical bidirectional D-systems, denoted HiBi(D), anddefined asfollows. Theobjects
ofHiBi(D)arepairs(X,A)ofobjectsinE. Morphisms(X,A)→(Y,B)arefunctorsD(XyA)→D(YyB).
Thecomposition ruleisjustcomposition ofthecorresponding functors, andidentitymorphismsid :
(X,A)
(X,A)→(X,A)aregivenbytheidentity functorid
D(XyA)
:D(XyA)→D(XyA).
Proof. Immediatefromtheassociativity andunitality ofcomposition offunctors.
T
Inparticular, wecantakeD=MrkProc toobtain“hierarchical bidirectional Markovsystems”.
P
3.3 Nested Systems and Dependent Polynomials
The foregoing formalism suffices to describe systems’ shapes, and behaviours of those shapes that de-
pend on their sensoria. Butin our world, asystem has aposition as wellas ashape! Indeed, one might
want to consider systems nested within systems, such that the outer systems constitute the ‘universes’
ofthe inner systems; inthis way, inner shapes maydepend onouter shapes, andinner sensoria onouter
sensoria.2 Wecanmodelthissituation polynomially.
p
Recall that an object in Poly E corresponds to a bundle E → B, equivalently a diagram 1 ← E −→
B→1, and note that the unit polynomial ycorresponds to abundle 1→1. Wecan then think of Poly
E
as the category of “polynomials in one variable”, or “polynomials over y”. This presents a natural
generalization, to polynomials in many variables, corresponding to diagrams J ← E → B → I; these
diagrams formtheobjects ofacategory Poly (J,I). WhenJ isa(polynomial) bundleβoverI,thenwe
E
cantakethesubcategory ofPoly (J,I)whoseobjectsarecommutingsquaresandwhosemorphismsare
E
prismsasfollows;thecommutativity ensuresthatinnerandoutersensoria arecompatible.
2Wemightevenconsidertheoutershapesexplicitlyaspositionsinsomeworld-space,andtheoutersensoriumasdetermined
bypossiblepathsbetweenpositions,inagreementwiththeperspectiveof[12]onpolynomials.
142 PolynomialLife
Proposition 3.11. There is an indexed category of nested polynomials which by abuse of notation we
willcallPoly (−):Poly →Cat. Givenβ:J→I,thecategoryPoly (β)hascommutingsquaresason
E E E
the left below as objects and prisms as on the right as morphisms. Its action on polynomial morphisms
β→γisgivenbycomposition.
E J
E J
B f∗F
B F
B I
I C
Remark 3.12. This construction can be repeatedly iterated, modelling systems within systems within
systems. We leave the consideration of the structure of this iteration to future work, though we expect
it to have an opetopic shape equivalent to that obtained by iterating the Para construction (cf. Remark
2.23).
Observation 3.13. Ourpolynomially indexed categories ofdynamical behaviours andstatistical games
(Prop. 4.9) generalize to the case of nested polynomials, giving a doubly-indexed structure. For more
information ontheformercase,wereferthereadertoourpreprint[17].
4 Theories of Approximate and Active Inference
Wenow start to bring together the structures of the previous sections, in order to breathe life into poly-
nomials. Webeginbysketchingapproximateinferencedoctrines,whichcharacterizedynamicalsystems
that optimize their performance atstatistical games, without reference tomorphology. Inthis paper, we
do not concentrate on the detailed structure of these doctrines, leaving their exposition and comparison
tofuturework,inwhichwewillalsobeinterested inmorphismsbetweendoctrines.
4.1 ApproximateInference Doctrines
An approximate inference doctrine will be a monoidal functor from a category of statistical games into
anappropriatecategoryofdynamicalsystems,takinggamestosystemsthat‘play’thosegames,typically
by implementing an optimization process. In the free-energy literature (e.g., [3]), these systems have a
hierarchical structure in which the realization of a game has access to the dynamics realizing the prior,
mirroring the context-dependence of the games themselves, and it is for this reason that we use the
category ofhierarchical bidirectional systemsdefinedabove.
Proposition 4.1. Let P :E → E be a probability monad on E, and let C be a category that admits
Bayesian inversion, equipped withafunctorF :C →Kℓ(P). SinceSGameC isaGrothendieck fibra-
tion,itisequippedwithacanonicalprojectionfunctorSGameC →C. SupposethatG isasubcategoryof
SGameC. ThenthereisafunctorFG :G ֒→SGameC →C −→ F Kℓ(P)whoseimageimFG inKℓ(P)
consists oftheforwardsmapsofG realizedasstochastic channels inKℓ(P).
T.St.ClereSmithe 143
Definition4.2. Suppose p:Poly
E
andthatC isasubcategoryofKℓ(P). DenotebyMrkProc T
P
(p)|C
the subcategory of MrkProc T (p) whose objects (Θ,θo,θu) satisfy the condition that, for all t :T, the
P
followingcomposite belongstoC:
∑∑p[θo(t,x)]− θ − u − ( → t) PΘ− P −− θ − o( → t) Pp(1).
t:Tx:Θ
T
NotethatMrkProc
P
(−)|C doesnotingeneraldefineanindexedcategory.
Definition 4.3. Suppose C is a subcategory of Kℓ(P). Denote by HiBi MrkProc T
P
|C the re-
T T
striction of HiBi MrkProc
P
defined as follows. The objects of HiBi Mr(cid:0)kProc
P
|C (cid:1)are the ob-
jects of HiBi Mr(cid:0)kProc T
P
, b(cid:1)ut morphisms (X,A)→ (Y,B) are now func(cid:0)tors MrkPro(cid:1)c T
P
|C(XyA) →
MrkProc T
P
|C(cid:0)(YyB). Comp(cid:1)ositionandidentities aredefinedasforHiBi MrkProc T
P
.
(cid:0) (cid:1)
Wearenowinaposition todefineapproximate inferencedoctrines.
Definition4.4. LetP:E →E beaprobabilitymonadonE andletG beasubcategoryofSGame
Kℓ(P)
.
Anapproximate inferencedoctrineinG withtimeTisafunctor fromG toHiBi MrkProc T
P
|imF
G
,
whereFG isdefinedasinProposition 4.1. (cid:0) (cid:1)
Many informal approximate inference schemes—including Markov chain Monte Carlo, variational
Bayes, expectation-maximization, particle filtering—give risetoapproximate inference doctrines; func-
torialitytypicallyfollowsfromTheorem2.12. Herewenoteoneexplicitly,forlaterreference;adetailed
presentation willappearinanupcoming paper.
Definition 4.5. We say that f :X→• Y in Kℓ(P) is Gaussian if, for any x:X, the state f(x):PY is
Gaussian. Note that Gaussian morphisms are not themselves closed under composition, though we can
consider thesubcategory ofmorphismsgenerated byGaussianmorphisms.
Lemma4.6(Laplaceapproximation). Suppose:
(a) GaussisthesubcategoryofchannelsgeneratedbyGaussianmorphismsbetweenfinite-dimensional
EuclideanspacesinKℓ(P);
(b) (γ,ρ,φ):X →Y isasimpleD -freeenergygamewithGaussianchannels;
KL
(c) forallpriorsπ:PX,thestatistical parameters ofρ :Y →PX aredenoted by(µ ,Σ ):Y →
π ρπ ρπ
R|X|×R|X|×|X|,where|X|isthedimension ofX;and
(d) forally:Y,theeigenvalues ofΣ (y)aresmall.
ρπ
Thenthelossfunctionφ:BayesLens ((X,X),(Y,Y))→Rcanbeapproximated by
Gauss
φ(π,k)= E F(y) ≈ E FL(y)
y∼k•γ•π y∼k•γ•π
(cid:2) (cid:3) (cid:2) (cid:3)
where
FL(y)=E µ (y),y −S [ρ (y)] (4)
(π,γ) ρπ X π
(cid:0) (cid:1)
=−logp (y|µ (y))−logp (µ (y))−S [ρ (y)]
γ ρπ π ρπ X π
andwhereS [ρ (y)]=E [−logp (x|y)]istheShannonentropyofρ (y),and p :Y×X →[0,1],
x π x∼ρπ(y) ρπ π γ
p :X →[0,1],and p :X×Y →[0,1]aredensity functions forγ,π,andρ respectively. Theapprox-
π ρπ π
imationisvalidwhenΣ satisfies
ρπ
Σ (y)= ∂2E µ (y),y −1 . (5)
ρπ x (π,γ) ρπ
(cid:0) (cid:1)(cid:0) (cid:1)
144 PolynomialLife
Theorem4.7. Suppose:
(a) GaussisthesubcategoryofchannelsgeneratedbyGaussianmorphismsbetweenfinite-dimensional
EuclideanspacesinKℓ(P);
(b) SimpSGame Gauss ֒→SGame Kℓ(P) is the subcategory of simple statistical games over Kℓ(P)
withchannels inGauss;and
(c) G isthesubcategory ofD -Bayesian inference gamesinSimpSGame .
KL Gauss
Then the discrete-time free-energy principle under the Laplace approximation induces an approximate
inference doctrine inG withtimeN,Laplace:G →HiBi MrkProc T
P
|imF
G
.
(cid:0) (cid:1)
4.2 Statistical GamesoverPolynomials
Approximate inference doctrines of the foregoing type do not supply a satisfactory model of active
systems. One piece of structure is still missing, with which we can describe action and interaction
faithfully: anindexed category ofstatistical gamesoverpolynomials. Inorder toconstruct this, wefirst
define categories of “gamesoninterfaces”: this issimpler than slicing thecategory ofstatistical games,
aswedonotrequiregamesbetweengames.
Definition 4.8. Let P :E →E be a probability monad on E. Let X :E be an object in E. Define a
category of simple statistical games on the interface X, denoted by IntGameP(X), as follows. Its
objects are simple statistical games with codomain X; that is, points of ∑ A:E SimpSGame Kℓ(P) (A,X).
Let (γ,ρ,φ) :A → X and (δ,σ,χ) : B → X be two such simple statistical games. Then a morphism
(γ,ρ,φ)→(δ,σ,χ) is a deterministic function f :A→B—that is, a point of E(A,B)—such that γ=
δ◦ f. Unitalityandassociativity followimmediatelyfromthoseproperties inE/PX.
We then use this to construct games over polynomials. The intuition here is that ‘inside’ a system
with a polynomial phenotype is a statistical model of the system’s sensorium. This involves an object
representing thespace ofpossible causes ofobservations, andasimple statistical gamefrom this object
onto the sensorium; by its nature, this model induces predictions about the system’s configurations, as
wellasabouttheimmanentsignals. Bysamplingfromthesepredictedconfigurations,thesystemcanact;
by observing its actual configuration and the corresponding immanent signals, it can update its internal
beliefs, and any parameters of the model. Later, we will equip this process with (random) dynamics,
thereby givingthesystemslife.
Proposition4.9. LetP:E →E beaprobabilitymonadonalocallyCartesianclosedcategoryE. There
isapolynomiallyindexedcategoryofstatistical gamesPSGameP :Poly
E
→Cat,definedonobjects
pasIntGameP ∑
i:p(1)
p[i] .
(cid:0) (cid:1)
Example4.10. Tounderstand theaction ofPSGameP(ϕ)onstatistical games, itmayhelptoconsider
theexampleofacorporation. Suchasystemiscomposedofanumberofactivesystems,whichinstantiate
statisticalgamesandinteractaccordingtosomepatternformalizedbythepolynomialmapϕ. Givensuch
a collection of games, PSGameP(ϕ) tells us how to construct a game for the corporation as a whole:
in particular, we obtain a stochastic channel generating predictions for the (exposed) sensorium of the
corporation, andaninversion updating theconstituent systems’beliefsaccordingly.
4.3 ActiveInference
We are now ready to define active inference doctrines; given all the foregoing structure, this proves
relatively simple.
T.St.ClereSmithe 145
Definition4.11. LetP:E →E beaprobablitymonad,andletTbeatimemonoid. Anactiveinference
T
doctrineisamonoidalindexedfunctorfromPSGameP toMrkProc
P
.
Proposition4.12. TheLaplacedoctrineliftsfromapproximatetoactiveinference. Thefunctorsoneach
fibre are as before on games (here, objects), and on morphisms between games they are given merely
by lifting the corresponding maps to maps between state spaces. One then checks that morphisms of
polynomials correspond tonaturaltransformations betweenthesefunctors.
Remark4.13. Itwouldbedesirabletoincorporatethecompositionalstructureofthegamesthemselves,
ratherthantreatthemopaquely asobjects. Thissuggestsadouble-categorical structure theinvestigation
of which we leave to future work. Similarly, we do not here elaborate the extension of these indexed
categories tothedependent-polynomial case.
5 Polynomial Life and Embodied Cognition
Finally, wesketch how a number of classic biological processes can be modelled as processes ofactive
inferenceoverpolynomials. Thekeyinsightisthat,byfixingthepriorofan‘active’free-energygameto
encodehigh-precision (low-variance) beliefsabouttheexternalstate,wecaninducethesystemtoprefer
acting (i.e., reifying those beliefs) over perceiving (i.e., updating the beliefs to match perceptions). In
doing so,onecaninducevolition orgoal-directedness inthesystem. Akeyfeature oftheseexamplesis
that they demonstrate ‘embodied’ cognition, in which a system’s form and interactions become part of
itscognitiveapparatus.
Remark5.1. Ofcourse, onemustbecarefulnottochooseapriorwithexcessivelyhighprecision (such
as a Dirac delta distribution), as this would cause the system to forego any belief-updating, thereby
rendering itsactionsindependent ofthe‘actual’externalstate.
Example5.2. Suppose that the system’s sensorium includes akeyparameter such asambient tempera-
ture or blood pH. Suppose that by adjusting its configuration, the system can move around in order to
sample this parameter. And suppose that the prior encodes a high-precision distribution centred on the
acceptablerangeofthisparameter. Thenitisstraightforward toshowthatthesystem,byminimizingthe
free energy, will attempt to configure itself so as to remain within the acceptable parameter range. We
canconsider thisasasimplemodelofhomeostasis.
Example5.3. Wecanextendthepreviousexampletoasystemwithmultiple(polynomial) components,
eachequippedwitha“homeostasis game”,inordertomodelmorphogenesis. Supposetheenvironmen-
tal parameter in the sensorium is the local concentration of some signalling molecule, and suppose the
polynomialmorphismformingthecompositesystemencodesthepatternofsignallingmoleculeconcen-
trations in the neighbourhood of each system, as a result of their mutual configurations. Suppose then
that thetarget state encoded inthe prior ofeach system corresponds tothe system being positioned ina
particularwayrelativetothesystemsaroundit,asrepresented bythesignalconcentrations. Free-energy
minimization theninduces thesystemstoarrange themselvesinordertoobtainthetargetpattern.
Remark 5.4. The foregoing examples begin to point towards a compositional theory of autopoiesis:
here, onemight expect thetarget state toencode the proposition “maintain mymorphology”, which ap-
pearsself-referential. Themostelegantwayofencoding thisproposition inthepriorisnotimmediately
clear, although a number of possibilities present themselves (such as avoiding some undesirable con-
figuration representing dissolution). We expect a satisfactory answer to this to be related to “Bayesian
mechanics” (see§6).
146 PolynomialLife
Remark 5.5. It has been shown informally that, given a finite time horizon Markov decision problem,
active inference can recover the Bellman-optimal policy traditionally obtained by backward induction
[7]. Ongoing work by the present author is directed at formalizing the structure of this relationship. In
particular, the result rests on encoding directly into the prior the expectation of the loss function given
a policy and a goal, which strikes us as a large amount of information to push into an unstructured
distribution overnumbers.
Example5.6. Theexamplesneednotberestrictedtosimplebiologicalcases. Forinstance,wecanmodel
spatial navigation quite generally: we can use parameterized statistical games to encode uncertainty
aboutthestructureofthe‘externalspace’(forinstance: whichpointsorneighbourhoodsareconnectedto
which,andbywhichpaths). Bysettingahigh-precisionprioratsomelocation,thesystemwillattemptto
reachthatlocation,learningthespatialstructurealongtheway;reducingtheprecisionofthepriorcauses
the system to prefer “mere exploration”. One can attach sense-data to each location using the natural
polynomial bundle structure. Moreover, the ‘external space’ need not be a simple topological space:
it may be something more structured. For instance, categories and sites can themselves be modelled
polynomially. One can think of “taking an action” as precisely analogous to “following a morphism”:
thus, in a topos-theoretic setting, one can consider the structure of the ‘external space’ to be a type-
theoretic context, and positions in the world to be objects in the corresponding topos. One could then
encode in the prior a target proposition, and free-energy minimization would cause the system then to
explore the ‘space’ (learning its structure), and seek a path to the target. But such a path is precisely a
proof! Thereisincreasingevidencethattheneuralmechanismsunderlyingspatialandabstractnavigation
arethesame[1],andalineofthinking assketched heremaysupplyamathematical justification.
6 Future Directions
Besides expanding the examples above in detail, there are many future directions to pursue. Our last
examplepointstowardsa‘well-typed’theoryofcognition, findingtype-theoretic analoguesofcognitive
processes (such asaction, planning, ornavigation). Byformalizing the connection between polynomial
statistical games and Markov decision processes, we hope finally to relate our ‘statistical’ account of
cybernetics with the account emerging from research in compositional game theory. In particular, we
believe that the hierarchical/nested structure of our polynomial systems is structurally similar to that of
(parameterized) players inopen games. Along similar lines, weexpect aconnection between statistical
gamesand‘learners’ [13]implementing backprop.
In a more physical direction, there is a controversy in the informal literature about whether one
should expect any system with a boundary (and hence any system on a polynomial) to admit a canon-
ical statistical-game description; the typical suggestion is that such a description should obtain at non-
equilibrium steady state, through a manipulation of the corresponding Fokker-Planck equation; this is
the notion of “Bayesian mechanics” [9]. Our results suggest that such a canonical description should
formaleftadjointtosomeactiveinference doctrine; thisisamatterofongoing researchbytheauthor.
Workingtopos-theoretically pointsfurtherinametaphysical direction: aBayesianperspective lends
itself to subjectivism, but considering the “internal universe” of a navigating system to be a topos in
somecontextalsopointstoasubjectiverealism. Itseemslikelythenthatcomposite systemsneednotin
general agreeabouttheirobservations. Weshouldtherefore expecttofindevidenceofcontextuality and
disagreement inmulti-agent systems,andtoinvestigate thisusingcohomological tools(e.g.,[5]).
T.St.ClereSmithe 147
References
[1] Timothy EJ Behrens, Timothy H Muller, James CR Whittington, Shirley Mark, Alon B Baram,
KimberlyLStachenfeld&ZebKurth-Nelson(2018): Whatisacognitivemap? Organizingknowl-
edgeforflexible behavior. Neuron100(2), pp.490–509, doi:10.1016/j.neuron.2018.10.002.
[2] JoeBolt,JulesHedges&PhilippZahn(2019): Bayesianopengames. arXivpreprint. Availableat
http://arxiv.org/abs/1910.03656.
[3] Christopher LBuckley,ChangSubKim,SimonMcGregor&AnilKSeth(2017): Thefreeenergy
principle for action and perception: Amathematical review. JournalofMathematicalPsychology
81,pp.55–79, doi:10.1016/j.jmp.2017.09.004.
[4] MatteoCapucci,BrunoGavranovic´,JulesHedges&EigilFjeldgrenRischel(2021): Towardsfoun-
dationsofcategoricalcybernetics. thisvolumeofEPTCS,OpenPublishingAssociation. Available
athttps://arxiv.org/abs/2105.06332.
[5] Giovanni Caru` (2017): On the Cohomology of Contextuality. In: Proceedingsofthe13thInter-
nationalConferenceonQuantumPhysicsandLogic, 236, pp. 21–39, doi:10.4204/EPTCS.236.
2.
[6] Kenta Cho & Bart Jacobs (2017): Disintegration and Bayesian Inversion via String Di-
agrams. Mathematical Structures in Computer Science 29, pp. 938–971, doi:10.1017/
S0960129518000488.
[7] LancelotDaCosta,NoorSajid,ThomasParr,KarlFriston&RyanSmith(2020): TheRelationship
between Dynamic Programming and Active Inference: The Discrete, Finite-horizon Case. arXiv
preprint. Available athttps://arxiv.org/abs/2009.08111.
[8] K.Friston,J.Mattout,N.Trujillo-Barreto,J.Ashburner&W.Penny(2007): Variationalfreeenergy
and the Laplace approximation. Neuroimage34(1), pp. 220–234, doi:10.1016/j.neuroimage.
2006.08.035.
[9] Karl Friston (2019): A free energy principle for a particular physics. arXivpreprint. Available at
http://arxiv.org/abs/1906.10184.
[10] Chris Heunen, Ohad Kammar, Sam Staton & Hongseok Yang (2017): A Convenient Category for
Higher-OrderProbabilityTheory. In:32ndAnnualACM/IEEESymposiumonLogicinComputer
Science(LICS),IEEE,doi:10.1109/lics.2017.8005137.
[11] David I. Spivak (2019): Generalized Lens Categories via functors Cop → Cat. arXivpreprint.
Availableathttp://arxiv.org/abs/1908.02202.
[12] David I. Spivak (2020): Poly: An abundant categorical setting for mode-dependent dynamics.
arXivpreprint(presentedatthe3rdAnnualInternationalAppliedCategoryTheoryConference).
Availableathttps://arxiv.org/abs/2005.01894.
[13] DavidI.Spivak(2021): Learners’languages. thisvolumeofEPTCS,OpenPublishingAssociation.
Availableathttps://arxiv.org/abs/2103.01189.
[14] TobySt.ClereSmithe(2020): Bayesian Updates ComposeOptically. arXivpreprint. Available at
https://arxiv.org/abs/2006.01631.
[15] TobySt.ClereSmithe(2020): CyberKittens,orSomeFirstStepsTowardsCategoricalCybernetics.
In: Proceedings3rdAnnualInternationalAppliedCategoryTheoryConference2020(ACT2020),
333,pp.108–124, doi:10.4204/EPTCS.333.8.
148 PolynomialLife
[16] Toby St. Clere Smithe (2021): Compositional Active Inference I: Bayesian Lenses. Statistical
Games. arXivpreprint. Availableathttps://arxiv.org/abs/2109.04461.
[17] Toby St. Clere Smithe (2021): Some Notions of (Open) Dynamical System on Polynomial Inter-
faces. arXivpreprint. Availableathttps://arxiv.org/abs/2108.11137.
[18] TobySt.ClereSmithe(2022): Opendynamicalsystemsascoalgebrasforpolynomialfunctors,with
application to predictive processing. In: Proceedings5thAnnualInternationalAppliedCategory
TheoryConference2021(forthcoming). Availableathttps://arxiv.org/abs/2206.03868.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Polynomial Life: the Structure of Adaptive Systems"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
