### A Neural Active Inference Model of Perceptual-Motor Learning – Summary### OverviewThis paper investigates the application of active inference (AIF) as a computational framework for understanding human perceptual-motor learning, specifically in the context of intercepting a moving target. The authors propose a neural AIF agent that captures the role of anticipation in guiding visual guidance of action. The core idea is that humans, like the agent, must actively predict sensory information to effectively control their movements, and that this process is underpinned by a generative model of the world. The paper demonstrates that AIF can successfully model human behavior in this task, highlighting the importance of anticipatory control and the role of free energy minimization.### MethodologyThe authors developed a neural AIF agent that utilizes a two-headed artificial neural network to estimate free energy and predict future observations. The agent operates by selecting actions based on a weighted combination of reward-based reinforcement learning and short-term predictive models. The agent’s architecture includes an EFE (estimation) head and a transition dynamics (prediction) head. The EFE head estimates free energy values for all possible actions, while the transition dynamics head predicts the next observation given the current state. The agent’s learning process involves minimizing free energy, which is a measure of the discrepancy between the predicted and actual observations. The authors implemented the agent using TensorFlow2 and conducted experiments on a simulated interception task. The task involved a moving target that changed its speed semi-predictably, and the agent’s goal was to intercept the target. The authors compared the performance of the AIF agent to a baseline deep-Q-network (DQN) agent.### ResultsThe AIF agent demonstrated a significantly higher success rate in intercepting the moving target compared to the DQN agent. Specifically, the AIF agent achieved an average success rate of approximately90% with a low variance, while the DQN agent achieved a success rate of approximately22%. The authors observed that the AIF agent’s behavior closely matched the behavior of human subjects in the original study, as demonstrated by the close alignment of the agent’s TTC (time-to-collision) with the target’s actual TTC. The authors found that the AIF agent’s performance was sensitive to the discount factor (γ) and the pedal lag coefficient (K), highlighting the importance of these parameters in shaping the agent’s anticipatory behavior. The AIF agent’s performance was significantly better when the pedal lag coefficient was set to0.5, compared to1.0, indicating that a more responsive vehicle dynamics is crucial for successful interception.### Key Claims & Findings*"The authors state: 'The behavior of an AIF agent involves the selection of action-plans that span into the near future and centers around the learning of expected free energy.'"*"They note: 'Anticipatory behavior emerged only when required by limitations on the agent’s movement capabilities, and only when the agent was able to estimate accumulated free energy over sufficient lengths of time into the future.'"*"The paper argues: 'AIF offers a plausible model of anticipatory visually guided behavior in humans.'"*"According to the research: 'The agent’s ability to accurately predict the target’s speed was crucial for successful interception.'"*"The study demonstrates: 'The agent’s performance was sensitive to the discount factor γ.'"*"The authors state: 'The agent’s ability to estimate accumulated free energy over sufficient lengths of time into the future was critical.'"*"They note: 'The agent’s behavior closely matched the behavior of human subjects in the original study.'"*"The paper argues: 'AIF offers a plausible model of anticipatory visually guided behavior in humans.'"*"According to the research: 'The agent’s performance was sensitive to the pedal lag coefficient K.'"*"The study demonstrates: 'The agent’s ability to accurately predict the target’s speed was crucial for successful interception.'"### DiscussionThe results of this study demonstrate the potential of AIF as a computational framework for understanding human perceptual-motor learning. The AIF agent successfully modeled human behavior in the interception task, highlighting the importance of anticipatory control and the role of free energy minimization. The authors’ findings suggest that humans, like the agent, actively predict sensory information to effectively control their movements. The sensitivity of the agent’s performance to the discount factor and pedal lag coefficient further underscores the importance of these parameters in shaping human behavior. Future research could explore the application of AIF to other perceptual-motor tasks and investigate the neural mechanisms underlying AIF in the human brain.