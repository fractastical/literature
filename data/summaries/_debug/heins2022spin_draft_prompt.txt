=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Spin glass systems as collective active inference
Citation Key: heins2022spin
Authors: Conor Heins, Brennan Klein, Daphne Demekas

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2022

Abstract: An open question in the study of emergent behaviour in multi-agent Bayesian sys-
tems is the relationship, if any, between individual and collective inference. In this
paper we explore the correspondence between generative models that exist at two dis-
tinct scales, using spin glass models as a sandbox system to investigate this question.
Weshowthatthecollectivedynamicsofaspecifictypeofactiveinferenceagentisequiv-
alent to sampling from the stationary distribution of a spin glass system. A colle...

Key Terms: systems, glass, konstanz, collective, university, models, inference, behaviour, active, spin

=== FULL PAPER TEXT ===

Spin glass systems as collective active inference
Conor Heins∗1-4, Brennan Klein1,4,5, Daphne Demekas4,6,
Miguel Aguilera7,8, and Christopher Buckley1,7,8
1VERSES Research Labs, Los Angeles, California, USA
2Department of Collective Behaviour, Max Planck Institute of
Animal Behavior, 78464 Konstanz, Germany
3Department of Biology and Centre for the Advanced Study
of Collective Behaviour, University of Konstanz, 78464 Konstanz, Germany
4Network Science Institute, Northeastern University, Boston, Massachusetts, USA
5Laboratory for the Modeling of Biological and Socio-Technical Systems,
Northeastern University, Boston, Massachusetts, USA
6Birkbeck Department of Film, Media and Cultural Studies, London, UK
7Sussex AI Group, Department of Informatics, University of Sussex, Brighton, UK
8Sackler Centre for Consciousness Science, University of Sussex, Brighton, UK
July 15, 2022
Abstract
An open question in the study of emergent behaviour in multi-agent Bayesian sys-
tems is the relationship, if any, between individual and collective inference. In this
paper we explore the correspondence between generative models that exist at two dis-
tinct scales, using spin glass models as a sandbox system to investigate this question.
Weshowthatthecollectivedynamicsofaspecifictypeofactiveinferenceagentisequiv-
alent to sampling from the stationary distribution of a spin glass system. A collective
of specifically-designed active inference agents can thus be described as implementing
a form of sampling-based inference (namely, from a Boltzmann machine) at the higher
level. However, this equivalence is very fragile, breaking upon simple modifications
to the generative models of the individual agents or the nature of their interactions.
We discuss the implications of this correspondence and its fragility for the study of
multiscale systems composed of Bayesian agents.
1 Introduction
Emergent phenomena in multi-agent systems are central to the study of self-organizing, com-
plex systems, yet the relationship between individual properties and group-level phenomena
∗conor.heins@gmail.com
1
2202
luJ
41
]nn-sid.tam-dnoc[
1v07960.7022:viXra
remains opaque and lacks formal explanation. One principled approach to understanding
such phenomena is offered by the Free Energy Principle and so-called ‘multiscale active
inference’ [1, 2]. Proponents of this multiscale approach propose that groups of individually-
Bayesian agents necessarily entail an emergent, higher-order Bayesian agent — in other
words, systems are ‘agents all the way down’ by definition [2–6]. However, to date, there
has been little theoretical or modeling work aimed at investigating whether this proposition
is true in general or even demonstrating an existence proof in a specific system.
In this work we investigate this proposal by building a network of active inference agents
that collectively implement a spin glass system. Spin glasses are a well-studied model class
with a long history in statistical physics and equilibrium thermodynamics [7, 8]. In the
context of machine learning and computational neuroscience, spin glass systems can be tied
to models of Bayesian inference and associative memory, particularly in the form of Hopfield
networks and undirected graphical models like Boltzmann machines [9, 10]. Boltzmann
machines are a canonical example of an energy-based model in machine learning — they are
defined by a global energy function and are analytically equivalent to a particular sort of spin
glass model. The Boltzmann machine can straightforwardly be shown to be an inferential
model by conditioning on the states of particular spins and sampling from the posterior
distribution over the remaining spins’ states [11, 12]. In doing so, Boltzmann machines and
spin glass systems can be described as performing Bayesian inference about the latent causes
(spin configurations) of the ‘data’ (conditioned spins).
In this paper, we set out to investigate whether an inference machine (in our case, a
Boltzmann machine) that exists at a ‘higher-level’, can be hierarchically decomposed into
an ensemble of agents collectively performing active inference at a ‘lower level.’ We show a
simple but rigorous equivalence between collective active inference and spin glass systems,
providingthefirststepsforfuturequantitativestudyintotherelationshipbetweenindividual
and collective generative models. We show that a group of active inference agents, equipped
with a simple but very specific generative model, collectively sample from the stationary
distribution of a spin glass system at the higher scale. This can be connected to a particular
form of sampling known as Glauber dynamics [7, 13]. When we further condition on the
states of particular agents, then the system can be interpreted as collectively performing
a form of sampling-based posterior inference over the configurations of the unconditioned
agents, i.e., Boltzmann machine inference.
This paper is structured as follows: first, we specify the generative model that each spin
sitein amulti-agent spinglasssystemisequippedwith, notingthatthe singleagentsarecon-
structedexplicitlysuchthattheirinteractionsatthelower-levelleadtoaspinglasssystemat
the higher level. Then, we establish the equivalence between this multi-agent active inference
process and Glauber dynamics, a scheme that samples from the stationary distribution of a
spin glass system. We then generalize this result to sampling-based inference in Boltzmann
machines by relaxing the homogeneous parameterization of each agent’s generative models.
We draw exact equivalences between the precisions of each agent’s generative model and
the parameters of a higher-level Boltzmann machine. We conclude by noting the fragility
of the equivalence between multi-agent active inference and sampling from a collective spin
2
glass system, and discuss the implications of our results for the study of emergent Bayesian
inference in multiscale systems.
2 Generative model for a single spin
We begin by constructing a generative model for a single Bayesian agent, which we imagine
as a single spin in a collective of similar agents. From the perspective of this single ‘focal
agent’ or spin, this generative model describes the agent’s internal model of how the local
environment generates its sensory data. Throughout this section we will take the perspective
ofthissinglefocalagent, keepinginmindthatanygivenagentisembeddedinalargersystem
of other agents.
2.1 States and observations
We begin by specifying the state-space of observations and hidden states that characterize
the focal agent’s ‘world.’ The focal agent’s observations or sensations are comprised of a
collection of binary spin states σ˜ = σ : j M where σ = 1 and M is the set of other
j j
{ ∈ } ±
spins that the focal agent has direct access to. In other words, the agent directly observes
the spin states of neighbouring agents (but not its own).
The focal agent assumes these observed spin states σ˜ all depend on a single, binary
latent variable z — the ‘hidden spin state’, which could also be interpreted as a coarse-
grained ‘average spin’ of its neighbours. Having specified observations σ˜ and latent states
z, the full generative model can be written as a joint distribution over observations and the
hidden spin state, P(σ˜,z). This in turn factorizes into a set of distributions that describe
the likelihood over observations, given the latent state P(σ˜ z), and prior beliefs about the
|
latent state P(z):
P(σ˜,z) = P(σ˜ z)P(z)
|
We parameterize the likelihood and prior distributions as Bernoulli distributions (ex-
pressed in a convenient exponential form):
exp(γσ j z) exp(ζz)
P(σ˜ z;γ) = P(z;ζ) =
| 2cosh(γz) 2cosh(ζz)
j∈M
(cid:89)
Likelihood Prior
The likelihood factorizes into a product of independent Bernoulli distributions over each
neighbouring spin σ . The full likelihood is parameterized with a single sensory precision
j
parameter γ whose magnitude captures the focal agent’s assumption about how reliably
neighbouring spin states σ indicate the identity of the latent state z. A positive γ indicates
j
that σ lends evidence to z being aligned with σ , whereas a negative γ means that σ lends
j j j
evidence to z being opposite to σ .
j
3
(A) Spinsystem (B) Asinglespin(agent)
σm= σm=
σl= σi= σj= σ l= σ i= σ j=
σ k=
σk=
(C) Posterioroverhiddenstates
1.0
0.8
0.6
0.4
0.2
0.0
10 5 0 5 10
− −Spindifference,∆σ
ytilibaborproiretsoP
P(σ˜,z)
Sensorydata:σ˜= { σj:j ∈ M } = { , , , } ; Hiddenspinstate:z
whereK= | M | z= 1 z=+1
1− 1
P(σj| z;γ)= 2 ex co p s ( h γ ( σ γ jz z ) ) = 1+exp 1 ( − 2γ) 1+ex 1 p(2γ) 
(lik a e s l s ih u o m o e d c f o a n ct d o i r ti i o ze n s al o i v n e d r e K pe n n e d ig e h n b ce ors) c   on 1 di + tio e n x a p lB ( e 2 r γ n ) oullidi 1 st + rib e u x ti p o ( n − so 2 v γ e ) r   σj
P(σ˜ | z;γ)=∏ 2
ex
c
p
os
(
h
γ
(
σ
γ
jz
z
)
) =exp zγ∑σj− Klog 2cosh(γz)
j∈M (cid:16) j∈M (cid:0) (cid:1)(cid:17)
Sensoryprecision:γ measureof”reliability”ofsensoryinformationfrom
neighbors;eitheruniformorheterogeneousoverM
exp(ζz)
P(z;ζ)= =exp ζz log(2cosh(ζ))
2cosh(ζz) −
whereσ 1,+1 = ,
∈{− } { } (cid:0) (cid:1)
Priorprecision:ζ
1
overhiddensta
P
te
(
s
z=+1
|
σ˜,γ,ζ)=
1+exp − 2(ζ+γ∆σ)
where∆σ=
j∈
∑
M
σj
sampledfrom σ p i os∼teri Q or (ut;φu∗) whereφu≈ φzfor (cid:0) 0 ≤ φz≤ 1andφz (cid:1) =P(z=+1 | σ˜,γ,ζ)
overcontrolstates
10 5 0 5 10
− −Spindifference,∆σ
Figure 1: Schematic illustration of individual and collective dynamics. (A) Exam-
ple of a system of 16 spin sites connected via a 2-D lattice, each in a state of σ 1,+1
∈ {− }
(green down-arrow or yellow up-arrow above), with a focal agent and its spin, σ = 1,
i
−
highlighted in blue. (B) Generative model of a single spin. (C) The posterior belief over
z = +1 as a function of the spin difference ∆σ. Left: The steepness of the function is tuned
by γ (ζ = 0.0 shown). Right: The horizontal shift depends on ζ (γ = 0.5 shown).
The prior over z is also a Bernoulli distribution, parameterized by a precision ζ that acts
as a ‘bias’ in the focal agent’s prior belief about the value of z. When ζ > 0, the focal agent
believes the ‘UP’ (z = +1) state is more likely a priori, whereas ζ < 0 indicates that the
agent believes that z = 1 is more likely, with the magnitude of ζ reflecting the strength or
−
confidence of this prior belief.
2.2 Bayesian inference of hidden states
Having specified a generative model, we now consider (from the perspective of a focal agent)
the problem of estimating z, given observations σ˜ = σ : j M and generative model
j
{ ∈ }
parameters γ,ζ. This is the problem of Bayesian inference, specifically the calculation of
the posterior distribution over z. The conjugate-exponential form of the generative model
means that the Bayesian posterior can be calculated exactly, and has a Bernoulli form that
depends on σ˜ and z:
4
exp z(ζ +γ σ )
P(σ˜,z;γ,ζ) j j
P(z σ˜;γ,ζ) = = (1)
| P(σ˜;γ,ζ) 2co (cid:16) sh ζ +γ(cid:80) σ (cid:17)
j j
(cid:16) (cid:17)
(cid:80)
If we fix the hidden state z to a particular value (e.g. z = +1), then we arrive at a simple
expression for the posterior probability that the hidden spin state is in the ‘UP’ state, given
the observations and the generative model parameters γ,ζ. The posterior belief expressed
as the sum of sensory input σ assumes a logistic or sigmoid form. Hereafter we refer
j j
to the sum of observed spin states as the ‘spin difference’ ∆σ = σ , since this sum is
(cid:80) j j
equivalent to the difference in the number of positive (σ = +1) and negative (σ = 1)
j j
(cid:80) −
spins. Intuitively, the steepness and horizontal shift of this logistic function are determined
by the likelihood and prior precisions:
1
P(z = +1 σ˜,γ,ζ) = (2)
| 1+exp( 2(ζ +γ∆σ))
−
Figure 1C shows the effect of varying the likelihood and prior precisions on the posterior
beliefoverz asafunctionof∆σ. WecanalsoexpresstheposteriorasaBernoullidistribution
using the more common form, with parameter φ :
z
P(z σ˜,γ,ζ;φ z ) = (1 φ z
)1−z+
2
1
φ z
z+
2
1
| −
1
φ = (3)
z
1+exp( 2(ζ +γ∆σ))
−
We now have a simple update rule that expresses how a focal agent updates its beliefs
about z in response to observed spins σ˜. This sigmoid belief update has a clear, intuitive
relationship to the parameters of the focal agent’s generative model, with γ encoding the
sensitivity of the belief to small changes in ∆σ and ζ encoding a ‘bias’ that skews the belief
towards either 1 or +1. In the next section, we connect the generation of spins themselves
−
to an active inference process, that leverages the Bayesian estimation problem of the current
section to determine a focal agent’s inference of its own spin state.
2.3 Active inference of spin states
Having addressed the issue of Bayesian inference or state estimation, we can now specify
a mechanism by which agents generate their own spin states. These generated spin states
will then serve as observations for the neighbours to whom the focal agent is connected.
This turns into a problem of belief-guided action selection or decision-making. To enable
agents to sample spin states as a function of their beliefs, we supplement each agent’s current
generative model with an extra random variable that corresponds to control states, and some
forwardmodelofhowthosecontrolstatesdetermineobservations. Weuseactive inference to
5
optimize a posterior belief over these control states [14–16]; an agent can then act to change
itsspinstatebysamplingfromthisposterior. Byequippingeachagentwithaparticulartype
of forward model of how its actions impact observations, we can formally tie the collective
dynamics of active inference agents with this generative model to a sampling scheme from
a spin glass model. Appendix B walks through the steps needed to add a representation
of control states into the generative model introduced in the previous section, and perform
active inference with respect to this augmented generative model.
Active inference agents entertain posterior beliefs not only about the hidden states of
the world, but also about how their own actions affect the world. Posterior beliefs about
actions are denoted Q(u;φ ), where u is a random variable corresponding to actions and φ
u u
are the parameters of this belief. As opposed to the analytic posterior over hidden states z,
Q(u;φ ) is an approximate posterior, optimized using variational Bayesian inference [17]. In
u
our focal agent’s simple action model, control states have the same support as hidden states,
i.e. u = 1. The value of u represents a possible spin action to take (‘UP’ vs. ‘DOWN’). We
±
parameterize Q(u;φ ) as a Bernoulli distribution with parameter φ , which itself encodes
u u
the probability of taking the ‘UP’ (+1) action:
Q(u t ;φ u ) = (1 φ z
)1−ut
2
+1
φ z
ut
2
+1
(4)
−
When we equip our spin glass agents with a particular (predictive) generative model, we
can show that the approximate posterior over control states simplifies to the state posterior
(see Appendix B for details), and an agent can generate a spin state by simply sampling
from the posterior over actions:
Q(u;φ ) P(z σ˜,γ,ζ;φ ) σ Q(u;φ )
u z u
≈ | ∼
φ φ : 0 φ 1 Q(z;φ ) (cid:44) P(z σ˜;γ,ζ) (5)
u z z z
≈ ≤ ≤ ∼ |
We now have an active inference agent that 1) calculates a posterior belief P(z σ˜,γ,ζ;φ )
z
|
about the latent state z in response to the observed spins of other agents and 2) generates a
spin of its own by sampling from this belief, which ends up being identical to the posterior
over actions. Intuitively, each agent just broadcasts its beliefs about the latent cause of its
social observations, by sampling from its posterior over this hidden (average) state. Another
way of looking at this is that each agent emits actions that maximize the accuracy of its
beliefs (i.e., minimize variational free energy), under the prior assumption it is the author
of its sensations, which, implicitly, are shared with other agents. Note that the choice to
sample from the posterior over actions (as opposed to e.g. taking the maximum) renders this
action-selection scheme a form of probability matching [18, 19].
2.4 Completing the loop
Given this sampling scheme for generating actions, we can simulate a collective active infer-
ence process by equating the actions of one agent to the observations of another. Specifically,
6
each focal agent’s spin action becomes an observation (σ for some j) for all the other agents
j
that it (the focal agent) is connected to. Next, we will show how the dynamics of multi-
agent active inference is analogous to a particular algorithm for sampling from the stationary
distribution of a spin glass model, known as Glauber dynamics [7]. We then examine the
fragility of this equivalence by exploring a number of simple modifications that break it.
3 Equivalence to Glauber dynamics
Spin glass models are formally described in terms of a global energy function over states of
the system. The global energy is related to the stationary probability distribution of the
system through a Gibbs law or Boltzmann distribution:
1
p∗(σ˜) = exp( βE(σ˜)) (6)
Z −
where the stationary density p∗ and energy function E are defined over spin configurations,
where a configuration is a particular setting of each of the N spins that comprise the system:
σ˜ = σ N : σ 1. The partition function Z is a normalizing constant that ensures
{ i }i=1 i ±
p∗(σ˜) integrates to 1.0, and β plays the role of an inverse temperature that can be used to
arbitrarily rescale the Gibbs measure. In the case of the Ising model, this energy function is
a Hamiltonian that can be expressed as a sum of pairwise interaction terms and an external
drive or bias (often analogized to an external magnetic field):
E(σ˜) = σ J σ h σ (7)
i ij j i i
− −
(cid:104)i,j(cid:105) i
(cid:88) (cid:88)
where J specifies a (symmetric) coupling between spin sites i and j and h specifies an
ij i
external forcing or bias term for site i. The bracket notation i,j denotes a sum over pairs.
(cid:104) (cid:105)
In numerical studies of the Ising model, one is typically interested in generating samples
from this stationary density. One scheme for doing so is known as Glauber dynamics, where
each spin σ of the system is updated using the following stochastic update rule:
i
σ P(σ = ( 1,+1))
i i
∼ −
1
P(σ = +1) =
i
1+exp( β∆ E)
i
−
∆ E = E E = 2 J σ +h (8)
i σi=DOWN
−
σi=UP ij j i
(cid:32) (cid:33)
j
(cid:88)
∈Mi
where ∆ E represents the difference in the energy between configurations where σ = 1 and
i i
−
those where σ = +1. In other words, the probability of unit i flipping to +1 is proportional
i
7
to the degree to which the global energy E would decrease as a result of the flip. If units
are updated sequentially (also known as ‘asynchronous updates’), then given sufficient time
Glauber dynamics are guaranteed to sample from the stationary density in Equation (6) [7].
The probability of agent i taking action σ = +1 is given by the action sampling rule in
i
Equation (5) of the previous section. We can thus write the probability of taking a particular
action in terms of the posterior over latent states z, by plugging in the posterior belief over
z = +1 (given in Equation (2)) into Equation (5):
1
P(σ = +1) = (9)
i
1+exp( 2(ζ +γ ∆ σ))
i i i
−
where we now index ζ,γ,∆σ by i to indicate that these are the generative model parameters
and observations of agent i. The identical forms shared by Equations (8) and (9) allow us to
directly relate the parameters of individual generative models to the local energy difference
∆ E and the global energy of the system.
i
∆ E J σ +h = γ∆ σ +ζ = J = γ, h = ζ
i j i i i i i
∝ ⇒
j
(cid:88)
∈Mi
where we assume all agents share the same likelihood precision γ = γ∗ : i, which is
i
∀
equivalent to forcing all couplings to be identical J = J : i,j. Individual active inference
ij
∀
agents in this multi-agent dynamic thus behave as if they are sampling spin states in order
to minimize a global energy function defined over spin configurations, which in the case of
spin glass systems like the Ising model, can be computed using local observations (the spins
of one’s neighbours) and model parameters γ,ζ. Going the other direction, one can sample
from the stationary distribution of spin glass system by simulating a collective of active
inference agents with an appropriately parameterized generative model.
However, the equivalence between Glauber sampling from the stationary distribution of
an Ising model and collective active inference breaks down when agents update their actions
in parallel or synchronously, rather than asynchronously. In particular, under parallel action
updates, the system samples from a stationary distribution with a different energy function
than that from Equation (7). See Appendix C for derivations on the relationship between
the schedule of action updates (synchronous vs. asynchronous) and the resulting stationary
density of the system.
4 Equivalence to inference in Boltzmann machines
Connecting the collective dynamics of these specialized active inference agents to inference in
Boltzmann machines is straightforward. We now equip each agent’s generative model with
a vector of sensory precisions γ˜ = γ : j M that act as different reliabilities assigned to
j
{ ∈ }
different neighbours’ spin observations. The new factorized likelihood can be written:
8
exp(γ σ z)
j j
P(σ˜ z;γ˜) = (10)
| 2cosh(γ z)
j
j∈M
(cid:89)
We can then write the posterior over z as a function of observations and generative model
parameters σ˜,ζ,γ˜ . By fixing z to the value +1, we obtain again a logistic expression for
{ }
the posterior probability P(z = +1 σ˜,γ˜,ζ) that is nearly identical to the original Equation
|
(2):
1
P(z = +1 σ˜,γ˜,ζ) = (11)
| 1+exp( 2(ζ + γ σ ))
− j∈M j j
ABoltzmannmachineisaspecialvariantofaspinglass(cid:80)model, definedbyaglobalenergy
that in turn defines the stationary probability assigned to each of the system’s configura-
tions. The Boltzmann energy E , as with the classical spin glass energy, is defined over
B
configurations of the system’s binary units (also known as nodes or neurons) x˜ = x N .
{ i }i=1
In the context of inference, it is common to partition the system’s units into ‘visible units’
˜
and ‘hidden units’, x˜ = v˜,h , with the following energy function:
{ }
1
E (v˜,h ˜ ) = (v˜(cid:62)W v˜+h ˜(cid:62)W h ˜ +v˜(cid:62)W h ˜ ) θ ˜(cid:62)v˜ θ ˜(cid:62)h ˜ (12)
B −2 vv hh vh − v − h
where W ,W ,W are weight matrices with symmetric couplings between units with
vv hh vh
no ‘self-edges’ (W = 0 : i) that mediate dependencies both within and between the two
ii
˜ ˜∀ ˜
subsets of units v˜,h; and θ ,θ are vectors of unit-specific biases or thresholds. The Bayesian
v h
inference interpretation of Boltzmann machines considers the conditional probability distri-
˜
bution over h, given some fixed values of v˜. The ‘clamping’ of visible nodes to some data
˜ ˜
vector v˜ = d can simply be absorbed into the biases θ , such that samples from the posterior
v
˜ ˜ ˜
P(h v˜ = d) are analogous to sampling from the joint distribution P(h,v˜) where the biases
|
of the visible nodes are adjusted to reflect this clamping. Sampling from this model can
be achieved with Glauber dynamics, since the model is a spin glass system with heteroge-
neous (but symmetric) couplings. We can therefore write the single unit ‘ON’ probability as
˜
follows, now in terms of weights W and thresholds θ:
1 1
P(x = +1) = = (13)
i
1+exp( ∆ E ) 1+exp( W x θ )
− i B − j ij j − i
where the interaction term that comprises the local energy di(cid:80)fference ∆ E is equivalent to
i B
a dot-product between the ith row of W and vector of activities x˜. It is thus straightforward
to relate the weights and biases of a Boltzmann machine to the sensory and prior precisions
of each agent’s generative model. In particular, the weight connecting unit j to unit i in a
Boltzmann machine W is linearly related to the precision that agent i associates to spin
ij
9
observations coming from agent j: W = 2γ where the subscript (i,j) refers to agent i’s
ij (i,j)
likelihood model over observations emitted by agent j. If agents i and j are not connected,
then W = γ = 0. The bias of the ith unit is also straightforwardly related to agent i’s
ij (i,j)
prior precision via θ = 2ζ .
i i
We have seen how sampling from the posterior distribution of a Boltzmann machine with
fixed visible nodes v˜ is equivalent to the collective dynamics of a specific multi-agent active
inference scheme. We have thus shown a carefully-constructed system, in which a form of
sampling-based Bayesian inference at one scale emerges from a process of collective active
inference at a lower scale.
5 Discussion
Although the equivalences we have shown are exact, there are numerous assumptions that,
when broken, violate the equivalence between the multi-agent dynamics defined at the lower
level, and the higher-level sampling dynamics of the spin glass system.
The energy-based models we have studied (Ising models, Boltzmann machines) are all
undirected graphical models: this means that the global energy function is defined by sym-
metric interaction terms across pairs of spins: J = J 1. In order to meet this requirement
ij ji
at the level of the individual agents, one must force the precisions that a pair of agents assign
to one another to be identical: γ = γ . This constraint also underpins the equilibrium
(i,j) (j,i)
nature of classical spin glass systems where detailed balance conditions are met, i.e., the
system is in thermodynamic equilibrium. In natural complex systems (especially biological
ones), these detailed balance conditions are often broken, and the systems operate far from
equilibrium [20–27]. This may manifest in the case of realistic multi-agent dynamics in the
form of asymmetric beliefs about reliability of social signals that agents assign to one another
[28].
Another fragility of the multiscale equivalence is the structure of the individual gener-
ative model, which relies on very specific assumptions about how hidden states z relate to
observations. Without this generative model at the single-agent level, there is no equivalence
between the collective active inference process and a spin glass model — the model’s dy-
namics could become more complex (and potentially analytically intractable), because the
posterior update is not guaranteed to be a simple logistic function of the sum of neighbour-
ing spins. This could be easily shown by changing the single agent’s likelihood model to
include a separate latent variable for each neighbour’s spin state2, or if the total likelihood
over neighbouring spin observations did not factorize into a product of neighbour-specific
likelihoods, but had some more complex statistical structure.
Finally, the convergence of Glauber dynamics to samples from the joint density over spin
configurationsdependsonthetemporalscheduleofactionupdating; namely, spinshavetobe
updated sequentially or asynchronously, rather than in parallel (see Appendix C for details)
1W=W(cid:62) for the Boltzmann machine, respectively
2This is analogous to the approach taken in [28], where each agent had beliefs about the belief state of
each of its neighbours
10
in order to guarantee sampling from the stationary distribution in Equation (6). If agents
act in parallel, then the stationary distribution of spin states is different than that given by
the classical spin glass Hamiltonian. In other words, depending on the relative timescales
of collective action, agents either will or will not minimize the global energy function that
their actions appear to local minimize (i.e. actions that minimize the local energy difference
∆ E).
i
6 Conclusion
In this work we demonstrate an exact equivalence between a collective active inference pro-
cess and sampling from the stationary density of a spin glass system. Furthermore, we
connect the system’s collective dynamics to sampling-based inference in energy-based mod-
els like Boltzmann machines. In particular, when we constrain certain agents in the network
to be ‘visible nodes’ and fix their actions, then the whole system samples from the posterior
distribution over spin configurations, given the actions of the ‘visible’ agents. Despite these
exact relationships, we also note the fragility of the equivalence, which relies on very particu-
lar assumptions. These include the symmetry of the precisions that pairs of agents assign to
each other, the temporal scheduling of the action updates, and the specific generative model
used by the agents. It remains to be seen, whether when these assumptions are broken,
an inferential or ‘agentive’ interpretation still obtains at higher scales, and if so, whether
the form of the ‘collective’ generative model can be analytically related to the individual
generative models as it was in the present, equilibrium case.
Our results have important implications for the overall agenda of multiscale active in-
ference, and the quest to uncover the quantitative relationship between generative models
operating at distinct scales in complex systems. In the system presented in the current work,
we show that active inference agents may collectively achieve sampling-based inference at a
distinct, higher level under particular conditions. Despite the apparent consistency at the
two scales, our result actually conflicts with claims made in the multiscale active inference
literature, that posits that systems hierarchically decompose into nested levels of active in-
ference agents [1–5] — in other words, that systems are inherently active inference processes
‘all the way down.’ Note that in our system, there are only active inference agents operating
at the lower level — the higher level is not an active inference agent, but is better described
as a passive agent that performs hidden state-estimation or inference by sampling from a
posterior belief over spin configurations. The agenda of the present work also resonates with
ongoing research into the necessary and sufficient conditions for generic complex systems to
be considered ‘agentive’ or exhibit inferential capacities [29–31].
Our results suggest that multiscale inference interpretations of complex systems do not
necessarily emerge in any system. We nevertheless hope that the simple equilibrium case
we presented here may serve as a launching pad for future studies into whether inference
interpretations can be rescued at the higher scale in cases when the fragile assumptions at
the single-agent level are broken.
11
Additional information
Acknowledgements The authors thank Alex Kiefer, Beren Millidge, Dalton Sakthivadi-
vel, Magnus Koudahl, Dimitrije Markovic and Maxwell Ramstead for their feedback and
comments throughout the writing of the manuscript.
Funding information C.H. is supported by the U.S. Office of Naval Research (N00014-
19-1-2556). C.H., B.K., &D.D.acknowledgethesupportofagrantfromtheJohnTempleton
Foundation (61780). The opinions expressed in this publication are those of the author(s)
and do not necessarily reflect the views of the John Templeton Foundation.
References
[1] Karl Friston. “A free energy principle for a particular physics”. In: arXiv (2019). doi:
10.48550/arXiv.1906.10184.
[2] Maxwell J.D. Ramstead, Paul B. Badcock, and Karl Friston. “Answering Schrödinger’s
question: A free-energy formulation”. In: Physics of Life Reviews 24 (2018), pp. 1–16.
doi: 10.1016/j.plrev.2017.09.001.
[3] Michael Kirchhoff, Thomas Parr, Ensor Palacios, Karl Friston, and Julian Kiverstein.
“TheMarkovblanketsoflife:Autonomy,activeinferenceandthefreeenergyprinciple”.
In: Journal of the Royal Society Interface 15 (138 2018). doi: 10.1098/rsif.2017.
0792.
[4] Ensor Rafael Palacios, Adeel Razi, Thomas Parr, Michael Kirchhoff, and Karl Friston.
“On Markov blankets and hierarchical self-organisation”. In: Journal of Theoretical
Biology 486 (2020), p. 110089. doi: 10.1016/j.jtbi.2019.110089.
[5] Maxwell J.D. Ramstead, Axel Constant, Paul B. Badcock, and Karl Friston. “Vari-
ational ecology and the physics of sentient systems”. In: Physics of Life Reviews 31
(2019), pp. 188–205. doi: 10.1016/j.plrev.2018.12.002.
[6] CasperHesp,MaxwellJ.D.Ramstead,AxelConstant,PaulB.Badcock,MichaelKirch-
hoff, and Karl Friston. “A multi-scale view of the emergent complexity of life: A free-
energy proposal”. In: Evolution, Development and Complexity. Springer, 2019, pp. 195–
227. doi: 10.1007/978-3-030-00075-2_7.
[7] Roy J. Glauber. “Time-dependent statistics of the Ising model”. In: Journal of Math-
ematical Physics 4.2 (1963), pp. 294–307. doi: 10.1063/1.1703954.
[8] Stephen G. Brush. “History of the Lenz-Ising model”. In: Reviews of Modern Physics
39.4 (1967), p. 883. doi: 10.1103/RevModPhys.39.883.
[9] Max Welling and Yee Whye Teh. “Approximate inference in Boltzmann machines”. In:
Artificial Intelligence 143.1 (2003), pp. 19–50. issn: 0004-3702. doi: 10.1016/S0004-
3702(02)00361-2.
12
[10] John J. Hopfield. “Neural networks and physical systems with emergent collective
computational abilities”. In: Proceedings of the National Academy of Sciences 79.8
(1982), pp. 2554–2558. doi: 10.1073/pnas.79.8.2554.
[11] Geoffrey E. Hinton and Terrence J. Sejnowski. “Optimal perceptual inference”. In:
Proceedings of the IEEE conference on Computer Vision and Pattern Recognition.
Vol. 448. 1983, pp. 448–453. url: http://www.cs.toronto.edu/~hinton/absps/
optimal.pdf.
[12] Geoffrey E. Hinton and Terrence J. Sejnowski. “Learning and relearning in Boltz-
mann machines”. In: Parallel Distributed Processing: Explorations in the Microstruc-
ture of Cognition, Vol. 1: Foundations. Vol. 1. MIT Press, 1986, pp. 282–317. isbn:
026268053X. url: https://dl.acm.org/doi/10.5555/104279.104291.
[13] Jean-Charles Walter and Gerard T. Barkema. “An introduction to Monte Carlo meth-
ods”. In: Physica A 418 (2015), pp. 78–87. doi: 10.1016/j.physa.2014.06.014.
[14] Karl Friston, Jean Daunizeau, and Stefan J. Kiebel. “Reinforcement learning or active
inference?” In: PloS One 4.7 (2009), e6421. doi: 10.1371/journal.pone.0006421.
[15] Karl Friston, Francesco Rigoli, Dimitri Ognibene, Christoph Mathys, Thomas Fitzger-
ald, and Giovanni Pezzulo. “Active inference and epistemic value”. In: Cognitive Neu-
roscience 6.4 (2015), pp. 187–214. doi: 10.1080/17588928.2015.1020053.
[16] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and Gio-
vanni Pezzulo. “Active inference: A process theory”. In: Neural Computation 29.1
(2017), pp. 1–49. doi: 10.1162/NECO_a_00912.
[17] David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. “Variational inference: A review
for statisticians”. In: Journal of the American Statistical Association 112.518 (2017),
pp. 859–877. doi: 10.1080/01621459.2017.1285773.
[18] David R. Shanks, Richard J. Tunney, and John D. McCarthy. “A re-examination of
probability matching and rational choice”. In: Journal of Behavioral Decision Making
15.3 (2002), pp. 233–250. doi: 10.1002/bdm.413.
[19] Alfonso Pérez-Escudero and Gonzalo de Polavieja. “Collective animal behavior from
Bayesian estimation and probability matching”. In: PLOS Computational Biology 7.11
(2011), pp. 1–14. doi: 10.1371/journal.pcbi.1002282.
[20] Chulan Kwon and Ping Ao. “Nonequilibrium steady state of a stochastic system driven
byanonlineardriftforce”.In:Physical Review E 84.6(2011),p.061106.doi:10.1103/
PhysRevE.84.061106.
[21] Han Yan, Lei Zhao, Liang Hu, Xidi Wang, Erkang Wang, and Jin Wang. “Nonequilib-
rium landscape theory of neural networks”. In: Proceedings of the National Academy
of Sciences 110.45 (2013), E4185–E4194. doi: 10.1073/pnas.1310692110.
13
[22] Yian Ma, Qijun Tan, Ruoshi Yuan, Bo Yuan, and Ping Ao. “Potential function in
a continuous dissipative chaotic system: Decomposition scheme and role of strange
attractor”.In:International Journal of Bifurcation and Chaos 24.02(2014),p.1450015.
doi: 10.1142/S0218127414500151.
[23] Ana P. Millán, Joaquín J. Torres, and Ginestra Bianconi. “Explosive higher-order Ku-
ramoto dynamics on simplicial complexes”. In: Physical Review Letters 124.21 (2020),
p. 218301. doi: 10.1103/PhysRevLett.124.218301.
[24] Karl Friston, Conor Heins, Kai Ueltzhöffer, Lancelot Da Costa, and Thomas Parr.
“Stochastic chaos and markov blankets”. In: Entropy 23.9 (2021), p. 1220. doi: 10.
3390/e23091220.
[25] Miguel Aguilera, S. Amin Moosavi, and Hideaki Shimazaki. “A unifying framework for
mean-field theories of asymmetric kinetic Ising systems”. In: Nature Communications
12.1 (2021), pp. 1–12. doi: 10.1038/s41467-021-20890-5.
[26] Christopher W. Lynn, Eli J. Cornblath, Lia Papadopoulos, Maxwell A. Bertolero, and
DaniS.Bassett.“Brokendetailedbalanceandentropyproductioninthehumanbrain”.
In: Proceedings of the National Academy of Sciences 118.47 (2021), e2109889118. doi:
10.1073/pnas.2109889118.
[27] Miguel Aguilera, Masanao Igarashi, and Hideaki Shimazaki. “Nonequilibrium thermo-
dynamics of the asymmetric Sherrington-Kirkpatrick model”. In: arXiv (2022). doi:
10.48550/arXiv.2205.09886.
[28] Mahault Albarracin, Daphne Demekas, Maxwell J.D. Ramstead, and Conor Heins.
“Epistemic communities under active inference”. In: Entropy 24.4 (2022), p. 476. doi:
10.3390/e24040476.
[29] Nathaniel Virgo, Martin Biehl, and Simon McGregor. “Interpreting dynamical sys-
tems as Bayesian reasoners”. In: Joint European Conference on Machine Learning and
Knowledge Discovery in Databases. Springer. 2021, pp. 726–762. doi: 10.1007/978-
3-030-93736-2_52.
[30] David Krakauer, Nils Bertschinger, Eckehard Olbrich, Jessica C. Flack, and Nihat
Ay. “The information theory of individuality”. In: Theory in Biosciences 139.2 (2020),
pp. 209–223. doi: 10.1007/s12064-020-00313-7.
[31] PeaksKrafft,ErezShmueli,ThomasL.Griffiths,JoshuaB.Tenenbaum,etal.“Bayesian
collective learning emerges from heuristic social learning”. In: Cognition 212 (2021),
p. 104469. doi: 10.1016/j.cognition.2020.104469.
14
Appendix: Spin glass systems as collective active inference
A Bayesian inference for a single agent
In this appendix we derive the exact Bayesian inference update for the posterior over the
latentstatez,takingtheperspectiveofasingleagent. Webeginbyrehearsingthecomponent
likelihood and prior distributions of the generative model in more detail.
A.1 Likelihood
The likelihood model relates the hidden state z to the observed spin state of a particular
neighbour σ as an exponential distribution parameterized by a sensory precision parameter
j
γ:
exp(γσ z)
j
P(σ z;γ) = (A.1)
j
| 2cosh(γz)
The sign and magnitude of γ determines the nature of the expected mapping between
hidden states z and neighbouring spin observations σ . For γ > 0, then the observed spin
j
is expected to reflect the latent state z, and with γ < 0, then the observed spin is expected
to be opposite to the latent state z. The magnitude of γ then determines how deterministic
this mapping is.
Equation (A.1) can alternatively be seen as a collection of two conditional Bernoulli
distributions over σ , one for each setting of z. This can be visualized as a symmetric matrix
j
mapping from the two settings of z (the columns, corresponding to z = 1,+1) to the values
−
of σ (the rows σ = 1,+1):
j j
−
1 1
1+exp( 2γ) 1+exp(2γ)
P(σ z;γ) = (A.2)
j  1 − 1 
|
1+exp(2γ) 1+exp( 2γ)
 
−
 
where this mapping approaches the identity matrix as γ .
→ ∞
Now we can move onto writing down the likelihood over the observed spins of multiple
neighbours: σ˜ = σ : j M where M denotes the set of the focal agent’s neighbours.
j
{ ∈ }
We build in a conditional independence assumption into the focal agent’s generative model,
whereby the full likelihood model over all observed spins factorizes across the agent’s neigh-
bours. Thismeanswecanwritethelikelihoodasaproductofthesingle-neighbourlikelihoods
shown in Equation (A.1):
exp(γσ z)
j
P(σ˜ z;γ) =
| 2cosh(γz)
j∈M
(cid:89)
= exp zγ σ Klog(2cosh(γz)) (A.3)
j
−
(cid:32) (cid:33)
j∈M
(cid:88)
15
where K is the number of the focal agent’s neighbours (i.e. the size of the set M). We
can easily generalize this likelihood to heterogeneous precisions by instead parameterizing it
with a precision vector γ˜ = γ : j M that assigns a different precision to observations
j
{ ∈ }
coming from each of the focal agent’s neighbours:
exp(γ σ z)
j j
P(σ˜ z;γ˜) =
| 2cosh(γ z)
j
j∈M
(cid:89)
= exp z γ σ log(2cosh(γ z)) (A.4)
j j j
−
(cid:32) (cid:33)
j∈M j∈M
(cid:88) (cid:88)
A.2 Prior
We parameterize the focal agent’s prior beliefs about the latent spin state z as a simple
Bernoulli distribution, and similarly to the likelihood model, we will express it as an expo-
nential function parameterized by a ‘prior precision’ parameter ζ:
exp(ζz)
P(z;ζ) = = exp(ζz log(2cosh(ζ)))
2cosh(ζz) −
As with the sensory precision γ, the prior precision also scales the strength of the focal
agent’s prior belief that the spin state z is +1.3
A.3 Bayesian inference of hidden states
Now we ask the question: how would a focal agent (i.e., the agent that occupies a single
lattice site) optimally compute a belief over z, that is most consistent with a set of observed
spins σ˜? This is a problem of Bayesian inference, which can be expressed as calculation of
the posterior distribution over z via Bayes Rule:
P(σ˜,z;γ,ζ)
P(z σ˜;γ,ζ) = (A.5)
| P(σ˜;γ,ζ)
Since we are dealing with a conjugate exponential model 4, we can derive an analytic
form for the posterior: P(z σ˜,γ,ζ):
|
exp z(ζ +γ σ )
j j
P(z σ˜;γ,ζ) = (A.6)
| 2co (cid:16) sh ζ +γ(cid:80) σ (cid:17)
j j
(cid:16) (cid:17)
3Note that cosh(ζz) can be re-written cosh(ζ) when z 1,+ (cid:80) 1 due to the symmetry of the hyperbolic
∈{− }
cosine function around the origin.
4The Bernoulli prior is conjugate to the likelihood model, which can also be described of as a set of
conditional Bernoulli distributions.
16
where the sum over neighbouring spins j only includes the neighbours of the focal agent, i.e,
σ . If we fix the hidden state z to a particular value (e.g. z = +1), then we arrive at a
j∈M j
simple expression for the posterior probability that the hidden spin state is in the ‘UP’ state,
(cid:80)
given the observations and the generative model parameters γ,ζ. This probability reduces
to a logistic or sigmoid function of sensory input, which is simply the sum of neighbouring
spin values ∆σ = σ . This can also be seen as the ‘spin difference’, or the number
j j
of neighbouring spins that are in the ‘UP’ position, minus those that are in the ‘DOWN’
(cid:80)
position. The steepness and horizontal shift of this logistic function are intuitively given by
likelihood and prior precisions, respectively:
exp(ζ +γ∆σ)
P(z = +1 σ˜,γ,ζ) =
| exp(ζ +γ∆σ)+exp( (ζ +γ∆σ))
−
exp( (ζ +γ∆σ)) −1
= 1+ −
exp(ζ +γ∆σ)
(cid:18) (cid:19)
1
= (A.7)
1+exp( 2(ζ +γ∆σ))
−
The denominator in the first line of (A.7) follows from the identity cosh(x) = 1(exp(x)+
2
exp( x)).
−
B Active inference derivations
In this section we provide the additional derivations needed to equip each agent with the
ability to infer a posterior over control states and sample from this posterior to generate
actions. This achieved through the framework of active inference.
Active inference casts the selection of control states or actions as an inference problem,
whereby actions u are sampled or drawn from posterior belief about controllable hidden
states. The posterior over actions is computed as the softmax transform of a quantity called
the expected free energy [1]. This is the critical objective function for actions that enables
active inference agents to plan actions into the future, since the expected free energy scores
the utility of the anticipated consequences of actions.
B.1 Predictive generative model
We begin by writing a so-called ‘predictive’ generative model that crucially includes proba-
bility distributions over the agent’s own control states u 1,+1 and how those control
∈ {− }
states relate to future (anticipated) observations. In other words, we consider a generative
model over two timesteps: the current timestep t and one timestep in the future, t+1. This
will endow our agents with a shallow form of ‘planning’, where they choose actions in order
to maximize some (pseudo-) reward function defined with respect to expected outcomes.
This can be expressed as follows:
17
˜
P(σ˜ ,z ,u , ;γ,ζ) = P( z ,u ,σ˜ )P(σ˜ ,z ,u ;γ,ζ) (B.8)
t t t t+1 t+1 t t t t t t
O O |
˜
where the generative model at the second timestep P( z ,u ,σ˜ ) we hereafter refer to as
t+1 t t t
O |
the ‘predictive’ generative model, defined over a single future timestep.
Active inference consists in sampling a belief from the posterior distribution over control
states u — this sampled control state or action is then fixed to be the spin state of the
agent under consideration. Thus the action of one agent is fed in as the observations for
those spin sites that it’s connected to. In order to imbue active inference agents with a
sense of goal-directedness or purpose, we encode a prior distribution over actions P(u) that
is proportional to the negative of the expected free energy, via the softmax relationship:
exp( G(u))
P(u) = − (B.9)
exp( G(u))
u −
Crucially, the expected free energy of(cid:80)an action G is a function of outcomes expected
under a particular control state u, where beliefs about future outcomes are ‘biased‘ by prior
beliefs about encountering particular states of affairs. In order to optimistically ‘bend’ these
future beliefs towards certain outcomes, and thus make some actions more probable than
˜
others, we supplement the predictive generative model P with a binary ‘optimality’ variable
1 that the agent has an inherent belief that it will observe. This is encoded via a ‘goal
O ±
prior’ or preference vector, which is a Bernoulli distribution over seeing a particular value of
with some precision parameter ω:
O
exp(ω )
˜
P( ;ω) = O (B.10)
t+1
O 2cosh(ω )
O
Hereafter we assume an infinitely high precision, i.e. ω . This renders the preference
→ ∞
an ‘all-or-nothing’ distribution over observing the optimality variable being in the ‘positive’
state = +1:
O
˜
P( = 1) 0.0
= O t+1 − = (B.11)
P ˜ ( = +1) 1.0
t+1
(cid:20) O (cid:21) (cid:20) (cid:21)
To allow an agent the ability to predict the relationship between their actions and ex-
pected observations, it’s important to include an additional likelihood distribution, what we
might call the ‘forward model’ of actions P( z ,u ;ξ). This additional likelihood en-
t+1 t t
O |
codes the focal agent’s assumptions about the relationship between hidden states, actions,
and the (expected) optimality variable. By encoding a deterministic conditional dependence
relationship into this likelihood, we motivate the agent (via the expected free energy) to
honestly signal its own estimate of the hidden state via its spin action u. To achieve this, we
18
explicitly design this likelihood to have the following structure, wherein the optimality vari-
able is only expected to take its ‘desired value’ of = +1 when z = u. This can be written
O
as a set of conditional Bernoulli distributions over , and each of which jointly depends on
O
z and u and is parameterized by a (infinitely high) precision ξ:
exp(ξ z u )
t+1 t t
P( z ,u ;ξ) = O (B.12)
t+1 t t
O | 2cosh(ξz u )
t t
When we assume ξ , then we arrive at a form for this likelihood which can be
→ ∞
alternatively expressed as a set of Bernoulli distributions that conjunctively depend on z
and u, and can be visualized as follows:
0 1
P( z ,u = 1) =
O t+1 | t t − 1 0
(cid:20) (cid:21)
1 0
P( z ,u = +1) =
O t+1 | t t 0 1
(cid:20) (cid:21)
(B.13)
where the columns of the matrices above correspond to settings of z 1,+1 . Therefore,
∈ {− }
the agent only expects to see = +1 (the desired outcome) when the value of the hidden
O
stateandthevalueofthecontrolvariableareequal,i.e. z = u; otherwise = 1isexpected.
O ˜−
For the purposes of the present study, we assume both the optimality prior P( ;ω) and the
O
optimality variable likelihood P( z,u;ξ) are parameterized by infinitely high precisions
O|
ω = ξ = , and hereafter will exclude them when referring to these distributions for
∞
notational convenience.
Having specified these addition priors and likelihoods, we can write down the new (pre-
dictive) generative model as follows:
˜ ˜
P( ,u ,z ) = P( z ,u )P(u )P( )P(z ) (B.14)
t+1 t t t+1 t t t t+1 t
O O | O
B.2 Active inference
Underactiveinference, bothstateestimationandactionareconsequencesoftheoptimization
of an approximate posterior belief over hidden states and actions Q(z,u;φ). This approxi-
mate posterior is optimized in order to minimize a variational free energy (or alternatively
maximize an evidence lower bound). This is the critical concept for a type of approximate
Bayesian inference known as variational Bayesian inference [2]. This can be described as
finding the optimal set of variational parameters φ that minimizes the following quantity:
φ∗ = argmin
F
φ
= E [lnQ(z ,u ;φ) lnP ˜ (σ˜ ,z ,u , ;γ,ζ)] (B.15)
Q t t t t t t+1
− O
19
In practice, because of the factorization of the generative model into a generative model
of the current and future timesteps, we can split state-estimation and action inference into
two separate optimization procedures. To do this we also need to factorize the posterior as
follows:
Q(z,u;φ) = Q(z;φ )Q(u;φ ) (B.16)
z u
where we have also separated the variational parameters φ = φ ,φ into those that pa-
z u
{ }
rameterize the belief about hidden states φ , and those that parameterize the belief about
z
actions φ .
u
When considering state-estimation (i.e. optimization of Q(z ;φ )), we only have to con-
t z
sider the generative model of the current timestep P(σ˜ ,z ;γ,ζ). The optimal posterior
t t
parameters φ∗ are found as the minimum of the variational free energy, re-written using only
z
those terms that depend on φ :
z
φ∗ = argmin (φ )
z F z
φz
(φ ) = E [lnQ(z ;φ ) lnP(σ˜ ,z ;γ,ζ)] (B.17)
F
z Q(zt;φz) t z
−
t t
To solve this, we also need to decide on a parameterization of the approximate posterior
over hidden states z . We parameterize Q(z ;φ ) as a Bernoulli distribution with parameter
t t z
φ , that can be interpreted as the posterior probability that z is in the ‘UP’ (+1) state:
z t
Q(z t ;φ z ) = (1 φ z
)1−zt
2
+1
φ z
zt
2
+1
(B.18)
−
By minimizing the variational free energy with respect to φ , we can obtain an expression
z
for the optimal posterior Q(z;φ∗) that sits at the variational free energy minimum. Due to
z
the exponential and conjugate form of the generative model, Q(z ;φ ) is the exact posterior
t z
andthusvariationalinferencereducestoexactBayesianinference. Thismeanswecansimply
re-use the posterior update equation of Equation (A.7) to yield an analytic expression for
φ∗:
z
1
φ∗ = (B.19)
z 1+exp( 2(ζ +γ∆σ))
−
Whenconsideringinferenceofactions, wenowconsiderthegenerativemodelofthefuture
timestep, which crucially depends on the current control state u and the optimality variable
t
. We can then write the variational problem as finding the setting of φ that minimizes
t+1 u
O
the variational free energy, now re-written in terms of its dependence on φ :
u
φ∗ = argmin (φ )
u F u
φu
(φ ) = E [lnQ(u ;φ ) lnP ˜ ( ,u ,z )] (B.20)
F
u Q(ut;φu) t u
− O
t+1 t t
20
As we did for the posterior over hidden states, we need to decide on a parameterization
for the posterior over actions Q(u ;φ ); we also parameterize this as a Bernoulli distribution
t u
with parameter φ that represents the probability of taking the ‘UP’ (+1) action:
u
Q(u t ;φ u ) = (1 φ z
)1−ut
2
+1
φ z
ut
2
+1
(B.21)
−
FromEquation(B.20)itfollowsthattheoptimalφ isthatwhichminimizestheKullback-
u
Leibler divergence between the approximate posterior Q(u ;φ ) and the prior P(u ), which is
t u t
a softmax function of the expected free energy of actions G(u ). In this particular generative
t
model, the expected free energy can be written as a single term that scores the ‘expected
utility’ of each action [1, 3]:
G(u ) = E [lnP ˜ ( )] (B.22)
t
−
Q(Ot+1|ut)
O
t+1
To compute this, we need to compute the ‘variational marginal’ over , denoted
t+1
O
Q( u ):
t+1 t
O |
Q( u ) = E [P( z ,u )] (B.23)
O
t+1
|
t Q(zt;φ∗
z
)
O
t+1
|
t t
We can simplify the expression for Q( u ) when we take advantage of the Bernoulli-
t+1 t
O |
parameterization of the posterior over hidden states Q(z;φ∗). This allows us to then write
z
the variational marginals, conditioned on different actions as a matrix, with one column for
each setting of u :
t
φ∗ 1 φ∗
Q( u ) = z − z (B.24)
O t+1 | t 1 φ∗ φ∗
(cid:20) − z z (cid:21)
The expected utility (and thus the negative expected free energy) is then computed as
the dot-product of each column of the matrix expressed in Equation (B.24) with the log of
˜
the prior preferences P( ):
t+1
O
φ∗
E [lnP ˜ ( )] = −∞ z
Q(Ot+1|ut) O t+1 (1 φ∗)
(cid:20)−∞ − z (cid:21)
φ∗
= G(u ) = ∞ z (B.25)
⇒ t (1 φ∗)
(cid:20)∞ − z (cid:21)
Because the probability of an action is proportional to its negative expected free energy,
this allows us to write the Bernoulli parameter φ∗ of the posterior over actions directly in
u
terms of the parameter of the state posterior:
21
1
φ∗ =
u 1+exp(β( (1 φ∗)))
∞ − z
1
= (B.26)
1+Cexp( φ∗)))
− z
The inverse temperature parameter β is an arbitrary re-scaling factor that can be used
to linearize the sigmoid function in (B.26) over the range [0,1] such that
φ∗ φ∗ (B.27)
u ≈ z
Note that the equivalence relation in Equation (B.27) is only possible due to the infinite
precisions ω and ξ of the likelihood and prior distributions over the ‘optimality’ variable
˜
P( u ,z ) and P( ), and from an appropriately re-scaled β parameter that linearizes
t+1 t t t+1
O | O
the sigmoid relationship in Equation (B.26).
B.3 Action sampling as probability matching
Now that we have an expression for the parameter φ∗ of the posterior over control states
u
Q(u ;φ∗), an agent can generate a spin state by simply sampling from this posterior over
t u
actions:
σ Q(u ;φ∗)
∼ t u
Q(z ;φ∗) (cid:44) P(z σ˜;γ,ζ) (B.28)
∼ t z t |
In short, each agent samples its spin state from a posterior belief over the state of the la-
tentvariablez , renderingtheiraction-selectionatypeofprobabilitymatching[4–6], whereby
t
actions (whether to spin ‘UP’ or ‘DOWN’) are proportional to the probability they are as-
signed in the agent’s posterior belief. Each agent’s sampled spin state also serves as an
observation (σ for some j) for the other agents that the focal agent is a neighbour of. This
j
collective active inference scheme corresponds to a particular form of sampling from the
stationary distribution of a spin glass model known as Glauber dynamics [7]. Crucially,
however, the temporal scheduling of the action-updating across the group determines which
stationary distribution the system samples from. We explore this distinction in the next
section.
C Temporal scheduling of action sampling
In this appendix we examine how the stationary distribution from which the collective active
inference system samples depends on the order in which actions are updated across all agents
22
in the network. First, we consider the case of synchronous action updates (all agents update
their actions in parallel and only observe the- spin states of their neighbours from the last
timestep), and show how this system samples from a different stationary distribution than
the one defined by the standard Ising energy provided in Equation (7). We then derive the
more ‘classical’ case of asynchronous updates, where agents update their spins one at a time,
and show how in this case the system converges to the standard statioanry distribution of
the Ising model. This Appendix thus explains one of the ‘fragilities’ mentioned in the main
text, that threaten the unique equivalence between local active inference dynamics and a
unique interpretation at the global level in terms of inference.
We denote some agent’s spin using σ and its set of neighbours as M . The local sum of
i i
spins or spin difference σ for agent i we denote ∆ σ = σ .
j∈M j i j∈Mi j
(cid:80) (cid:80)
C.1 Synchronous updates
To derive the stationary distribution in case of synchronous updates, we can take advantage
of the following detailed balance relation, which obtains in the case of systems at thermody-
namic equilibrium:
P(σ˜) P(σ˜ σ˜(cid:48))
= |
P(σ˜(cid:48)) P(σ˜(cid:48) σ˜)
|
P(σ˜ σ˜(cid:48))P(σ˜(cid:48))
= P(σ˜) = | (C.29)
⇒ P(σ˜(cid:48) σ˜)
|
where σ˜ and σ˜(cid:48) are spin configurations at two adjacent times τ and τ + 1. In the case
of synchronous updates (all spins are sampled simultaneously, given the spins at the last
timestep), then the spin action of each agent σ(cid:48) at time τ +1 is conditionally independent
i
of all other spins, given the vector of spins σ˜ at the previous timestep τ. We can therefore
expand the ‘forward’ transition distribution P(σ˜(cid:48) σ˜) as a product over the action posteriors
|
of each agent:
P(σ˜(cid:48) σ˜) = P(σ σ˜)P(σ σ˜)...P(σ σ˜)
1 1 N
| | | |
= Q(u ;φ∗ )
t u,i
i
(cid:89)
exp σ(cid:48) ζ +γ σ
=
i j∈Mi j
(cid:16) (cid:16) (cid:17)(cid:17)
2cosh ζ +γ(cid:80) σ
(cid:89) i j∈Mi j
(cid:16) (cid:17)
(cid:80)
= exp σ(cid:48)(ζ +γ σ ) log 2cosh(ζ +γ σ ) (C.30)
i j − j
(cid:32) (cid:32) (cid:33)(cid:33)
(cid:88)
i j
(cid:88)
∈Mi
(cid:88)
i j
(cid:88)
∈Mi
Note we have replaced each latent variable in the posterior z with the agent’s own spin
stateσ ,becausethereisaone-to-onemappingbetweentheposterioroverz andtheposterior
i t
over actions σ .
i
23
The reverse transition distribution, yielding the probability of transitioning from config-
uration σ˜(cid:48) σ˜ is the same expression as for the forward transition, except that σ(cid:48) and σ
→ i i
are swapped:
P(σ˜ σ˜(cid:48)) = exp σ (ζ +γ σ(cid:48)) log 2cosh(ζ +γ σ(cid:48)) (C.31)
| i j − j
(cid:32) (cid:32) (cid:33)(cid:33)
(cid:88)
i j
(cid:88)
∈Mi
(cid:88)
i j
(cid:88)
∈Mi
The detailed balance equation in (C.29) then tells us that the stationary probability
distribution over σ˜ is proportional to the ratio of the backwards transition to the forwards
transition:
exp σ (ζ +γ σ(cid:48)) log 2cosh(ζ +γ σ(cid:48))
P(σ˜)
=
i i j∈Mi j − i j∈Mi j
P(σ˜(cid:48))
exp
(cid:16)
(cid:80) σ(cid:48)(ζ +γ(cid:80) σ ) (cid:80) log
(cid:16)
2cosh(ζ +γ(cid:80) σ )
(cid:17)(cid:17)
i i j∈Mi j − i j∈Mi j
(cid:16) (cid:16) (cid:17)(cid:17)
exp (cid:80)ζ σ +γ (cid:80) σ σ(cid:48) ex(cid:80)p log 2cosh((cid:80)ζ +γ σ(cid:48)
=
i i (cid:104)i,j(cid:105) i j − i j∈Mi j
(cid:16) (cid:17) (cid:16) (cid:16) (cid:17)(cid:17)
exp ζ(cid:80) σ(cid:48) +γ(cid:80) σ(cid:48)σ exp (cid:80) log 2cosh(ζ +γ(cid:80) σ
i i (cid:104)i,j(cid:105) i j − i j∈Mi j
(cid:16) (cid:17) (cid:16) (cid:16) (cid:17)(cid:17)
exp ζ(cid:80) σ + (cid:80)log 2cosh(ζ +γ (cid:80) σ (cid:80)
=
i i i j∈Mi j
(C.32)
(cid:16) (cid:16) (cid:17)(cid:17)
exp ζ(cid:80) σ(cid:48) +(cid:80) log 2cosh(ζ +γ(cid:80) σ(cid:48)
i i i j∈Mi j
(cid:16) (cid:16) (cid:17)(cid:17)
(cid:80) (cid:80) (cid:80)
Therefore, we can write down the stationary distribution in the case of synchronous
updates as an exponential term normalized by a partition function:
P(σ˜) = Z−1exp ζ σ + log 2cosh(ζ +γ σ )
i j
(cid:32) (cid:32) (cid:33)(cid:33)
(cid:88)
i
(cid:88)
i j
(cid:88)
∈Mi
Z = exp ζ σ + log 2cosh(ζ +γ σ ) (C.33)
i j
(cid:32) (cid:32) (cid:33)(cid:33)
(cid:88)
σ˜
(cid:88)
i
(cid:88)
i j
(cid:88)
∈Mi
Note that the action update for an individual agent can still be written in terms of the
local energy difference ∆ E, where the energy is defined using the standard Hamiltonian
i
function given by Equation (7) in the main text. However, due to the temporal sampling of
each agent’s action with respect to the others, the system collectively sample from a system
with a different energy function and Gibbs measure, given by Equation (C.33). This energy
function is therefore nonlinear and can be written:
E (σ˜) = ζ σ log(2cosh(ζ +γ σ )) (C.34)
sync j
− −
(cid:88)
i
(cid:88)
i j
(cid:88)
∈Mi
24
C.2 Asynchronous updates
Now we treat the case where agents update their agents one-by-one or asynchronously. This
means that at each timestep only one agent is updated, and that particular agent uses the
spin states of all the other agents at the last timestep as inputs for its posterior inference.
We can write down the forward transition as follows, using the notation σ to denote all
\i
the spins except for σ :
i
exp(σ(cid:48)(ζ +γ σ ))
p(σ(cid:48),σ˜ σ˜) = i j∈Mi j (C.35)
i \i | 2cosh(ζ +γ σ )
(cid:80)j∈Mi j
which indicates that only agent i is updated at the cu(cid:80)rrent timestep. The detailed balance
condition implies that
p(σ(cid:48),σ˜ σ˜)p(σ˜) = p(σ˜ σ(cid:48),σ˜ )p(σ(cid:48),σ˜ ) (C.36)
i \i | | i \i i \i
Then
p(σ˜) p(σ˜ σ(cid:48),σ˜ ) exp(σ (ζ +γ σ ) log(2cosh(ζ +γ σ )))
= | i \i = i j∈Mi j − j∈Mi j (C.37)
p(σ(cid:48),σ˜ ) p(σ(cid:48),σ˜ σ˜) exp(σ(cid:48)(ζ +γ σ ) log(2cosh(ζ +γ σ )))
i \i i \i | i (cid:80)j∈Mi j − (cid:80)j∈Mi j
exp(σ (ζ +γ σ ))
=
i j∈Mi j (cid:80) (cid:80)
(C.38)
exp(σ(cid:48)(ζ +γ σ ))
i (cid:80)j∈Mii j
By repeating this operat(cid:80)ion for every agent (i.e. N 1 more times), then we arrive at:
−
p(σ˜) = p(σ˜) p(σ i (cid:48),σ˜ \i ) ... p(σ˜ \ (cid:48) i ,σ i ) = exp(ζ i σ i +γ i<j σ i σ j ) (C.39)
p(σ˜(cid:48)) p(σ(cid:48),σ˜ )p(σ(cid:48),σ(cid:48),σ˜ ) p(σ˜(cid:48)) exp(ζ σ(cid:48) +γ σ(cid:48)σ(cid:48))
i \i i j \i,j (cid:80)i i (cid:80)i<j i j
We can therefore write the marginal distributions p(σ˜)(cid:80)as proport(cid:80)ional to the numerator
of the last term in Equation (C.39)5:
p(σ˜) exp(ζ σ +γ σ σ )
i i j
∝
i (cid:104)i,j(cid:105)
(cid:88) (cid:88)
= p(x) =Z−1exp(ζ σ +γ σ σ ) (C.40)
i i j
⇒
i (cid:104)i,j(cid:105)
(cid:88) (cid:88)
We thus recover the original stationary distribution with the standard, linear energy
function as given by Equation (7) in the main text, written now in terms of generative
model parameters γ,ζ instead of the standard ‘couplings’ and ‘biases’ J,h:
5Note that because of assumption that the system is at thermal equilibrium, the same reasoning could
be applied to write the distribution over p(σ˜(cid:48)) in terms of the denominator of Equation (C.39)
25
E (σ˜) = γ σ σ ζ σ (C.41)
async i j i
− −
(cid:104)i,j(cid:105) i
(cid:88) (cid:88)
Supplemental References
[1] Karl Friston, Francesco Rigoli, Dimitri Ognibene, Christoph Mathys, Thomas Fitzger-
ald, and Giovanni Pezzulo. “Active inference and epistemic value”. In: Cognitive Neu-
roscience 6.4 (2015), pp. 187–214. doi: 10.1080/17588928.2015.1020053.
[2] David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. “Variational inference: A review
for statisticians”. In: Journal of the American Statistical Association 112.518 (2017),
pp. 859–877. doi: 10.1080/01621459.2017.1285773.
[3] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, and Gio-
vanni Pezzulo. “Active inference: A process theory”. In: Neural Computation 29.1
(2017), pp. 1–49. doi: 10.1162/NECO_a_00912.
[4] Nir Vulkan. “An economist’s perspective on probability matching”. In: Journal of Eco-
nomic Surveys 14.1 (2000), pp. 101–118. doi: 10.1111/1467-6419.00106.
[5] David R. Shanks, Richard J. Tunney, and John D. McCarthy. “A re-examination of
probability matching and rational choice”. In: Journal of Behavioral Decision Making
15.3 (2002), pp. 233–250. doi: 10.1002/bdm.413.
[6] Wolfgang Gaissmaier and Lael J. Schooler. “The smart potential behind probability
matching”. In: Cognition 109.3 (2008), pp. 416–422. doi: 10.1016/j.cognition.
2008.09.007.
[7] Roy J. Glauber. “Time-dependent statistics of the Ising model”. In: Journal of Math-
ematical Physics 4.2 (1963), pp. 294–307. doi: 10.1063/1.1703954.
26

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Spin glass systems as collective active inference"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
