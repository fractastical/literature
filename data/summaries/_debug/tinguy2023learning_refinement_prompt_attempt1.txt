=== IMPORTANT: ISOLATE THIS PAPER ===
You are revising a summary for ONLY the paper below. Do NOT reference or use content from any other papers.
Paper Title: Learning Spatial and Temporal Hierarchies: Hierarchical Active Inference for navigation in Multi-Room Maze Environments
Citation Key: tinguy2023learning
REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Issues to fix:
1. CRITICAL: The current summary has severe repetition issues. You MUST eliminate all repeated sentences, phrases, and paragraphs. Each idea should be expressed only once. If you find yourself repeating content, remove the duplicates entirely. Focus on variety and uniqueness in your wording.
2. Severe repetition detected: Same sentence appears 4 times (severe repetition)

Current draft (first 2000 chars):
Here's a summary of the paper "Learning Spatial and Temporal Hierarchies: Hierarchical Active Inference for navigation in Multi-Room Maze Environments," adhering to all the specified instructions:**Summary**This paper introduces a novel hierarchical active inference model designed to address the challenges of autonomous navigation in complex, multi-room maze environments. The model, comprised of a cognitive map, an allocentric, and an egocentric world model, leverages curiosity-driven exploration alongside goal-oriented behavior at multiple timescales. The core innovation lies in integrating spatial and temporal hierarchies to effectively learn the underlying structure of the maze and achieve robust navigation. The model avoids the limitations of existing approaches, which often struggle with long-term planning and aliased observations.**Key Claims and Findings**The authors state: “The ability to learn and infer the underlying structure of the environment is crucial for effective exploration and navigation.” They note: “These generative models aim to capture the underlying structure and dynamics of the world, but these are typically limited to small simulations with discrete state and observation spaces.” The paper argues: “Without a preferred state leading the agent to explore, the model is driven by epistemic foraging, i.e. maximising information gain.” The authors demonstrate: “The model achieves a stable place description within about three observations in room sizes that were part of its training.” The study demonstrates: “The model achieves a stable place description within about three observations in room sizes that were part of its training.” The authors report: “The model achieves a stable place description within about three observations in room sizes that were part of its training.” The study demonstrates: “The model achieves a stable place description within about three observations in room sizes that were part of its training.” The authors report: “The ...

Key terms: navigation, world, hierarchies, environments, maze, hierarchical, learning, multi

=== FULL PAPER TEXT ===
Learning Spatial and Temporal Hierarchies:
Hierarchical Active Inference for navigation
in Multi-Room Maze Environments
Daria de Tinguy1, Toon Van de Maele1, Tim Verbelen2 and Bart Dhoedt1
Abstract—Cognitive maps play a crucial role in facilitating a global prefixed frame. While all these generative models
flexible behaviour by representing spatial and conceptual re- aim to capture the underlying structure and dynamics of the
lationships within an environment. The ability to learn and
world, these are typically limited to small simulations with
infertheunderlyingstructureoftheenvironmentiscrucialfor
discrete state and observation spaces.
effective exploration and navigation. This paper introduces a
Addressing this aspect, recent approaches like G-SLAM
hierarchical active inference model addressing the challenge of
inferring structurein theworld from pixel-based observations. [11] and Dreamer [12] use deep neural networks to learn
We propose a three-layer hierarchical model consisting of a generativeworldmodelsfromhigh-dimensionalobservations
cognitive map, an allocentric, and an egocentric world model, such as pixels. However, as these capture the world in a
combining curiosity-driven exploration with goal-oriented be-
flat latent state space, these models struggle with long-term
haviouratthedifferentlevelsofreasoningfromcontexttoplace
planning, especially in aliased environments.
tomotion.Thisallowsforefficientexplorationandgoal-directed
search in room-structured mini-grid environments. In this paper, in order to enhance the agent’s ability to
navigate autonomously and intelligently we propose a pixel-
I. INTRODUCTION
based hierarchical active inference model exhibiting both
The development of autonomous systems able to navigate spatial and temporal hierarchies. The model is geared to-
intheirenvironmentisacrucialsteptowardsbuildingintelli- wardslearningthestructureofmazemini-gridenvironments
gentagentsthatcaninteract with therealworld.Developing [13]. A maze consists of interconnected, visually similar
navigationskillsinartificialagentstomirrorthenaturalnav- rooms with variations in shape, size, and colour as depicted
igational abilities observed in animals, enabling these agents in Fig 1. Within the maze, there is a single white goal tile.
to adeptly move autonomously through their surroundings, Our model consists of amortised inference models at the
has been a topic of great interest in the field of robotics and lowerlevels,whicharetrainedonpixeldata,forrepresenting
artificialintelligence.Understandingcomplexandpotentially movement and pose in egocentric and allocentric reference
aliasedenvironmentsandeffectivelynavigatingthemrequire framesrespectively,combinedwithagraph-structuredmodel
both spatial hierarchy, i.e. capturing spatial structures and at the top to capture the maze structure. The model navi-
relationships [1], and temporal hierarchy [2] as they are gation is based on a principled active inference approach,
essential for devising long-term navigation strategies. This which balances goal-directed behaviour and epistemic for-
has led to the exploration of various approaches, including agingthroughinformationgain[14].Moreover,theplanning
cognitive mapping inspired by animal navigation strategies. happensatdifferenttemporaltimescalesateachlevelinthe
In the animal kingdom, cognitive mapping plays a crucial hierarchy, allowing for long-term decision-making.
role in navigation. Cognitive maps allow animals to under- Our contributions can be summarised as follows:
stand the spatial layout of their surroundings [3], [4], [5], • Weintroduceasystemleveraginghierarchicalactivein-
remember key locations, solve ambiguities thanks to context ference and world modelling for achieving autonomous
[6]andplanefficientroutes[6],[7].Byleveragingcognitive navigation without the necessity for task-specific train-
mapping strategies, animals can successfully navigate com- ing. This approach allows agents to navigate intelli-
plexenvironments,adapttochanges,andreturntopreviously gently in familiar environments.
visited places. • Our system is built upon visual observations, which
Several approaches have been proposed to learn the struc- holds promise for real-world applications.
ture of the world in the context of navigation. [8] proposes • The proposed system not only learns the spatial struc-
a clone structured graph representation of the environment ture of the environment but also adapts to its dynamic
to disambiguate aliased observations. [9] presents a deep constraints enhancing autonomous navigation.
hierarchical model based on active inference and casts • It creates an internal map of the entire environment,
structure learning as a Bayesian model reduction problem. exhibiting scalability by not demanding increased com-
[10] introduces a hierarchical generative model learning and putational resources with larger environments.
recognising maze structures based on specific localisation in • We conduct comprehensive evaluations in a mini-grid
room maze environment [13]. Our approach demon-
1Department of Information Technology, University of Ghent, Ghent,
strates its efficiency in tasks related to exploration and
Belgium,2Verses AI, Vancouver, Canada {Correspondence to:
Daria de Tinguy <Daria.detinguy at ugent.be> goal attainment, outperforming other Reinforcement
3202
peS
81
]IA.sc[
1v46890.9032:viXra
Thecognitivemap:Thetoplayerinthegenerativemodel,
illustrated in Fig 2a) functions at the coarsest time scale
(T), each tick at this time scale corresponds to a distinct
location (l ) integrating the initial positions (pT) of the
T 0
place (zT). These locations are depicted as nodes in a
topologicalgraph,asshowninFig2d).Edgesbetweennodes
are added as the agent moves from one location to another,
effectively learning the maze structure. In order to maintain
thespatialstructurebetweenlocations,theagentkeepstrack
of its relative rotation and translation using a continuous
attractornetwork(CAN)asin[17].Hencethecognitivemap
forms a comprehensive representation of the environment,
Fig.1:Exampleofa3×3roomsmini-gridenvironmentand enabling the agent to navigate by formulating believes over
our model navigation in it during an exploration and goal- its surroundings.
reaching task, where the starting position is the red triangle. The allocentric model: The middle layer, illustrated in
Noise on the visualised path was added in post-processing Fig 2b), plays a crucial role in constructing a coherent
for observing superposed visits on a single tile. understandingoftheenvironment,denotedasz T .Thismodel
functions at a finer time scale (t), forming a belief over the
place by integrating a sequence of observations (sT) and
Learning (RL) models. t
poses (pT) to generate this representation [18], [19]. Fig 2e)
• Through quantitative and qualitative analyses, we and Fig t 5 showcase the resulting place defining the environ-
demonstrate the effectiveness of our hierarchical active
ment given accumulated observations. As the agent moves
inference world model in accomplishing various tasks.
from one place to another, once the current observations do
Our approach exhibits resilience to aliasing and show-
not align with the previously formed prediction about the
cases its ability to learn the underlying structure of the
place, the allocentric model resets its place description and
environment.
gathers new evidence to construct a representation of the
newly discovered room (z ), advancing by one tick on
T+1
II. METHOD
the coarser time scale and resetting the mid-level time scale
t to 0.
Symbols AssociatedTerms The egocentric model: The lowest layer, illustrated in
l location,experience Fig 2c), has the finest time scale (τ). To evolve in time
z place,room,allocentricstate
this model requires the prior state (st) and current action
p pose,position τ
s egocentricstate (at ) to infer the current observation (ot ) [20]. Based
τ+1 τ+1
a action on its current position, the model generates possible future
o observation
trajectorieswhileconsideringtheconstraintsimposedbythe
c collision
πx policy,sequenceofx environment, such as the inability to pass through walls
(achievedbydiscerningthecause-effectrelationshipbetween
TABLE I: Description of the variables used in our model
actions and observations). Fig 2f) illustrates the current ob-
servation in the middle o) and shows the imagined potential
The active inference framework [15] is built on the observations if the agent were to turn left i), right iii), or
premise that intelligent agents minimise their surprise. An move forward ii).
active inference agent entails an internal generative model Planning:Themodeloperateswithinahierarchicalactive
aiming to best explain the causes of external observation inference scheme, planning at different time scales. The
andtheconsequencesofitsactionsthroughtheminimisation cognitive map plays a vital role in long-term navigation by
of surprise or prediction error, which is also known as free handling place connectivity, allowing the model to plan the
energy (FE). Agents minimise this quantity with respect to locationstovisit(π)atahighlevel,theposestovisitwithin
model parameters in learning and with respect to action in eachplace(π )atamid-level,anddeterminingthebestaction
l
planning [14], [16]. policy(π )atthelowlevelwhileconsideringobstaclessuch
p
We propose a hierarchical generative model consisting of as walls. To infer the best navigation strategy to reach a
three layers functioning at nested timescales (see Fig 2). desired objective, the agent employs active inference and
From top to bottom: the cognitive map, creating a coherent utilises the concept of Expected Free Energy (EFE). EFE
topological map, the allocentric model, representing space, is a measure of the agent’s projected uncertainty or surprise
and the egocentric model, managing motions. The system aboutfuturestates.ByminimisingEFE,theagentaimstore-
infers the environment’s structure, over time, by agglomer- duce uncertainty and make accurate predictions about future
ating visual observations, creating representations of distinct outcomes, thus determining an optimal path to the objective
placessuchasrooms,andprogressivelyrevealingthemaze’s [16],[21].Thishierarchicalactiveinferenceprocess,coupled
connectivity as a graph. with the integration of EFE, allows the agent to effectively
Fig. 2: Our generative model unrolled in time and levels as defined in Eq.1. The left shows the graphical model of the
3-layerhierarchicalActiveinferencemodelconsistingofa)thecognitivemap,b)theallocentricmodel,andc)theegocentric
model, each operating at a different time scale. The orange circles represent latent states that have to be inferred, the blue
circles denote observable outcomes and the white circles are random variables to be inferred by planning. The right part
visualises the representation at each layer. The cognitive map is represented as d) a topological graph composed of all the
locations (l) and their connections, in which each location is stored in a distinct node. The allocentric model e) infers place
representations (z) by integrating sequences of states (s) and poses (p), from which the room structure can be generated.
The egocentric model f) imagines future observations given the current position, state (s), and possible actions (a) from this
position. Here o) depicts an actual observation (o) and the predicted observations of the possible actions left i), forward ii),
and right iii).
explore new rooms at the highest level, navigate within the III. RESULTS
roomsatthemid-level,andexecuteactionsseamlesslyatthe A. Tasks oriented navigation
low level.
Our testing primarily centre around assessing the model’s
The overall system can be represented as the formula
capacity to execute specific functional tasks, including ac-
equation 1.
quiring spatial maps through exploration in the presence
of aliased and disjoint sensory input, transferring structural
P(o˜,z˜,s˜,˜l,π,π˜,π˜)=P(π) (cid:89) P(z ,p0|l )P(l |π)P(π ) knowledge, and facilitating hierarchical planning. The agent
l p T T T T l
is assigned two tasks: exploration and goal-reaching, both
T
(cid:89) achieved without requiring re-training beyond learning fa-
P(st|z ,pT)P(pT|π ,pT)P(π )
0 T t t l 0 p miliar room structures.
t
(cid:89) Baseline. To establish a baseline for the navigation tasks,
P(st |st,at )P(at|π )P(ot,ct|st)
τ+1 τ T τ p τ τ τ we compare our method against:
τ
(1) • C-BET [22], an RL algorithm combining model-based
planningwithuncertaintyestimationforefficientexplo-
Our model hyper-parameters are defined Appendix C. ration decision-making.
It is trained on a dataset of pixel observations collected • Random Network Distillation (RND) [23], integrates
by sampling random actions in a 3 by 3 rooms mini-grid intrinsic curiosity-driven exploration to incentivise the
environment as depicted in Fig1. For more details on the agent’s visitation of novel states, meant to foster a
models and training procedure we also refer to Appendix E. deeper understanding of the environment.
• Curiosity[24],leveragesinformationgainasanintrinsic cannot see through walls (see Appendix D), entering a room
rewardsignal,encouragingtheagenttoexploreareasof may result in missing the adjacent wall corners, but these
uncertainty and novelty. corners hold limited importance for the agent’s objective.
• Count-based exploration [25] uses a counting mecha- As an unlikely example, missing all the corner tiles of each
nism to track state visitations, guiding the agent toward room results in 9% of the environment not being observed
less explored regions. (thus no matter the scale of the environment).
• Dreamerv3 [26] represents an advanced iteration of
world models for RL, offering the potential to enhance success
models
rate(%)
navigation by predicting and simulating future trajecto-
environment
ries for improved decision-making. configuration ours C-BET RND curiosity count
• A-star Algorithm (Oracle) [27], is a path planning 3x3rooms 93 81 16 32 13
3x4rooms 94 87 16 19 0
algorithm to which the full layout of the environment
4x4rooms 91 81 26 16 0
and its starting position is given to plan the ideal path
4x5rooms 81 74 7 23 3
to take between two points.
TABLEII:Thesuccessrateofeachmodelacrossallrunsin
Each of these models propose various RL based explo-
each environment is defined as the percentage of runs where
ration strategies for robotics navigation. All baselines were
the exploration covers at least 90% of the environment.
trained and tested on the exact same environments. For each
model training details, please refer to Appendix A to D.
The testing environments consist of connected rooms of 2) Exploitative Behaviour: To evaluate the exploitative
increasing scale, ranging from 9 up to 20 rooms, each room behaviour of the models, we configure all the models men-
with a width of 4 tiles. tioned in the baseline to navigate to the single white tile
1) Exploration: We assess to what extent the hierarchi- within the environment. This is conducted across environ-
cal active inference model enables our agent to efficiently ments of escalating size, ranging from 9 to 20 rooms. Goal-
explore the environment. Without a preferred state leading directed behaviour is induced in our model by setting a
the model toward an objective, the agent is purely driven preferred observation (i.e. the white tile) as typically done
by epistemic foraging, i.e. maximising information gain, in active inference [14], [21]. In the other RL models, an
effectively driving exploration [14]. extrinsic and intrinsic reward is associated with this white
Our evaluation involves comparing the performance of tile, motivating the agents to explore until they reach this
various models, including our proposed hierarchical active tile. The task is considered successful when the agent steps
inferencemodel,C-BET,Count,Curiosity,RNDmodels,and on the single white tile of the maze. All the models, except
an Oracle. These models are tasked with exploring fully the oracle, start without knowing their and the goal position
new environments with configurations ranging from 9 to in the environment, they therefore need to explore until
20 rooms. While the oracle possesses complete knowledge they find the objective. Fig.4 displays the results of all the
of the environment and its initial position, other models model in the goal seeking task in the diverse environments.
are equipped only with their top down view observations Our model requires, in average, more steps than the Count
(and, in the case of some RL models, extrinsic rewards) model to reach the white tile in the 3 by 3 and 3 by 4
-see AppendixD for more information about each model rooms configurations, however we can observe that count
observationtype-.TheRLmodelsareencouragedtoexplore also has the lowest success rate. The Count model often
until they locate a predefined goal (white tile); however, the failswhenreaching thegoalrequiresto cross severalrooms.
reward associated with the white tile is muted to encourage Overall our model reaches the white tile 89% of the time
continued exploration. Notably, the DreamerV3 model faces over all environments (see Tab.III), Dreamerv3 is showing
challenges in effective exploration due to its reliance on a poor performance because of over-fitting, not adapting
visual observations of the white tile for reward extraction. well to new rooms configurations and white tile placement
Consequently, an adapted environment without the white it has never seen during training. All models underwent
tile or a specific training would be necessary to employ training using the identical dataset detailed in Appendix B,
DreamerV3 as an exploration-oriented agent in this study. and the optimal models are selected for testing purposes.
Acrossmorethan30runsbyenvironmentscale,ourmodel This observation suggests that Dreamerv3 might require
demonstratesefficientexplorationcomparabletoC-BETand a comparatively higher degree of human intervention to
notablyoutperformingotherRLmodelsinalltestedenviron- effectivelyoperatewithinourenvironmentcomparedtoother
ments,asdepictedinFig.3.Moreover,theagentsuccessfully models.
achievesthedesiredlevelofexplorationmorefrequentlythan
B. Qualitative results
any other model across all configurations, as demonstrated
in Table II. For an exploration attempt to be considered Figure 5 illustrates the inference process of place descrip-
successful,theagentsmustobserveaminimumof90%ofthe tions. Within approximately three steps, the main features
observableenvironment.Thiscriterionensuresthatallrooms of the environment are captured and form a reasonably
areobservedatleastonce,withoutimposingapenaltyonthe accuratepictureoftheseenobservations.Whenencountering
modelsfornotcapturingeverysinglecorner.Sincetheagents a new aisle for the first time at step 11, the model is able
(a) coverage over steps of (c) coverage over steps of
all models in 3 by 3 rooms (b) coverage over steps of all models in 4 by 4 rooms (d) coverage over steps of
environments all models in 3 by 4 rooms environments all models in 4 by 5 rooms
environments environments
Fig. 3: The average exploration coverage across all test instances (>30runs) for each model computed within a certain scale
of environment. Our model and C-Bet demonstrate similar performances in terms of speed and overall coverage, with our
model exhibiting a narrower error margin in 3 by 4 rooms configuration, indicating consistent achievement of the specified
coverage in most runs.
observationcorrespondstotheredagent’sclearfieldofview,
as depicted in the agent position row of the figure (more
details about the observations AppendixD).
Figure 6 provides a direct comparison between the ac-
curacy of the cognitive map’s room reconstruction and the
corresponding physical environment. This comparison re-
veals that the estimated map closely aligns with the actual
map,withonlyminordiscrepanciesobservedinsomeblurry
passageways and a slight misplacement of the aisle in
the bottom right room. This shows how important global
position estimation is as the cognitive map uses believed
location to distinguish between two identical rooms (purple
rooms in the second column). This alignment between real
and imagined map underscores the fidelity of our model’s
internal representation in capturing the structural layout of
the environment. A supplementary demonstration showing
Fig. 4: All models are assigned a goal seeking task in more
the model’s ability for place recognition can be found in
than30environmentsvaryinginmazescalefrom3by3to4
by5roomspresentedinorderfromthe1stcolumntothelast. AppendixF Fig.10.
Additional quantitative and qualitative findings are avail-
The first row presents the mean number of steps each model
able in Appendix F, illustrating the agent’s capacity to gen-
take to successfully achieve the objective, with the black
eraliseandadeptlyreconstructmoreexpansiveenvironments
bars indicating a deviation of 15% around the mean. The
beyond its training exposure. The appendix also presents
second row representing the success rate of each model in
an instance of navigation within a maze characterised by
completingthetaskasapercentage.Acrossallenvironments,
aliasing, showcasing the model’s ability in constructing and
bothC-BETandourmodeloutperformtheotherRLmodels
selecting pertinent place representations. Furthermore, we
in terms of the mean number of steps required to reach the
demonstrate the proficiency of our hierarchical model in
goal. Each model has its own colour: Grey for the Oracle,
making precise predictions over extended time-frames, en-
red for Count, blue for Ours, green for curiosity, orange for
compassing transitions across various rooms where, in con-
C-BET, pink for DreamerV3 and purple for RND.
trast,recurrentstatespacemodelsoftenencounterchallenges
success
Models
rate(%)
Oracle 100%
Ours 89%
C-BET 86%
RND 81%
Curiosity 79%
DreamerV3 72%
Count 31%
TABLE III: The success rate of each model across all
Fig.5:Evolutionoftheplacerepresentationinaroomasnew
environments and runs.
observationsareprovidedbythemovingagent(redtriangle).
Themodelisabletocorrectlyreconstructthestructureofthe
room as observations are collected.
to adapt and generate a well-imagined representation. Each
position, and the egocentric model imagines action conse-
quences.
Low Computational Demands. Our hierarchical active
inferencemodelhasalowcomputationaldemandsregardless
of the environment’s scale. This efficiency is particularly
valuable as environments scale up, making our approach a
potential solution for real-world applications.
Scalability.Ourmodelefficientlylearnspatiallayoutsand
theirconnectivity.Thereexiststhepotentialforourapproach
toadapttonovelscenariosbyincorporatingdiverseenviron-
ments into its learning process, thus expanding allocentric
representations. Furthermore, the possibility of introducing
(a) A 3 by 4 room-maze seen from above. additional higher layers could facilitate greater abstraction,
transitioning from room-level learning to broader structural
insights.
Task Agnostic. The system doesn’t require task-specific
training, promoting adaptability to diverse navigational sce-
narios. It learns environment structures and generalises to
new scenarios, demonstrating applicability to various objec-
tives.
Visual based navigation. Leveraging visual cues should
enhance our model’s real-world applicability.
Aliasing Resistant. We show resistance to aliases, distin-
guishingbetweenidenticalplacesandthusideallysupporting
robust navigation.
(b) A map of a 3 by 4 environment and rooms representation given While our approach offers several advantages, it is also
by the cognitive map. We can see that the estimated map is loyal to
important to acknowledge its limitations:
the real map aside from some non precisely defined aisles and the
Environment Adaptation Our model requires adaptation
bottom right room having a slightly wrong aisle position.
tofullynewenvironmentsforoptimalperformance.Training
Fig. 6: a) displays the real map while b) is a composition of the allocentric model on room-specific data restricts navi-
a cognitive map room’s representations. Overall, the rooms gation to familiar settings. To mitigate this, and generalise
are recognisable when compared to the real map. to arbitrary environments, we could consider splitting the
data by unsupervised clustering [1], or by using the model’s
prediction error to chunk the data into separate spaces [28].
whentaskedwithpredictingacrossroomboundaries.Lastly, Recognition of Changed Environments Our proposal
we highlight the computational efficiency of our system in might struggle to detect environmental changes like altered
comparison to the conventional RL models employed in this tile colors, although this may not significantly impact navi-
study (Appendix A and F Tab.VII ). gation performance as a new place will replace or be added
with the previous one in the cognitive map, it remains an
IV. DISCUSSION
area for improvement.
The discussion section of this paper aims to provide a
Our comprehensive assessment, both quantitative and
comprehensive analysis of the proposed hierarchical active
qualitative,underscorestheadaptabilityandresilienceofour
inference model for autonomous navigation, considering its
approach, which fares well in explorative and exploitative
strengths and limitations. We outline the key contributions
taskscomparedtoC-BET[22],RandomNetworkDistillation
of our work and discuss the potential future works.
(RND) [23], Curiosity [24] or Count [25], Dreamerv3 [26].
Hierarchical Active Inference Model. Our proposal in-
In conclusion, while our navigation demonstrates promis-
troduces a three-layered hierarchical active inference model
ingexplorationandgoal-reachingabilitiesinaminigrid[13]
:
environment by learning structures and leveraging visual
• The cognitive map unifies spatial representation and cues, future research could focus on enhancing adaptation
memorises location characteristics. to new environments, handling changes in familiar ones,
• Theallocentricmodelcreateschunkedspatialrepresen- and adding comprehension to the cognitive map. Scalability
tations. and extension to complex dynamic scenarios are also poten-
• The egocentric model assesses policy plausibility, con- tial avenues for exploration. While our model demonstrates
sidering dynamic limitations. promising performance in a mini-grid environment, its ap-
These layers collaborate at different time scales: the high plication to more realistic scenarios, such as the Memory
level oversees the whole environment through locations, the maze [29] or Habitat [30], could lead to more practical
allocentric model refines place representations as it change implementations. Further improvements could also involve
learning a prior over topological map structures, promoting [18] S. M. A. Eslami, D. J. Rezende, F. Besse, F. Viola, A. S. Morcos,
informed exploration and imagination of shortcuts [31]. M. Garnelo, A. Ruderman, A. A. Rusu, I. Danihelka, K. Gregor,
D. P. Reichert, L. Buesing, T. Weber, O. Vinyals, D. Rosenbaum,
N. Rabinowitz, H. King, C. Hillier, M. Botvinick, D. Wierstra,
ACKNOWLEDGMENT
K. Kavukcuoglu, and D. Hassabis, “Neural scene representation
and rendering,” Science, vol. 360, no. 6394, pp. 1204–1210, 2018.
This research received funding from the Flemish Govern-
[Online]. Available: https://www.science.org/doi/abs/10.1126/science.
ment under the “Onder- zoeksprogramma Artificie¨le Intelli- aar6170
gentie (AI) Vlaanderen” programme. [19] T.VandeMaele,T.Verbelen,O.C¸atal,C.DeBoom,andB.Dhoedt,
“Activevisionforrobotmanipulatorsusingthefreeenergyprinciple,”
Frontiers in Neurorobotics, vol. 15, 2021. [Online]. Available:
REFERENCES
https://www.frontiersin.org/articles/10.3389/fnbot.2021.642780
[20] O. C¸atal, S. Wauthier, C. De Boom, T. Verbelen, and
[1] Y. Asano, C. Rupprecht, and A. Vedaldi, “Self-labelling via
B. Dhoedt, “Learning generative state space models for active
simultaneousclusteringandrepresentationlearning,”inInternational
inference,” Frontiers in Computational Neuroscience, vol. 14,
Conference on Learning Representations, 2020. [Online]. Available:
2020.[Online].Available:https://www.frontiersin.org/article/10.3389/
https://openreview.net/forum?id=Hyx-jyBFPr
fncom.2020.574372
[2] A. Zakharov, M. Crosby, and Z. Fountas, “Episodic memory for
[21] P. Schwartenbeck, J. Passecker, T. U. Hauser, T. H. FitzGerald,
learningsubjective-timescalemodels,”2020.
M. Kronbichler, and K. J. Friston, “Computational mechanisms of
[3] R.Epstein,E.Z.Patai,J.Julian,andH.Spiers,“Thecognitivemapin
curiosityandgoal-directedexploration,”eLife,vol.8,p.e41703,may
humans:Spatialnavigationandbeyond,”NatureNeuroscience,vol.20,
2019.[Online].Available:https://doi.org/10.7554/eLife.41703
pp.1504–1513,102017.
[22] S. Parisi, V. Dean, D. Pathak, and A. Gupta, “Interesting object,
[4] P. Foo, W. Warren, A. Duchon, and M. Tarr, “Do humans integrate
curious agent: Learning task-agnostic exploration,” CoRR, vol.
routesintoacognitivemap?map-versuslandmark-basednavigation
abs/2111.13119,2021.[Online].Available:https://arxiv.org/abs/2111.
of novel shortcuts.” Journal of experimental psychology. Learning,
13119
memory,andcognition,vol.31,pp.195–215,042005.
[23] Y. Burda, H. Edwards, A. J. Storkey, and O. Klimov, “Exploration
[5] M. Peer, I. K. Brunec, N. S. Newcombe, and R. A. Epstein,
by random network distillation,” CoRR, vol. abs/1810.12894, 2018.
“Structuring knowledge with cognitive maps and cognitive graphs,”
[Online].Available:http://arxiv.org/abs/1810.12894
Trends in Cognitive Sciences, vol. 25, no. 1, pp. 37–54, 2021.
[24] D.Pathak,P.Agrawal,A.A.Efros,andT.Darrell,“Curiosity-driven
[Online]. Available: https://www.sciencedirect.com/science/article/pii/
explorationbyself-supervisedprediction,”CoRR,vol.abs/1705.05363,
S1364661320302503
2017.[Online].Available:http://arxiv.org/abs/1705.05363
[6] J. Balaguer, H. Spiers, D. Hassabis, and C. Summerfield, “Neural
[25] M.Bellemare,S.Srinivasan,G.Ostrovski,T.Schaul,D.Saxton,and
mechanisms of hierarchical planning in a virtual subway network,”
R. Munos, “Unifying count-based exploration and intrinsic motiva-
Neuron,vol.90,pp.893–903,052016.
tion,”inAdvancesinNeuralInformationProcessingSystems,D.Lee,
[7] M. S. Tomov, S. Yagati, A. Kumar, W. Yang, and S. J. Gershman,
M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, Eds., vol. 29.
“Discovery of hierarchical representations for efficient planning,”
CurranAssociates,Inc.,2016.
bioRxiv, 2018. [Online]. Available: https://www.biorxiv.org/content/
[26] D. Hafner, J. Pasukonis, J. Ba, and T. Lillicrap, “Mastering diverse
early/2018/12/17/499418
domainsthroughworldmodels,”2023.
[8] D.George,R.Rikhye,N.Gothoskar,J.S.Guntupalli,A.Dedieu,and
[27] A. Candra, M. A. Budiman, and K. Hartanto, “Dijkstra’s and a-
M. La´zaro-Gredilla, “Clone-structured graph representations enable
star in finding the shortest path: a tutorial,” in 2020 International
flexiblelearningandvicariousevaluationofcognitivemaps,”Nature
Conference on Data Science, Artificial Intelligence, and Business
Communications,vol.12,042021.
Analytics(DATABIA),2020,pp.28–32.
[9] V.Neacsu,M.B.Mirza,R.A.Adams,andK.J.Friston,“Structure
[28] T. Verbelen, D. de Tinguy, P. Mazzaglia, O. Catal, and A. Safron,
learning enhances concept formation in synthetic active inference
“Chunking space and time with information geometry,” in NeurIPS
agents,” PLOS ONE, vol. 17, no. 11, pp. 1–34, 11 2022. [Online].
2022 Workshop on Information-Theoretic Principles in Cognitive
Available:https://doi.org/10.1371/journal.pone.0277199
Systems,2022.
[10] I.Stoianov,D.Maisto,andG.Pezzulo,“Thehippocampalformation
[29] J. Pasukonis, T. Lillicrap, and D. Hafner, “Evaluating long-term
as a hierarchical generative model supporting generative replay
memoryin3dmazes,”2022.
and continual learning,” Progress in Neurobiology, vol. 217, p.
[30] M.Savva,A.Kadian,O.Maksymets,Y.Zhao,E.Wijmans,B.Jain,
102329, 2022. [Online]. Available: https://www.sciencedirect.com/
J.Straub,J.Liu,V.Koltun,J.Malik,D.Parikh,andD.Batra,“Habitat:
science/article/pii/S0301008222001150
Aplatformforembodiedairesearch,”inProceedingsoftheIEEE/CVF
[11] A. Safron, O. C¸atal, and T. Verbelen, “Generalized simultaneous
InternationalConferenceonComputerVision(ICCV),October2019.
localization and mapping (g-SLAM) as unification framework for
[31] D.d.Tinguy,P.Mazzaglia,T.Verbelen,andB.Dhoedt,“Homerun:
natural and artificial intelligences: towards reverse engineering the
Findingyourwayhomebyimaginingtrajectories,”inActiveInference.
hippocampal/entorhinalsystemandprinciplesofhigh-levelcognition,”
Cham:SpringerNatureSwitzerland,2023,pp.210–221.
Oct.2021.[Online].Available:https://doi.org/10.31234/osf.io/tdw82
[32] O. C¸atal, T. Verbelen, T. Van de Maele, B. Dhoedt, and
[12] D. Hafner, T. P. Lillicrap, M. Norouzi, and J. Ba, “Mastering
A.Safron,“Robotnavigationashierarchicalactiveinference,”Neural
atariwithdiscreteworldmodels,”CoRR,vol.abs/2010.02193,2020.
Networks, vol. 142, pp. 192–204, 2021. [Online]. Available: https:
[Online].Available:https://arxiv.org/abs/2010.02193
//www.sciencedirect.com/science/article/pii/S0893608021002021
[13] M. Chevalier-Boisvert, L. Willems, and S. Pal, “Minimalistic grid-
[33] D. P. Kingma and J. Ba, “Adam: A method for stochastic
world environment for openai gym,” https://github.com/maximecb/
optimization.”[Online].Available:https://arxiv.org/abs/1412.6980
gym-minigrid,2018.
[14] K. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbeck, J. O.
Doherty, and G. Pezzulo, “Active inference and learning,”
Neuroscience & Biobehavioral Reviews, vol. 68, pp. 862–879,
2016. [Online]. Available: https://www.sciencedirect.com/science/
article/pii/S0149763416301336
[15] T. Parr, G. Pezzulo, and K. J. Friston, Active Inference: The Free
Energy Principle in Mind, Brain, and Behavior. The MIT Press,
2022.[Online].Available:https://direct.mit.edu/books/oa-monograph/
5299/Active-InferenceThe-Free-Energy-Principle-in-Mind
[16] R. Kaplan and K. Friston, “Planning and navigation as active infer-
ence,”122017.
[17] M.Milford,G.Wyeth,andD.Prasser,“Ratslam:ahippocampalmodel
forsimultaneouslocalizationandmapping,”vol.1,pp.403–408Vol.1,
2004.
APPENDIX
The appendixes are composed of two parts, the training specifics detailed from the models required computational
consideration Appendix A, then describing the dataset App.B then describing for each model the hyperparameters used
if any different from their source paper and the observations used for their model App.C and each model observation type
App.D. Moreover Appendix E details our training more in depth with the loss functions used for optimisation. Finally
App.F shows all the additional tests results from quantitative assessment of the generalisation ability to represent places to
the models testing computational requirements.
A. Training system requirements
Training used used
model n◦ CPU n◦ GPU GPUtype
time(h) RAM(G) Memory(G)
Ours
32 4 1 12 GTX980
egocentric
Ours
95 2 1 2.5 20 GTX1080
allocentric
Dreamerv3 411 5 2 10 30 GTX1080Ti
C-BET 232 10 1 2.6 32 GTX980
RND 117 6 1 2.7 10 GTX980
Curiosity 90 6 1 3 10 GTX980
Count 141 6 1 2.7 11 GTX980
TABLE IV: Comprehensive insights into the training specifics of all models are provided, encompassing their respective
trainingdurationuntilreachingtheirfinalisedversions.Additionally,detailsregardingthecomputationalresourcesemployed
are presented including the maximum RAM and memory allocation required for each model. Notably, our model underwent
training for both egocentric and allocentric components, executed in parallel using the same dataset, their division into
distinctsetsrealisedforpracticalreasons.Unfortunately,theinformationpertainingtotheRAMutilisationbytheegocentric
model is unavailable.
B. Training Dataset
Uniformity in training conditions was achieved by conducting training sessions for all models within identical environ-
ments, facilitated by the consistent application of a shared seed to generate these environments. The model is trained on a
mini-grid environment consisting of 3 by 3 squared rooms of 4 to 7 tiles wide connected by aisles of fixed length randomly
placed, separated by a closed door in the middle. Each room is assigned a colour at random from a set of four: red, green,
blue, and purple. In addition, white tiles may be present at random positions in the map. The agent has a top view of the
environment covering a windows of 7 by 7 tiles, including it’s own occupied tile. It cannot see behind itself, nor through
walls or closed doors.
C. Hyper-Parameters
Alltheadversarialmodelsweretraineduponpre-sethyper-parameters,withC-BET,Count,CuriosityandRNDupon[22]
described parameters. And DreamerV3 upon [26] proposed work, however the behaviour was modified from the original,
setting an Exploring task behaviour and a Greedy exploration behaviour as the original configuration was over-fitting in our
scenarios.
Ourmodelwastrainedusingthehyper-parametersinTab.VfortheallocentricmodelandTab.VIfortheegocentricmodel
Layer Neurons/Filters Stride
PositionalEncoder Linear 9
Convolutional 16 1//(kernel:1)
Posterior Convolutional 32 2
Convolutional 64 2
Convolutional 128 2
Linear 2*32
Concatenation
Linear 256*4*4
Upsample
Convolutional 128 1
Likelihood
Upsample
Convolutional 64 1
Upsample
Convolutional 32 1
Upsample
Convolutional 3 1
TABLE V: allocentric model parameters
Layer Neurons/Filters Stride
Concatenation
Prior LSTM 256
Linear 2*32
Convolutional 8 2
Convolutional 16 2
Convolutional 32 2
Concatenation
Posterior
Linear 256
Linear 64
Linear 256
Linear 32*7*7
ImageLikelihood
Upsample
Convolutional 16 1
Upsample
Convolutional 8 1
Upsample
Convolutional 3 1
Linear 16
CollisionLikelihood Linear 8
Linear 1
TABLE VI: egocentric model parameters
D. Models observations
Allmodelsusetheagent’stopdownvisionoftheagent,consistingin7by7tileswiththeagentplacedatthebottomcentre
of the image, as shown in 7. Our model and DreamerV3 use an RGB pixel rendering of shape 3x56x56. The observation
the agent interprets is a . while C-BET, Count, Curiosity and RND use a flat hot-encoded view of the environment as well
as an extrinsic reward when passing over the single white tile in the environment. We can point out that the agent can’t see
through walls in RGB image, we can see in Fig.7 a) the environment and the agent’s field of view represented by lighter
colours. Fig.7 b) shows the actual observation seen by the agent.
The number of actions cbet could take is greatly reduced compared to the original work, limiting to actions such as
forward, left, right and stand-by.
Fig. 7: a) cropped top down view of the environment, b) the RGB view of the agent, each tile of the environment are
composed of 8 by 8 pixels, generating a 56 by 56 total image. c) the equivalent hot-encoded view as a matrix, the numbers
and colours are only relevant for the example.
All the RL models have a sparse reward system, with an extrinsic reward generated only when passing on the white tile
disposed in the environment. Our model doesn’t require rewards, as such the goal we desire to set during the testing could
be any kind of observation.
E. Our Model training
In order to effectively train this hierarchical model, the two lower level models are considered independent and trained
in parallel To optimise the two ego-allocentric neural network models we first obtain a dataset of sequences of action-
observationpairsbyinteractingwiththeenvironment.Thiscanforexamplebeobtainedusingarandompolicyorbyhuman
demonstrations.
The egocentric and allocentric models are considered independent to optimise training. While they are trained over the
same data, the allocentric model has sequences chunked up to maximum the transition between two rooms, so that each
sequence encompass only a room each time. Thus the allocentric model received as training data of 1000 sequences of
40steps per room size (4 to 7 tiles width) while the egocentric received 100 sequences of 400 steps per room size, each full
sequence then cut in sub-sequences of 20 steps. All the training took place in 3x3 rooms maze where the agent could start
thesequencerandomlyfromanydoor(orneardoor)position.Thetrainingwasrealisedon100environmentsperroomsize.
Both neural networks can be trained in parallel end-to-end on this dataset using stochastic gradient descent by minimising
the free energy loss function.
For the egocentric model:
T
(cid:88)
L= D [p (s |s ,a ,o )||p (s |s ,a )]−log[p (o |s )] (2)
KL ϕ t t−1 t−1 t θ t t−1 t−1 ξ t t
t=1
The egocentric model was trained by minimising, in one part, the difference between the expected belief state given the
couple action, previous history and the estimated posterior obtained given the action, observation and updated history. And
in a second part minimising the difference between the reconstructed observation and the input observation [32].
While for the allocentric model:
T
(cid:88)
L= D [Qϕ(z|o ,p )||N(0,1)]+||oˆ −o ||2 (3)
KL t t t t
t=0
The approximate posterior Q is being modelled by the factorisation of the posteriors after each observation. The belief
over z can then be acquired by multiplying the posterior beliefs over z for every observation. We learn an encoder neural
network with parameters ϕ to learn the posterior state z given a single observation and pose pair (o ,s ).
k k
And the Likelihood being optimised by an MSE given the real observation o and the predicted observation oˆ [19], for
k k
each room the posterior is built on random sequence length varying from 15 observations up to the whole sequence of 40
steps. In order to obtain a position, the action of the agent is integrated into the next position. Both models use an Adam
optimisation [33].
While the cognitive map has been adapted for navigation in this type of mini-grid world [13], it is thought to be re-scaled
or adapted to other environments.
F. Supplementary results
The following appendix contributes to the work by shedding additional lights on the ability of the model to solve rooms
aliasing and its ability to generalise.
Fig3 shows the agent consistently achieving a stable place description within about three observations in room sizes that
were part of its training. Interestingly, the agent also demonstrates the ability to accurately reconstruct larger rooms, even
though it did not encounter such sizes during training. In particular, stable place descriptions for 8-tile wide rooms are
achieved in approximately five steps. This showcases the agent’s allocentric model generalisation abilities beyond the limits
ofitstraining.Theexperimentwasconductedover125runsin25environmentswiththeagenttaskedtopredictobservations
from unvisited poses after each new motion. Fig4 demonstrate the significance of the Mean Squared Error (MSE) value by
displaying examples of predicted observations and their corresponding MSE values. It can be observed that under an MSE
of 0.5, the predictions of the observations are visually quite accurate.
Fig.8:Predictionerrorofunvisitedpositionsover
min 5 tests per 5 environments by room size
starting from step 0 where the models has no Fig. 9: Observation queries, sampled prediction over unvisited
observation. position and mean MSE over 5 samples of predictions
In order to navigate autonomously, an agent must be capable of self-localisation and position correction based on visual
information and its internal beliefs about the environment. We perform navigation in a highly aliased mini-grid maze
consisting of four interconnected rooms. These rooms shared similarities in colour, configuration, or both colour and
configuration, differing only by a single white tile. These four rooms are depicted in Figure 10 A. The complete Figure 10
demonstrates the agent’s exploration of the rooms and its ability to differentiate between them without becoming confused,
even when retracing its path from the starting room by entering rooms through different aisles than before.
effectively, when the agent identifies a new place, it creates a fresh experience by incorporating its location. Figure 10 B.
displays each newly generated experience with a distinct ID and colour. has entered a new place or returned to a familiar
one, the agent considers the probability of each place to explain the current observations, as depicted in Figure 10 C. The
bars illustrate the number of hypotheses considered at each step, and the lines represent the probability of the place being
either a new or a previously visited one. The colours of the lines correspond to the colours attributed to the experiences
in Figure 10 B, with blue lines representing new unidentified places. Figure 10 D. displays the internal representation of
the places the agent uses. It is evident that the rooms are accurately imagined, and even a doubt in an aisle position in
experience 1 is not sufficient to confuse the agent.
In this context, the agent demonstrates the capability to navigate effectively and distinguish between rooms in a novel,
highlyaliasedenvironment.Theagent’saptitudetoidentifypreviouslyvisitedroomsevenuponenteringfromanewdoorway
underscores its capacity to retain a spatial memory of the environment.
Fig.10:Navigationsamplesoftheagentloopingclockwiseandanti-clockwise(resultinginentrythroughdifferentdoors)in
a new 2 by 2 room environment. Clockwise navigation corresponds to entirely new exploration, generating new places (as
seen with the blue lines in C. corresponding to a new room generation), while the anti-clockwise loop traverses previously
explored places. A. shows a new world comprising four visually similar rooms (identical in colour, shape, or both). B.
illustrates the model’s association of each room with a distinct experience ID C. C depicts the probability of a new place
being created (in blue, representing the most probable place among all possibilities) or an existing place being deemed the
most likely to explain the environment. The grey bars indicate the number of new places considered concurrently, with the
count of simultaneous hypotheses displayed on the right side of the plot. D. showcases the imagined place generated for
each experience ID. Experience 1 is not entirely accurate, yet it suffices to distinguish it from other rooms given actual
observations of it.
Furthermore,ourhierarchicalmodelalsofacilitatesaccuratepredictionsoverextendedtimescalesthatspandifferentrooms.
In contrast, recurrent state space models commonly struggle when tasked with predicting across room boundaries. Fig11
illustrates the prediction capabilities of each layer over a prolonged imagined trajectory within a familiar environment. The
figure showcases the predictions that each layer of the model would make as we project the imagination into the future, up
tothepointoftransitioningtoanewroomandbeyond.Thefirstrowdemonstrateshowtheegocentricmodelgraduallyloses
the spatial layout information over time, making it more suitable for short-term planning. The second row highlights the
model’s limitation to a single place in the environment, failing to recognise the subsequent room as the same place. Lastly,
in the third row, the cognitive map’s imagined trajectory accounts for the agent’s location and is capable of summoning
the appropriate place representation while estimating the agent’s motion across space and time. The final row displays the
ground truth trajectory, which aligns quite closely with the expectations of the cognitive map.
Finally, among all the reinforcement learning (RL) models employed in this study, an increase in the number of steps
directly correlates with higher memory usage, frequently leading to failure if memory capacity falls short. In contrast, our
approachprovidesanotablymoreefficientsolution,requiringamaximumof1Gofmemoryspaceandmitigatingscalability
concerns related to the size of the environment. Refer to Table VII for a summary of the most demanding requirements for
an exploration/goal task involving a maximum of 1500 steps.
Fig. 11: A trajectory leading toward a previously visited room is imagined by each model’s layer. The egocentric model,
characterised by its short-term memory, gradually loses information as time progresses. This is evident from step 2 onward,
where the front aisle is no longer represented after the agent makes a few turns without visual input. In contrast, the
allocentric model maintains the place description over time but encounters difficulty once it moves beyond the current place
itoccupies.Thecognitivemap,possessingknowledgeoftheconnectionsbetweenlocations,accuratelydeducestheexpected
place behind the door, resulting in a prediction remarkably similar to the ground truth.
used
model n◦ CPU n◦ GPU
Memory(G)
Ours 2 0 1
Dreamerv3 2 1 28
C-BET 2 0 12
RND 2 0 9
Curiosity 2 0 11
Count 2 0 8
TABLEVII:Everymodelhasspecificsystemrequirements,thistableoutlinesthemostdemandingcriterianeededtoachieve
successful exploration or goal seeking in the 4 by 5 rooms environment configuration.

=== REVISE TO ===
PROFESSIONAL TONE: Begin directly with content - NO conversational openings like 'Okay, here's...'

1. Fix all issues above
2. Title: "Learning Spatial and Temporal Hierarchies: Hierarchical Active Inference for navigation in Multi-Room Maze Environments"
3. Include 10-15 quotes from paper text
   - Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
   - Use consistent quote formatting: 'The authors state: "quote"' or vary attribution phrases
   - Vary attribution phrases to avoid repetition
   - CRITICAL: Only extract quotes that actually appear in the paper text
4. ELIMINATE ALL REPETITION - each sentence must be unique
   - Check before each sentence: 'Have I already said this?' If yes, write something new
   - Vary attribution phrases - do NOT repeat 'The authors state' multiple times
5. Extract methodology, results with numbers, key quotes
6. 1000-1500 words, structured with ### headers

Generate COMPLETE revised summary.