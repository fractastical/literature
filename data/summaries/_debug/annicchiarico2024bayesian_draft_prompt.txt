=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Bayesian model of individual learning to control a motor imagery BCI
Citation Key: annicchiarico2024bayesian
Authors: CÃ´me Annicchiarico, Fabien Lotte, JÃ©rÃ©mie Mattout

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2024

Key Terms: subject, lyon, imagery, learn, france, individual, learning, cognitive, bayesian, control

=== FULL PAPER TEXT ===

BAYESIAN MODEL OF INDIVIDUAL LEARNING TO CONTROL A
MOTOR IMAGERY BCI
C. Annicchiarico1,2,3, F. Lotte2, J. Mattout1,3
1 Lyon Neuroscience Research Center, CRNL, INSERM U1028, CNRS UMR5292, Computation,
Cognition and Neurophysiology Team, Lyon, France
2 Inria Center at the University of Bordeaux / LaBRI, France
3 UniversitÃ© Claude Bernard Lyon 1, Lyon, France
E-mail: come.annicchiarico@inserm.fr
ABSTRACT: The cognitive mechanisms underlying poorly understood. Some theoretical approaches [6], [7]
subjects' self-regulation in Brain-Computer Interface have proposed unifying frameworks to describe such
(BCI) and neurofeedback (NF) training remain poorly processes during BCI or NF training. Among those
understood. Yet, a mechanistic computational model of processes, the nature of subject learning has been the
each individual learning trajectory is required to improve main focus of academic debate [8]. Two views mostly
the reliability of BCI applications. The few existing prevail and are in relative opposition. Proponents of
attempts mostly rely on model-free (reinforcement operant conditioning reflect a model-free (reinforcement
learning) approaches. Hence, they cannot capture the learning) view on how subjects learn during BCI training
strategy developed by each subject and neither finely [9]. A different view that also assume that subjects learn
predict their learning curve. In this study, we propose an from trial and error, supporters of cognitive skill learning
alternative, model-based approach rooted in cognitive [10], [11], [12] suggest that subject actively build an
skill learning within the Active Inference framework. We interaction model of the BCI system in order to reliably
show how BCI training may be framed as an inference interact with it. According to this second view, users
problem under high uncertainties. We illustrate the learn a skill (â€œinteracting with the BCIâ€) in order to
proposed approach on a previously published synthetic control the interface despite the high levels of uncertainty
Motor Imagery ERD laterality training. We show how of the paradigm. This form of learning, more akin to
simple changes in model parameters allow us to â€œmodel-basedâ€ reinforcement learning (RL), provides
qualitatively match experimental results and account for more satisfactory explanations for phenomena such as
various subject. In the near future, this approach may transfer learning and the effect of metacognition on
provide a powerful computational to model individual regulation [7]. The true nature of subject experience
skill learning and thus optimize and finely characterize during BCI training probably stands between these two
BCI training. views on adaptation, with initial interactions generally
driven by RL and progressively building a more
INTRODUCTION complete model-based representation of the system.
The general lack of understanding of the self-regulation
Motor Imagery is one of the most employed non-invasive mechanisms at play during successful and failed training
BCI paradigm due to its potential in stroke rehabilitation procedures has prompted the scientific community
and motor control. Event-related desynchronization towards the development of models of subject learning in
(ERD) in motor cortices is associated with motor task order to explain and hopefully predict the outcome of
execution, observation or mental imagery. It is a key BCI training given a particular subject, experimental
biomarker to pick up to interface the brain with an design, etc. These models have built on the above-
assistive (e.g. neuroprosthetics) or a rehabilitation (e.g. described R.L. perspective to leverage difficult credit
neurofeedback) device. Studies focusing on MI training assignment problems as when learning individual neuron
have demonstrated notable positive outcomes, including activations under high uncertainty [13], [14]. We argue
enhanced hand dexterity [1] and post-stroke that in order to model the cognitive dynamics of training
improvements [2], [3]. These interventions capitalize on and account for its metacognitive and transfer learning
the overlapping neural pathways between mental dimensions, an explicit modelling of the subjectâ€™s
imagery and motor execution. Particularly in the context representations is needed. To our knowledge, such an
of hemispheric ischemic stroke, some studies have approach to BCI has barely been tackled. In this work,
attempted to address motor control deficits [4] by using we show how the Active Inference framework [15] may
neurofeedback training to strengthen MI laterality, with be leveraged to provide an adequate theoretical and
some success [5]. computational ground for developing this modelling
Despite those results, the core neuropsychological strategy. To illustrate our modelling approach, we
mechanisms behind subject self-regulation are still consider a rich and original study that has implemented a
multimodal right-hand Motor Imagery neurofeedback information. Importantly, BCI training can be nicely
training [16], [17]. framed with such an POMDP.
Table 1 provides the description of the above model
MATERIALS AND METHODS component and parameters in the context of BCI training.
Given this formulation, the subjectâ€™s Free Energy can be
Active Inference and BCI training: Active Inference minimized in three ways: through perception (inference
is a process theory that provides a description of agent on hidden states), action (transition between hidden
perception, action and representational learning as a states) and learning (updating model parameters). Under
single joint process based on minimization of this premise, agent s may pick actions in order to reduce
(variational) Free Energy [18], [19]. Active Inference is their (expected) free energy on the basis of anticipated
closely related to the predictive coding account of brain future observations, in a way that optimize a trade-off
function, which posits that the brain entertains and between information seeking (exploration) and reward
constantly updates a generative model ğ‘š of the maximization (exploitation). In this paper, agents plan
environment in order to formulate accurate predictions their future actions by comparing all the plausible action
about its dynamics and guide its actions. To minimize the trajectories within a specific temporal horizon [20].
prediction errors, agents continuously maintain beliefs Finally, learning occurs at a slower pace at which
about the hidden states of their environment and update subjects update their model parameters. In the discrete
them with regard to new observations (perceptual state space leveraged by Active Inference, these model
inference). This Bayesian process can be further parameters are categorical distributions equipped with
formalized as follows: assuming a set of beliefs ğ‘  about conjugate Dirichlet priors. Learning occurs through
hidden (causal) states ğ‘ Ì‚ of the environment and given counting co-occurrences between state posteriors and
new observations ğ‘œ, updated beliefs about those states observations (likelihood ğš), or transitions between states
write: following a given action (transition ğ›), akin an evidence
ğ‘(ğ‘œ|ğ‘ ,ğ‘š)ğ‘(ğ‘ |ğ‘š) Eq. 1 accumulation process [15]. In essence, Active Inference
ğ‘(ğ‘ |ğ‘œ,ğ‘š)=
ğ‘(ğ‘œ|ğ‘š) describes the evolution of subjectâ€™s beliefs (ğ‘¥,ğœ‹) and
Variational (Bayesian) inference provides both the model representations (ğš,ğ›,ğœ,ğ,ğ) depending on
evidence or marginal likelihood ğ‘(ğ‘œ|ğ‘š) and the posterior environmental parameters (ğ€,ğ,ğƒ). This translates
distribution ğ‘(ğ‘ |ğ‘œ,ğ‘š). Precisely, the former is directly to BCI training where we may cast the feedback
maximized and amounts to minimize an approximate provided to the subject as the observations, and the
energy function, which is a lower bound to the model mental states targeted by the training procedure
evidence (ELBO). Importantly, Active Inference makes (attention, hand motor imagery level, â€¦) as the true
use of two additional mathematical constructs to hidden states. The subject tries to reach high levels of
implement full representational learning and action. positive feedback by learning an accurate representation
First, it frames this belief updating process as a Hidden of the BCI system (ğš,ğ›,ğ).
Markov process or model (HMM) thus accounting for the
temporal evolution of subjectâ€™s beliefs. Second, it Table 1: Correspondence between Active Inference
includes action as part of the energy minimization graph parameters and BCI training elements
process, turning this HMM graph into a POMDP Active Inference BCI training element
(Partially Observable Markov Decision Process) (see parameter
Figure 1). In other words, free energy, surprise or ğ€ Emission rule: relation between
prediction is not only minimized through belief updating feedback and subjectâ€™s true mental state
but also by acting upon the environment to make it fit ğ,ğƒ Transition rule: effect of mental action
with predictions. onto mental states
ğš Subjectâ€™s belief about the feedback
(affected by instructions, experienceâ€¦)
ğ›,ğ Subjectâ€™s belief about its mental
strategies and the effect of its mental
actions (idem)
ğœ,ğ Subject preferences (towards positive
feedback) and habits
ğ¬Ì‚,ğ¬ True and belief about mental states,
respectively
ğ¨ Observations (feedback)
ğ›‘,ğ® Subjectâ€™s mental policy and possible
actions
Figure 1: Active Inference (POMDP) canonical model of
subjectâ€™s representation and interaction with a changing A Motor Imagery Neurofeedback training task: To
environment. This model makes explicit that the agent illustrate our modeling approach, we consider a
must infer and navigate the hidden, noisy and partially simplified version of the task implemented by Perronet,
observable environment based on noisy and sparse Lioi et al. [16], [17]. In their first experiment, (N=10)
subjects were instructed to perform kinesthetic right hand and the process in terms of state space dimensions could
motor imagery and to â€œfind their own strategyâ€ in order be accounted for and their effect on training simulated
to control a feedback gauge across 3 x 10 blocks. Each within this framework.
block comprised a 20s rest and a 20s task block. The task Emissions: Agents receive outcomes ğ‘œ based on their
ğ‘¡
was multimodal as both fMRI and EEG data were true state ğ‘ Ì‚ =(ğ‘–Ì‚(ğ‘¡),ğ›¼Ì‚(ğ‘¡)). This feedback modality
ğ‘¡
recorded and the feedback was based on either EEG (denoted as AsI) is based on the laterality of the ERD. It
alone, fMRI alone or both signals (two feedback gauges is computed using an asymmetry index between the left
simultaneously). Importantly, the gauge levels were and right ERDs, for ğ‘–Ì‚(ğ‘¡)>0 : (Eq.3)
always based on a measure of lateral asymmetry between ğ¸Ì‚ğ‘…ğ· (ğ‘¡)âˆ’ğ¸Ì‚ğ‘…ğ· (ğ‘¡)
left and right motor cortex activities (For EEG: an ğ‘œÌ‚ ğ‘¡ =ğ´ğ‘ ğ¼(ğ›¼Ì‚)= ğ¸Ì‚ğ‘…ğ· ğ¿ (ğ‘¡)+ğ¸Ì‚ğ‘…ğ· ğ‘… (ğ‘¡) âˆˆ[âˆ’1,1]
asymmetry index computed on the normalized difference ğ¿ ğ‘…
To account for the noise in the biomarker and feature
in ğœ‡ (8-12 Hz) band power between C3 and C4, updated
extraction process, the categorical emission matrix ğ€
every 250 ms; for fMRI: a laterality index as described in
encodes the emission rule of the BCI pipeline as a
[21] , updated every 2 s).
discretized gaussian distribution ğ¶ğ‘ğ‘¡(ğ‘(ğ‘œÌ‚ ;ğœ )) with
This study is quite unusual, namely because of the two ğ‘¡ ğ‘ğ‘Ÿğ‘œğ‘
N = 5 possible feedback values.
neuroimaging modalities employed. However, it offers ğ´ğ‘ ğ¼
During the experimental task [16], the strength of left
an appealing example to model, for at least two reasons.
ERD was continuously monitored but was not provided
First, the well-defined laterality biomarker permits fairly
as a feedback signal. We mimic this observation channel
simple assumptions regarding the subject's self-
with a second emission modality (referred to as L-ERD)
regulatory process. Second, data availability [17] allows
based on the simulated left ERD level. Similarly, these
for broad model calibration. In what follows, we propose
outcomes are not observed by the synthetic subject
a computational model of this protocol and provide
during training. They are used to compare physiological
general predictions regarding long-term training
measurements to model predictions and broadly estimate
outcomes.
which parameter values best matched the study results
Modeling Motor Imagery laterality training: The
(see Results). Just like with the AsI modality, the L-ERD
Motor Imagery neurofeedback loop is formalized as a
observations are noisy (same noise parameter ğœ ) and
high uncertainty self-regulation task. The agent trains ğ‘ğ‘Ÿğ‘œğ‘
discretized so as to take one out of 5 possible values.
over ğ‘ , each trial being composed of an arbitrary 40
ğ‘¡ğ‘Ÿğ‘–ğ‘ğ‘™ğ‘ 
rest and 40 MI timesteps (each timestep corresponding to
2 EEG feedback update for the experimental task).
During MI, the agent is given a feedback based on its
hidden states and attempts to reach highly rewarding
outcomes. No feedback is provided during rest. During
the whole training, the agent activity was defined by two
hidden states based on electrophysiology : the left and
right ERD levels.
ğ¸Ì‚ğ‘…ğ· (ğ‘¡)=ğ‘–Ì‚(ğ‘¡) cos(ğ›¼Ì‚(ğ‘¡))+ğœ–
{ ğ¿ Eq.2
ğ¸Ì‚ğ‘…ğ· (ğ‘¡)=ğ‘–Ì‚(ğ‘¡) sin(ğ›¼Ì‚(ğ‘¡))+ğœ–
ğ‘…
Where the radius ğ‘–Ì‚(ğ‘¡)âˆˆ[0;1] captures the global ERD
ğœ‹
strength and the angle ğ›¼Ì‚(ğ‘¡)âˆˆ[0; ] its lateralization or
2
orientation. ğœ– is a baseline level accounting for
spontaneous desynchronizations outside of MI, which we
set to 0.01 (weak baseline level).
Agents have no direct observation of these two
physiological states that reflect cortical motor
excitability and could be associated with mental states
such as motor preparation and sensorimotor expectation.
In this framework, agents entertain a belief or prior over Figure 2: The modeled Motor Imagery intensity /
these states (ğ‘–;ğ›¼) and use the feedback provided (see orientation training. The agent internal representation
Emissions) to update this belief. drives the brain activity based on the feedback provided.
We further adopt a discretized, POMDP compatible
formulation of our model, considering that ğ‘–Ì‚,ğ›¼Ì‚ (process Transitions: At each timestep t, the subjectâ€™s true
states) and ğ‘–,ğ›¼ (model states) can each span a finite set of states evolve depending on previous state value ğ‘ Ì‚ and
ğ‘¡âˆ’1
ğ‘ğ‘  possible states. For the sake of simplicity, the mental actions ğ‘¢ . During the actual task, agents could
ğ‘¡âˆ’1
simulations were conducted with ğ‘ğ‘ (ğ‘–Ì‚)=ğ‘ğ‘ (ğ‘–)=4 {0: potentially explore and use a large number of mental
null, 1: low, 2: medium, 3: high ERD strength} and strategies (attentional / sensorial exercises, relaxation
ğœ‹
ğ‘ğ‘ (ğ›¼Ì‚)=ğ‘ğ‘ (ğ›¼)=5 {L: left (0) , CL: center-left ( ), C: efforts, etc.), among which only a limited amount would
8
ğœ‹ 3ğœ‹ ğœ‹ prove â€œeffectiveâ€ and allow the subject to control their
center ( ), CR: center-right ( ), R: right ( ) ERD
4 8 2 mental state with a probability ğ‘ =0.99. Since
ğ‘’ğ‘“ğ‘“ğ‘’ğ‘ğ‘¡
orientation}. Note that discrepancies between the model
mental actions are poorly understood, we assumed a values of ğ‘ , as high values of the parameter would
ğ‘ğ‘Ÿğ‘’
synthetic topological state space that statisfies the three render the training useless (this would mean the subject
as following constraints: was already knowing how to perform the task optimally).
- Continuity: for a specific state factor (ğ‘– / ğ›¼), the Goals & simulations: Using this simple model of self-
mental states could only move from value k to regulation, our goal was to predict training outcome
adjacent (or same) values {k-1, k , k+1}. depending on the individual priors of each subject.
- Invariability: for a specific state factor, the effect of Therefore, several families of agents were instantiated
â€œeffectiveâ€ actions was independent from the with various initial mental imagery familiarity levels. We
occupied state. demonstrate how these priors affect the way subjects
- Resting states: to reflect the natural tendency of learn how to perform the task and the evolution of the
Motor imagery intensity to return to a resting state, overall quality of their mental imagery models. To that
non â€œeffectiveâ€ actions pulled the mental state of the end, we conducted simulations of agents performing
subject towards this resting state with probability Active Inference using the parametrized graph
ğ‘ =0.1. The resting states were ğ‘–Ì‚=0 for MI parameters ğšğŸ,ğ›ğŸ,ğ€,ğ. The process parameters used in
ğ‘‘ğ‘’ğ‘ğ‘ğ‘¦
intensity and ğ›¼Ì‚ =ğ¶ (center) for MI orientation. these simulations are ğœ ,ğ‘ (ğ‘–) and ğ‘ (ğ›¼).
ğ‘ğ‘Ÿğ‘œğ‘ğ‘’ğ‘ ğ‘  ğ‘ğ‘Ÿğ‘’ ğ‘ğ‘Ÿğ‘’
For each state factor (ğ‘– / ğ›¼), ğ‘ =ğ‘ =1 action All simulations in this paper were conducted
ğ‘¢ğ‘ ğ‘‘ğ‘œğ‘¤ğ‘›
were â€œeffectiveâ€ and allowed the subject to control their using active_pynference, a freely available Python
mental states. ğ‘ =10 actions were non package for running sophisticated inference schemes.
ğ‘›ğ‘’ğ‘¢ğ‘¡ğ‘Ÿğ‘ğ‘™
â€œeffectiveâ€ and resulted in spontaneous drift towards the The code used in these simulations is freely available at:
resting state. https://github.com/Erresthor/ActivPynference_Public/bl
Subject priors: the agents entertained ob/main/paper_scripts/paper_grazBCI/simulations.ipyn
representational priors about the BCI loop before starting b .
the training. This included belief about the feedback
modality (also called the â€˜likelihood modelâ€™ ğš) and RESULTS
beliefs about the effect of their mental actions (ğ›).
We assumed biased agents. We model them as having the Agents already familiar with MI: Figure 3 illustrates
expectation that high levels of motor imagery intensity the outcome of 10 simulated agents performing 10 trials
would lead to higher feedback levels. This is in fact each, starting with informed action priors ğ‘ (ğ‘–)=1
ğ‘ğ‘Ÿğ‘’
misleading but fits with the initial instructions they and ğ‘ (ğ›¼)=1. These subjects thus started the training
ğ‘ğ‘Ÿğ‘’
actually received in this experiment: â€œto perform Motor with high mental imagery control skills, rendering the
Imageryâ€. This assumption is supported with further training unnecessary. The feedback provided was noisy,
arguments in the discussion. The agentsâ€™ model of the but informative (ğœ =1.5). The average simulated
ğ‘ğ‘Ÿğ‘œğ‘ğ‘’ğ‘ ğ‘ 
feedback was initiated using the Dirichlet conjugate prior
mental states (true ERD intensity and orientation) are
for the categorical likelihood ğš:
shown as well as the provided feedback (green). These
ğš ğŸ =ğ‘ ğ‘ ğŸ+ğ‘  ğ‘ ğ¶ğ‘ğ‘¡(ğ‘(ğ‘–.ğ´ğ‘ ğ¼(ğ›¼);ğœ ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ )) Eq.4 can be compared to the corresponding performances of
Where ğ‘ ğ‘ and ğ‘  ğ‘ are the initial concentration and neurofeedback subjects from [16] shown below for a few
confidence parameters, which we set to 1 and 100, subjects (Figure 3.A). The quite large mismatch between
respectively. This means that subjects were very the empirical and simulated time series suggest that
confident that the feedback actually reflects (albeit with subjects entertained less precise action priors.
some noise) their mental imagery level. ğ´ğ‘ ğ¼ is the Interestingly, the agents quickly learned to maintain a
asymmetry index previously formulated and ğœ ğ‘šğ‘œğ‘‘ğ‘’ğ‘™ is a weak ERD strength while correctly lateralizing their
noise term encoding subjectâ€™s prior confidence in the ERDs, leading to less effortful, more optimal behavior.
feedback modality. It was set to 0.5.
Finally, subject prior beliefs about their mental
actions were set as the combination of three terms: a prior
concentration parameter ğ‘ indicating how much new
ğ‘
evidence is needed for the subjects to change their prior
beliefs, a â€˜stickinessâ€™ parameter ğ‘  that encodes subjectâ€™s
ğ‘
belief about actions not affecting their mental state, and
an initial mental action confidence vector ğ‘ that
ğ‘ğ‘Ÿğ‘’
encodes previous knowledge about the effect of their
mental actions. Importantly, ğ‘ is a vector with one
ğ‘ğ‘Ÿğ‘’
value for each state factor (ğ‘– / ğ›¼). The initial mental action
model of the agents was thus, for each state factor:
ğ› =ğ‘ ğŸ+ğ‘  ğˆğ+ğ‘ ğ Eq.5
ğŸ ğ‘ ğ‘ ğ‘ğ‘Ÿğ‘’
With ğˆğ the identity matrix. Simulations were conducted Figure 3: First empirical trials from [16] (A.) compared
with ğ‘ ğ‘ =1.0 and ğ‘  ğ‘ =1.0 (i.e. subjects were opened to with the simulated laterality feedback and left ERD (B.)
new evidence regarding their mental strategies). Of and motor imagery states (C.) from 10 simulated agents
course, subjects started the training with relatively low with high initial motor imagery control.
results from subjects initially well versed in their ability
Agents initially unable to perform MI lateralization: to lateralize their ERDs but lacking the ability to reliably
Another class of agents was instantiated who were perform an ERD (e.g. subjects who misinterpret Motor
initially unable to produce lateralized motor imagery. Imagery by performing right hand visual instead of
They had no priors on how to control the orientation of kinesthetic motor imagery). Conversely, subjects who
their ERD (ğ‘ (ğ›¼)=0.0), but had some poor priors on were very good at performing mental imagery but lacked
ğ‘ğ‘Ÿğ‘’
how to control their intensity (ğ‘ (ğ‘–)=0.1). They thus control over their MI laterality tended to benefit from
ğ‘ğ‘Ÿğ‘’
had to fully rely on the feedback to learn these transitions. training and managed to learn how to direct their
To facilitate their training, a fairly reliable biomarker was attention, despite the noisy feedback.
assumed (ğœ =0.5). The training results are show in
ğ‘ğ‘Ÿğ‘œğ‘
Figure 4. Overall, agents managed to reliably produce a
lateralized ERD, although after quite a long training.
Figure 5: Simulated motor imagery performance before
(top) and after (bottom) neurofeedback depending on
initial experience ğ’ƒ (ğ’Š) (y-axis) and ğ’ƒ (ğœ¶) (x-
ğ’‘ğ’“ğ’† ğ’‘ğ’“ğ’†
axis).
DISCUSSION
The reported simulations provided an account of Motor
Imagery training using Neurofeedback for various
groups of subjects parametrized mostly by their past
experience with Motor Imagery: (i) subjects familiar with
Figure 4: Agents with no prior knowledge of ERD
motor imagery and who had good initial priors, (ii)
lateralization performed 100 simulated neurofeedback
subjects with poor initial ability to lateralize their ERD
trials. We show their average ERD strength (red) and
and had to learn from scratch, and (iii) intermediate
orientation (blue) across the training (A) and at specific
subjects who started with mixed priors about MI
points of the training (B, C) The similarity between the
laterality and strength, but had to finetune them in order
simulated initial MI levels and the empirical
to perform the task efficiently.
observations (B) suggests that this set of parameters
Simulations showcased very different training curves and
better matches the data than the over-optimistic
general subject classes that would more or less benefit
previous simulations.
from the training depending on their initial situation.
They illustrated the crucial role of subjectâ€™s prior skills
Agents with mixed prior abilities: Finally, 21 x 21
(i.e. previous experience), expectations about the
group of 10 agents with intermediate MI lateralization
feedback, training and beliefs following task instructions.
priors were simulated. Each group had a different pair of
Subjects starting training with uninformed priors
parameter values {ğ’ƒ (ğ’Š), ğ’ƒ (ğœ¶)}, set between 0 and
ğ’‘ğ’“ğ’† ğ’‘ğ’“ğ’† performed poorly. This was in part due to the sparse
2. This reflected individual differences in subjects
feedback modality (low temporal resolution / low
starting BCI training with different Motor Imagery prior
dimensionality) which made learning from scratch a very
experience. The feedback provided was very noisy
tricky task. This suggests that reducing the amount of
(ğˆ =ğŸ.ğŸ“). Figure 5 shows the evolution of average
ğ’‘ğ’“ğ’ğ’„ targeted mental dimensions may be instrumental to
Motor Imagery performance in each group of subjects, at
guarantee successful training [6]. The lackluster ability
the start of training and at the end. Our simulations reveal
of the subjects when they had to build a model of
counter-intuitive training effects, such as poor training
interaction from scratch also suggests that more basic
learning mechanisms such as classical (model free) designing neurofeedback treatments,â€ Front.
Reinforcement Learning may play a significant role in Hum. Neurosci., vol. 8, 2014,
the initial phase of the training, with a more complex [8] L. H. Sherlin et al., â€œNeurofeedback and Basic
representational learning taking over later on [13]. Learning Theory: Implications for Research and
The proposed framework is very general and flexible Practice,â€ J. Neurother., vol. 15, no. 4, pp. 292â€“
enough to capture a large variety of experimental 304, 2011,
paradigms. For instance, the multidimensional feedback [9] N. Lubianiker, C. Paret, P. Dayan, and T.
based learning implemented in [16] may be modelled by Hendler, â€œNeurofeedback through the lens of
agents learning simultaneously several sensory mappings reinforcement learning,â€ Trends Neurosci., vol.
of the same internal dynamical state. 45, no. 8, pp. 579â€“593, 2022,
[10] A. V. P. Veilahti, L. Kovarskis, and B. U.
CONCLUSION Cowley, â€œNeurofeedback Learning Is Skill
Acquisition but Does Not Guarantee Treatment
This paper presents a computational account of Benefit: Continuous-Time Analysis of Learning-
neurofeedback/BCI Motor Imagery training using the Curves From a Clinical Trial for ADHD,â€ Front.
Active Inference framework. Preliminary simulations Hum. Neurosci., vol. 15, p. 668780, 2021,
reveal that the Active Inference framework has great [11] F. Lotte, F. Larrue, and C. MÃ¼hl, â€œFlaws in
potential to provide an account of individual self- current human training protocols for spontaneous
regulation dynamics. Future work will consist in fitting Brain-Computer Interfaces: lessons learned from
alternative instantiations of such models to actual data in instructional design,â€ Front. Hum. Neurosci., vol.
order to demonstrate the validity of this approach to 7, 2013,
disentangle between learning profiles and identify [12] D. J. McFarland and J. R. Wolpaw, â€œBrainâ€“
individual traits for BCI learning curves and empirically computer interface use is a skill that user and
observed neurophysiological dynamics. system acquire together,â€ PLOS Biol., vol. 16, no.
7, p. e2006719, 2018,
REFERENCES [13] E. J. Davelaar, â€œMechanisms of Neurofeedback:
A Computation-theoretic Approach,â€
[1] Y. Ota et al., â€œMotor Imagery Training With Neuroscience, vol. 378, pp. 175â€“188, 2018,
Neurofeedback From the Frontal Pole Facilitated [14] E. F. Oblak, J. A. Lewis-Peacock, and J. S.
Sensorimotor Cortical Activity and Improved Sulzer, â€œSelf-regulation strategy, feedback timing
Hand Dexterity,â€ Front. Neurosci., vol. 14, p. 34, and hemodynamic properties modulate learning in
2020, a simulated fMRI neurofeedback environment,â€
[2] A. Kruse, Z. Suica, J. Taeymans, and C. Schuster- PLOS Comput. Biol., vol. 13, no. 7, p. e1005681,
Amft, â€œEffect of brain-computer interface training 2017,
based on non-invasive electroencephalography [15] K. Friston, T. FitzGerald, F. Rigoli, P.
using motor imagery on functional recovery after Schwartenbeck, J. Oâ¿¿Doherty, and G. Pezzulo,
stroke - a systematic review and meta-analysis,â€ â€œActive inference and learning,â€ Neurosci.
BMC Neurol., vol. 20, no. 1, p. 385, 2020, Biobehav. Rev., vol. 68, pp. 862â€“879, 2016,
[3] M. Mihara et al., â€œNear-infrared Spectroscopyâ€“ [16] L. Perronnet et al., â€œUnimodal Versus Bimodal
mediated Neurofeedback Enhances Efficacy of EEG-fMRI Neurofeedback of a Motor Imagery
Motor Imageryâ€“based Training in Poststroke Task,â€ Front. Hum. Neurosci., vol. 11, p. 193,
Victims: A Pilot Study,â€ Stroke, vol. 44, no. 4, 2017,
pp. 1091â€“1098, 2013, [17] G. Lioi et al., â€œSimultaneous MRI-EEG during a
[4] J. Yan, X. Guo, Z. Jin, J. Sun, L. Shen, and S. motor imagery neurofeedback task: an open
Tong, â€œCognitive Alterations in Motor Imagery access brain imaging dataset for multi-modal data
Process after Left Hemispheric Ischemic Stroke,â€ integration,â€ Neuroscience, preprint, 2019.
PLoS ONE, vol. 7, no. 8, p. e42922, 2012, [18] K. Friston, â€œThe free-energy principle: a unified
[5] S. Boe, A. Gionfriddo, S. Kraeutner, A. brain theory?,â€ Nat. Rev. Neurosci., vol. 11, no. 2,
Tremblay, G. Little, and T. Bardouille, â€œLaterality pp. 127â€“138, 2010,
of brain activity during motor imagery is [19] K. Friston, J. Mattout, N. Trujillo-Barreto, J.
modulated by the provision of source level Ashburner, and W. Penny, â€œVariational free
neurofeedback,â€ NeuroImage, vol. 101, pp. 159â€“ energy and the Laplace approximation,â€
167, 2014, NeuroImage, vol. 34, no. 1, pp. 220â€“234, 2007,
[6] A. Gaume, A. Vialatte, A. Mora-SÃ¡nchez, C. [20] K. Friston, L. Da Costa, D. Hafner, C. Hesp, and
Ramdani, and F. B. Vialatte, â€œA T. Parr, â€œSophisticated Inference,â€ 2020,
psychoengineering paradigm for the [21] M. Chiew, S. M. LaConte, and S. J. Graham,
neurocognitive mechanisms of biofeedback and â€œInvestigation of fMRI neurofeedback of
neurofeedback,â€ Neurosci. Biobehav. Rev., vol. differential primary motor cortex activity using
68, pp. 891â€“910, 2016, kinesthetic motor imagery,â€ NeuroImage, vol. 61,
[7] U. Strehl, â€œWhat learning theories can teach us in no. 1, pp. 21â€“31, 2012,

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Bayesian model of individual learning to control a motor imagery BCI"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   âŒ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   âœ… GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   âŒ BAD: Repeating the same claim 3+ times with slight variations
   âœ… GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
