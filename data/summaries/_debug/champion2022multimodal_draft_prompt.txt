=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Multi-Modal and Multi-Factor Branching Time Active Inference
Citation Key: champion2022multimodal
Authors: Théophile Champion, Marek Grześ, Howard Bowman

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2022

Abstract: Activeinferenceisastate-of-the-artframeworkformodellingthebrainthatexplainsawiderangeofmechanismssuchas
habitformation,dopaminergicdischargeandcuriosity. Recently,twoversionsofbranchingtimeactiveinference(BTAI)
basedonMonte-Carlotreesearchhavebeendevelopedtohandletheexponential(spaceandtime)complexityclassthat
occurswhencomputingtheprioroverallpossiblepoliciesuptothetimehorizon. However,thosetwoversionsofBTAI
still suffer from an exponential complexity class w.r.t the number of observed and late...

Key Terms: united, dsprites, kingdom, university, computing, canterbury, kent, factor, champion, school

=== FULL PAPER TEXT ===

Multi-Modal and Multi-Factor Branching Time Active Inference (BTAI ).
3MF
Th´eophile Champion tmac3@kent.ac.uk
University of Kent, School of Computing
Canterbury CT2 7NZ, United Kingdom
Marek Grze´s m.grzes@kent.ac.uk
University of Kent, School of Computing
Canterbury CT2 7NZ, United Kingdom
Howard Bowman H.Bowman@kent.ac.uk
University of Birmingham, School of Psychology,
Birmingham B15 2TT, United Kingdom
University of Kent, School of Computing
Canterbury CT2 7NZ, United Kingdom
Editor: TO BE FILLED
Abstract
Activeinferenceisastate-of-the-artframeworkformodellingthebrainthatexplainsawiderangeofmechanismssuchas
habitformation,dopaminergicdischargeandcuriosity. Recently,twoversionsofbranchingtimeactiveinference(BTAI)
basedonMonte-Carlotreesearchhavebeendevelopedtohandletheexponential(spaceandtime)complexityclassthat
occurswhencomputingtheprioroverallpossiblepoliciesuptothetimehorizon. However,thosetwoversionsofBTAI
still suffer from an exponential complexity class w.r.t the number of observed and latent variables being modelled. In
thepresentpaper,weresolvethislimitationbyfirstallowingthemodellingofseveralobservations,eachofthemhaving
its own likelihood mapping. Similarly, we allow each latent state to have its own transition mapping. The inference
algorithm then exploits the factorisation of the likelihood and transition mappings to accelerate the computation of
the posterior. Those two optimisations were tested on the dSprites environment in which the metadata of the dSprites
dataset was used as input to the model instead of the dSprites images. On this task, BTAI (Champion et al.,
VMP
2022b,a) was able to solve 96.9% of the task in 5.1 seconds, and BTAI (Champion et al., 2021a) was able to solve
BF
98.6%ofthetaskin17.5seconds. Ournewapproach(BTAI )outperformedbothofitspredecessorsbysolvingthe
3MF
task completly (100%) in only 2.559 seconds. Finally, BTAI has been implemented in a flexible and easy to use
3MF
(python) package, and we developed a graphical user interface to enable the inspection of the model’s beliefs, planning
process and behaviour.
Keywords: Branching Time Active Inference, Monte-Carlo Tree Search, Belief Propagation, Bayesian Prediction,
Temporal Slice
1. Introduction
Active inference extends the free energy principle to generative models with actions (Friston et al., 2016; Costa et al.,
2020; Champion et al., 2021b) and can be regarded as a form of planning as inference (Botvinick and Toussaint,
2012). Thisframeworkhassuccessfullyexplainedawiderangeofneuro-cognitivephenomena, suchashabitformation
(Fristonetal.,2016),Bayesiansurprise(IttiandBaldi,2009),curiosity(Schwartenbecketal.,2018),anddopaminergic
discharges (FitzGerald et al., 2015). It has also been applied to a variety of tasks, such as animal navigation (Fountas
et al., 2020), robotic control (Pezzato et al., 2020; Sancaktar et al., 2020), the mountain car problem (C¸atal et al.,
2020), the game DOOM (Cullen et al., 2018) and the cart pole problem (Millidge, 2019).
However, active inference suffers from an exponential (space and time) complexity class that occurs when com-
puting the prior over all possible policies up to the time horizon. Recently, two versions of branching time active
inference(BTAI)basedonMonte-Carlotreesearch(Browneetal.,2012)havebeendevelopedtohandlethisexponen-
tial growth. In the original formulation of the framework (Champion et al., 2022b,a), inference was performed using
the variational message passing (VMP) algorithm (Winn and Bishop, 2005; Champion et al., 2021b). In a follow up
©2020Th´eophileChampionandMarekGrze´sandHowardBowman.
2202
nuJ
42
]IA.sc[
1v30521.6022:viXra
Champion et al.
paper, VMP was then replaced by a Bayesian filtering (Fox et al., 2003) scheme leading to a faster inference process
(Champion et al., 2021a).
In this paper, we develop an extension of Branching Time Active Inference (BTAI), to allow modelling of several
modalities as well as several latent states. Indeed, even if the Bayesian filtering version of Branching Time Active
Inference (BTAI ) is fast, its modelling capacity is limited to one observation and one hidden state. Consequently,
BF
if one wanted to model n latent states S1,...,Sn, then those n latent states would have to be encoded into one latent
t t
state X representing all possible configurations of the n latent states S1,...,Sn. Unfortunatly, the total number of
t t
configurations is given by:
n
(cid:89)
#X = #Si ≥ 2n,
t
i=1
where #X is the number of possible values taken by X, and similarly #Si is the number of possible values taken by
t
Si. The above inequality is obtained by realizing that #Si ≥ 2, and is problematic in practice because #X is growing
t t
exponentially with the number of latent states n being modelled. Also, note that in practice this exponential growth
may be way worse than 2n. For example, if one were to model the five modalities of the dSprites environment (c.f.
Section 3.1), the total number of configurations would be:
#Sy ×#Sx×#Sscale×#Sorientation×#Sscale = 33×32×3×40×6 = 760,320 (cid:29) 25 = 32.
t t t t t
A similar exponential explosion also appears when trying to model several modalities O1,...,Om using a single one
t t
Y, i.e.
m
(cid:89)
#Y = #Oi ≥ 2m,
t
i=1
where #Y is the number of possible values taken by Y, and similarly #Oi is the number of possible values taken by
t
Oi. Note, throughout this paper, we will use the term states to refer to the latent states of the model at a specify
t
time step, e.g., S1,...,Sn for time step t. Additionally, we will use the terms state configurations or values to refer
t t
to particular values taken by the latent variables.
Thepresentpaperaimstoremovethosetwoexponentialgrowths,byallowingthemodellingofseveralobservations
and latent states, while providing an easy to use framework based on a high-level notation, which allows the user
to create models by simply declaring the variables it contains, and the dependencies between those variables. Then,
the framework performs the inference process automatically. Appendix A shows an example of how to implement
a custom BTAI agent using our framework. In section 2, we describe the theory underlying our approach.
3MF
Importantly, BTAI takes advantage of the generative model struture to perform inference efficiently using a
3MF
mixture of belief propagation (Yedidia, 2011; Friston et al., 2017; Kschischang et al., 2001) and forward predictions
as will be explained in Section 2.3. The name BTAI is an abbreviation for BTAI that stands for: Multi-
3MF MMMF
Modal and Multi-Factor Branching Time Active Inference. Next, in Section 2.4, we provide the definition of the
expected free energy in the context of our new approach, and in Section 2.5, we describe the planning algorithm
used to expand the generative model dynamically. Then, in Section 3, we compare BTAI to BTAI and
3MF VMP
BTAI , and demonstrate empirically that BTAI outperformed both BTAI and BTAI on the dSprites
BF 3MF VMP BF
environment, which requires the modelling of many latent states and modalities. Finally, Section 4 concludes this
paper by summarizing our approach and results.
2. Theory of BTAI
3MF
In this section, we introduce the mathematical foundation of BTAI . To simplify the graphical representation
3MF
of our generative model, we first introduce a notion of “temporal slice”. Then, we build on this idea to describe
the generative model of BTAI . Next, we explain how belief updates are performed using a mixture of belief
3MF
propagation and forward predictions. Afterwards, we provide the definition of the expected free energy for this new
generative model. Finally, we describe the planning algorithm used to dynamically expand the generative model, and
the action selection process.
2
Multi-Modal and Multi-Factor BTAI.
2.1 Temporal slice
A temporal slice TS = {O1,...,O#O,S1,...,S#S} is a set of random variables indexed by a sequence of actions
J J J J J
J. Each random variable of the temporal slice represents either an observation Oo or a latent state Ss. The index
J J
of the temporal slice correponds to the sequence of actions that lead to this temporal slice. By definition, if J is an
empty sequence, i.e., J = ∅, then TS is the temporal slice of the present time step t, also denoted TS . Within a
J t
temporal slice TS , an observation Oo depends on a number of latent states ρo ⊆ {Ss | s = 1,...,#S}, such that
J J J J
P(Oo|ρo) is a factor in the generative model. Given an action a and a sequence of actions J, we let I = J::a be the
J J
sequence of actions obtained by appending the action a at the end of the sequence of actions J. If I = J::a, then
the temporal slice TS can be the parent of TS . This means that a latent state Ss in TS can depend on the latent
J I I I
states ρs ⊆ {Ss | s = 1,...,#S} in TS , such that P(Ss|ρs) is a factor in the generative model. The concept of
I J J I I
temporal slice is illustrated in Figure 1, and Figure 2 depicts a more compact representation of the content of Figure
1.
s = 1,...,#S s = 1,...,#S
Ss Ss
t I
Oo Oo
t I
o = 1,...,#O o = 1,...,#O
TS TS
t I
Figure 1: This figure illustrates two temporal slices TS and TS , which are depicted by rectangles with thick border.
t I
Within each temporal slice, plate notation is used to generate #S latent states and #O observations. The dashed
lines that connect two random variables from two different plates are new to this paper, and represent an arbitrary
connectivity between the two sets of random variables generated by the plates. For example, the dashed line from Ss
t
to Oo, means that for each observation Oo, the parents of Oo denoted ρo is a subset of {Ss | s = 1,...,#S}, i.e., the
t t t t t
generative model contains the factor P(Oo|ρo) where ρo ⊆ {Ss | s = 1,...,#S}.
t t t t
TS TS
t I
Figure 2: This figure illustrates the two temporal slices TS and TS from Figure 1 in a more compact fashion. Since
t I
Oo is an observed variable for all o ∈ {1,...,#O}, the square representing TS has a gray background. In contrast,
t t
the square representing TS has a white background because Oo is a latent variable for all o ∈ {1,...,#O}.
I I
2.2 Generative model
In this section, we build upon the notion of temporal slice to describe the full generative model. Intuitively, the
probability of the entire generative model is the product of the probability of each temporal slice within the model.
This includes the current temporal slice TS and the future temporal slices TS for all I ∈ I, where I is the set
t I
of all multi-indices expanded during the tree search (c.f., Section 2.5). Within each temporal slice, there are #O
observations and #S latent states. Each observation depends on a subset of the latent states. Moreover, each latent
state depends on a subset of the latent states of the parent temporal slice. Note, the current temporal slice TS
t
does not have any parents, therefore its latent state does not depend on anything. In other words, the model makes
the Markov assumption, i.e., each state only depends on the states at the previous time step. More formally, the
3
Champion et al.
generative model is defined as:
(cid:89)
P(O
t
,S
t
,OI,SI) = P(TS
t
) P(TS
I
)
I∈I
#O #S (cid:34)#O #S (cid:35)
(cid:89) (cid:89) (cid:89) (cid:89) (cid:89)
= P(Oo|ρo) P(Ss) P(Oo|ρo) P(Ss|ρs)
t t t I I I I
o=1 s=1 I∈I o=1 s=1
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
currenttemporalsliceTSt futuretemporalsliceTSI
where t is the current time step, ρx is the set of parents of Xx, O = {Oo | o = 1,...,#O} is the set of all
τ τ t t
observations at time t, O = {Oo | o = 1,...,#O} is the set of all future observations that would be observed after
I I
performing the sequence of actions I, OI = ∪ I∈IO
I
is the set of all future observations contained in the temporal
slices expanded during the tree search (c.f., Section 2.5), S = {Ss | s = 1,...,#S} is the set of all latent states at
t t
time t, S = {Ss | s = 1,...,#S} is the set of random variables describing the future latent states after performing
I I
the sequence of actions I, SI = ∪ I∈IS
I
is the set of latent variables representing all future states contained in the
temporal slices expanded during the tree search (c.f., Section 2.5). Importantly, the above generative model has to
satisfy:
• ∀I ∈ I,∀o ∈ {1,...,#O},ρo ⊆ S ;
I I
• ∀I::a ∈ I,∀s ∈ {1,...,#S},ρs ⊆ S , also, if I = ∅ then by definition S =∆ S .
I::a I I t
Additionally, we define the factors of the generative model as:
P(Oo|ρo) = Cat(Ao), P(Ss) = Cat(Ds),
t t t t
P(Oo|ρo) = Cat(Ao), P(Ss|ρs) = Cat(Bs),
I I I I I
where Ao is the tensor modelling the likelihood mapping of the o-th observation, Ds is the vector modelling the prior
t
over the s-th latent state at time t (see below for details), Bs is the tensor modelling the transition mapping of the
s-th latent state under each possible action, Bs is the tensor modelling the transition mapping of the s-th latent state
I
under the last action I
last
of the sequence I, i.e., B
I
s = Bs(•,...,•,I
last
). Also, note that at the beginning of a trial,
i.e., when t = 0, Ds is a vector that encodes the modeller’s understanding of the task. Afterwards, when t > 0, Ds is
t t
a vector containing the parameters of the posterior over hidden states according to the observations made and actions
taken so far, i.e., P(Ss) =∆ P(Ss|O ,A ) = Cat(Ds) for all s ∈ {1,...,#S}. Finally, Figure 3 illustrates the
t t 0:t−1 0:t−1 t
full generative model using the notion of temporal slices.
(cid:110) (cid:111)
TS I = (1),(2),(11),(12)
t
TS TS
(1) (2)
TS TS TS TS
(11) (12) (21) (22)
Figure 3: This figure illustrates the full generative model of BTAI . The temporal slices depited in light gray
3MF
correspond to temporal slices that have not yet been explored by the planning algorithm, c.f., Section 2.5. The
numbers between parentheses correspond to the sequence of actions performed to reach the temporal slice.
4
Multi-Modal and Multi-Factor BTAI.
2.3 Belief updates: the inference and prediction (IP) algorithm
The IP algorithm is composed of two steps, i.e., the inference step (or I-step) and the prediction step (or P-step).
The goal of the I-step is to compute the posterior beliefs over all the latent variables at time t. In other words, the
goal of the I-step is to compute: P(Ss|O ),∀s ∈ {1,...,#S}. The P-step takes as inputs the posterior beliefs over
t t
all the latent variables corresponding to the states of the system after performing a sequence of actions I, and an
action a to be performed next. The goal of the P-step is to compute the posterior beliefs over all the latent variables
corresponding to the future states and observations after performing the sequence of actions I::a, where I::a is the
sequence of actions obtained by adding the action a at the end of the sequence of actions I. In other words, given
P(Ss|O ),∀s ∈ {1,...,#S} and an action a, the goal of the P-step is to compute: P(Ss |O ),∀s ∈ {1,...,#S} and
I t I::a t
P(Oo |O ),∀o ∈ {1,...,#O}. Notethatbydefinition,weletP(Sm|O ) =∆ P(Sm|O )ifI = ∅. Toderivetheinference
I::a t I t t t
and prediction steps, the following sections make use of the sum-rule, product-rule, and d-separation criterion (c.f.,
Appendix C for details about those properties).
2.3.1 Inference step
As just stated, the goal of the I-step is to compute P(Sm|O ),∀m ∈ {1,...,#S}. First, we re-write the posterior
t t
computation to fit the kind of problem that belief propagation — also known as the sum-product algorithm — can
solve:
T
(cid:88)
P(Sm|O ) ∝ P(Sm,O ) (Bayes theorem)
t t t t
∼Sm
t
(cid:88)
= P(S ,O ) (sum rule)
t t
∼Sm
t
#O #S
(cid:88) (cid:89) (cid:89)
= P(Oo|ρo) P(Ss) (product rule & d-separation)
t t t
∼Smo=1 s=1
t
where S = {Ss | s = 1,...,#S} is the set of all latent states at time t, ∼Sm = S \Sm is the set of all latent states
t t t t t
at time t except Sm, and the summation is over all possible configurations of ∼Sm, i.e., we are marginalizing out
t t
all states, apart from one; thus P(S ,O ) has #S +#O dimensions, while P(Sm,O ) has 1+#O dimensions. Since
t t t t
ρo ⊆ S , the expression inside the summation is a function g(S ) that factorizes as follows:
t t t
#O #S
(cid:89) (cid:89)
g(S ) = P(Oo|ρo) P(Ss)
t t t t
o=1 s=1
N
(cid:89)
=∆ f (X ),
i i
i=1
where X ⊆ S for all i ∈ {1,...,#O+#S}, the number of factors is N = #O+#S, and:
i t
(cid:40)
P(Oi|ρi) if i ∈ {1,...,#O}
f (X ) =∆ t t .
i i P(Si−#O) if i ∈ {#O+1,...,#O+#S}
t
Note that, because Oo (denoted Oi here) are known constants, we do not specify that g(S ) depends on Oo. To
t t t t
conclude, by substituting the definition of g(S ) into the formula of the posterior P(Sm|O ) presented above, we get:
t t t
(cid:88)
P(Sm|O ) ∝ g(S ),
t t t
∼Sm
t
5
Champion et al.
which means that the posterior P(Sm|O ) can be computed by first marginalizing g(S ) w.r.t. Sm, i.e.,
t t t t
(cid:88)
g(Sm) = g(S ),
t t
∼Sm
t
and then normalizing:
g(Sm)
P(Sm|O ) = t .
t t (cid:80) g(Sm)
Sm t
t
The marginalization of g(S ) can be performed efficiently using belief propagation (Kschischang et al., 2001), which
t
can be understood as a message passing algorithm on a factor graph. The message from a node x to a factor f is
given by:
(cid:89)
m (x) = m (x),
x→f h→x
h∈n(x)\{f}
where n(x) are the neighbours of x in the factor graph. Note, in a factor graph the neighbours of a random variable
are factors. Moreover, the message from a factor f to a node x is given by:
(cid:32) (cid:33)
(cid:88) (cid:89)
m (x) = f(X) m (y) ,
f→x y→f
Y y∈Y
where X = n(f) are the neighbours of f in the factor graph, Y = X \{x} are all the neighbours of f except x, and
the summation is over all possible configurations of the variables in Y. Note, in a factor graph the neighbours of a
factor are random variables. Once all the messages have been computed, the marginalization of g(S ) w.r.t. Sm is
t t
given by the product of all the incoming messages of the node Sm, i.e.,
t
(cid:89)
g(Sm) = m (Sm).
t f→Sm t
t
f∈n(Sm)
t
2.3.2 Prediction step
The P-step is analogous to the prediction step of Bayesian filtering (Fox et al., 2003). Given P(Ss|O ) for each
I t
s ∈ {1,...,#S}andanactiona, thegoaloftheP-stepistocomputeP(Ss |O )foreachlatentstates ∈ {1,...,#S}
I::a t
and P(Oo |O ) for each future observation o ∈ {1,...,#O}. For the sake of brevity, we let J =∆ I::a. Let’s start
I::a t
with the computation of P(Ss |O ):
I::a t
M
(cid:88)
P(Ss |O ) =∆ P(Ss|O ) = P(Ss,ρs|O ) (sum rule)
I::a t J t J J t
ρs
J
M
(cid:88)
= P(Ss|ρs,O )P(ρs|O ) (product rule)
J J t J t
ρs
J
M
(cid:88)
= P(Ss|ρs)P(ρs|O ) (d-separation)
J J J t
ρs
J
#ρs
(cid:88) (cid:89)J
≈ P(Ss|ρs) P(ρs |O ) (mean-field approximation)
J J J,i t
ρs i=1
J
where #ρs is the number of parents of Ss, and ρs is the i-th parent of Ss. Importantly, P(Ss|ρs) is known from the
J J J,i J J J
definition of the generative model. Moreover, since ρs ∈ S , then P(ρs |O ) = P(Sm|O ) for some m ∈ {1,...,#S}.
J,i I J,i t I t
6
Multi-Modal and Multi-Factor BTAI.
Thus, P(ρs |O ) is given as input to the P-step, i.e., P(ρs |O ) is a known distribution. Similarly, the computation
J,i t J,i t
of P(Oo |O ) proceeds as follows:
I::a t
M
(cid:88)
P(Oo |O ) =∆ P(Oo|O ) = P(Oo,ρo|O ) (sum rule)
I::a t J t J J t
ρo
J
M
(cid:88)
= P(Oo|ρo,O )P(ρo|O ) (product rule)
J J t J t
ρo
J
M
(cid:88)
= P(Oo|ρo)P(ρo|O ) (d-separation)
J J J t
ρo
J
#ρo
(cid:88) (cid:89)J
≈ P(Oo|ρo) P(ρo |O ) (mean-field approximation)
J J J,i t
ρo i=1
J
where#ρo isthenumberofparentsofOo, andρo isthei-thparentofOo. Importantly, P(Oo|ρo)isknownfromthe
J J J,i J J J
definition of the generative model. Moreover, since ρo ∈ S , then P(ρo |O ) = P(Ss|O ) for some s ∈ {1,...,#S}.
J,i J J,i t J t
Thus, P(ρo |O ) has already been computed during the first stage of the P-step and is a known distribution, c.f.,
J,i t
derivation of P(Ss |O ) =∆ P(Ss|O ).
I::a t J t
2.4 Expected Free Energy
In this section, we discuss the definition of the expected free energy, which quantifies the cost of pursuing a particular
sequence of actions and will be useful for planning, cf. Section 2.5. The expected free energy (see below) is composed
of the risk and ambiguity terms. The risk terms quantify how much the posterior beliefs over future observations
(computed by the P-step) diverge from the prior preferences of the agent. On the other hand, the ambiguity terms
correspond to the expected uncertainty of the likelihood mapping, where the expectation is with respect to the
posterior beliefs over states computed by the P-step.
First, we partition the set of observations O = {Oo | o = 1,...,#O} into disjoint subsets XI, i.e., O =
I I i I
XI∪...∪XI and XI∩XI = ∅ if i (cid:54)= j. Then, we define the prior preferences over the i-th subset of observations as:
1 N i j
V(XI) = Cat(Ci). This formulation allows us to define prior preferences over subsets of random variables, and will
i
be useful in Section 3.1, where the agent needs to possess preferences that depend upon both the shape and (X,Y)
position of the object. Finally, the expected free energy, which needs to be minimised, is given by:
N (cid:32) (cid:33) #O (cid:32) (cid:33)
(cid:88) (cid:88)
G =∆ D [P(XI|O )||V(XI)] + E [H[P(Oo|ρo)]] , (1)
I
i=1 (cid:124)
KL i
(cid:123)(cid:122)
t i
(cid:125) o=1 (cid:124)
P(ρo
I
|Ot)
(cid:123)(cid:122)
I I
(cid:125)
riskofi-thsetofobservations ambiguityofo-thobservation
whereP(XI|O )andP(ρo|O )aretheposteriorsoverthei-thsubsetofobservationsandtheparentofOo,respectively,
i t I t I
and P(Oo|ρo) is known from the generative model. Assuming a mean-field approximation, those posteriors are given
I I
by:
#ρo
(cid:89)I
P(ρo|O ) ≈ P(ρo |O )
I t I,i t
i=1
x
(cid:89)
P(XI|O ) ≈ P(Oo|O )
i t I t
O
I
o∈Xi
whereP(Oo|O )andP(ρo |O )aretheposteriorsoverOo andthei-thparentofOo,respectively. Note,bothP(Oo|O )
I t I,i t I I I t
and P(ρo |O ) were computed during the P-step. The definition of the expected free energy given by (1) may not be
I,i t
7
Champion et al.
very intuitive. Fortunatly, the special case where each subset contains a single observation, i.e., XI = Oo, leads to
o I
the following equation:
#O (cid:32) (cid:33)
(cid:88)
G =∆ D [P(Oo|O )||V(Oo)] + E [H[P(Oo|ρo)]] ,
I
o=1 (cid:124)
KL I
(cid:123)(cid:122)
t I
(cid:125) (cid:124)
P(ρo
I
|Ot)
(cid:123)(cid:122)
I I
(cid:125)
riskofo-thobservation ambiguityofo-thobservation
which is the summation over all observations Oo of the expected free energy of Oo, i.e., the risk of Oo plus the
I I I
ambiguity of Oo. Finally, our framework allows to specify prior preferences over only a subset of variables in O . For
I I
example, if a task contains four variables, i.e., Ox, Oy, Oshape and Oscale, but it only makes sense to have preferences
I I I I
over three of them, i.e., Ox, Oy and Oshape, then the prior preference over the fourth variable is set to the posterior
I I I
overthisrandomvariable, i.e., V(Oshape) =∆ P(Oshape|O ). Inotherwords, nothavingpriorpreferencesoverarandom
I I t
variable is viewed by our framework as liking whatever we predict will happen. Effectively, this renders the risk term
associated with such variable equal to zero, i.e.,
D [P(Oshape|O )||V(Oshape)] = D [P(Oshape|O )||P(Oshape|O ))] = 0.
KL I t I KL I t I t
2.5 Planning: the MCTS algorithm
In this section, we describe the planning algorithm used by BTAI . At the beginning of a trial when t = 0, the
3MF
agent is provided with the initial observations O . The I-step is performed and returns the posterior over all latent
0
states, i.e., P(Ss|O ) for all s ∈ {1,...,#S}, according to the prior over the initial hidden states provided by the
0 0
modeller, i.e., P(Ss) for all s ∈ {1,...,#S}, and the available observations O .
0 0
Then, we use the UCT criterion to determine which node in the tree should be expanded. Let the tree’s root TS
t
be called the current node. If the current node has no children, then it is selected for expansion. Alternatively, the
child with the highest UCT criterion becomes the new current node and the process is iterated until we reach a leaf
node (i.e. a node from which no action has previously been selected). The UCT criterion (Browne et al., 2012) for
the j-th child of the current node is given by:
(cid:115)
lnn
UCT = −G¯ +C , (2)
j j explore
n
j
where G¯ is the average expected free energy calculated with respected to the actions selected from the j-th child,
j
C is the exploration constant that modulates the amount of exploration at the tree level, n is the number of
explore
times the current node has been visited, and n is the number of times the j-th child has been visited.
j
Let S be the (leaf) node selected by the above selection procedure. We then expand all the children of S , i.e.,
I I
all the states of the form S , where a ∈ {1,...,#A} is an arbitrary action, #A is the number of available actions,
I::a
and I::a is the multi-index obtained by appending the action a at the end of the sequence defined by I. Next, we
perform the P-step for each action a, and obtain P(Ss |O ) for each latent state s ∈ {1,...,#S} and P(Oo |O )
I::a t I::a t
for each future observation o ∈ {1,...,#O}.
Then, we need to estimate the cost of (virtually) taking each possible action. The cost in this paper is taken to
be the expected free energy given by (1). Next, we assume that the agent will always perform the action with the
lowest cost, and back-propagate the cost of the best (virtual) action toward the root of the tree. Formally, we write
the update as follows:
∀K ∈ A ∪{I}, G ← G + min G , (3)
I K K I::a
a∈{1,...,#A}
where I is the multi-index of the node that was selected for (virtual) expansion, and A is the set of all multi-indices
I
corresponding to ancestors of TS . During the back propagation, we also update the number of visits as follows:
I
∀K ∈ A ∪{I}, n ← n +1. (4)
I K K
8
Multi-Modal and Multi-Factor BTAI.
If we let Gaggr be the aggregated cost of an arbitrary node S obtained by applying Equation 3 after each expansion,
K K
then we are now able to express G¯ formally as:
K
Gaggr
G¯ = K .
K
n
K
The planning procedure described above ends when the maximum number of planning iterations is reached.
2.6 Action selection
After performing planning, the agent needs to choose the action to perform in the environment. As discussed in
Section 3.1 of (Browne et al., 2012), many possible mechanisms can be used to select the action to perform in the
environment. BTAI performs the action corresponding to the root child with the highest number of visits.
3MF
Formally, this is expressed as:
a∗ = argmax n , (5)
(a)
a∈{1,...,#A}
where a∗ is the action performed in the environment, and n is the number of visits of the root child corresponding
(a)
to action a.
2.7 Closing the action-perception cycle
After performing an action a∗ in the environment, the agent receives a new observation O , and needs to use this
t+1
observation to compute the posterior over the latent states at time t+1, i.e., P(Ss |O ) for all s ∈ {1,...,#S}.
t+1 t+1
ThiscanbeachievedbyperformingtheI-step,butrequirestheagenttohavepriorbeliefsoverthelatentstatesattime
t+1, i.e., P(Ss ) for all s ∈ {1,...,#S}, in addition to the new observation O obtained from the environment.
t+1 t+1
In this paper, we define those prior beliefs as:
P(Ss ) = P(Ss|O ), for all s ∈ {1,...,#S},
t+1 I t
where I = (a∗) is a sequence of actions containing the action a∗ performed in the environment, P(Ss|O ) is the
I t
predictiveposteriorcomputedbytheP-stepwhenassumingthatactiona∗ isperformed. Inotherwords,thepredictive
posteriorP(Ss|O )computedbytheP-stepattimet,isusedasanempiricalpriorP(Ss )attimet+1. Thisempirical
I t t+1
prior P(Ss ) along with the new observation O can then be used to compute the posterior P(Ss |O ) for all
t+1 t+1 t+1 t+1
9
Champion et al.
s ∈ {1,...,#S}. This posterior will be used to perform planning in the next action-perception cycle. Algorithm 1
concludes this section by summarizing our approach.
Algorithm 1: BTAI : action-perception cycles (with relevant equations indicated in round brackets).
3MF
Input: env the environment,
O = {Oo | o = 1,...#O} the initial observations,
0 0
A = {Ao | o = 1,...#O} the likelihood mapping of each observation,
B = {Bs | s = 1,...,#S} the transition mapping for each hidden state,
C = {Ci | i = 1,...N} the prior preferences of each subset of observations,
D = {Ds | s = 1,...#S} the prior over each initial state,
0 0
N the number of planning iterations,
M the number of action-perception cycles.
space
P(Ss|O ) ← I-step(O , A, D ) // I-step from Section 2.3.1
0 0 0 0
root ← CreateTreeNode(
beliefs = P(Ss|O ), action = -1, cost = 0, visits = 1
0 0
) // Create the root node for the MCTS, where -1 is a dummy value
repeat M times
repeat N times
node ← SelectNode(root) // Using (2) recursively
eNodes ← ExpandChildren(node, B) // P-step from Section 2.3.2 for each action
Evaluate(eNodes, A, C) // Compute (1) for each expanded node
Backpropagate(eNodes) // Using (3) and (4)
end
a∗ ← SelectAction(root) // Using (5)
O ← env.Execute(a∗)
t+1
child ← root.children[a∗] // Get root child corresponding to a∗
P(Ss ) ← child.beliefs // Get the empirical prior P(Ss ) = Cat(Ds )
t+1 t+1 t+1
P(Ss |O ) ← I-step(O , A, D ) // I-step from Section 2.3.1
t+1 t+1 t+1 t+1
root ← CreateTreeNode(
beliefs = P(Ss |O ), action = a∗, cost = 0, visits = 1
t+1 t+1
) // Create the root node of the next action-perception cycle
end
3. Results
In this section, we compare our new approach to BTAI with variational message passing (BTAI ) and BTAI
VMP
with Bayesian filtering (BTAI ). Section 3.1 presents the simplified version of the dSprites environment on which
BF
the agents are compared. Section 3.2 describes how the task is modelled by the BTAI agent and reports its
VMP
performance, finally, Sections 3.3 and 3.4 do the same for the BTAI and BTAI agents. For the reader
BF 3MF
interested in implementing a custom BTAI agent, Appendix A provides a tutorial of how to create such an
3MF
agent using our framework, and Appendix B desbribes a graphical user interface (GUI) that can be used to inspect
the model. This GUI displays the structure of the generative model and prior preferences, the posterior beliefs of
each latent variable, the messages sent throughout the factor graph to perform inference, the information related to
the MCTS algorithm, and the expected free energy (EFE) of each node in the future. It also shows how the EFE
decomposes into the risk and ambiguity terms.
3.1 dSprites Environment
The dSprites environment is based on the dSprites dataset (Matthey et al., 2017) initially designed for analysing
the latent representation learned by variational auto-encoders (Doersch, 2016). The dSprites dataset is composed of
images of squares, ellipses and hearts. Each image contains one shape (square, ellipse or heart) with its own scale,
10
Multi-Modal and Multi-Factor BTAI.
orientation, and (X,Y) position. In the dSprites environment, the agent is able to move those shapes around by
performing four actions (i.e., UP, DOWN, LEFT, RIGHT). To make planning tractable, the action selected by the
agent is executed eight times in the environment before the beginning of the next action-perception cycle, i.e., the X
or Y position is increased or decreased by eight between time step t and t+1. The goal of the agent is to move all
squares towards the bottom-left corner of the image and all ellipses and hearts towards the bottom-right corner of
the image, c.f. Figure 4.
Figure 4: This figure illustrates the dSprites environment, in which the agent must move all squares towards the
bottom-left corner of the image and all ellipses and hearts towards the bottom-right corner of the image. The red
arrows show the behaviour expected from the agent.
Since BTAI is a tabular model whose likelihood and transition mappings are represented using matrices, the agent
does not directly take images as inputs. Instead, the metadata of the dSprites dataset is used to specify the state
space. In particular, the agent observes the type of shape (i.e., square, ellipse, or heart), the scale and orientation
of the shape, as well as a coarse-grained version of the shape’s true position. Importantly, the original images are
composed of 32 possible values for both the X and Y positions of the shapes. A coarse-grained representation with a
granularity of two means that the agent is only able to perceive 16×16 images, and thus, the positions at coordinate
(0,0), (0,1), (1,0) and (1,1) are indistinguishable. Figure 5 illustrates the coarse grained representation with a
granularity of eight and the corresponding indices observed by the BTAI and BTAI agents. Note that this
VMP BF
modification of the observation space can be seen as a form of state aggregation (Ren and Krogh, 2002). Finally, as
shown in Figure 5, the prior preferences of the agent are specified over an absorbing row below the dSprites image.
This absorbing row ensures that the agent selects the action “down” when standing in the “appropriate corner”, i.e.,
bottom-left corner for squares and bottom-right coner for ellipses and hearts.
0 5 1015 20253035 40455055
1 6 1116 21263136 41465156
2 7 1217 22273237 42475257
3 8 1318 23283338 43485358
4 9 1419 24293439 44495459
(cid:3) ♥
Figure 5: This figure illustrates the observations made by the agent when using a coarse-grained representation with
a granularity of eight on the input image. On the left, one can see an image from the dSprites dataset and a grid
containing red squares of 8×8 pixels. Any positions in those 8×8 squares are indistinguishable from the perspective
of the agent. Also, the bottom most row is an absorbing row used to specify the prior preferences of the agent, i.e.
the green square is the goal state and the orange squares correspond to undesirable states. Finally, the three tables on
the right contain the indices observed by the BTAI and BTAI agents for each type of shape at each possible
VMP BF
position.
Theevaluationoftheagent’sperformanceisbasedontherewardobtainedbytheagent. Briefly, theagentreceives
a reward of −1, if it never enters the absorbing row or if it does so at the antipode of the appropriate corner. As
the agent enters the absorbing row closer and closer to the appropriate corner, its reward increases until reaching a
11
Champion et al.
maximum of 1. The percentage of the task solved (i.e., the evaluation metric) is calculated as follows:
total rewards+number of runs
P(solved) = .
2.0×number of runs
Intuitively, the numerator shifts the rewards so that they are bounded between zero and two, and the denominator
renormalises the reward to give a score between zero and one. A score of zero therefore corresponds to an agent
always failing to enter the absorbing row or doing so at the antipode of the appropriate corner. In contrast, a score
of one corresponds to an agent always entering the absorbing row through the appropriate corner.
3.2 BTAI modeling approach and results
VMP
In this section, we evaluate BTAI (Champion et al., 2022b,a) on the dSprites environment. As shown in Figure
VMP
5, BTAI observes one index for each possible configuration of shape, and (X,Y) positions. Importantly, this
VMP
version of BTAI suffers from the exponential growth described in the introduction, and thus does not model the
scale and orientation modalities. Also, to make the inference and planning process tractable, the granularity of the
coarse-grained representation was set to four or eight. Table 1 provides the value of each hyper-parameter used by
BTAI inthissection. Note,thehyper-parametervaluesarethesameforallBTAImodelspresentedinthispaper.
VMP
Only the number of action perception cycles, and the number of planning iterations may vary from one experiment
to the next.
Name Value
NB_SIMULATIONS 100
NB_ACTION_PERCEPTION_CYCLES 30
NB_PLANNING_STEPS 10, 25 or 50
EXPLORATION_CONSTANT 2.4
PRECISION_PRIOR_PREFERENCES 2
PRECISION_ACTION_SELECTION 100
EVALUATION_TYPE EFE
Table 1: The value of each hyper-parameter used by BTAI in this section. NB_SIMULATIONS is the number of
VMP
simulations run during the experiment. NB_ACTION_PERCEPTION_CYCLES is the maximum number of actions executed
ineachsimulation, afterwhichthesimulationisterminated. NB_PLANNING_STEPSisthenumberofplanningiterations
performed by the agent. EXPLORATION_CONSTANT is the exploration constant of the UCT criterion. PRECISION_
PRIOR_PREFERENCES is the precision of the prior preferences. PRECISION_ACTION_SELECTION is the precision of the
distribution used for action selection. EVALUATION_TYPE is the type of cost used to evaluate the node during the
tree search. Those hyper-parameters can be used to re-run the experiments using the code of the following GitHub
repository: https://github.com/ChampiB/Experiments_AI_TS.
Briefly, the agent is able to solve 88.5% of the task when using a granularity of eight, c.f. Table 2. To understand
whyBTAI wasnotabletosolvethetaskwith100%accuracy, letusconsidertheexampleofanellipseatposition
VMP
(24,31). With a granularity of eight, the agent perceives that the ellipse is in the bottom-right corner of the image,
i.e., in the red square just above the goal state in Figure 5. From the agent’s perspective, it is thus optimal to pick the
action “down” to reach the goal state. However, in reality, the agent will not receive the maximum reward because
its true X position is 24 instead of the optimal X position of 31.
12
Multi-Modal and Multi-Factor BTAI.
Planning iterations P(solved) Time (sec)
10 0.813 0.859 ± 0.868
25 0.846 0.862 ± 0.958
50 0.885 1.286 ± 1.261
Table 2: The percentage of the dSprites environment solved by the BTAI agent when using a granularity of
VMP
eight, c.f. Figure5. Thelastcolumnreportstheaverageexecutiontimerequiredforonesimulationandtheassociated
standard deviation.
As shown in Table 3, we can improve the agent’s perfomance, by using a granularity of four. This allows the
agent to differentiate between a larger number of (X,Y) positions, i.e., it reduces the size of the red square in Figure
5. With this setting, the agent is able to solve 96.9% of the task. However, when decreasing the granularity, the
number of states goes up, and so does the width and height of the A and B matrices. As a result, more memory
and computational time is required for the inference and planning process. This highlights a trade-off between the
agent’s performance and the amount of memory and time required. Indeed, a smaller granularity leads to better
performance, but requires more time and memory.
Planning iterations P(solved) Time (sec)
10 0.859 3.957 ± 4.027
25 0.933 3.711 ± 4.625
50 0.969 5.107 ± 5.337
Table 3: The percentage of the dSprites environment solved by the BTAI agent when using a granularity of
VMP
four. In this setting, there are 9×8×3 = 216 states. The last column reports the average execution time required
for one simulation and the associated standard deviation.
3.3 BTAI modeling approach and results
BF
In this section, we evaluate BTAI (Champion et al., 2021a) on the dSprites environment. As shown in Figure
BF
5, BTAI observes one index for each possible configuration of shape, and (X,Y) positions. Also, to make the
BF
inference and planning process tractable, the granularity of the coarse-grained representation was set to two, four or
eight. Table4providesthevalueofeachhyper-parameterusedbyBTAI inthissection. Note,thehyper-parameter
BF
values are the same for all BTAI models presented in this paper. Only the number of action perception cycles, and
the number of planning iterations may vary from one experiment to the next.
13
Champion et al.
Name Value
NB_SIMULATIONS 100
NB_ACTION_PERCEPTION_CYCLES 20
NB_PLANNING_STEPS 50
EXPLORATION_CONSTANT 2.4
PRECISION_PRIOR_PREFERENCES 1
PRECISION_ACTION_SELECTION 100
EVALUATION_TYPE EFE
Table 4: The value of each hyper-parameter used by BTAI in this section. NB_SIMULATIONS is the number of
BF
simulations run during the experiment. NB_ACTION_PERCEPTION_CYCLES is the maximum number of actions executed
ineachsimulation, afterwhichthesimulationisterminated. NB_PLANNING_STEPSisthenumberofplanningiterations
performed by the agent. EXPLORATION_CONSTANT is the exploration constant of the UCT criterion. PRECISION_
PRIOR_PREFERENCES is the precision of the prior preferences. PRECISION_ACTION_SELECTION is the precision of the
distribution used for action selection. EVALUATION_TYPE is the type of cost used to evaluate the node during the
tree search. Those hyper-parameters can be used to re-run the experiments using the code of the following GitHub
repository: https://github.com/ChampiB/Branching_Time_Active_Inference.
As shown in Table 5, the agent is able to solve: 86.1% of the task when using a granularity of eight, 97.7% of
the task when using a granularity of four, and 98.6% of the task when using a granularity of two. However, as the
performance improves from 86.1% to 98.6%, the computational time required to run each simulation skyrockets from
around 50 milliseconds to around 17.5 seconds. In other words, a simulation with a granularity of two is 350 times
slower than a simulation with a granularity of eight.
Planning iterations Granularity P(solved) Time (ms)
50 8 0.861 49.93 ± 36.4124
50 4 0.977 241.63 ± 118.379
50 2 0.986 17503.8 ± 12882.8
Table 5: The percentage of the dSprites environment solved by the BTAI agent when using a granularity of eight,
BF
four and two. Note, when a granularity of two is used, there are 17×16×3 = 816 possible states. The last column
reports the average execution time required for one simulation and the associated standard deviation. Note, the
change in time granularity to milliseconds.
3.4 BTAI modeling approach and results
3MF
In this section, we evaluate our new approach (BTAI ) on the dSprites environment. In contrast to what is shown
3MF
in Figure 5, BTAI does not observe one index for each possible configuration of shape, and (X,Y) positions.
3MF
Instead, BTAI has five observed variables representing the shape, the orientation, the scale, as well as the X and
3MF
Y position, respectively. Each of those observed variable has its hidden state counterparts. Each observation depends
on its hidden state counterparts through an identity matrix. This parametrisation is common in the literature on
active inference, see (Sajid et al., 2021) for an example. The transition mappings of the hidden variables representing
the shape, orientation, and scale, are defined as an indentity matrix. This forwards the state value at time t to the
next time step t + 1. For the hidden variables representing the X and Y position of the shape, the transition is
set to reflect the dynamics of the dSprites environment when the actions taken are repeated eight times, i.e., if the
action “DOWN” is selected, then the agent’s position in Y will be decreased by eight before the start of the next
action-perception cycle (Fountas et al., 2020).
The hyper-parameters used in those simualtions are presented in Table 6. Note, the hyper-parameter values are
the same for all BTAI models presented in this paper. Only the number of action perception cycles, and the number
of planning iterations may vary from one experiment to the next.
14
Multi-Modal and Multi-Factor BTAI.
Table 7 shows the results obtained by BTAI on the dSprites environment when running 100 trials. Due to
3MF
the change in the format of representations, the agent exhibits little increase in execution time as the granularity
decreases, however, in general, the capacity to solve the task increases with this reduction in granularity. When a
granularity of one is used, the agent is able to solve the task perfectly with 150 planning iterations.
Note, the agent using a granularity of 1 and 150 planning iterations is as fast as the agent using a granularity of
1 and 50 planning iterations. This is because as the number of planning iterations increases the agent requires more
computation time per action-perception cycle, but as the agent performance increases on the task, the agent reaches
the goal state faster, and therefore requires less action-perception cycles per simulation. To conclude, the agent with
150 planning iterations requires less action-perception cycles per simulation, but more time per action-perception
cycle than the agent with 50 planning iterations. The code relevant to this section is available at the following URL:
https://github.com/ChampiB/BTAI_3MF.
Name Value
NB_SIMULATIONS 100
NB_ACTION_PERCEPTION_CYCLES 50
NB_PLANNING_STEPS 50 or 100 or 150
EXPLORATION_CONSTANT 2.4
PRECISION_PRIOR_PREFERENCES 1
EVALUATION_TYPE EFE
Table 6: The value of each hyper-parameter used by BTAI in this section. NB_SIMULATIONS is the number of
3MF
simulations run during the experiment. NB_ACTION_PERCEPTION_CYCLES is the maximum number of actions executed
ineachsimulation, afterwhichthesimulationisterminated. NB_PLANNING_STEPSisthenumberofplanningiterations
performedbytheagent. EXPLORATION_CONSTANTistheexplorationconstantoftheUCTcriterion. PRECISION_PRIOR_
PREFERENCES is the precision of the prior preferences. EVALUATION_TYPE is the type of cost used to evaluate the node
during the tree search. Those hyper-parameters can be used to re-run the experiments using the code of the following
GitHub repository: https://github.com/ChampiB/BTAI_3MF.
Planning iterations Granularity P(solved) Time (sec)
50 8 0.895 1.279 ± 12.8
50 4 0.977 1.279 ± 12.8
50 2 0.996 1.279 ± 12.8
50 1 0.72 2.559 ± 18.01
100 1 0.77 5.119 ± 25.209
150 1 1 2.559 ± 18.01
Table 7: This table presents the percentage of the dSprites environment solved by the BTAI agent when using a
3MF
granularityofeight, four, twoandone. Note, whenagranularityofoneisused, thereare33×32×3×40×6 = 760,320
possible state configurations. The last column reports the average execution time required of one simulation and the
associated standard deviation.
4. Conclusion
In this paper, we presented a new version of Branching Time Active Inference that allows for modelling of several
observed and latent variables. Taken together, those variables constitute a temporal slice. Within a slice, the model
is equipped with prior beliefs over the initial latent variables, and each observation depends on a subset of the latent
variables through the likelihood mapping. Additionally, the latent states evolve over time according to the transition
mapping that describes how each latent variable at time t+1 is generated from a subset of the hidden states at time
t and the action taken.
15
Champion et al.
At the beginning of each trial, the agent makes an observation for each observed variable, and computes the
posterior over the latent variables using belief propagation. Then, a Monte-Carlo tree search is performed to explore
the space of possible policies. During the tree search, each planning iteration starts by selecting a node to expand
using the UCT criterion. Then, the children of the selected node are expanded, i.e., one child per action. Next, the
posterior over the latent variables of the expanded nodes is computed by performing forward predictions using the
known transition mapping, and the posterior beliefs over the latent states of the node selected for expansion. Once
the posterior is computed, the expected free energy can be computed and back-propagated through the tree. The
planning process stops after reaching a maximum number of iterations.
In the results section, we compared our new approach, called BTAI , to two earlier versions of branching
3MF
time active inference, named BTAI (Champion et al., 2022b,a) and BTAI (Champion et al., 2021a). Briefly,
VMP BF
at the current time step t: BTAI performs variational message passing (VMP) with a variational distribution
VMP
composed of only one factor, BTAI performs exact inference using Bayes theorem, and BTAI implements
BF 3MF
belief propagation to compute the marginal posterior over each latent variable. For the hidden variables in the future,
BTAI doesthesamemean-fieldapproximationasattimesteptandperformsVMP,BTAI performsBayesian
VMP BF
prediction to compute the posterior over the only latent variable being modelled, and likewise, BTAI performs
3MF
prediction to compute the posterior over all future latent variables.
Since, none of the aforementioned approaches are equipped with deep neural networks, we compared them on a
version of the dSprites environment in which the metadata of the dSprites dataset are used as inputs to the model
instead of the dSprites images. The best performance obtained by BTAI was to solve 96.9% of the task in
VMP
5.1 seconds. Importantly, BTAI was previously compared to active inference as implemented in SPM both
VMP
theoretically and experimentally (Champion et al., 2022b,a). BTAI was able to solve 98.6% of the task but at the
BF
cost of 17.5 seconds of computation. Note, BTAI was using a granularity of two (i.e., 816 states) while BTAI
BF VMP
wasusingagranularityoffour(i.e.,216states),whichiswhyBTAI seemstobethreetimesslowerthanBTAI .
BF VMP
In reality, if BTAI had been using a granularity of four, it would have been much faster than BTAI while
BF VMP
maintaining a similar performance, i.e., around 96.9% of the task solved. Finally, BTAI outperformed both of its
3MF
predecessors by solving the task completely (100%, granularity of 1) in only 2.559 seconds. Importantly, BTAI
3MF
was able to model all the modalities of the dSprites environment for a total of 760,320 possible states.
In addition to the major boost in performance and computational time, BTAI provides an improved mod-
3MF
elling capacity. Indeed, the framework can now handle the modelling of several observed and latent variables, and
takes advantage of the factorisation of the generative model to perform inference efficiently. As described in detail
in Appendix A, we also provide a high level notation for the creation of BTAI that aims to make our approach
3MF
as staightforward as possible to apply to new domains. The high-level notational language allows the user to create
models by simply declaring the variables it contains, and the dependencies between those variables. Then, the frame-
work performs the inference process automatically. Moreover, driven by the need for interpretability, we developed a
graphical user interface to analyse the behaviour and reasoning of our agent, which is described in Appendix B.
There are two major directions of future research that may be explored to keep scaling up this framework. First,
BTAI is not yet equipped with deep neural networks (DNNs), and is therefore unable to handle certain types
3MF
of inputs, such as images. In addition to the integration of DNNs into the framework, further research should be
performed in order to learn useful sequences of actions. Typically, in the current version of BTAI , we built in
3MF
the fact that each action should be repeated eight times in a row. This inductive bias works well in the context of
the dSprites environment, but may be a limitation in other contexts.
It is also worth reflecting on how the BTAI model sits with theories of brain function. In this respect, it is
3MF
interesting to consider neural correlates of the “standard” approach that BTAI is being placed in opposition to.
3MF
As previously discussed, this standard active inference approach could be considered as monolithically tabular; that
is, the key matrices, such as the likelihood mapping (the A matrix) and the transition mapping (the B matrix), grow
in size exponentially with the number of states and observations. This is simply due to a combinatorial explosion,
e.g. the set of all combinations of states grows intractably with the number of states.
How would the combinations of states in the monolithic tabular approach be represented in the brain? The
obvious neural correlate would be conjunctive (binding) neurons (O’Reilly and Rudy, 2001), which become active
when multiple feature values are present; for example, one might have a neural unit for every X, Y combination in
the dSprites environment. If this is to be realised with a fully localist code, i.e. one unit for every combination, in
16
Multi-Modal and Multi-Factor BTAI.
the absence of any hierarchical structure, the required number of conjunctive units would explode in the same way
as the A and B matrices do. This is why some models have proposed a binding resource that supports distributed
(rather than localist) representations (Bowman and Wyble, 2007), which scale more tractably.
BTAI avoids this combinatorial explosion by not combining features, enabling them to be represented sepa-
3MF
rately. In a very basic sense, this separated representation is consistent with the observation that the brain contains
distinct, physically separated, feature maps, e.g. Itti et al. (1998). Thus, at least to some extent, different feature
dimensions are processed separately in the brain, as they are in BTAI .
3MF
Thetime-sliceideainBTAI assumesakindofdiscretesynchronisingglobalclock. Thus, eventhoughfeatures
3MF
have been separated from one another and may be considered to execute in different parts of the system, they update
in lock-step. That is, implicitly, time is a binder, it determines which values of different feature dimensions/states are
associated, e.g. an X-dimension value is associated with a particular Y-dimension value because they are so assigned
in the same temporal slice. In this sense, in BTAI , time synchronisation resolves the binding problem.
3MF
This aspect of BTAI resonates with theories of binding based upon oscillatory synchrony (Uhlhaas et al.,
3MF
2009). These theories suggest that different feature dimensions are bound by the corresponding neurons firing in
synchronyrelativetoanongoingoscillation, withthatongoingoscillationpotentiallyplayingtheroleofaglobalclock.
Such oscillatory synchrony can be seen as a way to resolve the binding problem that does not require conjunctive
units.
Conjunctionerrorexperiments, e.g. Botellaetal.(2001), arealsorelevanthere. Intheseexperiments, participants
makeerrorsinassociatingmultiplefeaturedimensions,perceivingillusorypercepts,e.g. ifaredKispresentedbeforea
blueAinarapidserialvisualpresentationstream,insomecases,aredAandablueKisperceived. Theseexperiments
firstly,re-emphasizethatdifferentfeaturedimensionsareprocessedseparately,asperBTAI : iffeaturedimensions
3MF
were not separated, then conjunction errors could not happen. Additionally though, these experiments suggest that
there is not a “perfect” synchronising global clock, since if there were, there would not be any conjunction errors even
despite separation of feature dimensions. Generating such conjunction error patterns is an interesting topic for future
BTAI modelling work.
3MF
Acknowledgments
TO BE FILLED
References
J Botella, M Suero, and MI Barriopedro. A model of the formation of illusory conjunctions in the time domain.
Journal of experimental psychology. Human perception and performance, 27(6):1452—1467, December 2001. ISSN
0096-1523. doi: 10.1037//0096-1523.27.6.1452. URL https://doi.org/10.1037//0096-1523.27.6.1452.
Matthew Botvinick and Marc Toussaint. Planning as inference. Trends in Cognitive Sciences, 16(10):485 – 488, 2012.
ISSN 1364-6613. doi: https://doi.org/10.1016/j.tics.2012.08.006.
Howard Bowman and Brad Wyble. The simultaneous type, serial token model of temporal attention and working
memory. Psychological review, 114(1):38, 2007.
C.B.Browne,E.Powley,D.Whitehouse,S.M.Lucas,P.I.Cowling,P.Rohlfshagen,S.Tavener,D.Perez,S.Samoth-
rakis,andS.Colton.Asurveyofmontecarlotreesearchmethods.IEEETransactionsonComputationalIntelligence
and AI in Games, 4(1):1–43, 2012.
Th´eophile Champion, Marek Grze´s, and Howard Bowman. Branching Time Active Inference with Bayesian Filtering,
2021a.
Th´eophileChampion, MarekGrze´s, andHowardBowman. RealizingActiveInferenceinVariationalMessagePassing:
The Outcome-Blind Certainty Seeker. Neural Computation, 33(10):2762–2826, 09 2021b. ISSN 0899-7667. doi:
10.1162/neco a 01422. URL https://doi.org/10.1162/neco_a_01422.
17
Champion et al.
Th´eophile Champion, Howard Bowman, and Marek Grze´s. Branching time active inference: Empirical study and
complexity class analysis. Neural Networks, 2022a. ISSN 0893-6080. doi: https://doi.org/10.1016/j.neunet.2022.
05.010. URL https://www.sciencedirect.com/science/article/pii/S0893608022001824.
Th´eophile Champion, Lancelot Da Costa, Howard Bowman, and Marek Grze´s. Branching time active inference: The
theory and its generality. Neural Networks, 151:295–316, 2022b. ISSN 0893-6080. doi: https://doi.org/10.1016/j.
neunet.2022.03.036. URL https://www.sciencedirect.com/science/article/pii/S0893608022001149.
LancelotDaCosta, ThomasParr, NoorSajid, SebastijanVeselic, VictoritaNeacsu, andKarlFriston. Activeinference
on discrete state-spaces: a synthesis, 2020.
Maell Cullen, Ben Davey, Karl J. Friston, and Rosalyn J. Moran. Active inference in openai gym: A paradigm
for computational investigations into psychiatric illness. Biological Psychiatry: Cognitive Neuroscience and Neu-
roimaging, 3(9):809 – 818, 2018. ISSN 2451-9022. doi: https://doi.org/10.1016/j.bpsc.2018.06.010. URL http:
//www.sciencedirect.com/science/article/pii/S2451902218301617. Computational Methods and Modeling
in Psychiatry.
Carl Doersch. Tutorial on variational autoencoders, 2016.
Thomas H. B. FitzGerald, Raymond J. Dolan, and Karl Friston. Dopamine, reward learning, and active inference.
Frontiers in Computational Neuroscience, 9:136, 2015. ISSN 1662-5188. doi: 10.3389/fncom.2015.00136. URL
https://www.frontiersin.org/article/10.3389/fncom.2015.00136.
ZafeiriosFountas,NoorSajid,PedroA.M.Mediano,andKarlFriston. DeepactiveinferenceagentsusingMonte-Carlo
methods, 2020.
V.Fox, J.Hightower, LinLiao, D.Schulz, andG.Borriello. Bayesianfilteringforlocationestimation. IEEE Pervasive
Computing, 2(3):24–33, 2003. doi: 10.1109/MPRV.2003.1228524.
Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, John O Doherty, and Giovanni Pezzulo.
Active inference and learning. Neuroscience & Biobehavioral Reviews, 68:862 – 879, 2016. ISSN 0149-7634. doi:
https://doi.org/10.1016/j.neubiorev.2016.06.022.
Karl J. Friston, Thomas Parr, and Bert de Vries. The graphical brain: Belief propagation and active inference.
Network Neuroscience, 1(4):381–414, 2017. doi: 10.1162/NETN\ a\ 00018. URL https://doi.org/10.1162/
NETN_a_00018.
L.Itti,C.Koch,andE.Niebur. Amodelofsaliency-basedvisualattentionforrapidsceneanalysis. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 20(11):1254–1259, 1998. doi: 10.1109/34.730558.
Laurent Itti and Pierre Baldi. Bayesian surprise attracts human attention. Vision Research, 49(10):1295 – 1306,
2009. ISSN 0042-6989. doi: https://doi.org/10.1016/j.visres.2008.09.007. URL http://www.sciencedirect.com/
science/article/pii/S0042698908004380. Visual Attention: Psychophysics, electrophysiology and neuroimag-
ing.
Frank R Kschischang, Brendan J Frey, and H-A Loeliger. Factor graphs and the sum-product algorithm. IEEE
Transactions on information theory, 47(2):498–519, 2001.
Loic Matthey, Irina Higgins, Demis Hassabis, and Alexander Lerchner. dsprites: Disentanglement testing sprites
dataset. https://github.com/deepmind/dsprites-dataset/, 2017.
Beren Millidge. Combining active inference and hierarchical predictive coding: A tutorial introduction and case
study., 2019. URL https://doi.org/10.31234/osf.io/kf6wc.
Randall C O’Reilly and Jerry W Rudy. Conjunctive representations in learning and memory: principles of cortical
and hippocampal function. Psychological review, 108(2):311, 2001.
18
Multi-Modal and Multi-Factor BTAI.
Corrado Pezzato, Carlos Hernandez, and Martijn Wisse. Active inference and behavior trees for reactive action
planning and execution in robotics, 2020.
Zhiyuan Ren and B.H. Krogh. State aggregation in Markov decision processes. In Proceedings of the 41st IEEE
Conference on Decision and Control, 2002., volume 4, pages 3819–3824 vol.4, 2002. doi: 10.1109/CDC.2002.
1184960.
Noor Sajid, Philip J. Ball, Thomas Parr, and Karl J. Friston. Active Inference: Demystified and Compared. Neural
Computation, 33(3):674–712, 03 2021. ISSN 0899-7667. doi: 10.1162/neco a 01357. URL https://doi.org/10.
1162/neco_a_01357.
Cansu Sancaktar, Marcel van Gerven, and Pablo Lanillos. End-to-end pixel-based deep active inference for body
perception and action, 2020.
PhilippSchwartenbeck, JohannesPassecker,TobiasUHauser, ThomasHBFitzGerald,MartinKronbichler, andKarl
Friston. Computationalmechanismsofcuriosityandgoal-directedexploration. bioRxiv, 2018. doi: 10.1101/411272.
URL https://www.biorxiv.org/content/early/2018/09/07/411272.
Peter Uhlhaas, Gordon Pipa, Bruss Lima, Lucia Melloni, Sergio Neuenschwander, Danko Nikoli´c, and Wolf Singer.
Neural synchrony in cortical networks: history, concept and current status. Frontiers in integrative neuroscience,
3:17, 2009.
John Winn and Christopher Bishop. Variational message passing. Journal of Machine Learning Research, 6:661–694,
2005.
Jonathan S. Yedidia. Message-passing algorithms for inference and optimization. Journal of Statistical Physics,
145(4):860–890, Nov 2011. ISSN 1572-9613. doi: 10.1007/s10955-011-0384-7. URL https://doi.org/10.1007/
s10955-011-0384-7.
Ozan C¸atal, Tim Verbelen, Johannes Nauta, Cedric De Boom, and Bart Dhoedt. Learning perception and planning
with deep active inference, 2020.
Appendix A: How to create a BTAI agent?
3MF
In this appendix, we describe how to build a BTAI agent using our framework. The relevant code can be found
3MF
in the file main_BTAI_3MF.py at the following URL: https://github.com/ChampiB/BTAI_3MF. Any script running
a BTAI agent must start by instantiating an environment in which the agent will be run. Our code provides an
3MF
implementation of the dSprites environment, which can be created as follow:
# Create the environment.
env = dSpritesEnv(granularity=1, repeat=8)
env = dSpritesPreProcessingWrapper(env)
The first line creates the dSprites environment, the second makes sure that the observations generated by the envi-
ronment are in the format expected by the agent. Once the environment has been created, we need to define the
parameters of the model. Assume that we want to have a latent variable Sshape representing the shape in the current
t
image. This variable can takes three values, i.e., zero for squares, one for ellipses and two for hearts. In this case, the
parameters of the prior over Sshape may be created as:
t
# Create the parameters of the prior over the latent variable shape.
d = {}
d["S_shape"] = torch.tensor([0.2, 0.3, 0.5])
19
Champion et al.
The first line above creates a python dictionary, the second line adds a vector of parameters in the dictionary. This
vector can be accessed using the key “S shape”, which corresponds to the name of the latent variable. The values
in d[“S shape”] mean that a priori the agent believes it will observe a square with probability 0.2, an ellipse with
probability 0.3, and a heart with probability 0.5. Also, by convention, the name of a latent variable must start with
“S ”. Similarly, if we assume that the shape is provided to the agent through an observed variable Oshape, we can
t
create the parameters of the likelihood mapping for this variable as:
# Create the parameters of the likelihood mapping for the shape variable.
a = {}
a["O_shape"] = torch.eye(3)
The first line above creates a python dictionary, and the second line adds a 3×3 identity matrix1 in the dictionary.
This reflects the fact that there is a one-to-one relationship between the value taken by Sshape and Oshape. Also, by
t t
convention, the observations name must start with “O ”. Since, defining all the parameters manually can be tedious,
our framework provides built-in functions that return the model parameters for the dSprites environment. Using
those functions, the parameters can be retrieved as follows:
# Define the parameters of the generative model.
a = env.a()
b = env.b()
c = env.c()
d = env.d(uniform=True)
Once all the parameters have been created, it is time to define the structure of the generative model. This can be
done using a temporal slice builder, which is an object used to facilitate the creation of a temporal slice. First, we
need to create the builder as follows:
# Create the temporal slice builder.
ts_builder = TemporalSliceBuilder("A_1", env.n_actions)
The builder takes two parameters, i.e., the name of the action random variable (i.e., “A 1”) that must start by “A ”,
and the number of possible actions (i.e., env.n actions = 4). Then, we need to tell the builder what state variables
shouldbecreated, andwhataretheparametersofthepriorbeliefsoverthosevariables. ForthedSpritesenvironment,
this can be done as follows:
# Add the latent states of the model to the temporal slice.
ts_builder.add_state("S_pos_x", d["S_pos_x"]) \
.add_state("S_pos_y", d["S_pos_y"]) \
.add_state("S_shape", d["S_shape"]) \
.add_state("S_scale", d["S_scale"]) \
.add_state("S_orientation", d["S_orientation"])
The function “add state” adds a state variable to the temporal slice. The first parameter of this function is the name
of the state to be added, and the second argument is the parameters of the prior beliefs over this new state. Next, we
need to add the variables corresponding to the observations made by the agent. For the dSprites environment, this
can be done as follows:
# Define the likelihood mapping of the temporal slice.
ts_builder.add_observation("O_pos_x", a["O_pos_x"], ["S_pos_x"]) \
.add_observation("O_pos_y", a["O_pos_y"], ["S_pos_y"]) \
.add_observation("O_shape", a["O_shape"], ["S_shape"]) \
.add_observation("O_scale", a["O_scale"], ["S_scale"]) \
.add_observation("O_orientation", a["O_orientation"], ["S_orientation"])
1. Note, in practice the identity matrix is noisy to avoid taking the logarithm of zero.
20
Multi-Modal and Multi-Factor BTAI.
The function “add observation” adds an observation variable to the temporal slice. The first parameter of this
function is the name of the observation to be added, the second argument is the parameters of the likelihood mapping
for this new observation, and the third parameter is the list of parents on which the observation depends. The next
step is the definition of the transition mapping for each hidden state, which can be performed as follows:
# Define the transition mapping of the temporal slice.
ts_builder.add_transition("S_pos_x", b["S_pos_x"], ["S_pos_x", "A_1"]) \
.add_transition("S_pos_y", b["S_pos_y"], ["S_pos_y", "A_1"]) \
.add_transition("S_shape", b["S_shape"], ["S_shape"]) \
.add_transition("S_scale", b["S_scale"], ["S_scale"]) \
.add_transition("S_orientation", b["S_orientation"], ["S_orientation"])
The function “add transition” adds a transition mapping to the temporal slice. The first parameter of this function
is the name of the state for which the transition is defined, the second argument is the parameters of the transition
mapping for this state, and the third parameter is the list of parents on which the state depends. Importantly, in
the above snippet of code, only the states representing the position in x and y of the shape depends on the action
variable “A 1”. The final step is about the defintion of the prior preferences of the agent, and can be done as follows:
# Define the prior preferences of the temporal slice.
ts_builder.add_preference(["O_pos_x", "O_pos_y", "O_shape"], c["O_shape_pos_x_y"])
The function “add preference” adds some prior preferences to the temporal slice. The first parameter of this function
is the list of observations for which the prior preferences are defined, and the second argument are the parameters of
the prior preferences for those observations. At this stage, the initial temporal slice can be built:
# Create the initial temporal slice.
ts = ts_builder.build()
Once the initial temporal slice has been created, it is possible to instantiate the agent and implement the action-
perception cycle as follows:
# Create the agent.
agent = BTAI_3MF(ts, max_planning_steps=150, exp_const=2.4)
# Implement the action-perception cycles.
n_trials = 100
for i in range(n_trials):
obs = env.reset()
env.render()
agent.reset(obs)
while not env.done():
action = agent.step()
obs = env.execute(action)
env.render()
agent.update(action, obs)
Most of the above code is self explanatory. Put simply, this code runs “n trials” simulations of the dSprites en-
vironment. The line “action = agent.step()” performs inference, planning and action selection. The line “obs =
env.execute(action)” executes the selected action in the environment, and the line “agent.update(action, obs)” up-
dates the agent so that it has taken into account the action taken in the environment and the observations received.
Appendix B: How to inspect a BTAI agent?
3MF
Inthisappendix, wedescribehowtoanalyseaBTAI agentusingourgraphicaluserinterface(GUI).Therelevant
3MF
codecanbefoundinthefileanalysis_BTAI_3MF.pyatthefollowingURL:https://github.com/ChampiB/BTAI_3MF.
21
Champion et al.
The first step is to create the environment and agent as described in Appendix A. Then, we create a GUI object and
run the main loop as follows:
# Create the GUI for analysis.
gui = GUI(env, agent)
gui.loop()
The above two lines should open a graphical user interface as shown in Figure 6. When clicking on the node of the
current temporal slice TS(t), one can obtain additional information about this temporal slice, c.f., Figure 8. When
clicking on the button named “Next planning iteration” in Figure 6, a planning iteration is performed and the tree
displayed on the right-hand-side of this frame is updated as shown in Figure 7. When clicking on the root’s children,
e.g., “TS(1)”, it is possible to navigate through the tree created by the MCTS algorithm as shown in Figure 9. When
“TS(1)” is displayed as the new root as in Figure 9, clicking on “TS(1)” again will display the information of this
node as depicted by Figure 10. Finally, Figure 11 shows how the ambiguity term of the expected free energy can be
decomposed into its component parts.
Figure 6: This figure illustrates the visualisation frame of the GUI used to analyse a BTAI agent. The image
3MF
corresponding to the current state of the environment is displayed in the upper-left corner. Under the image are four
buttons allowing the user to: reset the environment and agent, perform the next planning iteration, perform all the
remaining planning iterations, and perform the current best action in the environment. Finally, on the right hand
side of the image is a depiction of the MCTS planning, where TS(t) represents the current temporal slice. At the
moment, the current temporal slice has no children, and therefore its children are displayed in orange with the text
“None”. Additionally, the current slice has no parent because it is the tree’s root. Therefore, the arrow above the
TS(t) node is also orange.
22
Multi-Modal and Multi-Factor BTAI.
Figure7: ThisfigureillustratesthevisualisationframeoftheGUIusedtoanalyseaBTAI agentafterperforming
3MF
one planning iteration. The children of the root node are now available. One of them is displayed in green, it
corresponds to the best action found so far by the MCTS algorithm. The root node has a red square surronding it,
which means that it was selected for expansion by the MCTS algorithm.
Figure 8: This figure illustrates the frame displaying the information of the current temporal slice of the BTAI
3MF
agent. Six widgets are displayed. The first displays the structure of the likelihood model using the factor graph
formalism. On this graph, we see that the model is composed of five obervations and five hidden states. Each
observation depends on only one hidden state. The second widget displays the structure of the transition mapping.
We see that only two hidden states depend on the action taken by the agent, i.e., the hidden states corresponding
to the X and Y position of the shape. The third widget shows the structure of the prior preferences. Here, there is
only one factor over three random variables, i.e., the shape and its (X, Y) position. Note, when moving your mouse
over a variable in the likelihood, transition or prior preference widget the complete name of the variable is displayed,
e.g., when moving over “S1” the label “S shape” is displayed. The fourth widget illustrates the posterior over the
latent variable corresponding to the x position of the shape. The random variable whose posterior is displayed can be
changed either by using the combo box in the bottom-right corner of the widget or by clicking on a latent variable in
the likelihood model widget. The fifth widget displays information related to the Monte-Carlo tree search. Finally,
the last widget illustrates the message sent from the observation variable corresponding to the X position of the shape
to its likelihood factor.
23
Champion et al.
Figure 9: This figure illustrates what happens when clicking on the child “TS(1)” in Figure 7. Put simply, “TS(1)”
becomes the new root and we see that its children have not been expanded yet. Additionally, the arrow above the
“TS(1)” node is gray meaning that this node has a parent, i.e., “TS(t)”. Clicking on this arrow leads us back to
Figure 7.
Figure 10: This figure illustrates what happens when clicking on “TS(1)” in Figure 9. Most of the widgets have
already been explained with the exception of the one in the bottom right-corner, which displays how the expected
free energy decomposes into risk (blue box) and ambiguity (red box). When clicking on the blue or red box, the
decomposition of the risk or ambiguity term is displayed as shown in Figure 11.
24
Multi-Modal and Multi-Factor BTAI.
Figure 11: This figure illustrates how the ambiguity term decomposes into the ambiguity of the likelihood of each
observed variable, i.e., the ambiguity of “O shape” in blue, “O scale” in red, “O orientation” in orange, “O pos x”
in green, and “O pos y” in gray.
Appendix C: sum-rule, product-rule and d-separation criterion.
In this appendix, we explain three important properties than are used in the core of the paper, namely: the sum-rule
and product-rule of probability and the d-separation criterion.
Sum-rule of probability
GivenasetofrandomvariablesX = {X ,...,X }, andajointdistributionP(X ,...,X )overX. Thesum-ruleallows
1 n 1 n
to sum out a subset of the random variables. Here are a few examples:
(cid:88)
P(X ,...,X ) = P(X ,...,X ),
1 n−1 1 n
Xn
(cid:88) (cid:88)
P(X ,...,X ) = P(X ,...,X ),
1 n−2 1 n
Xn−1 Xn
(cid:88) (cid:88) (cid:88)
P(X ,...,X ) = P(X ,...,X ).
1 n−3 1 n
Xn−2Xn−1 Xn
Note, the sum-rule can also be used with a conditional distribution P(X ,...,X |Y ,...,Y ), for examples:
1 n 1 m
(cid:88)
P(X ,...,X |Y ,...,Y ) = P(X ,...,X |Y ,...,Y ),
1 n−1 1 m 1 n 1 m
Xn
(cid:88) (cid:88)
P(X ,...,X |Y ,...,Y ) = P(X ,...,X |Y ,...,Y ),
1 n−2 1 m 1 n 1 m
Xn−1 Xn
(cid:88) (cid:88) (cid:88)
P(X ,...,X |Y ,...,Y ) = P(X ,...,X |Y ,...,Y ).
1 n−3 1 m 1 n 1 m
Xn−2Xn−1 Xn
Product-rule of probability
Given a set of random variables X = {X ,...,X }, and a joint distribution P(X ,...,X ) over X. The product-rule
0 n 0 n
allows us to factorise the joint into a product of factors without doing any conditional independence assumptions
about P(X ,...,X ). More formally:
1 n
n−1
(cid:89)
P(X ,...,X ) = P(X ) P(X |X ),
0 n n i i+1:n
i=0
25
Champion et al.
where X = {X ,...,X } is the set of random variables containing all the variables between X and X (included).
i:j i j i j
Note, the product-rule can also be used with a conditional distribution P(X ,...,X |Y ,...,Y ):
0 n 1 m
n−1
(cid:89)
P(X ,...,X |Y ,...,Y ) = P(X |Y ,...,Y ) P(X |X ,Y ,...,Y ).
0 n 1 m n 1 m i i+1:n 1 m
i=0
The d-separation criterion
The d-separation criterion is a tool than can be used to check whether two sets of random variables (X and Y) are
independent given a third set of random variables Z. More formally, the d-separation criterion is a tool to check
whether X ⊥⊥ Y |Z. Knowing that X ⊥⊥ Y |Z holds in a distribution P is useful because if X ⊥⊥ Y |Z, then:
P(X,Y|Z) = P(X|Y,Z)P(Y|Z) (product-rule)
= P(X|Z)P(Y|Z). (X ⊥⊥ Y |Z)
First, let G = (X,E) be a graph over a set of nodes X connected by a set of directed edges E. Given two nodes in the
graph (i.e., N ,N ∈ X), we note: (i) N → N if there is a directed edge from N to N in the graph, (ii) N ← N if
i j i j i j i j
the graph contains a directed edge from N to N , and (iii) N (cid:29) N if (i) or (ii) holds. Second, we say that there is
j i i j
a trail between two nodes (i.e., N ,N ) in the graph, if there is a sequence of distinct nodes N = (N ,...,N ), such
1 n 1 n
that: N (cid:29) N holds for all i ∈ {1,...,n−1}. Third, we say that a trail between N and N is active if: (a) each
i i+1 1 n
time there is a v-structure (i.e., N → N ← N ) in the trail, then either N or (at least) one of its descendants
i−1 i i+1 i
are in Z, and (b) no other node along the trail are in Z. Finally, we say that X and Y are d-separated by Z if for all
X ∈ X and Y ∈ Y there is no active trail between X and Y (given Z).
i i i i
Using our terminology, the d-separation criterion states that if X and Y are d-separated by Z in a graph G
representing the factorisation of a distribution P, then X ⊥⊥ Y |Z holds in the distribution P. Intuitively, the d-
separation criterion help us to determine whether X ⊥⊥ Y |Z holds in P by looking at the topology of the graph G.
For example, consider the Bayesian network illustrated in Figure 12, and let P be the joint distribution represented
by this Bayesian network. Using the product rule, we get:
P(A,B,C,D,E,F) = P(F|A,B,C,D,E)P(E|A,B,C,D)P(C|A,B,D)P(D|A,B)P(B|A)P(A).
Note, that all trails between C and A,D are blocked by B, i.e., there is no active trails between C and A,D given B.
Thus, we have C ⊥⊥ A,D|B and:
P(A,B,C,D,E,F) = P(F|A,B,C,D,E)P(E|A,B,C,D)P(C|B)P(D|A,B)P(B|A)P(A).
Moreover, there is no active trail between B and A given ∅, therefore B ⊥⊥ A|∅ and:
P(A,B,C,D,E,F) = P(F|A,B,C,D,E)P(E|A,B,C,D)P(C|B)P(D|A,B)P(B)P(A).
Using the same reasoning, one can see that F ⊥⊥ A,B,C,D|E and thus:
P(A,B,C,D,E,F) = P(F|E)P(E|A,B,C,D)P(C|B)P(D|A,B)P(B)P(A).
Finally, using the d-separation one more time leads to the following factorisation for P:
P(A,B,C,D,E,F) = P(F|E)P(E|B,D)P(C|B)P(D|A,B)P(B)P(A).
A B C
D E F
Figure 12: This figure illustrates a Bayesian network in which the following independences assumptions hold: A ⊥
⊥ B|∅; A,D ⊥⊥ C|B; and A ⊥⊥ E|D,B,C. In contrast, the following independences assumptions does not hold:
A ⊥⊥ B|D; A ⊥⊥ E|B,C; and A ⊥⊥ B|E .
26

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Multi-Modal and Multi-Factor Branching Time Active Inference"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
