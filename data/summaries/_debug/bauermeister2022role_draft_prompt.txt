=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: The Role of Valence and Meta-awareness in Mirror Self-recognition Using Hierarchical Active Inference
Citation Key: bauermeister2022role
Authors: Jonathan Bauermeister, Pablo Lanillos

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2022

Key Terms: multisensory, meta, perception, test, processes, awareness, mirror, recognition, hierarchical, valence

=== FULL PAPER TEXT ===

The Role of Valence and Meta-awareness in Mirror
Self-recognition Using Hierarchical Active Inference
Jonathan Bauermeister1 and Pablo Lanillos1
Radboud University, Houtlaan 4, 6525 XZ Nijmegen, NL
Abstract. The underlying processes that enable self-perception are crucial for under-
standing multisensory integration, body perception and action, and the development of
the self. Previous computational models have overlooked an essential aspect: affective or
emotionalcomponentscannotbeuncoupledfromtheself-recognitionprocess.Hence,here
we propose a computational approach to study self-recognition that incorporates affect
usingstate-of-the-arthierarchicalactiveinference.Weevaluatedourmodelinasynthetic
experiment inspired by the mirror self-recognition test, a benchmark for evaluating self-
recognitioninanimalsandhumansalike.Resultsshowthati)negativevalenceariseswhen
theagentrecognizesitselfandlearnssomethingunexpectedaboutitsinternalstates.Fur-
thermore,ii)theagentinthepresenceofstrongpriorexpectationsofanegativeaffective
statewillavoidthemirroraltogetherinanticipationofanundesiredlearningprocess.Both
results are in line with current literature on human self-recognition.
Keywords: Active Inference · Affect · Self-mirror recognition
1 Introduction
The ability of self-recognition has been typically attributed only to humans and few other
species [2] and hides several essential brain processes related to multisensory perception, em-
bodiment and decision making [14,15]. To evaluate this ability, Gallup, in 1970, developed a test
forchimpanzeesnamedthemirrorself-recognition(MSR)[12].Thistest,whichwasalsoadapted
for infants [1], consists of placing a mark, unbeknownst to the subject, on her face. The subject
is then placed in front of a mirror. The agent passes the test if there are reaching or exploratory
behaviours to remove the mark or inspect it.
While most studies postulate mark directed behaviour (inspect or remove) as a necessary
condition for self-recognition [3], more recent cross-cultural studies have shown that children
from cultures with higher parental authority are not inclined to remove the mark [4]. Similarly
if one creates a social context during the mirror test, where several other subjects around the
infantalsohavemarksontheirface,theinfantdespitehavingpassedthemirrortestbeforeisless
motivated to engage in mark directed behaviour [19]. Both results, by enriching the complexity
of such behaviour by environmental and social factors, cast doubts on interpreting the necessity
or sufficiency of mark directed behaviour for self-recognition.
On the other hand, it has been evidenced in humans a strong emotional component, i.e., to
express negative affect when seeing their own reflection. When infants pass the test around the
age of two, they universally express negative affect toward their mirror image, which has been
interpreted as embarrassment, shyness or puzzlement [1,18]. Ultimately, we do not know what
the phenomenology of a two-year-old seeing herself in the mirror is like. Anyhow, the negative
affective part of the experience seems to be uncontested.
Whilethereispreviousresearchoncomputationalmodelsofself-recognition(e.g.,generative
modellingfocusingonvisual-kinestheticmatchingorappearancecues[16,14]),noneoftheworks
2202
guA
82
]CN.oib-q[
1v31231.8022:viXra
2 J. Bauermeister and P. Lanillos
hasattendedtotheemotionalcomponent.Here,westudiedself-recognitionby(i)developingofa
computational model that incorporates the affective component into the self-recognition process
and (ii) evaluating it on a new synthetic experiment based on the MSR.
To model the affective component we use the notion of valence [13]. The working hypothesis
is that the negative or positive quality of an affective experience can arise as a consequence of
obtaining new information about oneself through mirror self-recognition. Importantly, this new
informationmightfavourdifferentactionselectionpolicies(actiondependentvalence),leadingto
achangeinvalence.Thisiterativeprocesscoherentlyconnectsemotionswithself-recognitionand
decision-making.Toincorporatevalenceintotheperception-actionloopweusedthehierarchical
activeinference construct[11],wheretheagentperceives,learnsandactstoobtaintheexpected
outcomes by minimizing the expected free energy.
Wefurtherdevelopedanexperimentalbenchmarktoevaluatetheeffectofvalenceinthepro-
cessofdecision-makingandself-recognition.Intheexperiment,theagentcandecidetolookata
mirror,lookatawallorlookatavideoofanotheragent.Furthermore,thankstothehierarchical
nature of the model, we further studied the importance of meta-cognition (‘higher’ layers), in
combination with affect, for (anticipated) self-recognition. For instance, adults in full possession
of a self-concept can also anticipate a confrontation with their mirror image. If self-evaluation
is negative, or one’s body image has radically shifted due to surgery, patients are motivated to
actively avoid the mirror [10].
Related Work. There were several tries to build a computational model of self-recognition—
See [14] for a review. Relevant to this work, in [16] the robot inferred itself by answering the
question ’did I generate those sensory outcomes?’. For example, if the robot has an intention
to move its arm and can predict its interoceptive and exteroceptive sensory outcomes with
low prediction error, then it will infer that the likeliest cause of this action was the system
itself. While this approach may be promising to give insights into self-recognition, it does not
yet explain how affect arises during the human MSR test. It has been theorized that affective
and action based self-modelling naturally arises for a system engaged in deep temporal active
inference [6,7]. Nevertheless, to the authors knowledge, there is no computational model as of
now,thatexplicitlyassessesaffectwithinself-recognition.Fortunately,recentlywithintheactive
inference research, there has been an effort to introduce internal drivers that modulate the
generativemodelparametersandtheactionselectionprocess.Forinstance,valence–pleasantness
or unpleasantness of an emotional stimulus – was introduced in [13] to model the confidence
of the model estimates. Importantly, valence encodes how well the agent is performing in the
environment, thus, aiding action selection. The mathematical formalization of valence and the
hierarchical structure of the generative model allows the building of a complex agent that has
beliefs over beliefs, which are modulated by the increase or decrease of valence, thus affecting
the whole decision making process. In this work, we adapt this model to study self-recognition
and decision making.
2 Methods
First,wedescribethegeneralframeworkofourapproachandhowtointroducevalencebasedon
theworkof[13].Second,wedetailtheaffectiveself-recognitioncomputationalmodelandfinally,
we describe the experimental setup for self-recognition.
Title Suppressed Due to Excessive Length 3
2.1 Discrete hierarchical active inference
We model the problem under the discrete state-space formulation of active inference [17]1. The
agentcomputesboththeposteriorstateestimation(perception)andactionselectionbyminimiz-
ing,throughmarginalmessagepassing,asinglequantity:theexpectedfreeenergy.Thisquantity
measures the divergence from the current expectations to the real world state. In order to be
able to compute it the agent needs a generative model of the world, thus, allowing predictions of
the future outcomes. See Appendix 5 for detailed explanation.
Temporal DepthToachievetemporaldepthweuseahierarchicalgenerativemodelasdepicted
inFig.1.Here,thehiddenstatesonthesecondlayerchangeslowerthanthehiddenstatesonthe
first layer. Thus the beliefs about states in the first layer (bottom) can fluctuate several times
within one trial, where the beliefs on the second layer (top) only change at the end of each trial
(the length of a trial is defined by the modeller). For example, the agent can have the abstract
beliefthatitisinahappymood.Thisbeliefwillsetthepriorsonthefirstlevelatthebeginning
of a trial accordingly. So now the agent expects certain observations (facial muscles expressing a
smile, heart rate going up etc.), even if within the trial the facial muscles will most likely change
several times (depending on the granularity of the model) and not only stay in one position, say
smiling, the agent could still infer that overall it is happy (which is an abstract second-order
belief that integrates information over time). Only if in the course of the trial it consistently
observes unexpected observations (prediction errors) it will update its belief on the second level
at the end of a trial accordingly.
Mathematically,thesecondlayerhaslikelihoodmappingsandstatetransitionslikethefirstlayer.
They differ in that the likelihood mapping A2 does not map from observation to hidden state
but from the hidden state at layer one (facial expression i.e smile, frown, neutral) to the hidden
state on layer two (mood i.e happy or sad). The transition matrix B2 then encodes how likely
the context, for example, the agent’s mood, changes over trials. As a consequence, the prior D1
is replaced by a more dynamically changing higher-order state. At the beginning of each trial,
the higher-order state acts as prior for the agent. By the end of the trial the agent updates the
higher-orderstatebasedontheinformationcollectedinthistrial.Foramathematicalexpression
of ascending and descending messages—See [13] for further description.
Meta-cognition and Valence. Anagentequippedwith sucha deeptemporalmodel canlearn
contextandperformsometasksverywellbutunderperformsinavolatilechangingenvironment.
Here we describe, based on the work of [13], how affect can be included in a discrete hierarchical
activeinferencenetwork.Affectcanbeformalizedthroughvalence(negativeorpositive).Valence
can be explained as the expression of confidence in the model estimates. If the agent’s actions
continuously lead to the outcomes that it expects and prefers, it grows more confident in its
action model and weighs it stronger as acquired habits. Whereas if the environment is very
volatile and it cannot rely on its learned action model yielding to an ’anxious’ state. The agent
equipped with affective states finds better and biologically more plausible action plans (policies)
than one without [13]. Partly because it takes time to construct a reliable action model that
tells the agent which policies to take under which circumstances. Hence, when the environment
changes fast and unexpected the action model (learn by experience) might become completely
useless. An affective agent that reacts with negative valence towards the unexpected change
in the environment will able to quickly adapt by lowering the precision of its action model to
1 Forathoroughtutorialondiscreteactiveinferenceformulationsee[21]andforaconcisemathematical
overview see [5].
4 J. Bauermeister and P. Lanillos
Fig.1.Atemporallydeepgenerativemodelwithtwohierarchicallayers.Theblueboxesinthefirstlayer
correspond to trials (here simplified). This is the architecture the agent uses to perceive and act in the
world.Thesecondlayeronlycommunicateswiththefirstatthebeginningofatrialthroughdescending
Messages and at the end of the trial is informed by ascending messages. Hence, it can already be seen
that states on the second level change slower (only once every trial) than states on the first layer. Here
theagenthastwostatefactorsonthesecondlevel.Ithasacontextualbeliefwhichreplacesthepriorat
the beginning of each trial. Additionally, it has an affective state which sets the precision on G at the
beginning of the trial. The impact of G on π can now be regulated by the agent through its affective
state. Figure adapted from [13].
reevaluate the new situation. Conversely, an agent without affective states cannot quickly adapt
and will execute the same actions despite an environment that has changed.
Thus, valence acts as a second-order state. Implementation-wise the agent has a categorical
distribution over it being either in the state ’positive valence’ or ’negative valence’, and it is
updated at the end of a trial via ascending messages. If in a trial the agent could rely on its
action model then it increases its valence for the next trial. At the beginning of the next trial,
instead of using a static prior the second-order affective state informs the precision of the action
model. Such a top-down estimation of the reliability of its model can also be understood as a
form of meta-cognition as it is monitoring the confidence of the cognitive process.
Meta-awareness and attention. The meta-cognition architecture can be extended to model
meta-awarenessbyaddingathirdlayer,andallowingtheagenttodynamicallychangetheinfor-
mation flow between second and first layer. This has been implemented by [20] as a precision on
the likelihood mapping. Generally, precision on likelihood matrices in active inference is linked
to attentional processes. The states on the third level then represent if the agent is aware of
Title Suppressed Due to Excessive Length 5
her cognitive processes on the second level. The benefits and biological plausibility of this meta-
awarenesscapacityhavebeenshownby[20].Hereweuseasimplifiedsetupwherewechangethe
precision of the 2nd layer likelihood by hand to see how the agent’s behaviour changes if it is
very aware of its emotional states and hence, can use the information for cognition deeper down
the hierarchy. The precision modulates how strong the connection between the two layers is and
therefore how informative descending and ascending messages are. For instance, low precision
will lead the agent to rely more on its ‘direct experience’ (first layer of its generative model).
2.2 Affective self-recognition model
Based on the previously described framework, we propose a computational model to investi-
gate self-recognition with the emotional component. We focused on the following two research
questions:(i)Howdoesvalenceinfluencebehaviourduringmirrorself-recognition?and(ii)How
might negative valence arise in mirror self-recognition?
To evaluate the model and further be able to answer the questions, we designed an exper-
iment where an agent can decide to either see its emotional expression in the mirror, look at
a wall and see no face or look at a video of an emotional expression of another person. Note
that our computer-simulated agent can not look into an actual physical mirror, so we need to
formalize the function of the mirror, which possibly leads to an affective reaction. We interpret
making an observation in the mirror as acquiring information about oneself (here: about the
agent’s emotional state via its facial expression) by dragging the internal attention of the agent
onto this aspect of itself. Thus, the mirror is a self-exploration tool that allows this information
to be available for decision making and introspection from layers higher up the hierarchy.
Generative Model. We formalize a two-layered deep generative model to capture the self-
recognition experiment, as described in Fig. 2. The agent can obtain exteroceptive observations,
where it either sees a face that is happy, neutral or sad, or nothing when it looks at the wall.
This information can be used to infer the emotional state of the other person. And it can obtain
interoceptive observations about its facial expression (for example sensing its facial muscles) to
inferitsemotionalstate(happy,neutral,sad).Theagentalsohasastate(attentioninthefigure)
thatcapturesifitispayingattentiontoitsinteroceptiveobservationwithvaluesYesorNo.This
is an attention state, in the sense that it modulates the precision on the likelihood A, but it
cannot be actively controlled by the agent. Instead, it captures what happens internally when
theagentseesitselfinthemirror.Byrecognizingitself,itisforcedtopayattentiontoitsinternal
observation(theprecisionω onAwillbecomeveryprecise).Hence,formalizingthenotionofthe
mirror dragging attention onto oneself and making certain observations informative.
On the second layer, the agent has two state factors. The valence can be positive or negative
(implemented as a categorical distribution). Its value depends on the expected precision of the
action model G. Additionally, the agent has a second-order belief about which mood it is in
(happy,neutral,sad).Thisstatesetsthepriorsofwhatfacialexpressiontheagentexpectswhen
observing itself. For all the details of how this generative model is implemented please see the
Appendix 5.
Agent operational specification. First, inspired by the idea that if self-evaluation is positive
one seeks out a mirror, we assume that the agent prefers to see itself but only if it is ’happy’ or
‘neutral’ instead of ‘sad’. This is encoded in the preference matrix C. The agent’s actions are to
go to one of the three locations: mirror, wall or tv. Because the agent knows from its generative
model that it will pay attention to itself if it goes to the mirror its behaviour will depend on its
self-knowledge,i.e.,whatstateitbelievestobeinandhowawareitisofthatstate.Ifitthinksit
6 J. Bauermeister and P. Lanillos
Fig.2. Generative model description. Two layered model of an agent inferring its own mood and
deciding weather to look at the mirror or not. At any given time step the 1st layer includes an action
model G, preferences C and four state factors: Location, Other-facial-expression, My-facial-expression
andAttention.TheAttentionstatemodulatesthelikelihoodAviatheprecisionω.Foreachstatefactor,
theagenthasacategoricaldistributionofwhichstateitbelievesitselftobein.The2ndlayertracksthe
agent’s valence and belief about its mood. Valence interacts with the action model G and the mood or
context state interacts with the agents belief of its facial expression on the first level via A2.
ishappyonewouldexpectthattheagentwillacttoadmireitselfinthemirror.Second,thetrue
emotional state of the agent may change. Here we have coupled the dynamics of the true state
to the current valence of the agent. If its positive valence goes above 70 % its true state shifts
to happy, below 30% to sad and otherwise neutral. To be robust against small fluctuations, we
imposed that the agent’s belief about its valence has to shift at least by 15% to make a switch.
Although, these decisions are arbitrary, they are designed to show how the agent adapts to a
change in its true state.
3 Results
we analyzed our model behaviour in our synthetic experiment to study which actions the agent
chooses and when and how the valence of the agent changes under different conditions, such as
changing the true emotional state, the prior knowledge the agent has about its emotional state
ortheintrospectiveavailabilityofitsemotionalstates(precisiononA2).Particularly,wefocused
ontwodifferentinitialconditions.Inthefirstexperiment(Sec.3.1),westudyhowvalencemight
naturally evolve in a mirror self-recognition scenario. To this end, the agents true state was set
to sad, but it had low meta-awareness. For the second experiment (Sec. 3.2), we studied mirror
avoidancebehaviour.Thus,theagenthadhighmeta-awareness.Thecodetoreplicatetheresults
can be found in this this link.
Each agent was evaluated for 8 consecutive trials in each condition, where each trial lasts for
three time steps (three observations). After the first observation, the agent will have to decide
where to go (mirror, wall or tv). Its action plan horizon is two steps ahead, thus, it can predict
outcomes until the end of a trial by using its generative model.
3.1 Experiment 1: I am sad and I know it, but I am not very aware of it
Wesetthetruestateoftheagentto‘sad’andtheprecisiononA2low.Also,theagent‘knows’that
itissadonthesecondlevelofthehierarchy.However,duetothelowprecisiononA2thiswillnot
Title Suppressed Due to Excessive Length 7
Fig.3. Experiment 1. The belief distribution of My- facial-expression (SFace1 and SFace2) at the
beginning of each trial are shown. Below that the agent with its true state is shown as smiley. It is
indicatedatwhatlocationitcurrentlyis.Thegreenboxindicatesifitsattentionisontheexteroceptive
or interoceptive observation. The graph next to it shows how the agent’s valence evolves throughout
the trials. The value is a probability, where a high value means high confidence in being in the state of
‘positive valence’. At each trial, the agent has to choose where to go and hence at which location it will
start the next trial. The valence graph shows how negative affect is elicited when the agent makes an
unexpected observation in the mirror and therefore learns something new about its internal states.
informthefirstlevel,thus,theagentwillbemoreinformedbytheactualperceptualinformation
in a given trial. The experiment is described in Fig. 3. At trial 0 the agent is convinced enough
that it is sad and calculates that its best action will be to go to the video. Paying attention to
the other face, loosens its priors making them less informative about its emotional state. This
is reflected in the categorical distribution at trial 1. It is more entropic or less precise as in trial
0. In trial 1 it decides to go to the mirror. Hence in trial 2, it makes an unexpected observation
(seeing itself frown in the mirror) which also results in a drop in valence, indicating that this
particular mirror encounter is negatively experienced. Having reaffirmed its belief that it is sad,
it finds it best to go to the video. With this decision, the agent regains a bit of confidence in its
action model. The valence goes up between trials 2 and 3. And due to the in build dynamics,
its true state shifts to neutral. Finally, the agent notices the change in its true state to neutral
and decides it’s time to go to the mirror again, which even further improves its confidence in its
action model and for the rest of the trials it will be happily smiling at itself in the mirror.
3.2 Experiment 2: I am sad and I know it and I am aware of it
We explored how the behaviour of the agent changes if its first-order states are introspectively
available to it. The experiment is described in Fig. 4. We set the same initial state as in the
previousstudy:truestateis‘sad’andfirstlocationisthe‘wall’.Differently,thistimethemapping
A2 is very precise.
8 J. Bauermeister and P. Lanillos
Fig.4. Experiment 2. The agent, now being more aware of its own internal state, is anticipating an
uncanny encounter with the mirror. Hence it is avoiding the mirror longer. However, it is also less able
to pick up on a change in the true state of its emotion due to it expecting, much stronger, that it is
actuallysad.Itsvalenceonlyshiftsbetweensadandneutral.Theresultsshowhowhavingstrongpriors
aboutitsemotionalstateandbeingabletoattendtoitdiscouragesexploratorybehavioursuchasgoing
to the mirror and learning about itself.
Atthefirsttimepointofeachtrial,thebeliefsonbothlevelsofthehierarchyarethesamedue
tothealmostone-to-onemappingofA2.Theagent’sbehaviourdiffersfrompreviousexperiment
in that it decides to stay at the video until trial 3. Only after a much longer time—when its
priors have loosened enough—it tries out the mirror again. When this happens (in trial 4) we
observe again a reconfirmation of its belief of being sad. This is accompanied by the same drop
in valence once it realizes it wasn’t the best action to go to the mirror. When going back to the
video the agent has the chance to pick up on the change of its true state. However, it misses it
because it keeps its prior belief of being sad extended through time.
4 Discussion
The experiments showed a possible self-recognition process where the agent gets insight into its
own generative model due to observations about itself made available through the mirror. The
valence of the agent was coupled to this observation being surprising or not. The results show,
how the valence changes and how the agents favoured actions change as a result of a change in
valence.Thus,modellingmirrorself-recognitionasaninternalshiftofattentionshowshownega-
tiveandpositivevalenceplausiblyarises.Themirrorself-recognitionprovidestheagentwithnew
self-knowledge, which can be used by deeper levels in the hierarchy to perform further inference.
For example, changing precision estimates, thereby possibly favouring different actions, which
in turn results in a change in action-based valence. We do not model how self-knowledge first
arises, but what can be shown here is that negative valence arises in self-recognition processes
Title Suppressed Due to Excessive Length 9
that yield insights about oneself, which change the best available action. The negative valence
is not directly dependent on the agent feeling sad or happy (its emotional states that the agents
tries to infer), but rather about the (accurate) knowledge the agent has about these states. It
is important to highlight that emotion is a more complex phenomenon that is likely constituted
by many more dimensions than just valence [8]. Therefore, this computational model only offers
thefirststeps,namelytryingtoaccountforthevalencedpartofmirrorself-recognition.Besides,
onlyusingacategoricalattentioninternalstateisastrongsimplificationofthereflectionofone’s
physical appearance for visual-kinesthetic matching as shown by [16,14]. Mirror self-recognition
in humans may additionally involve further internal attentional dynamics.
Meta-awareness. The capacity of meta-awareness allows an agent to change the strength with
whichoneisawareofoneself.Fromdreamingtobeingawake,frombeinglostinthoughttopaying
attention, humans in full possession of a self-concept do it all the time. The model behaviour in
experiment 2 (Fig. 4) shows how meta-awareness is important to explain mirror avoidance and
engagement behaviour. Being highly aware of a negative state of self an agent can anticipate an
unsettling mirror encounter and prefers to avoid the mirror. Although at the cost of potentially
missing a change in its true state. Given the limitations of the model, these statements are
speculative.Byexpandingthemodelinfutureresearchonecanpotentiallyaddressopenquestions
suchasmirroravoidanceandmodellingmirrorsintherapy[9].Airingonthesideofcaution,even
iftheproposedcomputationalmodelheredoesnotsimulateself-awareness,itcanbeusedtopose
interestingquestionsaboutactiondependentaffectinmirrorself-recognitionforfuturework.For
examplewhataretheactionsavailabletoaninfantrecognizingitselfinthemirror?Isitsnegative
affect resulting from suddenly being suspect of its usual policy of playful engagement with the
other in the mirror? Or is it a feeling of alienation? If one prefers to interpret the negative affect
asafeelingofalienationonecouldarguetoexpandthemodeltoincludementalactions.Planning
on the second level (mental actions) could have its own confidence and valence associated with
them. Actions on this (or even higher levels) could answer more existential questions such as
what kind of person should I be? How do others see me? Tracking the expected confidence in
one’smentalactionsmightbeaninterestingchoicetomodelmorecomplexemotionssuchasthe
feeling of alienation. It could be interesting to design clever mirror tests, that involve different
action affordances to test different stages of self-awareness more specifically.
5 Conclusion
This thesis proposes an affective self-recognition model based on the formalization of action
dependent valence, using hierarchical active inference. As a proof of concept, we have shown
howasyntheticaffectiveresponsetowardsone’smirrorimagemightarise.Theresultsshowthat
mirror self-recognition provides the agent with new information, which changes the favoured
strategy and hence leads to negative valence. Secondly, the results show how an active inference
agent with high meta-awareness of a negative evaluated state of self displays mirror avoidance
behaviour.Thereforeemphasizingtheimportanceofdeeperhierarchicallayers,regardedasmeta-
cognition and meta-awareness, to explain more complex behaviours seen when facing the MSR
test.
References
1. Amsterdam,B.:Mirrorself-imagereactionsbeforeagetwo5(4),297–305(1972).https://doi.org/
10.1002/dev.420050403
10 J. Bauermeister and P. Lanillos
2. Anderson,J.R.,Gallup,G.G.:Whichprimatesrecognizethemselvesinmirrors?PLoSBiology9(3),
e1001024 (mar 2011). https://doi.org/10.1371/journal.pbio.1001024
3. Bard, K.A., Todd, B.K., Bernier, C., Love, J., Leavens, D.A.: Self-awareness in human and chim-
panzee infants: What is measured and what is meant by the mark and mirror test? 9(2), 191–219
(mar 2006). https://doi.org/10.1207/s15327078in0902_6
4. Broesch, T., Callaghan, T., Henrich, J., Murphy, C., Rochat, P.: Cultural variations in children’s
mirrorself-recognition42(6),1018–1029(sep2010).https://doi.org/10.1177/0022022110381114
5. Costa, L.D., Parr, T., Sajid, N., Veselic, S., Neacsu, V., Friston, K.: Active inference on discrete
state-spaces: A synthesis. Journal of Mathematical Psychology 99, 102447 (dec 2020). https://
doi.org/10.1016/j.jmp.2020.102447
6. Deane, G.: Dissolving the self. Philosophy and the Mind Sciences 1(I), 1–27 (mar 2020). https:
//doi.org/10.33735/phimisci.2020.i.39
7. Deane, G.: Consciousness in active inference: Deep self-models, other minds, and the challenge of
psychedelic-induced ego-dissolution. Neuroscience of Consciousness 2021(2) (2021). https://doi.
org/10.1093/nc/niab024
8. Fontaine, J.R., Scherer, K.R., Roesch, E.B., Ellsworth, P.C.: The world of emotions is not two-
dimensional. Psychological Science 18(12), 1050–1057 (dec 2007). https://doi.org/10.1111/j.
1467-9280.2007.02024.x
9. Freysteinson, W.M.: Demystifying the mirror taboo: A neurocognitive model of viewing self in the
mirror. Nursing Inquiry 27(4) (mar 2020). https://doi.org/10.1111/nin.12351
10. Freysteinson, W.M., Deutsch, A.S., Lewis, C., Sisk, A., Wuest, L., Cesario, S.K.: The experience
of viewing oneself in the mirror after a mastectomy. Oncology Nursing Forum 39(4), 361–369 (jun
2012). https://doi.org/10.1188/12.onf.361-369
11. Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., Pezzulo, G.: Active inference: A process
theory. Neural Computation 29(1), 1–49 (jan 2017). https://doi.org/10.1162/neco_a_00912
12. Gallup, G.G.: Chimpanzees: self-recognition. Science 167(3914), 86–87 (1970)
13. Hesp, C., Smith, R., Parr, T., Allen, M., Friston, K.J., Ramstead, M.J.D.: Deeply felt affect: The
emergenceofvalenceindeepactiveinference.NeuralComputation33(2),398–446(feb2021).https:
//doi.org/10.1162/neco_a_01341
14. Hoffmann, M., Wang, S., Outrata, V., Alzueta, E., Lanillos, P.: Robot in the mirror: Toward an
embodied computational model of mirror self-recognition. KI - Künstliche Intelligenz 35(1), 37–51
(2021). https://doi.org/10.1007/s13218-020-00701-7
15. Lanillos,P.,Dean-Leon,E.,Cheng,G.:Enactiveself:astudyofengineeringperspectivestoobtainthe
sensorimotor self through enaction. In: 2017 Joint IEEE International Conference on Development
and Learning and Epigenetic Robotics (ICDL-EpiRob). pp. 72–78. IEEE (2017)
16. Lanillos,P.,Pages,J.,Cheng,G.:Robotself/otherdistinction:activeinferencemeetsneuralnetworks
learning in a mirror (Apr 2020)
17. Parr, T., Markovic, D., Kiebel, S.J., Friston, K.J.: Neuronal message passing using mean-field,
bethe,andmarginalapproximations.ScientificReports9(1)(feb2019).https://doi.org/10.1038/
s41598-018-38246-3
18. Rochat, P.: Five levels of self-awareness as they unfold early in life. Consciousness and Cognition
12(4), 717–731 (dec 2003). https://doi.org/10.1016/s1053-8100(03)00081-3
19. Rochat,P.,Broesch,T.,Jayne,K.:Socialawarenessandearlyself-recognition21(3),1491–1497(sep
2012). https://doi.org/10.1016/j.concog.2012.04.007
20. Sandved-Smith, L., Hesp, C., Mattout, J., Friston, K., Lutz, A., Ramstead, M.J.D.: Towards a
computational phenomenology of mental action: modelling meta-awareness and attentional control
with deep parametric active inference. Neuroscience of Consciousness 2021(1) (aug 2021). https:
//doi.org/10.1093/nc/niab018
21. Smith,R.,Friston, K.,Whyte,C.:Astep-by-step tutorialonactiveinference anditsapplicationto
empirical data (jan 2021). https://doi.org/10.31234/osf.io/b4jm6
Title Suppressed Due to Excessive Length 11
Appendix
Discrete Hierarchical Active Inference
Fig.5. A generative model of one trial with three time steps. Rectangles correspond to categorical
distributions and circles to the random variables the agent wants to learn (here hidden states and
policies).AisthelikelihoodthatdefineshowlikelyobservationsaregiventhestateP(o |s ).Bencodes
τ τ
the probability of moving from one state into the next one P(s |s ,π) given the policy π. C is a
τ+1 τ
vector or matrix that encodes which observations the agent prefers. D gives the prior at the first time
stepinthetrialtoperformBayesianinference.Gistheexpectedfreeenergy.Thebestpolicyistheone
that minimizes G (future reward + information gain) and F (current perceptual evidence or prediction
error). F is also calculated for each policy meaning that the agent has a posterior state estimate for all
possible policies. Lastly, E sets a ‘habitual’ prior for policies in case G is uninformative. Note that the
pastmessagelnB s atthefirsttimepointbecomesthepriorlnD andatthelasttimepointthe
πτ−1 τ−1
future message becomes ones (hence uninformative). Finally, the actual observation is marked with a
bar o in contrast to the predictive posterior over observations o. Figure adapted from [13].
Figure5showsagenerativemodelusedfordiscretehierarchicalactiveinference.Theagent’s
hidden state is s , where τ indexes the time step. At each step, the agent gets an observation
τ
from the environment o . Following active inference simplified notation [5] we will use capital
τ
letters to define the probabilistic functions. The agent has a prior belief D about hidden states
s ,alikelihoodmappingAbetweenstatesandobservations(P(o |s )),andatransitionsmatrix
τ τ τ
Bthatencodeshowstatesevolveovertimedependingonthepolicyπ (P(s |s ,π)).Theagent
τ+1 τ
12 J. Bauermeister and P. Lanillos
can invert the generative model to perform Bayesian inference and get from an observation to a
posterioroverhiddenstates(inactiveinferencethisinferenceprocessisequatedwithperception).
To encode the intention or goal, the agent has preferred observations defined by the matrix
C. By minimizing the expected free energy the agent chooses a policy that changes the hidden
states such that they are likely to produce preferred observations (and minimize overall percep-
tual ambiguity). The action model G uses those preferences to track how well each policy π is
expected to achieve this goal.
To understand the computations we will describe an agent that performs a trial with three
time steps, meaning it has three observations τ = {1,2,3}, as described in Fig. 5. Here an ac-
tual observation is denoted with a bar o in contrast to the probability distribution of expected
observations o. From the first observation the agent infers the posterior hidden state s at time
τ
instant τ =0 through Bayesian inference, via the likelihood matrix A2 and the prior D:
s =lnA·o +lnD
τ τ
Note that we almost get classical Bayesian inference (likelihood multiplied by the prior), but
withoutnormalizingbytheevidenceterm(themultiplicationturnsintoadditionduetoworking
in logarithmic space). The evidence term is mostly intractable in larger models. So to compute
the full posterior, we can alternatively minimize the variational free energy bound instead [11].
This free energy formulation in discrete state space boils down to the difference in the belief the
agent has about the world before (prior s ) and after (posterior s ) an observation.
τ τ
F =s −s
τ τ
In other words, the free energy encodes the prediction error. If the prior belief matches or is
supported by the observation the free energy is low. In contrast to a surprising observation that
renders the prior belief less likely and therefore increases F. The agent can predict observations
with the generative model and the belief about hidden states. It evaluates these predictions by
how well they compare to the actual evidence, by calculating F. Then the agent can iteratively
makepredictionsthatwilldecreaseFandhenceleadtomoreaccurateestimatesofhiddenstates.
We have described how the agent updates its belief s about the world by trying to minimize
τ
prediction errors, therefore getting good at expecting what is really out there. Next, the agent
also computes the expected observations to optimize not only for the current time point but for
the whole trial. Under each policy or plan of actions π the agent can evaluate, how likely certain
observations are in the future. Additionally, it can consider how ambiguous possible future ob-
servations are. Both, information gain and preferred observations, are described in the expected
free energy G:
(cid:80)
G= (o ·(lno −C)−diag(A·lnA)·s )
τ τ τ τ
The first part of the equation is the average difference in expected observations o and preferred
τ
outcomesCoveralltimepoints.Thesecondpartrelatestothemodelentropyorhowprecisethe
distribution is from which the expected observations are sampled. For each state at time τ there
is a likelihood A that can give the agent more or less certainty about what outcome to expect.
To sum up, the agent minimizes F to optimize the posterior belief about states (estimation)
and minimizes G to compute which policy to choose (action). Lastly, marginal message passing
2 Using the discrete space formulation of active inference in matrix form this is computed by selecting
the right column of the matrix A, i.e., through a one-hot observational vector.
Title Suppressed Due to Excessive Length 13
isjustamathematicalwayofsendinginformationacrosstime.Forexample,iftheagentalready
knows which policy it is likely to take after seeing the first observation then that knowledge
can, through marginal message passing, already inform its prior at the next time point in the
trial. Vice versa the agent can update past beliefs, based on new observations which later can
be helpful for learning. This leaves us with the final equations for posterior state estimation
including future and past messages (using the transition matrix B) and the average free energy
over timepoints in one trial:
s =σ(lnB s +lnA·o +lnB s ) (1)
τ τ−1 τ−1 τ τ τ+1
(cid:88)
F = s ·(s −s ) (2)
τ τ τ
τ
Whereσ isasoftmaxfunctionthatnormalizestheinputvectorsuchthatitsumsto1andforms
a proper probability distribution. The G and these two equations defined as shown in Fig. 5,
describe the agents’ basis to act in the world within a given trial. A limitation of this scheme
is the static nature of the prior D at the beginning of each trial. It would be preferable that
the agent can update/learn its prior based on the information it gathered in a trial. To make
the context in which the agent navigates learnable one can expand the generative model with
a deep temporal layer [11]. This allows the agent to form abstract and contextual beliefs that
carry across trials—as described in the next subsection.
Affective self-recognition model implementation details
This section provides details about the generative model. Simulations were run by extending
the pymdp infer-actively framework on github. The inference process of state estimation and
policy selection on the first layer has been calculated using the pymdp framework. Inference
on the second level, via ascending and descending messages was programmed for this setup. A
commented code is available on github via this link.
First Layer
ThepriorsonthestatefactorsarespecifiedintheDmatrix.Forthestatefactor’Location’(Mir-
ror, Wall, Video) the prior is uniform. The state factor ’Other emotional state’ (Happy, Neutral,
Sad, Null), which can be inferred via the observations (Smile, Neutral, Frown, None) also has
a uniform prior. The prior on ’Self emotional state’ depends on the starting condition and the
secondlayer.Lastly,thestate’Mirror-controlledattention’(don’tattend,attend)issetondon’t
attend:
P(SMC−Attention)=[0.99, 0.01]
τ0
For each observation, there is a likelihood tensor A . The first observation is exteroceptive
1−3
(Smile, Neutral, Frown, None), the second interoceptive (Smile, Neutral, Frown) and the third
an observation about the location (which ensures the agent always knows where she is). The di-
mensionsofthelikelihoodsaretheobservationandallthehiddenstatefactors,i.e:A[Observation,
Location,Other,Self,Attention]orA [4,3,3,3,2].Forexample,ifIwanttoindexthelikelihood
1
of my exteroceptive observation given that I am looking at the wall:
14 J. Bauermeister and P. Lanillos
P(O |SLocation =Wall,SSelf,SOther,SMC−Attention)=
ex
for i,j in 0:2, k in 0:1
 
0.01 Smile
0.01 Neutral
A 1 [:,1,i,j,k]= 0.01 Frown  
0.97 None
Basically saying the agent knows her probability of seeing ’None’ if she is at the wall is 0.97,
independentofalltheotherstatessheisin.Iftheagentisinthe’attend’statesheisattendingto
herself and therefore can only relate the information of the exteroceptive observation to herself.
This has to be defined for all states, but effectively the agent only makes use of this attention
when she is in front of the mirror and the exteroceptive observation in fact relates to her:
P(O |SMC−Attention =attend,SSelf,SLocation)=
ex
for l,i in 0:3 :
 
0.97 0.01 0.01 Smile
0.01 0.97 0.01 Neutral
A 1 [:,l,i,:,0]= 0.01 0.01 0.97 Frown  
0.01 0.01 0.01 None
Here the columns stand for the different states in the state factor ’Self emotional state’ (Happy,
Neutral,Sad).Iftheagentisnotpayingattentionwegetthesamematrix,butthistimerelating
to the state of the other.
P(O |SMC−Attention =don’t attend,SLocation,SOther)=
ex
for l,j in 0:3 :
 
0.97 0.01 0.01 Smile
0.01 0.97 0.01 Neutral
A 1 [:,l,:,j,1]= 0.01 0.01 0.97 Frown  
0.01 0.01 0.01 None
Now for the interoceptive observation, the precision on A will depend on the state of at-
tention the agent is in. Therefore one can push A through a softmax with a precision (inverse
temperature) parameter c.
P(O |SMC−Attention,SLocation,SOther)=
in
for l,i in 0:3 and k in 0:1 :
 
0.97 0.01 0.01, c Smile
A
2
[:,l,i,:,0]=0.01 0.97 0.01, c Neutral
0.01 0.01 0.97, c Frown
Where paying attention has c = 5 and not paying attention c = 0.001. Finally, the location
observation is a 1 to 1 mapping:
P(O |SMC−Attention,SSelf,SOther)=
loc
 
1 0 0 Mirror
A 3 [:,l,i,:,0]=0 1 0 Wall 
0 0 1 Video
Next the transition matrices B need to be defined. The rows correspond to the state in the
Title Suppressed Due to Excessive Length 15
next time step and columns the state in the current time step. The transition for the location
depends on the action chosen and the agent knows with certainty where she will be next. The
agent also knows that her attention state will shift to focused when she goes to the mirror and
unfocused going to the video. The agent has a bit of uncertainty around how her own emotional
stateischangingintimeandabitmoreuncertaintyabouthowthestateoftheotherischanging.
P(SSelf|SSelf)=
τ+1 τ
 
0.95 0.05 0.05
B
1
[:,:,0]=0.05 0.95 0.05
0.05 0.05 0.95
P(SOther|SOther)=
τ+1 τ
 
0.8 0.1 0.1
B
2
[:,:,0]=0.1 0.8 0.1
0.1 0.1 0.8
The preference are set with the C matrix. For all observation modalities C will be initiated
with zeros. Then the preference to see self happy or neutral can be encoded as:
C [0]=3.0
1
C [1]=3.0
1
The description of the first layer concludes with the policies available to the agent. They are
any combination of going to a location that is possible within a trial. The trials consist of three
observations and 2 actions. The agent starts by sampling an observation then decides where to
go, and repeats this step. After the final observation, the agent doesn’t need to go anywhere
because the trial is over and will start again from the beginning.
Second Layer
The A and B matrix for the Valence state are the same as in [13]:
(cid:18) (cid:19)
0.97 0.3
A2 [:,:]=
valence 0.3 0.97
(cid:18) (cid:19)
0.8 0.3
B2 [:,:]=
valence 0.2 0.7
ForthestateS2Faceor’Mood’,theA2matrixcanagainbechangedwithaprecisionparam-
eter c. This one is set manually to simulate meta-awareness. In my simulation high means c = 5
and low c = 1.
(cid:18) (cid:19)
1 0, c
A2 [:,:]=
Face 0 1, c
16 J. Bauermeister and P. Lanillos
 
1 0 0
B2 Face [:,:]=0 1 0 
0 0 1
This concludes the description of the two-layered generative model.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "The Role of Valence and Meta-awareness in Mirror Self-recognition Using Hierarchical Active Inference"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
