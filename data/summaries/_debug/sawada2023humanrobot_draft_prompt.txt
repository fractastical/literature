=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Human-Robot Kinaesthetic Interaction Based on Free Energy Principle
Citation Key: sawada2023humanrobot
Authors: Hiroki Sawada, Wataru Ohata, Jun Tani

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Abstract: The current study investigated possible human-robot kinaesthetic interaction using a variational
recurrent neural network model, called PV-RNN, which is based on the free energy principle.
OurpriorroboticstudiesusingPV-RNNshowedthatthenatureofinteractionsbetweentop-down
expectationandbottom-upinferenceisstronglyaffectedbyaparameter,calledthemeta-prior,which
regulatesthecomplexityterminfreeenergy.Thecurrentstudyexamineshowchangingthemeta-prior
w in the interaction phase affects the counter force ...

Key Terms: principle, energy, hirokisawada, robot, prior, wataruohata, interaction, free, human, kinaesthetic

=== FULL PAPER TEXT ===

HUMAN-ROBOT KINAESTHETIC INTERACTION BASED ON FREE
ENERGY PRINCIPLE
HirokiSawada,WataruOhata,JunTani∗
CognitiveNeuroroboticsResearchUnit
OkinawaInstituteofScienceandTechnologyGraduateUniversity
Okinawa,Japan904-0302.
{hiroki.sawada1, wataru.ohata, jun.tani}@oist.jp
ABSTRACT
The current study investigated possible human-robot kinaesthetic interaction using a variational
recurrent neural network model, called PV-RNN, which is based on the free energy principle.
OurpriorroboticstudiesusingPV-RNNshowedthatthenatureofinteractionsbetweentop-down
expectationandbottom-upinferenceisstronglyaffectedbyaparameter,calledthemeta-prior,which
regulatesthecomplexityterminfreeenergy.Thecurrentstudyexamineshowchangingthemeta-prior
w in the interaction phase affects the counter force generated when an experimenter attempts to
inducemovementpatterntransitionsfamiliartotherobotthroughitspriortraining. Thestudyalso
comparesthecounterforcegeneratedwhentrainedtransitionsareinducedbyahumanexperimenter
andwhenuntrainedtransitionsareinduced. Ourexperimentalresultsindicatedthat(1)thehuman
experimenterneedsmore/lessforcetoinducetrainedtransitionswhenwissetwithlarger/smaller
values,(2)thehumanexperimenterneedsmoreforcetoactontherobotwhenheattemptstoinduce
untrainedasopposedtotrainedmovementpatterntransitions. Ouranalysisoftimedevelopment
ofessentialvariablesandvaluesinPV-RNNduringbodilyinteractionclarifiedthemechanismby
whichgapsinactionalintentionsbetweenthehumanexperimenterandtherobotcanbemanifested
asreactionforcesbetweenthem.
Keywords Human-robotkinaestheticinteraction·predictivecoding·activeinference·freeenergyprinciple.
1 Introduction
Studies on social human-robot interaction have attracted considerable attention recently because of their practical
applications,especiallywithusingthelinguisticmodality[1,2,3]. However,investigationofmoredirectinteraction
such as via kinaesthesia should be also indispensable when considering more embodied aspects or enactivism [4]
of human-robot interactions. Although there have been a reasonable number of practical studies on human-robot
interactionusingkinaesthesia,whichhavecontributedgreatlytohuman-robotjointcollaboration,humanassistance,
anduserinterface[5,6,7],fewstudieshaveattemptedtounderstandessentialmechanismsunderlyingkinaesthetic
interactioninlightofembodiedcognition,socialcognition,andsystem-levelneuroscience.
Inthisregard,thecurrentstudyinvestigatedhuman-robotkinaestheticinteractionbyapplyingsystemneuroscience
theory,thefreeenergyprinciple,proposedbyFriston[8]whichisconsonantwithenactivism[9,10]. Letusconsidera
situationinwhicharobotandahumandance,holdingeachotherwithbothhands,executingmemorizeddancepatterns.
Iftherobotinitiatesaparticularpatternfrommemorywithstrongintention,thehumancounterpartmightfollowit
withoutresistingbecauseofthestrongcounterforce. Ontheotherhand,iftherobotgeneratesapatternwithoutstrong
intention,thehumancounterpartmightbeabletoshifttoadifferentpatternwithoutexperiencingstrongcounterforce.
Letusconsideranothersituation. Ifthehumancounterpartattemptstoinduceamovementpatternthatisfamiliartothe
robot,suchguidanceshouldproceedeasilywithoutstrongcounterforce,sincetherobotcaninfertheintendedpattern
immediatelyandcanmoveasanticipated. Ontheotherhand,ifthehumancounterpartattemptstoinduceamovement
patternunfamiliartotherobot,suchguidanceshouldexperiencestrongcounterforce,sincethemovementisneither
inferentialnorpredictablefortherobot.
3202
raM
72
]OR.sc[
1v31251.3032:viXra
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Wepresumethatthesesituationscanbewellexplainedbypredictivecoding[11]andactiveinference[12,13,14],
basedonthefreeenergyprinciple[8]. Predictivecodingprovidesatheoryinwhichperceptionisachievedbyinferring
hiddencausesforsensoryobservationsthatminimizetheerrorbetweentop-downpredictionofsensationmadebythe
generativemodelandtheactualsensation. Ontheotherhand,activeinferenceprovidesatheoryforactiongeneration
inwhichanoptimalactionisinferredtominimizetheerrorbetweenthepreferredsensationandtheactualsensation
resultingfromtheaction. Thesetwoarenotseparate,butintegratedthroughasensorimotorloopinembodiedcognition
inwhichaperceptualinferenceandactiongenerationcanbeachievedsimultaneouslybyminimisingerrorsthrough
iterativeinteractionbetweenthetop-downpredictive/generativeprocessandthebottom-upinference. Alsoinsocial
embodiedcognition,thedynamicinteractionbetweenthetop-downpathwayforpredictingwhileactingontheothers
andthebottom-uppathwayforinferringtheactionalintentionofthecounterpartthroughsensoryobservationshould
becomeacrucialelement. Accordingly,wepresumethatdifferentinteractionsinthedanceappear,dependingonthe
balancebetweenthestrengthofthetop-downpathwayandthatofthebottom-uppathway.
Recently,thenumberofstudiesaddressingapplicationoffreeenergyprincipleincognitiveroboticshasincreased
[15,16,17]. Masellietal. [18]showedthattheactiveinferencemodelisabletocharacterisemovementsgenerated
bytheagent’sintentiontoresolvemulti-sensoryconflictortoachieveanexternalgoal,suchasreachingwithitsarm
toacertainpointwiththeagenthavingaVR-visionofitsarmthatwastiltedfromtheactualpositiontoconfusethe
agent. Tschantzetal. [19]presentedaworkingimplementationofactiveinferencetoreinforcementlearning that
demonstratedefficientexplorationandanorderofmagnitudehighersampleefficiencyinahigh-dimensionaltask,such
asamountain-carenvironment. Also,Pezzatoetal. [20],showedthatarobotictask,suchasreactiveactionplanning
canbeformulatedasafreeenergyminimisationproblembyintroducingahybridcombinationofactiveinferenceand
behaviourtrees. However,studiesinvestigatinghuman-robotinteractionusingthefreeenergyprincipleremainfewin
number.
Theauthor’sgrouphasconductedneuroroboticstudiesrelatedtoframeworksofpredictivecodingandactiveinference
todevelopvarioustypesofrecurrentneuralnetwork(RNN)models[21]. However,anessentialprobleminthesestudies
isthatRNNmodelshavedifficultyindealingwithprobabilisticpropertieshiddenininteractionsbetweenrobotsand
environments. Totacklethisproblem,ourgroupdevelopedaprobabilisticvariationalRNNmodel,calledPV-RNN
[22],basedonthefreeenergyprinciple.
AnindispensablefeatureofPV-RNNisthatfreeenergyiscomputedasasumofthenegativeaccuracytermandthe
complexityterm,weightedbyaparameterw,calledthemeta-prior. Herethecomplexitytermrepresentsthedivergence
betweentheapproximatedposteriorprobabilitydistributionandthepriorprobabilitydistributioninprobabilisticlatent
variablesallocatedinPV-RNN.Moreintuitively,thecomplexitytermcanbeunderstoodastheinternalgapbetween
top-downexpectationandbottom-upsensoryreality. Themodelcanlearntoextractprobabilisticstructureshiddenin
dataeitherbyembeddingtheminnonlinear,deterministicdynamicsofchaosbysettingalargevalueofthemeta-prior
worintostochasticprocessesbysettingasmallw[22].
By following the above study, Chame et al. [23] conducted a human-robot bodily interaction experiment using a
PV-RNN model and attempted to show possible effects of w on the interaction dynamics. However, this study is
consideredpreliminarybecauseonlysomesnapshotsoftheexperimentswereshownandnorigorousanalysisofthe
experimentalresultswasmade. Wirkuttisetal. [24]performedsimulationstudiesonsynchronizedimitativeinteraction
ofdyadicrobotsusingaPV-RNNmodelinwhichrobotsobservedthesensationofsimplifiedvisionandproprioception,
butwithoutkinaesthesis. Throughstatisticalanalysisofrepeatedsimulationexperiments,thesestudiesshowthata
robotwithalargerwinboththelearningphaseandthetestphasetendstoleadthecounterpartrobotsetwithsmallerw
byprojectingstrongeractionalintentiontothecounterpart.
Thecurrentstudyexaminedhuman-robotkinaestheticinteractionbyimplementingaPV-RNNmodelinarealhumanoid
robot. In particular, the study attempted to translate top-down intention or prior belief, formulated using the free
energyprincipletotheforcebodilyexertedonthecounterpartbyconductingstatisticalanalysisondataobtainedfrom
repeatedexperiments. Inthisexperiment, ahumanoidrobotcontrolledbyaPV-RNNmodelistrainedtogenerate
movementpatternswithspecifictransitionprobabilitydistributionsamongthem. Afterthetrainingphase,twotypes
of human-robot kinaesthetic interaction experiments were conducted. In the first experiment, while the robot was
generatingtrainedpatterns,ahumanexperimentertriedtophysicallyinduceasetoftrainedfamiliarmovementpattern
transitionintherobot. Weexaminedhowtherobot’srigidityintermsofthecounterforceinitsresponsechanged
dependingonw,whichwassetduringtheinteractionphase. Thesecondexperimentcomparedthecounterforceduring
responsesinthesetwocases,i.e.,whentheexperimenterinducedtherobottoproceedwithlearnedmovementpattern
transitionsandwhentheexperimenterinitiatedpreviouslyunlearnedpatterntransitions.
Ourintensiveanalysisoftime-developmentofthelatentvariables,complexityterm,andpredictionerrorobserved
intheseexperimentsunderdifferentconditionsclarifieshowbodilyinteractionbetweenanexperimenterandarobot
2
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
proceeds and what sorts of neural activities are generated through top-down and bottom-up interactions during an
experimentaltask.
2 Model
2.1 FreeEnergyPrinciple
AsmentionedintheIntroduction,thecurrentstudyusedPV-RNN,basedonthefreeenergyprinciple,asthebasic
model. Thefreeenergyprincipleassumesthatbrainslearnaswellasinferredforgivenobservations,byminimizing
freeenergy,definedinEq. 1.
F =D [q (z|X)(cid:107)p (z)]−E [logp (X|z)],
(cid:124)
KL φ
(cid:123)(cid:122)
θ
(cid:125) (cid:124)
qφ(z|X)
(cid:123)(cid:122)
θ
(cid:125) (1)
complexity accuracy
p (X|z)isthelikelihoodofthesensoryobservationX,giventheprobabilisticlatentvariableszwhichisparameterized
θ
byθ. q (z|X)istheinferencemodelparameterisedbyφ. AsshowninEq. 1,freeenergyconsistsoftwoterms. The
φ
firsttermindicatesthecomplexity,whichisthedivergencebetweentheapproximateposteriorprobabilitydistribution
andpriorprobabilitydistributionforthelatentvariablez,andthesecondtermistheaccuracyinpredictingthesensory
observation.
2.2 PV-RNNimplementation
PV-RNNisoperatedintwodistinctphases,atrainingphaseandaninteractionphase. Inthetrainingphase,weprepared
adataset(jointanglesequencesoftherobot)andtrainedthePV-RNNmodelusingit. Intheinteractionphase,therobot
andthehumanexperimenterinteractphysically,suchthatthePV-RNNattemptstodrivetherobot’sarmsbypredicting
next-time-steptargetjointangleswhileitinferslatentvariablesusingactualjointanglereadings. Eachoperationphase
isexplainedindetailbelow.
2.2.1 TrainingPhase
First, westartwithcomputationduringthetrainingphase. Theevidence-freeenergyFtrain asalossfunctionfor
trainingthePV-RNNwiththejointangleobservationfromtimestep1toT isshowninEq.2(theexactderivation
shouldreferto[25]).
Ftrain =β×D [q (z |d ,X )(cid:107)p (z )]
KL φ 1 0 1 θ 1
(cid:124) (cid:123)(cid:122) (cid:125)
complexity
T−1
+w× (cid:88) E (cid:2) D [q (z |d ,X )(cid:107)p (z |d )] (cid:3)
qφ(z1:t|dt,Xt:T+1) KL φ t+1 t t+1:T+1 θ t+1 t
t=1
(2)
(cid:124) (cid:123)(cid:122) (cid:125)
complexity
T
(cid:88)
− E [lnp (X |d )],
qφ(z1:t−1|dt−1,Xt:T) θ t t
t=1
(cid:124) (cid:123)(cid:122) (cid:125)
accuracy
where q(φ) and p(θ) are the inference model parameterised by φ and the generative model parameterised by θ,
respectively.
AsshowninEq.2,themeta-priorwweightsthecomplexityterm,exceptfortheinitialstep. Asdescribedpreviously,
thesettingofmeta-priorinthetrainingphasestronglyaffectsbehaviouralcharacteristicsofthetrainednetwork. Prior
studies[25,24]showedthatanetworktrainedwithalargerwdevelopshigherprecision,i.e.,smallerstandarddeviation,
inthepriordistribution,whereasasmallerwdevelopslowerprecisionintheprior. Moreorlessprecisionintheprior
meansstrongerorweakertop-downbelief,respecyively. PV-RNNiscomposedoftwovariablesd,z;inwhichthe
formerisadeterministiclatentvariable,andthelatterisarandomlatentvariablesampledfromaGaussiandistribution.
DuringforwardcomputationofPV-RNN,dinlayerl(l=1isthebottomlayer,whichisclosesttotheoutputlayer)at
timesteptiscomputedas,
(cid:18) (cid:19) (cid:18) (cid:19)
1 1
hl = 1− hl + Wll dl +Wll zl +Wll+1dl+1+b ,
t τl t−1 τl dd t−1 zd t dd t h (3)
dl =tanh(hl).
t t
3
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Here,hl denotestheinternalstateofdl beforetheactivationfunctiontanhisapplied,andb denotesthebiastermof
t t h
h. τl isatimeconstantuniquetoeachlayer,whichencouragesthenetworktoprocessinformationbyfollowingan
intrinsictimescaleofthelayer[26,27,28,29]. MatricesW andW expressintra-andinter-layerconnectivity
dd zd
weightsinthenetwork,respectively. Att=1,theinputtohinthetoplayeriscalculatedonlyfromzl andb .
1 h
Eachdimensionofzpissampledoverthepriordistribution,whichisaGaussiandistributionofmeanµµµpandstandard
t t
deviationσσσpindividually. Att=1,zpissampledfromastandardnormaldistribution,andzpforthefollowingtime
t 1 t
stepsiscomputedby,
µµµp =tanh(Wll d +bp),
t dµ t−1 µ
(4)
σσσp =exp(Wll d +bp),
t dσ t−1 σ
zp =µµµp+σσσp∗(cid:15)(cid:15)(cid:15) , with(cid:15)(cid:15)(cid:15) ∼N(0,I), (5)
t t t t t
where∗indicatestheelement-wiseproductofthetwovectors. Thisequationfollowstheideaoftheconditionalprior
[30]. Here,Wll ,Wll ,bp andbp aretheweightmatricesandthebiastermsforµµµpandσσσp,respectively.(cid:15)(cid:15)(cid:15)isavalue
dµ dσ µ σ t t
sampledfromthestandardnormaldistribution. Inordertomakemodelparametersdifferentiablethroughtherandom
latentvariable,weusethereparametrizationtrick[31]tosamplezp.
t
Ontheotherhand,zq ininferencemodelq issampledfromtheapproximateposteriorprobabilitydistributionq(z )
t φ t
whichisaGaussiandistributionwithmeanµq andstandarddeviationσq whicharecomputedas,
t t
µµµq =tanh(Aµ),
t t
σσσq =exp(Aσ), (6)
t t
zq =µµµq+σσσq∗(cid:15)(cid:15)(cid:15) , with(cid:15)(cid:15)(cid:15) ∼N(0,I)
t t t t t
Aµ,Aσ areadaptivevariableswhichareoptimisedduringtraining. Duringthetrainingphase,z inEq.3issampled
t t t
fromtheapproximateposterior. Ontheotherhand,zpissampledfromthepriordistributiontocomputetheKullback-
t
Leiblerdivergence(KLD)betweentheapproximateposteriorandtheprior,whichisthecomplexitytermoftheloss
functionEq.2.
Theobtainedd1isusedforcomputingtheoutputlayer,ofwhichfunctionis,
t
o =W d1+b , (7)
t o t 0
whereW ,b istheweightmatrixandthebiasoftheoutputlayer,respectively.
o o
Finally,wecomputethepredictedoutputx¯ . Eachdimensionofthepredictedoutputisrepresentedinaprobabilistic
t
distributionusingtheSoftmaxofN elements. Therefore,thej-thsoftmaxelementofthei-thdimensionofthe
soft
predictedoutputx¯i,j iscomputedby,
t
exp(o )
x¯ = t,i,j . (8)
t,i,j (cid:80)Nsoftexp(o
)
j=1 t,i,j
AsshowninEq.2,theevidence-freeenergyF,whichisthelossfunctionofthismodel,isthesumoftheKLDbetween
theapproximateposteriorq(z |x )andpriorp(z |d ),andthenegativelog-likelihoodcalculatedfromtheoutputx¯
t t t t−1 t
andtheperceptionx .
t
Attimestept,theKLDbetweentheapproximateposteriorandpriorisdefinedas,
D [q(z |x )||p(z |d )]= (cid:88) Nz q(zi|x )ln p(z t i|d t−1 ) , (9)
KL t t:T t t−1 t t:T q(zi|x )
i t t:T
where zi is the i-th dimension of z , T is the length of the sequence and N is the dimension of z of each layer.
t t z t
Here,q(z |x )andp(z |d )arebothassumedtofollowmultivariateGaussiandistributionswithdiagonalcovariant
t t t t−1
matrices. Hence, they are expressed with the meanµµµ (= [µ ,µ ,...,µ ]) and the standard deviationσσσ (=
t t,1 t,2 t,Nz t
[σ ,σ ,...,σ )asbelow,
t,1 t,2 t,Nz]
1

1
(cid:32) zi−µq (cid:33)2 
q(z
t
i|x
t:T
)=
(cid:113) 2π(σq )2
exp−
2
t
σ t q ,i
t,i , (10)
t,i
1

1
(cid:32) zi−µp (cid:33)2 
p(z
t
i|d
t−1
)=
(cid:113) 2π(σp )2
exp−
2
t
σ t p ,i
t,i . (11)
t,i
4
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Therefore,theKLDlossr betweentheapproximateposteriorandtheprioriscomputedas,
t
(cid:26)(cid:80) D [q(zi|x )||p(zi|N(0,1))], ift=1,
r = i KL t t t (12)
t (cid:80) D [q(zi|x )||p(zi|d )], otherwise.
i KL t t t t−1
Ontheotherhand,asanequivalentofthenegativelog-likelihoodtermofEq.2,theKLDbetweenthetargetandthe
predictedoutputiscomputed. Asmentionedabove,thepredictedoutputisrepresentedasaprobabilisticdistribution
P(xi|θ)usingSoftmax. ThetargetsequenceisalsotransformedintoaprobabilisticdistributionQ(xi)alongthesame
t t
line[32]. Therefore,theKLDiscomputedas,
e = (cid:88) Nx D [Q(x )||P(x )]= (cid:88) Nx N (cid:88) soft Q(x )ln Q(x t,i,j ) . (13)
t KL t,i t,i t,i,j P(x |θ)
t,i
i i j
Thelossfunctionofourmodelwhichisequivalenttotheevidence-freeenergyFtrain iscomputedastheweighted
sumofEq.12andEq.13. AsshowninEq.2,theKLDbetweentheapproximateposteriorandpriorisregularisedwith
ameta-priorβ fort=1andwfort(cid:54)=1. Here,β istheweightingparameterspecificallyfort=1,whichregulates
theinitialsensitivityofthePV-RNNmodel. Therefore,thelossfunctionofourmodelduringthetrainingphaseis
computedas,
 (cid:16) (cid:17)
F =  (cid:80)T t=1 (cid:16) e t + N N x z βr t (cid:17) , ift=1, (14)
 (cid:80)T t=1 e t + N N x z wtr t , otherwise
where N and N are the x¯ dimension and z dimension in each layer, respectively. T is the length of the dataset
x z
sequence. Thenegativelog-likelihood,whichwedenoteaspredictionerror,e isproportionaltoN andtheKLD
t x
betweentheapproximateposteriorandpriorisproportionaltoN ,undertheassumptionthateachx¯ dimensionand
z
z dimension is independent. Therefore, the meta-prior during the training phase wt is normalised by N and N
x z
sothatitcanbecomparedamongPV-RNNmodelswithdifferentx¯ dimensionandzdimension. Throughtraining,
weightmatrices,biasesandadaptivevariablesAµ,Aσ areupdatedbasedonback-propagationthroughtime(BPTT)
t t
[33,34,35].
2.2.2 Interactionphase
Weperformedahuman-robotreal-timeinteractionintheinteractionphasewherethepre-trainedPV-RNNdrivesthe
robot’smovementbypredictingjointanglesofthenexttimestep. Theforwardcomputationpartremainsthesame
asthatinthetrainingphase. However,therearesomedifferencesinthelossfunctionusedandinwaysofupdating
variables. Unlikethetrainingphase,weightmatricesandbiasesarenotupdated. OnlytheadaptivevariablesAµand
t
Aσ areupdatedsothattheapproximateposteriorcanadapttotheongoingobservationofthejointanglesequence.
t
PV-RNNpredictsthefuturesensationandinferspastlatentvariablesusingthepastwindowspanningfromtime-step
t −t tothecurrenttime-stept withawindowsizet asshowninFig. 1. Theevidence-freeenergyintheinteraction
c w c w
phaseFint,normalizedinthesamewayasEq.14,iscomputedinsidethepastwindowas:
 (cid:16) (cid:17)
Fint =  (cid:80)t t c =tc−tw(cid:16) e t + N N x z βr t (cid:17) , ift=1, (15)
 (cid:80)t t c =tc−tw e t + N N x z wir t , otherwise,
The adaptive variables Aµ and Aσ at each time-step t from t −t to t are modified so as to minimize Fint by
t t c w c
iteratingtheforwardcomputationandtheerrorback-propagationthroughtimeforafixednumberoftimes,called
epochs. Aftermodifyingtheapproximateposteriorbygoingthroughepochsofiteration,next-stepjointanglesare
predictedandfedintothePIDcontrolleroftherobotinordertogenerateitsmovement. Then,thepastwindowis
shiftedonestepahead. wi,whichisthemeta-priorusedintheinteractionphase,couldbesetwithdifferentvaluesfrom
wtusedinthetrainingphase. In[36],asimulationexperimentusingaPV-RNNmodelshowsthatwhenaPV-RNN
trainedwithaparticularwtwasresetwithasmallerwiinthelaterinteractionphase,theapproximateposteriorshifted
awayfromthepriorandthePV-RNNtendedtoadapttotheobservedsensorysequence. Thismeansthattop-down
intentioninthePV-RNNbecameweaker. Ontheotherhand,whenresetwithalargerwi,thePV-RNNtendedtoignore
theobservedsensorysequencebygeneratingitsownintendedpatterns,whichmeansthattop-downintentionbecomes
stronger. However,theprecisionstructureinthepriordoesnotchangeevenaswiischanged,sincethepriordistribution
wasdevelopedinthelearningphase.
5
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Figure1: GraphicalrepresentationoftheinteractionphaseofPV-RNN.d ,zp ,zq ,x andx¯ indicatesthedetermin-
l,t l,t l,t t t
isticlatentvariable,priordistribution,approximateposterior,outputandtargetoflayerlandtime-stept,respectively.
Blueandredarrowsindicateforwardpropagationandbackwardpropagation,respectively. Thefuture,thepastwithin
thewindowandthepastoutsidethewindowarecolouredred,blue,andgreenrespectively. Thepastwindowsizeis2
inthisgraphicalmodel. a)showsthenetworkattime-stept. b)showsthenetworkattime-stept+1.
6
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
2.3 Theemployedrobotcontroller
Thecurrentstudyusesahumanoidrobot,Torobo1 toconducthuman-robotkinestheticinteractionexperiments. Torobo
isequippedwithabuilt-inforce-feedbackcontrollerthatenableshumanstoback-drivejointangleswithsubtleforce. In
theTorobocontrolsystem,whenahumanexertscertaintorqueonjointsbypushingorpullingthelimbsofTorobo,the
exertedtorquecanbeestimatedbysubtractingthetorqueinferredasnecessarytoaccountforthecurrentstaticstateas
wellasadynamicstateoftherobotfromtheactualtorquemeasuredinthejoints. Bycomputingthenexttime-step
jointtargetpositionsbyaddingthecurrentpositionswiththeestimatedexertedtorquemultipliedbyaconstantgainand
feedingtheminthePIDcontroller,Torobo’slimbsmovebyfollowingtheforceexertedonthembythehuman. This
force-feedbackcontrollerisintegratedwiththePV-RNN,whichgeneratesthenexttime-steptargetjointangles(Fig.2).
Figure2: thehumaninteractingwithTorobo,thePV-RNNtargetjointanglegenerator,theinversemodel,andthePID
jointcontroller.
TheoverallcontroldiagramisshowninFig.2, whichincludesahumanexperimenterinteractingwithTorobo, the
PV-RNN target joint angle generator, the inverse model, and the PID joint controller. The inverse model and PID
controllerweredevelopedbythemanufacturerofTorobo. Detailsareasfollows. Excesstorque,τexcwhichistorque
t
exertedonjointsbythehuman,canbeestimatedbyextractingτdynmasthetorqueinferredforthecurrentposition,
t
velocity,andaccelerationofthejointsbyusingtheinversemodelofTorobofromthecurrentmeasuredtorque,τ . Next,
t
excesstorque,τexcisappliedwithathresholdcontrolande asexcesstorqueafterthresholdcontrolisobtained. Then,
t t
e istime-filteredwiththedecayparameter0<α<1,whichgeneratese˜ asthetime-filteredexcesstorque. These
t t
operationsarenecessarytopreventunnecessaryoverreactionofthetorqueestimationagainstnoise. Theselinesof
1Humanoid-robotTorobofromTokyoRobotics:https://robotics.tokyo/products/torobo/
7
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
processesaredescribedinthefollowingmathematicalform:
τexc =τ −τdynm,
t t t
(cid:26) max(0,τexc−τth), ifτext >0,
e = t t
t min(0,τ t exc+τth), otherwise, (16)
(cid:40)
e , fort=1,
t
e˜ = (cid:16) (cid:17)
t max α×e˜ +e ,e , otherwise,
t−1 t max
wheree˜ hasafixedupperlimite .
t max
ThePV-RNNpredictsθ¯ nexttime-stepjointangleswhileperformingtheonlineinference,whichissubtractedbyθ as
t t
thecurrentjointangletogenerate∆θ ,thetargetjointangledifferenceshownas:
t
∆θ =θ¯ −θ (17)
t t t
Finally,∆θ representingthenextmoveintendedbythePV-RNNande˜ representingtheestimateoftorqueexertedby
t t
thehumanaremultipliedbyeachgaink andk ,respectivelyandtheyareaddedtothecurrentjointanglestogenerate
r p
thefinaltargetjointpositions,θ¯,whicharefedintothePIDcontrollerasshowninthefollowing:
t
∗
θ =∆θ ×k +e˜ ×k +θ , (18)
t+1 t r t p t
3 Experiment
3.1 ExperimentSetup
3.1.1 TrainData-SetPreparation
TheproposedPV-RNNmodelwastrainedinasupervisedmannerbypreparing4-dimensionaljointangleteaching
trajectories. Inpreparationforteachingtrajectories,weconsideredfourtypesofcyclicmovementpatterns(20time-
stepsforeachcycle)usingTorobo’sshoulderandelbowjointanglesinbotharms. Then,itwasassumedthatcycling
movementpatternstransitfromonetoanotherfollowingaprobabilisticfinitestatemachine(Fig.3). Forexample,after
amovementpatternAisgeneratedforonecyclewiththestateatS1,Acanbegeneratedforonemorecyclewith90%
probabilitystayingatthesamestate,orBorCcantransittoS2orS3withaprobabilityof3%and7%,respectively. We
B
90 %
B S2 10 % 95 %
D
3 %
A S1 A 5 % S4 D
7 %
C S3 D
90 % 15 %
85 %
C
Figure3: Schematicoftheprobabilisticfinitestatemachinefromwhichtrainingdatawasgenerated.
prepared10sequencesthateachconsistedof200cyclesofmovementpatterns,extending4000time-steps.
3.1.2 TheNetworkConfigurationandTraining
To conduct human-robot dyadic interaction experiments, PV-RNN was trained 3 times with identical parameters
(Table.1). #d,#z,τ,wt,wiindicatesthenumberofdneuronsandzneurons,timeconstant,andmeta-priorduring
thetrainingphaseandinteractionphase,respectively. Thenetworkwastrainedfor50,000epochstominimizethe
evidence-freeenergyshowninEq.2,startingwithrandomweightsgeneratedwithdifferentseedsforeachtraining.
Fig.4showsoneoftheresultanttrainingprocesses. ItcanbeseenthatpredictionerrorandtheKLdivergenceinboth
thetopandthebottomlayersdecreasedthroughouttraining. Allthreetrainingprocessesconvergedinasimilarway,
achievingpredictionerrorsandKL-divergencesshowninTable.2.
8
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Table1: PV-RNNParameters
#d #z τ wt wi
Layer1(Top) 60 6 3 0.01 [0.01,0.05,0.1]
Layer2(Bottom) 30 3 9 0.01 [0.01,0.05,0.1]
Figure4: Resultanttime-developmentfromthetrainingphaseofoneofthePV-RNNmodels. DevelopmentofKLD
withrespecttothenumberoftrainingepochsisshownfor(a)theToplayer(layer2)and(b)theBottomlayer(layer1).
Developmentoftheaveragepredictionerrorovertimestepsineachteachingsequenceisshownin(c).
Table2: TrainingprocessesofallthreePV-RNNmodel
Epoch
Model 2,000 5,000 50,000
1 2.0×10−3 5.4×10−4 4.4×10−5
KLdivergence 2 2.4×10−3 9.1×10−4 5.6×10−5
3 2.5×10−3 7.2×10−4 6.9×10−5
1 1.8×10−2 7.2×10−4 1.4×10−4
Pred. Err. 2 1.4×10−2 6.6×10−3 4.6×10−5
3 1.3×10−2 1.6×10−3 1.4×10−4
9
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
3.1.3 Evaluationofthetrainednetworks
TrainedPV-RNNswereevaluatedonthebasisofhowcloselythestatetransitionprobabilitywasreconstructedcompared
with the target (Fig.3). For this purpose, we conducted Prior Generation in which the forward computation by
followingEq.3-7wasperformedwithoutanyexternalobservationfor40,000time-stepsforeachtrainednetwork. Then,
probabilitiesforallpossiblemovementpatterntransitionsweremeasuredduringpriorgenerationandtheresultingstate
transitionprobabilitywasinferred(Table.3). Thestatetransitionprobabilitycomputedforalltrainednetworksisquite
similartothetargetone. Outputandnetworkdynamicsofmovementpatterntransitionsduringpriorgenerationare
showninAppendix,Fig.8.
Table3: TransitionprobabilitiesofthePriorGenerationanddataset
Model S1→S2 S1→S3 S2→S4 S3→S4 S4→S1
1 2.8% 3.5% 15.6% 12.5% 3.1%
2 2.7% 9.3% 14.1% 11.5% 7.2%
3 3.1% 4.1% 9.8% 12.3% 5.1%
Target 3% 7% 10% 15% 5%
3.1.4 Human-RobotInteraction
Afterthetrainingphase,weconductedtwotypesofhuman-robotinteractionexperimentsusingtrainedPV-RNNs. In
theseexperiments,whileTorobowasgeneratingmovementpatterntransitionssuccessivelybasedonthetraining,the
humanexperimenterattemptedtoinducevariousmovementpatterntransitionsbygraspingbotharmsofToroboand
exertingforceonthem. Thesemovementpatterntransitionsincludedtrainedtransitions(AB,AC,BD,CD,DA)and
untrainedtransitions(AD,DB,DC,BA,CA)inwhichAB,forexample,dictatesthatApatternisforcedtotransittoB
pattern. Eachtransitionfromonepatterntoanotherrequiressomeguidingforcebyahumanexperimenter,evenfor
trainedtransitions,sinceongoingpatternstendtorepeatanothercyclewithhighprobability,morethan85%forall
patterns. Thismeansthatthereexistsomeconflictsbetweenmovementtrajectoriesintendedbytherobotandthoseby
thehumanexperimenterduringbothtrainedanduntrainedtransitions.
Experiment-1examinedtheeffectofwisettingsontheinteractions. WhileTorobowasgeneratingmovementpattern
transitionssuccessivelyfor2,200time-steps,thehumanexperimenterattemptedtoinduceoneofthetrainedtransition
every200time-stepsstartingfromt=200whichresultedin10trainedtransitions. Thedurationofeachattemptlasted
100time-stepsatthemost. ThisexperimentwasconductedthreetimesforallthreetrainedPV-RNNsbychangingwi
with0.01,0.05,and0.1.
Experiment-2examinedthedifferencebetweentrainedanduntrainedtransitionsbysettingwiwithafixedvalue. The
experimentalprocedurewasthesameasinExperiment-1, althoughthistime, wi wasfixedat0.01forbothlayers.
Thisexperiment,usingallthreetrainedPV-RNNs,resultedin30untrainedtransitionattempts. Intheseexperiments,
werecordedthetimedevelopmentofessentialvaluesincludinglatentvariables,predictedandobservedjointangles,
predictionerror,andtheKL-divergenceinbothlayersforlateranalysisofexperimentresults.
3.2 ExperimentResults
Inthissection,weshowtheresultsoftheaforementionedexperiments.
3.2.1 Experiment-1
First,weexaminedtime-developmentofessentialvaluesduringmovementpatterntransitionsinducedbytheexperi-
menterforeachcasewithadifferentmeta-priorsetting. Fig.5showsanexamplesnapshotoffuturepredictionand
pastreflection,whichshiftedevery7time-stepsofthecurrenttimeduringthetransitionABperformedunderdifferent
settingsofmeta-prior, wi = 0.01,0.05,0.1. Eachsnapshotshowsoneoftheobservedjointanglesθ (dottedblue)
anditspredictionθ¯(blue)inthetoprow,theKL-divergencesbetweentheapproximateposteriorandthepriorinthe
layer1(orange)andinthelayer2(darkorange)inthesecondrow,thepredictionerror(green)inthethirdrow,andthe
excesstorque(black)inthebottomrow. Thegreyarearepresentsthepastwindowwheretheapproximateposteriorin
termsofadaptivevariablesAµ,Aσ isupdated. Weprovidetwosupplementaryvideosforexperiment-1showingthe
t t
interactionbetweentheexperimenterandTorobo,aswellasnetworkdynamicsinthecasewiththemeta-priorwi setto
0.01(video-link1)and0.1(video-link2).
10
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Figure5: Time-developmentofexcesstorque,predictionerror,andKL-divergencebetweentheapproximateposterior
andthepriorintrainedmovementtransitionsincaseswiththreedifferentmeta-priorwisettingswith0.01,0.05,and
0.1. Thegreyarearepresentsthepastwindowwheretheheadofthewindowisthecurrenttime. Thewindowisshifted
5timesduringthemovementtransitionAB.
Thesequencesoftime-shiftedsnapshotsinFig.5,showthatexcesstorqueappearsfirstfollowedbyrisesintheprediction
error(negativelog-likelihood)andtheKL-divergence. Later,thepredictedjointanglepatternshiftsfrompatternAtoB
whilethegapbetweentheobservedjointangleandthereconstructedjointangleremainsinthepastwindow. Thisisthe
sameforallthreecaseswithdifferentwisettings.
However,wecanseesomequalitativedifferencesinthetransitionprocessdependingonthewisetting. Theprediction
errorandtheexcesstorqueinthecasewithasmallwi (wi = 0.01)aresmallerthanthoseinthecasewithlargewi
(wi = 0.1). Also,theerrorandtorquewithasmallwi arelesspersistentthanthosewithalargerwi. However,the
KL-divergenceinthecasewithasmallwiislargerandpersistslongerthanthatinthecasewithlargewi. Inorderto
confirmtheseobservations,weconductedstatisticalanalysisontheexcesstorque,KL-divergence,andpredictionerror
time-averagedforeachtransitionperiod(100steps). Thiscomputationwasrepeated10timesforeachofthreedifferent
trainednetworkssetwiththreedifferentwivalues.
TheresultsareshowninFig.6. Boththetime-averagedpredictionerrorandtheexcesstorquemeasuredinthecases
withsmallwiaresignificantlysmallerthanthosewithlargewi. Ontheotherhand,thetime-averagedKL-divergence
withsmallwiissignificantlylargerthanthatwithlargewi.
Byconsideringthesestatisticalresults,movementpatterntransitionsexertedbytheexperimenterrequiregreaterforce
whenwiissetlarger,sincetheapproximateposteriordistributionstronglyfollowsthepriordistributionrepresenting
thecurrentmovementintentionofPV-RNN,minimizingtheKL-divergencebetweenthemwhiletheerror∆θ between
t
thepredictedjointangleθ¯ andtheobservedjointangleθ becomeslarger. Iftheexperimenterattemptstomovethe
t t
trajectoryoftherobot’sjointanglesinadirectiondifferentfromthatpredictedbythePV-RNN,thisrequiresalarge
excesstorquee˜ tocounteractthelargeerror∆θ ,asderivedfromEq. 18.
t t
Ontheotherhand,whenwi issetsmaller,theapproximateposteriorfollowstheprioronlyweakly,allowinglarger
KL-divergencebetweenthemwhilethepredictionerrorbecomessmaller. Inthiscase,onlyasmallamountofexcess
torqueisnecessarytocounteractthesmallerror. Thetop-downactionalintentionoftherobotbecamestrongerinthe
caseoflargerwi settings;therefore,thehumanexperimenterwasrequiredtoexertmoreforceontherobotarmsto
induceatransition,whereaslessforcewasrequiredwithsmallerwisettings,sincethetop-downactionalintentionof
therobotbecameweaker.
11
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Figure6: Time-averagedexcesstorque,predictionerror,andtheKL-divergencebetweentheapproximateposteriorand
thepriorinthetrainedmovementtransitionincaseswiththreedifferentmeta-priorwisettingswith0.01,0.05,and0.1.
Inthecurrentexperiment,thevalueofwiwassetbetween0.01and0.1. Thisisbecauseourpreliminaryexperiments
showedthattherobot’sbehaviourbecamenoisywhenwiwassetsmallerthan0.01,sincetheapproximateposterior
couldeasilydeviatefromthepriorbynoisesampling. Ontheotherhand,itbecamedifficultfortheexperimenterto
initiateatransitionwhenwiwassetlargerthan0.1,becauseofsubstantiallyincreasedresistance.
3.2.2 Experiment-2
Next, we looked at the difference in the excess torque, prediction error, and KL-divergence between trained and
untrainedtransitionswhilewi wasfixedatagivenvalue. Bothtrainedanduntrainedtransitionswereattempted10
timesforeachofthethreetrainednetworkswithwi setto0.01forbothtrainedanduntrainedcases. However,for
theuntrainedcase,among30attempts,only24succeededinperformingatransition. Ourpreliminaryexperiment
showedthattheuntrainedtransitionbecamemoredifficultwhenwi wassethigherthan0.01becauseofthestrong
resistancewhentherobotattemptedtoleadtrainedmovementtransitions. Fig.7showsthetime-averageoftheexcess
torque,predictionerror,andKL-divergenceforbothtrainedanduntrainedtransitionsattemptedbytheexperimenter.
Thetime-averageofthepredictionerror,theexcesstorque,andtheKL-divergencearelargerinuntrainedthantrained
transitions.Thismeansthatuntrainedtransitionsrequiretheexperimentertoexertmoreforcethanfortrainedtransitions
becauseofthefreeenergy,whichisthesumofthepredictionerrorandtheKL-divergence,andwhichincreasesmorein
untrainedtransitions. Weprovidetwosupplementaryvideosforexperiment-2showingtheinteractionbetweenthe
experimenterandToroboaswellasthenetworkdynamicsinthecasewithmeta-priorwi setto0.01,wheretrained
transitions(video-link1)anduntrainedtransitions(video-link3)areperformed.
4 Discussion
The current study investigated human-robot bodily interactions via kinaesthesia using a PV-RNN model that was
developedbasedonthefreeenergyprinciple. Bodilyinteractionsbetweenahumanexperimenterandarobotwere
conductedusingTorobo,ahumanoidrobotequippedwithaPV-RNNmodelthatcansenseexcesstorqueexertedbya
humancounterpart. Weespeciallyexaminedhowthecounterforcebetweentherobotandthehumanexperimenter
12
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Figure 7: The amount of excess torque, prediction error exerted and the KL-divergence between the approximate
posteriorandthepriorcduringeachattemptfortrainedanduntrainedtransitions. Themeta-priorwiwassetto0.01.
changedduringmovementpatterntransitionsphysicallyguidedbythehumanexperimenter,dependingontwodifferent
conditionchanges.
In experiment 1, we examined how the setting of a parameter called the meta-prior wi, which regulates the KL-
divergencebetweentheapproximateposteriordistributionandthepriordistributionintheinteractionphase,affectsthe
counterforcegeneratedinexecutedorattemptedtransitions. Resultsofthisexperimentshowedthatinthecaseofa
smallerwi,whiletheKL-divergencebetweentheapproximateposteriorandthepriordistributionbecomeslarger,the
predictionerror(negativelog-likelihood)becomessmaller. Sincethepredictionerrordiminishes,theexcesstorque
tocounteractthiserroralsodecreases. Ontheotherhand,inthecaseofalargerwisetting,whiletheKL-divergence
betweentheapproximateposteriorandthepriordistributionbecomessmaller,thepredictionerrorbecomeslarger,
whichrequiresmoreexcesstorqueforthetransition. Theconflictthatappearedbetweenthemovementintendedby
therobotandthatexecutedbytheexperimenterisdistributedtothepredictionerrorandtheKL-divergencebetween
theapproximateposteriorandthepriorinproportionsdeterminedbythemeta-priorwi. Withlargerwithetop-down
movementintentionoftherobotbecomesstronger,whichresultsinastrongercounterforce,whereasthetop-down
intentionaswellasthecounterforcebecomeweakerwithsmallerwi.
The above is consistent with past research from our group [37]. In [37], Tani conducted simulation studies on
synchronizedimitativeinteractionbydyadic,vision-basedrobotsusingaPV-RNNmodel. Thatstudyshowedthat
arobotwithsmaller/largerwi tendstofolloworleadtheotherrobotsetwithalargerorsmallerwi withweakeror
strongeractionalintentioninsynchronizedimitativeinteraction. Similarlyinthecurrentstudy,theexperimentereasily
ledtherobotwithasmallerwi withasmallercounterforcebecauseoftheweakertop-downintentionoftherobot.
Ontheotherhand,whenwiisquitelarge,suchas>0.1fortherobot,itwasdifficultfortheexperimentertoleadthe
robotbecauseoftheextremelystrongcounterforce. Inthissituation,theexperimenterjustfollowedmovementpatterns
stronglyledbytherobotwhilegraspingtherobot’shands,asshowninthepreliminaryexperimentdescribedpreviously.
Inexperiment2,weexaminedthedifferenceinthecounterforcerequiredfortheexperimentertoexecutetrainedand
untrainedmovementpatterntransitions. Theseexperimentalresultsshowedthatuntrainedtransitionsrequiremoreforce
sincesuchtransitionsareaccompaniedbylargerincreasesinfreeenergy,theKL-divergence(betweentheapproximate
posteriorandtheprior),andthepredictionerror. Trainedtransitions,ontheotherhand,requirelessforcebecauseof
smallerincreasesinfreeenergy,theKL-divergence,andthepredictionerror.
13
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Asalreadymentioned,therehavebeenfewstudiesofhuman-robotinteractionsbasedonthefreeenergyprinciple.
Although[23]showedthatthesettingofwtasmeta-priorinthetrainingphasecouldstronglyaffectcharacteristicsof
human-robotkinaestheticinteractions,thedescriptionoftheirexperimentresultsdidnotincluderigorousanalysiswith
repeatedexperiments.
The major limitation of the present study is that presented human-robot interactions are not fully interactive since
experimenter-inducedsequencesofmovementpatterntransitionsweredeterminedapriori. Inthisregard,Ikegami
andhiscolleagues[38,39]investigatedunderlyingmechanismsforturn-takingthatweregeneratedbyspontaneous
interactionbetweenartificialagentsaswellasartificialagentsandhumans. Recently,Masumorietal. [40]developeda
humanoidrobotplatform,calledAlter3,behaviourofwhichwascontrolledbysub-modules,includingaself-simulator,
anautomaticmimicryunit, andmemorystorage, whichwereperturbedbyaspecificneurodynamicmodelforthe
purposeofconductingexperimentsonspontaneoushuman-robotinteractions.Theyshowedthatspontaneousturn-taking
betweenimitatorandimitatedcouldbedevelopedbyautonomousswitchingofinformationflowbetweenthetwosides.
Infuturestudies,wewillundertakehuman-robotkinaestheticinteractionexperimentsthatassumelessapriori. Such
experimentsshouldbedonenotwithexperimentersascounterpartsoftherobots(asinthepresentstudy)butbyinviting
anadequatenumberofhumanparticipants,sincethehumansidealsoneedstobeanalyzed. Suchstudieswillfocus
ontworesearchissues. Oneistoinvestigatehowspontaneousturn-takingcanoccurinimitativeinteractionbased
onkinaesthesisbyusingtheactiveinferenceframework[12,14,41]. Spontaneousturn-takinginthissettingmeans
thattheroleoftheleadertoinitiatethenextsharedpatternsswitchesautonomouslybetweenthetwosides,suchthat
sometimestherobotmaypushhardwithitsownintendedpatternsandthehumancounterpartmaydosoatothertimes.
Thisstudymayrequiredevelopmentofanautonomouswiadaptationscheme,sinceifwiontherobotsidecanshift
adaptivelybysensingcontextualflowintheinteraction,theleader-followerrelationshipshouldshiftaccordingly.
Theotherfocusistoinvestigatehownovelmovementpatternscanbedevelopedthroughrepeatedkinaestheticinteraction
associatedwithcontinuouslearninginbothrobotsandhumanparticipants,basedonthefreeenergyprinciple. One
assumptionisthatnovelpatternscoulddevelopintermsoffalsememoryasthenumberofmovementpatternsmemorized
distributivelyinthePV-RNNmodelincreases. Thisphenomenonoffalsememoryisduetopotentialnon-linearityand
stochasticityinthePV-RNNmodel. AstudyonadeterministicRNNmodeldemonstratedthisproperty[42]. Novel
patternsgeneratedbyrobotscouldenhanceimprovisationofnewpatterngenerationfromhumancounterpartsthrough
iterativeinteraction.
PriorGeneration
Here,inFig.8,weshowpartoftheresultfromthepriorgeneration,includingtwotransitions. AsshowninTable1,
sincethenumbersofdneuronsinlayers2and1were30and60,respectively,weperformedprinciplecomponent
analysisandreducedbothdimensionsto3.
References
[1] SergioGuadarrama,LorenzoRiano,DaveGolland,DanielGo,YangqingJia,DanKlein,PieterAbbeel,Trevor
Darrell,etal.Groundingspatialrelationsforhuman-robotinteraction.In2013IEEE/RSJInternationalConference
onIntelligentRobotsandSystems,pages1640–1647.IEEE,2013.
[2] TakayukiKanda,TakayukiHirano,DanielEaton,andHiroshiIshiguro. Interactiverobotsassocialpartnersand
peertutorsforchildren: Afieldtrial. Human–ComputerInteraction,19(1-2):61–84,2004.
[3] Joshua Wainer, Ben Robins, Farshid Amirabdollahian, and Kerstin Dautenhahn. Using the humanoid robot
kaspartoautonomouslyplaytriadicgamesandfacilitatecollaborativeplayamongchildrenwithautism. IEEE
TransactionsonAutonomousMentalDevelopment,6(3):183–199,2014.
[4] FranciscoJVarela,EvanThompson,andEleanorRosch. Theembodiedmind,revisededition: Cognitivescience
andhumanexperience. MITpress,2017.
[5] Shikhar Bahl, Abhinav Gupta, and Deepak Pathak. Human-to-robot imitation in the wild. arXiv preprint
arXiv:2207.09450,2022.
[6] JörgKrüger,TerjeKLien,andAlexanderVerl. Cooperationofhumanandmachinesinassemblylines. CIRP
annals,58(2):628–646,2009.
[7] Luka Peternel, Wansoo Kim, Jan Babicˇ, and Arash Ajoudani. Towards ergonomic control of human-robot
co-manipulation and handover. In 2017 IEEE-RAS 17th International Conference on Humanoid Robotics
(Humanoids),pages55–60.IEEE,2017.
14
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
Figure8: Neuralactivityinpriorgenerationwhileperformingamovementpatterntransition. Thetwocolumnsatthe
leftshowneuralactivitiesinlayers2and1,respectively. Thetoprowshowsthe3principalcomponentsofdvalues,
andthebottomrowshowsthemeanvalueµp oftheprior. Therightcolumnshowsthejointangleateachtimestep.
t
Thetransitionwasperformedattimestept=40,340.
[8] Karl Friston. A theory of cortical responses. Philosophical transactions of the Royal Society B: Biological
sciences,360(1456):815–836,2005.
[9] MaxwellJDRamstead,KarlJFriston,andInêsHipólito. Isthefree-energyprincipleaformaltheoryofsemantics?
fromvariationaldensitydynamicstoneuralandphenotypicrepresentations. Entropy,22(8):889,2020.
[10] JelleBruineberg,JulianKiverstein,andErikRietveld. Theanticipatingbrainisnotascientist: thefree-energy
principlefromanecological-enactiveperspective. Synthese,195(6):2417–2444,2018.
[11] KarlFristonandStefanKiebel. Predictivecodingunderthefree-energyprinciple. Philosophicaltransactionsof
theRoyalSocietyB:Biologicalsciences,364(1521):1211–1221,2009.
[12] KarlJFriston,JeanDaunizeau,JamesKilner,andStefanJKiebel. Actionandbehavior:afree-energyformulation.
Biologicalcybernetics,102(3):227–260,2010.
[13] Karl Friston, Thomas FitzGerald, Francesco Rigoli, Philipp Schwartenbeck, Giovanni Pezzulo, et al. Active
inferenceandlearning. Neuroscience&BiobehavioralReviews,68:862–879,2016.
[14] ThomasParrandKarlJFriston. Generalisedfreeenergyandactiveinference. Biologicalcybernetics,113(5):495–
513,2019.
[15] AlejandraCiria,GuidoSchillaci,GiovanniPezzulo,VerenaVHafner,andBrunoLara. Predictiveprocessingin
cognitiverobotics: areview. NeuralComputation,33(5):1402–1432,2021.
[16] PabloLanillos,CristianMeo,CorradoPezzato,AjithAnilMeera,MohamedBaioumy,WataruOhata,Alexander
Tschantz,BerenMillidge,MartijnWisse,ChristopherLBuckley,etal. Activeinferenceinroboticsandartificial
agents: Surveyandchallenges. arXivpreprintarXiv:2112.01871,2021.
[17] TadahiroTaniguchi,ShingoMurata,MasahiroSuzuki,DimitriOgnibene,PabloLanillos,EmreUgur,Lorenzo
Jamone,TomoakiNakamura,AlejandraCiria,BrunoLara,etal. Worldmodelsandpredictivecodingforcognitive
anddevelopmentalrobotics: Frontiersandchallenges. arXivpreprintarXiv:2301.05832,2023.
[18] Antonella Maselli, Pablo Lanillos, and Giovanni Pezzulo. Active inference unifies intentional and conflict-
resolutionimperativesofmotorcontrol. PLoScomputationalbiology,18(6):e1010095,2022.
15
Human-RobotKinaestheticInteractionBasedonFreeEnergyPrinciple
[19] AlexanderTschantz,ManuelBaltieri,AnilKSeth,andChristopherLBuckley. Scalingactiveinference. In2020
internationaljointconferenceonneuralnetworks(ijcnn),pages1–8.IEEE,2020.
[20] CorradoPezzato,CarlosHernándezCorbato,StefanBonhof,andMartijnWisse. Activeinferenceandbehavior
treesforreactiveactionplanningandexecutioninrobotics. IEEETransactionsonRobotics,2023.
[21] JunTani. Exploringroboticminds: actions,symbols,andconsciousnessasself-organizingdynamicphenomena.
OxfordUniversityPress,2016.
[22] AhmadrezaAhmadiandJunTani. Anovelpredictive-coding-inspiredvariationalrnnmodelforonlineprediction
andrecognition. Neuralcomputation,31(11):2025–2074,2019.
[23] HendryFerreiraChameandJunTani. Cognitiveandmotorcomplianceinintentionalhuman-robotinteraction.
arXiv:1911.01753,2019. acceptedforpublicationinIEEEICRA2020.
[24] NadineWirkuttisandJunTani. Leadingorfollowing? dyadicrobotimitativeinteractionusingtheactiveinference
framework. IEEERoboticsandAutomationLetters,6(3):6024–6031,2021.
[25] AhmadrezaAhmadiandJunTani. Anovelpredictive-coding-inspiredvariationalrnnmodelforonlineprediction
andrecognition. Neuralcomputation,31(11):2025–2074,2019.
[26] YuichiYamashitaandJunTani. Emergenceoffunctionalhierarchyinamultipletimescaleneuralnetworkmodel:
ahumanoidrobotexperiment. PLoScomputationalbiology,4(11),2008.
[27] LéoPio-Lopez,AngeNizard,KarlFriston,andGiovanniPezzulo. Activeinferenceandrobotcontrol: acase
study. JournaloftheRoyalSocietyInterface,16,2016.
[28] GuidoSchillaci,AlejandraCiria,andBrunoLara.Trackingemotions:Intrinsicmotivationgroundedonmulti-level
predictionerrordynamics. 10thJointIEEEICDL-EPIROB,pages1–8,2020.
[29] J.Hwang,J.Kim,A.Ahmadi,M.Choi,andJ.Tani. Dealingwithlarge-scalespatio-temporalpatternsinimitative
interactionbetweenarobotandahumanbyusingthepredictivecodingframework. IEEETransactionsonSystems,
Man,andCybernetics: Systems,50(5):1918–1931,2020.
[30] JunyoungChung,KyleKastner,LaurentDinh,KratarthGoel,AaronCCourville,andYoshuaBengio. Arecurrent
latentvariablemodelforsequentialdata. InAdvancesinneuralinformationprocessingsystems,pages2980–2988,
2015.
[31] DiederikPKingmaandMaxWelling. Auto-encodingvariationalbayes. arXivpreprintarXiv:1312.6114,2013.
[32] Ahmadreza Ahmadi and Jun Tani. How can a recurrent neurodynamic predictive coding model cope with
fluctuationintemporalpatterns? roboticexperimentsonimitativeinteraction. NeuralNetworks,92:3–16,2017.
[33] Paul J Werbos. Backpropagation through time: what it does and how to do it. Proceedings of the IEEE,
78(10):1550–1560,1990.
[34] Timothy P Lillicrap and Adam Santoro. Backpropagation through time and the brain. Current opinion in
neurobiology,55:82–89,2019.
[35] DavidERumelhart,GeoffreyEHinton,andRonaldJWilliams. Learningrepresentationsbyback-propagating
errors. nature,323(6088):533–536,1986.
[36] WataruOhataandJunTani. Investigationofthesenseofagencyinsocialcognition,basedonframeworksof
predictive coding and active inference: A simulation study on multimodal imitative interaction. Frontiers in
Neurorobotics,14:61,2020.
[37] NadineWirkuttis,WataruOhata,andJunTani. Turn-takingmechanismsinimitativeinteraction: Roboticsocial
interactionbasedonthefreeenergyprinciple. Entropy,25(2):263,2023.
[38] TakashiIkegamiandHiroyukiIizuka. Turn-takinginteractionasacooperativeandco-creativeprocess. Infant
BehaviorandDevelopment,30(2):278–288,2007.
[39] HiroyukiIizukaandTakashiIkegami. Adaptabilityanddiversityinsimulatedturn-takingbehavior. ArtificialLife,
10(4):361–378,2004.
[40] AtsushiMasumori,NorihiroMaruyama,andTakashiIkegami. Personogenesisthroughimitatinghumanbehavior
inahumanoidrobot“alter3”. FrontiersinRoboticsandAI,7,2021.
[41] ManuelBaltieriandChristopherLBuckley. Pidcontrolasaprocessofactiveinferencewithlineargenerative
models. Entropy,21(3):257,2019.
[42] JunTani,MasatoIto,andYuuyaSugita. Self-organizationofdistributedlyrepresentedmultiplebehaviorschemata
inamirrorsystem: reviewsofrobotexperimentsusingrnnpb. NeuralNetworks,17(8-9):1273–1289,2004.
16

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Human-Robot Kinaesthetic Interaction Based on Free Energy Principle"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
