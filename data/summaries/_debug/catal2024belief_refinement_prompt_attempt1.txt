=== IMPORTANT: ISOLATE THIS PAPER ===
You are revising a summary for ONLY the paper below. Do NOT reference or use content from any other papers.
Paper Title: Belief sharing: a blessing or a curse
Citation Key: catal2024belief
REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Issues to fix:
1. Too short: 177 words (minimum 200)

Current draft:
### OverviewThis paper, “Belief sharing: a blessing or a curse,” investigates the potential pitfalls of sharing beliefs within multi-agent systems, specifically under the framework of active inference. The authors demonstrate that naive belief sharing can lead to undesirable social dynamics, including echo chambers and self-doubt, significantly impairing collaborative performance. The paper proposes a novel strategy – likelihood sharing – to mitigate these issues, arguing for a shift from sharing posterior beliefs to sharing interpreted observations.### MethodologyThe research employs a simulation-based approach to model communication between agents. The experimental setup centers around an object-finding task within a graph environment, where multiple agents search for a rewarding object. Each agent utilizes a generative model based on active inference, characterized by variational message passing and Bayesian updating. The model incorporates a three-dimensional tensor representing agent movement and a likelihood mapping between observed states and latent states. 

The core of the methodology involves simulating the agents’ interactions and observing the emergent behavior. 

The authors utilize a three-dimensional tensor representing agent movement and a likelihood mapping between observed states and latent states

Key terms: curse, belief, blessing, sharing, beliefs, department, information, verses

=== FULL PAPER TEXT ===
Belief sharing: a blessing or a curse
Ozan Çatal1, Toon Van de Maele1, Riddhi J. Pitliya1,2, Mahault Albarracin1,3,
Candice Pattisapu1, and Tim Verbelen1
1 VERSES Research Lab, Los Angeles, California, 90016, USA
2 Department of Experimental Psychology, University of Oxford, Oxford, UK
3 Department of Computer Science, Université du Québec à Montréal, Montréal,
Canada
ozan.catal@verses.ai
Abstract. When collaborating with multiple parties, communicating
relevant information is of utmost importance to efficiently completing
thetasksathand.Underactiveinference,communicationcanbecastas
sharingbeliefsbetweenfree-energyminimizingagents,whereoneagent’s
beliefsgettransformedintoanobservationmodalityfortheother.How-
ever,thebestapproachfortransformingbeliefsintoobservationsremains
an open question. In this paper, we demonstrate that naively sharing
posterior beliefs can give rise to the negative social dynamics of echo
chambers and self-doubt. We propose an alternate belief sharing strat-
egy which mitigates these issues.
Keywords: Active inference · Belief sharing · Multi-agent systems.
1 Introduction
Communication and the emergence of language have been a cornerstone in the
development of human intelligence, as they enable human collaboration at mul-
tiple communal scales [1]. This collaborative capability hinges significantly on
how agents share and process information, particularly requiring their internal
beliefsabouttheworldtobealigned[2,3].Activeinferenceprovidesacompelling
frameworkforunderstandinganddesigningsuchcollaborativeinteractionsinthe
interest of building ecosystems of intelligence [4,5,6]. In this paradigm, agents
minimize variational free energy [7], as each agent maintains a generative model
of the world which it uses to make inferences about hidden states and to plan
actions.Then,communicationbetweenagentsatthelowestlevelcanbeconcep-
tualized as sharing these internal beliefs, transforming the beliefs of one agent
intoobservabledataforanother[8],thesebeliefscanbeshareddirectlyaswewill
demonstrate in this paper, but could also be present in the environment more
permanentlyintheformofscripts[9]andtexts[10,11].Thisbelief-sharingmech-
anism is intended to facilitate a more coherent and efficient joint exploration of
the environment.
However, translating and sharing beliefs has its challenges, as the messages
shared are typically colored by one’s personal priors and biases [12]. We found
4202
luJ
2
]IA.sc[
1v56420.7042:viXra
2 O. Çatal et al.
thatnaivelysharingposteriorbeliefscaninadvertentlyleadtodetrimentalsocial
dynamics, such as echo chambers, in which agents reinforce each other’s biases,
and self-doubt, in which agents discount their observations to favor shared, yet
incorrect, beliefs. These phenomena can significantly impair the collective per-
formance of the agents, highlighting the need for more sophisticated strategies
in belief communication. In this paper, we explore these dynamics in depth. We
begin by modeling the communication between agents as belief sharing under
theactiveinferenceframework,demonstratingthepitfallsofstraightforwardbe-
lief sharing. We then propose an alternative strategy that mitigates these issues
byadjustinghowbeliefsarecommunicated.Specifically,weadvocateforsharing
likelihood information rather than posterior beliefs, treating other agents’ ob-
servationsasadditionalindependentsourcesofinformation.Thisapproachaims
to harness the benefits of collaborative inference while avoiding the pitfalls of
misleading belief reinforcement.
Our contributions are threefold: (i) We provide a detailed analysis of how
naive belief-sharing can lead to echo chambers and self-doubt. (ii) We propose a
novelcommunicationstrategythatmitigatestheseissuesbysharinglikelihoods.
(iii) We validate our approach through simulations, demonstrating improved
performance and robustness in collaborative tasks. The following sections out-
line our active inference model for communication, describe the experimental
setup used to test our hypotheses, present our findings on echo chambers and
self-doubt, and discuss our proposed solution and its implications for designing
collaborative AI systems.
2 An active inference model for communication
In this section, we provide a summary overview of active inference, and how it
can be adopted to model communication between agents. For a more in depth
overview of active inference we refer the reader to [7].
2.1 Perception and planning as inference
Active inference posits that agents entertain a generative model of the environ-
ment they operate in, and casts perception and action as Bayesian inference [7].
In general, the agent’s generative model can be written as the joint probability
distribution over states s, observations o and actions a, with tilde denoting a
time sequence of those over timesteps t:
(cid:89)
P(s˜,o˜,a˜)=P(s ) P(o |s )P(s |s ,a )P(a ) (1)
0 t t t t−1 t−1 t−1
t
Perception now becomes inferring the posterior distributions of states given
the performed actions and observations. As this is typically intractable, agents
resort to variational Bayesian inference, where an approximate posterior Q(s˜|o˜)
is optimized instead, by minimizing the variational Free Energy:
Belief sharing: a blessing or a curse 3
F =D [Q(s˜|o˜))||P(s˜|a˜,o˜)]− logP(o˜)
KL
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
posteriorapproximation logevidence
(2)
=D [Q(s˜|o˜))||P(s˜,a˜)]−E [logP(o˜|s˜)]
KL Q(s˜|o˜)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
complexity accuracy
It is clear that minimizing variational Free Energy is equivalent with maxi-
mizing a bound on the (log) evidence or ELBO [13], and encourages the model
to maximize accuracy with minimal complexity.
To interact with the environment, an agent also needs to select a sequence
of actions or policy π ={a ,a ,...} to execute. In active inference, planning is
t t+1
alsotreatedasinference,assumingthatagentswillpreferpoliciesthatminimize
expected Free Energy G. More specifically, policies are selected from
P(π)=σ(−G(π)), with
T
G(π)= (cid:88) E (cid:2) D [Q(s |o ,π)||Q(s |π)] (cid:3) −E (cid:2) logP(o ) (cid:3) (3)
Q(oτ|π) KL τ τ τ Q(oτ|π) τ
τ=t+1(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
(negative)InformationGain Utility
Here,σdenotesthesoftmaxfunction,andtheexpectedFreeEnergybalances
information gain with some prior preference distribution over future outcomes
or utility.
2.2 Communication as belief sharing
When agents share a common world and world model, they can benefit from
sharing beliefs among each other [8]. The most straightforward way to realize
this would be to share the agent’s respective posterior beliefs on some shared
modality. In order to achieve this, the agents generative model is expanded as
shown in Fig. 1. In particular, any agent, for example., the primary focal agent,
assumes other agents with a similar generative model will communicate infor-
mationaboutitsbeliefsoftheworld.Todoso,weequipthefocalagentwithan
extra observation modality os. Instead of being observed from the environment,
t
os is an observation generated by another agent based on its internal beliefs s′.
t t
This approach is the kind of model posited in earlier work [8].
To realize posterior belief-sharing, agents require a likelihood mapping be-
tween posterior beliefs about latent states that are shareable among agents, i.e.,
s , and this observation modality os. In natural systems, these can be a very
t t
complex likelihood mapping, e.g., language [14] or birdsong [15]. However, in
the case of AI agents, we can decide on the communication channel ourselves.
Oneparticularnaivechoiceistodirectlysharethesufficientstatisticsofone’sin-
ternalbeliefss′ andintegratethesewithanidentitylikelihoodmapping,asused
t
in[8].However,intheremainderofthispaper,wewilldemonstratethefallacies
of using this approach and propose a different format for shared messages.
4 O. Çatal et al.
Focal agent
...
...
Other agent
...
...
Fig.1: Two active inference agents sharing beliefs. The generative model
ofeachagentisaPOMDP,whereobservationsaregeneratedfromahiddenstate
s . Actions a , generated from a policy π, transition this state. In addition to
t t
the typical observation o at each timestep t, each agent also receives a shared
t
observation os that is generated from the other agent’s internal beliefs s′. Blue
t t
variables are observed from the perspective of the focal agent, i.e. they observe
theirownactions,observationsandtheobservationssharedwiththeotheragent.
Belief sharing: a blessing or a curse 5
0
Agent 1
1
? 2 3 Agent 2
4
?
5
?
(b)
(a)
Fig.2: Illustration of the graph environment and the agent’s factor
graph.(a)agentsarelocatedonaconnectedgraphoflocationsandneedtofind
a rewarding object that might be present at one of the locations. (b) a factor
graph representation of the agent’s generative model. Two latent state factors
that model the agent’s location and the object’s location respectively, give rise
to two sensory modalities through a likelihood factor: the agent’s location (A )
1
and whether the object is visible (A ). In addition, agents can share beliefs
2
about the object location through belief sharing (A ). The agent’s location can
3
change conditioned on move actions (B ), whereas the object is kept static in
1
our experiments (B =I).
2
3 Experimental setup
To demonstrate multi-agent belief sharing, we simulate an object-finding task,
where multiple agents search for a rewarding object in the same environment,
andcanpotentiallysharebeliefsonwheretheythinktheobjectis.Thesetupand
generative model for this task is depicted in Figure 2. The world is represented
by a graph of N locations that can be visited by the agents, and agents can
move between connected nodes in the graph. Each agent has two state factors,
a Categorical(N) variable sl which is the belief about the agent’s location, and
t
a Categorical(N) variable so which is the belief about the object location. An
t
agentcanperformoneofN moveactionsa,modeledusingthethree-dimensional
dynamics tensor B .
1

1.0, if a=i∧connected(i,j)

Bi,j,a = 1.0, if i=j
1
0.0,
otherwise
6 O. Çatal et al.
We assume the object is static, i.e. its dynamics B are modeled by the
2
identity matrix I. The agent has three observation modalities. First, it observes
its location ol, with a near identity likelihood mapping to the location state
t
factor:
(cid:40)
0.99, if i=j
Ai,j =
1 0.01, otherwise
Second, it observes ov whether the object is visible or not. This is governed by
t
a three-dimensional likelihood mapping A where
2

0.2, if i=j∧v =not visible
0.8,
if i̸=j∧v =not visible
Av,i,j =
2  0
0
.
.
8
2
,
,
i
i
f
f
i
i
=
̸=
j
j
∧
∧
v
v
=
=
v
v
i
i
s
s
i
i
b
b
l
l
e
e
Finally, there is the belief-sharing observation os which contains the shared in-
t
formation from the other agent.
The agents are initialized with a prior on sl set to their starting location,
t
and a prior on so set to the initial belief on where to find the object. This is
t
typically set uniform to (a subset of) the available locations to foster searching
behavior. The preference C is to have the object visible outcome.
4 Echo chambers
In a model which shares the posterior beliefs of one agent as observations of an-
other,Bayesianmodelupdatingreinforcesredundantpriorssharedamongthem.
The consequent simulated behavior mirrors the “echo chamber effect" wherein
messages communicated by like-minded agents are amplified and returned. Psy-
chologicalinterpretationsoftheechochambereffectareillustratedintheconse-
quencesofsocialmediafeedalgorithms,whichareoftenengineeredtoencourage
user engagement with sympathetic posts [16]. An algorithmically curated social
media curriculum increases engagement by anticipating a user’s expected social
media observations and fulfilling those expectations. Promoted content thereby
constructshomophilicinteractionnetworkswhichfacilitatetheconstructionand
reinforcement of shared narratives among users. In worst case scenarios, the re-
sult is the unimpeded flow of misinformation on social media platforms. More
generally, shared narratives facilitated by social media feed algorithms result
in an increase in confidence of posterior beliefs even when external evidence is
absent or intentionally excluded.
Ignoringnewevidencecanbeadaptive,suchaswhenthisstrategyfacilitates
in-group cooperation [17]. However, negative consequences also result, such as
when outside sources are discredited or distrusted.
Correspondingtotheechochambereffect,onepitfallofbeliefsharingisthat
whenagentshaveestablishedevensmallpriorbeliefsontheirgoal,ifthosepriors
Belief sharing: a blessing or a curse 7
are shared, then an echo chamber forms. The agents, however, reinforce their
prior beliefs through the communication method, resulting in ever-increasing
beliefs on the goal location even when there is no new evidence to support this
belief. Fig. 3 shows a simulation triggering this situation. The agents start with
a small belief that the object will be present at two locations within the graph
to simulate a longer-running experiment where such a situation might naturally
occur.Wehaverestrictedthemovementoftheagentsandprohibitedtheagents
from accumulating more evidence about the object’s actual location. However,
theagentskeepincreasingtheirbeliefontheobjectbeingpresentattheapriori
believed location because of the constant sharing of beliefs. Once the agents
create such an echo chamber, more often than not, they are stuck in this faulty
belief unless they all sufficiently change their belief at the same time.
5 Self-doubt
In an echo chamber, a belief sharing agent’s confidence about their priors is
reinforced in the absence of external evidence. Conversely, self-doubt refers to
a scenario in which the agent’s self-confidence is degraded as a result of belief
sharing. In our simulations, the paradigmatic example is when multiple agents
are fixated on a search task with complimentary plans for exploring the envi-
Fig.3:Simulationofanecho-chamber.Weinitializebothagentswithasmall
prior belief that the object will be present at location 11 or 13. Then, we let the
agentssharetheirbeliefs.Notethatthisreinforcesthebeliefthattheobjectwill
be at either one of the locations. The next columns show the evolution of both
agentswheretheykeepobservingtheenvironment.Weseethatinthetransition
from time 1 to time 2 the agents increase the belief that the object is at the
a priori believed location even though there is no new evidence to support this
belief. Agent location is depicted using the blue dots in both panels.
8 O. Çatal et al.
Fig.4: Simulation of self-doubt for 4 agents. Again, each panel displays
the evolution of the posterior belief as a function of time, where darker colors
indicates a higher degree of belief. Blue dots indicate the agent location. All
agentsareinitializedwithastrongpriorbeliefthattheobjectwillbeatlocation
1,asindicatedbythedarkshadedarea.Thisreflectsapotentialsituationwhere
all agents have been acting in the environment for a long time, accruing faulty
evidence. In this case the communication mechanism prohibits the agents from
discoveringthattheobjectisnotthere,evenafterobservingitsabsencemultiple
times.
ronment. Naturally, siblings faulty beliefs and ignore all evidence that points
to the contrary. This can occur after an echo chamber is formed but could also
occur independently. In this scenario, the agents again reinforce each other’s
beliefs in such a strong way that the agents “doubt” their observations origi-
nating from the environment. Fig. 4 visually overviews a simulation showcasing
this phenomenon. The agents are initialized with a strong belief on the object
location. In this particular simulation, the agents have a single peaked belief on
the object location (location 1 in the graph), which could occur after an echo
chamber situation. The agents are unrestricted in their movement as long as
they follow the underlying graph structure. We see that even though eventually
all agents visit location 1, they cannot correctly eliminate that location as a
possible object location. The incoming beliefs of the other agents overrule their
sensory observations.
6 To share or not to share?
Given that sharing agents’ beliefs can give rise to the aforementioned issues, it
is worth wondering what information can best be shared to allow multi-agent
cooperation in active inference agents. In particular, the update rule for so,
t
Belief sharing: a blessing or a curse 9
written in variational message passing notation [18], is of the form
so =σ(µ2 +µ2 +µ2 ),
t →B2 ↑A2 ↑A3
(4)
µf =og⊙φ(ag)⊙ si,
↑Ag t i∈pa(g)\f t
whereσisthesoftmaxfunction,µf themessagefromobservationmodality
↑Ag
g to state factor f and φ(ag) the digamma function of the Dirichlet counts
corresponding to the parameters of the likelihood model [8]. Effectively, the
update message is comprised of a part coming from a prior given by our beliefs
on the previous timestep µ2 , a part based on the latest observation µ2 ,
→B2 ↑A2
andapartcommunicatedbytheotherµ2 .Whenwecommunicatetheother’s
↑A3
posterior parameters directly through an identity likelihood mapping, we have
µ2 = µ2,other +µ2,other. This shows that, indeed, when agents have similar
↑A3 →B2 ↑A2
priors, this gets double counted in the belief update.
Toaddressthis,wewillnowinsteadsharetheother’slikelihoodmessageonly,
i.e. µ2 =µ2,other. This scheme leaves out agents’ prior beliefs about the state
↑A3 ↑A2
and only shares the agent’s interpretation of the observation, treating the other
agents as extra independent observers for the exact latent cause in the world.
We call this scheme ‘likelihood sharing‘.
Fig.5: Illustration of the lack of echo-chamber like behaviour when
sharing likelihoods.Inthisfigure,thesituationleadingtoanechochamberis
recreated.Bothagentsareinitializedwiththesamepriorbeliefthattheobjectis
mostlikelyatlocations11and13;however,becauseofthesharingoflikelihoods,
they do not get stuck in an echo chamber and do not increase the beliefs when
there is no new evidence.
Intheparticularscenarioofobject-findingagentsinagraphworld,theagents
share their current location and visibility observation as passed through their
10 O. Çatal et al.
object location A-tensor; each receiving agent can integrate this observation
quite easily into their own posterior belief by using Bayes rule. In effect, each
agent treats the other agents as an extra “pair of eyes” in the search for the
object, inferring their posterior update if they observed what the other agent
had observed.
In Fig. 5 and Fig 6, the same simulations from earlier are reprised but using
the new likelihood-sharing mechanism. The echo chamber and self-doubt phe-
nomena are no longer present even when providing the same initial conditions.
Finally, Figure 7 compares likelihood sharing to belief sharing and not com-
municatingatall.Allmethodsaretestedoverallpossiblecombinationsofagent
starting locations and object locations in the environment, and each configura-
tion is repeated five times. The trials are evaluated on the percentage of times
theobjectwasfound.Fromtheexperiments,thelikelihood-sharingagentsareon
parwiththenaivebelief-sharingagents.Atthesametime,theybothoutperform
the random agents and the non-communicating agents.
Fig.6: Alleviation of the self-doubt behavior under likelihood-sharing.
As with the previous depiction of this scenario, the agents are initialized with
a strong belief that the object will be at location 1; nonetheless, due to the
different communicated belief, the agent no longer ignores the evidence for the
object’s absence.
7 Discussion
The results presented in this paper highlight the potential pitfalls of belief-
sharing in multi-agent systems under the framework of active inference. Our
findings suggest that naive sharing of posterior beliefs can lead to undesirable
social dynamics such as echo chambers and self-doubt, severely hampering the
agents’ performance in collaborative tasks.
Belief sharing: a blessing or a curse 11
Fig.7: Overview of the average object find rate for each type of agent.
We measured the percentage of finding the object by any of the two agents over
all possible start configuration in the environment. This is repeated five times
to account for variability in the action selection process.
Echo chambers in human societies are well-documented phenomena where
groups of individuals reinforce their preconceptions, often without external val-
idating evidence. In our simulations, a similar effect occurs when agents con-
tinuously share their posterior beliefs. Initial biases can get amplified through
repetitive belief sharing, leading to overly confident but potentially erroneous
shared beliefs. This results in the agents becoming overconfident in incorrect
hypotheses, thereby hampering their search or exploration processes. Similarly,
self-doubt arises when agents’ observations contradict the reinforced shared be-
liefs, leading them to disregard their sensory inputs. This mirrors real-world
psychological effects where individuals question their perceptions in the face of
strongpeerinfluence.Inoursimulations,agentsmaintainedstrongincorrectbe-
liefs about the object’s location despite direct evidence to the contrary due to
the influence of shared but incorrect posterior beliefs.
Our proposed strategy of sharing likelihoods rather than posterior beliefs
mitigatestheissuesofechochambersandself-doubt.Bysharinginterpretedob-
servationsratherthanfullyformedbeliefs,agentscanintegratenewinformation
without being overwhelmed by the potentially erroneous priors of others. This
approach allows agents to utilize each other as additional sensing mechanisms,
providing independent evidence that can be more robustly combined with their
observations. By treating other agents’ observations as additional data points
rather than beliefs, the system remains more flexible and resilient to individual
errors. The proposed approach was only validated in simulated experiments but
might also apply to more general and complex scenarios with further modifica-
tions.
Ourworksuggeststhatthetypeofinformationsharedamongactiveinference
agentsmustbecarefullyconsideredtoavoidcounterproductivedynamics.Future
research can build on these insights by exploring other belief-sharing strategies
and their impacts on system performance. Additionally, exploring these dynam-
ics in more complex and varied environments, including those with adversarial
12 O. Çatal et al.
elements, could provide deeper insights into the performance of different com-
munication strategies. As our approach assumed full and honest collaboration
between the agents, another future avenue of research would be to investigate
the impact of dishonesty and, consequently, the discounting of communications
between untrusted agents.
In conclusion, while belief sharing among active inference agents can en-
hance collaborative performance, it also risks reinforcing incorrect beliefs and
undermining individual observations. Our proposed likelihood-sharing mecha-
nism offers a promising solution by leveraging the strengths of collective sensing
while mitigating the pitfalls of echo chambers and self-doubt without significant
changestotheunderlyingmodel.Suchstrategieswillbeessentialfordeveloping
robust, efficient, and adaptive collaborative agents as multi-agent active infer-
ence systems are designed.
References
1. J.Henrich,The Secret of Our Success: How Culture Is Driving Human Evolution,
Domesticating Our Species, and Making Us Smarter. Princeton University Press,
Oct. 2015.
2. B. Bahrami, K. Olsen, P. E. Latham, A. Roepstorff, G. Rees, and C. D. Frith,
“Optimally interacting minds,” Science, vol. 329, p. 1081–1085, Aug. 2010.
3. A. Constant, M. J. D. Ramstead, S. P. L. Veissière, and K. Friston, “Regimes of
expectations: An active inference model of social conformity and human decision
making,” Frontiers in Psychology, vol. 10, Mar. 2019.
4. K. J. Friston, M. J. Ramstead, A. B. Kiefer, A. Tschantz, C. L. Buckley, M. Al-
barracin, R. J. Pitliya, C. Heins, B. Klein, B. Millidge, D. A. Sakthivadivel,
T. St Clere Smithe, M. Koudahl, S. E. Tremblay, C. Petersen, K. Fung, J. G.
Fox, S. Swanson, D. Mapes, and G. René, “Designing ecosystems of intelligence
from first principles,” Collective Intelligence, vol. 3, Jan. 2024.
5. K. J. Firston and C. D. Firth, “Active inference, communications and hermeneu-
tics,” Cortex, vol. 68, pp. 129–143, 2015.
6. R. Tison and P. Poirier, “Active inference and cooperative communication: An
ecological alternative to the alignment view,” Frontiers in Psychology, vol. 12,
2021.
7. T.Parr,G.Pezzulo,andK.J.Friston,ActiveInference:TheFreeEnergyPrinciple
in Mind, Brain, and Behavior. The MIT Press, 03 2022.
8. K.J.Friston,T.Parr,C.Heins,A.Constant,D.Friedman,T.Isomura,C.Fields,
T. Verbelen, M. Ramstead, J. Clippinger, and C. D. Frith, “Federated inference
and belief sharing,” Neurosci. Biobehav. Rev., p. 105500, Dec. 2023.
9. M.Albarracin,A.Constant,K.J.Friston,andM.J.D.Ramstead,“Avariational
approach to scripts,” Frontiers in Psychology, 2021.
10. S. Gallagher and M. Allen, “Active inference, enactivism and the hermeneutics of
social cognition,” Synthese, vol. 195, no. 6, pp. 2627–2648, 2018.
11. N. Bouizegarene, M. Ramstead, A. Constant, K. Friston, and L. Kirmayer, “Nar-
rative as active inference,” Frontiers in Psychology, vol. 15, 2024.
12. M. Albarracin, D. Demekas, M. J. D. Ramstead, and C. Heins, “Epistemic com-
munities under active inference,” Entropy, vol. 24, p. 476, mar 2022.
Belief sharing: a blessing or a curse 13
13. C. M. Bishop, Pattern Recognition and Machine Learning (Information Science
and Statistics). Springer, 1 ed., 2007.
14. K.J.Friston,T.Parr,Y.Yufik,N.Sajid,C.J.Price,andE.Holmes,“Generative
models, linguistic communication and active inference,” Neuroscience &; Biobe-
havioral Reviews, vol. 118, p. 42–64, Nov. 2020.
15. K.J.FristonandC.D.Frith,“Activeinference,communicationandhermeneutics,”
Cortex, vol. 68, p. 129–143, July 2015.
16. M. Cinelli, G. De Francisci Morales, A. Galeazzi, W. Quattrociocchi, and
M. Starnini, “The echo chamber effect on social media,” Proceedings of the Na-
tional Academy of Sciences, vol. 118, Feb. 2021.
17. M. Kim, B. Park, and L. Young, “The psychology of motivated versus rational
impressionupdating,” TrendsinCognitiveSciences,vol.24,p.101–111,Feb.2020.
18. J. Winn and C. M. Bishop, “Variational message passing,” Journal of Machine
Learning Research, vol. 6, no. 23, pp. 661–694, 2005.

=== REVISE TO ===
PROFESSIONAL TONE: Begin directly with content - NO conversational openings like 'Okay, here's...'

1. Fix all issues above
2. Title: "Belief sharing: a blessing or a curse"
3. Include 10-15 quotes from paper text
   - Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
   - Use consistent quote formatting: 'The authors state: "quote"' or vary attribution phrases
   - Vary attribution phrases to avoid repetition
   - CRITICAL: Only extract quotes that actually appear in the paper text
4. ELIMINATE ALL REPETITION - each sentence must be unique
   - Check before each sentence: 'Have I already said this?' If yes, write something new
   - Vary attribution phrases - do NOT repeat 'The authors state' multiple times
5. Extract methodology, results with numbers, key quotes
6. 1000-1500 words, structured with ### headers

Generate COMPLETE revised summary.