=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Tactile-based Active Inference for Force-Controlled Peg-in-Hole Insertions
Citation Key: kamijo2023tactilebased
Authors: Tatsuya Kamijo, Ixchel G. Ramirez-Alpizar, Enrique Coronado

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Key Terms: tactile, force, insertions, policy, alignment, hole, learning, inference, insertion, active

=== FULL PAPER TEXT ===

Tactile-based Active Inference for
Force-Controlled Peg-in-Hole Insertions
Tatsuya Kamijo1, Ixchel G. Ramirez-Alpizar2, Enrique Coronado2, Gentiane Venture1,3
Abstract—Reinforcement Learning (RL) has shown great
promise for efficiently learning force control policies in peg-
in-hole tasks. However, robots often face difficulties due to
visual occlusions by the gripper and uncertainties in the initial
grasping pose of the peg. These challenges often restrict force-
controlledinsertionpoliciestosituationswherethepegisrigidly
fixed to the end-effector. While vision-based tactile sensors
offer rich tactile feedback that could potentially address these
issues, utilizing them to learn effective tactile policies is both
computationally intensive and difficult to generalize. In this
paper,weproposearobusttactileinsertionpolicythatcanalign
the tilted peg with the hole using active inference, without the
need for extensive training on large datasets. Our approach
employs a dual-policy architecture: one policy focuses on
insertion, integrating force control and RL to guide the object
into the hole, while the other policy performs active inference
basedontactilefeedbacktoalignthetiltedpegwiththehole.In
real-world experiments, our dual-policy architecture achieved
90% success rate into a hole with a clearance of less than 0.1
mm, significantly outperforming previous methods that lack
tactile sensory feedback (5%). To assess the generalizability
of our alignment policy, we conducted experiments with five
differentpegs,demonstratingitseffectiveadaptationtomultiple Fig.1:Proposeddual-policysystemforrobustinsertion.Itleverages
objects. deep active inference for tactile pose alignment.
I. INTRODUCTION
Broadeningtheapplicationofindustrialrobotsnecessitates
We propose a safe tactile insertion policy that leverages
theabilitytosafelyexecuteprecisecontact-richmanipulation
vision-based tactile sensors for robot pose alignment. Our
tasks, such as peg insertion. Yet, the achievement of safe
method combines the strengths of force control and active
and robust execution of insertion tasks is challenging due
inference, a promising neuroscience theory that unifies per-
to grasp uncertainty, visual occlusions by the gripper, and
ception and action under a single objective of minimizing
complexphysicalinteractionbetweenthegraspedobjectand
freeenergy.Inoursystem,theagentpredictstactilesensation
the environment.
from its own internal state, namely the tilt of the peg.
Early work on peg-in-hole tasks leverage mathematical
This internal state (i.e. inferred tilt) is updated in a way
or geometrical model of the environment [1], [2]. In recent
that minimizes discrepancies between predicted and current
years,learning-basedapproacheshaveshowngreatsuccessin
tactile image. The key insight is that by formulating tactile
various manipulation tasks by learning complex behaviours,
perception under free energy minimization problem, the
thus avoiding the need to model physical interactions be-
active inference agent can adapt to diverse objects without
tween the manipulated object and the environment [3].
extensive training on vast datasets. Our approach consists of
Reinforcement Learning (RL) methods have especially been
two policies as depicted in Fig. 1:
shown to be effective in object insertion tasks. While RL
policies can successfully learn peg-in-hole insertion tasks, • Insertion policy that executes force-controlled policy
most of the work either consider the peg to be part of the learned by RL in simulation to insert the grasped peg.
robot’s end-effector or fix it to the gripper, assuming no in- • Alignment policy that employs active inference based
hand slippage occurs during the insertion process [4]. This on tactile feedback to change the robot pose.
paper addresses this assumption by using feedback signal The insertion policy handles the main process of inserting
from the vision-based tactile sensors. the peg. When the peg slips while in contact with the
environment, the alignment policy takes over. It executes
1Department of Mechanical Engineering, Faculty of Engineering, The
UniversityofTokyo,Japantatsukamijo@g.ecc.u-tokyo.ac.jp active inference to adjust the robot’s end effector pose in
2AutomationResearch Team,IndustrialCPS ResearchCenter, National a way that aligns the peg with the hole.
InstituteofAdvancedIndustrialScienceandTechnology(AIST),Japan
This paper presents three main contributions. First, we
3CNRS-AIST JRL (Joint Robotics Laboratory), National Institute of
AdvancedIndustrialScienceandTechnology(AIST),Japan proposeanoveldeepactiveinferenceapproachtotactilepose
3202
peS
72
]OR.sc[
1v18651.9032:viXra
alignment. Building on the free energy principle, this ap- that is consistent with Bayes’ rule given an observation o:
proachadaptstovariousobjectswithoutapre-trainedmodel
p(o|z)p(z)
built on a large dataset or prior knowledge of their shape. p(z|o)= . (1)
Second, we introduce the self-data augmentation method to p(o)
realize deep active inference without collecting extensive Here, p(z|o) is the posterior probability of the internal
data in the real world. Third, we combine a force-controlled state z given a sensory observation o. To avoid calculating
insertion policy and the active inference-based tactile pose the marginal likelihood p(o) = (cid:82) p(o|z)p(z)dz, which is
z
alignment policy. This dual-policy system is experimentally intractable when the dimension of the hidden state is large,
validatedwiththeUR5e-seriesroboticarmandtheGelsight a reference distribution, also referred to as the recognition
Mini [5] tactile sensor. density, q(z) is introduced. By minimizing the Kullback-
Leibler divergence D between the true posterior and the
II. BACKGROUNDANDRELATEDWORK KL
recognition density, the hidden state z can be optimized.
A. Learning Contact-Rich Manipulation Tasks
(cid:90) q(z)
Learning force control by RL has shown significant D (q(z)∥p(z|o))= q(z)ln dz =F +lnp(o)
KL p(o,z)
promise for handling complex, contact-rich manipulation
(2)
tasks [3]. Beltran-Hernandez et al. [6] proposes a learning-
Rearranging (2), free energy can be written as
based force control framework that combines RL techniques
with traditional force control methods. The authors use F =D (q(z)∥p(z|o))−lnp(o). (3)
KL
transfer-learningtechniques(Sim2Real)anddomainrandom-
The first term is associated with perception, where the agent
ization to close the reality gap. Although these methods
performsBayesianinferencetobettermodelitsenvironment.
have advanced work in object-insertion tasks, they typically
The second term −lnp(o) represents the sensory surprise
assumethatthepegisrigidlyfixedtotherobot’send-effector
and is related to the action component, where the agent acts
to prevent in-hand slippage during the insertion process.
tominimizethissensorysurpriseandtherebyachievedesired
However, visual occlusions by the gripper often make it
sensory outcomes.
difficult for a robot to receive feedback about the physical
Activeinferenceisatheorythatoutlinesthespecificmech-
state around the end-effector.
anismbywhichasystemactsonitsworldtochangesensory
Recent advances in high-resolution vision-based tactile
inputs, thereby minimizing free energy. From Equation (3),
sensors [5], [7], [8], [9] have enabled robots to obtain rich
minimizing D is equivalent to minimizing free energy F
tactile information directly from their grippers. Approaches KL
whentheobservationoisfixed.Thisisknownasperceptual
leveraging tactile information for manipulation tasks include
inference.Perceptualinferencecantightlyconstrainthelevel
tactile mapping [10], pose estimation [11], [12] and super-
of surprise by approximating the world but cannot lessen
vised learning [13], [14]. Learning a tactile insertion policy
the surprise within the observations themselves −lnp(o).
through RL is one way to utilize this tactile information.
In active inference, the agent can decrease this sensory
Dong et al. [15] study different design choices for tactile-
surprise by acting upon the environment to change sensory
based feedback insertion policies and propose an RL-based
observations o, thereby minimizing free energy. Thus, both
insertion policy that incorporates curriculum training and
perception and action can be done under the single free
tactile flow representation. They also argue that raw tactile
energy minimization:
RGB images contain detailed object-specific features, which
can cause a learning-based agent to easily overfit to the z =argminF(z,o), (4)
trainingobjects.Whiletactileflowrepresentationiseffective z
in dynamical situation where markers on the surface change a=argminF(z,o(a)). (5)
position in response to actions, it is not the best option a
when you need to obtain the static state of the peg such Active inference has been recently applied in the field of
as tilt. Contrary to this, our work demonstrates that static robotics[18].Inapplyingactiveinferencetorobotics,gener-
RGB images can also generalize across various objects ative functions are critical. Generative functions are learned
when you use active inference in combination with contact mappings that approximate the internal hidden state dynam-
area estimation. We utilize the neural network architecture ics and how sensory observations are generated from this
proposed in[16] to estimatethe contact area.This estimated hiddenstate,essentiallyservingasthemodel’sunderstanding
shapeisthenusedasinputforouractiveinferencecontroller. of the underlying causal structure of its environment. The
work in [19] presents a deep learning approach to learn the
B. Free Energy Principle and Active Inference
generative function, proposing PixelAI that deals with high-
The free energy principle is a theoretical framework dimensionalRGBinputforbodyperceptionandaction.This
from neuroscience that proposes that living systems seek to type of learning-based method called Deep Active Inference
minimize a statistical quantity known as free energy [17]. (Deep AIF) in general has extended the active inference
Building upon this theory, body perception can be modeled frameworktohigh-dimensionalinputsbylearninggenerative
as inferring the hidden state z from the sensory observation functions [20], [21], [22], [23]. As for the choice of hidden
o. The objective in perception is to find a hidden state z state, previous work that apply active inference to robotics
often assume the robots’ joint angles as internal state [24],
[25], [26], [27]. This makes sense as joint angles are the
only factors that bring change to visual sensations in the
context of robot body perception and action. Our work sets
apart from these approaches in that we treat external objects
within the framework of active inference. We adopted the
tiltofthegraspedobjectastheinternalstateandlearnedthe
generativemodelthatpredictstactilesensationsfromthistilt.
Further details about our approach are presented in Section
IV.
III. PROBLEMSTATEMENT
Wetacklethepeg-in-holetaskwitha6DoFUR5e-series
robot arm equipped with vision-based tactile sensors within
its fingers. The objective is to safely insert various objects
Fig. 2: The internal state is updated in real-time to minimize free
into corresponding holes given the initial and the goal
energy, thereby reducing discrepancies between the predicted and
end-effector pose. During the whole insertion process, the
the actual tactile images of the contact area estimation. Note that
robot has access to its joint angles, force-torque readings vague contact area estimation is enough for performing µ updates
and tactile readings from one of the tactile sensors. No based on prediction error minimization. The agent calculates the
visual information was given to the robot in this work. In inversekinematicsbasedontheinferredtiltµandadjuststheend-
effector pose to align the peg with the hole.
the experiments we made the following assumptions:
1) The width of the peg to be grasped is small enough
learned by an RL policy in simulation and transferred to the
such that a “tilt” can be perceived in the tactile image.
real world (Sim2Real). Domain randomization [28] is used
2) The inferred tilt obtained from the iteration of free
to close the reality gap between simulation physics and the
energy minimization is accurate enough to be used as
real-world dynamics. For more details, see [6].
an observation of the robot.
3) The target pose of the end effector is known.
C. Alignment Policy
IV. METHODOLOGY Fig. 2 outlines the agent’s perception of tactile observa-
A. Overview tions based on its internal state. In the following sections,
we detail our active inference model and describe how it is
To achieve robust and adaptive insertion, we propose a
implemented for tactile sensory data.
dual-policy structure, as depicted in Fig. 1. The system
1) Active Inference Model: We model perception as
initially employs a learned force control policy to insert the
the inference of an unobservable internal state µ, which
graspedpegintotheholewhileavoidingexcessiveforce[6].
representsthetiltofthepegrelativetotheendeffector.This
Whenthegraspedpegslipsandtiltswithinthegripperdueto
internal state is modeled as a one-dimensional scalar. The
physicalcontactwiththeenvironment,thesystemtransitions
robot’s observations, denoted as o, comprise a preprocessed
to executing active inference. In this phase, the agent infers
tactile image o and the relative angle θ between the peg
thetiltofthepegandusesthisinferencetodecidewhatpose tac
and the hole. Since µ is belief of the tilt angle between the
to take.
peg and the end effector, the angle θ may differ from µ
B. Insertion Policy in situations where the peg undergoes multiple tilts. Fig. 3
Our force-controlled insertion policy is based on [6]. We illustrates the definition of µ and θ. The generative model
use a PID-based parallel position-force control scheme with g maps this internal state to predicted tactile sensations as
a selection matrix to determine the degree of control exerted follows:
on position and force along each direction. The control o =g(µ)+ϵ , (7)
tac o
command given to the robot x is composed of a PD action
c
on position, a PI action on force, a selection matrix S, and where ϵ o is zero-mean Gaussian noise with variance Σ o .
a position action from the RL policy a : We assume a Gaussian prior for µ with mean zero and
x
variance σ2. Using these assumptions, the free energy F
(cid:90) µ
x =S(Kxx +Kxx˙ )+a +(I−S)(KfF +Kf F dt), can be expressed as:
c p e d e x p e i e
(6)
F =−lnp(o |µ)−lnp(µ)−lnp(θ)+Const. (8)
tac
where F and x represent the target force and position
e e
error, respectively. Kx, Kx, Kf, and Kf are the controller Here, p(θ) is also assumed Gaussian with zero mean and
p d p i
gain parameters. In this work, we exclude rotational action varianceσ2.UndertheLaplaceapproximation,weassumea
θ
from the control command, as the alignment policy handles Gaussian form for the recognition density q(µ), defined by
that aspect. All the PID and selection matrix parameters are its mean µ and variance σ2.
Algorithm 1: π by Deep Active Inference
align
Instant Decoder Training
o ←ContactArea(tactile image in a straight pose)
init
Dataset←DataAugmentation(o )
init
Decoder.train(Dataset)
Active Inference Loop
µ←0
while True do
o ←ContactArea(tactile image)
tac
g(µ)←Decoder.forward(µ)
∂g ←Decoder.backward(µ)
Fig. 3: Left: Definition of θ. While µ does not change after the
e =o −g(µ) ▷ Prediction error
action, θ becomes close to zero. Right: Depending on the surface tac tac
of the peg, the estimated contact area can become noisy (top right µ=Update(µ,∂g,e tac ) ▷ Perception
figure), which poses challenges for accurate tilt estimation. Our if µ>threshold then
proposed deep active inference approach addresses this issue by InverseKinematics(µ) ▷ Action
updatingtheinternalstateµinawaythatminimizestheprediction
end
error.
end
Given that the agent’s action of aligning its pose does not
affect the internal state µ, the optimal state that minimizes single numerical value, which is the tilt.
free energy can be found through gradient descent. The 3) InstantDecoderTraining: Ourframeworktrainsade-
update rule is: coderbetweentheinitialgraspandtheinsertionstageinjust
d ∂F(µ) a few seconds, removing the need for a pre-trained model.
µ=− Twokeycomponentsenablethis:contactareaestimationand
dt ∂µ
self-data augmentation.
∂g(µ)T
= Σ−1(o −g(µ))−σ−2µ. (9) We use the neural network architecture from [16] to
∂µ tac tac µ
estimatethepeg’scontactareaforeachframe,asonlyshape
In this equation, the term o −g(µ) represents the pre- information is essential for tilt inference. This serves as the
tac
diction error, while Σ−1 serves as a precision parameter. first component.
tac
The expression ∂g(µ)T/∂µ maps the tactile sensory space The second component is self-data augmentation. A no-
to the internal state space, which can be obtained through table limitation of using vision-based tactile sensors is their
a backward pass of the network when the generative model susceptibility to damage. To avoid damaging the sensor
is approximated by a deep neural network [25]. The second surface by collecting large datasets in a real-world setting,
term acts as a regularization term that mitigates excessive we developed a self-data augmentation method that creates
updates. Upon updating the internal state to µ′ =µ+∆ µ˙, a dataset from a single tactile image of the peg in a straight
t
the agent performs inverse kinematics to correct the tilt by pose. Assuming that we have access to this tactile image of
rotatingtheendeffectoraroundtheToolCenterPoint(TCP), a peg in a straight pose (aligned with the hole).
which is defined at the center of the two fingers. To create a dataset for decoder training, we use computer
Updating µ according to Equation (9) constitutes the vision techniques to rotate this estimated contact area of
perceptual component of our model, as it aims to minimize the peg in a straight pose o by a specified degree to
init
thefirstandsecondtermsofthefreeenergyinEquation(8). generate new tactile data. As discussed in [15], raw tactile
Conversely, the action performed by the agent targets the RGB images can be complex and contain task-irrelevant
minimization of the third term in the free energy equation, features (see Fig. 3). Our method overcomes this issue
reflecting its goal to align the peg with the hole. by performing active inference based on prediction error
2) Generative Model: For the generative model g (i.e. minimization in conjunction with contact area estimation.
generative function) to predict tactile sensation from the Extracting the contact area of the grasped peg enables the
inferred tilt, we approximate it using a neural network agenttoquicklylearnthedecodereverytimeitgraspsanew
architecture closely following the design proposed in [25], object.
which is based on [29]. The network consists of two fully The core advantage of this rapid training lies in its
connected layers followed by alternating transposed con- efficiency: our agent updates its internal state, denoted as µ,
volution and standard convolution layers, with a final 1D- byminimizingpredictionerror.Thismeansthedecoderdoes
Dropout layer to mitigate overfitting. For a comprehensive not need to capture detailed shapes of the contact area for
understanding,readersarereferredto[25].Ourmodification effective performance, as illustrated in Fig. 2. Consequently,
to the architecture involves reducing the input dimension this allows our system to swiftly adapt to new pegs without
from 4 to 1 in order to decode the tactile image from a the need for a large, diverse pre-trained model.
translations along the x-axis are not the focus of our study,
we opted for a 3D-printed cuboid peg instead of the shaft.
This cuboid has an industrial-level clearance of 0.08 mm
(measured with a caliper), compared to the shaft’s 0.05 mm.
The motor pulley has a clearance of 0.3 mm. The average
width of the pegs is 8mm. We used Gazebo simulator [31]
version9forthesimulationenvironmenttotraintheinsertion
policy. To control the robot, the Robot Operating System
(ROS) [32] with the Universal Robot ROS Driver is used.
B. Experimental Procedure
To validate our approach, we conduct two independent
experiments. The first one is the perceptual inference exper-
iment, where we focus on evaluating our alignment policy’s
capabilityofinferringthetiltofmultipleobjects.Thesecond
oneistheactiveinferenceexperiment,wherethewholedual-
policy system is evaluated.
1) Perceptual Inference Procedure: Forthisexperiment,
we aim to validate our alignment policy’s ability to infer the
tiltsofmultipleobjectsaccurately.Assumingtheavailability
of a tactile image from a straightly grasped peg, the agent’s
Fig. 4: Overview of our experimental setup. In the bottom right goal is to infer peg tilts based on tactile images captured by
corner, the pegs used in the experiments are displayed, arranged
the GelSight sensor. The initial tactile image is processed
from left to right as follows: shaft, pulley, cylinder, cuboid, and
through a pre-trained neural network model to estimate the
ellipticalcylinder.Forthedual-policyexperiments,weutilizedtwo
peg-in-hole tasks: inserting the pulley into the motor and inserting contact area [16]. We used the trained model made publicly
the cuboid into the peg hole. available by the authors of [16] for all tactile images in
the experiments. A training dataset (D ) of 500 tactile
train
images, along with their corresponding tilts, is then created
4) Algorithm: Algorithm 1 summarizes the flow of the byrotatingtheinitialcontactareaobservationbyarandomly
proposed alignment policy. The agent employs self-data sampled value from [-20, 20] degrees. Test sets (D )
test
augmentationtocreateadataset.Thisdatasetconsistsoftilt- containing100samplesarecreatedusingthetactileimagein
labelled, estimated contact areas derived from tactile images astraightposeatadifferenttimesteptoavoidusingthesame
of a peg in a straight pose o init . The decoder is trained exact shape among the train and the test data. The decoder
subsequently using this dataset. During the force-controlled model was trained over five epochs, taking approximately
insertion process, a perceptual inference loop runs in real- one second on average using an Intel Core i9-9900K CPU
time, updating µ following Equation (9) at regular intervals. and an Nvidia RTX-2080 Ti GPU.
The agent takes an action only when µ exceeds a specified Upon completing the instant decoder training, perceptual
threshold, indicating that the peg is tilted. The action is inference is performed for each of the 100 test data D .
test
designed to reduce the relative angle between the peg and The initial value of µ is set to 0.0, with a maximum of
the hole, θ becomes zero by rotating the end effector around 500 inference iterations. The update for µ is based on
TCP, as calculated through inverse kinematics. Equation (9) and involves two parameters: Σ−1 and σ2. We
tac µ
empirically set Σ−1 =2×104 and σ2 =1×10−2.
V. EXPERIMENTSANDRESULTS tac µ
2) Dual-policy Procedure: Before deploying the dual-
A. Experimental Setup
policy architecture, the force-controlled insertion policy was
We evaluate the proposed method on several peg-in-hole trained in Gazebo simulation environment. During the train-
insertion tasks. We use a 6 DoF UR5 e-series robot arm ing, the agent’s task was to insert a cuboid peg fixed to the
with a control frequency of 500 Hz. The robotic arm has a end effector into a hole. The goal position, object-surface
built-in force/torque sensor at its wrist and a Robotiq 2F-85 stiffness, goal pose uncertainty, and desired insertion force
Adaptive Gripper. Two GelSight Mini sensors are mounted wererandomizedforeachepisode.Theagentwastrainedfor
on the gripper, where only one of them is used during the 100000 time steps, which takes about an hour to complete.
experiments. We use the assembly task (motor, pulley, and The active inference experiment follows the same procedure
shaft) from the Assembly Challenge of the World Robot as perceptual inference for decoder training, except that we
Summit 2020 edition [30]. Additionally, we use other 3D- do not create test data D . The robot initially trains the
test
printed pegs such as a cuboid, a cylinder, and an elliptical decoder using a tactile image of the peg in a straight pose.
cylinder. For the peg-in-hole insertion tasks, we use a motor The agent creates a dataset of 1000 tactile images whose
pulley and a cuboid. We observed that working with the tilts were drawn randomly from [-10, 10]. We narrowed the
shaft resulted in significant slippage along the x-axis. Since range of degrees since we noticed that in real situations the
TABLE I: Mean absolute error of estimated tilts [deg] TABLE II: Success rate of insertions
Object Supervised Proposedmethod Object Withouttactilefeedback Proposedmethod
Shaft 4.5 1.0 Cuboid 1/20(5%) 36/40(90%)
Pulley 0.3 1.3 Pulley 14/20(70%) 37/40(93%)
Cylinder 2.7 1.5
Cuboid 4.4 1.5
EllipticalCylinder 1.0 1.2
supervised learning method was only feasible because the
internal state was defined as a single scalar. In contrast, our
proposedmethodcanbeappliedtointernalstateswithhigher
tilts were mostly within this range. The robot then moves
dimensions simply by altering the decoder input dimension.
to an initial position, which is about 1 cm far in x axes
2) Dual-policy Result: The success rates of insertions
from the hole, and [-1, 1] cm in y and z axes. This initial
for different objects are summarized in Table. II. For the
positionischangedafter10insertions,atotalof40insertions
cuboidpegwithaclearanceof0.08mm,thebaselinemethod
were done. At this initial position, the robot grasps the peg
without tactile feedback achieved a success rate of just 5%,
with a random tilt, assuming that a tilt has occurred due
corresponding to 1 out of 20 trials. Given the stringent
to the contact with the environment, or initial grasp pose
clearance, the baseline method generally failed to insert the
uncertainty.Whilegraspingthepeg,theperceptualinference
peg with an initial random grasp pose, except in one trial
runs in real-time with 0.5 Hz, starting from µ=0 to update
where it managed to grasp the peg in almost a straight pose
untilitreachesthemaximumof1000iterations.Theupdated
by chance. In contrast, our proposed method significantly
µ is used as the current belief of the internal state. The
improved the success rate to 90% with the aid of the tactile
agentfirstperformstheactiveinference-basedpolicytoalign
alignmentpolicy,succeedingin36outof40trials.Similarly,
the tilted peg with the hole and transitions to the insertion
for the pulley, the baseline method achieved a relatively
policy. When θ becomes greater than a threshold, the agent
better but still suboptimal success rate of 70%, or 14 out
switches to the alignment policy to make the peg straight.
of 20 trials. Our proposed method again outperformed the
This threshold is empirically set to 0.7.
baseline, with a success rate of 93% based on 37 successful
C. Comparison insertions out of 40 trials. The relatively higher success rate
of motor pulley insertions by baseline method compared
Tovalidatetheadaptabilityandaccuracyofouralignment
with the cuboid insertions comes not only from the higher
policy on multiple objects, we also tested a baseline method
clearance (0.3 mm) but also from the shape and the material
that employs supervised learning with Convolutional Neural
of pulley. As illustrated in bottom right of Fig. 4, the pulley
Networks (CNNs) [33]. This baseline model is designed to
has a hole in the center, whose position itself does not
predict the tilt of the peg based on the tactile image of
change due to slippage, or rotation. We also noticed that
the estimated contact area. The baseline was trained using
the motor pulley insertion has less friction than 3D printed
an identical dataset and the same number of epochs as our
cuboid and the hole, guiding the the hole of the pulley
proposed method.
to the motor. However, while this small friction enabled
For the dual-policy experiments, we employed our inser-
the baseline method to insert with 70% success rate, it
tion policy without tactile feedback [6] as a baseline for
greatly damaged the gel of the tactile sensors. Due to this
comparison. To make fair comparison under same friction,
significant damage on the tactile sensor observed during the
weconductedthebaselineexperimentswiththetactilesensor
experiments, we decided to run only 20 insertions for the
attached to the finger, although not used.
baseline method.
D. Results
VI. CONCLUSION
1) PerceptualInferenceResult: Theresultsofthepercep-
In this paper, we introduced a novel, tactile-based active
tual inference experiments are summarized in Table I. The
inference approach for force-controlled peg-in-hole inser-
maximum mean absolute error for estimated tilts using the
tions. Our method achieved a 90% success rate in physical
supervised learning method is 4.5 degrees, while maximum
robot experiments, with a clearance of less than 0.1 mm by
mean absolute error for our proposed method is 1.5 degrees.
utilizing active inference on tactile data for peg alignment.
As evidenced by the results for the shaft (4.5 deg) and the
Furthermore,wedemonstratedthatourapproachgeneralizes
cylinder (2.7 deg), the supervised learning method struggles
to five different objects without the need for a pre-trained
toextractmeaningfulfeaturesfromsmalldatasets,especially
model or the collection of real-world data. This addresses a
when the peg is round and has an indistinct border in the
significant limitation associated with the fragility of vision-
tactile image of the contact area. In contrast, our proposed
based tactile sensors. As a pathway for future work, we aim
method is robust against such noise, as the tilt inference is
to integrate vision into the system to enhance its robustness
basedonmaximizingthepixeloverlapbetweenthepredicted
byaccountingforslippageinboththeinsertionandrotational
(i.e.,inferred)contactareag(µ)andthecontactareaderived
directions. Additionally, we see potential in expanding the
from the actual tactile sensation. This result indicates that
internal states of our active inference model to handle more
ouragent’sinferenceisgenerallyapplicabletomultiplepegs
complex tasks in the tactile space.
with different geometry. It’s worth noting that the baseline
REFERENCES [18] PabloLanillos,CristianMeo,CorradoPezzato,AjithAnilMeera,Mo-
hamedBaioumy,WataruOhata,AlexanderTschantz,BerenMillidge,
MartijnWisse,ChristopherL.Buckley,andJunTani.Activeinference
[1] H. Bruyninckx, S. Dutre, and J. De Schutter. Peg-on-hole: a model
inroboticsandartificialagents:Surveyandchallenges,2021.
basedsolutiontopegandholealignment.InProceedingsof1995IEEE
[19] CansuSancaktar,MarcelA.J.vanGerven,andPabloLanillos.End-to-
International Conference on Robotics and Automation, volume 2,
endpixel-baseddeepactiveinferenceforbodyperceptionandaction.
pages1919–1924vol.2,1995.
In 2020 Joint IEEE 10th International Conference on Development
[2] M.E.Caine,T.Lozano-Perez,andW.P.Seering. Assemblystrategies
andLearningandEpigeneticRobotics(ICDL-EpiRob),2020.
forchamferlessparts. InProceedings,1989InternationalConference
[20] Kai Ueltzho¨ffer. Deep active inference. Biological Cybernetics,
onRoboticsandAutomation,pages472–477vol.1,1989.
112(6):547–573,oct2018.
[3] ´In˜igoElguea-Aguinaco,AntonioSerrano-Mun˜oz,DimitriosChrysos-
[21] ZafeiriosFountas,NoorSajid,PedroMediano,andKarlFriston.Deep
tomou, Ibai Inziarte-Hidalgo, Simon Bøgh, and Nestor Arana-
activeinferenceagentsusingmonte-carlomethods. InH.Larochelle,
Arexolaleiba. A review on reinforcement learning for contact-rich
M.Ranzato,R.Hadsell,M.F.Balcan,andH.Lin,editors,Advances
robotic manipulation tasks. Robotics and Computer-Integrated Man-
inNeuralInformationProcessingSystems,volume33,pages11662–
ufacturing,81:102517,2023.
11675.CurranAssociates,Inc.,2020.
[4] Cristian Camilo Beltran-Hernandez, Damien Petit, Ixchel Georgina [22] Otto van der Himst and Pablo Lanillos. Deep active inference for
Ramirez-Alpizar, Takayuki Nishi, Shinichi Kikuchi, Takamitsu Mat- partially observable mdps. In International Workshop on Affective
subara, and Kensuke Harada. Learning force control for contact- Interactions,2020.
rich manipulation tasks with rigid position-controlled robots. IEEE [23] BerenMillidge. Deepactiveinferenceasvariationalpolicygradients.
RoboticsandAutomationLetters,5(4):5709–5716,oct2020. JournalofMathematicalPsychology,96:102348,2020.
[5] Wenzhen Yuan, Siyuan Dong, and Edward H. Adelson. Gelsight: [24] PabloLanillosandGordonCheng. Adaptiverobotbodylearningand
High-resolution robot tactile sensors for estimating geometry and estimationthroughpredictivecoding.In2018IEEE/RSJInternational
force. Sensors(Basel,Switzerland),2017. ConferenceonIntelligentRobotsandSystems(IROS).IEEE,oct2018.
[6] Cristian C. Beltran-Hernandez, Damien Petit, Ixchel G. Ramirez- [25] CansuSancaktar,MarcelA.J.vanGerven,andPabloLanillos.End-to-
Alpizar,andKensukeHarada.Variablecompliancecontrolforrobotic endpixel-baseddeepactiveinferenceforbodyperceptionandaction.
peg-in-hole assembly: A deep-reinforcement-learning approach. Ap- In 2020 Joint IEEE 10th International Conference on Development
pliedSciences,10(19),2020. andLearningandEpigeneticRobotics(ICDL-EpiRob),2020.
[7] ElliottDonlon,SiyuanDong,MelodyLiu,JianhuaLi,EdwardAdel- [26] Corrado Pezzato, Riccardo Ferrari, and Carlos Herna´ndez Corbato.
son, and Alberto Rodriguez. Gelslim: A high-resolution, compact, A novel adaptive controller for robot manipulators based on active
robust, and calibrated tactile-sensing finger. In 2018 IEEE/RSJ inference. IEEERoboticsandAutomationLetters,PP:1–1,022020.
International Conference on Intelligent Robots and Systems (IROS), [27] Guillermo Oliver, Pablo Lanillos, and Gordon Cheng. An empirical
pages1927–1934,2018. studyofactiveinferenceonahumanoidrobot. IEEETransactionson
[8] Mike Lambeta, Po-Wei Chou, Stephen Tian, Brian Yang, Benjamin CognitiveandDevelopmentalSystems,14(2):462–471,2022.
Maloon,VictoriaRoseMost,DaveStroud,RaymondSantos,Ahmad [28] Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech
Byagowi,GreggKammerer,DineshJayaraman,andRobertoCalandra. Zaremba, and Pieter Abbeel. Domain randomization for transferring
Digit: A novel design for a low-cost compact high-resolution tactile deep neural networks from simulation to the real world. In 2017
sensorwithapplicationtoin-handmanipulation. IEEERoboticsand IEEE/RSJInternationalConferenceonIntelligentRobotsandSystems
AutomationLetters,2020. (IROS),pages23–30,2017.
[9] Akhil Padmanabha, Frederik Ebert, Stephen Tian, Roberto Calandra, [29] Alexey Dosovitskiy, Jost Springenberg, Maxim Tatarchenko, and
ChelseaFinn,andSergeyLevine.Omnitact:Amulti-directionalhigh- Thomas Brox. Learning to generate chairs, tables and cars with
resolution touch sensor. 2020 IEEE International Conference on convolutional networks. IEEE Transactions on Pattern Analysis and
RoboticsandAutomation(ICRA),pages618–624,2020. MachineIntelligence,39:1–1,052016.
[10] MariaBauza´,OleguerCanal,andAlbertoRodriguez.Tactilemapping [30] World Robot Summit. Assembly Challenge 2020, 2020. Accessed:
and localization from high-resolution tactile imprints. 2019 Interna- 2023-9-15.
tionalConferenceonRoboticsandAutomation(ICRA),pages3811– [31] N.KoenigandA.Howard. Designanduseparadigmsforgazebo,an
3817,2019. open-source multi-robot simulator. In 2004 IEEE/RSJ International
[11] MariaBauza´,EricValls,BryanLim,TheoSechopoulos,andAlberto Conference on Intelligent Robots and Systems (IROS) (IEEE Cat.
Rodriguez. Tactile object pose estimation from the first touch with No.04CH37566),volume3,pages2149–2154vol.3,2004.
geometriccontactrendering. InConferenceonRobotLearning,2020. [32] MorganQuigley,KenConley,BrianGerkey,JoshFaust,TullyFoote,
[12] TarikKelestemur,RobertPlatt,andTaskinPadir. Tactileposeestima- Jeremy Leibs, Rob Wheeler, and Andrew Ng. Ros: an open-source
tion and policy learning for unknown object manipulation. In Piotr robotoperatingsystem. volume3,012009.
Faliszewski,VivianaMascardi,CatherinePelachaud,andMatthewE. [33] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet
Taylor,editors,21stInternationalConferenceonAutonomousAgents classificationwithdeepconvolutionalneuralnetworks.InProceedings
andMultiagentSystems,AAMAS2022,Auckland,NewZealand,May ofthe25thInternationalConferenceonNeuralInformationProcessing
9-13,2022,pages742–750.InternationalFoundationforAutonomous Systems-Volume1,NIPS’12,page1097–1105,RedHook,NY,USA,
AgentsandMultiagentSystems(IFAAMAS),2022. 2012.CurranAssociatesInc.
[13] Siyuan Dong and Alberto Rodriguez. Tactile-based insertion for
dense box-packing. In 2019 IEEE/RSJ International Conference on
IntelligentRobotsandSystems(IROS),pages7953–7960,2019.
[14] LetianFu,HuangHuang,LarsBerscheid,HuiLi,KenGoldberg,and
Sachin Chitta. Safe self-supervised learning in real of visuo-tactile
feedbackpoliciesforindustrialinsertion. In2023IEEEInternational
ConferenceonRoboticsandAutomation(ICRA),pages10380–10386,
2023.
[15] Siyuan Dong, Devesh Jha, Diego Romeres, Sangwoon Kim, Daniel
Nikovski, and Alberto Rodriguez. Tactile-rl for insertion: General-
izationtoobjectsofunknowngeometry. In2021IEEEInternational
ConferenceonRoboticsandAutomation(ICRA),2021.
[16] Niklas Funk, Paul-Otto Mu¨ller, Boris Belousov, Anton Savchenko,
Rolf Findeisen, and Jan Peters. Canfnet: High-resolution pixelwise
contactareaandnormalforceestimationforvisuotactilesensorsusing
neuralnetworks. 2023.
[17] Karl Friston. Friston, k.j.: The free-energy principle: a unified brain
theory?nat.rev.neurosci.11,127-138.Naturereviews.Neuroscience,
11:127–38,022010.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Tactile-based Active Inference for Force-Controlled Peg-in-Hole Insertions"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
