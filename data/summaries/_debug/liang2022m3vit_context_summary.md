# Context Summary for liang2022m3vit

## Paper Identity
- Title: M$^3$ViT: Mixture-of-Experts Vision Transformer for Efficient Multi-task Learning with Model-Accelerator Co-design
- Full Text Length: 63,324 chars
- Full Text Words: 3,741 words

## Extracted Sections
- Abstract: 2002 chars
- Introduction: 2999 chars
- Conclusion: 0 chars
- Methods: 0 chars
- Results: 0 chars
- Discussion: 0 chars

## Key Terms
vision, mixture, task, accelerator, design, efficient, transformer, learning, model, experts, multi

## Equations Found
7 equations extracted

## Full Text Preview (first 500 chars)
M3ViT: Mixture-of-Experts Vision Transformer
for Efficient Multi-task Learning
with Model-Accelerator Co-design
HanxueLiang1∗,ZhiwenFan1∗,RishovSarkar2,ZiyuJiang3,TianlongChen1,
KaiZou4,YuCheng5,CongHao2,ZhangyangWang1
1UniversityofTexasatAustin,2GeorgiaInstituteofTechnology
3TexasA&MUniversity,4ProtagolabsInc,5MicrosoftResearch
{haliang,zhiwenfan,tianlong.chen,atlaswang}@utexas.edu
{rishov.sarkar,callie.hao}@gatech.edu,jiangziyu@tamu.edu
kz@protagolabs.com,yu.cheng@microsoft.com
Abstract
Multi-...
