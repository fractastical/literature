=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: The free energy principle for action and perception: A mathematical review
Citation Key: buckley2017free
Authors: Christopher L. Buckley, Chang Sub Kim, Simon McGregor

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2017

Abstract: The ‘free energy principle’ (FEP) has been suggested to provide a unified the-
oryofthebrain, integratingdataandtheoryrelatingtoaction, perception, and
learning. The theory and implementation of the FEP combines insights from
Helmholtzian ‘perception as inference’, machine learning theory, and statistical
thermodynamics. Here,weprovideadetailedmathematicalevaluationofasug-
gested biologically plausible implementation of the FEP that has been widely
used to develop the theory. Our objectives are ...

Key Terms: principle, energy, action, review, implementation, perception, theory, brain, learning, mathematical

=== FULL PAPER TEXT ===

The free energy principle for action and perception: A
mathematical review
Christopher L. Buckleya,1,˚, Chang Sub Kimb,1, Simon McGregora, Anil K.
Setha
aSchool of Engineering and Informatics, Evolutionary and Adaptive Systems Group,
University of Sussex, Brighton, BN1 9QJ, UK
bDepartment of Physics, Chonnam National University, Gwangju 61186, Republic of Korea
Abstract
The ‘free energy principle’ (FEP) has been suggested to provide a unified the-
oryofthebrain, integratingdataandtheoryrelatingtoaction, perception, and
learning. The theory and implementation of the FEP combines insights from
Helmholtzian ‘perception as inference’, machine learning theory, and statistical
thermodynamics. Here,weprovideadetailedmathematicalevaluationofasug-
gested biologically plausible implementation of the FEP that has been widely
used to develop the theory. Our objectives are (i) to describe within a single
article the mathematical structure of this implementation of the FEP; (ii) pro-
vide a simple but complete agent-based model utilising the FEP; (iii) disclose
the assumption structure of this implementation of the FEP to help elucidate
its significance for the brain sciences.
Keywords: Free energy principle, perception, action, inference, Bayes
1. Introduction
The brain sciences have long searched for a ‘unified brain theory’ capable
of integrating experimental data relating to, and disclosing the relationships
among, action, perception, and learning. One promising candidate theory that
has emerged over recent years is the ‘free energy principle’ (FEP) [1, 2]. The
5
˚Correspondingauthor
1Jointcontribution
Preprint submitted to Journal of Mathematical Psychology May 26, 2017
7102
yaM
42
]CN.oib-q[
1v65190.5071:viXra
FEPisambitiousinscopeandattemptstoextendevenbeyondthebrainscience
toaccountforadaptivebiologicalprocessesspanninganenormousrangeoftime
scales, from millisecond neuronal dynamics to the tens of millions of years span
covered by evolutionary theory [3, 1].
The FEP has an extensive historical pedigree. Some see its origins starting
10
with Helmholtz’ proposal that perceptions are extracted from sensory data by
probabilistic modelling of their causes [4]. Helmholtz also originated the notion
ofthermodynamicfreeenergy,providingasecondkeyinspirationfortheFEP2.
Theseideashavereachedrecentprominenceinthe‘Bayesianbrain’and‘predic-
tive coding’ models, according to which perceptions are the results of Bayesian
15
inversion of a causal model, and causal models are updated by processing of
sensorysignalsaccordingtoBayes’rule[5,6,7,8]. However,theFEPnaturally
accommodate and description of both action and perception within the same
framework [9] thusothersee it’soriginsin20th-centurycyberneticprinciplesof
homeostasis and predictive control [10].
20
A recognisable precursor to the FEP as applied to brain operation was de-
veloped by Hinton and colleagues, who showed that a function resembling free
energycouldbeusedtoimplementavariationoftheexpectation-maximization
algorithm[11],aswellasfortrainingautoencoders[12]andlearningpopulation
codes [13]. Because these algorithms integrated Bayesian ideas with a notion of
25
free energy, Hinton named them as ‘Helmholtz machines’ [14]. The FEP builds
on these insights to provide a global unified theory of cognition. Essentially,
this work generalizes these results by noting that all (viable) biological organ-
isms resist a tendency to disorder as shown by their homeostatic properties (or,
more generally, their autopoietic properties), and must therefore minimize the
30
occurrence of events which are atypical (‘surprising’) in their habitable envi-
ronment. For example, successful fish typically find themselves surrounded by
water, and very atypically find themselves out of water, since being out of wa-
2Thermodynamic free energy describes the macroscopic properties of nature, typically in
thermalequilibriumwhereittakesminimumvalues,intermsofafewtractablevariables.
2
ter for an extended time will lead to a breakdown of homeostatic (autopoietic)
relations. Because the distribution of ‘surprising’ events is in general unknown
35
and unknowable, organisms must instead minimise a tractable proxy, which ac-
cording to the FEP turns out to be ‘free energy’. Free energy in this context
is an information-theoretic construct that (i) provides an upper bound on the
extent to which sensory data is atypical (‘surprising’) and (ii) can be evaluated
by an organsim, because it depends eventually only on sensory input and an
40
internal model of the environmental causes of sensory input. While at its most
general this theory can arguably be applied to all life-processes [15], it provides
a particularly appealing account of brain function. Specifically it describes how
neuronalprocessescouldimplementfreeenergyminimisationeitherbychanging
sensory input via action on the world, or by updating internal models via per-
45
ception, with implications for understanding the dynamics of, and interactions
among action, perception, and learning. These arguments have been developed
in a series of papers which have appeared over the course of the last several
years [16, 17, 18, 19, 20, 21, 22, 23, 9, 24, 25, 26, 27, 28, 29].
The FEP deserves close examination because of the claims made for its
50
explanatory power. It has been suggested that the FEP discloses novel and
straightforward relationships among fundamental psychological concepts such
as memory, attention, value, reinforcement, and salience [2]. Even more gen-
erally, the FEP is claimed to provide a “mathematical specification of ‘what’
the brain is doing” [[2], p.300], to unify perception and action [9], and to pro-
55
videabasisforintegratingseveralgeneralbraintheoriesincludingtheBayesian
brainhypothesis, neuralDarwinism, Hebbiancellassemblytheory, andoptimal
control and game theory [1]. The FEP has even been suggested to underlie
Freudian constructs in psychoanalysis [25].
Our purpose here is first to supply a mathematical appraisal of the FEP,
60
which we hope will facilitate evaluation of claims such as those listed above;
note that we do not attempt to resolve any such claims here. A mathematical
appraisalisworthwhilebecausetheFEPcombinesadvancedconceptsfromsev-
eral fields, particularly statistical physics, probability theory, machine learning,
3
and theoretical neuroscience. The mathematics involved is non-trivial and has
65
been presented over different stages of evolution and using varying notations.
Here we first provide a complete technical account of the FEP, based on a his-
tory of publications through which the framework has been developed. Second
we provide a complete description of simple agent based model working under
this formulation. While we note that several other agent based models have
70
been presented they have often made use of existing toolboxes which, while
powerful, have perhaps clouded a fuller understanding of the FEP. Lastly we
use our account to identify the assumption structure of the FEP, highlighting
several instances in which non-obvious assumptions are required.
In the next section we provide a brief overview of the FEP followed by
75
detailed guide to the technical content covered in the rest of the paper.
2. An overview of the FEP
BroadlytheFEPisanaccountofcognitionderivedfromtheconsiderationof
how biological organisms maintain their state away from thermodynamic equi-
librium with their ambient surroundings. The argument runs that organisms
are mandated, by the very fact of their existence, to minimize the dispersion of
their constituent states. The atypicality of an event can be quantified by the
negative logarithm of the probability of its sensory data, which is commonly
known in information theory as ‘surprise’ or ‘self-information’ and the overall
atypicality of an organism’s exchanges with its environment can be quantified
as a total lifetime surprise [1, 2]. The term surprise has caused much confusion
since it is distinct from the subjective psychological phenomenon of surprise.
Instead, it is a measure of how atypical a sensory exchange is. This kind of sur-
prise canbe quantified usingthe standard information-theoreticlog-probability
measure
´lnppϕq
where ppϕq is the probability of observing some particular sensory data ϕ in a
typical (habitable) environment. Straightforwardly this quantity is large if the
4
probability of the observed data is small and zero if the data is fully expected,
80
i.e., probability 1. To avoid confusion with the common-sense meaning of the
word ‘surprise’ we will refer to it as “surprisal” or “sensory surprisal”.
2.1. R- and G- Densities
The FEP argues organisms cannot minimise surprisal directly, but instead
minimiseanupperboundcalled‘freeenergy’. Toachievethisitisproposedthat
85
all (well adapted) biological organisms maintain a probabilistic model of their
typical (habitable) environment (which includes their body), and attempt to
minimizetheoccurrenceofeventswhichareatypicalinsuchanenvironmentas
measuredbythismodel. Twokeyprobabilitydensitiesarenecessarytoevaluate
freeenergy. Firstitissuggestedthatorganismsmaintainanimplicitaccountof
90
abestguessattherelevantvariablesthatcomprisetheirenvironment(i.e. those
variables which cause its sensory data). This account is in the form of a prob-
ability distribution over all possible values of those variables, like a Bayesian
belief; this model is instantiated, and parameterised, by physical variables in
the organism’s brain such as neuronal activity and synaptic strengths, respec-
95
tively. When an organism receives sensory signals, it updates this distribution
to better reflect the world around it, allowing it to effectively model its envi-
ronment. Inotherwords, theorganismengagesinaprocesssimilartoBayesian
inference regarding the state of its environment, based on sensory observations.
This internal model of environmental states is called the “recognition density”
100
or the R-density. In order to update the R-density appropriately, the organ-
ism needs some implicit assumptions about how different environmental states
shape sensory input. These assumptions are presumed to be in the form of a
jointprobabilitydensitybetweensensorydataandenvironmentalvariables,the
“generativedensity”,orG-density. Thisdensityisalsopresumedtobeencoded
105
withintheorgansimsbrain. Aswewillsee,followingaBayesianformalism,this
joint density is calculated as the product of two densities; a likelihood describ-
ingtheprobabilityofsensoryinputgivensomeenvironmentalstateandaprior
describing the organisms current ”beliefs” of the probability distribution over
5
environmental states.
110
2.2. Minimising Free Energy
Free energy is a (non-negative) quantity formed from the Kullback-Leibler
divergence between the R- and G-densities. Consequently, it is not a directly
measurablephysicalquantity: itdependsonaninterpretationofbrainvariables
as encoding notional probability densities. Note: the quantity ’free energy’
115
is distinct from thermodynamic free energy thus here we will refer to it as
informational free energy (IFE).
Minimisation of IFE has two functional consequences. First it provides an
upperboundonsensorysurprisal. Thisallowsorganismstoestimatethedisper-
sionoftheirconstituentstatesandiscentraltotheinterpretationofFEPasan
120
accountoflifeprocesses[1]. However,IFEminimisationalsoplaysacentralrole
in a Bayesian approximation method. Specifically ideal (exact) Bayesian infer-
ence,ingeneral,involvesevaluatingdifficultintegralsandthusacorehypothesis
of the FEP framework is that the brain implements approximate Bayesian in-
ference in an analogous way to a method known as variational Bayes. It can
125
be shown that minimising IFE makes the R-density a good approximation to
posterior density of environmental variables given sensory data. Under this in-
terpretation the surprisal term in the IFE becomes more akin to the negative
of log model evidence defined in more standard implementations of variational
Bayes [30].
130
2.3. The Action-Perception Cycle
MinimisingIFEbyupdatingtheR-densityprovidesanupper-boundonsur-
prisal but cannot minimise it directly. The FEP suggests that organisms also
act on their environment to change sensory input, and thus minimise surprisal
indirectly [1, 2]. The mechanism underlying this process is formally symmet-
135
ric to perceptual inference, i.e., rather than inferring the cause of sensory data
an organism must infer actions that best make sensory data accord with an
internal environmental model [9]. Thus, the mechanism is often referred to as
6
active inference. Formally,actionallowsanorganismstoavoidthedispersionof
its constituent states and is suggested to underpin a form of, homoeostasis, or
140
perhaps more precisely homeorhesis [10]. However, equivalently, one can view
action as satisfying hard constraints encoded in the organisms environmental
model [9]. Here expectations in the organism’s G-density (its ”beliefs” about
theworld)cannotbemetdirectlybyperceptionandthusanorganismmustact
to satisfy them. In effect these expectations effectively encode the organism’s
145
desires on environmental dynamics. For example, the organisms model may
prescribe it maintains a desired local temperature; we will see an example of
this in Section 7. Here action is seen as more akin to control [10] where be-
haviour arises from a process of minimising deviations between the organisms
actual and a desired trajectory [9]. Note: an implicit assumption here is that
150
theseconstraintsareconducivetotheorganismssurvival[1,2], perhapsarrived
at by an evolutionary process. Other different roles for action within the FEP
have also been suggested, e.g., action as a process of experimentation with the
goal to disambiguate competing environmental models [31, 10]. However, here
we only consider action as a source of control [9, 10].
155
2.4. Predictive Coding
ThereatleasttwogeneralwaystoviewmostFEP-basedresearch. Firstthe
central theory [17] which offers a particular explanation of cognition in terms
of Bayesian inference. Second a biologically plausible process theory of how the
relevant probability densities could be parameterised by variables in the brain
160
(i.e. a model of what it is that brain variables encode), and how the variables
should be expected to change in order to minimize IFE. The most commonly
usedimplementationoftheFEP,andtheonewefocusonhere,isstronglyanal-
ogous with the predictive coding framework [6]. Specifically predictive coding
theory constitutes one plausible mechanism whereby an organism could update
165
itsenvironmentalmodel(R-density)givenabeliefofhowitsenvironmentworks
(G-density). Theconceptofpredictivecodingoverturnsclassicalnotionsofper-
ception(andcognition)asalargelybottom-upprocessofevidenceaccumulation
7
orfeaturedetectiondrivenbyimpingingsensorysignals,proposinginsteadthat
perceptual content is determined by top-down predictive signals arising from
170
multi-level generative models of the environmental causes of sensory signals,
which are continually modified by bottom-up prediction error signals commu-
nicating mismatches between predicted and actual signals across hierarchical
levels (see [8] for a nice review). In the context of the FEP the R-density is
updated using a hierarchical predictive coding (see Section 8). This has several
175
theoretical benefits. Firstly, under suitable assumption IFE becomes formally
equivalent to prediction error (weighted by confidence terms), which can read-
ily be computed in neural hardware. Hierarchical coding also provides a very
genericpriorwhichallowshigh-levelabstractsensoryfeaturestobelearnedfrom
the data, in a manner similar to deep learning nets [32]. Finally, the sense in
180
which the brain models the environment can be conceptualised in a very direct
way as the prediction of sensory signals. We will also see in Section 8 that this
implementation suggests that we do not even need to know what environmen-
tal features the R- and G-densities constitute a model of. Given appropriate
assumptions, the formalism can be rewritten to depend only on predictions of
185
sensory data, along with recursive predictions of the brain variables which en-
code those predictions.
2.5. A technical guide
In the rest of this work we review the FEP in detail but first we provide a
detailed guide to each section. Most of what we present is related to standard
190
concepts and techniques in statistical mechanics and machine learning. How-
ever, here we present these ideas in detail to make clear their role for the FEP
as theory of biological systems.
In Section 3 we describe the core technical concepts of FEP including the
R-density, G- density, and IFE. We show how minimising IFE has two conse-
195
quences. First, it makes the R-density a better estimate of posterior beliefs
about environmental state given sensory data, thus implementing approximate
Bayesian inference. Second, it makes the IFE itself an upper-bound on sensory
8
surprisal.
InSection4wediscusstheapproximationsthatallowthebraintoexplicitly
200
instantiate the R-density and thus specify IFE. Specifically, we make the ap-
proximationthattheR-densitytakeGaussianform,theLaplace approximation,
and that brain states, e.g. neural activity, represent the sufficient statistics of
thisdistribution(meanandvariance). Utilising this formforthe R-densityand
variousotherapproximationswederiveanexpressionfortheIFEintermsofthe
205
unknown G-density only; we refer to this approximation as the Laplace encoded
energy. The derivations in this section are done for the univariate Gaussian
case, but we give an expression for the full multivariate case at the end of the
section.
InSection5welookatdifferentformsfortheG-density. Westartbyspecify-
210
ingsimplegenerativemodelswhichcomprisethebrain’smodelofhowtheworld
works,i.e.,howsensorydataiscausedbyenvironmental(includingbodily)vari-
ables. We utilise these generative models to specify the brain’s expectation on
environmental states given sensory data in terms of a Gaussian distribution
parametrised by expected means and variances (inverse precisions) on brain
215
states. Combining this with the result of the last section allows us to write an
expression for Laplace encoded-energy as a quadratic sum of prediction errors
(differencebetweenexpectedandactualbrainstatesgivensensorydata)modu-
latedbyexpectedvariances(orinverseprecisions),inlinewithpredictive-coding
processtheories. Initiallyweshowthisforastaticgenerativemodelbutextend
220
it to include dynamic generative models by introducing the concept of gener-
alised motion. Again we derive the results for the univariate case but provide
expressions for the multivariate case.
InSection6weshowhowthebraincoulddynamicallyminimisesIFE.Specif-
ically, we describe how brain states are optimised to minimise IFE through
225
gradient descent. We discuss complications of this method when considering
dynamical generative models.
Section 7 demonstrates how action can be implemented as a similar gradi-
ent descent scheme. Specifically we show how, given a suitable inverse model,
9
actionsarechosentochangesensationsuchthattheyminimiseIFE.Weground
230
this idea, and the mechanisms for perception described in prior sections, in a
simple agent based simulation. We show how an agent with an appropriate
model of the environment, can combine action and perception to minimise IFE
constrained both by the environment and its own expectations on brain states.
In Section 8 we extend the formalism to include learning. Specifically we
235
show how the brain could modify and learn the G-density. To facilitate this we
describenotionofhierarchicalgenerativemodelswhichinvolveempiricalpriors.
We lastly describe a gradient descent schemes which allows the brain to infer
parameters and hyperparameters of the IFE and thus allow the brain to learn
environmental dynamics based on sensory data.
240
Finally, Section 9 summarizes the FEP and discusses the implications of its
assumption structure for the brain sciences.
3. Informational free energy
We start by considering a world that consists of a brain and its surrounding
body/environment. For the rest of the presentation we refer to the body and
245
environment as simply the environment and use this to refer to all processes
outside of the brain. The brain is distinguished from its environment by an in-
terface which is not necessarily a physical boundary but rather may be defined
functionally; thus the boundary could reside at the sensory and motor surfaces
ratherthan, forexample, atthelimitsofthecranialcavity. Theenvironmentis
250
characterized by states, denoted collectively as tϑu, which include well-defined
characteristics like temperature or the orientation of a joint but also unknown
and uncontrollable states, all evolving according to physical laws. The envi-
ronmental states, as exogenous stimuli, give rise to sensory inputs for which
the symbols tϕu are designated collectively. These sensory inputs are assumed
255
to reside at the functional interface distinguishing the brain from the environ-
ment, and we assume a many-to-one (non-bijective) mapping between tϑ} and
tϕu [33]. We further assume that the brain, in conjunction with the body, can
10
perform actions to modify sensory signals.
We assume that the important states of the environment cannot be directly
perceivedbyanorganismbutinsteadmustbeinferredbyaprocessofBayesian
inference. Specifically, the goal of the agent is to determine the probability
of environmental states given its sensory input. To achieve this we assume
organism’s encodes prior beliefs about these states characterized by the joint
density ppϑ,ϕq or G-density. Where the G-density can be factorized into (with
respecttoϑ),theprior ppϑq(correspondingtotheorganism’s”beliefs”aboutthe
worldbeforesensoryinputisreceived)andalikelihood ppϕ|ϑq(correspondingto
the organism’s assumptions about how environmental dynamics cause sensory
input),
ppϑ,ϕq“ppϕ|ϑqppϑq. (1)
Give an observation, ϕ “ φ (e.g. some particular sensory data), a posterior
260
belief about the environment can then be written as ppϑ|ϕ“φq. This quantity
can be calculated using the prior and likelihood using Bayes theorem as,
1 ppφ|ϑqppϑq
ş
ppϑ|φq“ ppφ|ϑqppϑq“ . (2)
ppϕ“φq ppφ|ϑqppϑqdϑ
All the probability densities are assumed to be normalized as
ż ż ż ż
dϑ dϕ ppϑ,ϕq“ dϑ ppϑq“ dϕ ppϕq“1,
whereppϑqandppϕqarethereducedormarginalprobability-densitiesconform-
ing to ż ż
ppϑq“ dϕ ppϑ,ϕq and ppϕq“ dϑ ppϑ,ϕq. (3)
Tocalculatetheposteriorprobabilityitisnecessarytoevaluatethemarginal
ş
integral, ppφ|ϑqppϑqϑ, in the denominator of equation (2). However, this is
often difficult, if not practically intractable. For example, when continuous
functions are used to approximate the likelihood and prior, the integral may
be analytically intractable. Or in the discrete case, when this integral reduces
to a sum, the number of calculations may grow exponentially with the number
of states. Variational Bayes (sometimes known as ‘ensemble learning’) is a
11
method for (approximately) determining ppϑ|ϕq which avoids the evaluation of
this integral, by introducing an optimization problem [20]. Such an approach
requires an auxiliary probability density, representing the current ‘best guess’
of the causes of sensory input. This is the recognition density, or R-density,
introduced in the overview. Again the R-density is also normalised as:
ż
qpϑqdϑ“1. (4)
We can construct a measure of the difference between this density and the true
posterior in terms of an information-theoretic divergence, e.g., the Kullback-
Leibler divergence [34], i.e.,
ż
qpϑq
D pqpϑq||ppϑ|ϕqq“ dϑ qpϑqln (5)
KL ppϑ|ϕq
An R-density that minimises this divergence would provide a good approxi-
mation to the true posterior. But obviously we cannot evaluate this quantity
because we still do not know the true posterior. However, we can rewrite this
equation as,
D pqpϑq||ppϑ|ϕqq“F `lnppϕq (6)
KL
where we have defined F as the informational free energy (IFE),
ż
qpϑq
F ” dϑ qpϑqln . (7)
ppϑ,ϕq
Note here we have introduced the G-density to the denominator on the right-
hand side. In contrast to equation (5) we can evaluate IFE directly because it
depends only on the R-density, which we are free to specify, and the G-density,
265
i.e., a model of the environmental causes of sensory input. Furthermore, the
second term on the right-hand side in equation (6) only depends on sensory
input and is independent of the form of the R-density. Thus, minimising equa-
tion (7) with respect to the R-density will also minimise the Kullback-Leibler
divergence between the R-density and the true posterior. Thus, the result of
270
this minimisation will make the R-density approximate the true posterior.
TheminimisationofIFEalsosuggestsanindirectwaytoestimatesurprisal.
12
Specifically according to Jensen’s inequality [34], the Kullback-Leibler diver-
gence is always greater than zero. This implies the inequality,
F ě´lnppϕq. (8)
which means that the IFE also provides an upper bound on the surprisal as
described in Section 1. However, note the IFE is equal to surprisal only when
the R-density qpϑq becomes identical with the posterior density ppϑ|ϕq; i.e., it
is this condition that specifies when IFE provides a tight bound on surprisal
275
(see Section 2). Furthermore, while this process furnishes the organism with
an approximation of surprisal it does not minimise it. Instead the organism
can minimise IFE further by minimising surprisal indirectly by acting on the
environment and changing sensory input, see Section 7.
Note: formally ppϕq, which describes the agent’s internal (implicit) prob-
280
abilistic predictions of sensory inputs, should be written as as ppϕ|mq. This
follows a convention in Bayesian statistics to indicate that a reasoner must be-
gin with some arbitrary prior before it can learn anything; ppϕq indicates the
prior assigned to p ab initio by agent m. However, this notation is unwieldly
and does not change the derivations that follow thus we will omit this for the
285
rest of the presentation.
There are several analogies between the terms in the formalism above and
theformulationofHelmoltz’thermodynamicfreeenergy. Thesetermscanserve
as useful substitutions in the derivation to come and, thus, we describe them
here. SpecificallywhentheG-densityisunpackedinequation(7),theIFEsplits
into two terms,
ż ż
F “ dϑ qpϑqEpϑ,ϕq` dϑ qpϑqlnqpϑq (9)
where, formally speaking, the first term in equation (9) is an average of the
quantity
Epϑ,ϕq”´lnppϑ,ϕq (10)
over the R-density qpϑq and the second term is essentially the negative entropy
associated with the recognition density. By analogy with Helmoltz’ thermody-
13
namic free energy the first term in equation (9) is called average energy [Ac-
cordingly, Epϑ,ϕq itself may be termed the energy] and the second term the
290
negative of entropy [35].
In summary, minimising IFE with respect to the R-density, given an ap-
propriate model for the G-density ppϑ,ϕq in which the sensory inputs are en-
capsulated, allows one to approximate the Bayesian posterior. Furthermore
minimising IFE through perception also gives a lower bound on the sensory
295
surprisal.
Table1providesasummaryofthemathematicalobjectsassociatedwiththe
IFE.
4. The R-density: How the brain encodes environmental states
To implement the method described above the brain must explicitly encode
300
the R-density. To achieve this it is suggested that neuronal quantities (e.g.,
neural activity) parametrize sufficient statistics (e.g., means and variances, see
later)ofaprobabilitydistribution. Morepreciselytheneuronalvariablesencode
afamilyofprobabilitydensitiesoverenvironmentalstates,ϑ. Theinstantaneous
state of the brain µ then picks out a particular density qpϑ;µq (the R-density)
305
from this family; the semicolon in qpϑ;µq indicates that µ is a parameter rather
than a random variable.
Finding the optimal qpϑ;µq that minimises IFE in the most general case
is intractable and thus further approximations about the form of this density
are required. Two types of approximation are often utilised. First, an assump-
310
tion that the R-density qpϑq can be factorised into independent sub-densities
q pθ qˆ¨¨¨q pθ q. Under this assumption the optimal R-density still cannot
1 1 N N
be expressed in closed form but an approximate solution (of general form) can
be improved iteratively [36]. This leads to a formal solution in which the sub-
densities affect each other only through mean-field quantities. Approaches that
315
utilise this form of the R-density are often referred to an ensemble learning.
This approach is not the focus of the work presented here but for completeness
14
we provide a treatment of unconstrained ensemble learning in Appendix A.
A more common approximation is to assume that the R-density take Gaus-
sian form, the so called Laplace approximation [20]. In this scenario, the suf-
ficient statistics of the Gaussian become parameters which can be optimized
numerically to minimize IFE. For example the R-densities take the form
(cid:32) (
1
qpϑq”Npϑ;µ,ζq“ ? exp ´pϑ´µq2{p2ζq (11)
2πζ
where µ and ζ are the mean and variance values of a single environmental
variable ϑ. Substituting this form for the R-density into equation (7), and
carryingouttheintegrationproducesavastlysimplifiedexpressionfortheIFE.
Infollowingweexaminethisderivationindetail. Fortheclarityofpresentation
we pursue it in the univariate case which captures all the relevant assumptions
for the multivariate case. We write the formulation for the multivariate case at
the end of the section. For notational ease we define
a
Z ” 2πζ and Epϑq”pϑ´µq2{p2ζq, (12)
to arrive at
1
qpϑ;µ,ζq“ e´Epϑq, (13)
Z
where here we have drawn on terminology from statistical physics in which the
normalizationfactorZ iscalledthepartitionfunction andEpϑqtheenergyofthe
320
subsystem tϑu [37]. Substituting this equation into equation (9) and carrying
out the integration leads to a much simplified expression for IFE :
ż ż
F “ dϑ qpϑqp´lnZ´Eq` dϑ qpϑqEpϑ,ϕq
ż
“ ´lnZ´ dϑ qpϑqEpϑq
ż
` dϑ qpϑqEpϑ,ϕq (14)
wherewehaveusedthenormalizationcondition,equation(4)inthesecondstep.
TheGaussianintegrationinvolvedinthefirstandsecondtermsinequation(14)
canbeevaluatedstraightforwardly. Specifically,utilisingequation(12),thefirst
15
term in equation (14) can be readily manipulated into
1
´lnZ “´ pln2πζq.
2
Using equation (12) the second term in equation (14) becomes
ż
1 1
´ dϑ qpϑq pϑ´µq2 Ñ´ .
2ζ 2
The final term demands further technical consideration because the energy
Epϑ,ϕq is still unspecified. However, further simplifications can be made by
assuming that the R-density, equation (13) is sharply peaked at its mean value
325
µ (i.e., the Gaussian bell-shape is squeezed towards a delta function) and that
Epϑ,ϕq is a smooth function of ϑ. Under these assumptions we notice that the
integrationisappreciablynon-zeroonlyatthepeaks. OnecanthenuseaTaylor
expansionofEpϑ,ϕqaroundϑ“µwithrespecttoasmallincrement,δϑ. Note:
while these assumptions permit a simple analytic model of the FEP, they have
330
non-trivial implications for the interpretation of brain function so we return to
this issue at the end of this section and in the Discussion. This assumption
brings about,
ż
dϑ qpϑqEpϑ,ϕq,
ż # „  „  +
dE 1 d2E
« dϑ qpϑq Epµ,ϕq` δϑ` δϑ2 .
dϑ 2 Bϑ2
µ µ
Now substituting back δϑ“ϑ´µ we get,
„  ż
BE
«Epµ,ϕq` dϑ qpϑqpϑ´µq
Bϑ
„  ż µ
1 d2E
` dϑ qpϑqpϑ´µq2.
2 dϑ2
µ
Here the second term in the third line is zero identically because the integral
equates to the mean. Furthermore recognising the expression for the variance
in the third term allows us to write
„ 
1 d2E
«Epµ,ϕq` ζ. (15)
2 dϑ2
µ
16
WhereweidentifyEpµ,ϕqastheLaplace-encodedenergy. Substitutingallterms
derived so far into equation (14) furnishes an approximate expression for the
IFE, ˜„  ¸
1 d2E
F “Epµ,ϕq` ζ´ln2πζ´1 (16)
2 dϑ2
µ
whichisnowwrittenasafunction (i.e.,notafunctional)oftheGaussianmeans
335
and variances, and sensory inputs, i.e. F “ Fpµ,ζ,ϕq. To simplify further we
remove the dependence of the IFE on the variances by taking derivative of
equation (16) with respect ζ as follows:
# ˜„  ¸ +
1 d d2E 1
dF “ ζ ´ dζ
2 dζ dϑ2 ζ
#„  µ+
1 d2E 1
“ ´ dζ.
2 dϑ ζ
l µ
Minimising by demanding that dF ”0 one can get
„ 
d2E ´1
ζ˚ “ (17)
dϑ2
µ
where the superscript in ζ˚ indicates again that it is an optimal variance (i.e.,
it is the variance which optimizes the IFE). Substituting equation (17) into
equation (16) gives rise to the form of the IFE as
1
F “Epµ,ϕq´ lnt2πζ˚u. (18)
2
ThebenefitofthisprocesshasbeentorecasttheIFEintermsofajointdensity
ppµ,ϕq over sensory data ϕ and the R-density’s sufficient statistics µ, rather
340
than a joint density over some (unspecified) environmental features ϑ. Note:
this joint density amounts to an approximation of the G-density described in
equation (1); we shall examine the implementation of this density in detail in
the next section. Furthermore, under these assumptions the IFE only depends
onGaussianmeans(first-orderGaussianstatistics)andsensoryinputs,andnot
345
on variances (second-order Gaussian statistics), which considerably simplifies
the expression. It is possible to pursue an analogous derivation for the full
multivariate Gaussian distribution under the more general assumption that the
17
environment states only weakly covary, i.e., both the variance of, and covari-
ances between, variables are small. Under this assumption the full R-density
350
distribution is still tightly peaked and the Taylor expansion employed in equa-
tion (15) is still valid.
To get rid of the constant variance term in equation (18), we write the
Laplace-encoded energy for the full multivariate case, as an approximation for
the full IFE as
Eptµ u,tϕ uq“´lnpptµ u,tϕ uq, (19)
α α α α
where we define tµ u and tϕ u as vectors of brain states and sensory data re-
α α
spectively, corresponding to environmental variables tϑ u with α“1,2,¨¨¨ ,N
α
indexing N variables. This equation for the Laplace-encoded energy serves as a
355
general approximation for the IFE which we will use in the rest of this study.
Conceptually this expression suggests the brain represents only the most
likelyenvironmentalcausesofsensorydataandnotthedetailsoftheirdistribu-
tion per se .However, as we will see later, the brain also encodes uncertainties
through (expectations about) variances (inverse variances) in the G-density.
360
Table 2 provides a glossary of mathematical objects involved in the Laplace
encoding of the environmental states in the brain.
5. The G-density: Encoding the brains beliefs about environmental
causes
In the previous section we constructed an approximation of the IFE, which
365
we called the Laplace-encoded energy, in terms of the approximate G-density
ppµ,ϕq where the environmental states ϑ have been replaced by the sufficient
statistics µ of the R-density. In this section we consider how the brain could
specify this G-density, and thus evaluate IFE. We start specifying a generative
model of the environmental causes of sensory data (informally, a description of
370
causal dependencies in the environment and their relation to sensory signals).
We then show how to move from these generative models to specification of the
G-density, in terms of brain states and their expectations, and finally construct
18
expressionsfortheIFE.WedevelopvariousspecificationsofG-densitiesforboth
static and dynamic representations of the environment and derive the different
375
expressions for IFE they imply.
Table 3 provides a summary of the mathematical objects associated with
the G-density in the simplest model and also its extension to the dynamical
generative model.
5.1. The simplest generative model
380
We first consider a simplified situation corresponding to an organism that
believes in an environment comprising of a single variable and a single sensory
channel. To represent this environment the agent utilise a single brain state µ
andsensoryinputϕ. Wethenwritetheorganismsbeliefabouttheenvironment
directlyintermsofagenerativemappingbetweenbrainstatesandsensorydata.
Notetheseequationswillhaveaslightlystrangeconstructionbecauseinreality
sensorydataiscausedbyenvironmental,notbrain,states. However,writingthe
organismbeliefsinthiswaywillallowustoeasilyconstructagenerativedensity,
see below. Specifically we assume the agent believe its sensory is generated as
ϕ“gpµ;θq`z (20)
where g is a linear or nonlinear function, parametrized by θ and z is a random
variablewithzeromeanandvarianceσ . Thustheorganismbelievesitssensory
z
data is generated as non-linear mapping between environmental states (here
denoted in terms of its belief about environmental state µ) with added noise.
Similarly we specify the organism beliefs about how environmental state are
generated as
µ“µ¯`w, (21)
where µ¯ is some fixed parameter and w is random noise drawn from a Gaus-
sian with zero mean and variance σ . In other words, the organism takes the
w
environment’sfuturestatestobehistory-independent, fluctuatingaroundsome
mean value µ¯ which is given a priori to the organism. There is a potential
confusion here because equation equation (21) describes a distribution over the
385
19
brainstatevariableµ,whichitselfrepresentsthemeanofsomerepresentedenvi-
ronmentalstateϑ. Specificallyitisworthreiteratingthatµ¯ andσ aredistinct
w
from the sufficient statistics of the R-density µ and ζ [see equation (11)]. The
variables µ¯ represent the organism’s belief about the future state of the envi-
ronmentasencodedintheG-densityandσ encodestheorganism’sconfidence
390 w
in its estimate of those future states. By contrast µ,ζ belong to the R-density,
encoding the organism’s uncertain beliefs about its current environment ϑ. As
we will see in Section 7, there is conflict here because the organism’s best esti-
mate µ (the mean of its subjective distribution over ϑ) may not be in line with
its expectation µ¯ stemming from its model of environmental dynamics.
395
To construct the generative density we assume that the noise z is given as
(cid:32) (
?
Gaussian, r1{ 2πσ sexp ´z2{p2σ q . Then, rewriting equation (20) as z “
z z
ϕ´gpµ;θq, the functional form of the likelihood ppϕ|µq can be written as
! )
1
ppϕ|µq“ ? exp ´pϕ´gpµ;θqq 2 {p2σ q . (22)
z
2πσ
z
Assuming similar Gaussian noise for the random deviation w “µ´µ¯, in equa-
tion (34), the prior density ppµq can be written as
! )
1
ppµq“ ? exp ´pµ´µ¯q 2 {p2σ q (23)
w
2πσ
w
where σ is the variance.
w
Thus far, we have specified the likelihood and the prior of µ which together
determine the G-density ppµ,ϕq according to the identity,
ppµ,ϕq“ppϕ,µq“ppϕ|µqppµq.
Next, we construct the Laplace-encoded energy by substituting the likelihood
and prior densities obtained above into equation (19) to get, up to a constant,
Epµ,ϕq “ ´lnppϕ|µq´lnppµq (24)
1 1 1
“ ε2` ε2 ` lnpσ σ q, (25)
2σ z 2σ w 2 z w
z w
where the auxiliary notations have been introduced as
ε ”ϕ´gpµ;θq and ε ”µ´µ¯.
z w
20
which comprise a residual error or a prediction error in the predictive coding
terminology[6]. Thequantityε isameasureofthediscrepancybetweenactual
400 z
ϕ and the outcome of its prediction gpµ;θq. While ε describes the extent to
w
which µ itself deviates from its expectation µ¯. The former describes sensory
prediction errors, ε , while the latter describe model predictions, ε , (i.e.,
z w
how brain states deviate from their expectation). Each erro term is multiplied
by the inverse of variance which weight the relative confidence of these term,
405
i.e., how they contribute to the Laplace-encoded energy. We note in other
works the inverse of variance, know as a precision, is used in these equations
perhaps to highlight that these terms weight the confidence, or preciseness, of
theprediction. Howeverinthispresentationwesticktomorestandardnotation
involving variances.
410
Theabovecalculationcanbestraightforwardlyextendedtothemultivariate
case. Specifically,werepresenttµ uasarowvectorofN brainstates,andwrite
α
their expectations as
µ “µ¯ `w .
α α α
Heretw uisarowvectordescribingcorrelatednoisesources,thusgenerallythe
α
fluctuationsofeachvariablearenotindependent, whichallhavezeromeanand
covariance Σ . We can the write a set of N sensory inputs tϕ u which depend
w α
on combination of these brain states in some nonlinear way such that
ϕ “g pµ ,µ ,...,µ q`z . (26)
α α 0 1 N α
Again tz u are noise sources with zero mean and covariance Σ and thus each
α z
sensory input may receive statistically correlated noise. Then, the prior over
brainstatesmayberepresentedasthemultivariatecorrelatedGaussiandensity,
ˆ ˙
1 1
pptµ uq“ a exp ´ tµ ´µ¯ uΣ´1tµ ´µ¯ uT , (27)
α p2πqN|Σ | 2 α α w α α
w
where tµ ´µ¯ uT is the transpose of vector tµ ´µ¯ u; |Σ | and Σ´1 are the
α α α α w w
determinantandtheinverseofthecovariancematrixΣ ,respectively. Similarly,
w
21
we can write down the multivariate likelihood as
ˆ ˙
1 1
pptϕ u|tµ uq“ a exp ´ tϕ ´g pµquΣ´1tϕ ´g pµquT .
α α p2πqN|Σ | 2 α α z α α
z
(28)
Now substituting these expressions into equation (19) we can get an expression
of the Laplace-encoded energy as, up to an overall constant,
1 1
Eptϕ u,tµ uq “ tµ ´µ¯ uΣ´1tµ ´µ¯ uT ` ln|Σ |
α α 2 α α w α α 2 w
1 1
` tϕ ´g pµquΣ´1tϕ ´g pµquT ` ln|Σ |. (29)
2 α α z α α 2 z
Theaboveequation(29)containsnon-trivialcorrelationsamongthebrainvari-
ables and sensory data. It is possible to pursue the full general case, e.g., see
[38] for a nice tutorial on this, but we do not consider this here. Instead we can
415
simplify on the assumption of statistical independence between environmental
variables and between sensory inputs. Under this assumption the prior and
likelihood are factorised into the simple forms, respectively,
źN
pptµ uq“ ppµ q, (30)
α α
α“1
źN
pptϕ u|tµ uq“ ppϕ |tµ uq, (31)
α α α α
α“1
where probability densities are the uncorrelated Gaussians,
źN
1
(cid:32) (
pptµ uq“ ? exp ´rµ ´µ¯ s2{p2σαq ,
α 2πσα α α w
α“1 z
źN
1
(cid:32) (
pptϕ u|tµ uq“ ? exp ´rϕ ´g pµqs2{p2σαq .
α α 2πσα α α z
α“1 w
This gives the Laplace-encoded energy as
„  „ 
ÿN
pεαq2 1
ÿN
pεαq2 1
Eptϕ u,tµ uq“ w ` lnσα ` z ` lnσα , (32)
α α 2σα 2 w 2σα 2 z
α“1 w α“1 z
wherethevariancesσα andσα arediagonalelementsofthecovariancematrices
420 w z
Σ and Σ , respectively. In equation (32) we have again used the auxiliary
w z
variables
εα “ µ ´µ¯ ,
w α α
εα “ ϕ ´g ,
z α α
22
Thestructureofequation(32)suggeststhattheLaplace-encodedenergy,which
is an approximation for the IFE, is a quadratic sum of the prediction-errors,
modulated by the corresponding inverse variances, and an additional sum of
425
the logarithm of the variances.
5.2. A dynamical generative model
Intheprevioussectionweconsideredasimplegenerativemodelwhereanor-
ganismunderstoodtheenvironmenttobeeffectivelystatic. Hereweextendthe
formulation to dynamic generative models which have the potential to support
inference in dynamically changing environments. Again we start by examining
a single sensory input ϕ and a univariate brain state µ. Here we assume that
theagent’smodelofenvironmentaldynamics(againexpressedintermsofbrain
states) follows not equation (21), but rather a Langevin-type equation [39]
dµ
“fpµq`w (33)
dt
where f is a function of µ and w is a random fluctuation. A dynamical gener-
ative model can then be obtained by combining the simple generative model,
equation (20), with equation (33).
430
The FEP utilizes the notions of generalized coordinates and higher-order
motion [20] to incorporate general forms of dynamics into the G-density. Gen-
eralised coordinates involve representing the state of a dynamical system in
termsofincreasinglyhigherorderderivativeofitsstatevariables. Forexample,
generalized coordinates of a position variable may correspond to bare ‘position’
435
as well as its (unbounded) higher-order temporal derivatives (velocity, accel-
eration, jerk, and so on) allowing a more precise specification of a system’s
state [20]. To obtain these coordinates we simply take recursively higher order
derivatives of both equation (20) and equation (33).
23
For the sensory data:
440
ϕ “ gpµq`z
Bg
ϕ1 “ µ1`z1 (34)
Bµ
Bg
ϕ2 “ µ2`z2
Bµ
.
.
.
where we have used the notations,
ϕ1 ”dϕ{dt, µ1 ”dµ{dt, µ2 ”d2µ{dt2, etc.
and where z,z1,... are thenoises sources at each dynamicorder. Here nonlinear
derivativetermssuchasµ12,µ1µ2,etc,havebeenneglectedunderalocallinearity
assumption [18] and only linear terms have been collected. In some treatments
of the FEP it is assumed that the noise sources are correlated [20]. However,
here, for the clarity of the following derivations, we follow more standard state
445
space models and assume each dynamical order receives independent noise, i.e,
we assume the covariance between noise sources is zero.
Similarly, the Langevin equation, equation (33), is generalized as
µ1 “ fpµq`w
Bf
µ2 “ µ1`w1 (35)
Bµ
Bf
µ3 “ µ2`w2
Bµ
.
.
.
where again we have applied the local linearity approximation and we assume
each dynamical order receives independent noise denoted as w,w1,.... Here, it
is convenient to denote the multi-dimensional sensory-data ϕ˜ as
ϕ˜“pϕ,ϕ1,ϕ1,¨¨¨q”pϕ ,ϕ ,ϕ ,¨¨¨q
r0s r1s r2s
and states µ˜ as
µ˜ “pµ,µ1,µ2,¨¨¨q”pµ ,µ ,µ ,¨¨¨q, (36)
r0s r1s r2s
24
both being row vectors; where the nth-components are defined to be
dn dn
ϕ ” ϕ“ϕ1 and µ ” µ“µ1 .
rns dtn rn´1s rns dtn rn´1s
The generalized coordinates, equation (36), span the generalized state-space
in mathematical terms. In this state-space, a point represents an infinite-
dimensionalvectorthatencodestheinstantaneoustrajectoryofabrainvariable
[21]. By construction, the time-derivative of the state vector µ˜ becomes
d
µ˜1 ”Dµ˜ ” pµ,µ1,µ2,¨¨¨q“pµ1,µ2,µ3¨¨¨q”pµ ,µ ,µ ,¨¨¨q.
dt r1s r2s r3s
The fluctuations in the generalized coordinates are written as
z˜“pz,z1,z2,¨¨¨q”pz ,z ,z ,¨¨¨q,
r0s r1s r2s
w˜ “pw,w1,w2,¨¨¨q”pw ,w ,w ,¨¨¨q.
r0s r1s r2s
In addition, we denote the vectors associated with time-derivatives of the gen-
erative functions as
g˜”pg ,g ,g ,¨¨¨q and f˜ ”pf ,f ,f ,¨¨¨q
r0s r1s r2s r0s r1s r2s
where the components are given as g ” gpµq and f ” fpµq, and for n ě 1
r0s r0s
as
Bg Bf
g ” µ and f ” µ .
rns Bµ rns rns Bµ rns
In terms of these constructs the infinite set of coupled equations (34) and (35)
can be written in a compact form as
450
ϕ˜ “ g˜`z˜ (37)
Dµ˜ “ f˜ `w˜ (38)
The generalized map, equation (37), describes how the sensory data ϕ˜ are in-
ferredbytherepresentationsoftheircausesµ˜ateachdynamicalorder. Accord-
ing to this map, the sensory data at a particular dynamical order n, i.e. ϕ ,
rns
engages only with the same dynamical order of the brain states, i.e. µ . The
rns
25
generalized equation of motion, equation (38), specifies the coupling between
455
adjacent dynamical orders.
Asbefore, inordertoobtaintheG-densityweneedtospecifythelikelihood
of the sensory data ppϕ˜|µ˜q and the prior ppµ˜q. The statistical independence
of noise at each dynamical order means that we can write the likelihood as a
product of conditional densities, i.e.,
460
ppϕ˜|µ˜q “ ppϕ ,ϕ ,ϕ ,¨¨¨|µ ,µ ,µ ,¨¨¨q
r0s r1s r2s r0s r1s r2s
ź8
“ ppϕ |µ q. (39)
rns rns
n“0
Assuming that the fluctuations at all dynamics orders, z , are induced by
rns
Gaussian noise, the conditional likelihood-density ppϕrns|µrnsq is specified as
” (cid:32) ( ` ˘ı
1
ppϕ |µ q“ a exp ´ ϕ ´g 2 { 2σ .
rns rns 2πσ rns rns zrns
zrns
Similarly,thepostulateoftheconditionalindependenceofthegeneralizednoises
w leads to a prior in the form
rns
ź8
ppµ˜q“ppµ ,µ ,µ ,¨¨¨q“ ppµ |µ q (40)
r0s r1s r2s rn`1s rns
n“0
The form of the prior density at dynamical order n is fixed by the assumption
of Gaussian noise, which is then given as
” (cid:32) ( ` ˘ı
1
ppµ |µ q“ a exp ´ µ ´f 2 { 2σ .
rn`1s rns 2πσ rn`1s rns wrns
wrns
Utilizing equations (39) and (40), the G-density is specified as
ź8
ppϕ˜,µ˜q“ ppϕ |µ qppµ |µ q. (41)
rns rns rn`1s rns
n“0
GiventheG-density,theLaplace-encodedenergycanbecalculated(equation(19))
to give, up to a constant,
" *
ÿ8
1 1
Epµ˜,ϕ˜q “ rε s2` lnσ
2σ zrns 2 zrns
n“0" zrns *
ÿ8
1 1
` rε s2` lnσ (42)
2σ wrns 2 wrns
n“0 wrns
26
where ε and ε are nth component of the vectors ε˜ and ε˜ , respectively,
zrns wrns z w
which have been defined to be
ε ”ϕ ´g and ε ”µ ´f .
zrns rns rns wrns rn`1s rns
Asbefore,theauxiliaryvariables,ε andε ,encodepredictionerrors: ε
zrns wrns zrns
is the error between the sensory data ϕ and its prediction g at dynamical
rns rns
ordern. Likewise,ε measuresthediscrepancybetweentheexpectedhigher-
wrns
order output µ and its generation f from dynamical order n. Typically
rn`1s rns
only dynamics up to finite order are considered. This can be done by setting
the highest order term to random fluctuations, i.e.,
µ “w
rnmaxs rnmaxs
where w has large variance; thus, the corresponding error term in equa-
rnmaxs
tion (42) will be close to zero and effectively eliminated from the expression for
the Laplace-encoded energy. In effect it means that the order below is uncon-
465
strained, and free to change in a way that best fits the incoming sensory data.
ThisisrelatedtothenotionofempiricalpriorsasdiscussedinSection8.1. Thus
we have expressed Laplace-encoded energy for dynamics environment, which is
anapproximationfortheIFE,isaquadraticsumofthesensoryprediction-error,
ε , and model prediction errors, ε , across different dynamical orders.
470 wrns wrns
Again each error term is modulated by the corresponding variances describing
the degree of certainty in those predictions.
Again its is straightforward we can generalise this to the multivariate case.
We set tϕ˜ u and tµ˜ u as vectors of brain states and rewrite equations (37) and
α α
(38) as
475
ϕ˜ “ g˜ `z˜ (43)
α α α
Dµ˜ “ f˜ `w˜ , (44)
α α α
27
where α runs from 1 to N. Thus, equation (42) becomes
# +
ÿN ÿ8
1 1
Eptµ˜ u,tϕ˜ uq “ rεα s2` lnσα
α α 2σα zrns 2 zrns
α“1n“0# zrns +
ÿN ÿ8
1 1
` rεα s2` lnσα (45)
2σα wrns 2 wrns
α“1n“0 wrns
where we have again used the auxiliary variables
εα ” ϕ ´g (46)
zrns αrns αrns
εα ” µ ´f . (47)
wrns αrn`1s αrns
Thus this constitutes an approximation of IFE for a multivariate system across
arbitrary number of dynamical orders.
6. IFE minimisation: How organisms infer environmental states
480
Intheprevioussectionwedemonstratedhowtogofromagenerativemodel,
specifyingtheorganism’sbeliefsabouttheenvironment,toagenerativedensity
given expectations on brain states, and finally to an expression for the IFE.
In this section we discuss how organisms could minimises IFE to make the R-
densityagoodapproximationoftheposteriorandthuswebegintooutlineafull
485
biologically plausible process theory. In particular, here, we focus on how this
minimisationcouldbeimplementedinneuronaldynamicsofthebrainoutlining
one particular process theory.
Under the FEP it is proposed that the innate dynamics of the neural ac-
tivity evolves in such a way as to minimise the IFE. Specifically, it is sug-
gested that brain states change in such way that they implement a gradient
descentschemeonIFEreferredtoasrecognition dynamics. Undertheproposed
gradient-descent scheme, a brain state µ is updated between two sequential
α
steps t and t`1 as
µt`1 “µt ´κµˆ ¨∇ Eptµ u,tϕ uq
α α α µα α α
28
where κ is the learning rate and µˆ is the unit vector along µ . This process
α α
recursively modifies brain states in a way that follows the gradient of Laplace-
encodedenergy. Inthecontinuouslimittheupdateµα ´µα maybeconverted
t`1 t
to a differential form as
µt`1´µt ”µ9 .
α α α
Then, the above discrete updating-scheme can be transformed into a spatio-
temporal differential equation,
µ9 “´κµˆ ¨∇ Eptµ u,tϕ uq. (48)
α α µα α α
The essence of the gradient descent method, as described in equation (48), is
that the minima of the objective function E, i.e., the point where ∇ E “ 0,
490 µ
occur at the stationary solution when µ9 vanishes. Thus the dynamics of the
α
brain states settle at a point where the Laplace-encoded energy is minimized.
To update dynamical orders of the brain state µ , equation (48) must be
α
further generalized to give
µ ´µ ”´κµˆ ¨∇ Eptµ˜ u,tϕ˜ uq
αrn`1s αrns αrns µ˜α α α
where µˆ is the unit vector along µ , nth-component of the generalized
αrns αrns
brain state µ˜ (Section 5.2). Also, as before (equation (48)) the sequential
α
dynamical order pn,n`1q can be recast into a differential form to give
µ1 “´κµˆ ¨∇ Eptµ˜ u,tϕ˜ uq. (49)
αrns αrns µ˜α α α
Note that in order to be consistent with the definition of the generalised co-
ordinates we have used the distinctive notation for the temporal derivative of
dynamic update from the parametric update, equation (48). Here, we face a
complication because the temporal derivative of the dynamical order µ is
αrns
already contained within the generalized coordinates, i.e., µ1 “ µ , in
αrns αrn`1s
virtue of the definition of the latter. Consequently, it is not possible to make
µ1 vanishatanyorder,meaningthatthegradientdescentprocedureisunable
αrns
to construct a stationary solution at which the gradient of the Laplace-encoded
29
energyvanishes. However,itcanbearguedthatthemotionofapoint(velocity),
i.e. µ˜9 , in the generalized state-space is distinct from the ‘trajectory’ encoded
α
in the brain (flow velocity) [20, 36, 21]. The latter object is denoted by Dµ˜
α
whereD impliesalsoatime-derivativeoperatorwhich,whenactedonµ˜,results
in (see Section 5.2)
Dµ˜ ”pµ1 ,µ1 ,µ1 ¨¨¨q”pµ1 ,µ2,µ3¨¨¨q,
α αr0s αr1s αr2s α α α
butisbythisassumptiondistinctfromtheusualtime-derivativeµ˜9 ,i.e. µ1 ‰
α αrns
µ9 . The term ‘velocity’ here has been adapted by analogy with velocity in
αrns
mechanics in the sense that µ˜9 denotes first order time-derivative of ‘position’,
α
namely the bare variable µ˜ . Prepared with this extra theoretical construct,
α
the gradient descent scheme is restated in the FEP as
µ9 ´Dµ “´κµˆ ¨∇ Eptµ˜ u,tϕ˜ uq (50)
αrns αrns αrns µ˜α α α
where Dµ “ µ1 . According to this formulation, E is minimized with
αrns αrns
respect to the generalized state µ˜ when the ‘path of the mode’ (generalized
α
velocity) is equal to the ‘mode of the path’ (average velocity), in other words
495
the gradient of E vanishes when µ˜9 “ Dµ˜ . It is worth noting that in ‘static’
α α
situations where generalized motions are not required (see section 8.4), the
concept of the ‘mode of the path’ is not needed, i.e. Dµ˜ ”0 by construction.
α
Insuchsituationsweconsidertherelevantbrainvariablesµ toreachthedesired
α
minimum when there is no more temporal change in µ in the usual sense, i.e.
500 α
when µ9 “0.
α
In sum, these equations specify sets of first order ordinary differential equa-
tions that could be straightforwardly integrated by neuronal processing, e.g.,
they are very similar equations for firing rate dynamics in neural networks (e.g,
see [40]). Continuously integrating these equations in the presence of stream
505
of sensory data would make brain states continuously minimise IFE and thus
implement approximate inference on environmental states. Furthermore with
additional assumption about there implementation [41] they become strongly
analogous to the predictive coding framework [6].
30
7. Active inference
510
A central appeal of the FEP is that it suggests not only an account of
perceptual inference but also an account of action within the same framework:
active inference. Specifically while perception minimises IFE by changing brain
states to better predict sensory data, action instead acts on the environment to
altersensoryinputtobetterfitsensorypredictions. ThusactionminimisesIFE
515
indirectly by changing sensations.
In this section we describe a gradient-descent scheme analogous to that in
theprevioussectionbutforaction. Togroundthisideaforaction,andcombine
it with the framework for perceptual inference discussed in previous sections,
we present an implementation of a simple agent-based model.
520
Under the FEP action does not appear explicitly in the formulation of IFE
but minimises IFE by changing sensory data. To evaluate this the brain must
haveainversemodel[42]ofhowsensorydatachangewithaction[9]. Specifically,
for a single brain state variable µ we write this as ϕ“ϕpaq where a represents
the action and ϕ is a single sensory channel ϕ. Given this relationship we can
then write the gradient of the Laplace-encoded energy with respect to action
using the chain rule as,
dEpµ,ϕq dϕBEpµ,ϕq
” . (51)
da da Bϕ
Thus we can write the same gradient decent scheme outlined in the last section
to calculate the actions that minimise the Laplace-encoded energy as
dϕdEpµ,ϕq
a9 “´κ (52)
ada dϕ
where κ is the learning rate associated with action.
a
It is straightforward to write this gradient descent scheme for a vector of
brain states in generalised coordinates as
ÿ
dϕ˜
a9 “´κ α ¨∇ Eptµ˜ u,tϕ˜ uq. (53)
a da ϕ˜α α α
α
The idea that brains innately possess a inverse model, at first glance, seems
somewhattroublesome. However,undertheFEPtheexecutionofmotorcontrol
31
depends only on predictions about proprioceptors (internal sensors) which can
be satisfied by classic reflex arcs [43, 9]. On this reading exteroceptive, and
525
perhaps interoceptive [10], sensations are only indirectly minimised by action.
While a full assessment of this idea’s implications is outside the remit of this
work, it provides an interesting alternative to conventional notions of motor
control,orbehaviouroptimisation,thatrestonmaximisingorminimisingvalue
[43].
530
To give a concrete example of how perceptual and active inference work
we present an implementation of a simple agent-based model. Specifically we
present a model that comprises a mobile agent that must move to achieve some
desired local temperature, T . The agent’s environment, or generative pro-
desire
cess [9],consistsofa1-dimensionalplaneandasimpletemperaturesource. The
agent’s position on this plane is denoted by the environmental variable ϑ and
the agent’s temperature depends on its position in the following manner,
T
Tpϑq“ 0 , (54)
ϑ2`1
where T is the temperature at the origin, i.e., this equation gives the true
0
dynamics of the agents’ environment (the environmental causes of its sensory
signals). The corresponding temperature gradient is readily given by,
dT 2ϑ
“´T ”T .
dϑ 0 pϑ2`1q2 ϑ
The temperature profile is depicted by the black line in Fig. 1a. We allow the
agent to sense both the local temperature and the temporal derivative of this
temperature
ϕ “ T `z (55)
gp
ϕ1 “ T ϑ1`z1 (56)
ϑ gp
where z and z1 are normally distributed noise in the sensory readings. Note
gp gp
thatthesubscriptgpremindsusthatthisnoiseisapartoftheagent’senviron-
535
ment (rather than its brain model) described by the generative process.
32
In this model the agent is presumed to sit on a flat frictionless plane and,
thus, in the absence of action the agent is stationary. We allow the agent to set
its own velocity by setting it equal to the action variable a as,
ϑ1 “a. (57)
The agent has brain state µ which represents the agents estimate of its tem-
perature in the environment. Following equations (35), we write a generative
model for the agent, up to third order, as
µ1 “ fpµq`w where fpµq”´µ`T
desire
µ2 “ ´µ1`w1
µ3 “ w2,
where the third order term is just random fluctuations with large variance and
540
thusiseffectivelyeliminatedfromtheexpressionfortheLaplace-encodedenergy,
see Section 5.2. Following equation (34), we write the agent’s belief about it’s
sensory data only to first order as,
ϕ “ gpµq`z where gpµq”µ
ϕ1 “ µ1`z1
Note the actual environment is not dynamic but the agent’s belief about the
environment is. Indeed, examining the agent’s generative model we easily see
545
thatitpossessesastableequilibriumpointatT . Ineffecttheagentbelieves
desire
inaenvironmentwheretheforcesitexperiencesnaturallymoveittoitsdesired
temperature, see Section 2 and [9]. However, these dynamics are different to
those that describe the environment thus the agent must take action to make
the environment conform.
550
We can write the Laplace-encoded energy, equation (45), for this model, as
„ 
1 1 1 1 1
Epµ˜,ϕ˜q“ pε q2` pε q2` pε q2` pε q2 ,
2 σ zr0s σ zr1s σ wr0s σ wr1s
zr0s zr1s wr0s wr1s
(58)
33
where the various error terms are given as
ε “ ϕ´µ
zr0s
ε “ ϕ1´µ1
zr1s
ε “ µ1`µ´T
wr0s desire
ε “ µ2`µ1.
wr1s
Also,σ ,σ ,σ ,andσ inequation(58)arethevariancescorrespond-
zr0s zr1s wr0s wr1s
ingtothenoisetermsz,z1,w,andw1,respectively. Inadditionwehavedropped
logarithm of variance terms, see equation (24) because they play no role when
we minimise these equations with respect to the brain variable µ.
555
Note, that the noise terms in the agents internal model are distinct from
those in equation (56) and represent the agents beliefs about the noise on en-
vironmental states and sensory data rather than the actual noise on these vari-
ables. Aswewillseethesetermseffectivelyrepresenttheconfidenceoftheagent
in its own sensory input.
560
Using the gradient decent scheme described in equation (50) we write the
recognition dynamics as
„ 
ε ε
µ9 “ µ1´κ ´ zr0s ` wr0s
a σ σ
„ zr0s wr0s 
ε ε ε
µ91 “ µ2´κ ´ zr1s ` wr0s ` wr1s (59)
a σ σ σ
zr1s wr0s wr1s
ε
µ92 “ ´κ wr1s.
aσ
wr1s
Here we have considered generalised coordinates up to second order only. To
allow the agent to perform action we must provide it with an inverse model,
which we assume is hard-wired [9]. Replacing the agent’s velocity with the
action variable a in equation (56) we specify this as
dϕ1 d ` ˘
“ aT `z1 “T . (60)
da da ϑ gp ϑ
Effectivelytheagentbelievesthatactionchangesthetemperatureinawaythat
isconsistentwithit’sbeliefsaboutthetemperaturegradient. Giventhisinverse
34
model we can write down the minimisation scheme for action as.
„ 
a9 “´κ
dϕBE
`
dϕ1 BE
“´κ T
ε
zr1s.
(61)
a da Bϕ da Bϕ1 a ϑσ
zr1s
Thus, equations (59) through (61) describe the complete agent-environment
system and can be straightforwardly integrated (see Appendix B for details).
Fig. 1 shows the behaviour of the agent in the absence of action, i.e., when
565
the agent is unable to move. We examine two conditions. In a first condition
theagent’ssensoryvariancesσ ,σ areseveralordersofmagnitudesmaller
zr0s zr1s
thanmodelvariancesσ andσ . Thustheagenthashigherconfidence(see
wr0s wr1s
Section 5.1) in sensory input than in its internal model. Under this condition
the agent successfully infers both the local temperature and its corresponding
570
derivatives,seeFig.1bblacklines. Ineffecttheagentignoresitsinternalmodel
and the gradient decent scheme is equivalent to a least mean square estimation
on the sensory data, see supplied code in Appendix B. In a second condition,
see Fig. 2 red lines, we equally balance internal model and sensory variances
(σ “ σ , i “ 0,1). Now minimisation of IFE cannot satisfy both sensory
575 zris wris
perception and predictions of the agent’s internal model, i.e., what the agent
perceivesisinconflictwithwhatitdesires. Thustheinferredlocaltemperature
sits somewhere between its desired and sensed temperature, see Fig. 1b.
In Fig. 2, after an initial period, the agent is allowed to act according to
equation (61). It does so by changing the environment to bring it in line with
580
withsensorypredictionsandthedesiresencodedwithinitsdynamicmodel,i.e.,
the agent moves toward the desired temperatures.
The reduction of surprisal can be quantified as the difference between the
Laplace-encoded energy (and thus IFE) in presence and absence of action, i.e.,
thedifferencebetweenblackandredtracesinFig.2e, respectively. Specifically,
585
itistheportionoftheIFEthatmustbeminimisedbyactingontheenvironment
rather than through optimisation of the agent’s environment model. We leave
a more explicit quantification of the dynamics of surprisal for future work.
In summary we have presented an example of an agent performing a very
simple task under the FEP. The model demonstrates how the minimisation
590
35
0 2 4 6
Position ϑ
erutarepmeT
100
80
60
40
0 5 10
20
0
µ
20
15
10
5
0
0 5 10
time
''µ
3
2
1
0
-1
0 5 10
time
EFI
2500
2000 0 5 10
1500
1000
500
0
'µ
a b
--- Starting pos and temp
--- Desired pos and temp
1
0
c -1
-2
-3
Figure 1: Perceptual inference: The agent’s environment comprises a simple temper-
ature gradient (a), the blue and magenta lines give the actual and desired positions
of the agent, respectively. The agent per3f6orms simple perceptual inference (b), the
dynamics of three generalized coordinates, µ, µ1 and µ2, are given in the top, middle
and bottom panels, respectively. Two conditions are shown, when the confidence in
the sensory input is high (i.e. σ is small in comparison to σ ), black line, and
zris wris
when confidence is equal between the internal model and sensory input, red line, re-
spectively. IFE in both conditions monotonically decreases (c): black and red traces,
respectively. The tension between sensory input and internal model manifests a rel-
atively high value of IFE (c) (red curve), compared to the case where sensation has
much higher confidence than the internal model (black curve).
20 T
#
10
0
0 20 40 60 80 100
20 7
7'
10 7''
0
-10
0 20 40 60 80 100
30
'
20
''
10
0
-10
0 20 40 60 80 100
0 20 40 60 80 100
a
0.4
0.2
0
-0.2
0 20 40 60 80 100
time
EFI
a
b
c
d
e
2000
1000
0
Figure 2: Perceptual and active inference: An agent with equal confidence in its
internal model and sensory input σ “ σ “ 1 is allowed to act at t “ 25. The
zris wris
agent acts, see (d), to alter its position, see (a: orange line), to bring down its initial
temperature(T “20)tothedesiredtemperature(T “T “4),see(a: blueline).
desire
Itdoesthisbybringingitssensorydata(c)inlinewithitsdesire,i.e.,ϕ“T and
desire
thusthebrainstatebecomesequaltoitsdesiredstate,see(b). IFEwascalculatedin
37
the presence and absence of the onset of action at t“25, see e, black and red lines,
respectively. First IFE is reduced by inference (tă25), then later through action (e:
black line).
of IFE can underpin both perception and action. Furthermore, it shows how
a tension between desires and perception can be reconciled through action.
Many other agent based implementations of the FEP have been presented in
the literature, .e.g. [9], which can be constructed in a similarly simplistic way.
8. Hierarchical Inference and Learning
595
In the previous sections we developed the FEP for organisms given simple
dynamicalgenerativemodels. Wetheninvestigatedtheemergenceofbehaviour
inasimulatedorganism(agent)furnishedwithanappropriategenerativemodel
of a simple environment. The assumption here was that organisms possess
some knowledge or beliefs of about how the environment works a priori, in
600
the form of a pre-specified generative model. However, another promise of
the FEP is the ability to learn and infer arbitrary environmental dynamics
[21]. To achieve this it is suggested that brain starts out with a very general
hierarchical generative model of environmental dynamics which is moulded and
refined through experience. The advantage of using hierarchical models, as we
605
will see, is that they suggest a way of avoiding specifying an explicit and fixed
prior, and thus can implement empirical Bayes [44]. In this section we first
provide a description of a hierarchical G-density which is capable of empirical
Bayes [44]. We then combine this with dynamical generative model described
in equation (45) to define what we shall call the full construct. We go on to
610
describe how appropriate parameters and hyperparameters of the G-density for
given world could be discovered through learning. We finish this section by
showing how action could be described in this construct.
8.1. Hierarchical generative model
A key challenge for Bayesian inference models is how to specify the priors.
615
Hierarchical models provide a powerful response to this challenge, in which
higher levels can provide empirical priors or constraints on lower levels [45].
In the FEP, hierarchical models are mapped onto the hierarchical organisation
38
of the cortex [46, 47], which requires extension of the simple generative model
described above.
620
We denote µpiq as a brain state at hierarchical level i and we assume M
cortical levels, with i“1 the lowest level and i“M as the highest. Then, the
hierarchical model may be written explicitly as [21]
ϕ “ gp1qpµp1qq`zp0q
µp1q “ gp2qpµp2qq`zp1q
µp2q “ ¨¨¨
.
.
.
µpMq “ zpMq
which can be written compactly as
µpiq “gpi`1qpµpi`1qq`zpiq (62)
where i runs through 1,2,¨¨¨M. We further assume that the sensory data ϕ
reside exclusively at the lowest cortical level µp1q and dynamics at the highest
level µpMq are governed by a random fluctuation zpMq, i.e:
µp0q ”ϕ and gpM`1q ”0. (63)
The hierarchy equation (62) specifies that a cortical state µpiq is connected to
higher level µpi`1q through the generative function gpi`1q. The fluctuations zpiq
625
exist at each level, in particular zp0q designating the observation noise at the
sensory interface, and are assumed to be statistically independent.
Having defined the hierarchical model, one can write the corresponding G-
density as
ppϕ,µq “ ppµp0q|µp1q,µp2q,¨¨¨ ,µpNqqppµp1q,µp2q,¨¨¨ ,µpMqq
” ppµp0q|µp1qqppµp1q|µp2qq¨¨¨ppµpM´1q|µpMqqppµpMqq. (64)
The second step in equation (64) assumes that the transition probabilities from
higher levels to lower levels are Markovian. Consequently, equation (64) asserts
39
thatthelikelihoodofalevel,forinstanceppµpiq|µpi`1qq,servesasapriordensity
for the level immediately below, i´1. The prior at the highest level ppµpMqq
contains information only with respect to its spontaneous noise, which may be
given by a Gaussian form
! ´ ¯)
1
ppµpMqq“ b exp ´rµpMqs2{ 2σpMq (65)
z
2πσpMq
z
wherethemeanhasbeenassumedtobezeroandσpMq isthevariance. Weshall
z
further assume that the Gaussian noises are responsible for the (statistically
independent) fluctuations at all hierarchical levels. Accordingly, the likelihoods
ppµpiq|µpi`1qq are given as
„ ! ) ! )
1 2
ppµpiq|µpi`1qq“ b exp ´ µpiq´gpi`1qpµpi`1qq { 2σpiq . (66)
z
2πσpiq
z
and the G-density reduces to
» fi ˜ ¸
ppϕ,µq“ –
źM
b 1 fl exp ´
ÿM
1 rεpi`1qs2 (67)
i“0 2πσ
z
piq i“0 2σ z piq
where the auxiliary variables εpiq have been introduced as
εpiq ”µpi´1q´gpiqpµpiqq. (68)
Thequantityεpiq measuresthediscrepancybetweentheprediction(estimation)
630
at a given level µpiq via gpiq and µpi´1q at a lower-level, which comprises a
prediction error.
Finally, by substituting the G-density, constructed in equation (67), into
equation (19), after a simple manipulation, the Laplace-encoded energy E is
given up to a constant as
" *
ÿM
1 1
Epµ,ϕq“ rεpi`1qs2` lnσpiq . (69)
2σpiq 2 z
i“0 z
The variance of the noise at the top level of hierarchy is typically assumed to
be large and thus the corresponding term in the Laplace-encoded energy equa-
tion (69) is approximately zero. As with the higher dynamical orders discussed
635
40
above Section 5.2 this means that the level below is effectively unconstrained
(hasnoprior)andthusthistypeofinferenceconstitutesanexampleofempirical
Bayes [44].
Table 4 itemizes the mathematical objects associated with the hierarchical
generative model.
640
8.2. Combining hierarchical and dynamical models: The full construct
Wenowcombinethedynamicalstructureandthemultivariatebrainstatesin
a single expression. First we note that under the FEP brain states representing
neuronalactivityµ aredividedintothehidden statesx andthecausal states
α α
v ,
α
µ “px ,v q.
α α α
Then, the full FEP implementation can be derived formally by extending equa-
tions (43) and (44) (equation (62))
v˜piq “ g˜pi`1qpx˜pi`1q,v˜pi`1qq`z˜piq, i“0,1,¨¨¨ .M (70)
α α α α α
Dx˜piq “ f˜piqpx˜piq,v˜piqq`w˜piq, i“1,2.¨¨¨ ,M (71)
α α α α α
where the brain-state index runs through α “ 1,2,¨¨¨ ,N and v˜p0q designates
α
the sensory data at the lowest cortical layer, i “ 1. Inter-layer hierarchical
links are made through the causal states and intra-hierarchical layer dynamics
through the hidden states. The generalized coordinates of neuronal brain state
α in hierarchical layer i are given by the infinite-dimensional vectors
x˜piq ”pxpiq ,xpiq ,xpiq ,¨¨¨q and v˜piq ”pvpiq ,vpiq ,vpiq ,¨¨¨q
α αr0s αr1s αr2s α αr0s αr1s αr2s
where the components are labelled by the subscripts rns, n“0,1,¨¨¨ ,8. Note
that we have introduced different notations in the vector components: The
subscript α for brain states at a given hierarchical level, the superscript piq for
the hierarchical indices, and the subscript rns for the dynamical orders. Recall
thatthen-thcomponentofthevectorx˜piq andv˜piq aretime-derivativesoforder
α α
n, namely
dn dn
xpiq ” xpiq and vpiq ” vpiq.
αrns dtn α αrns dtn α
41
Theothermathematicalquantitiesinequations(70)and(71)aregivenexplicitly
as:
Dx˜piq “pxpiq ,xpiq ,xpiq ,¨¨¨q,
α αr1s αr2s αr3s
z˜piq ”pzpiq ,zpiq ,zpiq ,¨¨¨q, and w˜piq ”pwpiq ,wpiq ,wpiq ,¨¨¨q.
α αr0s αr1s αr2s α αr0s αr1s αr2s
The generative functions appearing in equations (70) and (71) are specified for
ně1, under the local-linearity assumption, as
Bg
g pxpi`1q,vpi`1qq” vpi`1q ”gpi`1q
αrns αrns αrns Bvpi`1q αrns αrns
αrns
and
Bf
f pxpiq ,vpiq q” xpiq ”fpiq .
αrns αrns αrns Bxpiq αrns αrns
αrns
For the lowest dynamical order of n“0,
gpi`1q “gpxpi`1q,vpi`1qq and fpiq “fpxpiq ,vpiq q.
αr0s αr0s αr0s αr0s αr0s αr0s
Itisevidentfromequation(70)thatthecausalstatesv˜piq atonehierarchical
α
layer are predicted from states at one level higher in the hierarchy v˜pi`1q via
645 α
the map g˜pi`1q: z˜piq specifies the fluctuations associated with these inter-layer
α α
links. Equation (71) asserts that the dynamical transitions of the hidden states
x˜piq are induced within a given hierarchical layer via f˜piq: The corresponding
α α
fluctuationsaregivenbyw˜piq. Inordertodescribethesetransitionsmoretrans-
α
parently, we spell out equations (70) and (71) explicitly:
650
v˜p0q “g˜p1qpx˜p1q,v˜p1qq`z˜p0q x˜9p1q “f˜p1qpx˜p1q,v˜p1qq`w˜p1q
α α α α α α α α α α
v˜p1q “g˜p2qpx˜p2q,v˜p2qq`z˜p1q x˜9p2q “f˜p2qpx˜p2q,v˜p2qq`w˜p2q
α α α α α α α α α α
. .
. .
. .
v˜pM´1q “g˜pMq`z˜pM´1q x˜9pM´1q “f˜pM´1q`w˜pM´1q
α α α
v˜pMq “z˜pMq x˜9pMq “f˜pMq`w˜pMq
α α α α α
where we have set that
ϕ˜ ”v˜p0q and g˜pM`1q ”0.
α α α
42
Note that the sensory data ϕ˜ reside at the lowest hierarchical layer and are
α
to be inferred by the causal states v˜p1q at the corresponding dynamical orders.
α
At the highest cortical layer M the causal states v˜pMq are described by the
α
spontaneous fluctuations z˜pMq around their means (which have been set to be
α
zero without loss of generality). Note that the generalized motions of hidden
655
states are still present at the highest cortical level, in just the same way that
theymanifestatalltheotherhierarchicallevels: thecorrespondingspontaneous
fluctuations are given by w˜pMq.
α
Separating brain states into causal and hidden states, we can now express
the G-density by generalizing equation (64) as
660
źN źN Mź´1
ppϕ˜,µ˜q “ ppϕ˜ ,µ˜ q“ ppµ˜pMqq ppµ˜piq|µ˜pi`1qq
α α α α α
α“1 α“1 i“0
źN Mź´1
ñ ppx˜pMq,v˜pMqq ppx˜piq,v˜piq|x˜pi`1q,v˜pi`1qq
α α α α α α
α“1 i“0
źN Mź´1
“ ppx˜pMq,v˜pMqq ppx˜piq|v˜piqqppv˜piq|x˜pi`1q,v˜pi`1qq (72)
α α α α α α α
α“1 i“0
where in the second step we have used µ˜piq “ px˜piq,v˜piqq and only the causal
α α α
states v˜piq are involved in the inter-layer transitions in the third step. Also,
α
it must be understood that ppx˜p0q|v˜p0qq ” 1 in equation (72), which appears
α α
solelyforamathematicalcompactness. Theintra-layerconditionalprobabilities
ppx˜piq|v˜piqq are given as
665 α α
ppx˜piq|v˜piqq “ ppxpiq ,xpiq ,¨¨¨|vpiq ,vpiq ,¨¨¨q
α α αr0s αr1s αr0s αr1s
ź8
“ ppxpiq |vpiq q (73)
αrns αrns
n“0
where in the second step we have made use of the assumption of statistical
independence among the generalized states at different dynamical orders. The
quantity ppxpiq |vpiq q specifies the conditional density at the dynamical order
αrns αrns
nwithinthehierarchicallayeri,wherethecorrespondingfluctuationswpiq are
αrns
assumed to take Gaussian form as
„ ´ ¯ ´ ¯
1 2
ppxpiq |vpiq q” b exp ´ xpiq ´fpiq { 2σαpiq . (74)
αrns αrns 2πσαpiq αrn`1s αrns wrns
wrns
43
The conditional densities ppv˜piq|x˜pi`1q,v˜pi`1qq appearing in equation (72) link
α α α
two successive causal states in the cortical hierarchy which are specified by a
similar Gaussian fluctuation for zpiq via equation (70) as
αrns
ź8
1
„ ´ ¯
2
´ ¯
ppv˜piq|x˜pi`1q,v˜pi`1qq” b exp ´ vpiq ´gpi`1q { 2σαpiq .
α α α
n“0
2πσαpiq αrns αrns zrns
zrns
(75)
What is left unspecified in constructing the G-density fully, i.e. equation (72),
is the prior density ppx˜pMq,v˜pMqq at the highest cortical layer. It is given here
α α
explicitly as
ź8
1
! ´ ¯)
ppx˜pMq,v˜pMqq ” b exp ´rxpMq ´fpMqs2{ 2σαpMq
α α
n“0
2πσαpMq αrn`1s αrns wrns
wrns
ź8
1
! ´ ¯)
ˆ b exp ´rvpMqs2{ 2σαpMq . (76)
n“0
2πσαpMq αrns zrns
zrns
The prior in the highest cortical layer, equation (76), comprises the lateral gen-
eralizedmotionsofthehiddenstatesandthespontaneous, randomfluctuations
670
associated with the causal states. It is assumed that both causal and hidden
states fluctuate about zero means.
Next,theLaplace-encodedenergyEcanbewrittenexplicitlybysubstituting
equation (72) into equation (19) and incorporating the likelihood and prior
densities,equations(74),(75),and(76),atallhierarchicallayersanddynamical
675
orders. After a straightforward manipulation, we obtain the Laplace-encoded
energy for a specific brain variable µ as
$ α ,
ÿ8 &
1
´ ¯
2 1
.
E pµ˜ ,ϕ˜ q “ xpMq ´fpMq ` lnΩαpMq
α α α % 2ΩαpMq αrn`1s αrns 2 wrns -
n“0 $ wrns ,
ÿ8 &
1
´ ¯
2 1
.
`
vpMq
`
lnΩαpMq
% 2ΩαpMq αrns 2 zrns -
n“0 $zrns ,
Mÿ´1 ÿ8 &
1
´ ¯
2 1
.
`
xpiq ´fpiq
`
lnΩαpiq
% 2Ωαpiq αrn`1s αrns 2 wrns-
i“1 n“0 $ wrns ,
Mÿ´1 ÿ8 &
1
´ ¯
2 1
.
`
vpiq ´gpi`1q
`
lnΩαpiq
% 2Ωαpiq αrns αrns 2 zrns-
i“0 n“0 zrns
44
where the first and second terms are from prior-densities at the highest layer,
equation (76), the third term is from equation (74), and last term from equa-
tion (75). A quick inspection reveals that the first and second terms can be ab-
680
sorbedintothethirdandfourthterms,respectively. Then,theLaplace-encoded
energy for multiple brain variables is written compactly as
ÿN
Epµ˜,ϕ˜q “ E pµ˜ ,ϕ˜ q
α α α
α“1 $ ,
1
ÿN ÿ8 ÿM &
1
´ ¯
2
.
“
εαpiq `lnσαpiq
2 % σαpiq wrns wrns-
α“1n“0i“1 $ wrns ,
1
ÿN ÿ8 ÿM &
1
´ ¯
2
.
` εαpi`1q `lnσαpiq . (77)
2 % σαpiq zrns zrns-
α“1n“0i“0 zrns
where we have defined the prediction errors
´ ¯
εαpiq ” vpi´1q´gpiq xpiq ,vpiq (78)
zrns αrns αrns ´αrns αrns ¯
εαpiq ” xpiq ´fpiq xpiq ,vpiq . (79)
wrns αrn`1s αrns αrns αrns
Thus, it turns out that the Laplace-encoded energy is expressed essentially
as a sum of the prediction-errors squared and their associated variances. It
685
appears in equation (77) that the structure of the first term differs from the
second term: In the first term the hierarchical index runs from i “ 1 which
indicates the lowest cortical layer, while the second term includes additional
i“0 in the hierarchical sum which designates the sensory data, ϕ˜”v˜p0q. Note
alsoinequation(78)thatεαpM`1q “vpMq becausethehighesthierarchicallayer
690 zrns αrns
is at i“M, accordingly gpM`1q ”0 by construction.
αrns
Table 5 provides the glossary of the mathematical objects involved in the
G-density in the full construct for a single brain activity µ .
α
To summarize, the ‘full construct’ incorporates into the G-density, both
multi-layer hierarchies corresponding to cortical architecture, and multi-scale
695
dynamics in each layer via generalized coordinates. The G-density is expressed
as the sequential product of the priors and the likelihoods, cascading down
the cortical hierarchy to the lowest layer where the sensory data are registered
45
(mediated by causal states), and taking into account the intra-layer dynam-
ics, mediated by hidden states. The final form of the Laplace-encoded energy,
700
equation (77), has been derived from equation (19) which specifies the Laplace-
encodedenergyasthe(negative)logarithmofthegenerativedensityconstructed
for the hidden and causal brain states.
8.3. The full-construct recognition dynamics and neuronal activity
Wenowdescriberecognitiondynamicsincorporatingthefullconstruct(sec-
705
tion 8.2), given the Laplace-encoded energy Epµ˜,ϕ˜q, equation (77). In the full
construct, the brain states µ˜ are decomposed into the causal states v˜ which
α α
link the cortical hierarchy and the hidden states x˜ which implement the dy-
α
namical ordering within a cortical layer.
Distinguishing the ‘path of the modes’ from the ‘modes of the path’, see
Section6, thelearningalgorithmforthedynamicalcausalstatesonthecortical
layer i can be constructed from
v9piq ´Dvpiq ”´κ vˆpiq ¨∇ Epµ˜,ϕ˜q (80)
αrns αrns z αrns v˜α
where κ is the learning rate and vˆpiq is the unit vector along vpiq . As men-
710 z αrns αrns
tionedinSection6, thecrucialassumptionhereisthatwhenthepathofmodes
becomes identical to the modes of the path, i.e. v˜9piq´Dv˜piq Ñ0, the Laplace-
α α
encoded energy E takes its minimum, and vice versa. The gradient operation
in the RHS of equation (80) can be made explicit to give
vˆpiq ¨∇ Epµ˜,ϕ˜q
αrns » v˜α fi
! ) ! ) ! )
“
B – 1 εαpiq 2
`
1 εαpi`1q 2
`
1 εαpiq 2fl
Bvpiq 2σαpi´1q zrns 2σαpiq zrns 2σαpiq wrns
αrns zrns zrns wrns
1
Bεαpiq
1
Bεαpi`1q
1
Bεαpiq
“ εαpiq zrns ` εαpi`1q zrns ` εαpiq wrns (81)
σαpi´1q zrns Bvpiq σαpiq zrns Bvpiq σαpiq wrns Bvpiq
zrns αrns zrns αrns wrns αrns
where one can further see that
Bεαpiq Bgαpiq Bεαpi`1q Bεαpiq Bfpiq
zrns
“´
zrns, zrns
“1, and
wrns
“´
αrns.
Bvpiq Bvpiq Bvpiq Bvpiq Bvpiq
αrns αrns αrns αrns αrns
46
The additional auxiliary variables are introduced:
! ´ ¯)
ξαpiq ”εpiq {σαpi´1q ”Λαpi´1q vpi´1q´gpiq xpiq ,vpiq , (82)
zrns zrns zrns zrns αrns αrns αrns αrns
! ´ ¯)
ξαpiq ”εpiq {σpiq ”Λαpiq xpiq ´fpiq xpiq ,vpiq , (83)
wrns wrns wrns wrns αrn`1s rns αrns αrns
where Λαpiq and Λαpiq are the inverse of the variances,
zrns wrns
Λαpiq ”1{σαpiq and Λαpiq ”1{σαpiq, (84)
zrns zrns wrns wrns
which are called the precisions. Note that the precisions reflect the magnitude
715
of the prediction errors.
Its is proposed that the auxiliary variables ξαpiq and ξαpiq represent error
zrns wrns
units and that the brain states, vpiq and xpiq , similarly represent state units
αrns αrns
or, equivalently, representation units, within neuronal populations [23, 1].
In terms of predictive coding or (more generally) hierarchical message pass-
720
ing in cortical networks[21], equation (82) implies that the error-units ξαpiq
zrns
receive signals from causal states vpi´1q lying in immediately lower hierarchical
αrns
layer and also from causal and hidden states in the same layer, vpiq and xpiq ,
αrns αrns
viathegenerativefunctiongpiq . Similarly,equation(83)impliesthattheerror-
αrns
units ξαpiq specify prediction-error in the within-layer (lateral) dynamics: ξαpiq
725 wrns wrns
designates prediction error between the objective hidden-state xpiq and its
αrn`1s
estimation from one-order lower causal- and hidden-states vpiq and xpiq , via
αrns αrns
the different generative function fpiq .
αrns
With the help of equation (81), one can recast the learning algorithm equa-
tion (80) to give the dynamics of the causal states as
Bgαpiq Bfpiq
v9piq “Dvpiq `κ rns ξαpiq´κ ξαpi`1q`κ αrnsξαpiq (85)
αrns αrns z Bvpiq zrns z zrns z Bvpiq wrns
αrns αrns
which shows clearly how hierarchical links are made among nearest-neighbor
cortical layers. Specifically, the representation units of causal states vpiq are
730 αrns
updated by the error units ξαpi`1q which reside in the layer immediately above,
zrns
and also by the error-units ξαpiq and ξαpiq in the same hierarchical layer, all at
zrns wrns
the same dynamical order.
47
The intra-layer dynamics of hidden states are generated similarly as
x9piq ” Dxpiq ´κ xˆpiq ¨∇ Epµ˜,ϕ˜q
αrns αrns w αrns x˜α
Bfpiq Bgpiq
“ Dxpiq ´κ ξαpiq `κ αrnsξαpiq `κ αrnsξαpiq (86)
αrns w wrn´1s w Bxpiq wrns w Bxpiq zrns
αrns αrns
whereκ istheleaningrate. Inpassingtothesecondlineinequation(86), one
735 w
needs to evaluate
xˆpiq ¨∇ Epµ˜,ϕ˜q
αrns x˜α
1
Bεαpiq
1
Bεαpiq
1
Bεαpiq
Ñ
εαpiq wrn´1s
`
εαpiq wrns
`
εαpiq zrns,
σαpiq wrn´1s Bxpiq σαpiq wrns Bxpiq σαpi´1q zrns Bxpiq
wrn´1s αrns wrns αrns zrns αrns
and an explicit evaluation of the derivatives of the prediction errors, equa-
tions(78)and(79). Thehidden-statelearningalgorithm,equation(86),specifies
how the representation-units xpiq are driven by the error-units in the current
αrns
layer i at both the immediately lower dynamical order ξαpiq and the same
740 wrn´1s
dynamical order ξαpiq, and also by the error units ξαpiq in the current layer at
wrns zrns
the same dynamical order.
To summarize, the hierarchical, dynamical causal structure of the genera-
tive model is fully implemented in the mathematical constructs given by equa-
tions (82) and (83) (specifying prediction errors), and equations (85) and (86)
745
(specifying update rules for state-units).
According to these equations, the state units come to encode the condi-
tional expectations of the environmental causes of sensory data, and the error
units measure the discrepancy between these expectations and the data. Er-
ror units are driven by state units at the same layer and from the layer below,
750
whereas state units are driven by error units at the same layer and the layer
above. Thus,predictionerrorsarepassedupthehierarchy(bottom-up)andpre-
dictions (conditional expectations) are passed down the hierarchy (top-down),
fully consistent with predictive coding [6].
48
8.4. Parameters and hyper-parameters: Synaptic efficacy and gain
755
Thus far we have discussed how environmental variables can be inferred
given an appropriate G-density. In this section we discuss how the G-density
itself can be learned. It is proposed that the dynamics of neural systems is
captured by three time-scales, τ ă τ ă τ . The first, τ , represents the
µ θ γ µ
timescaleofthedynamicsofsufficientstatisticsoftheencodedintheR-density
i,.e µ ” px,vq as described above. In contrast τ and τ represent the slow
θ γ
timescale of synaptic efficacies and gains which are parameterised implicitly in
equation (77) through the generative functions, f and g, and the variances σ
(ortheprecisionsΛ,equation(84)),respectively. UndertheFEPslowvariables
are assumed to be approximately ‘static’ or ‘time-invariant’ in contrast to the
‘time-varying’ neuronal states µ [23]. Second, changes in θ and γ (with respect
to a small δt) have a much smaller effect on the Laplace-encoded energy (or
IFE) than do changes in µ, i.e.
BF δθ BF δµ
! .
Bθ δt Bµ δt
The latter point implies that, from the perspective of gradient-descent, what is
relevant for θ and γ is not the IFE F but the accumulation, more precisely the
integration of F over time [19]
ż
SrFs” dtFpµ˜,ϕ˜;θ,γq (87)
where the time-dependence of F is implicit through the arguments. To distin-
guish their different roles, θpiq are called parameters and γpiq are called hyper-
α α
parameters, corresponding to brain state µ , in each hierarchical layer i. Equa-
α
tions (82) and (83) can now be generalized to include these parameters and
hyper-parameters as
! ´ ¯)
ξαpiq “Λαpi´1qpγpi´1qq vpi´1q´gpiq xpiq ,vpiq ;θpiq , (88)
zrns zrns α αrns αrns αrns αrns α
! ´ ¯)
ξαpiq “Λαpiqpγpiqq xpiq ´fpiq xpiq ,vpiq ;θpiq . (89)
wrns wrns α αrn`1s αrns αrns αrns α
49
The Laplace-encoded energy including θ and γ may therefore be written as
1
ÿN ÿ8 ÿM ! )
Epµ˜,ϕ˜;θ,γq “ εαpiqξαpiq ´lnΛαpiq
2 wrns wrns wrns
α“1n“0i“1
1
ÿN ÿ8 ÿM ! )
` εαpi`1qξαpi`1q´lnΛαpiq . (90)
2 zrns zrns zrns
α“1n“0i“0
We are now in a position to write down the recognition dynamics for the
slowsynapticefficacyθandfortheslowersynapticgainγ. Specifically,gradient
descent for the parameters θpiq is applied using the time-integral of F, given in
α
equation (87), assuming a static model (i.e., without dynamical order indices),
as
θ9piq “´κ θˆpiq¨∇ S
α θ α θ
which, when temporal differentiation is repeated on both sides, gives rise to
θ:piq “´κ θˆpiq¨∇ Epµ˜,ϕ˜;θ,γq. (91)
α θ α θ
After explicitly carrying out the gradient on the RHS of equation (91), one ob-
tainsanequationtominimiseθpiq correspondingtobrainvariableµ atcortical
α α
layer i » fi
ÿ8 Bgpiq Bfpiq
θ:piq “ – κ αrnsξαpiq`κ αrnsξαpiqfl (92)
α θ Bθpiq zrns θ Bθpiq wrns
n“0 α α
where the summation over the dynamic index n reflects the generalized motion
overcausalaswellashiddenstates. AccordingtoEquation(92)synapticefficacy
is influenced by error-units only in the same cortical layer.
Similarly, the learning algorithm for the hyper-parameters γ, specifically for
γpiq associatedwithbrain’srepresentationofenvironmentalstatesµ atcortical
α α
layer i, is given from
γ9piq “´κ γˆpiq¨∇ S
α γ α γ
which results in
760 » fi
γ:piq “ ´ 1
ÿ8
– κ
BΛα
w
p
r
i
n
q
s
!
ξαpiq
)
2 ´κ B lnΛαpiqfl
α 2 γ Bγpiq wrns γ Bγpiq wrns
n“0 α α
» fi
´ 1
ÿ8
– κ
BΛα
zr
p
n
iq
s
!
ξαpi`1q
)
2 ´κ B lnΛαpiqfl . (93)
2 γ Bγpiq zrns γ Bγpiq zrns
n“0 α α
50
According to this equation, synaptic gains are influenced by error units in the
same layer ξpiq and also by error units in one-layer above ξpi`1q.
w z
Notethattheequationsforθandγ,equations(92)and(93),arebyconstruc-
tion second-order differential equations, unlike the corresponding equations for
state-units µ [equations (85) and (86)], which are first-order in time [20]. Table
765
6 provides the summary of mathematical symbols appearing in the recognition
dynamics in the dynamical construct and also in the static construct.
To summarize the FEP prescribes recognition dynamics by gradient descent
with respect to the sufficient statistics µ˜, parameters θ, and hyper-parameters
γ on the Laplace-encoded energy Epµ˜,ϕ˜;θ,γq, given the sensory input ϕ˜. At
770
the end of this process, an optimal µ˜˚ is specified which represents the brain’s
posterior expectation of the environmental cause of the observed sensory data.
In theory the second term in the IFE F, equation (18), can be fixed according
to equation (17) thereby completing the minimization of the IFE, although
in practice this is rarely done and the focus is on approximating the means,
775
parameters and hyper-parameters.
This whole minimization process is expressed abstractly as
µ˜˚ “arg minFpµ˜,ϕ˜q (94)
µ˜
where µ˜˚ is the minimizing (optimal) solution and the conditional dependence
m is expressed explicitly. The resulting minimized IFE can be calculated by
substituting the optimizing µ˜˚ for µ˜ as
F˚ “Fpµ˜˚,ϕ˜ q.
The only remaining task is to specify the generative functions f and g,
which will depend on the particular system being modelled. We have utilised a
concrete model in our calculation in Section 7. Examples of various generating
functions have already been provided[21, 9, 29, 28, 48], to which we refer the
780
reader.
51
8.5. Active inference on the full construct
The IFE also accounts for an active inference by minimising the IFE with
respect to action, for which a formal procedure can be written as
a˚ “arg minFpµ˜,ϕ˜paqq (95)
a
where a˚ is the minimizing solution. Similarly with equation (52) we can write
down the gradient descent scheme for the minimisation in the full construct for
action corresponding to brain’s representation µ as
α
a9 “´κ aˆ ¨∇ Epµ˜,ϕ˜paqq (96)
α a α aα
where equation (90) is to be used for the Laplace-encoded energy. Then, af-
ter the gradient operation is completed, the organism’s action is implemented
explicitly in the brain as
ÿ8
dϕ˜
a9 “´κ
αrnsΛαp0qεαp1q
(97)
α a da zrns zrns
n“0 α
where εαp1q “ ϕ ´gp1q pxp1q ,vp1q ;θp1qq is the prediction-error associated
zrns αrns αrns αrns αrns α
withlearningofthesensorydataonthedynamicalordernatthelowestcortical
layer and Λαp0q “ Λαp0qpγp0qq is the precision of the sensory noise. To our
785 zrns zrns α
knowledge most existing models of active inference under the FEP require one
to provide an explicit world model. Thus an important goal for for future work
will be to develop agent based models that work with the full construct.
9. Discussion
The FEP framework is an ambitious project, spanning a chain of reasoning
790
from fundamental principles of biological self-maintenance essential for sustain-
able life, to a mechanistic brain theory that proposes to account for a startling
range of properties of perception, cognition, action and learning. It draws con-
clusions about neurocognitive mechanisms from extremely general statistical
considerations regarding the viability of organism’s survival in unpredictable
795
environments. Under certain assumptions - which we discuss in more detail
52
below - it entails a hierarchical predictive processing model geared towards the
inference and control of the hidden causes of sensory inputs, which both sheds
newlightonexistingdataaboutfunctionalneuroanatomyandmotivatesanum-
ber of specific hypotheses regarding brain function in health and in disease. At
800
the same time, the current status of much of the research under the rubric of
the FEP does depend on, to different degrees, a variety of assumptions and ap-
proximations,bothattheleveloftheoverarchingtheoryandwithregardtothe
specificimplementation(orprocesstheory)thetheoryproposes. Inthissection,
wediscusstheconsequencesofsomeofmoreimportantoftheseassumptionsand
805
approximations, with respect to the framework and implementation described
in the body of this paper.
A central assumption in this (representative) exposition of the FEP is that
the brain utilizes properties of Gaussian distributions in order to carry out
probabilistic computation. Specifically, the Laplace approximation assumes a
810
GaussianfunctionalformfortheR-densityandG-densitywhichareencodedby
sufficientstatistics,seeSection4. Additionally,itisassumedthattheR-density
istightlypeaked,i.e.,thevarianceandcovariancearesmall,seeSection4. This
assumption implies that an organism only represents the expectation value of
environmentalvariables, andnotadistributionoverstates, see[38,49,50]fora
815
nicedescriptionsofthisassumption. Atfirstglancethisassumptionmayappear
troublesome, because it suggests that organisms do not directly represent the
uncertainty of environmental variables (hidden causes of sensory signals). This
worry is misplaced, however, since representations of uncertainty enter into the
FEP formalism via precisions on the expectations of brain states that comprise
820
the G-density, see equation (32). Intuitively this means that organisms do not
encode uncertainty about world states per se, but rather uncertainties about
their model of how hidden causes relate to each other and to sensory signals.
The main advantage of adopting Gaussian assumptions is that they vastly
simplifytheimplementationoftheFEP,andmakeitformallyequivalenttothe
825
morewidelyknownpredictivecodingframework[51,8,41],seetheIntroduction.
Furthermore, it can be argued this implementation is compatible with a plausi-
53
bleneuronalfunctionalarchitectureintermsofmessagepassingincorticalhier-
archies[16]. Specifically,inferredvariables(hiddencauses)canberepresentedin
termsofneuralfiringrates;thedetailsofgenerativemodelsencodedaspatterns
830
of synaptic connectivity, and the process of IFE minimisation by the relaxation
of neuronal dynamics [52]. The concept of hierarchical generative models, see
Section 8, also maps neatly onto the hierarchical structure of cortical networks,
at least in the most frequently studied perceptual modalities like vision. Here,
the simple idea is that top-down cortical signalling conveys predictions while
835
bottom-up activity returns prediction errors [52]. However, it remains an open
question whether representing the world in terms of Gaussian distributions is
sufficient given the complexities of real-world sensorimotor interactions. For
example, standard robotics architectures have long utilized practical strategies
for representing more complex distributions [53] including (for example) multi-
840
modal peaks [54].Other authors have proposed that brains engage in Bayesian
sampling rather than the encoding of probability distributions, suggesting that
samplingschemesparsimoniouslyexplainclassiccognitivereasoningerrors[50].
Whether these alternate schemes can be used to construct more versatile and
behaviourally powerful implementations of the FEP, and whether they remain
845
compatible with neuronally plausible process theories, remains to be seen.
The minimisation of IFE, for both inference and learning, is assumed to
be implemented as a gradient descent scheme. While this has the major ad-
vantage of transforming difficult or infeasible inference problems into relatively
straightforward optimization problems, it is not clear whether the propose gra-
850
dient descent schemes always have good convergence properties. For example,
the conditions under which gradient descent will become stuck in local minima,
or fail to converge in an appropriate amount of time, are not well understood.
Furthermore, parameters such as learning rate will be crucial for the timely
inference of the dynamics of variables, as well as central to the dynamics of
855
control, see Fig. 1 and 2. Parameters like these, which play important roles in
the estimation of but not specification of the IFE, can be incorporated into
process theories in many ways, with as yet no clear consensus (though see, for
54
one proposal [55]).
Theimplementationdescribedinthispapersupportsinferenceindynamical
860
environments. This is based on the concept of generalised motions, whereby
it is assumed that the brain infers not only the current value of environmental
variables (e.g.,position) but also their higher-order derivatives (i.e., velocity,
acceleration, jerk, etc.). This involve both that the relevant sensory noise is
differentiable, and, that interactions between derivatives are linear [18]. The
865
extent to which these assumptions are justifiable remains unclear, as does the
utility of encoding generalized motions in practical applications. It is likely,
for example, that signal magnitudes after the second derivative will be small
and carry considerable noise, thus practical usefulness of including higher order
derivatives is unclear, although this may be justifiable in some cases [56].
870
Under active inference, prediction errors are minimised by acting on the
worldtochangesensoryinput,ratherthanbymodifyingpredictions. Activein-
ference therefore depends on the ability to make conditional predictions about
the sensory consequences of actions. To achieve this the FEP assumes that
agents have a model of the relationship between action and sensation, in the
875
form of an inverse model, in addition to their generative model [57, 29]. In the
generalcasethespecificationofaninversemodelisnon-trivial[42],whichatfirst
glance seems like a strong assumption. However, the FEP suggests generation
of motor actions are driven through the fulfilment of proprioceptive predictions
only, where relations between actions and (proprioceptive) sensations are as-
880
sumed to be relatively simple such that minimisation of prediction error can be
satisfiedbysimplereflexarcs[9,43]. Onthisview,actiononlyindirectlyaffects
exteroceptiveorinteroceptivesensations,obviatingtheneedforcomplicatedin-
verse models like those described in the motor control literature [42, 43]. In the
implementation of the FEP given in this paper there is no distinction between
885
different types of sensory input.
In Section 7 we showed that behaviour is extremely sensitive to precisions.
This is often presented as an advantage of the framework, allowing an agent
to balance sensory inputs against internal predictions in an optimal and con-
55
text sensitive manner, through precision weighting (which is associated with
890
attention) [8]. Supposedly the appropriate regulation of precision should also
emerge as a consequence of the minimisation of free energy, see Section 8 for a
description of this. But how the interplay between brain states and precisions
will unfold in an active agent involved in a complex behaviour is far from clear.
Where do the priors come from? This is an intuitive way to put a key
895
challenge for models involving Bayesian inference [45]. To some extent the
FEP circumvents this problem via the concept of hierarchical models, which
maps neatly onto the framework of ‘empirical Bayes’ [44]. In this view, the
hierarchical structure allows priors at one level to be supplied by posteriors at
a higher level. Sensory data are assumed to reside only at the lowest level in
900
the hierarchy, and the highest level is assumed to generate only spontaneous
random fluctuations. While this is a powerful idea within formal frameworks,
its practicality for guiding inference in active agents remains to be established.
These discussion points merely scratch the surface of the promises and pit-
falls of the FEP formalism, a formalism which is rapidly advancing both in its
905
theoretical aspects and in its various implementations and applications. Never-
theless, research directed towards addressing these issues should further clarify
boththeexplanatorypowerandthepracticalutilityofthisincreasinglyinfluen-
tial framework. In this paper, we have focused on encapsulating within a single
presentation the essential mathematical aspects of the FEP and its implemen-
910
tation. In doing so we hope to clarify the scientific contributions of the FEP,
facilitate discussions of some of the core issues and assumptions underlying it,
and motivate additional research to explore how far the grand ambitions of the
FEP can be realized in scientific practice.
10. Acknowledgements
915
The work of C.S.K. was supported by a special fund granted by the Chon-
nam National University. C.S.K. is grateful to the hospitality of the School
of Engineering aand Informatics at the University of Sussex where he spent a
56
sabbatical. SupportisalsogratefullyacknowledgedfromtheDr. Mortimerand
Theresa Sackler Foundation.
920
References
References
[1] K. Friston, The free-energy principle: a unified brain theory?, Nat Rev
Neurosci 11 (2010) 127–138.
[2] K. Friston, The free-energy principle: a rough guide to the brain?, Trends
925
Cogn Sci 13 (2009) 293–301.
[3] K. Friston, Some free-energy puzzles resolved: response to Thornton,
Trends Cogn Sci 14 (2010) 54.
[4] H.vonHelmholz,Treatiseonphysiologicaloptics,3rdEdition,Voss,Ham-
burg, 1909.
930
[5] D. C. Knill, A. Pouget, The Bayesian brain: the role of uncertainty in
neural coding and computation, Trends Neurosci 27 (2004) 712–719.
[6] R.P.Rao,D.H.Ballard,Predictivecodinginthevisualcortex: afunctional
interpretationofsomeextra-classicalreceptive-fieldeffects, NatNeurosci2
(1999) 79–87.
935
[7] A.Bubic,D.Y.vonCramon,R.I.Schubotz,Prediction,cognitionandthe
brain, Front Hum Neurosci 4 (2010) 25–25.
[8] A.Clark,Whatevernext? predictivebrains,situatedagents,andthefuture
ofcognitivescience,BehavioralandBrainSciences36(03)(2013)181–204.
[9] K. J. Friston, J. Daunizeau, J. Kilner, S. J. Kiebel, Action and behavior:
940
a free-energy formulation, Biol Cybern 102 (3) (2010) 227–260.
[10] A.K.Seth,Thecyberneticbayesianbrain: Frominteroceptiveinferenceto
sensorimotor contingencies, Open MIND. Frankfurt A. M: MIND Group.
57
[11] R. Neal, G. Hinton, A view of the em algorithm that justifies incremental,
sparse, and other variants, in: M. Jordan (Ed.), Learning in Graphical
945
Models, MIT Press, Cambridge, MA, 1998, pp. 355–368.
[12] G. Hinton, R. Zemel, Autoencoders, minimum description length, and
helmholtz free energy., in: G. T. J. D. Cowan, J. Alspector (Eds.), Ad-
vances in Neural Information Processing Systems 6, Morgan Kaufmann,
San Mateo, CA, 1994, pp. 3–10.
950
[13] R.Zemel,G.Hinton,Learningpopulationcodesbyminimizingdescription
length, Neural Computation 7 (1995) 549–564.
[14] P. Dayan, G. E. Hinton, R. M. Neal, R. S. Zemel, The Helmholtz machine,
Neural Comput 7 (1995) 889–904.
[15] K. Friston, Life as we know it, Journal of The Royal Society Interface
955
10 (86) (2013) 20130475.
[16] K.Friston, Atheoryofcorticalresponses, PhilosTransRSocLondBBiol
Sci 360 (2005) 815–836.
[17] K. Friston, J. Kilner, L. Harrison, A free energy principle for the brain, J
Physiol Paris 100 (2006) 70–87.
960
[18] K. Friston, J. Mattout, N. Trujillo-Barreto, J. Ashburner, W. Penny, Vari-
ational free energy and the Laplace approximation, Neuroimage 34 (2007)
220–234.
[19] K. J. Friston, K. E. Stephan, Free-energy and the brain, Synthese 159
(2007) 417–458.
965
[20] K. J. Friston, N. Trujillo-Barreto, J. Daunizeau, DEM: a variational treat-
ment of dynamic systems, Neuroimage 41 (2008) 849–885.
[21] K. Friston, Hierarchical models in the brain, PLoS Comput Biol 4 (2008)
e1000211–e1000211.
58
[22] K. J. Friston, J. Daunizeau, S. J. Kiebel, Reinforcement learning or active
970
inference?, PLoS One 4 (2009) e6421–e6421.
[23] K.Friston,S.Kiebel,Corticalcircuitsforperceptualinference,NeuralNetw
22 (2009) 1093–1104.
[24] K. Friston, S. Kiebel, Predictive coding under the free-energy principle,
Philos Trans R Soc Lond B Biol Sci 364 (2009) 1211–1221.
975
[25] R. L. Carhart-Harris, K. J. Friston, The default-mode, ego-functions and
free-energy: a neurobiological account of Freudian ideas, Brain.
[26] R. A. Adams, S. Shipp, K. J. Friston, Predictions not commands: active
inferenceinthemotorsystem,BrainStructureandFunction218(3)(2013)
611–643.
980
[27] K. Friston, K. Stephan, B. Li, J. Daunizeau, Generalised filtering, Mathe-
matical Problems in Engineering 2010.
[28] G. Pezzulo, F. Rigoli, K. Friston, Active inference, homeostatic regulation
and adaptive behavioural control, Progress in neurobiology 134 (2015) 17–
35.
985
[29] K. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbeck, G. Pezzulo, Active
inference: A process theory, Neural Computation.
[30] G.E.Hinton,R.S.Zemel,Autoencoders,minimumdescriptionlength,and
helmholtz free energy, Advances in neural information processing systems
(1994) 3–3.
990
[31] K. Friston, R. A. Adams, L. Perrinet, M. Breakspear, Perceptions as hy-
potheses: saccades as experiments, Frontiers in psychology 3.
[32] G. E. Hinton, Learning multiple layers of representation, Trends in cogni-
tive sciences 11 (10) (2007) 428–434.
[33] K. Friston, Is the free-energy principle neurocentric?, Nat Rev Neurosci.
995
59
[34] T. M. Cover, J. A. Thomas, Elements of information theory, Wiley-
Interscience, New York, 1991.
[35] A. Adkins, Equilibrium thermodynamics, 3rd Edition, Cambridge Univer-
sity Press, Cambridge, 1983.
[36] K. Friston, Variational filtering, NeuroImage 41 (2008) 747–766.
1000
[37] K. Huang, Statistical mechanics, John Wiley and Sons, New York, 1987.
[38] R. Bogacz, A tutorial on the free-energy framework for modelling
perception and learning, Journal of Mathematical Psychology (2015)
–doi:http://dx.doi.org/10.1016/j.jmp.2015.11.003.
URL http://www.sciencedirect.com/science/article/pii/
1005
S0022249615000759
[39] R.Zwanzig,Nonequilibriumstatisticalmechanics,OxfordUniversityPress,
Oxford, 2001.
[40] S. Haykin, N. Network, A comprehensive foundation, Neural Networks
2 (2004).
1010
[41] K. Friston, S. Kiebel, Predictive coding under the free-energy principle,
Philosophical Transactions of the Royal Society B: Biological Sciences
364 (1521) (2009) 1211–1221.
[42] D. M. Wolpert, Computational approaches to motor control, Trends in
cognitive sciences 1 (6) (1997) 209–216.
1015
[43] K. Friston, What is optimal about motor control?, Neuron 72 (3) (2011)
488–498.
[44] G. Casella, R. Berger, Statistical inference, Duxbury, Pacific Grove, 2002.
[45] R.E.Kass,D.Steffey,ApproximateBayesianinferenceinconditionallyin-
dependent hierarchical models (parametric empirical Bayes models), Jour-
1020
nal of the American Statistical Association 407 (1989) 717–726.
60
[46] S. Zeki, S. Shipp, The functional logic of cortical connections, Nature 335
(1988) 311–317.
[47] D.J.Felleman,D.C.VanEssen,Distributedhierarchicalprocessinginthe
primate cerebral cortex, Cerebral Cortex 1 (1991) 1–47.
1025
[48] L.Pio-Lopez,A.Nizard,K.Friston,G.Pezzulo,Activeinferenceandrobot
control: acasestudy,JournalofTheRoyalSocietyInterface13(122)(2016)
20160616.
[49] A. Pouget, J. M. Beck, W. J. Ma, P. E. Latham, Probabilistic brains:
knowns and unknowns, Nature neuroscience 16 (9) (2013) 1170–1178.
1030
[50] D. C. Knill, A. Pouget, The bayesian brain: the role of uncertainty in
neural coding and computation, TRENDS in Neurosciences 27 (12) (2004)
712–719.
[51] P.Elias,Predictivecoding–i,IRETransactionsonInformationTheory1(1)
(1955) 16–24.
1035
[52] A. M. Bastos, W. M. Usrey, R. A. Adams, G. R. Mangun, P. Fries, K. J.
Friston,Canonicalmicrocircuitsforpredictivecoding,Neuron76(4)(2012)
695–711.
[53] S. Thrun, W. Burgard, D. Fox, Probabilistic robotics, MIT press, 2005.
[54] M. Otworowska, J. Kwisthout, I. van Rooij, Counter-factual mathematics
1040
of counterfactual predictive models, Frontiers in psychology 5.
[55] M. Joffily, G. Coricelli, Emotional valence and the free-energy principle,
PLoS Comput Biol 9 (6) (2013) e1003094.
[56] B. Balaji, K. Friston, Bayesian state estimation using generalized coordi-
nates, in: SPIE Defense, Security, and Sensing, International Society for
1045
Optics and Photonics, 2011, pp. 80501Y–80501Y.
61
[57] A. K. Seth, A predictive processing theory of sensorimotor contingencies:
Explainingthepuzzleofperceptualpresenceanditsabsenceinsynesthesia,
Cognitive neuroscience 5 (2) (2014) 97–118.
Appendix A. Variational Bayes: Ensemble learning
1050
Here, we present an alternative approach to how the brain may achieve
true posterior density, which makes no assumptions about how the R-density
is encoded in the brain’s state; namely the Laplace approximation for the R-
densityisdispensedwith. Technicallytheabovemethodistermed‘Generalized
Filtering’ in [27] and the present one ‘Variational Filtering’ in [36].
1055
Accordingtoequation(7)theIFEisafunctionaloftheR-densityqpϑqwhere
thevariableϑdenotestheenvironmentalstatescollectively. Theenvironmental
sub-states ϑ , α “ 1,2,¨¨¨ ,N, must vary on distinctive time-scale, τ ă τ ă
α 1 2
¨¨¨ăτ ,whereτ isassociatedwithϑ ,conformingtophysicslaws,ingeneral.
N α α
Then,thesub-densitiesmaybeassumedtobestatistically-independenttoallow
the factorization approximation for qpϑq as
źN
qpϑq” q pϑ q. (A.1)
α α
i“1
Equation (4) gives rise to the individual normalization condition:
ż ż
źN
dϑ qpϑq“ dϑ q pϑ q“1
α α α
α“1
which asserts that ż
dϑ q pϑ q“1. (A.2)
α α α
When the factorization approximation, equation (A.1) is substituted into equa-
tion (7), the IFE is written as
# +
ż
ź ÿ
F “ rdϑ q pϑ qs Epϑ,ϕq` lnq pϑ q
α α α σ σ
α σ
” Frqpϑq;ϕs
where the last expression indicates explicitly that the IFE is to be treated as
a functional of the R-density. We now optimize the IFE functional by taking
62
the variation of F with respect to a particular R-density q pϑ q. We treat
β β
the remainder of the ensemble densities as constant and use the normalization
constraint, equation (4), in the form
˜ ¸
ż
ź
λ dϑ q pϑ q´1 “0 (A.3)
α α α
α
where λ is a Lagrange multiplier.
A straightforward manipulation brings about
# ˜ ¸ +
ż ż
ź ÿ
δ F “ dϑ dϑ q pϑ q Epϑ,ϕq` lnq pϑ q `1`λ δq
β β α α α σ σ β
α‰β σ
where δ represents a functional derivative with respect to q pϑ q. Next, by
β β β
imposingδ F ”0itfollowsthattheintegrationmustvanishidenticallyforany
β
change in δq ,
β
˜ ¸
ż
ź ÿ
dϑ q pϑ q Epϑ,ϕq` lnq pϑ q `1`λ“0
α α α σ σ
α‰β σ
which is to be solved for q pϑ q. The result brings out the optimal density for
β β
the sub-state ϑ as
β
# +
ż
ÿ ź
q˚ “exp ´pλ`1q´ dϑ q pϑ qlnq pϑ q´E pϑ ,ϕq (A.4)
β α α α σ σ β β
σ‰β α‰β
where use has been made of the definition
ż
ź
E pϑ ,ϕq” dϑ q pϑ qEpϑ,ϕq (A.5)
β β α α α
α‰β
which is the partially-averaged energy [17, 18]. Here, it is worthwhile to note
that the following relation holds
ż ż
dϑ q pϑ qE pϑ ,ϕq“ dϑ qpϑqEpϑ,ϕq,
β β β β β
which states that the expectation of the partially-averaged energy E pϑ ,ϕq
β β
under q pϑ q is the average energy, i.e. the first term in equation (9). The
β β
undeterminedLagrangemultiplierisnowfixedbythenormalizationconstraint,
equation (A.2), which results in
„ż  # ż +
ÿ ź
dϑ
β
e´Eβpϑβ,ϕq exp ´pλ`1q´ dϑ
α
q
α
pϑ
α
qlnq
σ
pϑ
σ
q “1,
σ‰β α‰β
63
which is to be solved for λ. When the determined λ is substituted back into
equation (A.4), the resulting ensemble-learned R-density can be expressed for-
mally as 3
1
q
β
˚pϑ
β
q“
Z
e´Eβpϑβ,ϕq (A.6)
β
where Z has been defined to be
β
ż
Z
β
” dϑ
β
e´Eβpϑβ,ϕq. (A.7)
The superscript ˚ appearing in q˚ indicates that it is the solution which op-
β
timizes the IFE. The functional form of equation (A.6) is reminiscent of the
1060
equilibriumcanonicalensembleinstatisticalphysicsinwhichthenormalization
factor Z is called the partition function of the subsystem tϑ u [37].
β β
Under the factorization approximation, by substituting equation (A.6) into
equation (A.1), the R-density becomes
1
q˚pϑq“ e´ETpϑ,ϕq (A.8)
Z
T
where
ż
ÿN źN
E pϑ,ϕq” E pϑ ,ϕq and Z ” Z “ dϑe´ETpϑ,ϕq.
T α α T α
α“1 α“1
In equation (A.8) Z may be called the ‘total’ partition function of the envi-
T
ronmental states and E is the sum of the partially-averaged energies. Note
T
that, as a consequence of the ensemble-learning, the optimizing R-density ap-
1065
proximatestheposteriordensityppϑ|ϕq(seeSection3andbelow). Inprinciple,
the optimizing R-density, equation (A.8), completes the ensemble-learning of
the sensory data. However, it does not provide a functionally fixed-form for
the optimal R-density. This is because the partially-averaged energy appearing
on the RHS of equation (A.8) is a functional of the R-density itself (see equa-
1070
tion (A.5)). One possible way to obtain a closed form of q˚pϑ,ϕq is to seek
3Note that the minus sign arises in the exponent because we have defined the energy as
equation (10) differently from other papers on the free energy principle. We have made this
choice because our definition resembles the Boltzmann factor in the canonical ensemble in
statisticalphysics.
64
a self-consistent solution: One starts with an educated guess (an ‘ansatz’) for
the optimal R-density to evaluate the partially-averaged energy, equation (A.5)
and uses the outcome to update the R-density, equation (A.6). This iterative
process is to be continued until a convergence reaches between estimation and
1075
evaluation of the R-densities.
We now exploit what actually the optimal R-density, q˚pϑ q given in equa-
β β
tion(A.6),is. Thepartiallyaveraged-energyappearinginq˚canbemanipulated
β
as
ż
ź
E pϑ ,ϕq “ dϑ q pϑ qEpϑ,ϕq
β β α α α
α‰βż
ÿ ź
“ ´ dϑ q pϑ qlnppϑ ,ϕ q, (A.9)
α α α σ σ
σ α‰β
wherewehaveusedthefactorizationapproximationfortheG-densityappearing
in the energy E “´lnppϑ,ϕq as
ź ź
ppϑ,ϕq“ ppϑ ,ϕ q“ ppϑ |ϕ qppϕ q. (A.10)
σ σ σ σ σ
σ σ
Next, one can separate out the environmental sub-state ϑ among summation
β
on the RHS of equation (A.9) to cast it into
ż
ÿ ź
E pϑ ,ϕq“´lnppϑ ,ϕ q´ dϑ q pϑ qlnppϑ ,ϕ q. (A.11)
β β β β α α α σ σ
σ‰β α‰β
Then, it follows from equation (A.6) that
q˚pϑ q“ ş
e´Eβpϑβ,ϕq
Ñ ş
ppϑ
β
,ϕ
β
q
“ppϑ |ϕ q,
β β dϑ
β
e´Eβpϑβ,ϕq dϑ
β
ppϑ
β
,ϕ
β
q β β
where the last step can be obtained by noticing the identity, ppϑ ,ϕ q “
β β
ş
ppϑ |ϕ qppϕ q, and dϑ ppϑ ,ϕ q “ ppϕ q. Finally, the ensemble-learned R-
β β β β β β β
density, equation (A.8), is given by
ź ź
q˚pϑq“ q˚pϑ q“ ppϑ |ϕ q“ppϑ|ϕq. (A.12)
α α α α
α α
Equation(A.12)statesthattheR-densityqpϑqisdirected totheposteriorppϑ|ϕq
1080
when the IFE, equation (7) is minimized, conforming to the idea of variational
Bayes.
65
By substituting the optimal R-density, equation (A.12), into expression for
IFE given in equation (7), we can also obtain the minimized IFE as
ż
q˚pϑq
F˚ “ dϑ q˚pϑqln
ppϑ,ϕq
ż
ppϑ|ϕq
“ dϑ q˚pϑqln
ppϑ|ϕqppϕq
ż
“ ´lnppϕq dϑ q˚pϑq
“ ´lnppϕq. (A.13)
where we have used equation (A.12) in moving to second line and the normal-
1085
ization condition for q˚pϑq in the last step. Note that we have made it explicit
that the sensory density ppϕq is conditioned on the biological agent m. Thus,
we have come to a conclusion that the minimum IFE provides a tight bound on
surprisal.
Insummary,thevariationoftheIFEfunctionalwithrespecttotheR-density
1090
(ensemble-learning) has allowed us to specify an optimal (ensemble-learned) R-
density, q˚pϑ,ϕq, selected among an ensemble of R-densities. The specified
R-density is the brain’s solution to statistical inference of the posterior density
about the environmental states given sensory inputs. The minimum IFE, fixed
in this way, is identical to the surprisal. To fulfill this it was assumed that dis-
1095
tinctiveindependenttime-scalescharacterizeenvironmentalsub-states(thefac-
torization approximation). The ensemble-learned R-density of each partitioned
variable set ϑ , q˚pϑ q, is specified by the corresponding partially-averaged en-
β β β
ergy (see equation (A.6)). The influence from other environmental sets tϑ u
σ
(σ ‰ β) occurs as their average effect: Their complicated interactions have
1100
been averaged out in equation (A.5). In this sense, ϑ may be regarded as a
β
‘mean-field’ of the environmental states. Accordingly, the procedure described
in the above is sometimes referred to as a mean-field approximation [20, 36].
Appendix B. Dynamic Bayesian Thermostat
% A Simple Bayesian Thermostat
1105
66
% A free energy principle for action and perception sciences : A mathematical evaluation
% Christopher L. Buckley ,Chang Sub Kim, Simon M. McGregor and Anil K. Seth
clear ;
rng(6);
%simulation params
1110
simTime=100; dt=0.005; time =0:dt:simTime;
N =length(time);
action =true;
%Generetaive Model Parameters
Td = 4; %desired temperature
1115
%Time we trun on action
actionTime =simTime/4;
%initialise sensors
1120
rho 0(1) =0;
rho 1(1)=0;
%sensory variances
Omega z0 =0.1;
1125
Omega z1 =0.1;
%hidden state variances
Omega w0 =.1;
Omega w1 =.1;
1130
%Params for generative process
T0 = 100; %temperature at x=0
%intialise brain state variables
mu 0(1)=0;
1135
67
mu 1(1)=0;
mu 2(1)=0;
% sensory noise in the negerateive proess
zgp 0 = randn(1,N)∗.1;
1140
zgp 1 = randn(1,N)∗.1;
%Initialise action varaible
a(1) =0;
1145
%Initialise generative process
x dot(1) = a(1);
x(1) = 2;
T(1) = T0/(x(1)ˆ2+1);
Tx(1)= ´2∗T0∗x(1)∗(x(1)ˆ2+1)ˆ´2;
1150
T dot(1) = Tx(1)∗(x dot(1));
%Initialise sensory input
rho 0(1) = T(1);
rho 1(1) = T dot(1);
1155
%Intialise error terms
epsilon z 0 = (rho 0(1)´mu 0(1));
epsilon z 1 = (rho 1(1)´mu 1(1));
1160
epsilon w 0 = (mu 1(1)+mu 0(1)´Td);
epsilon w 1 = (mu 2(1)+mu 1(1));
%Intialise Variational Energy
IFE(1) = 1/Omega z0∗epsilon z 0ˆ2/2 ...
1165
68
+ 1/Omega z1∗epsilon z 1ˆ2/2 ...
+1/Omega w0∗epsilon w 0ˆ2/2 ...
+1/Omega w1∗epsilon w 1ˆ2/2 ...
+1/2∗log(Omega w0∗Omega w1∗Omega z0∗Omega z1);
1170
%Gradient descent learning params
k=.1; %for inference
ka=.01; %for learning
1175
for i=2:N
%The generative process
x dot(i) = a(i´1);%action
x(i) = x(i´1)+dt∗(x dot(i ));
1180
T(i) = T0/(x(i)ˆ2+1);
Tx(i)= ´2∗T0∗x(i)∗(x(i)ˆ2+1)ˆ´2;
T dot(i) = Tx(i)∗(x dot(i ));
rho 0(i) = T(i) + zgp 0(i ); %calclaute sensory input
1185
rho 1(i) = T dot(i) + zgp 1(i );
%The generative model
epsilon z 0 = (rho 0(i´1)´mu 0(i´1));%error terms
epsilon z 1 = (rho 1(i´1)´mu 1(i ´1));
1190
epsilon w 0 = (mu 1(i´1)+mu 0(i´1)´Td);
epsilon w 1 = (mu 2(i´1)+mu 1(i ´1));
IFE(i) = 1/Omega z0∗epsilon z 0ˆ2/2 ...
1195
69
+1/Omega z1∗epsilon z 1ˆ2/2 ...
+1/Omega w0∗epsilon w 0ˆ2/2 ...
+1/Omega w1∗epsilon w 1ˆ2/2 ...
+1/2∗log(Omega w0∗Omega w1∗Omega z0∗Omega z1);
1200
mu 0(i) = mu 0(i´1) ...
+dt∗(mu 1(i´1)´k∗(´epsilon z 0/Omega z0 ...
+epsilon w 0/Omega w0));
mu 1(i) = mu 1(i´1) +dt∗(mu 2(i´1)´ k∗(´epsilon z 1/Omega z1 ...
1205
+epsilon w 0/Omega w0+epsilon w 1/Omega w1));
mu 2(i) = mu 2(i ´1)...
+dt∗´k∗(epsilon w 1/Omega w1);
1210
if (time(i) >25)
a(i) = a(i´1) +dt∗´ka∗Tx(i)∗epsilon z 1/Omega z1; %active inference
else
a(i) = 0;
1215
end
end
figure (1); clf ;
1220
figure (1);
subplot(5,1,1)
plot(time ,T); hold on;
1225
70
plot(time ,x); hold on;
legend(’T’ , ’x’)
subplot(5,1,2)
plot(time ,mu 0, ’k’); hold on;
1230
plot(time ,mu 1, ’m’); hold on;
plot(time ,mu 2, ’b’); hold on;
legend(’\mu’ , ’\mu’ , ’\mu’);
1235
subplot(5,1,3)
plot(time ,rho 0 , ’k’); hold on;
plot(time ,rho 1 , ’m’); hold on;
legend(’\rho’ , ’\rho ’);
1240
subplot(5,1,4)
plot(time , a, ’k’);
ylabel(’a’)
1245
subplot(5,1,5)
plot(time , IFE, ’k’); xlabel(’time ’); hold on;
ylabel(’IFE’)
71
Table 1. Mathematical Objects in the IFE
Symbol Name Description
ϑ Environmental states These refer to all states outside of the brain and in-
clude both environmental and bodily variables.
ϕ Sensory data Signals caused by the environment.
qpϑq R-density Organism’s (implicit) probabilistic representation of
environmental states which cause sensory data.
ppϕ,ϑq G-density Joint probability density, encoded in the brain relat-
ing sensory data to environmental states. Assumed
tobeencodedinaformwhichmakesppϕ|ϑqandppϑq
accessible, but not ppϑ|ϕq or ppϕq.
ppϑq Prior density Organism’spriorbeliefs,encodedinthebrain’sstate,
about environmental states.
ppϕ|ϑq Likelihood density Organism’s implicit beliefs about how environmental
states map to sensory data.
ppϑ|ϕq Posterior density Theinferencethataperfectlyrationalagent(within-
complete knowledge) would make about the environ-
ment’sstateuponobservingnewsensoryinformation,
given the organism’s prior assumptions.
ppϕq Sensory density Probability density of the sensory input, encoded in
the brain’s state, which cannot be directly quantified
given sensory data alone.
´lnppϕq Surprisal Surprise or self-information in information-theory
terminology, which is equal to the negative of log
model evidence in Bayesian statistics.
F Information-theoretic free The quantity minimised under the FEP which forms
energy (IFE) anupperboundonsurprisalallowstheapproximation
of the posterior density.
72
Table 2. Mathematical objects in the Laplace encoding
Symbol Name Description
Frqpϑq;ϕs Variational IFE A functional (higher-order function) of the R-
density qpϑq and a function of the sensory data
ϕ.
Npϑ;µ,ζq (Gaussian) fixed-form R- An‘ansatz’forunknownqpϑq(theLaplaceapprox-
density imation)
µ, ζ Parameters for the R- Sufficient statistics (expectation and variance) of
density the fixed-form R-density, encoded in the brain’s
state.
ζ˚ Optimal variance Analytically derivable optimal ζ, removing an ex-
plicit dependence of F on ζ.
ppϕ,µq Laplace-encoded G- TheG-densityinwhichdependenceonϑhasbeen
density replaced with a dependence on µ.
Epµ,ϕq Laplace-encoded energy Mathematicalconstructdefinedtobe´lnppµ,ϕq.
73
Table 3. Mathematical glossary in the generative models
Symbol Name & Description
Simple model ppϕ,µq“ppϕ|µqppµq
gpµ;θq Generativemappingbetweenthebrainstatesµandtheobserveddata
ϕ, paramterised by θ
z, w Random fluctuations represented by Gaussian noise
σ , σ That variance of these fluctuations (the inverse of precisions)
z w
ppϕ|µq, ppµq Likelihood, prior of µ, which together determine ppϕ,µq
ś
Dynamical model ppϕ,µq“ 8 ppϕ |µ qppµ |µ q
n“0 rns rns rn`1s rns
µ˜ Brain states in generalized coordinates; an infinite vector whose com-
ponents are given by successive time-derivatives, µ˜ ”pµ,µ1,µ2,¨¨¨q”
pµ ,µ ,µ ,¨¨¨q.
r0s r1s r2s
ϕ˜ Sensory data, similarly defined as ϕ˜“pϕ,ϕ1,ϕ2,¨¨¨q.
ϕ “g `z Generalizedmappingbetweentheobserveddataϕandthebrainstates
rns rns rns
µ at the dynamical order n
µ “f `w Generalizedequationsofmotionofthebrainstateµatthedynamical
rn`1s rns rns
order n
g , f Generative functions in the generalized coordinates
rns rns
ppϕ |µ q Likelihood of the generalized state µ , given the data ϕ
rns rns rns rns
ppµ |µ q Gaussian prior of the generalized state µ
rn`1s rns rns
74
Table 4. Mathematical constructs in the hierarchical generative model
Symbol Name & Description
ś
Hierarchical model ppϕ,µq“ppµpMqq M´1ppµpiq|µpi`1qq
i“0
µpiq Brain states at cortical layer i (i“1,2,¨¨¨ ,M); µp0q ”ϕ denotes the
sensory data which reside at the lowest cortical layer.
gpiqpµpiqq Generative map (or function) of the brain state µpiq to estimate one-
levellowerstateµpi´1qinthecorticalhierarchyviaµpi´1q “gpiqpµpiqq`
zpi´1q; where zpi´1q is Gaussian noise.
ppµpiq|µpi`1qq Likelihood of µpiq given a value for µpi`1q; which acts as a prior for
ppµpi´1q|µpiqq in the cortical hierarchy.
ppµpMqq Probabilistic representation of brain states at the highest layer, which
forms the highest prior.
75
Table 5. Mathematical constructs in the full generative model
Symbol Name & Description
ś
Full construct ppϕ˜ ,µ˜ q“ppx˜pMq,v˜pMqq M´1ppx˜piq|v˜piqqppv˜piq|x˜pi`1q,v˜pi`1qq
α α α α i“0 α α α α α
µ˜piq Brain state α in cortical layer i in generalized coordinates, whose nth
α
component is denoted as µpiq .
αrns
x˜piq, v˜piq Twodistinctiveneuronalrepresentations,µ˜piq “px˜piq,v˜piqq;designated
α α α α α
as hidden and causal states, respectively.
g˜piq Generative map of the causal state v˜piq to learn the state one layer
α α
below, v˜pi´1q “g˜piqpx˜piq,v˜piqq`z˜pi´1q.
α α α α α
f˜piq Generative function which induces the Langevin-type equation of mo-
α
tion of the hidden state x˜piq, x˜9piq “f˜piqpx˜piq,v˜piqq`w˜piq.
α α α α α α
z˜piq, w˜piq Random fluctuations treated as Gaussian noise.
α α
ppx˜pMq,v˜pMqq Prior density of the brain state µ˜ at the highest cortical layer pMq.
α α α
ppx˜piq|v˜piqq Probabilistic representation of the intra-layer dynamics of hidden
α α
states x˜piq conditioned on the causal state v˜piq via f˜piq; dynamic tran-
α α α
sitionfromordernton`1ishypothesizedastheGaussianfluctuation
of wpiq “xpiq ´fpiq .
αrns αrn`1s αrns
ppv˜piq|x˜pi`1q,v˜pi`1qq Likelihood density of the causal state v˜piq which serves as a prior for
α α α
one layer lower density, representing statistically the inter-layer map
between two successive causal states, zpiq “ vpiq ´gpi`1q, by the
αrns αrns αrns
Gaussian fluctuation.
76
Table 6. Mathematical objects for recognition dynamics
Symbol Name & Description
∇ Epµ˜,ϕ˜q ‘Gradient’ of the Laplace encoded-energy: Multi-dimensional deriva-
µ˜
tive of the scalar function E; which vanishes at an optimum µ˜˚.
Dynamical construct µ˜9piq´Dµ˜piq “´κ ∇ Epµ˜,ϕ˜q, µ˜piq “px˜piq,v˜piqq
α α α µ˜p
α
iq α α α
µ˜piq Generalized brain states: A point in the generalized state space to
α
represent fast ‘time-dependent’ neuronal activity µ on each cortical
α
layer i [see equations (70) and (71)].
µ˜9piq, Dµ˜piq µ˜9piq is the ‘path of the mode’; Dµ˜piq is the ‘mode of the path’. µ˜9piq
α α α α α
representstherateofchangeofabrainstateingeneralizedstatespace,
while Dµ˜piq represents the encoded motion in the brain; when the
α
two become identical, i.e. µ˜9piq “ Dµ˜piq, in the course of recognition
α α
dynamics, E reaches its minimum.
Static construct µ:piq “´κ µˆpiq¨∇ Epµ˜,ϕ˜;θ,γq, µ “θ,γ
β β β µβ β
Λ˜αpiq, Λ˜αpiq Precisions: Inverse variances in the generalised coordinates [see equa-
z w
tion (84)].
θpiq, γpiq Parameters, hyper-parameters: The slow brain states are treated
α α
‘static’ and are associated with θpiq and γpiq, respectively, on each
α α
cortical layer; where θpiq appear as parameters in the generative func-
α
tions gpiq and fpiq, and γpiq are hyper-parameters in the precisions
α α α
Λαpiq and Λαpiq.
z w
ξ˜αpiq, ξ˜αpiq Prediction errors; measuring the discrepancy between the observation
z w
and the evaluation [e.g. equations (88), (89)]
77

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "The free energy principle for action and perception: A mathematical review"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
