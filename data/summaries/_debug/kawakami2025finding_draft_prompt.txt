=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Finding Similar Objects and Active Inference for Surprise in Numenta Neocortex Model
Citation Key: kawakami2025finding
Authors: Hajime Kawakami

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Abstract: Jeff Hawkins and his colleagues in Numenta have proposed the thousand-brains system. This is
amodelofthestructureandoperationoftheneocortexandisunderinvestigationasanewform
of artificial intelligence. In their study, learning and inference algorithms running on the system
are proposed, where the prediction is an important function. The author believes that one of
the most important capabilities of the neocortex in addition to prediction is the ability to make
association,thatis,tofindtherelation...

Key Terms: surprise, system, finding, similar, objects, problem, akita, brains, proposed, inference

=== FULL PAPER TEXT ===

5202
nuJ
11
]CN.oib-q[
1v45512.6052:viXra
Finding Similar Objects and Active Inference for Surprise
in Numenta Neocortex Model
Hajime Kawakami
Akita University, Akita, 010-8502, Japan
kawakami@math.akita-u.ac.jp, hjm.kwkm.07091210@gmail.com
June 11, 2025
Abstract
Jeff Hawkins and his colleagues in Numenta have proposed the thousand-brains system. This is
amodelofthestructureandoperationoftheneocortexandisunderinvestigationasanewform
of artificial intelligence. In their study, learning and inference algorithms running on the system
are proposed, where the prediction is an important function. The author believes that one of
the most important capabilities of the neocortex in addition to prediction is the ability to make
association,thatis,tofindtherelationshipsbetweenobjects. Similarityisanimportantexample
of such relationships. In our study, algorithms that run on the thousand-brains system to find
similarities are proposed. Although the setting for these algorithms is restricted, the author
believes that the case it covers is fundamental. Karl Friston and his colleagues have studied the
free-energy principle that explains how the brain actively infers the cause of a Shannon surprise.
In our study, an algorithm is proposed for the thousand-brains system to make this inference.
The problem of inferring what is being observed from the sensory data is a type of inverse
problem, and the inference algorithms of the thousand-brains system and free-energy principle
solve this problem in a Bayesian manner. Our inference algorithms can also be interpreted as
Bayesian or non-Bayesian updating processes.
Keywords Neocortex · Thousand Brains · Similarity · Active Inference · Bayesian Inference ·
non-Bayesian Inference · Inverse Problem
1 Introduction
Conventionally, scientists state that the neocortex of the brain vertically comprises six layers.
Thus, the layers run parallel to the surface of the neocortex. The neocortex is horizontally
divided into several regions such as the visual and touch regions. For instance, the visual region
comprises several areas such as V1, V2, and V3. The neocortex, each region, and each area
comprise numerous cortical columns that penetrate the six layers. Numerous feedforward and
feedback connections exist between neurons in these cortical columns.
On pages 24 and 25 of [7], citing [15], Hawkins states:
Mountcastle is proposing that all the things we associate with intelligence, which on
the surface appear to be different, are, in reality, manifestations of the same under-
lying cortical algorithm. ... So, what was Mountcastle’s proposal for the location of
the cortical algorithm ? He said that the fundamental unit of the neocortex, the unit
of intelligence, was a “cortical column.”
1
However, Mountcastle did not propose any algorithm: how a cortical column does all the things
weassociatewithintelligence. Thus,Hawkinsetal. inNumentaproposedsuchalgorithmsin[6],
[7],[9],[11],and[14]. WerefertothesealgorithmscollectivelyastheNumenta(neocortex)model.
In these studies, prediction is considered as the most important capability of the neocortex,
and algorithms in the cortical columns for learning and inference, including prediction, have
been proposed (see Algorithms 3.1 and 3.2 described below). The cortical columns learn the
structure of objects using this learning algorithm, and infer the object under observation using
this inference algorithm with the sensory input. Hawkins named the system they created, which
included the Numenta model, the thousand-brains system. While writing this manuscript, the
paper [1] by Hawkins et al. was published. In this paper, Monty, the first instantiation of
the thousand-brains system, is proposed. Our study is based primarily on [9] and [14], which
explicitly describe the Numenta model algorithms, and it also refers to [1].
Whataretheotherimportantcapabilitiesoftheneocortexinadditiontoprediction? Section
2.4 of [1] lists the expected functions of a model of the neocortex. Related to this list, the
author believes that one of the important capabilities is making “association,” that is, finding
the relationships between objects. Similarity between objects is an important example of such
relationships. Theimportanceof“association”hasbeenhighlightedbynumerousscientists. For
instance, Polya [20] states the following on the list entitled “How to Solve it”:
Find the connection between the data and the unknown.
and
Have you seen it before ? Or have you seen the same problem in a slightly different
form ?
P. A. M. Dirac states that:
With the mathematical procedure there are two main methods that one may follow,
(i) to remove inconsistencies and (ii) to unite theories that were previously disjoint.
on page 58 of [19]. Hawkins emphasizes the importance of similarities with respect to Mount-
castle’s idea (see Chapter 3 of [6] and Chapter 2 of [7]). He also states that:
When mathematicians see a new equation, they recognize it as similar to previous
equations they have worked with.
on page 82 of [7]. In this study, we propose algorithms (Algorithms 4.1 and 4.2) that run on
the Numenta model to find similarities. These algorithms are based on the Numenta inference
algorithm (Algorithm 3.2). The setting for these algorithms is restricted, and for more general
“associations,” this setting is significantly limited. However, the author believes that the case
it covers is fundamental.
Friston et al. have studied the free-energy principle, for instance, [4], [5], and [18]. The free-
energy principle explains how the brain infers the cause for a Shannon surprise (informational
surprise). Inourstudy, analgorithm(Algorithm5.1)basedonAlgorithm3.2isproposedforthe
Numenta model to obtain this inference. A relationship between the thousand-brains system
and free-energy principle has been investigated in studies such as [22]. Friston’s theory is based
on probability theory, specifically the Bayesian inference theory. Inference in the Numenta
model is refined by reducing the ambiguity based on successive observations. Therefore, this
inference can be considered to be Bayesian. The problem of inferring what is being observed
from the sensory data is a type of inverse problem, and the inference algorithms of the Numenta
model and free-energy principle solve this problem in a Bayesian manner. We also consider our
inference algorithms from the perspective of Bayesian inference.
2
The remainder of this manuscript is organized as follows: In §2 and §3, the Numenta neocor-
texmodelandlearningandinferencealgorithms(Algorithms3.1and3.2)arereviewed. However,
these algorithms are slightly changed, primarily for simplicity. In §4 and §5, by slightly chang-
ing the Numenta inference algorithm, algorithms to find objects that are similar to a given
object (Algorithms 4.1 and 4.2) and an algorithm to actively infers surprise (Algorithm 5.1) are
proposed.
Although the proposed algorithms of this study are limited and are not based on brain
experimental results, the author hopes that they will contribute to future studies on the brain
or artificial intelligence. Real systems almost always encounter errors, and in the following,
the equations contain few of such errors, unless otherwise noted. It is believed that not only
neurons but also glial cells are important for the transmission of information in the brain (cf.
[3]). However, only neurons are considered in the Numenta model and this study.
2 Object, observation, learning, inference, and recognition
The Numenta model learns, infers, and recognizes objects. Figure 2.1 (A) shows an example of
such an object (see Figure 2 of [9] and Figure 5 of [14]). This object O comprises ten pairs of
locations and features, (location, feature), where ⋆, (cid:50), and ◦ are the features. (Several cases of
more general objects are considered in [1]. In §3.1 of [1], it is stated that “an object is a discrete
entity composed of a collection of one or more other objects.” Habitat objects, YCB object
dataset, and other datasets are listed in §6 as objects for simulation.) In the Numenta model,
time t is a discrete variable, t = 0,1,2,..., and each cortical column of the model observes and
senses one pair of (location, feature) at each time step. Figure 2.1 (B) illustrates an example of
an observation of O. The first observation location is the starting point of the red arrow, and
the sensory feature is ⋆ at this location. The next observation location is the end point of the
arrow, and the sensory feature is (cid:50) at this location. Such an arrow is called a movement vector
in[9]and[14]. Thus, acorticalcolumnoftheNumentamodellearnsO byobservingandsensing
pairs (location, feature) individually (by Algorithm 3.1).
Figure 2.1: An object and a movement vector
(A) (B)
⋆ ⋆
⋆ (cid:50) (cid:50) ⋆ ⋆ (cid:50) (cid:50) ⋆
(cid:1)(cid:21)
(cid:50) ◦ ◦ (cid:50) (cid:1) ◦ ◦
(cid:1)
(cid:1)
⋆ ◦ ⋆ ◦
O O
As described below, the inference is also performed by observing and sensing pairs (location,
feature) individually (by Algorithm 3.2). Assume that the model has already learned objects
O, O′, and O′′ of Figure 2.2, and then begins observing and inferring object O. In Figure 2.3
(A), the red arrow represents the first real movement vector. Then, both the first and second
sensory features are ◦, and this movement can not be distinguished from the other movements
3
Figure 2.2: Example of objects
⋆ ⋆ •
⋆ (cid:50) (cid:50) ⋆ ⋆ ◦ ◦ ⋆ • ◦ (cid:50) •
(cid:50) ◦ ◦ ◦ (cid:50) (cid:50) (cid:50) ◦ (cid:50)
⋆ ◦ (cid:50) • ◦
O O′ O′′
Figure 2.3: Convergence onto a representation for O
(A)
⋆ ⋆ •
(cid:45)
⋆ (cid:50) (cid:50) ⋆ ⋆ ◦(cid:27) ◦ ⋆ • ◦ (cid:50) •
(cid:54)
(cid:45)
(cid:50) ◦(cid:27) ◦ (cid:63)◦ (cid:50) (cid:50) (cid:50) ◦ (cid:50)
(cid:54) (cid:54)
⋆ (cid:63)◦ (cid:50) • ◦(cid:63)
O O′ O′′
(B)
⋆ ⋆ •
⋆ (cid:50) (cid:50) ⋆ ⋆ (cid:27) ◦ ◦ ⋆ • ◦ (cid:50) •
(cid:54) (cid:54)
(cid:50) ◦ (cid:45) ◦ ◦ (cid:50) (cid:50) (cid:50) ◦ (cid:50)
⋆ ◦ (cid:50) • ◦
O O′ O′′
(C)
⋆ ⋆ •
⋆ (cid:50) (cid:50)(cid:27) ⋆ ⋆ ◦ ◦ ⋆ • ◦ (cid:50) •
(cid:54)
(cid:50) ◦ (cid:45) ◦ ◦ (cid:50) (cid:50) (cid:50) ◦ (cid:50)
⋆ ◦ (cid:50) • ◦
O O′ O′′
4
represented by the blue vectors on O, O′, and O′′. Therefore, the model can not identify the
object that it has observed. In Figure 2.3 (B), the red arrows represent the first and second
real movement vectors. Then, these movements can not be distinguished from the movements
represented by the blue vectors on O′. Therefore, although the model is aware that it did not
observe O′′, it is unaware whether it has observed object O or O′. In Figure 2.3 (C), the red
arrows represent the first, second, and third real movement vectors. Then, the model is aware
that it has observed O, that is, it recognizes O. When this is the case, it is said that the
inference has converged onto a representation for the object O. The convergence property has
been investigated in detail in [9] and [14].
The inference by the Numenta model converges to an object, as the ambiguity regarding the
object under observation decreases. The problem of inferring an object using observed data is
an inverse problem. One of the well-known methods for solving inverse problems is successive
approximation such as gradient descent. By contrast, the inference of the Numenta model can
be considered as a Bayesian updating inference (see §5).
3 Numenta model of the neocortex
ThissectionreviewstheNumentamodelofthestructureofneocortexandlearningandinference
algorithms operating on the neocortex, based on [9] and [14]. However, it is slightly changed,
mainly for simplicity (see Remarks 3.1 and 3.3). The neocortex comprises numerous cortical
columns that are stacked vertically next to each other. All the cortical columns have the same
structure and Figure 3.1 shows one of the cortical columns. Although each cortical column is
said to comprise six horizontal layers, the cortical column of Figure 3.1 comprises the following
three layers: the output, sensory, and location layers corresponding to layers 2/3, 4, and 6a,
respectively. The sensory layer is also called the input layer in [9]. The model depicted in Figure
3.1 is obtained by combining the models in [9] and [14]. The model in [9] comprises only the
output and sensory layers, and that in [14] comprises only the sensory and location layers. The
model of Figure 3.1 also corresponds to the learning module in [1] (see Figure 3 in [1]).
EachbluebulletinFigure3.1isanhierarchicaltemporalmemory(HTM)neuron(see[8]and
[16]). HTM neurons are also called cells. Each cell can be in one of the following three states:
active, predictive, or inactive. The location layer comprises several grid cell modules, and each
module comprises several cells arranged in a triangular lattice. In Figure 3.1, only one module
is depicted. The number of modules in the location layer of each cortical column is denoted by
Nloc and the number of cells in each module by Mloc. In some simulations run in [14], Nloc = 10
and Mloc = 30 × 30 – 40 × 40. The sensory layer comprises several mini-columns, and each
mini-column comprises several cells arranged in a line. In Figure 3.1, only one mini-column is
depicted. The number of mini-columns in the sensory layer of each cortical column is denoted
by Nin and the number of cells in each mini-column by Min. In the simulations run in [9] and
[14], Nin = 150 and Min = 16. The output layer has no internal structure such as modules or
mini-columns. In Figure 3.1, only seven cells are depicted. The number of cells in the output
layer of each cortical column is denoted by Nout. In the simulations run in [9], Nout = 4096.
The Numenta model is a discrete time model. The arrows in Figure 3.1 represents the flow
of information between the cells. In the inference, the one cycle of the ordered flow is ⃝1 → ⃝2
→ ⃝3 → ⃝5 → ⃝6 → ⃝7 → ⃝4 → ⃝1 . In the model proposed by [14], it is ⃝1 → ⃝2 → ⃝3 → ⃝4 →
⃝1 , and in the model proposed by [9], it is ⃝2 → ⃝3 → ⃝5 → ⃝6 → ⃝7 → ⃝2 . These two flows are
sub-flows of the flow shown in Figure 3.1. The information flows in learning are similar to the
above. Steps ⃝1 to ⃝4 correspond to the stages 1 to 4 in [14]. Arrow ⃝1 is called the motor input
in [14], and ⃝3 is called the sensory input in [9] and [14]. These inputs originate from outside
5
the cortical column, and the motor input is either conscious or unconscious. Arrow ⃝6 shows the
internal flow of the output layer of a cortical column and the flow between the output layers of
cortical columns. Figure 3.2 illustrates three cortical columns. Different cortical columns may
receive the same type of sensory inputs, and they may also receive different types of sensory
inputs, suchasshapeandcolorinvision. Therefore, theNumentamodelcanhandlemultimodal
sensory inputs.
Figure 3.1: Numenta cortical column
⃝6 ⃝6
(cid:0) (cid:64) Dout • Dout (cid:0) (cid:64)
(cid:64) (cid:0) k,d • k,d (cid:64) (cid:0)
•
•
output •
layer •
f •
ijk
(cid:0)(cid:64)
⃝7
⃝5
sensory (cid:64)(cid:0)
layer f
ijk •
(input •
layer) •
•
(cid:64) Win •
⃝3 (cid:0) t •
•
Din •
c,d
(cid:0)(cid:64)
mini-column
⃝4
⃝2
(cid:64)(cid:0)
Dloc
γ,d
location
layer
• • • •
(cid:64) • • • • module
⃝1 (cid:0) • • • •
• • • •
Let v be a vector or tensor. If each component of v is either 0 or 1, we refer to v as a binary
vector or tensor. For a binary vector or tensor v, the number of 1s in the components of v is
denoted by ♮v. The inner product of vectors u and v of the same dimension is denoted by u•v.
Let Nc be the number of the considered cortical columns. We assume that the values of Nloc,
Mloc, Nin, Min, and Nout are equal for all considered cortical columns. Let Din, Dloc, and
c,d γ,d
Dout be binary vectors, and F = (f ) a binary tensor, where
k,d ijk
dimDin = NlocMloc, dimDloc = NinMin, dimDout = NcNout, dimF = NinMinNout.
c,d γ,d k,d
6
Vector Din represents a dendritic segment d of a cell c in the sensory layer, Dloc represents a
c,d γ,d
dendritic segment d of a cell γ in the location layer, Dout represents a dendritic segment d of a
k,d
cell k in the output layer, and f represents the pair of a cell j in mini-column i of the sensory
ijk
layer and a cell k in the output layer. The components of Din correspond to all the cells in
c,d
the location layer of the cortical column containing c, those of Dloc correspond to all the cells
γ,d
in the sensory layer of the cortical column containing γ, and those of F correspond to all the
pairs of the cells in the sensory and output layers in the same cortical column. The components
of Dout correspond to all the cells in the output layers of all considered cortical columns. Each
k,d
component of Din, Dloc, Dout, and F represents the connections between specified cells; for
c,d γ,d k,d
instance, if and only if a component of Din is 1, a connection exists between the cell in the
c,d
location layer represented by this component and the segment d of cell c. All the capabilities of
the Numenta model are realized by these connections.
Figure 3.2: Numenta cortical columns
(cid:63) (cid:63)
(cid:27) (cid:27) (cid:27) (cid:27)
(cid:45) (cid:45) (cid:45) (cid:45)
(cid:54) (cid:63) (cid:54) (cid:63) (cid:54) (cid:63)
(cid:45) (cid:45) (cid:45)
(cid:54) (cid:63) (cid:54) (cid:63) (cid:54) (cid:63)
(cid:45) (cid:45) (cid:45)
In §3.1 and §3.2, we consider learning and inference/recognition algorithms for objects. Fig-
ure 2.1 shows an example of such an object. This object O comprises ten pairs of (location,
feature). When a cortical column observes or recalls O, the location is specified by active cells
in the location layer, and the feature is specified by active cells in the sensory layer. Each
module in the location layer acts as a reference frame (or coordinate frame) of the locations
on the object under consideration. This is emphasized in [7] and [14]. According to [7] and
[14], the information flow in the model proposed by [14] is fundamentally sufficient for learning,
inferring, and recognizing any (simple) object. If an object is complex to be recognized by only
one cortical column, the connections ⃝6 between the output layers of the cortical columns assist
in recognizing this object. According to [1], each learning module can recognize objects, and
multiple learning modules can recognize more complex objects at a faster rate through voting
and a hierarchical structure.
Algorithm 3.1 is a learning algorithm and Algorithm 3.2 is an inference algorithm, based
on [9] and [14]. In the author’s opinion, some steps omitted in the algorithms of [9] and [14]
are added to Algorithms 3.1 and 3.2, and some steps are changed, mainly for simplicity. In
7
Algorithms 3.1 and 3.2, Aloc and Ain are binary vectors such that
t t
dimAloc = NlocMloc, dimAin = NinMin,
t t
and the components of Aloc and Ain correspond to the cells in the location and sensory layers
t t
of the considered cortical column at time t, respectively. If and only if a component of Aloc or
t
Ain is 1, the corresponding cell is active. In the following, Aloc and Ain are identified with the
t t t
sets of all cells in the location and sensory layers, respectively. When a location on an object is
observed, the feature f at this location provides a sensory input to the sensory layer, some mini-
columns in the sensory layer are selected, and some cells in these mini-columns are activated.
The set of such selected mini-columns is denoted by Win(f). Note that Win(f) is sparse, that
is, ♯Win(f) is significantly lower than Nin, where ♯S for a set S is the number of elements of
S. In [16], Win(f) is called the sparse distributed representation (SDR) of f. In Algorithms 3.1
and 3.2, Win(f) at time t is denoted by Win = Win(f).
t t
3.1 Learning
Algorithm 3.1 is a learning algorithm obtained by combining such algorithms of [9] and [14].
Algorithm 3.1 learns an object O by observing and sensing pairs (location, feature) on O indi-
vidually.
Algorithm 3.1 (Numenta learning algorithm)
This algorithm runs on each cortical column. In this algorithm, steps 6 to 12 are repeated
from the second round onwards. If πin = 0 for every c in (3.4), steps 11 and 12 are the same
c,t
as step 5. The positive constant θin in (3.4) is a threshold. The symbol “|” in (3.1), (3.2), and
b
(3.3) is designated as bitwise OR.
1. Set Din = 0 for every (c,d), Dloc = 0 for every (γ,d), Dout = 0 for every (k,d), and
c,d γ,d k,d
f = 0 for every (i,j,k).
ijk
2. For the object O, select a binary vector Aout of dimension Nout at random, that is, the
O
values of the components of Aout are determined at random. However, Aout must be
O O
sparse, that is, ♮Aout must be much less than dimAout. This Aout is fixed throughout
O O O
this algorithm. Denote by A out the NcNout dimensional vector obtained by concatenating
O
Aouts of all considered cortical columns.
O
The components of Aout correspond to all cells of the output layer. If and only if a
O
component of Aout is 1, the corresponding cell is active. In the following, Aout is identified
O O
with the set of all cells in the output layer.
3. For every active cell k ∈ Aout, select a dendritic segment d of k at random and set Dout =
O k,d
A out . Vector Dout is fixed throughout this algorithm.
O k,d
4. Set t = 0 and start observing O. From each module i in the location layer, randomly select
one cell and make it active. Thus, the initial value of the vector of Aloc is set.
t
The active cell in module i at time t represents a position vector ϕ⃗ in the reference frame
i,t
(cid:110) (cid:111)
given by module i. The set of vectors Φ := ϕ⃗ corresponds to the current observation
t i,t
location on O.
8
5. This step is stage ⃝3 in Figure 3.1. Sense the feature of O at the location in step 4. For the
sensory input from the feature, select a set of mini-columns Win of the sensory layer as
t
follows. Iftheinputhasbeenobservedinapreviouslearning, letWin bethemini-columns
t
selected then. If not, randomly select Win such that ♯Win ≪ Nin. Select one cell from
t t
each mini-column of Win at random and make this cell active. Thus, the initial value of
t
the vector of Ain is set.
t
6. Thisstepisstage⃝2. Foreveryactivecellcinthesensorylayer, selectadendriticsegment
d of c at random. It is fixed throughout this algorithm. For every such pair (c,d), update
Din by
c,d
(cid:12)
Din := Din (cid:12)Aloc . (3.1)
c,d c,d (cid:12) t
This is equation (9) of [14].
7. This step is stages ⃝5 and ⃝7 . For every active cell k ∈ Aout, randomly select some active
O
cells {c } in the sensory layer such that ♯{c } < ♯Win. Set γ = 1 and update f by
ij ij t ijk ijk
f := f |γ . (3.2)
ijk ijk ijk
8. Thisstepisstage⃝4. Foreveryactivecellγ inthelocationlayer,selectadendriticsegment
d of γ at random. It is fixed throughout this algorithm. For every such pair (γ,d), update
Dloc by
γ,d
Dloc := Dloc (cid:12) (cid:12)Ain . (3.3)
γ,d γ,d t
This is equation (8) of [14].
9. If the observation of O is finished, stop this algorithm. Otherwise, set t := t+1 and go to
the next step.
10. This step is stage ⃝1 . Change the observation location on O by motor input. This motor
input is represented by a vector ⃗δ in each module i of the location layer, and we obtain
i,t
(cid:110) (cid:111)
Φ = ϕ⃗ := ϕ⃗ +⃗δ ,
t i,t i,t−1 i,t
where the addition ϕ⃗ +⃗δ is considered on the torus made from the lattice of module
i,t−1 i,t
i. Make all cells in Φ active and the other cells inactive. Thus, Aloc is updated.
t t
The active cell in module i represents a position vector ϕ⃗ . The set Φ corresponds to the
i,t t
current observation location on O.
Notonlyavectorthatrepresentsamovementonanobject, suchastheredarrowinFigure
2.1, but also a vector in the location layer that represents a motor input, such as ⃗δ , is
i,t
also called a movement vector.
11. This step is stage ⃝2 . For every cell c in the sensory layer, calculate
(cid:40)
πin :=
1 ∃d : D
c
in
,d
•Al
t
oc ≥ θ
b
in
(3.4)
c,t
0 otherwise.
If and only if πin = 1, the cell c is predictive. If the current location is a location that has
c,t
not been visited before, then πin = 0 for almost all cells c.
c,t
9
12. This step is stage ⃝3 . Sense the feature of O at the location in step 10, get sensory input,
and select Win as in step 5. For every cell c = (ij) in the sensory layer (the j-th cell in
t
the i-th mini-column), calculate the activity of c:
 1 if i ∈ Win and πin = 1
 t ij,t

ain := ∗ if i ∈ Win and ∀k ∈ mini-column i,πin = 0
ij,t t ik,t


0 otherwise,
where ∗ = 1 for only one cell j that is randomly selected from the i-th mini-column and
∗ = 0 for the other every cell j. If and only if ain = 1, the cell c = (ij) is active. Thus,
ij,t
Ain is updated. Then, go back to step 6.
t
Remark 3.1 Compared with the learning algorithms in [9] and [14], Algorithm 3.1 is simpli-
fied as follows:
• In the learning algorithm of [9], the synaptic permanence values are used for Din, Dout,
c,d k,d
and f based on Hebbian-style adaptation (see (6), (7), and (8) in [9]). In contrast,
ijk
in the learning algorithm of [14], they are not used for Din and Dloc as shown in (3.1)
c,d γ,d
and (3.3), respectively. For simplicity, Algorithm 3.1 does not use synaptic permanence
values for Din, Dout, and f either. In particular, learning Dout is performed only once,
c,d k,d ijk k,d
at step 3. Note that, on page 5 in [9], the following is stated: “The output layer learns
representations corresponding to objects. When the network first encounters a new object,
a sparse set of cells in the output layer is selected to represent the new object. These cells
remain active while the system senses the object at different locations.” Based on this, we
maintain Aout fixed throughout learning.
O
• In [14], the activity in the location layer is considered for not a cell but a bump of cells,
and the structure of the reference frame and the lengths and angles of movement vectors
are precisely defined. In the present study, the activity is considered only for a cell and
movement vector ⃗δ is used for simplicity. The important ideas of the modules acting as
i,t
reference frames are explained in [7], [11], [13], and [14].
Remark 3.2 We make some remarks regarding Algorithm 3.1.
• The Numenta model can handle multimodal information through connections between
cortical columns via {Dout}. Connections {Dout} and {f } realize associative memory.
k,d k,d ijk
• For an object O, vector Aout is an SDR of O. Therefore, if O and O′ are different objects,
O
Ao
O
ut •Ao
O
u
′
t is expected to be approximately zero. Additionally, learning a new object is
expected not to result in catastrophic forgetting.
• In [9], ♮Aout in step 2 typically satisfies 40 ≤ ♮Aout ≪ dimAout = 4096. In [9] and [10],
O O O
♯Win in steps 5 and 12 and ♯{c } in step 7 are constants throughout learning, and their
t ij
typical values are 10 = ♯Win ≪ Nin = 150 and ♯{c } = 5 – 8. In the present study, the
t ij
values of ♮Aout, ♯Win, and ♯{c } are assumed to be equal for all objects, features, and
O t ij
times.
• In Algorithm 3.1, overlaps of the learned cells corresponding to different objects probably
exist because of random selections. In real learning, some noises that interfere with it
probably exist. See [9], [10], and [14] for the capacity for representing locations and
features, and noise robustness.
10
Figure 3.3: Learned connections between cells
totally connected
• • •• •
(cid:8)(cid:8)
(cid:74) (cid:10) (cid:8)
Aout in (cid:74) (cid:10) (cid:8)
O ······ (cid:8)
(cid:74) (cid:10) (cid:8)
output (cid:8)
(cid:74)(cid:10)(cid:8)
layer • =⇒ • • •
(cid:2) (cid:66)
(cid:2) (cid:66)
3 4
(cid:2) (cid:66)
(cid:2) (cid:66)
randomly selected (cid:2) (cid:66) ⇑ (cid:65)(cid:65) (cid:66)(cid:66) (cid:2)(cid:2) (cid:1)(cid:1) ⇓
(cid:2) (cid:66)
(cid:65) (cid:66) (cid:2) (cid:1)
(cid:2) (cid:66)
(cid:65) (cid:66) (cid:2) (cid:1)
(cid:2) (cid:66)
(cid:65)(cid:66) (cid:2)(cid:1)
(cid:2) (cid:66)
(cid:65)(cid:66) (cid:2)(cid:1)
(cid:2) (cid:66)
(cid:65)(cid:66) (cid:2)(cid:1)
(cid:2) (cid:66)
(cid:2) (cid:66) (cid:65)(cid:66)(cid:1)(cid:2)
Win in • • • • • • • • • •
t
sensory (cid:1)(cid:2)(cid:65)(cid:66)
(cid:1)(cid:2) (cid:66)(cid:65)
layer
(cid:1)(cid:2) (cid:66)(cid:65)
(cid:1)(cid:2) (cid:66)(cid:65)
2 5
(cid:1) (cid:2) (cid:66) (cid:65)
(cid:1) (cid:2)(cid:2) (cid:66)(cid:66) (cid:65)
totally connected
⇑ ⇓
totally connected
(cid:65) (cid:2)(cid:2) (cid:1) (cid:10)(cid:10)
(cid:65) (cid:2) (cid:1)(cid:10)
(cid:65) (cid:2)(cid:1)(cid:10)
(cid:65) (cid:2)(cid:1)(cid:10)
(cid:65) (cid:2)(cid:1)(cid:10)
location • • • • ⇐= • (cid:65) • (cid:2)(cid:1)(cid:10) • •
layer
1 6
An example of the connections between cells obtained using the learning algorithm 3.1 is
illustrated in Figure 3.3. The figures of two cortical columns in Figure 3.3 represent the same
cortical column: on the left, information flows upwards, whereas on the right, information flows
downwards. In 1 and 6 , the four rectangles represent the modules, and the four red points
represent the cells corresponding to a location. The five rectangles in 2 and 5 represent the
mini-columns in Win for the feature sensed at the location of 1 and 6 . The five red points
t
represent the cells selected from each mini-column in Win. For each cell in Aout, three cells were
t O
randomly selected from five active cells in Win. Algorithm 3.1 creates total connections between
t
all the cells representing the current location and all the cells representing the corresponding
feature. This algorithm also creates connections between all the cells in the output layer that
represent the same object. However, these connections are not required to be total connections
11
and probabilistic connections are also possible.
3.2 Inference, prediction and recognition
Algorithm 3.2 is an inference algorithm for objects learned by Algorithm 3.1. It is obtained
by combining such algorithms of [9] and [14]. Algorithm 3.2 makes inference by observing and
sensingpairs(location, feature)onanobjectO individually, inthesamemannerasinAlgorithm
3.1. (In§2.2of[1],itisstatedthat“thereisnocleardistinctionbetweenlearningandinference.”)
Let Aout be an Nout-dimensional binary vector such that the components of Aout correspond to
t t
the cells of the output layer at time t. If and only if a component of Aout is 1, the corresponding
t
cell is active. In the following, Aout is identified as the set of all cells in the output layer. The
t
NcNout-dimensional vector obtained by concatenating Aouts of all considered cortical columns
t
out
is denoted by A .
t
Algorithm 3.2 (Numenta inference algorithm)
O is an object learned by Algorithm 3.1. It is assumed that this object is observed in this
algorithm. This algorithm runs on each cortical column. The positive constants θout, θout, θin,
p b p
θin, and θloc are thresholds. In this algorithm, steps 8 to 15 are repeated from the second round
b
onwards.
1. Set t = 0, Aloc = 0, Ain = 0, Aout = 0, and A out = 0.
t t t t
2. This step is stage ⃝1 in Figure 3.1. Select a location on O at random. However, it is
unknown which of the learned locations this location is.
3. This step is stage ⃝3 . Obtain Win from the sensory input at the location of step 2. For
t
every cell c = (ij) in the sensory layer (the j-th cell in the i-th mini-column), calculate
the activity of c:
(cid:40)
1 if i ∈ Win
ain := t
ij,t
0 otherwise.
4. This step is stage ⃝5 . For every cell k in the output layer, calculate
 (cid:88)
1 if f ·ain ≥ θout
 ijk ij,t p
aout := (3.5)
k,t i,j
 0 otherwise.
(cid:16) (cid:17)
Thus, Aout = aout and the concatenated vector A out are obtained. Set
t k,t t
Wout := (cid:8) k : aout = 1 (cid:9) . (3.6)
t k,t
5. This step is stage ⃝6 . For every cell k in the output layer, calculate
ρout :=
(cid:40) 1 ∃d : A o
t
ut •D
k
ou
d
t ≥ θ
b
out
(3.7)
k,t
0 otherwise
and
(cid:26) 1 if k ∈ Wout and ρout = 1
aout := t k,t
k,t 0 otherwise.
Thus, Aout and A out are updated.
t t
12
6. This step is stage ⃝7 . For every cell c = (ij) in the sensory layer, calculate
 (cid:88)
 1 if f ijk ·ao k u ,t t ≥ θ p in
ϖin := (3.8)
ij,t k
 0 otherwise,
and update the activity of c:
(cid:40)
1 if ain = 1 and ϖin = 1
ain := ij,t ij,t (3.9)
ij,t
0 otherwise.
7. This step is stage ⃝4 . For every cell γ in the location layer, calculate
(cid:40)
πloc :=
1 ∃d : D
γ
lo
,
c
d
•Ai
t
n ≥ θloc
(3.10)
γ,t
0 otherwise,
(cid:16) (cid:17)
where Ain := ain . Let ϕ⃗ be the location vector of the h-th cell in the module i, and
t ij,t ih,t
set
 (cid:110) (cid:111)
 ϕ⃗ ih,t : γ = (ih) satisfies π γ lo , c t = 1 if ∃γ = (ih) : π γ lo , c t = 1
Φsense :=
i,t
 ∅ otherwise.
Note that the elements of Φsense may indicate not only the true location on O but also
i,t
other locations on O or locations on objects other than O. For example, in Figure 2.3 (A),
if the true location is the end point of the red vector, then this location and the locations
of the all end points of the blue vectors in O, O′, and O′′ are indicated by Φsense.
i,t
8. Set t := t+1.
9. This step is stage ⃝1 . Virtually or really, change the observation location on O by (imag-
inary) motor input (see Remark 3.4). This motor input is represented by a movement
vector ⃗δ in each module i of the location layer, and we obtain
i,t
(cid:110) (cid:111)
Φmove := ϕ⃗ := ϕ⃗ +⃗δ : ϕ⃗ ∈ Φsense , (3.11)
i,t t t−1 i,t t−1 i,t−1
where ϕ⃗ +⃗δ is considered on the torus made from the lattice of module i. Make all
i,t
cells corresponding to the elements of Φmove active and the other cells inactive. Thus,
i,t
Aloc := Aloc is updated.
t,move t
10. This step is stage ⃝2 . For every cell c in the sensory layer, calculate
(cid:40)
πin :=
1 ∃d : D
c
in
,d
•Al
t
o
,m
c
ove
≥ θ
b
in
(3.12)
c,t
0 otherwise.
Cell c is predictive if and only if πin = 1.
c,t
11. This step is stage ⃝3 . Move to a new observation location on O by the movement vector
⃗δ in step 9. Then, obtain Win from the sensory input at this location. For every cell
i,t t
c = (ij) in the sensory layer, calculate the activity of c:
 1 if i ∈ Win and πin = 1
 t ij,t

ain := 1 if i ∈ Win and ∀ cell k ∈ mini-column i,πin = 0 (3.13)
ij,t t ik,t


0 otherwise.
Thus, Ain is updated.
t
13
12. This step is stage ⃝5 . For every cell k in the output layer, calculate (3.5). Thus, Aout and
t
A out are updated. Set Wout using (3.6).
t t
13. This step is stage ⃝6 . For every cell k in the output layer, calculate (3.7) and the activity
of k:
(cid:26) 1 if k ∈ Wout and ρout = ρout = 1
aout := t k,t−1 k,t (3.14)
k,t 0 otherwise.
Thus, Aout and A out are updated.
t t
Stop this algorithm and we say that O is recognized, if only the object O is active in the
sense of Definition 3.1 described below. Otherwise, go to the next step.
14. This step is stage ⃝7 . For every cell c = (ij) in the sensory layer, calculate (3.8) and (3.9).
Thus, Ain is updated.
t
15. This step is stage ⃝4 . For each cell γ = (ih) in the location layer, calculate (3.10), and set
 (cid:110) (cid:111)
 ϕ⃗ ih,t : γ = (ih) satisfies π γ lo , c t = 1 if ∃γ = (ih) : π γ lo , c t = 1
Φsense := (3.15)
i,t
 Φmove otherwise.
i,t
Then, go to step 8.
Remark 3.3 Compared with the inference algorithms in [9] and [14], Algorithm 3.2 has the
following changes:
• The condition ρout = 1 in (3.14) is added by the author. In [9], the feedback stage ⃝7 ,
k,t
that is, the operation in steps 6 and 14, is optional and definite formulae are omitted. In
the present study, as such formulae, (3.8) and (3.9) are added as matches to (3.12) and
(3.13), respectively. Condition ρout = ρout = 1 and the feedback stage ⃝7 result in the
k,t−1 k,t
voting system described in §3.3.
• In Algorithm 3.2, as in Algorithm 3.1, cells are used instead of bumps to represent the
activity in the location layer, which differs from the algorithm in [14].
Remark 3.4 As policies for selecting motor inputs in step 9, the paper [1] lists model-based
policies and model-free policies (see “action policy” in §3.4 and §11 in [1]). Model-based policies
enable principled movement, such as moving a sensor to a location that will minimize the
uncertainty of the currently observed object. In other words, the prediction can drive movement
(cf. §1.7 of [21]). One must be able to compare the likelihoods of candidates for the observed
object to achieve this minimization. The more candidates there exist, the costlier it becomes.
However, avoiding this remains unclear to the author. Model-free policies are useful for purely
sensory-based actions such as focusing on a prominent feature.
Algorithm 3.2 can be considered as a Bayesian (or non-Bayesian) updating process, where
object O is the unknown parameter. The conditional probability is denoted by P(·|·), a sensory
input by S , and a location on O at time t by L (O). As events, S implies “the sensory input
t t t
is S ” and L (O) implies “the observation location is L (O).” Then, roughly speaking, the
t t t
correspondences between the steps in Algorithm 3.2 and probabilities calculated at each step
are considered as summarized in Table 3.1. These probabilities are based on the generative
model that the cortical columns have, and P(L (O)|S ) essentially depends on the selection
t+1 t
mechanism of the motor input as described in Remark 3.4. The details of Table 3.1, including
the case of a non-Bayesian model, will be explained in §5.
14
Table 3.1: Correspondences between steps in Algorithm 3.2 and probabilities
steps 10, 11 steps 12 – 15 step 9
P(S |L (O)) P(L (O)|S ) P(L (O)|S )
t t t t t+1 t
likelihood posterior prior
3.3 Activity and selection of an object
Onpage6of[9], itisstatedthat“The set of active cells in the output layer represents the objects
that are recognized by the network. During inference we say that the network unambiguously
recognizes an object when the representation of the output layer overlaps significantly with the
representation for correct object and not for any other object.” Based on this concept, we define
the following (see step 8 of Algorithm 3.2).
Definition 3.1 Let θout and θ out be real numbers (thresholds) such that θout > 0 and 0 <
o o o
out
θ < 1. Object O is active in cortical column C (more precisely, in the output layer of cortical
o
column C) at time t if
♯ (cid:0)(cid:8) k : k = 1 in Aout(cid:9) ∩ (cid:8) k : aout = 1 in (3.14) (cid:9)(cid:1)
O k,t
≡ ♯ (cid:0)(cid:8) k : k = 1 in Aout(cid:9) ∩ (cid:8) k : aout = 1 in (3.6) (cid:9) ∩ (cid:8) k : ρout = ρout = 1 (cid:9)(cid:1) ≥ θout
O k,t k,t−1 k,t o
is satisfied in C. Furthermore, object O is active in the considered cortical columns at time t if
♯{cortical column C : O is active in C at time t} ≥ θ out Nc
o
is satisfied.
If Algorithm 3.2 results in only one active object, O, then O is unambiguously recognized. In
Algorithm3.2, theflow ofinformation between differentcortical columnsis realized by(3.7) and
(3.14). The other information flows remain in each cortical column. Condition ρout = ρout = 1
k,t−1 k,t
causes and accelerates convergence of recognition, that is, convergence onto a representation for
object O. This system is a voting system among the cortical columns such that it combines the
sensory inputs received by the cortical columns into a single perception (see [11], [7], and [1]).
Throughout the duration of Algorithms 4.1 and 4.2, a specific object must be continuously
recognized. Additionally, in these algorithms, an object must be selected (randomly) from
multiple active objects. How should these processes be implemented ? The author considers
the following as one of the mechanisms for such an implementation: Let C ,C ,...,C be the
1 2 I
cortical columns that store the considered objects O := {O ,O ,...,O }. Each object is stored
1 2 J
inoneormorecorticalcolumns. LetC beanothercorticalcolumnwiththefollowingproperties:
• Let M ,...,M be the modules of the location layer of C. Each object is represented by
1 m
a set of cells {c ,...,c } such that c is selected from M as follows:
1 m j j
– For the object that is first recorded in C, cell c is randomly selected from M .
j j
– Cell c′ for the second and subsequent object recorded in M is obtained by
j j
−−→
c c′ =⃗v,
j j
where c represents a recorded object O ∈ O and⃗v is a movement vector. The object
j
O and the vector v are common to M , ..., M .
1 m
15
Connections exist between the cells representing an object O ∈ O in the output layers of
C ,...,C and the cells {c ,...,c } representing O in the location layer of C. Thus, the
1 I 1 m
set of cells {c ,...,c } acts as a pointer to the cells representing O in the output layers
1 m
of C , ..., C . For instance, as shown in Figures 4 and 5 in [1], C , ..., C and C form a
1 I 1 I
hierarchical structure, and C belongs to the layer one level above C , ..., C .
1 I
• A movement vector in the location layer of C represents a movement from one object to
another.
• The cells representing an object O ∈ O in the location layer of C are connected to some
cells in the sensory layer of C. These cells represent the features of O.
• The output layer of C is optional.
We consider the following selection method for an object or objects from objects O ,...,O in
1 J
C. Only the selected object(s) in C ,...,C and C are activated.
1 I
(S1) One of the cells representing objects stored in a module of the location layer of C is
randomly activated. If the activated cell c is one of the cells representing object O, then
the cells in the output layers of C ,...,C connected to c (the cells representing O) are also
1 I
activated, and the cells representing O in the location layer of C are activated. In this
way, one object is randomly selected.
(S2) AmovementvectorinthelocationlayerofC startingfromobjectO selectedin(S1)results
in the selection of another object.
(S3) To select objects with desired features F, first the cells representing F in the sensory layer
of C are activated. Then, the objects in the location layer of C that are connected to these
cells are activated.
Furthermore, if a specific object O must be continuously recognized in C ,...,C , it is realized
1 I
byactivatingOinC continuously. EachobjectOstoredinC canbeconsideredasanabstraction
of the object stored in C ,...,C . For instance, it may be assumed that C is storing a language
1 I
and O is the name of the object.
In (S1), initially only one cell is activated. This process is not robust to noise; however, if
more than one cell is randomly selected, a high probability that more than one object will be
selected exists.
3.4 Values of thresholds
We assume that relationships between the values of thresholds θout, θout, θout, θin, and θloc in
p b o b
Algorithm 3.2 and the constants ♯{c }, ♮Aout, and Nloc are as follows (cf. Remark 3.2), where
ij O
the values in ( ) are used in [9] and/or [14]:
• θout(= 3) ≤ c¯:= ♯{c } (= 5–8),
p ij
• θout(= 18) ≤ θout(= 30 ≤ 40) ≤ ♮A out ,
b o O
• θin(= 6–8) ≤ Nloc(= 10),
b
• θloc(= 8) ≤ c¯.
16
Note that θloc is only used in [14] and c¯is only used in [9]. In [9], some permanence values used
duringlearning, andin[14], bumpsareusedtorepresentactivityinthelocationlayer. Although
these are not used in the present study, the values listed above are also consistent in this study.
Thresholds θ out in Definition 3.1 and θin in Algorithm 3.2 are not used in [9] and [14]. The value
o p
out
of θ should not be excessively small because when some overlap exists between the SDR of
o
the observed object O and that of another object O′, this O′ may also be active. The value of
θin is as follows. We set w := ♯Win and a := ♮Aout. For any cell c in the sensory layer, define
p t O ij
a random variable X as the number of cells in the output layer such that they are connected
ij
to c by Algorithm 3.1. If the connections are generated independently of each other, then the
ij
probability of X ≥ θin is independent of (ij) and is given by
ij p
P
(cid:0)
X ≥
θin(cid:1)
=
(cid:88) a (cid:18) a (cid:19) (cid:16)c¯(cid:17)r(cid:16)
1−
c¯(cid:17)a−r
.
ij p r w w
r=θin
p
Then,acriterionforselectingthevalueofθinisthatP (cid:0) X ≥ θin(cid:1) ≥ pforthedesiredprobability
p ij p
p.
4 Finding similar objects
The set of learned and considered objects is denoted by Ω. In this section, two algorithms are
proposedtofindobjectsinΩsimilartoagivenobjectO ∈ Ω,basedonAlgorithm3.2. Although
the setting for the proposed algorithms is restricted, the author believes that the case it covers
is fundamental. Each object comprises a set of (location, feature) pairs as described in §2.
Therefore, O and O′ are similar if and only if the (location, feature) pairs on O and O′ are
similar.
Each sensory feature f corresponds to the SDR Win = Win(f) in the sensory layer. Let F
t
be the set of all SDRs in the sensory layer. We introduce a distance function D on F such that
D(Win(f),Win(g)) is small if and only if features f and g are similar. For instance, colors with
similar wavelengths, such as blue and purple, are often considered as similar features. Then,
we assume that the brain knows that these are similar, that is, D(Win(blue),Win(purple)) is
small. Note that distance D does not necessarily represent the physical distance on the sensory
layer. Let d be a nonnegative number, and for W ∈ F, define a neighborhood N (W) by
d
N (W) := (cid:8) W′ ∈ F : D(W,W′) ≤ d (cid:9) . (4.1)
d
If d = 0, then N (W) = {W}. We consider N (W) as a set of SDRs similar to W.
d d
Algorithms4.1and4.2tofindsimilarobjectsarebasedonAlgorithm3.2. Theauthorbelieves
thatitwouldbepreferabletomakeasfewchangesaspossiblefromAlgorithm3.2. InAlgorithm
4.1, the only essential change is the replacement of Win with N (Win), and several additional
t d t
changes exist in Algorithm 4.2. If d = 0, Algorithm 4.1 is essentially the same as Algorithm 3.2.
Algorithms 4.1 and 4.2 stop at a specified time. Algorithm 3.2 can also find objects similar to
the observed object O, provided that it stops before converging on the representation of O. Let
C ,...,C , and C be the cortical columns described in §3.3, and let O and O′ be objects stored
1 I
inC ,...,C .ThesimilarityrelationshipbetweenO andO′ obtainedbythesealgorithmscanbe
1 I
recorded as the positional relationship between O and O′ in the location layer of C by arranging
or rearranging similar objects close together. This is learning the “similarity” between objects.
17
Algorithm 4.1 (Finding objects in Ω similar to the given object O)
T is a nonnegative integer and d is a nonnegative real number. Using Algorithm 3.2, the
object O has been recognized in the considered cortical columns. It is assumed that O can
always be referred to (see §3.3), and all the real movement vectors and observation locations are
on O.
1. Set t = 0, Aloc = 0, Ain = 0, Aout = Aout, and A out = A out because O has been already
t t t O t O
recognized.
2. Select a location on O at random. Then, this location is recognized.
3. This step is the same as step 3 of Algorithm 3.2, except Win is replaced with N (Win).
t d t
4 – 10. These steps are the same as steps 4 to 10 of Algorithm 3.2.
11. This step is the same as step 11 of Algorithm 3.2, except Win is replaced with N (Win).
t d t
12. This step is the same as step 12 of Algorithm 3.2.
13. For every cell k in the output layer, calculate (3.7) and (3.14). Thus, Aout and A out are
t t
updated.
If t = T, stop this algorithm. Otherwise, go to the next step.
When this algorithm stopped, randomly select an object O′ ∈ Ω such that it is active in
the sense of Definition 3.1 as an object similar to O (see §3.3). The end time T may be
determined dynamically. For example, when the number of active objects in the output
layer falls below a certain number, we set t := T.
14, 15. These steps are the same as steps 14 and 15 of Algorithm 3.2.
Algorithm 4.1 uses all the mechanisms for convergence onto the representation of object(s)
in Algorithm 3.2, that is, the mechanisms of the algorithms in [9] and [14]. Therefore, the
convergence property of Algorithm 4.1 is essentially the same as that of Algorithm 3.2.
Accordingto[2], itisnotpossibleforthebraintorecognizemultipleobjects, simultaneously.
Therefore, if the brain executes Algorithm 4.1, most of it (particularly the selection in step 13)
would be executed unconsciously.
Figure 4.1: Example of objects (they are the same objects as in Figure 2.2)
⋆ ⋆ •
⋆ (cid:50) (cid:50) ⋆ ⋆ ◦ ◦ ⋆ • ◦ (cid:50) •
(cid:50) ◦ ◦ ◦ (cid:50) (cid:50) (cid:50) ◦ (cid:50)
⋆ ◦ E′ (cid:50) • ◦
O O′ O′′
Inthefollowing,abrokenlineconnectingthelocationsthroughwhichmovementvectorspass
is called a path. The starting point of a path is the starting point of the first movement vector,
18
whereas the end point of a path is the end point of the last movement vector. In Algorithm
4.1, once an object becomes inactive, it cannot become active again. Assume that, in Figure
4.1, features ◦ and (cid:50) are similar. If the path is as shown in Figure 4.2 (A), O′ is active and
O′′ is inactive from the third step onwards. Next, assume that in Figure 4.1, features ◦ and (cid:50)
are similar, and features ⋆ and • are similar. If the path is as shown in Figure 4.2 (B), O′′ is
active and O′ is inactive from the third step onwards, because all corresponding paths on O′ are
inactive (i.e., the third step locations of these paths do not exist or are inactive). One of the
reasons of this inactivity is that no location labeled E′ exists on O′.
As shown in the examples above, two cases exist in which an object becomes inactive:
(NL) No location exists on the object corresponding to the current location on O.
(NF) Although corresponding locations exist, the features on none of these locations are similar
to the feature on the location on O.
If the above inactivities are not acceptable, we can execute Algorithm 4.2, which is obtained by
modifying Algorithm 4.1. In this algorithm, if necessary, values of ρouts and aouts are reset by
k,t k,t
(4.2) and an additional process is performed in step 15. Therefore, in either case (NL) or (NF),
the location information of the object is not lost, and the object continues to be observed in the
next round.
Algorithm 4.2 (Finding objects in Ω similar to the given object O)
T is a nonnegative integer and d is a nonnegative real number. Using Algorithm 3.2, the
object O has been recognized in the considered cortical columns. It is assumed that O can
always be referred to, and all the real movement vectors and observation locations are on O. For
O′ ∈ Ω,α (O′)denotesabinaryvariablerepresentingtheactivityofO′ inthesenseofDefinition
t
3.1 at time t, 1 ≤ t ≤ T. Γ is a positive integer such that Γ ≤ T.
1, 2, 3. These steps are the same as steps 1, 2, and 3 of Algorithm 4.1.
4. This step is the same as step 4 of Algorithm 4.1. Set γ (O′) := 0 for every active O′ ∈ Ω.
0
5 – 12. These steps are the same as steps 5 to 12 of Algorithm 4.1.
13. For every cell k in the output layer, calculate (3.7) and (3.14). Thus, Aout and A out are
t t
updated. For every O′ that is active at time t−1
• set α (O′) := 1 if O′ is active, and set α (O′) := 0 if O′ becomes inactive,
t t
• calculate
γ (O′) := γ (O′)+ (cid:0) 1−α (O′) (cid:1) .
t t−1 t
If α (O′) = 0, γ (O′) < Γ, and O′ should be made active again, reset the activity of the
t t
out
cells in A of each cortical column by resetting
O′
ρout := ρout and aout := aout (4.2)
k,t k,t−1 k,t k,t−1
for every cell k in A out . Thus, Aout and A out are updated.
O′ t t
If t = T, stop this algorithm. Otherwise, go to the next step.
When this algorithm stopped, randomly select an active object O′ as an object similar to
O (see §3.3). The end time T may be determined dynamically.
19
14. This step is the same as step 14 of Algorithm 4.1.
15. If there exists no O′ reactivated in step 13, this step is the same as step 15 of Algorithm
4.1.
If there exists such an O′, add the end point of every current path on every such O′ that
satisfies (NF) or (NL) to Φsense in each cortical column. In case (NL), the set Φsense
i,t i,t
contains such end points as virtual position vectors.
Then, go to step 8.
Remark 4.1 Algorithm 4.2 considers both (NF) and (NL); however, it could also consider
just one or the other. For instance, to consider only (NF), Algorithm 4.2 is changed as follows:
• In step 13, reset the activity using (4.2) only if there exists a path on O′ such that it
satisfies (NF). Therefore, if no path on O′ satisfies (NF), O′ is not reactivated.
• In step 15, perform processing only for (NF).
Remark 4.2 In the (NF) case, step 15 is implemented by rewriting step 14 as follows:
14’ Thisstepisthesameasstep14ofAlgorithm4.1,exceptthatforeveryobjectO′reactivated
in step 13, change (3.9) to
(cid:40)
1 if πin = 1 and ϖin = 1
ain := ij,t ij,t
ij,t
0 otherwise.
Then, in step 15, the end point of every current path on O′ that satisfies (NF) is automatically
added to Φsense. In the (NL) case, implementing step 15 would require a mechanism for infor-
i,t
mation to pass directly from the output layer to the location layer. This requires making the
model shown in Figure 3.1 more complicated. It is unclear to the author whether Algorithm 4.2
can be rewritten to avoid this complication.
In step 13, α (O′) = 0 implies that
t
♯ (cid:0)(cid:8) k : k = 1 in Aout(cid:9) ∩ (cid:8) k : ρout = 1 (cid:9)(cid:1) ≥ θout
O′ k,t−1 o
holds for θ out Nc or more cortical columns and
o
♯ (cid:0)(cid:8) k : k = 1 in Aout(cid:9) ∩ (cid:8) k : ρout = 1 (cid:9)
O′ k,t−1
∩ (cid:8) k : ρout = 1 (cid:9) ∩ (cid:8) k : aout = 1 in (3.6) (cid:9)(cid:1) < θout
k,t k,t o
(cid:16) (cid:17)
holds for 1−θ out Nc or more cortical columns.
o
We now provide some examples of how Algorithm 4.2 runs. Assume that Ω = {O,O′,O′′}
as shown in Figure 4.1 and features ◦ and (cid:50) are similar. As mentioned above, if the path is as
shown in Figure 4.2 (B) and Algorithm 4.1 is used, two paths on O′ are active at the end of
the second movement vector and both paths become inactive at the end of the third movement
vector. One of the end points is location E′. Suppose O′ is to be reactivated. Then, O′ becomes
active again by (4.2) and end point E′ on one of the two paths above is recorded as the virtual
end point of a vector in Φsense (t = 3) by step 15. In this step, the third and fourth movement
i,t
vectors in Figure 4.2 (B) on O, that is, the movement vectors in Figure 4.2 (C), are translated
20
to a movement vector on O′ as in Figure 4.2 (D). One of the two locations at time t+1 = 4 is
the end point of this movement vector.
Algorithm 4.2 for Γ = 1 is nothing but Algorithm 4.1. As well as O′, suppose O′′ should also
be reactivated if it becomes inactive. Assume that features ◦ and (cid:50) are similar. If T = 5, Γ = 3,
and the path is as shown in Figure 4.2 (B), then γ (O′) = 1 < Γ, γ (O′′) = 2 < Γ. Therefore,
T T
both O′ and O′′ are active at time T, and one of them is selected as an object similar to O. If the
value of Γ is changed to 2, then O′ is active and O′′ is inactive at time T; thus, O′ is selected.
Figure 4.2: Example of movement vectors
(A) (B)
⋆ ⋆
⋆ (cid:50) (cid:50) ⋆ ⋆ (cid:50) (cid:50) ⋆
(cid:1)(cid:21) (cid:54) (cid:0)(cid:54)
(cid:63) (cid:1) (cid:0)(cid:9)
(cid:50) ◦ ◦(cid:63) (cid:50) ◦ ◦
(cid:1) (cid:54)
(cid:64) (cid:0)
(cid:1)
⋆ (cid:64)(cid:82)◦ ⋆(cid:0)(cid:9) ◦
O O
(C) (D)
⋆ ⋆
⋆ (cid:50) (cid:50) ⋆ ⋆ ◦ ◦ ⋆
(cid:50) ◦ ◦ ◦ (cid:27) (cid:50) (cid:50)
(cid:54)
(cid:0)
⋆(cid:0)(cid:9) ◦ E′ (cid:50)
O O′
For location L, the neighborhood N (L) in the location layer can be considered in the same
d
manner as in (4.1), where d is a value of a distance function (cf. §9.10 of [1]). In this case, the
“corresponding location” in (NL) and (NF) can be considered to be the “location L′ nearest to
the corresponding (virtual) location L with L′ ∈ N (L),” and similarly for Algorithms 4.1 and
d
4.2.
For some simple cases, numerical experiments were conducted to obtain the probability of
an object being active at the end of Algorithm 4.2. It was assumed that no noise existed when
Algorithm 4.2 was executed. We considered a pair of observed object O and another object
O′ ∈ Ω. In the experiments, 1000 randomly generated pairs of (O,O′) were used for each of the
cases of T = 3,4,5 and Γ = 1,2. The experimental settings were as follows:
• Both objects O and O′ comprise 5×5 grid locations.
• The number of types of groups of similar features is 5. These five types of features are
uniformly randomly placed in 25 locations on each of objects O and O′.
• Let p be a path connecting T movement vectors on O such that each path p for T = 3,4,5
is as depicted in Figure 4.3. These paths are used in the experiment.
21
• O′ should be reactivated if it becomes inactive. However, only movement vectors whose
end points remain inside O′ are considered for simplicity. Therefore, the operation for case
(NL) is not be executed. (See Remark 4.1.)
Let N(p) be the number of paths with the same shape as p on O′. Then, for T = 3,4, and
5, the values of N(p) are 40, 20, and 16, respectively. The results of experiments by using a
Java program are as summarized in Table 4.1. In this program, the Mersenne Twister random
number generator MTRandom.java was used (see [17]). The “probability” in this table refers
to the probability (percent) that O′ is active at the end of Algorithm 4.2.
Figure 4.3: Paths connecting movement vectors
(cid:54)
(cid:45) (cid:45) (cid:45) (cid:45) (cid:45) (cid:45) (cid:45) (cid:45) (cid:45) (cid:45) (cid:45)
T = 3 T = 4 T = 5
Table 4.1: Probability (percent) that O′ is active at the end of Algorithm 4.2
Γ Γ = 1 Γ = 2
T T = 3 T = 4 T = 5 T = 3 T = 4 T = 5
probability (%) 7.0 0.4 0.1 59.6 10.2 1.6
Figure 4.4: Example of movement vectors
(A) (B) (C)
⋆ ⋆ ⋆
(cid:54)
(cid:27)
⋆ (cid:50) (cid:50) ⋆(cid:54) ⋆ ◦ ◦ (cid:45)⋆ ⋆ ◦ ◦ ⋆
(cid:54)
(cid:50)(cid:63) ◦ ◦ ◦ (cid:50) (cid:50) ◦ (cid:50) (cid:50)
(cid:0)(cid:18) (cid:0)
⋆(cid:63) (cid:45)◦ (cid:0) E′ (cid:50) E′ (cid:50)(cid:0)
O O′ O′
Remark 4.3 We provide some supplementary explanations for Algorithms 4.1 and 4.2.
• Assumethatfeatures◦and(cid:50)aresimilar, Γ = 2,T = 5,andthepathisasshowninFigure
4.4 (A). Suppose O′ should be reactivated if it becomes inactive. The three red paths in
Figure 4.4 (B) are active at t = 2 and no active paths exist at t = T. In the red path
in Figure 4.4 (C), there exists only one location such that it corresponds to either (NL)
22
or (NF). This path appears to be active even at t = T when Γ = 2. However, although
the paths in Figure 4.4 (B) are active even at the second step, the path in Figure 4.4
(C) becomes inactive at the second step. Therefore, the path in Figure 4.4 (C) remains
inactive after the second step. We can rewrite Algorithm 4.2 to avoid this; however, as it
would be complicated, we do not proceed it.
• InAlgorithms4.1and4.2, anyobjectthatwasnotactivatedinstep4willnotbeactivated
thereafter. If it is a problem, we may rerun Algorithms 4.1 and 4.2. It is easy if T is a
small value.
5 Surprise and active inference
AccordingtoFriston’sfree-energyprinciple,activeinferencecausedbysurpriseisconsidered(see
[4], [5], and [18]). The surprise of sensory input S is defined by −logP(S ), the negative log
t t
evidence of S . Thus, the smaller P(S ) is, the larger the surprise. In the present study, surprise
t t
also refers to sensory input that is (mostly) not predicted. Thus, if in step 11 of Algorithm
3.2, most of mini-columns in Win satisfy the second condition of (3.13), then we consider that
t
S causing such a set Win is a surprise. As an active inference for surprise, we consider the
t t
following two essentially identical types:
(I) Updating the prior to take the sensory input obtained at time t as the predicted sensory
input at time t+1. An example of this active inference is when someone attempts to pour
coffee into a cup from a pot but pours water instead, and then updates her/his knowledge
about the contents of the pot.
(II) Action at time t+1 to grasp the sensory input obtained at time t as the predicted sensory
inputattimet+1.Anexampleofthisactiveinferenceiswhensomeoneseessomethingout
of the corners of her/his eyes that is not predicted and turns her/his eyes in that direction.
We propose Algorithm 5.1 as an algorithm such that it is a changed version of Algorithm 3.2
to actively infer in both cases (I) and (II). Condition ρout = 1 in (3.14) interferes with this
k,t−1
active inference. Therefore, in Algorithm 5.1, the value of ρout is set to 1 in (5.3) for the case
k,t−1
where (5.2) is satisfied.
Algorithm 5.1 (Active inference for surprise)
The constants θ , θ′ , and θ′′ are thresholds such that 0 < θ < 1, θ′ > 0, and 0 < θ′′ < 1,
w w w w w w
where θ is close to 1.
w
1 – 10. These steps are the same as steps 1 to 10 of Algorithm 3.2.
11. This step is the same as step 11 of Algorithm 3.2, except at the end of this step, check
whether
♯ (cid:8) i ∈ Win : ∀k ∈ mini-column i,πin = 0 (cid:9) ≥ θ ·♯Win ≥ θ′ (5.1)
t i,k,t w t w
or not.
12. This step is the same as step 12 of Algorithm 3.2.
13. Check whether
(The number of cortical columns that satisfy (5.1)) ≥ θ′′Nc, (5.2)
w
and perform the following.
23
The case where (5.2) is not satisfied.
13, 14, 15. These steps are the same as steps 13, 14, and 15 of Algorithm 3.2.
The case where (5.2) is satisfied.
13. For every cell k ∈ Wout in (3.6), set
t
ρout = 1. (5.3)
k,t−1
For every cell k in the output layer, calculate (3.7) and (3.14). Thus, Aout and A out are
t t
updated.
If there exist no active objects, stop this algorithm. Then, this inference is a failure.
14. This step is the same as step 14 of Algorithm 3.2.
15. Calculate Φsense by (3.15).
i,t
Because (5.2) is satisfied, probably this Φsense is very different from Φmove.
i,t i,t
Then, go to step 8 described below.
8. Set t := t+1.
9. Let the vector ⃗δ in (3.11) be ⃗δ = 0. Then, the obtained locations correspond to the
i,t i,t
sensory input Win .
t−1
10. This step is the same as step 10 of Algorithm 3.2.
Then, go to step 11 described above.
Remark 5.1 We provide some supplementary explanations for Algorithm 5.1.
• If condition (5.2) does not hold, then Algorithm 5.1 is the same as Algorithm 3.2. In this
case, although the activity in the second line of (3.13) may be reflected in (3.6), its effect
will usually disappear in (3.14).
• In step 9, by setting ⃗δ = 0, the active inference mapping Φmove → Φmove is realized.
i,t i,t−1 i,t
Because the selection of ⃗δ takes no time, this process is assumed to be instantaneous.
i,t
Remark 5.2 Let the current time be t. The setting of the value of ρout in (5.3) contrasts
k,t−1
with that of the value of ρout in (4.2). In (5.3) the value of ρout is reset, whereas in (4.2) the
k,t k,t−1
value of ρout is reused. The set Φmove = Φsense induced by the reset (5.3) causes a rewriting of
k,t−1 i,t+1 i,t
L (O) in Definition 5.1 below. In this case, the prior probability obtained from the information
t
prior to time t is lost, and only the second term in (5.6) remains.
In the following, we consider Algorithm 5.1 from a non-Bayesian (modified Bayesian) inference
perspective. The Bayesian updating process is defined as follows:
P(s |θ)P (θ|s )
t t−1 t−1
P (θ|s ) = (t = 1,2,...),
t t (cid:80)
P(s |θ)P (θ|s )
θ t t−1 t−1
24
where θ is the considered parameter, (s ,s ,...) are the given data, P(·|·) is the conditional
1 2
probability, and P (θ|s ) := P(θ). Thus, P (θ|s ) is the posterior to θ at time t−1 and the
0 0 t−1 t−1
prior of θ at time t. In [12], the author considered the following non-Bayesian updating process:
P(s |θ)P (θ|s ) P(s |θ)
t t−1 t−1 t
P (θ|s ) = (1−γ ) +γ (t = 1,2,...), (5.4)
t t t (cid:80) t(cid:80)
P(s |θ)P (θ|s ) P(s |θ)
θ t t−1 t−1 θ t
where0 ≤ γ < 1.In[12],thisupdatingruleisinterpretedasanoverreactingtotheobservations.
t
The second term on the right-hand side of (5.4) can be nonzero even if the prior P (θ|s ) is
t−1 t−1
zero. Thus, this term may be valid even if s is not predicted, that is, P(s |θ) = 0. From
t−1 t−1
this perspective, we consider the non-Bayesian formulation of Algorithm 5.1 as follows.
Let L (O) and S be as defined in §3.2, and Ω be as defined in §4. Even if the brain is
t t
conscious of the movement vector, we consider L (O) to be probabilistically determined. In the
t
following, the inequality P > 0 means that P is sufficiently large to be distinguished from 0. If
not P > 0, then we set P = 0. We define
(cid:26)
1 if (5.2) is satisfied
γ = γ(S ) := (5.5)
t t 0 if (5.2) is not satisfied
and
Ω := {O ∈ Ω : P (L (O)|S ) = 0},
t,0 t t+1 t
Ω := {O ∈ Ω : P (L (O)|S ) > 0},
t,+ t t+1 t
Ω := {O ∈ Ω : P(S |L (O)) > 0}.
t,L t t
Then, we define a non-Bayesian updating process. It is also a type of state-space model.
Definition 5.1 The stochastic process L (O) is called a non-Bayesian updating process with
t
discrete time t = 1,2,... if it satisfies
P(S |L (O))·P (L (O)|S )
t t t−1 t t−1
P (L (O)|S ) = (1−γ )
t t t t (cid:80)
P(S |L (O))·P (L (O)|S )
O∈Ωt,L∩Ωt−1,+ t t t−1 t t−1
P(S |L (O))
t t
+γ (5.6)
t(cid:80)
P(S |L (O))
O∈Ωt,L∩Ωt−1,0 t t
P (L (O)|S ) → P (L (O)|S ). (5.7)
t t t t t+1 t
The posterior P (L (O)|S ) obtained by (5.6) is updated to the prior P (L (O)|S ) as (5.7)
t t t t t+1 t
by the movement vector in step 9 of Algorithm 5.1 at time t+1.
For consistency between Definition 5.1 and (5.5), we assume the following:
Assumption 5.1 Assume that for every O ∈ Ω and t, if γ = 1 and P(S |L (O)) > 0, then
t t t
P (L (O)|S ) = 0.
t−1 t t−1
From this assumption, we obtain that when γ = 1,
t
P(S |L (O))·P (L (O)|S ) = 0
t t t−1 t t−1
holds. This is consistent with the range of sum of the first term on the right-hand side of (5.6).
It is natural to make Assumption 5.1 when θ is sufficiently large. If θ is sufficiently large,
w w
then no predicted objects probably exist if γ = 1. Assume P (L (O)|S ) > 0. Then, object
t t−1 t t−1
25
O was probably active at time t−1. Therefore, if P(S |L (O)) > 0, then we can believe that S
t t t
is predicted, which implies γ = 0. Thus, we have Assumption 5.1.
t
As described below, we consider Algorithm 5.1 to correspond to the non-Bayesian updating
process in Definition 5.1. This formulation is a different (non-)Bayesian type formulation from
Friston’s free-energy principle and it does not have the universality that Friston’s theory does.
However, it can make a description of surprises and active inferences such as those in (I) and
(II).
We illustrate the probabilistic aspects of Algorithm 5.1. The likelihood P(S |L (O)) corre-
t t
sponds to steps 10 and 11. For instance, if we have no information regarding P(S |L (O)), we
t t
consider
 1
 if O ∈ Ω
t,L
P(S |L (O)) = ♯Ω (5.8)
t t t,L
 0 if O ̸∈ Ω .
t,L
The posterior P (L (O)|S ) and prior P (L (O)|S ) correspond to steps 12 to 15 at time t and
t t t t t+1 t
step 9 at time t+1, respectively. Depending on whether condition (5.2) holds, one of the terms
on the right-hand side of (5.6) is selected, and the probability P (L (O)|S ) is obtained. Table
t t t
3.1 is based on this concept.
Inbothcasesγ = 0andγ = 1,theposteriorP (L (O)|S )isupdatedbyL (O) → L (O)in
t t t t t t t+1
step9,L (O) = L (O)whenγ = 1,andP (L (O)|S )becomestheprior. In[1],model-based
t+1 t t t t+1 t
and model-free policies are provided as policies for determining the motor input as described
in Remark 3.4. In both learning and inference, both policies can work in concert. However,
the policies in the inference following learned connections in Figure 3.3, that is, inference by
Algorithm 3.2, will be primarily model-based. By contrast, the policies for the case γ = 1 and
t
(II)areconsideredtobeprimarilymodel-free. Instep13ofAlgorithm5.1forthecaseγ = 1,the
t
selectionisassumedtobemadeuniformlyrandom. Uniformrandomnessisalsoassumedin(5.8).
(The random policy is a special case of the model-free policy.) However, if the strength of the
sensory input, ♯W , differs for each object, this could be reflected in probabilities. Furthermore,
t
using information from multiple cortical columns would yield more precise probabilities.
6 Conclusion
In this study, we studied the Numenta neocortex model. In §2 and §3, the Numenta model
was reviewed. Algorithms that find objects similar to the given object O (Algorithms 4.1 and
4.2) and an algorithm that actively infers surprise (Algorithm 5.1) were proposed by slightly
changing the Numenta inference model (Algorithm 3.2).
An important aspect of these algorithms is how the motor input (movement vector) is se-
lected. As described in Remark 3.4 and §5, model-based and model-free policies to determine
the motor input were proposed by [1]. These policies enable the model to quickly identify the
observed object and react to the surprise. According to [2], [4], [5], and [18], the motor input
appears to be generated unconsciously in numerous cases, and according to [4], [5], and [18], un-
conscious processing is generally performed to minimize the variational free energy. The policies
proposed by [1] and Algorithm 3.2 could be deemed to be a method of performing this mini-
mization. However, it seems that implementing conscious selection of the motor input remains
unclear. This is an open problem for the author.
From the perspective of “association,” the setting for the algorithms in §4 is significantly
limited. To improve this, it is expected that research on association, such as that described in
Chapter6of[7]and[23], whichinvestigatesassociationinfeedforwardartificialneuralnetworks,
is useful. In Algorithms 4.1 and 4.2, the selection method of the motor input is important. This
26
selection in the inference depends on the learning results. Thus, the learning method of the
associations between objects is important. These are also open problems for the author.
Acknowledgements
This work was supported by JSPS KAKENHI Grant Number JP22K11916.
References
[1] Viviane Clay, Niels Leadholm, and Jeff Hawkins, The thousand brains project: a new
paradigm for sensorimotor intelligence, arXiv: 2412.18354v1, 2024
[2] Stanislas Dehaene, Consciousness and the Brain: Deciphering How the Brain Codes Our
Thoughts, Viking Penguin, 2014
[3] R. Douglas Fields, The Other Brain: The Scientific and Medical breakthroughs that will
hear our brains and revolutionize our health, Simon & Schuster Paperbacks, 2009.
[4] Karl Friston, The free-energy principle: A rough guide to the brain ?, Trends in Cognitive
Sciences, 13, 293-301, 2009
[5] Karl Friston, The free-energy principle: A unified brain theory ?, Nature Review Neuro-
science, 11, 127-138, 2010
[6] Jeff Hawkins with Sandra Blakeslee, On Intelligence: How to New Understanding of the
Brain Will Lead to the Creation of Truly Intelligent Machines, Times Books, 2004
[7] Jeff Hawkins, A Thousand Brains: A New Theory of Intelligence, Basic Books, 2022
[8] Jeff Hawkins and Subutai Ahmad, Why neurons have thousands of synapses, a theory of
sequence memory in neocortex, Frontiers in Neural Circuits, vol.10, article no.23, 2016
[9] Jeff Hawkins, Subutai Ahmad, and Yuwei Cui, A theory of how columns in the neocortex
enablelearningthestructureoftheworld, FrontiersinNeuralCircuits, vol.11, articleno.81,
2017
[10] Supplementary material of [9]
[11] JeffHawkins, MarcusLewis, MirkoKlukas, ScottPurdy, andSubutaiAhmad, Aframework
forintelligenceandcorticalfunctionbasedongridcellsintheneocortex,FrontiersinNeural
Circuits, vol.12, article no.121, 2019
[12] Hajime Kawakami, Doob’s consistency of a non-Bayesian updating process, Statistics and
Probability Letters, 203, 109921, 2023
[13] Niels Leadholm, Marcus Lewis, and Subutai Ahmad, Grid cell path integration for
movement-based visual object recognition, The 32nd British Machine Vision Conference,
22nd - 25th November, 2021
[14] Marcus Lewis, Scott Purdy, Subutai Ahmad, and Jeff Hawkins, Locations in the neocortex:
A theory of sensorimotor object recognition using cortical grid cells, Frontiers in Neural
Circuits, vol.13, article no.22, 2019
27
[15] Vernon Mountcastle, An organizing principle for cerebral functions: The unit module and
the distributed system, in The Mindful Brain, edited by Gerald M. Edelman and Vernon
B. Mountcastle, 7-50, Cambridge, MA: MIT Press, 1978
[16] Numenta, Hierarchical Temporal Memory including HTM Cortical Learning Algorithms,
2011.
https://hearingbrain.org/docs/HTM white paper.pdf
[17] Jonathan Passerat-Palmbach and David Beaumont, MTRandom.java,
http://www.math.sci.hiroshima-u.ac.jp/m-mat/MT/VERSIONS/JAVA/PATCH/MTRandom.java,
2011
[18] Thomas Parr, Giovanni Pezzulo, and Karl J. Friston, Active Inference: The Free Energy
Principle in Mind, Brain, and Behavior, MIT Press, 2022
[19] Abraham Pais, Maurice Jacob, and David I. Olive, Paul Dirac: The Man and His Work,
Cambridge University Press, 1998
[20] George Polya, How to Solve It: A New Aspect of Mathematical Method, Princeton Uni-
versity Press, 1975
[21] Richard S. Sutton and Andrew G. Barto, Reinforcement Learning: An Introduction, 2nd
Edition, MIT Press, 2018
[22] Toon Van de Maele, Tim Verbelen, Ozan C¸atal, and Bart Dhoedt, Embodied object repre-
sentation learning and recognition, Frontiers in Neurorobotics, 16, 840658, 2022
[23] Rufin VanRullen and Ryota Kanai, Deep learning and the global workspace theory, Trends
in Neuroscience, 14, 2021
28

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Finding Similar Objects and Active Inference for Surprise in Numenta Neocortex Model"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
