=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Environment-Centric Active Inference
Citation Key: esaki2024environmentcentric
Authors: Kanako Esaki, Tadayuki Matsumura, Takeshi Kato

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2024

Key Terms: people, environment, defined, centric, robot, japan, inference, active, agent, changes

=== FULL PAPER TEXT ===

Environment-Centric Active Inference
Kanako Esaki1, Tadayuki Matsumura1, Takeshi Kato2,
Shunsuke Minusa1, Yang Shao1, and Hiroyuki Mizuno1
1 Hitachi, Ltd., Tokyo, Japan
2 Kyoto University, Kyoto, Japan
Abstract. Tohandleunintendedchangesintheenvironmentbyagents,
weproposeanenvironment-centricactiveinferenceEC-AIFinwhichthe
Markov Blanket of active inference is defined starting from the environ-
ment.Innormalactiveinference,theMarkovBlanketisdefinedstarting
from the agent. That is, first the agent was defined as the entity that
performstheâ€œactionâ€ suchasarobotoraperson,thentheenvironment
was defined as other people or objects that are directly affected by the
agentâ€™s â€œaction,â€ and the boundary between the agent and the environ-
ment was defined as the Markov Blanket. This agent-centric definition
does not allow the agent to respond to unintended changes in the en-
vironment caused by factors outside of the defined environment. In the
proposed EC-AIF, there is no entity corresponding to an agent. The
environment includes all observable things, including people and things
conventionallyconsideredtobetheenvironment,aswellasentitiesthat
perform â€œactionsâ€ such as robots and people. Accordingly, all states, in-
cludingrobotsandpeople,areincludedininferencetargets,eliminating
unintended changes in the environment. The EC-AIF was applied to a
robotarmandvalidatedwithanobjecttransporttaskbytherobotarm.
The results showed that the robot arm successfully transported objects
while responding to changes in the target position of the object and to
changes in the orientation of another robot arm.
Keywords: robotÂ·MarkovBlanketÂ·embodiedagentÂ·objecttransport.
1 Introduction
Active inference, which explains the intelligence of living organisms, has in-
creasedtheintelligenceofvariousagents.Accordingtothefreeenergyprinciple,
whichisthebasisofactiveinference,livingorganismsminimizetheirfreeenergy
by either changing their actions for sampling the environment or by changing
their perceptions for inferring environmental states [7,4,14]. The unique feature
of this principle is that changing action, i.e., active inference, is also explained
in a unified manner [6,18]. This sensorimotor contingency, in which perception
and action are treated in a unified manner, is compatible with agents such as
robots because it eliminates actions that are unrelated to perception. Thus, ac-
tive inference has been implemented in various agents and has contributed to
generate intelligent actions [25,3,8,10,12,15,20,23,24,1,2].
4202
guA
32
]OR.sc[
1v77721.8042:viXra
2 K. Esaki et al.
Defining the agent and the environment in active inference has been left
to researchers [22,21,16,13,26]. In these studies, especially in systems with an
embodiment such as a robot, the implicit guideline has been to define the robot
as the agent and the surroundings as the environment. Defining the agent and
the environment implies designing Markov Blanket of active inference. As long
as the defined environment is maintained, the agent will outperform the human
in some cases. However, changes in the environment that cannot be directly
changed by the agent or in the presence of other agents can occur. The implicit
guideline for designing Markov Blanket would be unable to respond to such
changes in the environment that the agent does not intend.
Design strategies for Markov Blanket are required that can accommodate
unintended changes in the environment. It is not an implicit guideline, but a
specific strategy that is independent of the system configuration, such as the
robot and its surroundings. What are agents and environments? The design
strategy should answer this essential question. Changes in the environment that
are not intended by the agent originate from assuming an entity corresponding
to the agent (e.g., a robot) and defining its surroundings as the environment.
Instead of assuming the entity corresponding to the agent, considering all of
the world as the environment, the changes in the environment must be under
the intention of the agent. Therefore, defining a Markov Blanket based on the
environmentbyassumingthateverythingintheworldistheenvironmentwould
allow the agent to respond to changes in the environment.
We propose an environment-centric active inference EC-AIF that designs
Markov Blanket based on the environment. The concept of Markov Blanket is
shown in Fig. 1. The conventional Markov Blanket has defined the agent as
the entity that performs the â€œactionâ€, such as a robot or a person, and the
environment as the other people or objects, as shown in Fig. 1(a). The state
of the agent is fully known. In addition, the state of the environment within
the definition is inferred with high precision, but the state of the environment
outside the definition is not inferred at all. The proposed EC-AIF is completely
different, as shown in Fig. 1(b): there is no entity corresponding to an agent. In
addition to the people and objects that have been considered the environment,
theenvironmentincludes theentities thatperformâ€œactions,â€ suchas robotsand
people. The state of the environment is inferred with varying accuracy. The
EC-AIF was applied to a robot arm and demonstrated in an object transport
task. The robot arm adapted to changes in the environment and successfully
transported the object.
2 Method
2.1 Free Energy Principle and Active Inference
Living organisms are said to follow the Free Energy Principle (FEP). Living
organisms repeat a process of perception and action. Perception is the process
of acquiring an observation o from the environment and inferring a hidden state
s of the environment. Action is the process of inferring the appropriate policy Ï€
Environment-Centric Active Inference 3
Agent Environment Agent Environment
No
entity
Inference not inferred Inference
level level
(a) (b)
Fig.1. Concept of (a) conventional Markov Blanket (b) Markov Blanket of EC-AIF.
and acting on the environment. The hidden state s and policy Ï€ are inferred so
thatthefreeenergybecomessmaller,usingthegenerativemodelp(o,s,Ï€)ofthe
environment that living organisms have. One important feature of the FEP is
that actions are also regarded as inferences of policy, i.e., active inference. FEP
handles perception and action as a unified â€œinference.â€
Inferenceassumesthatthecategoriesofperceptionandactionarepredefined.
Perceptionandactionarerepresentedbyanobservationo,ahiddenstates,and
a policy Ï€, which are treated as probability distributions. Accordingly, defining
the probability variables for each of observation o, hidden state s, and policy Ï€
is equivalent to defining the categories of perception and action. For example,
considerthecasewheretheobservationvariableistheretinalimage,thehidden
state variable is the position of the target object, and the policy variable is the
directionofeyemovement.Inthiscase,perceptionistoinferthepositionofthe
target object based on the retinal image, and action is to infer the appropriate
direction to move the eye based on the position of the target object. The set
of these probability variables is called the Markov Blanket. Markov Blanket
determines the categories of perception and action.
2.2 Markov Blanket
LivingorganismsareconsideredtoadaptivelyselecttheirMarkovBlankets.The
Markov Blanket commonly imagined is the boundary between the living organ-
ismâ€™s body and its surroundings. However, this is not the only Markov Blanket
of a living organism. Living organisms have Markov Blankets as hierarchical
structures, such as the boundary between organs and their surroundings, and
between cells and their surroundings [5,11,17,19]. Depending on the goal, the
appropriate Markov Blanket is selected from among them.
To construct an active inference model for the interpretation of intelligent
actions of living organisms or the generation of intelligent actions of artifacts,
the researcher is required to design a Markov Blanket. For example, in the T-
maze problem [6], which is typical of active inference, an active inference model
is constructed from a rat, which is an agent with actions (movement in the
maze). Observation variables are designed for the two modalities of the ratâ€™s
exteroception (the ratâ€™s position in the maze) and interoception (attraction or
4 K. Esaki et al.
aversion stimuli). In addition, hidden state variables are designed as factors
that may explain the observation variables. The goal of the observation, called
â€œpreference,â€ provides a gradient of expected free energy, leading to appropriate
action. Similarly, when active inference is applied to a robot, a Markov Blanket
isdesignedstartingfromtherobot,whichisanagentwithactions.Agent-centric
design of Markov Blankets isusefulwhen active inference is applied toa limited
phenomenon in the world or a limited task assigned to a robot.
Agent-centric design of Markov Blanket does not address outside of the lim-
ited phenomena or tasks. Agents infer hidden states and policies defined in
Markov Blanket. In turn, agents cannot infer hidden states or policies that are
not defined in the Markov Blanket. Generating intelligent actions of robots and
other artifacts are expected to be general-purpose, i.e., to respond to changes
in the environment that are not intended by the agent. The agentâ€™s unintended
changesintheenvironmentarechangesinhiddenstatesandpoliciesthatinvolve
the outside of the environment defined by Markov Blanket. Changes in the hid-
den state are caused by the presence of agents other than the target agent. For
example, in the case where another robot is installed in addition to the target
robot, the hidden state is changed by the position, orientation, and movement
of the another robot. Changes in the policy, on the other hand, are caused by a
change to a goal that the target agent cannot directly achieve. For example, in
thecasewherethetargetrobotperformsacertaintask,thepolicyischangedby
achangetoataskthatcannotbeperformedbythatrobotalone.Theagentdoes
not â€œintendâ€ these changes because they involve â€œoutsideâ€ of the environment.
This implies that the agent can respond by incorporating these changes â€œinsideâ€
the environment. This requires a paradigm shift in the design of the Markov
Blanket from agent-centric to environment-centric.
2.3 Environment-Centric Active Inference EC-AIF
We propose an environment-centric active inference, EC-AIF, which designs
Markov Blankets starting from the environment. Fig. 2 shows the decision pro-
cessofobservationvariableso,hiddenstatevariabless,andpolicyvariablesÏ€ in
EC-AIF. In EC-AIF, the what and where that guide modality selection in nor-
mal active inference [18] are applied to the environment. First, where is defined
by considering the environment as the entire observable space. For example, the
observable space is simply divided into a grid, and each grid point is defined as
where ,where ,andsoon.Then,whatisenumeratedfromtheobservablespace,
1 2
in which where is independently changing. The what includes whatc, which is
connected to a controller like a robot, and whatnc, which is not connected to a
controller like a ball but the where changes due to robot operations. For whatc,
those that are connected to a controller are enumerated for each controller. For
whatnc, objects whose where changes with robot manipulation are considered
partially independent and thus included. Consequently, a ball that is glued to
the robot and whose where always changes with the robot is not included in
whatnc. Observation variables o are then defined by the possible combinations
of what and where:
Environment-Centric Active Inference 5
Define Enumerate Define Definehidden
Define policy
where what Observation state
Observable Observable Observable Observable
ğ‘¤â„ğ‘ğ‘¡
space ğ‘ space space space
Stop
1 2
ğ‘¤â„ğ‘ğ‘¡
ğ‘›ğ‘
3 4
Move to 1
Controller
Fig.2.Decisionprocessofobservation,hiddenstates,andactionsvariablesinEC-AIF.
o={o |iâˆˆZ ,iâ‰¤n}
whati +
(1)
o ={where |j âˆˆZ ,j â‰¤m}
whati j +
where n is the number of what (including whatc and whatnc) and m is the
number of where. After that, the hidden state variables s are determined based
on the observation variables o. The hidden state variables s are defined by the
possible combinations of observation variables o:
s={(o ,o ,...,o )|j1,j2,...,jnâˆˆZ ,j1,j2,...,jnâ‰¤m}
what1j1 what2j2 whatnjn +
(2)
where n is the number of what (including whatc and whatnc) and m is the
number of where. Finally, the policy variables Ï€ are determined based on the
observation variables o. The policy variables Ï€ are defined for each whatc by a
transition to where and a stop which means not changing where:
Ï€ ={Move(what ,where ),Stop(what )|iâˆˆZ ,iâ‰¤n,j âˆˆZ ,j â‰¤m} (3)
i j i + +
Algorithm1showstheprocessflowinEC-AIF.Foreachwhatc,agenerative
modelisconfigured,representedbytheobservationo,hiddenstates,andpolicy
Ï€ variables defined in the above decision flow.
3 Results and Discussion
3.1 Experimental Setup
The experiments were conducted with a scene of object transport by a robot.
The object is mainly transferred by Universal Robotsâ€™ 6-axis robot arm UR5e
and Robotiqâ€™s adaptive gripper 2F-140 attached to the end of the UR5e shown
in Fig. 3(a). In this scene, the world is composed of the robot arm UR5e and
6 K. Esaki et al.
Algorithm 1 Process flow of EC-AIF
1: for all whatc do
2: Create generative model p(o,s,Ï€)
3: end for
4: Acquire initial observation o
0
5: for Ï„ =0 to Timesteps T do
6: for all whatc do
7: Infer state s
Ï„
8: Infer policy Ï€
Ï„
9: Choose action a
Ï„
10: if whatc in a then
Ï„
11: Convert action a to control value u
Ï„ Ï„
12: Send control value u to controller
Ï„
13: Break
14: end if
15: end for
16: end for
DENSOWAVEâ€™s6-axisrobotarmCOBOTTAshowninFig.3(b),andthetarget
object placed around UR5e. Accordingly, what in this scene is as follows:
what={UR5e,COBOTTA,target object} (4)
Furthermore, where is the grid points P1 to P15, including UO, the origin posi-
tion of UR5e, CO, the origin position of COBOTTA, and Int., the intermediate
position between the two robots.
(a) (b)
Fig.3. Robots in Experiment (a) UR5e (b) COBOTTA.
We evaluated the proposed method in two scenarios that capture changes in
the environment in object transport:
Environment-Centric Active Inference 7
Scenario 1: The target position for object transport changes.
Scenario 2: Another robotâ€™s orientation changes.
Thefirstscenarioisanexampleofchangeintheenvironmentthatcannotbe
directly changed by the agent: the target position for object transport changes.
Specifically,asshowninFig.4(a),thetargetpositionisinitiallyinfrontofrobot
arm UR5e (P12) and then changes to the side of robot arm COBOTTA (P5).
Before the target position changes, the target position is within the reach of
UR5e, allowing object transport by UR5e by itself. After the target position
changes, the target position is outside the reach of UR5e and within the reach
of COBOTTA, requiring UR5e to cooperate with COBOTTA to transport the
object.Thesecondscenarioisanexampleofachangeintheenvironmentwhere
there is another robot, and the target position for object transport remains the
same, but the orientation of the other robot changes. Specifically, as shown in
Fig. 4(b), the target position is in front of COBOTTA (P14), and COBOTTA
initially faces the other direction from the target position, and then changes to
thedirectionofthetargetposition.BeforetheorientationofCOBOTTAchanges,
UR5e does not have contact with COBOTTA when it places an object at the
target position, allowing UR5e to transport the object on its own. After the
COBOTTAâ€™s orientation changes, UR5e requires cooperation with COBOTTA
to transport objects because UR5e will have contact with COBOTTA when
UR5eplacesobjectsatthetargetposition.Inbothscenarios,theinitialposition
of the target object was P7. The target position was given as the preference
regarding the observation of the target object.
Target
UR5e COBOTTA UR5e COBOTTA
(after)
Arm
P1 UO Int. CO P5 P1 UO Int. CO P5 direction
(before)
Initial Initial
P6 P7 P8 P9 P10 P6 P7 P8 P9 P10
Target
P11 P12 P13 P14 P15 P11 P12 P13 P14 P15
Target Armdirection
(before) (after)
(a) (b)
Fig.4.Scenariosof(a)thetargetpositionforobjecttransportchanges,and(b)another
robotâ€™sorientationchanges.Eachcirclerepresentsagridpointcomprisingwhere.UO
is the origin position of UR5e, CO is the origin position of COBOTTA, and Int. is
the intermediate position between UR5e and COBOTTA. The light blue circles (P1,
UO, P6, P7, P8, P11, P12, P13) are grid points in the reach range of UR5e, the blue
circles (CO, P5, P10, P15) are grid points in the reach range of COBOTTA, and the
purple circles (Int., P9, P14) are grid points in the reach range of both robots. In the
experiment, the grid points are not evenly distributed, and the position of the points
is shifted due to the constraints of the mechanism in which the robot is installed.
8 K. Esaki et al.
The proposed EC-AIF and the normal AIF as a benchmark are applied to
bothrobotarmsUR5eandCOBOTTA.BothEC-AIFandAIFareimplemented
usingpymdp[9],anactiveinferenceOSS.Theoutputoftheactionsispassedto
the robot control in the form of the target position and orientation of the robot
hand. The robot control used ROS melodic, a robot OSS installed on Ubuntu
18.04.
3.2 Change in Target Position for Object Transport
When the target position is within the reach of UR5e, the path of object trans-
port to the target position by UR5e was obtained in both cases where normal
AIF was applied and where EC-AIF was applied. Fig. 5 shows the transition
of the selected action when the target position is within the reach of UR5e. In
both cases, in timestep 1, an action to move UR5e to P7, where the object was
placed,wasselected,andthenintimestep2,anactiontoplacetheobjectatthe
targetposition,P12byUR5e,wasselected.Fig.6alsoshowsthetotalnumberof
observations of the object when the target position is within the reach of UR5e.
In both cases, where normal AIF was applied and where EC-AIF was applied,
the values of the objectâ€™s starting position (P7) and P12 were relatively higher
thantheotherpositions,andaroutewaschosentotransporttheobjectdirectly
from P7 to P12.
Action
p o tS 4 1
P
3 1
P
2 1
P
1 1
P
9
P
8
P
7
P
6
P
1
P
tn
I
.
U U U U U U U U U U U
Notation of action 1.0
p1
e U[X]: ğ‘€ğ‘œğ‘£ğ‘’ ğ‘ˆğ‘…5ğ‘’,ğ‘‹
ts
e2 UStop:ğ‘†ğ‘¡ğ‘œğ‘ ğ‘ˆğ‘…5ğ‘’
m C[X]: ğ‘€ğ‘œğ‘£ğ‘’ ğ¶ğ‘‚ğµğ‘‚ğ‘‡ğ‘‡ğ´,ğ‘‹ 0.8
iT3
CStop: ğ‘†ğ‘¡ğ‘œğ‘ ğ¶ğ‘‚ğµğ‘‚ğ‘‡ğ‘‡ğ´
(a)
0.6
Action e
u
p o tS C 5 1 P C 4 1 P C 0 1 P C 9 P C 5 P C tn I C . p o ts U 4 1 P U 3 1 P U 2 1 P U 1 1 P U 9 P U 8 P U 7 P U 6 P U 1 P U t U n I . 0.4 la V
p1
e ts
e2
0.2
m
iT3
0.0
(b)
Fig.5. Transition of the selected action when the target position is within the reach
of UR5e by (a) normal AIF and (b) EC-AIF.
Environment-Centric Active Inference 9
2
P1 UO Int. CO P5 P1 UO Int. CO P5
e
P6 P7 P8 P9 P10 P6 P7 P8 P9 P10 1 u
la
V
P11 P12 P13 P14 P15 P11 P12 P13 P14 P15
0
(a) (b)
Fig.6. Total number of observations of the object when the target position is within
the reach of UR5e by (a) normal AIF and (b) EC-AIF. Each cell in the heat map
correspondstowhereoftheobject.Thevalueofeachcellisthetotalnumberoftimes
the object was placed at the corresponding cellâ€™s position.
AfterthetargetpositionchangedoutsidethereachofUR5e,differenceswere
observed between cases where normal AIF was applied and cases where EC-
AIF was applied. Fig. 7 shows the transition of the selected action when the
target position is outside the reach of UR5e. In the case where normal AIF was
applied,variousactionsofUR5ewereselectedatalltimestepsandnoconsistent
sequence of actions was observed. In the case where EC-AIF was applied, on
the other hand, in timestep 1, the action of UR5e moving to P7, where the
object was placed, was selected, followed by the action of UR5e transporting
the object to the intermediate position between UR5e and COBOTTA (Int.) in
timestep 2. Furthermore, in timestep 3, after the action of COBOTTA moving
totheintermediateposition(Int.)wasselected,theactionofCOBOTTAplacing
the object to the target position, P5, was selected. Fig. 8 also shows the total
number of observations of the object when the target position is outside the
reach of UR5e. In the case where normal AIF was applied, only the value of P7,
whichistheinitialpositionofthetargetobject,ishigher.InthecasewhereEC-
AIF was applied, on the other hand, the values of the objectâ€™s starting position
(P7),theintermediateposition(Int.),andtheobjectâ€™stargetposition(P5)were
relatively higher than the other positions, and the shortest path was chosen for
UR5eandCOBOTTAtocooperativelytransportfromP7toP5.Thus,therobot
applying EC-AIF was able to respond to changes in target position.
The results suggest that EC-AIF can be used for environments that cannot
be changed directly by the agent. In normal AIF, the environment is defined
around UR5e, i.e. within the reach of UR5e. As long as the target position is
within the reach of UR5e, UR5e can transport objects. In normal AIF, actions
can be selected more quickly because there are fewer action variables than in
EC-AIF. Once the target position is outside the reach of UR5e for some reason
oftherobotuser,however,UR5ewillnotbeabletodeterminehowtotransport
theobject.Thisisbecausethetargetpositionisnowoutsideoftheenvironment
and no preferences regarding the objectâ€™s position are defined. In EC-AIF, the
environment is independent of the reach range of UR5e. Therefore, even if the
target position is outside the reach range of UR5e, the actions of UR5e can be
10 K. Esaki et al.
Action
p o tS 4 1
P
3 1
P
2 1
P
1 1
P
9
P
8
P
7
P
6
P
1
P
tn
I
.
U U U U U U U U U U U
1.0
Notation of action
1
U[X]: ğ‘€ğ‘œğ‘£ğ‘’ ğ‘ˆğ‘…5ğ‘’,ğ‘‹
p2 UStop:ğ‘†ğ‘¡ğ‘œğ‘ ğ‘ˆğ‘…5ğ‘’
e ts
e m 3
C
C
[
S
X
to
]:
p : ğ‘†
ğ‘€
ğ‘¡
ğ‘œ
ğ‘œ
ğ‘£
ğ‘
ğ‘’
ğ¶
ğ¶
ğ‘‚
ğ‘‚
ğµ
ğµ
ğ‘‚
ğ‘‚
ğ‘‡
ğ‘‡
ğ‘‡
ğ‘‡
ğ´
ğ´,ğ‘‹
0.8
iT4
5
(a) 0.6
e
u
Action la
V
p o tS C 5 1 P C 4 1 P C 0 1 P C 9 P C 5 P C tn I C . p o ts U 4 1 P U 3 1 P U 2 1 P U 1 1 P U 9 P U 8 P U 7 P U 6 P U 1 P U t U n I . 0.4
1
p2
e
ts
e3
0.2
m
iT4
5
0.0
(b)
Fig.7. Transition of the selected action when the target position is outside the reach
of UR5e by (a) normal AIF and (b) EC-AIF.
appropriately selected by only changing the preferences regarding the objectâ€™s
position.
The shortest path of object transport indicates that the principle of least
action is implicitly included in the active inference. There are various paths
otherthanthepathselectedhereforobjecttransportfromthestartingposition
P7 to the target positions P12 and P5. Nevertheless, the robot following active
inference transported the object using the shortest path. The agent that follows
active inference acts to minimize surprises to the environment. This means that
this agent minimizes the surprise to the result of the motion of the object that
followstheprincipleofleastaction.Thus,activeinferencenaturallyincludesthe
principle of least action.
3.3 Change in Another Robotâ€™s Orientation
The EC-AIF allowed the object transport route to be adjusted to the direction
in which COBOTTA was facing. Fig. 9 shows the motion sequences and the
object transport routes when COBOTTA is facing in a different direction from
the target position and when it is facing in the direction of the target position.
Environment-Centric Active Inference 11
2
P1 UO Int. CO P5 P1 UO Int. CO P5
e
P6 P7 P8 P9 P10 P6 P7 P8 P9 P10 1 u
la
V
P11 P12 P13 P14 P15 P11 P12 P13 P14 P15
0
(a) (b)
Fig.8. Total number of observations of the object when the target position is outside
the reach of UR5e by (a) normal AIF and (b) EC-AIF. Each cell in the heat map
correspondstowhereoftheobject.Thevalueofeachcellisthetotalnumberoftimes
the object was placed at the corresponding cellâ€™s position.
When COBOTTA was facing the other direction from the target position, the
object was directly transported from the start position to the target position.
In contrast, when COBOTTA was facing the direction of the target position,
the objectâ€™s route changed. Specifically, the object was transported from the
start position to the target position via the intermediate position (Int.). While
there was no possibility of contact between UR5e and COBOTTA, the object
was transported on the shortest route, and as the possibility of contact between
UR5e and COBOTTA increased, the object was transported on a detour path
to avoid contact.
P1 UO Int. CO P5
P6 P7 P8 P9 P10
UR5e move UR5e move
P11 P12 P13 P14 P15
to P7 to P14
(a)
P1 UO Int. CO P5
P6 P7 P8 P9 P10
UR5e move UR5e move COBOTTA COBOTTA
P11 P12 P13 P14 P15
to P7 to Int. move to Int. move to P14
(b)
Fig.9.Motionsequencesandobjecttransportroutes(a)whenCOBOTTAisfacingin
adifferentdirectionfromthetargetpositionand(b)whenitisfacinginthedirection
of the target position.
12 K. Esaki et al.
The result suggests that the EC-AIF is capable of adapting to changes in
the environment in which another robot is present. Both the starting and tar-
get positions were within the reach of UR5e. Accordingly, in a situation where
there were no obstacles, including another robot, objects were transported from
the starting position to the target position through the shortest path. However,
when the situation changed and COBOTTA was facing the direction of the tar-
get position, COBOTTA became an obstacle in the object transport path by
UR5e. As a result, even if UR5e chooses an action to transport the object to
the target position, the corresponding trajectory of UR5e would not be gener-
ated. Consequently, the action via the intermediate position (Int.), which is the
shortest path while avoiding the obstacle, was selected.
4 Conclusion
To handle unintended changes in the environment by agents, we proposed an
environment-centered active inference EC-AIF that defines the Markov Blanket
of active inference from the environment. In ordinary active inference, the envi-
ronment is defined from the starting point of an agent that performs â€œactions,â€
suchasarobotoraperson,andtheagentcannotrespondtounintendedchanges
intheenvironmentcausedbyfactorsotherthanthedefinedenvironment.Inthe
proposed EC-AIF, the environment is defined as the starting point, and there
is no entity equivalent to an agent. Therefore, all states, including robots and
people, are included in the inference target and unintended changes in the en-
vironment can be eliminated EC-AIF was applied to a robot arm and verified
in an object transport task by a robot arm. The results showed that the robot
arm successfully transported objects while responding to changes in the target
position of the object and changes in the posture of other robot arms. In future
work, the design of the generative model will be further refined by consider-
ing the mechanism by which each robotâ€™s preferences are transferred between
robots by extending the change in the robotâ€™s trajectory due to another robotâ€™s
orientation.
References
1. Esaki, K., Matsumura, T., Ito, K., Mizuno, H.: Sensorimotor visual perception
on embodied system using free energy principle. In: Machine Learning and Prin-
ciples and Practice of Knowledge Discovery in Databases. pp. 865â€“877. Springer
International Publishing, Cham (2021)
2. Esaki, K., Matsumura, T., Minusa, S., Shao, Y., Yoshimura, C., Mizuno, H.: Dy-
namicalperception-actionloopformationwithdevelopmentalembodimentforhier-
archicalactiveinference.In:ActiveInference.pp.14â€“28.SpringerNatureSwitzer-
land, Cham (2024)
3. Fountas,Z.,Sajid,N.,Mediano,P.,Friston,K.:Deepactiveinferenceagentsusing
monte-carlo methods. In: Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M.,
Lin, H. (eds.) Advances in Neural Information Processing Systems. vol. 33, pp.
Environment-Centric Active Inference 13
11662â€“11675.CurranAssociates,Inc.(2020),https://proceedings.neurips.cc/
paper/2020/file/865dfbde8a344b44095495f3591f7407-Paper.pdf
4. Friston,K.:Thefree-energyprinciple:aunifiedbraintheory?Naturereviewsneu-
roscience 11(2), 127â€“138 (2010)
5. Friston, K.: A free energy principle for a particular physics. arXiv preprint
arXiv:1906.10184 (2019)
6. Friston, K., FitzGerald, T., Rigoli, F., Schwartenbeck, P., Pezzulo, G.: Active In-
ference: A Process Theory. Neural Computation 29(1), 1â€“49 (01 2017). https:
//doi.org/10.1162/NECO_a_00912, https://doi.org/10.1162/NECO_a_00912
7. Friston, K., Kilner, J., Harrison, L.: A free energy principle for the brain.
Journal of Physiology-Paris 100(1), 70â€“87 (2006). https://doi.org/https:
//doi.org/10.1016/j.jphysparis.2006.10.001, https://www.sciencedirect.
com/science/article/pii/S092842570600060X, theoretical and Computational
Neuroscience: Understanding Brain Functions
8. Friston, K.J., Parr, T., Yufik, Y., Sajid, N., Price, C.J., Holmes, E.: Gen-
erative models, linguistic communication and active inference. Neuroscience
& Biobehavioral Reviews 118, 42â€“64 (2020). https://doi.org/https:
//doi.org/10.1016/j.neubiorev.2020.07.005, https://www.sciencedirect.
com/science/article/pii/S0149763420304668
9. Heins,C.,Millidge,B.,Demekas,D.,Klein,B.,Friston,K.,Couzin,I.D.,Tschantz,
A.: pymdp: A python library for active inference in discrete state spaces. Journal
of Open Source Software 7(73), 4098 (2022). https://doi.org/10.21105/joss.
04098, https://doi.org/10.21105/joss.04098
10. Horii, T., Nagai, Y.: Active inference through energy minimization in
multimodal affective humanâ€“robot interaction. Frontiers in Robotics and
AI 8 (2021). https://doi.org/10.3389/frobt.2021.684401, https://www.
frontiersin.org/articles/10.3389/frobt.2021.684401
11. Kirchhoff, M., Parr, T., Palacios, E., Friston, K., Kiverstein, J.: The markov
blankets of life: autonomy, active inference and the free energy principle. Jour-
nal of The Royal Society Interface 15(138), 20170792 (2018). https://doi.org/
10.1098/rsif.2017.0792
12. Lanillos,P.,Meo,C.,Pezzato,C.,Meera,A.A.,Baioumy,M.,Ohata,W.,Tschantz,
A., Millidge, B., Wisse, M., Buckley, C.L., Tani, J.: Active inference in robotics
and artificial agents: Survey and challenges (2021)
13. VandeMaele,T.,Dhoedt,B.,Verbelen,T.,Pezzulo,G.:Integratingcognitivemap
learningandactiveinferenceforplanninginambiguousenvironments.In:Buckley,
C.L., Cialfi, D., Lanillos, P., Ramstead, M., Sajid, N., Shimazaki, H., Verbelen,
T., Wisse, M. (eds.) Active Inference. pp. 204â€“217. Springer Nature Switzerland,
Cham (2024)
14. McGregor,S.,Baltieri,M.,Buckley,C.L.:Aminimalactiveinferenceagent.arXiv
preprint arXiv:1503.04187 (2015)
15. Millidge,B.:Deepactiveinferenceasvariationalpolicygradients.JournalofMath-
ematical Psychology 96, 102348 (2020). https://doi.org/10.1016/j.jmp.2020.
102348
16. Oliver, G., Lanillos, P., Cheng, G.: An empirical study of active inference on a
humanoid robot. IEEE Transactions on Cognitive and Developmental Systems
14(2), 462â€“471 (2022). https://doi.org/10.1109/TCDS.2021.3049907
17. Palacios, E.R., Razi, A., Parr, T., Kirchhoff, M., Friston, K.: On markov blan-
ketsandhierarchicalself-organisation.JournalofTheoreticalBiology486,110089
(2020). https://doi.org/10.1016/j.jtbi.2019.110089
14 K. Esaki et al.
18. Parr, T., Pezzulo, G., Friston, K.J.: Active inference: the free energy principle in
mind, brain, and behavior. MIT Press (2022)
19. Pearl, J.: Probabilistic reasoning in intelligent systems: networks of plausible in-
ference. Morgan kaufmann (1988)
20. Pezzato, C., Corbato, C.H., Bonhof, S., Wisse, M.: Active inference and behavior
treesforreactiveactionplanningandexecutioninrobotics.IEEETransactionson
Robotics39(2),1050â€“1069(2023).https://doi.org/10.1109/TRO.2022.3226144
21. Pio-Lopez, L., Nizard, A., Friston, K., Pezzulo, G.: Active inference and
robot control: a case study. Journal of The Royal Society Interface
13(122), 20160616 (2016). https://doi.org/10.1098/rsif.2016.0616, https:
//royalsocietypublishing.org/doi/abs/10.1098/rsif.2016.0616
22. Priorelli, M., Stoianov, I.P.: Efficient motor learning through action-perception
cyclesindeepkinematicinference.In:Buckley,C.L.,Cialfi,D.,Lanillos,P.,Ram-
stead,M.,Sajid,N.,Shimazaki,H.,Verbelen,T.,Wisse,M.(eds.)ActiveInference.
pp. 59â€“70. Springer Nature Switzerland, Cham (2024)
23. Sajid, N., Ball, P.J., Parr, T., Friston, K.J.: Active Inference: Demystified and
Compared.NeuralComputation33(3),674â€“712(032021).https://doi.org/10.
1162/neco_a_01357, https://doi.org/10.1162/neco_a_01357
24. UeltzhÃ¶ffer, K.: Deep active inference. Biological cybernetics 112(6), 547â€“573
(2018). https://doi.org/10.1007/s00422-018-0785-7
25. Ã‡atal, O., Verbelen, T., Nauta, J., Boom, C.D., Dhoedt, B.: Learning perception
and planning with deep active inference. In: ICASSP 2020 - 2020 IEEE Inter-
national Conference on Acoustics, Speech and Signal Processing (ICASSP). pp.
3952â€“3956 (2020). https://doi.org/10.1109/ICASSP40776.2020.9054364
26. Ã‡atal, O., Wauthier, S., De Boom, C., Verbelen, T., Dhoedt, B.: Learning gener-
ative state space models for active inference. Frontiers in Computational Neuro-
science14(2020).https://doi.org/10.3389/fncom.2020.574372,https://www.
frontiersin.org/articles/10.3389/fncom.2020.574372

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Environment-Centric Active Inference"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   âŒ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   âœ… GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   âŒ BAD: Repeating the same claim 3+ times with slight variations
   âœ… GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
