=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Spatial and Temporal Hierarchy for Autonomous Navigation using Active Inference in Minigrid Environment
Citation Key: tinguy2023spatial
Authors: Daria de Tinguy, Toon van de Maele, Tim Verbelen

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Abstract: Robustevidencesuggeststhathumansexploretheirenvironmentusingacombinationoftopologicalland-
marksandcoarsegrainedpath-integration. Thisapproachreliesonidentifiableenvironmentalfeatures(topo-
logicallandmarks)intandemwithestimationsofdistanceanddirection(coarsegrainedpath-integration)to
constructcognitivemapsofthesurroundings. Thiscognitivemapisbelievedtoexhibitahierarchicalstruc-
ture,allowingefficientplanningwhensolvingcomplexnavigationtasks. Inspiredbythehumanbehaviour,
this paper presents a sc...

Key Terms: navigation, orientedbehaviour, environment, autonomous, inference, spatial, active, minigrid, hierarchy, integration

=== FULL PAPER TEXT ===

Spatial and Temporal Hierarchy for Autonomous Navigation
using Active Inference in Minigrid Environment
DariadeTinguy1,ToonVandeMaele2,TimVerbelen2,andBartDhoedt1
September16,2024
Abstract
Robustevidencesuggeststhathumansexploretheirenvironmentusingacombinationoftopologicalland-
marksandcoarsegrainedpath-integration. Thisapproachreliesonidentifiableenvironmentalfeatures(topo-
logicallandmarks)intandemwithestimationsofdistanceanddirection(coarsegrainedpath-integration)to
constructcognitivemapsofthesurroundings. Thiscognitivemapisbelievedtoexhibitahierarchicalstruc-
ture,allowingefficientplanningwhensolvingcomplexnavigationtasks. Inspiredbythehumanbehaviour,
this paper presents a scalable hierarchical active inference model for autonomous navigation, exploration,
andgoal-orientedbehaviour.Themodelusesvisualobservationandmotionperceptiontocombinecuriosity-
drivenexplorationwithgoal-orientedbehaviour. Motionisplannedusingdifferentlevelsofreasoning, i.e.
fromcontexttoplacetomotion. Thisallowsforefficientnavigationinnewspacesandrapidprogresstoward
atarget. Byincorporatingthesehumannavigationalstrategiesandtheirhierarchicalrepresentationoftheen-
vironment,thismodelproposesanewsolutionforautonomousnavigationandexploration. Theapproachis
validatedthroughsimulationsinamini-gridenvironment.
Activeinference;autonomousnavigation;spatialhierarchy,temporalhierarchy;predictivecoding
1 Introduction
Thedevelopmentofautonomoussystemsthatareabletonavigateintheirenvironmentisacrucialsteptowards
buildingintelligentagentsthatcaninteractwiththerealworld. Justasanimalspossesstheabilitytonavigate
theirsurroundings,developingnavigationskillsinartificialagentshasbeenatopicofgreatinterestinthefield
ofroboticsandartificialintelligence[1,2,3]. Thishasledtotheexplorationofvariousapproaches,including
takinginspirationfromanimalnavigationstrategies(e.gbuildingcognitivemaps[4]),aswellasstate-of-the-art
techniquesusingneuralnetworks[5]. However,despitesignificantadvancements,therearestilllimitationsin
bothnon-neuralnetworkandneuralnetwork-basednavigationapproaches[2,3].
Intheanimalkingdom,cognitivemappingplaysacrucialroleinnavigation. Cognitivemapsallowanimals
to understand the spatial layout of their surroundings [6, 7, 8], remember key locations, solve ambiguities
thankstocontext[9]andplanefficientroutes[9,10]. Byleveragingcognitivemappingstrategies,animalscan
successfullynavigatecomplexenvironments,adapttochanges,andreturntopreviouslyvisitedplaces.
In the field of robotics, traditional approaches have been explored to develop navigation systems. These
approachesoftenrelyonexplicitmappingandplanningtechniques,suchasgrid-based[11,12]and/ortopolog-
icalmaps[13,14],toguideagentmovement. Whilethesemethodshaveshownsomesuccess,theysufferfrom
limitationsinhandlingcomplexspatialrelationships,dynamicenvironmentsaswellasscalabilityissuesasthe
environmentgrowslarger[3,15,2].
To overcome the limitations of these non-neural network approaches, recent advancements have focused
on utilising neural networks for navigation [16, 5, 17, 18]. Neural network-based models, trained on large
datasets, have shown promise in learning navigational policies directly from raw sensory input. These mod-
els can capture complex spatial relationships and make decisions based on learned representations. However,
currentneuralnetwork-basednavigationapproachesalsofacechallenges,includingtheneedforextensivetrain-
ingdata,limitationsingeneralisationtounseenenvironments,distinguishingaliasedareasandthedifficultyof
handlingdynamicandchangingenvironments[2].
Toaddressthesechallenges,weproposebuildingworldmodelsbasedonactiveinference. Activeinference
isaframeworkcombiningperception,action,andlearningtoenableagentstoactivelyexploreandunderstand
theirenvironment[19,20]. Worldmodelsforminternalrepresentationsoftheworld,facilitatinginferenceand
decision-makingprocessesusingactiveinferenceframeworks[21,22].
1
4202
peS
31
]OR.sc[
3v85050.2132:viXra
Active inference provides a principled approach to agent-environment interactions. By formulating navi-
gationasanactiveinferenceproblem,agentscancontinuouslyupdatetheirbeliefsabouttheenvironmentand
activelygatherinformationthroughinteractions. Thisenablesthemtomakeinformeddecisionsandeffectively
navigateintheworld[23].
Notingthatbiologicalagentsarebuildinghierarchicallystructuredmodels,weconstructmulti-levelworld
modelsashierarchicalactiveinference.Hierarchicalactiveinferenceempowersagentstoutiliselayersofworld
models,facilitatingahigherlevelofspatialabstractionandtemporalcoarse-graining. Itenableslearningcom-
plexrelationshipsintheenvironmentandallowsmoreefficientdecision-makingprocessesandrobustnavigation
capabilities[24].Byincorporatinghierarchicalstructuresintoactiveinference-basednavigationsystems,agents
caneffectivelyhandlecomplexenvironmentsandperformtaskswithgreateradaptability[25].
Inthispaper,inordertoimprovetheagent’sabilitytonavigateautonomouslyandintelligently,wepropose
a hierarchical active inference model composed of three layers. Our proposed system highest layer is able to
learntheenvironmentstructure,remembertherelationshipbetweenplaces,andnavigatewithoutpriortraining
in a familiar yet new world. The second layer, the allocentric model, learns to predict the local structure of
roomswhilethelowestlevel,ouregocentricmodel,considersthedynamiclimitationoftheenvironment. We
aimto enhancethe agent’sability tonavigate through complexand dynamicenvironments whilemaintaining
scalabilityandadaptability.
Ourcontributionscanbesummarisedasfollows:
• We present a system combining hierarchical active inference with world modelling for task agnostic
autonomousnavigation.
• Oursystemusespixel-based,visualobservations,whichshowspromiseforreal-worldscenarios.
• Ourmodellearnsthestructureoftheenvironment,itsdynamiclimitationsandformsaninternalmapof
the full environment independently of its size, without requiring more computation as the environment
scalesup.
• Oursystemcanplanlong-termwithoutworryingaboutlook-aheadlimitations.
• Weevaluatethesysteminamini-gridroommazeenvironment[26],showingtheefficiencyofourmethod
forexplorationandgoal-relatedtasks,comparedagainstotherReinforcementLearning(RL)modelsand
otherbaselines.
• Wequantitativelyandqualitativelyassessourwork,showinghowourhierarchicalactiveinferenceworld
model fares in accomplishing given tasks, how it resists aliasing, and how it learns the environment
structure.
The subsequent sections of this paper will delve into the details of our proposed approach, including the
theoreticalfoundationsofactiveinferenceandhierarchicalactiveinference,thearchitectureofournavigation
system,experimentalresults,andacomprehensivediscussionoftheadvantagesandlimitationsofourapproach.
2 Related work
Navigating complex environments is a fundamental challenge for both humans and artificial agents. To solve
navigation, traditional approaches often address simultaneous localisation and mapping (SLAM) by building
a metric (grid) map [11, 12] and/or topological map of the environment [13, 14]. Although there is progress
in this area, Placed et al. [3] state that active SLAM still lack autonomy in complex environments. Current
approachesarealsostilllackingindistinctaspectsfornavigationsuchaspredictingtheuncertaintyoverrobot
location, gainingabstractionovertheenvironment(e.g. havingasemanticmapinsteadofaprecise3Dmap),
and reasoning in dynamic, changing, spaces. Recent studies have explored the adoption of machine learning
techniques to add autonomy and adaptive skills in order to learn how to handle new scenarios in real-world
situations.ReinforcementLearning(RL)typicallyreliesonrewardstostimulateagentstonavigateandexplore.
In contrast, our model breaks away from this convention, as it doesn’t necessitate the explicit definition of
a reward during agent training. Moreover, despite the success of recent machine learning, these techniques
typically require a considerable amount of training data to build accurate environment models. This training
datacanbeobtainedfromsimulation[27,28],providedbyhumans(eitherbylabellingasin[29,30]worksor
bydemonstrationasin [31]proposition), orbygatheringdatainanexperimentalsetting[32,33,16]. These
2
methods all aim to predict the consequences of actions in the environment, but typically poorly generalise
acrossenvironments. Assuch,theyrequireconsiderablehumaninterventionwhendeployingthesesystemsin
newsettings [2]. Weaimtoreduceboththehumaninterventionandthequantityofdatarequiredfortraining
bysimultaneouslyfamiliarisingtheagenttothestructureanddynamicsfoundinitsenvironment.
Whendesigninganautonomousadaptablesystem,natureisasourceofinspiration.Tolman’scognitivemap
theory[34]proposesthatbrainsbuildaunifiedrepresentationofthespatialenvironmenttosupportmemoryand
guidefutureaction. Morerecentstudiespostulatethathumanscreatementalrepresentationsofspatiallayouts
to navigate [6], integrating routes and landmarks into cognitive maps [7]. Additionally, research into neural
mechanisms suggest that spatial memory is constructed in map-like representation fragmented into sub maps
withlocalreferenceframes[35],whilehierarchicalplanningisprocessedinthehumanbrainduringnavigation
tasks [9]. The studies of Balaguer et al. [9] and Tomov et al. [10] show that hierarchical representations are
essentialforefficientplanningforsolvingnavigationtasks.Hierarchiesprovideastructuredapproachforagents
tolearncomplexenvironments, breakingdownplanningintomanageablelevelsofabstractionandenhancing
navigationcapabilities,bothspatially(sub-maps)andtemporally(time-scales).Assuch,ourmodelincorporates
theseelementsasthefoundationofitsoperation.
Theconceptofhierarchicalmodelshasgainedinterestinnavigationresearch[25,13]. Hierarchicalstruc-
turesenableagentstolearncomplexrelationshipswithintheenvironment, leadingtomoreefficientdecision-
making and enhancing adaptability in dynamic scenarios. There are two main types of hierarchy, both con-
sidered in our work, temporal -planning over sequence of time- [36, 37, 38, 39] and spatial -planning over
structures-[24,40,41,13].
Inordertonavigatewithoutteachingtheagenthowtodoso,weusetheprincipledapproachofactiveinfer-
ence(AIF),aframeworkcombiningperception,action,andlearning. Itisapromisingavenueforautonomous
navigation [22]. By actively exploring the environment and formulating beliefs, agents can make informed
decisions. Within this framework, world models play a pivotal role in creating internal representations of the
environment,facilitatingdecision-makingprocesses. AfewmodelshavebeencombiningAIFandHierarchical
models for navigation. Safron et al. [42] proposes a hierarchical model composed of 2 layers of complexity
to learn the structure of the environment. The lowest level inferring the state of each step while the higher
level represent locations, created in a more coarse manner. However large, complex, aliased, and/or dynamic
environmentsarechallengestothismodel. Nozarietal.[43]showahierarchicalsystembyusingaDynamic
BayesianNetwork(DBN)overanaiveandanexpertagent,thenaivelearningtemporalrelationships,withthe
highestlevelcapturingsemanticinformationabouttheenvironmentandlow-leveldistributionscapturingrough
sensoryinformationwiththeirrespectiveevolutionthroughtime. Thissystemhoweverrequiresexpertdatato
trainbyimitationlearning,whichlimitsitsperformanceofthemodeltotheoneoftheexpert.Ourstudyfocuses
onfamiliarisingthemodelwithenvironmentalstructuresratherthanlearningoptimalpolicieswithinenviron-
ments. Thisapproachenhancesthemodel’sautonomyandadaptabilitytodynamicchanges. Furthermore,the
incorporationofspatialandtemporalhierarchicalabstractionseffectivelymitigatesaliasingambiguity,aswell
asextendstheagent’splanninghorizonforimproveddecision-making.
Collectively,thesestudiesprovideinsightsintothecognitivemappingstrategiesusedbyhumans,theben-
efitsofhierarchicalrepresentationsinnavigation, andtheapplicationofactiveinferenceandworldmodelsto
afforddecisionmakingintheenvironment. Theconceptofhierarchicalactiveinferenceoffersapossiblefoun-
dation to achieve robust and efficient navigation through complex and dynamic environments. In this school
of thought, our work proposes a new alternative to navigate in environments using pixel based hierarchical
generativemodelstolearntheworldandactiveinferencetonavigatethroughit.
3 Methods
Thissectionpresentsabreakdownofthenavigationframeworkproposedinthiswork. Itisdividedintoseveral
subsections, starting with an exploration of world models and their importance in capturing the environment.
We then delve into active inference, planning through inference, and our hierarchical active inference model.
Next, we discuss the specific components of our model, including the egocentric model, allocentric model,
andcognitivemap. Thesubsectiononnavigationcoverskeymechanismssuchascuriosity-drivenexploration,
uncertaintyresolution,andgoal-reaching. Finally,weconcludewithabriefoverviewofthetrainingprocess.
3
3.1 WorldModel
Wewillfirstintroducetheconceptofworldmodelsinthecontextofnavigation. Anyagent,artificialornatural,
canonlysenseitssurroundingsthroughsensoryobservationsandchangeitssurroundingsthroughactions. This
conceptofastatisticalboundary,knownasaMarkovBlanket,playsacrucialroleindefiningtheinformation
flowbetweenanagentanditsenvironment[44,23].
The agent’s world model can be defined as partially observable, corresponding to a partially observable
Markov decision process (POMDP). In the framework of active inference those world models are generative,
they capture how hidden causes generate observations through actions. Given a set of observations o and
actions a, the agent creates a latent state s, representing its belief about the world. This corresponds to the
probabilitydistributionP(s˜|o˜,a˜,π),wheretildesareusedtodenotesequences,definingtheagent’sbeliefstates,
observations, actions, andpolicies. Inthisformalism, apolicyπ isnothingmorethanaseriesofactionsa
t:T
fromtimetupuntilsomehorizonT.
WeassumetheworldmodelisMarkovianwithoutlossofgenerality,sothattheagent’sstates attimestep
t
tisonlyinfluencedbythepriorstates andactiona .
t−1 t−1
Technically,thegenerativemodelisfactorisedasfollows,usingthenotationexplainedabove[38]:
T
(cid:89)
P(s˜,o˜,a˜,π)=P(s )P(π) P(o |s )P(s |s ,a )P(a |π) (1)
0 t t t t−1 t−1 t−1
t=1
3.2 ActiveInference
The Markov blanket acts as a barrier between the agent and the environment, restricting the agent’s direct
knowledge of the world’s state. Consequently, the agent must rely on observations to gauge the effects of its
actions. ThisnecessitatesBayesianinferencestorevisebeliefsaboutpotentialstatevalues,basedonobserved
actions and their corresponding observations. In fact, the agent uses the posterior belief P(s˜|o˜,a˜) to infer its
beliefstates[19].
Inpractice,calculatingthetrueposteriorinthisform,derivedpurelyfromBayesrule,isusuallyintractable
directlyfromthegivenjointmodelinEquation1.
To prevent this, the agent employs variational inference and approximates the true posterior by some ap-
proximateposteriordistributionQ(s˜|o˜,a˜),whichisinatractableform[45].
Theestimatedposteriordistributioncanbedecomposedasthemodelproposedin1:
T
(cid:89)
Q(s˜|o˜,a˜)=Q(s |o ) Q(s |s ,a ,o ) (2)
0 0 t t−1 t−1 t
t=1
Thisapproximateposteriormapsfromobservationsandactionstointernalstatesusedtoreasonabouttheworld.
The agent is assumed to act accordingly to the Free Energy Principle which states that all agents aim to
minimisetheirvariationalfreeenergy[19]. Givenourgenerativemodel,wecanformalisethevariationalfree
energyFinthefollowingway[38]:
F =E [logQ(s˜|a˜,o˜)−logP(s˜,a˜,o˜)]
Q(s˜|a˜,o˜)
=D [Q(s˜|a˜,o˜))||P(s˜|a˜,o˜)]−logP(o˜)
KL
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
posteriorapproximation logevidence (3)
=D [Q(s˜|a˜,o˜))||P(s˜,a˜)]−E [logP(o˜|s˜)]
KL Q(s˜|a˜,o˜)
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
complexity accuracy
Thisequationdescribestheperceptionprocessoverpastandpresentobservations,whereinminimisingthe
variational free energy leads to the approximate posterior becoming increasingly aligned to the true posterior
beliefs. Essentially,thismeansthattheprocessinvolvesformingbeliefsabouthiddenstatesthatofferaprecise
and concise explanation of observed outcomes while minimising complexity. Complexity, in this case, is the
differencebetweenpriorandposteriorbeliefs,indicatinghowmuchoneadjuststheirbeliefwhenmovingfrom
priortoposterior[40].
4
3.3 PlanningasInference
Inactiveinference,agentsareexpectedtotakeactionsthatminimisethefreeenergyinthefuture. Minimising
freeenergyw.r.t.tofutureobservationsencouragestheagenttogetadditionalobservationsinordertomaximise
itsevidence,andcanthusbeemployedasanaturalstrategytoexploration. However,asfutureobservationsand
actions are not available to the agent, the agent minimises its Expected Free Energy (EFE). To calculate this
Expected Free Energy G, the effect of adopting several policies (i.e. sequences of actions) on the future free
energyisanalysed.
(cid:88)
G(π)= G(π,τ) (4)
τ
TheexpectedfreeenergyG(π,τ)foracertainpolicyπandtimestepτ inthefutureforthegenerativemodel
isdefinedas:
G(π,τ)=E [ln(Q(s |π)−ln(Q(s |o ,π))]−E [ln(P(o ))] (5)
Q(oτ,sτ|π) τ τ τ Q(oτ,sτ|π)) τ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
informationgainterm utilityterm
Theexpectedfreeenergynaturallybalancestheagent’sdrivetowardsitspreferences,i.e. informationgain,
withtheexpecteduncertaintyofthepathtowardsthegoal,i.e. utilityvalue[25,46].
In order to effectively navigate, sophisticated inference is a key concept in active inference, given current
knowledgeabouttheenvironment,itinvolvesselectingpoliciesthattakeintoconsiderationexpectedsurpriseat
futuretimesteps[47].
Whilethedependencyonpoliciesintheprioroverstatescanbeomitted,theagent’sdesiretoattainitspreferred
world’sstatesremainsevidentregardlessofwhichpolicyitpursues. Theexpectedfreeenergyiscalculatedfor
eachfuturetimesteptheagentconsidersandisthenaggregatedtoinferthemostlikelysequenceofactionsto
reachapreferredstate. Thisbeliefoverpoliciesisachievedthrough:
P(π)=σ(−γG(π)) (6)
Where σ, the softmax function is tempered with a temperature parameter γ converting the expected free
energy of policies into a categorical distribution over policies. By using sophisticated inference, planning is
transformedintoaninferenceproblem,withbeliefsaboutpoliciesproportionatetotheirexpectedfreeenergy.
The softmax temperature γ represents the agent’s confidence in its current beliefs over policies. Overall, so-
phisticatedinferenceallowstheagenttoplanaheadandoptimiseitsbehaviourovertime, takingintoaccount
theuncertaintyandcomplexityoftheenvironmenttoachieveitsgoals. Inotherwords, wepassfromabelief
overpoliciestoabeliefoverthebeliefsoverpolicies. Thisisnecessaryforhigh-levelcognitiveprocessessuch
asreasoning,planning,anddecision-making[25,47].
3.4 AhierarchicalActiveInferencemodel
Active inference enables us to plan across a span of time; however, employing a non-hierarchical model that
capturestheenvironmentinasinglestateorlayerexhibitsnumerouslimitations. Thosemodelsareoftenweak
to aliasing as they lack abstraction to distinguish identical observations. Secondly, they are often limited by
the model’s look-ahead horizon and is short-term memory by design, making long-term planning hazardous.
Table1: Descriptionofthevariablesusedinourmode
notation associatedmeaning
l location,experience
z place,room,allocentricstate
p pose,position
s egocentricstate
a action
o observation
c collision
π policy,sequenceofx
x
5
Moreover,thosemodelsoftenlackadaptabilityincaseofunexpectedchangesintheenvironment. Finally,the
largertheenvironmentis,themorecomputationalresourcesmightberequiredforsuchamodeltoformafull
comprehensiverepresentation[48,46].
Therefore, in navigation, hierarchical models are sought after to gain in abstraction, generalisation, and
adaptabilitybyaddinglevelstocapturehierarchicalstructuresandrelationships[25,49].
From that perspective, we propose a hierarchical generative model consisting of three layers of reasoning
functioningatnestedtimescales,aimingforamoreflexiblereasoningovertimeandspace(seeFig1). Inorder
ofdecreasingabstractionlevel: (a)thecognitivemap, creatingacoherenttopologicalmap, (b)theallocentric
model,representingspace,and(c)theegocentricmodel,modelingmotions. Thestructureoftheenvironment
isinferredovertimebyagglomeratingvisualobservationsintorepresentationsofdistinctplaces(e.g. rooms)
whilethehighestleveldiscovertheconnectivitystructureofthemazeasagraph. Thefulljointdistributionof
thegenerativemodelcanbewrittendownasinEquation7,whereweexplicitlyindexthethreedistinctnested
timescaleswithT,tandτ respectively:
Figure 1: Our generative model unrolled in time and levels as defined in Eq.7. The left figure shows the
graphical model of the 3-layer hierarchical Active inference model consisting of a) the cognitive map, b) the
allocentric model, and c) the egocentric model, each operating at a different time scale. The orange circles
representlatentstatesthathavetobeinferred,thebluecirclesdenoteobservableoutcomesandthewhitecircles
are internal variables to be inferred. The right part visualises the representation at each layer. The cognitive
mapisrepresentedasd)atopologicalgraphcomposedofallthelocations(l)andtheirconnections,inwhich
eachlocationisstoredinadistinctnode.Theallocentricmodele)infersplacerepresentations(z)byintegrating
sequencesofstate(s)andposes(p),fromwhichtheroomstructurecanbegenerated. Theegocentricmodelf)
imaginesfutureobservationsgiventhecurrentposition, state(s), andpossibleactions(a). Hereo)depictsan
actualobservation(o)andthepredictedobservationsofthepossibleactionsturnlefti),moveforwardii),and
turnrightiii).
6
P(o˜,z˜,s˜,˜l,π,π˜,π˜)=P(π) (cid:89) P(z ,p0|l )P(l |π)P(π )
l p T T T T l
T
(cid:89)
P(st|z ,pT)P(pT|π ,pT)P(π )
0 T t t l 0 p (7)
t
(cid:89)
P(st |st,at )P(at|π )P(ot,ct|st)
τ+1 τ T τ p τ τ τ
τ
Atthetoplayerofthegenerativemodelyouhavethecognitivemap,asdepictedinFig1a,itoperatesatthe
coarsesttimescale(T). Eachtickatthistimescalecorrespondstoadistinctlocation(l ),integratingtheinitial
T
positions(pT)oftheplace(zT). Theselocationsarerepresentedasnodesinatopologicalgraph,asshownin
0
Fig1d. Astheagentmovesfromonelocationtoanother,edgesareaddedbetweennodes,effectivelylearning
thestructureofthemaze. Tomaintainthespatialrelationshipbetweenlocations,theagentutilisesacontinuous
attractornetwork(CAN),similarto[50],keepingtrackofitsrelativerotationandtranslation. Asaresult,the
cognitive map forms a comprehensive representation of the environment, enabling the agent to navigate and
gainanunderstandingofitssurroundings.
Themiddlelayer,theallocentricmodel,depictedinFig1b,playsavitalroleinbuildingacoherentformu-
lation of the environment, referred to as z . This model operates at a finer time scale (t), generating a belief
T
about the place by integrating a sequence of observations (sT ) and poses (pT ) to create this representation
0:t 0:t
[51, 52]. The resulting place, as shown in Fig 1e and Fig 5, defines the environment based on accumulated
observations. When the agent transitions from one place to another and the current observations no longer
alignwiththepreviouslyformedpredictionoftheplace,theallocentricmodelresetsitsplacedescriptionand
gathers new evidence to construct a representation of the newly discovered room (z ). This advancement
T+1
correspondstoonetickonthecoarsertimescale,andthemid-leveltimescaletisresetto0.
Then the lowest layer is called the egocentric model, shown in Fig 1c, it operates at the finest time scale
(τ). This model utilises the prior state (st) and current action (at ) to infer the current observation (ot )
τ τ+1 τ+1
[38]. Byconsideringitscurrentposition,themodelgeneratespotentialfuturetrajectorieswhileincorporating
environmentalconstraints,suchastheinabilitytopassthroughwalls. Fig1fshowcasesthecurrentobservation
atthecentero)andvisualisestheimaginedpotentialobservationsiftheagentweretoturnlefti),rightiii),or
moveforwardii).
Itisimportanttoobservethatthesethreelevelsoperateatadifferenttimescale. Inspiteofthefactthatthe
full sequences of variables cover the same time period in the environment, the different layers of the models
functionatseparatelevelsofabstraction.Thehigherleveloperatesonacoarsertimescale,implyingthatnumer-
ouslowerleveltime-stepsoccurinasinglehigherlevelstep. Theegocentricmodeloperatesonafine-grained
timescaleτ,andisresponsiblefordynamicdecisionsandpathintegration. Theallocentricmodeloperateson
acoarsertimescaletwhereasequenceofposespoveraperiodoftimetupdatesaspecificlocationplacez .
T
Inthismodel, atanytimet, theposep andplacez cangivebackthecorrespondingobservationo . Atthe
t T t
topmostlayer,thetemporalresolutionislowest,whereasingletickoftheclockcorrespondstoadistinctloca-
tionl,associatedwiththeallocentricmodelatthattime. Thisisdonewithoutaccountingfortheintermediary
time-stepsofthelowerlayers.
Thishierarchicalarrangementallowstheagenttoreasonaboutitsenvironmentfurtherahead,bothtempo-
rallyandspatially. Intemporalterms,planningonestepatthehighestlevel(suchasaimingtochangelocation)
translatestoplanningovermultiplestepsatthelowerlevels,andthispatterncontinuesthroughoutthehierarchy.
Inspatialterms,theenvironmentisorganisedinlevelsofabstraction,becomingmoredetailedasonedescends
thehierarchy(forinstance,fromdetailsofindividualroomstoconnectionsbetweenrooms).
Inthefollowing,wewilldiscussthedetailsofmodelateachlayerofthehierarchy,inabottom-upapproach.
3.4.1 Egocentricmodel
The egocentric model learns its latent state through the joint probability of the agent’s observations, actions,
policies,beliefstatesanditscorrespondingapproximateposterior. Itcomprisesatransitionmodelforfactoring
in actions when transitioning between states, likelihood models for generating pixel-based observations and
estimating collision probability based on the state, and a posterior model for integrating past events into the
presentstate.
7
Figure 2: Generative model for the egocentric level: POMDP depicting the model transition from past and
present(uptotimestepτ)tofuture(fromtimestepτ +1). Astates isdeterminedbythecorrespondingob-
τ
servationo andinfluencedbythepreviousstates andactiona ,generatingthesupplementarycollision
τ τ−1 τ−1
observationc . Theactionaswellasbothobservationsareassumedobservable,indicatedbythebluecolour.
τ
Inthefuture,theactionsaredefinedbyapolicyπ influencingthenewstatesinorangeandnewpredictionsin
grey.
T T
(cid:89) (cid:89)
P(o˜,c˜,s˜,a˜)=P(s ) P(s |s ,a ) P(o ,c |s )
0 τ τ−1 τ−1 τ τ τ
τ=1 τ=1
(8)
T
(cid:89)
Q(s˜|o˜,c˜,a˜)=Q(s |o ) Q(s |s ,a ,o )
0 0 τ τ−1 τ−1 τ
τ=1
Theegocentricmodelcontinuouslyupdatesitsbeliefsaboutthestate(s)byincorporatingthepreviousaction
(a) and the most recent visual observation (o) from the environment [38]. This belief correction process is
describedinEquation8.
Theincorporationofconsecutivestatesformstheshort-termmemoryofthemodel. Itacquiresaninherent
comprehension of the dynamics of the environment through a process of trial and error, interacting with the
environmental frontiers (e.g walls). This learning is accompanied by the notion of action and consequences
introducedbyactiveinference. Theobservationsofthemodelarevisualobservations(o)anddynamiccollision
(c)intheenvironment.
The egocentric model serves as the lowest level of the overall model and is responsible for predicting
the dynamic do-ability of policies. It discards any sequence of actions that are deemed impossible based on
its understanding of the environment. Additionally, the egocentric model plays a crucial role in facilitating
curiosity-drivenexplorationbymakingshort-termpredictionswhentheagentisuncertainaboutthebeliefsof
theallocentricmodel.
3.4.2 Allocentricmodel
The allocentric model is responsible for generating environment states that describe the surroundings of the
agent.ItreliesonGenerativeQueryNetworks(GQN)[51,52].Toformaconceptionoftheagent’senvironment,
itsinternalbeliefabouttheworldisupdatedthroughinteractionswiththeworld,resultinginplace(latentstatez)
structureduponpositions(p)andcorrespondingobservations(o)[51,52]. Thecorrespondingjointprobability
distributionP(z,o˜,p˜)definingrespectivelytheagent’sbeliefstate,observations,andposesandtheapproximate
Posteriorofthisallocentricmodelare:
8
Figure 3: Generative model for the allocentric level as a Bayesian network. One place is considered and
describedbyalatentvariablez. Theobservationso dependonboththeplacedescribedbyz andtheagent’s
t
positionp . From0tot,thepositionshavebeenvisitedandareusedtoinferabeliefoverthejointdistribution.
t
Futureviewpointp hasnotbeenvisitedorobservedyet.Observedvariablesareshowninblue,whileinferred
t+1
variablesareshowninwhite,andpredictionsarepresentedingrey.
T
(cid:89)
P′(z,o˜,p˜)=P(z) P(o |p ,z)P(p )
t t t
t=1
(9)
T
(cid:89)
Q′(z|o˜,p˜)= Q(z|o ,p )
t t
t=0
Thismodelthereforecondenseschunksofinformationintoaconcisedescriptionoftheenvironment.Inthis
paper,wecalloneofthesechunksaplace,butitcouldalsorepresentacontextasdefinedbyNeacsuetal.[40].
Inordertocorrectlycondenseinformationintotheappropriateplace,sequencesofstatesatthelowerlevelare
separatedusinganeventboundarybasedonthepredictionerror.[53,54].Eachformedplace(statez)represents
a static structure of the environment. A dynamic environment will result in new places being generated. The
processofupdatingorgeneratinganewplaceinvolvesevaluatingtheagent’sestimatedglobalpositionwithin
thecognitivemap. Thisassessmentresultsinclosingtheloopiftheplaceisrecognised,orcreatinganewbelief
ifitisnot.
Eachnewplacehasitsownlocalreferenceframe,createdwithabelievedposeasorigin.
3.4.3 Cognitivemap
The cognitive map is responsible for memorising places and matching them with their relative positions in
global space. It does this by creating nodes which we call experience or location. The creation of several
experiencesgeneratesametric-topologicalmapoftheenvironmentallowingthesystemtointegratethenotion
ofdistanceandconnectionsbetweenlocations.
AContinuousAttractorNetwork(CAN)isemployedtohandlemotionintegration. Thisnetworkprocesses
successiveactionsacrosstimesteps,allowingtheestimationoftheagent’stranslationandrotationwithina3D
grid[50]. TheCAN’sarchitecture, featuringinterconnectedunitswithbothexcitatoryandinhibitoryconnec-
tions, emulatesthebehaviourobservedinnavigationneuronsknownasgridcells, foundinvariousmammals
[55],internallymeasuringtheexpecteddifferenceintherobot’spose(i.e. itscoordinatesx,yandrelativerota-
tionoverthez-axis).TheCANwrapsarounditsedges,accommodatingtraversingspaceslargerthanthenumber
ofgridcells. Theactivationvalueofeachgridcellrepresentsthemodel’sbeliefintherobot’srelativepose,and
multipleactivecellsindicatevaryingbeliefsovermultiplehypotheses. Thehighestactivatedcellrepresentsthe
current most likely pose. Motion and proprioceptive translation modify cell activity, while view-cell linkage
modifies activity when a place latent state (z) significantly differs from others. This is determined through a
cosinesimilarityscore.
When an experience is stimulated, it adds an activation to the CAN at the stored pose estimate [42, 56].
Eachnewcombinationofpositionandplace(z)generatedbytheallocentricmodeldevelopsanewexperience
inthecognitivemapthatisrepresentedbynodesinatopologicalgraph. Suchanodeintegratestheviewcell
(place),theposition,andtheposecellofthevisitedlocation[41]. Eachplacereferenceframeismappedinthe
9
cognitive map global reference frame by remembering the local pose origin of the place reference frame and
associateitwiththelocationglobalposition. whentheagentstartsmovingforthefirsttime,theglobalframeis
createdwiththisfirstmotionasoriginoftheglobalreferenceframe.
Whennavigating,contextisconsideredforclosingloops.
Whenthecurrentbeliefalignswithapastexperience’splace,thecorrespondingviewcellactivates. How-
ever,toresolvepotentialaliasing,theagentalsoconsidersitsglobalposition. Ifthepositionisdeterminedtobe
toofarfromthepastexperience(basedonasetthreshold),anewplaceiscreated. Thisnewplacewilladaptto
newvisualinputwithoutaffectingtheexistingviewcellassociatedwiththepastexperience.
3.5 Navigation
Themodelistrainedtolearnthestructureoftheenvironment,andshould,thereforebeabletoaccomplishava-
rietyofnavigatingtask,regulatedthroughactiveinference. Therefore,theagentisabletorealisethefollowing
navigationtaskswithoutneedinganyadditionaltraining.
Exploration. Theagentisabletoexploreanenvironmentbyevaluatingthesurpriseitcangetfrompredicted
paths.
Goalreaching. Theagentcanbegivenanobservationasapreferenceandtrytorecallanypastlocationmatch-
ingthisobservationandplantheoptimalpathtowarditorsearchforit.
To find a suitable navigation policy, we need to evaluate a range of policies, each considering a numer of
actions. Tothisend,wedefinealook-aheadparameter,definingthenumberoffutureactionswhenevaluating
thecandidatepolicy. Asconsidereingeachpossibleactionateachpositionisuntractablewithincreasinglook-
aheadvalues,welimitthesearchtostraightlinepoliciesasshowninFig. 4.
Figure4: IllustrationdepictingL-shapedpathsencompassingtheupperrightquadrantofanareasurrounding
theagent. Thechosenlook-aheaddistanceinthisscenariois2.
Toestablishthoseeffectivepolicies,weimagineasquareperimeteraroundtheagentwithawidthequalto
thedesiredlook-ahead. Thissquareboundaryissubsequentlydividedintosegments,eachregardedasdistinct
objectives. OurcoverageapproachinvolvescraftingL-shapedpathsoriginatingfromtheagent’spositionand
extendingtowardsthesesegmentedgoals. Byincrementallyelongatingthevectorinitiatingfromtheagent,we
ensurethoroughareacoverage. Thisstrategyresultsineverypositionwithinthesquareareabeingapproached
from two divergent directions, as illustrated in Fig 4 within a quarter of the square area. This methodology
allowstoemployextendedlook-aheaddistanceswithoutriskingintractablecalculations.
Once those policies are generated, the egocentric model evaluates their plausibility and truncates any se-
quence of actions leading to a collision with a wall. Using those plausible policies, the agent’s navigation is
guidedbyactiveinference. Whentheagentholdsahighlevelofconfidenceinitsworldbelief,itsactionsare
determined by the variable weights in the following equation, leading it to either explore or pursue a specific
goal.
10
G(π,T,τ)=W ·E [ln(Q′(z |π))−ln(Q′(z |o ,π))]
1 Q′(oτ,zT|π) T T τ
(cid:124) (cid:123)(cid:122) (cid:125)
AllocentricExploration
+W ·E [ln(P′(o |g))]
3 Q′(oτ|π) τ
(cid:124) (cid:123)(cid:122) (cid:125)
AllocentricPreferenceseeking
(10)
+W ·E [ln(Q(s |π))−ln(Q(s |o ,π))]
2 Q(oτ,sτ|π) τ τ τ
(cid:124) (cid:123)(cid:122) (cid:125)
EgocentricExploration
+W ·E [ln(P(o |g))]
4 Q(oτ|π) τ
(cid:124) (cid:123)(cid:122) (cid:125)
EgocentricPreferenceseeking
With Q′ and P′ being the approximate posterior and prior of the allocentric model and Q and P the ap-
proximateposteriorandprioroftheegocentricmodel. Theweightsofthisformulaarearetreatedasadaptive
parameters of the model. If we have a preferred observation g defined, it effectively drives the agent toward
reachingsuchanobservation. Boththeegocentricandallocentricmodelsareusedtoinferthepresenceofthe
objective,usingthesamelogpreferencemechanism. Theegocentricmodelcorrectspossiblywrongmemories
of the allocentric model on the goal position in the immediate vicinity, it out-weights -with W - the allocen-
4
tric model predictions when there is a discrepancy between the two. Therefore while the egocentric model is
trusted to infer the objective in its immediate vicinity, the allocentric model is trusted to search this objective
inmemorythroughallpreviouslyvisitedplaces,fromthelatesttotheoldest. Forlong-termplanningbetween
severalplaces,themodelaimstogettotheplacecontainingthispreferredobservationusingsophisticatedactive
inferenceovertheplacesleadingtowardthegoal. ConcretelyashortestpathalgorithmsuchasDijkstra[57]is
usedtodeterminethequickestpathconsideringthedistancebetweenplaces,thenumberofplacestocross,and
theprobabilityofaconnectionbetweenplaces,allowingforamoregreedyorconservativeapproachdepending
ontheweightweputonprobableandimprobableconnectionsbetweenplaces. Inthiswork,theinferenceisset
asconservative,andunconnectedplacesareconsideredunlikelytoleadtowardtheobjectivefaster. Theagent
movesfromplacetoplacebysettingpositions’observationsleadingfromoneplacetothenextassub-objective
C in eq.10. The agent moves by searching this preferred observation g while considering the direction it is
headedtowardtogenerateappropriatepolicies.
In the absence of any preference, the agent doesn’t prioritise any particular observation, thus the weights
(W and W ) associated with preference seeking in both models are zero, prompting the agent to engage in
3 4
explorationinstead.
Duringexploration,theagentfocusesonmaximisingthepredictedinformationgainbasedontheexpected
posterior. Since the agent considers having a clear understanding of the environment after characterising a
place,theuncertaintyinobservationsbecomeslessrelevant. Aswiththepreferenceseeking,iftheallocentric
model fails to identify a relevant policy to explore new territories, the egocentric model encourages the agent
to venture beyond its familiar surroundings. It is important to recall that a latent state z describes one place
and does not encompass the whole environment. Once the model considers that a place does not explain the
observations anymore it will reset its beliefs and form a new place. To imagine passing from one place to
another,thecognitivemapconsiderstheagent-predictedlocationtoshifttheplaceofreference,thisresultsin
unvisited locations being much more attractive, as they have highly unexpected predictions, in contrast with
visitedplaces. Anexampleofeachlayer’spredictiveabilityisshowninFig.10.
When transitioning between places, the allocentric model’s confidence in the current place drops below a
pre-definedthreshold.Ingeneral,anumberofstepsareneededtobuildupconfidenceontheplacevisitedgiven
theobservations. Duringthisphase,Equation10isnotemployedfornavigation. Instead,ourprimarygoalisto
ascertainthemostaccuraterepresentationoftheenvironment.Toachievethis,theagentformulateshypotheses,
involving new and memorised places z and poses p , which potentially account for the observed data. The
n t
model strives to acquire additional data to converge towards a single hypothesis, accurately determining its
spatialposition.
In order to ascertain the best actions for acquiring observations that aid in convergence, Equation 11 is
appliedtoeachprobablehypothesisn.
11
(cid:88)
G(π,n)=W · E [ln(Q′(z ,p |π)−ln(Q′(z ,p |o ,π))]
Q′(zn,pt|o0:i+t,π) n t n t 0:i+t
t>i(cid:124) (cid:123)(cid:122) (cid:125)
informationgain
(11)
−E (cid:2) ln(P(o )) (cid:3)
Q′(zn,pt|o0:i+t,π) t
(cid:124) (cid:123)(cid:122) (cid:125)
expectedutility
Hypotheses are weighted based on their alignment with the egocentric model’s predictions. A hypothesis
gains weight if its predictions closely match the expected observations. If no hypothesis stands out, they are
consideredequallyprobable.
Whateverthesituationwearein,theleadingpolicyistheninferredthrough:
P(π)=σ(−γG(π)) (12)
Thiseffectivelycasttheplanningasaninferenceproblem,andbeliefsoverpoliciesareproportionaltothe
expected free energy. γ value offering a useful balance as it enables elimination of policies that are highly
unlikely,improvingefficiencyofplanningwhilealsobeingrelativelyconservative[47].
3.6 Training
In order to effectively train this hierarchical model, the two lower level models are considered independent
andtrainedinparallel. Tooptimisethetwoego-allocentricneuralnetworkmodelswefirstobtainadatasetof
sequencesofaction-observationpairsbyinteractingwiththeenvironment. Thiscanbeobtained,forinstance,
using a random policy, A-star-like policies, or even by human demonstrations. In this paper, the model was
trainedonamini-gridenvironmentconsistingof3by3squaredroomsof4to7tileswideconnectedbyaisles
of fixed length randomly placed, separated by a closed door in the middle. Each room is assigned a colour
at random from a set of four: red, green, blue, and purple. In addition, white tiles may be present at random
positions in the map. The agent could start a training sequence from any door (or near door) position. The
trainingwasrealisedon100environmentsperroomwidthgoingfrom4tilesto7tiles. Theagenthasatopview
of the environment covering a window of 7 by 7 tiles, including its own occupied tile. It cannot see behind
itself, nor through walls or closed doors. The observation the agent interprets is an RGB pixel rendering of
shape3x56x56(seeAppendixB.3Fig17foranillustrationofanobservation). Theallocentricmodelistrained
on 1000 sequences per room size (4 to 7 tiles), each sequence has a random length of between 15 and 40
observations in a room that is separated between learning the room structure and predicting the observations
giventheposeandlearnedplace(posterior). Themodelisoptimisedthroughtheloss:
T
(cid:88)
L= D [Q′ϕ(z|o ,p )||N(0,1)]+||oˆ −o ||2 (13)
KL t t t t
t=0
TheapproximateposteriorQ’ismodeledbythefactorisationoftheposteriorsaftereachobservation. The
belief over z can then be acquired by multiplying the posterior beliefs over z for every observation. We train
an encoder neural network with parameters ϕ to enable the determination of the posterior state z based on
a single observation and pose combination (o ,s ). The likelihood is optimised using Mean Square Error
k k
(MSE),whichinvolvestherealobservationo andthepredictedobservationoˆ [52]. Todetermineaposition,
k k
theagent’sactionisincorporatedintothesubsequentpositionbeforebeingshuffledforpredictions.
Theegocentricmodelistrainedon100sequencesof400stepsperroomsize,eachfullsequenceiscutinto
sub-sequencesof20steps. Ateachstepthemodelpredictswhattheobservationshouldbeandcomparesitto
therealobservation,improvingitsposteriorandpriormodelparametersθandϕthroughthelossfunction:
T
(cid:88)
L= D [Q (s |s ,a ,o )||P (s |s ,a )]−log[P (o |s )] (14)
KL ϕ t t−1 t−1 t θ t t−1 t−1 ξ t t
t=1
Thismodelistrainedbyminimising,inonepart,thedifferencebetweentheexpectedbeliefstategiventhe
coupleaction,previoushistory,andtheestimatedposteriorobtainedgiventheaction,observation,andupdated
history. And in the second part by minimising the difference between the reconstructed observation and the
inputobservation[25],effectivelyoptimisingthelikelihoodparametersξ. Boththeegocentricandallocentric
modelsareoptimisedusingAdam[58].
Thecognitivemap, originallydesignedfornavigationinmini-gridenvironments[26], canbere-scaledor
adaptedtodifferentenvironmentswithouttheneedforadditionaltraining.
12
4 Results
The objective of this paper is to propose a navigation model based on active inference theory in new similar-
lookingenvironmentstowhichtaskrequirementscouldbeadded. Thereisnodefinitebenchmarktoassesstask
agnosticmodels,thusourmodelisevaluateduponitsparticularabilityto:
• Imagineandreconstructtheenvironmentstheagentvisited
• Createpathsincomplexenvironments
• Disambiguatevisualaliases
• Usememorytonavigate
In addition, the ability to explore an environment as well as goal-reaching capabilities are compared to
competingapproaches.
The model is tested in diverse mini-grid maze environments composed of connected rooms. Our agent is
modelledtoachieveautonomousnavigationgivenonlypixel-basedobservations.
Toevaluatetheeffectivenessoftheproposedmodel, aseriesoftestshavebeenrealised, eachfocusingon
aspecificaspectofthemodel. Thoseexperimentsrangefromevaluatingthemodelscomposingthesystemto
assessingitsoverallnavigationperformance. Eventhoughthetestinggroundsaresimilartothetrainingset,all
thetestswereperformedonenvironmentstheagentneversawduringtraining.
4.1 Spacerepresentation
Themodel’scapacitytodescribetheobservedplaceiscriticaltoenablehigher-levelinferences. Therefore,the
fewerobservationsitrequirestoachieveconvergencetoanaccurate, orattheveryleast, distinctiverepresen-
tation of the environment, the more effectively it can recognise a place and navigate through it from various
viewpoints. Themodel’srapidconvergenceiscrucial,butitalsoneedstomaintainadaptability,whichinvolves
thecapabilitytoincorporatenewinformationabouttheplaceinitsbelief(suchasdiscoveringnewcorridors).
Thefollowingtwofiguresdemonstratetheplacerepresentationaccuracyandconvergencespeed.
Figure5illustratestheinferenceprocessofplacedescriptions. Withinapproximatelythreesteps,themain
features of the environment are captured reasonably accurately based on the accumulated observations. Even
when encountering a new aisle for the first time at step 11, the model is able to adapt and generate a well-
imaginedrepresentation. Eachobservationcorrespondstotheredagent’sclearfieldofview,asdepictedinthe
agentpositionrow(2ndrow)ofthefigure(moredetailsabouttheobservationsAppendixB.3).
Figure5:Evolutionoftheplacerepresentationinaroomasnewobservationsareprovidedbythemovingagent
(redtriangle). Themodelisabletocorrectlyreconstructthestructureoftheroomasobservationsarecollected.
Fig6showstheagentconsistentlyachievingastableplacedescriptionwithinaroundthreeobservationsin
roomsizespartofitstraining. Interestingly,theagentalsoexhibitstheabilitytoaccuratelyreconstructlarger
rooms, even though it did not encounter such sizes during training. In particular, stable place descriptions
for 8-tile wide rooms are attained in approximately five steps. This showcases the agent’s allocentric model
generalisation abilities beyond the limits of its training. The experiment was conducted over 125 runs in 25
environmentswiththeagenttaskedtopredictobservationsfromunvisitedposesaftereachnewmotion. Fig7
demonstratethesignificanceoftheMSEvalue,usedasmetricforthisexperiment,bydisplayingexamplesof
13
Figure6:Predictionerrorofunvisitedpositionsover25 Figure7: Observationgroundtruth,predictedob-
runsbyroomsizestartingfromstep0wherethemodels servationandMSEbetweenobservations
hasnoobservation.
predictedobservationsandtheirattributedMSEvalues. Inourexperimentswesetthethresholdto0.5inorder
tosettleonaplacetoimproveoversuccessivesteps.
Themodeldemonstratesitsabilitytodifferentiateemptyroomsbasedontheirsize,colourandshape.
4.2 Navigation
Our navigation tests are focused on evaluating the model’s ability to complete a well-defined task, such as
forming a spatial map through exploration in an aliased environment. The agent is set to perform two tasks,
environmentexplorationandgoalreaching,withoutanyadditionaltrainingafterlearningfamiliarroomsstruc-
ture.
Baseline. Toestablishabaselineforthenavigationtasks,wecompareourmethodagainst:
• C-BET[16],anRLalgorithmcombiningmodel-basedplanningwithuncertaintyestimationforefficient
explorationdecision-making.
• RandomNetworkDistillation(RND)[59],integratesintrinsiccuriosity-drivenexplorationtoincentivise
theagent’svisitationofnovelstates,meanttofosteradeeperunderstandingoftheenvironment.
• Curiosity[60],leveragesinformationgainasanintrinsicrewardsignal,encouragingtheagenttoexplore
areasofuncertaintyandnovelty.
• Count-based exploration [61] uses a counting mechanism to track state visitations, guiding the agent
towardlessexploredregions.
• Dreamerv3[5]representsanadvancediterationofworldmodelsforRL,offeringthepotentialtoenhance
navigationbypredictingandsimulatingfuturetrajectoriesforimproveddecision-making.
• A-starAlgorithm(Oracle)[62],isapathplanningalgorithmtowhichthefulllayoutoftheenvironment
anditsstartingpositionisgiventoplantheidealpathtotakebetweentwopoints.
EachofthesemodelsproposedifferentRLbasedexplorationstrategiesforroboticsnavigation.Allbaselines
havebeentrainedandtestedontheexactsameenvironmentsasourmodel. Foreachmodeltrainingdetails,we
refertoAppendixB.
Thetestenvironmentsconsistofmaze-likeroomsthatprogressivelyincreaseinscale,rangingfrom9rooms
upto20rooms,allwithawidthof4tiles.
4.2.1 Explorationbehaviour
Weevaluatetowhichextentthehierarchicalactiveinferencemodelenablesouragenttoefficientlyexplorethe
environment. Without a preferred state leading the model toward an objective, the agent is purely driven by
epistemicforaging,i.e. maximisinginformationgain,effectivelydrivingexploration [23].
Our evaluation involves comparing the performance of our model against various models such as C-BET,
Count,Curiosity,RNDmodels,andanOracle. Thesemodelsaretaskedwithexploringfullynewenvironments
14
withconfigurationsrangingfrom9to20rooms. Whiletheoraclepossessescompleteknowledgeoftheenvi-
ronment and its initial position, other models are only equipped with their top-down view observations (and,
inthecaseoftheRLmodels,extrinsicrewards). TheRLmodelsareencouragedtoexploreuntiltheylocatea
predefinedgoal(whitetile);however,therewardassociatedwiththewhitetileismutedtoencouragecontinued
exploration. Notably, the DreamerV3 model faces challenges in effective exploration due to its reliance on
visualobservationsofthewhitetileforrewardextraction. Consequently,anadaptedenvironmentwithoutthe
whitetileorspecifictrainingwouldbenecessarytoemployDreamerV3asanexploration-orientedagentinthis
study.
Acrossmorethan30runsbyenvironmentscale,ourmodeldemonstratesefficientexploration,intermsof
coverage and speed, comparable to C-BET and notably outperforming other RL models in all tested environ-
ments, as depicted in Fig 8 where we can see the percentage of area covered along steps in the environment.
Moreover,theagentsuccessfullyachievesthedesiredlevelofexplorationmorefrequentlythananyothermodel
acrossallconfigurations,asdemonstratedinTable2.Foranexplorationattempttobeconsideredsuccessful,the
agentsmustobserveaminimumof90%oftheobservableenvironment.Thiscriterionensuresthatallroomsare
observedatleastonce,withoutimposingapenaltyonthemodelsfornotcapturingeverysinglecorner. Since
theagentscannotseethroughwalls(seeAppendixB.3),enteringaroommayresultinmissingtheadjacentwall
corners, butthesecornersholdlimitedimportancefortheagent’sobjective. Asanunlikelyexample, missing
allthecornertilesofeachroomresultsin9%oftheenvironmentnotbeingobserved(thusnomatterthescale
oftheenvironment). Inthisexplorationtask,theoraclestopsexploringassoonastheexplorationtaskisdone
(exploring90%ofthemaze)ascanbeseenFig8,givingagoodideaofwhattheidealexplorationshouldlook
likeandthethresholdtheyhavetoreach. However, tofurtheranalysethem, theotheragentsarerequestedto
continueexploringuponcompletionofthetask,thusleadingtoover90%maze’scoverageinthefigures.
(a)coverageastheexplorationprogressofallmodelsin3by(b)coverageastheexplorationprogressofallmodelsin3by
3roomsenvironments 4roomsenvironments
(c)coverageastheexplorationprogressofallmodelsin4by(d)coverageastheexplorationprogressofallmodelsin4by
4roomsenvironments 5roomsenvironments
Figure8: Theaverageexplorationcoverageacrossalltestinstances(>30runs)foreachmodelcomputedfora
givenenvironment’sscale. Theoraclestopsexploringassoonastheexplorationtaskisdone(exploring90%
ofthemaze).
15
success
models
rate(%)
environment
ours C-BET RND curiosity count
configuration
3x3rooms 93 81 16 32 13
3x4rooms 94 87 16 19 0
4x4rooms 91 81 26 16 0
4x5rooms 81 74 7 23 3
Table2: Thesuccessrateofeachmodelacrossallrunsineachenvironmentisdefinedasthepercentageofruns
wheretheexplorationcoversatleast90%oftheenvironment.
4.2.2 Preferenceseekingbehaviour
To evaluate the exploitative behaviour of the models, we configure all the models mentioned in the baseline
to navigate towards the single white tile within the environment. This is conducted across environments of
increasing size, ranging from 9 to 20 rooms. Goal-directed behaviour is induced in our model by setting a
preferred observation (i.e. the white tile) as typically done in active inference [23, 1]. In our model, the
reference for the white tile within the environment is not explicitly provided. Instead, the model is tasked
with the objective of identifying a white tile based on its conceptual understanding of what the colour white
represents.Thisapproachenablesthemodeltosearchforandrecognisewhitetilesinitsgeneratedobservations
withoutdirectaccesstotherealobservationinthetestedenvironment. IntheotherRLmodels,anextrinsicand
intrinsicrewardisassociatedwiththiswhitetileintheenvironment,motivatingtheagentstoexploreuntilthey
reach this tile. The task is considered successful when the agent steps on the single white tile of the maze.
A run is considered a failure if the agent has not reached the goal in under X number of steps, X depending
on the world size. All the models, except the oracle, start without knowing their and the goal position in the
environment. Theyneedtoexploreuntiltheyfindtheobjective. Fig9displaysalltheresultsbyenvironments.
Thefirstcolumnshowshowmuchthemodelsexploreinaveragebeforereachingthegoalandtheirsuccessrate
indiverseenvironments. Ourmodelrequires,onaverage,fewerstepsthantheothermodelstoreachthegoal,
withtheexceptionoftheCountmodel. However,wecanobservethatCountalsohasthelowestsuccessrate.
TheCountmodeloftenfailstoreachthegoalwhenitrequirescrossingseveralrooms.Overallourmodelreaches
thewhitetile89%ofthetimeoverallenvironments(seeTable3),Dreamerv3isshowingapoorperformance
becauseofover-fitting,notadaptingwelltonewroomsconfigurationsandwhitetileplacementithasneverseen
duringtraining. ThisobservationsuggeststhatDreamerv3mightrequireeitheracomparativelyhigherdegree
ofhumaninterventionoranextendeddatasettoeffectivelyoperatewithinourenvironmentcomparedtoother
models.
Thesecondcolumnillustratestheproportionofgoalattainmentasthenumberofstepsprogressesrelatively
totheoracle’soptimaltrajectory,normalisedforcomparison.Ourmodelstandsamongthemostefficientmodels
toreachthegoalrapidly,with80%oftherunsreachingtheobjectiveinlessthantentimesthestepstakenby
theoracleinmostenvironments,exceptionmadeforthe4by5roomsmazes.
Finallythethirdcolumnprovidesadditionalinformationabouttheproportionofsuccessandfailureaccord-
ingtotherelativenumberofstepstheoracleneedstoreachthegoal. Fromthisplotwecanobservethatmost
models are more likely to fail when the goal is far from the starting position. Our model, C-BET, Count and
Curiosity models show some failures at relative step 0 or before. It can be linked to the model returning an
errorduetoexcessiveCPUconsumption(inthecaseofC-BET,CountandCuriosity)orbytheagentbelieving
anon-whitetiletobewhiteandstickingtoit,terminatingthetask.
Ourmodelcapacitytore-localiseitselfafterpositionaldisturbancesallowsustoconductasupplementary
experiment we call ”ours wt prior”. After permitting the model to explore the environment, we teleport the
agentbacktoitsinitialpositionandtaskitwithseekingthegoal. Thisexperimentalsetupisexclusivetoour
model, which relies on a topological internal map for localisation. In contrast, other models in the baseline
dependonsequentialmemory.
Intuitively,onemightexpectthemodeltoachievethegoalmoreefficientlyduetoitsinternalmap. Effec-
tively, we observe that in 3 by 3 rooms mazes, 80% of successful runs reach the goal in less than three times
thestepstakenbytheoracle,over86%successfulrunsintotal. However,theoverallsuccessrateislowerthan
thegoalseekingexperimentswithoutaprior. Thisdiscrepancyarisesfromvariousfactorssuchasthequality
ofthemapandnavigationerrors. Themapgeneratedduringexplorationcansometimesbeimprecise,leading
16
(a)3by3roomsenvironments.
(b)3by4roomsenvironments.
(c)4by4roomsenvironments.
(d)4by5roomsenvironments.
Figure 9: For environments ranging from a) 3∗3 to d) 4∗5 rooms, results are presented in three graphs. The
firstcolumndisplaysgoal-reachingsuccessratesandaveragesteps. Thesecondcolumnillustratesnormalised
deviationsofeachmodel’sperformancecomparedtotheoracle,whilethethirdcolumnshowsthedistribution
ofsuccessandfailurebasedonnormalisedstepdeviationscomparedtotheoracle.
the agent to form erroneous assumptions about the location of the objective or guiding it along sub-optimal
paths. Whenthemodelseeksagoalwhilehavingapriorunderstandingoftheenvironment,itmightpursuesan
incorrectobjectiveapproximately35%ofthetime. Incontrast,withoutanypriorknowledge,theagentchases
anerroneousobjectivearound29%ofthetimeoverallenvironmentsandruns. Additionally,theagentseeksa
paththatsurelyleadstotheobjective,anddoesn’textrapolateoverpossibleshortcuts. Thereforeiftheshortest
pathleadingtothegoalgoesthroughroomsthatarenotdirectlyconnectedinthecognitivemap,thepathwon’t
beoptimal. Furthermore,theagent,guidedbyitspriors,maynotrecognisearoomwhileprogressingtowards
17
the goal. This can result in the creation of a new experience that lacks proper connections to nearby rooms.
Consequently,theagentmightattempttoestablishlinkswithfamiliarroomsorbacktrackinanefforttoreach
theroomitdidn’tinitiallyrecognise. Wastingstepsonthosetasks. Theagent’sdependenceonstochasticset-
tingscanleadtobothfailuresandsuccessesinsimilarsituations,accountingforthesevariedoutcomes.Despite
that,thesettingshowspromisewithasuccessratecomparabletoothermodels.
Ours
Models Oracle Ours C-BET RND Curiosity DreamerV3 Count
wtprior
successrate(%) 100% 89% 86% 81% 79% 76% 72% 31%
Table3: Thesuccessrateofeachmodelacrossallenvironmentsandruns.
4.3 Qualitativeassessments
Visualassessmentsofaspecificenvironmentareconductedtogaininsightsintothebenefitsofusingacognitive
mapfornavigation. Theseassessmentsalsoinvolveevaluatingthegeneratedcognitivemapsincomparisonto
the actual environment. Additionally, we compare exploration paths taken by various models to gain insights
intotheirnavigationstrategies.Eventhoughthatisbutafewsituations,itallowsdeeperinsightintounderstand-
ingthegeneralbehaviourofthemodels,includingourown,sheddinglightontheirnavigationcapabilitiesand
the accuracy of our model internal representation. Additional evaluation of our model’s system requirements
duringthetestsisavailableintheAppendixA.
Figure 10: A trajectory leading toward a previously visited room is imagined by each model’s layer. From
bottom to top, the egocentric model, characterised by its short-term memory, gradually loses information as
timeprogresses. Thisisevidentfromstep2onward,wherethefrontaisleisnolongerpresentaftertheagent
makes a few turns without visual input. In contrast, the allocentric model maintains the place description
over time but encounters difficulty once it moves beyond the current place it occupies. The cognitive map,
possessingknowledgeoftheconnectionsbetweenlocations,accuratelydeducestheexpectedplacebehindthe
door,resultinginapredictionremarkablysimilartothegroundtruth.
Our hierarchical model facilitates accurate predictions over extended timescales where the agent navigate
betweendifferentrooms. Incontrast, recurrentstatespacemodelscommonlystrugglewhentaskedtopredict
observationsacrossroomboundaries[51]oroverlonglook-ahead[41]. Fig10illustratesthepredictioncapa-
bilitiesofeachlayeroveraprolongedimaginedtrajectorywithinafamiliarenvironment. Thefigureshowcases
thepredictionsthateachlayerofthemodelcreateasweprojecttheimaginationintothefuture,uptothepoint
oftransitioningtoanewroomandbeyond.Thelastrowdemonstrateshowtheegocentricmodelgraduallyloses
18
thespatiallayoutinformationovertime,makingitmoresuitableforshort-termplanning. Thethirdrowhigh-
lightstheallocentricmodel’slimitationtoasingleplaceintheenvironment,failingtorecognisethesubsequent
roomgivencurrentbeliefs. Lastly,inthesecondrow,thecognitivemap’simaginedtrajectoryaccountsforthe
agent’slocationandiscapableofsummoningtheappropriateplacerepresentationwhileestimatingtheagent’s
motionacrossspaceandtime. Thefirstrowdisplaysthegroundtruthtrajectory,whichalignsquitecloselywith
theexpectationsofthecognitivemap.
In order to navigate autonomously, an agent has to localise itself and correct its position given the visual
informationandhisinternalbeliefsovertheplace.Weperformednavigationinanhighlyaliasedmini-gridmaze
composedof4connectedroomshavingeitherthesamecolour,thesameconfigurationorthesamecolourand
configurationbutasinglewhitetileofdifference,those4roomsaredepictedinFigure11A.ThefullFigure11
illustratestheagent’sexplorationoftheroomsanditsabilitytodistinguishthemwithoutgettingconfusedwhile
enteringroomsbyadifferentaislethanpreviously.
Figure11:Navigationsamplesoftheagentloopingclockwiseandanti-clockwise(thusenteringfromadifferent
door)inanewenvironmentof2by2roomsover142steps. Theclockwisenavigationcorrespondstoafully
newexplorationgeneratingnewplaces(seeC.)whiletheanti-clockwiseloopleadsthroughexploredplaces.A.)
anewworldcomposedof4closelookingrooms(colouror/andshapes),B.)themodelassociatedeachroomto
adifferentexperienceidcorrespondingtotheplaceC.)theprobabilityofanewplacebeingcreated(inblue,the
mostprobableplaceamongallpossibilities)oranexistingplacebeingdeemedthemostprobabletoexplainthe
environment.Thegreybarsrepresenthowmanynewplacesareconsideredatonce,thenumberofsimultaneous
hypothesisbeingconsideredcanbereadontherightpartoftheplot. D.)theimaginedplacegeneratedforeach
experienceid. Wecanseethatexperience1isnotfullyaccurate,yetitisenoughtodistinguishitfromtheother
roomsgivenrealobservationsofit.
Effectively, when the agent identifies a new place, it creates a new experience for it by considering its
location, Figure 11 B. displays each newly generated experience by a distinct id and colour. To determine
whether it enters a new place or comes back to a known one, it considers the probability of each place to
describethecurrentobservationsascanbeseeninFigure11C.Thebarsrepresenthowmanyhypothesesare
considered at each step and the lines represent the probability of the place being a new one or a previously
visitedone. ThecolourofthelinescorrespondstotheexperienceattributedcolourinFigure11B.,bluelines
beingnewunidentifiedplaces.Figure11D.displaystheinternalrepresentationoftheplacestheagentuses.We
canseethattheroomsareaccuratelyimagined,andevenanhesitationinanaislepositioninexperience1isnot
enoughtolosetheagent.
Inthiscontexttheagentwasabletosuccessfullynavigateanddifferentiatebetweenroomsinanovelhighly
aliasedenvironment. Theagent’sabilitytorecognisepreviouslyvisitedroomsevenwhenenteringfromanew
doorindicatesitscapabilitytomaintainaspatialmemoryoftheenvironment.
Extending the experiment depicted in Fig 11, Fig 12 presents the complete trajectory’s information gain
according to the model. The graph exhibits a distinct pattern when exploring or exploiting, with the agent
initiallyexploringthefourrooms,asindicatedbythefluctuatingblueline,thenretracinghispathinidentified
rooms,indicatedbycoloursrelativetotheirID.Theinformationgainincreasesastheagententersanewroom,
19
remains relatively steady while traversing within a place, and decreases during transitions between different
places. Whentheagentretracesitsstepsataroundstep100,theinformationgainbecomesminimal,indicating
thattheagenthasalreadygainedknowledgeabouttheselocations. Theinfogainishigherorlowerdepending
onhowwellhepredictedthenextobservation,meaningthebetterhisinitialbeliefovertheplaceis,thelower
themaximumaccumulatedinfogain.
Throughoutitsexploration,theagent’scuriosityplaysapivotalrole,highlightingthesignificanceofinfor-
mationgainindirectingtheagent’sexplorationtowardsunvisitedareasratherthanrevisitingfamiliarplaces.
Figure12: Infogainofeachvisitedplace. Thebluecurvecorrespondtoanewplacebeingvisited, whilethe
colouredcurvescorrespondtopreviouslyvisitedplacesaspresentedinFig11. Thefirst100stepscorrespond
totheexplorationoftheagentof4differentrooms,whiletherestofthenavigationcorrespondtothere-visiting
ofthoseplaces. Theinfogaininapreviouslyvisitedplaceismuchlowerthaninanewroom.
Figure13providesadirectcomparisonbetweentheaccuracyofthecognitivemap’sroomreconstructionand
thecorrespondingphysicalenvironment.Thiscomparisonrevealsthattheestimatedmapcloselyalignswiththe
actualmap,withonlyminordiscrepanciesobservedinsomeblurrypassagewaysandaslightmisplacementof
theaisleinthebottomrightroom. Thisshowshowimportantglobalpositionestimationisasthecognitivemap
uses believed locationto distinguishbetween twoclosely lookingrooms (purplerooms inthe secondcolumn
orblueroomsinthirdcolumn). Thisalignmentbetweenrealandimaginedmapunderscoresthefidelityofour
model’sinternalrepresentationincapturingthestructurallayoutoftheenvironment.
(a)Groundtruthmapofanenvironment. (b)Reconstructionbythehierarchicalmodel.
Figure13: a)displaystherealmapwhileb)isacompositionofacognitivemaproom’srepresentations.
A correct internal mapping and layout structure definition allows our model to exhibit sensible decision-
makingwhenitcomestoexploringtheenvironment. Figure14presentsanillustrativeexampleofpathgener-
ation for each exploration model in the same environment. The paths are represented by consecutive discrete
stepsfromonetiletothenext,withtheprogressionfromblack(initialsteps)towhite(finalsteps). Theoracle
Fig14ashowsthemostidealpathtoobserve95%oftheenvironment. Althoughlackinginitialknowledgeof
the overall environment layout, our model demonstrates intriguing behaviour, as evidenced in Figure 14b. It
exhibits a looping pattern, passing from the third to the first room. Upon realising the familiarity of the first
room,themodelsubsequentlyaltersitscoursetoreturntothethirdroomthenexplorethefourthroominstead.
Itresultsinacompleteexploration(100%ofthetilesobserved)in212steps,151stepslessthanC-BETFig14c.
20
TheCountmodeldisplaysitsinabilitytointelligentlytakesdoorstoreachnewrooms,over-exploringthesame
environmentagainandagain. It’sinefficiencyprobablycomingfromtheobservationsbeingveryaliased.
(a)Oraclepath, observed95%(561tiles)ofthemazein145(b) Our model path, observed 100% of the environment in
steps. 212steps(585tiles).
(c)C-BETmodelpath,observed100%oftheenvironmentin(d)Curiositymodelpath,observed100%oftheenvironment
363steps(585seentiles). in400steps(585seentiles).
(e)RNDmodelpath,observed62%oftheenvironmentin900(f) Count model path, observed 40% of the environment in
steps(364seentiles). 900steps(235seentiles).
Figure14: Pathstakenbyeachmodelduringanexplorationruninthesame3by4roomsenvironment.
Ourstudydemonstratesthecapabilitiesofouragenttoidentifyroomsrapidly,navigatetonewplacesand
back,whileresolvingaliasesandrecognisingpreviouslyvisitedenvironmentsevenwhenenteringfromanew
21
location.
5 Discussion
The discussion section of this paper aims to provide a comprehensive analysis of the proposed hierarchical
activeinferencemodelforautonomousnavigation,consideringitsstrengthsandlimitations. Weoutlinethekey
contributionsofourworkanddiscussthepotentialfutureworks.
Hierarchical Active Inference Model. Our proposal introduces a three-layered hierarchical active infer-
encemodel:
• Thecognitivemapunifiesspatialrepresentationandmemoriseslocationcharacteristics.
• Theallocentricmodelcreatesdiscretespatialrepresentations.
• Theegocentricmodelassessespolicyplausibility,consideringdynamiclimitations.
These layers collaborate at different time scales: the high level oversees the whole environment through lo-
cations, the allocentric model refines place representations as it change position, and the egocentric model
imaginesactionconsequences.
LowComputationalDemands. Ourhierarchicalactiveinferencemodelhasalowcomputationaldemands
regardlessoftheenvironment’sscale. Thisefficiencyisparticularlyvaluableasenvironmentsscaleup,making
ourapproachapotentialsolutionforreal-worldapplications.
Scalability. Ourmodelefficientlylearnspatiallayoutsandtheirconnectivity. Thereexiststhepotentialfor
ourapproachtoadapttonovelscenariosbyincorporatingdiverseenvironmentsintoitslearningprocess, thus
expandingallocentricrepresentations.Furthermore,thepossibilityofintroducingadditionalhigherlayerscould
facilitategreaterabstraction,transitioningfromroom-levellearningtobroaderstructuralinsights.
TaskAgnostic. Thesystemdoesn’trequiretask-specifictraining,promotingadaptabilitytodiversenaviga-
tionalscenarios. Itlearnsenvironmentstructuresandgeneralisestonewscenarios,demonstratingapplicability
tovariousobjectives.
Visualbasednavigation. Leveragingvisualcuesshouldenhanceourmodel’sreal-worldapplicability.
AliasingResistant. Weshowresistancetoaliases,distinguishingbetweenidenticalplacesandthusideally
supportingrobustnavigation.
Whileourapproachoffersseveraladvantages,itisalsoimportanttoacknowledgeitslimitations:
Environment Adaptation Our model requires adaptation to fully new environments for optimal perfor-
mance. Training the allocentric model on room-specific data restricts navigation to familiar settings. To
mitigate this, and generalise to arbitrary environments, we could consider splitting the data by unsupervised
clustering[63],orbyusingthemodel’spredictionerrortochunkthedataintoseparatespaces[64].
RecognitionofChangedEnvironmentsOurproposalmightstruggletodetectenvironmentalchangeslike
altered tile colours, although this may not significantly impact navigation performance as a new place will
replaceorbeaddedwiththepreviousoneinthecognitivemap,itremainsanareaforimprovement.
Inlightofthesecontributionsandlimitations, ourworkoffersaprincipledapproachtoautonomousnavi-
gation. Theintegrationofhierarchicalactiveinferenceandworldmodellingenablesouragenttonavigateand
exploreanenvironmentefficiently. Ourmodelfocusesonlearningenvironmentstructureandleveragingvisual
cues,aligningwiththewayanimalsnavigatetheirsurroundings,contributingtoitsreal-worldapplicability.
Our experimental evaluation in mini-grid room maze environments showcases the effectiveness of our
method in exploration and goal-related tasks. When compared to other Reinforcement Learning (RL) mod-
elssuchasC-Bet[16],Count[61],Curiosity[60],RND[59],DreamerV3[5],ourhierarchicalactiveinference
worldmodelconsistentlydemonstratescompetitiveperformanceinexplorationspeedandcoverageaswellas
goalreachingspeedandsuccessrate. Moreover,qualitativeassessmentsshowhowaccuratecanthecognitive
mapbecomparedtotherealenvironmentandhowtheagentisabletodifferentiatealiasinganduseinformation
gaintooptimisenavigation.
Ourcomprehensiveassessment,bothquantitativeandqualitative,underscorestheadaptabilityandresilience
of our approach. As we move forward, there are several avenues for future research. The model’s adaptation
to new environments could be optimised, and methods for handling changes in familiar environments can be
explored further. Additionally, exploration and goal-seeking tasks could be improved by adding a layer of
comprehension to our cognitive map by integrating possible unexplored rooms when planning, in the form
of potential places to visit [65]. Finally, the scalability and flexibility of our hierarchical structure could be
22
extended to more complex, dynamic or realist scenarios such as Memory maze [66] or Habitat [67] to step
towardrealapplications. Thusrequiringtoconsidernewchallengesinplacedetermination.
Inconclusion,bycombiningprinciplesofactiveinferenceandhierarchicallearning,ourhierarchicalactive
inference model presents a preliminary solution holding promise to enhance autonomous agents’ ability to
navigatecomplexenvironments.
Acknowlegment
A Additional Tests Analysis
Whentheagentfacesadoor,itopensautomaticallyandclosesoncetheagentisnolongerfacingit(eitherby
passingthroughorturningaway). Thisfeatureallowstheagenttofocusonitsmotionbehaviour.
Among all the reinforcement learning (RL) models used in this study, an increase in the number of steps
directlycorrespondstolargermemoryusage,whichoftenresultsinfailureifmemorycapacityisinsufficient.In
contrast,ourapproachoffersasolutionthatisnotablymoreefficient,requiringmaximum1Gofmemoryspace
and avoiding scalability concerns associated with environment size. See Table 4 for a layout of the highest
requirementsnecessaryforanexploration/goaltaskofmaximum1500steps. Independentlyofthoseresults,it
seemsrelevanttoremarksthatallofthoseevaluatedsystemsareslow. TheRLmethodsgrowsslowerwiththe
numberofsteps,thankstothememorybuffer. Whileourmethodisslowbecauseofthehypothesiscalculations
andpoliciesevaluationsthatarenotparalleledandcangrowlarge,dependingonthesetspacedimensionsand
look-ahead.
used
model n◦CPU n◦GPU
Memory(G)
Ours 2 0 1
Dreamerv3 2 1 28
C-BET 2 0 12
RND 2 0 9
Curiosity 2 0 11
Count 2 0 8
Table4: Everymodelexhibitsdistinctsystemrequirements,thefollowingtablehighlightsthemostdemanding
criterianecessaryforachievingsuccessfulexplorationorgoalseekingacrossthe4by5roomsenvironments’
configuration.
B Training Procedures
Each model necessitated specific considerations, which we will outline below. We’ll start with an overview
of the training system (see Table 5), followed by a description of the hyperparameters used for each model,
highlighting any deviations from their source paper, finally we will describe the observations used for each
system.
B.1 SystemsRequirements
Each system required different training time to reach the optimal behaviour. All the other RL models were
trainedtooptimisetheirpolicycontrarilytooursthathadarandommotioninordertolearnthestructureofthe
environment.
23
Training used used
model n◦CPU n◦GPU GPUtype
time(h) RAM(G) Memory(G)
Ours
32 4 1 12 GTX980
egocentric
Ours
95 2 1 2.5 20 GTX1080
allocentric
Dreamerv3 411 5 2 10 30 GTX1080Ti
C-BET 232 10 1 2.6 32 GTX980
RND 117 6 1 2.7 10 GTX980
Curiosity 90 6 1 3 10 GTX980
Count 141 6 1 2.7 11 GTX980
Table 5: Training characteristics for considered models. insights into the training specifics of all models are
provided,encompassingtheirrespectivetrainingdurationuntilreachingtheirfinalisedversions. Unfortunately,
theinformationpertainingtotheRAMutilisationbytheegocentricmodelisunavailable.
B.2 Dataset
Uniformityintrainingconditionswasachievedbyconductingtrainingsessionsforallmodelswithinidentical
environments, facilitated by the consistent application of a shared seed to generate these environments. The
training environments consisted of mini-grid room mazes of 3 by 3 rooms configuration. These mazes were
characterisedbyarangeofroomsizes,spanningfrom4-tilewidthto7-tilewidth, therebyconstitutingatotal
of100distinctroomsperroomsize.
B.3 Hyper-Parameters
All the benchmark models were trained using pre-set hyper-parameters, with C-BET, Count, Curiosity and
RNDusingParisietal.[16]describedparameters. DreamerV3usesHafneretal.[5]proposedwork,however
the behaviour was modified from the original, setting an Exploring task behaviour and a Greedy exploration
behaviourastheoriginalconfigurationwasunderperforminginourscenarios.
Our model was trained using the hyper-parameters in Tab.6 for the allocentric model and Tab.7 for the
egocentricmodel
Layer Neurons/Filters Stride
PositionalEncoder Linear 9
Convolutional 16 1//(kernel:1)
Posterior Convolutional 32 2
Convolutional 64 2
Convolutional 128 2
Linear 2*32
Concatenation
Linear 256*4*4
Upsample
Convolutional 128 1
Likelihood
Upsample
Convolutional 64 1
Upsample
Convolutional 32 1
Upsample
Convolutional 3 1
Table6: allocentricmodelparameters
24
Figure15: Schematicviewofthegenerativemodel. Theleftpartistheencoderthatproducesalatentdistribu-
tionforeverypairofobservation,position. ThisencoderconsistsofconvolutionallayersinterfiledwithFILM
[68] layers that condition on the positions. This transforms the intermediate representation to encompass the
spatialinformationfromtheviewpoint. Thelatentdistributionsarecombinedtoformanaggregateddistribu-
tion over the latent space. A sampled vector is concatenated with the query position from which the decoder
generatesanovel/predictedobservation. Thedecodermimicstheencoderarchitectureandupsamplestheim-
ageandprocessesitwithconvolutionallayers,interfiledwithaFiLMlayerthatconditionsontheconcatenated
informationvector.
Layer Neurons/Filters Stride
Concatenation
Prior LSTM 256
Linear 2*32
Convolutional 8 2
Convolutional 16 2
Convolutional 32 2
Concatenation
Posterior
Linear 256
Linear 64
Linear 256
Linear 32*7*7
ImageLikelihood
Upsample
Convolutional 16 1
Upsample
Convolutional 8 1
Upsample
Convolutional 3 1
Linear 16
CollisionLikelihood Linear 8
Linear 1
Table7: egocentricmodelparameters
25
Figure16: Thegenerativemodelisparameterisedby3neuralnetworks. TheTransitionmodelinferstheprior
probabilityofgoingfromstates tos underactiona .ThePosteriormodelsthesametransitionwhilealso
t−1 t t−1
incorporatingthecurrentobservationo .Finallythelikelihoodmodeldecodesastatesamples toadistribution
t t
over possible observations. These models are used recurrently, meaning they are reused every time step to
generatenewestimates[38].
26
B.4. ModelsObservations
Allmodelsusetheagent’stopdownvisionoftheagent,consistingin7by7tileswiththeagentplacedatthe
bottomcentreoftheimage,asshownin17. OurmodelandDreamerV3useanRGBviewoftheenvironment
whileC-BET,Count,CuriosityandRNDuseaflathot-encodedviewoftheenvironmentaswellasanextrinsic
reward when passing over the single white tile in the environment. We can point out that the agent can’t see
throughwallsinRGBimage,wecanseeinFig.17a)theenvironmentandtheagent’sfieldofviewrepresented
bylightercolours. Fig.17b)showstheactualobservationseenbytheagent.
The number of actions C-BET could take was greatly reduced compared to the original work, limiting to
actionssuchasforward,left,rightandstand-by.
Figure 17: a) cropped top down view of the environment, b) the RGB view of the agent, each tile of the
environmentarecomposedof8by8pixels, generatinga56by56totalimage. c)theequivalenthot-encoded
viewasamatrix,thenumbersandcoloursareonlyrelevantfortheexample.
All RL models had a sparse reward system, with an extrinsic reward generated only when passing on the
whitetiledisposedintheenvironment.Ourmodeldoesnotrequirerewards,andthegoalwedesiretosetduring
thetestingcouldbeanykindofobservation.
References
[1] P. Schwartenbeck, J. Passecker, T. U. Hauser, T. H. FitzGerald, M. Kronbichler, and K. J. Friston,
“Computational mechanisms of curiosity and goal-directed exploration,” eLife, vol. 8, p. e41703, may
2019.[Online].Available: https://doi.org/10.7554/eLife.41703
[2] S. Levine and D. Shah, “Learning robotic navigation from experience: principles, methods and recent
results,”PhilosophicalTransactionsoftheRoyalSocietyB:BiologicalSciences,vol.378,no.1869,dec
2022.
[3] J.A.Placed,J.Strader,H.Carrillo,N.Atanasov,V.Indelman,L.Carlone,andJ.A.Castellanos,“Asurvey
onactivesimultaneouslocalizationandmapping: Stateoftheartandnewfrontiers,”IEEETransactions
onRobotics,pp.1–20,2023.
[4] D. George, R. Rikhye, N. Gothoskar, J. S. Guntupalli, A. Dedieu, and M. La´zaro-Gredilla, “Clone-
structured graph representations enable flexible learning and vicarious evaluation of cognitive maps,”
NatureCommunications,vol.12,042021.
[5] D.Hafner,J.Pasukonis,J.Ba,andT.Lillicrap,“Masteringdiversedomainsthroughworldmodels,”2023.
[6] R. Epstein, E. Z. Patai, J. Julian, and H. Spiers, “The cognitive map in humans: Spatial navigation and
beyond,”NatureNeuroscience,vol.20,pp.1504–1513,102017.
[7] P.Foo,W.Warren,A.Duchon,andM.Tarr,“Dohumansintegrateroutesintoacognitivemap? map-ver-
suslandmark-basednavigationofnovelshortcuts.”Journalofexperimentalpsychology.Learning,mem-
ory,andcognition,vol.31,pp.195–215,042005.
[8] M.Peer,I.K.Brunec,N.S.Newcombe,andR.A.Epstein,“Structuringknowledgewithcognitivemaps
andcognitivegraphs,”TrendsinCognitiveSciences,vol.25,no.1,pp.37–54,2021.[Online].Available:
https://www.sciencedirect.com/science/article/pii/S1364661320302503
27
[9] J.Balaguer,H.Spiers,D.Hassabis,andC.Summerfield,“Neuralmechanismsofhierarchicalplanningin
avirtualsubwaynetwork,”Neuron,vol.90,pp.893–903,052016.
[10] M. S. Tomov, S. Yagati, A. Kumar, W. Yang, and S. J. Gershman, “Discovery of hierarchical
representations for efficient planning,” bioRxiv, 2018. [Online]. Available: https://www.biorxiv.org/
content/early/2018/12/17/499418
[11] R.Lakaemper,L.J.Latecki,X.Sun,andD.Wolter,“Geometricrobotmapping,”vol.3429,042005,pp.
11–22.
[12] K.Kamarudin,S.M.Mamduh,A.Y.M.Shakaff,andA.Zakaria,“Performanceanalysisofthemicrosoft
kinectsensorfor2dsimultaneouslocalizationandmapping(slam)techniques,”Sensors,vol.14,no.12,
pp.23365–23387,2014.[Online].Available: https://www.mdpi.com/1424-8220/14/12/23365
[13] S. S. Ge, Q. Zhang, A. T. Abraham, and B. Rebsamen, “Simultaneous path planning and
topological mapping (sp2atm) for environment exploration and goal oriented navigation,” Robotics
and Autonomous Systems, vol. 59, no. 3, pp. 228–242, 2011. [Online]. Available: https:
//www.sciencedirect.com/science/article/pii/S0921889010002009
[14] S.-H. Kim, J.-G. Kim, and T.-K. Yang, “Autonomous slam technique by integrating grid and topology
map,”in2008InternationalConferenceonSmartManufacturingApplication,2008,pp.413–418.
[15] Z.Li,G.Chen,B.Peng,andX.Zhu,“Robotnavigationmethodbasedonintelligentevolution,”in2018
IEEE 4th Information Technology and Mechatronics Engineering Conference (ITOEC), 2018, pp. 620–
624.
[16] S. Parisi, V. Dean, D. Pathak, and A. Gupta, “Interesting object, curious agent: Learning task-agnostic
exploration,”CoRR,vol.abs/2111.13119,2021.[Online].Available: https://arxiv.org/abs/2111.13119
[17] Y.Matsuo,Y.LeCun,M.Sahani,D.Precup,D.Silver,M.Sugiyama,E.Uchibe,andJ.Morimoto,“Deep
learning, reinforcement learning, and world models,” Neural Networks, vol. 152, pp. 267–275, 2022.
[Online].Available: https://www.sciencedirect.com/science/article/pii/S0893608022001150
[18] K. Gregor, D. Jimenez Rezende, F. Besse, Y. Wu, H. Merzic, and A. van den Oord, “Shaping
belief states with generative environment models for rl,” in Advances in Neural Information
Processing Systems, H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alche´-Buc, E. Fox,
and R. Garnett, Eds., vol. 32. Curran Associates, Inc., 2019. [Online]. Available: https:
//proceedings.neurips.cc/paper files/paper/2019/file/2c048d74b3410237704eb7f93a10c9d7-Paper.pdf
[19] K. Friston, “Life as we know it,” Journal of the Royal Society, Interface / the Royal Society, vol. 10, p.
20130475,062013.
[20] K. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbeck, J. O. Doherty, and G. Pezzulo, “Active inference
and learning,” Neuroscience & Biobehavioral Reviews, vol. 68, pp. 862–879, 2016. [Online]. Available:
https://www.sciencedirect.com/science/article/pii/S0149763416301336
[21] D. Ha and J. Schmidhuber, “World models,” CoRR, vol. abs/1803.10122, 2018. [Online]. Available:
http://arxiv.org/abs/1803.10122
[22] K. Friston, R. J. Moran, Y. Nagai, T. Taniguchi, H. Gomi, and J. Tenenbaum, “World model
learning and inference,” Neural Networks, vol. 144, pp. 573–590, 2021. [Online]. Available:
https://www.sciencedirect.com/science/article/pii/S0893608021003610
[23] K. Friston, T. FitzGerald, F. Rigoli, P. Schwartenbeck, J. O. Doherty, and G. Pezzulo, “Active inference
and learning,” Neuroscience & Biobehavioral Reviews, vol. 68, pp. 862–879, 2016. [Online]. Available:
https://www.sciencedirect.com/science/article/pii/S0149763416301336
[24] I. Stoianov, D. Maisto, and G. Pezzulo, “The hippocampal formation as a hierarchical generative model
supporting generative replay and continual learning,” Progress in Neurobiology, vol. 217, p. 102329,
2022.[Online].Available: https://www.sciencedirect.com/science/article/pii/S0301008222001150
28
[25] O. C¸atal, T. Verbelen, T. Van de Maele, B. Dhoedt, and A. Safron, “Robot navigation as
hierarchical active inference,” Neural Networks, vol. 142, pp. 192–204, 2021. [Online]. Available:
https://www.sciencedirect.com/science/article/pii/S0893608021002021
[26] M. Chevalier-Boisvert, L. Willems, and S. Pal, “Minimalistic gridworld environment for openai gym,”
https://github.com/maximecb/gym-minigrid,2018.
[27] F. Sadeghi and S. Levine, “Cad2rl: Real single-image flight without a single real image,” CoRR, vol.
abs/1611.04201,2016.[Online].Available: http://arxiv.org/abs/1611.04201
[28] M. Mu¨ller, A. Dosovitskiy, B. Ghanem, and V. Koltun, “Driving policy transfer via modularity and
abstraction,”CoRR,vol.abs/1804.09364,2018.[Online].Available: http://arxiv.org/abs/1804.09364
[29] J. Janai, F. Gu¨ney, A. Behl, and A. Geiger, “Computer vision for autonomous vehicles:
Problems, datasets and state-of-the-art,” CoRR, vol. abs/1704.05519, 2017. [Online]. Available:
http://arxiv.org/abs/1704.05519
[30] D. Feng, C. Haase-Schu¨tz, L. Rosenbaum, H. Hertlein, F. Duffhauss, C. Gla¨ser, W. Wiesbeck,
and K. Dietmayer, “Deep multi-modal object detection and semantic segmentation for autonomous
driving: Datasets, methods, and challenges,” CoRR, vol. abs/1902.07830, 2019. [Online]. Available:
http://arxiv.org/abs/1902.07830
[31] D. Silver, J. A. Bagnell, and A. Stentz, “Learning from demonstration for autonomous navigation in
complex unstructured terrain,” The International Journal of Robotics Research, vol. 29, no. 12, pp.
1565–1592,2010.[Online].Available: https://doi.org/10.1177/0278364910369715
[32] S.Gupta,J.Davidson,S.Levine,R.Sukthankar,andJ.Malik,“Cognitivemappingandplanningforvisual
navigation,”CoRR,vol.abs/1702.03920,2017.[Online].Available: http://arxiv.org/abs/1702.03920
[33] D. S. Chaplot, D. Gandhi, S. Gupta, A. Gupta, and R. Salakhutdinov, “Learning to explore using active
neuralSLAM,”CoRR,vol.abs/2004.05155,2020.[Online].Available: https://arxiv.org/abs/2004.05155
[34] E. C. Tolman, “Cognitive maps in rats and men.” Psychological review, vol. 55 4, pp. 189–208, 1948.
[Online].Available: https://api.semanticscholar.org/CorpusID:42496633
[35] T. Madl, S. Franklin, K. Chen, R. Trappl, and D. Montaldi, “Exploring the structure of
spatial representations,” PLOS ONE, vol. 11, no. 6, pp. 1–46, 06 2016. [Online]. Available:
https://doi.org/10.1371/journal.pone.0157343
[36] A. Zakharov, M. Crosby, and Z. Fountas, “Episodic memory for learning subjective-timescale models,”
2020.
[37] D. Shah, B. Eysenbach, N. Rhinehart, and S. Levine, “RECON: rapid exploration for open-
world navigation with latent goal models,” CoRR, vol. abs/2104.05859, 2021. [Online]. Available:
https://arxiv.org/abs/2104.05859
[38] O.C¸atal,S.Wauthier,C.DeBoom,T.Verbelen,andB.Dhoedt,“Learninggenerativestatespacemodels
for active inference,” Frontiers in Computational Neuroscience, vol. 14, 2020. [Online]. Available:
https://www.frontiersin.org/article/10.3389/fncom.2020.574372
[39] M.Milford, A.Jacobson, Z.Chen, andG.Wyeth, RatSLAM:UsingModelsofRodentHippocampusfor
RobotNavigationandBeyond,042016,pp.467–485.
[40] V.Neacsu,M.B.Mirza,R.A.Adams,andK.J.Friston,“Structurelearningenhancesconceptformation
insyntheticactiveinferenceagents,”PLOSONE,vol.17,no.11,pp.1–34,112022.[Online].Available:
https://doi.org/10.1371/journal.pone.0277199
[41] O. C¸atal, W. Jansen, T. Verbelen, B. Dhoedt, and J. Steckel, “Latentslam: unsupervised multi-sensor
representation learning for localization and mapping,” CoRR, vol. abs/2105.03265, 2021. [Online].
Available: https://arxiv.org/abs/2105.03265
29
[42] A. Safron, O. C¸atal, and T. Verbelen, “Generalized simultaneous localization and mapping (g-SLAM)
as unification framework for natural and artificial intelligences: towards reverse engineering the
hippocampal/entorhinal system and principles of high-level cognition,” 10 2021. [Online]. Available:
https://doi.org/10.31234/osf.io/tdw82
[43] S.Nozari,A.Krayani,P.Marin-Plaza,L.Marcenaro,D.M.Go´mez,andC.Regazzoni,“Activeinference
integrated with imitation learning for autonomous driving,” IEEE Access, vol. 10, pp. 49738–49756,
2022.
[44] M.D.Kirchhoff,T.Parr,E.R.Palacios,K.J.Friston,andJ.D.Kiverstein,“Themarkovblanketsoflife:
autonomy,activeinferenceandthefreeenergyprinciple,”JournaloftheRoyalSocietyInterface,vol.15,
2018.[Online].Available: https://api.semanticscholar.org/CorpusID:3284518
[45] M.Beal,“Variationalalgorithmsforapproximatebayesianinference/,”PhDthesis,012003.
[46] R.KaplanandK.Friston,“Planningandnavigationasactiveinference,”122017.
[47] K.Friston,L.DaCosta,D.Hafner,C.Hesp,andT.Parr,“SophisticatedInference,”NeuralComputation,
vol.33,no.3,pp.713–763,032021.[Online].Available: https://doi.org/10.1162/neco a 01351
[48] C.D.Mathys,E.I.Lomakina,J.Daunizeau,S.Iglesias,K.H.Brodersen,K.J.Friston,andK.E.Stephan,
“Uncertaintyinperceptionandthehierarchicalgaussianfilter,”FrontiersinHumanNeuroscience,vol.8,
2014.[Online].Available: https://www.frontiersin.org/articles/10.3389/fnhum.2014.00825
[49] A.E.McGlothlinandK.Viele,“BayesianHierarchicalModels,”JAMA,vol.320,no.22,pp.2365–2366,
122018.[Online].Available: https://doi.org/10.1001/jama.2018.17977
[50] M.Milford,G.Wyeth,andD.Prasser,“Ratslam: ahippocampalmodelforsimultaneouslocalizationand
mapping,”vol.1,pp.403–408Vol.1,2004.
[51] S.M.A.Eslami,D.J.Rezende,F.Besse,F.Viola,A.S.Morcos,M.Garnelo,A.Ruderman,A.A.Rusu,
I.Danihelka,K.Gregor,D.P.Reichert,L.Buesing,T.Weber,O.Vinyals,D.Rosenbaum,N.Rabinowitz,
H. King, C. Hillier, M. Botvinick, D. Wierstra, K. Kavukcuoglu, and D. Hassabis, “Neural scene
representation and rendering,” Science, vol. 360, no. 6394, pp. 1204–1210, 2018. [Online]. Available:
https://www.science.org/doi/abs/10.1126/science.aar6170
[52] T. Van de Maele, T. Verbelen, O. C¸atal, C. De Boom, and B. Dhoedt, “Active vision for robot
manipulators using the free energy principle,” Frontiers in Neurorobotics, vol. 15, 2021. [Online].
Available: https://www.frontiersin.org/articles/10.3389/fnbot.2021.642780
[53] C. Kurby and J. Zacks, “Segmentation in the perception and memory of events,” Trends in cognitive
sciences,vol.12,pp.72–9,032008.
[54] T.Verbelen, D.deTinguy,P.Mazzaglia,O.Catal,andA.Safron,“Chunkingspaceandtimewithinfor-
mationgeometry,”p.6,2022.
[55] T. Hafting, M. Fyhn, S. Molden, M.-B. Moser, and E. Moser, “Microstructure of a spatial map in the
entorhinalcortex,”Nature,vol.436,pp.801–6,092005.
[56] M.Milford,G.Wyeth,andD.Prasser,“Ratslamontheedge:Revealingacoherentrepresentationfroman
overloadedratbrain,”pp.4060–4065,2006.
[57] H.Wang,Y.Yu,andQ.Yuan,“Applicationofdijkstraalgorithminrobotpath-planning,”in2011Second
InternationalConferenceonMechanicAutomationandControlEngineering,2011,pp.1067–1069.
[58] D.P.KingmaandJ.Ba,“Adam: Amethodforstochasticoptimization,”2017.
[59] Y. Burda, H. Edwards, A. J. Storkey, and O. Klimov, “Exploration by random network distillation,”
CoRR,vol.abs/1810.12894,2018.[Online].Available: http://arxiv.org/abs/1810.12894
[60] D. Pathak, P. Agrawal, A. A. Efros, and T. Darrell, “Curiosity-driven exploration by self-supervised
prediction,”CoRR,vol.abs/1705.05363,2017.[Online].Available: http://arxiv.org/abs/1705.05363
30
[61] M. Bellemare, S. Srinivasan, G. Ostrovski, T. Schaul, D. Saxton, and R. Munos, “Unifying
count-based exploration and intrinsic motivation,” in Advances in Neural Information Processing
Systems, D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett, Eds., vol. 29. Curran
Associates, Inc., 2016. [Online]. Available: https://proceedings.neurips.cc/paper files/paper/2016/file/
afda332245e2af431fb7b672a68b659d-Paper.pdf
[62] A. Candra, M. A. Budiman, and K. Hartanto, “Dijkstra’s and a-star in finding the shortest path: a tuto-
rial,” in 2020 International Conference on Data Science, Artificial Intelligence, and Business Analytics
(DATABIA),2020,pp.28–32.
[63] Y. Asano, C. Rupprecht, and A. Vedaldi, “Self-labelling via simultaneous clustering and representation
learning,” in International Conference on Learning Representations, 2020. [Online]. Available:
https://openreview.net/forum?id=Hyx-jyBFPr
[64] T.Verbelen, D.deTinguy,P.Mazzaglia,O.Catal,andA.Safron,“Chunkingspaceandtimewithinfor-
mationgeometry,”inNeurIPS2022WorkshoponInformation-TheoreticPrinciplesinCognitiveSystems,
2022.
[65] D.d.Tinguy,P.Mazzaglia,T.Verbelen,andB.Dhoedt,“Homerun:Findingyourwayhomebyimagining
trajectories,”inActiveInference. Cham: SpringerNatureSwitzerland,2023,pp.210–221.
[66] J.Pasukonis,T.Lillicrap,andD.Hafner,“Evaluatinglong-termmemoryin3dmazes,”2022.
[67] M.Savva,A.Kadian,O.Maksymets,Y.Zhao,E.Wijmans,B.Jain,J.Straub,J.Liu,V.Koltun,J.Malik,
D.Parikh,andD.Batra,“Habitat: Aplatformforembodiedairesearch,”inProceedingsoftheIEEE/CVF
InternationalConferenceonComputerVision(ICCV),October2019.
[68] E. Perez, F. Strub, H. de Vries, V. Dumoulin, and A. Courville, “Film: Visual reasoning with a general
conditioninglayer,”2017.
31

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Spatial and Temporal Hierarchy for Autonomous Navigation using Active Inference in Minigrid Environment"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
