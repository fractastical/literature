### OverviewThis paper investigates active multimodal distillation for few-shot action recognition, addressing the limitations of single-modal approaches and the need for efficient representation learning. The authors propose a novel framework, termed AMFIR, that dynamically identifies the most reliable modalities for each query sample, leveraging active inference and mutual distillation to enhance recognition performance. The core of the framework involves an active sample inference (ASI) module, which predicts reliable modalities based on posterior distributions, and an active mutual distillation module, which transfers knowledge from reliable modalities to less reliable ones. The framework employs a meta-learning paradigm, where each learning unit consists of labeled support samples and unlabeled query samples.### MethodologyThe authors present the AMFIR framework, which integrates an active sample inference (ASI) module and an active mutual distillation module. The ASI module utilizes Bayesian inference to estimate the reliability of each modality based on the posterior distributions. The module dynamically selects the most reliable modality for each query sample, which is then used to construct the query sample's representation. The active mutual distillation module transfers knowledge from reliable modalities to less reliable ones through bidirectional distillation. The module utilizes a similarity-preserving knowledge distillation strategy to enhance the representation ability of less reliable modalities. The framework employs a meta-learning paradigm, where each learning unit consists of labeled support samples and unlabeled query samples. The ASI module takes the modality-specific posterior distributions as inputs and performs reliability inference to predict the most reliable modality for each query sample. The active mutual distillation module transfers knowledge from reliable modalities to less reliable ones through bidirectional distillation. The framework employs a meta-learning paradigm, where each learning unit consists of labeled support samples and unlabeled query samples.### ResultsThe experimental results demonstrate that the AMFIR framework significantly outperforms existing methods on several benchmark datasets, including Kinetics-400, Something-Something V2, HMDB51, and UCF101. Specifically, the framework achieves state-of-the-art results in1-shot and5-shot settings. The authors report accuracy scores of70.6% and92.3% on the SSv2 dataset in the1-shot setting, and82.8% and96.1% on the Kinetics-400 dataset in the1-shot setting. The results highlight the effectiveness of the active multimodal distillation approach in improving few-shot action recognition performance. The authors also demonstrate that the framework can effectively handle sensor noise and motion ambiguity. The experimental results show that the AMFIR framework achieves state-of-the-art results in1-shot and5-shot settings on several benchmark datasets, including Kinetics-400, Something-Something V2, HMDB51, and UCF101. The authors report accuracy scores of70.6% and92.3% on the SSv2 dataset in the1-shot setting, and82.8% and96.1% on the Kinetics-400 dataset in the1-shot setting. The results highlight the effectiveness of the active multimodal distillation approach in improving few-shot action recognition performance.### DiscussionThe authors discuss the key findings of their research and highlight the contributions of the AMFIR framework. They emphasize the importance of active inference and mutual distillation in addressing the limitations of single-modal approaches and enhancing representation learning. They also discuss the potential of the framework for future research directions, such as exploring different modalities and incorporating temporal information. The authors highlight the synergy between active inference and mutual distillation, which enables the framework to dynamically adapt to the specific characteristics of each query sample and improve recognition performance. The authors also discuss the potential of the framework for future research directions, such as exploring different modalities and incorporating temporal information. The authors emphasize the importance of active inference and mutual distillation in addressing the limitations of single-modal approaches and enhancing representation learning. The authors highlight the synergy between active inference and mutual distillation, which enables the framework to dynamically adapt to the specific characteristics of each query sample and improve recognition performance.### Active InferenceTo establish the active inference model, we input the representationsofquerysamples{qm}M andtheprototypesofsupportsamples{tm}N into the module. We consider the dominant modality for each query sample as the one that can reflect more task-specific discriminative features. This approach dynamically evaluates the reliability of each modality, prioritizing those with lower free energy for inference. To enhance the representation ability of less reliable modalities, we transfer knowledge from reliable modalities to less reliable ones through bidirectional distillation. The authors state: "The ASI module takes the modality-specific posterior distributions as inputs and performs reliability inference to predict the most reliable modality for each query sample."### Active Mutual DistillationThe authors note: "The active mutual distillation module transfers knowledge from reliable modalities to less reliable ones through bidirectional distillation."### ConclusionThe authors conclude: "The AMFIR framework achieves state-of-the-art results in1-shot and5-shot settings on several benchmark datasets, including Kinetics-400, Something-Something V2, HMDB51, and UCF101."