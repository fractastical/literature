=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Active Inference on the Edge: A Design Study
Citation Key: sedlak2023active
Authors: Boris Sedlak, Victor Casamayor Pujol, Praveen Kumar Donta

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Key Terms: casamayor, systems, sedlak, service, design, edge, inference, active, model, vienna

=== FULL PAPER TEXT ===

Active Inference on the Edge: A Design Study*
Boris Sedlak, Victor Casamayor Pujol, Praveen Kumar Donta, and Schahram Dustdar
Distributed Systems Group, Vienna University of Technology (TU Wien), Vienna 1040, Austria.
Email: {b.sedlak, v.casamayor, pdonta, dustdar}@dsg.tuwien.ac.at
Abstract—MachineLearning(ML)isacommontooltointerpret distribution changes and the ML model is not adjusted, this
andpredictthebehaviorofdistributedcomputingsystems,e.g.,to makes it impossible to interpret the metrics correctly, and any
optimizethetaskdistributionbetweendevices.Asmoreandmore
consequential reconfiguration will fail to fulfill its purpose.
dataiscreatedbyInternetofThings(IoT)devices,dataprocessing
EnsuringtheprecisionofanMLmodelrequiresacontinuous
andMLtrainingarecarriedoutbyedgedevicesincloseproximity.
To ensure Quality of Service (QoS) throughout these operations, feedback mechanism; such behavior could, for example, be
systems are supervised and dynamically adapted with the help of achieved by optimizing a value function, as in reinforcement
ML.However,aslongasMLmodelsarenotretrained,theyfailto learning[7],[8].However,webelievethatthisrequiresamore
capture gradual shifts in the variable distribution, leading to an
holisticapproach,whichstartswithmakingtheSLOsfirst-class
inaccurate view of the system state. Moreover, as the prediction
citizens during the ML training process. Further, we want to
accuracy decreases, the reporting device should actively resolve
uncertainties to improve the model’s precision. Such a level of highlight the responsibility of any service that uses the ML
self-determination could be provided by Active Inference (ACI) model to actively resolve or report ambiguities. Such a level
– a concept from neuroscience that describes how the brain of self-determination could be provided by Active Inference
constantlypredictsandevaluatessensoryinformationtodecrease
(ACI), a concept from neuroscience that describes how the
long-term surprise. We encompassed these concepts in a single
brain constantly predicts and evaluates sensory information to
action-perception cycle, which we implemented for distributed
agentsinasmartmanufacturingusecase.Asaresult,weshowed decrease long-term surprise. ACI combines various concepts
how our ACI agent was able to quickly and traceably solve an thathavealreadybeenrudimentarilyimplementedindistributed
optimization problem while fulfilling QoS requirements. systems,e.g.,causalinferencetoidentifydependenciesbetween
Index Terms—Active Inference, Machine Learning, Edge Intel-
systemparts[3],ordynamicadaptationsofthesystemtoensure
ligence, Service Level Objectives, Markov Blanket
QoS – called homeostasis. This shows the potential of ACI.
In this paper, we advance one step further by combining the
I. INTRODUCTION
ACIconceptsinacomprehensivedesignstudyofanACIagent
Recent years have reported a constant transition of logic
that optimizes the throughput of a smart factory. Internally,
from the central cloud towards the edge of the network [1],
the agent follows an action-perception cycle: First, it estimates
thus,closertotheInternetofThings(IoT)devicesthatactually
which parameter assignments would violate given SLOs, then
generate data. This transition includes the training of Machine
itcomparesthisexpectationwithnewobservations,andfinally,
Learning (ML) models (i.e., to save bandwidth and improve
it adjusts its beliefs (i.e., the ML model) accordingly. The
privacy), as well as data processing (i.e., to decrease latency)
agentfocusesonexploringvaluesthatpromiseahighthrough-
[2].Assoonastraininghasfinished,MLmodelsareacommon
put while avoiding such that are likely to violate the SLOs.
measure to interpret and predict the behavior of distributed
Furthermore, it favors solutions that are likely to improve the
systems, e.g., to estimate the impact of redeployment [3] or
modelprecision,which,inturn,providestheagentwithaclear
forecast potential system failures [4], which must be circum-
understanding of the causal relations between model variables.
vented to ensure the Quality of Service (QoS).
Hence, the contributions of this article are the following:
ML models are applied throughout the Computing Contin-
uum (CC), i.e., from the cloud, over the fog, to the network • A novel ML paradigm based on ACI that continuously
evaluates the quality of predictions. Thus, agents improve
edge – close to where models were trained. However, in many
themodelprecisiontoensureQoSforongoingoperations.
cases, ML models are not retrained, although new observa-
tions would be available [3], [4]; this inevitably leads to an • The composite representation of an agent’s behavior
throughout the action-perception cycles. The distinct fac-
inaccurate view of the system state, which, in turn, decreases
torscanbefine-tunedtodeterminetheagent’spreferences.
the quality of any inference mechanism that uses the ML
model. Imagine an elastic computing system, like envisioned • A complete design study for a smart manufacturing agent
thatpavesthewayforotherresearcherstoimplementACI
in [5], [6], which observes the system through a set of metrics,
in related automative use cases.
evaluates whether QoS requirements – also called Service
Level Objectives (SLOs) – were fulfilled, and dynamically The remainder of the paper is structured as follows: Sec-
reconfiguresthesystemtoensureSLOsaremet.Ifthevariable tion II provides background information on ACI principles in
distributed systems; in Section III we present existing work
* Funded by the European Union (TEADAL, 101070186). Views and that included ACI; within Section IV we outline the design
opinions expressed are however those of the author(s) only and do not
processofanACIagent,whichweimplementedandevaluated
necessarilyreflectthoseoftheEuropeanUnion.NeithertheEuropeanUnion
northegrantingauthoritycanbeheldresponsibleforthem. in Section V. Finally, Section VI concludes the paper.
3202
voN
71
]YS.ssee[
1v70601.1132:viXra
II. BACKGROUND actions. While pragmatic actions (e.g., picking an umbrella)
fulfill agents’ preferences (e.g., staying dry), agents improve
We consider ACI an unknown concept for most readers
their decision-making by exploring the environment through
outside of neuroscience; therefore, we use this section to
epistemic actions. For example, a mere look at the sky reveals
summarize core concepts of ACI according to Friston et
thattheneighborhaswateredherplants,avoidingsurprisewhen
al. [8]–[12]. This includes but is not limited to (1) free
wrongfully leaving with an umbrella. The agent thus updates
energy minimization, (2) hierarchical organization of beliefs,
itspriorbeliefs(i.e.,rain→water)accordingtonewdata(i.e.,
(3) action-perception cycles, and (4) Bayesian inference and
rain → water ← flowers) to form posterior beliefs.
belief updating. Following that, we delineate our view of the
intersection between ACI and distributed systems, in particular B. ACI Principles in Distributed Systems
edge computing.
ACI encompasses multiple concepts; although there exist
A. Active Inference Principles few implementations that combine them in one framework,
most of them can be encountered in distributed systems. In
Tointerpretobservableprocesses,agentsconstructgenerative
the following, we review the principles described above and
models, e.g., a person would reason that it rains due to water
map them to existing concepts as far as possible:
drops falling from the sky. Based on these observations, the
1) Causal Inference: Causal structures (e.g., Bayesian net-
agent can learn to understand real-world processes. However,
works [13]) can be trained to identify dependencies between
if the generative model and the process diverge, the agent
parts of distributed systems. As pointed out by [14], causal
will eventually be “surprised”, e.g., because water drops were
structureshavethefundamentaladvantage(overdeeplearning)
caused by a neighbor watering her plants. The discrepancy
of justifying their actions or recommendations, thus improving
(or uncertainty) between the agent’s understanding of the
trustworthiness. Distributed systems can explain how metrics
processandrealityiscalledFreeEnergy(FE);amoreaccurate
(e.g., latency or CPU load) are related to the system state [5],
understanding decreases FE at the same time.
backtrack which service or device caused a system failure [3],
More formally, the surprise ℑ(o|m) of observation o given
or predict the impact of redeployment [15].
model m is the negative log-likelihood of the observation. The
2) Free Energy Minimization: AI models are trained to
surprise itself is capped by the FE of the model – expressed as
improve their prediction accuracy, which, in turn, reduces their
the Kullback-Leibler divergence (D ) between approximate
KL
FE.Energy-basedmodels[16],inparticular,rateuncertaintyas
posteriorprobability(Q)ofthehiddenstates(x)andtheirexact
(free) energy. To ensure model accuracy over time, one option
posteriorprobability(P).Whilemathematicalapproaches,such
istocontinuouslyreportpredictionerrors(e.g.,[17]).However,
asexemplifiedinEq.(1)&(2),provideamuch-needednotation
in many cases, systems lack adequate feedback loops and thus
for working with the FE principle, in practice, many variables
fail to capture gradual shifts in the variable distributions (e.g.,
are computationally intractable, e.g., the true probability P.
[3], [15], [18]) While ML training is essential to decrease FE,
ModelEvidence epistemic actions often suffice to reduce uncertainties about
(cid:122) (cid:125)(cid:124) (cid:123)
expected outcomes: Distributed systems resolve contextual in-
ℑ(o|m)=−ln P(o|m) (1)
formation before executing pragmatic actions, e.g., identify a
F[Q,o]=D KL [Q(x)||P(x|o,m)]+ℑ(o|m)≥ℑ(o|m) (2) low-utilized agent for load balancing or task offloading [19],
(cid:124) (cid:123)(cid:122) (cid:125)
[20], or evaluate resource availability before scaling a system
(Variational)FreeEnergy
[5],[21].Itisthegeneraltradeoffbetweenseekingeitherprag-
Internally, agents organize their generative models in hi- matic value (exploitation) or information (exploration); multi-
erarchical structures; each level interprets lower-level causes agentsystems(e.g.,[22])controlthisthroughahyperparameter
and, based on that, provides predictions to higher levels. For called “exploration rate”, which fosters early exploration of a
example, suppose it rains with a certain probability, I bring global value space but decays over time as agents report little
an umbrella. This is commonly known as Bayesian inference improvement.Toimprovegenerativemodelswheneverfeasible,
and allows agents to use existing beliefs (widely known as this is also implemented for edge-based systems [19].
priors) to calculate the probability of related events. Such 3) Homeostasis: The ultimate goal for an ACI agent is
decision processes can be segregated into self-contained causal to persist over time; this requires maintaining certain internal
structures (i.e., Markov blankets), e.g., one to interpret the variablesundercontrol.Thisconceptiscalledhomeostasisand
weather and another to dress. As the agent infers that it canbefoundinvarioussystems:Thehumanbody,forexample,
is raining, he decides to pick the umbrella. However, when requires a core temperature of 37° for chemical processes;
dressing, the agent only considers the weather (rainy or sunny) distributed systems, on the other hand, specify QoS require-
anddisregardslower-levelobservationsthatledhimtoconclude ments as SLOs [5], [6], [21], [23]. While the human body
that it’s raining (e.g., humidity or obscurity). has its own temperature-controlling mechanisms, distributed
ACI agents constantly engage in action-perception cycles, systems rely on elasticity strategies to ensure QoS, e.g., by
where they (1) predict sensory inputs, actively seek the infor- scalingcomputationalresourcestocapresponsetime.Although
mation, and update their beliefs depending on the outcome – surprise plays a significant role here, e.g., when reporting
widely known as predictive coding. Afterward, they (2) can SLO violations, the preferred strategy is to engage with the
adjust the world to their existing beliefs through their own environment to correct this instead of changing the perception.
III. RELATEDWORK
While,tothebestofourknowledge,thereexistsnocomplete
implementation of ACI in distributed systems; a handful of
research works have combined ACI with computer science:
The authors in [24] discuss ACI as a general computational
framework, highlighting how existing research used ACI for
(simulating) sensory processing. Touching on the design of
ACI agents, Heins et al. [25] provide a Python simulation that
exemplifies how to structure action-perception cycles. Heins et
al.furtherremarkthatexistingACIresearchlargelyfocuseson
formally constructing models in isolated environments such as
Matlab SPM (e.g., [11]) rather than putting them into action,
e.g., to improve the precision of ML models. A more hands- Fig. 1: Overview of the action-perception cycle in ACI
on application of ACI is thus to extend reinforcement learning
with ACI principles [7], [8]. However, most research to date
either uses only a few ACI principles or is not applied enough
to easily transfer presented concepts to distributed systems.
The work in [22] is, therefore, an exception because it
embeds ACI into the IoT and describes how ACI can improve
the behavior of adaptive agents. Thus, individual agents
may dynamically regroup into hierarchical teams, federate
knowledge, and collectively strive after a common goal (i.e., Fig. 2: A factory producing machine parts in batches
a search task). By emphasizing the exchange of experiences
between agents, they were able to speed up the convergence
of the distributed task. However, while they focused on FE to which they are affected. Afterward, the agent starts to
minimization, they did not treat the other two principles we continuously predict the probability of observations, might
identified for ACI in distributed systems: causal inference actively seek a corresponding input, and then compares the
and homeostasis. In this paper, we will present an agent that event against the expectation. To decrease FE, the agent now
uses all three ACI principles to infer actions, maintain agents’ has three options: (1) adjust its beliefs accordingly, i.e., update
internal equilibrium, and persist over time. Nevertheless, we the causal graph and conditional probabilities; (2) change the
will use the representation from [22] for FE minimization. environment toward its preferences, e.g., executing elasticity
strategies; or (3) resolve contextual information to improve
decision-making.
IV. ACTIVEINFERENCEDESIGNPROCESS
B. Use Case Description
In the following, we will walk through the design of an ACI
agent by (1) building upon ACI background information to The following use case is embedded in the smart manufac-
drawanaction-perceptionloop,(2)describingausecasewhere turingenvironment,whichprovidesnumerousopportunitiesfor
theagenttrainsamodelfromscratchtooptimizeperformance, sensor-orientedanalysisanddynamicadaptationofproduction.
(3)markingtheboundariesofthegenerativemodeltrained,and Fig. 2 provides a high-level overview of the use case:
(4) defining the agent’s behavior throughout the cycles. Within a factory, machine parts are fabricated in batches of
12to30pieces;alargerbatchsizeincreasesthethroughputand
A. Action-Perception Loop
utilizationofthefactoryengine.Eachbatchmustbecompleted
To continuously ensure the precision of ML models and any within 500 ms; thus, an increasing batch size decreases the
consequential action, we will employ self-evidenced agents, timeframe for processing each part. The engine’s utilization
i.e., they reason about their environment and train models is supposed to impact the processing duration, though the
autonomously. To that extent, ACI agents operate in action- magnitude is unknown. Also, due to a consecutive assembly
perception cycles; each iteration aims to improve the accuracy step, the distance between parts should be above 5 cm. Given
of the model, infer optimal actions, and thus persist over time. this setup, the factory manager would like to know the largest
Assuch,agentscanbeembeddedintodistributedsystems,e.g., batch size that fulfills all constraints. However, because they
to maintain the QoS for a distributed task. lack historical data, it is difficult to answer this by training
Fig. 1 provides a high-level overview of the steps that are an ML model; this issue must be actively explored. Ideally,
repeatedbytheagent:Initially,asetofSLOsdefinetheagent’s the learning process would also be autonomous and allow the
preferences (e.g., delay ≤ δ) and establishes its expectations factory to simultaneously produce their goods.
prior to evaluating any sensory data. The agent then assembles To provide the factory manager with the optimal batch size,
a causal graph to determine which factors influence these we supervise the factory engine through an ACI agent. The
parameters;theconditionalprobabilitytablecontainsthedegree resulting smart engine now enters what can be understood
TABLE I: Model variables and their boundaries
Name Unit Description Range
batchsize num numberofmachinepartsperbatch [12,30]
utilization % utilizationofthefactoryengine [1,100]
distance cm spacebetweentwomachineparts [1,∞[
partdelay ms processingtimepermachinepart [1,∞[
batchdelay ms totaltimeforbatchprocessing [1,∞[
Fig. 3: Initial beliefs of relations between model variables
as a continuous calibration mechanism: throughout its action-
perception cycle, it (1) estimates if an increase or decrease
the prediction is compared against the events observed during
in batch size would violate the given constraints (i.e., its
that time. While the cycle’s length can be chosen freely,
SLOs), (2) compares the expectation with the result, and (3)
longer periods decrease the prediction accuracy or increase
continuously explores the value space by slightly varying the
the computational complexity (i.e., to evaluate the SLO once,
batch size. The agent thus gradually approaches solutions that
it must consider multiple cycles or fractions of them). The
promise high throughput while satisfying all constraints.
hierarchical depth, on the other hand, is determined by the
numberofvariablesandedgesinthemodel.Adeeperhierarchy
C. Generative Model Setup
wouldincreasethecomplexityofmodeltrainingandinference;
While the use case showed how ACI can help solve opti-
however,theusecasedoesnotprovidevariablesotherthanthe
mizationproblems,wewillnowdivedeeperintothegenerative
ones already contained in the DAG.
model created by the agent. The design process is loosely
So far, it only remains to explain what priors are in the
oriented towards the guidance provided by Parr et al. [26],
given example: Priors are our assumptions about the system
which depicts an abstract sequence of steps to design ACI
before verifying them, e.g., which batch size should provide
systems. The main questions we aim to answer are:
the highest throughput without violating the SLOs. Priors are
1) What is part of the generative model, and what are the subject to the learning process, while SLOs are fixed; each
interfaces to the exterior? action-perceptioncycleaimstoimprovethegenerativemodel’s
2) Whatisthehierarchicalandtemporaldepthofthemodel, accuracy, thus decreasing FE. As we will see in Section V, the
and how do they affect causal inference? initial beliefs (i.e., before evaluating any cycle) speed up the
3) What are the model variables and prior beliefs – what convergence of ACI to the optimal solution.
can be modified (i.e., learned), and what is immutable?
D. Active Inference Agent
TopredictwhetherabatchsizewouldfulfilltheSLOs,agents To find the optimal batch size, the central mechanism of the
must identify the variables that have an impact on them. These agent is the action-perception cycle shown in Fig. 1. Initially,
couldbeextractedthroughacausalstructure(e.g.,[3],[15])or, the agent has little information available to form priors or
in the absence of training data, come from expert knowledge, infer a fitting batch size; however, as the agent samples the
whichcanbeupdatedovertime.Themanagerinitiallybelieves environment through its interface variables, each cycle adds
that variables are related as depicted by the Directed Acyclic new observations (s ) to the total amount of known samples
n
Graph (DAG) in Fig. 3; the respective variables are described (s ). The agent’s behavior throughout each cycle (i.e., how
k
in Table I. Variables in ACI represent an interface between the it interprets sensory information and which action it takes) is
generative model and the exterior world, i.e., if the utilization determined by three main factors: (1) pragmatic value (pv) of
of the physical engine changes, this is reflected through the actions; (2) ambiguity or risk assigned (ra) to actions; and
respective variable (i.e., utilization), which in turn determines (3) epistemic value or information gained (ig) by actions. The
the internal view of the system state. Information provided following notation of these factors is related to [22], [26],
through interface variables is used to construct the generative though the composition is different. The only parameter that
model, but also to evaluate SLO fulfillment (e.g., batch delay the agent can actively set is batch size; the remaining variables
≤ 500 ms). To that extent, it needs to analyze the respective arecausallyinfluencedbythisfactor.Thus,iftheagentchanges
variable (from the DAG), as well as its parent, child, and the batch size, this is reflected through the related variables.
spousenodes.Thissubsetprovidesacausalfiltertothevariable The pragmatic value that emerges from higher batch size
state,calledMarkovblanket.Acentralpremiseisthatallthese is simple: more throughput. Therefore, we define pv(bs) =
sensory variables accurately reflect the exterior; otherwise, bs× 100, which encourages the agent to increase batch size.
30
subsequent decisions (e.g., decreasing batch size to decrease Themultiplier 100 scalesthefactortotherange[1,100],which
30
delay) would perpetuate any measurement error. is equal for all three factors. Contrarily, high batch size might
For the given use case, we use an SLO-induced boundary exceedbd≤500msord≥5cm,i.e.,theSLOsassociatedwith
as our natural limit on temporal depth: Equal to the maximum batch delay and distance (d). To evaluate the risk of violating
batch delay (bd), each action-perception cycle lasts 500 ms. the SLOs we consider how often past observations for a batch
Withineachcycle,theagentpredictstheengine’sbehavior(i.e., size(s )haveviolatedtheSLOs.Thera,e.g.,forbatchsize=
kb
reflected through the metrics) over the next 500 ms; afterward, 20,wouldthusbedeterminedbytheratebetweensamplesthat
fulfilled the SLOs and the total number of samples (|s |); this
kb
isformalizedinEq.(3)&(5).Aslongasthelistofsamplesfor
a batchsize (or short bs) is empty (i.e., |s | = 0), the agent
kb
interpolates the value with the prior and latter ra as reference
points, e.g., if the agent knows ra(30)=90 and ra(20)=20,
in the absence of samples for batchsize = 25, it infers that
ra(25)=55. This interpolation is contained in Eq. (4).

inter(bs), if |s
kb
|=0
ra(bs)=100− (3)
 valid(bs) ×100, otherwise (a) Batch size / cycle (b) Risk / batch size
|skb|
Fig. 4: History of best scoring batch size and associated risk
(ra −ra )
inter(bs)=ra +(bs−bs )× i+1 i−1 (4)
i−1 i−1 (bs −bs )
i+1 i−1
and observes for each item a set of metrics, which represent
|
(cid:88)
skb|
the variables from Table I. In each round, the agent computes
valid(bs)= [(bd ≤500)∧(d ≥5)] (5)
i i the factors that determine its behavior (i.e., pv, ra, and ig)
i=1 as described, chooses the highest common factor (cf), and
The ig of an action is determined by the ambiguity that it instructs the engine to operate with the new batchsize. This
resolves;inotherwords,weaimtomakefuturepredictionsless concludes one iteration in the action-perception cycle.
surprising. Reviving the idea of surprise from Eq. (1), we now
requirethesurprisefors givens :Eq.(7)showshowthetotal A. Comparative Analysis & Results
n k
surpriseisthesumofsurprisesofnewsamples;f(x)describes We evaluated two main aspects of the implementation: (1)
the probability density function1 with µ = s¯ k and σ sk . For whichbatchsizeitchoosesattheendofeachcycle,and(2)how
each s n , the surprise is appended to a list of past surprises well the generative model can reflect the partially observable
S =S∪surprise(s n ,s k );S x ∈S containsallvalueswithx= relation between utilization and part delay.
batchsize. If a batchsize has reported repeatedly surprising Fig. 4a tracks the chosen batch size depending on the cf
values, it supposedly provides more information gain: This is score: The blue line depicts the agent’s behavior when starting
reflectedthroughEq.(6)becausethemediansurprise(S˜ x )will with batchsize = 12, and the red line when starting with 30,
riseabovetheglobalaverage(S¯).Tofosterexplorationofprior
i.e., the safest or most ambitious priors. Agent reaches a
30
unknown batchsize, in the absence of surprise values, e.g., batch size of 21 after 5 iterations; whether this is a good (or
|S 25 |=0, it assumes ra(25)=max(S). optimal) solution is determined by multiple opposite factors:
(cid:32) S˜ (cid:33) As batch size increases, both pa and ra rise. To provide more
ig(bs)= bs ×100 (6) detail, Fig. 4b contains the ra that agent assigned to each
S¯ 30
batchsizeafter100iterations.Operatingwithbatchsize=21,
(cid:88)
|sk|
agent reported SLO violations for 12% of all observations.
surprise(s ,s )= −logf(d ) (7) 30
n k i Ifthiscannotbetolerated,theramustbeadjustedaccordingly;
i=1
otherwise, 21 presents a very high (if not optimal) pv because
Ultimately, to evaluate the potentials but also risks that any larger batch size would be more than three times more
emerge from each batchsize, the three factors are merged into likely to violate the SLOs, according to their ra. Complemen-
a common one – (cf). Since all factors are scaled to the range tarily, the green line shows the agent’s behavior if it simply
[1,100], they can be combined as cf(bs)=pv(bs)−ra(bs)+ increases or decreases the batch size depending on whether
ig(bs). At the end of each cycle, the agent resolves cf(x) for SLOs were fulfilled for the current batch.
x=[12,30]andchoosesthehighestscoringasnewbatchsize.
While one goal was to reach a high pv, the agent’s intrinsic
motivationistodecreasetheFEbydevelopinganaccurategen-
V. EVALUATION
erativemodel.Thisincludesestimatingthemagnitudeofcausal
ToevaluatetheideaspresentedinthelastSection,weprovide
relations such as utilization → part delay. Therefore, after
a Python implementation of the ACI agent that comprises the
receiving a number of samples, the agent can use (polynomial)
action-perception loop to create a generative model. Although
regression to infer part delay for unknown utilization. Fig. 5a
we did not embed the agent in a physical engine to measure
shows a 2D representation of this relation for 2500 processed
sensory information, we used a compatible data set generated
batch items, supervised by agent ; the red line represents
12
with [27] to simulate an equal behavior. The prototype of the
the agent’s internal model after training on all observations,
agent,thedata,aswellastheanalysisareavailableonGitHub2.
and the red line after training on only 30 values. After the
The agent starts the simulation by processing a batch of items
first round, agent decided to explore only batchsize ≥ 19,
12
thus, Fig. 5a contains no observations for utilization [45,60].
1Afunctionthatdescribedthelikelihoodofanobservationoinacontinuous
The distribution of prediction errors between the regression
rangegiventhattheprobabilitiesaredistributedwithO∼N(µ,σ).
2https://anonymous.4open.science/r/analysis-20F6/DATE/ functions and all items is shown in Fig. 5b. We observe that
[3] P.Chen,Y.Qi,andD.Hou,“CauseInfer:AutomatedEnd-to-EndPerfor-
mance Diagnosis with Hierarchical Causality Graph in Cloud Environ-
ment,”IEEETransactionsonServicesComputing,2019.
[4] A. Morichetta, V. C. Pujol, S. Nastic, T. Pusztai, P. Raith, S. Dustdar,
D.Vij,Y.Xiong,andZ.Zhang,“Demystifyingdeeplearninginpredictive
monitoringforcloud-nativeSLOs,”2023.
[5] B.Sedlak,V.CasamayorPujol,P.K.Donta,andS.Dustdar,“Controlling
Data Gravity and Data Friction: From Metrics to Multidimensional
ElasticityStrategies,”inIEEESSE2023,Chicago,IL,USA,Jul.2023.
[6] S. Nastic, A. Morichetta, T. Pusztai, S. Dustdar, X. Ding, D. Vij, and
Y.Xiong,“SLOC:ServiceLevelObjectivesforNextGenerationCloud
Computing,”IEEEInternetComputing,vol.24,no.3,May2020.
[7] E.C.Mart´ınez,J.W.Kim,T.Barz,andM.Cruz,“ProbabilisticModeling
(a) Polynomial regression function (b) Prediction errors for Optimization of Bioreactors using Reinforcement Learning with
ActiveInference,”ComputerAidedChemicalEngineering,2021.
Fig. 5: Estimated relation between utilization and part delay [8] K. J. Friston, J. Daunizeau, and S. J. Kiebel, “Reinforcement Learning
orActiveInference?”PLOSONE,vol.4,no.7,p.e6421,Jul.2009.
[9] K.Friston,“Lifeasweknowit,”JournalofTheRoyalSocietyInterface,
vol.10,no.86,p.20130475,Sep.2013.
a larger sample size improved the accuracy, but also that a [10] M. Kirchhoff, T. Parr, E. Palacios, K. Friston, and J. Kiverstein, “The
relatively small number of samples (i.e., 30) provided initially Markovblanketsoflife:autonomy,activeinferenceandthefreeenergy
principle,”JournalofTheRoyalSocietyInterface,2018.
acceptable results.
[11] R.Smith,K.J.Friston,andC.J.Whyte,“Astep-by-steptutorialonactive
inferenceanditsapplicationtoempiricaldata,”JournalofMathematical
VI. CONCLUSION Psychology,vol.107,p.102632,Apr.2022.
[12] N. Sajid, P. J. Ball, T. Parr, and K. J. Friston, “Active inference:
An ML model should not only reflect a generative process
demystifiedandcompared,”NeuralComputation,vol.33,no.3,pp.674–
at one moment; ideally, it should persist over time without 712,Mar.2021.
losing its precision. However, as long as the model is not [13] J. Pearl, Probabilistic reasoning in intelligent systems : networks of
plausibleinference. SanMateo,Calif.:MorganKaufmann,1988.
retrained, a lack of continuous feedback inevitably leads to
[14] N. Ganguly et al., “A Review of the Role of Causality in Developing
pooraccuracy.Thus,anysystemthataimstodynamicallyadapt TrustworthyAISystems,”Feb.2023.
its service must supervise its inference mechanisms to ensure [15] M. Tariq, A. Zeitoun, V. Valancius, N. Feamster, and M. Ammar,
“Answeringwhat-ifdeploymentandconfigurationquestionswithwise,”
QoSisfulfilled.Withtheintentiontosolvethis,wepresenteda
ACMSIGCOMMComputerCommunicationReview,2008.
distributed agent that is based on Active Inference – a concept [16] Y. W. Teh, M. Welling, S. Osindero, and G. E. Hinton, “Energy-Based
from neuroscience that describes how the brain constantly Models for Sparse Overcomplete Representations,” Journal of Machine
LearningResearch,vol.4,pp.1235–1260,Dec.2003.
predicts and evaluates sensory information to decrease long-
[17] K. Veeramachaneni, I. Arnaldo, V. Korrapati, C. Bassias, and K. Li,
term surprise. Operating in cycles, the agent maximizes the “AIˆ2: Training a Big Data Machine to Defend,” in IEEE Big Data
modelevidencebyexploringthespaceofvaluesthatfulfillthe Security,Apr.2016,pp.49–54.
[18] M.Simsek,B.Kantarci,andY.Zhang,“DetectingFakeMobileCrowd-
QoS. Thus, the agent improves any decision-making based on
sensingTasks:EnsembleMethodsUnderLimitedData,”IEEEVehicular
the ML model because ambiguities are repeatedly resolved. TechnologyMagazine,vol.15,no.3,pp.86–94,Sep.2020.
To solve a smart manufacturing use case, we presented a [19] X. Huang, L. He, and W. Zhang, “Vehicle Speed Aware Computing
Task Offloading and Resource Allocation Based on Multi-Agent Rein-
design study that defines the agent’s behavior when creating
forcementLearninginaVehicularEdgeComputingNetwork,”inIEEE
a generative model. Which action the agent takes and how it InternationalConferenceonEdgeComputing(EDGE),Oct.2020.
adaptsitsbeliefsisdeterminedbythreemainfactors:pragmatic [20] H. Guo, J. Liu, and J. Lv, “Toward Intelligent Task Offloading at the
Edge,”IEEENetwork,vol.34,no.2,pp.128–134,Mar.2020.
value, assigned risk (of violating SLOs), and information gain.
[21] J. Fu¨rst, M. Fadel Argerich, B. Cheng, and A. Papageorgiou, “Elastic
We implemented the ACI agent in Python and tracked each Services for Edge Computing,” in 2018 14th International Conference
cycle’s preferred action – including the factors that led to it – onNetworkandServiceManagement(CNSM),Nov.2018,pp.358–362.
[22] G.Levchuk,K.Pattipati,D.Serfaty,A.Fouse,andR.McCormack,“Ac-
and the agent’s causal understanding between two variables.
tiveInferenceinMultiagentSystems:Context-DrivenCollaborationand
After 5 cycles, the agent converged to a solution that pre- DecentralizedPurpose-DrivenTeamAdaptation,”inArtificialIntelligence
sented an optimal tradeoff between high pragmatic value and fortheInternetofEverything. AcademicPress,Jan.2019.
[23] T. Pusztai, A. Morichetta, V. C. Pujol, S. Dustdar, S. Nastic, X. Ding,
negligible SLO violations. Further, the agent needed only 30
D.Vij,andY.Xiong,“ANovelMiddlewareforEfficientlyImplementing
observations (i.e., 2 cycles) to estimate a previously unknown ComplexCloud-NativeSLOs,”in2021IEEE14thInternationalConfer-
variable relation. Exploring causalities between variables and enceonCloudComputing(CLOUD),Sep.2021,pp.410–420.
[24] M. G. Vilas, R. Auksztulewicz, and L. Melloni, “Active Inference as a
constructing the agent’s behavior from empirical factors makes
ComputationalFrameworkforConsciousness,”ReviewofPhilosophyand
theproducedsolutionstraceable.Basedontheseresults,wesee Psychology,vol.13,no.4,pp.859–878,Dec.2022.
astrongpotentialforACItosupportelasticcomputingsystems [25] C.Heins,B.Millidge,D.Demekas,B.Klein,K.Friston,I.Couzin,and
A. Tschantz, “pymdp: A Python library for active inference in discrete
by continuously ensuring the precision of ML models.
statespaces,”JournalofOpenSourceSoftware,May2022.
[26] T.Parr,G.Pezzulo,andK.J.Friston,ActiveInference:TheFreeEnergy
REFERENCES
PrincipleinMind,Brain,andBehavior. TheMITPress,Mar.2022.
[1] S. Deng, H. Zhao, W. Fang, J. Yin, S. Dustdar, and A. Y. Zomaya, [27] B.Sedlak,I.Murturi,P.K.Donta,andS.Dustdar,“APrivacyEnforcing
“Edge Intelligence: The Confluence of Edge Computing and Artificial FrameworkforTransformingDataStreamsontheEdge,”IEEETransac-
Intelligence,”IEEEInternetofThingsJournal,Aug.2020. tionsonEmergingTopicsinComputing,2023.
[2] V.C.Pujol,P.K.Donta,A.Morichetta,I.Murturi,andS.Dustdar,“Edge
intelligence—researchopportunitiesfordistributedcomputingcontinuum
systems,”IEEEInternetComputing,vol.27,no.4,pp.53–74,2023.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Active Inference on the Edge: A Design Study"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
