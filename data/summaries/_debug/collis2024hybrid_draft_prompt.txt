=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical Planning and Control
Citation Key: collis2024hybrid
Authors: Poppy Collis, Ryan Singh, Paul F Kinghorn

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2024

Key Terms: systems, recurrent, descriptions, support, planning, emergent, models, hierarchical, hybrid, control

=== FULL PAPER TEXT ===

Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical
Planning and Control
PoppyCollis*1 RyanSingh*12 PaulFKinghorn1 ChristopherLBuckley12
Abstract sentsahighlydesirablefeatureinthedesignofautonomous
systems. Humansareabletoflexiblyspecifyabstractsub-
Anopenprobleminartificialintelligenceishow
goalsduringplanning,therebyreducingproblemsintoman-
systems can flexibly learn discrete abstractions
ageablechunks(Newell&Simon,1972;Gobetetal.,2001).
thatareusefulforsolvinginherentlycontinuous
Furthermore,theyareabletotransferthisknowledgeacross
problems. Previousworkhasdemonstratedthata
newtasks;aprocesswhichhasprovenacentralchallenge
classofhybridstate-spacemodelknownasrecur-
in artificial intelligence (d’Avila Garcez & Lamb, 2023).
rentswitchinglineardynamicalsystems(rSLDS)
Translatingproblemsintodiscretespaceoffersdistinctad-
discover meaningful behavioural units via the
vantages in decision-making. Namely, the computation-
piecewiselineardecompositionofcomplexcon-
allyfeasibleapplicationofinformation-theoreticmeasures
tinuousdynamics(Lindermanetal.,2016). Fur-
(e.g. information-gain), aswellasthedirectimplementa-
thermore,theymodelhowtheunderlyingcontinu-
tionofclassicaltechniquessuchasdynamicprogramming
ousstatesdrivethesediscretemodeswitches. We
(LaValle, 2006; Friston et al., 2023). One prevalent ap-
proposethattherichrepresentationsformedbyan
proach to tackling continuous spaces involves the simple
rSLDScanprovideusefulabstractionsforplan-
grid-based discretisation of the state-space, however this
ningandcontrol. Wepresentanovelhierarchical
becomesextremelycostlyasthedimensionalityincreases
model-basedalgorithminspiredbyActiveInfer-
(Coulom,2007;Mnihetal.,2015).Wethereforeaskhowwe
enceinwhichadiscreteMDPsitsabovealow-
mightbeabletosmoothlyhandlethepresenceofcontinuous
level linear-quadratic controller. The recurrent
variableswhilstmaintainingthebenefitsofdecision-making
transitiondynamicslearnedbytherSLDSallow
inthediscretedomain.
usto(1)specifytemporally-abstractedsub-goals
inamethodreminiscentoftheoptionsframework, Toaddressthis,weexploretherichrepresentationslearned
(2)lifttheexplorationintodiscretespaceallow- byrecurrentswitchinglineardynamicalsystems(rSLDS)
ingustoexploitinformation-theoreticexploration in the context of planning and control. This class of hy-
bonusesand(3)‘cache’theapproximatesolutions bridstate-spacemodelconsistsofdiscretelatentstatesthat
tolow-levelproblemsinthediscreteplanner. We evolveviaMarkoviantransitions,whichacttoindexadis-
successfullyapplyourmodeltothesparseCon- crete set of linear dynamical systems (Linderman et al.,
tinuous Mountain Car task, demonstrating fast 2016). Importantly,acontinuousdependencyinthediscrete
system identification via enhanced exploration state transition probabilities is included in the generative
andnon-trivialplanningthroughthedelineation model. Byprovidinganunderstandingofthecontinuous
ofabstractsub-goals. latentcausesofswitchesbetweendiscretemodes,thisre-
currenttransitionstructurecanbeexploitedsuchthatacon-
trollercanflexiblyspecifyinputstodrivethesysteminto
a desired region of the state-action space. By embracing
1.Introduction theestablishedcontrol-theoreticstrategyofpiecewiselinear
decomposition of nonlinear dynamics, our approach lies
Inaworldthatisinherentlycontinuous,thebrain’sapparent
incontrasttothecomparativelyopaquesolutionsfoundby
capacitytodistildiscreteconceptsfromsensorydatarepre-
continuousfunctionapproximators(Liberzon,2003;Mnih
et al., 2015). Using statistical methods to fit these mod-
*Equalcontribution 1SchoolofEngineeringandInformatics,
UniversityofSussex,Brighton,UK2VERSESAIResearchLab, elsprovidesameansbywhichwecaneffectivelyperform
LosAngeles,California,USA.Correspondenceto:PoppyCollis online discovery of useful non-grid discretisations of the
<pzc20@sussex.ac.uk>. state-spaceforsystemidentificationandcontrol.
Wedescribeanovelmodel-basedalgorithminspiredbyAc-
1
4202
guA
02
]IA.sc[
1v07901.8042:viXra
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
Figure1.HHAsolvesnonlinearproblemsviaspecifyingabstractsub-goalsinstate-space. (a)Piecewiselineardynamicsofthe
ContinuousMountainCarstate-spacefoundbyrSLDS.Rewardlocationshown(blacktriangle). WhiletherSLDSretrives5modes
intotal,hereweplotonlythemodesseenintheposition-velocity(x)spacewithoutshowingthecontrolinput(u)axis. (b)Example
trajectory(segmentscolouredbymode)showingtheHHAconsistentlynavigatingtothegoal.(c)Continuouscontrolinput(colouredby
discreteactionspecifiedbyplannerandarrowsizeindicatingmagnitudeanddirection)oversameexampletrajectoryin(b).
tiveInference(Parretal.,2022),inwhichadiscreteMDP, approximation,incontrast,welearnonlinewithoutexpert
informed by the representations of an rSLDS, interfaces dataandfocusonflexiblediscreteplanning.
withafinitehorizonlinear-quadraticregulator(LQR)imple-
mentingclosed-loopcontrol. Wedemonstratetheefficacy
3.Framework
ofthisalgorithmbyapplyingittotheclassiccontroltaskof
ContinuousMountainCar(OpenAI,2021). Weshowthat Here, we provide a overall outline of the approach to ap-
information-theoreticexplorationdriveintegratedwiththe proximatecontroltakenwithourHybridHierarchicalAgent
emergentpiecewisedescriptionofthetask-spacefacilitates (HHA)algorithm. Considerthatwehavedecomposedthe
fastsystemidentificationtofindsuccessfulsolutionstothis nonlineardynamicsintopiecewiseaffineregionsofthestate-
non-trivialplanningproblem. spaceusinganrSLDS.ShouldtheHHAwishtonavigate
toagoalspecifiedincontinuousspace,therecurrentgen-
1.1.Contributions erativemodelparametersoftherSLDSallowittoidentify
thediscreteregionwithinwhichthegoalresides,thereby
• Theenhancementofplanningviatheintroductionof
liftingthegoalintoahigh-levelobjective. Theagentmay
temporally-abstractedsub-goalsbydecouplingadis-
thengenerateaplanatadiscretelevel,makinguseofthe
creteMDPfromthecontinuousclocktimeusingthe
information-seeking bonuses that this affords. Planning
emergentrepresentationsfromanrSLDS.
translates to specifying a sequence of abstract sub-goals.
Againusingtherecurrentgenerativemodel,theagentcan
• The lifting of information-seeking decision-making
specify, for each sub-goal region, a continuous point in
intoa(discrete)abstractionofthestatesenablingef-
state-spacewithwhichtodrivethesysteminto. Onceinthe
ficientexplorationandtherebyreducingsensitivityto
discretegoalregion,theagentstraightforwardlynavigates
thedimensionalityofthetask-space.
to the continuous goal. The following sections detail the
componentsoftheHHA.Foradditionalinformation,please
2.Relatedwork refertoAppendix.A
Inthecontextofcontrol,hybridmodelsintheformofpiece-
3.1.rSLDS(ro)
wiseaffine(PWA)systemshavebeenrigorouslyexamined
andarewidelyappliedinreal-worldscenarios(Bemporad In the recurrent-only (ro) formulation of the rSLDS, the
et al., 2000; Borrelli et al., 2006). Previous work by Ab- discretelatentstatesz ∈ {1,2,...,K}aregeneratedasa
t
dulsamadet. al. hasappliedavariantonrSLDS(recurrent functionofthecontinuouslatentsx ∈RM andthecontrol
t
autoregressivehiddenMarkovmodels)totheoptimalcon- inputu ∈RN viaasoftmaxregressionmodel
t
trol of general nonlinear systems (Abdulsamad & Peters,
P(z |x ,u )=softmax(W x +W u +r) (1)
2023;2020). Theauthorsusethesemodelstotheapproxi- t+1 t t x t u t
mateexpertcontrollersinaclosed-loopbehaviouralcloning wherebyW andW areweightmatriceswithdimensions
x u
context. Whiletheiralgorithmfocusesonvaluefunction RK×M andrisabiasofsizeRK. Thecontinuousdynam-
2
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
Figure2.HHAwithinformation-gainexploredawiderrangeofthestate-space.State-spacecoverageinContinuousMountainCar
after10,000stepsandbestof3runsfor(a)HHAwithinformation-gaindrive,(b)HHAwithoutinformationgaindriveand(c)randomly
sampledcontinuousactionsbaseline.
icsevolveaccordingtoadiscretelineardynamicalsystem providing the agent with an optimistic bias during policy
indexedbyz withGaussiandiagonalnoise, inference(Millidgeetal.,2020;Parretal.,2022).
t
x |x ,u ,z =A x +B u +b +ν , The discrete planner outputs a discrete action, where the
t+1 t t t zt t zt t zt t
(2) firstactionistakenfromarecedinghorizonoptimisation:
ν ∼N(0,Q )
t zt
a =argminJ(a ) (4)
0 1:T
y
t
|x
t
=C
zt
x
t
+ω
t
, ω
t
∼N(0,S
zt
) (3) a1:T
T
andidentityemissionsmodelwithGaussiandiagonalnoise. (cid:88)
J(a )=E[ R(s ,a )+IG (α)|s ,a ]. (5)
InordertolearntherSLDSparametersusingBayesianup- 1:T t t t 0 1:T
t=0
dates, conjugate matrix normal inverse Wishart (MNIW)
This includes an explicit information-seeking incentive
priorsareplacedontheparametersofthedynamicalsystem
IG (α) (see A.4). This descending discrete action a is
and recurrence weights. Inference requires approximate t 0
translatedintoacontinuouscontrolpriorx viathefollow-
methodsgiventhattherecurrentconnectionsbreakconju- j
inglinkfunction,
gacy rendering the conditional likelihoods non-Gaussian.
DetailsoftheLaplaceVariationalExpectationMaximisation x =argmaxP(z =j|x,u) (6)
j
algorithmusedisdetailedin(Zoltowskietal.,2020). x
whichrepresentsanapproximatelycentralpointinthede-
3.2.Discreteplanner sireddiscreteregionjrequestedbyactiona (seeA.6). The
0
ascendingmessagesfromthecontinuouslevelaretranslated
WehaveaBayesianMarkovDecisionProcess(MDP)(Vlas-
intoacategoricaldistributionviatherSLDSsoftmaxlink
sisetal.,2012)describedbyM = (S,A,P ,R,P ). S
B a θ function. Importantly,thediscreteplannerisonlytriggered
representsthesetofallpossiblediscretestatesofthesystem
whenthesystemswitchesintoanewmode1. Inthissense,
and are essentiallya re-description of the discretelatents
discrete actions are temporally abstracted and decoupled
Z foundbytherSLDS.Aisthesetofallpossibleactions
fromcontinuousclock-timeinamethodreminiscentofthe
which,inourcase,isequaltothenumberofstatesS. The
optionsframework(Suttonetal.,1999;Danieletal.,2016).
statetransitionprobabilities,p (s |s =s,a =a,θ)∼
a t+1 t t
Cat(θ ),andareparameterisedbyθ ∈Rs×s×aforwhich
as
3.3.Continuouscontroller
wemaintainDirichletpriorsover,p(θ ) ∼ Dir(α ),fa-
as as
cilitatingdirectedexploration. Duetoconjugatestructure, Continuous closed-loop control is handled by a finite-
astheagentobtainsnewempiricalinformation,Bayesian horizon linear-quadratic regulator (LQR) controller. For
updatesamounttoasimplecount-basedupdateoftheDirich- controlling the transition from mode i to mode j (x to
i
letparameters(Murphy,2012). Importantly,thestructure x ). TheobjectiveoftheLQRcontrolleristominimisethe
j
of the state transition model has been constrained by the followingquadraticcostfunction:
adjacency structure of the polyhedral partitions extracted
π (x)=argminJ (π) (7)
fromrecurrenttransitiondynamicsoftherSLDS:invalid ij ij
π
transitions are assigned zero probability while valid tran- (cid:20)
sitionsareassignedahighprobability(seeA.5). Risthe J ij (π)=E π,xi (x S −x j )TQ f (x S −x j )
rewardfunctionwhich,translatedintotheActiveInference
framework,actsasapriordistributionoverrewardingstates 1Oramaximumdwell-time(hyperparameter)isreached.
3
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
S (cid:88) −1 (cid:21) driveinpolicyselectioncomparedtowithout. Interestingly,
+ uTRu (8)
t t evenwithoutinformation-gain,theareacoveredbytheHHA
t=0 isstillnotablybetterthanthatoftherandomactioncontrol.
where S is the finite time horizon, Q f is the matrix that Thisisbecausethenon-griddiscretisationofthestate-space
penalisestheterminalstatedeviationfromx j andRisthe significantlyreducesthedimensionalityofthesearchspace
controlcostwherehighcontrolinputispenalisedsuchthat inabehaviourallyrelevantway.
thecontrolleronlyprovidessolutionswithinconstraints(for
WecomparetheperformanceoftheHHAtootherreinforce-
furtherdiscussion,seeSec.5).Theapproximateclosed-loop
mentlearningbaselines(Actor-CriticandSoftActor-Critic)
solutiontoeachofthesesub-problemsiscomputedoffline
andfindthattheHHAbothfindstherewardandcaptilises
bytakingintheparametersofthelinearsystemsindexedby
onitsexperiencesignificantlyquickerthantheothermodels
thediscretemodesandthecontinuouscontrolpriorsacting
(see Fig. 3). Indeed, our model competes with the state-
asreferencepoints(seeA.3).
spacecoverageachievedbymodel-basedalgorithmswith
exploratoryenhancementsinthediscreteMountainCartask,
4.Results
whichisinherentlyeasiertosolve(see A.8).
Toevaluatetheperformanceofour(HHA)model,weap-
pliedittotheclassiccontrolproblemofContinuousMoun- 5.Discussion
tainCar. Thisproblemisparticularlyrelevantforourpur-
ThroughtheapplicationofourHybridHierarchicalAgent
posesduetothesparsenatureoftherewards,necessitating
totheContinuousMountainCarproblem,wehavedemon-
effectiveexplorationstrategiestoachievegoodperformance.
stratedthatrSLDSrepresentationsholdpromiseforenrich-
TheHHAisinitialisedaccordingtotheprocedureoutlined
ingplanningandcontrol. Theemergenceofnon-griddis-
in (Linderman et al., 2016). The rSLDS parameters are
cretisationsofthestate-spaceallowsustoperformfastsys-
thenfittedtotheobservedtrajectoriesevery1000stepsof
temsidentificationviaenhancedexploration,andsuccessful
theenvironmentunlessarewardthresholdwithinasingle
non-trivialplanningthroughthedelineationofabstractsub-
episodeisreached.
goals. Hence,thetimespentexploringeachregionisnot
equivalentineuclideanspacewhichhelpsmitigatethecurse
ofdimensionalitythatothergrid-basedmethodssufferfrom.
Such a piecewise affine approximation of the space will
incursomelossofoptimalityinthelongrunwhenpitted
againstblack-boxapproximators.Thisisduetothenatureof
cachingonlyapproximateclosed-loopsolutionstocontrol
withineachpiecewiseregion,whilstthediscreteplannerim-
plementsopen-loopcontrol. However,thisapproacheases
the online computational burden for flexible re-planning.
Hence in the presence of noise or perturbations within a
Figure3.HHAbothfindstherewardandcaptilisesonitsexpe-
region,thecontrollermayadaptwithoutanynewcompu-
riencesignificantlyquickerthanothermodel-freeRLbaselines.
tation. Thisisincontrasttoothernonlinearmodel-based
Averagereward(+/-std)over6runsforContinuousMountainCar
algorithmslikemodel-predictivecontrolwherereactingto
(20 episodes, max episode length of 200 steps) for HHA (our
model),Soft-ActorCritic(with2Q-functions),andActor-Critic disturbancesrequiresexpensivetrajectoryoptimisationat
models.Notethatafter20episodes,SACandACareyettofind every step (Schwenzer et al., 2021). By using the piece-
therewardandconvergeonasolution. wiseaffineframework,wemaintainfunctionalsimplicity
andinterpretabilitythroughstructuredrepresentation. This
WefindthattheHHAfindspiecewiseaffineapproximations method is amenable to future alignment with a control-
ofthetask-spaceandusesthesediscretemodeseffectively theoreticapproachtosafetyguaranteesforensuringrobust
to solve the task. Fig.1 shows that while the rSLDS has systemperformanceandreliability.
divided up the space according to position, velocity and
Weacknowledgetheremaybebettersolutionstodealing
control input, the useful modes for solving the task are
withcontrolinputconstraintsthantheonegiveninSec.3.3.
those found in the position space. Once the goal and a
Differentapproacheshavebeentakentotheproblemofim-
goodapproximationtothesystemhasbeenfound,theHHA
plementingconstrained-LQRcontrol,suchasfurtherpiece-
successfullyandconsistentlynavigatestothereward.
wiseapproximationbasedondefiningreachabilityregions
Fig.2showsthattheHHAperformsacomprehensiveex- forthecontroller(Bemporadetal.,2002).
plorationofthestate-spaceandsignificantgainsinthestate-
spacecoverageareobservedwhenusinginformation-gain
4
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
ImpactStatement N., Markovic, D., Parr, T., Verbelen, T., and Buck-
ley, C. L. Supervised structure learning, 2023. URL
Thispaperpresentsworkwhosegoalistoadvancethefield
https://arxiv.org/abs/2311.10300.
of Machine Learning. There are many potential societal
consequences of our work, none which we feel must be Gobet,F.,Lane,P.,Croker,S.,Cheng,P.,Jones,G.,Oliver,
specificallyhighlightedhere. I.,andPine,J. Chunkingmechanismsinhumanlearning.
Trendsincognitivesciences,5:236–243,072001. doi:
References 10.1016/S1364-6613(00)01662-4.
Abdulsamad,H.andPeters,J. Hierarchicaldecomposition Gou,S.Z.andLiu,Y. DQNwithmodel-basedexploration:
ofnonlineardynamicsandcontrolforsystemidentifica- efficientlearningonenvironmentswithsparserewards.
tionandpolicydistillation. InBayen,A.M.,Jadbabaie, CoRR,abs/1903.09295,2019.
A.,Pappas,G.,Parrilo,P.A.,Recht,B.,Tomlin,C.,and
Heins,C.,Millidge,B.,Demekas,D.,Klein,B.,Friston,K.,
Zeilinger,M.(eds.),Proceedingsofthe2ndConference
Couzin,I.,andTschantz,A. pymdp: Apythonlibraryfor
onLearningforDynamicsandControl,volume120of
activeinferenceindiscretestatespaces. arXivpreprint
ProceedingsofMachineLearningResearch,pp.904–914.
arXiv:2201.03904,2022.
PMLR,10–11Jun2020.
Abdulsamad, H. and Peters, J. Model-based reinforce- LaValle,S.M. PlanningAlgorithms,chapter2. Cambridge
mentlearningviastochastichybridmodels. IEEEOpen UniversityPress,Cambridge,2006.
Journal of Control Systems, 2:155–170, 2023. doi:
Liberzon,D. SwitchinginSystemsandControl. Systems&
10.1109/OJCSYS.2023.3277308.
Control:Foundations&Applications.Birkha¨userBoston,
Bemporad,A.,Borrelli,F.,andMorari,M. Piecewiselinear 2003. ISBN9780817642976.
optimalcontrollersforhybridsystems. InProceedingsof
Linderman,S.W.,Miller,A.C.,Adams,R.P.,Blei,D.M.,
the2000AmericanControlConference.ACC(IEEECat.
Paninski, L., and Johnson, M. J. Recurrent switching
No.00CH36334),volume2,pp.1190–1194vol.2,2000.
lineardynamicalsystems,October2016.
doi: 10.1109/ACC.2000.876688.
Millidge,B.,Tschantz,A.,Seth,A.K.,andBuckley,C.L.
Bemporad,A.,Morari,M.,Dua,V.,andPistikopoulos,E.N.
Ontherelationshipbetweenactiveinferenceandcontrol
The explicit linear quadratic regulator for constrained
asinference,2020.
systems.Automatica,38(1):3–20,2002.ISSN0005-1098.
doi: https://doi.org/10.1016/S0005-1098(01)00174-1.
Mnih,V.,Kavukcuoglu,K.,Silver,D.,Rusu,A.A.,Veness,
Borrelli,F.,Bemporad,A.,Fodor,M.,andHrovat,D. An J.,Bellemare,M.G.,Graves,A.,Riedmiller,M.A.,Fidje-
mpc/hybridsystemapproachtotractioncontrol. IEEE land,A.K.,Ostrovski,G.,Petersen,S.,Beattie,C.,Sadik,
TransactionsonControlSystemsTechnology,14(3):541– A.,Antonoglou,I.,King,H.,Kumaran,D.,Wierstra,D.,
552,2006. doi: 10.1109/TCST.2005.860527. Legg,S.,andHassabis,D. Human-levelcontrolthrough
deepreinforcementlearning. Nature,518:529–533,2015.
Coulom, R. Efficientselectivityand backup operatorsin
monte-carlotreesearch. InvandenHerik,H.J.,Ciancar- Murphy,K.P.Machinelearning:aprobabilisticperspective.
ini,P.,andDonkers,H.H.L.M.J.(eds.),Computersand MITpress,2012.
Games, pp. 72–83, Berlin, Heidelberg, 2007. Springer
Newell, A. and Simon, H. A. Human Problem Solving.
BerlinHeidelberg. ISBN978-3-540-75538-8.
Prentice-Hall,EnglewoodCliffs,NJ,1972.
Daniel, C., van Hoof, H., Peters, J., and Neumann, G.
Probabilistic inference for determining options in re- OpenAI. Continuousmountaincarenvironment,2021. Ac-
inforcement learning. Machine Learning, 104(2):337– cessed: 2024-05-25.
357,September2016. ISSN1573-0565. doi: 10.1007/
Parr,T.,Pezzulo,G.,andFriston,K. ActiveInference: The
s10994-016-5580-x.
FreeEnergyPrincipleinMind,Brain,andBehavior.MIT
d’AvilaGarcez,A.andLamb,L.C. Neurosymbolicai: the Press,2022. ISBN9780262045353.
3rdwave. ArtificialIntelligenceReview,56(11):12387–
Schwenzer, M., Ay, M., Bergs, T., and Abel, D. Review
12406,November2023. ISSN1573-7462. doi: 10.1007/
onmodelpredictivecontrol: anengineeringperspective.
s10462-023-10448-w.
The International Journal of Advanced Manufacturing
Friston, K.J., Costa, L.D., Tschantz, A., Kiefer, A., Sal- Technology,117(5):1327–1349,November2021. ISSN
vatori, T., Neacsu, V., Koudahl, M., Heins, C., Sajid, 1433-3015. doi: 10.1007/s00170-021-07682-3.
5
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
Sutton, R. S., Precup, D., and Singh, S. Between mdps
andsemi-mdps: Aframeworkfortemporalabstraction
inreinforcementlearning. ArtificialIntelligence,112(1):
181–211,1999. ISSN0004-3702. doi: https://doi.org/10.
1016/S0004-3702(99)00052-1.
Vlassis,N.,Ghavamzadeh,M.,Mannor,S.,andPoupart,P.
BayesianReinforcementLearning,pp.359–386.Springer
BerlinHeidelberg,Berlin,Heidelberg,2012. ISBN978-
3-642-27645-3. doi: 10.1007/978-3-642-27645-3 11.
Zoltowski,D.M.,Pillow,J.W.,andLinderman,S.W. Uni-
fyingandgeneralizingmodelsofneuraldynamicsduring
decision-making,2020.
6
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
A.Appendix/supplementalmaterial
A.1.Framework
OptimalControl
Weadopttheoptimalcontrolframework,specificallyweconsiderdiscretetimestatespacedynamicsoftheform:
x =f(x ,u ,η ) (9)
t+1 t t t
with known initial condition x , and η drawn from some time invariant distribution η ∼ D, where f we assume
0 t t
p(x |x ,u )isavalidprobabilitydensitythroughout.
t+1 t t
We use c : X ×U → R for the control cost function at time t and let U be the set of admissible (non-anticipative,
t
continuous)feedbackcontrollaws,possiblyrestrictedbyaffineconstraints. Theoptimalcontrollawforthefinitehorizon
problemisgivenas:
T
(cid:88)
J(π)=E [ c (x ,u )] (10)
x0,π t t t
t=0
π∗ =argminJ(π) (11)
π∈U
PWAOptimalControl
Thefactwedonothaveaccesstothetruedynamicalsystemf motivatestheuseofapiecewiseaffine(PWA)approximation.
Alsoknownashybridsystems:
x =A x +B u +ϵ (12)
t+1 i t i t t
when(x ,u )∈H (13)
t t i
WhereH={H :i∈[K]}isapolyhedralpartitionofthespaceX×U.
i
Inthecaseofaquadraticcostfunction,itcanbeshowntheoptimalcontrollawforsuchasystemispeicewiselinear. Further
there exist many completeness (universal approximation) type theorems for peicewise linear approximations implying
iftheoriginalsystemiscontrollable,therewillexistapeicewiseaffineapproximationthroughwhichthesystemisstill
controllable(Bemporadetal.,2000;Borrellietal.,2006).
RelationshiptorSLDS(ro)
WeperformacanonicaldecompositionofthecontrolobjectiveJ intermsofthecomponentsormodesofthesystem. By
slightabuseofnotation[x =i]:=[(x ,u )∈H ]representtheIversonbracket.
t t t i
(cid:90)
(cid:88)
J(π)= p (x |x ,u )c (x ,u )dx dx (14)
π t t−1 t t t t t t−1
t
(cid:90)
(cid:88) (cid:88)
= [x =i]p (x |x ,u )c (x ,u )dx dx (15)
t−1 π t t−1 t t t t t t−1
t i∈[K]
(16)
Nowletz betherandomvariableon[K]inducedbyZ =iif[x =i]wecanrewritetheabovemoreconciselyas,
t t t
(cid:90)
(cid:88) (cid:88)
J(π)= p (x ,z =i|x ,u )c (x ,u )dx dx (17)
π t t−1 t−1 t t t t t t−1
t i∈[K]
(cid:90)
(cid:88) (cid:88)
= p (x ,z =i|x ,u )c (x ,u )dx dx (18)
π t t−1 t−1 t t t t t t−1
i∈[K] t
(cid:88) (cid:88)
= E [c (x ,u )] (19)
πi t t t
i∈[K] t
7
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
(20)
whichisjusttheexpectationunderarecurrentdynamicalsystemwithdeterministicswitches. Later(seeA.4),weexploitthe
non-deterministicswitchesofrSLDSinordertodriveexploration.
A.2.HierarchicalDecomposition
Ouraimwastodecouplethediscreteplanningproblemfromthefastlow-levelcontroller. Inordertobreakdownthecontrol
objectiveinthismanner,wefirstcreateanewdiscretevariablewhichsimplytracksthetransitionsofz,thisallowsthe
discreteplannertofunctioninatemporallyabstractedmanner.
DecouplingfromclocktimeLettherandomvariable(ζ ) recordthetransitionsof(z ) i.e. let
s s>0 t t>0
τ (τ )=min{t:z ̸=z ,t>τ },τ =0 (21)
s s−1 t+1 t s−1 0
bethesequenceoffirstexittimes,thenζ isgivenbyζ =z .
s τs
Withthesevariablesinhand,weframeasmallsectionoftheglobalproblemasafirstexitproblem.
LowlevelproblemConsiderthefirstexitproblemdefinedby,
π (x )=argminJ (π,x ,S) (22)
ij 0 ij 0
π,S
S
(cid:88)
J (π,x ,S)=E [ c(x ,u )] (23)
ij 0 π,x0 t t
t=0
s.t. (x ,u )∈H (24)
t t i
s.t. c(x,u)=0when(x,u)∈∂H (25)
ij
(cid:84)
where∂H istheboundaryH H .
ij i j
Due,toconvexityofthepolyhedralpartition,thefullobjectiveadmitsthedecompositionintosubproblems
(cid:88)
J(π)= J (π) (26)
ζ(s+1),ζ(s)
s
(27)
SlowandfastmodesThegoalistotacklethedecomposedobjectivesindividually,howeverthehiddenconstraintthatthe
trajectorieslineuppresentsacomputationalchallenge. Herewemaketheassumptionthatthedifferenceincostinduced
bydifferentstartingpositions,inducesarelativelysmallchangeintheminimumcostJ ,intuitivelythishappensifthe
ij
minimumstatecostineachmodeisrelativelyuniformascomparedtothedifferencebetweenregions.
HighlevelproblemIftheaboveassumptionholds,weletJ∗ = min (cid:82) J (π,x )p(x )betheaveragecostofeach
ij π x0 ij 0 0
low-levelproblem. Weformamarkovchain:
p (u)=P(ζ =k |ζ =i,π∗,ud =j) (28)
ik s+1 s ij
andletp betheassociateddistributionovertrajectoriesinducedbysomediscretestatefeedbackpolicy,alongwiththe
πd
discretestateactioncostc (ud =j,η =i)=J∗ wemaywritethehighlevelproblem:
d ij
π∗ =minJ (π,η ) (29)
d d 0
πd
S
(cid:88)
=Ep [ c (η ,ud)] (30)
πd d s s
s=0
Ourapproximatecontrollawisthengivenbyπ∗ ◦π∗◦id(x)
ij d
8
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
A.3.OfflineLowLevelProblems: LinearQuadraticRegulator(LQR)
Ratherthansolvethefirst-exitproblemdirectly,weformulateanapproximateproblembyfindingtrajectoriesthatendat
specific‘controlpriors’(seeA.6). Recallthelowlevelproblemgivenby:
π (x )=argminJ (π,x ,S) (31)
ij 0 ij 0
π,S
S
(cid:88)
J (π,x ,S)=E [ c(x ,u )] (32)
ij 0 π,x0 t t
t=0
s.t. (x ,u )∈H (33)
t t i
s.t. c(x,u)=0when(x,u)∈∂H (34)
ij
InordertoapproximatethisproblemwithonesolvablebyafinitehorizonLQRcontroller,weadoptafixedgoalstate,
x∗ ∈H . Imposingcostsc (x ,u )=uTRu andc (x ,u )=(x−x∗)Q (x−x∗). Formallywesolve,
j t t t t t S S S f
π (x )=argminJ (π,x ,S) (35)
ij 0 ij 0
π,S
S−1
(cid:88)
J (π,x ,S)=E [(x −x∗)TQ (x −x∗)+ uTRu ] (36)
ij 0 π,x0 S f S t t
t=0
(37)
byintegratingthediscreteRicattiequationbackwards. Numerically, wefoundoptimisingoverdifferenttimehorizons
madelittledifferencetothesolution,soweoptedtoinsteadspecifyafixedhorizon(hyperparameter). Thesesolutionsare
recomputedofflineeverytimethelinearsystemmatriceschange.
DesigningthecostmatricesInsteadofimposingthestateconstraintsexplicitly,werecordahighcostwhichinformsthe
discretecontrollertoavoidthem. Inordertoapproximatetheconstrainedinputwechooseasuitablylargecontrolcost
R=rI. Weadoptedthisapproachforthesakeofsimplicity,potentiallyacceptingagooddealofsub-optimality. However,
webelievemoreinvolvedmethodsforsolvinginputconstrainedLQRcouldbeusedinfuture,e.g. (Bemporadetal.,2000),
especiallybecausewecomputethesesolutionsoffline.
A.4.Onlinehighlevelproblem
The high level problem is a discrete MDP with a ‘known’ model, so the usual RL techniques (approximate dynamic
programming,policyiteration)apply. Here,howeverwechoosetouseamodel-basedalgorithmwitharecedinghorizon
inspiredbyActiveInference,allowingustoeasilyincorporateexplorationbonuses.
Let the Bayesian MDP be given by M = (S,A,P ,R,P ) be the MDP, where p (s | s ,a ,θ) ∼ Cat(θ ) and
B a θ a t+1 t t as
p(θ )∼Dir(α)Weestimatetheopenlooprewardplusoptimisticinformationtheoreticexplorationbonuses
as
ActiveInferenceconversionWeadopttheActiveInferenceframeworkfordealingwithexploration. Accordinglyweadopt
thenotationlnp˜(s ,a )=R(s ,a )andrefertothis‘distribution’asthegoalprior(Millidgeetal.,2020),andoptimise
t t t t
overopenlooppoliciesπ =(a ,...,a ).
0 T
T
(cid:88)
J(a ,s )=E[ R(s ,a )+IG +IG |s ,a ] (38)
1:T 0 t t p s 0 1:T
t=0
whereparameterinformation-gainisgivenbyIG =D [p (θ)||p (θ)],withp (θ)=p(θ |s ). Inotherwords,we
p KL t+1 t t 0:t
addabonuswhenweexpecttheposteriortodivergefromtheprior,whichisexactlythetransitionswehaveobservedleast
(Heinsetal.,2022).
We also have a state information-gain term, IG = D [p (s ) || p (s )]. In this case (fully observed),
s KL t+1 t+1 t t+1
p (s ) = δ is a one-hot vector. Leaving the term E [−lnp (s )] leading to a maximum entropy term (Heins
t+1 t+1 s t t t+1
etal.,2022).
WecalculatetheabovewithMonteCarlosamplingwhichispossibleduetotherelativelysmallnumberofmodes. Local
approximationssuchasMonteCarloTreeSearchcouldeasilybeintegratedinordertoscaleuptomorerealisticproblems.
9
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
Alternatively,forrelativelystationaryenvironmentswecouldinsteadadoptapproximatedynamicprogrammingmethodsfor
morehabitualactions.
A.5.ExtractingtheadjacencymatrixfromrSLDS
InordertogeneratethepossibletransitionsfromtherSLDS,wecalculatethesetofactiveconstraintsforeachregionfrom
thesoftmaxrepresentation,p(z | x) = σ(Wx+b). Specificallytocheckregioniisadjacenttoregionj weverifythe
solutionlinearprogram:
−b =min(W −W )x (39)
j i j
s.t. (W −W )x≤(b −b )∀k ∈[K] (40)
i k i k
s.t. x∈(x ,x ) (41)
lb ub
Where(x ,x )areboundschosentoreflectrealisticvaluesfortheproblem. Thisensuresweonlylifttransitionstothe
lb ub
discretemodel,iftheyarepossible. Again,thesecanbecalculatedoffline.
We initialise the entries of the transition model in the discrete MDP for possible transitions to 0.9 facilitating guided-
explorationviainformation-gainthroughacount-basedupdatestothetransitionpriors.
A.6.Generatingcontinuouscontrolpriors
InordertogeneratecontrolpriorsfortheLQRcontrollerwhichcorrespondtoeachofthediscretestateswemustfinda
continuousstatex whichmaximisestheprobabilityofbeinginadesiredz:
i
x =argmaxP(z =i|x,u) (42)
i
x
Forthisweperformanumericaloptimisationinordertomaximisethisprobability. Considerthatthisprobabilitydistribution
P(z =i|x)isasoftmaxfunctionforthei-thclassisdefinedas:
exp(v )
σ(v )= i ,v =w ·x+r (43)
i (cid:80) exp(v ) i i i
j j
wherew isthei-throwoftheweightmatrix,xistheinputandr isthei-thbiasterm. Theupdatefunctionusedinthe
i i
gradientdescentoptimisationcanbedescribedasfollows:
x←x+η∇ σ(v ) (44)
x i
whereηisthelearningrateandthegradientofthesoftmaxfunctionwithrespecttotheinputvectorxisgivenby:
∂σ(v ) ∂v
∇ σ(v )= i · =σ(v )(e −σ(v))·W (45)
x i ∂v ∂x i i
inwhichσ(v)isthevectorofsoftmaxprobabilities,ande isthestandardbasisvectorwith1inthei-thpositionand0
i
elsewhere. ThegradientdescentprocesscontinuesuntiltheprobabilityP(z =i|x)exceedsaspecifiedthresholdθwhichwe
settobe0.7. Thisthresholdenforcesastoppingcriterionwhichisrequiredforthecasesinwhichtheregionzisunbounded.
10
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
A.7.Model-freeRLbaselines
A.7.1.SOFT-ACTORCRITICWITH2Q-FUNCTIONS
Table1. SummaryoftheSoftActor-CriticalgorithmwithmultipleQ-functions.
COMPONENT INPUT
Q-NETWORK 3×256×256×256×2
POLICYNETWORK 2×256×256×256×2
ENTROPYREGULARIZATIONCOEFF 0.2
LEARNINGRATES(QNET+POLNET) 3E-4
BATCHSIZE 60
A.7.2.ACTOR-CRITIC
Table2. SummaryoftheActor-Criticalgorithm
COMPONENT INPUT
FEATUREPROCESSING STANDARDSCALER,RBFKERNELS(4×100)
VALUE-NETWORK 4001PARAMETERS(1DENSELAYER)
POLICYNETWORK 802PARAMETERS(2DENSELAYERS)
GAMMA 0.95
LAMBDA 1E-5
LEARNINGRATES(POLICY+VALUE) 0.01
A.8.Model-basedRLbaseline
A.8.1.ADEEPQ-NETWORKWITHMODEL-BASEDEXPLORATION(DQN-MBE)
(a) HHA(ourmodel)onContinuousMountainCar (b) DQN-MBEonDiscreteMountainCar
Figure4.OnContinuousMountainCar,ourmodel(HHA)competeswiththestate-spacecoverageachievedbymodel-based
baselinesonDiscreteMountainCar(aneasierproblem)State-spacecoverageafter10,000timestepson(a)ContinuousMountainCar
taskusingourmodel(HHA)and(b)DiscreteMountainCartaskusingaDeepQ-NetworkwithModel-BasedExploration(DQN-MBE)
(Gou&Liu,2019).ExactparametersinTable3.
11
HybridRecurrentModelsSupportEmergentDescriptionsforHierarchicalPlanningandControl
Table3. SummaryofDQN-MBEalgorithm(Gou&Liu,2019)
COMPONENT INPUT
Q-NETWORK 1HIDDEN-LAYER,48UNITS,RELU
DYNAMICSPREDICTORNETWORK(FULLYCONNECTED) 2HIDDEN-LAYERS(EACH24UNITS),RELU
ϵMINIMUM 0.01
ϵDECAY 0.9995
REWARDDISCOUNT 0.99
LEARNINGRATES(QNET/DYNAMICS-NET) 0.05/0.02
TARGETQ-NETWORKUPDATEINTERVAL 8
INITIALEXPLORATIONONLYSTEPS 10000
MINIBATCHSIZE(Q-NETWORK) 16
MINIBATCHSIZE(DYNAMICSPREDICTORNETWORK) 64
NUMBEROFRECENTSTATESTOFITPROBABILITYMODEL 50
12

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Hybrid Recurrent Models Support Emergent Descriptions for Hierarchical Planning and Control"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
