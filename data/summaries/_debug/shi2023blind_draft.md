### OverviewThis paper investigates blind image quality assessment (BIQA) for computed tomography (CT) images using a novel approach combining denoising diffusion probabilistic models (DDPMs) and transformer-based evaluators. The authors propose a conditional DDPM to generate primary content from distorted CT images, followed by a transformer-based quality evaluator to predict image quality. The research demonstrates the efficacy of this approach, achieving second place in the2023 low-dose CT perceptual image quality assessment grand challenge.### MethodologyThe authors employ a conditional DDPM to emulate the active inference process of the human visual system (HVS). The DDPM is trained to generate high-quality primary content from distorted CT images, closely mimicking the primary content that the HVS would perceive. The primary content is then extracted using a transformer-based quality evaluator. The transformer-based quality evaluator is designed to process the multi-channel image tensor, which is generated by the DDPM. The authors utilize a U-Net architecture for the transformer-based quality evaluator. The U-Net architecture consists of multiple layers, each of which employs a convolutional neural network. The authors employ a Swin transformer block to enhance the multi-scale feature extraction. The authors utilize a transposed attention block to facilitate cross-channel dependency modeling. The authors employ a patch-weighted quality prediction strategy. The authors utilize a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale feature extraction. The authors employ a lightweight attention mechanism that utilizes decomposed large kernel convolutions to extract multi-scale features. The authors employ a multi-dimensional attention network to enhance the multi-scale