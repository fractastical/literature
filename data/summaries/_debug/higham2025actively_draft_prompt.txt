=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Actively Inferring Optimal Measurement Sequences
Citation Key: higham2025actively
Authors: Catherine F. Higham, Paul Henderson, Roderick Murray-Smith

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Abstract: Measurement of a physical quantity such as light intensity is an integral part of many re-
construction and decision scenarios but can be costly in terms of acquisition time, invasion
ofordamagetotheenvironmentandstorage. Dataminimisationandcompliancewithdata
protection laws is also an important consideration. Where there are a range of measure-
ments that can be made, some may be more informative and compliant with the overall
measurement objective than others. We develop an active sequential i...

Key Terms: inferring, actively, glasgow, university, latent, computing, sequences, space, optimal, data

=== FULL PAPER TEXT ===

Actively Inferring Optimal Measurement Sequences
Catherine F. Higham Catherine.Higham@glasgow.ac.uk
School of Computing Science
University of Glasgow, Glasgow, G12 8QQ, UK
Paul Henderson Paul.Henderson@glasgow.ac.uk
School of Computing Science
University of Glasgow, Glasgow, G12 8QQ, UK
Roderick Murray-Smith Roderick.Murray-Smith@glasgow.ac.uk
School of Computing Science
University of Glasgow, Glasgow, G12 8QQ, UK
Abstract
Measurement of a physical quantity such as light intensity is an integral part of many re-
construction and decision scenarios but can be costly in terms of acquisition time, invasion
ofordamagetotheenvironmentandstorage. Dataminimisationandcompliancewithdata
protection laws is also an important consideration. Where there are a range of measure-
ments that can be made, some may be more informative and compliant with the overall
measurement objective than others. We develop an active sequential inference algorithm
that uses the low dimensional representational latent space from a variational autoencoder
(VAE) to choose which measurement to make next. Our aim is to recover high dimensional
data by making as few measurements as possible. We adapt the VAE encoder to map par-
tial data measurements on to the latent space of the complete data. The algorithm draws
samples from this latent space and uses the VAE decoder to generate data conditional on
the partial measurements. Estimated measurements are made on the generated data and
fed back through the partial VAE encoder to the latent space where they can be evaluated
prior to making a measurement. Starting from no measurements and a normal prior on
the latent space, we consider alternative strategies for choosing the next measurement and
updating the predictive posterior prior for the next step. The algorithm is illustrated us-
ing the Fashion MNIST dataset and a novel convolutional Hadamard pattern measurement
basis. We see that useful patterns are chosen within 10 steps, leading to the convergence
of the guiding generative images. Compared with using stochastic variational inference to
infertheparametersoftheposteriordistributionforeachgenerateddatapointindividually,
the partial VAE framework can efficiently process batches of generated data and obtains
superior results with minimal measurements.
1 Introduction and overview
Inmanycircumstances,datacollectionincursacost. Thiscostmaybeintermsofacquisitiontime,invasion
of or damage to the environment and storage. Identifying which, out of a range of data measurements,
to collect next is potentially a valuable cost saving activity. Importantly, it also facilitates fast decision
making(Horvitz&Barry,1995). Dataminimisationisanimportantconsiderationforcompliancewithdata
protectionlawsworldwide1. Indefensesituations,therequirementforcoverthumanintelligencemeansthat
the act of taking measurements can also pose a security risk. 2
1https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/
2https://www.gov.uk/government/publications/covert-human-intelligence-sources-code-of-practice-2022/covert-human-
intelligence-sources-revised-code-of-practice-accessible
1
5202
beF
52
]GL.sc[
1v24181.2052:viXra
Inthiswork,ouroverallaimistoidentifyanoptimalmeasurementsequence. Wedevelopanactivesequential
inference algorithm that uses a low dimensional data representation to infer its high dimensional state
conditional on partial measurement of that state. Reducing dimension allows for more efficient exploration
ofthespaceofstatepossibilities. Thestateandtypesoftasksweareprimarilyinterestedinareimage/scene
reconstruction and related classification tasks using photon based imaging and sensing technology such as a
singlepixelcamera(Highametal.,2018). However,themethodisapplicabletoabroaderrangeofactivities.
The overall aim is to customise a generative probabilistic model to provide the agent or user with different
reconstructionscenariosconditionalonpartialmeasurements. Givenasuitablylargedatasetoftaskrelevant
data, an appropriate generative model is the variational autoencoder (VAE) (Kingma & Welling, 2014). A
VAElearnstoencodedataintheconvenientformofalowdimensionalmultivariateGaussianandtodecode
this representation back to data space. This provides a means to obtain different reconstructions through
manipulation of a low dimensional latent space. This neural network model is trained on relevant data to
learn the underlying distribution of the training data and used to generate new data. A VAE comprises an
encoder (a map from data space to a low dimensional latent representative space) and a decoder (a map
from the low dimensional space back to data space). To achieve this the VAE introduces latent variables
and the objective of a VAE is to understand the true posterior distribution of the latent variables. A VAE
accomplishes this by employing an encoder network to approximate the genuine posterior distribution with
a learned approximation. Once trained, samples from the prior on the latent space can be pushed through
the decoder in order to obtain new generated data. Similarly, samples from the posterior can be pushed
throughthedecoderinordertoobtaindataconditionalontheinputdata. Hereweadapttheencodertomap
partially measured data to the latent space. This necessitates creating a training set of partially measured
data. Once trained, the partial encoder and the original decoder are used by the algorithm to sequentially
reason about the full state and choose the next measurement. The probabilistic model we are inferring over
is capturing both the (approximate) data-generating process and the noisy measurement model.
The main idea of variational methods is to cast inference as an optimization problem (Blei et al., 2017).
Stochastic variational inference (SVI) (Hoffman et al., 2013) can be used to infer the posterior probability
distribution for specific data and a given set of measurements but requires multiple computation steps and
thus is prohibitively slow when required to estimate many possible measurement sets. We propose a hybrid
approach, in a similar spirit to Kim et al. (2018) but novel in our context, to combine the strengths of
VAE and SVI. We use the partial encoder to choose between patterns and integrate robust SVI when a
pattern has been selected for inferring the posterior distribution parameters based on actual measurements.
The algorithm is developed to actively select the next best measurement. It starts by pushing samples
from the prior distribution on the latent space through the decoder to obtain candidate images. Possible
measurementsonthesecandidateimagesareestimated,forminganindexedset. Theproblemcanbethought
ofaschoosingthenextmeasurementindexfromasetofpossiblemeasurementindexes. Thepartialencoder
orSVIisusedtocharacterisetheposteriordistributionandhenceprovideascoreunderthatdistributionfor
eachpossiblemeasurementindexforeachcandidateimage. Therearedifferentwaystodefinethisscore. We
consider two approaches. First, we choose the index with the highest average (over the candidate images)
likelihood score. Second, we choose the index with the least uncertainty score. The aim is to develop a
method that is flexible to the task context and measurement basis. In Section 3 we describe our method for
posteriorinferencegivenmeasurements. TheactivesequentialmeasurementalgorithmisoutlinedinSection
4. An overview of the algorithm is provided in Figure 1.
2 Related work
There is a large literature on data driven models for solving inverse problems (Arridge et al., 2019). In
particular, generative variational models have been developed for a range of inverse problems in imaging
(Habring & Holler, 2022). These include inpainting, denoising, deblurring, super resolution and JPEG
decompression. Here,wefocusonacquiringdataratherthanhowtoutilisedataoncecollected. Quantitative
methods for optimizing data acquisition have been explored in statistics and machine learning literature
(Rainforth et al., 2024). Bayesian experimental design is a powerful model-based framework for choosing
designs optimally using information-theoretic principles. This includes Bayesian active learning (MacKay,
1992a), sequential (Foster et al., 2021) and Bayesian optimization (Mockus, 1989; Garnett, 2023). Other
2
Figure 1: Active Learning. At step k = 0, for each of N starting points, sample z from the prior for step
i
k = 0, push z through the decoder to obtain a generated image xˆ and estimate possible measurements
i i
yˆ for each pattern not yet measured (e.g. yˆ , yˆ and yˆ illustrated above). Use the partial encoder
i 1 2 3
to approximate the posterior with probability distributions and estimate probability densities q1(z |yˆ ),
1 1
q2(z |yˆ ) and q3(z |yˆ ) (illustrated above). Select the pattern which maximises the chosen expression and
1 2 1 3
take the measurement associated with this pattern. Update the measurement set and update the predictive
prior for the next step. By repeating these steps, we move towards the target distribution p(z|x).
relatedtopicsincludeactivefeatureacquisition(Saar-Tsechanskyetal.,2009),activemulti-modalacquisition
(Kossenetal.,2023),activeperception(Bajcsyetal.,2018),Bayesianactivelearning(MacKay,1992b),active
reinforcement learning (Andreopoulos & Tsotsos, 2013) and active vision (Whitehead & Ballard, 1990).
A generative model-based approach to Bayesian inverse problems, such as image reconstruction from noisy
and incomplete images, is developed in Böhm et al. (2019). Their inference framework makes use of a
VAE to provide complex, data-driven priors that comprise all available information about the uncorrupted
data distribution and enables computationally tractable uncertainty quantification in the form of posterior
analysis in latent and data space. Our approach differs in how we extend the VAE to the data. Our focus is
identifyinghighvaluedatapointssoweproposeadifferentVAEtoprovidethepriorandfacilitateposterior
analysis in latent and data space. Similarly our approach can be adapted to different data systems without
retraining the core VAE. Our extended VAE can be used repeatedly for the sequence of measurements
whereas the method in Böhm et al. (2019) has as its focus corrupted or missing data and is designed to
tackle recovery of data for a given instance rather than exploring uncertainty in a sequential manner.
Apartialvariationalautoencoder(PartialVAE)isintroducedinMaetal.(2019b)topredictproblemspecific
missing data entries given a subset of of the observed ones. The model is combined with an acquisition
function that maximises expected information gain on a set of target variables. The VAE based framework
is extended to a Bayesian treatment of the weights in Ma et al. (2019a). Our work overlaps in that we
develop a VAE and use it to identify high value data points. However it differs in that we are concerned
with measurements of data taken with respect to a basis. We adapt our encoder to the measurement basis
rather than the problem and hence extend the active learning application to image reconstruction using
3
Figure 2: Graphical representation of the VAE model. An image x is generated by a random variable z
parameterized by a deep neural network with parameters θ, a). A variational distribution parameterized by
a deep neural network with parameters ϕ is introduced to infer z given x, b). The encoder and decoder are
trained together using N images. To train the partial encoder we simulate N ×E measurements y[b] where
b is a subset of patterns, c). The partial encoder parameterized by ϕp is trained with the original decoder,
d). The SVI method involves inferring the mean µ and variance Σ for each image individually, e).
sensing technology. The workshop paper by Saar-Tsechansky et al. (2009) is also relevant to our work and
extends the work (Ma et al., 2019b) by adding transformer components to the partial VAE architecture.
One advantage of our partial encoder, over these works, is that given a full VAE on a domain, the partial
encoder can be trained on different measurement basis.
3 Method for posterior inference given measurements
We describe the underlying VAE, Section 3.1, the extension of this framework to sensor measurements,
Section 3.2, and the SVI method, Section 3.3. We then introduce the partial encoder, Section 3.4, and
training of the partial encoder, Section 3.5.
3.1 Underlying VAE model
We assume that an image, x, is generated by a latent random variable, z, in a complex non-linear manner,
parameterized by a deep neural network decoder, D , with parameters θ. The structure of this model is
θ
represented graphically in column (a) of Figure 2. To do inference in this model we introduce a variational
distribution to approximate the posterior distribution of z given x. Through training the VAE learns a
functionthatmapseachxtotheparametersofposteriordensities. Typicallythismappingencodesthemean,
µ, andvariance, Σ, ofaGaussiandistribution, N(µ,Σ), inlatentspace. Thisfunctionisalsoparameterized
byadeepneuralnetworkwithparametersϕ(encodernetworkE )andthevariationaldistribution, q (z|x),
ϕ ϕ
is represented graphically in column (b) of Figure 2. The goal of training is to find optimal values for θ and
ϕ so that the model, p (x|z), is a good fit to the data (log evidence is large) and the variational distribution
θ
is a good approximation to the posterior, p(z|x).
Having learnt θ and ϕ we can generate images by sampling z from the latent space according to the prior
p(z) and pushing z through the decoder map, D (z) : z → x. We can also generate images, xˆ, conditioned
θ
on test x, in three steps. First by using the encoder map, E (x) : x → µ,Σ, to characterise the posterior,
ϕ
q (z|x;µ,Σ). Second, by drawing samples from this distribution. And third, by using the decoder map
ϕ
as before, D (z|x) : z|x → xˆ. The full VAE is trained by maximising an evidence lower bound (ELBO),
θ
L(θ,ϕ;x), which is equivalent to minimizing the KL divergence between p(z|x) and q (z|x) (Kingma &
ϕ
4
Welling, 2014), given by
p(x)=D (q (z|x)∥p(z|x))+L(θ,ϕ;x)
KL ϕ
p(x)≥L(θ,ϕ;x)≡E [logq (z|x)−logp (x|z)−logp(z)]. (1)
z∼qϕ(z|x) ϕ θ
3.2 Extension of VAE framework to sensor measurements
We now consider the situation where we wish to determine a new x by taking optimal sequential measure-
ments on x with respect to a measurement basis with N indexes. At sequential step k the measurement
basis indexes chosen so far are denoted Bk = {b ,b ,...,b }. We obtain y[Bk] by taking a measurement
1 2 k
using these basis indices; for convenience we write
y[Bk] =f(x,Bk). (2)
We model these measurements using isotropic Gaussians with variance σ2.
3.3 SVI method
Here inference is performed for one measurement instance y[Bk]. Marginalising x and applying Bayes’ rule,
we have
p(z)p(y|z)
p(z|y)= . (3)
p(y)
The log of the posterior distribution of the latent variables for a given partial observation y[Bk] is therefore
logp(z|y[Bk])=logp(z)+logp(y[Bk]|z)−logp(y[Bk]).
(4)
This equation, as Equation (2), is intractable motivating the use of SVI. The aim of SVI is to approximate
the posterior with a multivariate Gaussian and infer the mean µk and variance Σk of this distribution. As
the posterior, qk = q(z|y[Bk];µk,Σk), evolves with the number and index of basis measurements, the mean
and variance are indexed by k. SVI is an iterative method. The variational parameters for each data input
are randomly initialized and then optimized to minimise the KL divergence
Lk ≡E [logqk(z|y[Bk])−logp(y[Bk]|z)−logp(z)]. (5)
z∼qk(z|y[Bk])
3.4 Partial encoder
The aim of the partial encoder is to encode incomplete measurements y[Bk] as defined in Equation (2). We
introduceapartialvariationaldistribution,q ,toapproximatetheposteriordistributionandtrainapartial
ϕp
encoder, E , to infer µk and Σk for specific y[Bk], see Figure 1d). The partial encoder VAE is trained
ϕp
by minimizing the KL divergence between p(z|x), established by the full VAE, and the partial posterior
distribution, q (z|y[Bk];µk,Σk), parameterised also by a neural network with parameters ϕp.
ϕp
L ≡E [logq (z|y[Bk])−logp(x|z)−logp(z)]. (6)
partial z∼qϕp(z|y[Bk]) ϕp
AswiththefullVAE,oncewehavelearntϕp wecangenerateimagesfromasetofmeasurementsbysampling
fromtheapproximateposteriordistributionq (z|y[b])andthenpushingthesesamplesthroughthedecoder,
ϕp
D (z|y[Bk]):z|y[Bk] →xˆ to generate the reconstructed image xˆ.
θ
In summary, we have two approaches to approximate the posterior p(z|y[Bk]). First using a partial encoder,
q (z|y[Bk]), and second using SVI, qk(z|y[Bk]). We compare these approaches in Section 5.2.
ϕp
5
3.5 Training the partial encoder
To train the partial encoder we assume that our measurement sensor can provide a series of J = Bk
observations, {y ,y ,...,y }, each associated with an action (experiment or basis measurement resulting in
1 2 J
an observation) for an image x, see Equation (2). We now simulate training data by randomly sampling N
experiments for every image x, simulating observations y[J] for each of them. This is repeated E times for
each x giving N ×E experiments in total where the measurement vector, y[J], varies in terms of both the
numberofmeasurementsandthemeasurementindex. Thisisachievedinanefficientmannerbyintroducing
a mask layer into the encoder network that randomly masks a different number and index of measurements
with each training batch. Using this training set we learn a variational autoencoder which generates the
required mapping, E (y[J],j):→µJ,ΣJ.
ϕp
4 Method for active sequential inference
4.1 The algorithm
We now present our sequential algorithm to actively choose the next best measurement. Our proposed
activeinferencealgorithmisillustratedinFigure1andpseudocodeprovidedinAlgorithm1. Theaimofthe
algorithmistoidentify,undersomecriteria(detailsinSection4.2),thenextbestmeasurementtotake. The
algorithm is designed to leverage the encoding and decoding properties of the VAE. The encoder provides a
meanstomapincompletemeasurementsontoalowdimensionalspaceforexploration. Thedecoderprovides
a means to project back to image space to assess future measurements.
At the first step, k = 0, N samples are drawn from the prior on the latent space, p = N(0,1). These
0
samples, z , arepushedthroughthedecoder, D (z ):z →xˆ , toobtainN generatedimages, xˆ . Simulated
i θ i i i i
measurements, yˆ =f(xˆ ,j), are made under the chosen measurement basis for each basis element indexed
i i
j. Thesimulatedmeasurementsarepushedthroughtheencoder, E :yˆ →:µj,Σj, andtheoutputusedto
ϕp i
characterise the conditional posterior, qj. The algorithm evaluates each measurement indicator and chooses
i
the measurement indicator which best satisfies the decision criteria. This indicator is added to the indicator
set, Bk+1. Actual measurements are taken on the test image, y[Bk+1] =f(x,Bk+1). SVI is used to infer the
posterior and predictive prior for the next step, pk+1 =qk+1. The algorithm continues for K−1 steps.
At step k+1, N samples, z = {z ,...z }, are drawn from the predictive prior, p = N(µBk,ΣBk), where
1 N k
µBk and ΣBk are the mean and variance predicted by the partial encoder conditional on the measurements,
y[Bk], made so far
enc
(y[Bk]):y[Bk] →µBk ,ΣBk
. (7)
ϕp
These samples are then mapped by the decoder to generate images
dec (z):z→xˆ ={xˆ ...xˆ }. (8)
θ 1 N
For each remaining pattern indicator, j ∈ B\Bk, we create a set of pattern indicators J = {b ,...b ,b }
1 k j
andsimulatemeasurementsmadeoneachgeneratedimage, {yˆ[J],...,yˆ[J]}. Wenowusethepartialencoder
1 N
to approximate the posterior distribution conditional on these simulated measurements for each generated
image denoted qJ =N(µJ,ΣJ).
i i i
4.2 Criteria for choosing next measurement
We consider three criteria for choosing the next pattern to measure. A good choice of measurement is one
that provides useful information to the agent.
6
4.2.1 Likelihood (QP)
Here, the criterion for choosing the next pattern, b , corresponds to choosing the pattern, b , with the
k+1 j
highest log likelihood with respect to qJ over all N images;
i
N
X
b =argmax log(qJ(z )). (9)
k+1 i i
j
i=1
By using the likelihood we establish which measurements provide information that is consistent with the
predictive prior for that step. We investigate the ability of the algorithm to move towards the target
distribution.
4.2.2 Mutual Information (MI)
An alternative criterion based on the concept of conditional mutual information (Bishop, 2006) is to choose
the measurement which most reduces the posterior entropy or uncertainty. The mutual information, MI,
between z and yˆ[J] is defined in terms of entropy He as
i i
MI(z ;yˆ[J])=He(z )−He(z|yˆ[J]). (10)
i i i i
The entropy of random variable x from a multivariate Gaussian of dimension D and variance Σ is
D 1
He(x)= (1+log(2π))+ log|Σ|. (11)
2 2
Our criteria for choosing the next pattern is then
N
b =argmax
X1
(log|ΣJ|−log|ΣBk
|). (12)
k+1 2 i
j
i=1
High MI between measurement and posterior means that we learn as much as possible about the posterior
from the new measurement given what we already know.
4.2.3 Inference-free Hadamard optimisation (HO)
Somemeasurementbases,forexampletheHadamardtransform(Ahmed&Rao,1975),permitpatternstobe
prioritised according to the absolute value of the measurement instead of involving inference. High absolute
values(oftheeigenvaluesassociatedwitheachbasiseigenvector)contributemoretothereconstructedimage
which motivates the choice
N
b =argmax X |{yˆ[J]}|. (13)
k+1 i
j
i=1
5 Experimental Results
We illustrate the algorithm on Fashion MNIST (Xiao et al., 2017). The basic VAE is trained using the
60,000 training images from Fashion MNIST Xiao et al. (2017). The encoder/decoder architectures and
trainingdetailsareprovidedinAppendixA.Thepartialencoderistrainedonsimulatedmeasurementsfrom
a novel 4×4 convolutional Hadamard measurement basis, details given in Section 5.1. The partial encoder
architecture is adapted and fitted with a random measurement layer so that experiments involving different
numbers and types of patterns can be efficiently simulated, in terms of computation and memory, during
training.
7
Algorithm 1 Active Sequential Inference
B0 ←∅ ▷ pattern index set
for k =0...K−1 do ▷ for each step
for i=1...N do ▷ for each generated image
if k =0 then
p =N(0,1) ▷ set prior for step 0
0
else if k >0 then
p ←qk ▷ set predictive posterior prior for step k
k
end if
z ∼p ▷ sample latent vector from current pdf
i k
xˆ ←dec (z ) ▷ A. input to decoder to obtain generated image xˆ
i θ i i
for each element j ∈B\Bk do ▷ for each remaining pattern
J ←{b ,...,b ,j} ▷ add pattern index j to measurement set J
1 k
yˆ ←f(xˆ,J) ▷ B. estimate possible measurements
i i
qj ←enc (yˆ ) ▷ C. use partial encoder to approximate pdf qj
i ϕp i
end for
end for
M ←log(qj(z ))−log(p (z )) ▷ D. store results in matrix M
ij i i k i
P
{b }←{argmax M } ▷ E. find pattern index which maximises expression
k+1 j i ij
Bk+1 ←Bk∪{b } ▷ add pattern index to pattern index set
k+1
y[Bk+1] ←f(x,Bk+1) ▷ take actual measurement on x
qk+1 ←SVI(y[Bk+1]) ▷ F. set predictive posterior prior for next step
end for
5.1 Convolutional Hadamard basis
In the context of single pixel imaging, the measurements, y, are made by projecting a series of spatial
patterns on to a scene and capturing the reflected light with a single pixel detector sensor Higham et al.
(2018). Mathematically, the measurement is the inner product between the patterns and the scene and
definesfunctionf fromequation(2). Expressinganimageinvectorform,x,andthepatternbasisinmatrix
form, H, where H ∈ RD×D, we have y = Hx. Of particular interest is the Hadamard basis, an orthogonal
binary −1,1 basis (Ahmed & Rao, 1975). A Hadamard basis is suitable for experimental realization due to
the binary nature of patterns that can be projected using DMD (Digital Micromirror Device) technology as
spatial light modulator (Edgar et al., 2019). We take H to be this basis though we emphasise our method
is not specific to the Hadamard basis and the approach could be generalised to another appropriate basis.
For an image with 2n×2n pixels where n is a positive integer, the complete Hadamard basis, required for
perfect image reconstruction, comprises N =22n patterns.
In this work we develop a novel convolutional Hadamard basis inspired by convolutional layers. The convo-
lutional approach provides local spatial and resolution rather than global frequency information.
A Hadamard basis matrix with 24 rows and columns is rearranged as a 4×4×16 tensor which replaces the
filter of a standard convolutional mapping layer, f . The Hadamard basis has the property of being its
conv
own inverse so the tensor can be used with transpose convolutional mapping layer, f , to recover the
tpconv
input image from the feature image, f :x→y and f :y→x.
conv tconv
An advantage of this convolutional Hadamard basis is that the resulting feature f ∈RN/4×N/4×16 has both
spatial (vertical and horizontal) and frequency or resolution dimension associated to each element f where
j
j =1...N2. We exploit this in our illustration to give further insights into the decision making process.
5.2 Comparison of pVAE and SVI
At each step of the algorithm, estimating the parameters of the approximate posterior, qJ, requires one
pass through the partial encoder but several iterations with the SVI method. We compare the performance
8
of pVAE (1 iteration) with SVI and a variable number of iterations {10,20,30,40,50,60,70} in terms of
reconstruction indexes: mean square error (MSE) and similarity structure (SSIM) Wang et al. (2004).
The performance scores are averaged over 100 samples from ten images (each from a different class) and
the algorithm is run for 100 steps, see Figure 3. The SVI method improves as the number of iterations
increases but only matches the pVAE method after 60 iterations. This makes the SVI method an order of
magnitude slower than pVAE. For our final algorithm, we therefore use pVAE to approximate qJ based on
i
simulatedmeasurements(CinAlgorithm1)andSVIwith100iterationstoapproximateqk+1basedonactual
measurements (F in Algorithm 1). This way we achieve a balance between performance and computation
time.
Figure 3: Comparison of pVAE and SVI. The performance scores (mse left column and ssim right column)
are averaged over 100 samples from ten images (each from a different class) and the algorithm is run for
100 steps. Here lower is better for mse left and higher is better for ssim right. The performance of pVAE
(1 iteration) bold line with SVI and a variable number of iterations {10,20,30,40,50,60,70} mixed light
lines. The SVI method improves as the number of iterations increases. At 100 steps the results for pVAE
lie between the results for SVI with 60 (SVI60) and 70 (SVI70) iterations. In terms of timings, the pVAE
takes 9×10−4 seconds per step and the SVI method takes 7.2×10−3 seconds per iteration. With many
iterations required for SVI, this makes the SVI method at least an order of magnitude slower than pVAE.
Time measurements were taken using a NVIDIA GeForce RTX 3090 GPU.
5.3 Comparison of choice criteria
The different criteria for choosing the next pattern (QP, MI and HO), equations (9), (12) and (13) respec-
tively, were evaluated using 10 test images, one from each class, and Ns = {1,10,100,200} latent vector
samples over 100 steps. Performance measures, SSIM and MSE, were evaluated at each step and averaged
over the test images, see Figure 4 and, in Appendix B, Figure 6.
Our method (QP) outperforms Hadamard optimisation (HO) for the first 25 steps with 1, 10, 100 and
200 starting images in terms of MSE and SSIM. The methods QP and HO differ in both the criteria for
choosingthenextpatternandreconstructionwhereasthemethodsQPandMIdifferonlyinthecriteriafor
9
Figure 4: Comparison of choice criteria in terms of the structural similarity index (SSIM). The different
criteria for choosing the next pattern (QP, MI and HO), equations (9), (12) and (13) respectively, were
evaluated (mean SSIM) using 10 test images, one from each class, and 1 (top left), 10 (top right), 100
(bottom left), 200 (bottom right) latent vector samples over 100 steps. Our method (QP) outperforms
Hadamard optimisation (HO) for the first 25 steps and both show superior performance to MI across all
theexperiments. Intermsoftimings,HOtook0.7778seconds,QPtook1.3583secondsandMItook1.4219
seconds to complete 50 steps. Time measurements were taken using a NVIDIA GeForce RTX 3090 GPU.
choosing the next pattern. After these first steps, the performance of both methods plateaus with a slightly
superior performance from the Hadamard reconstruction. Comparing QP with MI, QP shows superior
performance across all the experiments. Investigation of the patterns chosen suggest that using MI early
in the process leads to the algorithm getting stuck in the latent space. This method relies on choosing the
next pattern to reduce uncertainty across several generated images whereas QP chooses the next pattern
to increase likelihood. The MI strategy promotes larger initial steps in the latent space and consequently
a tendency to get stuck and miss patterns that are useful for reconstruction. The QP strategy encourages
smaller steps in the latent space and moves more steadily to a convergence of generated images. The QP
method is therefore the one that we recommend.
5.4 Visualisation of the active learning algorithm using UMAP
We now illustrate the active learning algorithm by exploring low dimensional image space using a two
dimensional representation of the latent space of 10,000 test images from Fashion MNIST created with
UMAP Meehan et al. (2022). UMAP is applied to the mean of the latent representations. The classes are
colour coded and the UMAP clusters within class and between similar classes (i.e. ankle boot, sneaker and
shoe) indicate that class structure has been retained by the latent representation and further dimension
reduction, see Figure 5.
A number, N, of latent variables are drawn from the prior. These are shown as black crosses projected on
to the two dimensional space along with the projected class colour coded test images. These variables are
then passed to the generator, p (x |z ), to produce the generated images shown on the right. Also shown is
θ i i
the image reconstruction from actual measurements made so far (top right box), none at step 0, 10 at step
10 and 30 at step 30, and the target image (bottom left box).
10
At steps 1 to K, the generated images from the previous step are used to estimate possible measurements
corresponding to the set of pattern indexes not yet taken. These possible measurements are individually
addedtotheactualmeasurementsandpassedtotheencodertoobtaintheposteriorprobabilitydistribution.
The measurement index, j, which is considered most informative satisfies the following expression:
X
argmax log(q (z )−log(p (z )). (14)
ij i k i
j
i
At step k our certainty, quantified by a probability distribution about our location in latent space, having
taken k−1 measurements, is denoted by p (z ). If we were to take another measurement, our certainty
k−1 i
becomes q (z ). In the interest of increasing our certainty we choose the value which maximises the above
kij i
expression. This simple procedure allows us to move through latent space converging on a reconstruction
close to the target.
6 Discussion and Conclusion
We have shown that given a large dataset and a measurement basis the encoder of a VAE, trained on this
largedataset,canbeadaptedtomappartialmeasurementsontoarepresentativelatentspace. Ansequential
measurementalgorithmisdevelopedtoexplorethislatentspaceinordertooptimisethenextbestmeasure-
ment. The algorithm is illustrated using the Fashion MNIST dataset and a novel convolutional Hadamard
measurementbasis. Weseethatusefulpatternsarechosenwithin10stepsleadingtotheconvergenceofthe
guidinggenerativeimages. Insituationswherethereisacostattachedtomeasurement,theabilitytoreduce
thenumberofmeasurementsisasignificantbenefit. Webelievethatthisalgorithmisthefirsttoaddressthe
task of active sequential inference in this context, and we note that it has the potential to increase efficiency
dramatically in many high profile applications.
Acknowledgments
C.F.H and R.M-S. received funding from EP/T00097X/1, EP/R018634/1, and EP/T021020/1. R.M-S. also
receivedfundingfromtheDesigningInteractionFreedomviaActiveInference(DIFAI)ERCAdvancedGrant
(proposal 101097708, funded by the UK Horizon guarantee scheme as EPSRC project EP/Y029178/1).
References
Nasir Ahmed and Kamisetty Ramamohan Rao. Walsh-Hadamard Transform, pp. 99–152. Springer Berlin
Heidelberg, Berlin, Heidelberg, 1975. ISBN 978-3-642-45450-9. doi: 10.1007/978-3-642-45450-9_6. URL
https://doi.org/10.1007/978-3-642-45450-9_6.
Alexander Andreopoulos and John K. Tsotsos. A computational learning theory of active object recognition
under uncertainty. Int. J. Comput. Vision, 101(1):95–142, January 2013. ISSN 0920-5691. doi: 10.1007/
s11263-012-0551-6. URL https://doi.org/10.1007/s11263-012-0551-6.
Simon Arridge, Peter Maass, Ozan Öktem, and Carola-Bibiane Schönlieb. Solving inverse problems using
data-driven models. Acta Numerica, 28:1–174, 2019. doi: 10.1017/S0962492919000059.
R. Bajcsy, Y. Aloimonos, and J.K. Tsotsos. Revisiting active perception. Autonomous Robots, 42:177–196,
2018.
Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics).
Springer-Verlag, Berlin, Heidelberg, 2006. ISBN 0387310738.
David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational inference: A review for statisticians.
Journal of the American Statistical Association, 112(518):859–877, April 2017. ISSN 1537-274X. doi:
10.1080/01621459.2017.1285773. URL http://dx.doi.org/10.1080/01621459.2017.1285773.
11
Figure5: UMAPisusedtoreducethemeanofthelatentrepresentationsof10,000testimagesto2dimensions
(left hand column). The classes are colour coded and the UMAP clusters within class and between similar
classes (i.e. ankle boot, sneaker and shoe) indicate that the class structure has been retained by the latent
representation and further dimension reduction. The mean of 100 samples is similarly projected (black
crosses) on to the map at each step of the algorithm. The measurements made, the samples projected back
into image space and the image to be recovered are shown in the top left corner, centre and bottom right
corner of the (right hand column) respectively. We see the diversity of possible images in the right hand
12
column, and this decreases as uncertainty is reduced by more measurements.
Vanessa Böhm, François Lanusse, and Uroš Seljak. Uncertainty Quantification with Generative Models. In
33rd Annual Conference on Neural Information Processing Systems, 10 2019.
M.P. Edgar, G.M. Gibson, and M.J. Padgett. Principles and prospects for single-pixel imaging. Nature
Photon, 13:13–20, 2019.
AdamFoster,DesiRIvanova,IlyasMalik,andTomRainforth. Deepadaptivedesign: Amortizingsequential
bayesian experimental design. In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th Interna-
tional Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pp.
3384–3395. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/foster21a.html.
Roman Garnett. Bayesian Optimization. Cambridge University Press, 2023.
Andreas Habring and Martin Holler. A generative variational model for inverse problems in imaging. SIAM
Journal on Mathematics of Data Science, 4(1):306–335, 2022. doi: 10.1137/21M1414978. URL https:
//doi.org/10.1137/21M1414978.
IrinaHiggins, LoicMatthey, ArkaPal, ChristopherBurgess, XavierGlorot, MatthewBotvinick, ShakirMo-
hamed, andAlexanderLerchner. beta-VAE:Learningbasicvisualconceptswithaconstrainedvariational
framework. In International Conference on Learning Representations, 2017.
C.F.Higham,R.Murray-Smith,M.J.M.J.Padgett,andM.P.Edgar. Deeplearningforreal-timesingle-pixel
video. Sci Rep, 8:2018, 2018.
Matthew D. Hoffman, David M. Blei, Chong Wang, and John Paisley. Stochastic variational inference.
Journal of Machine Learning Research, 14(40):1303–1347, 2013.
Eric Horvitz and Matthew Barry. Display of information for time-critical decision making. In Proceedings
of the Eleventh Conference on Uncertainty in Artificial Intelligence, UAI’95, pp. 296–305, San Francisco,
CA, USA, 1995. Morgan Kaufmann Publishers Inc. ISBN 1558603859.
Yoon Kim, Sam Wiseman, Andrew Miller, David Sontag, and Alexander Rush. Semi-amortized variational
autoencoders. InJenniferDyandAndreasKrause(eds.),Proceedings of the 35th International Conference
on Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 2678–2687. PMLR,
10–15 Jul 2018.
DiederikKingmaandJimmyBa. Adam: Amethodforstochasticoptimization. InInternational Conference
on Learning Representations (ICLR), San Diega, CA, USA, 2015.
DiederikP.KingmaandMaxWelling. Auto-encodingvariationalBayes. InYoshuaBengioandYannLeCun
(eds.), 2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April
14-16, 2014, Conference Track Proceedings, 2014.
Jannik Kossen, Cătălina Cangea, Eszter Vértes, Andrew Jaegle, Viorica Patraucean, Ira Ktena, Ne-
nad Tomasev, and Danielle Belgrave. Active acquisition for multimodal temporal data: A challeng-
ing decision-making task. Transactions on Machine Learning Research, 2023. ISSN 2835-8856. URL
https://openreview.net/forum?id=Gbu1bHQhEL.
Chao Ma, Wenbo Gong, Sebastian Tschiatschek, Sebastian Nowozin, José Miguel Hernández-Lobato, and
Cheng Zhang. Bayesian EDDI: Sequential variable selection with Bayesian partial VAE. Workshop on
Real-World Sequential Decision Making: Reinforcement Learning and Beyond at NeurIPS, 2019a.
Chao Ma, Sebastian Tschiatschek, Konstantina Palla, Jose Miguel Hernandez-Lobato, Sebastian Nowozin,
and Cheng Zhang. EDDI: Efficient dynamic discovery of high-value information with partial VAE. In
Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference
on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 4234–4243. PMLR,
09–15 Jun 2019b.
13
DavidJ.C.MacKay. Information-BasedObjectiveFunctionsforActiveDataSelection. NeuralComputation,
4(4):590–604, 07 1992a. ISSN 0899-7667. doi: 10.1162/neco.1992.4.4.590. URL https://doi.org/10.
1162/neco.1992.4.4.590.
David J. C. MacKay. Information-based objective functions for active data selection. Neural Computation,
4(4):590–604, 1992b. doi: 10.1162/neco.1992.4.4.590.
Connor Meehan, Jonathan Ebrahimian, Wayne Moore, and Stephen Meehan. Uniform manifold approx-
imation and projection (UMAP). https://www.mathworks.com/matlabcentral/fileexchange/71902,
2022.
Jonas Mockus. Bayesian Approach to Global Optimization. Springer Dordrecht: Kluwer Academic, 1989.
TomRainforth,AdamFoster,DesiR.Ivanova,andFreddieBickfordSmith. ModernBayesianExperimental
Design. Statistical Science, 39(1):100 – 114, 2024. doi: 10.1214/23-STS915. URL https://doi.org/10.
1214/23-STS915.
MaytalSaar-Tsechansky, PremMelville, andFosterProvost. Activefeature-valueacquisition. Manage. Sci.,
55(4):664–684, April 2009. ISSN 0025-1909. doi: 10.1287/mnsc.1080.0952. URL https://doi.org/10.
1287/mnsc.1080.0952.
Zhou Wang, A.C. Bovik, H.R. Sheikh, and E.P. Simoncelli. Image quality assessment: from error visibility
to structural similarity. IEEE Transactions on Image Processing, 13(4):600–612, 2004.
Steven D. Whitehead and Dana H. Ballard. Active perception and reinforcement learning. Neural Compu-
tation, 2(4):409–419, 1990.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms, 2017. URL http://arxiv.org/abs/1708.07747.
14
A VAE architecture and training
Theencodercomprisedanimageinputlayer,twoencodingblocksandafullyconnectedlayer. Eachencoding
block contained a convolutional layer, a batchnorm layer and a ReLU activation layer. The input image
(28×28) was downsized to (14×14×32) and (7×7×64) by the encoding blocks respectively. The output
of the fully connected layer, [µ,logΣ], is twice the size of the latent space (32×1).
The partial encoder was formed by replacing the first encoding block with a convolutional layer, modified
to use the convolutional Hadamard basis as fixed weights, resulting in a feature (7×7×64). This block
was followed by a random mask layer that randomly selects a number of patterns and pattern indexes. The
subsequent encoding block was adjusted to downsize to (4×4×64).
Thedecodercomprisedanlatentsampleinputlayer(16×1),aprojectandreshapelayer(7×7×64)andthree
decoding blocks. The decoding blocks each contained a transposed convolutional layer and an activation
layer RELU for the first two blocks and sigmoid for the last block). The input feature was up sampled to
(14×14×64), (28×28×32) and (28×28×1) by the decoding blocks respectively.
The encoder and decoder were trained together using a custom training loop and 60,000 fashion MNIST
images Xiao et al. (2017) in mini-batches of 128 for 100 epochs. The parameters were updated using the
adaptive moment estimation (ADAM) algorithm (Kingma & Ba, 2015) with settings: learning rate = 0.001,
gradient decay = 0.9, squared gradient decay = 0.999 and epsilon = 1e-8) chosen using validation set
performance.
Thepartialencoderwastrainedusingthepreviouslytraineddecoderwithfixedsettingsfor200epochs. The
random mask layer was reset for each mini-batch iteration simulating 200×450 different experiments.
We modify the KL divergence term in the loss functions to include an additional scaling factor, β, in front
of the KL divergence term. This βVAE approach was introduced in Higgins et al. (2017) to encourage a
more flexible latent space representation, while still ensuring that the learned distribution is close to the
prior distribution. The value of β is set to 0.1 for the VAE and the partial VAE.
B More results
The different criteria for choosing the next pattern (QP, MI and HO), equations (9), (12) and (13) respec-
tively, were evaluated using 10 test images, one from each class, and Ns = {1,10,100,200} latent vector
samples over 100 steps. Performance measures, SSIM and MSE, were evaluated at each step and averaged
over the test images, see Figure 4 and, in Appendix B, Figure 6.
C Interpreting results
ThepatternsbelongingtotheconvolutionalHadamardbasishavetwospatialandoneresolutioncomponent.
A log likelihood map for each generated image can be formed by averaging the row M over the resolution
i,:
component
X
M = M . (15)
i,xy i,xyr
r
Figure7showsresizedM overlaidonthegeneratedimagexˆatstep0. Thisvisualisationhighlightsregions
xy
of interest. Namely the tops of the sleeves for T-shirt (a), the back and toe of the boot (b) and the waist
and lower legs for the trousers (c).
15
Figure 6: Comparison of choice criteria in terms of mean squared error (MSE). The different criteria for
choosing the next pattern (QP, MI and HO), equations (9), (12) and (13) respectively, were evaluated
(mean MSE) using 10 test images, one from each class, and 1 (top left), 10 (top right), 100 (bottom left),
200 (bottom right) latent vector samples over 100 steps. (QP) outperforms Hadamard optimisation (HO)
for the first 25 steps.
(a) (b) (c)
Figure 7: After step 0, we overlay M over xˆ to indicate regions of high information (white) and low
i i
information(black)withintheactivelearningframeatthisstep. Forthelongsleevedtop,regionsofinterest
are the tops of the sleeves (a). The back and toe of the boot are regions of interest (b). The waist and lower
legs are regions of interest for the trousers (c). Using expression in equation 14 the next measurement taken
is determined by averaging the information over N images.
16

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Actively Inferring Optimal Measurement Sequences"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
