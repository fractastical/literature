### OverviewThis paper investigates the development of a bio-inspired topological autonomous navigation system utilizing the Active Inference Framework (AIF) for robots. The authors present a novel approach that integrates mapping, localization, and decision-making within a unified, adaptive agent capable of exploring and reaching objectives in dynamic and partially observable environments. The system constructs a topological map of the environment in real-time, planning goal-directed trajectories to explore or reach objectives without requiring pre-training. Key contributions include a probabilistic reasoning framework for interpretable navigation, robust adaptability to dynamic changes, and a modular ROS2 architecture compatible with existing navigation systems. The authors demonstrate the system’s effectiveness through simulated and real-world experiments, proving it comparable to other exploration strategies such as Gbplanner, FAEL, and Frontiers. This approach offers a scalable and transparent approach for navigating complex, unstructured environments. "The authors state: “Achieving fully autonomous exploration and navigation remains a critical challenge in robotics, requiring integrated solutions for localization, mapping, decision-making and motion planning.”"### MethodologyThe proposed system leverages the AIF framework, treating navigation as a predictive inference process. The generative model, central to the system, is defined by Equation (1), encapsulating causal relationships among observable outcomes, agent actions, and hidden environmental states. The model builds a360° panoramic representation of the environment by stitching images, comparing it to stored memories using Structural Similarity Index (SSIM) to identify new locations, and updating its topological map. The agent’s movement is governed by a hierarchical control system, combining the model’s predictions with odometry data and potential field methods for motion planning. The system utilizes a modular architecture based on ROS2, facilitating seamless integration with existing robotic platforms and sensor configurations. "They note: “Our model creates and updates a topological map of the environment in real-time, planning goal-directed trajectories to explore or reach objectives without requiring pre-training.”" The system’s transition probabilities between states are dynamically adjusted based on the observed situation, with a lower impact on transitions that the model has directly experimented through motion. "The authors state: “To improve the internal map of the agent, representing how the robot can navigate the environment, our model sits its parameters to minimise FreeEnergy, a concept in Active Inference (AIF) [16].”"### ResultsThe system was evaluated in four simulated environments – a mini (36m2), small (80m2) and large (280m2) warehouse, inspired by the Amazon Gazebo environment [27], featuring aisles, boxes, and industrial obstacles like forklifts; and a156m2 home environment [35] without doors, including a kitchen-living area, sports a and play rooms, and a bedroom. Both settings include challenging objects for LiDAR-based detection, such as curved chairs or forklifts. In each scenario, the agent begins exploration from random initial positions. Since our model does not construct a metric map, we rely on LiDAR ranging to associate observations with the agent’s internal representation of new states. "At the heart of decision-making and adaptive behaviour lies a delicate balance between exploitation and exploration[18].Exploitationinvolvesselectingthemostvaluableoptionbasedonexistingbeliefsabouttheworld,while exploration entails choosing options to learn and understandtheenvironment[29].“When the agent predicts new states and updates its internal representation, the exploration and goal-reaching ability is not impacted by this shift, showing the robustness of the model to drift and explorationefficiency. Frontiershadasimilarexperience withanobjectthatthelidarcouldnotdetect,theodometryshifted,andnav2SLAMwasnotabletorecoverfrom this.TheusedFrontiersalgorithm[1]andGbplanner[39]donotproposeanalternativeobjectivetoreachifnavigationfails.Moreover,thesystem’sperformance is quantified by the number of human interventions required, which was minimal, primarily due to the system’s ability to handle unexpected situations. "Table2 summarizes the number of times the robot got stuck and required intervention per environment overall runs. In all cases, the interventions for our agent were due to physical limitations (e.g., the two robot wheels lifted off the ground after hitting an obstacle), while other models also required interventions due to an inability to consider the obstacle and replan. FAEL also got stuck in open areas and required a little push to correctly consider LiDAR data."### DiscussionOur model uses Active Inference (AIF) to build a cognitive map by integrating visual observations and estimated body position into a generative topological graph[45]. Unlike existing AIF systems that rely solely on past observations [46], [47], our approach predicts possible future states, enabling proactive and adaptive exploration[48].Thisresultsin a robust, self-organising internal map that guides decision-making without requiring prior training, offering zero-shot, online learning capabilities. The framework is modular, based on ROS2[30] and fully interpretable, with decision-making grounded in the minimisation of expected free energy [17]. This explainability allows users to trace how navigation decisions are made and how predictions shape exploration or goal-reaching. "The authors prove to be as reliable in exploration tasks as state-of-the-art (GBplanner[39], FAEL[37]) topological planning and more efficient than traditional methods such as Frontiers[1], even in dynamic environments. Future enhancements like semantic perception[49] or hierarchical planning [50] could improve generalisation and efficiency, and are meant to be integrated. More tests should be conducted in a larger real-world warehouse for exploration and goal-reaching to fully confirm those results. Moreover, we still have to formally demonstrate that our method is computationally affordable in robotics platforms. Despite these limitations, our method demonstrated that a biologically inspired, modular, and adaptive navigation system is possible using AIF, which is promising for real-world robotic applications in uncertain and changing environments."### AcknowledgementThis research received funding from the Flemish Government under the “Onderzoeksprogramma Artificie¨le Intelligentie(AI)Vlaanderen”programme.