=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Modeling motor control in continuous-time Active Inference: a survey
Citation Key: priorelli2023modeling
Authors: Matteo Priorelli, Federico Maggiore, Antonella Maselli

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Abstract: The way the brain selects and controls actions is still widely debated.
Mainstream approaches based on Optimal Control focus on stimulus-
response mappings that optimize cost functions. Ideomotor theory and
cyberneticsproposeadifferentperspective: theysuggestthatactionsare
selected and controlled by activating action effects and by continuously
matching internal predictions with sensations. Active Inference offers a
modernformulationoftheseideas,intermsofinferentialmechanismsand
prediction-error...

Key Terms: national, continuous, pezzulo, research, italy, giovanni, modeling, active, survey, inference

=== FULL PAPER TEXT ===

Modeling motor control in continuous-time
Active Inference: a survey
Matteo Priorelli1,†, Federico Maggiore2,3,†, Antonella Maselli2,
Francesco Donnarumma2, Domenico Maisto2, Francesco
Mannella2, Ivilin Peev Stoianov1, and Giovanni Pezzulo∗2
1ISTC-CNR, National Research Council, Padua, Italy
2ISTC-CNR, National Research Council, Rome, Italy
3Department of Engineering, Roma Tre University, Rome, Italy
†These two authors contributed equally
Abstract
The way the brain selects and controls actions is still widely debated.
Mainstream approaches based on Optimal Control focus on stimulus-
response mappings that optimize cost functions. Ideomotor theory and
cyberneticsproposeadifferentperspective: theysuggestthatactionsare
selected and controlled by activating action effects and by continuously
matching internal predictions with sensations. Active Inference offers a
modernformulationoftheseideas,intermsofinferentialmechanismsand
prediction-error-basedcontrol,whichcanbelinkedtoneuralmechanisms
oflivingorganisms. ThisarticleprovidesatechnicalillustrationofActive
InferencemodelsincontinuoustimeandabriefsurveyofActiveInference
models that solve four kinds of control problems; namely, the control of
goal-directedreachingmovements,activesensing,theresolutionofmulti-
sensory conflict during movement and the integration of decision-making
andmotorcontrol. Crucially,inActiveInference,allthesedifferentfacets
of motor control emerge from the same optimization process - namely,
the minimization of Free Energy - and do not require designing separate
cost functions. Therefore, Active Inference provides a unitary perspec-
tive on various aspects of motor control that can inform both the study
of biological control mechanisms and the design of artificial and robotic
systems.
Keywords— Active Inference; motor control; active sensing; predictive brain;
ideomotor theory; cybernetics
∗Correspondingauthor: GiovanniPezzulo,ISTC-CNRViaS.MartinodellaBattaglia44,
00185Rome,Italy,giovanni.pezzulo@istc.cnr.it
1
3202
tcO
8
]CN.oib-q[
1v44150.0132:viXra
1 Introduction
Acentralquestionincomputationalmotorcontrolishowthebrainselectsandcontrols
actions. A common assumption in formal frameworks such as Optimal Control [1,2]
andreinforcementlearning[3]isthatthebuildingblocksofactioncontrolarestimulus-
response mappings, or policies. Policies can be selected using either cheap-but-rigid,
habitualmechanisms(i.e.,basedonthehistoryofpreviousreinforcements),orcostly-
but-flexible,deliberativemechanisms(i.e.,basedonthevalueofactionoutcomes)[4].
Then, when a policy is selected, its execution follows stimulus-response control rules
and could be accompanied by a process of prediction of action effects (via a so-called
forward model) that helps manage delayed feedback [5].
An alternative to this stimulus-response perspective is the ideomotor view that
movementsareselectedandcontrolledonthebasisoftheireffects(oroutcomes), not
of stimuli [6–10]. The general idea of the ideomotor theory is that the brain might
learnthestatistical(bidirectional)relationsbetweenactionsandtheireffectsandthen
usethelearnedaction-effectcodesbothtopredictactionconsequences(intheforward
direction, from actions to effects) and to select and plan actions that achieve the in-
tended effects (in the backward direction, from effects to actions). Stimuli could be
partofthispicture,leadingtostimulus-action-effectcodes,buttheywouldnotbethe
mainresponsibleforactionplanning,selection,andcontrol. Variousempiricalfindings
support the claim of ideomotor theory that action effects influence the selection and
control of actions. For example, one study required participants to press one of four
horizontally arranged buttons in response to color stimuli [11]. After each keypress,
aneffect stimuluswasshowninoneoffourhorizontallyarrangedlocations. Crucially,
responsestocolor stimuliwerefasterwhentherewasacorrespondencebetweenthelo-
cationsoftheeffect stimulusandthepressedbutton. Thisoccurreddespitecolorstim-
uliappearedbeforeeffectstimuli,indicatingthatanticipatedactioneffectsinfluenced
actions. Thisinfluencewouldnotbepresentifactionselectionwasstimulus-response,
because effects only occur after actions are completed. Other subsequent studies sug-
gestthattheinfluenceofeffectsoveractionsregardsvariousprocesses,suchasaction
planning,selection,preparation,initiation,andcontrol[12–15]andtheycouldalready
be present in infancy [16].
Another framework that highlights the centrality of action effects (or outcomes)
ratherthanstimulus-responsecodesiscybernetics[17]. Forexample,theearlyTOTE
(test, operate, test, exit) model assumes that the brain continuously tests whether
there is a mismatch between an internally defined event (roughly, a goal, outcome,
or setpoint) and the currently sensed event; and in case it detects a mismatch, it
triggers a corrective action that reduces it [18]. A simple illustration of this “closed-
loop” control mechanism is the functioning of a thermostat: a discrepancy between
a desired temperature or set point (say, 37 degrees) and a sensed temperature (say,
35 degrees) triggers an action (say, switch a heating device on) until there is no more
mismatch. While the TOTE scheme did not natively include sophisticated planning
orcontrolmechanisms,itexemplifiesamechanismbywhichitisaninternalmatching
operation, not a stimulus, which triggers actions. Similarly, in perceptual control
theory, the central goal of a system is to continuously monitor that some internally
representedperceptualvariablehasthedesiredvalue(e.g.,thatthenumberindicated
byaspeedometerinacaris80km/h)andifnot,triggercorrectiveactions(accelerate
or decelerate) that cancel out discrepancies from the desired value [19,20].
Thetwoabove(ideomotorandcybernetic)schemesrequirethebraintointernally
represent action effects and other expected (or intended) events and to continuously
2
perform matching operations to calculate discrepancies between expected and sensed
events. Recently, these internal matching operations and discrepancies have become
thefocusofalargesetoftheoreticalandempiricalstudies[21–25],whicharetypically
conceptualizedintermsofpredictivecodingandActiveInferencetheories[23]. These
theories assume that the brain maintains a statistical model of the regularities of the
environmentandusesittocontinuouslygeneratepredictionsaboutpresentandfuture
events,includingactioneffects. Crucially,thebrainmodelscanincludesomepreferred
states (e.g., desired values of physiological parameters or setpoints for motor control)
that regulate the control of externally directed actions such as overt movements [26]
andinternalregulatoryactions[27,28]. Thisisbecausethebraincontinuouslypredicts
the desired values (e.g., of body posture or temperature) and monitors discrepancies
withsensedstimuli. Anydiscrepancyisregisteredasapredictionerrorthattriggersa
correctiveactionthatminimizestheerror(oralternatively,dependingonthecontext,
leadstomodelrevisionandlearning)thatultimatelyensuresthatthesystemremains
within its preferred states.
Inkeepingwithideomotorandcyberneticsaccountsofmotorbehavior,ActiveIn-
ference formalizes the problem of motor control by assuming that agents act on the
surrounding environment in a goal-directed manner, to achieve a desired state. Ac-
tiveInferenceagentsmonitorthestateofthesystem(whichmayincludetheexternal
environmentandtheirownbodilyconfiguration)throughthesenses(i.e.,perception)
andcontinuouslypredicthowthestateofthesystemwillevolveintime. Thispredic-
tiveprocessingisgrantedbyaninternalrepresentationofthesystemdynamics,which
is assumed to be learned through exposure to the statistical regularities that govern
theenvironmentandthebody(thelawsofphysics,kinematicregularities,etc.),both
during the lifespan and throughout evolution. Furthermore, Active Inference agents
continuously formulate sensory predictions (e.g., about action outcomes) and com-
pare them with sensory events gathered through the senses. The resulting sensory
prediction errors are considered within the state estimation process, which strives to
minimize the errors. To minimize the prediction errors, the (brain of the) agent has
two ways. First, it can change the model that generated the predictions in the first
place: thisamountstoaprocessofbeliefrevisionandlearningintheoriesofpredictive
coding,DEMandgeneralizedfiltering[29,30],[31,32]. Second,theagentcanminimize
predictionerrorsbyactinguponthesystemandchangingitsstate,insuchawaythat
the system-produced events (registered as sensory events by the agent) become more
similar to its sensory predictions. This second way to minimize prediction errors –
by acting – is key to Active Inference and permits formalizing early ideomotor and
cybernetic ideas, by linking them to the biologically plausible scheme of predictive
coding [23].
While several surveys and tutorials can be found in the literature about Active
Inference in discrete state spaces [33,34], the continuous framework has received rel-
atively less attention. Discrete models are critical to perform planning and decision-
making, but handling continuous signals is key when interacting with the external
environment. Given the growing interest in predictive processing, here we provide an
overview of how motor control is modeled.
In the rest of this article, we provide a short formal introduction to Active Infer-
ence;wediscussvariousexamplesofActiveInferencemodelsofmotorcontrol;finally,
we discuss the unique features of this framework.
3
Figure 1: Generative process (in blue) and generative model (in red) in Active inference.
Thegenerativeprocessincludesthedynamicsf (x,a)thatgovernsthetemporalevolution
GP
of the hidden states x, and the sensory mapping g (x) that maps the hidden states into
GP
the sensory input y that the agent receives from the environment, along with sensory noise
w. The generative model includes an internal representation f about the system dynamics
generated from a belief µ over the hidden states, and an internal model g that maps this
belief into sensory predictions. The latter are used to compute prediction errors εy which
contributetoperceptualinferenceandthegenerationofactionsaviathecorrespondingFree
Energyminimizationterms. Eventually,actionsaffectthegenerativeprocessbyenteringthe
systemdynamics. Notethatf doesnotincludeanexplicitrepresentationoftheactionsand
isinsteaddrivenbyinternalrepresentationsofintentionsencodedintothehiddencausesν.
2 Active Inference in continuous time
Active Inference has been used to model a large variety of problems of motor con-
trol, decision-making, planning and rule learning that are relevant for both biological
organisms and robots [26,35–38]. This section provides a concise formal introduc-
tion to Active Inference in continuous time; a more detailed treatment comprising
discrete-time formulations can be found in [23].
ActiveInferenceisbuiltupontheFreeEnergyPrinciple(FEP),whichassumesthat
alllivingorganismsstrivetominimizethe“surpriseassociatedwithsensoryexchanges
with the world”, allowing them to resist a natural tendency to disorder [23]. The
Variational Free Energy (VFE) – or Free Energy, for brevity – F is introduced as a
mathematically treatable upper bound on surprise; it is a functional that is widely
used in statistics as part of Variational Bayes methods [39], and it is analogous to
theevidencelowerbound(ELBO)usedinmachinelearning. ActiveInferenceappeals
to the minimization of Free Energy to model the action-perception loop of living
organisms and assumes that both action and perception minimize the same (Free
Energy) quantity, as will become clear later.
Any implementation of an Active Inference agent requires specifying two inter-
acting systems, as shown in Fig. 1. The first one is the “generative process”, which
describes how the physical system which the agent interacts with (e.g., the environ-
mentand/ortheagent’sbody)evolvesintime,andhowitmapsintothesensoryinputs
observedbytheagent. Thesecondoneisthe“generativemodel”,whichdescribesthe
internal model that the agent holds about how the system is expected to evolve in
timeandtomapintosensorystates. AsillustratedinFig. 1,thetwosystemsinteract
bidirectionally: the generative process determines the sensory inputs that the agent
receivesandprocesses(e.g.,tocomputepredictionerrors),whilethegenerativemodel
produces actions that influence the dynamics of the generative process.
4
Theaction-perceptionloopofActiveInferencecanbesummarizedasfollows. Con-
sideranagentimmersedinadynamicenvironmentandreceivingobservationsy gen-
eratedfromhiddenvariablesu,whichgenerallyconsistofhiddenstatesxandhidden
causesv (buttheycouldalsoincludeothervariables,likeparametersevolvingondif-
ferenttimescales)[40]. Thevariationalmethodapproximatestheintractableposterior
P(u|y)=P(u,y)/P(y) through the definition of an auxiliary, approximate posterior
distribution Q(u), sometimes called recognition density [39,41]. The approximation
is achieved by minimizing the Kullback-Leibler (KL) divergence between these two
distributions. However, since this quantity still depends on the intractable marginal
P(y), it is replaced by the (formally equivalent) minimization of VFE F. The latter
providesanupperboundonlogevidence(orsurprise)anditsminimizationistractable
because it depends on two quantities that the agent knows or has inferred: the joint
probability P(u,y) and the approximate posterior Q(u).
Since the optimization of F for an arbitrary Q(u) is often complex, it is common
tomakesomeadditional(biologicallyplausible)assumptions. Astandardassumption
made in Active Inference is the Laplace approximation [42], which implies that the
approximate posterior is a multivariate Gaussian distribution, i.e., in the simple case
of u = {x,v}, Q(u) = N({µ,ν},Π−1), where µ is the best guess or belief about
the hidden states, ν is the belief about the hidden causes, and Π is their precision
or inverse covariance matrix. A second common assumption used to simplify the
recognitiondensityisthemean-fieldapproximation[40],whichrenderssomevariables
ofthemodelconditionallyindependent(forexample,hiddenstatevariablesandother
model parameters that we did not consider here). Given the above assumptions, it is
possibletotransformthefunctionalF intoafunctionandevaluateit,uptoconstant
quantities that do not affect the minimization process:
F ≈−lnP(u,y)| (1)
x=µ,v=ν
Hence, under the FEP, everything is reduced to a process of Free Energy min-
imization; however, this requires specifying a generative model - which is our next
topic.
2.1 Generative model
Designingthegenerativemodelimpliesadditionalassumptionsregardinghowanagent
representsthesystemdynamicsandthemappingintoitssensoryinputs. Agenerative
modelcanbedescribedintermsofajointprobabilitydensityP(u,y)=P(y|u)P(u),
which highlights the separation between two components: the observation (or like-
lihood) model and the prior about the hidden variables. The latter can be further
factorized into the joint density P(u) = P(x|v)P(v). In general, the hidden causes
v are quantities that act as causal variables (or priors) over the hidden states x used
to describe the environment, thus enriching the representation of the system dynam-
ics. In some Active Inference implementations, hidden causes are used to encode the
agent’sgoals(aswillbecomeclearwhenwediscussspecificexamples). Thisisbecause,
inkeepingwithideomotorandcyberneticformulations,anydeviationfromthehidden
causes is registered as a prediction error that the agent tries to minimize.
The dynamic environment represented by an agent is usually modeled with the
following stochastic equations:
y=g(x,v)+ω x˙ =f(x,v)+ω v=η+ω (2)
y x v
5
where the function g converts latent variables x and v into observed states y, f
encodes the evolution of the hidden states over time, η is the mean of the prior
distribution over the hidden causes, while w , w and w are noise terms describing
y x v
systemuncertainty,hereassumedtobelongtomultivariatenormaldistributionswith
zero mean and precisions Π , Π , and Π .
y x v
This leads to the VFE:
1(cid:104) (cid:105)
F ≈ εTΠ ε +εTΠ ε +εTΠ ε
2 y y y x x x v v v
ε =y−g(µ,ν)
y (3)
ε =µ′−f(µ,ν)
x
ε =ν−η
v
where µ and µ′ are respectively the internal representations (beliefs) about the 0th
and1sttemporalordersofthehiddenstatesxandx˙. Hence,theVFEtakestheform
ofasumofquadraticformsofpredictionerrors: asensorypredictionerrorε ,astate
y
or model prediction error ε , and a prior prediction error ε .
x v
To effectively represent complex dynamics of the generative process, it is possible
toimprovetheagent’smodelbyusinggeneralizedcoordinatesofmotion[32,43]beyond
the1storder. Forinstance,supposethatthebrainrepresentsbeliefsabouttheposition
of an object. Under a generalized coordinates model, it would also maintain beliefs
about its velocity, acceleration, jerk, and so on. All these time derivatives are then
concatenated to form a generalized belief, denoted by a vector µ˜ ≡ [µ,µ′,µ′′, ...].
The same notation is used for the time derivatives of the other variables (i.e., y˜ ≡
[y,y′,y′′, ...]).
Applying a local linearization [43] to the system dynamics, and then eliminating
thecrosstermsinthederivatives,itispossibletoexpressthegenerativemodelbythe
following set of equations:
y=g(x)+ω x′ =f(x,v)+ω
y x
∂g(x) ∂f(x,v)
y′ = x′+ω′ x′′ = x′+ω′
∂x y ∂x x
∂g(x) ∂f(x,v) (4)
y′′ = x′′+ω′′ x′′′ = x′′+ω′′
∂x y ∂x x
. .
. .
. .
whichcanbeexpressedinacompactformasy˜ =g˜(x˜)+ω˜ andDx˜ =f˜(x˜,v)+ω˜ .
y x
Here, the D operator maps each element of the generalized coordinates to its time
derivative: Dµ˜ = [µ′,µ′′,µ′′′, ...]. Note that using generalized coordinates permits
dealingnotonlywithwhitebutalsocolorednoise. Ingeneral, thesecoordinateshave
beenintroducedtodealwithnon-Markovianprocesses[40,44],adoptingaStratonivich
interpretation with continuous stochastic variables having finite, non-zero autocorre-
lation functions. This is usually done using a temporal covariance matrix acting as
a Gaussian filter between noise terms that modify generalized precision matrices, de-
noted as Π˜. This leads to a Free Energy that has the same (quadratic) form of
prediction errors [43].
6
2.2 Free Energy minimization
Active Inference assumes that the Free Energy is minimized in two complementary
ways. One,sharedwithpredictivecoding[30],consistsofmodifyingtheagent’sinter-
nalbeliefs,toproducepredictionsthatmatchthecurrentobservations. Inparticular,
it has been proposed [40] that the intrinsic dynamics of neural activity evolve in such
a way as to implement a (modified) gradient descent scheme:
∂F ∂F
µ˜˙ −Dµ˜ =−k ν˙ =−k (5)
µ∂µ˜ ν∂ν
where k and k are tunable learning rates.
µ ν
Inbiologicalterms,thismeansthatagentsareconstantlyengagedinaninferential
process to capture the hierarchical relationships between what is perceived at every
instant and what causes those perceptions. Importantly, the instant derivative of a
particular order of the generalized belief does not necessarily correspond to the belief
overthatderivative(i.e.,µ˙ ̸=µ′);thedifferencebetweenthosetwotermsprovidesan
additionalerror-termtominimize. AsevidentinEq. 5,itisonlywhentheFreeEnergy
is minimized that the generalized belief captures the real instantaneous trajectory of
the environment. Furthermore, since the Free Energy consists of a sum of quadratic
forms, its partial derivatives lead to simple update equations – proportional to the
prediction errors weighted by their respective precisions – which are similar to those
originally derived in the predictive coding model of [30]:
µ˜˙ ∝∂ g˜TΠ˜ ε˜ +∂ f˜T Π˜ ε˜ −DTΠ˜ ε˜ (6)
µ˜ y y µ˜ x x x x
Thus,theoverallupdateforthegeneralizedbeliefoverhiddenstatesissubjectto
three different forces: a likelihood component proportional to the sensory prediction
error; forward and backward components of the state prediction errors coming from
the previous and next temporal orders.
InActiveInference,thereishoweverasecondwaytominimizetheFreeEnergy: by
actingintheenvironment,theagentproducessensoryobservationsthatmatchitspre-
dictions. This action-related way to minimize the Free Energy is especially appealing
tomodelbiologicalorganismsthatstrivetorealizetheirgoals(orthepriorpreferences
encoded in their generative models). For example, if an organism is endowed with a
prior over a desired body temperature and senses a different value, it can maintain
its integrity by acting (e.g., by moving to a place having the desired temperature) –
whereas only changing its belief would probably lead to death in the long term. In
short, the predictions are fulfilled by acting, rather than corrected by changing mind.
Figure 2: ComparisonbetweenmotorcontrolschemesinOptimalControl(left)andActive
Inference(right). Seethemaintextforadetaileddiscussion.
7
Formally, minimizing the Free Energy with respect to the actions a results in a
gradient descent scheme similar to the previous case:
∂F ∂F ∂y
a˙ =−k =−k (7)
a∂a a∂y ∂a
where k is a learning rate.
a
Note that in the last gradient of Eq. 7, the presence of the term ∂ y is key – and
a
points to the agent’s “implicit” knowledge of (simple) sensory outcomes of actions.
Here, “implicit” is used in the sense that the action variable a is not considered
to be part of the generative model, but at the interface between generative model
and process (see Fig. 1). This knowledge does not correspond to a sophisticated
“inverse” model, but to simple and short-term action consequences, which could be
associatedwithreflexarcs. Forexample,the“inverse”modelforavelocity-controlled
schemecouldbesimplyapproximatedbyatimeconstant∆ [45]. Aswillbeexplained
t
below, in the Active Inference framework reflex arcs are key to motor execution via
theminimizationofproprioceptivepredictionerrorsinducedbytop-downmodulatory
signals from motor areas [26].
Insum,theabovediscussionhighlightsthattheinteractionbetweentheagentand
the environment is characterized by a closed loop, during which the agent minimizes
theFreeEnergy(orundersomesimplifyingassumptions,predictionerrors). Theagent
couldminimizepredictionerrorsthroughbeliefupdates,whichrendersthegenerative
model closer to the generative process, therefore creating a good representation of
the environment. Alternatively, it could generate actions that render the generative
process closer to the generative model. Whether the former (belief updating) or the
latter (action) process is selected simply depends on the relative balance between
prediction errors and their relative precisions. For example, an agent endowed with
an extremely precise prior would never update it in the light of novel evidence and
hence would always try to minimize the Free Energy by acting. Conversely, an agent
endowed with an imprecise prior would be more willing to update its beliefs in the
light of novel evidence. This implies that the design of the generative model is a
crucialchoicetodeterminetheagent’sbehavior. Twoagentsthatdealwiththesame
situationbutareendowedwithdifferentgenerativemodels(e.g.,withdifferentpriors)
could produce completely different patterns of behavior.
2.3 Neural underpinnings of motor control in Active In-
ference
It is useful to briefly summarize the key biological assumptions of motor control in
Active Inference and compare them with classical theories such as Optimal Control;
see [46] for an extensive treatment of these differences and of forward and inverse
models in the brain. As we highlight in Fig. 2, both Active Inference and Optimal
Control [1,2] use similar processes and variables, but arrange them differently. The
main difference is that in Active Inference, the forward (generative) models convey
proprioceptive predictions down to the spinal cord to compute motor commands at
the level of the reflex arcs. Instead, in Optimal Control, the forward models are
coupled with inverse models at a higher level to compute motor control signals.
Thus,inActiveInferenceactionismadepossiblethroughlow-levelsuppressionof
prediction errors, which not only climb up the hierarchy but also exert forces on the
muscle states. It is worth noting that while the mathematical formulation of Active
8
Figure3: Anexampleofgoal-directedreaching,from[37]. Leftpanel: thestimulatedrobot.
Right panels: Reaching trajectories of the robot’s 7 DoF arm in three dimensions, from a
startlocation(bottom)toagoallocation(greendot)infourscenarios: (subpanela)without
noise; (subpanel b) with noisy proprioception; (subpanel c) with noisy vision; (subpanel d)
withnoisyproprioceptionandvision. Thebluetrajectoryisthemeanofthe20trajectories,
showningray.
Inferenceallowsinvolvinganysensorymodalityinactionprocesses,inbiologicaltreat-
mentsitisoftenassumedthatmotorcontrolisrealizedbyminimizingproprioceptive
- and not exteroceptive - prediction errors [26], whereas autonomic control is realized
by minimizing interoceptive prediction errors [27,47]. The reason for assuming that
only proprioceptive prediction errors are involved in motor control is the observation
that the efferents of the somatomotor system share crucial similarities with top-down
projections of other brain areas, thus seeming to encode proprioceptive predictions
rather than motor commands [26]. In this perspective, proprioceptive prediction er-
rors are computed in the spinal cord through the reflex arcs and backpropagated by
afferentsthroughoutthecorticalhierarchy,whereasexteroceptivepredictionerrorsare
generated locally in their respective functional areas. It is thus unlikely that direct
somatomotor efferents convey pure exteroceptive signals from the respective sensory
areastothemuscles,orthatadifficultinversionisrealizedinthespinalcordbetween
motorandexteroceptivedomains. Thismakesitunlikelythatexteroceptivesensations
aredirectlyusedforactionexecutionandmarksanothersignificantdifferencewithOp-
timalControl. However,movementsdrivenonlybyproprioceptivecontributionsraise
a few concerns regarding multisensory conflict resolution, as will be explained later.
3 Examples of Active Inference models of motor
control
Here we review some examples of Active Inference models that target four kinds of
problems: goal-directedmotorcontrol,activesensing,multisensoryconflictresolution,
and decision-making in dynamic environments. The list of selected models and func-
tions is not exhaustive, but provides an overview of the scope of Active Inference in
continuous time.
3.1 Goal-directed reaching: four examples
Asexplainedabove,actionfollowspredictionerrorsthatmayresultfromadiscrepancy
between a proprioceptive observation and a proprioceptive prediction. This situation
can be exemplified in the case of goal-directed reaching actions, where the start and
the goal positions of the agent’s arm initially differ. One example of Active Inference
implementationofagoal-directedreachingtaskwasproposedin[37]. Here,asimulated
7 Degrees of Freedom (DoF) robotic arm had to reach a static target (see Fig. 3, left
9
panel). The agent maintained a belief over the arm’s joint angles, and was endowed
with a proprioceptive model producing predictions in the same domain and a visual
model generating the end effector’s position. The goal states were embedded into
the 1st-order dynamics function, where the trajectory of each joint was modeled by
Newtonian dynamics with parameters λ, κ and m representing elasticity, viscosity,
and mass. The role of the dynamics function is to make the agent perceive a force
proportional to the desired one, (or better, “think that it will perceive” the force,
sincetheforcedoesnothaveanycounterpartinthegenerativeprocess). Thisforceis
computed by performing a kinematic inversion of the error between the end effector
andthetarget’sposition,andbytakingintoaccountallthepossiblesingularities. The
right panels of Fig. 3 show the different trajectories that the agent performs under
variousconditionsinwhichthenoiseofoneormoreinformationsourcesisintroduced.
These results highlight the advantages of relying on precise multisensory information
(panel a) compared to situations in which proprioceptive (panel b), visual (panel c),
or both sources (panel d) are noisy.
Another implementation for a similar reaching task is described in [48]. Here, the
agent had to perform two tasks: continuously tracking a moving target and realizing
multi-stepmovementstowardtwodifferentobjectlocations. Inthiscase,thehigh-level
beliefconsistednotonlyofthearm’sjointangles,butalsoofasmanycomponentsas
every object to interact with. Such components were encoded in the proprioceptive
domainandtheycouldbeinterpretedasparticularaffordancesthattheagentwanted
to realize. To address the first (target tracking) task, the belief dynamics uses a
custom “intention” that manipulates the current belief to produce a possible future
configuration. For example, if the belief consists of three components corresponding
tojointconfigurationsofanarm,atarget,andapreviouslymemorizedhomebutton-
i.e.,µ=[µ ,µ ,µ ]-anintentiontoreachthetargetisbuiltthroughafunctionthat
a t h
sets the first component equal to the second one, i.e., µ∗ = [µ ,µ ,µ ]. This future
t t t h
predictionisthensubtractedfromthecurrentbeliefandembeddedintothe0th-order
dynamics:
f(t) =λ(µ∗−µ)=λ·[µ −µ ,0,0] (8)
t t a
where λ is an attractive gain. Since the target configuration is continuously inferred
through visual predictions (here, generated by the decoder of a Variational Autoen-
coder (VAE) [49], the agent is able to reach and track moving objects, as shown in
Fig. S1. Furthermore, [48] generalized the above approach by considering multiple
intentions that operate simultaneously, thus allowing one to realize more complex
movements or multi-step tasks, such as the one represented in Fig. 4. For example,
if a home button reaching intention is constructed in the same way as the first one,
called µ∗, the overall attractive force is:
h
µ˙′ =−π ε −π ε (9)
x,t x,t x,h x,h
whereε andε arethestatepredictionerrorsofthetwointentions,withprecisions
x,t x,h
π andπ . Amulti-stepbehaviormaythenbeachievedbydynamicallymodulating
x,t x,h
thelatter,e.g.,throughabeliefovertactilesensations[50]. Notethatwhiletheabove
examplessuggestthatthepresenceofagoalstateoraproprioceptivepredictionerror
always results in an immediate movement, this is not always the case. A simple
demonstrationisindelayedreachingtaskswheremotorintentionsarealreadypresent
in the preparatory phase but the onset of action execution depends on a sensory cue
thatispresentedataparticulartime. Theprecisionsmodulationcanthenalsobeused
to separate the two phases of action preparation and execution (see Fig. 4), as done
10
Figure 4: Visual representation of the two-step delayed reaching task of [48], composed
of two distinct phases. Real and estimated arms are displayed in blue and green, real and
estimatedtargetsinredandpurple.
in [48]. In short, a delicate balance is in place between high- and low-level precisions:
indeed,movementinActiveInferenceispossiblethroughsensoryattenuation,i.e.,by
reducing the precisions of sensory generative models, so that the belief can be free
to change by its own dynamics, ultimately affecting what sensations will be sampled
next [51].
A more realistic implementation of reaching (and other advanced) movements is
illustratedin[52]. ThisstudyintroducesablockcalledIEmodel thatconsistsofintrin-
sic (e.g., joint angles) and extrinsic (e.g., Cartesian positions) beliefs, linked through
a generative kinematic model. While the previous examples required inverse models
(either in the dynamics function – as a pseudoinverse or a Jacobian transpose – or in
theimplicitbackwardpassoftheVAE),in[52]theinversionarisesnaturally,through
inference. Theextrinsicgoalisdefinedatalowerlevelcomparedtotheintrinsicstate,
followingthecausalrelationsencodedintothegenerativeprocess. Maintaininganex-
trinsicbeliefhascriticalbenefits,sinceitpermitstoeasilydesigncomplexmovements
(e.g.,circularorlineartrajectories),withoutworryingaboutintrinsictransformations.
Furthermore,differentblockscanbecombinedtoencodeintrinsicandextrinsicinfor-
mation for each DoF of the kinematic chain separately. This scheme affords more
efficient control, permitting to simulate whole-body kinematics during (for example)
sophisticated reaching and obstacle avoidance tasks. See Figures S2 and S3 for some
examples.
Beyond reaching, Active Inference has been used also to simulate the control of
eye movements [53–55]. For example, the study of [56] uses a hierarchical model that
includesabeliefoverthetargetinabsolutecoordinatesandabeliefoverthevergence-
accommodation angles. The model consists of two parallel pathways – one for each
eye – that perform a perspective projection of the target into the eye planes. This
approachpermits: (i)inferringthedepthofthetargetbyaveragingthecontributions
frombotheyes;(ii)fixatingatarget,byimposinganattractorintheprojectivespace
of the eyes; and (iii) performing concurrent depth estimation and target fixation –
or active vision – through action-perception cycles – which is particularly useful to
counteract the nonuniform fovea resolution of the eyes (see Figure S4).
Taken together, the above examples show that in Active Inference, it is possible
to define goals for movement as priors over the internal representation of the system
dynamics. These priors then lead to a goal-directed control through Free Energy
minimization,ratherthanappealingtostimulus-responsemappingsandcostfunctions
as in Optimal Control [1,2] and reinforcement learning [3] (see [46] for a detailed
discussion of the differences between the roles of cost functions in Optimal Control
and Active Inference). As explained before, priors play a similar role as setpoints
for movement control in cybernetics. The above examples also help illustrate the
differencesbetweenthegenerativeprocessencodingtherealenvironmentaldynamics,
11
andtheagent’sgenerativemodel–andthefactthattheyarereciprocallyconnectedin
anaction-perceptionloop. Finally,theyillustratethattherearevariouswaysinwhich
movementcanbegenerated,e.g.,itispossibletoimposedifferentkindsofpriorsthat
determine different behaviors; we will return to this point in the Discussion.
3.2 Active sensing
Active sensing refers to the ability of an agent to adapt its perception using self-
generatedenergytosampletheenvironment[57–59]. SeveralActiveInferencemodels
implement active sensing routines to support visual processing [23,60] and whisker
movements [61], among other examples.
The model of [35] combines motor prediction – the reuse of the motor system to
predictperceivedmovements–andanactivesensing(orhypothesistesting)strategy:
the use of saccadic eye movements to disambiguate among alternative hypotheses.
The architecture embeds a generative model of how (arm and hand) actions are per-
formed to generate hypothesis-specific visual predictions, and directs saccades to the
most informative (or diagnostic) visual locations to test them. The model follows
the hierarchical form for generalized predictive coding, as shown in Fig. 5A. Internal
statesencodearepresentationofthecenterofoculomotorfixationandtheprobability
that each hypothesis is the cause of the visual input. Hidden controls determine the
locationthatattractsthegaze. Themodelistestedbyevaluatingthesalienceofsam-
pling dynamic visual locations under two competing hypotheses (power grasp versus
precision grip) in two conditions: with and without preshape.
Themodelreproducesthedifferencesobservedempiricallybetweentheobservation
ofgoal-directedgraspingactions,withorwithoutinformativecues(i.e.,whenthehand
oftheactoris“preshaped”tograsponeofthetwopossibleobjects,bigorsmall,versus
when there is no preshape). The study of [62] reported that during the observation
of goal-directed grasping actions without informative cues (e.g., without preshape),
visualsaccadestendtofollowtheobservedarm. Rather,wheninformative(preshape)
cues are present, people make anticipatory saccades to the object to be grasped.
Thesimulationresultsshowsignificantdifferencesbetweenareactivehand-following
gaze strategy, which emerges in the no-preshape condition, and an anticipatory gaze
strategy,whichemergesinthepreshapecondition,shortlyafterthebeginningofatrial
- analogous to the empirical study of [62]. The crucial model component that affords
this active sensing strategy is a saliency map that assigns salience to the elements of
the visual scene that afford information gain about the to-be-inferred grasping move-
ments(handshape)ortheirdestination(objects)-insuchawaythattheobjectsonly
becomesalientwhentheuncertaintyaboutthegraspingmovementhasbeenresolved.
See [35] for details.
The authors assume that a hierarchically organized “action observation” brain
network computes both the expected hand position (at lower hierarchical levels) and
theprobabilityofthetwocompetinghypotheses(athigherhierarchicallevels). Fig. 5B
showsthetwocompetinghypothesesconsidered,whicharenotonlyaboutfinalstates
(handonbigversussmallobject),butencompassthewholeactionunfoldingintime.
Inpractice,theycorrespondtosequencesof(superimposed)imagesofhandtrajectories
(here,6timeframes). Asevidentinthefigure,thehypothesisthattheactorisreaching
a small (or big) object entails that the hand will be configured in a precision grip (or
powergrasp)duringactionexecution–anditisthissortofhypothesisthattheagent
tests by performing saccades to the most informative locations. Fig. 5C-L shows the
results of two example trials during which the agent observes an actor performing a
12
Figure 5: The active sensing model of [35]. (A) The model describes which visual stimuli
shouldbeexpectedundertwoperceptualhypotheses(e.g.,iftheactiontargetisthebig/small
object,whendoingasaccadetothenexthandpositionIshouldseeapower/precisiongrasp)
andgeneratessaccadestocheckiftheexpectationsarecorrectandtorevisetheprobabilityof
thetwohypotheses. Inthefirsthierarchicallayerofthearchitecture,proprioceptiveandvisual
signals yp and yq are generated, which are then used to compute the respective expectation
µ˜x,p and µ˜x,q through message passing of prediction errors εx,p and εx,q. (B) Schematic
illustration of the two competing hypotheses, corresponding to sequences of images. (C-L)
Simulationresultsoftworepresentativetrials,duringwhichtheagentobservesanactorthat
grasps the small object without hand preshape (left) or with hand preshape (right); see the
maintext.
13
precision grip toward the small object, without (left) or with preshape (right). In
particular,thepanelsshowtheexpectedprobabilityofthetwocompetinghypotheses
duringanexampletrial(C);thelocationofthesaccadesinthevideoframeatsixtime
frames (D); the corresponding saliency maps, with white locations corresponding to
the locations to which the model assigns greater salience, hence the best candidates
forthenextsaccade(E);thehidden(oculomotor)statescomputedbythemodel(F);
the content of what is sampled by a saccade in the (filtered) map (G); the posterior
beliefs about the “true” hypothesis, where expectations (expected log probabilities)
are plotted in blue and the associated uncertainty (90% confidence interval) in gray
(H);theobservationsofthemodeli.e.,themixtureoftheviablehypothesesweighted
bytheposteriorexpectation,representedasaweightedsuperpositionofalltheframes
duringthesimulationsteps(I);andthesequenceofsaccadesthatthemodelperforms
during the experiment (L).
Without preshape (left panels), the gaze follows a reactive, hand-following strat-
egy and the action is disambiguated fairly late in the trial. Rather, with preshape
information (right panels), the clues present in the hand movement afford a faster
disambiguation of the correct hypothesis and anticipatory saccades to the inferred
objects: the eyes land on the small object before the hand arrives. This example
illustrates that the same Active Inference mechanism that we discussed above in the
contextofgoal-directedactions(e.g.,reachinganexternaltarget)canalsomodelactive
and higher-level oculomotor control, where the objective is to sample the sensorium
for hypothesis testing. Both forms of behavior stem from Free Energy minimization
underdifferentgenerativemodels;whileweillustratethemseparately,theycouldalso
emerge simultaneously in the same model [23].
3.3 Unintentional actions driven by multisensory conflict
Sofar,wediscussedActiveInferencemodelsofgoal-directedmovement(e.g.,reaching
or following a target) and active sensing. However, movement can also arise uninten-
tionally,withlittleornoawareness. Whilethestudyofunintentionalmotorbehavior
found so far little space in the motor control literature, recent evidence for the sys-
tematic induction of unintentional actions comes from embodiment studies, in which
subjects undergo an illusory experience in which fake bodies (e.g., virtual avatars) or
bodyparts(e.g.,rubberhands)areperceivedasbeing(partof)theirownbody[63–66].
During these body ownership illusions, subjects process the seen body (parts) as the
samecausalentitygeneratingsomatosensorysensations[67–69],andtosomeextentit
is possible to introduce multisensory conflicts about the body configuration without
breaking the illusion [70,71]. For example, in the Rubber Hand Illusion (RHI), when
the rubber hand is placed next to the real (occluded) hand, a visuo-proprioceptive
conflict about the hand location is in place. This conflict has been associated with a
proprioceptive recalibration of the perceived hand location since the very first report
of the RHI [63], and consists of a shift of perceived hand location in the direction of
thevisualhand. Interestingly,laterworkshaveassociatedanactivecomponenttothe
illusion; namely, the tendency to unconsciously exert a force in the direction of the
visual hand and to move along with it if no restrictions are in place, in some cases
even when subjects are explicitly instructed to stay still [72–74]. This behavior has
been associated with an active strategy for suppressing prediction errors associated
with the perceived location of the hand. Additionally, movements may arise because
the subject tries to minimize model uncertainty, e.g., to understand if the perceived
and the real hand positions match. The latter process has been successfully repro-
14
ducedinActiveInferenceimplementationsoftheaction-perceptionloopsduringbody
ownership illusions [36,72,74].
Thestudyof[72]introducedanActiveInferencemodeloftheactivestrategiesthat
emergeduringownershipillusionstosuppressmultisensory(self-perception)conflicts.
ThemodelistailoredtotheclassicRHIinitsvirtualversion(usingavirtualhand,not
arubberhand),inwhichsubjectsarenotallowedtomovetheirhand. Inlinewiththis,
the model computes the actions but these do not enter the computation of the hand
dynamics. Indeed,actionsareherecomputedasaproxyfortheforcethatparticipants
exerted while experiencing the illusions with their arms restrained. In this respect,
the model has the intrinsic limitation of being uncoupled with the arm dynamics.
This limitation was addressed in another study [36], which proposed a unified model
that can account for both goal-directed motor behavior (i.e., reaching actions) and
unintentional motor adjustments arising from multisensory conflicts associated with
self-perception, and for their interaction.
The model of [36] implements an agent that continuously infers its own bodily
configuration and could be set to have a goal of reaching a given target. If no goal to
reach is instantiated, which corresponds to no intention to move, the agent is set to
fulfill the requirement to keep its current configuration. A schematic summary of the
model is given in Fig. 6A. An important novelty with respect to previous implemen-
tations of arm control is the possibility to simulate the case in which the agent has
no goal (i.e., no intention to move), enabled by keeping the internal representation of
system dynamics used for reaching tasks (i.e., a damped oscillator) and setting the
attractor(i.e.,thedesiredstate)tothecurrentarmconfiguration. Despiteitssimplic-
ity,thisextensioniskey,becauseitallowsinspectingsubtleaspectsofmovementsuch
as how unintentional motor adjustments arise as a byproduct of self-perception, and
how these adjustments interfere with goal-directed behavior. This is exemplified by
some of the results of the model that we discuss in the following. A second difference
frommostpreviousimplementationsisthatactioniscomputedbyconcurrentlymini-
mizingpredictionerrorsintheproprioceptiveandtheexteroceptive(visual)domains.
Thisisessentialtocorrectlymodelvisually-guidedactionoperatedundermultisensory
conflict about the body state.
Fig. 6B shows results comparing standard reaching, unintentional alignment of
thephysicalhandtoitsvisualcounterpartduringanownershipillusion,andreaching
underbodilymultisensoryconflict(columnsfromlefttorightrespectively). Thethree
simulationsusethesameagentexposedtodifferentcombinationsoftasksandsensory
inputs. In the first, the agent is assigned a standard reaching task; in the other two,
the agent undergoes an ownership illusion over a rubber/virtual hand, and sensory
input about limb state is streamed by the fake the real hand in the visual and the
proprioceptive domain, respectively. In one case, the static rubber hand is displaced
with respect to the real hand and the agent does not have a task assigned besides
observing (and inferring) its own state. In the other case, the agent has to reach a
targetbutthevelocityofthevirtualhandissetto1.3timestheoneoftherealhand,
so that during the task execution the two hands get progressively displaced from one
another. The model assumes that the ownership illusion is in place by treating the
visualinputfromthefakehandasifgeneratedbytheinferredarmconfiguration,which
isencodedbytheagentintheproprioceptivedomains(y ). Thussensorypredictions
θ
takes the form: y = [y ,y ], with y = µ and y = [µ ,µ ] (see
µ µP µV µP θ µV PRH,x PRH,y
Fig. 6Aformoredetails). InthesimulationofthestaticRHI,theinternalmodelhas
been adapted by tuning two of its parameters: (i) the gain of the action component
driven by vision, set to zero to account for the fact that the fake hand is static and
15
Figure 6: Schematic implementation and results from the Active Inference model that si-
multaneouslyaccountsforintentional(goal-directed)andunintentionalmovements,described
in[36]. (A)Themodelimplementsa1-DoFagent,whoseconfigurationisuniquelydescribed
by its elbow’s joint angle and angular velocity – x = [θ,θ′] – and who receives informa-
tion about its own configuration and the environment through proprioception and vision –
y=[yP,yV]. Thedynamicsoftherealarm–x˙ =fx(x,a)–representsadampedsystemthat
maybesubjecttointernalforcesgeneratedthroughactions(here,formalizedasjointangular
accelerations),whiletheinternalmodelofthearmdynamicsfµ(µ
θ
,µ
θT
)byadampedoscil-
lator where the attractor is either set to the arm configuration µ in which the hand is on
θT
target(forreachingactions),ortothecurrentstatewhentheagenthasnointentiontomove.
(B) Results from three simulations: standard reaching (left column), classic rubber hand il-
lusion (central column), and reaching under visuo-proprioceptive conflict (right column). In
eachcolumn,panelsfromtoptobottomshowthetemporalevolutionoftherealandinferred
joint angles and joint angular velocity, of the prediction errors, and of the contributions to
actionarisingfromtheminimizationofproprioceptiveandvisualpredictionerrors.
16
not under the control of the agent, and (ii) the internal estimate of the sensory noise
in the visual domain, increased to roughly account for the fact that (as it happens in
therealworld)whileundergoinganownershipillusiontheagentisstillawarethatthe
seenhandisfakeandtherefore“lessreliable”asasourceofinformationaboutitsown
bodily state; see [36] for more details.
The results from the three simulations shown in Fig. 6B demonstrated that the
proposed implementation could account for intentional motor behavior, as in the ex-
emplificationofstandardreaching,andforunintentionalmotoradjustmentsdrivenby
multisensory conflict in self-body processing, as observed in experimental settings of
ownership illusions. In addition, the model successfully reproduces the motor behav-
ior observed for visually-guided actions in presence of multisensory conflicts, like in
the case of reaching under visuomotor rotations or with aberrant velocity mappings.
Importantly, this case would indicate that the action is driven by both visual and
proprioceptive prediction errors; in fact, keeping action exclusively associated with
theminimizationofproprioceptivepredictionerrorswouldleadtotheimplausiblere-
sult of the agent overshooting the visual target (see [36] for details). Interestingly, a
previousActiveInferencemodelofasimilarvisuomotorrotationtaskhasshownthat
modulating the relative weighting of the internal estimates of the (visual and propri-
oceptive) sensory noises can mimic attentional effects akin to those observed in the
laboratory [75].
Together, these results lead to two main insights. First, in the case of intentional
reaches,predictionerrorsareinitiallydominatedbymodelerrorsdrivenbytheinternal
dynamics under the effect of the target attractors; then, sensory prediction errors
arise as a consequence of the model errors on perceptual inference. In the case of the
RHI, model errors are absent (as no motor intention is instantiated) and the sensory
predictionerrors–thustheactions–ariseasabyproductofthevisuo-proprioceptive
conflicts associated with self-body perception. An important consequence of the lack
of model errors is that the agent does not update the internal estimate of the joint
angularvelocity, whichstaysnullasifnomovementhasoccurred(providingthatthe
agenthasnodirectaccesstojointvelocitythroughproprioceptivereceptors). Thishas
beensuggestedasapossibleexplanationforthelackofmotorawarenessthattypically
characterizes subtle unintentional motor adjustments.
Second, when simulating reaching under visuo-proprioceptive conflicts, a better
fit with experimental data can be obtained by also allowing exteroceptive (not only
proprioceptive) prediction errors to drive the action. Given the spatial misalignment
that emerges from the aberrant velocity mapping between real and fake hands, the
inferred posture (µ ) is biased toward the visual hand. If action were only driven by
θ
proprioceptive prediction errors, both the virtual and the real hand would overshoot
thetarget,whichrunsagainsttheempiricalobservationthatthetaskisaccomplished
once the visual hand correctly reaches the target.
3.4 Mixed models for sensorimotor decisions
Despitethetraditionalliteratureviewsdecision-makingandactioncontrolsystemsas
separatedcognitiveprocesses,amorerecenttendencyconsidersthemastwointeract-
ing levels of the same integrated system [76–78]. Accomplishing various skilled tasks
engages a series of decisions to establish the sequence of movements to make, and to
guidethesensorimotorbehavior. Atthesametime,actionscandeterminechangesin
the real world that force us to modify the goal of the executed task and to revise the
plan previously imagined.
17
Fromamodelingperspective,thevariablesemployedinthissensorimotordecision-
making system are of different natures: decision-making typically involves discrete
variables that select the sequence of actions composing a motor behavior, while the
executionofmotorbehaviorinducesadynamicvariationofsomecontinuousvariables
(e.g., contracting muscles or decreasing the body temperature). To integrate both
discrete and continuous time variables within the same Active Inference model, it is
possibletoadoptso-called“mixed”models[79]. Mixedmodelsinheritthearchitecture
ofhierarchicalgenerativemodels,wherethepredictionofalevelactsasapriorforthe
levelbelow,whichinturncomputesapredictionerrorthatisthenusedasalikelihood
signalforthehigherlevel. Inatypicalmixedmodelhavingtwolayers,thehigherlayer
consistsofadiscretePartiallyObservableMarkovDecisionProcess(POMDP);inthis
article, we did not focus on this discrete-time Active Inference, but a full treatment
can be found in [23]. Rather, the lower layer of the typical mixed model implements
exactlytheActiveInferenceincontinuoustimethathasbeenthefocusofthisarticle.
Thehigherlayergeneratessequencesofdiscreteoutcomes,whichconstitutethepriors
– or fixed-point attractors – on the hidden causes, guiding the sensorimotor process
controlled by the lower layer. Since the two layers consist of variables of different
natures,theyareconnectedbyaparticularinterfacedescribedin[79]thatpropagates
the beliefs from one layer to another, via descending and ascending messages.
In mixed models, inference progresses by determining probabilities π about se-
quences of control states (i.e., policies) at the higher layer. Each policy π generates
π
a transition between hidden discrete states s , which corresponds to a sequence of
π,τ
predicted outcomes o . By performing a Bayesian model average of the outcomes
π,τ
(cid:80)
of all policies, a posterior predictive distribution o = π ·o is obtained and
τ π π π,τ
sent as a descending message to the lower continuous layer. Each component o
τ,m
canbeunderstoodasaparticularmodel,steeringthelower-levelcontinuousdynamics
in a specific direction. The mapping of an outcome model into the continuous space
is denoted as η , encoding a fixed empirical prior; a second Bayesian model average
m
(cid:80)
defines the actual prior η over the hidden causes ν, i.e., η = η ·o . Having
m m τ,m
sampled continuous observations, the lower layer returns an ascending posterior esti-
mationforthebeliefofeachdiscreteoutcomethroughamodelevidenceaccumulated
by the dynamical system over some time T:
(cid:90) T
E(t) =−lno − L(t) dt (10)
m τ,m m
0
where L(t) = lnP(y˜(t)|η ) − lnP(y˜(t)|η), with lnP(y˜(t)|η ) and lnP(y˜(t)|η)
m m m
denotingthelogevidencesaboutcontinuousobservationsy˜(t)=[y(t),y′(t),y′′(t),...]
regarding a single model m and the full set of models, respectively. In other words,
L(t) isapost-hocBayesiancomparisonbetweentwo(Gaussian)probabilitydensities
m
usedtosampletheoutcomes,undertheempiricalreduced(η )andthefull(η)priors
m
[80]. It can be shown that if η =η, then L(t) =0; see [79] for a demonstration.
m m
Ontheotherhand,E(t) expressestheFreeEnergyofcompetingoutcomemodels
m
defined as the sum between their descending prior surprise −lno and the log evi-
τ,m
denceL(t) oftheirascendingposteriorintegratedovertime. NotethatwhenT =0,
m
the ascending posterior reduces to the descending prior. Thus, E(t) assigns a score
m
to the sampled continuous outcomes in relation to the predicted discrete models. To
convert this score for each model back to the discrete layer, E(t) is passed through a
softmax function to give a posterior over each outcome model, so that it can be used
as discrete observation into the POMDP inference process.
18
In the last few years, various studies have used mixed models to target scenar-
ios requiring both discrete and continuous variables. For example, [81] proposed a
mixed generative model to sample visual information from the environment, which
sharessomeresemblanceswiththeactivesensingmodelof[35]introducedabove,but
integrates both discrete and continuous variables. The discrete layer of the model
implements a POMDP to build a sequence of saccade targets and to decide where to
look. Such decisions are translated into movements of the oculomotor system by the
continuous layer that implements how to look, i.e., the realization of the saccades by
controlling the anatomical effectors. Successively, the sampled observations are fed
back to the discrete layer to evaluate the goodness of the saccade sequence.
Asimilarmixedgenerativemodelwasusedtostudytheinteractionbetweenphar-
maceuticals and oculomotor behaviors, by focusing on the influence of cholinergic
and GABAergic agents upon the choice of the target to fixate and the speed of sac-
cades [54]. The authors simulated an oculomotor task introduced in [82], in which a
cueforagivensaccadelocationispresentedandafteritsdisappearance,asaccadeto
the target is executed. In the mixed model used to simulate the oculomotor task, the
discrete layer generates predictions about the fixation locations, which constitute the
attractor points for the oculomotor system dynamics in the continuous state-space.
The effects of neuromodulators are simulated by changing various parameters of the
mixed model; namely, the precision of the hidden states transitions (noradrenaline),
themappingbetweenhiddenstatesandsensorydata(acetylcholine),thebeliefabout
thebestsaccadetoselect(dopamine),ortheempiricalpriorsthatcontrolthesaccade
peak velocity (GABA).
Another application of mixed models is the “active listening” model [83], which
simulates the parsing of meaningful words from auditory perception. Following some
insights borrowed from active vision, the generative model segments the continuous
stream of acoustic signals by placing word boundaries in accordance with some prior
constraints. For example, the offset of one word should precede, in some plausible
time range, the onset of the subsequent word; in a speech, signal segmentations are
more likely to contain words than non-words; chosen a specific language, there exists
a prior knowledge on the possible produced words; etc. The active listening model
then proceeds by identifying several plausible boundary intervals, which provide the
greatest evidence for the prior beliefs about the words.
Anotherinterestingapplicationisillustratedin[84]. ThisstudyshowsthatActive
Inference can simulate several neurological conditions and that some reflexes might
naturally emerge under the appropriate generative model. Furthermore, this imple-
mentation shows that linking a continuous model of the arm dynamics and a discrete
decision model permits performing multi-step reaching movements, by planning from
a high-level goal. A similar model was used to solve a dynamic pick-and-place opera-
tion[85]. Inthiscase,twonoveltiesareintroduced. First,thediscretemodelgenerates
and integrates predictions simultaneously from the intrinsic and extrinsic modalities
also used in [52]. Second, the reduced priors of the agent are updated at each dis-
cretestep,allowingittograspmovingobjects. Asimilargraspingtaskwassimulated
in [86], but using an unconventional approach. In this case, the hidden causes were
sampled by a categorical distribution, while the reduced priors were generated by in-
dependent dynamics functions of the hidden states. This allowed to impose and infer
staticanddiscreteintentionscorrespondingtodynamictrajectoriesinthecontinuous
environment.
Yet another example of mixed models - this time, in the domain of interoceptive
processing and autonomic (not action) control - is provided by [28]. The authors
19
describe the mechanisms of adaptive physiological regulation using three generative
models of increasing complexity, which are able to simulate homeostatic, allostatic,
and goal-directed regulation of bodily and interoceptive parameters, such as temper-
ature, thirst, and hunger. While the first two generative models use only continuous
variables, the latter generative model (for goal-directed control) is a mixed model, in
whichthehigherlayerimplementsaPOMDPprocesstoselectamongdiscretepolicies
(e.g., to run with or without a bottle of water), while the lower layer is a continuous
timesystemthatregulatesinteroceptivedata(e.g.,bodytemperature)viaautonomic
reflexes (which might be considered largely analogous to motor reflexes, but operate
oninteroceptivestreams[47,87]). Inordertoestimatethelong-termconsequencesofa
certainpolicy,themodelmapsdiscreteoutcomesatthehigherlayerintopriorbeliefs
for specific interoceptive observations at the lower layer. Conversely, the lower layer
model provides evidence about the discrete outcomes used as hypotheses about the
expected prediction errors, so that it contributes evaluating the policies at the higher
layer. Models of this kind can be used to support computationally guided investiga-
tionsofinteroceptiveprocessinganditsdysfunctionsthatarepossiblyassociatedwith
psychopathological conditions [88–94].
4 Discussion
Howdoesthebraincontrolmovementstowardgoals? Thereisaviewofmotorcontrol
– pioneered by ideomotor theory and cybernetics – according to which actions are
inextricably linked to their effects, rather than stemming as responses to stimuli. In
thesetheories,actionstartswithsomeinternalimageofanintendedeffect–sometimes
called a preference, a goal, or a setpoint – and the movement is the consequence of
fillingthegapbetweentheintendedeffectandthesensedenvironmentalcondition. In
other words, these theories assign a role to action effects, or the discrepancy between
actioneffectsandsensoryevents,intheselectionandthecontrolofmovements. Active
Inference formalizes key intuitions of these theories, in terms of priors, predictions,
and prediction errors, therefore linking to a large body of studies about predictive
processing and Bayesian inference in biological organisms [22–25,78] and in robotics
[38,95–99].
Here, we provided a brief illustration of Active Inference in continuous time and
discussed specific models that targeted various aspects of motor control; namely, the
execution of goal-directed reaching actions, active sensing, the resolution of multi-
sensory conflicts, and the integration of discrete (decision-related) and continuous
(perception- and action-related) processes. Each of the example models that we have
brieflyreviewedcanbeevaluatedbyitsownmerits,suchasbyitscapabilitytoaccu-
ratelyaccountforempiricaldata. However,takentogether,thesemodels(andothers)
showthatActiveInferencecanaddressalargevarietyofmotorcontrolprocesses. Im-
portantly,allthemotorcontrolphenomenaillustratedbyourexamplesstemfromthe
same process of Free Energy minimization, rather than requiring separate objective
functions. This feature makes Active Inference appealing both as a general theory of
biological systems and as a technical framework to advance AI and robotics research.
Despitetheappealofthemodelsthatwehavereviewed,ActiveInferenceaccounts
of motor control are still relatively young compared to other frameworks, such as
Optimal Control [1,2]. Several open issues need to be clarified to develop Active
Inference accounts of motor control that are more mature from both biological and
roboticperspectives. Belowwebrieflydiscusssomeofthemostimportantopenissues
20
that need to be addressed in future research.
Oneopenissueconcernsthesensorymodalitiesinvolvedinmotorcontrol. Asdis-
cussedinSection2.3,somebiologicalconsiderationssuggestthatmotorcontrolcould
be realized by minimizing proprioceptive, not exteroceptive prediction errors [26].
However, as highlighted in [36], driving action with exteroceptive errors would seem
necessary to correctly reproduce visually-guided reaching behavior in the presence of
visuomotor conflict. From a practical perspective, including exteroceptive modalities
intheFreeEnergyminimizationthroughactionoffersvariousadvantages[45,100]. For
example, the reaching model of [101] uses proprioceptive and visual sensory modali-
ties for perception and action. An advantage of this approach is that the agent can
perform smooth and accurate movements even in the presence of high proprioceptive
noise,giventhatthevisualinputismorestable. Asnotedin[48],theincreasedstabil-
ityderivesnotonlyfromthefactthatthereislessnoiseintheactionupdate,butalso
becauseboththeactionandthehigh-levelbeliefareupdatedwiththesameinforma-
tion,andtheeffectismoreprominentasthevisualprecisionincreases. Furtherstudies
are thus needed to understand the actual role of visual predictions in action execu-
tion or, more clearly, how visually-guided movements can be correctly realized, from
a biologically plausible perspective, in presence of noise or conflicts between different
sensory modalities.
This open issue implies that there might be a tension between standard formu-
lations of Active Inference that focus on biological aspects, and studies that realize
efficient robotic implementations. Besides multisensory integration, an Active Infer-
ence agent may also act by minimizing increasing temporal orders of the prediction
error,asin[102],whereanagentiscontrolledbybothpositionandvelocity,resulting
inincreasedstabilityandadditionalcontrolovertheenvironment,ifanappropriateat-
tractorisembeddedathighordersofthebeliefdynamics. Designdifferencesexistalso
aboutthetemporalorderprimarilyaffectedbytheattractor: whilethisisusuallyem-
bedded into the 1st-order dynamics function, some models encode it in the 2nd-order
toachieveamorestablecontrol,especiallywhentherobotisforce-controlled[37,103].
Finally, different models use different kinds of errors as the attractive force for motor
control. As discussed in Section 2, the belief update depends on three components: a
likelihooderrorfromlowerhierarchicallevels,abackwarderrorcomingfromthenext
temporalorder,andaforwarderrorfromthepreviousorder. Generally,theattractive
role is fulfilledby the backward error, which however requires the computation of the
gradient of the dynamics function [100]. Other studies use instead the forward error
(whichissimplertocompute)asthemainattractiveforce[48]. Finally,analternative
strategy consists of including control costs in the Free Energy expression, to remove
estimation biases and afford optimal action [104]. The pros and cons of the different
approaches and their biological plausibility remain to be systematically investigated.
AnotherdimensionthatisimportanttoconsiderinActiveInferencestudiesisthe
waythegenerativemodelisdesignedorlearned-sincethegenerativemodelimplicitly
defines the agent’s behavior. One crucial design choice regards the extent to which
thegenerativemodelandthegenerativeprocessaresimilarordissimilar. Forthesake
of simplicity, many Active Inference studies use generative models that are almost
identical to the respective generative processes, with few quantitative differences. In
these studies, the generative model is usually aligned to the generative process, in
three ways. First, the internal state variables are modeled as explicit representations
of features of the physical environment or the body, so that the generative model
already incorporates explicit task-related variables such as speed, pressure, position
in the allocentric space, etc. Second, the internal prior dynamics are designed as a
21
copy of the simulated world dynamics, in the sense that the sets of differential equa-
tions implementing the changes of the state variables are the same. Third, motor
commands are built as inverse models of physical world/body features, so that ac-
tions are direct changes in speed, pressure, positions in the allocentric space or other
physical entities. For example, [51] shows an Active Inference model of the behavior
in a force-matching task, where subjects have to match a reference force by pressing
directlyonthemselves. Inthiscase,physicsissimulatedwithtwocoupleddifferential
equations defining the dynamics of the self-generated and the external force. Sensory
(proprioceptive and somatosensory) observations are simple linear mappings of these
hidden variables with the only exception that while proprioception is a linear map-
ping of self-generated forces alone, touch is a raw sum of self-generated and external
force. The prior dynamics of the generative model are then built in strict relation to
the generative process, as a set of differential equations which is quite similar to the
onedescribedabove,withtheonlyexceptionthatacausalvariabletakestheplaceof
the action. Accordingly, all mappings to the sensory predictions also have the same
featuresastheonesgeneratingthedescribedobservationsfromthesimulatedphysics.
A similar example of the similarity between generative model and generative process
is offered by a model of the accommodation of delays in oculomotor control [53]. In
the model, the generative process consists of a set of ordinary differential equations,
which describes the dynamics of the current oculomotor displacement and the target
location; and the mappings generating sensory observations (displacement and target
position)arelinearcombinationsofthehiddenvariables. Asinthepreviousexample,
the generative model is simply a copy of the generative process, except for the fact
that the latter includes a contribution from the action.
Nevertheless, Active Inference does not necessarily require that the two systems
arethesame. Whatis importantisthatthegenerativemodel affordsadaptivemotor
control, by translating the internal dynamics into commands to the motor actuators,
to change the environment in a predictable way. This is in keeping with the “good
regulator theorem”, which states that a good controller needs to either include or be
(embody) a model of a system [105–107]. One possibility is using generative mod-
els that only generate predictions at the level of the proximal (e.g., proprioceptive)
features, which are the closest consequences of motor commands, rather than distal
features. Anexampleisamodeloftheactivecontrolofwhiskingbehavior,inwhichthe
generative model only predicts the (somatosensory and proprioceptive) consequences
ofwhiskermovements. Themodeldoesnotincludeanyinternalvariablethatdirectly
representsthedistancefromexternalobjectsortheiridentity,yetitisabletoestimate
themimplicitly[61]. Theestimationstrategyisbasedontheactivecontrolofwhiskers.
Namely, whisker amplitude is continuously adapted to fit the (expected) distance to
objects and at convergence, it could be used as an implicit inference of animal-object
distance, as shown empirically [57,108]. Designing or learning appropriate generative
models is a key prerequisite to accurately model motor control (or other) tasks. Cur-
rent advances in machine learning permit inferring models from data, but it remains
to be investigated how to better incorporate them into Active Inference models [38].
Finally, another key issue that deserves further investigation is the link between
the biologically motivated aspects of the theory and the computational models used
in practical implementations e.g., deep neural networks. From a biological viewpoint,
hierarchical Active Inference assumes a temporally deep model based on predictive
coding, which uses local message passing of predictions and prediction errors across
brain areas. In principle, an architecture of this kind would allow the formation of
effectiveandincreasinglymoreinvariantrepresentationsofthesensoryinputathigher
22
levelsofthecorticalhierarchy,viaabiologicallymotivatedscheme[109]. However,in
practical implementations, it is common to use (deep) neural networks as generative
models[100]ratherthanhierarchicalpredictivecoding. Whileusingdeepnetworksis
effective, it does not take advantage of the local message passing of predictive coding
suchasinthehierarchicalkinematicmodelof[52]. Furthermore,ratherthanassuming
prediction error minimization at every level of the hierarchy, deep networks often
only pass their final gradient to beliefs encoded at high hierarchical layers. A similar
argument could be made for precision control, which links to learning and attention
inActiveInference. Whiletheprecisionofsignalsateverylevelshouldbeinferredby
minimizing Free Energy, this is rarely done in practice. For example, in the studies
illustratedinChapter3,theprecisionmatricesoflatentstateswerefixed. Inprinciple,
allowingActiveInferencemodelstochangetheprecisionofsignalsateveryhierarchical
levelshouldmakethemmoreadaptiveandeffective,butthispossibilityremainstobe
fully investigated in future studies.
References
[1] E. Todorov and M. I. Jordan, “Optimal feedback control as a theory of motor
coordination,” Nat Neurosci, vol. 5, no. 11, pp. 1226–1235, 2002.
[2] J. Diedrichsen, R. Shadmehr, and R. B. Ivry, “The coordination of movement:
optimalfeedbackcontrolandbeyond,”TrendsCognSci,vol.14,no.1,pp.31–39,
2010.
[3] R.S.SuttonandA.G.Barto,ReinforcementLearning: AnIntroduction. Cam-
bridge MA: MIT Press, 1998.
[4] N.D.Daw,Y.Niv,andP.Dayan,“Uncertainty-basedcompetitionbetweenpre-
frontal and dorsolateral striatal systems for behavioral control,” Nat Neurosci,
vol. 8, no. 12, pp. 1704–1711, 2005.
[5] D.M.WolpertandM.Kawato,“Multiplepairedforwardandinversemodelsfor
motor control,” Neural Netw., vol. 11, no. 7-8, pp. 1317–1329, 1998.
[6] A. G. Greenwald, “Sensory feedback mechanisms in performance control: With
specialreferencetotheideomotormechanism,”Psychol.Rev.,vol.77,pp.73–99,
1970.
[7] J. Hoffmann, “Anticipatory behavioral control,” in Anticipatory Behavior in
Adaptive Learning Systems: Foundations, Theories, and Systems. M.V.Butz,
O. Sigaud, and P. Gerard, Eds. Berlin Heidelberg: Springer-Verlag, 2003, pp.
44–65.
[8] B. Hommel, J. Musseler, G. Aschersleben, and W. Prinz, “The theory of event
coding (tec): a framework for perception and action planning,” Behav. Brain
Sci, vol. 24, no. 5, pp. 849–78, 2001.
[9] H. R. Lotze, Medicinische Psychologie oder Physiologie der Seele. Leipzig:
Weidmannsche Buchhandlung, 1852.
[10] A. Wohlschlaeger, M. Gattis, and H. Bekkering, “Action generation and action
perceptioninimitation: Aninstanceoftheideomotorprinciple,”Philos. Trans.
R. Soc. Lond., vol. 358, pp. 501–515, 2003.
[11] W. Kunde, “Response-effect compatibility in manual choice reaction tasks,” J.
Exp. Psychol. Hum. Percept. Perform., vol. 27, pp. 387–394, 2001.
23
[12] B. Elsner, B. Hommel, C. Mentschel, A. Drzezga, W. Prinz, B. Conrad, and
H. Siebner, “Linking actions and their perceivable consequences in the human
brain,” NeuroImage, vol. 17, no. 1, pp. 364–372, 2002.
[13] B. Hommel, “The cognitive representation of action: Automatic integration of
perceived action effects,” Psychol. Res, vol. 59, pp. 176–186, 1996.
[14] W. Kunde, I. Koch, and J. Hoffmann, “Anticipated action effects affect the
selection, initiation, and execution of actions,” Q. J. Exp. Psychol. A, vol. 57,
no. 1, pp. 87–106, 2004.
[15] T.Melcher,M.Weidema,R.M.Eenshuistra,B.Hommel,andO.Gruber,“The
neural substrate of the ideomotor principle: an event-related fmri analysis,”
NeuroImage, vol. 39, no. 3, pp. 1274–1288, 2008.
[16] M.Paulus,S.Hunnius,M.vanElk,andH.Bekkering,“Howlearningtoshakea
rattle affects 8-month-old infants’ perception of the rattle’s sound: electrophys-
iological evidence for action-effect binding in infancy,” Dev. Cogn. Neurosci.,
vol. 2, no. 1, pp. 90–96, 2012.
[17] N. Wiener, Cybernetics: or Control and Communication in the Animal and the
Machine. Cambridge, MA: The MIT Press, 1948.
[18] G. A. Miller, E. Galanter, and K. H. Pribram, Plans and the Structure of Be-
havior. New York: Holt, Rinehart and Winston, 1960.
[19] W.Mansell,“Controlofperceptionshouldbeoperationalizedasafundamental
property of the nervous system,” Top. Cogn. Sci, vol. 3, no. 2, pp. 257–261,
2011.
[20] W. T. Powers, Behavior: The control of perception. Hawthorne, NY: Aldine,
1973.
[21] A.Clark,SurfingUncertainty: Prediction,Action,andtheEmbodiedMind. Ox-
ford University Press, 2016.
[22] J. Hohwy, The predictive mind. Oxford University Press, 2013.
[23] T.Parr,G.Pezzulo,andK.J.Friston,Activeinference: thefreeenergyprinciple
inmind,brain,andbehavior. Cambridge,Massachusetts: TheMITPress,2022.
[24] G.Pezzulo,Tracing the roots of cognition in predictive processing. OpenMind,
2017.
[25] K. S. Walsh, D. P. McGovern, A. Clark, and R. G. O’Connell, “Evaluating the
neurophysiologicalevidenceforpredictiveprocessingasamodelofperception,”
Ann. N. Y. Acad. Sci, vol. 1464, no. 1, pp. 242–268, 2020.
[26] R.Adams,S.Shipp,andK.J.Friston,Predictions not commands: active infer-
ence in the motor system. Brain Struct. Funct, 2012.
[27] G. Pezzulo, F. Rigoli, and K. J. Friston, “Active inference, homeostatic regu-
lation and adaptive behavioural control,” Prog. Neurobiol., vol. 136, pp. 17–35,
2015.
[28] A. Tschantz, L. Barca, D. Maisto, C. L. Buckley, A. K. Seth, and G. Pezzulo,
“Simulatinghomeostatic,allostaticandgoal-directedformsofinteroceptivecon-
trol using active inference,” Biological Psychology, vol. 169, p. 108266, 2022.
[29] K.J.Friston,“Atheoryofcorticalresponses,”Philos Trans R Soc Lond B Biol
Sci, vol. 360, no. 1456, pp. 815–836, 2005.
24
[30] R.P.N.RaoandD.H.Ballard,“Predictivecodinginthevisualcortex: afunc-
tional interpretation of some extra-classical receptive-field effects,” Nat. Neu-
rosci., vol. 2, no. 1, pp. 79–87, 1999.
[31] A.AnilMeeraandM.Wisse,“Dynamicexpectationmaximizationalgorithmfor
estimation of linear systems with colored noise,” Entropy, vol. 23, no. 10, 2021.
[32] K. Friston, K. Stephan, B. Li, and J. Daunizeau, “Generalised filtering,” Math.
Probl. Eng, vol. 2010, pp. 1–34, 2010.
[33] L. Da Costa, T. Parr, N. Sajid, S. Veselic, V. Neacsu, and K. Friston, “Ac-
tive inference on discrete state-spaces: A synthesis,” Journal of Mathematical
Psychology, vol. 99, 2020.
[34] R. Smith, K. J. Friston, and C. J. Whyte, “A step-by-step tutorial on active
inference and its application to empirical data,” Journal of Mathematical Psy-
chology, vol. 107, p. 102632, 2022.
[35] F. Donnarumma, M. Costantini, E. Ambrosini, K. Friston, and G. Pezzulo,
“Action perception as hypothesis testing,” Cortex, vol. 89, pp. 45–60, 2017.
[36] A.Maselli,P.Lanillos,andG.Pezzulo,“Activeinferenceunifiesintentionaland
conflict-resolution imperatives of motor control,” PLOS Comput. Biol, vol. 18,
no. 6, 2022.
[37] L.Pio-Lopez,A.Nizard,K.Friston,andG.Pezzulo,“Activeinferenceandrobot
control: a case study,” J. R. Soc. Interface, vol. 13, p. 122, 2016.
[38] T. Taniguchi, S. Murata, M. Suzuki, D. Ognibene, P. Lanillos, E. Ugur, L. Ja-
mone, T. Nakamura, A. Ciria, B. Lara, and G. Pezzulo, “World models and
predictive coding for cognitive and developmental robotics: Frontiers and chal-
lenges,” arXiv, vol. 14, 2023.
[39] M. J. Beal, “Variational algorithms for approximate bayesian inference,” Uni-
versity of London, 2015.
[40] K.Friston,“Hierarchicalmodelsinthebrain,”PLoSComput.Biol,vol.4,no.11,
2008.
[41] C. L. Buckley, C. S. Kim, S. McGregor, and A. K. Seth, “The free energy
principleforactionandperception: Amathematicalreview,”J.Math.Psychol.,
vol. 81, pp. 55–79, 2017.
[42] K.Friston,J.Mattout,N.Trujillo-Barreto,J.Ashburner,andW.Penny,“Vari-
ational free energy and the laplace approximation,” NeuroImage, vol. 34, no. 1,
pp. 220–234, 2007.
[43] K.J.Friston,N.Trujillo-Barreto,andJ.Daunizeau,“Dem: Avariationaltreat-
ment of dynamic systems,” NeuroImage, vol. 41, no. 3, pp. 849–885, 2008.
[44] A. Jazwinski, Stochastic processes and filtering theory, ser. Mathematics in sci-
ence and engineering. New York, NY [u.a.]: Acad. Press, 1970, no. 64.
[45] G. Oliver, P. Lanillos, and G. Cheng, “Active inference body perception and
action for humanoid robots,” IEEE Trans. Cogn. Dev. Syst., vol. 14, no. 2, pp.
462–471, 2022.
[46] K. Friston, “What is optimal about motor control?” Neuron, vol. 72, no. 3, pp.
488–498, 2011.
[47] A.K.SethandK.J.Friston,“Activeinteroceptiveinferenceandtheemotional
brain,” Phil Trans R Soc B, vol. 371, no. 1708, 2016.
25
[48] M.PriorelliandI.P.Stoianov,“Flexibleintentions: Anactiveinferencetheory,”
bioRxiv, vol. 8, 2022.
[49] D.P.KingmaandM.Welling,“Auto-encodingvariationalbayes,”ArXivPrepr.,
vol. 13126114, 2013.
[50] M. Priorelli and I. P. Stoianov, “Intention modulation for multi-step tasks in
continuous time active inference,” presented at the 3rd International Workshop
on Active Inference, 2022.
[51] H. Brown, R. A. Adams, I. Parees, M. Edwards, and K. Friston, “Active in-
ference, sensory attenuation and illusions,” Cogn. Process, vol. 14, no. 4, pp.
411–427, 2013.
[52] M. Priorelli, G. Pezzulo, and I. P. Stoianov, “Deep kinematic inference affords
efficient and scalable control of bodily movements,” bioRxiv, pp. 1–33, 2023.
[53] L. Perrinet, R. A. Adams, and K. J. Friston, “Active inference, eye movements
andoculomotordelays,”Biol.Cybern.Model,vol.106,no.8,pp.777–801,2014.
[54] T. Parr and K. J. Friston, “The computational pharmacology of oculomotion,”
Psychopharmacology (Berl.), vol. 236, no. 8, pp. 2473–2484, 2019.
[55] T. Parr and K. Friston, “Active inference and the anatomy of oculomotion,”
Neuropsychologia, vol. 111, no. January, pp. 334–343, 2018.
[56] M. Priorelli, G. Pezzulo, and I. Stoianov, “Active vision in binocular depth
estimation: a top-down perspective,” bioRxiv, 2023.
[57] E.AhissarandE.Assa,“Perceptionasaclosed-loopconvergenceprocess,”eLife,
vol. 5, 2016.
[58] B.Morillon,T.A.Hackett,Y.Kajikawa,andC.E.Schroeder,“Predictivemotor
controlofsensorydynamicsinauditoryactivesensing,”Curr.Opin.Neurobiol.,
vol. 31, pp. 230–238, 2015.
[59] N.O.ZweifelandM.J.Z.Hartmann,“Defining‘activesensing’throughananal-
ysisofsensingenergetics: homeoactiveandalloactivesensing,”J.Neurophysiol.,
vol. 124, no. 1, pp. 40–48, 2020.
[60] K. Friston, R. A. Adams, L. Perrinet, and M. Breakspear, “Perceptions as hy-
potheses: saccades as experiments,” Front. Psychol., vol. 3, p. 151, 2012.
[61] F.Mannella,F.Maggiore,M.Baltieri,andG.Pezzulo,“Activeinferencethrough
whiskers,” Neural Networks, vol. 144, pp. 428–437, 2021.
[62] E. Ambrosini, M. Costantini, and C. Sinigaglia, “Grasping with the eyes,” J.
Neurophysiol., vol. 106, no. 3, pp. 1437–1442, 2011.
[63] M. Botvinick and J. Cohen, “Rubber hands ‘feel’ touch that eyes see,” Nature,
vol. 391, no. 6669, p. 756, 1998.
[64] H.H.Ehrsson,C.Spence,andR.E.Passingham,“That’smyhand! activityin
premotor cortex reflects feeling of ownership of a limb,” Science, vol. 305, no.
5685, pp. 875–877, 2004.
[65] A. Maselli and M. Slater, “The building blocks of the full body ownership illu-
sion,” Front. Hum. Neurosci., vol. 7, p. 83, 2013.
[66] V. Petkova and H. Ehrsson, If I were you: perceptual illusion of body swapping.
PloS One, 2008.
26
[67] M. Chancel, H. H. Ehrsson, and W. J. Ma, “Uncertainty-based inference of a
common cause for body ownership,” eLife, vol. 11, p. e77221, 2022.
[68] K.Kilteni,A.Maselli,K.P.Kording,andM.Slater,“Overmyfakebody: body
ownershipillusionsforstudyingthemultisensorybasisofown-bodyperception,”
Front. Hum. Neurosci., vol. 9, 2015.
[69] M.Samad,A.J.Chung,andL.Shams,“Perceptionofbodyownershipisdriven
by bayesian sensory inference,” Plos One, vol. 10, no. 2, 2015.
[70] D. M. Lloyd, “Spatial limits on referred touch to an alien limb may reflect
boundariesofvisuo-tactileperipersonalspacesurroundingthehand,”Brainand
cognition, vol. 64, no. 1, pp. 104–109, 2007.
[71] A. Maselli, K. Kilteni, J. Lo´pez-Moliner, and M. Slater, “The sense of body
ownership relaxes temporal constraints for multisensory integration,” Scientific
reports, vol. 6, no. 1, p. 30628, 2016.
[72] P. Lanillos, S. Franklin, A. Maselli, and D. W. Franklin, “Active strategies for
multisensoryconflictsuppressioninthevirtualhandillusion,”Sci. Rep,vol.11,
no. 1, pp. 1–14, 2021.
[73] T. Asai, “Illusory body-ownership entails automatic compensative movement:
for the unified representation between body and action,” Exp. Brain Res, vol.
233, no. 3, pp. 777–785, 2015.
[74] M. Gonzalez-Franco, B. Cohn, D. Burin, and A. Maselli, “The self-avatar fol-
lower effect in virtual reality,” IEEE Conf. Virtual Real. 3D User Interfaces,
p. 8, 2020.
[75] J.LimanowskiandK.Friston,“Activeinferenceundervisuo-proprioceptivecon-
flict: Simulationandempiricalresults,”Scientificreports,vol.10,no.1,p.4010,
2020.
[76] J. P. Gallivan, C. S. Chapman, D. M. Wolpert, and J. R. Flanagan, “Decision-
making in sensorimotor control,” Nat. Rev. Neurosci., vol. 19, no. 9, 2018.
[77] N. F. Lepora and G. Pezzulo, “Embodied choice: how action influences percep-
tual decision making,” PLoS Comput Biol, vol. 11, no. 4, 2015.
[78] G.PezzuloandP.Cisek,“Navigatingtheaffordancelandscape: Feedbackcontrol
asaprocessmodelofbehaviorandcognition,”Trends Cogn. Sci,vol.20,no.6,
pp. 414–424, 2016.
[79] K.J.Friston,T.Parr,andB.deVries,“Thegraphicalbrain: Beliefpropagation
and active inference,” Netw. Neurosci., vol. 1, no. 4, pp. 381–414, 2017.
[80] K. Friston and W. Penny, “Post hoc bayesian model selection,” Neuroimage,
vol. 56, no. 4, pp. 2089–2099, 2011.
[81] T. Parr and K. J. Friston, “The discrete and continuous brain: From decisions
to movement - and back again,” Neural Comput., vol. 30, no. 9, pp. 2319–2347,
2018.
[82] S. Funahashi, C. J. Bruce, and P. S. Goldman-Rakic, “Mnemonic coding of
visual space in the monkey’s dorsolateral prefrontal cortex,” J. Neurophysiol.,
vol. 61, no. 2, pp. 331–349, 1989.
[83] K. J. Friston, N. Sajid, D. R. Quiroga-Martinez, T. Parr, C. J. Price, and
E. Holmes, “Active listening,” Hear. Res., vol. 399, p. 107998, 2021.
27
[84] T.Parr,J.Limanowski,V.Rawji,andK.Friston,“Thecomputationalneurology
ofmovementunderactiveinference,”Brain,vol.144,no.6,pp.1799–1818,2021.
[85] M.PriorelliandI.P.Stoianov,“Slowbutflexibleorfastbutrigid? discreteand
continuous processes compared,” bioRxiv, 2023.
[86] M. Priorelli and I. Stoianov, “Dynamic inference by model reduction,” bioRxiv,
2023.
[87] L.F.BarrettandW.K.Simmons,“Interoceptivepredictionsinthebrain,”Nat.
Rev. Neurosci., vol. 16, no. 7, pp. 419–429, 2015.
[88] L. Barca and G. Pezzulo, “Interoceptive inference in anorexia nervosa,” 2018,
open Science Framework, Preprint.
[89] K. J. Friston, K. E. Stephan, R. Montague, and R. J. Dolan, “Computational
psychiatry: the brain as a phantastic organ,” Lancet Psychiatry, vol. 1, no. 2,
pp. 148–158, 2014.
[90] S. S. Khalsa, R. Adolphs, O. G. Cameron, H. D. Critchley, P. W. Davenport,
J.S.Feinstein,J.D.Feusner,S.N.Garfinkel,R.D.Lane,W.E.Mehling,A.E.
Meuret, C. B. Nemeroff, S. Oppenheimer, F. H. Petzschner, O. Pollatos, J. L.
Rhudy, L. P. Schramm, W. K. Simmons, M. B. Stein, K. E. Stephan, O. V.
den Bergh, I. V. Diest, A. von Leupoldt, and M. P. Paulus, “Interoception and
mental health: A roadmap,” Biol. Psychiatry Cogn. Neurosci. Neuroimaging,
vol. 3, no. 6, pp. 501–513, 2018.
[91] D. Maisto, L. Barca, O. V. den Bergh, and G. Pezzulo, Perception and misper-
ception of bodily symptoms from an Active Inference perspective: Modelling the
case of panic disorder. Psychological Review, 2021.
[92] M. P. Paulus, J. S. Feinstein, and S. S. Khalsa, “An active inference approach
tointeroceptivepsychopathology,”Annu.Rev.Clin.Psychol.,vol.15,no.1,pp.
97–122, 2019.
[93] G. Pezzulo, D. Maisto, L. Barca, and O. V. den Bergh, “Symptom perception
from a predictive processing perspective,” Clinical Psychology in Europe, 2019.
[94] O. V. den Bergh, M. Witth”oft, S. Petersen, and R. J. Brown, “Symptoms and
the body: Taking the inferential leap,” Neurosci. Biobehav. Rev., vol. 74, pp.
185–203, 2017.
[95] O. C¸atal, T. Verbelen, T. V. de Maele, B. Dhoedt, and A. Safron, “Robot
navigationashierarchicalactiveinference,”NeuralNetw.,vol.142,pp.192–204,
2021.
[96] A. Ciria, G. Schillaci, G. Pezzulo, V. V. Hafner, and B. Lara, “Predictive pro-
cessing in cognitive robotics: A review,” Neural Comput., vol. 33, no. 5, pp.
1402–1432, 2021.
[97] P. Lanillos, C. Meo, C. Pezzato, A. A. Meera, M. Baioumy, W. Ohata,
A. Tschantz, B. Millidge, M. Wisse, C. L. Buckley, and J. Tani, “Active in-
ference in robotics and artificial agents: Survey and challenges,” arXiv, vol. 03,
2021.
[98] T. Matsumoto and J. Tani, “Goal-directed planning for habituated agents by
active inference using a variational recurrent neural network,” Entropy, vol. 22,
no. 5, 2020.
28
[99] P.Mazzaglia,T.Verbelen,O.C¸atal,andB.Dhoedt,“Thefreeenergyprinciple
forperceptionandaction: Adeeplearningperspective,”Entropy,vol.24,no.2,
2022.
[100] C. Sancaktar, M. van Gerven, and P. Lanillos, “End-to-end pixel-based deep
activeinferenceforbodyperceptionandaction,”Jt. IEEE 10th Int. Conf. Dev.
Learn. Epigenetic Robot. ICDL-EpiRob, vol. 2020, pp. 1–8, 2020.
[101] K. Friston, J. Daunizeau, J. Kilner, and S. J. Kiebel, “Action and behavior: a
free-energy formulation,” Biol Cybern, vol. 102, no. 3, pp. 227–260, 2010.
[102] M. Baioumy, P. Duckworth, B. Lacerda, and N. Hawes, “Active inference for
integrated state-estimation, control, and learning,” in 2021 IEEE International
Conference on Robotics and Automation (ICRA), 2021, pp. 4665–4671.
[103] K. Friston, J. Daunizeau, and S. J. Kiebel, “Reinforcement learning or active
inference?” PLoS One, vol. 4, no. 7, 2009.
[104] M. Baioumy, C. Pezzato, R. Ferrari, and N. Hawes, “Unbiased active inference
forclassicalcontrol,”in2022IEEE/RSJInternationalConferenceonIntelligent
Robots and Systems (IROS). IEEE, 2022, pp. 12787–12794.
[105] R. C. Conant and W. R. Ashby, “Every good regulator of a system must be a
model of that system,” Intl J Syst. Sci, pp. 89–97, 1970.
[106] G. Pezzulo, F. Donnarumma, P. Iodice, D. Maisto, and I. Stoianov, “Model-
based approaches to active perception and control,” Entropy, vol. 19, no. 6, p.
266, 2017.
[107] A.K.Seth,The Cybernetic Bayesian Brain. OpenMIND.FrankfurtamMain:
MIND Group, 2014.
[108] J. Voigts, D. H. Herman, and T. Celikel, “Tactile object localization by antici-
patory whisker motion,” J. Neurophysiol., vol. 113, no. 2, pp. 620–632, 2015.
[109] A. Ororbia and D. Kifer, “The neural coding framework for learning generative
models,” Nat. Commun., vol. 13, no. 1, 2022.
Acknoledgments
This research received funding from the European Research Council under the Grant
Agreement No. 820213 to GP, the European Union’s Horizon 2020 Framework Pro-
gramme for Research and Innovation under the Specific Grant Agreements 945539 to
GPand951910toI.S.,andtheItalianMinistryforResearchunderGrantAgreements
2017KZNZLNtoIS,2020529PCPtoFDandPE0000013-FAIRandIR0000011–EBRAINS-
Italy to GP.
29
Supplementary
Figure S1: Illustration of the performance of the Active Inference model of [48] during a
target tracking task. The left and right panels show the performance of the model during
the reaching movement and target estimation. Each line corresponds to a trial. L2 distance
between the real hand and target over time (left), and error between the real and estimated
targetpositionsovertime(right). Bothdecreaseinmosttrials,asthearmsuccessfullyreaches
thetarget(thedottedlineindicatestheminimumdistancefromthetargettoconsideratrial
successful).
FigureS2: Controllingasimplifiedhumanoidbodycomposedof23-DoF.Thegoalisreaching
3differenttargetlocations,withtheleftkneeandthetwoarms.
30
Figure S3: Controllingasimplifiedhumanoidbodycomposedof23-DoF.Thetaskconsists
ofavoidingadynamicobstaclewiththewholebody.
Figure S4: Sequence of time frames of a depth estimation task with simultaneous target
fixation. Theagentusesalternatingaction-perceptionphasestoavoidbeingstuckduringthe
minimization process. The eyes are represented in blue, and the real and estimated target
position in red and orange. The fixation trajectory (when vergence occurs) is represented
in cyan. Each frame is composed of three images: a view of the overall task (top), and the
projectionofthetargettothetwocameraplanesoftheeyes(bottomleftandbottomright).
31

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Modeling motor control in continuous-time Active Inference: a survey"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
