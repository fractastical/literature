=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Stochastic Surprisal: An inferential measurement of Free Energy in Neural Networks
Citation Key: prabhushankar2023stochastic
Authors: Mohit Prabhushankar, Ghassan AlRegib

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2023

Abstract: This paper conjectures and validates a framework that allows for action during inference in
supervised neural networks. Supervised neural networks are constructed with the objective to
maximize their performance metric in any given task. This is done by reducing free energy and
its associated surprisal during training. However, the bottom-up inference nature of supervised
networks is a passive process that renders them fallible to noise. In this paper, we provide a
thorough background of supervi...

Key Terms: inferential, energy, prabhushankar, neural, surprisal, mohit, supervised, alregib, networks, measurement

=== FULL PAPER TEXT ===

3202
beF
11
]GL.sc[
1v67750.2032:viXra
Citation M. Prabhushankar and G. AlRegib, ”Stochastic Surprisal: An inferential measurement of
Free Energy in Neural Networks,” Frontiers in Neuroscience - Perception Science, 17,
2023.
Review DataofInitialSubmission: 22April 2022
DateofFirst Revision:13 Dec2022
DateofSecond Revision: 08Feb 2023
DateofAcceptance: 09Feb 2023
Codes https://github.com/olivesgatech/Stochastic-Surprisal
Copyright ©2023 Prabhushankar and AlRegib. This is an open-access article distributed under the
terms of the Creative Commons Attribution License (CC BY). The use, distribution or
reproduction in other forums is permitted, provided the original author(s) or licensor
are credited and that the original publication in this journal is cited, in accordance with
accepted academic practice. No use, distribution or reproduction is permitted which does
not complywiththeseterms.
Contact mohit.p@gatech.eduORalregib@gatech.edu
https://ghassanalregib.info/
Stochastic Surprisal: An inferential
measurement of Free Energy in Neural
Networks
∗
Mohit Prabhushankar , Ghassan AlRegib
Omni Lab for Intelligent Visual Engineering and Science (OLIVES), Georgia
Institute of Technology, Electrical and Computer Engineering, Atlanta, GA, USA
Correspondence*:
Mohit Prabhushankar
mohit.p@gatech.edu
ABSTRACT
This paper conjectures and validates a framework that allows for action during inference in
supervised neural networks. Supervised neural networks are constructed with the objective to
maximize their performance metric in any given task. This is done by reducing free energy and
its associated surprisal during training. However, the bottom-up inference nature of supervised
networks is a passive process that renders them fallible to noise. In this paper, we provide a
thorough background of supervised neural networks, both generative and discriminative, and
discuss their functionality from the perspective of free energy principle. We then provide a
framework for introducing action during inference. We introduce a new measurement called
stochastic surprisal that is a function of the network, the input, and any possible action. This
action can be any one of the outputs that the neural network has learnt, thereby lending
stochasticity to the measurement. Stochastic surprisal is validated on two applications: Image
Quality Assessment and Recognition under noisy conditions. We show that, while noise
characteristics are ignored to make robust recognition, they are analyzed to estimate image
quality scores. We apply stochastic surprisal on two applications, three datasets, and as a plug-
in on twelve networks. In all, it provides a statistically significant increase among all measures.
We conclude by discussing the implications of the proposed stochastic surprisal in other areas
of cognitive psychology including expectancy-mismatch and abductive reasoning.
Keywords:FreeEnergyPrinciple, NeuralNetworks, Stochastic Surprisal, ImageQuality Assessment, RobustRecognition, Human
VisualSaliency,AbductiveReasoning,ActiveInference
1 INTRODUCTION
The human visual system is the resultant of an evolutionary process influenced and constrained by
the natural visual stimuli present in the outside environment (Geisler, 2008; Sebastian et al., 2017).
The free energy principle is an over-arching theory that provides a mathematical framework for this
evolutionary process (Friston, 2009). The principle provides a theory of cognition that can unify and
discuss relationships among fundamental psychological concepts such as memory, attention, value,
reinforcement, and salience (Friston, 2009). It decomposes the visual system into perception and action
modalities and argues that the visual system is an inference engine whose objective is to perceive the
1
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
outsideenvironmentasbestasitcan.Ifthisperceptionisinsufficientformakinganinference,anactionis
takentoachievetheobjectivebyinfluencingtheoutsideenvironment.Whiletheactionisdependentonthe
typeofinference that is to bemade, perception is dependent on thenatural visual stimuli.Hence, a study
of the human visual system warrants a study of the patterns that it is sensitiveto. Broadly, these patterns
are classified under natural scene statistics (Geisler, 2008). Color, luminance, spatio-temporal structures
and spectral residues are some statistics that are useful in performing fundamental visual tasks including
image quality assessment (Zhang and Li, 2012), visual saliency detection (Hou and Zhang, 2007), and
objectdetectionand recognition(Sebastian etal., 2017).
Image quality assessment is the objective assessment of subjective quality of images. Visual saliency
detection finds those regions in an image that attract significant human attention. Object recognition
attempts to recognize any given object in an image. Methods like (Hou and Zhang, 2007; Murray et al.,
2013) use spectral residue to detect salient regions. Hou and Zhang (2007) extend their spectral residue-
basedsaliencydetectionalgorithmtoshowthatobjectdetectionispossible.Thespectralresidualconcept
is used in SR-SIM (Zhangand Li, 2012) and BleSS (Temel andAlRegib, 2016a) to utilize the frequency
characteristicstoquantifyresidualsforIQA.Allthreedisparateapplicationssharecommonalitiesintheir
spectral residual statisticsthat are used to showcomparable performance within each application. Hence,
natural scene statistics and their governing visual system principles are buildingblocks of computational
machinevisionsystemsthatattemptto mimichumanperception.
One such a principleis theconsistencyin spatial structures that allowsfor a sparse set of convolutional
kernels to represent natural scenes. Large-scale neural networks are built on this principle. Neural
networks are empowered to mimic human vision by performing the same tasks as the human visual
system including image quality assessment (Temel etal., 2016), visual saliency detection (Sun et al.,
2020), and object recognition (Krizhevskyet al., 2012) among others. Recently the generalization
capabilities of neural networks has led to their widespread adoption in a number of computational
fields. Neural networks have produced state-of-the-art results on multifarious data ranging from
natural images (Krizhevskyet al., 2012), computed seismic (Shafiq et al., 2018b,a), and biomedical
images (Prabhushankaret al., 2022; Prabhushankarand AlRegib, 2021b). In object recognition on
Imagenetdataset(Deng et al.,2009),Heet al.(2016)surpassedthetop-5humanaccuracyof94.9%.Inthe
applicationofimagequalityassessment,Bosseet al.(2017)extractedpatch-wisedistortioncharacteristics
from images using deep neural networks before fusing them to obtain an objective quality score. The
authors in Liuet al. (2017) device a sparse representation-based entropic measure of quality that is
inspired by the free energy principle. This is extended in Liuet al. (2019) where the authors use the
free energy principle as a plug-in on top of existing blind image quality assessment techniques. In both
these works, free energy principle is seen as a technique that measures the disparity between an outside
environmentand thetheexpectationofthatenvironmentthroughsomebiologicallyplausiblemechanism.
Other existing works, including (Zhaiet al., 2011; Gu etal., 2014), quantify this disparity to estimate
quality.
Hence, from the perspective of free energy principle, neural networks act as biologically plausible
mechanisms to perceive the outside environment. This is done by supervising the networks to learn
particulartasks.Prabhushankarand AlRegib(2021a)describesupervisedlearningasassociativelearning
where a set of learned features is associated with any given class. This class can be an objective score
in image quality assessment or an object class from recognition. The learned features are associated
with a specific dataset and application, and are not easily transferable (Temelet al., 2018). A number
of recent works including (Temelet al., 2017; Goodfellowet al., 2014; Hendrycksand Dietterich, 2019)
Frontiers 2
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
describethefallibilityofneuralnetworkstoadversarialnoiseandslightperturbationsindataarisingfrom
acquisitionorenvironmentalerrors. Thefeaturerepresentationspacecanbealteredsignificantlybynoise
thatissometimesnon-noticeableindata.Thisisincontrastwiththespectralresidualfeaturewhichisused
to infer both object (Hou and Zhang, 2007) and image quality (Zhangand Li, 2012; Temel andAlRegib,
2016a).
We posit that these shortcomings of supervised neural networks are a resultant of neural networks
exclusively utilizing the perception modality of free energy principle. In other words, the passivity
of neural networks during inference leads to their non-robust nature. This view is corroborated
by Demekaset al. (2020) who identify three challenges in supervised learning. Firstly, they claim
that neural networks lack an explicit control mechanism of incorporating prior beliefs into predictions.
Secondly,neuralnetworkstrainviaascalarlossfunctionthatdoesnotallowforincorporatinguncertainty
inaction.Lastly,neural networksdonotperform anyaction duringinferencethat wouldelicitchangesin
theinputfrom theoutsideenvironment.
In this paper, we tackle the above challenges by introducing a framework for action during inference.
ThisisopposedtothefreeenergyprinciplebasedworksinLiu et al.(2017,2019)wherethemethodology
does not require actions at inference. Based on the free energy principle, we treat any trained neural
network as an inference engine. We define a quantity called stochastic surprisal that is a function of a
neural network’s inference and some action performed on this inference. Reducing surprisal is generally
seen as a singleaction that reduces thedistributionaldifference between two quantities.However, during
inference, we have access to only a single data point. We overcome this challenge by considering that
all possible actions that the network can undertake are equally likely. The term stochastic is derived
based on this assumption of action-randomness. Stochastic surprisal acts on top of any existing neural
networksto address thechallengeof passiveinference. Existingneural networkscan eitherbe generative
ordiscriminative.Weevaluatestochasticsurprisalontwoapplicationsincludingimagequalityassessment
androbustobjectrecognition.Inimagequalityassessment,weevaluateourtechniquetoassessthequality
ofdistorted images at different levelsof distortions.Similarly, in robust object recognition, we recognize
distorted images when the original neural network is only trained on pristine images. In other words, we
propose a concept that is able to assess the noise characteristics in images to assign objective quality, as
well as ignore the same noise characteristics to robustly classify images. The contributions of this paper
include,
1.We unify the concepts of image quality assessment and robust object recognition. We show that the
features that are extracted from neural networks simultaneously characterize the scene and context
withintheimageforrecognitionas well as thenoiseperturbingit’squality.
2.We term our features as stochasticsurprisal and relate them to the free energy principle. We provide a
mathematical framework to extract stochastic surprisal from both discriminative and generative neural
networks as afunctionofsomeaction.
3.Wediscusstheimplicationsofourproposedmethodfromanabductivereasoningaswellasexpectancy-
mismatchperspective.Boththeseconceptsleadtoseparateapplicationsincludingcontextandrelevance
based contrastivevisualexplanationsand humanvisualsaliencydetection.
We first describe the free energy principle in Section 2.1.1. The free energy principle is then
related to neural networks in Section 2.1.2 before describing stochastic surprisal. The generation of
stochasticsurprisal ingenerativeand discriminativenetworksis described in Sections 2.1.2.1 and 2.1.2.2
respectively. Finally, the applications of image quality assessment and robust recognition and our
Frontiers 3
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
methodology is discussed in Section 2.3. The results are provided in Section 3. We further discuss the
implicationsoftheproposedstochasticsurprisalonothercognitiveconceptsand concludein Section 4.
2 THEORETICAL OVERVIEW AND METHODOLOGY
Inthissection,weprovideathoroughbackgroundofthefreeenergyprincipleanditsapplicationinneural
networks,bothgenerativeanddiscriminative.Wethendefineanddetailtheframeworkfortheextractionof
stochasticsurprisal.Thisisfollowedbytheapplicationofstochasticsurprisalinimagequalityassessment
androbustrecognition.
2.1 Background
2.1.1 Free Energy Principle
The Free Energy Principle (FEP) proposes a theory to explain the self-organizing capability of any
intelligent and adaptive system (Friston, 2009). FEP assumes the demarcation of a system that exists
in an environment through a functional Markov Blanket. The Markov Blanket (Hipo´litoet al., 2021)
provides statistical independence to the system from its environment, thereby imbuing the system with
a sense of self. A consequence of this separation is that the system only experiences the environment
through the Markov Blanket based on a limited set of sensory inputs. These sensory inputs are used to
create a generative model of the outside environment within the system. The system then performs a
limited set of actions affecting the outside environment while updating its internal model of the outside
environment. The FEP provides a mathematically concrete set of principles to bound the long-term
entropy of the internal generative model that is confined in the set of all possible sensory inputs and
its possible performative actions. Friston (2019) argues that the assumption of the Markov Blanket and
theensuingFEPisanoverarchingtheorythatprovidesatooltostudyandexplainself-organizationatany
spatio-temporalscalefrom infinitesimalquantummechanics togenerationalbiologicalevolution.
In this paper, we are interested in the FEP’s application to visual processes related to the human brain.
The applicability of FEP across concepts such as memory, attention, value, and reinforcement (Friston,
2009) is possible because of the central assumption that the limited sensory inputs from the outside
environment to the brain are also likely sensory inputs. In other words, the human brain only allows for
a limited set of likely encounters (Demekaset al., 2020). The term likely is a function of the expectation
setby theinternalgenerativemodelwithinthebrain.Hence, thebrainis consideredto encodeabayesian
recognitiondensity that predicts thesensory inputs based on somehypothesisregardingtheir cause. This
leads to the proposition that the brain is an inverse generative model where it expects to sense only a
limited set of likely inputs from the environment. Any mismatch to this expectation is handled in two
stages.Firstly,theinternalmodelisupdatedwiththemismatchedsensoryinputtoimprovetheperception.
Secondly, an action is performed to change the environment. This way, the environment and the model
are made to fit each other by reducing the mismatched input. A mismatched input is typically termed as
asurprisingevent(Buckleyet al.,2017). Self-organizationinthebraincreates animperativetominimize
thesurprisalofanyeventandtheFEPprovidesamathematicaltheoryofthisminimizationbyprovidinga
tractableupperboundtothesurprisal.Mathematically,average surprisalistheentropy ofthedistribution
of all events. More unlikely an event, more surprisal it creates in the internal model. The free energy
decomposedusingsurprisal(Demekas et al., 2020)isgivenby,
Free Energy = Divergence+Surprisal. (1)
Frontiers 4
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
Figure 1. Block diagram for perception (in blue) and proposed action (in red) for a sparse autoencoder.
The image x is taken from the CURE-TSR dataset (Temelet al., 2017). The training loss function is
J(θ,φ). The latent representation z = f (·) is z . The reconstructed image is shown as xˆ. This forms the
θ g
perception pipeline. The action pipeline is shown in red where the action A is backpropagated through
g
thedecodertothelatentrepresentationspace.Thelearnedblueperceptionrepresentationspacez changes
g
totheactionspaceza as aconsequenceofA .Thischangeis stochasticsurprisal,givenby ∂A g(x,xˆ) .
g g ∂φ
Here, divergence is the difference between the variables representing the outside environment that
generate the sensory inputs and the variables in the internal generative model that mimic the outside
world.
2.1.2 Free Energy Principle in Neural Networks
The assumption of the existence of an internal tractable generative model that is an inference engine
has been adopted in the construction of early neural networks. Hintonand Zemel (1993) describe the
Helmholtz free energy that is used to construct autoencoders as agents that minimize the reconstruction
cost and the code cost. The code cost is a function of the entropy of the probability distribution
given a vector. In FEP, this code cost is the surprisal. Variational Autoencoders (KingmaandWelling,
2019) minimize Variational Free Energy (VFE) and consequently surprisal. VFE is a generalization
of the Helmholtz free energy where the divergence of the approximate and true probabilities are
minimized (Gottwaldand Braun, 2020). While the generative models of autoencoders lend themselves
directlytotheFEP,thediscriminativemodelsalsotrainthemselvesusingsomevariationofalossfunction
that resembles free energy. In this paper, we use both generative and discriminative models and we
introducetheminterms ofthefree energy principle.
2.1.2.1 Generative Networks
In this section, we consider a general autoencoder as our generative model. An autoencoder is an
unsupervised learning network which learns a regularized representation of inputs to reconstruct them
as its output (Hintonand Zemel, 1993; Kwonet al., 2019). Since Hintonand Zemel (1993), a number
of variations have been proposed to autoencoders to construct either application-specific or property-
specific networks. These variations generally deal with constraining the latent representations learned
by an autoencoder. For instance, Ng (2011) constrain the latent representation to be sparse, thereby
constructing sparse autoencoders. Kingmaand Welling (2013) constrain the latent representation to
follow a Gaussian distribution. These are termed as variational autoencoders. These are two instances
Frontiers 5
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
of property-specific autoencoders. Application-specific autoencoders include fully-connected networks
used for image compression (Gedeonand Harris, 1992), and convolutional autoencoders for image
denoising(Mao et al., 2016).
All these autoencoders consist of the same base architecture as shown in Fig. 1. They consist of
an encoder f (·), parameterized by θ to map inputs x to a latent representation z . These latent
θ g
representations z are used to reconstruct the same input xˆ using a decoder g (·). This operation is
g φ
mathematicallyrepresented as,
z = f (x) xˆ = g (z) = g (f (x)), (2)
θ φ φ θ
For a natural image input, x ∈
RH×W×C,
where H,W,C are height, width, channel of input image,
respectively. The encoder and decoder are trained jointly by minimizing a loss function J(θ,φ) defined
as:
J(θ,φ) = L(x,g (f (x)))+Ω(z ;θ,φ), (3)
φ θ g
where L is a reconstruction error which measures the dissimilarity between the input x, and the
reconstructedimagexˆ.Ωisaregularizationtermaddedtoavoidoverfittingthenetworktothetrainingset
and to imbue the required constraints. For a sparse autoencoder, Ω is an l sparsity constraint. However,
1
since the l constraint is not differentiable, a practical solution for constructing this sparsity constraint is
1
touseKL-Divergenceonz . Specifically,thesumofz isconstrainedtoeitherzerooraverysmallvalue
g g
usinga distancemetriclikeKL-Divergence.ThisisshowninFig. 1 inblue.
Duringtraining,thenetworkparameters,θandφareupdatedbybackpropagatingthegradientsofJ(θ,φ)
w.r.t.theparameters. Theupdateruleis givenby,
∂J(θ,φ) ∂J(θ,φ)
′ ′
θ = θ− , φ = φ− , (4)
∂θ ∂φ
Thetwogradientsprovidethechangeinthenetworkparametersrequired toincorporatebetterperception
capabilitiesas measured bythelossfunctionJ(θ,φ).
Consider Eq. 3 and compare this against the free energy decomposition in Eq. 1. The L reconstruction
error measures the divergence. The regularization is the surprisal. Technically, regularization prevents
the network from reconstructing x exactly. Hence, surprisal is added in generative networks to make
them generalizable. A thorough analysis of regularization for reconstruction and feature transfer of
autoencoders to multiple tasks is provided in Prabhushankaret al. (2018). While regularization impacts
the reconstruction negatively, it enhances the adaptability and usability of features for generalized tasks
andtest sets.
2.1.2.2 Discriminative Networks
Discriminative networks are neural networks whose function is to assign labels to input data. While
the required training data in generative networks are images x ∈
RH×W×C,
the training data for
discriminative networks are (x,y), where x ∈
RH×W×C
and y ∈ [1,N]. Here, y is an integer label
assigned to x, ranging between 1 and the total number of classes N. The goal of a discriminative
network is to assign the label y, given x at inference. The simplest discriminative network is an image
classificationnetwork.ConsideranL-layerednetworkf(·)trainedtoclassifyimagesonadomainX.For
the task of classification, where f(·) is trained to classify between N classes, the last layer is commonly
a fully connected layer consisting of N weights or filters. During inference, the representation space
Frontiers 6
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
z d = f L−1 (x) after the first (L − 1) layers are projected independently onto each of the N filters. The
filter with the maximum projection is inferred as the class yˆto which x belongs. Mathematically, z and
d
yˆare related as,
z d = f L−1 (x), (5)
y˜= argmax(WTz +b ), yˆ= argmax(y˜) (6)
L d L
∀W ∈ ℜ d L−1 ×N,z ∈ ℜ d L−1 ×1,b ∈ ℜ N×1,y˜∈ ℜ N×1,yˆ∈ [1,N], (7)
L L
whereW and b aretheparameters ofthefinal fullyconnected layer. Noteourchoiceofthevariablez .
L L d
This is a similar variable that is used to denote the latent representation in Eq. 2. Similar to the decoder
g (·)actingonz ingenerativenetworks,wehavethefinalfullyconnectedlayerW andb actingonz .
φ g L L d
Thisformstheperceptionpipelinethatclassifies xas yˆ. ThisisshowninblueinFig. 2.
Training an image classification technique requires a loss function J(yˆ,y;θ), where θ are the network
parameters and (x,y) are the image-label pairs required for training. A common choice of J(·) is the
cross-entropy loss. Considering σ(y˜) to be the softmax probability distribution of the output vector from
f(·),thecross-entropy lossintermsofKL-Divergenceand entropycan beexpressedas,
N
J(·) = KL(y||σ(y˜))− (σ(y˜))ln(σ(y˜)). (8)
i i
i=1
X
Here, KL(||) refers to the KL-divergence between the probability output of the network and the label
vector y expressed as a one-hot probability distribution. Notice the similarity between Eqs. 1 and 8. The
divergence in the FEP is the KL divergence and the surprisal is the entropy given by the second term in
Eq. 8. Unlike the generative networks, surprisal is not introduced into the network. Rather, the existing
surprisal is minimized. A number of foundational works in FEP (Friston, 2009, 2019) use the entropy of
a distribution to describe free energy. The network is then trained by backpropagating the errors w.r.t θ
similarto Eq.4.
2.1.2.3 Terminologies
Before describing our contributions, we summarize a few key terminologies that are extensively used
withintheFEP setupand howtheyrelatetoneural networks.
External state of the world X is the observed distribution of the outside world and each x ∈ X is an
instanceofthisdistribution.When describingdiscriminativesystems,dataisdenotedas(x,y)wherexis
thedatapointand y isitslabel.Whendealingwithgenerativemodels,dataisxonly.Whenthereissome
′ ′
distortion associated with the outside environment, the sampled data is x and the distribution is X . We
′ ′
willseeX andx inIQA and recognitionexperimentswhen inputdataare distortedby noise.
System A neural network f(·) trained on a distribution X. A trained system is one that does not take in
anyexternal inputsto changeor updateits weights.We considerthat atrained systemis at NESS density.
For a discriminative network, f(·) is the entire system and its training data is denoted by (x,y). For a
generative network, f (·) is an encoder trained to produce a latent representation space z given data
θ g
denotedbyx and g (·) isthedecodertrainedto reconstructtheimagegivenalatentrepresentationz .
φ g
Frontiers 7
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
Figure2. Blockdiagramforperception(inblue)andproposedaction(inred)foraclassificationnetwork.
Theimagex istaken from theCURE-TSR dataset (Temel et al., 2017). Theperception pipelineisshown
in blue where the network assigns a class 3 to x. The action pipeline is shown in red where the action
A ,a = 1 is backpropagated through the final fully connected layer to the learned blue perception
d
manifold z . z changes to the action manifold za as a consequence of A . This change is stochastic
d d d d
surprisal,givenby
∂A d(yˆ,i;W)
.
∂W
L
Markov Blanket The part of thesystem that produces the latent representation z. In a generativesystem
the markov blanket is the encoder f (·) and in a discriminative system, the markov blanket is the initial
θ
part ofthenetworkfrom Eq. 5, f L−1 (·).
Internal State of the system Let z denote the internal state of the latent representation within a system.
Given a generative network, the latent representation after the encoder, z = f (x) is the internal state.
g θ
Givenadiscriminativenetwork,theinternalstateisz d = f L−1 (x).Theinternalstatesofboththenetworks
are interchangeably referred to as latent representations or as perception manifolds. Note that similar to
′
external state, if an input x is distorted to x , its internal state is also distorted and we will use either
z ′ or z ′ to denote the internal state of the system. Given any action, a, the internal state shifts to za to
d g
accommodatethisactionwithoutnecessarilychangingx. All thesestates areshowninFigs. 1and 2.
2.2 Stochastic Surprisal
During inference, the networks are passive. As discussed in Section 1 and noted by Demekas et al.
(2020), there is no mechanismto includea non-scalarsurprisal that allowsforan actionduring inference.
In this paper, we alleviate this challenge by defining a new quantity called stochastic surprisal as a
function of a hypothetical action. Consider the differences in the existing definitions of surprisal. In
generativenetworksfromEq.3,surprisalistheinducedregularizationthatpreventsoverfittingandcreates
specific constraints for a latent representation z . In discriminative networks from Eq. 8, surprisal is
g
the entropy of the network’s predicted distribution obtained from a linear combination on z . While the
d
surprisal in Eq. 1 deals with bounding the system’s surprise of the distributional divergence between the
internal model and external environment, the regularization-based and entropy-based definitions provide
amathematically-tractabledefinitionin neural networks.In thispaper, weprovidea newmathematically-
tractable definition of surprisal that is inherently a function of an action A and its effect on the network.
A formaldefinitionis providedfirst.
Definition 2.1 (Stochastic Surprisal). Given a trained neural network f (·) parameterized by θ, the
θ
gradientchange
∂A
withrespecttothenetworkparametersforallpossibleactionsAfromtheperspective
∂θ
off (·)is termedstochasticsurprisal.
θ
Frontiers 8
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
Stochastic surprisal measures the change required in the trained perception network to measure any
givenactionA.Itisstochasticsinceitdoesnotmeasurethedivergencebetweendistributionsbutrathera
single data point’s influence on the network. It is a non-scalar value that acts on the network parameters
accordingtoEq.4.Notethatwedonotactuallyupdatethenetwork.Rather,weonlymeasurethenetwork
update and use it as a surprisal quantity. This update is possible based on some action all of which are
consideredequallylikely.Athoroughdiscussionofthenamingis providedin Section 4.1.
2.2.1 Action and Stochastic Surprisal
Action is a function of any application. We first define it in a general fashion for generative and
discriminativenetworks. In Section 2.3, we define it specifically for imagequalityassessmentand robust
recognition.
2.2.1.1 Generative Networks
The action in generative networks is straightforward. Given an image x and its reconstructed image
xˆ, the possible action is to change the weight parameters in a way that reduces the disparity between x
and xˆ. In this paper, we quantify this disparity as the Mean Square Error given by kx − x˜k2. However,
2
as described in Section 2.1.2.1, the surprisal is present in the regularization terms. Hence, any action
performedhastoaccountforthissurprisal.Inthispaper,weusetheelasticnetregularization.Theoverall
actionthatinduces achangeinthenetworkis givenby,
h
A = kx−xˆk2 +β KL(z ||ρˆ )+λkWk2. (9)
g 2 j j 2
j=1
X
where A is a generative action. kx − xˆk2 is the MSE loss function, and kWk2 is the regularization on
g 2 2
h
the weights. KL(z ||ρˆ ) is the sparsity constraint denoted as the divergence between the latent
j=1 j j
representation and some small value ρˆ ,j ∈ [1,h] where h is the size of the latent representation.
j
P
By minimizing the KL divergence, the latent variables z ,j ∈ [1,h] are made sparse. β and λ are
j
hyperparameterscontrollingtheregularization.
StochasticsurprisalisthethegradientofthisactionA withrespect to thedecoderweights.Theaction
g
pipeline along with the stochastic surprisal generation is shown in Fig. 1 in red. At inference, a test
image is passed through a trained network and reconstructed. The action from Eq. 9 is calculated and
backpropagated to the latent representation space z . The change, measured as the gradients, creates a
d
change in z and the new action manifold is termed za. A toy example of the geometric interpretation of
d d
thischangeisalsoshownFig.1.Theblueperceptionmanifoldz thatreconstructsxˆ isacted onbyA to
g g
obtainanewredactionmanifoldza.Thedecodercanusethisspacetoreconstructxexactly.InSection3,
d
we show how these generated gradients can be used as features for image quality assessment. Note that
wekeep theperceptionpipelineas isand makenochanges to thetrainingprocess.
2.2.1.2 Discriminative Networks
TheactionA indiscriminativenetworksismoreinvolvedthangenerativenetworks.Whileingenerative
d
networks, the possible action is to reconstruct the image with higher fidelity, in discriminativenetworks,
the action can take any one of N outcomes. At inference, discriminative networks are given an image x
andaskedtopredictitslabely.Assumingthatyˆistheprediction,theactionweusetoelicitchangeinthe
Frontiers 9
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
networkparameters isby backpropagatingan action classain thelossfunctionJ(yˆ,a;W),a ∈ [1,N].
A = ka −y˜k2,i ∈ [1,N]. (10)
d i 2
Herea istheactionclass defined as aKroneckerdeltafunctiongivenby,
i
1, ifi = class,
a = (11)
i
(0, otherwise
Thereisnoregularizationaddedtothediscriminativeactionsincetheprobabilitydistributionσ(y˜)derived
from y˜is a function of its surprisal entropy. Note that we use an MSE function for A in Eq. 10 similar
d
to A from Eq. 9. An important difference between Eqs. 9 and 10 is the number of possible actions. In
g
discriminativenetworksthatclassifybetweenN classes,thereareN possibleiinEq.10.Hence,thereare
∂Ai
N possibleactionsA andN possiblesurprisals d ,∀i ∈ [1,N]. Theactionpipelinefordiscriminative
d ∂W
L
network for a toy example where the predicted class is 3 and the action class is 1 is shown in Fig. 2 in
red. The surprisalsare the red gradients from thefinal fully connected layer. We also showthe geometric
interpretation of a given action on the learned representation space z . The blue perception manifold is
d
acted upon by A1 through
∂A1
d to obtain the red action manifold. Note that there are N such possible
d ∂W
L
red za due to the N possible actions. This idea of N separate gradients to characterize data is not new.
d
In Settleset al. (2007), theauthors construct positiveand negativeinstance labels for a giveninput x in a
binarydecisionsetting.Thisisdonetoquantifyuncertaintyinanactivelearningsetting.Inthispaper,we
extendthischaracterizationtoN-labelsettingsandusetheimage-labelpairstoextractstochasticsurprisal
fromthenetwork.
Noticethedifferenceinthedefinitionsofaction.InFEP, thegenerativemodelactsontheoutsideworld
creating a change that reduces its surprisal. Our definition in Eq. 10 is the same one that is used in I-
FGSM (Goodfellowetal., 2014) adversarial generation technique. Eq. 10 is continuously applied and a
∂A
gradient w.r.t. the input, i.e. d, is added to x until the prediction changes adversarially. Changing the
∂x
input would be a true action from the FEP sense. However, in this paper, we do not explicitlychange the
∂A
outside world or x. Rather, we measure the effect of such a change on the network using d without
∂W
L
makingsaid change.
2.3 Methodology
Wevalidatetheeffectivenessofstochasticsurprisalduringinferenceontwoapplications:ImageQuality
Assessment (IQA) and Robust Classification. The action gradients,
∂A
are used in two ways. The first
∂φ
approach is to use the surprisal gradients as error directions. This is done by projecting images with
and without distortions onto the gradient space and comparing them. In this case, the surprisal acts as
a measurement between the images and acts as a Full-Reference IQA metric. The second approach is
to directly use surprisal gradients as feature vectors. The directional change caused by the actions is
dependent on the network, the input and the action class. By keeping the network same across action
classes, surprisal becomes a characteristic of the data. This approach is explored for the application of
robustclassification.
2.3.1 Image Quality Assessment
Image quality assessment is a field of image processing that objectively estimates the
perceptual quality of a degraded image. Multiple methods have been proposed to predict the
Frontiers 10
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
Figure3. Blockdiagram oftheproposedframework ofIQA as aplug-inontopofTemel et al.(2016).
subjective quality of images (Ponomarenko etal., 2011; Wang et al., 2004, 2003; Wangand Li, 2011;
Sampatet al., 2009; Zhang and Li, 2012; Zhang et al., 2011; Mittalet al., 2012; Temel andAlRegib,
2019;Prabhushankaret al.,2017a,2018).Allthesemethodsextractstructurerelatedhand-craftedfeatures
from both reference and distorted images and compare them to predict the quality. Recently, machine
learning models directly extract features from images Temel etal. (2016); Prabhushankaret al. (2017b);
Bosseetal. (2017). The authors in (Bosseet al., 2017) proposeto do so in either thepresence or absence
of the original pristine image. In Maet al. (2021), the authors propose a free energy inspired technique
to predict the quality. They use a Generative-Adversarial Network as the base perception module and an
additional CNN to model content and degradation dependent characteristics. In this paper, we approach
theactionmoduleinFEP as afunction oftheperception moduleitself. Wedo so by extractingstochastic
surprisalfromthesameperceptionnetwork.Hence,ourmethodactsasaplug-inontopofexistingquality
estimators. In this paper, we show quantitative results by plugging-in on top of UNIQUE (Temel et al.,
2016) and qualitative results on top of Bosseet al. (2017). We first describe and motivate the usage of
UNIQUEforquantitativeresults.
UNIQUE: We choose UNIQUE as the base technique since it follows the generative process described
in Section 2.1.2.1 and Fig. 1. This allows for the generation of stochastic surprisal from Eq. 3 based
on the Action in Eq. 9. The authors in Temelet al. (2016) train a sparse autoencoder with a one layer
encoder and decoder and a sigmoid non-linearity on 100,000 patches of size 8 × 8 × 3 extracted from
ImageNet (Deng etal., 2009) testset. The autoencoder is trained with MSE reconstruction loss. This
network is f(·) from Eq. 3. UNIQUE follows a full reference IQA workflow which assumes access to
both reference and distorted images while estimating quality. The reference and distorted images are
convertedtoYGCrcolorspaceandconvertedto8×8×3patches.Thesepatchesaremeansubtractedand
ZCAwhitenedbeforebeingpassedthroughthetrainedencoder.Theactivationsofallreferencepatchesin
thelatentspaceareextractedandconcatenated.Activationslesserthanathresholdof0.025aresuppressed
to0.Thechoiceofthreshold0.025ismadebased onthesparsitycoefficientusedduringtraining.Similar
procedure is followed for distorted image patches. The suppressed and concatenated features of both the
reference and distorted images are compared using Spearman correlation. The resultant is the estimated
qualityofthedistortedimage.
Frontiers 11
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
Table1. StructureofH(·) fordifferentResNet architecturesas f(·).
NETWORK f(·) STRUCTURE OF H(·)- ALL LAYERS SEPARATED BY SIGMOID
RESNET-18,34 640×300−300×100−100×10
RESNET-50, 101 2560×300−300×100−100×10
2.3.1.1 Proposed Methodology
We provide the block diagram for the proposed methodology in Fig. 3. Both the pristine and distorted
images go through the same pre-processing steps detailed in UNIQUE (Temel etal., 2016) and are
projected onto the stochastic surprisal gradients of the decoder. The gradients
∂A
g are extracted by
∂φ
backpropagatingEq.9. Inthispaper, weusethesamehyperparametersβ = 3, λ = 3e
−3,
andρ = 0.035
j
as used in Temel et al. (2016). Once projected, the resultant is passed through an inverse sigmoidal layer
′
toobtainthelatentrepresentation.Notethatthelatentrepresentationisz forthepristineimageandz for
g g
thedistortedimage.Oncepassedthroughtheinversionlayer,boththemagnitudeandphaseofeachlatent
representation is concatenated and their spearman correlation coefficient is taken to estimate the quality
scoreoftheimage.
2.3.2 Robust Classification
ThegoalistocharacterizeanimagexusingallN actions.Consideranimagexwhoseclassaspredicted
by f (·) is yˆ. Stochastic surprisal of x against class 1 is provided by backpropagating a loss between yˆ
θ
and 1 and obtaining corresponding gradients. The gradient is proportional to A (yˆ,1;W ), where W is
d L
the weight parameters and 1 is the action class. Specifically, it is ∇ A (yˆ,1;W ) for weights in layer
W d L
L
Landclassi ∈ [1,N]. WebackpropagateoverallN classestoobtaintheoverallsurprisalfeaturesacross
allclasses.Thefinal feature, r foran imagex, isgivenbyconcatenatingall individualfeatures andr is
x x
characteristicofimagex. Hence,
r = (∇ A (yˆ,i;W ))),∀i ∈ [1,N],
i W d L
L (12)
r = [r ,r ...r ].
x 1 2 N
Given a trained feed-forward network f(·) and image x, we extract gradients using Eq. 12
which serve as our features. Gradients as features are used in diverse applications including visual
explanations (Selvaraju et al., 2017; Prabhushankaretal., 2020; Prabhushankarand AlRegib, 2021b),
adversarial attacks (Goodfellowet al., 2014), anomaly detection (Kwonet al., 2020), and image quality
assessment (Kwon et al., 2019) among others. In this work, we use gradients as features to characterize
data.
MLP(H(·)):Oncer isobtainedforallN classes,thesurprisalfeatureisnowanalogoustoz fromEq.5.
x d
However, r
x
is of
dimensionalityℜ(N×d L−1)×1
since it is a concatenation of N gradients. To account for
thelargerdimensionsize,weclassifyr bytraininganMLPH(·)ontopofr derivedfromtrainingdata.
x x
Inthispaper, weuseasimplethreelayeredMLPasH(·)withsigmoidactivations.Theexactstructureof
theMLPisdependentond L−1 ofthebasef(·)networkandisgiveninTable1forResNets18,34,50,and
101(Heet al., 2016)thatare consideredinSection 3.
Training H(·): The concatenated r features for all training data are extracted and normalized. H(·) is
x
trainedonalltrainingr usingthesametrainingprocedureastheperceptionnetworkf(·).H(·)istrained
x
Frontiers 12
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
for 200 epochs with SGD optimizer and cross-entropy loss, momentum = 0.9, weight decay = 5e − 4,
andadaptivelearningrates of0.1,0.02,0.004changed atepochs 60,120,160respectively.
Testing using f(·)and H(·):During testtime,theproposed frameworkoperates inthreesteps. In step 1,
asshowninEq.13,thegivenimagepassesthroughtheperceptionnetworktoprovideacoarseestimation
yˆ.Instep2,thestochasticsurprisalfeaturesr areextractedaccordingtoEq.14andconcatenated.Instep
x
3, r is normalized and passed through the MLP H(·) to obtain the final prediction y˜. This is shown in
x
Eq.15.
yˆ= argmaxf(x), (13)
r = [(∇ MSE(yˆ,δi )),∀i ∈ [1,N]], (14)
x W L i
y˜= H(r ), (15)
x
Notethat wesubstitutedA inEq. 14withtheMSE formulationofactionfrom Eq.10.
d
3 RESULTS
3.1 Image Quality Assessment
We report the results of the our proposed method in comparison with commonly cited methods in this
section.Wefirstdiscussthethedatasetsusedforcomparisonaswellastheevaluationmetrics.Wefinally
showtheresultsinTable2 and discusstheseresults.
DatasetsWecompareourproposedqualityestimationtechniqueonthreedatasets-MULTI-LIVE(Jayaraman et al.,
2012), TID2013 (Ponomarenko etal., 2015), and DR IQA (Atharand Wang, 2023). We choose
MULTI-LIVE and TID2013 datasets for two reasons. Firstly, our proposed technique is a plug-in
approach on top of an existing technique (Temel etal., 2016). Hence, it is imperativeto compare against
and show results on datasets that were used in Temel etal. (2016). Secondly, the two datasets provide
access to seven categories of distortion among five levels. This is useful in comparison against the
recognition experiments discussed in Section 3.2 which follows a similarsetup. The complex distortions
can either be a combination of multiple distortions such as distortions generated in the MULTI-LIVE
dataset Jayaraman et al. (2012) or the human visual system (HVS) specific peculiar distortions such as
the ones presented in the TID2013 (Ponomarenkoet al., 2015) dataset. A more challenging scenario is
presentedinDR IQAdataset,wheretheauthorsconjectureadegradedreferencesettingforimagequality
assessment.Inthissetting,pristineimagesareunavailableasareference. Instead,singlydistortedimages
areusedasreferencetoconstructIQAmetricsformultiplydistortedimages.InTable2,weprovideresults
for DR IQA dataset as DRv1 and DRv2 based on the author’s division of the dataset. Each of DRv1
and DRv2 have 31,790 multiply distorted images and 1,122 singly distorted images. Additionally, this
dataset does not have true subjective quality scores from humans but is derived from a synthetic quality
benchmark. This synthetic score uses existing Full Reference metrics for quality generation including
someofcomparisonsin Table2.
Evaluation metrics The performance is validated using outlier ratio (consistency), root mean square
error (accuracy), Pearson correlation (linearity), Spearman correlation (rank), and Kendall correlation
(rank). Arrows next to each metric in Table 2 indicate the desirability of a higher number (↑) or a lower
number(↓). Statistical significance between correlation coefficients is measured with the formulations
suggestedinITU-TRec.P.1401ITU-T(2012)andprovidedbeloweachcorrelationcoefficient.A0value
Frontiers 13
Table2.
Overallperformance
ofimagequalityestimators.
Mohit
Prabhushankaretal.
Stochastic
Surprisalin
NeuralNetworks
PSNR SSIM MS CW IW SR FSIM FSIMc BRIS BIQI BLII Per CSV UNI COHER SUM Proposed
Databases HA SSIM SSIM SSIM SIM QUE NDS2 SIM QUE ENSI MER
OutlierRatio(OR,↓)
MULTI 0.013 0.016 0.013 0.093 0.013 0.000 0.018 0.016 0.067 0.024 0.078 0.004 0.000 0.000 0.031 0.000 0.000
TID13 0.615 0.734 0.743 0.856 0.701 0.632 0.742 0.728 0.851 0.856 0.852 0.655 0.687 0.640 0.833 0.620 0.620
RootMeanSquareError(RMSE,↓)
MULTI 11.320 11.024 11.275 18.862 10.049 8.686 10.866 10.794 15.058 12.744 17.419 9.898 9.895 9.258 14.806 8.212 7.943
TID13 0.652 0.762 0.702 1.207 0.688 0.619 0.710 0.687 1.100 1.108 1.092 0.643 0.647 0.615 1.049 0.630 0.596
DRv1 16.19 17.11 16.17 17.18 14.02 13.64 12.98 13.24 - - - 16.01 15.07 13.59 21.82 16.98 13.85
DRv2 16.47 16.42 15.76 17.48 14.04 13.17 12.82 12.92 - - - 16.23 15.35 13.19 21.57 17.59 13.24
PearsonLinearCorrelationCoefficient(PLCC,↑)
0.801 0.813 0.803 0.380 0.847 0.888 0.818 0.821 0.605 0.739 0.389 0.852 0.852 0.872 0.622 0.901 0.908
MULTI
-1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 -1 -1 0
0.851 0.789 0.830 0.227 0.832 0.866 0.820 0.832 0.461 0.449 0.473 0.855 0.853 0.869 0.533 0.861 0.877
TID13
-1 -1 -1 -1 -1 0 -1 -1 -1 -1 -1 -1 -1 0 -1 -1
0.731 0.693 0.732 0.586 0.800 0.819 0.833 0.830 - - - 0.738 0.738 0.820 0.432 0.698 0.800
DRv1
-1 -1 -1 -1 0 1 1 1 - - - -1 -1 1 -1 -1
0.709 0.702 0.738 0.521 0.799 0.826 0.836 0.833 - - - 0.720 0.720 0.825 0.417 0.658 0.815
DRv2
-1 -1 -1 -1 -1 0 1 1 - - - -1 -1 0 -1 -1
Spearman’sRankCorrelationCoefficient(SRCC,↑)
0.715 0.860 0.836 0.631 0.884 0.867 0.864 0.867 0.598 0.611 0.386 0.818 0.849 0.867 0.554 0.884 0.887
MULTI
-1 0 -1 -1 0 0 0 0 -1 -1 -1 -1 -1 0 -1 0
0.847 0.742 0.786 0.563 0.778 0.807 0.802 0.851 0.414 0.393 0.396 0.854 0.846 0.860 0.649 0.856 0.865
TID13
-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0 -1 0 -1 0
0.739 0.702 0.738 0.760 0.798 0.807 0.823 0.820 - - - 0.742 0.769 0.810 0.518 0.706 0.807
DRv1
-1 -1 -1 -1 -1 0 1 1 - - - -1 -1 0 -1 -1
0.720 0.705 0.738 0.755 0.795 0.809 0.819 0.816 - - - 0.727 0.755 0.813 0.525 0.672 0.816
DRv2
-1 -1 -1 -1 -1 -1 0 0 - - - -1 -1 0 -1 -1
Kendall’sRankCorrelationCoefficient(KRCC,↑)
0.532 0.669 0.644 0.457 0.702 0.678 0.673 0.677 0.420 0.440 0.268 0.624 0.655 0.679 0.399 0.698 0.702
MULTI
-1 0 0 -1 0 0 0 0 -1 -1 -1 -1 0 0 -1 0
0.666 0.559 0.605 0.404 0.598 0.641 0.629 0.667 0.286 0.270 0.277 0.678 0.654 0.667 0.474 0.667 0.677
TID13
0 -1 -1 -1 -1 -1 -1 0 -1 -1 -1 0 0 0 -1 0
0.534 0.505 0.537 0.559 0.597 0.609 0.629 0.626 - - - 0.537 0.563 0.609 0.357 0.503 0.605
DRv1
-1 -1 -1 -1 0 0 1 1 - - - -1 -1 0 -1 -1
0.517 0.509 0.539 0.553 0.595 0.613 0.626 0.623 - - - 0.525 0.594 0.613 0.342 0.475 0.616
DRv2
-1 -1 -1 -1 -1 0 1 0 - - - -1 -1 0 -1 -1
Frontiers
14
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
correspondstostatisticallysimilarperformance, -1meansthemethodisstatisticallyinferiortoproposed
method,and1indicatesthatthemethodisstatisticallysuperiortoproposedmethod.Twobestperforming
methodsforeach metricare highlighted.
Results We compare our proposed stochastic surprisal-based UNIQUE against other image
quality estimators based only on handcrafted features and perception pipeline in Table 2. These
compared full reference estimators include PSNR-HA (Ponomarenko et al., 2011), SSIM (Wang et al.,
2004), MS-SSIM (Wang et al., 2003), CW-SSIM (Sampat et al., 2009), IW-SIM (Wang and Li,
2011), SR-SIM (Zhangand Li, 2012), FSIM (Zhang et al., 2011), FSIMc (Zhanget al., 2011),
PerSIM (Temeland AlRegib, 2015), CSV (Temeland AlRegib, 2016b), UNIQUE (Temel et al.,
2016). We also compare against no reference metrics including BRISQUE (Mittalet al., 2012),
BIQI (Moorthyand Bovik, 2010), and BLIINDS2 (Saad et al., 2012). All these techniques were
also comapred against the base UNIQUE algorithm in Temel et al. (2016). In addition to
these, we compare against new estimators including COHERENSI (Temeland AlRegib, 2019) and
SUMMER(Temel andAlRegib, 2019). SUMMER beats UNIQUE among six ofthe ten categories. Note
thatwedonotshowresultsforBRISQUE, BIQI, and BLIINDS2 forDR IQAdatasetsinceNRmethods,
thataregenerallytrainedonsinglydistortedimages,exhibitalargeperformancegaponmultiplydistorted
images(AtharandWang, 2023).
The proposed stochastic surprisal-based method plugs on top of UNIQUE and its results are provided
under the last column in Table 2. It is always in the top two methods for MULTI-LIVE and TID2013
datasets in all evaluation metrics. In particular, the proposed method achieves the best performance for
allthecategoriesexceptinORandKRCC inTID2013dataset.UNIQUE,byitself,doesnotachievethe
bestperformanceforanyofthemetricsinMULTIdataset.However,thesamenetworkusingtheproposed
gradientfeaturessignificantlyimprovestheperformanceandachievesthebestperformanceonallmetrics.
For instance, UNIQUE is the third best performing method in MULTI dataset in terms of RMSE, PLCC,
SRCC, and KRCC. However, the action-based features improve the performance for those metrics by
1.315,0.036,0.020,and 0.023,respectivelyand achievethebestperformanceforallmetrics.Thisfurther
reinforces the plug-in capability of the proposed method during inference. On DR IQA dataset, FSIM
and FSIMc perform the best across all categories. The authors in Atharand Wang (2023) used FSIMc to
construct DR IQA models. However, the proposed algorithm remains competitive among all evaluation
metrics. The results are statistically significant in 53 of the 78 compared metrics across both DRv1 and
DRv2.NotethatanumberofthesecomparedFR-IQAmetricshavebeenutilizedtoconstructthesynthetic
groundtruthqualityscores.
3.2 Robust Classification
Neural networks are sensitive to distortions in test that the network was not privy to during
training (Temelet al., 2017, 2018; Hendrycksand Dietterich, 2019). These distortions include image
acquisition errors, environmental conditions during acquisition, transmission and storage errors among
others. CIFAR-10C (Hendrycks andDietterich, 2019) dataset consists of 19 real world distortions each
of which has five levels of degradation that distort the 10000 images in CIFAR-10 testset. Neural
networksthatuseperception-onlymechanicssufferperformanceaccuracydropsonCIFAR-10C.Current
techniques that alleviate the drop in perception-only accuracy require additional training data. The
authors in Vasiljevicet al. (2016) show that finetuning or retraining networks using distorted images
increases the performance of classification under the same distortion. However, performance between
different distortions is not generalized well. For instance, training on gaussian blurred images does
Frontiers 15
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
Table3. Stochasticsurprisal-basedplug-inon topofexistingrobustnesstechniques.
METHODS ACCURACY
RESNET-18 PERCEPTION-ONLY 67.89%
PROPOSED 71.4%
DENOISING PERCEPTION-ONLY 65.02%
PROPOSED 68.86%
ADVERSARIAL TRAIN (HENDRYCKS AND DIETTERICH, 2019) PERCEPTION-ONLY 68.02%
PROPOSED 70.86%
SIMCLR (CHEN ET AL., 2020) PERCEPTION-ONLY 70.28%
PROPOSED 73.32%
AUGMENT NOISE (VASILJEVIC ET AL., 2016) PERCEPTION-ONLY 76.86%
PROPOSED 77.98%
AUGMIX (HENDRYCKS ET AL., 2019) PERCEPTION-ONLY 89.85%
PROPOSED 89.89%
not guarantee a performance increase in motion blur images (Geirhos etal., 2018b). Other proposed
methods include training on style-transferred images (Geirhoset al., 2018a), training on adversarial
images(Hendrycksand Dietterich,2019),trainingonsimulatednoisyvirtualimages(Temel et al.,2017),
and self-supervised methods like SimCLR Chen et al. (2020) that train by augmenting distortions.
Augmix (Hendrycks et al., 2019) creates multiple chains of augmentations to train the base network. All
these works require additional training data. Our proposed stochasticsurprisal-based technique is a plug-
in on top of any existing method that increases the base network’s robustness to distortions without any
need fornewdata.
Experimental setup anddataset:WeuseCIFAR-10C(Hendrycks and Dietterich,2019)as ourdataset
of choice with all its 95 distortions and degradation levels. ResNet-18,34,50, and 101 (Heet al., 2016)
architectures are used as the base f(·) perception-only networks. These are trained from scratch on
CIFAR-10 dataset. Following the terminologies established in Section 2, X is the training set of
CIFAR-10 and X ′ are the 19 distorted domains in which the testing set of CIFAR-10C reside. Each
ofthe19corruptionshave5levelsofdistortions.Higherthelevel,higheristhedistortion.Thedistortions
include blur characteristics like gaussian blur, zoom blur, glass blur, and environmental distortions like
rain,snow,fog,haze amongothers.
Comparison against existing State of the Art Methods: In Table 3, we compare the Top-1 accuracy
between perception-only inference and our proposed stochastic surprisal-based inference. All the state-
of-the-art techniques require additional training data - noisy images (Vasiljevicetal., 2016), adversarial
images (Hendrycks and Dietterich, 2019), self-supervision SimCLR augmentations (Chen et al., 2020),
′
and augmentation chains (Hendryckset al., 2019). We term these perception-only techniques as f (·)
′
and we actively infer on top of them. For all f (·) other than Augmix, the base network is a ResNet-
18. For Augmix, we use WideResNet architecture following the authors in Hendrycks et al. (2019).
Another commonly used robustness technique is to pre-process the noisy images to denoise them.
Denoising 19 distortions is, however, not a viable strategy assuming that the characteristics of the
distortions are unknown. We use Non-Local Means (Buades et al., 2011) denoising and the results
obtained are lower than the perception-only accuracy by almost 3%. However, the proposed technique
on this model increases the results by 3.84%. We create untargeted adversarial images using FGSM
attack (Goodfellowet al., 2014) and use them to train a ResNet-18 architecture. In the experimental
Frontiers 16
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
Figure 4. Visualization of accuracy gains (in red) of using the proposed stochastic surprisal-based
inference over perception-only inference (in red) on CIFAR-10C dataset (Hendrycksand Dietterich,
2019)forfournetworksacross 19distortions.
setup of augmenting noise (Vasiljevicet al., 2016), we augment the training data of CIFAR-10 with six
distortions provided by Temel et al. (2018) to randomly distort 500 CIFAR-10 training images to train
′ ′
f (·).Foralltechniques,theproposedtechniqueplugsontopoff (·)andincreasestheaccuracytocreate
robust networks. Note that in all the perception-only methods in Table 3, we do not use the augmented
data to train H(·). The gain obtained is by creating actions on only the undistorted data. Even when the
′ ′
augmented network f (·) gains on non-augmented f(·), the proposed technique plugs on top of f (·) to
provideadditionalgains.
Analyzing distortion-wise accuracy gains: The results of all four ResNet architectures for each of the
19 distortionsis shownin Fig 4. X-Axis in each plot shows19 distortionsaveraged overall 5 distortion
levels. Y-Axis shows Top-1 accuracy. The bars in blue show perception-only inference results and the
red region in each bar represents the performance gain obtained by stochastic surprisal-based inference.
There is an increase in performance across distortions and networks. In 9 of the 19 distortions, the
proposed method averages 4% more than its perception-only counterpart. These include gaussian blur,
gaussian noise, glass blur, impulse noise, motion blur, pixelate, shot noise, speckle noise, and zoom blur.
The highest increase is 8.22% for glass blur. In 2 of the distortions, brightness and saturate, the results
increase by less than 0.4% averaged over all levels. This is because of the statistics that the distortions
affect. Distortionscan change either the local or global statistics within images. Distortionslike saturate,
brightness, contrast, fog, and frost change the low level or global statistics in the image domain. Neural
Frontiers 17
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
Figure 5. Visualization of accuracy gains (in red) of using the proposed stochastic surprisal-based
inference over perception-only inference (in blue) on CIFAR-10C dataset (Hendrycksand Dietterich,
2019) for four networks (a) averaged across 19 distortions and 5 levels (b) shown across 5 levels of
distortion.
networks are actively trained to ignore such changes so that their effects are not propagated beyond
the first few layers. Hence, gradients derived from the final fully connected layer do not capture the
necessary changes required withinf(·) to compensateforthesedistortions.Therefore, both theproposed
andperception-onlyinference followeach othercloselyin distortionslikebrightnessand saturate.
Level-wise Recognition on CIFAR-10C: In Fig. 5b, the proposed performance gains for the four
networksarecategorizedbasedonthedistortionlevels.All19categoriesofdistortiononCIFAR-10Care
averagedforeachlevelandtheirrespectiveperception-onlyaccuracyandstochasticsurprisal-basedgains
′
are shown. Note that the levels are progressivelymore distorted. Hence, level 1 distributionX is similar
to the training distribution X when compared to level 5 distributions. As the distortion level increases,
the proposed method’s accuracy gains also increase. This is because, with a larger distributional shift,
morecharacteristicistheactionrequiredw.r.t.thenetworkparameters.InFig.5a,weshowthedistortion-
wise and level-wise accuracy gains for each network. Note that, a stochastic surprisal-based ResNet-18
performssimilarlyto aperception-onlyResNet-50.
4 DISCUSSION
We conclude this paper by considering the terminology of stochastic surprisal as well as some of the
broader implications of the proposed technique. These include the abductive reasoning module and
expectancy-mismatchhypothesisincognitivescience.
4.1 Choice of the terminology of Stochastic Surprisal
Wemotivatetheterminologyofstochasticsurprisalintwoways:
1.As an analogy to gradient descent and stochastic gradient descent: Gradient descent requires
the gradients from the all available training data to update the weights. However, since this is
computationally infeasible for large neural networks, stochastic gradient descent allows using a single
Frontiers 18
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
training datapoint to estimate gradients, repeated across all data. In stochastic surprisal, we use the
singledatapoint,availableat inference, underall allowableactionsto estimatesurprisal.
2.Meaning of stochastic: The word stochastic implies some randomness within the setting. This
randomness is derived from the possible set of all actions. In discriminative networks in Eq. 10,
a ,i ∈ [1,N]isthesetofallpossibleactionswithN beingthenumberoftrainedclasses. Thissuggests
i
thatweallowadatapointtobeanyavailableclass,allofwhichareequallylikely.Similarly,ingenerative
networks in Eq. 9, we add random perturbations at the output of the autoencoder. Hence, there is an
inherent randomnesswithintheactionsthatallowfortheusageoftheword stochastic.
4.2 Abductive Reasoning
The free energy principlepostulates that the brain encodes a Bayesian recognition density that predicts
sensory data based upon some hypotheses about their causes. This mode of inference is called inference
tothebestexplanation.Theunderlyingreasoningmodelisabductivereasoning.Abductivereasoningwas
introduced by the philosopher Charles Sanders Peirce (Peirce, 1931), who saw abduction as a reasoning
process from effect to cause (Paul, 1993). An abductive reasoning framework creates a hypothesis and
tests its validity without considering the cause. A hypothesis can be considered as an answer to one
of the three following questions: a causal ‘Why P?’ question, a counterfactual ‘What if?’ question, and a
contrastive‘WhyP,ratherthanQ?’question(AlRegiband Prabhushankar,2022).HereP istheprediction
and Q is any contrast class. The action considered in this paper is the latter contrastive question of the
form ‘Why P, rather than Q?’. Stochastic surprisal measures the answer to this question. We explore this
further in AlRegiband Prabhushankar (2022); Prabhushankaretal. (2020). We borrow the visualization
procedure from Prabhushankaret al. (2020) to visually analyze stochastic surprise in the applications of
IQA andrecognitionin Fig.6. Wedo soto illustratethebroaderimpactofactionat inference time.Asin
Section2.3.1.1, weusestochasticsurprisalas aplug-inapproach.
Figure 6. Stochastic surprisal answers contrastive questions. The highlighted regions in each image
providesa visual explanation to the questionbeneath it. WhileGrad-CAM (Selvarajuet al., 2017) shows
alltheperceivedregionsintheimage,thestochasticsurprisalprovidesfine-grainedanswerstocontrastive
questions.Best viewedincolor.
Frontiers 19
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
For IQA visualizations, we use a trained full-reference metric DIQaM-FR Bosseet al. (2017) as our
perception model. In Fig. 6a, the pretrained network from Bosseet al. (2017) provides a quality score of
0.58 to the distorted lighthouseimage. Here 0.58 acts as P in the contrastivequestion. We use MSE loss
function as A and a real number Q ∈ [0,1] to calculate stochastic surprisal. Contrastive explanations
d
of Q values including 0.25,0.75, and1 along with Grad-CAM results are shown in Fig. 6a. Grad-CAM
highlights the entire image indicating that the network estimates the quality based on the whole image.
Whilethisbuildstrustinthenetwork,itdoesnothelpus understandthenetworkdecision.Thestochastic
surprisal,however,providesfine-grained explanations.Considerthecontrastivequestionsaskingwhythe
qualityisneither1 nor0.75.Thenetworkestimatesthistobeprimarilyduetodistortionsconcentratingin
theforegroundportionoftheimage. ThisexplanationisinlinewithpreviousworksinIQA thatpositthat
distortions in the more salient foreground or edge features cause a larger drop in perceptual quality than
thatincolororbackground(Prabhushankaret al.,2017b)(Chandler,2013).Whenthecontrastivequestion
askswhythepredictionisnot0.25,thenetworkhighlightstheskyindicatingitsgoodqualityforahigher
scoreof0.58.
Fig. 6b shows the contrastive questions answered by the stochastic surprisal for the application of
recognition. Given an image of a spoonbill from ImageNet dataset (Denget al., 2009), a VGG-16
network highlights the body, feathers, legs and beak of the bird in the Grad-CAM (Selvaraju et al.,
2017) explanation. Consider a more fine grained contrastive question regarding the difference between a
spoonbilland flamingo.Thestochasticsurprisalhighlightsregionsintheneck ofthespoonbillindicating
that the contrast between the input spoonbill image and the network’s notion of a flamingo lies in the
spoonbill’s lack of S-shaped neck. Similarly, the contrast between a spoonbill and a crane is in the color
of the spoonbill’sfeathers. The contrast between a pig and a spoonbillis in the shape of neck and legs in
the spoonbill which is emphasized. All these visualizations serve to illustratethe stochastic nature of the
proposedmethod.Itisstochasticinthesensethatitindividuallydependsonthenetwork,thedata,aswell
as theaction. In thiscase, the actionof not predictinga flamingo has adifferent explanationcompared to
theaction ofnotpredictingapig.
4.3 Expectancy-Mismatch
The expectancy-mismatch hypothesis in cognitive science is a way to quantify and analyze human
attention. According to this hypothesis, human attention mechanism suppresses expected messages and
focuses on the unexpected ones (Summerfield andEgner, 2009; Krebs et al., 2012; Horstmannet al.,
2016; Horstmann, 2002; Becker and Horstmann, 2011; Sun et al., 2020). Becker and Horstmann (2011)
shows that a message which is unexpected, captures human attention. Then, the human visual system
establishes whether the input matches the observers’ expectation. If they are conflicting, error neurons
in the human brain encode the prediction error and pass the error message back to the representational
neurons.Theproposedmethodusesgradientswithrespecttothenetworkparameterstomeasureanaction.
In both the generative and discriminative networks, this action takes the form of a change in the output
therebycreating amismatchwiththenetwork’sexpected result.Hence, theproposedmethodcan act as a
frameworkforexploringexpectancy-mismatchin futureworks.
4.4 Related Learning Paradigms
The proposed stochastic surprisal decomposes the decision making and training process of a neural
network into perception and action phases. A number of other machine learning paradigms including
continual and lifelong learning (Parisi et al., 2019), online learning (Hoi etal., 2021), and introspective
learning (Prabhushankarand AlRegib, 2022) also have multiple stages. Online learning assumes an
Frontiers 20
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
exploration and exploitation stage in a neural network’s training process. Hence, the differentiation in
the training stages is based on time rather than the proposed action. Continual and lifelong learning is
a research paradigm that tackles the topic of catastrophic forgetting when a neural network is trained
to perform multiple tasks. Introspective learning conjectures reasons in the form of counterfactual or
contrastive questions in its two stages to make predictions. Hence, while there are multiple machine
learning paradigms that conjecture decomposition of neural network’s training and decision processes,
the proposed framework that is based on the FEP is unique in its decomposition. The field of active
learning(Loganet al.,2022;Benkert et al.,2022)involvesactionswithinthetraininganddecisionmaking
processes. However, active learning requires actions from the users while the considered actions in the
proposedmethodologyare withrespect to theneural network.
4.5 Conclusion
In this paper, we examine supervised learning from the perspective of Free Energy Principle. The
learning process of both generative and discriminative models can be decomposed into divergence and
surprisal measures. Surprisal is introduced in generative models via regularization and constraints that
allowagenerativeaspecttotheirfunctionality.Whilethiscomplicatestheactionitself,thesetofpossible
actions is still limited. Discriminative networks follow the traditional route of free energy minimization
by defining surprisal in terms of recognition entropy and minimizing it. This allows the action itself to
be a simple fidelity-based reconstruction error. However, in discriminative networks, there are N set of
possible actions, N being the number of classes in the recognition density. We account for both these
peculiarities in defining our action space. We use a fidelity-based MSE loss for both generative and
discriminativenetworks.Inaddition,generativenetworksarereinforcedwithKL-divergencebasedelastic
net regularization, and in discriminative networks we backpropagate N possible actions. We measure
this scalar action quantity in terms of a vector quantity called stochastic surprisal that is a function
of the network parameters and an individual data point rather than a distribution. We use stochastic
surprisal to assess distortionsin imagequality assessment and disregard distortionsin robust recognition.
We then discuss the implications of stochastic surprisal in other areas of cognitive science including
abductive reasoning and expectancy-mismatch. A computational bottleneck within the framework is the
consideration of all N possible actions to estimate the surprisal feature r . r scales linearly with N
x x
thereby becoming prohibitive on datasets with a large number of classes. Selecting only a subset of the
mostlikelyactionsis oneplausiblesolutiontothechallengeofscalability.
REFERENCES
AlRegib, G. and Prabhushankar, M. (2022). Explanatory paradigms in neural networks. arXiv preprint
arXiv:2202.11838
Athar, S. and Wang, Z. (2023). Degraded reference image quality assessment. IEEE Transactions on
ImageProcessing
Becker, S. I. and Horstmann, G. (2011). Novelty and saliency in attentional capture by unannounced
motionsingletons. ActaPsychologica136,290–299. doi:https://doi.org/10.1016/j.actpsy.2010.12.002
Benkert, R., Prabhushankar, M., and AlRegib, G. (2022). Forgetful active learning with switch events:
Efficient sampling for out-of-distribution data. In 2022 IEEE International Conference on Image
Processing(ICIP) (IEEE), 2196–2200
Bosse, S., Maniry, D., Mu¨ller, K.-R., Wiegand, T., and Samek, W. (2017). Deep neural networks for
no-reference and full-reference image quality assessment. IEEE Transactionson image processing27,
206–219
Frontiers 21
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
Buades, A., Coll, B., and Morel, J.-M. (2011). Non-local means denoising. ImageProcessingOn Line 1,
208–212
Buckley, C. L., Kim, C. S., McGregor, S., and Seth, A. K. (2017). The free energy principle for action
and perception:A mathematicalreview. Journalof MathematicalPsychology81,55–79
Chandler,D.M.(2013). Sevenchallengesinimagequalityassessment:past,present, andfutureresearch.
ISRN SignalProcessing2013
Chen,T.,Kornblith,S.,Norouzi,M.,andHinton,G.(2020). Asimpleframeworkforcontrastivelearning
ofvisualrepresentations. arXivpreprintarXiv:2002.05709
Demekas,D.,Parr,T.,andFriston,K.J.(2020). Aninvestigationofthefreeenergyprincipleforemotion
recognition. Frontiersin ComputationalNeuroscience14,30
Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. (2009). Imagenet: A large-scale
hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition
(Ieee), 248–255
Friston,K.(2009). Thefree-energy principle:aroughguidetothebrain? Trendsincognitivesciences13,
293–301
Friston,K. (2019). A free energy principleforaparticularphysics. arXivpreprintarXiv:1906.10184
Gedeon, T. and Harris, D. (1992). Progressive image compression. In [Proceedings 1992] IJCNN
InternationalJointConferenceon NeuralNetworks (IEEE), vol. 4,403–407
Geirhos,R.,Rubisch,P.,Michaelis,C.,Bethge,M.,Wichmann,F.A.,andBrendel,W.(2018a). Imagenet-
trainedcnnsarebiasedtowardstexture;increasingshapebiasimprovesaccuracyandrobustness. arXiv
preprintarXiv:1811.12231
Geirhos, R., Temme, C. R., Rauber, J., Schu¨tt, H. H., Bethge, M., and Wichmann, F. A. (2018b).
Generalisation in humans and deep neural networks. In Advances in Neural Information Processing
Systems. 7538–7550
Geisler,W.S.(2008). Visualperceptionandthestatisticalpropertiesofnaturalscenes. Annu.Rev.Psychol.
59, 167–192
Goodfellow, I. J., Shlens, J., and Szegedy, C. (2014). Explaining and harnessing adversarial examples.
arXivpreprintarXiv:1412.6572
Gottwald, S. and Braun, D. A. (2020). The two kinds of free energy and the bayesian revolution. PLoS
computationalbiology16,e1008420
Gu, K., Zhai, G., Yang, X., and Zhang, W. (2014). Using free energy principle for blind image quality
assessment. IEEETransactionsonMultimedia17,50–63
He, K., Zhang, X., Ren, S., and Sun, J. (2016). Deep residual learning for image recognition. In
ProceedingsoftheIEEEconference oncomputervisionand patternrecognition.770–778
Hendrycks, D. and Dietterich, T. (2019). Benchmarking neural network robustness to common
corruptionsand perturbations. arXivpreprintarXiv:1903.12261
Hendrycks, D., Mu, N., Cubuk, E. D., Zoph, B., Gilmer, J., and Lakshminarayanan, B. (2019).
Augmix: A simple data processing method to improve robustness and uncertainty. arXiv preprint
arXiv:1912.02781
Hinton, G. E. and Zemel, R. (1993). Autoencoders, minimum description length and helmholtz free
energy. Advancesin neuralinformationprocessingsystems6
Hipo´lito, I., Ramstead, M. J., Convertino, L., Bhat, A., Friston, K., and Parr, T. (2021). Markov blankets
in thebrain. Neuroscience& BiobehavioralReviews 125,88–97
Hoi, S. C., Sahoo, D., Lu, J., and Zhao, P. (2021). Online learning: A comprehensive survey.
Neurocomputing459,249–289
Frontiers 22
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
Horstmann, G. (2002). Evidence for attentional capture by a surprising color singleton in visual search.
PsychologicalScience13, 499–505. doi:10.1111/1467-9280.00488. PMID: 12430832
Horstmann,G., Becker, S., and Ernst, D. (2016). Perceptual saliencecaptures theeyes on a surprisetrial.
Attention,Perception, &Psychophysics78, 1889–1900
Hou,X.andZhang,L.(2007). Saliencydetection:Aspectralresidualapproach. In2007IEEEConference
on computervisionandpatternrecognition(Ieee), 1–8
ITU-T (2012). P.1401: Methods, metrics and procedures for statistical evaluation, qualification and
comparisonofobjectivequalitypredictionmodels. Tech. rep., ITU Telecom.Stand. Sector
Jayaraman, D., Mittal, A., Moorthy, A. K., and Bovik, A. C. (2012). Objective quality assessment of
multiplydistortedimages. In AsilomarConf.Sig.Syst. Comp.1693–1697
Kingma,D. P. and Welling,M.(2013). Auto-encodingvariationalbayes. arXiv:1312.6114
Kingma, D. P. and Welling, M. (2019). An introduction to variational autoencoders. arXiv preprint
arXiv:1906.02691
Krebs, R., Fias, W., Achten, E., and Boehler, C. (2012). Stimulus conflict and stimulus novelty trigger
saliency signalsin locus coeruleus and anterior cingulatecortex. In Front.Hum. Neurosci. Conference
Abstract:BelgianBrainCouncil.doi:10.3389/conf.fnhum.vol. 114
Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classification with deep convolutional
neural networks. Advances inneuralinformationprocessingsystems25
Kwon, G., Prabhushankar, M., Temel, D., and AlRegib, G. (2019). Distorted representation space
characterization through backpropagated gradients. In 2019 IEEE International Conference on Image
Processing(ICIP) (IEEE), 2651–2655
Kwon, G., Prabhushankar, M., Temel, D., and AlRegib, G. (2020). Backpropagated gradient
representations for anomaly detection. In European Conference on Computer Vision (Springer),
206–226
Liu, Y., Gu, K., Zhang, Y., Li, X., Zhai, G., Zhao, D., et al. (2019). Unsupervised blind image quality
evaluationviastatisticalmeasurementsofstructure,naturalness,andperception. IEEETransactionson
Circuitsand SystemsforVideoTechnology30, 929–943
Liu, Y., Zhai, G., Gu, K., Liu, X., Zhao, D., and Gao, W. (2017). Reduced-reference image quality
assessment in free-energy principle and sparse representation. IEEE Transactions on Multimedia 20,
379–391
Logan, Y.-y., Prabhushankar, M., and AlRegib, G. (2022). Decal: Deployable clinical active learning.
arXivpreprintarXiv:2206.10120
Ma, J., Wu, J., Li, L., Dong, W., Xie, X., Shi, G., et al. (2021). Blind image quality assessment with
activeinference. IEEE Transactionson ImageProcessing30,3650–3663
Mao, X., Shen, C., and Yang, Y.-B. (2016). Image restoration using very deep convolutional encoder-
decodernetworkswithsymmetricskipconnections. Advancesinneuralinformationprocessingsystems
29
Mittal,A.,Moorthy,A.K.,andBovik,A.C.(2012). No-referenceimagequalityassessmentinthespatial
domain. IEEE Trans.ImageProc.21,4695–4708
Moorthy, A. K. and Bovik, A. C. (2010). A two-step framework for constructing blind image quality
indices. IEEE Sig.Proc.Let. 17,513–516
Murray, N., Vanrell, M., Otazu, X., and Parraga, C. A. (2013). Low-level spatiochromatic grouping for
saliencyestimation. IEEE transactionsonpatternanalysisand machineintelligence35,2810–2816
Ng,A. (2011). Sparse autoencoder. CS294ALecture notes72, 1–19
Frontiers 23
Mohit Prabhushankaretal. Stochastic Surprisalin NeuralNetworks
Parisi, G. I., Kemker, R., Part, J. L., Kanan, C., and Wermter, S. (2019). Continuallifelong learning with
neural networks:A review. NeuralNetworks 113,54–71
Paul, G. (1993). Approaches to abductive reasoning: an overview. Artificial intelligence review 7, 109–
152
Peirce, C. S. (1931). Collected papersof charlessanderspeirce(Harvard UniversityPress)
Ponomarenko, N., Ieremeiev, O., Lukin, V., Egiazarian, K., and Carli, M. (2011). Modified image visual
qualitymetricsforcontrastchange andmean shiftaccounting. In Proc.CADSM. 305–311
Ponomarenko, N., Jin, L., Ieremeiev, O., Lukin, V., Egiazarian, K., Astola, J., et al. (2015). Image
databasetid2013:Peculiarities,resultsandperspectives. SignalProcessing:ImageCommunication30,
57–77
Prabhushankar, M. and AlRegib, G. (2021a). Contrastive reasoning in neural networks. arXiv preprint
arXiv:2103.12329
Prabhushankar, M. and AlRegib, G. (2021b). Extracting causal visual features for limited label
classification. In2021IEEEInternationalConferenceonImageProcessing(ICIP)(IEEE),3697–3701
Prabhushankar, M. and AlRegib, G. (2022). Introspective learning: A two-stage approach for inference
in neural networks. arXivpreprintarXiv:2209.08425
Prabhushankar, M., Kokilepersaud, K., Logan, Y.-y., Corona, S. T., AlRegib, G., and Wykoff, C.
(2022). Olives dataset: Ophthalmic labels for investigating visual eye semantics. arXiv preprint
arXiv:2209.11195
Prabhushankar, M., Kwon, G., Temel, D., and AIRegib, G. (2018). Semantically interpretable and
controllablefiltersets. In201825thIEEEInternationalConferenceonImageProcessing(ICIP)(IEEE),
1053–1057
Prabhushankar, M., Kwon, G., Temel, D., and AlRegib, G. (2020). Contrastive explanations in neural
networks. In 2020IEEE InternationalConferenceon ImageProcessing(ICIP) (IEEE), 3289–3293
Prabhushankar, M., Temel, D., and AlRegib, G. (2017a). Generating adaptiveand robust filter sets using
an unsupervised learning framework. In 2017 IEEE International Conference on Image Processing
(ICIP) (IEEE), 3041–3045
Prabhushankar, M., Temel, D., and AlRegib, G. (2017b). Ms-unique: Multi-model and sharpness-
weighted unsupervisedimagequalityestimation. ElectronicImaging2017,30–35
Saad, M. A., Bovik, A. C., and Charrier, C. (2012). Blind image quality assessment: A natural scene
statisticsapproach in thedct domain. IEEETrans.onImageProc.21, 3339–3352
Sampat,M.P.,Wang,Z.,Gupta,S.,Bovik,A.C.,andMarkey,M.K.(2009). Complexwaveletstructural
similarity:A newimagesimilarityindex. IEEE Trans.ImageProc.18,2385–2401
Sebastian, S., Abrams, J., and Geisler, W. S. (2017). Constrained samplingexperimentsreveal principles
ofdetectionin naturalscenes. Proceedingsof theNationalAcademyof Sciences 114,E5731–E5740
Selvaraju, R. R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., and Batra, D. (2017). Grad-cam:
Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE
internationalconference oncomputervision.618–626
Settles, B., Craven, M., and Ray, S. (2007). Multiple-instance active learning. Advances in neural
informationprocessingsystems20
Shafiq, M., Prabhushankar, M., and AlRegib, G. (2018a). Leveraging sparse features learned from
natural images for seismic understanding. In 80th EAGE Conference and Exhibition 2018 (European
AssociationofGeoscientists& Engineers),vol.2018,1–5
Frontiers 24
MohitPrabhushankaretal. Stochastic Surprisalin NeuralNetworks
Shafiq, M. A., Prabhushankar, M., Di, H., and AlRegib, G. (2018b). Towards understanding common
features between natural and seismic images. In SEG Technical Program Expanded Abstracts 2018
(Society ofExplorationGeophysicists).2076–2080
Summerfield,C.andEgner,T.(2009). Expectation(andattention)invisualcognition. TrendsinCognitive
Sciences 13,403– 409. doi:https://doi.org/10.1016/j.tics.2009.06.003
Sun, Y., Prabhushankar, M., and AlRegib, G. (2020). Implicitsaliency in deep neural networks. In 2020
IEEE InternationalConferenceon ImageProcessing(ICIP) (IEEE), 2915–2919
Temel,D.andAlRegib,G.(2015). PerSIM:Multi-resolutionimagequalityassessmentintheperceptually
uniformcolordomain. In IEEE Int.Conf. ImageProc.1682–1686
Temel, D. and AlRegib, G. (2016a). Bless: Bio-inspired low-level spatiochromatic similarity assisted
image quality assessment. In 2016 IEEE International Conference on Multimedia and Expo (ICME)
(IEEE), 1–6
Temel,D.andAlRegib,G. (2016b). CSV:Imagequalityassessmentbasedoncolor,structure,andvisual
system. Sig.Proc.:ImageComm. 48, 92– 103. doi:http://dx.doi.org/10.1016/j.image.2016.08.008
Temel,D.andAlRegib,G.(2019). Perceptualimagequalityassessmentthroughspectralanalysisoferror
representations. Sig.Proc.:ImageComm.
Temel, D., Kwon, G., Prabhushankar, M., and AlRegib, G. (2017). Cure-tsr: Challenging unreal and real
environmentsfor trafficsignrecognition. arXivpreprintarXiv:1712.02463
Temel,D.,Lee, J.,andAlRegib,G.(2018). Cure-or:Challengingunrealandrealenvironmentsforobject
recognition. In 2018 17th IEEE International Conference on Machine Learning and Applications
(ICMLA) (IEEE), 137–144
Temel,D.,Prabhushankar,M.,andAlRegib,G.(2016). UNIQUE:Unsupervisedimagequalityestimation.
IEEE Sig.Proc.Let. 23,1414–1418
Vasiljevic,I.,Chakrabarti,A.,andShakhnarovich,G.(2016). Examiningtheimpactofbluronrecognition
by convolutionalnetworks. arXivpreprintarXiv:1611.05760
Wang,Z.,Bovik,A.C.,Sheikh,H.R.,andSimoncelli,E.P.(2004). Imagequalityassessment:fromerror
visibilitytostructural similarity. IEEE Trans.ImageProc.13,600–612
Wang, Z. and Li, Q. (2011). Information content weighting for perceptual image quality assessment.
IEEE Trans.ImageProc.20, 1185–1198
Wang, Z., Simoncelli, E. P., and Bovik, A. C. (2003). Multiscale structural similarity for image quality
assessment. In AsilomarConf.Sig.,Syst. &Comp. vol.2, 1398–1402
Zhai, G., Wu, X., Yang, X., Lin, W., and Zhang, W. (2011). A psychovisualqualitymetricin free-energy
principle. IEEE Transactionson ImageProcessing21,41–52
Zhang,L.andLi,H.(2012). Sr-sim:Afastandhighperformanceiqaindexbasedonspectralresidual. In
2012 19thIEEE internationalconferenceon imageprocessing(IEEE), 1473–1476
Zhang,L.,Zhang,L.,Mou,X.,Zhang,D.,etal.(2011). Fsim:afeaturesimilarityindexforimagequality
assessment. IEEETrans.ImageProc.20,2378–2386
Frontiers 25

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Stochastic Surprisal: An inferential measurement of Free Energy in Neural Networks"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
