=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Free Energy Risk Metrics for Systemically Safe AI: Gatekeeping Multi-Agent Study
Citation Key: walters2025free
Authors: Michael Walters, Rafael Kaufmann, Justice Sefas

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2025

Key Terms: safe, gaialab, energy, systemically, metrics, gatekeeping, germany, agent, free, study

=== FULL PAPER TEXT ===

FREE ENERGY RISK METRICS FOR SYSTEMICALLY SAFE AI:
GATEKEEPING MULTI-AGENT STUDY
MichaelWalters RafaelKaufmann JusticeSefas ThomasKopinski
GaiaLab PrimordiaCo. UniversityofBritishColumbia GaiaLab
Nuremberg,Germany Cascais,Portugal B.C.,Canada FachhochschuleSu¨dwestfalen
Meschede,Germany
February7,2025
ABSTRACT modelasenergyakintostatisticalmechanics,learningpro-
ceedsastheminimizationofvariationalfreeenergy(VFE)
WeinvestigatetheFreeEnergyPrincipleasafoundation throughvariationalinference1. Fast-forwardtothepresent
for measuring risk in agentic and multi-agent systems. dayandtheBayesianBrainhypothesishasfoundpopular-
From these principles we introduce a Cumulative Risk ityinneurosymbolicmodeling,wherebyperceptionand
Exposuremetricthatisflexibletodifferingcontextsand otherdecision/controlmechanismsaredrivenbypredictive
needs. Wecontrastthistootherpopulartheoriesforsafe (generative)modelsandhierarchicalBayesianuncertainty-
AI that hinge on massive amounts of data or describing resolvingdirectives[Deu10;PF19]. Foranenrichingsum-
arbitrarilycomplexworldmodels.Inourframework,stake- maryaroundFEPanditsconnectionstoBayesian/Active
holdersneedonlyspecifytheirpreferencesoversystemout- Inference,seeGottwaldandBraun[GB20].
comes,providingstraightforwardandtransparentdecision
TheFEPinActiveInferencecanbeappliedinafewdiffer-
rulesforriskgovernanceandmitigation. Thisframework
entways[MTB21;GB20],andinterpretedinmanymore
naturally accounts for uncertainty in both world model
[Da+20]. Theseinterpretationsarevariationsonaclassic
andpreferencemodel,allowingfordecision-makingthat
theme: exploitationvs.exploration. Whetherit’saccuracy
isepistemicallyandaxiologicallyhumble,parsimonious,
vs.complexity,riskvs.ambiguity,intrinsicvaluevs.extrin-
andfuture-proof. Wedemonstratethisnovelapproachin
sicvalue,modelevidencevs.informationgain,orenergy
asimplifiedautonomousvehicleenvironmentwithmulti-
vs.entropy,themechanicsoftheFEPliveinthetensionof
agent vehicles whose driving policies are mediated by
thisduality.
gatekeepers that evaluate, in an online fashion, the risk
to the collective safety in their neighborhood, and inter- Toillustratetherichconnectionbetweenprobabilisticmod-
venethrougheachvehicle’spolicywhenappropriate. We elingandtheFEP,webeginwiththecommonsetupofan
showthattheintroductionofgatekeepersinanAVfleet, agent making observations o at time t, and wishing to
t
evenatlowpenetration,cangeneratesignificantpositive infer the latent state of the world x through actions a
t t
externalitiesintermsofincreasedsystemsafety. accordingtopolicyπ(whichwewilltakeasMarkovian).
The agent’s uncertainty about x given its observations
t
is expressed as the posterior p(x |o )=p(o ,x )/p(o ).
t t t t t
Withthestandardassumptionoftheintractabilityofp(o ),
1 Introduction t
Variational Inference prescribes we instead work with a
tractableapproximation,q(x )thatcanbecomputed.
t
Rooted in physics, the Free Energy Principle (FEP), in
Typically,themismatchbetweenp(x)andq(x)isquanti-
tandemwithBayesianinferenceofworldmodels,offers
fiedbytheKullback-Leiblerdivergence,
acompellingfoundationintheActiveInference(ActInf)
formulationofintelligentsystems[Da+20;Fri+24;GB20; (cid:90) (cid:18) q(x) (cid:19)
Hyl+24; KGT21; Lei22; MTB21; PPF22]. One of the D (q||p)= q(x)ln dx.
KL p(x)
earliestprogenitorsofthisideaistheHelmholtzmachine, x
proposed by Dayan, Hinton, Neal, and Zemel in 1995
[Day+95], connecting the statistical mechanics govern- 1Astheauthorsin[GB20]pointout,thoughVFEisnotthe
ingtheHelmholtzFreeEnergyandperceptualprocessing. sameasHelmholtzFreeEnergy,thetwoconceptscanbeformally
Here,treatingthelog-likelihoodofperceptronsinaneural related.
5202
beF
6
]IA.sc[
1v94240.2052:viXra
Wewilldropthesubscripttgoingforwardinmostcases • (Action) Exploration and actions in the world to
whenitisirrelevant.TheKLdivergenceisconvexforfixed elicitdesirableoutcomesorreduceuncertainty.
p. Thus,theproblemisrecastwithanewproxyobjective:
theminimizationofD (q||p)throughinferenceonq. Withagenerativemodelp(x,o),artificialagentscansimu-
KL
latepotentialfuturesandusetheexpectedfreeenergyto
Finally,theKLdivergencebetweenthevariationalapprox-
(cid:0) (cid:1) evaluatepoliciesandinformtheirdecisions.
imation of the true posterior D q(x)||p(x|o) has an
KL
intrinsicconnectiontothelog-evidencelnp(o):
1.1 Extendingintothefuture
(cid:0) (cid:1) (cid:90) (cid:18) q(x)p(o) (cid:19)
D q(x)||p(x|o) = q(x)ln dx
KL p(x,o) TheVFE-basedobjectivediscussedthusfarhasfocusedon
x
derivingavariationalmodelq(x)throughinferencethat
(cid:90)
=− q(x)lnp(x,o)dx bothexplainsthedataandisbalancedbyanentropicterm.
x However,thisfallsshortofhowafullyequippedActInf
(cid:90) agentwouldoperateintelligently: usingpreference-biased
+ q(x)lnq(x)dx predictedfuturestoinformitsactions. Wedeferthephilo-
x sophicaljustification[PPF22],butinsum,incorporatinga
(cid:90) preferencepriordistributionp˜(o)overexpectedoutcomes
+ q(x)lnp(o)dx
(or states p˜(x)) embeds the goal directives of the agent
x
intotheobjective—elevatingitfrombeingjustaBayesian
⇒E q(x) [lnq(x)−lnp(x,o)]+lnp(o). (1) evidence-buildingmachine.
InferencethenproceedstowardsminimizingtheExpected
Inline(1)wemakeuseofthefactthatp(o)isindependent
FreeEnergy(EFE)acrosscandidatepolicies,wherequality
ofq(x). Rearranging,wecanexpresstheevidenceas
offitisjudgedbytheexpectedloglikelihoodofdesired
lnp(o)=D KL (cid:0) q(x)||p(x|o) (cid:1) −E q(x) (cid:2) lnq(x) observations,andexplorationisencouragedthroughmax-
(cid:3) imizingthedivergencebetweentheexpectedvariational
−lnp(x,o)
posteriorandtheexpectedvariationalprior2.
(cid:0) (cid:1)
=D q(x)||p(x|o) −F(q).
KL EFE ≡E [lnq(x |π)−lnp˜(o ,x )] (3)
t q(ot,xt|π) t t t
The −F(q) term gives a floor for the evidence (since ≈−E (cid:2) lnp˜(o ) (cid:3) (4)
D
KL
(q||p)≥0),andastheevidencelnp(o)isfixedwith
(cid:124)
q(ot,xt|π
(cid:123)
)
(cid:122)
t
(cid:125)
respecttoq(x),minimizingF(q)drivesthefloorupand ExtrinsicValue
minimizestheKLdivergencebetweenqandp. −E D (cid:2) q(x |o )||q(x |π) (cid:3)
q(ot|π) KL t t t
Asmentionedearlier,thefreeenergyinstatisticalmechan- (cid:124) (cid:123)(cid:122) (cid:125)
EpistemicValue
ics is, abstractly, the sum of an accuracy term (energy),
andacomplexityterm(entropy). Forexample,forsome
where p˜(o ,x ) = p(o |x )p˜(x ). Taking a tempo-
distributionϕ,theHelmholtzFreeEnergy, t t t t t
ral mean-field factorization of the variational poste-
1 riorq(x ,π)≈q(π) (cid:81)τ q(x |π)andgenerativemodel
F (ϕ)=⟨E⟩ + H(ϕ) t:τ s=t s
H ϕ β p˜(o ,x )≈ (cid:81)τ p˜(o )q(x |o ), severs the temporal
t:τ t:τ s=t s s s
whereinversetemperatureβ playsaweightingfactorbe- dependence between steps, meaning the optimal path is
(cid:80)
tweenenergyandentropy. Itisthissimilarityinformwhy thatwiththelowestsum t EFE t .
F(q)isalsocalledthevariationalfreeenergy(VFE): Millidge,Tschantz,andBuckley[MTB21]giveconsider-
F(q)=−E [lnp(x,o)]+E [lnq(x)] ablecontemplationtothequestionofextendingtheVFE
q(x) q(x)
intothefutureandthenaturaloriginsoftheEFE3. The
=−E [lnp(x,o)]−H[q(x)]. (2)
q(x)
(cid:124) (cid:123)(cid:122) (cid:125) 2We use an approximation here that the true and approxi-
“Energy”
mateposteriorsaresimilar,q(x|o)≈p(x|o),meaninginference
wassuccessful.Withoutthisassumption,thereisanadditional
TheentropictermisaformofOccam’srazor,encourag-
divergencetermbetweenthesetwoquantities.
ingmodelstomakefewerassumptionsorhavetoomany
3Ultimately,itisarguedthattheEFE—thego-toformulation
extraneous parameters. It also functions like a regular-
inActInf—isbynomeansmandatoryandevenlessnaturalof
izer against overfitting to model evidence by the energy
aconstructionthantheirproposedFreeEnergyoftheExpected
term. IntheActInfframework,agentsaredriventoreduce
Future(FEEF)alternative(nottobeconfusedwiththeFEFdis-
“surprisal”—thediscrepancybetweentheirmodelsandthe
cussedinthismanuscript).Thedifferencebeingthattheextrinsic
world,i.e.VFE—primarilythroughtwomeans([PPF22] valueoftheEFEisthemaximizationofthelogmodelevidence
§2.6,[MTB21]): (Eq. (4)), whereas in the FEEF it is the minimization of the
KL-divergencebetweenthelikelihoodofobservationspredicted
• (Perception)Updatingworldmodelstobetterfitthe underaveridicalgenerativemodelandthemarginallikelihood
evidence. ofobservationspredictedunderthebiasedgenerativemodel—
2
authorsgoontointroduceanadditionalFEP-basedformu- andambiguity(suchasresearchandcorporatestrategy)or
lation,theFreeEnergyoftheFuture(FEF),whichhasan wheredownsideriskisnotdeemedsignificant(suchasarts
objectivedrivenbytheminimizationoftheentropicterm, andentertainment),anEFEformulationwouldencourage
instarkcontrasttoepistemicmaximization: exploration.
FEF ≡E [lnq(x |o )−lnp˜(o ,x )] (5)
t q(ot,xt|π) t t t t
2.1 Adaptingforobservation-space
≈−E (cid:2) lnp˜(o |x ) (cid:3)
q(ot,xt|π) t t
Often it is the case that a preference prior is expressed
+E q(ot|π) D KL (cid:2) q(x t |o t )||q(x t |π) (cid:3) (6) in terms of outcomes, not hidden states. Thus, it use-
ful to express the VFE formulae in observation-space.
NotetheepistemictermsbetweentheEFEandFEFdiffer
FromthedefinitionofEFEinEq.(3)(droppingthetime-
only in their sign. Encouraging the minimization of an
dependence),
information-seeking term seems anathema to an ActInf
agent, yet minimizing the FEF satisfies the FEP-driven E (cid:2) lnq(x|π)−lnp˜(o,x) (cid:3)
q(o,x|π)
goalsof1)boundingthemodelevidence(surprisal),and2)
minimizingthedivergencebetweenavariationalposterior =E q(o,x|π) (cid:2) lnq(x|π)−lnp˜(o)−lnq(x|o) (cid:3)
andatargetmodel(whetherthatisbasedonthetrueworld =E (cid:2) (cid:24)ln(cid:24)q(x (cid:24) |π (cid:24) )−lnp˜(o)−lnq(o|x)
distributionorapreferencepriorinthecontextofActive q(o,x|π)
Inference). −(cid:24)ln(cid:24)q(x (cid:24) |π (cid:24) )+lnq(o|π) (cid:3)
=E (cid:2) −lnp˜(o)−lnq(o|x)+lnq(o|π) (cid:3)
2 CumulativeRiskExposure q(o,x|π)
=−E (cid:2) lnp˜(o) (cid:3) −E (cid:2) D [q(o|x)||q(o|π) (cid:3)
q(o,x|π) q(x|π) KL
Weproposeandshowcaseanarrangementthatrepurposes (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
and reframes the VFE construction laid out above. The Extrinsic InformationGain
canonical Active Inference agent begins with a known
making use of the definitions p˜(x,o) = q(x|o)p˜(o) and
preferencepriorthatinformsitsactionsasexpectedVFE
q(x,o|π) = q(x|π)q(o|x) = q(o|π)q(x|o), and Bayes’
computations. However, by obfuscating the preference
rule. Computationally, one can estimate these values
priorfromtheagent—oratleastthetruestakeholderpref-
throughsamplingofthevariationalpriorandtheproduced
erence prior, if we still want the agent to operate in an
observations. Similardecompositionscanbeachievedfor
ActInffashionwithitsownpreferenceprior—wecanhelp
theFEF:
bufferagainstcertainrewardspecificationpitfalls,likere-
wardhacking,etc. Inessence,thisdefinesaGatekeeper E (cid:2) lnq(x|o)−lnp˜(o,x) (cid:3)
q(o,x|π)
(GK)arrangement,wheretheGKhasaccesstotheagent’s
policiesandcancomputeapolicy’sexpectedfreeenergy =E (cid:2) lnq(x|o)−lnp˜(o|x)−lnq(x|π) (cid:3)
q(o,x|π)
a ev cc a o lu r a d t i i n o g n t a o n i d ts ri h s i k dd m e e n tr p ic re . f E er x e p n r c e e ss p in ri g or va a l s u a es fo a r s m pr o e f fe p r o e l n ic c y e =E q(o,x|π) (cid:2) lnq(o|x)+(cid:24)ln(cid:24)q(x (cid:24) |π (cid:24) )−lnq(o|π)
priordistributionsallowsforawiderangeofpreference −lnp˜(o|x)−(cid:24)ln(cid:24)q(x (cid:24) |π (cid:24) ) (cid:3)
structures,includingrisk-aversion,socialpreferences,and
non-Markovianutilityfunctions[SA23]. =E (cid:2) lnq(o|x)−lnq(o|π)−lnp˜(o|x) (cid:3)
q(o,x|π)
Thefreeenergyriskmetriccanbeutilizedascontextpre- =−E (cid:2) lnp˜(o|x) (cid:3) +E (cid:2) D [q(o|x)||q(o|π)] (cid:3)
scribes,andwedemonstrateasimplemethodwherebya q(o,x|π) q(x|π) KL
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
riskthresholdisdefinedasapointofcriticalitydemanding Extrinsic InformationGain
gatekeeperintervention4.Toourknowledge,thisisthefirst
VFE-basedgatekeepermodelforagenticAIapplications. Betweenthetwodecompositions,weseethesignflipon
theepistemictermpersist.
When defining a risk metric, both the FEF and the EFE
provide viable options. For contexts where exploration Finally,theVFEriskformulationsthusfararelackinga
isdiscouraged,theFEFoffersabetterformsinceitsob- balancingvariablethatweightstheepistemicandextrinsic
jective is minimized through low-entropy futures. This components. In analogy with free energy formulations
may be the better choice for safety-critical applications of thermodynamics, we can introduce an inverse “tem-
whereminimizingunexpectedbehaviorispreferred. Con- perature” to balance the terms of our risk equation. In
versely,indomainswithsignificantstructuraluncertainty abstract,theinstantaneousriskattimet,foravariableset
ϕ=[q,p˜,π]is
whichisarguedtobemorealignedwiththegoalsofanActInf
agent. 1
4Abinaryriskthresholdisnottheonlyoption.Specifically,in G t (ϕ)=⟨E⟩ ϕ,t ± β H[ϕ,t], (7)
asettingwithcontinuouscontrolvariables,itwouldbepossibleto
performasmoothhandover(linearcombination)betweenagent
policyandgatekeeperpolicy.Thisintroducescomplexitiesinthe whereEandHaretheenergeticandentropiccomponents5.
simulationmodelandwillbelefttofuturework. Recall,theEFEandFEFareexpectedfreeenergyforms,
3
whichcanbeγtime-discountedinaggregationacrosstime. 2.3 Extendingtheapproach
WethusdefinetheCumulativeRiskExposure(CRE)
As discussed by Hyland et al. [Hyl+24], minimizing a
τ
G (ϕ,t)= (cid:88) γt′ G (ϕ), (8) joint free energy as a sum of individual agent free ener-
Σ t+t′
giescanavailgame-theoreticallyoptimizedsolutionsthat
t′
wouldotherwisenotbeplayedinselfishpolicies. Indeed,
thoughwewillcommonlydropthetimesubscriptinour joint free energy minimization has been postulated as a
discussions. potentialcoremechanismbehindcollectiveagencyinbi-
ologicalsystems[SL24;ML24]. Itisalsotranslatableto
theCooperativeInverseReinforcementLearningparadigm
2.2 Preferencepriorconstruction
[Had+24],asagentsmodelthepreferencesofhumansand
Choice of preference prior is context-dependent, but a themselves. In our AV experiment, the free energy of
naturalformistheBoltzmanndistributionoversomeloss neighboringvehiclegatekeepersisaggregatedbeforemak-
functionL: ingdecisions,andcouldforinstancedeteravehiclefrom
p˜(L)=e−βL/Z, (9) speedingupbecausetoreducethecollectivefreeenergy,
(cid:88) attheexpenseofreducingtheirown.
Z = e−βLj.
ExtendingCREandVFE-basedmetricshierarchicallyaf-
j
fords a natural and mathematically straightforward ap-
With this formulation, the inverse temperature term in proachtofirst-principlesAIsafety. Severalcontemporary
Eq.(7),whichservestobalancetheextrinsicandintrinsic AIsafetyproposalsfeatureprolificconstructionofproba-
terms,equivalentlyoperatesontheextrinsic,preference- bilisticmodels(themselvesconstructedfromAIs,atleast
basedterminsteadoftheintrinsicterm, inpart). “GuaranteedSafeAI”demandsrigorousworld
G =−E q (cid:2) lnp˜ (cid:3) ± β 1 H T m O o 2 d 3 el ] i . n B g a t y o e c s o ia n n s , tr “ u S c c t ie fo n r ti m st a A ls I a s” fe e ty xe g r u t a c r a a u n ti t o e n es w [D ith a i l n +2 u 4 n ; -
certaintyboundsaccordingtotheirworldmodels,aidedby
⇒βE (cid:2) L (cid:3) ±H+ln(Z). simulation,butarealsoexpectedtorequirepotentiallymas-
q
siveamountsofcompute[Ben24;Ben+24].Elsewhere,the
Consequently,fromEq.(9)βquantifiesatolerancetoloss, GaiaProtocol6ofgloballycoordinated,amortizedlearning,
scalingp˜accordingly,andcanbethoughtofasapreference dependsonLLM-aidedcontext-dependentmodelconstruc-
temperatureofoursystem. Verystrongpreferencebiases tion [KL23; KL24]. There is strong overlap in each of
create a “low temperature” (high β) system that is very these pursuits, grounded in thecreation and exploration
energeticallysensitivetopreferencealignment;conversely, of probabilistic world models, and the VFE framework
weakpreferencebiascreaturesasmoothedoutpreference outlinedhereinprovidesanaturallanguageto1)embed
distribution that is more entropy dominated, with lower safetyspecificationsintoworldmodels,2)directagentic
energeticsensitivity. learningandexplorationintheiraccordance,while3)tak-
ingactionsthatareinthecollectiveinterestthroughthe
Further,theBoltzmanndistributionhasthepropertythat
minimizationofthejointfreeenergy.
theratioofstateprobabilities
p˜(L )
1 =exp(−β(L −L )).
p˜(L ) 1 2 3 GatekeepingExperiment
2
Thus,wecancalibrateβ fromamaximumandminimum Weinvestigatedtheapplicationofthisprincipleinasimu-
lossrange,andthosecorrespondingstakeholder-assigned latedautonomousvehicle(AV)setting,usingapared-back
desirabilities, simulator,highway-env[Leu18],whichisbuiltontopof
(cid:18) p˜ (cid:19) gymnasium[Tow+24]. Codeforthisexperimentisavail-
ln p˜ max =−β(L max −L min ) ableonGithub[Wal24],andasamplevideocanbefound
min
here.
ln(p˜ /p˜ )
⇒β = min max ≥0. Our highway track featured autonomous vehicles with
L −L
max min a variable number of these being gatekeeper controlled.
β isnon-negativesincesincebydefinitionthedesirability Weadopt(andabuse)terminologyfromtheory-of-mind
p˜ ≥p˜ ,andL ≥L . researchtodistinguishAltersandEgosasthetwomain
min max max min
typesofvehiclesontheroad. Altershaveastaticpolicy
5Theinversetemperaturehasaninterestingparallelwiththe and constitute the background traffic of our simulation,
ProbabilityDependencyGraphframework,whereaβtermrepre- whereasEgosarethevehiclesofinterestthatweoptionally
sentsthedegreeofconfidence/beliefinadistribution[Ric22].In
assigngatekeepersto,measure,etc. Ourresultsfindthat
ourconstruction,confidenceinp˜canfactoredinto1/β,butthe
the introduction of gatekeepers controlling Ego policies
inversetemperaturecarriesaslightlydifferentimplication:one
couldbeentirelyconfidentinp˜butstillvalueincludingentropic
contributions. 6Ofwhichsomeoftheauthorsareaffiliated.
4
accordingtoCREhasanincreasinglypositiveimpacton ThefactthatR isnegativeisappropriatelyhandledinthe
C
theroadasdefinedbystakeholder-definedpreferences. rewardnormalizationprocess. Losswasthensimplythe
negativesumofrewards,andconstitutedouronlyobserved
Eachinvestigatedconfigurationwasseededacross1200
variable,
worldsimulations,foradurationof80steps,whichwas (cid:88)
L=− R .
enoughtimetoallowtrafficbehaviorsandconsequences i
to emerge. When computing energy and risk estimates,
Itisworthhighlightingherethattheresultingimproved
every5worldstepsgatekeepersranN =128internal
MC
road safety, as a consequence of gatekeeper decision-
MonteCarlo(MC)trajectoriesouttoaτ =10stephorizon.
making, was achieved with this single aggregate scalar
N isnotexceedinglylarge, butforarelativelyclose
MC
variableanddidnotrequirethesuiteofAVsensorinputs
horizon is sufficient for collecting an expectation of the
initsdecisionevaluation.
upcomingfuture. Thegatekeeperinternaltrajectorieswere
fully observable—though their measurements naturally
onlyconsideredneighborswithinareasonableradius. 3.2 Riskformulation
Sinceourexperimentwasafullyobservableenvironment,
3.1 RewardsandLoss
andweassertexhypothesithatourlossandp˜formulations
aresufficientandaccurate,wecandropanyentropiccon-
Ourrewardscorewasconstitutedfromthreeaspects:target
tributions. Inthiscontext,therefore,CREisidenticalto
speed, collisions, and defensive driving. Ego vehicles
time-discountedexpectedutility7. Additionally,whereas
received a speed reward R in the form of a Gaussian
S
theextrinsictermsinEFE/FEFareexpectationsoverthe
centeredonatargetspeedv :
T
variational model q(x,o|π), we can directly work with
R S (v)=αexp[−(v−v T )2/2σ2], (10) p(o,x|π) since we have a fully observable environment,
anduseMonteCarlomethodstoapproximatep(o,x|π).
where constants α, σ, and v were heuristically chosen.
T The removal of entropy simplifies the determination of
ThecollisionrewardR wassimplyaconstantbasedon
C ourstakeholdertoleranceparameter. Withoutexploratory
collisionstates=s ,
c requirements,thescaleofbetaisirrelevant—aswithen-
(cid:26) −κ ifs=s ergyinmanyothercontexts,weareonlyconcernedwith
R C (s)= 0 otherwis c e relative values, not absolutes8. In other applications, β
maybedeterminedasaforcedconstraint: costindollars,
quantity,etc.
withκheuristicallychosenappropriatelytoascribehigh
disincentive. Takentogether,ourfinalCREistheexpectedutility
Brakingdistance—thedistanceittakestocometoafull τ
stop—is a property that scales quadratically with speed G Σ (L)=−
(cid:88) γt′E
p(L) [lnp˜(L)]
[THH00]. Thisisanimportantpropertytocapture,which t′
wecombinewiththecommonsensethatproximityisin- τ
herentlymorerisky,toformulateourdefensive-driving = (cid:88) γt′E [L] (12)
p(L)
reward:
t′
(cid:20) (cid:21)
(cid:88) 1
R (j)=R −λ w(i,j)2+ζ , (11)
D D,max 2md 3.3 Policies
ij
i∈Vj
The highway-env library has an automated Intelligent
w(i,j)=max(0,v −v )×H(x −x ) DrivingModel(IDMVehicle)[THH00]class,whichem-
j i i j
ploys a combination of deterministic logic to calculate
+max(0,v −v )×H(x −x ),
i j j i accelerationandsteering. Lanechangesaredeterminedin
partaccordingtotheMinimizingoverallbrakinginduced
withscalarλ>0,vehicleindexiofvehiclej’sneighbors bylanechange“MOBIL”model[KTH07],which,asad-
(setV
j
),lanedifferentialm∈{0,1,2,...},andneighbor
vertised,triestoreduceimposedbrakinginitslane-change
distance d ij . w(i,j) returns the magnitude of relative selection.
speed between j and its neighbor, using the Heaviside
binaryfunctionHtocontrolforifaneighborisinfront This vehicle policy is deterministic and has no machine
orbehind. Ifvehiclesj andiaredriftingapart,w(i,j)is learningorsamplinginvolvedinitsdecision-making.How-
0. Theconstantζ addsanadditionalpenaltyforvehicle
7Infutureexperimentsinvolvingpartially-observableenviron-
proximity. Sincethetermsarepenalizing,wesubtractthe
mentsandothersourcesofuncertainty,thevalueofthecomplete
bulkfromamaxrewardR andtruncatetotherange
D,max CREformulationgiveninEq.(8)willbecomemoreevident.See,
R D (j) ∈ [0,R D,max ]. Thefinalresultisafunctionthat forinstance,[KGT21;Da+20;PPF22;TSB20;Saj+21;Uel18;
1) penalizes quadratically with relative speeds between Lan+21;BB18;BB19;BFB11].
neighbors,2)penalizeswithincreasedproximity∝1/d ij , 8The scale and shape of G does become relevant when its
but3)lesssoaslanedifferentialincreases. absolutevaluematters,suchasdeterminingariskthresholdρ∗.
5
ever,thereareseveralknobswecantunetoproducedif- stakeholder. WeoptedforasimpleCREthresholdmethod,
ferentbehaviortypes. FortheAltervehicles,weincreased where crossing the risk threshold, ρ∗, triggers a policy
theirappetiteandaggressionforlanechanges,increasing switchresponse. Toavoiderraticbehavioratthethreshold,
the course difficulty for Egos. We also constructed two i.e. frequentpolicyswitching, weemployedtwothresh-
policies for Ego vehicles called “Defensive” and “Hot- oldsρ∗ = 1.1×ρ∗ andρ∗ = 0.9×ρ∗,suchthatwhen
+ −
shot”. Thesedifferintheircomfortwithbrakingdistance risk crosses ρ∗ from below, the GK engages Defensive
+
andlane-changeaggression—Hotshotvehiclesaremore driving,andsubsequentlycrossingρ∗ fromaboveengages
−
comfortablewithtailgatingadriverinfrontofthemifit Hotshot. Additionally,weuseda10-stepgraduationfor
allows them to approach their target speed or get closer policyparameterdeltas,tosmoothpolicytransitionsand
toalanechangetheywant. Theyarealsomorelikelyto further reduce erratic behavior. We selected a heuristic
acceptanaggressivelanechange. valueofρ∗ = 2, howeverdeterminingρ∗ islikelytobe
morestraightforwardinpracticalapplicationswherethe
In our experiment, a total of 24 vehicles were divided
lossorCREhaveunitswithbearing.
evenly between ego and alter vehicles. Among the ego
vehicles,weexperimentedwithdifferentfractionsofthem
beingunderGKcontrol,alsotermed“online”. Inonecon-
3.5 Results&Discussion
figuration,4/12egovehicleswereonline,andinanother
12/12. EgovehicleswouldstartintheHotshotpolicy,so
Theultimategoalhereisbetterdecision-makingaccording
inthe4/12arrangement,theother8remainedHotshotfor
tostakeholderpreferencesthroughsimulatedfutures. To
the entire run. Those under GK control were available
that end, our main measuring stick is the defined loss
for policy modulation between Hotshot and Defensive,
L and collision results. Two baselines were simulated
basedonthegatekeeper’sCREcomputationfromsimu-
across 1200 world runs, for the Defensive and Hotshot
latedfutures—likeadrivinginstructorcopilotthattakes
policies. In a given baseline, all 12 of the ego vehicles
overwhentheyanticipateupcomingdanger.
would stick to the defined policy throughout, and thus
Sincecollisionsareametricofinterest,conditionswereset noCREcalculationswereperformedforGKoperations.
upsuchthatthesewerenotexceedinglyrareevents.During Realized rewards and loss values were still measured at
arun,4onlineegovehicleswouldbetrackedforacollision, eachstep,however.
theeventofwhichwouldterminatearun. Additionally,if
ThoughtheHotshotpolicyhasaconsistentlyhigherspeed
any6+vehicleswereeverinacollisionstate,thiswould
reward,itsuffersinthedefensiverewardcomparedtothe
beconsideredajamandtherunterminated. Runswerenot
Defensivepolicy,andincurssubstantiallymorecollisions
terminatedonanycollisionbecauseitisstillvaluableto
(Fig.1). Ultimately,theerratic,dangerousHotshotbehav-
measureperformanceofegovehiclesinadaptingtosuch
iorgarnersgreaterlossonaverage.
roadconditions.
Withtheintroductionofonlinegatekeepers,weaspirefor
3.4 GatekeeperPolicyControl the best of both worlds: intelligent policy selection that
respondstoenvironmentconditions. Wefoundaconsider-
Foronlinevehicles,gatekeepersanticipateupcomingrisk ablesignalinsupportofthis,thatbecameincreasinglypro-
through internal simulations, then toggle their vehicle’s nouncedproportionaltoGKpresence. AtfullGKstrength,
policytoDefensiveinriskysituations,orbacktoHotshot crashavoidancewassignificantlyimproved,whilefinding
whendeemedsafeenough. UsingHotshotasanominal opportunitytoexcelindefensivedrivingandtargetspeed.
policymayseemodd,butitgivesastrongercounterbalance
Forthemostpart,theDefensiveBaselineisalwaysgoing
toobservethephenomenonofinterest9.
to be hard to surpass: It is expected to have the fewest
GatekeepersrunN internalMonteCarlotrajectories crashes and the highest R . Thus, gatekeepers need to
MC D
at regular, frequent intervals in the world simulation to performcomparativelywellinthosetwodimensionswhile
computeaCREestimate,followingEq.(12). Valuesfor ekingoutgainsinR —whichisatoddswithR andR .
S D C
a given trajectory’s risk are accumulated out to an MC Nonetheless,theOnline-12configurationhandledthisre-
horizon τ = 10 steps. Each vehicle’s actions are not in markablywell,especiallyforthefirsthalfofthesimula-
avacuum. Sharinglocalobservationsandpredictionsby tionwhereittrackedHotshot-levelR whileapproaching
S
openingchannelsofcommunicationthroughgatekeepers Defensive-levelR . Thissuperiorperformancecombina-
D
enhancesdecision-makingthroughacollectiveintelligence. tionwasmoststronglyexhibitedintheLossminimumby
AftercomputingindividualCREs,wereplaceeachwith Online-12aroundStep25thatsubstantiallyoutperformed
theaverageoftheirlocalneighborhoodsandhaveonline bothbaselines. Fromvisualobservations,thefirsthalfof
vehiclesmakepolicydecisionsfromthisaverage. thesimulationisthemoredynamicportionofthesimu-
lation,requiringegostonavigatearoundthemselvesand
Converting from a unitless CRE value to a policy deci-
alters more (since they have a higher target speed than
sion is not self-evident, and is open to the needs of the
alters),versusthelatterportionwheretheroadapproaches
9Asourconstructioncouldalsoapplytogatekeepinghuman more of a steady-state. (Example video.) The selection
drivers,theHotshotpolicyisnotabadmodelofstandarddriver ofρ∗ = 2yieldedmodestpolicyswitchingactivity,and
behaviorinmanypartsoftheworld. the“DefensiveFraction”inFig.1indicatesthattypically
6
0.9
0.8
0.7
DR
Online-4 Online-12 Def. Hotshot
0.6
0.4
0.2
0.0
SR
0.200
0.175
0.150
0.125
ssoL
1.50
1.75
2.00
2.25
]ygrenE[E
2.25
2.00
1.75
1.50
ksiR
0.4
0.2
0.0
0 10 20 30 40 50 60 70
Step
evisnefeD
noitcarF
750
500
250
0
0 10 20 30 40 50 60 70
Step
dehsarC
Figure1:Baselineandgatekeeperresults.Gatekeeperrunshadeither4/12or12/12egovehiclesonline.R ,R ,Loss,Crashed,
D S
andFractionDefensiveareaveragedrealizedvalues.EachE[Energy]andRiskmeasurementisacrossN MCtrajectories.The
MC
FractionDefensiveistheproportionofegovehiclesintheDefensivepolicy.Crashedisacumulationofhowmanyworldshavehad
anegocrashatorbeforeagivenstep.Valuesareaveragedacross1200worlddraws,90%CIdisplayed.
between10-40%ofegoswouldbeinDefensivemodefor 4 Conclusion
thebulkoftherun.
The Free Energy Principle, as one of the foundational
Collisions(“Crashed”,Fig.1)couldnotbewhollyelimi-
underpinningsofActiveInference, drawspowerfulcon-
nated,butthesewerepresentevenintheDefensivebase-
nectionsbetweenphysicalenergeticlawsandintelligent
line,sothisisexpected. TheOnline-4configurationwas
action,withexplanationsforexploitation-explorationnat-
slightlybutmeasurablybetterthantheHotshotbaseline
urally emergent. Encoding stakeholder preferences via
inthis,thoughOnline-12keptintowwiththeDefensive
the preference prior provides a highly flexible means to
baseline for the first half of the duration before diverg-
direct agentic learning. The Cumulative Risk Exposure
ing. Inpracticalapplications,ifstakeholderswanttopush
metricintroducedleveragesthesefoundationstocreatean
somethinglikecollisionlikelihooddownevenfurther,they
interpretable,modularutilitytoscorepoliciesaccording
needonlyupdatetheirpreferenceprior,orthelossfunction
tobiasedfutures. Thepreference-temperatureandtoler-
penaltyforcollision,κ.
ancemechanicsoutlinedalsointroduceaconceptualand
The Energy and Risk figures are from gatekeeper MC instructionalfootholdforusage.
estimates. Risk calculations consider trajectories out to
StakeholdersandAIagentscanemploythissafetymetric
τ =10steps,soweshouldexpectthatearlyonwithvehi-
to anticipate upcoming high risk situations and respond
clesinHotshotpolicythatitanticipatesriskthatreflects
intelligently,asdemonstratedbyourautonomousvehicle
thebaseline10stepsahead. Indeedthisbehaviortracksas
experiment,whichsawincreasinglysuperiordrivingper-
theinitialpeak,subsequentdip,andplateauareanticipated
formanceproportionaltoonlineusage. Thisprinciplehas
bytheRiskτ stepsinadvance. Tryingtocorrelatespikes
immensepotentialacrossagenticapplicationsasaquick
in Risk for Online modes with spikes in future baseline
andeffectiveutilityforgaugingriskwhich,incontrastto
Lossbecomeslessaccuratefurtherintothesimulationas
simplelossmeasures,isbiasedtowardsstakeholderprefer-
theirworldscontinuetoincreasinglydivergeaftert=0.
ences,providingstraightforwardandtransparentdecision
Theresultsshowacleartrend: theeffectofgatekeepers rulesforriskgovernanceandmitigation.
produces increasingly safer roads for everyone through
superior driving according to our embedded preference.
References
TheycanscorehighlyinR ,whileincorporatingsmarter,
S
safer driving when needed, reducing collisions, improv-
ingtheirR scoring,andultimatelyachievingbetterloss [BB19] ManuelBaltieriandChristopherL.Buckley.
D
resultsthaneitherbaselinepolicy. “ActiveInference:ComputationalModelsof
MotorControlwithoutEfferenceCopy”. In:
7
2019ConferenceonCognitiveComputational [Hyl+24] David Hyland et al. “Free-Energy Equilib-
Neuroscience. Berlin,Germany,2019. DOI: ria:TowardaTheoryofInteractionsBetween
10.32470/CCN.2019.1144-0. Boundedly-RationalAgents”. In:ICML2024
[BB18] ManuelBaltieriandChristopherL.Buckley. WorkshoponModelsofHumanFeedbackfor
“TheModularityofActionandPerceptionRe- AIAlignment. 2024. URL:https://openreview.
visitedUsingControlTheoryandActiveIn- net/forum?id=4Ft7DcrjdO.
ference”. In:The2018ConferenceonArtifi- [KGT21] RafaelKaufmann,PranavGupta,andJacob
cialLife. The2018ConferenceonArtificial Taylor. “AnActiveInferenceModelofCol-
Life. Tokyo,Japan,2018, pp.121–128. DOI: lectiveIntelligence”. In:Entropy23.7(7July
10.1162/isal a 00031. 2021), p. 830. ISSN: 1099-4300. DOI: 10.
[Ben24] YoshuaBengio. TowardsaCautiousScientist 3390/e23070830.
AI with Convergent Safety Bounds. https:// [KL23] RafaelKaufmannandRomanLeventov. Gaia
yoshuabengio.org/2024/02/26/towards-a- Network: A Practical, Incremental Pathway
cautious-scientist-ai-with-convergent-safety- to Open Agency Architecture. Dec. 2023.
bounds/. Feb.2024. URL: https://www.lesswrong.com/posts/
[Ben+24] YoshuaBengioetal. CanaBayesianOracle AKBkDNeFLZxaMqjQG/gaia-network-a-
Prevent Harm from an Agent? Aug. 2024. practical-incremental-pathway-to-open-
DOI:10.48550/arXiv.2408.05284. agency.
[BFB11] HarrietBrown,KarlFriston,andSvenBest- [KL24] RafaelKaufmannandRomanLeventov. Gaia
mann. “ActiveInference,Attention,andMo- Network: An Illustrated Primer. Jan. 2024.
torPreparation”. In:FrontiersinPsychology URL: https://forum.effectivealtruism.org/
2 (2011). ISSN: 1664-1078. DOI: 10.3389/ posts/BaoA3gz7xRaqn764J/gaia-network-
fpsyg.2011.00218. an-illustrated-primer.
[Da+20] Lancelot Da Costa et al. “Active Inference [KTH07] ArneKesting,MartinTreiber,andDirkHel-
on Discrete State-Spaces: A Synthesis”. In: bing. “General Lane-Changing Model MO-
JournalofMathematicalPsychology99(Dec. BIL for Car-Following Models”. In: Trans-
2020), p. 102447. ISSN: 0022-2496. DOI: portationResearchRecord1999.1(Jan.2007),
10.1016/j.jmp.2020.102447. pp.86–94. ISSN:0361-1981. DOI:10.3141/
1999-10.
[Dal+24] DavidDalrympleetal. TowardsGuaranteed
Safe AI: A Framework for Ensuring Robust [Lan+21] Pablo Lanillos et al. Active Inference in
and Reliable AI Systems. July 2024. DOI: Robotics and Artificial Agents: Survey and
10.48550/arXiv.2405.06624. Challenges. Dec.2021. DOI:10.48550/arXiv.
2112.01871.
[Day+95] Peter Dayan et al. “The Helmholtz Ma-
chine”. In: Neural Computation 7.5 (Sept. [Lei22] Felix Leibfried. Variational Inference for
1995),pp.889–904. ISSN:0899-7667. DOI: Model-FreeandModel-BasedReinforcement
10.1162/neco.1995.7.5.889. Learning. Dec.2022. DOI:10.48550/arXiv.
2209.01693.
[Deu10] SidDeutsch. “BayesianBrain:Probabilistic
ApproachestoNeuralCoding(Doya,K.,Eds., [Leu18] Edouard Leurent. An Environment for Au-
etal.;2007)[BookReview]”. In:IEEEPulse tonomous Driving Decision-Making. https:
1.3(2010),pp.64–65. DOI:10.1109/MPUL. //github.com/eleurent/highway-env. 2018.
2010.939182. [ML24] PatrickMcMillenandMichaelLevin.“Collec-
[Fri+24] Karl J. Friston et al. “Designing Ecosys- tiveIntelligence:AUnifyingConceptforInte-
tems of Intelligence from First Principles”. gratingBiologyacrossScalesandSubstrates”.
In: Collective Intelligence 3.1 (Jan. 2024). In:CommunicationsBiology7.1(Mar.2024),
ISSN:2633-9137,2633-9137. DOI:10.1177/ p. 378. ISSN: 2399-3642. DOI: 10.1038/
26339137231222481. s42003-024-06037-4.
[GB20] Sebastian Gottwald and Daniel A. Braun. [MTB21] Beren Millidge, Alexander Tschantz, and
“The Two Kinds of Free Energy and the Christopher L. Buckley. “Whence the Ex-
Bayesian Revolution”. In: PLOS Computa- pectedFreeEnergy?”In:NeuralComputation
tionalBiology16.12(Dec.2020). ISSN:1553- 33.2(Feb.2021),pp.447–482. ISSN:0899-
7358. DOI:10.1371/journal.pcbi.1008420. 7667. DOI:10.1162/neco a 01354.
[Had+24] Dylan Hadfield-Menell et al. Cooperative [PF19] Thomas Parr and Karl J. Friston. “Gener-
InverseReinforcementLearning. Feb.2024. alisedFreeEnergyandActiveInference”. In:
DOI:10.48550/arXiv.1606.03137. BiologicalCybernetics113.5–6(Dec.2019),
pp. 495–513. ISSN: 0340-1200, 1432-0770.
DOI:10.1007/s00422-019-00805-w.
8
[PPF22] ThomasParr,GiovanniPezzulo,andK.J.Fris-
ton. ActiveInference:TheFreeEnergyPrinci-
pleinMind,Brain,andBehavior. Cambridge,
Massachusetts:TheMITPress,2022. 296pp.
ISBN:978-0-262-04535-3.
[Ric22] Oliver E. Richardson. Loss as the Inconsis-
tencyofaProbabilisticDependencyGraph:
ChooseYourModel,NotYourLossFunction.
Feb. 2022. URL: http://arxiv.org/abs/2202.
11862.
[Saj+21] NoorSajidetal. “ActiveInference:Demys-
tifiedandCompared”. In:NeuralComputa-
tion 33.3 (Mar. 2021), pp. 674–712. ISSN:
0899-7667, 1530-888X. DOI: 10.1162/
neco a 01357.
[SL24] Lakshwin Shreesha and Michael Levin.
“StressSharingasCognitiveGlueforCollec-
tiveIntelligences:AComputationalModelof
StressasaCoordinatorforMorphogenesis”.
In: Biochemical and Biophysical Research
Communications731(Oct.2024),p.150396.
ISSN:0006-291X. DOI:10.1016/j.bbrc.2024.
150396.
[SA23] JoarSkalseandAlessandroAbate. “Onthe
LimitationsofMarkovianRewardstoExpress
Multi-Objective, Risk-Sensitive, and Modal
Tasks”. In:ProceedingsoftheThirty-Ninth
ConferenceonUncertaintyinArtificialIntel-
ligence. UncertaintyinArtificialIntelligence.
July 2023, pp. 1974–1984. URL: https://
proceedings.mlr.press/v216/skalse23a.html.
[TO23] MaxTegmarkandSteveOmohundro. Prov-
ablySafeSystems:TheOnlyPathtoControl-
lableAGI. Sept.2023. DOI:10.48550/arXiv.
2309.01933.
[Tow+24] MarkTowersetal. Gymnasium:AStandard
Interface for Reinforcement Learning Envi-
ronments. https://arxiv.org/abs/2407.17032.
2024.
[THH00] MartinTreiber,AnsgarHennecke,andDirk
Helbing. CongestedTrafficStatesinEmpir-
ical Observations and Microscopic Simula-
tions. Aug.2000. DOI:10.48550/arXiv.cond-
mat/0002177.
[TSB20] Alexander Tschantz, Anil K. Seth, and
Christopher L. Buckley. “Learning Action-
OrientedModelsthroughActiveInference”.
In:PLOSComputationalBiology16.4(Apr.
2020), e1007805. ISSN: 1553-7358. DOI:
10.1371/journal.pcbi.1007805.
[Uel18] Kai Ueltzho¨ffer. “Deep Active Inference”.
In:BiologicalCybernetics112.6(Dec.2018),
pp. 547–573. ISSN: 0340-1200, 1432-0770.
DOI:10.1007/s00422-018-0785-7.
[Wal24] MichaelWalters. AutonomousVehicleStudy
Repository. https://github.com/m-walters/av-
agents. May2024.
9

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Free Energy Risk Metrics for Systemically Safe AI: Gatekeeping Multi-Agent Study"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
