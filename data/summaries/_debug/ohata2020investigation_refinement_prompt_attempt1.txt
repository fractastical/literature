=== IMPORTANT: ISOLATE THIS PAPER ===
You are revising a summary for ONLY the paper below. Do NOT reference or use content from any other papers.
Paper Title: Investigation of the Sense of Agency in Social Cognition, based on frameworks of Predictive Coding and Active Inference: A simulation study on multimodal imitative interaction
Citation Key: ohata2020investigation
REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Issues to fix:
1. CRITICAL: The current summary has severe repetition issues. You MUST eliminate all repeated sentences, phrases, and paragraphs. Each idea should be expressed only once. If you find yourself repeating content, remove the duplicates entirely. Focus on variety and uniqueness in your wording.
2. Severe repetition detected: Same phrase appears 388 times (severe repetition)

Current draft (first 2000 chars):
Okay, let's begin. I will follow these instructions precisely.## Investigation of the Sense of Agency in Social Cognition, based on frameworks of Predictive Coding and Active Inference: A simulation study on multimodal imitative interaction**1. Introduction**The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “The authors state: “T...

Key terms: multimodal, interaction, simulation, investigation, imitative, cognition, complexity, interactions

=== FULL PAPER TEXT ===
INVESTIGATION OF THE SENSE OF AGENCY IN SOCIAL
COGNITION, BASED ON FRAMEWORKS OF PREDICTIVE CODING
AND ACTIVE INFERENCE: A SIMULATION STUDY ON
MULTIMODAL IMITATIVE INTERACTION
WataruOhataandJunTani∗
CognitiveNeuroroboticsResearchUnit
OkinawaInstituteofScienceandTechnologyGraduateUniversity,Okinawa,Japan
{wataru.ohata, jun.tani}@oist.jp
ABSTRACT
When agents interact socially with different intentions (or wills), conflicts are difficult to avoid.
Althoughthemeansbywhichsocialagentscanresolvesuchproblemsautonomouslyhasnotbeen
determined,dynamiccharacteristicsofagencymayshedlightonunderlyingmechanisms. Therefore,
thecurrentstudyfocusedonthesenseofagency,aspecificaspectofagencyreferringtocongruence
betweentheagent’sintentioninactingandtheoutcome,especiallyinsocialinteractioncontexts.
Employingpredictivecodingandactiveinferenceastheoreticalframeworksofperceptionandaction
generation,wehypothesizethatregulationofcomplexityintheevidencelowerboundofanagent’s
modelshouldaffectthestrengthoftheagent’ssenseofagencyandshouldhaveasignificantimpact
on social interactions. To evaluate this hypothesis, we built a computational model of imitative
interactionbetweenarobotandahumanviavisuo-proprioceptivesensationwithavariationalBayes
recurrentneuralnetwork,andsimulatedthemodelintheformofpseudo-imitativeinteractionusing
recorded human body movement data, which serve as the counterpart in the interactions. A key
featureofthemodelisthatthecomplexityofeachmodalitycanberegulateddifferentlybychanging
thevaluesofahyperparameterassignedtoeachlocalmoduleofthemodel. Wefirstsearchedforan
optimalsettingofhyperparametersthatendowthemodelwithappropriatecoordinationofmultimodal
sensation. These searches revealed that complexity of the vision module should be more tightly
regulatedthanthatoftheproprioceptionmodulebecauseofgreateruncertaintyinvisualinformation
flow. Using this optimally trained model as a default model, we investigated how changing the
tightness of complexity regulation in the entire network after training affects the strength of the
sense of agency during imitative interactions. The results showed that with looser regulation of
complexity,anagenttendstoactmoreegocentrically,withoutadaptingtotheother. Incontrast,with
tighterregulation,theagenttendstofollowtheotherbyadjustingitsintention. Weconcludethatthe
tightnessofcomplexityregulationsignificantlyaffectsthestrengthofthesenseofagencyandthe
dynamicsofinteractionsbetweenagentsinsocialsettings.
Keywords senseofagency,predictivecoding,activeinference,multimodalperception,human-robot
interaction,recurrentneuralnetwork,variationalBayes
1 Introduction
Humansaresocialbeingsbynature,andeachindividualregularlyinteractswithothersinvariousways. Eventhough
individuals act based on their intentions or wills, they sometimes acts in agreement with others, doing something
collaboratively,whileatothertimestheydisagree. Eithercasemaybeconsciousorunconscious. Whatdetermines
∗Correspondingauthor
0202
guA
11
]OR.sc[
2v23610.2002:viXra
suchthetypeofinteractionandhow? Toevaluatethisproblem,weconsiderpossiblerelationshipsbetweenagencyof
eachindividualandsocialinteractionsbetweenindividuals. Then,weintroducepredictivecodingandactiveinference
toformulatetheprobleminacomputationalframeworkandweproposeaspecifichypothesistopredictthetypeof
interaction. Wedeliveraschematicofourcomputationalmodelandexperimentalsetuptoevaluatethehypothesisand
concludethesectionbyhighlightingsomecriticalfindings.
1.1 Agencyinsocialcognition
Insocialinteractions,agentssometimescooperatebysharingintentionssoastoderivemutualbenefits,whileatother
timestheycauseconflictsbyfollowingtheirownintentionsandignoringtheinterestsofothers. Althoughhowsuch
complexitiesinsocialinteractionsemergeisnotobvious,wehypothesizedthatdynamiccharacteristicsofagencyin
socialinteractionsmightshedlightonunderlyingmechanisms. Recently,thestudyofagencyhasattractedconsiderable
attentionfromresearchersinvariousdisciplines,includingphilosophy,psychology,cognitivescience,andneuroscience.
Specifically,thesenseofagency(SoA)(Gallagher,2000;Synofziketal.,2008;Mooreetal.,2009)referstocongruence
betweenanagent’sintentionorbeliefinanactionanditsanticipatedoutcome,whichendowstheagentwiththesense
that“Iamtheonegeneratingthisaction”. Alongwithstudiesinexperimentalpsychology,buildingacomputational
modelofSoAisalsoimportantinordertoexplorethenatureofagency(LegaspiandToyoizumi,2019). Inthestudy
ofcomputationalmodelsofagents,predictivecoding(PC)(RaoandBallard,1999;TaniandNolfi,1999;Leeand
Mumford,2003;Friston,2005;Hohwy,2013;Clark,2015;Friston,2018)andactiveinference(AIF)(Fristonetal.,
2009,2010;BaltieriandBuckley,2017;Buckleyetal.,2017;Pezzuloetal.,2018;Oliveretal.,2019)haverecently
attracted considerable attention since they provide rigid theoretical frameworks for defining perception and action
generation. IntheframeworkofPCandAIF,anagent’sintentionorbeliefcanbeformulatedasapredictivemodel,and
itisthoughtthatcongruencebetweenthepredictionofactionoutcomesandobservationsreinforcestheSoA(Friston,
2012).
Insituationsinvolvingsocialinteraction,however,wheremultipleagentsinteract,itbecomeschallengingforeachagent
tosustainitsSoA,becauseotheragents,havingtheirownintentions,maynotactasdesired. Ifsocialagentsarerequired
tocoordinateactionssoastoobtainbenefitsbyminimizingpossibleconflicts,wespeculatedthatthestrengthofagency
shouldbearbitratedamongthoseagentsduringsomeconflicts. Letusconsideradyadicsynchronizedimitationasan
exampleofsocialinteraction,whereintwoagentsattempttosynchronouslyimitateoneanother’smovementpatterns
usingpredictionsbasedonpriorlearning. Inaddition,letusassumeasettinginwhichtwoagentsimitateoneanotherin
sequencesofmovementpatternsbasedonmemorizedtransitionrules,inwhichunpredictabletransitionsinmovement
patternsareincluded. Forexample,eithermovementpatternBorCcanappearaftermovementpatternA(seealso
Figure3.2(A)).Inthissetting,agent1mayoptformovementpatternBafterA,actingasaleaderwithstrongagency
andagent2mayjustfollowagent1bygeneratingpatternBwithweakagency. Thiscanresultinsuccessfulmutual
imitationwithoutgeneratingconflict. However, ifbothagentsmaintainstrongagency, eachmaygenerateitsown
pattern(BorC)withoutcompromise,resultinginconflict.
Whileinvestigatingagencyinsocialinteractions,weconcludedthatitwouldalsobeworthwhiletoconsiderhowagency
andmirrorneuronsystems(MNS)(RizzolattiandFogassi,2014;Kilneretal.,2007)mightberelated,sinceMNSare
thoughttocontributetovarioustypesofsocialcognitivebehavior,includingimitation(Hurley,2005). MNSwasfirst
discoveredinareaF5ofthemonkeypremotorcortex(DiPellegrinoetal.,1992;Galleseetal.,1996),anditisactivated
whenmonkeysexecutetheirownactions,aswellaswhenobservingthoseperformedbyothers. BecauseMNSuses
observationsofanactiontogeneratethesameaction,itmayparticipateinimitativebehaviors,whicharethoughttobe
thebasisofvarioushighercognitivefunctions(AlyandTapus,2015;Kohleretal.,2002;Oztopetal.,2006,2013).
AnaturalquestionregardingsuchanMNSmechanismishowtheagencyofeachindividualcanbeexertedifMNS
isthedefaultmode. Intentiontogenerateanactioncouldconflictwithanautomaticresponsetoimitateanaction
demonstratedbyothers. AlthoughmodelingstudiesofMNShavealsobeenconductedfromtheviewpointofPCand
AIFusingBayesianframeworks(Fristonetal.,2011;Kilneretal.,2007)andbyusingdeterministicrecurrentneural
networks(RNNs)(ItoandTani,2004;AhmadiandTani,2017;Hwangetal.,2020),theaforementionedproblemof
agencyhasnotbeenwellconsidered.
1.2 Predictivecodingandactiveinference
Next,letusconsiderhowthestrengthofagencycanbemodeledusingaframeworkofPCandAIF.Forthispurpose,
firstwebrieflyreviewtheconceptsofPCandtheirmathematicalproperties,asfollows. InPC,perceptionisthought
tobeachievedviaiterativeinteractionsbetweenapriorexpectationofasensationandaposteriorinferencefroma
sensoryoutcome. Thepriorexpectationofthesensationcanbemodeledbystatisticalgenerativemodelsthatmapthe
priorofthelatentvariabletothesensoryexpectation. Theposteriorinferencecanbecarriedoutbytakingtheerror
betweentheexpectedsensationanditsoutcomeandbyupdatingtheposteriorofthelatentvariableinthedirection
2
ofminimizingtheerror,undertheconstraintofminimizingKullback-Leiblerdivergence(KLdivergence)between
theposteriordistributionandthatoftheprior. Typically,boththepriorandtheposteriorarerepresentedbyGaussian
distributionswithparametersofmeanandvariance,aswillbedescribedlater. Thisisequaltomaximizingthelower
boundofthelogarithmofmarginallikelihood(a.k.aevidencelowerbound)expressedbytwoterms: accuracyand
complexity.
(cid:90) p (X,z)
lnp (X)≥ q (z|X)ln θ dz (1)
θ φ q (z|X)
φ
(cid:124) (cid:123)(cid:122) (cid:125)
Evidencelowerbound
=E [lnp (X|z)]−D [q (z|X)(cid:107)p(z)] (2)
qφ(z|X) θ KL φ
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Accuracy Complexity
where X is the observation, z is the latent variable, q (z|X) is the approximate posterior, and θ and φ are the
φ
parametersofthemodel. Accuracyistheexpectationoflog-likelihoodwithrespecttotheapproximateposterior,which
representsreconstructionoftheobservationwiththeapproximateposterior. ComplexityistheKLdivergencebetween
theapproximateposteriorandtheprior,whichservestoregularizethemodel. Importantly,inmaximizingthelower
bound,theinterplaybetweenthesetwotermscharacterizeshowthemodelbehavesinlearningandprediction(Higgins
etal.,2017).Maximizationofthelowerboundisequivalenttominimizationoffree-energyproposedbyFriston(Friston,
2005).
Next,AIFisdescribedbriefly. AIFexplainsthatactionormotorcommandsshouldbegeneratedsothattheirsensory
outcomescoincidewithexpectedoutcomes. Asasimpleexample,considerhowexpectedproprioceptioninterms
ofrobotjointanglescanbeachievedbygeneratingsufficientmotortorque. Thiscanbedonewithaninversemodel
thatmapsexpectedjointanglestotherequiredmotortorques,orbyemployingaPIDcontrollersuchthatnecessary
motortorquetominimizeerrorsbetweenexpectedjointanglesandactualanglescanbederivedbymeansofasimple
errorfeedbackmechanism. BothPCandAIFattempttominimizeerrorbetweentheexpectedsensationandtheactual
outcome;however,inPCthisisaccomplishedbychangingtheintentionviatheposteriorinferenceandbychanging
theenvironmentstatethroughactioninAIF.WhenPCandAIFareperformedintandem,whileanagentactsonthe
environment,anagentwithamorepreciseprior(smallervariance)shouldbehavewithstrongagency,beinglesslikely
tochangeitsownintention,andmorelikelytochangetheenvironmentalstate. Ontheotherhand,anagentwithaless
preciseprior(withlargervariance)shouldbehavewithweakeragency,beingmorelikelytochangeitsownintention
thantheenvironmentalstate.
1.3 Relatedwork
AlthoughPCandAIFhaveattractedmuchattentionfrombrainmodelingresearchers,itisunusualtoseethemused
in computational studies employing learnable neural network models, especially those that can handle continuous
spatio-temporalpatternscharacterizedinmultimodalsensoryinputs. Tothisintent,AhmadiandTani(Ahmadiand
Tani,2019)recentlyproposedso-called,Predictive-coding-inspiredVariationalRecurrentNeuralNetwork(PV-RNN).
PV-RNNisatypeofvariationalrecurrentneuralnetworkthatapproximatestheposteriorateachtimestepinsequential
patternswithvariationalinference,andisformalizedbyemployingpredictivecoding.Bymakingpredictionsintheform
ofthesequentialprior(Chungetal.,2015)withtime-varyingparameterizedGaussiandistribution,PV-RNNenablesthe
modeltorepresentstrengthofintentionoragency. AhmadiandTani(2019)introducedahyperparameterwcalledthe
meta-prior,whichweightsregulationofthecomplexitytermintheevidencelowerbound(thesecondterminequation
2). Theyfoundthatamodeltrainedwithlooserregulationofthecomplexityterm,achievedbysettingthemeta-priorto
alargervalue,developsmoredeterministicdynamicswithhigherestimatedprecisioninthesequentialprior,whereas
a model trained with tighter regulation, accomplished by setting the meta-prior to a smaller value, develops more
probabilisticdynamicswithlowerestimatedprecision. Inanotherattempttoimplementfree-energyminimizationwith
anartificialneuralnetwork,Pittietal. (Pittietal.,2020)proposedaspikingneuralnetworkarchitecturethatminimizes
free-energytomodelthefronto-striatalsysteminthebrain.
ChameandTani(ChameandTani,2019)usedPV-RNNtoconductahuman-robotinteractionexperimentusingasingle
perceptualchannelofproprioception. Althoughtheiranalysisoftheexperimentswaspreliminary,theysuggestedthat
whenthemodelistrainedunderlooserregulationofthecomplexityterm,themodeltendstobehaveegocentrically,
adaptinglesstoproprioceptiveinputs,whereasundertighterregulationofthecomplexityterm,thenetworktendsto
behavemorepassively,adaptingmoretoproprioceptiveinputs. However,suchnetworkcharacteristics,oncedeveloped
throughlearningunderparticularconditionstoregulatethecomplexityterm,cannotbechangedthereafter. Insocial
interactions,itisnaturalthatagentsactdifferently,dependingonthesocialcontextatagivenmoment. Sometimesthey
tendtopreservetheirpriorintentionbyactingperversely,andatothertimestheychangeitmoreeasilybyadaptingto
intentionsofothers. Thecurrentstudyexamineswhethersuchshiftsinstrengthofagencycanbeachievedduringthe
interactionphasebychangingthevalueofthemeta-priorfromthedefaultstrengthsetinthelearningphase.
3
1.4 ImitativeinteractionusingavariationalBayesrecurrentneuralnetwork
Here,weexplainthegeneralconceptunderlyingourcomputationalmodel,experimentaldesign,andobtainedresults.
Wefirstproposedanartificialneuralnetworkmodelthatcanbeappliedtoanimitativeinteractiontaskusingmultimodal
sensationofvisionandproprioceptionbyextendingPV-RNN.PV-RNNisusedbecausetoourknowledgethisnetwork
modelistheonlyRNN-typemodelthatcaninstantiatepredictivecodingandactiveinferenceinacontinuousspatio-
temporaldomainbyfollowingaBayesianframework. Theproposedmodeliscomprisedofamulti-layeredPV-RNN
withabranchingstructure,inwhichtwobranchesresponsibleforperceptionofvisionandproprioceptionareconnected
throughanassociativemodule. Inaddition,thecurrentmodelinheritsthestructureofMultipleTimescaleRecurrent
NeuralNetwork(MTRNN)(YamashitaandTani,2008). MTRNNextractsatemporalhierarchycontainedinsequential
patterns(YamashitaandTani,2008;NishimotoandTani,2009;Hwangetal.,2020). Byassigningfastertimescales
to the peripheral sensory modules for vision and proprioception and slower timescales to the associative module,
hierarchicalmultimodalintegrationfromsensory-motorlevelstoabstractintentionlevelsshouldbeachieved.
Theentirenetworkmodelisconsideredagenerativemodelthatpredictsincomingvisualsensationandproprioception
simultaneouslythroughagenerativeprocessalongwithatop-downpathwayfromtheassociativemoduletobothofthe
sensorymodules. Theresultantpredictionerrorforeachsensorymodalityisback-propagatedthroughtime(Werbos,
1974;Rumelhartetal.,1985)(BPTT)andthrougheachmoduletotheassociativemodule,bywhichthelatentstatein
eachmoduleismodulatedsoastomaximizetheevidencelowerboundshownintheequation2. Thiscorrespondsto
theposteriorinference. Thenetworkistrainedthroughsupervisedlearningbymaximizingtheevidencelowerbound.
However,coordinatingmultimodalsensationsappropriatelyisstillnotaneasyproblemwhenintrinsiccomplexityand
randomnessinspatio-temporalpatternsdifferineachmodality(Ogataetal.,2010;Valentinetal.,2019). Studieson
cueintegrationinmultimodalsensationhaveshownthatinferencesaboutthehiddenstateoftheenvironmentshould
beaccomplishedbyassigningthegreatestweighttoinformationobtainedfromthemostreliablesensorymodality
(Battagliaetal.,2003). Inpredictivecoding,reliabilitycanberepresentedbytheaccuracyestimatedforeachmodality
ofthesensorymodel,providedthatitsgeneralizationispreservedbyminimizingmodelcomplexityadequatelywhen
theamountoftrainingdataislimited. Wespeculatethatthecomplexitytermshouldberegulatedadequatelyforeach
sensorymodalityduringtraining, suchthatthebestgeneralizationcanbeachievedforeach. SinceeachPV-RNN
modulecanbeassigneddifferentvaluesofthemeta-prior,theabovecouldbeachievedbysearchingforanadequate
valueofeachmeta-priorthoughtrialanderrorduringthelearningphase.
Theproposedmodelwasevaluatedbysimulating“pseudo"imitativeinteractionusingvisuo-proprioceptivesequence
patterns recorded from human demonstrators. Although human-robot interaction should be studied in a physical
systemtoallowthehumanandtherobottorespondtoeachotherinanonlinefashion,itisdifficultforthecurrent
systemtoworkinrealtimebecauseinferenceoftheposteriorusingPV-RNNiscomputationallyintensive,especially
whenpixel-levelvisionisusedasoneofthesensorymodalities. Therefore,thecurrentstudyfocusesonsimulation
experimentsusingpre-recordeddata.
First,weinvestigatedhowchangingthetightnessusedtoregulatethecomplexitytermforeachsensorymoduleinthe
learningphaseaffectsthequalityofintegratingmultimodalsensationinanimitativeinteraction. Forthispurpose,we
examinedpossibleeffectsofassigningdifferentvaluesofthemeta-priortothevisionmoduleandtheproprioceptive
module,onperformancecharacteristicsinlearning,aswellasintheresultingimitativeinteraction. Ourresultssuggest
thatregulatingcomplexitymoreinthevisionmodulethanintheproprioceptionmodulefacilitatesbetterimitation
performanceinmulti-modalsensationafterlearning,becausevisualsensoryinformationcontainsmorerandomness
thanproprioceptiveinformation.
Second,asthemainmotivationofthecurrentstudy,weinvestigatedhowchangingthetightnessusedtoregulatethe
complexitytermintheentirenetworkafterthelearningphaseaffectsthestrengthofagency. Usinganetworktrained
bytuningthemeta-priorsassignedtoeachsensorymoduleinthepreviousexperiment,weexaminedhowincreasingor
decreasingmeta-priorvaluesthroughoutthenetworkcomparedtothoseusedduringlearningaffectsimitativebehavior.
Wefoundthatanetworkthattightlyregulatesthecomplexitytermbysettingsmallervaluesofthemeta-priortendsto
followhumanmovementpatternsbyadaptingitsinternalstates. Ontheotherhand,thenetworkthatlooselyregulates
thecomplexitytermbysettinglargervaluesofthemeta-priortendstogeneratemoreegocentric/self-centeredmovement
patternswithlesssensitivitytochangesorfluctuationsinhumanmovementpatternsbyadaptingitsinternalstateless.
Thecurrentpaperpresentsadetailedanalysisoftheunderlyingmechanismsaccountingfortheseobservedphenomena.
Below,theModelsectiondetailstheproposedmodel. Itdescribesanoverallsystem,learningprocess,derivationofthe
evidencelowerboundoftheproposedmodel,howthetrainedmodelwastestedinpseudoimitativeinteraction,and
implementationofthemodel. TheExperimentsectionexplainstheexperimentaldesign,proceduresofdatapreparation,
andtheresultsofthetwoexperiments. TheDiscussionsectionsummarizestheexperimentalresultsanddiscussestheir
implications.
4
2 Model
2.1 Modeloverview
Thissubsectiondescribesbrieflyhowmultimodalimitativeinteractionofagentsperceivingvisuo-proprioceptivesensory
inputscanbemodeledusingconceptsofpredictivecodingandactiveinference. Amongvarioustypesofimitation,
synchronizedimitationisconsideredinthecurrentstudybyvirtueofitssimplicity. Insynchronizedimitation,theagent
isrequiredtoimitatetargetpatternsdemonstratedbyitscounterpartbypredictingthemonthebasisofpriorlearning.
Althoughtargetpatternstoimitatearestructurallythesameaspreviouslylearnedpatterns,theycouldinvolvemarginal
variations,asinspeed,amplitude,andshape. Synchronizedimitationcanbeachievedbymeansofiterativecyclingof
sensoryinputpredictionsduringthedemonstration,generationofcorrespondingmovement,andupdatingthelatent
stateofthenetworkusingtheresultingsensorypredictionerror. Togeneratemovement,onestep,look-aheadprediction
ofproprioceptionisfedintoaninversemodel(Kawatoetal.,1987),whichisoftenimplementedbyaPIDfeedback
controllerinrobots. APIDfeedbackcontrollercomputesanoptimalmotortorqueasthemotorcommandtominimize
theerrorbetweenthepredictedproprioception(thetargetjointangles)andtheactualproprioception(theactualjoint
angles). Thiscorrespondstoactiveinference(Fristonetal.,2010,2011), asdescribedpreviously. Thelatentstate
canbeupdatedusingaschemecallederrorregression(TaniandNolfi,1999;ItoandTani,2004;Hwangetal.,2020;
AhmadiandTani,2019),bywhichsensoryperceptionassumedinapredictivecodingframeworkcanbeperformed.
Now we look at how the PV-RNN (Ahmadi and Tani, 2019) can be used to implement the model for multimodal
imitativeinteractionofarobotagentreceivingvisuo-proprioceptivesensoryinputsbasedonframeworksofpredictive
codingandactiveinference. Figure1showstheoverallsystemview,consistingofaPV-RNN,arobot,andahuman
counterpart. Thehumandemonstratesmovementpatternstotherobotbothvisuallyandkinesthetically,guidingthe
robot’s posture via a motion capture suit. Unfortunately, it was infeasible for the proposed system to work stably
inreal-timebecauseposteriorinferenceusinganerror-regressionscheme,detailedinsection2.4,requiresintensive
computation. Hence,inthecurrentstudy,wesimulatedtheimitativeinteractionbetweenahumanandarobotshownin
Figure1asapseudoimitativeinteractioninwhichpre-recordedbodymovementssampledfromahumanserveasthe
robotcounterpartusingthesettingshowninFigure1(C).
PV-RNNisconsideredagenerativemodel,formulatedinacontinuousspatio-temporaldomain,employingavariational
Bayesframework,asdescribedpreviously. Itinferstheposteriorateachtimestepusingvariationalinference,inwhich
thereconstructionerrorisminimizedwithregularizationoftheKLdivergencebetweentheinferredposteriorandthe
conditionalprior. Thisisimplementedbymeansofaso-callederror-regressionscheme,detailedinsection2.4.
APV-RNNinheritstheconceptofaMultipleTimescaleRecurrentNeuralNetwork(MTRNN)(YamashitaandTani,
2008),whichischaracterizedbyitsarchitecturebecauseitallocatesdifferenttimescaledynamicstodifferentlayers.
Higher layers are endowed with slower timescale dynamics and lower layers with faster dynamics, as inspired by
recent cognitive neuroscience evidence (Newell et al., 2001; Huys et al., 2004; Smith et al., 2006; Kording et al.,
2007). Introductionofmultipletimescaledynamicscanenhanceabstractionandgeneralizationinlearningbyextracting
action-primitivehierarchiesorchunkingstructuresfromobservedmultimodalsensoryinputs(YamashitaandTani,
2008;ChoiandTani,2018;Hwangetal.,2020).
ThesecharacteristicsofvariationalBayesframeworksandMTRNNenablePV-RNNtoutilizehierarchicallyorganized
probabilisticrepresentation,i.e.,whilethenetworkextractsahierarchicalstructurefromanobservation,italsoassigns
adifferentdegreeofuncertaintywithinthehierarchy. Forexample,givenataskinwhichthenetworkisrequiredto
predictasequenceofbodymovementscomprisedofasmallnumberofprimitivepatterns,thenetworkcanbecertain
aboutdetailsoftheprimitivepatterns,butlesscertainaboutthesequenceoftheprimitives. Insuchacase,thelower
levelofthenetworkresponsibleforpredictionofdetailsofeachprimitivemovementshowssmalluncertainty,whilethe
higherlevelinchargeofpredictionoftheorderofthoseprimitivepatternsshowshighuncertainty.
Sensorymodulesforproprioceptionandvisionweremodeledwithmulti-layeredPV-RNNsandmoduleswereconnected
viaanassociativemodule,alsobasedonaPV-RNN.Figure1(A)depictsaschematicoftheproposedmodelandhowit
istrained. Theassociativemodulegeneratestheprior,conditionedbythelatentstateattheprevioustimestepinthis
module. Theprioristhenfedtoboththeproprioceptionandvisionmodulesalongthetop-downpathway. Eachsensory
modulealsogeneratesapriorateachtimestepconditionedbythepreviouslatentstateofthemodule,computedusing
top-downinformationprovidedbytheassociativemodule,bywhichpredictionsofsensoryinputs,proprioceptionand
vision,aregeneratedinthesubsequenttimestep. Notethatthevisionmodulepredictsalow-dimensionalvector,which
isthenfedtoaCNN-typedecoder(LeCunetal.,1989,1998)togenerateactualpixelvisualimages,inordertoreduce
computationalcosts.
Adatasetofvisuo-proprioceptivepatternsdemonstratedbyhumanparticipantsisusedtotrainthemodel. Togenerate
thesedata,ahumanwearingamotion-capturesuitdemonstratesbodymovementswhilesimultaneouslyrecordinga
5
video. Themotioncapturesuitmapsthehuman’sbodyconfigurationintothehumanoidrobot’sjointanglevalues.
Thesesynchronizedjoint-angletrajectoriesandvideosserveasthetargetofthemodel. Thewholenetworkisoptimized
simultaneouslysoastomaximizetheevidencelowerboundofthemodelviaBPTT.Thedesignofbodymovement
patternsusedinthisstudyisdetailedinsection3.2.
Figure1(B)describeshowthetrainedmodelperformsimitativeinteractions. Animitativeinteractioninvolvesacycle
ofpredictionswithconditionalpriorandposteriorinferences. Ateachtimestep,thenetworkpredictsproprioceptionp
t
andalow-dimensionallatentrepresentationofvisionl withthepriorconditionedbythelatentvariableineachmodule
t
attheprevioustimestep. Theproprioceptivepredictionp issuppliedtothecontroller,followedbycomputationof
t
motorcommandsm toachievetheexpectedjointpositionsandgenerationofthemovement. Then,anewvisualimage
t
andproprioceptionareacquired. TherawpixelimageisfedtoaCNN-typeencoderthathasbeenseparatelytrainedto
obtainthetargetforthelow-dimensionallatentrepresentationl¯. Resultantpredictionerrorsel andeparecomputedin
t t t
visionandproprioception,respectively,whicharethenusedtoinfertheposteriorineachPV-RNNlayerwithregulation
oftheKLdivergencebetweentheinferredposteriorandtheconditionalpriorsothatthelowerboundismaximized
byBPTT.Thisoptimizationprocesstoinfertheposteriorisiteratedafixednumberoftimesateachsensory-motor
samplingtimestep,andtheoptimizedposteriorisusedtomakethebestpredictionwiththeconditionalpriortothe
succeedingtimestep.
Figure1(C)denoteshowtherobot’snetworkmodelsensesmovementpatternsdemonstratedbythehumancounterpart.
Figure1: Overallschematicoftheproposedmodel. Blueandredbellcurvesrepresentpriorandposteriordistributions,
respectively. Blueandredarrowsillustrateinformationflowsofthepredictionwithconditionalpriorandposterior
inferences, respectively. (A) The training scheme of the proposed network model. (B) The cycle of prediction
withconditionalpriorandposteriorinferencesduringaninteractionwithahuman. (C)Adiagramofprovidingthe
configurationofahumancounterparttothenetwork.
2.2 Derivationofevidencelowerbound
PV-RNNisagenerative,inferencemodelbasedonthegraphicalrepresentationshowninFigure2(thisfigurewill
beexplainedindetailinsection2.4). Itiscomprisedofdeterministicvariablesd,i.e.,assumedtofollowDiracdelta
distributions,andstochasticvariablesz.Themodelincludesapriorandinfersthecorrespondingposteriorbyvariational
inference. WemodifiedtheoriginalPV-RNNatfourpointswithrespecttodependenciesofvariables. First,inour
model, there are no connections between the output of the network x and z, which exist in the original PV-RNN.
Thisisforsimplificationofthemodel,anditwasconfirmedthatremovingtheseconnectionsdidnothindernetwork
performance. Second,thecurrentnetworkdoesnothaveconnectionsfromthelowerlayertothehigherlayer,which
theoriginalnetworkdoeshave. Thismodificationisintendedtoseparatemoreclearlytheinformationflowbetween
top-downgenerativepredictionandbottom-uperrorpropagation. Third,diagonalconnectionsfromthehigherlayer
duringtheprevioustimesteptothelowerlayerduringthesucceedingtimesteparechangedtoverticalconnections
duringthesametimestep. Last,thepriordistributionofz attimestep1hasbeenchanged. Intheoriginalstudy,the
t
6
distributionissimplymappedfromd . Inthecurrentstudy,however,itisassumedthatp(z )followsaunitGaussian
0 1
distributiontocontroltheinitialsensitivityofthemodel. FollowingderivationoftheevidencelowerboundinAhmadi
andTani(2019)andconsideringtheintroductionoftheunitGaussianattimestep1,theevidencelowerboundofthe
proposedvisuo-proprioceptivemodelisderivedas
T (cid:26) (cid:27)
ln(p
1:T
,v
1:T
|d∗
0
)≥ (cid:88) E qa,qp[lnP(p
t
|dp
t
,1)]+E qa,qv[lnP(v
t
|dv
t
,1)]
t=1
− (cid:88) D [q(zl|dl,ep ,ev )(cid:107)p(zu)]− (cid:88) D [q(zl|dl,ep )(cid:107)p(zu)]
KL 1 0 1:T 1:T KL 1 0 1:T
l∈A l∈P
(3)
T (cid:26)
− (cid:88) D [q(zl|dl,ev )(cid:107)p(zu)]+ (cid:88) − (cid:88) D [q(zl|dl ,ep ,ev )(cid:107)p(zl|dl )]
KL 1 0 1:T KL t t−1 t:T t:T t t−1
l∈V t=2 l∈A
(cid:27)
− (cid:88) D [q(zl|dl ,ep )(cid:107)p(zl|dl )]− (cid:88) D [q(zl|dl ,ev )(cid:107)p(zl|dl )]
KL t t−1 t:T t t−1 KL t t−1 t:T t t−1
l∈P l∈V
whereA,P,andVrepresenttheassociativemodule,theproprioceptionmodule,andthevisionmodule,respectively,
andlindicatestheindexofalayerineachmodule. p andv aretimeseriespropriocetiveandvisualpatterns. d∗
1:T 1:T 0
representsdinalllayersattimestep0. E denotestheexpectationoveralldistributionsofz intheassociative
qa,qp
moduleandtheproprioceptionmodule,andE denotesexpectationoveralldistributionsofz intheassociative
qa,qv
moduleandthevisionmodule. dp,1isthedeterministicvariableinthelowestlayeroftheproprioceptionmoduleat
t
timestept,anddv,1isthatinthelowestlayerofthevisionmodule. zl isthestochasticvariableattimesteptinthelth
t t
layerineachmodule. ep andev arethepredictionerrorsbetweenthepredictedpatternsandthetargetpatternsat
t:T t:T
timestepfromttoT inproprioceptionandvision,respectively. p(zu)indicatestheunitGaussiandistributionserving
asthepriorattimestep1. Byintroducingthemeta-prior,whichweightstheKLdivergencebetweentheapproximate
posteriorandthepriorinalayer-specificmanner,theevidencelowerboundofthemodelisdefinedas
T (cid:26) (cid:27)
L
w
:= (cid:88) E qa,qp[lnP(p
t
|dp
t
,1)] +E qa,qv[lnP(v
t
|dv
t
,1)]
t=1 (cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
Accuracyinproprioception Accuracyinvision
− (cid:88) wl D [q(zl|dl,ep ,ev )(cid:107)p(zu)]− (cid:88) wl D [q(zl|dl,ep )(cid:107)p(zu)]
1 KL 1 0 1:T 1:T 1 KL 1 0 1:T
l∈A (cid:124) (cid:123)(cid:122) (cid:125) l∈P (cid:124) (cid:123)(cid:122) (cid:125)
Complexityinassociativemodule Complexityinproprioceptionmodule
(4)
T (cid:26)
− (cid:88) wl D [q(zl|dl,ev )(cid:107)p(zu)]+ (cid:88) − (cid:88) wlD [q(zl|dl ,ep ,ev )(cid:107)p(zl|dl ))]
1 KL 1 0 1:T KL t t−1 t:T t:T t t−1
l∈V (cid:124) (cid:123)(cid:122) (cid:125) t=2 l∈A (cid:124) (cid:123)(cid:122) (cid:125)
Complexityinvisionmodule Complexityinassociativemodule
(cid:27)
− (cid:88) wlD [q(zl|dl ,ep )(cid:107)p(zl|dl )]− (cid:88) wlD [q(zl|dl ,ev )(cid:107)p(zl|dl )]
KL t t−1 t:T t t−1 KL t t−1 t:T t t−1
l∈P (cid:124) (cid:123)(cid:122) (cid:125) l∈V (cid:124) (cid:123)(cid:122) (cid:125)
Complexityinproprioceptionmodule Complexityinvisionmodule
wherewl indicatesthemeta-priorinthelthlayeratt=1intheassociativemodule,theproprioceptionmodule,andthe
1
visionmodule,respectively. wl representsthemeta-priorsinthelthlayeraftert=2ineachmodule. Parametersofthe
modelareoptimizedbymaximizingthelowerbound,whichcorrespondstominimizingthefreeenergy.
2.3 Learningprocess
Itisnotedthatunlikeothermodelsemployingonlinelearningmethods(Boucennaetal.,2014,2016),ourmodelis
trainedofflinewithpre-recordeddataset. Theentirenetworkmodelistrainedbymaximizingtheevidencelowerbound.
Thus,giventhetimesteplengthT ofproprioceptivepatternsp andvisualpatternsv ,thecostfunctiontobe
1:T 1:T
minimizedisdefinedas
T (cid:26)
cost:= (cid:88) 1 (cid:107)p −p¯(cid:107)2+ 1 (cid:107)v −v¯ (cid:107)2
2Rp t t 2Rv t t
t=1
+
(cid:88)w
1
l
D [q(zl|dl,ep ,ev )(cid:107)p(zu)]+
(cid:88)w
1
l
D [q(zl|dl,ep )(cid:107)p(zu)]
Rl KL 1 0 1:T 1:T Rl KL 1 0 1:T
l∈A l∈P
(5)
+ (cid:88)w 1 l D [q(zl|dl,ev )(cid:107)p(zu)]|+ (cid:88) T (cid:26) (cid:88)wl D [q(zl|dl ,ep ,ev )(cid:107)p(zl|dl )]
Rl KL 1 0 1:T Rl KL t t−1 t:T t:T t t−1
l∈V t=2 l∈A
+
(cid:88)wl
D [q(zl|dl ,ep )(cid:107)p(zl|dl )]+
(cid:88)wl
D [q(zl|dl ,ev )(cid:107)p(zl|dl )]
(cid:27)
Rl KL t t−1 t:T t t−1 Rl KL t t−1 t:T t t−1
l∈P l∈V
7
whereA,P,andVrepresenttheassociativemodule,theproprioceptionmodule,andthevisionmodule. RpandRv are
thedimensionsofproprioceptivepatternsandvisualpatternstonormalizepredictionerrors,andRl isthedimension
ofthedistributionsofz tonormalizetheKLdivergence. Eachoutputinthevisionandproprioceptivemodulesis
representedbyamultivariateGaussiandistributionwithanestimationofthemeanforeachdimensionandcovariant
matrixastheidentitymatrix,forsimplicity. Thisleadstominimizationofthemeansquarederror,whichisanestimator
ofthelog-likelihoodintheaccuracytermwhenmaximizingthelowerbound.
SincethepriorandposteriordistributionsareassumedtofollowamultivariateGaussiandistributionwithadiagonal
covariantmatrix,theKLdivergenceinthecostfunctionisanalyticallycomputed. Giventwondimensionalmultivariate
Gaussian distributions p(z) = N(z;µp,σp) and q(z) = N(z;µq,σq) where µ = (µ ,µ ,...,µ )T and σ =
1 2 n
(σ ,σ ,...,σ )T,
1 2 n
(cid:88) n (cid:26) (cid:18) σp(cid:19) (µp−µq)2+(σq)2 1 (cid:27)
D [q(z)(cid:107)p(z)]= ln i + i i i − (6)
KL σq 2(σp)2 2
i=1 i i
Theparametersofthemodel,includinganadaptivevariableaintroducedinthefollowingsection,areoptimizedusing
BPTT.Toperformerror-regressionexplainedinsection2.4,anencoderwasalsotrainedseparately.
2.4 Error-regressionwithshiftingwindow
AhmadiandTani(2019)proposedascheme,theerror-regression(ER)withshiftingwindowtotestthetrainedmodelin
awaythatisconsistentwithconceptsofpredictivecodingandactiveinference. Inthisscheme,thetrainednetwork
attemptstopredictsensoryinputsinthenexttimestepwhileinferringtheposteriorintheimmediatepastwindowofa
fixedlength,usingthereconstructionerrorinthewindow. ThewindowisreferredtoastheERwindowinthefollowing.
ItisessentialtonotethatERformaximizingtheevidencelowerboundisconductedbyiteratingtwoprocessesof
forwardcomputation(Figure2(A))andposteriorupdate(Figure2(B))forspecifictimesateachsensorysampling
timestep.
PV-RNNhasuniquevariablesathatfacilitateupdatingtheposterior. aistimestep-specificandhasthesamedimension
aszineachPV-RNNlayer. Inotherwords,whenaPV-RNNlayerwithzwithitsdimensionalityntriestoinferthe
posteriorforthelastT timestepsinsidetheERwindow,thePV-RNNlayerhasn×T avaluablesandupdatesthemto
modifytherepresentationoftheposterior. Adetailedcomputationschemeoftheposteriorusingtheadaptivevariablea
isfoundinsection2.5. Importantly,inER,weightsandbiasesofthenetworkarefixed,andonlytheadaptivevariables
aareupdated.
Letusconsideranexampleoferror-regressioninwhichthelengthoftheERwindowistwotimesteps,andthenetwork
has two layers, as shown in Figure 2. Figure 2 (A) illustrates the forward computation at time step t to infer the
posterior. Intheforwardcomputation,thenetworkcomputestheconditionalprior,p(z |d )andp(z |d ),and
t−1 t−2 t t−1
theposterior,q(z |d ,e )andq(z |d ,e )ineachlayer,andgeneratesthepredictionwithsamplingfrom
t−1 t−2 t−1:t t t−1 t
theposteriordistributioninsidethewindow. Then,thereconstructionerrore ande ,andtheKLdivergencebetween
t−1 t
respectivepairsoftheconditionalpriorandposteriorarecomputed.
BasedonthereconstructionerrorandKLdivergence,theinferredposteriorisupdatedtomaximizetheevidencelower
bound. Figure 2 (B) illustrates how the reconstruction error is back-propagated through variables and layers to a,
whichisresponsibleforupdatingtheposterior. Usingtheupdatedposterior,thenetworkagainperformstheforward
computation. Itshouldbenotedthatsincetheq(z |d ,e )hasbeenupdated,d isdifferentfromtheone
t−1 t−2 t−1:t t−1
before the update; thus, p(z|d ) is also changed through the posterior update. The reconstruction error and the
t−1
KLdivergencearefurthercomputed,andtheposteriorisupdated. Thisiterativeprocessofforwardcomputationand
posteriorupdateisrepeatedafixednumberoftimestooptimizetheapproximateposteriorformaximizingtheevidence
lowerboundcomputedwithgivenmeta-priorvalues.
Afterfinishingalliterations,thenetworkgeneratesanewsensorypredictionx withaconditionalpriorusingthe
t+1
inferredposteriorinsidetheERwindow. ThentheERwindowshiftsonetimestepandthenexttargetsensationx is
t+1
sampled,andtheforwardcomputationandtheposteriorupdatearereiteratedattimestept+1. Intheproposedmodel,
theERisperformedforbothvisualsensationandproprioceptionsimultaneously,andthisschemeofusingERwitha
shiftingwindowwasusedtotestanimitativeinteractionaftertrainingtheentirenetwork,aswillbedescribedlater.
8
Figure 2: A graphical representation of error-regression with a shifting window. The gray area represents the ER
window. Blackarrowsindicateforwardcomputations. Redarrowsindicatehowreconstructionerrorsarepropagatedto
ainsidetheERwindowbyBPTT.(A)illustratestheinformationflowofforwardcomputationattimestept. (B)shows
theupdateoftheposteriorinsidetheERwindowattimestept. (C)showsthewindowshiftingtotimestept+1.
2.5 Modelimplementation
The proposed model for the imitative interaction via visuo-proprioceptive sensation consists of three modules: an
associativemodule,aproprioceptionmodule,andavisionmodule. Thissubsectiondescribesadetailedcomputation
schemeineachmodule.
2.5.1 Theassociativemodule
TheassociativemoduleiscomprisedofaPV-RNN.SinceweadoptedanMTRNNcomputationschemeinPV-RNN,its
computationsareasfollows.
(cid:40) Wa,llda,l +Wa,llza,l+ba,l iftoplayer (7)
ua,l = dd t−1 dz t
t Wa,llda,l +Wa,ll+1da,l+1+Wa,lza,l+ba,l otherwise (8)
dd t−1 dd t dz t
(cid:18) (cid:19)
1 1
ha,l = 1− ha,l + u (9)
t τa,l t−1 τa,l tl
(cid:16) (cid:17)
da,l =tanh ha,l (10)
t t
whereua,l isthesumofinputstolthlayeroftheassociativemodule. Wa,ll,Wa,ll,andWa,ll+1areweightmatrices
t dd dz dd
forrecurrentconnections,thestochasticvariablez,andtheinputfromthehigherlayer,respectively. ba,l isthebias
inthelthlayerintheassociativemodule,andτa,l isthetimeconstantforMTRNNcomputationinthelthlayerof
theassociativemodule. tanhistheactivationfunction. Thestochasticvariablezisassumedtofollowamultivariate
Gaussiandistributionwithadiagonalcovariantmatrix,andthedeterministicvariabledpredictsmeanµandvarianceσ
ofthedistribution. Thatis,forcomputationoftheprior,
(cid:40) N(zu;0,I) if t=1 (11)
p(zp,a,l)=
t p(zp,a,l|da,l )=N(zp,a,l;µp,a,l,σp,a,l) otherwise (12)
t t−1 t t t
µp,a,l =tanh(Wa,lda,l +ba,l) (13)
t µd t−1 µ
σp,a,l =exp(Wa,lda,l +ba,l) (14)
t σd t−1 σ
zp,a,l =µp,a,l+σp,a,l∗(cid:15) (15)
t t t
9
whereµp,a,l andσp,a,l arethemeanandvarianceforthepriordistributionofzp,a,l attimesteptinlthlayerinthe
t t t
associativemodule. Wa,landWa,laretheweightmatricesforda,l . ba,landba,larethebiasesforeachcomputation.
µd σd t−1 µ σ
tanhincomputationofmeanisusedforstabilityofoptimization,andexpinσ isforvariancetobepositive. (cid:15)is
sampledfromN(0,I). Toapproximatetheposterior,PV-RNNhasadaptivevariablesathatarespecifictotimestep
andsequence. aisoptimizedduringlearningwiththepredictionerrorviaBPTT.Byconsideringa,thecomputations
ofposteriorare
q(zq,a,l|da,l ,ep ,ev )=N(zq,a,l;µq,a,l,σq,a,l) (16)
t t−1 t:T t:T t t t
µq,a,l =tanh(Wa,lda,l +aa,l +ba,l) (17)
t µd t−1 µ,t µ
σq,a,l =exp(Wa,lda,l +aa,l +ba,l) (18)
t σd t−1 σ,t σ
zq,a,l =µq,a,l+σq,a,l∗(cid:15) (19)
t t t
where µq,a,l and σq,a,l are mean and variance for the posterior distribution of zq,a,l at time step t in lth layer in
t t t
theassociativemodule. Notethattheweightmatricesfordaredifferentfromthoseusedtocomputetheprior. In
addition,unliketheperipheralsensorymodulesofproprioceptionandvision,theassociativemoduledoesnotpredict
thesensoryoutputdirectly,butratherpredictsthelatentrepresentationofvisuo-proprioceptivesequences. Therefore,
theweightsandbiases,aswellastheadaptivevariableaoftheassociativemodulearenotoptimizedinstantlyfromthe
reconstructionerrorofthesensoryoutcomes,butfromtheerrorsignalsmediatedthrougheachsensorymodule.
2.5.2 Theproprioceptionmodule
Proprioceptive patterns are directly generated from the PV-RNN. The highest layer in the proprioception module
receivestheinputfromthelowestlayerintheassociativelayer,anditscomputationsare
(cid:40) Wpada,1+Wp,lldp,l +Wp,lzp,l+bp,l iftoplayer (20)
up,l = dd t dd t−1 dz t
t Wp,lldp,l +Wp,lzp,l+bp,l otherwise (21)
dd t−1 dz t
(cid:18) (cid:19)
1 1
hp,l = 1− hp,l + up,l (22)
t τp,l t−1 τp,l t
(cid:16) (cid:17)
dp,l =tanh hp,l (23)
t t
Aproprioceptivepatternattimestept,p ,isgeneratedfromthelowestlayeroftheproprioceptionmodule.
t
p =tanh
(cid:0) Wpdp,1+bp(cid:1)
(24)
t t
2.5.3 Thevisionmodule
Forthevisionmodule, aschemetoreducethecomputationtimeisintroduced. Asdescribedinsection2.4above,
intheproposedimitativeinteractionscheme,thenetworkisrequiredtoinfertheposteriorfortheimmediatepastat
everysensorysamplingtimestepbyrepeatingforwardcomputationandBPTT,whichdemandsintensivecomputation.
Nevertheless,ourmodelisexpectedtoworkinactualrobotsinreal-timeinthefuture,whichnecessitatesreducingthe
model’scomputationalcomplexity. Toreducethecomputationaldemandintheposteriorinferenceinvisualperception,
weconsideracompositenetworkcombiningadynamicPV-RNNandstaticCNNsfordecodingandencodingpixel
patterns,insteadofintroducingfullrecurrentconnectionsinthismodule. Inthiscompositenetwork,whengenerating
predictiveoutputforthevisualinput,thePV-RNNpartpredictsthelatentstaterepresentationwitharelativelylow
dimension,whichisfedtoaCNNdecodertogeneratethecorrespondingvisualpixelimage. Ontheotherhand,when
receivingthevisualinput,itistransformedtothelatentstaterepresentationbyaCNNencoder. Then,theprediction
errorcanbecomputedasthediscrepancyinthelatentstatewithalowdimensionratherthanatthepixellevelwithhigh
dimension. ThisreducesthecomputationalburdensignificantlyforconductingtheBPTTtoinfertheposteriorduring
imitativeinteraction. Asintheproprioceptionmodule,thehighestlayerofthevisionmodulereceivesinputfromthe
lowestlayeroftheassociativelayer,anditscomputationsare
(cid:40) Wvada,1+Wv,lldp,l +Wv,lzv,l+bv,l iftoplayer (25)
uv,l = dd t dd t−1 dz t
t Wv,lldv,l +Wv,lzv,l+bv,l otherwise (26)
dd t−1 zd t
(cid:18) (cid:19)
1 1
hv,l = 1− hv,l + uv,l (27)
t τv,l t−1 τv,l t
(cid:16) (cid:17)
dv,l =tanh hv,l (28)
t t
10
ThenthelowestlayerofthePV-RNNpredictsthelatentstatel attimestept,andthevisualpatternv isgeneratedby
t t
thedecoder.
(cid:16) (cid:17)
l =tanh Wldv,1+bl (29)
t t
v =decoder(l ) (30)
t t
In the imitative interaction, the target of latent dynamics l¯ of visual patterns v¯ at time step t is computed by the
t t
encoder.
¯l =encoder(v¯ ) (31)
t t
Toimprovethegeneralizationcapabilityoftheencoderanddecoder,CoordConvarchitecture(Liuetal.,2018)was
introduced.
3 Experiments
3.1 Experimentaldesign
Usingtheproposedmodel,imitativeinteractionexperimentsconsideringhuman-robotinteractionswereconducted.
Althoughhuman-robotinteractionsoughttobestudiedinanonlinefashiontoreflecthumanbehaviorinresponseto
robotactions, becauseoftheintensivecomputationrequiredintheerrorregressionscheme, wecouldnotconduct
suchexperimentsonline. Therefore, thecurrentstudyexaminedonlythedynamicresponseofthemodelnetwork
usingrecordedsequencesofvisuo-proprioceptivepatterns. Therefore,datacontaininghuman-demonstratedmovement
patternsintermsofvisuo-proprioceptivesequenceswerecollectedbothfortrainingthenetworkandforlatertestingof
pseudo-synchronizedimitativeinteraction. Aftertraining,themodelwastestedforpseudo-imitativeinteractionusing
novelvisuo-proprioceptivepatternswithtwodifferentscenarios(Experiment1andExperiment2).
Experiment1investigatedtheissueofcoordinationandintegrationofdifferentmodalitiesofsensationbychanging
thetightnessusedtoregulatethecomplexitytermforeachsensorymodule. Forthispurpose,thenetworkwastrained
byassigningdifferentvaluesofthemeta-priortotheproprioceptionandvisionmodules. Weexaminedthedifferent
effectsofregulatingcomplexityinthetwomodulesoncoordinationofdifferentmodalitiesbyanalyzingtheminboth
thelearningprocessandinthepseudo-imitativeinteractiontestedafterlearning.
Experiment2investigatedtheissueofstrengthofagencyasthemainmotivationofthecurrentstudybychanging
thetightnessusedtoregulatethecomplexitytermfortheentirenetworkfromthatintroducedinthetrainingphase.
Accordingly,weselectedanetworktrainedandevaluatedassuccessfulinExperiment1andthenthecharacteristicsof
thepseudo-imitativeinteractionwereexaminedbyequallyadjustingthemeta-priorsofeachmoduleofthistrained
networktolargerorsmallervalues.
Insubsequentexperiments,someparametersthatdeterminenetworkstructureweresetasfollows. Theassociative
moduleconsistedofaone-layerPV-RNN,andtheproprioceptionmoduleandthevisionmoduleconsistedoftwo
layers. ThesePV-RNNlayerswerecharacterizedbyatimescaleimposedonMTRNNcomputation. Thatis,thehigher
layerhadalargertimeconstant,producingslowtime-scaledynamics,andthelowerlayerhadsmallertimeconstants,
generatingfasttime-scaledynamics. Therefore,inthisstudy,thehigherlayeroftheproprioceptionmoduleandthe
visionmodule,whichreceiveinputfromtheassociativemodule,arereferredtoastheslowlayer,andthelowerlayeris
referredtoasthefastlayer. Asdescribedinsection2.5.3,thevisualperceptionofthemodelinvolvesanencoderanda
decoder. TheirarchitecturesaresummarizedinTable1.
3.2 Datapreparation
Toobtainadatasetofsynchronizedvisuo-proprioceptivesequences,weusedahumanoidrobot,Torobo(TokyoRobotics
Inc.) andamotioncapturesuit(PerceptionNeuron,NoitomLtd.). Toroboisahuman-sized,torso-typehumanoidrobot
with16joint-angles,ofwhich6areforeacharmand4areforthetorsoandheadpositions. Humanbodymovements
canbemappedtojoint-angletrajectoriesoftherobotusingthemotioncapturesuit. Ahumanexperimenterwearingthe
suitdemonstratedasetofbodymovements,whichweremappedasjoint-angletrajectories. Thisdemonstrationwasalso
recordedwithacameratoobtaincorrespondingvisualpatterns. Thetargetsequentialmovementpatterntobelearned
bytherobotwasdesignedbyconsideringaprobabilisticfinitestatemachinethatcangenerateprobabilisticsequences
ofthreedifferentprimitivemovementpatterns. Thosewere(A)wavingwithbotharmsthreetimes,(B)rotatingthe
torsototheleftwiththearmsthreetimes,and(C)rotatingthetorsototherightwiththearmsthreetimes. Primitive
patternAisfollowedeitherbyprimitivepatternBorprimitivepatternCwitha50%chance,andprimitivepatternsB
andCarefollowedbypatternAwitha100%chance(Figure3(A)).Onesequenceconsistsof8probabilistictransitions
ofprimitivemovements. Threehumanparticipantsdemonstratedandrecorded10movementsequenceseach. Inother
11
Layer Kernelsize Stride Filter Activation
Encoder
Conv 33×33 1 5 ReLu
Conv 17×17 1 15 ReLu
Conv 16×16 1 30 tanh
Decoder
Convtranspose 16×16 1 15 ReLu
Convtranspose 17×17 1 5 ReLu
Convtranspose 33×33 1 1 tanh
Table1: Thearchitectureoftheencoderandthedecoder.
words,thedatasetcomprised30sequencesofvisuo-proprioceptivetemporalpatterns. Recordedvisuo-proprioceptive
patternsweredown-sampledto3.75Hzsothatonesequencebecame400timesteps. Joint-angletrajectorieswere
normalizedtoarangebetween−1and1. Visionpatternswerefurtherconvertedintograyscaleimagesanddown-sized
to64×64pixels(Figure3(B)).AsummaryofthetrainingdataisshowninTable2. Visualtrajectoriesfluctuatedfar
morethanproprioceptivetrajectoriesduetovariousopticalconditions,suchasilluminationandsurfacereflectiveness.
Dimension timestep Participants Totalsequences
Proprioception 16
400 3 30
Vision 64×64
Table2: Asummaryofthetrainingdata.
Figure3: Trainingdata. (A)Adiagramoftheprobabilisticfinitestatemachine. (B)Anexampleofthetrainingdataset.
Thetoprowispartofajoint-angletrajectory. Thecorrespondinglabelsofprimitivepatterns(A,B,andC)areindicated
abovetheplots. Forsimplicity,only4joint-anglesoutof16representingthemovementsareshown. Themiddlerow
showscorrespondingvisualpixelimagesineachperiod. Thebottomrowshowsvisualtrajectoriesinthelatentspace
embeddedbytheencoder. Forsimplicity,onlythreevariablesoutof20areshown.
Usingthetrainingexample,themodelisrequiredtoextractaprobabilisticstructuresuchthattheprimitivepatternofB
orCappearswithonlya50%chanceaftereveryappearanceoftheprimitiveA,byestimatingprecisionintransitionsof
12
primitiveswithlearning. Suchlearningshouldbeachievedwithoutprovidingexplicitlabelsforthoseprimitives,by
extractingtheunderlyingchunkingandsegmentationstructurefromcontinuoussensorysignalspreparedinthedataset.
ThePV-RNNcanachievesuchtasksusingamultipletimescaleRNNschemecombinedwithaBayesianinference
approach(AhmadiandTani,2019).
3.3 Experiment1: Trainingwithdifferentmeta-priorsindifferentmodalities
Thisexperimentinvestigateseffectsofchangingthetightnessusedtoregulatethecomplexitytermforeachsensory
modulewithregardtocoordinationandintegrationofdifferentmodalitiesofsensation. Inaddition,thisexperiment
providessuccessfullytrainednetworkswithwell-balancedcomplexitybetweenthevisionandproprioceptivemodules
forpossibleuseinExperiment2. Toaccomplishthis,weexaminedhowassigningdifferentvaluesofthemeta-priorto
theproprioceptionandvisionmodulesaffectsthelearningprocessandperformanceinthepseudo-imitativeinteraction.
Twosetsofmeta-priorsw andw wereassignedtothemodel(Table3). w haslargervaluesofthemeta-priorinthe
1 2 1
proprioceptionmodulethaninthevisionmodule,andtheywereexchangedinw . Bothw andw havethesamevalue
2 1 2
forthemeta-priorintheassociativemodule. First,themodelwastrainedwiththew andw settings,andthelearning
1 2
processwasexamined,withspecialattentiontoeachcomponentofthelowerbound. Tofacilitatetraining,theAdam
optimizer(KingmaandBa,2014)wasutilizedwiththeparametersettingsα=0.001,β =0.9,andβ =0.999. The
1 2
modelwastrained10timeswithdifferentrandominitializationsofmodelparametersfor10,000epochs,andthemean
andstandarddeviationofthepredictionerrorsofproprioceptionandvision,andtheKLdivergenceofeachlayerofthe
modelateachepochwerecomputed.
ResultsaresummarizedinFigure4. Incomparingw andw conditions, eventhoughthepredictionerrorsinthe
1 2
proprioceptionandvisionmodulesshowedsimilarbehavior(Figure4(A),(B)),theKLdivergenceineachmodulewas
optimizeddifferently. Despitedifferentvaluesofthemeta-priorassignedtothefastlayeroftheproprioceptionmodule,
itsKLdivergencesinw andw conditionswerereducedinexactlythesameway(Figure4(E)).Thisisnotthecasein
1 2
thefastlayerofthevisionmodule(Figure4(G)).TheKLdivergenceintheslowlayeroftheproproceptionmodule
andtheslowlayerofthevisionmoduleshoweddifferentvaluesinw andw settings(Figure4(D),(F)).Interestingly,
1 2
althoughtheassociativemodulewassettothesamevalueofmeta-priorinw andw conditions,theKLdivergencein
1 2
thew settingreachedalargervaluethaninthew setting. Thisisbecausethelargervalueofthemeta-priorassigned
2 1
tothefastlayerofthevisionmoduleinthew conditionpreventedthevisionmodulefromabsorbingthefluctuationin
2
observedvisualpatterns,whichresultedinbottom-upfluctuationfromthevisionmoduletotheassociativemodule,
appearingasadiscrepancybetweenthepriorandtheposteriorinthismodule. Becausevisualsensationcontainsmore
inherentrandomnessthanproprioceptivesensation,asmentionedpreviously,complexityinthismodalityshouldbe
adequatelyregulatedbysettingasmallermeta-priorvalue. Otherwise,thediscrepancythatappearsinthevisualmodule
tendstoleaptothehigherassociativemodulewithoutbeingwellresolvedbefore.
w setting w setting
Rd Rz τ 1 2
wl wl wl wl
1 1
Assoc. module 10 1 15 0.0025 0.01 0.0025 0.01
Prop. slowlayer 20 2 8 0.005 0.01 0.0025 0.05
Prop. fastlayer 30 3 2 0.01 0.01 0.005 0.05
Visionslowlayer 20 2 8 0.0025 0.05 0.005 0.01
Visionfastlayer 30 3 2 0.005 0.05 0.01 0.01
Table3: ThemodelconfigurationinExperiment1. Rd andRz arethedimensionsofdandz,respectively. τ isthe
timeconstantoftheMTRNNcomputationineachlayer.
Wefurthertestedthetrainedmodelsinthepseudo-imitativeinteraction. Trainingofthemodelsstoppedafter4,000
epochs. Threenovelvisuo-proprioceptivesequencesrecordedfromthreehumanparticipantswerepreparedforthe
pseudo-imitativeinteraction,whichalsocomprisedthepreviousprimitivebodymovementsA,B,andC,thelengthsof
whichwere400timesteps. ThelengthoftheERwindowwassetto30timesteps,andthenumberofoptimization
iterationsforposteriorinferencebyBPTTateachtimestepwas30. Namely,ateachsensorysamplingtimestep,the
networkinferstheposteriordistributionofzresponsibleforreconstructingtheobservationinsidetheERwindow,in
whichthecycleoftheforwardcomputationandtheposteriorupdatedescribedinsection2.4repeats30times. As
inlearning, Adamwasusedtoimproveoptimizationwithparametersettingsα = 0.2, β = 0.9, andβ = 0.999.
1 2
Evaluationoftheerror-regressionexaminedhowmuchthereconstructionerrorineachmodalityandtheKLdivergence
ateachsub-networkinthePV-RNNwereminimized. Thatis,atthepointwhenT(cid:48)timestepwindowfortheimmediate
pastshiftsttimesteps,i.e.,thecurrenttimestepist,theadaptivevariableaassignedwithinthewindowisoptimized
13
Figure 4: The learning process of the model with two different meta-prior settings. (A) The prediction error in
proprioception. (B)Thepredictionerrorinvision. (C)TheKLdivergenceintheassociativemodule. (D)TheKL
divergenceintheslowlayeroftheproprioceptionmodule. (E)TheKLdivergenceinthefastlayeroftheproprioception
module. (F)TheKLdivergenceintheslowlayerofthevisionmodule. (G)TheKLdivergenceinthefastlayerofthe
visionmodule. Theshadowsarethestandarddeviationof10trialswithdifferentparameterinitializations. Notethat
valuesofpredictionerrorsarethesumofthepredictionerrorsatalltimestepsandsequencesnormalizedbythedata
dimension.
withtheiterativeprocess,andatthelastiteration,thereconstructionerrorandtheKLdivergencearecomputedinside
thewindow. Therefore,theyaredefinedas
T T(cid:48)
Proprioceptionerror:= 1 (cid:88) 1 (cid:88) 1 (cid:107)p −p¯ (cid:107)2 (32)
T T(cid:48) Rp t(cid:48) t(cid:48)
t=1 t(cid:48)=1
T T(cid:48)
Visionerror:=
T
1 (cid:88)
T
1
(cid:48)
(cid:88)
R
1
l
(cid:107)l t(cid:48) −¯l t(cid:48)(cid:107)2 (33)
t=1 t(cid:48)=1
T T(cid:48)
1 (cid:88) 1 (cid:88) 1
KLD:= T T(cid:48) Rz D KL [q(z t(cid:48)|d t(cid:48)−1 ,e t(cid:48):T )(cid:107)p(z t(cid:48)|d t(cid:48)−1 )] (34)
t=1 t(cid:48)=1
wheret(cid:48) isthetimestepinsidethewindow. Rp andRl arethedimensionofproprioceptionandthelatentspaceof
vision, respectively. Rz isthedimensionofz, andtheKLdivergenceiscomputedforeveryPV-RNNsubmodule.
Modelstrainedinpreviousexperimentswereused. Thepseudo-imitativeinteractionexperimentwasrun10timeswith
differentrandomnumberseeds,andthemeanandstandarddeviationofeachquantitywerecomputed. Inaddition,
one-step,look-aheadpredictionerror,thediscrepancybetweenthepredictioninthenexttimestepofthecurrentwindow
andtheobservation,wascomputedinthevisionmoduletoevaluatepredictionaccuracy.
Figure5exemplifieshowthepseudo-imitativeinteractiondevelopedinthew1settingintime-lapse. Forclarity,only
partsinvolvingtheproprioceptiveinteractionareshown. Eachcolumnshowstherepresentationofthenetworkwhen
thenetworkfinishedaposteriorinferenceandmadeanewpredictionateachtimestep. Thefirst,second,andthirdrow
showrepresentationsintheassociativemodule,theslowlayerintheproprioceptionmoduleandthefastlayerinthe
proprioceptionmodule,respectively. Solidlinesindicatetheactivityofthreerandomlychosendneurons,anddashed
linesindicatetheKLdivergencevalueateachtimestepineachlayer. Thefourthrowshowsjoint-angletrajectories.
Solidlinesarepredictionsgeneratedbythenetwork,anddashedlinesarejoint-anglevaluesdemonstratedbythehuman
counterpartintherecordeddata. Thebottomrowshowsthereconstructionerror,insidetheERwindow,whichwas
minimizedbyupdatingaviaBPTTunderregularizationbytheKLdivergencebetweentheinferredposteriorandthe
conditionalprior. Insection2.4,describingtheerror-regressionscheme,thenetworkisillustratedinawaythatitonly
makesthepredictionatnexttimestepduringtheinteraction. Inthisexperiment,however,thenetworkwasallowed
togeneratethepredictionnotonlyatnexttimestep,butalsoatsubsequenttimestepswiththeconditionalpriorto
visualizethenetwork’slong-termprediction. ThisisalsothecaseinFigure8.
Ateachtimestep,thenetworkreceivesanewsensation,computesthereconstructionerrorandtheKLdivergence
withintheERwindow,updatestheasuchthatthelowerboundinsidetheERwindowismaximized,andmodifies
thepredictionafterthecurrenttimestepwiththeconditionalprior. InFigure5,thenetworkcontinuallymodifiedthe
14
futurepredictionasaresultoftheposteriorinference. SincethelowerboundsummedovertimestepsinsidetheER
windowismaximized,allasinsidetheERwindowareupdatedsothatthesumofthereconstructionerrorandtheKL
divergenceweightedbythemeta-priorinsidetheERwindowareminimized. Therefore,itisoftenobservedthatthe
valueofthereconstructionerrorortheKLdivergenceatacertaintimestepinsidetheERwindowbecomeslargerat
thenexttimestep,whichisconsideredatransientprocessintheoptimizationwhereinthepastisre-interpretedand
re-representedincopingwithanewenteringsensation,intermsofpost-diction(Shimojo,2014). Inthew setting,
1
largervaluesofthemeta-priorareassignedtolowerlayersofthenetworkandsmallertohigher. Inotherwords,KL
divergencesinlowerlayersareweightedmoreinthelowerbound,andwhilethoseinhigherlayersareweightedless.
Therefore,KLdivergencesinlowerlayerswerereducedmore,andthoseinhigherlayersremainedlargerafteriterative
optimization. OwingtoMTRNNcharacteristicsofdifferenttime-scalesamonglayers,higherlayersshowedslower
dynamicsandlowerlayersshowedfasterdynamics. Itisassumedthathigherlevelspredictswitchingofprimitivesand
lowerlevelspredictsensoryprofilechangesateachtimestep. Detailedanalysisofthisissuewasnotconductedinthe
currentstudysincesimilarphenomenausingMTRNNhavebeenreportedfrequently(e.g. YamashitaandTani(2008);
Hwangetal.(2020)).
Figure5: Anexampleofthenetworkrepresentationduringtestinginw setting. GrayareasindicatetheERwindow.
1
Thefirst,second,andthirdrowsshowrepresentationsintheassociativemodule,theslowlayerintheproprioception
module,andthefastlayerintheproprioceptionmodule,respectively. Solidlinesrepresentactivitiesofthreerandomly
chosendneurons,anddashedlinesrepresentthevalueoftheKLdivergenceateachtimestep. The4throwshows
predictions(solidlines)andsensations(dashedlines)ofjoint-angles. Forclarity,onlyfourjoint-anglesof16areshown.
Thebottomrowshowsthereconstructionerrorinproprioception.
ExperimentalresultsaresummarizedinTable4. Thereconstructionerrorinproprioceptionwasremarkablyminimized
comparedtothatinvision,inbothconditionsw andw .Thisisbecausevisioninvolvesmorenoisethanproprioception.
1 2
The reconstruction error in vision was smaller for the w condition than the w condition. Furthermore, the KL
1 2
divergenceintheassociativemodulewasreducedmoresignificantlyinthew conditionthanthew condition. This
1 2
occurred because the vision module generalized better with noisy visual patterns in the test of pseudo-imitative
interaction in the w case than in the w case by minimizing the complexity term more. Because fluctuation or
1 2
randomnessinvisualsensationwaswellresolvedinthevisionmoduleinthew case,theassociativemodulebecame
1
relativelyfreefromsuchfluctuation,asevidencedbythesmallerKLdivergenceobservedintheassociativemodule. As
aresult,theone-step,look-aheadpredictionwasalsomoreaccurate.
3.4 Experiment2: Imitationwithstrongerandweakeragency
Thisexperimentwasdevisedtorevealpossibleeffectsofchangingthetightnessusedtoregulatethecomplexitytermfor
theentirenetworkonthestrengthofagencyexertedinimitativeinteraction. Accordingly,weinvestigatedhowchanges
ofmeta-priorvaluesoftheentirenetworkfromdefaultvaluesusedinlearningaffectperformancecharacteristicsinthe
pseudo-imitativeinteraction. Weusedanetworkthatwastrainedfor4,000epochsinExperiment1withthew setting
1
asthedefaultnetwork. Fivemeta-priorsettingswerepreparedfortestingofimitativeinteraction: fromsmallervalues
ofthemeta-priorsettingW tothelargersettingW withaconsistentratioamongalllayersofallmodules(Table5).
1 5
Imitativeinteractionwithdifferentmeta-priorsettingswasperformedwiththenovelvisuo-proprioceptivepatternsused
inExperiment1. Interactionswereanalyzedintermsofthequantitiesintroducedinpreviousexperiments. Inaddition,
one-steplook-aheadpredictionerrorinproprioceptionwasalsomeasured. Eachtestwithadifferentmeta-priorsetting
wasrepeatedwith10networkmodelstrainedwithdifferentinitializationweights,butwiththesameparametersforthe
purposeofexaminingthesequantitiesstatistically.
15
Proprioception Vision Associative Proprioception
reconstructionerror reconstructionerror KLD slowKLD
w 0.017±9.5×10−4 0.12±6.9×10−3 2.0±0.091 1.6±0.12
1
w 0.011±2.9×10−4 0.19±1.5×10−2 3.2±0.15 2.6±0.11
2
Proprioception Vision Vision Visionone-step
fastKLD slowKLD fastKLD predictionerror
w 0.57±0.040 8.1±0.17 0.50±0.048 0.20±0.0097
1
w 0.57±0.041 1.9±0.071 0.54±0.048 0.24±0.017
2
Table4: Theresultofthepseudo-imitativeinteractionexperiment. Theerrorsarethestandarddeviationof10different
trialswithdifferentrandomnumberseeds.
W W W W W
1 2 3 4 5
Associativemodule 2.5×10−5 2.5×10−4 2.5×10−3 2.5×10−2 2.5×10−1
Proprioceptionslowlayer 5.0×10−5 5.0×10−4 5.0×10−3 5.0×10−2 5.0×10−1
Proprioceptionfastlayer 1.0×10−4 1.0×10−3 1.0×10−2 1.0×10−1 1.0
Visionslowlayer 2.5×10−5 2.5×10−4 2.5×10−3 2.5×10−2 2.5×10−1
Visionfastlayer 5.0×10−5 5.0×10−4 5.0×10−3 5.0×10−2 5.0×10−1
Table5: Thevaluesofmeta-priorinExperiment2.
ResultsaresummarizedinFigure6. Asawhole,withsmallervaluesofthemeta-prior,thereconstructionerrorwas
minimizedmore(Figure6(A)),andtheKLdivergenceremainedlarge(Figure6(D)),whereaswithlargervaluesof
themeta-prior,theKLdivergencewasminimizedmore(Figure6(D)),andthereconstructionerrorremainedlarge
(Figure6(A)). This tendency can also be seen in the local proprioception module and vision module, although the
reconstructionerrorinthevisionmodulewasnotsignificantlydifferent. Intheproprioceptionmodule,asvaluesofthe
meta-priorincreased,thereconstructionerrorinproprioceptionbecamelarge(Figure6(B)),andtheKLdivergence
becamesmall,bothintheslowlayer(Figure6(F))andinthefastlayer(Figure6(G)).Inthevisionmodule,asvaluesof
themeta-priorincreased,thoughthereconstructionerrorinvisiondidnotincreaseassignificantly(Figure6(C),theKL
divergencebecamesmallinboththeslowlayer(Figure6(H))andthefastlayer(Figure6(I)).TheKLdivergenceinthe
associativemodulealsoincreasedasvaluesofthemeta-priorincreased(Figure6(E)).Inaddition,withsmallervalues
ofthemeta-prior,theone-step,look-aheadpredictionerrorwasminimizedinbothproprioception(Figure6(J))andin
vision(Figure6(K)).
ThisisbecausetheKLdivergencetermintheevidencelowerboundwasweightedmoreforminimizationthanwas
the reconstruction error term. In this situation, the posterior q(z |d ,e ) at each time step in the ER window
t t−1 t:T(cid:48)
approacheditspriorp(z |d )bymodulatingtheadaptivevaluea ,whichisfedintothecomputationoftheposterior
t t−1 t
q(z|d ,e ),whilethepriorp(z |d )waslesschanged. Thismeansthatnetworkdynamicsweredrivenmainly
t−1 t:T(cid:48) t t−1
bytheprior,andwerelessaffectedbysensoryinputs. Networkdynamicsbecomemoreegocentricbyfollowingthe
prior,whichwaslessmodifiedbylooserregulationofthecomplexityterm(i.e.,moreweightingfortheKLdivergence
term). Ontheotherhand,withtighterregulation(i.e.,lessweightingoftheKLdivergenceterm),networkdynamics
becamemoreadaptivetochangesorfluctuationsofsensoryinputsbyfreelymodulatingtheposteriorinthedirectionof
errorminimizationwithoutbeingmuchconstrainedbytheprior. Inthiscondition,thepriorp(z |d )ateachtime
t t−1
stepinthewindowalsochangesbecausetheposteriorq(z |d )attheprevioustimestep,whichismappedto
t−1 t−2
p(z |d )throughd alsochanges.
t t−1 t
In the course of pseudo-imitative interaction, when the network observes a single time step of a new sensation, it
inferssequencesoftheposteriorinsidetheERwindowwiththeaforementionediterativecomputationoftheerror
regression. Figure7displayssomeexamplesoftheposteriorinferenceduringtheprocessinwhichtightregulationof
thecomplexityterm(W setting)(Figure7(A))andlooseregulationofthecomplexityterm(W setting)(Figure7
1 5
(B))arecompared. Forclarity,partofthenetworkresponsibleforproprioceptionisshown. Thecolumnsillustrate,
givenasingletimestepofsensoryobservation,howthenetworkinferredtheposteriorintermsofparametersofthe
posteriordistribution,meanµ,andvarianceσofmultivariateGaussiandistributionsundertheeffectofdifferentvalues
ofthemeta-priorthroughiterations. Fromtheleft,eachcolumnshowsnetworkdynamicsbeforetheinference,after
16
Figure 6: Reconstruction error, KL divergence minimization, and one-step, look-ahead prediction error in error-
regression with five meta-prior settings. (A) Sum of reconstruction errors in proprioception and vision. (B) The
reconstructionerrorinproprioception. (C)Thereconstructionerrorinvision. (D)SumoftheKLdivergenceinall
layers. (E)TheKLdivergenceintheassociativemodule. (F)TheKLdivergenceintheslowlayeroftheproprioception
module. (G)TheKLdivergenceinthefastlayeroftheproprioceptionmodule. (H)TheKLdivergenceintheslow
layerofthevisionmodule. (I)TheKLdivergenceofthefastlayerofthevisionmodule. (J)One-step,look-ahead
predictionerrorinproprioception. (K)One-step,look-aheadpredictionerrorinvision. Errorbarsrepresentthestandard
deviationof10modelswithdifferentweightinitialization. Asterisksrepresentthestatisticalsignificanceint-tests: ∗
forp<0.05,∗∗forp<0.01,and∗∗∗forp<0.001. Notethateachgraphhasadifferentscale.
5th,10th,15th,20th,25th,and30thiterationoftheupdateofadaptivevariableainsidetheERwindowwithBPTT.
Thefirst,third,andfifthrowsplottherelationshipamongthemeanofthepriorµp(bluelines),themeanoftheinferred
posteriorµq (redlines),andtheKLdivergence(dashedblacklines)intheassociativemodule,intheslowandfast
layersoftheproprioceptionmodule,respectively. Thesecond,fourth,andsixthrowsplotthevarianceofthepriorσp
(bluelines),thevarianceoftheinferredposteriorσq (redlines),andtheKLdivergence(dashedblacklines)inthe
associativemodule,intheslowandfastlayersoftheproprioceptionmodule,respectively. Althoughdimensionsofzin
thefastlayerandintheslowlayeroftheproprioceptionmodulearegreaterthanone,onlyonedimensionisplottedfor
visibility.
InW setting,thenetworkisassignedsmallervaluesofthemeta-prior,whichmeansthatthecomplexitytermistightly
1
regulated. Therefore,duringthecourseofposteriorinference,theinferredposteriorisallowedtodeviatesomewhat
fromthepriortominimizethereconstructionerrorcomparedtotheW settingwithlooserregulation. Thiscanbe
5
seeninFigure7(A).Intheleftmostcolumn,thenetworkencounteredalargereconstructionerrorinthelasttimestep
insidetheERwindow. Thisreconstructionerrorwaseventuallyresolvedwhileupdatingtheposteriorrepeatedlyasa
resultofdistributingtheKLdivergenceovertheentirenetworkinconsiderationofvaluesofthemeta-priorassignedto
eachlayer. IntheW setting,theassociativemodulehadthesmallestvalueofthemeta-prior,theslowlayerofthe
1
proprioceptionmodulehadonewithamoderatevalue,andthefastlayeroftheproprioceptionmodulehadthelargest
valueofthemeta-prior. Thus,thelargestdiscrepancybetweentheinferredposteriorandthepriorwasallowedinthe
associativemoduleandthesmallestdiscrepancyinthefastlayeroftheproprioceptionmodule. Thiscanbeconfirmed
bycomparingtheposterior,theprior,andthevalueofKLdivergenceineachlayerinFigure7(A).
Incontrast, intheW setting,thecomplexitytermislooselyregulatedwithlargervaluesofthemeta-prior, which
5
forcesthenetworktokeeptheKLdivergencesmallduringtheposteriorinference. ThiscanbeobservedinFigure7
(B).Duringtheiteration,thevalueoftheKLdivergencewasstronglysuppressed,andasaresult,thereconstruction
errorremainedlargeevenaftertheposteriorupdate. ComparedtoFigure7(A),theposteriorwasinferredsothatitwas
closertotheprior(redlinesareclosertobluelines).
17
Figure7: AnexampleoftheposteriorinferenceduringthepseudoimitativeinteractionintheW setting(A)andin
1
theW setting(B).Forclarity,onlythosepartsinvolvedintheproprioceptionmoduleareshown. Fromtheleft,each
5
columnrepresentsthenetworkrepresentationinsidetheERwindowbeforetheinference,afterevery5thiterationup
tothe30thiterationoftheposteriorinference. Thefirst,third,andfifthrowsshowtimetrajectoriesofthemeanµof
thezintheassociativemodule,theslowlayerofthepropriceptionmodule,andthefastlayeroftheproprioception
module,respectively. Theblueandredlinesrepresentthepriorµp andtheinferredposteriorµq,respectively. The
second,fourth,andsixthrowsshowthetimetrajectoriesofvarianceσofzintheassociativemodule,theslowlayerof
theproprioceptionmodule,andthefastlayeroftheproprioceptionmodule,respectively. Theblueandredlinesindicate
thepriorσp andtheinferredposteriorσq,respectively. DashedblacklinesindicatevaluesoftheKLdivergencein
eachlayer. Thebottomrowshowsthereconstructionerroratcorrespondingtimesteps.
Figure 8 (A) and (B) show examples of time-series plots of related neural activities of the proprioception module,
comparingcasesoftight(W setting)andloose(W setting)regulationofthecomplexityterm.Bothcasesarecomputed
1 5
forasituationobservingthesamevisuo-proprioceptivesequencepattern. Withtightregulationofthecomplexityterm
(Figure8(A)top),theobservationoftheprimitiveA(dashedlines)waswellreconstructed(solidlines)insidetheER
window(grayarea)fromtimesteps120to150,duetorelativelystrongerweightingoftheaccuracytermcomparedto
theW setting. Plotsaftertimestep150representfuturepredictionsoftheexpectationofencounteringtheprimitiveB.
5
Fromtimesteps150to180(Figure8(A)bottom),theagentobservednewsensoryinformationwheretheprimitive
CinsteadofthepredictedprimitiveofBwasencountered. (Rememberthatthereisa50%chanceofencountering
the primitive B or the primitive C.) This new observation was reconstructed inside the ER window. Based on the
inferredposteriorduringthisperiod,therobotupdatedthefuturepredictionaftertimestep180astheprimitiveCtobe
continued. Becauseofrelativelystrongerweightingintheaccuracyterm,theposteriorwasinferredtoadapttoreality.
Thepredictionwasalsoupdatedaccordingly(Figure8(A)bottom).
Inthecaseoflooseregulation(Figure8(B)top),theobservationwasstillwellreconstructedinsidetheERwindow.
ThisisbecauseprimitivepatternAalwaysfollowseitherprimitivepatternBorCsothatitiseasytopredictprimitive
18
A.Therefore,thereconstructionerrorinsidetheERwindowwassmallfromthebeginning. Plotsaftertimestep150
representfuturepredictionsexpectingprimitivepatternBtobeencountered. Afterobservingnewsensoryinformation
inwhichprimitivepatternCinsteadofthepredictedprimitivepatternBwasencounteredbetweentimesteps150and
180(Figure8(B)bottom);however,thenewobservationwasnotreconstructedwellinsidetheERwindow. Dueto
tightregulationoftheKLdivergenceterm(looseregulationofthecomplexityterm),theposteriorwasforcedcloserto
thepriorbyignoringthenewobservation. Consequently,theinferredposteriordidnotaffectthepriorasmuchasinthe
W setting,whichresultedingenerationofconsistentpredictionsforthefuture. Actually,thelook-aheadprediction
1
madeattimestep150,showninthetoprow,andtheonemadeattimestep180inthebottomrowarealmostthesame.
Theseobservationsimplythatboththepredictionofthefutureandthereflectionofthepastbecomemoreadaptive
tosensoryobservationinthecaseoftighterregulationofthecomplexityterm,whereastheybecomemorepersistent
regardlessofsensoryobservationsinthecaseoflooserregulation.
Figure8: Anexampleoftime-seriesplotsofneuralactivitiesintheoutputlayeroftheproprioceptionmoduleinthe
W setting(A)andintheW setting(B).Reconstructionofthepastobservationandthefuturepredictionattimestep
1 5
150(top)andattimestep180(bottom)areshown. Solidlinesrepresentpredictionoutputs,anddashedlinesrepresent
observations. The shadowed area indicates the error-regression window. For simplicity, only 4 of 16 joint-angles
representingmovementsareshown.
SomerepresentativevideosrelatedtoExperiment2canbeseenatvideolinkAandatvideolinkBfortheW condition
1
andtheW condition,respectively. Thesevideosshowhowpredictionofthefutureaswellasreflectionofthepast
5
canbeperformedforeachcondition. Also,furthertemporaldetailsduringtheerror-regressionprocesscanbeseen
atvideolinkCandatvideolinkDfortheW conditionandtheW condition,respectively. Inthesevideos,thereis
1 5
somedivergencebetweenthepriorandtheposteriorintermsofmeanandvarianceandtheyaredynamicallychanging
insidetheER-WintheW condition,whereasthesetwoprofilesapproximateeachother,showingrelativelypersistent
1
patternsintheW condition. Theseobservationsaccordwithouranalysis,describedpreviously.
5
4 Discussion
Thecurrentstudyinvestigatedunderlyingmechanismofthestrengthofagencyinsocialinteractionbyproposinga
modelforimitativeinteractionusingmultimodalsensationbasedontheframeworkofPCandAIF.Weproposeda
hypothesisthattightnessusedtoregulatethecomplexitytermintheevidencelowerboundintheproposedmodel
shouldcontributetothestrengthofagency. Thishypothesiswasevaluatedbyconductingsimulationexperimentsona
pseudo-human-robotimitativeinteractionusingthemodel.
First,weexaminedpossibleeffectsofchangingthetightnessusedtoregulatethecomplexitytermforeachsensory
moduleduringthelearningphaseincoordinationandintegrationofdifferentmodalitiesofsensationandthoseinthe
testimitationphase. Ourresultsshowedthatthecomplexityterminthevisionmoduleshouldberegulatedmorethan
thatoftheproprioceptionmodule. Thisisbecausevisionandproprioceptionaresignificantlydifferentwithrespectto
theirintrinsicrandomness,asvisualinputsfluctuatemoreduetoopticalconditions,suchasilluminationandsurface
reflectiveness. Weconcludedthatthecomplexityterminthevisionmoduleshouldberegulatedmuchmorethanthat
fortheproprioceptionmoduletoachievebettergeneralizationinlearning.
Next,weinvestigatedthestrengthofagencyasthemainfocusofthecurrentstudybychangingthetightnessusedto
regulatethecomplexitytermfortheentirenetworkrelativetothatwhichwasintroducedinthetrainingphase. Forthis
purpose,characteristicsofpseudo-imitativeinteractionwereexaminedbyscalingthemeta-priorofeachmoduleequally
tolargerorsmallervaluesusingthenetworkthathadbeenevaluatedassuccessfulinthepreviousexperiment. Our
resultsdemonstratedthatchangingthemeta-priorthiswayaffectsperformancecharacteristicsofimitativeinteraction
significantly. Withlooserregulationofthecomplexityterm,theagenttendstoactmoreegocentrically,withoutadapting
19
totheother. Incontrast,withtighterregulationofthecomplexityterm,theagenttendstofollowitshumancounterpart
byadaptingitsinternalstate. ThisresultimpliesthatthestrengthofSoAcanbemodulatedbyadjustingthetightness
withwhichthecomplexitytermisregulatedafterthelearningphase.
Inthecurrentstudy,weevaluatedthishypothesisbyconsideringataskofimitativeinteractionbetweenarobotand
ahumancounterpart. Insuchanimitativeinteraction,therecouldbetwosituations: therobotfollowsthehuman’s
movements,orthehumanfollowstherobot’smovements. Inourexperimentalresults,theagentwithtightregulation
ofthecomplexitytermcorrespondedtotheformercase,andthatwithlooseregulationtothelatter. Thesefindings
couldprovidenewinsightsintocomputationalmodelingstudiesofMNS.Ourgroup’spreviousstudies(Ahmadiand
Tani,2017;Hwangetal.,2020)onmodelingMNSusingdeterministicRNNsthatwereappliedtorobotimitation
experiments, introduced a scheme similar to the ER scheme described in the current study, in the sense that both
reinterpretpastobservationsandupdatefuturepredictions. Inthemodel,deterministiclatentvariablesattheonset
timestepoftheimmediatepastwindowareupdatedbymeansoftheERscheme. Sincetheselatentvariablesarenot
constrainedbyanypriorprobabilitydistribution(unlikethesequentialpriorscheme),theyadapttosensorysequences
encounteredforminimizingtheerrordirectlywhereinthespeedofupdatingissimplydeterminedbytheadaptationrate
toupdatethelatentvariables.
On the other hand, in the case of the ER, which uses PV-RNN, the update of stochastic latent variables z at each
timestepinsidetheERwindowareconstrainedbythesequentialpriorrepresentedintermsofaGaussianprobability
distribution. IfthePV-RNNisdevelopedmoretowarddeterministicdynamicsbysettingthemeta-priorwithlarger
values,thesequentialpriorforeachstochasticlatentvariableshouldhaveapeakydistributionwithrelativelysmall
variance. In such a case, the approximate posterior cannot adapt to the sensory sequence by using the propagated
errorsignalbecausethecurrentpriorisestimatedwithastrongbelief. Incontrast,ifthePV-RNNisdevelopedtoward
a more random process by setting the meta-prior with smaller values, at each time step the prior should exhibit a
wide distribution with large variance. Then, the posterior can easily adapt to the sensation using the error signal,
becausethecurrentpriorisestimatedwithaweakbelief. Therefore,thePV-RNNcanshowbothmirrorneuron-type
adaptiveresponseandegocentricbehavior,dependingonthesettingofthemeta-priorininteractionsamongagents.
ThedeterministicRNNmodelsshowninAhmadiandTani(2017);Hwangetal.(2020),however,canonlyshowmirror
neuron-likeadaptiveresponses.
Byfollowingtheabovediscussion,oneessentialadvantageofusingvariationalRNNs,suchasPV-RNN,comparedwith
conventionaldeterministicRNNs,isthattheycanpredictnotonlyfuturecontents,butcanalsoestimatepredictabilityof
suchpredictionsorinotherwords,thecredibilityofprediction,asdiscussedinformulationofthefree-energyprincple
(Friston,2005). Thissortofcognitivecompetencyofsecondorderpredictionbymeansofrepresentingthebeliefof
prediction,bywhichthestrengthofagencycanbemechanized,providesmodelingofagents,includingcognitiverobots
withmorecomplexityandrichnessinwaysofinteractingwithotheragents,aswellasthephysicalworld,asthecurrent
studydemonstrates,atleastpartially.
Ineverydaysocialinteractions,humansdon’tjustfollowothers,nordotheyleadthemallthetime. Ratherhumans
sometimesfollowothersandsometimesleadthem,dependingonthemoment-by-momentcontextorsocialsituation.
Psychologicalstudiesindicatethatturn-takingbetweenfollowingandleadingcanoccurquitespontaneouslyinvarious
social cognitive behaviors, including conversation (Sacks et al., 1978), mother-infant pre-verbal communication
(Trevarthen,1979)andimitation(Nadel,2002). Inconsideringpossiblemechanismsunderlyingturn-taking,some
researchers (Ikegami and Iizuka, 2007; Ito and Tani, 2004) suggest that turn-taking may develop due to potential
instability, suchaschaosformedincoupleddynamicsbetweentwoagentsintheirmodelingstudies. Weconsider
meta-leveldynamicscouplingtwoagents,wherebythevalueofthemeta-priortoregulatethecomplexitytermsin
thetwoagentscounteractoneanothermutually. Thiscouldresultinautonomousshiftsbetweentheleadingmodeby
increasingthemeta-priorandthefollowingmodebyreducingit.
Futurestudiesshouldexaminetheaforementionedmechanismforturn-takingbyconductinganonlineexperiment
ofhuman-robotinteractions. However,thecomputationalcostofonlineerror-regressionfortheposteriorinference
hasbeenthemajorbottleneckforconductingsuchexperimentsinrealtime, andthisiswhythecurrentstudywas
limitedtoasimulationofpseudo-imitativeinteractionusingrecordedvisuo-proprioceptivesequencepatterns,rather
than introducing actual, real-time, human-robot interaction. Although our group has shown that some real-time
experimentsusingonlineERarepossibleusingonlythesensorymodalityofproprioception(ChameandTani,2019),
itbecomesprohibitivewhenalsousingvision,withsufficientpixelresolution. Regardingthisproblem,somemay
suggestemployingothertypesofvariationalmodels,suchasavariationalrecurrentneuralnetwork(VRNN)(Chung
etal.,2015),becauseaVRNNdemandsfarlesscomputationtime,sincetheposteriorateachtimestepcanbeinferred
bysimplesequentialmappingofinputsusinganautoencoder(Kingmaetal.,2016). However,thecurrentschemefor
inferenceoftheposteriorthroughiterativecomputationforoptimizationisprobablyvitalforanyembodiedcognitive
systemsthatrequirerapidadaptationofinternalstatestotheenvironment.Actually,AhmadiandTani(AhmadiandTani,
20
2019)showedthatPV-RNNperformsbetterthanVRNNinonlinepredictionindynamicallychangingenvironmentsby
inferringtheposteriorusingtheerror-regressionscheme. Therefore,futurestudiesshouldexplorepossiblemethods
foracceleratingonlineerror-regressionofthemodel,suchasbymassiveparallelizationsoastoconductreal-time,
human-robotinteractionsusingthecurrentmodel.
Ethicsstatement
Writteninformedconsentwasobtainedfromtheindividualsforpublicationofanypotentiallyidentifiableimagesor
dataincludedinthisarticle.
ConflictofInterestStatement
Theauthorsdeclarethattheresearchwasconductedintheabsenceofanycommercialorfinancialrelationshipsthat
couldbeconstruedasapotentialconflictofinterest.
AuthorContributions
WOandJTconceivedtheconceptsandmodelsandcontributedtothewriting. WOconductedtheexperiments.
Funding
ThisstudywassupportedbyfundingfromOkinawaInstituteofScienceandTechnologyGraduateUniversity.Thisstudy
hasalsobeenpartiallysupportedbyaGrant-in-AidforScientificResearch(A)inJapan,20H00001,“Phenomenologyof
AlteredConsciousness: AnInterdisciplinaryApproachthroughPhilosophy,Mathematics,Neuroscience,andRobotics”.
Acknowledgments
WethanklabmembersintheCognitiveNeuroroboticsResearchUnit. WeareespeciallygratefultoAhmadrezaAhmadi
andPrasannaVijayaraghavanfortheirhelpindevelopingthemodel. WethankSiqingHouforhishelpincollecting
data. WealsothankStevenD.Airdforeditingthemanuscript.
References
Ahmadi,A.andTani,J.(2017). Howcanarecurrentneurodynamicpredictivecodingmodelcopewithfluctuationin
temporalpatterns? roboticexperimentsonimitativeinteraction. NeuralNetworks92,3–16
Ahmadi,A.andTani,J.(2019). Anovelpredictive-coding-inspiredvariationalrnnmodelforonlinepredictionand
recognition. Neuralcomputation31,2025–2074
Aly,A.andTapus,A.(2015). Anonlinefuzzy-basedapproachforhumanemotionsdetection: Anoverviewonthe
humancognitivemodelofunderstandingandgeneratingmultimodalactions. InIntelligentassistiverobots(Springer).
185–212
Baltieri,M.andBuckley,C.L.(2017). Anactiveinferenceimplementationofphototaxis. InArtificialLifeConference
Proceedings14(MITPress),36–43
Battaglia,P.W.,Jacobs,R.A.,andAslin,R.N.(2003). Bayesianintegrationofvisualandauditorysignalsforspatial
localization. Josaa20,1391–1397
Boucenna,S.,Cohen,D.,Meltzoff,A.N.,Gaussier,P.,andChetouani,M.(2016). Robotslearntorecognizeindividuals
fromimitativeencounterswithpeopleandavatars. Scientificreports6,19908
Boucenna,S.,Gaussier,P.,Andry,P.,andHafemeister,L.(2014). Arobotlearnsthefacialexpressionsrecognitionand
face/non-facediscriminationthroughanimitationgame. InternationalJournalofSocialRobotics6,633–652
Buckley,C.L.,Kim,C.S.,McGregor,S.,andSeth,A.K.(2017). Thefreeenergyprincipleforactionandperception:
Amathematicalreview. JournalofMathematicalPsychology81,55–79
Chame, H. F. and Tani, J. (2019). Cognitive and motor compliance in intentional human-robot interaction. arXiv
preprintarXiv:1911.01753AcceptedforpublicationinIEEEICRA2020
21
Choi,M.andTani,J.(2018). Predictivecodingfordynamicvisualprocessing: Developmentoffunctionalhierarchyin
amultiplespatiotemporalscalesrnnmodel. Neuralcomputation30,237–270
Chung,J.,Kastner,K.,Dinh,L.,Goel,K.,Courville,A.C.,andBengio,Y.(2015). Arecurrentlatentvariablemodel
forsequentialdata. InAdvancesinneuralinformationprocessingsystems.2980–2988
Clark,A.(2015). Surfinguncertainty: Prediction,action,andtheembodiedmind(OxfordUniversityPress)
Di Pellegrino, G., Fadiga, L., Fogassi, L., Gallese, V., and Rizzolatti, G. (1992). Understanding motor events: a
neurophysiologicalstudy. Experimentalbrainresearch91,176–180
Friston, K. (2005). A theory of cortical responses. Philosophical transactions of the Royal Society B: Biological
sciences360,815–836
Friston,K.(2012). Prediction,perceptionandagency. InternationalJournalofPsychophysiology83,248–252
Friston,K.(2018). Doespredictivecodinghaveafuture? Natureneuroscience21,1019
Friston,K.,Mattout,J.,andKilner,J.(2011). Actionunderstandingandactiveinference. Biologicalcybernetics104,
137–160
Friston,K.J.,Daunizeau,J.,andKiebel,S.J.(2009). Reinforcementlearningoractiveinference? PloSone4,e6421
Friston, K. J., Daunizeau, J., Kilner, J., and Kiebel, S. J. (2010). Action and behavior: a free-energy formulation.
Biologicalcybernetics102,227–260
Gallagher,S.(2000). Philosophicalconceptionsoftheself: implicationsforcognitivescience. Trendsincognitive
sciences4,14–21
Gallese,V.,Fadiga,L.,Fogassi,L.,andRizzolatti,G.(1996). Actionrecognitioninthepremotorcortex. Brain119,
593–609
Higgins,I.,Matthey,L.,Pal,A.,Burgess,C.,Glorot,X.,Botvinick,M.,etal.(2017). beta-vae: Learningbasicvisual
conceptswithaconstrainedvariationalframework. Iclr2,6
Hohwy,J.(2013). Thepredictivemind(OxfordUniversityPress)
Hurley,S.L.(2005). Perspectivesonimitation: Fromneurosciencetosocialscience(MITpress)
Huys,R.,Daffertshofer,A.,andBeek,P.J.(2004). Multipletimescalesandmultiformdynamicsinlearningtojuggle.
Motorcontrol8,188–212
Hwang,J.,Kim,J.,Ahmadi,A.,Choi,M.,andTani,J.(2020). Dealingwithlarge-scalespatio-temporalpatternsin
imitativeinteractionbetweenarobotandahumanbyusingthepredictivecodingframework. IEEETransactionson
Systems,Man,andCybernetics: Systems50,1918–1931
Ikegami,T.andIizuka,H.(2007). Turn-takinginteractionasacooperativeandco-creativeprocess. InfantBehavior
andDevelopment30,278–288
Ito,M.andTani,J.(2004). On-lineimitativeinteractionwithahumanoidrobotusingadynamicneuralnetworkmodel
ofamirrorsystem. AdaptiveBehavior12,93–115
Kawato,M.,Furukawa,K.,andSuzuki,R.(1987). Ahierarchicalneural-networkmodelforcontrolandlearningof
voluntarymovement. Biologicalcybernetics57,169–185
Kilner, J. M., Friston, K. J., and Frith, C. D. (2007). Predictive coding: an account of the mirror neuron system.
Cognitiveprocessing8,159–166
Kingma,D.P.andBa,J.(2014). Adam: Amethodforstochasticoptimization. arXivpreprintarXiv:1412.6980
Kingma,D.P.,Salimans,T.,Jozefowicz,R.,Chen,X.,Sutskever,I.,andWelling,M.(2016). Improvedvariational
inferencewithinverseautoregressiveflow. InAdvancesinneuralinformationprocessingsystems.4743–4751
Kohler,E.,Keysers,C.,Umilta,M.A.,Fogassi,L.,Gallese,V.,andRizzolatti,G.(2002).Hearingsounds,understanding
actions: actionrepresentationinmirrorneurons. Science297,846–848
Kording,K.P.,Tenenbaum,J.B.,andShadmehr,R.(2007). Thedynamicsofmemoryasaconsequenceofoptimal
adaptationtoachangingbody. Natureneuroscience10,779–786
LeCun,Y.,Boser,B.,Denker,J.S.,Henderson,D.,Howard,R.E.,Hubbard,W.,etal.(1989). Backpropagationapplied
tohandwrittenzipcoderecognition. Neuralcomputation1,541–551
LeCun,Y.,Bottou,L.,Bengio,Y.,andHaffner,P.(1998). Gradient-basedlearningappliedtodocumentrecognition.
ProceedingsoftheIEEE86,2278–2324
Lee,T.S.andMumford,D.(2003). Hierarchicalbayesianinferenceinthevisualcortex. JOSAA20,1434–1448
22
Legaspi,R.andToyoizumi,T.(2019). Abayesianpsychophysicsmodelofsenseofagency. Naturecommunications10,
1–11
Liu,R.,Lehman,J.,Molino,P.,Such,F.P.,Frank,E.,Sergeev,A.,etal.(2018). Anintriguingfailingofconvolutional
neuralnetworksandthecoordconvsolution. InAdvancesinNeuralInformationProcessingSystems.9605–9616
Moore,J.W.,Wegner,D.M.,andHaggard,P.(2009).Modulatingthesenseofagencywithexternalcues.Consciousness
andcognition18,1056–1064
Nadel,J.(2002). Imitationandimitationrecognition: Functionaluseinpreverbalinfantsandnonverbalchildrenwith
autism. Theimitativemind: Development,evolution,andbrainbases4262
Newell,K.M.,Liu,Y.-T.,andMayer-Kress,G.(2001). Timescalesinmotorlearninganddevelopment. Psychological
review108,57
Nishimoto,R.andTani,J.(2009).Developmentofhierarchicalstructuresforactionsandmotorimagery:aconstructivist
viewfromsyntheticneuro-roboticsstudy. PsychologicalResearchPRPF73,545–558
Ogata,T.,Nishide,S.,Kozima,H.,Komatani,K.,andOkuno,H.G.(2010). Inter-modalitymappinginrobotwith
recurrentneuralnetwork. PatternRecognitionLetters31,1560–1569
Oliver,G.,Lanillos,P.,andCheng,G.(2019). Activeinferencebodyperceptionandactionforhumanoidrobots. arXiv
preprintarXiv:1906.03022
Oztop,E.,Kawato,M.,andArbib,M.(2006). Mirrorneuronsandimitation: Acomputationallyguidedreview. Neural
networks19,254–271
Oztop,E.,Kawato,M.,andArbib,M.A.(2013). Mirrorneurons: functions,mechanismsandmodels. Neuroscience
letters540,43–55
Pezzulo,G.,Rigoli,F.,andFriston,K.J.(2018). Hierarchicalactiveinference: Atheoryofmotivatedcontrol. Trends
incognitivesciences22,294–306
Pitti,A.,Quoy,M.,Lavandier,C.,andBoucenna,S.(2020). Gatedspikingneuralnetworkusingiterativefree-energy
optimizationandrank-ordercodingforstructurelearninginmemorysequences(infernogate). NeuralNetworks121,
242–258
Rao, R. P. and Ballard, D. H. (1999). Predictive coding in the visual cortex: a functional interpretation of some
extra-classicalreceptive-fieldeffects. Natureneuroscience2,79
Rizzolatti, G. and Fogassi, L. (2014). The mirror mechanism: recent findings and perspectives. Philosophical
TransactionsoftheRoyalSocietyB:BiologicalSciences369,20130420
Rumelhart,D.E.,Hinton,G.E.,andWilliams,R.J.(1985). Learninginternalrepresentationsbyerrorpropagation.
Tech.rep.,CaliforniaUnivSanDiegoLaJollaInstforCognitiveScience
Sacks,H.,Schegloff,E.A.,andJefferson,G.(1978). Asimplestsystematicsfortheorganizationofturntakingfor
conversation. InStudiesintheorganizationofconversationalinteraction(Elsevier).7–55
Shimojo,S.(2014). Postdiction: itsimplicationsonvisualawareness,hindsight,andsenseofagency. Frontiersin
psychology5,196
Smith, M. A., Ghazizadeh, A., and Shadmehr, R. (2006). Interacting adaptive processes with different timescales
underlieshort-termmotorlearning. PLoSbiology4
Synofzik,M.,Vosgerau,G.,andNewen,A.(2008). Beyondthecomparatormodel: amultifactorialtwo-stepaccountof
agency. Consciousnessandcognition17,219–239
Tani,J.andNolfi,S.(1999). Learningtoperceivetheworldasarticulated: anapproachforhierarchicallearningin
sensory-motorsystems. NeuralNetworks12,1131–1141
Trevarthen,C.(1979). Communicationandcooperationinearlyinfancy: Adescriptionofprimaryintersubjectivity.
Beforespeech: Thebeginningofinterpersonalcommunication1,530–571
Valentin,P.,Boucenna,S.,Gaussier,P.,andPitti,A.(2019). Robotrecognizingvowelsinamultimodalway. In2019
JointIEEE9thInternationalConferenceonDevelopmentandLearningandEpigeneticRobotics(ICDL-EpiRob)
(Oslo,Norway),9thInternationalConferenceonDevelopmentandLearningandEpigeneticRobotics(ICDL-EpiRob),
103–104
Werbos, P. (1974). Beyond regression: New tools for prediction and analysis in the behavioral sciences. Ph. D.
dissertation,HarvardUniversity
Yamashita,Y.andTani,J.(2008). Emergenceoffunctionalhierarchyinamultipletimescaleneuralnetworkmodel: a
humanoidrobotexperiment. PLoScomputationalbiology4,e1000220
23

=== REVISE TO ===
PROFESSIONAL TONE: Begin directly with content - NO conversational openings like 'Okay, here's...'

1. Fix all issues above
2. Title: "Investigation of the Sense of Agency in Social Cognition, based on frameworks of Predictive Coding and Active Inference: A simulation study on multimodal imitative interaction"
3. Include 10-15 quotes from paper text
   - Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
   - Use consistent quote formatting: 'The authors state: "quote"' or vary attribution phrases
   - Vary attribution phrases to avoid repetition
   - CRITICAL: Only extract quotes that actually appear in the paper text
4. ELIMINATE ALL REPETITION - each sentence must be unique
   - Check before each sentence: 'Have I already said this?' If yes, write something new
   - Vary attribution phrases - do NOT repeat 'The authors state' multiple times
5. Extract methodology, results with numbers, key quotes
6. 1000-1500 words, structured with ### headers

Generate COMPLETE revised summary.