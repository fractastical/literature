=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Active Exploration based on Information Gain by Particle Filter for Efficient Spatial Concept Formation
Citation Key: taniguchi2022active
Authors: Akira Taniguchi, Yoshiki Tabuchi, Tomochika Ishikawa

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2022

Abstract: Autonomous robots need to learn the categories of various places by exploring
theirenvironmentsandinteractingwithusers.However,preparingtrainingdatasets
withlinguisticinstructionsfromusersistime-consumingandlabor-intensive.More-
over, effective exploration is essential for appropriate concept formation and rapid
environmental coverage. To address this issue, we propose an active inference
method,referredtoasspatialconceptformationwithinformationgain-basedactive
exploration (SpCoAE) that combines...

Key Terms: ritsumeikan, university, gain, concept, filter, efficient, information, particle, inference, spatial

=== FULL PAPER TEXT ===

ARTICLE TEMPLATE
Active Exploration based on Information Gain by Particle Filter
for Efficient Spatial Concept Formation
Akira Taniguchiaâˆ—, Yoshiki Tabuchib, Tomochika Ishikawaa,
Lotfi El Hafic, Yoshinobu Hagiwarac, and Tadahiro Taniguchia
aCollege of Information Science and Engineering, Ritsumeikan University, Shiga,
Japan;
bGraduate School of Information Science and Engineering, Ritsumeikan University,
Shiga, Japan;
cResearch Organization of Science and Technology, Ritsumeikan University, Shiga,
Japan
ARTICLE HISTORY
Compiled June 13, 2023
ABSTRACT
Autonomous robots need to learn the categories of various places by exploring
theirenvironmentsandinteractingwithusers.However,preparingtrainingdatasets
withlinguisticinstructionsfromusersistime-consumingandlabor-intensive.More-
over, effective exploration is essential for appropriate concept formation and rapid
environmental coverage. To address this issue, we propose an active inference
method,referredtoasspatialconceptformationwithinformationgain-basedactive
exploration (SpCoAE) that combines sequential Bayesian inference using particle
filters and information gain-based destination determination in a probabilistic gen-
erativemodel.Thisstudyinterpretstherobotâ€™sactionasaselectionofdestinations
to ask the user, â€˜What kind of place is this?â€™ in the context of active inference.
This study provides insights into the technical aspects of the proposed method, in-
cluding active perception and exploration by the robot, and how the method can
enable mobile robots to learn spatial concepts through active exploration. Our ex-
perimentdemonstratedtheeffectivenessoftheSpCoAEinefficientlydetermininga
destination for learning appropriate spatial concepts in home environments.
KEYWORDS
Active exploration, active inference, probabilistic generative model, particle
filtering, spatial concept
1. Introduction
Service robots deployed in office and home settings, where they should autonomously
categorize and identify various locations through interactions with their surrounding
environment and users. Semantic mapping, which assigns a label to an environmental
map [1,2], was recently proposed. In contrast, spatial concept-based approaches allow
unsupervised learning frameworks to categorize unknown places and flexible word as-
signments from user-language interactions [3,4]. The spatial concept is defined as the
âˆ—Correspondingauthor.Email:a.taniguchi@em.ci.ritsumei.ac.jp
3202
nuJ
21
]OR.sc[
2v43901.1122:viXra
Active exploration
Where can I
go to learn
about places
efficiently?
Movement Onlinelearning
There is living
What kind of
room.
place is this? â€¦..
â€¦..
Figure 1. Active exploration and learning of spatial concepts by the robot. The robot explores a position
that would provide the most information and reduce uncertainty. First, the robot decides which destination
to explore from the candidate destinations in the environment. After moving, the robot asks the user, â€˜What
kindofplaceisthis?â€™toobservethepositionandwords.Subsequently,therobotlearnsspatialconceptsbased
on the observations. Following this, the robot decides where to go next based on the spatial concepts it has
formed.Theaboveprocessisrepeated.
abstracted categorical knowledge of locations derived from the multimodal observa-
tions gathered through spatial perception in robots. However, to collect the training
data, the user follows and manipulates the robot, moves, and speaks multiple times
at each location to be taught. To solve these problems, robots should actively de-
termine and move autonomously toward their destinations. Learning through active
exploration requires the user to speak only when asked by the robot, which reduces
the burden on the user.
Our challenge is task-independent and interactive knowledge acquisition, in which
the robot asks the user questions. At the interface between artificial intelligence
and computational neuroscience, free-energy principle (FEP)-based active inference
(AIF) [5] has gained attention as an approach through which agents actively ex-
plore and acquire knowledge. The expected free energy based on AIF theoretically
encompasses information gain (IG), which is commonly used in traditional active
perception/learning in robotics, and provides further inspiration. The application of
AIF theories in robotics has gained increasing importance [6,7]. AIF encompasses
active exploration and online learning loops, which serve as the foundation for our
study. In the field of robotics, studies have been conducted on active exploration for
simultaneous localization and mapping (SLAM) [8], that is, active SLAM [9â€“11] and
activeperception/learningformultimodalcategorization[12,13].Ourstudyintegrated
these approaches, leading to active semantic mapping [14,15]. This study differs from
vision-and-language navigation (VLN) [16â€“18], which uses task-dependent knowledge
acquisition without AIF as its theoretical foundation. We focus on active exploration
inspired by AIF for grounding a spatial lexicon in a mobile robot.
The learning procedure that uses the active exploration approach is illustrated in
Figure 1. While moving in any environment, robots can acquire multimodal data on
places, such as the names spoken by users and their locations. The robot can actively
explore uncertain locations and ask the user questions. This allowed the robot to learn
spatial concepts efficiently. However, learning spatial concepts through active explo-
ration has not been achieved in previous studies [3,4]. In particular, it is important to
2
conduct efficient exploration that leads to appropriate concept formation and quickly
encompasses the environment rather than haphazard exploration.
This study addresses three main aspects: learning accuracy, learning efficiency, and
movement efficiency.
(i) Learning accuracy: Selecting data in an order that allows learning to be sta-
ble and accurate is important. In online unsupervised learning, such as particle
filtering, the order of the observed data affects the estimation accuracy [19].
(ii) Efficiency of learning: Inactive exploration,it is efficient to adapt tothe envi-
ronmentquickly.Itisrequiredtoreachasufficientlyaccuratelearningresultthat
encompasses the environment in a few steps. To reduce the uncertainty of learn-
ing results concerning the environment, learning by exploring using informationâ€“
theoretical criteria is expected to be effective [12,13].
(iii) Efficiency of movement: For mobile robots, the costs associated with travel
distancemustalsobeconsidered.Exploringadistantlocationrequiresmoretime
to move.
This study aims to improve the efficiency of learning spatial concepts through au-
tonomous active exploration using a mobile robot. Therefore, we propose an AIF-
inspired method that combines sequential Bayesian inference based on particle filters
and destination determination based on IG called spatial concept formation with IG-
based active exploration (SpCoAE). By considering the active exploration of spatial
conceptformationasanoptimizationproblem,werealizeautonomousdecision-making
for the questioning behavior of the robot.
This study also considers aspects of a constructive approach in cognitive develop-
mental robotics and symbolic emergence in robotics [20â€“22]. A probabilistic genera-
tive model (PGM) for spatial concept formation was proposed as a world model [23].
Learning and inferring world models is important for building human-like intelligent
machines[6].TheimplementationofAIFbasedonFEP,whichisproposedasafunda-
mental principle of the brain [5,24â€“27], and demonstrating its feasibility is challenging
in the robotics field [7].
The main contributions of this study are as follows.
1. We show that a robot can probabilistically relate flexible location-related words to
a map through place categorization by actively determining the destination and
asking the user there.
2. We realize active inference for efficient spatial concept formation by leveraging the
posteriordistributionestimatedbyparticlefilter-basedonlinelearningforIG-based
active exploration.
3. We demonstrate that the utility function, including the IG and travel distance,
achieves more efficient exploration compared to the baselines, suggesting a corre-
spondence with the expected free energy.
The remainder of this paper is organized as follows: Section 2 presents research on
spatial concept acquisition and active exploration. Section 3 describes the background
of AIF based on FEP. Section 4 describes the proposed method, SpCoAE, and the
online learning of spatial concepts. Section 5 presents experiments performed using a
simulator in multiple home environments. Section 6 discusses experiments performed
in real environments. Finally, Section 7 concludes the paper.
3
2. Related work
Asresearchrelatedtothisstudy,wedescribespatialperception,spatialconceptforma-
tion and semantic mapping in Section 2.1 and active spatial perception, exploration,
and learning in Section 2.2.
2.1. Spatial perception and semantic mapping
Recently, semantic mapping has been emphasized [1,2]. However, several studies
have provided preset labels for specific map areas. For example, LexToMap [28] as-
signs convolutional neural network-recognized lexical labels to a topological map.
Voxblox++[29]andKimera[30]constructeddensemetric-semanticmapsusingRGBD
(or dense-stereo) cameras. By contrast, our approach allows unsupervised learning to
categorize unknown places and flexible word assignments.
The robot must learn the spatial concepts online to select its next destination. In
onlinespatialconceptformationandlexicalacquisitionwithSLAM(SpCoSLAM) [3,4],
online learning is achieved by estimating parameters representing spatial concepts
usingparticlefilters.Incidentally,neuroscientificfindingssuggestthatspatialcognition
and inference take place in the hippocampal formation of the brain [31,32]. Online
learning with models such as spatial concept formation has been suggested to be
consistent with the function of the hippocampal formation [33]. Therefore, similar
to SpCoSLAM, the proposed method learns spatial concepts through online learning
using particle filters.
Considering the burden on the user, the robot was required to explore the envi-
ronment by moving actively. Thus far, the applications developed related to spatial
concepts include action selection for object tidy-up [34], spatial concept-based naviga-
tion by using speech instructions (SpCoNavi) [35], knowledge transfer across multiple
environments [36â€“38] and the relative location concept formation [39]. However, previ-
ous studies on spatial concept learning have used passive learning methods for robots,
in which a user manipulates the robot or the robot moves in the environment by fol-
lowing the user. The IG-based active exploration method proposed in this study has
the potential to be applied to these PGMs.
The VLN is the latest applied research that focuses on the boundary area between
computer vision and natural language processing for mobile robots [16,17]. Typical
conventional VLNs provide detailed linguistic texts that specify a route to a goal.
Accordingly, they performed navigation task-oriented knowledge acquisition through
numerous trial-and-error attempts using benchmark simulators [18,40]. By contrast,
our approach to spatial concept formation allows for non-task-oriented spatial knowl-
edge acquisition, including bottom-up lexical acquisition, even from small amounts of
real-world data.
2.2. Active spatial perception, exploration, and learning
Active SLAM selects the next destination when the robot performs SLAM in an envi-
ronment[9,11].IG-basedactiveSLAM[9]usesentropytodeterminemovedestinations
such that the uncertainty is reduced with FastSLAM, a particle-filter-based online
SLAM method [41,42]. Owing to the numerous candidate destinations, a frontier ap-
proach [43] was used to limit the candidate search points. In another approach, graph
structures have been proposed for fast exploration [10,44]. Active Neural SLAM [45]
4
and hierarchical AIF-based SLAM [46] have also been used for deep learning-based
SLAM. However, active SLAM does not involve learning place-related words or cate-
gories.
Active semantic mapping is a challenging task that involves efficiently exploring
spacewhileaccuratelycapturingthesemanticsoftheenvironment[11].Self-supervised
embodied active learning (SEAL) uses perception models trained on internet images
for active exploration policies [15], while our study employs unsupervised learning
without pre-training datasets. Veiga et al. proposed information-reward models based
on partially observable Markov decision processes [14]. Unlike room-specific models,
our study employed a unified model for spatial concept uncertainty. Instead of defin-
ing rewards and policies [14,15], our study directly determines actions using IG based
on PGM. Semantic octree mapping and Shannon mutual information computations
were proposed for autonomous robot operations in unstructured and unknown envi-
ronments [47]. This study is positioned as an active semantic mapping approach that
learns through active exploration to make a linguistic sense of the map, rather than
mapping.
Active robot learning approaches for language acquisition and understanding have
been developed. Efficient natural language understanding through interactive spa-
tial concept learning that considers user instructions and the environment is im-
portant [48,49]. Active learning was introduced to estimate the command ambiguity
in tabletop object manipulation in robot language acquisition [50]. Efficient cross-
situational object-word learning was achieved by actively selecting the order of the
training samples [51]. These studies have implications for constructive models for chil-
dren autonomously acquiring language. This study aims to achieve efficient spatial
language acquisition by robots through active action selection.
Online learning is appropriate for learning through active exploration because
new data are obtained each time. Active perception/learning, in which a robot ac-
tively selects the next piece of information to observe when recognizing object cate-
gories, has been proposed [12,13]. Based on a multimodal hierarchical Dirichlet pro-
cess (MHDP) [52], which is a hierarchical Bayesian model of multimodal categoriza-
tion, a robot selects an action corresponding to a sensory modality such as tactile,
visual, and auditory modalities. However, MHDP-based active perception/learning
methods [12,13] use a batch-learning algorithm based on Gibbs sampling. These con-
ventionalmethodscomputetheIGbyMonteCarloapproximationwithnewsampling,
whereastheproposedmethodusestheresultsofonlineestimationusingparticlefilters
to compute IG.
Many active-action selection methods use the IG maximization criterion, which is
known to satisfy submodularity [12]. Obtaining words related to a place from a user at
thepositionwheretheIGismaximizedisexpectedtoefficientlyreducetheuncertainty
in spatial concept formation.
The latest research on active exploration and visual goal navigation leverages se-
mantics as an approach to learning through exploration based on curiosity and other
factors [53,54]. In addition, recent studies on VLN have used deep and reinforcement
learning [16,17]. By contrast, the proposed method is an unsupervised learning ap-
proach based on a PGM; it conducts active exploration using probabilistic inference
based on information-theoretic criteria. The proposed method uses abstracted loca-
tions in the ground language, while ensuring extensibility to vision.
In the field of embodied computer vision, curiosity, novelty, coverage, and recon-
struction have been defined independently for exploration [55]. In contrast, AIF can
naturally combine these indicators into a single principle. In addition, applications of
5
AIF to robots include the estimation and control of body movements [56] and multi-
modal affective human-robot interactions [57]. This study is also significant because
it applies AIF to a robot that collects data in its environment by moving with an
embodied body.
3. Foundational Concepts: Active inference based on free energy principle
with world model
The FEP provides a unified explanation for the mechanisms of action, perception, and
learning [24]. Various theories of the brain, such as the Bayesian brain hypothesis [58]
and motor control, can be explained in a unified manner by the FEP [25]. When
humans estimate the state of the external world based on their perceptions, they
actively select the action most likely to provide the most information regarding that
state (i.e., they may maximize the expected free energy) [26,27]. This is called the
AIF [5], which infers what to do next to resolve the uncertainty.
A robot should acquire knowledge about its environment through active infer-
ence [6]. Forming a representation of the world (i.e., an internal representation of
the perception of the world) is necessary to appropriately promote action generation.
This abstract model of the environment is called the world model [6,23,59â€“61]. In
particular, predictive coding [62], which learns to predict future observations, can ef-
ficiently reduce uncertainty in the knowledge of the environment. In this study, we
constructed a PGM for spatial concept formation as a world model.
FEP is realized by simultaneous or reciprocal iterative inference of perceptual in-
ference and AIF [5]. In the perceptual inference formula proposed by Friston et al.,
variational free energy is defined, and an approximate posterior distribution is ob-
tained by variational inference. In this section, we assume that Z is the set of the
hidden states (latent variables), X is the set of observations, and q(Z) is the varia-
tional approximate distribution. In the FEP, the general equations (Eqs. (1) and (2))
for the variational and expected free energies have been proposed [5,24]. Here, the
probability distributions, p(Z | X) and q(Z), are arbitrary.
The variational free energy for perceptual inference and learning is described as
follows:
F(q,p;X) = D [q(Z)âˆ¥p(Z | X)]âˆ’logp(X). (1)
KL
where D [qâˆ¥p] is the Kullbackâ€“Leibler (KL) divergence between the distributions q
KL
and p. It is inferred that moves q(Z) closer to the posterior distribution p(Z | X).
The expected free energy for AIF is stated as follows:
G(Ï€,Ï„) = âˆ’E [D [q(Z | X ,Ï€)âˆ¥q(Z | Ï€)]]âˆ’E [logp(X )] (2)
q(XÏ„ |Ï€) KL Ï„ Ï„ Ï„ q(XÏ„ |Ï€) Ï„
(cid:124) (cid:123)(cid:122) (cid:125) (cid:124) (cid:123)(cid:122) (cid:125)
informationgain expectedlog-evidence
where policy Ï€ indexes a sequence of control states from current time t to the future.
The future time was Ï„ > t. The notation E [f(X)] represents the expected value
q(X)
of a function f(X) with respect to the distribution q(X).
IG (also called mutual information [11]) is responsible for the epistemic value term
in the expected free energy of the AIF. The epistemic value is also called the value
of information or intrinsic value. Epistemic value can be interpreted as the resolution
6
(i)Determination of (ii)Movement
destination by IG
ğ‘=1 ğ‘=2 ğ‘=3
ğ‘âˆ—=4
Section 4.3, Eq. (33)
Active exploration
Next step Algorithm 2(Line 13)
(Algorithm 2)
Ï„â†Ï„+1
What kind of (iii)Observation of
(iv)Online learning for
spatial concepts Section 4.2 place is this? multimodal information
(Algorithm 1) There is
living room.
â€¦..
User utterances
about place ğ‘† ğ‘› â€¦..
Robotâ€™s position ğ‘¥ ğ‘›
ğ‘¥,ğ‘¦ =(1.8,âˆ’2.0)
Figure 2. Overviewofflowoftheproposedmethod(SeeAlgorithm2fordetails.).(i)Therobotdetermines
nextdestinationaâˆ— usingtheutilityfunctionbasedonIG(SeeSection4.3;especiallyEq.(33)).(ii)Therobot
moves to the position xaâˆ— of the destination (See Algorithm 2, line 13). (iii) The robot asks the user, â€˜What
kind of place is this?â€™ to observe the position xn and words Sn (Here, n=aâˆ—) as multimodal observation of
the PGM in Figure 3. (iv) The robot learns spatial concepts based on the observations (See Section 4.2 and
Algorithm1).Theaboveprocessisrepeateduntilpotentialdestinationsareoveroruntillearningiscompleted
by sufficient exploration. In this scenario, it is assumed that a map has been pre-generated using SLAM,
allowingforaccurateself-localizationandnavigationtothedestination.
of uncertainty by motivating curiosity and novelty-seeking actions. The expected log
evidence is responsible for pragmatic value (extrinsic value).
Inthisstudy,therobotexploredandlearnedspatialconceptsautonomouslythrough
repeatedperceptual-basedonlinelearningandactiveexploration.Theperceptualinfer-
enceandlearningofthemodelparameterscorrespondtoonlinelearningusingparticle
filters. The variational inferences from Eq. (1) and the particle filter attempt to obtain
the same posterior distribution. This posterior distribution was approximated using
multiple samples (i.e., particles). IG maximization corresponds to policy selection in
AIF. If we assume the pragmatic value, whose prior distribution of the observed data
is uniform, the IG maximization becomes equivalent to the expected free energy mini-
mization. Instead of inferring the distribution of policy Ï€ and then determining action
a based on it as in Friston et al.â€™s formulation, we determine the action directly from
IG maximization.
4. Proposed method: Active Exploration for Spatial Concept Formation
In this study, we propose SpCoAE, a method for a robot to select the next destination
in the online learning of spatial concepts. Figure 2 illustrates the flow of the proposed
method. SpCoAE is an AIF-inspired method that combines online learning with par-
ticle filters (described in Section 4.2) and active exploration based on IG (formulated
in Section 4.3) in a PGM for spatial concept formation (defined in Section 4.1).
Section 4.1 presents model definitions. In this section, we describe the definition of
7
Gaussian mixture model Gaussian distribution
Clustering pairs of (position distribution)
word ğ‘† and place ğ‘– ï­ m,ï«
ğ‘› ğ‘› k 0 0
ğ¶ ğ‘† ğ‘– ğ‘–(cid:3404)6
(cid:3041) (cid:3041) (cid:3041) x ï“ V,ï® ğ‘–(cid:3404)1 ğ‘–(cid:3404)7
0 living room 2 n k 0 0
âˆ
ğ‘–(cid:3404)4 ğ‘–(cid:3404)5 ğ‘–(cid:3404)2
1 kitchen 8
1 cooking area 8 ï¡ ï° C n i n ï¦ l ï§ ğ‘–(cid:3404)3 ğ‘–(cid:3404)8 ğ‘–(cid:3404)0
2 bedroom 1
S W ï¢
2 bedroom 7 ğ‘ n l âˆ ğ¶ (cid:3041) :Index of spatial concepts
ãƒ»ãƒ»ãƒ» ãƒ»ãƒ»ãƒ» ãƒ»ãƒ»ãƒ»
Multimodal Dirichlet process mixture
ğ‘– (cid:3041) : Index of position distributions
Figure 3. Graphical model representation for spatial concept formation. The graphical model represents
conditional dependency between random variables. Gray and white nodes represent observations and unob-
servedlatentvariables,respectively.ThismodelisintegratedbyamultimodalDirichletprocessmixturewhose
emissiondistributionsaremultinomialdistributionsbasedonaGaussianmixturemodel.Table1summarizes
thedescriptionsofthevariablesinthemodel.
Table 1. Descriptionofthevariablesinthegenerativemodel.
Symbol Definition
xn Positionofrobot((x,y)-coordinatesoffloorplane)
Sn Wordsrepresentingplacecorrespondingtopositionxn (Bag-of-Words)
Cn Latentvariableforindexofspatialconcepts
in Latentvariableforindexofpositiondistributions
Ï€ ParametersofmultinomialdistributionforindexCn ofspatialconcepts
Ï•l Parametersofmultinomialdistributionforindexin ofpositiondistribution
Wl ParametersofmultinomialdistributionforobservingSn
Âµk,Î£k ParametersofGaussiandistribution(positiondistribution)forobservationofxn
Î±,Î²,Î³, HyperparametersofDirichletpriordistribution
m0,Îº0,V0,Î½0 HyperparametersofGaussianandinverseWishartpriordistributions
n Indexnumberoftrainingdata(nâˆˆ{1,2,...,N})
l Indexnumberofspatialconcepts(lâˆˆ{1,2,...,L})
k Indexnumberofpositiondistributions(kâˆˆ{1,2,...,K})
N Totalnumberoftrainingdata
L Upperlimitofnumberofspatialconcepts
K Upperlimitofnumberofpositiondistributions
the generative process of random variables in the proposed PGM for spatial concept
formation.BasedonthisPGM,onlinelearninginSection4.2andactiveexplorationin
Section 4.3 are executed. Section 4.2 discusses the learning of spatial concepts. In this
section, we present the mathematical derivation of the particle filter in the proposed
PGM. Section 4.3 describes the destination determination through active exploration.
In this section, we describe the formulation of IG-based active exploration and the
procedure for deriving the algorithm.
4.1. Probabilistic generative model
The capabilities of the proposed PGM are as follows. (i) Categorization is performed
using unsupervised learning based on multimodal observations. (ii) There is many-to-
many correspondence between the words and places. Moreover, the model does not
require a prior manual setting of the vocabulary labels or categories.
Figure 3 shows a graphical representation of spatial concept formation, and Table 1
summarizes the descriptions of the variables in the model. The generative process of
8
the model is as follows.
Ï€ âˆ¼ DP(Î±) (3)
Ï• âˆ¼ DP(Î³) l = 1,2,...,âˆ (4)
l
W âˆ¼ Dir(Î²) (5)
l
Î£ âˆ¼ IW(V ,Î½ ) k = 1,2,...,âˆ (6)
k 0 0
Âµ âˆ¼ N(m ,Î£ /Îº ) (7)
k 0 k 0
C âˆ¼ Cat(Ï€) n = 1,2,...,N (8)
n
i âˆ¼ Cat(Ï• ) (9)
n Cn
S âˆ¼ Mult(W ) (10)
n Cn
x âˆ¼ N(Âµ ,Î£ ) (11)
n in in
where DP() denotes the prior distribution in the Dirichlet process. Dir() is a Dirichlet,
Cat() is a categorical, Mult() is multinomial, IW() is an inverse-Wishart, and N() is
a Gaussian distribution. We refer to the literature on machine learning [63] for specific
formulas of the above probability distributions. In this study, the Dirichlet process
is represented as a stick-breaking process (SBP) [64,65]. We adopted a weak-limit
approximation [66] for SBP. Appropriate numbers of spatial concepts and position
distributions are probabilistically determined by learning based on observations.
4.2. Online learning algorithm
In this study, the robot learns spatial concepts from observations to select the next
move. Therefore, we introduced online learning using a Rao-Blackwellized particle fil-
ter (RBPF) [67] as in SpCoSLAM. This method estimates the posterior distributions
of the parameters of a spatial concept using words and positions as multimodal obser-
vations of a place. The learning algorithm is presented as Algorithm 1.
Thejointposteriordistributionsofalltheparameterstobeestimatedwhenlearning
spatial concepts and their factorization are as follows:
p(Î˜,C ,i | x ,S ,h)
1:n 1:n 1:n 1:n
= p(Î˜ | C ,i ,x ,S ,h)p(C ,i | x ,S ,h) (12)
1:n 1:n 1:n 1:n 1:n 1:n 1:n 1:n
where the parameter set of each spatial concept is Î˜ = {{Âµ },{Î£ },{Ï• },{W },Ï€}
k k l l
and the set of hyperparameters is h = {Î±,Î²,Î³,m ,Îº ,V ,Î½ }. Appendix A.4 explains
0 0 0 0
the calculation procedure for the posterior distribution of the model parameter Î˜.
4.2.1. Derivation and process in Rao-Blackwellized particle filter
Thesecondterm,p(C ,i | x ,S ,h),inEq.(12)wascalculatedusingtheRBPF.
1:n 1:n 1:n 1:n
The particle filter algorithm is based on sampling importance resampling. The process
can be summarized by the following steps:
Sampling: The latent variables C ,i are sampled simultaneously as the proposal
n n
9
Algorithm 1 Online learning algorithm for spatial concepts.
1: Z nâˆ’1 = {C 1 [r :n ] âˆ’1 ,i [ 1 r : ] nâˆ’1 ,Î˜ [ n r âˆ’ ] 1 }R r=1 , X 1:n = {x 1:n ,S 1:n ,h}
2: procedure Online Learning(Z nâˆ’1 ,X 1:n )
3: ZÂ¯ n = Z n = âˆ… â–· Initialize set of particles
4: for r = 1 to R do
5: C n [r] ,i [ n r] âˆ¼ p(C n ,i n | C 1 [r :n ] âˆ’1 ,i [ 1 r : ] nâˆ’1 ,x 1:n ,S 1:n ,h) â–· Sampling
6: Ï‰ n [r] = p(x n ,S n | C 1 [r :n ] âˆ’1 ,i [ 1 r : ] nâˆ’1 ,x 1:nâˆ’1 ,S 1:nâˆ’1 ,h) â–· Importance
7: Î˜ [ n r] = E[p(Î˜ | C 1 [r :n ] ,i [ 1 r : ] n ,x 1:n ,S 1:n ,h)] â–· Calculation of posterior
parameters
8: ZÂ¯ n = ZÂ¯ n âˆªâŸ¨C 1 [r :n ] ,i [ 1 r : ] n ,Î˜ [ n r] ,Ï‰ n [r]âŸ©
9: end for
10: for r = 1 to R do
11: draw j with probability âˆ {Ï‰ n [j]} â–· Resampling
12: add âŸ¨C 1 [j :n ] ,i [ 1 j : ] n ,Î˜ [ n j]âŸ© to Z n
13: end for
14: return Z n
15: end procedure
distribution, q , as follows1,2:
n
C ,i âˆ¼ p(C ,i | C ,i ,x ,S ,h) (13)
n n n n 1:nâˆ’1 1:nâˆ’1 1:n 1:n
âˆ p(x | x ,i ,h)p(S | S ,C ,Î²)p(C ,i | C ,i ,Î±,Î³).
n 1:nâˆ’1 1:n n 1:nâˆ’1 1:n n n 1:nâˆ’1 1:nâˆ’1
(14)
Importance Weighting: Weight Ï‰ is expressed as follows:
n
p(C [r] ,i [r] | x ,S ,h) P [r]
Ï‰[r] = 1:n 1:n 1:n 1:n = n (15)
n q(C [r] ,i [r] | x ,S ,h) Q [r]
1:n 1:n 1:n 1:n n
where r is the particle number, and R is the number of particles. The subsequent
equations were computed for each particle [r]; however, the subscripts indicating the
particle number were omitted.
Target distribution P can be transformed as follows3:
n
P âˆ p(C ,i | C ,i ,x ,S ,h)
n n n 1:nâˆ’1 1:nâˆ’1 1:n 1:n
p(x | C ,i ,x ,h)
n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1
p(S | S ,C ,h)P . (16)
n 1:nâˆ’1 1:nâˆ’1 nâˆ’1
1TheintermediateequationisprovidedinAppendixA.2.
2DetailsofthesimultaneoussamplingofCn andin arepresentedinAppendixA.3.
3TheintermediateformulasaregiveninAppendixA.1.
10
The proposal distribution Q can be transformed as follows:
n
Q = p(C ,i | C ,i ,x ,S ,h)
n n n 1:nâˆ’1 1:nâˆ’1 1:n 1:n
(cid:124) (cid:123)(cid:122) (cid:125)
qn
q(C ,i | x ,S ,h) (17)
1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1
(cid:124) (cid:123)(cid:122) (cid:125)
Qnâˆ’1
= q Q . (18)
n nâˆ’1
Here, the proposal distribution q is the marginal distribution of the parameter set Î˜
n
of latent variables C ,i .
n n
From Eqs. (15)â€“(18), weight Ï‰ is expressed as follows:
n
P
Ï‰ = p(x | C ,i ,x ,h)p(S | S ,C ,h)
nâˆ’1
. (19)
n n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 n 1:nâˆ’1 1:nâˆ’1
Q
nâˆ’1
(cid:124) (cid:123)(cid:122) (cid:125)
Ï‰nâˆ’1
The new weight terms for n in Eq. (19) are transformed and marginalized for C
n
and i as shown in Eq. (21). The terms in the sum operation are the same as those in
n
Eq. (14). These values were proportional to the proposal distribution q . These have
n
already been computed when C ,i is sampled from q . Therefore, all probabilities
n n n
were added before normalization.
p(x | C ,i ,x ,h)p(S | S ,C ,h)
n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 n 1:nâˆ’1 1:nâˆ’1
âˆ p(x ,S | C ,i ,x ,S ,h) (20)
n n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1
(cid:88)(cid:88)
= p(x | x ,i ,h)p(S | S ,C ,Î²)p(C ,i | C ,i ,Î±,Î³).
n 1:nâˆ’1 1:n n 1:nâˆ’1 1:n n n 1:nâˆ’1 1:nâˆ’1
Cn in
(21)
Resampling: As shown in lines 10â€“13 of Algorithm 1, the particles are sampled
again as R particles, according to their weights Ï‰ . After resampling, all the particles
n
have the same weights.
4.3. Active exploration algorithm
The proposed method uses IG, an information-theoretic measure, to select and move
towards a position in an environment that is most likely to reduce uncertainty. More-
over,itobtainsobservations,includinguserutterances.Thealgorithmfortheproposed
method is presented as Algorithm 2. The details of the derivation of the algorithm are
provided in Sections 4.3.1 and 4.3.2. We also describe a method for including costs
related to travel distance, as presented in Section 4.3.3.
4.3.1. Formulation of how to select destination
This section discusses, in the first half, the conceptual and basic formulations that un-
derlie active exploration and, in the second half, the practical formulation and deriva-
tion for executing the basic formulation with online learning.
Basic formulation of active exploration: The proposed method uses a for-
mulation that minimizes the KL divergence between the two types of posterior dis-
11
Algorithm 2 SpCoAE: Active exploration algorithm for spatial concept formation.
1: Initialize n 0 = âˆ…, Z 0 = âˆ…, X n0 = âˆ…
2: for Ï„ = 1 to T do â–· Number of action trials
3: for all {x a âˆˆ RD | free-space in a map} do â–· Number of candidate positions
4: for r = 1 to R do â–· Number of particles
5: for j = 1 to J do â–· Number of pseudo observations
6: X a [r,j] âˆ¼ p(X a | Z Ï„ [r âˆ’ ] 1 ,X n0 )
7: end for
8: end for
9: IG a = (cid:88) R (cid:88) J log (cid:80)R p(X p a [ ( r X ,j] [ | r,j Z ] Ï„ [ | r âˆ’ ] Z 1 , [r X â€²] n , 0 X ) )
r=1j=1 râ€²=1 a Ï„âˆ’1 n0
10: end for
11: aâˆ— = argmax a (IG a âˆ’Î·TravelCost(a)) â–· Select position x aâˆ—
12: n 0 = n 0 âˆª{aâˆ—}
13: Move to position x aâˆ— , and observe words S aâˆ— â–· Observe X n0
14: Z Ï„ = Online Learning(Z Ï„âˆ’1 ,X n0 )
15: end for
tributions4. The first is the final posterior distribution when data are observed N
times, p(Î˜,C ,i | x ,S ,h). The second is the current posterior distribu-
1:N 1:N 1:N 1:N
tion when the data are observed as the next destination from the current step,
p(Î˜,C ,i | x ,S ,h). This means determining the next observation so that
1:N 1:N n0 âˆªa n0 âˆªa
the distribution at the current observations makes similar to the final posterior dis-
tribution after all observations. This formulation aims to select data a. The index set
{1 : N} of the data points corresponding to multiple possible destinations for asking
the user a question is defined as the action set for a. In each step, as observed data is
obtained, it is minimized as follows:
minimizeD [p(Î˜,C ,i | x ,S ,h)âˆ¥p(Î˜,C ,i | x ,S ,h)]. (22)
a
KL 1:N 1:N 1:N 1:N 1:N 1:N n0 âˆªa n0 âˆªa
Note that n is the set of already observed data indices; that is, the subset of indices
0
of the plate representation from 1 to N in the graphical model for spatial concept
formation in Figure 3. In the first step, the case where data is unobserved is n = âˆ….
0
However,Eq.(22)cannotbecomputedinonlinelearning.Thisproblemmustbesolved
in some manner. Note that neither true {x ,S } nor {x ,S } can be observed
1:N 1:N a a
before moving to the next destination.
Formulation for computational feasibility: As a suitable alternative, we cal-
culated the expected value of the KL divergence using Eqs. (23)â€“(25)5 to obtain the
index of the candidate point aâˆ— of the data to be observed at the next destination as
4ThisformulationissimilartothatinMHDP-basedactiveperception/learningmethods[12,13].
5The transformation details of Eqs. (23)â€“(25); please refer to Appendix B.1. This derivation is based on
MHDP-basedactiveperception/learningmethods[12,13].
12
ğ‘ ğ‘ğ‘‹1:ğ‘ ğ‘ ğ‘ğ‘‹ğ‘›0âˆªğ‘
ğ‘ ğ‘âˆ— ğ‘
ğ·KL
ğ‘
ğ‘ ğ‘ğ‘‹ğ‘›0âˆªğ‘ ğ‘ ğ‘ğ‘‹ğ‘›0
ğ‘ ğ‘âˆ— ğ‘
ğ·KL
ğ‘
Figure 4. RelationshipdiagrambetweenEqs.(23)and(24).Eachellipseisdrawnasaspatialconcept.Top
(Eq.(23))representsanactiondecisionthatmovesthedistributionwhenanactionistaken(upperright)closer
tothefinalposteriordistribution(upperleft).Bottom(Eq.(24))representsanactiondecisionthatresultsina
distribution(bottomright)thatisthefurthestawayfromthecurrentdistribution(bottomright).Thisimplies
thattheseareequivalent.
follows:
aâˆ— = argminE [D [p(Z | X )âˆ¥p(Z | X )]] (23)
a
X{1:N}\n0 |Xn0 KL 1:N n0 âˆªa
= argmaxE [D [p(Z | X )âˆ¥p(Z | X )]] (24)
a
Xa |Xn0 KL n0 âˆªa n0
= argmaxIG(Z;X | X ), (25)
a n0
a
where a âˆˆ {1 : N}\n is the index of the data point to be observed at the next
0
destination, excluding the previously observed data n . Let Z = {C ,i ,Î˜},
0 1:N 1:N
X = {x ,S ,h}. Figure 4 shows the relationship between Eqs. (23) and (24),
n0 n0 n0
respectively. Eq. (24) expresses the maximization of the expected value of the KL
divergence between the posterior distributions after observing the data at the next
destination and the current step. Based on the information theory, the expected value
of the KL divergence in Eq. (24) is defined as IG in Eq. (25), i.e., IG(Z;X | X ) :=
a n0
E [D [p(Z | X )âˆ¥p(Z | X )]]. IG is known as mutual information [11].
Xa |Xn0 KL n0 âˆªa n0
4.3.2. Derivation of approximate computation of IG with particle filter
In this section, we describe a computationally efficient way to approximate IGs that
takes advantage of particle filter results in online learning. The formula for IG in
13
Eq. (25) as follows:
IG(Z;X | X )
a n0
(cid:20) (cid:21)
(cid:88)(cid:88) p(Z,X | X )
= p(Z,X | X )log a n0 (26)
a n0
p(Z | X )p(X | X )
Z Xa
n0 a n0
ï£® ï£¹
â‰ˆ (cid:88) R (cid:88) J ï£°Ï‰
n
[r
0
]log
(cid:80)R (cid:104)
p
p
(X
(X
a [j
[
]
j]
|
|
Z
Z
[r
[
]
r
,
â€²]
X
,X
n0 )
)Ï‰ [râ€²]
(cid:105)ï£»,
r=1j=1 râ€²=1 a n0 n0
Z[r] âˆ¼ q(Z | X ), X[j] âˆ¼ p(X | Z[r],X ) (27)
n0 a a n0
[r]
where R is the number of particles, J is the number of pseudo observations, and Ï‰
n0
is the particle weight. The equation above is approximated by sampling based on the
predictive distribution p(X | X ). There are two approximation levels.
a n0
First, p(Z | X ) is approximated by the estimated samples in a particle filter based
n0
on the observed values as follows:
(cid:88)
p(X | X ) = [p(X | Z,X )p(Z | X )] (28)
a n0 a n0 n0
Z
R
(cid:88)(cid:104) (cid:105)
â‰ˆ p(X | Z[r],X )Ï‰[r] , Z[r] âˆ¼ q(Z | X ). (29)
a n0 n0 n0
r=1
Next, p(X | Z[r],X ) in Eq. (29) can be approximated by sampling J pseudo
a n0
[j]
observations, where X denotes the pseudo observations obtained at the next desti-
a
nation. This distribution is expressed as follows:
p(X | Z,X ) = p(x ,S | C ,i ,x ,S ,h). (30)
a n0 a a n0 n0 n0 n0
[j]
When sampling the pseudo-observation X , assuming that x is fixed for some a,
a a
only S must be sampled. In this case, Eq. (30) is identical to Eq. (21) for weight
a
calculation in the particle filters.
X[j] = S | x âˆ¼ p(x ,S | C ,i ,x ,S ,h) (31)
a a a a a n0 n0 n0 n0
(cid:88)
= p(S | C ,S ,h)p(x | i ,x ,h)p(C ,i | C ,i ,h).
a n0 âˆªa n0 a n0 âˆªa n0 a a n0 n0
Ca,ia
(32)
In conventional similarity methods [12,13], the Monte Carlo approximation is per-
formed again. However, the proposed method can use the estimated results of existing
particle filters, as expressed in Eq. (27). As Z[r],Ï‰ [r] has already been estimated by
n0
the online learning algorithm, we can sample X [j] from p(X | Z[r],X ). Finally, we
a a n0
obtain probability p(X [j] | Z[r],X ) based on the sampled values. Weight Ï‰ [r] can be
a n0 n0
treated as a constant 1/R because it is resampled6. Thus, computational reuse based
on particle filters in learning can increase computational efficiency.
6Notethattheweightsneedtobeusediftheyarenotresampledbydevicessuchaseffectivesamplesize[68,69].
14
4
2
0
âˆ’2
âˆ’4
âˆ’6 âˆ’4 âˆ’2 0 2 4 6
x
(a)Simulatedhomeenvironment
y
(b)MapcreatedbySLAM
Figure 5. ExperimentalenvironmentonSIGVerseinExperimentI(Environment5)
4.3.3. Introduction of travel distance costs
When selecting a movable/reachable destination and controlling the robot at that
destination,IG(Eq.(27)).However,thecostofmovementalsoneedstobeconsidered.
In this study, the criterion of â€˜utilityâ€™ that includes the travel cost of distance, which
is used in active SLAM [9], is also introduced into the IG of SpCoAE. Therefore, the
utility function for destination a is defined as
aâˆ— = argmax(IG(Z;X | X )âˆ’Î·TravelCost(a)) (33)
a n0
a
where Î· is a parameter of a weighting factor that trades off the cost with the IG
and TravelCost(a) is the travel cost, which is the path length estimated by the Aâ‹†
algorithm from the current position to the target position, x , on the map.
a
Thus, the IG and travel costs can be treated as a tradeoff. Consequently, the des-
tination (a) that maximizes the utility, represented by Eq. (33) can be determined as
the optimal destination x , and the robot can move to that point.
aâˆ—
The introduction of travel costs has similar implications for the incorporation of
state transitions, that is, movements and time steps. The graphical model of SpCoAE
does not include SLAM. However, the consideration of state transitions is inherently
desirable because the robot moves to different locations on the map. Theoretically, we
expect the travel cost to act as an approximation of the state transition probabilities
in a graphical model such as SLAM. We believe that a graphical model of SpCoAE
can be integrated into SLAM in the future.
5. Experiment I: Simulator environments
We evaluated whether active exploration using the proposed method enables efficient
spatial concept formation.
5.1. Condition
In this experiment, we used a simulator environment with a virtual Toyota human-
support robot (HSR) [70]. We used a map (Figure 5b) created in advance in the home
environment (Figure 5a) constructed using the SIGVerse [71] simulator as the ex-
perimental environment. SIGVerse is a virtual environment platform for robots that
integratesUnity,agamedevelopmentengine,andRobot Operating System (ROS) [72],
15
a robot software platform. For mapping, we used the ROS package gmapping7, which
was implemented based on the grid-based FastSLAM 2.0 [42] algorithm. The inputs
for the SLAM were the depth sensor data from the lidar on the robot as the measured
values and odometry data as the control values.
Candidate position coordinates for data observation were set at 0.8 m intervals in
the white free space in the map in Figure 5b. Within this space, if there is a wall or an
obstacle within 0.5 m of the candidate positions, the candidates are deleted to provide
space for the HSR with a diameter of 0.43 m to move. In addition, a single exploration
was performed for each candidate point, and once a candidate point was searched, it
was assumed that it would not be searched again. It is assumed that the travel to a
destination by self-localization and path planning is accurate.
Figure 8a shows the ideal form of the spatial concept and the position distribu-
tion set by the tutor. The color of the candidate points where the data are ob-
served represents the index of the spatial concept C , and the color of the ellipses
n
corresponds to the index of the position distribution i . The ideal model parame-
n
ters are set such that for the spatial concept index C , both the index of the posi-
n
tion distribution i and the word of the place are assigned one-to-one. Specifically,
n
it is assumed that the same word is observed at all candidate points and indicated
by the same color. The word given at a candidate point corresponding to place is
Living room, Dining room, Kitchen, Bedroom A, Bedroom B, Bedroom C, Corridor,
Toilet, Bathroom, or Entrance. Bedroom A, Bedroom B, and Bedroom C are pseudo-
representations of the unique names called at certain places in the onsite environment,
e.g., Bobâ€™s room or catsâ€™ playroom.
ThenumberofparticleswassettoR = 1000,andthenumberofpseudo-observations
was J = 10. The hyperparameters are set as Î± = 1.0, Î² = 0.01, Î³ = 0.1, m =
0
[0.0,0.0]T, Îº = 0.001, V = diag(1.5,1.5), Î½ = 4.0. The upper limits for the number
0 0 0
of categories were set as K = 10 and L = 10.
5.2. Comparison methods
The following comparison methods were used:
(A) SpCoAE: The proposed method (IG maximization).
(B) SpCoAE with travel cost:Theproposedmethod(maximizationoftheIGwith
thetravelcost).ThenextdestinationpointisdeterminedusingEq.(33)described
in Section 4.3.3. The weighting factor for the travel cost is Î· = 0.005.
(C) Random: A method to randomly select a destination point with a uniform dis-
tribution.
(D) Travel cost: A method to select a destination point in order to decrease travel
cost.
(E) IG min: A method to select a destination point in order of decreasing IG.
5.3. Evaluation metrics
Evaluation of learning performance: As an evaluation metric, we adopted the
adjusted Rand index (ARI), which measures clustering performance. An ARI value
close to 0.0 indicates random clustering, whereas an ARI value close to 1.0 indicates
high clustering performance. In this experiment, the ARI value between the estimated
7ROSWiki:gmapping,http://wiki.ros.org/gmapping
16
Table 2. Evaluationresults(meanandstandarddeviation)oftentrialsineachof
thetenenvironments.
ARI Travel distance
Methods Cn in [grid/step]
SpCoAE 0.942(0.055) 0.920(0.067) 48.96(7.90)
SpCoAEwithtravelcost 0.953(0.041) 0.938(0.055) 22.79(4.36)
Random 0.878(0.076) 0.829(0.087) 71.37(9.82)
Travelcost 0.936(0.053) 0.919(0.066) 12.07(1.09)
IGmin 0.832(0.094) 0.755(0.116) 40.86(6.17)
result for each particle and the ideal clustering result was calculated, and the sum of
thevaluesmultipliedbytheweightofeachparticlewasevaluatedastheweightedARI.
We evaluated both the index of the spatial concept C and the index of the position
n
distribution i . Because the proposed method involves online learning, two metrics
n
are used: (i) ARI (step-by-step) for the observed data only at each step and (ii) ARI
(predictive padding) for all data, that is, observed and unobserved data. In predictive
padding, the latent variables for unobserved data are predicted and filled based on the
posteriorpredictivedistribution.Thisdistributionusesthespatialconceptparameters
Î˜ = {{Âµ },{Î£ },{Ï• },{W },Ï€} estimated at each step. The ARI (step-by-step) can
k k l l
be expected to show a value close to 1.0 in the first few steps, owing to its nature;
however, it does not necessarily indicate a high clustering performance.
Evaluation of learning efficiency: Two metrics were used to evaluate the learn-
ing efficiency. (i) Normalized minimum step above threshold (NMS) is the mini-
mum step that results in ARI (predictive padding) â‰§ 0.6, normalized to [0,100] for
the final step. NMS indicates that quick and high learning performance has been
achieved. (ii) Learning stability rate (LSR) is the percentage of steps that result in
ARI (predictive padding) â‰§ 0.6 (i.e., the total number of steps that result in ARI
higher than 0.6 / the final step in each environment). LSR indicates that the learning
performance is stable and high for multiple steps.
The lower the NMS and the higher the LSR, the higher the efficiency of quick en-
vironmental adaptation in learning. For spatial concept formation, an ARI of approx-
imately 0.6 or higher is sufficient to perform well on tasks such as navigation [35,73].
Evaluation of movement efficiency: The travel distance at each step was eval-
uated to compare the travel amount and time spent in the environment. The travel
distance is the total number of cells that move on the occupancy grid map. The move-
ment path is assumed to be obtained by path planning using the Aâ‹† algorithm from
the current self-position to the destination position.
5.4. Results
Evaluation values for each step: Figure 6 shows the mean and error bars for the
standard deviation of each evaluation value for all ten trials8. In terms of the ARI
(step-by-step), overall, SpCoAE showed higher values than the other methods. This
resultisattributedtothefactthatSpCoAEcanselectadestinationthatallowsspatial
concepts to be learned more accurately in each step. In addition, SpCoAE with travel
cost had consistently higher values than SpCoAE in steps 10 â€“ 40. In terms of the
ARI (predictive padding), SpCoAE had slightly inferior values compared with the
random method in the initial steps, whereas it showed higher values in the later steps.
SpCoAE is more effective for learning precise spatial concepts. In addition, SpCoAE
8The spatial concept learning results and evaluation values per environment for the ten environments are
presentedinAppendixD.
17
(a)ARI(step-by-step)ofCn (b)ARI(predictivepadding)ofCn (c)Cumulativetraveldistance
SpCoAE TravelCost
SpCoAE_TravelCost IG_min
Random
(d)ARI(step-by-step)ofin (e)ARI(predictivepadding)ofin (f)Legends
Figure 6. Evaluationvaluesforeachstep(Environment5)
with travel costs exhibited the highest value in the final step, although it was inferior
to SpCoAE in the first half. These results suggest that searching for one place after
another in the environment is advantageous for predicting unexplored regions during
the learning process. In terms of the cumulative travel distance, introducing travel
cost into SpCoAE resulted in a smaller value. The random method was less efficient
for movement because the travel distance was greater.
Evaluation result of learning efficiency: Figure 7 compares the methods for
LER and NMS with C and i . The results show that SpCoAE and the random
n n
method have higher learning efficiencies than the other methods. This indicates that
these methods are effective for rapidly covering an entire environment.
Evaluation values at the last step:Table2summarizestheevaluationresultsfor
all ten environments. The travel distance was normalized by the number of candidate
search points (i.e., the number of final steps) to adjust for the impact of the scale of
each environment. Consequently, the proposed method shows a higher ARI than the
othermethods;inparticular,SpCoAEwithtravelcostshasthehighestvalue.Further-
more, in terms of travel distance, the introduction of travel costs is effective, even in
environments with different structures. Thus, overall, IG-based SpCoAE, specifically
SpCoAE with travel costs, is shown to be effective.
Qualitative results: Figure 8 shows the results of learning spatial concepts for
each exploration method in Environment 5. The proposed methods were closer to
the ideal form than the other methods. However, the Random and IG min methods
have a higher tendency to combine multiple locations into a single category than the
proposed methods. For example, in Figure 8d, the bedroom and entrance, as well as
thehallwayandbathroom,hadthesamedistribution.InFigure8f,alargedistribution
can be observed across the bathroom, toilet, hallway, and kitchen. This indicates that
the order of exploration affects the learning of spatial concepts. Figure 9 shows an
example of sequential spatial concept formation constructed using SpCoAE. In Steps
25â€“28, the robot searches the three bottom-left locations consecutively. Steps 36â€“40
18
100
80
60
40
20
SpCoAE SpCoAE Random TravelCost IG_min
_TravelCost
C dlohserht
evoba
pets
muminim
dezilamroN
*
* p < 0.01 n.s.
*
* *
n.s.
* 100
80
60
40
20
SpCoAE SpCoAE Random TravelCost IG_min
_TravelCost
(a)NMSâ†“ofindexCn
i dlohserht
evoba
pets
muminim
dezilamroN
*
* p < 0.01 *
*
* *
n.s.
*
(b)NMSâ†“ofindexin
1.0
0.8
0.6
0.4
0.2
0.0
SpCoAE SpCoAE Random TravelCost IG_min
_TravelCost
C etar
ytilibats
gninraeL
*
* p < 0.01 n.s.
*
* *
n.s.
* 1.0
0.8
0.6
0.4
0.2
0.0
SpCoAE SpCoAE Random TravelCost IG_min
_TravelCost
(c)LSRâ†‘ofindexCn
i etar
ytilibats
gninraeL
*
* p < 0.01 *
*
* *
n.s.
*
(d)LSRâ†‘ofindexin
Figure 7. Box-and-whisker plot of learning efficiency constructed using the evaluation values of ten trials
gathered in each of the ten environments. The up or down arrows point in the direction of the desired value.
The statistical significance between the methods was checked by Welchâ€™s t-test with Bonferroniâ€™s adjustment
formultiplecomparisons.Ap-valueoflessthan0.01wasconsideredstatisticallysignificant.
focusedontheupper-middleroom.ThisindicatesthatSpCoAEcansufficientlyreduce
the uncertainty regarding a location by searching several times in a row in areas where
the location name is not provided and where there is uncertainty. In other words, the
robot can reduce the entropy of the word distribution for a location by obtaining
multiple instructions in close positions. It then searches for a different location. This
means that the robot has obtained enough observations about the location.
Discussion: According to our results, SpCoAE with travel costs achieved a higher
ARI than SpCoAE. This can be attributed to the exploration tendency of pure IG,
which tends to focus on the outer areas of the environment, potentially hindering
the exploration of the central area. By incorporating the travel cost, we consider
that the exploration candidate points were more evenly distributed throughout the
environment, including in the central areas. Based on the AIF framework, the travel
cost can be considered a pragmatic/extrinsic value with a preference, and can be
regarded as an appropriate approximation of the expected free energy. This finding
highlights the importance of considering both IG and distance in exploration and
learning strategies for effective semantic mapping.
19
(a)Ideal (b)SpCoAE (c)SpCoAEwithtravelcost
(d)Random (e)Travelcost (f)IGmin
Figure 8. Examplesoflearningresultsforeachmethod(Environment5):Theseresultsareforthehighest
weightedparticleinthefinalstep.Ellipsesdrawnonmaparepositiondistributions{Âµk,Î£k }.Colorsofellipses
indicate indices i1:n of position distributions. Colors of candidate points indicate indices C1:n of spatial con-
cepts. Colors of each ellipse and each candidate point are randomly determined for each trial. Sub-figure (a)
showstheidealformenvisionedbythetutor.Thismeansthatclusteringresultscloseto(a)aredesirable.
6. Experiment II: Real environment
The effectiveness of the proposed method was investigated in a realistic environment.
This experiment relaxed some of the limitations of Experiment I and demonstrated
the method in a more realistic scenario.
6.1. Condition
A room simulating a home environment was used as the experimental environment.
Figure 10 shows the actual environment and the robot. This experiment was set up in
a more difficult setting than Experiment I owing to the increased uncertainty. First,
the linguistic information provided by the user comprises multiword sentences. We
assume that the sentence is the response given by the user when the robot asks, â€˜Tell
me what kind of place is this?â€™ A different sentence is provided for each candidate
point. Examples of these sentences are as follows: â€˜A low table is placed between the
TV and the sofa, where one can place drinks and other refreshments.â€™ â€˜The room
in which you sleep at night is called a bedroom.â€™ â€˜The bathroom is used after first
filling the bathtub with hot water for washing the body.â€™ This linguistic information is
convertedintoabag-of-wordsrepresentationbypreprocessingasfollows:(i)Nonletters
have been removed. (ii) The hyphens were removed to separate them before and after.
(iii) All uppercase letters were converted to lowercase letters. (iv) Nouns are unified
into singular forms and (v) Stop words were removed.
Secondly, in this experiment, a single candidate was explored several times as a
challenge. This is because visiting a single candidate point once may not provide
sufficient information. In addition, visiting candidate points with a low priority should
20
Step 25 Step 28
Step 36 Step 40
Figure 9. Learning process of spatial concepts and position distributions by active exploration of the pro-
posed method in several steps (Environment 5). Each point indicates the position from which the robot has
acquireddatathusfar.
not be explored. In this case, the robot explored up to 100 steps because it could
explore infinitely.
ThenumberofparticleswassettoR = 1000,andthenumberofpseudo-observations
was set to J = 10. The hyperparameters are set as follows: Î± = 1.0, Î² = 0.1, Î³ =
0.01, m = [0.0,0.0]T, Îº = 0.001, V = diag(1.0,1.0), Î½ = 5.0. The upper limits for
0 0 0 0
the number of categories were set as K = 10 and L = 10.
6.2. Result
Figure 11 illustrates the learning process for active exploration in SpCoAE. For each
position distribution, a place-related word corresponded to each location. In approxi-
mately25steps,theexplorationofallroomswascompleted,andtheworddistribution
became stable. For example, â€˜bedroomâ€™ and â€˜sleepâ€™ in the lower right distribution and
â€˜shoeâ€™ and â€˜boxâ€™ in the upper left distribution are learned as words that characterize
places. Not only are place labels predefined, but the proposed method can also appro-
priately assign words that are called in the on-site environment and words related to
the place in the environment.
Figure 12 shows the transition of the IG values for each step. The value of IG forms
several peaks, rising and falling, and then converges to almost 0 after step 80. This
suggests that terminating the number of exploration steps according to the IG may
be effective. In other words, this suggests that the robot may be able to determine
whether or not to explore new areas based on the value of IG.
Furthermore, when the results in Figures 11 and 12 are combined, the following
can be inferred: In the initial steps, after IG decreased, an increase in IG values was
observed as a new distribution was created (e.g., steps 9, 22, and 33). After Step
33, the number of position distributions does not increase, and each is estimated as
an existing distribution. Even after the number of distributions stops increasing, the
area indicated by the position distribution tends to cover more of the entire area as
exploration progresses. As the IG values changed, the word distribution varied. This
may be attributable to the exploration of words that better represent places. Steps
21
Shelf Shelf
Shoe box
Door
Bathtub
Sofa
Chair
Sink TTaabbllee Desk Bookshelf
Chair
Low table Bed
TV Sofa Sofa
(a)HSR[70] (b)Realenvironment (c)Floorplan
Figure 10. RealrobotandrealexperimentalenvironmentinExperimentII:Thesizeoftheenvironmentis
8mÃ—9.4mwithanareaofapproximately74m2.Inthisenvironment,sixareasareassumed.Thenumberof
candidatesearchpointsis53.
80â€“100 exhibit little change. Because the candidate point is not explored, even in Step
100, a place is sufficiently informative owing to the already learned spatial concept.
In this experiment, the exploration was repeated for candidate points on an ad-
vanced trial basis. This approach may be particularly effective when dealing with
dynamic environments. In other words, when the robot revisits a previously explored
location, and the environment has changed, the entropy of the locationâ€™s distribution
increases, suggesting a greater possibility that the robot will further explore the area.
In conclusion, we demonstrated that SpCoAE works in real-world environments with
multiword utterances.
7. Conclusion
In this study, we proposed an active exploration algorithm for the spatial concept
formationofarobot.TheproposedmethodachievesAIFbyselectingcandidatepoints
with the maximum IG and performing online learning from observations obtained
at the destination. Simulation experiments demonstrate the effectiveness of active
exploration in terms of more accurate spatial concept formation. In addition to the
IG, introducing the cost of travel distance was effective. In real-world experiments
in which multiple words were provided, exploration proceeded to clarify the word
corresponding to a place.
WerealizedAIFwithmodelsinwhichthepositionandwordobservationswereused
for place categorization. Further valid categorization using visual images available at
the location, as in SpCoSLAM, is possible. The prospects include the application of
activeexplorationtothePGMofSpCoSLAM.Tothisend,weplantostudycandidate
selection, including image features and integration with active SLAM in unknown and
unmapped environments.
Inthisstudy,therobotlearnedspatialconceptsfromscratchbyaskingthequestion,
â€˜What kind of place is this?â€™. The use of generalized prior knowledge in multiple envi-
ronments [36â€“38] and large-scale language models [74,75] accelerates learning through
active exploration. This is expected to further reduce the number of questions and
diversify the question generation. Integration with such an approach is an emphasized
22
2
0
2
4
6
8
4 2 0 2 4 6
x
y
2
0
2
4
6
8
(a)Step5 4 2 0 2 4 6
x
y
(b)Step20
2
0
2
4
6
8
4 2 0 2 4 6
x
y
2
0
2
4
6
8
(c)Step25 4 2 0 2 4 6
x
y
(d)Step80
Figure 11. Process of spatial concept formation by active exploration in several steps (Experiment II).
Top five words according to the value of pointwise mutual information (PMI) with word s for each position
distribution k are obtained, i.e., PMI(Sn = s;in = k) = log(p(Sn = s | in = k,Î˜)/p(Sn = s | Î˜)). PMI
is an indicator that weights word distributions such that the words characteristic for a particular position
distributionexhibithighervalues.
future task.
It is also closely related to AIF based on the FEP [5,27] and control as an infer-
ence [76]. We will also consider exploring and learning the applications of these prin-
ciples in the future. This is expected to enable an integrated generalized formulation
that includes not only exploits for learning, but also moves for task execution [77].
Funding
This study was supported by JST CREST, grant number JPMJCR15E3; JST Moon-
shot R&D Program, grant number JPMJMS2011; and JSPS KAKENHI, grant num-
bers JP20K19900 and JP23K16975, Japan.
References
[1] Kostavelis I, Gasteratos A. Semantic mapping for mobile robotics tasks: A survey.
Robotics and Autonomous Systems. 2015;66:86â€“103. Available from: http://dx.doi.
org/10.1016/j.robot.2014.12.006.
[2] Garg S, SuÂ¨nderhauf N, Dayoub F, Morrison D, Cosgun A, Carneiro G, Wu Q, Chin TJ,
Reid I, Gould S, Corke P, Milford M. Semantics for Robotic Mapping, Perception and
23
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.0
0 20 40 60 80 100
Step
niaG
noitamrofnI
Mean of Each Step IG
Max IG
Min IG
Std of Each Step IG
Figure12. TrendsinIGvaluesperstep(ExperimentII);Maximum,minimum,mean,andstandarddeviation
ofIGvaluesobtainedforallcandidatesearchpointsateachsteparedrawn.
Interaction: A Survey. Foundations and TrendsÂ® in Robotics. 2020 jan;8(1â€“2):1â€“224.
2101.00443. Available from: http://arxiv.org/abs/2101.00443http://dx.doi.org/
10.1561/2300000059.
[3] Taniguchi A, Hagiwara Y, Taniguchi T, Inamura T. Online Spatial Concept and Lex-
ical Acquisition with Simultaneous Localization and Mapping. In: Proceedings of the
IEEE/RSJ international conference on intelligent robots and systems (IROS). 2017. p.
811â€“818.
[4] TaniguchiA,HagiwaraY,TaniguchiT,InamuraT.ImprovedandScalableOnlineLearn-
ingofSpatialConceptsandLanguageModelswithMapping.Autonomous Robots. 2020;
44(6):927â€“946.
[5] Friston KJ. Active Inference : A Process Theory. Neural Computation. 2017;49:1â€“49.
[6] Friston KJ, Moran RJ, Nagai Y, Taniguchi T, Gomi H, Tenenbaum J. World model
learning and inference. Neural Networks. 2021 dec;144:573â€“590.
[7] LanillosP,MeoC,PezzatoC,MeeraAA,BaioumyM,OhataW,TschantzA,MillidgeB,
Wisse M, Buckley CL, Tani J. Active Inference in Robotics and Artificial Agents: Survey
and Challenges. arXiv. 2021 dec;2112.01871. Available from: https://arxiv.org/abs/
2112.01871v1http://arxiv.org/abs/2112.01871.
[8] Thrun S, Burgard W, Fox D. Probabilistic Robotics. Cambridge, MA: MIT Press. 2005.
[9] Stachniss C, Grisetti G, Burgard W. Information Gain-based Exploration Using Rao-
Blackwellized Particle Filters. In: Robotics: Science and systems. Vol. 2. 2005. p. 65â€“72.
[10] MuB,GiamouM,PaullL,Agha-MohammadiAA,LeonardJ,HowJ.Information-based
Active SLAM via topological feature graphs. In: 2016 IEEE 55th conference on decision
and control, cdc 2016. Cdc. 2016. p. 5583â€“5590. 1509.08155.
[11] Placed JA, Strader J, Carrillo H, Atanasov N, Indelman V, Carlone L, Castellanos JA.
A Survey on Active Simultaneous Localization and Mapping: State of the Art and New
Frontiers. IEEE Transactions on Robotics. 2023 jul;:1â€“20.
[12] Taniguchi T, Yoshino R, Takano T. Multimodal Hierarchical Dirichlet Process-
Based Active Perception by a Robot. Frontiers in Neurorobotics. 2018 may;
12(MAY):22. 1510.00331. Available from: https://www.frontiersin.org/
article/10.3389/fnbot.2018.00022http://arxiv.org/abs/1510.00331https:
//www.frontiersin.org/article/10.3389/fnbot.2018.00022/full.
24
[13] Yoshino R, Takano T, Tanaka H, Taniguchi T. Active Exploration for Unsupervised Ob-
ject Categorization Based on Multimodal Hierarchical Dirichlet Process. In: IEEE/SICE
international symposium on system integrations (SII). 2021.
[14] Veiga TS, Silva M, Ventura R, Lima PU. A hierarchical approach to active semantic
mapping using probabilistic logic and information reward POMDPs. In: Proceedings in-
ternational conference on automated planning and scheduling (ICAPS). Icaps. 2019. p.
773â€“781.
[15] Chaplot DS, Dalal M, Gupta S, Malik J, Salakhutdinov R. SEAL: Self-supervised Em-
bodied Active Learning using Exploration and 3D Consistency. In: Proceedings of the
advances in neural information processing systems (NeurIPS). Vol. 16. 2021. p. 13086â€“
13098. 2112.01001.
[16] AndersonP,WuQ,TeneyD,BruceJ,JohnsonM,SuÂ¨nderhaufN,ReidI,GouldS,vanden
Hengel A. Vision-and-language navigation: Interpreting visually-grounded navigation in-
structions in real environments. In: Proceedings of the IEEE conference on computer
vision and pattern recognition (CVPR). 2018. p. 3674â€“3683.
[17] Chen K, Chen JK, Chuang J, VÂ´azquez M, Savarese S. Topological Planning with Trans-
formers for Vision-and-Language Navigation. In: Proceedings of the IEEE computer so-
ciety conference on computer vision and pattern recognition. Nashville, TN, USA. 2021.
p. 11271â€“11281. 2012.05292. Available from: http://arxiv.org/abs/2012.05292.
[18] Park SM, Kim YG. Visual language navigation: a survey and open challenges. Artificial
Intelligence Review 2022. 2022 mar;:1â€“63Available from: https://link.springer.com/
article/10.1007/s10462-022-10174-9.
[19] Ulker Y, GuÂ¨nsel B, Cemgil T. Sequential Monte Carlo samplers for Dirichlet process
mixtures. In: Proceedings of the international conference on artificial intelligence and
statistics (AISTATS). 2010. p. 876â€“883.
[20] AsadaM,HosodaK,KuniyoshiY,IshiguroH,InuiT,YoshikawaY,OginoM,YoshidaC.
Cognitive developmental robotics: a survey. IEEE Transactions on Autonomous Mental
Development. 2009;1(1):12â€“34.
[21] Cangelosi A, Schlesinger M. Developmental Robotics: From Babies to Robots. Intelligent
Robotics and Autonomous Agents Series. MIT Press. 2015. Available from: https://
books.google.co.jp/books?id=AbKPoAEACAAJ.
[22] Taniguchi T, Piater J, Worgotter F, Ugur E, Hoffmann M, Jamone L, Nagai T, Rosman
B, Matsuka T, Iwahashi N, Oztop E. Symbol Emergence in Cognitive Developmental
Systems: A Survey. IEEE Transactions on Cognitive and Developmental Systems. 2019;
11(4):494â€“516. 1801.08829.
[23] Ha D, Schmidhuber J. World models. 2018. Tech Rep. 1803.10122. Available from:
https://worldmodels.github.io.
[24] Friston KJ, Kilner J, Harrison L. A free energy principle for the brain. Journal of
Physiology-Paris. 2006 jul;100(1):70â€“87.
[25] Friston KJ, Adams RA, Perrinet L, Breakspear M. Perceptions as Hypotheses: Sac-
cadesasExperiments.FrontiersinPsychology.2012;3:151.Availablefrom:https://www.
frontiersin.org/article/10.3389/fpsyg.2012.00151.
[26] FristonKJ.Thefree-energyprinciple:aunifiedbraintheory?Naturereviewsneuroscience.
2010;11(2):127.
[27] Friston KJ, Rigoli F, Ognibene D, Mathys C, Fitzgerald T, Pezzulo G. Active inference
and epistemic value. Cognitive Neuroscience. 2015;6(4):187â€“214.
[28] RangelJC,Martinez-GomezJ,Garcia-VareaI,CazorlaM.LexToMap:lexical-basedtopo-
logical mapping. Advanced Robotics. 2017;31(5):268â€“281.
[29] Grinvald M, Furrer F, Novkovic T, Chung JJ, Cadena C, Siegwart R, Nieto J. Volumet-
ric Instance-Aware Semantic Mapping and 3D Object Discovery; Volumetric Instance-
Aware Semantic Mapping and 3D Object Discovery. IEEE Robotics and Automation
Letters. 2019;4(3). Available from: http://www.ieee.org/publications_standards/
publications/rights/index.html.
[30] RosinolA,VioletteA,AbateM,HughesN,ChangY,ShiJ,GuptaA,CarloneL.Kimera:
25
From SLAM to spatial perception with 3D dynamic scene graphs. The International
Journal of Robotics Research. 2021;40:1510â€“1546. 2101.06894v1. Available from: www.
sagepub.com/https://github.com/MIT-.
[31] Tolman EC. Cognitive maps in rats and men. Psychological Review. 1948;55(4):189â€“208.
[32] Oâ€™keefeJ,NadelL.TheHippocampusasaCognitiveMap.Vol.27.CambridgeUniversity
Press. 1978.
[33] Taniguchi A, Fukawa A, Yamakawa H. Hippocampal formation-inspired probabilis-
tic generative model. Neural Networks. 2022 mar;151:317â€“335. 2103.07356. Avail-
able from: http://creativecommons.org/licenses/by/4.0/http://arxiv.org/abs/
2103.07356.
[34] TaniguchiA,IsobeS,ElHafiL,HagiwaraY,TaniguchiT.Autonomousplanningbasedon
spatial concepts to tidy up home environments with service robots. Advanced Robotics.
2021;35(8):471â€“489. 2002.03671.
[35] Taniguchi A, Hagiwara Y, Taniguchi T, Inamura T. Spatial Concept-Based Naviga-
tion with Human Speech Instructions via Probabilistic Inference on Bayesian Gener-
ative Model. Advanced Robotics. 2020 sep;34(19):1213â€“1228. Available from: https:
//www.tandfonline.com/doi/full/10.1080/01691864.2020.1817777.
[36] KatsumataY,TaniguchiA,ElHafiL,HagiwaraY,TaniguchiT.SpCoMapGAN:Spatial
Concept Formation-based Semantic Mapping with Generative Adversarial Networks. In:
Proceedings of the IEEE/RSJ international conference on intelligent robots and systems
(IROS). Las Vegas, USA: Institute of Electrical and Electronics Engineers Inc.. 2020 oct.
p. 7927â€“7934.
[37] Katsumata Y, Kanechika A, Taniguchi A, El Hafi L, Hagiwara Y, Taniguchi T. Map
completion from partial observation using the global structure of multiple environmental
maps. Advanced Robotics. 2022 mar;00(00):1â€“12. 2103.09071. Available from: https:
//arxiv.org/abs/2103.09071v1.
[38] Hagiwara Y, Taguchi K, Ishibushi S, Taniguchi A, Taniguchi T. Hierarchical Bayesian
model for the transfer of knowledge on spatial concepts based on multimodal informa-
tion. Advanced Robotics. 2022 mar;36(1-2):33â€“53. 2103.06442. Available from: https:
//arxiv.org/abs/2103.06442v1.
[39] Sagara R, Taguchi R, Taniguchi A, Taniguchi T, Hattori K, Hoguro M,
Umezaki T. Unsupervised lexical acquisition of relative spatial concepts us-
ing spoken user utterances. Advanced Robotics. 2021 jun;36(1-2):54â€“70. 2106.
08574. Available from: https://www.tandfonline.com/action/journalInformation?
journalCode=tadr20https://arxiv.org/abs/2106.08574v1.
[40] Wang X, Huang Q, Celikyilmaz A, Gao J, Shen D, Wang YF, Wang WY, Zhang L. Re-
inforced cross-modal matching and self-supervised imitation learning for vision-language
navigation.In:ProceedingsoftheIEEEconferenceoncomputervisionandpatternrecog-
nition (CVPR). Vol. 2019-June. 2019. p. 6622â€“6631. 1811.10092.
[41] Montemerlo M, Thrun S, Koller D, Wegbreit B, Others. FastSLAM 2.0: An improved
particle filtering algorithm for simultaneous localization and mapping that provably con-
verges. In: Proceedings of the international joint conference on artificial intelligence (IJ-
CAI). Acapulco, Mexico. 2003. p. 1151â€“1156.
[42] Grisetti G, Stachniss C, Burgard W. Improving grid-based slam with Rao-Blackwellized
particle filters by adaptive proposals and selective resampling. In: Proceedings of the
IEEE international conference on robotics and automation (ICRA). April. IEEE. 2005.
p. 2432â€“2437.
[43] Yamauchi B. Frontier-based Exploration Using Multiple Robots. In: Agents. 1998. p.
47â€“53. Available from: http://doi.acm.org/10.1145/280765.280773.
[44] Placed JA, Castellanos JA. Fast Autonomous Robotic Exploration Using the Underlying
GraphStructure.In:ProceedingsoftheIEEE/RSJinternationalconferenceonintelligent
robots and systems (IROS). Section IV. 2021. p. 6649â€“6656.
[45] Chaplot DS, Gandhi D, Gupta S, Gupta A, Salakhutdinov R. Learning to Explore using
Active Neural SLAM. In: Proceedings of the international conference on learning repre-
26
sentations (ICLR). 2020. arXiv:2004.05155v1.
[46] CÂ¸atal O, Verbelen T, Van de Maele T, Dhoedt B, Safron A. Robot navigation
as hierarchical active inference. Neural Networks. 2021 oct;142:192â€“204. Available
from: https://linkinghub.elsevier.com/retrieve/pii/S0893608021002021https:
//doi.org/10.1016/j.neunet.2021.05.010.
[47] Asgharivaskasi A, Atanasov N. Semantic OcTree Mapping and Shannon Mutual In-
formation Computation for Robot Exploration. IEEE Transactions on Robotics. 2023;
2112.04063. Available from: https://doi.org/10.1109/TRO.2023.3245986.
[48] Paul R, Arkin J, Aksaray D, Roy N, Howard TM. Efficient grounding of abstract spatial
concepts for natural language interaction with robot platforms. International Journal of
Robotics Research. 2018;37(10):1269â€“1299.
[49] Patki S, Daniele AF, Walter MR, Howard TM. Inferring compact representations for
efficient natural language understanding of robot instructions. In: Proceedings of the
IEEE international conference on robotics and automation (ICRA). 2019. p. 6926â€“6933.
[50] Sugiura K, Iwahashi N, Kashioka H, Nakamura S. Active learning of confidence mea-
sure function in robot language acquisition framework. In: Proceedings of the IEEE/RSJ
international conference on intelligent robots and systems (IROS). 2010. p. 1774â€“1779.
[51] ChenY,BordesJBB,FilliatD.AnexperimentalcomparisonbetweenNMFandLDAfor
activecross-situationalobject-wordlearning.ProceedingsoftheJointIEEEInternational
ConferenceonDevelopmentandLearningandEpigeneticRobotics(ICDL-EpiRob).2016;
:217â€“222.
[52] Nakamura T, Araki T, Nagai T, Iwahashi N. Grounding of Word Meanings in Latent
Dirichlet Allocation-Based Multimodal Concepts. Advanced Robotics. 2011;25(17):2189â€“
2206.
[53] Chaplot DS, Jiang H, Gupta S, Gupta A. Semantic Curiosity for Active Visual Learning.
Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial In-
telligenceandLectureNotesinBioinformatics).2020;12351LNCS:309â€“326.2006.09367.
Available from: http://arxiv.org/abs/2006.09367.
[54] Georgakis G, Bucher B, Schmeckpeper K, Singh S, Daniilidis K. Learning to Map for
Active Semantic Goal Navigation. Proceedings of the International Conference on Learn-
ingRepresentations(ICLR).2022mar;2106.15648.Availablefrom:http://arxiv.org/
abs/2106.15648.
[55] Ramakrishnan SK, Jayaraman D, Grauman K. An Exploration of Embodied Visual Ex-
ploration.InternationalJournalofComputerVision.2021;129(5):1616â€“1649.2001.02192.
Available from: http://arxiv.org/abs/2001.02192.
[56] Oliver G, Lanillos P, Cheng G. An Empirical Study of Active Inference on a Humanoid
Robot. IEEE Transactions on Cognitive and Developmental Systems. 2022;14(2):462â€“
471. 1906.03022. Available from: http://arxiv.org/abs/1906.03022{%}0Ahttp://
dx.doi.org/10.1109/TCDS.2021.3049907.
[57] HoriiT,NagaiY.ActiveInferenceThroughEnergyMinimizationinMultimodalAffective
Humanâ€“Robot Interaction. Frontiers in Robotics and AI. 2021 nov;8:361.
[58] DoyaK,IshiiS,PougetA,RaoRPN.BayesianBrain:ProbabilisticApproachestoNeural
Coding. MIT Press. 2007.
[59] HafnerD,LillicrapT,FischerI,VillegasR,HaD,LeeH,DavidsonJ.Learninglatentdy-
namics forplanning from pixels.Proceedings of theInternational Conference on Machine
Learning (ICML). 2019;2019-June:4528â€“4547. 1811.04551.
[60] Okada M, Kosaka N, Taniguchi T. PlaNet of the Bayesians: Reconsidering and Im-
proving Deep Planning Network by Incorporating Bayesian Inference. In: Proceedings of
the IEEE/RSJ international conference on intelligent robots and systems (IROS). 2020.
arXiv:2003.00370v1.
[61] Ball PJ, Holder JP, Pacchiano A, Choromanski K, Roberts S. Ready policy one: World
building through active learning. In: 37th international conference on machine learning,
(ICML).Vol.PartF16814.2020.p.568â€“578.2002.02693.Availablefrom:http://arxiv.
org/abs/2002.02693.
27
[62] RaoRPN,BallardDH.Predictivecodinginthevisualcortex:Afunctionalinterpretation
of some extra-classical receptive-field effects. Nature Neuroscience. 1999 jan;2(1):79â€“87.
Available from: https://pubmed.ncbi.nlm.nih.gov/10195184/.
[63] Murphy KP. Machine learning: a probabilistic perspective. Cambridge, MA: MIT Press.
2012.
[64] Sethuraman J. A constructive definition of Dirichlet priors. Statistica Sinica. 1994;4:639â€“
650.
[65] Ishwaran H, James LF. Gibbs sampling methods for stick-breaking priors. Journal of the
American Statistical Association. 2001;96(453):161â€“173.
[66] Fox EB, Sudderth EB, Jordan MI, Willsky AS, Fox BEB, Sudderth EB, Jordan MI,
Willsky AS. A sticky HDP-HMM with application to speaker diarization. The Annals of
Applied Statistics. 2011;5(2A):1020â€“1056. arXiv:0905.2592v4.
[67] Doucet A, De Freitas N, Murphy K, Russell S. Rao-Blackwellised particle filtering for
dynamic Bayesian networks. In: Proceedings of the 16th conference on uncertainty in
artificial intelligence. Morgan Kaufmann Publishers Inc.. 2000. p. 176â€“183. 1301.3853.
[68] KongA,LiuJS,WongWH.SequentialImputationsandBayesianMissingDataProblems.
Journal of the American Statistical Association. 1994 mar;89(425):278.
[69] Liu JS. Metropolized independent sampling with comparisons to rejection sampling
and importance sampling. Statistics and Computing. 1996;6(2):113â€“119. Available from:
http://130.203.136.95/viewdoc/summary?doi=10.1.1.31.6718.
[70] YamamotoT,TeradaK,OchiaiA,SaitoF,AsaharaY,MuraseK.DevelopmentofHuman
SupportRobotastheresearchplatformofadomesticmobilemanipulator.ROBOMECH
Journal. 2019;6(1):4. Available from: https://doi.org/10.1186/s40648-019-0132-3.
[71] Inamura T, Mizuchi Y. SIGVerse: A Cloud-Based VR Platform for Research on Multi-
modal Human-Robot Interaction. Frontiers in Robotics and AI. 2021 may;8:158.
[72] Quigley M, Conley K, Gerkey BP, Faust J, Foote T, Leibs J, Wheeler R, Ng AY. ROS:
an open-source Robot Operating System. In: Proceedings of the icra workshop on open
source software. Kobe, Japan. 2009.
[73] Taniguchi A, Ito S, Taniguchi T. Spatial Concept-based Topometric Semantic Mapping
for Hierarchical Path-planning from Speech Instructions. arXiv. 2022 mar;2203.10820.
Available from: https://arxiv.org/abs/2203.10820v1http://arxiv.org/abs/2203.
10820.
[74] BrownTB,MannB,RyderN,SubbiahM,KaplanJ,DhariwalP,NeelakantanA,Shyam
P, Sastry G, Askell A, Agarwal S, Herbert-Voss A, Krueger G, Henighan T, Child R,
Ramesh A, Ziegler DM, Wu J, Winter C, Hesse C, Chen M, Sigler E, Litwin M, Gray S,
ChessB,ClarkJ,BernerC,McCandlishS,RadfordA,SutskeverI,AmodeiD.Language
models are few-shot learners. In: Advances in neural information processing systems.
Vol. 2020-December. Neural information processing systems foundation. 2020 may. p.
1877â€“1901. 2005.14165. Available from: https://commoncrawl.org/the-data/https:
//arxiv.org/abs/2005.14165v4.
[75] Ahn M, Brohan A, Brown N, Chebotar Y, Cortes O, David B, Finn C, Fu C, Gopalakr-
ishnanK,HausmanK,HerzogA,HoD,HsuJ,IbarzJ,IchterB,IrpanA,JangE,Ruano
RJ,JeffreyK,JesmonthS,JoshiNJ,JulianR,KalashnikovD,KuangY,LeeKH,Levine
S, Lu Y, Luu L, Parada C, Pastor P, Quiambao J, Rao K, Rettinghouse J, Reyes D, Ser-
manet P, Sievers N, Tan C, Toshev A, Vanhoucke V, Xia F, Xiao T, Xu P, Xu S, Yan M,
ZengA.DoAsICan,NotAsISay:GroundingLanguageinRoboticAffordances.In:arxiv
preprint. 2022 apr. 2204.01691. Available from: http://arxiv.org/abs/2204.01691.
[76] Levine S. Reinforcement Learning and Control as Probabilistic Inference: Tutorial and
Review. arXiv preprint arXiv:180500909. 2018;.
[77] Taniguchi T, El Hafi L, Hagiwara Y, Taniguchi A, Shimada N, Nishiura T. Semiotically
adaptive cognition: toward the realization of remotely-operated service robots for the
new normal symbiotic society. Advanced Robotics. 2021;35(11):664â€“674. Available from:
https://www.tandfonline.com/doi/abs/10.1080/01691864.2021.1928552.
28
Appendix A. Formula derivation in online learning of spatial concepts
A.1. Derivation of target distribution P
n
The target distribution P is transformed as follows:
n
P = p(C ,i | x ,S ,h) (A1)
n 1:n 1:n 1:n 1:n
= p(C ,i | C ,i ,x ,S ,h)p(C ,i | x ,S ,h) (A2)
n n 1:nâˆ’1 1:nâˆ’1 1:n 1:n 1:nâˆ’1 1:nâˆ’1 1:n 1:n
Bayesâ€™rule
= p(C ,i | C ,i ,x ,S ,h)
n n 1:nâˆ’1 1:nâˆ’1 1:n 1:n
p(x | C ,i ,x ,S ,h)p(C ,i | x ,S ,h)
n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:n
(A3)
p(x | x ,S ,h)
n 1:nâˆ’1 1:n
Markovian
âˆ p(C ,i | C ,i ,x ,S ,h)p(x | C ,i ,x ,h)
n Ï„n 1:nâˆ’1 1:nâˆ’1 1:n 1:n n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1
p(C ,i | x ,S ,h) (A4)
1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:n
Bayesâ€™rule
= p(C ,i | C ,i ,x ,S ,h)p(x | C ,i ,x ,h)
n n 1:nâˆ’1 1:nâˆ’1 1:n 1:n n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1
p(S | C ,i ,x ,S ,h)p(C ,i | x ,S ,h)
n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1
p(S | x ,S ,h)
n 1:nâˆ’1 1:nâˆ’1
(A5)
Markovian
âˆ p(C ,i | C ,i ,x ,S ,h)p(x | C ,i ,x ,h)
n n 1:nâˆ’1 1:nâˆ’1 1:n 1:n n 1:nâˆ’1 1:nâˆ’1 1:nâˆ’1
p(S | S ,C ,Î±,Î²)P . (A6)
n 1:nâˆ’1 1:nâˆ’1 nâˆ’1
A.2. Derivation of proposal distribution q
n
The proposal distribution q is transformed as follows:
n
q = p(C ,i | C ,i ,x ,S ,h) (A7)
n n n 1:nâˆ’1 1:nâˆ’1 1:n 1:n
Bayesâ€™rule p(x 1:n | C 1:n ,i 1:n ,S 1:n ,h)p(C n ,i n | C 1:nâˆ’1 ,i 1:nâˆ’1 ,S 1:n ,h)
= (A8)
p(x | C ,i ,S ,h)
1:n 1:nâˆ’1 1:nâˆ’1 1:n
Markovian
âˆ p(x | i ,h)p(C ,i | C ,i ,S ,h) (A9)
1:n 1:n n n 1:nâˆ’1 1:nâˆ’1 1:n
Baye = sâ€™rule p(x | i ,h) p(S 1:n | C 1:n ,i 1:n ,h)p(C n ,i n | C 1:nâˆ’1 ,i 1:nâˆ’1 ,h) (A10)
1:n 1:n
p(S | C ,i ,h)
1:n 1:nâˆ’1 1:nâˆ’1
Markovian
âˆ p(x | i ,h)p(S | C ,Î²)p(C ,i | C ,i ,Î±,Î³) (A11)
1:n 1:n 1:n 1:n n n 1:nâˆ’1 1:nâˆ’1
âˆp(x | x ,i ,h)p(S | S ,C ,Î²)
n 1:nâˆ’1 1:n n 1:nâˆ’1 1:n
p(C ,i | C ,i ,Î±,Î³). (A12)
n n 1:nâˆ’1 1:nâˆ’1
A.3. Simultaneous sampling of C and i
n n
Here, each term of Eq. (14). The probability distribution for x is
n
(cid:18) (cid:19)
V (Îº +1)
p(x | x ,i ,h) = St x | m , k k ,Î½ âˆ’d+1 (A13)
n 1:nâˆ’1 1:n n k Îº (Î½ âˆ’d+1) k
k k
i
whereSt()istheStudentâ€™st-distribution.Theparametersoftheposteriordistribution
of Eq. (A13) is calculated as follows:
1 (cid:88)
xÂ¯ = x (A14)
k j
(k)
t
nâˆ’1 xj âˆˆxk
(k)
t xÂ¯ +Îº m
m =
nâˆ’1 k 0 0
(A15)
k
(k)
t +Îº
nâˆ’1 0
(k)
Îº = t +Îº (A16)
k nâˆ’1 0
(k)
Î½ = Î½ +t (A17)
k 0 nâˆ’1
(cid:88)
V = V + x xT +Îº m mT âˆ’Îº m mT (A18)
k 0 j j 0 0 0 k k k
xj âˆˆxk
(k)
where t denotes the index of the data point assigned to the k-th position distribu-
nâˆ’1
tion when the nâˆ’1-th data point is obtained.
The probability distribution for the bag-of-words S is as follows:
n
p(S | S ,C ,Î²)
n 1:nâˆ’1 1:n
G
(cid:89)
= p(S | S ,C ,C = l,Î²) (A19)
n,g 1:nâˆ’1 1:nâˆ’1 n
g=1
G
(cid:32)
(l,g)
(cid:33)Sn,g
(cid:89) t +Î²
=
nâˆ’1
(A20)
(cid:80)G
(t
(l,gâ€²)
+Î²)
g=1 gâ€²=1 nâˆ’1
(l,g)
where t is the count number of the g-th word s of the l-th word distribution in
nâˆ’1 g
S when the nâˆ’1-th data point is obtained. In addition, G is the number of word
1:nâˆ’1
types (the number of dimensions of the word distribution), and B is the number of
t
words in an utterance.
The probability distribution with respect to i and C is
n n
p(C ,i | C ,i ,Î±,Î³)
n n 1:nâˆ’1 1:nâˆ’1
= p(i = k | C = l,C ,i ,Î³)p(C = l | C ,Î±) (A21)
n n 1:nâˆ’1 1:nâˆ’1 n 1:nâˆ’1
(l,k) (l)
t +Î³/K t +Î±/L
=
nâˆ’1 nâˆ’1
(A22)
(l) t +Î±
t +Î³ nâˆ’1
nâˆ’1
(l)
wheret denotesthecountnumberofdataassignedtothel-thspatialconceptwhen
nâˆ’1
thenâˆ’1-thdatapointisobtained.Inaddition,t (l,k) denotesthecountnumberofdata
nâˆ’1
assigned to the l-th spatial concept and k-th position distribution when the nâˆ’1-th
data are obtained.
ii
From the above, Eq. (14) can be expressed as follows:
(cid:18) (cid:19)
V (Îº +1)
q âˆ St x | m , k k ,Î½ âˆ’d+1
n n k Îº (Î½ âˆ’d+1) k
k k
G
(cid:32)
(l,g)
(cid:33)Sn,g
(l,k) (l)
(cid:89) t +Î² t +Î³/K t +Î±/L
nâˆ’1 nâˆ’1 nâˆ’1
. (A23)
(cid:80)G
(t
(l,gâ€²)
+Î²) t
(l)
+Î³
t
nâˆ’1
+Î±
g=1 gâ€²=1 nâˆ’1 nâˆ’1
A.4. Posterior distribution of model parameters Î˜
The first term p(Î˜ | C ,i ,x ,S ,h) in Eq. (12) is the posterior distribution of
1:n 1:n 1:n 1:n
the parameter Î˜, as follows:
p(Î˜ | C ,i ,x ,S ,h)
1:n 1:n 1:n 1:n
(cid:34) (cid:35)
K L
(cid:89) (cid:89)
= NIW(Âµ ,Î£ | m ,Îº ,V ,Î½ ) Dir(W | (t(l,g)+Î²))Dir(Ï• | (t(l,k)+Î³/K))
k k k k k k l n l n
k=1 l=1
Dir(Ï€ | (t(l)+Î±/L)) (A24)
n
where NIW() denotes a Gaussian inverse Wishart distribution. In practice, this set
of parameters Î˜ is obtained for each particle sampled using the RBPF. Each term in
Eq. (A24) can be computed independently for the corresponding parameters and cate-
gories. In addition, each term is a posterior distribution for each parameter, which can
becomputedbytheconjugacyofthepriordistributionandthelikelihoodfunction.To
obtain specific estimates for each parameter, the expected value of each posterior dis-
tribution was obtained. Refer to [63] for the specific formulas for the above probability
distributions.
Appendix B. Formula derivation in SpCoAE
B.1. Derivation of IG for destination selection
ThissectiondescribesthetransformationdetailsofEqs.(23)â€“(25).Asimilarderivation
has been employed in MHDP-based active perception/learning methods [12,13]. The
index aâˆ— of the candidate position for exploration observed at the next destination can
be obtained using the expected value of the KL divergence as follows:
aâˆ— = argminE [D [p(Z | X ),p(Z | X )]] (B1)
a
X{1:N}\n0 |Xn0 KL 1:N n0 âˆªa
(cid:20) (cid:21)
(cid:88) (cid:88) p(Z | X )
= argmin p(X | X )p(Z | X )log 1:N . (B2)
{1:N}\n0 n0 1:N p(Z | X ,X )
a
X{1:N}\n0 Z
a n0
In Eq. (B2), the numerator of the log function p(Z | X ) is eliminated because it
1:N
iii
does not depend on a, and the denominator and numerator are inverted as follows:
(cid:88) (cid:88)(cid:2) (cid:3)
Eq. (B2) = argmax p(X | X )p(Z | X )logp(Z | X ,X )
{1:N}\n0 n0 1:N a n0
a
X{1:N}\n0 Z
(B3)
(cid:88) (cid:88)(cid:2) (cid:3)
= argmax p(Z,X | X )logp(Z | X ,X ) . (B4)
{1:N}\n0 n0 a n0
a
X{1:N}\n0 Z
In Eq. (B4), the replacement of {1 : N}\n with a can be expressed as follows:
0
(cid:88)(cid:88)
Eq. (B4) = argmax [p(Z,X | X )logp(Z | X ,X )] (B5)
a n0 a n0
a
Xa Z
(cid:88)(cid:88) (cid:88)
= argmax [p(Z,X | X )logp(Z | X ,X )]âˆ’ [p(Z | X )logp(Z | X )]
a n0 a n0 n0 n0
a
Xa Z Z
(cid:124) (cid:123)(cid:122) (cid:125)
Add the constant term
(B6)
(cid:34)
(cid:88)(cid:88)
=argmax [p(X | X )p(Z | X ,X )logp(Z | X ,X )]
a n0 n0 a a n0
a
Xa Z
(cid:35)
(cid:88) (cid:88)
âˆ’ [p(X | X )p(Z | X ,X )logp(Z | X )] (B7)
a n0 n0 a n0
Xa Z
(cid:88) (cid:88) logp(Z | X ,X )
=argmax p(X | X ) p(Z | X ,X ) a n0 (B8)
a n0 n0 a
p(Z | X )
a
Xa Z
n0
(cid:124) (cid:123)(cid:122) (cid:125)
KL divergence
(cid:88)
=argmax p(X | X )D [p(Z | X ,X )âˆ¥p(Z | X )] (B9)
a n0 KL a n0 n0
a
Xa
= argmaxE [D [p(Z | X )âˆ¥p(Z | X )]] (B10)
a
Xa |Xn0 KL n0 âˆªa n0
= argmaxIG(Z;X | X ). (B11)
a n0
a
Based on information-theoretic definitions, the deformation from Eq. (B8) to Eq. (B9)
uses the definition of the KL divergence and deformation from Eq. (B10) to Eq. (B11)
defines the IG. IG is known as mutual information [11].
B.2. Another derivation: entropy-based IG derivation
ThealgorithmforderivingtheIGcalculationusinganentropy-basedproceduresimilar
to the active SLAM [9] is shown in Algorithm 3. The derivation of the algorithm is
presented in this section.
The IG function IG(Z;X | X ) in terms of the entropy difference is as follows:
a n0
IG(Z;X | X ) =H(p(Z | X ))âˆ’H(p(Z | X )) (B12)
a n0 n0 n0 âˆªa
=H(p(Î˜,C ,i | x ,S ,h))
1:n 1:n n0 n0
âˆ’H(p(Î˜,C ,i | x ,S ,h)) (B13)
1:n 1:n n0 âˆªa n0 âˆªa
iv
Thus, Eq. (25) becomes
Eq. (25) = argmax[H(p(Z | X ))âˆ’H(p(Z | X ))] (B14)
n0 n0 âˆªa
a (cid:124) (cid:123)(cid:122) (cid:125)
Constant
= argminH(p(Z | X ,X )). (B15)
n0 a
a
Thus,H(p(Z | X ,X ))canbeexpressedusingthedefinitionofconditionalentropy
n0 a
as follows:
(cid:88)
H(p(Z | X ,X )) = [p(X | X )H(p(Z | X ,X ))] (B16)
n0 a a n0 n0 a
Xa
J
(cid:88)
â‰ˆ H(p(Z | X ,X[j])), X[j] âˆ¼ p(X | X ). (B17)
n0 a a a n0
j=1
Therefore, from Eqs. (B17) and (29), H(p(Z | X ,X )) is expressed as:
n0 a
ï£® ï£¹
R J
(cid:88) (cid:88)
H(p(Z | X
n0
,X
a
)) â‰ˆ ï£°Ï‰
n
[r
0
] H(p(Z | X
n0
,X
a
[j]))ï£»,
r=1 j=1
Z[r] âˆ¼ q(Z | X ), X[j] âˆ¼ p(X | Z[r],X ). (B18)
n0 a a n0
In addition, H(p(Z | X ,X [j] )) is
n0 a
H(p(Z | X ,X[j])) = H(p(Î˜,C ,i | x ,S ,x[j],S[j],h)) (B19)
n0 a 1:n 1:n n0 n0 a a
â‰ˆ H(p(C ,i | x [j] ,S [j] ,h))
n0 âˆªa n0 âˆªa n0 âˆªa n0 âˆªa
R
+ (cid:88) Ï‰ [râ€²,j] H(p(Î˜ | C [râ€²,j] ,i [râ€²,j] ,x [j] ,S [j] ,h)). (B20)
n0 âˆªa n0 âˆªa n0 âˆªa n0 âˆªa n0 âˆªa
râ€²=1
This suggests that entropy is computed after turning the particle filters using the
pseudo-observation X [j] = {x [j] ,S [j]}.
a a a
B.3. Exploration of active inference algorithms in two derivations
Algorithm 2 is based on the IG-based active perception methods [12,13], and Algo-
rithm 3 is based on the method proposed for active SLAM [9]. These two algorithms
are identical, except for lines 9 and 11 in Algorithm 2 and lines 7, 10, and 12 in Al-
gorithm 3. In Algorithm 2, the calculation results in line 7 can be reused in line 10.
ComparedwithAlgorithm3,whichrequiresentropycalculations,Algorithm2iseasier
to implement and faster. Although Algorithm 3 appears to require more processing
in line 8, the results of the processing in line 7 can be directly reused in the sam-
pling and weight calculations of the online learning algorithm in line 8. In addition, if
X = {x ,S } = X [r,j] , the estimated value, ZÂ¯[r,j] , can be reused as Z .
aâˆ— aâˆ— aâˆ— a Ï„ Ï„
This study demonstrated the theoretical connectivity between SpCoAE and active
SLAM.Inthefuture,Algorithm3willbemorecompatiblewiththetheoreticalintegra-
tion of SpCoAE and active SLAM. However, because the two algorithms were derived
v
Algorithm 3 Entropy-based active exploration algorithm for spatial concept forma-
tion.
1: Initialize n 0 = âˆ…, Z 0 = âˆ…, X n0 = âˆ…
2: for Ï„ = 1 to T do â–· The number of action trials
3: for all {x a âˆˆ RD | free-space in a map} do â–· The number of candidate
positions
4: for r = 1 to R do â–· The number of particles
5: for j = 1 to J do â–· The number of samples
6: X a [r,j] âˆ¼ p(X a | Z Ï„ [r âˆ’ ] 1 ,X n0 )
7: ZÂ¯ Ï„ [r,j] = Online Learning(Z Ï„âˆ’1 ,{X n0 ,X a [r,j]})
8: end for
9: end for
R J
(cid:88)(cid:88)
10: H a = H(p(Z | X n0 ,X a [r,j]))
r=1j=1
11: end for
12: aâˆ— = argmin a H a â–· Select position x aâˆ—
13: n 0 = n 0 âˆª{aâˆ—}
14: Move to the position x aâˆ— , and observe words S aâˆ— â–· Observe X n0
15: Z Ï„ = Online Learning(Z Ï„âˆ’1 ,X n0 )
16: end for
from the same IG, an integrated reinterpretation based on Algorithm 2 was possible.
This allows for an almost intact extension of the algorithm and implementation.
Comparing the proposed and conventional methods, the number of samples K in
the Monte Carlo approximation [12,13] corresponds to R when J = 1 in the proposed
algorithm. Therefore, the proposed algorithm is more generalizable. Furthermore, as
describedinSection4.3.2,theMonteCarloapproximationisdescribedindetail[12,13].
However, the proposed method can use the estimation results of the existing particle
filters. In addition, whereas [12,13] assumed batch learning for Gibbs sampling for
each exploration, the proposed method is computationally more efficient than existing
methods because of online learning using particle filters.
Appendix C. Preliminary experiment: Comparison of accuracy and
computation time for spatial concept learning
The purpose of this experiment was to compare the accuracies of spatial concept
learning and computation time when the number of particles and pseudo-observations
in SpCoAE were varied.
C.1. Condition
Table C.1 lists the number of particles R and the number of pseudo-observations
J for each experimental pattern. Ten trials were conducted for each experimental
pattern. Environment 5 was used as the experimental environment in this study. The
conditions related to the candidate points were identical to those in Experiment I. A
totalof103candidateswereavailableforobservation.Inalltheexperimentalpatterns,
The hyperparameters were set as Î± = 1.0, Î² = 0.01, Î³ = 0.1, m = [0.0,0.0], Îº =
0 0
vi
Table C1. Experimentalconditionpattern.
Pattern Number of particles (R) Number of pseudo-observations (J)
A 1000 1
B 100 1
C 10 1
D 1 1
E 1000 10
F 100 10
G 10 10
H 1 10
K 1500 10
L 500 10
0.001, V = diag(1.5,1.5), Î½ = 4.0. The upper limits for the number of categories
0 0
were set as K = 10 and L = 10. The simulations were performed on a laptop with
the following specifications: Intel Core i7-7820HK CPU, 32 GB of DDR4 memory, and
NvidiaGeForceGTX1080GPU.TherobotwasoperatedusingtheROSkineticKame
running on Ubuntu 16.04 LTS.
The evaluation metrics were the same as those in Experiment I. In addition, the
computation time required for each step and the computation time required for all
steps were evaluated. The computation time excludes the time required to obtain
observations or travel time.
C.2. Results
Figure C1 shows examples of the learning results of the spatial concept index C and
the position distribution for each position coordinate in experimental patterns Aâ€“H.
Additionally, the color changed randomly for each trial because the category numbers
assigned to index C and index i changed randomly. For each experimental pattern,
the mean and standard deviation of each evaluation value for all ten trials are shown
in the graphs below.
Figure C2 shows the results of comparing experimental patterns Eâ€“H with R =
(1000, 100, 10, 1) number of particles and J = 10 pseudo-observations. In terms of
the weighted ARI for indices C and i in experimental patterns Aâ€“H, Figures C2(a)
and C2(b) indicate that the higher the number of particles, the higher the value from
approximately step 30 to the final step. In addition, an example of the learning results
(Figure C1) indicates that the higher the number of particles, the closer the result
is to an ideal position distribution. Figures C2(c) and C2(d) show that the larger
the number of particles, the longer is the computation time required. These results
confirma tradeoffbetweenthe numberof particlesand theaccuracy ofspatial concept
learning.
The comparison of experimental results A and E with the number of particles R =
1000 and the number of pseudo-observations J = (1, 10) are shown in Figure C3.
The results of comparing experimental patterns C and G with the number of particles
R = 10 and J = (1, 10) are shown in Figure C4. These results show that, regardless of
the number of particles, the difference in the number of pseudo-observations has little
effect on the accuracy and computation time of spatial concept learning. This can be
attributed to the present condition setting in which one word is assigned. The effect of
the number of pseudo-observations is more pronounced when there are many-to-many
correspondences between places and words.
Finally, we show the results of the experiments when the number of particles was
1500,500, based on the experimental pattern with the number of particles R = 1000,
vii
Wednesday31st May,2023 AdvancedRobotics output
4
2
0
2
4
8 6 4 2x 0 2 4 6
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(a) A(R=1000,J=1)
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(b) B(R=100,J=1)
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(c) C(R=10,J=1)
y
(d) D(R=1,J=1)
4
2
0
2
4
8 6 4 2x 0 2 4 6
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(e) E(R=1000,J=10)
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(f) F(R=100,J=10)
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(g) G(R=10,J=10)
y
(h) H(R=1,J=10)
FigureC1. ExamplesoflearningresultsforpositiondistributionsandindexCn ofspatialconceptforeachcoordinatein
experimentalpatternsAâ€“H.
1.0 0.8 0.6 0.4 0.2
0.0051015202530354045S5t0ep556065707580859095100
C xedni fo IRA dethgieW 1.0 0.8 0.6 0.4 EFGH (( ((pp pp== ==11 1100
,0o
00 ,=o,0o=1 ,=o
01
=1 )001 ))0)
0
0
.
.
0
2
051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni fo IRA dethgieW 80 70 60 50 40 30 EFGH (( ((pp pp== ==11 1100
,0o
00 ,=o,0o=1 ,=o
01
=1 )001 ))0)
1
2
0
0
0
051015202530354045S5t0ep556065707580859095100
(b) ARI(step-by-step)ofin-
dexin
)ces( pets hcae fo emit etucexE EFGH (( ((pp pp== ==11 1100 ,0o 00 ,=o,0o=1 ,=o 01 =1 )001 ))0) 4000 3000 2000 1000
0E (p=1000,o=10)F (p=10E0xp,oe=ri1m0e)nGt p (apt=te1r0n,o=10)H (p=1,o=10)
(c) Computation time re-
quiredforeachstep
)ces( emit etucexE
Wednesday31st May,2023 AdvancedRobotics output
4
2
0
2
4
8 6 4 2x 0 2 4 6
Figure C1. ExamplesoflearningresultsforpositiondistributionsandindexCn ofspatialconceptforeach
coordinateinexperimentalpatternsAâ€“H.
4596.1
459.7
47.2 5.6
(d) Cumulativecomputation
timerequiredforallsteps
FigureC2. WeightedARIvaluesandcomputationtimeinexperimentalpatternsEâ€“H.
(1000, 100, 10, 1) number of particles and J =10 pseudo-observations. In terms of the weighted
ARI for indices C and i in experimental patterns Aâ€“H, Figures C2(a) and C2(b) indicate that
the higher the number of particles, the higher the value from approximately step 30 to the final
step. In addition, an example of the learning results (Figure C1) indicates that the higher the
number of particles, the closer the result is to an ideal position distribution. Figures C2(c) and
C2(d)showthatthelargerthenumberofparticles,thelongeristhecomputationtimerequired.
These results confirm a tradeoff between the number of particles and the accuracy of spatial
concept learning.
The comparison of experimental results A and E with the number of particles R = 1000 and
thenumberofpseudo-observationsJ =(1, 10)areshowninFigureC3.Theresultsofcomparing
experimental patterns C and G with the number of particles R=10 and J =(1, 10) are shown
inFigureC4.Theseresultsshowthat,regardlessofthenumberofparticles,thedifferenceinthe
number of pseudo-observations has little effect on the accuracy and computation time of spatial
concept learning. This can be attributed to the present condition setting in which one word is
assigned. The effect of the number of pseudo-observations is more pronounced when there are
many-to-many correspondences between places and words.
Finally, we show the results of the experiments when the number of particles was 1500,500,
based on the experimental pattern with the number of particles R = 1000, which was the
most accurate in spatial concept learning in previous experiments. The results of comparing
experimental patterns K, E, and L with R = (1500, 1000, 500) number of particles and J = 10
pseudo-observations are shown in Figure C5. The weighted ARI for experimental patterns K, E,
andL,asshowninFiguresC5(a)andC5(b)indicatethattheARIof500particlesisslightlylower
than that of 1500 or 1000 particles. Combining Figures C5(c) and C5(d), when 1500 particles
were used, the computation time was approximately 1.5 times longer than when 1000 particles
were used, even though the accuracies of spatial concept learning were similar. Therefore, the
vii
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(a) A(R=1000,J=1)
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(b) B(R=100,J=1)
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(c) C(R=10,J=1)
y
(d) D(R=1,J=1)
4
2
0
2
4
8 6 4 2x 0 2 4 6
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(e) E(R=1000,J=10)
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(f) F(R=100,J=10)
y
4
2
0
2
4
8 6 4 2x 0 2 4 6
(g) G(R=10,J=10)
y
(h) H(R=1,J=10)
FigureC1. ExamplesoflearningresultsforpositiondistributionsandindexCn ofspatialconceptforeachcoordinatein
experimentalpatternsAâ€“H.
1.0 0.8 0.6 0.4
0.2
0.0051015202530354045S5t0ep556065707580859095100
C xedni fo IRA dethgieW 1.0 0.8 0.6 0.4
EFGH (( ((pp pp== ==11 1100
,0o
00 ,=o,0o=1 ,=o
01
=1 )001 ))0)
0
0
.
.
0
2
051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni fo IRA dethgieW 80 70 60 50 40 30
EFGH (( ((pp pp== ==11 1100
,0o
00 ,=o,0o=1 ,=o
01
=1 )001 ))0)
1
2
0 0
0
051015202530354045S5t0ep556065707580859095100
(b) ARI(step-by-step)ofin-
dexin
)ces( pets hcae fo emit etucexE EFGH (( ((pp pp== ==11 1100 ,0o 00 ,=o,0o=1 ,=o 01 =1 )001 ))0) 4000 3000 2000
1000
0E (p=1000,o=10)F (p=10E0xp,oe=ri1m0e)nGt p (apt=te1r0n,o=10)H (p=1,o=10)
(c) Computation time re-
quiredforeachstep
)ces( emit etucexE 4596.1
459.7 47.2 5.6
(d) Cumulativecomputation
timerequiredforallsteps
FigureC2. WeightedARIvaluesandcomputationtimeinexperimentalpatternsEâ€“H.
Figure C2. WeightedARIvaluesandcomputationtimeinexperimentalpatternsEâ€“H.
(1000, 100, 10, 1)numberofparticlesandJ =10pseudo-observations.Intermsoftheweighted
ARI for indices C and i in experimental patterns Aâ€“H, Figures C2(a) and C2(b) indicate that
thwehhicighhweratshtehneummboestr oafccpuarrtaitceleisn, tshpeahtiigahlecrotnhceepvatluleeafrrnoimngapinprporxeimviaotueslyesxtpeper3im0etonttsh.eTfihneal
streeps.ulItnsaodfdcitoiomnp,aarninegxaemxppleeriomf ethnetalleaprantintegrrnessuKlt,sE(F,iagunrdeLC1w)iitnhdiRcat=es(t1h5a0t0t,h1e0h0i0gh,e5r0t0h)e
nnuummbebrerofopfarptaicrlteisc,lethseacnlodseJr t=he1re0supltseiusdtoo-aonbsiderevaaltpioosnitsioanredissthroibwuntioinn.FFiigguurrees CC25(.c)Tahned
Cw2e(dig)hstheodwAthRaIttfhoerleaxrgpeerritmheennutamlbpeartotfeprnarstiKcl,esE,,thaenldonLge,raisstshheowconmipnutFatigiounretimCe5(raeq)uairnedd.
These results confirm a tradeoff between the number of particles and the accuracy of spatial
C5(b) indicate that the ARI of 500 particles is slightly lower than that of 1500 or 1000
concept learning.
particles. Combining Figures C5(c) and C5(d), when 1500 particles were used, the
The comparison of experimental results A and E with the number of particles R =1000 and
computation time was approximately 1.5 times longer than when 1000 particles were
thenumberofpseudo-observationsJ =(1, 10)areshowninFigureC3.Theresultsofcomparing
used, even though the accuracies of spatial concept learning were similar. Therefore,
experimental patterns C and G with the number of particles R=10 and J =(1, 10) are shown
the number of particles, R = 1000, and the number of pseudo-observations, J = 10 inFigureC4.Theseresultsshowthat,regardlessofthenumberofparticles,thedifferenceinthe
nwumerbeerdeotfeprsmeuindeod-obinserEvxaptieornismheanstliIt.tle effect on the accuracy and computation time of spatial
Wednesday31st May,2023 AdvancedRobotics output
concTephteleeaxrpneirnigm. eTnhtiswcaasnpbeerfaotrtrmibeudteodntoatshiengplree-sceonrtecConPdUitiotnosveetrtiifnygtinhewchoicmhpounteawtioorndalis
asspsiegended..InThreeaeliffteyc,titofisthpeosnsuimblbeetroopfaprsaeluldeloi-zoebasenrdvaitmiopnlsemisemnotreeapcrhonsaoumnpcleeddwuhreinngthMeroenatere
many-to-many correspondences between places and words.
Finally, we show the results of the experiments when the number of particles was 1500,500,
base1.0d on the experimental pattern with the number of particles R = 1000, which was the
0.8
most accurate in spatial concept learning in previous experiments. The results of comparing
0.6 experimental patterns K, E, and L with R =(1500, 1000, 500) number of particles and J =10 0.4
pseudo-observationsareshowninFigureC5.TheweightedARIforexperimentalpatternsK,E, 0.2
and0.L005 , 10 a 152 s 025 s 303 h 540 o 45S5 w t0ep556 n 06570 i 7 n 58085 F 909 i 51 g 00 uresC5(a)andC5(b)indicatethattheARIof500particlesisslightlylower
than that of 1500 or 1000 particles. Combining Figures C5(c) and C5(d), when 1500 particles
were used, the computation time was approximately 1.5 times longer than when 1000 particles
were used, even though the accuracies of spatial concept learning were similar. Therefore, the
vii
C xedni
fo IRA dethgieW
1.0
0.8
0.6 0.4
AE ((pp==11000000,,oo==110)) 0.2
0.0051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni
fo IRA dethgieW
80
70
60
50 40 30
20 AE ((pp==11000000,,oo==110)) 10
0051015202530354045S5t0ep556065707580859095100
(b) ARI(Step-by-step)ofin-
dexin
)ces(
pets
hcae fo emit etucexE
AE ((pp==11000000,,oo==110))
4000
3000 2000
1000
0 A (p=1000,o=1)Experiment patternE (p=1000,o=10)
(c) Computation time re-
quiredforeachstep
)ces(
emit etucexE
4602.1 4596.1
(d) Cumulativecomputation
timerequiredforallsteps
FigureC3. WeightedARIvaluesandcomputationtimeinexperimentalpatternsAandE.
1.0
0.8
0.6 0.4
0.2
0.0051015202530354045S5t0ep556065707580859095100
C xedni
fo IRA dethgieW
1.0
0.8
0.6 0.4
CG ((pp==1100,,oo==11)0) 0.2
0.0051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni
fo IRA dethgieW
0.8
0.7
0.6
0.5 0.4 0.3
0.2 CG ((pp==1100,,oo==11)0) 0.1
0.0051015202530354045S5t0ep556065707580859095100
(b) ARI(step-by-step)ofin-
dexin
)ces(
pets
hcae fo emit etucexE
50 CG ((pp==1100,,oo==11)0)
40
30 20
10
0 C (p=10,o=1)Experiment patternG (p=10,o=10)
(c) Computation time re-
quiredforeachstep
)ces(
emit etucexE
47.4 47.2
(d) Cumulativecomputation
timerequiredforallsteps
FigureC4. WeightedARIvaluesandcomputationtimesinexperimentalpatternsCandG.
1.0
0.8
0.6 0.4
0.2
0.0051015202530354045S5t0ep556065707580859095100
C xedni fo IRA dethgieW
1.0
0.8
0.6 0.4
KEL ((( ppp === 511 005 000 ,00 o,, =oo== 1011 )00)) 0.2
0.0051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni fo IRA dethgieW
120
100
80 60 40
KEL ((( ppp === 511 005 000 ,00 o,, =oo== 1011 )00)) 20
0051015202530354045S5t0ep556065707580859095100
(b) ARI(Step-by-step)ofin-
dexin
)ces(
pets hcae fo emit etucexE
KEL ((( ppp === 511 005 000 ,00 o,, =oo== 1011 )00))
6
7
0
0
0
0
0
0
5000 4000 3000 2000
1000
0 K (p=1500,o=10) EEx p(per=im10e0n0t ,poa=t1te0r)n L (p=500,o=10)
(c) Computation time re-
quiredforeachstep
)ces( emit etucexE
Figure C3. WeightedARIvaluesandcomputationtimeinexperimentalpatternsAandE.
viii
6927.0
4596.1 2309.0
(d) Cumulativecomputation
timerequiredforallsteps
FigureC5. WeightedARIvaluesandcomputationtimeinexperimentalpatternsofK,E,L.
numberofparticles,R=1000,andthenumberofpseudo-observations,J =10weredetermined
in Experiment I.
The experiment was performed on a single-core CPU to verify the computational speed. In
reality, it is possible to parallelize and implement each sample during Monte Carlo sampling
using particle filters. Therefore, in an actual operation, parallelization allows for accelerated
calculations.
viii
Wednesday31st May,2023 AdvancedRobotics output
1.0 0.8 0.6 0.4 0.2 0.0051015202530354045S5t0ep556065707580859095100 C xedni fo IRA dethgieW 1.0 0.8 0.6 0.4 AE ((pp==11000000,,oo==110)) 0.2 0.0051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni fo IRA dethgieW 80 70 60 50 40 30 20 AE ((pp==11000000,,oo==110)) 10 0051015202530354045S5t0ep556065707580859095100
(b) ARI(Step-by-step)ofin-
dexin
)ces( pets hcae fo emit etucexE AE ((pp==11000000,,oo==110)) 4000 3000 2000 1000 0 A (p=1000,o=1)Experiment patternE (p=1000,o=10)
(c) Computation time re-
quiredforeachstep
)ces( emit etucexE 4602.1 4596.1
(d) Cumulativecomputation
timerequiredforallsteps
FigureC3. WeightedARIvaluesandcomputationtimeinexperimentalpatternsAandE.
1.0 0.8 0.6 0.4 0.2 0.0051015202530354045S5t0ep556065707580859095100 C xedni fo IRA dethgieW 1.0 0.8 0.6 0.4 CG ((pp==1100,,oo==11)0) 0.2 0.0051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni fo IRA dethgieW 0.8 0.7 0.6 0.5 0.4 0.3 0.2 CG ((pp==1100,,oo==11)0) 0.1 0.0051015202530354045S5t0ep556065707580859095100
(b) ARI(step-by-step)ofin-
dexin
)ces( pets hcae fo emit etucexE 50 CG ((pp==1100,,oo==11)0) 40 30 20 10 0 C (p=10,o=1)Experiment patternG (p=10,o=10)
(c) Computation time re-
quiredforeachstep
)ces( emit etucexE 47.4 47.2
(d) Cumulativecomputation
timerequiredforallsteps
FigureC4. WeightedARIvaluesandcomputationtimesinexperimentalpatternsCandG.
1.0
0.8 0.6 0.4 0.2
0.0051015202530354045S5t0ep556065707580859095100
C xedni fo IRA dethgieW
1.0
0.8 0.6 0.4 KEL ((( ppp === 511 005 000 ,00 o,, =oo== 1011 )00)) 0.2
0.0051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni fo IRA dethgieW
120
100 80 60 40 KEL ((( ppp === 511 005 000 ,00 o,, =oo== 1011 )00)) 20
0051015202530354045S5t0ep556065707580859095100
(b) ARI(Step-by-step)ofin-
dexin
)ces( pets hcae fo emit etucexE
KEL ((( ppp === 511 005 000 ,00 o,, =oo== 1011 )00))
6
7
0
0
0
0
0
0
5000 4000 3000 2000 1000
0 K (p=1500,o=10) EEx p(per=im10e0n0t ,poa=t1te0r)n L (p=500,o=10)
(c) Computation time re-
quiredforeachstep
)ces( emit etucexE
Wednesday31st May,2023 AdvancedRobotics output
1.0 0.8 0.6 0.4 0.2
0.0051015202530354045S5t0ep556065707580859095100
Figure C4. WeightedARIvaluesandcomputationtimesinexperimentalpatternsCandG.
6927.0
4596.1 2309.0
(d) Cumulativecomputation
timerequiredforallsteps
FigureC5. WeightedARIvaluesandcomputationtimeinexperimentalpatternsofK,E,L.
numberofparticles,R=1000,andthenumberofpseudo-observations,J =10weredetermined
in Experiment I.
The experiment was performed on a single-core CPU to verify the computational speed. In
reality, it is possible to parallelize and implement each sample during Monte Carlo sampling
using particle filters. Therefore, in an actual operation, parallelization allows for accelerated
calculations.
viii
C xedni fo IRA dethgieW 1.0 0.8 0.6 0.4 AE ((pp==11000000,,oo==110)) 0.2
0.0051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni fo IRA dethgieW 80 70 60 50 40 30 20 AE ((pp==11000000,,oo==110)) 10
0051015202530354045S5t0ep556065707580859095100
(b) ARI(Step-by-step)ofin-
dexin
)ces( pets hcae fo emit etucexE AE ((pp==11000000,,oo==110)) 4000 3000 2000 1000
0 A (p=1000,o=1)Experiment patternE (p=1000,o=10)
(c) Computation time re-
quiredforeachstep
)ces( emit etucexE 4602.1 4596.1
(d) Cumulativecomputation
timerequiredforallsteps
FigureC3. WeightedARIvaluesandcomputationtimeinexperimentalpatternsAandE.
1.0 0.8 0.6 0.4 0.2
0.0051015202530354045S5t0ep556065707580859095100
C xedni fo IRA dethgieW 1.0 0.8 0.6 0.4 CG ((pp==1100,,oo==11)0) 0.2
0.0051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni fo IRA dethgieW 0.8 0.7 0.6 0.5 0.4 0.3 0.2 CG ((pp==1100,,oo==11)0) 0.1
0.0051015202530354045S5t0ep556065707580859095100
(b) ARI(step-by-step)ofin-
dexin
)ces( pets hcae fo emit etucexE 50 CG ((pp==1100,,oo==11)0) 40 30 20 10
0 C (p=10,o=1)Experiment patternG (p=10,o=10)
(c) Computation time re-
quiredforeachstep
)ces( emit etucexE 47.4 47.2
(d) Cumulativecomputation
timerequiredforallsteps
FigureC4. WeightedARIvaluesandcomputationtimesinexperimentalpatternsCandG.
1.0 0.8 0.6 0.4
0.2
0.0051015202530354045S5t0ep556065707580859095100
C xedni fo IRA dethgieW 1.0 0.8 0.6 0.4
KEL ((( ppp === 511 005 000 ,00 o,, =oo== 1011 )00)) 0.2
0.0051015202530354045S5t0ep556065707580859095100
(a) ARI(step-by-step)ofin-
dexCn
i xedni fo IRA dethgieW 120 100 80 60 40
KEL ((( ppp === 511 005 000 ,00 o,, =oo== 1011 )00)) 20
0051015202530354045S5t0ep556065707580859095100
(b) ARI(Step-by-step)ofin-
dexin
)ces( pets hcae fo emit etucexE KEL ((( ppp === 511 005 000 ,00 o,, =oo== 1011 )00)) 6 7 0 0 0 0 0 0 5000 4000 3000 2000
1000
0 K (p=1500,o=10) EEx p(per=im10e0n0t ,poa=t1te0r)n L (p=500,o=10)
(c) Computation time re-
quiredforeachstep
)ces( emit etucexE 6927.0 4596.1 2309.0
(d) Cumulativecomputation
timerequiredforallsteps
FigureC5. WeightedARIvaluesandcomputationtimeinexperimentalpatternsofK,E,L.
Figure C5. WeightedARIvaluesandcomputationtimeinexperimentalpatternsofK,E,L.
numberofparticles,R=1000,andthenumberofpseudo-observations,J =10weredetermined
in Experiment I.
CTahreloesxapmerpimlinengtuwsainsgpperafrotrimcleedfiolnteras.siTnghlee-rceoforereC,PinUatnoavcetruifayltohpeecroamtiopnut,aptaiornaallleslipzeaetdi.onIn
reaallloitwy,sitfoirsapcocsesliebrleatteodpcaarlaclulellaizteionans.d implement each sample during Monte Carlo sampling
using particle filters. Therefore, in an actual operation, parallelization allows for accelerated
calculations.
viii
ix
(a)Environment1 (b)Environment2 (c)Environment3 (d)Environment4 (e)Environment5
(f)Environment6 (g)Environment7 (h)Environment8 (i)Environment9 (j)Environment10
Figure D1. HomeenvironmentscreatedwithSIGVerseinExperimentI(tenenvironments)
Appendix D. Results of Experiment I in ten environments
In this section, we present the results of Experiment I using ten simulated home
environmentscreatedinSIGVerseastheexperimentalenvironment.Theexperimental
setup is shown in Figure D1. Maps previously created by SLAM were used in all
the environments. Examples of the learning results for all the methods are shown in
Figures D2â€“D11. The index of the spatial concept is colored according to the position
coordinates where the data are observed in each environment. Each ellipse represents
thepositiondistribution.Thecolorsofeachellipseandcandidatepointwererandomly
determined for each trial. Sub-figure (a) shows the ideal form envisioned by the tutor
for reference. Finally, the progress of the results of the evaluation values in the ten
experimental environments is shown in Figure D12.
x
Wednesday31st May,2023 AdvancedRobotics output
(a) Environment1 (b) Environment2 (c) Environment3 (d) Environment4 (e) Environment5
(f) Environment6 (g) Environment7 (h) Environment8 (i) Environment9 (j) Environment10
FigureD1. HomeenvironmentscreatedwithSIGVerseinExperimentI(tenenvironments)
6
4
2
0
2
4
6
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(a) Ideal
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(d) Random
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
F on ig F t u h r i e e gu D m r 2 a e . p. D Ex 2 a . mp E l x es am of p le le a s rn o in f g le r a e r s n u i l n ts g in re e s n u v l i t r s on in m e e n nt vi 1 r : o P n o m si e t n io t n 1 d : i P st o ri s b it u i t o io n n d s i a s n tr d ib in u d t i i c o e n s s C a1n:nd o i f n s d p i a c t e i s al C c 1 o : n n ce o p f t s s p d a r t a i w al n
conceptsdrawnonthemap.
Appendix D. Results of Experiment I in ten environments
Wednesday31st May,In202t3his sAecdtviaonnce,dwReobporteicssentotuhtepurtesults of Experiment I using ten simulated home environments
created in SIGVerse as the experimental environment. The experimental setup is shown in Fig-
ure D1. Maps previously created by SLAM were used in all the environments. Examples of the
learning results for all the methods are shown in Figures D2â€“D11. The index of the spatial
concept is colored according to the position coordinates where the data are observed in each
environm6ent. Each ellipse represents the position distribution. The colors of each ellipse and
candidate4 point were randomly determined for each trial. Sub-figure (a) shows the ideal form
envisioned2 by the tutor for reference. Finally, the progress of the results of the evaluation values
0
in the ten experimental environments is shown in Figure D12.
2
4
6
6 4 2 0 2 4
x
ix
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(a) Ideal
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(d) Random
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
FigureD3. Examplesoflearningresultsinenvironment2:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
4
2
0
2
4
6 4 2 0 2 4
x
y
4
2
0
2
4
6 4 2 0 2 4
x
(a) Ideal
y
4
2
0
2
4
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
4
2
0
2
4
6 4 2 0 2 4
x
y
4
2
0
2
4
6 4 2 0 2 4
x
(d) Random
y
4
2
0
2
4
6 4 2 0 2 4
x
(e) Travelcost
y
Figure D3. Examplesoflearningresultsinenvironment2:PositiondistributionsandindicesC1:n ofspatial
conceptsdrawnonthemap.
xi
(f) IGmin
FigureD4. Examplesoflearningresultsinenvironment3:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
x
Wednesday31st May,2023 AdvancedRobotics output
6
4
2
0
2
4
6
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(a) Ideal
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(d) Random
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
FigureD3. Examplesoflearningresultsinenvironment2:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
4
2
0
2
4
6 4 2 0 2 4
x
y
4
2
0
2
4
6 4 2 0 2 4
x
(a) Ideal
y
4
2
0
2
4
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
4
2
0
2
4
6 4 2 0 2 4
x
y
4
2
0
2
4
6 4 2 0 2 4
x
(d) Random
y
4
2
0
2
4
6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
FigureD4. Examplesoflearningresultsinenvironment3:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onFtihgeumraepD. 4. Examplesoflearningresultsinenvironment3:PositiondistributionsandindicesC1:n ofspatial
conceptsdrawnonthemap.
Wednesday31stMay,2023 AdvancedRobotics output
4
2
0
2
4
6 4 2 0 2 4
x
x
y
4
2
0
2
4
6 4 2 0 2 4
x
(a) Ideal
y
4
2
0
2
4
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
4
2
0
2
4
6 4 2 0 2 4
x
y
4
2
0
2
4
6 4 2 0 2 4
x
(d) Random
y
4
2
0
2
4
6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
FigureD5. Examplesoflearningresultsinenvironment4:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
4
2
0
2
4
8 6 4 2 0 2 4 6
x
y
4
2
0
2
4
8 6 4 2 0 2 4 6
x
(a) Ideal
y
4
2
0
2
4
8 6 4 2 0 2 4 6
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
4
2
0
2
4
8 6 4 2 0 2 4 6
x
y
4
2
0
2
4
8 6 4 2 0 2 4 6
x
(d) Random
y
4
2
0
2
4
8 6 4 2 0 2 4 6
x
(e) Travelcost
y
Figure D5. Examplesoflearningresultsinenvironment4:PositiondistributionsandindicesC1:n ofspatial
conceptsdrawnonthemap.
xii
(f) IGmin
FigureD6. Examplesoflearningresultsinenvironment5:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
xi
Wednesday31stMay,2023 AdvancedRobotics output
4
2
0
2
4
6 4 2 0 2 4
x
y
4
2
0
2
4
6 4 2 0 2 4
x
(a) Ideal
y
4
2
0
2
4
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
4
2
0
2
4
6 4 2 0 2 4
x
y
4
2
0
2
4
6 4 2 0 2 4
x
(d) Random
y
4
2
0
2
4
6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
FigureD5. Examplesoflearningresultsinenvironment4:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
4
2
0
2
4
8 6 4 2 0 2 4 6
x
y
4
2
0
2
4
8 6 4 2 0 2 4 6
x
(a) Ideal
y
4
2
0
2
4
8 6 4 2 0 2 4 6
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
4
2
0
2
4
8 6 4 2 0 2 4 6
x
y
4
2
0
2
4
8 6 4 2 0 2 4 6
x
(d) Random
y
4
2
0
2
4
8 6 4 2 0 2 4 6
x
(e) Travelcost
y
(f) IGmin
FigureD6. Examplesoflearningresultsinenvironment5:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
FoignutrheemDa6p.. Examplesoflearningresultsinenvironment5:PositiondistributionsandindicesC1:n ofspatial
conceptsdrawnonthemap.
Wednesday31st May,2023 AdvancedRobotics output
6
4
2
0
2
4
6
xi
4 2 0 2 4 6
x
y
6
4
2
0
2
4
6
4 2 0 2 4 6
x
(a) Ideal
y
6
4
2
0
2
4
6
4 2 0 2 4 6
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6
4 2 0 2 4 6
x
y
6
4
2
0
2
4
6
4 2 0 2 4 6
x
(d) Random
y
6
4
2
0
2
4
6
4 2 0 2 4 6
x
(e) Travelcost
y
(f) IGmin
FigureD7. Examplesoflearningresultsinenvironment6:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
6
4
2
0
2
4
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6 4 2 0 2 4
x
(a) Ideal
y
6
4
2
0
2
4
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6 4 2 0 2 4
x
(d) Random
y
6
4
2
0
2
4
6 4 2 0 2 4
x
(e) Travelcost
y
Figure D7. Examplesoflearningresultsinenvironment6:PositiondistributionsandindicesC1:n ofspatial
conceptsdrawnonthemap.
xiii
(f) IGmin
FigureD8. Examplesoflearningresultsinenvironment7:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
xii
Wednesday31st May,2023 AdvancedRobotics output
6
4
2
0
2
4
6
4 2 0 2 4 6
x
y
6
4
2
0
2
4
6
4 2 0 2 4 6
x
(a) Ideal
y
6
4
2
0
2
4
6
4 2 0 2 4 6
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6
4 2 0 2 4 6
x
y
6
4
2
0
2
4
6
4 2 0 2 4 6
x
(d) Random
y
6
4
2
0
2
4
6
4 2 0 2 4 6
x
(e) Travelcost
y
(f) IGmin
FigureD7. Examplesoflearningresultsinenvironment6:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
6
4
2
0
2
4
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6 4 2 0 2 4
x
(a) Ideal
y
6
4
2
0
2
4
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6 4 2 0 2 4
x
(d) Random
y
6
4
2
0
2
4
6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
FigureD8. Examplesoflearningresultsinenvironment7:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onFtihgeumraepD. 8. Examplesoflearningresultsinenvironment7:PositiondistributionsandindicesC1:n ofspatial
conceptsdrawnonthemap.
Wednesday31stMay,2023 AdvancedRobotics output
4
2
0
2
4
8 6 4 2 0 2 4
x
xii
y
4
2
0
2
4
8 6 4 2 0 2 4
x
(a) Ideal
y
4
2
0
2
4
8 6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
4
2
0
2
4
8 6 4 2 0 2 4
x
y
4
2
0
2
4
8 6 4 2 0 2 4
x
(d) Random
y
4
2
0
2
4
8 6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
FigureD9. Examplesoflearningresultsinenvironment8:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
6
4
2
0
2
4
6
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(a) Ideal
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(d) Random
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(e) Travelcost
y
Figure D9. Examplesoflearningresultsinenvironment8:PositiondistributionsandindicesC1:n ofspatial
conceptsdrawnonthemap.
xiv
(f) IGmin
Figure D10. Examples of learning results in environment 9: Position distributions and indices C1:n of spatial concepts
drawnonthemap.
xiii
Wednesday31st May,2023 AdvancedRobotics output
4
2
0
2
4
8 6 4 2 0 2 4
x
y
4
2
0
2
4
8 6 4 2 0 2 4
x
(a) Ideal
y
4
2
0
2
4
8 6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
4
2
0
2
4
8 6 4 2 0 2 4
x
y
4
2
0
2
4
8 6 4 2 0 2 4
x
(d) Random
y
4
2
0
2
4
8 6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
FigureD9. Examplesoflearningresultsinenvironment8:PositiondistributionsandindicesC1:nofspatialconceptsdrawn
onthemap.
6
4
2
0
2
4
6
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(a) Ideal
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6
6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(d) Random
y
6
4
2
0
2
4
6
6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
Figure D10. Examples of learning results in environment 9: Position distributions and indices C1:n of spatial concepts
draFwingounrethDem10a.p.Examplesoflearningresultsinenvironment9:PositiondistributionsandindicesC1:nofspatial
conceptsdrawnonthemap.
Wednesday31stMay,2023 AdvancedRobotics output
6
4
2
0
2
4
6
8 6 4 2 0 2 4
x
xiii
y
6
4
2
0
2
4
6
8 6 4 2 0 2 4
x
(a) Ideal
y
6
4
2
0
2
4
6
8 6 4 2 0 2 4
x
(b) SpCoAE
y
(c) SpCoAEwithtravelcost
6
4
2
0
2
4
6
8 6 4 2 0 2 4
x
y
6
4
2
0
2
4
6
8 6 4 2 0 2 4
x
(d) Random
y
6
4
2
0
2
4
6
8 6 4 2 0 2 4
x
(e) Travelcost
y
(f) IGmin
Figure D11. Examples of learning results in environment 10: Position distributions and indices C1:n of spatial concepts
dFraigwunroentDhe11m.apE. xamples of learning results in environment 10: Position distributions and indices C1:n of
spatialconceptsdrawnonthemap.
xv
xiv
Wednesday31stMay,2023 AdvancedRobotics output
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80
Step
i xedni
fo IRA
dethgieW
6000
5000
4000 3000
2000
1000
0 0 10 20 30 40 50 60 70 80
Step
ecnatsiD
levarT
evitalumuC
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
i xedni
fo IRA
dethgieW
4000
3000
2000
1000
0 0 10 20 30 40 50 60
Step
ecnatsiD
levarT
evitalumuC
1.0
0.8
0.6
0.4
0.2
0.00 20 40
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40
Step
i xedni
fo IRA
dethgieW
2500
2000 1500
1000
500
0 0 10 20 30 40 50
Step
ecnatsiD
levarT
evitalumuC
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
i xedni
fo IRA
dethgieW
4000
3000
2000
1000
0 0 10 20 30 40 50 60
Step
ecnatsiD
levarT
evitalumuC
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100
Step
i xedni
fo IRA
dethgieW
10000
8000
6000
4000
2000
00 20 40 60 80 100
Step
ecnatsiD
levarT
evitalumuC
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100 120
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100 120
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100 120
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100 120
Step
i xedni
fo IRA
dethgieW
12000
10000
8000 6000
4000
2000
0 0 20 40 60 80 100 120
Step
ecnatsiD
levarT
evitalumuC
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
i xedni
fo IRA
dethgieW
6000
5000
4000 3000
2000
1000
0 0 10 20 30 40 50 60 70
Step
ecnatsiD
levarT
evitalumuC
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80
Step
i xedni
fo IRA
dethgieW
6000
5000
4000
3000 2000
1000
0 0 20 40 60 80
Step
ecnatsiD
levarT
evitalumuC
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60
Step
i xedni
fo IRA
dethgieW
5000
4000
3000
2000
1000
0 0 10 20 30 40 50 60 70
Step
ecnatsiD
levarT
evitalumuC
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100
Step
i xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100
Step
C xedni
fo IRA
dethgieW
1.0
0.8
0.6
0.4
0.2
0.00 20 40 60 80 100
Step
i xedni
fo IRA
dethgieW
10000
8000
6000
4000
2000
0 0 20 40 60 80 100
Step
ecnatsiD
levarT
evitalumuC
SpCoAE SpCoAE_TravelCost Random TravelCost IG_min
FigureD12. Evaluationvaluesintenenvironments:fromlefttoright,ARI(step-by-step)valuesofCandi,ARI(predictive
Fpaidgduirneg)Dva1lu2e.sofECvaalnudatii,oanndvacluumesuliantivteentreanvevlirdoisntmanecnet.s:fromlefttoright,ARI(step-by-step)valuesofC and
i,ARI(predictivepadding)valuesofC andi,andcumulativetraveldistance.
xxvvi

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Active Exploration based on Information Gain by Particle Filter for Efficient Spatial Concept Formation"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   âŒ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   âœ… GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   âŒ BAD: Repeating the same claim 3+ times with slight variations
   âœ… GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
