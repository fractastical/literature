=== IMPORTANT: ISOLATE THIS PAPER ===
You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.
Do NOT mix information from different papers. Only use information from THIS specific paper.

Paper Title: Active Inference in Contextual Multi-Armed Bandits for Autonomous Robotic Exploration
Citation Key: wakayama2024active
Authors: Shohei Wakayama, Alberto Candela, Paul Hayne

REMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.

Year: 2024

Key Terms: armed, autonomous, bandits, contextual, robotic, data, inference, selection, active, exploration

=== FULL PAPER TEXT ===

IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 1
Active Inference in Contextual Multi-Armed
Bandits for Autonomous Robotic Exploration
Shohei Wakayama1, Alberto Candela2, Paul Hayne3, and Nisar Ahmed1
Abstract—Autonomous selection of optimal options for data
collection from multiple alternatives is challenging in uncertain
environments. When secondary information about options is ac-
I want to collect a
cessible,suchproblemscanbeframedascontextualmulti-armed
kaolinite specimen He wants to collect a
bandits (CMABs). Neuro-inspired active inference has gained kaolinite specimen…
interest for its ability to balance exploration and exploitation
usingtheexpectedfreeenergyobjectivefunction.Unlikeprevious
k =1
studies that showed the effectiveness of active inference based
strategyforCMABsusingsyntheticdata,thisstudyaimstoapply
active inference to realistic scenarios, using a simulated miner-
alogical survey site selection problem. Hyperspectral data from
AVIRIS-NGatCuprite,Nevada,servesascontextualinformation This area might be
for predicting outcome probabilities, while geologists’ mineral rich in alunite…
labels represent outcomes. Monte Carlo simulations assess the
robustness of active inference against changing expert prefer-
ences.Resultsshowactiveinferencerequiresfeweriterationsthan k =K
standard bandit approaches with real-world noisy and biased
data,andperformsbetterwhenoutcomepreferencesvaryonline
by adapting the selection strategy to align with expert shifts.
Hyperspectral contextual data
Index Terms—Active inference, contextual multi-armed ban-
dits, robotic exploration.
Fig.1. Anaerialrobotreasonswhereadesiredmineralrockspecimencanbe
sampledbyutilizingremotesensingdatasuchashyperspectralinformation.
Tospeeduptheprocess,itisdesirablenotonlytostrikeabalancebetween
I. INTRODUCTION
exploitationandexploration,butalsoincorporateaselectionbias,i.e.human
expertpriorpreferences,regardingthedesiredobservations.
For robotic exploration of uncertain environments such as
outer solar system planets, disaster sites, and geologically
intriguingareasonEarth,itisoftencrucialtooptimallyselect
tance between humans and robots, limited bandwidth in com-
amongmultiplealternativeoptionstoenableautonomousdata
munication,andnecessityforincreased“housekeeping”down-
collection (e.g. selecting a mineral rock specimen for detailed
time for the robots. Therefore, robots operating in uncertain
chemical analysis and landing site selection for a planetary
environments are expected to efficiently and autonomously
rover) [1]. Such decision making has been mostly performed
determine the best options for data collection to mitigate the
byhumandomainexperts,suchasscientistsandengineers[2],
aforementioned issues and to enhance the overall mission
since this mitigates the possible dangers posed to exploration
outcomes. Nevertheless, it is not straightforward to make
robots which are costly and difficult to replace. However,
such decisions due to the stochastic nature of the dispatched
this approach leads to significant mental workload on humans
environments, since sensing outcomes are stochastic and the
[3], [4]. Additionally, due to the difficulty of interpreting
distributions of the outcome observations are unknown a
low-quality data sent from the robots, there is a risk that
priori.
humans might overlook optimal options and make suboptimal
decisions, ultimately decreasing mission efficiency. Moreover, For instance, consider a scenario, as illustrated in Fig. 1,
for highly remote and underexplored uncertain environments where an aerial robot must autonomously select the most
(e.g.icymoonsofJupiteranddisastersitesatanuclearpower promising site for sampling a desired mineral rock specimen
plant), it is not possible to rely on frequent and information- during a follow-up in-situ survey mission [5]. This search site
rich human-robot interaction because of the significant dis- selection is based on remote sensing data (e.g. hyperspectral
information) gathered from predetermined search sites using
1S.WakayamaandN.AhmedarewiththeSmeadAerospaceEngineering a lightweight sensor (e.g. spectrometer). In this scenario,
Sciences Department, University of Colorado Boulder, Boulder, CO 80303 however, the sensing returns obtained by directing sensors are
USA[shohei.wakayama; nisar.ahmed]@colorado.edu
2A. Candela is with the Jet Propulsion Laboratory, Cal- stochasticforvariousreasons,forexample,duetoobservation
ifornia Institute of Technology, Pasadena, CA 91109, USA noise and the variability in the targeted coordinates for each
alberto.candela.garza@jpl.nasa.gov
site sampling instance. Moreover, model parameters used to
3P. Hayne is with the Astrophysical & Planetary Sciences
predict the likelihood of observing each outcome (e.g. a de-
Department, University of Colorado Boulder, CO 80303 USA
paul.hayne@lasp.colorado.edu tectedmineralspecimen)basedonthesereturnsarenotknown
5202
naJ
5
]OR.sc[
2v91140.8042:viXra
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 2
beforehand.Thus,therobotneedstocarefullystrikeabalance • Demonstrating the effectiveness of the AIF-based option
between exploitation (increasing the certainty in sites where selection algorithm using real scientific data, namely
desired mineral specimens are expected) and exploration (de- basedonhyperspectraldatacollectedbyAVIRIS-NG[23]
creasing the uncertainty in poorly explored search sites). This and mineral label data created by geologists [24]. This
sequential decision-making problem can be formulated with study marks the first application of active inference in
mathematicalframeworkssuchaspartiallyobservableMarkov geological data exploration.
decisionprocesses(POMDPs)[6],[7]andGaussianprocesses • Showcasing the superiority of the proposed method to
(GPs) [8], [9]. In the case of POMDPs, however, careful conventionalbanditoptionselectionstrategiesevenwhen
definitionsofastatetransitionfunction,arewardfunction,and human expert’s preferences for desired outcomes change
plannerhyperparameters(e.g.aplanningdepthandadiscount dynamically.
factor) are required. Reward and hyperparameter tuning, in The remainder of this paper is organized as follows. Sec.
particular,canbetrickyandtime-consuminginnewanduncer- II provides an overview of multi-armed bandits (MABs) and
tainenvironments[10].Ontheotherhand,inthecaseofGPs, CMABs, along with an introduction to active inference. Sec.
while they can leverage a spatial structure of an environment, III describes the problem statement, and then presents the
thecomputationcostofkernelfunctionsissignificantforreal- AIF-based option selection method for CMABs. In Sec. IV,
timeoperation[11],[12].Additionally,neitherframeworkeas- we explain the science dataset and detail the preprocessing
ilyincorporateshumanexpertpreferencesregardingoutcomes procedures. Following that, we present the offline training
easily.Thus,instead,weopttostudysimplercontextualmulti- resultsusedtolearnthe“true”(butunknowntotheexploration
armed bandit (CMAB) formulation, which has been widely robot) hidden parameters associated with options. Then, the
studied in recommendation systems, finance, healthcare, and simulation setup is outlined and the results from the simu-
recently, robotics [13]–[16], and allows us to advantageously lated Monte Carlo experiments are discussed. Finally, Sec. V
abstract certain lower-level behavioral aspects of the search concludes the study with a summary of key findings and the
site selection problem. potential research directions.
However, in general, bandit problems–depending on their
II. BACKGROUND
scale and complexity–often require a large number of itera-
A. Multi-Armed Bandits (MABs) and Contextual MABs
tive interactions with the environment to finalize the optimal
option. This need for numerous iterations can become a The multi-armed bandit (MAB) is a classic reinforcement
bottleneck when applying this mathematical framework to learning problem that involves identifying and utilizing the
practical robotic applications, such as space exploration and optimal option among multiple alternatives [25]. In MABs,
mineralogical surveys on Earth, where resources and time are an outcome from each option (a.k.a. “arm”) is probabilistic,
oftenconstrained.Moreover,existingconventionalmethodsin and its distribution is unknown a priori, leading to the so-
CMABs typically do not explicitly take into account human called exploration-exploitation dilemma since only one op-
experts’(e.g.scientists’)priorpreferencesregardingoutcomes tion’soutcomecanbeobservedperdecision-makingiteration.
in their decision-making processes. As a consequence, the Therefore, bandit agents repeatedly execute two key steps–
decisions derived from these methods may not always align 1) option/arm selection and 2) measurement update–to ideally
with what humans are actually interested in observing, lead- minimize the cumulative regret, which measures the disparity
ing to the decrease in mission efficiency. In light of these between the total reward achieved by consistently selecting
backdrops, our previous studies [17], [18] sought to emulate the best option (unknown during execution) and that obtained
the approach taken by astronaut Harrison Schmitt during following a specific option selection strategy [26]. In standard
the Apollo 17 mission, where he combined in-situ findings MAB,however,sincetheinformationusedforoptionselection
with geological expert knowledge to advance lunar geology is solely based on past outcome observations, a sufficiently
[19]. To achieve a similar behavior in robotic systems, we large number of iterations is typically required to identify the
applied active inference (AIF) [20]–[22]–which originated in best option.
computationalneuroscienceandhasrecentlygainedtractionin Conversely, in contextual MABs (CMABs), additional side
robotics–to develop option selection strategies for stationary, information, known as contexts, associated with each option
independent, and linear CMABs that are informed by expert- is used to predict outcome observation probabilities. This
provided prior preferences on observations. While these stud- prediction is done in conjunction with the unique hidden
ies showed that AIF agents could efficiently identify the best parameters of each option during option selection, and allows
option for humans compared to other strategies when expert formoreefficientidentificationoftheoptimaloptionandmin-
prior preference is stationary, the contextual information used imization of the cumulative regret. For measurement updates,
for decision-making and the true hidden model parameters Bayes’ theorem is primarily used. For option selection, ε-
associated with the options were randomly generated, which greedy,strategiesbasedontheupperconfidencebound(UCB)
doesnotreflectreal-worldconditions.Hence,inthisarticle,we [27], [28], Thompson sampling [29], [30], and methods using
aimtovalidatetheapplicabilityoftheAIF-basedoptionselec- the softmax function [26] are well-known. However, these
tion methodology in realistic problem scenarios. Specifically, conventional option selection methods often rely on heuristics
the key contributions and novelty with respect to previous to achieve good performance. Additionally, external prefer-
studies [17], [18] are: ences, such as those from domain experts regarding valuable
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 3
outcomeobservationsforroboticexploration,cannotbeeasily more realistic data. Also, in our previous studies, the prior
incorporated. Hence, the outcomes obtained by following preferencedistributionsareassumedtobestationary.However,
these option selection strategies may not align with what in realistic scenarios, human preferences regarding outcomes
humans actually want to observe. Therefore, it is important can change dynamically. Therefore, after introducing the
to develop an alternative option selection strategy particularly CMABproblemandreviewingtheproposedAIF-basedoption
for such robotics applications. This is because the number of selection method, we are going to present how the method is
iterations must generally be limited in such applications, and validated and demonstrated for more practical problems with
incorporating human prior preferences in decision-making is these characteristics, using a real scientific dataset.
crucial to enhance the interpretability of the robot’s decisions.
III. METHODOLOGY
B. Free Energy Principle and Active Inference A. Problem Statement
The free energy principle (FEP) is a theoretical framework Supposethetotalnumberofoptions(e.g.searchsites)taken
proposed in the field of computational neuroscience to math- into account by a robot is K ∈N. Note that these options are
ematically and systematically explain the functioning of the equivalent to the bandit arms and selecting an option k ∈
brain [31], [32]. According to this principle, biological agents {1,··· ,K} is denoted as a = k (for the ease of notation, in
form probabilistic internal models of external environments
thefollowing,weusea
k
↔a=k).Additionally,supposethat
and, based on these models, perceive, learn, and act to
asemanticobservationo
k
(e.g.minerallabel)ofeachoptionk
minimize the discrepancy (i.e. free energy) between predicted fromanobservationsourceismulticategoricalacrossF labels,
observationsandactualsensoryinputs,therebyincreasingtheir i.e. o k = f,f ∈ F = {1,··· ,F}. Therefore, the probability
chances of survival. Predictive coding, known in research on that a feature f is observed by investigating an option k at a
the visual cortex, is one specific implementation of the FEP decision instance t can be described as the following softmax
[33], [34]. likelihood function [45], [46]1,
a ic p a p A l li c a e t g s iv e t n e h t e s in F [ f 2 E e 0 r P ] e , n s [ c p 2 e e 1 c ] ( i . A fi I c I n a F l ) t l h y i e s to fi a e th l m d e a o b t f e h h n e a m e v u a i r o t o i r c s a c a l i l e n n f o r c r a m e m , s e it w o h f o a b r s k io b l t e o h e g a n - t p(o k,t =f|Θ⃗ k ;⃗x k,t )= (cid:80)F h e = w⃗ 1 k T e ,f w⃗ ⃗x k T k , , h t ⃗x + k b , k t , + f bk,h , (1)
used to understand the characteristic behavioral mechanisms where Θ⃗ = [w⃗ ,b ,··· ,w⃗ ,b ],Θ⃗ ∈ R(C+1)×F is
k k,1 k,1 k,F k,F k
observed in patients with autism [35], [36]. Recently, it has a hidden linear parameter vector unique to the option k, and
also garnered attention in the field of robotics for state ⃗x ∈ RC is a (dynamic) context vector (e.g. indicating the
k,t
estimation, adaptive control, and for decision making under
choice of in-situ hyperspectral measurement) specific to the
uncertainty [22], [37]–[39]. The reason for this lies in the option k, where C is the context feature dimension (e.g. the
expected free energy (EFE) objective function characterizing
number of available hyperspectral bands).
AIF. Although a detailed explanation is provided in Sec. III,
Recall that the objective of CMABs is to minimize cu-
the EFE for each possible option/action in the MAB/CMAB
mulative regret. Here, a unit reward (1) is provided if a
contextconsistsofthe(negative)valueresultingfromselecting
predetermined preferable feature f ∈ F is observed for o ,
p k
a particular option and the (negative) information gain (i.e.
and no reward (0) is given if any other feature is observed. In
mutual information commonly known in robotics [40], [41]
the case of the search site selection scenario, for instance, f
p
andBayesianexperimentaldesign[42],[43])representinghow
represents a particular mineral label that scientists want the
much the uncertainty about hidden states is reduced by taking
robot to investigate (e.g. a kaolinite specimen). Thus, if the
that option. Consequently, by optimizing (i.e. minimizing) the
probability of observing f with the best (unknown a priori)
p
EFE,agentscannaturallytakeanactionbalancingexploitation option is ψ∗, the cumulative regret is written as below [27],
and exploration. Additionally, since preference information
K
regarding outcome observations, known as prior preference, (cid:88)
Regret(T)=Tψ∗− N (k)ψ , (2)
can be externally incorporated into the value term, agents T k
k=1
take actions biased towards obtaining desired observations.
This characteristic has recently been studied for Pareto point where T is the total number of decision instances, N T (k)
selection problems in multi-objective reinforcement learning represents the number of times an option k is selected within
[44]. T iterations, and ψ k is the probability that f p is observed by
Given these backdrops, our previous works have proposed selecting the option k. In order to minimize the cumulative
AIF-based option selection methods for CMABs, particularly regrets, the robot is required to efficiently estimate the set
when hybrid discrete-continuous observation likelihoods such of softmax parameters Θ⃗ k for all k in the process of finding
as sigmoid and softmax functions are employed [17], [18]. an optimal option by iteratively performing the two steps of
Although autonomous robotic agents with these methods oc-
1It is also natural to choose a Dirichlet distribution as a prior and a
casionally get stuck in local minima due to selection bias,
categoricaldistributionasanobservationlikelihood,astheirconjugacyallows
extensive simulation experiments with synthetic datasets have foreasyposteriorcalculation[45].Nevertheless,thisapproachcannoteasily
demonstrated that the AIF agents can identify the best option incorporate continuous contextual information (such as hyperspectral data)
associated with the options. Hence, the softmax function, which is one of
with a far fewer number of iterations. Yet, the practicability
hybrid discrete-continuous likelihood functions and has gained attention in
of the proposed AIF methods has not been validated on thefieldofmulti-sensorfusion[47]–[50],isadopted.
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 4
(cid:90) (cid:111)
optionselectionandmeasurementupdate.AsdescribedinSec. − q(Θ⃗ |a )p(o|Θ⃗ )logp(o|Θ⃗ )dΘ⃗ , (4)
k k k k k
II-A, for measurement update, Bayes’ theorem is commonly Θ⃗
k
used. For option selection, ε-greedy, methods based on the where q(Θ⃗ |a ) is a proposal distribution that approximates
k k
upper confidence bound (UCB) and the softmax function are the posterior distribution p(Θ⃗ |o,a ), and p (o) is a prior
k k pr
widely used [26]. However, these methods cannot leverage preference distribution, which defines an outcome observation
additional information regarding the preference of observed distribution that the agent expects to see when undertaking
outcomes, which could enable the robot to selectively favor options. Since p can be arbitrarly determined, in the
pr(o)
options, leading to preferred outcomes and potential increase case of the mineralogical survey scenario, for example, a
oftheinterpretabilityoftherobot(issueA).Additionally,since humanscientistcanprovidetherobotwiththedesiredmineral
these methods rely on heuristics for exploring the unknown label distribution as p , specified as 1 × F probability
pr(o)
options, they usually require lots of decision instances to de- vector with non-negative entries summing to 1. This desired
terminetheoptimaloption,whichisnotdesirableforproblems distribution can be interpreted as a probabilistic characteri-
for which there are constraints on T (issue B). Hence, in this zation of worthwhile data that the scientist would expect to
study, we employ an option selection method that not just obtain. Specifying this distribution differentiates AIF from
exploitstheoutcomepreferencetoincreasetheinterpretability other conventional decision-making algorithms [6], [7], where
ofroboticdecision-making,butalsoexploresunknownoptions either robotics experts must manually adjust numeric reward
inamathematicallyrigorouswayforefficientlyidentifyingthe valuesassignedtoactions(aprocessthatlacksstraightforward
optimal options. interpretability),orrewardsmustbelearnedfrommultipleuser
demonstrations(whichisalsotime-consumingandimpractical
for many kinds of exploration missions). In AIF literature, (4)
B. Active Inference Option Selection
iscommonlyfurthertransformedasfollowstoeasilyinterpret
As experimentally validated in previous studies [17], [18], the meaning,
[51], option selection based on active inference (AIF) ad- (cid:104) (cid:105)
dresses the aforementioned desirable key elements. This is G(a k )=−E q(o|ak) logp pr (o)
because of the unique characteristics of its objective function, (cid:104) (cid:16) (cid:17)(cid:105)
−E D q(Θ⃗ |o,a )||q(Θ⃗ |a ) , (5)
i.e. expected free energy (EFE), which is composed of (i) q(o|ak) KL k k k k
the extrinsic value scoring the degree of how the predicted
where q(o|a ) is the predicted observation distribution
k
outcome observation distribution aligns with the desired dis-
(cid:90)
tribution,and(ii)theepistemicvalueevaluatinghowexecuting q(o|a )= q(Θ⃗ |a )p(o|Θ⃗ )dΘ⃗ . (6)
k k k k k
an option could reduce the uncertainty of the option [52]. Θ⃗
k
In the following, we begin with outlining the derivation of
The first term and the second term of (5) represent (i) the
EFE for constructing an option selection policy. Then, as a
(negative) extrinsic value and (ii) the (negative) epistemic
special case, we explain how to compute EFE when a prior
value, respectively. Thus, as can be seen from this equation,
proposaldistributionforahiddenlinearparametervectorΘ⃗ is
byoptimizing(i.e.minimizing)G(a ),theagentcannaturally
k
a multivariate Gaussian and the observation likelihood is the
strikeabalancebetweenexploitationcontributingto(issueA)
softmax function.
andexplorationcontributingto(issueB).Fordetailedequation
1) DerivationofOptionSelectionPolicyinAIF: According
transformations to obtain (4) and (5), refer to previous studies
to the theory of active inference [20], [21], the goal of a
[17], [20].
decision-makingagentistominimizethesurpriseofobserva-
To further reflect the possibility that the agent is not
tions to maintain its homeostasis. The surprise in the case of
necessarily confident of the values of G(a ), in this study, an
k
CMABs defined in Sec. III-A is expressed as,
option selection policy (7) is formed with the use of G(a ),
k
(cid:90) suchthattheagentsamplesthenextactionfromthecategorical
Surprise=−logp(o)=−log p(o,Θ⃗)dΘ⃗. (3)
distribution (8).
Θ⃗
exp(−γG(a ))
However, directly calculating (3) via multiple integrals tends q(a )= k , (7)
to be analytically intractable, so its upper bound derived from
k (cid:80)K
exp(−γG(a ))
j=1 j
Jensen’s inequality results in a function called free energy
(a.k.a. (negative) evidence lower bound) which is minimized a∼Cat(a ,··· ,a ;q(a ),··· ,q(a )). (8)
1 K 1 K
instead. Nevertheless, in decision making, outcomes o are
unknownuntilanoptionk isactuallyexecuted.Therefore,the In(7),γiscalledprecision(similartoinversetemperature)and
AIFagentinsteadoptimizesEFE(denotedasG(a ))described itadjuststheconfidenceofthecurrentEFEprediction[20](the
k
in (4). Hereafter, the decision instance index t and the context larger the value of γ, the higher the confidence). Algorithm
vector ⃗x are abbreviated for the ease of notation, 1 summarizes the process of active inference option selection
k,t
G(a )= (cid:90) q(Θ⃗ |a ) (cid:88) p(o|Θ⃗ )log q(Θ⃗ k |a k ) dΘ⃗ , f p o o r lic C y M r A es B em s. b A le t s fi th r e st s g o l f a tm nc a e x , o th p i t s io s n to s c e h le a c st t i i c on o t p e t c io h n niq se u l e ec u t s io e n d
k Θ⃗ k k k o k p(Θ⃗ k |o,a k )p pr (o) k for conventional MABs and CMABs [26]. However, unlike
= (cid:88)(cid:110) q(o|a )log q(o|a k ) AIF, the conventional MAB softmax method only uses the
k p (o) average reward/utility obtained by selecting an option k up
pr
o
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 5
Algorithm 1 Active Inference Option Selection for CMABs (9) reduces to
Input: EstimatedsetofparametersΘ⃗ k andcontextvector⃗x k,t logg(Θ⃗ )≈logg(Θ⃗ )+
k k,MAP
foralloptionsk,k ={1,··· ,K},andthepriorpreference
1 (cid:104) (cid:105)
distribution p (o) (Θ⃗ −Θ⃗ )TH logg(Θ⃗ ) (Θ⃗ −Θ⃗ ), (11)
pr 2 k k,MAP k,MAP k k,MAP
Output: Selected option index
where H is the Hessian (Note that the Hessian can be
1: Initialize G(a k ) for all options
calculated by computing the Jacobian of the gradient, and
2: for each option k do
the gradient can be derived with an optimizer imple-
3: for each outcome o do
mented in the standard scientific computing library such as
4: Compute G(a k ,o) via (5)
scipy.optimizer). Thus, if we define A = −H and by
5: end for
(cid:80) taking the logarithm from (11),
6: Derive G(a k )= o G(a k ,o)
7: end for g(Θ⃗ )≈
k
8: Construct the option selection policy Cat(·) via (7) (cid:16) (Θ⃗ −Θ⃗ )TA(Θ⃗ −Θ⃗ )(cid:17)
9: return Sample the option a from (8) g(Θ⃗ )·exp − k k,MAP k k,MAP ,
k,MAP 2
(12)
and the normalization constant, i.e. the predicted observation
until the current decision instance to calculate the probability
distribution (6), is computed as
of selecting that option. In other words, it does not take into
account the prediction of future outcomes by utilizing context (C+1)×F
i
o
n
u
f
t
o
c
r
o
m
m
a
e
tio
o
n
bs
a
e
s
rv
w
a
e
ti
l
o
l
n
a
s
s
.
th
T
e
he
(h
d
u
i
m
ff
a
e
n
re
)
n
p
c
r
e
io
s
r
o
p
f
re
t
f
h
e
e
re
b
n
e
c
h
e
a
r
v
e
i
g
o
a
rs
rdi
b
n
e
g
-
q(o|a k )=g(Θ⃗ k,MAP )· (2π) |A|1
2
2 . (13)
tween softmax and AIF agents are further discussed in Sec. By using (13) into (4), the first term of (4) (i.e.
IV. q(o|a k )logq p ( p o r | ( a o k ) )) can be calculated. To calculate the sec-
2) Special Case: Multivariate Gaussian Prior and Soft- ond term of (4), by approximating p(o|Θ⃗ ) as a Gaussian
k
max Observation Likelihood: When q(Θ⃗ k |a k ) is multivariate exponential form from the result of the Laplace posterior
Gaussian and p(o|Θ⃗ k ) is a softmax function, G(a k ) cannot approximation. More details can be found in [18].
be computed analytically since calculating (6) is intractable.
Luckily, several statistical methods have been proposed to IV. SIMULATIONSTUDY
approximate this normalization term [45], [47], [53], and in
To verify whether the proposed active inference option
this study we adopt the Laplace approximation due to its
selection method is effective not only for stationary, indepen-
computation efficiency.
dent, and linear CMABs formulated with randomly generated
Instatisticalmachinelearning,theLaplaceapproximationis
hidden parameters and contexts, as in previous studies [17],
often employed to approximate a probability density function
[18],butalsoforCMABsformulatedbasedonactualscientific
(pdf) as a Gaussian distribution [45]. This uses the second-
data, a mineral search site selection study is considered.
order approximation of the vector Taylor expansion of a loga-
In the following subsections, we begin with an overview
rithmic function whose gradient is a zero-vector. Particularly,
of the motivating autonomous robotic exploration scenario
intheprocessofapproximatingG(a ),afunctiong(Θ⃗ )isde-
k k focusing on surface mineralogical surveys. We then describe
fined as the joint unnormalized distribution q(Θ⃗ |a )p(o|Θ⃗ )
k k k the hyperspectral and mineral label dataset used as contexts
such that the following logarithmic function is used,
and outcome observations. This is followed by an explanation
logg(Θ⃗ )≈logg(Θ⃗(0)) of the preprocessing steps and the result of learning the true
k k hidden parameters necessary for calculating the cumulative
+
(C+
(cid:88)
1)×F
(Θ −Θ(0))
∂logg(Θ⃗(
k
0))
regret. Finally, we detail the simulation setup and present
k,r k,r ∂Θ the results of Monte Carlo simulation experiments under both
k,r
r=1
static and dynamic human prior preferences.
+ 1(cid:110) (C+ (cid:88) 1)×F (Θ −Θ(0)) ∂logg(Θ⃗( k 0))(cid:111)2 ,
2 k,r k,r ∂Θ k,r A. Motivating Scenario
r=1
(9) Limestone and iron are indispensable in construction and
manufacturing sectors. Minerals such as kaolinite and pyrox-
where Θ⃗(0) satisfies ∇logg(Θ⃗ ) =⃗0. However, as it is also
k k eneplayacrucialscientificrole,sheddinglightonsedimentary
analytically intractable to find Θ⃗(0), Θ⃗ is computed via
k k,MAP processes and enhancing our comprehension of rock forma-
Newton’smethod[54].Sincethesecondtermin(9)isremoved
tion [55]. Consequently, mineralogical surveys in unfamiliar
and the third term in (9) can be written as
territories are pivotal for uncovering resources and driving
1(cid:110) (C+ (cid:88) 1)×F (Θ −Θ(0)) ∂logg(Θ⃗( k 0))(cid:111)2 s o c f ie m nt i i n fi e c ral ad e v x a p n lo ce ra m ti e o n n ts. pre N s e e v n e ts rth t e im le e ss, an t d he sa e f x et t y en c si h v a e lle s n c g o e p s e ,
2 k,r k,r ∂Θ
r=1 k,r making effective human-led surveys difficult. As a result,
= 1(cid:110) (Θ⃗ −Θ⃗(0))T∇logg(Θ⃗(0)) (cid:111)2 , (10) research has been conducted to utilize robots equipped with
2 k k k sensing suits to autonomously perform exploration [56], [57].
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 6
0.45
0.40
0.35
0.30
0.25
0.20
2.0 2.1 2.2 2.2 2.3 2.3 2.4 2.5
Wavelength [ m]
ecnatcelfeR
Smectite + Montmorillonite
Sulfate + Alunite
Mica + Muscovite
SiOH + Chalcedony
Fig.2. ExamplerawhyperspectraldatafromtheAVIRIS-NGdataset. Fig.3. Mineralmap:differentcolorscorrespondtodifferent(mixture)mineral
labels. In total, there are 215 labels in this region. Note that pixels on the
edge with dark blue colors are invalid and no mineral labels are assigned.
Thesepixelsareignoredwhentrainingtruesoftmaxparameters.
Inthefollowing,weconsidertheproblemofanautonomous
aerialrobot(asshowninFig.1)identifyingthemostpromising
site(s) where a mineral rock specimen desired by a scientist C. Training True Latent Parameters
can be sampled in a follow-up sample-return mission [5].
When calculating the cumulative regret to evaluate and
These K number of sites are predetermined based on satellite
comparingtheperformanceofoptionselectionalgorithms,the
images [58]. In this problem, the aerial robot uses relatively
ground truth best-fit softmax parameters Θ⃗∗ are required to
lightweightsensors,suchasaspectrometer,toscanthesearch k
sampletheoutcomesforthebestpossiblecase.Notethatthese
sites, and predicts the site with the highest likelihood of
softmax parameters are never known by a decision-making
containing the desirable specimen based on the obtained con-
agent during deployment and can only be accessed/trained
textual hyperspectral information ⃗x. The robot then receives
an observation f on the detected mineral2 at the selected offline (i.e. one of the goals of the decision-making agent
is to efficiently learn the values of these parameters). In
site k from another robot, which is remotely operated by
this subsection, we outline the preprocessing steps for the
humans and can quickly access the scanned coordinate. By
hyperspectral and mineral dataset introduced in Sec. IV-B
hierarchicallystructuringthesearchprocessinmultiplestages
and detail the training procedure of the ground truth best-fit
as such, rather than exhaustively dispatching the robots to
softmax parameters3.
survey the entire region, it is expected that survey efficiency
significantly improves. However, the outcome observation is Firstofall,somepixelslackhyperspectraldata,whileothers
probabilistic by nature and the latent relationship between the lack mineral label data. Since these pixels do not necessarily
context⃗x and the observation f used to predict the likelihood overlap, we take the union of these sets, marked them as
of observing each mineral specimen are unknown a priori, so invalid pixels (shown in dark blue in Fig. 3), and excluded
a CMAB described in Sec. III is adopted to carefully take a them from the training process. Next, since the AVIRIS-NG
balance between exploitation and exploration. dataset has a very high spectral resolution, its dimensionality
C is reduced from 97 to 8 via principal component analysis
(PCA) [45]. This dimensionality reduction is plausible as the
B. Dataset cumulative explained variance ratio (i.e. the sum of the target
number of eigenvalues divided by the sum of all eigenvalues,
The hyperspectral data used in this study is collected using
which ranges between 0 and 1) when the number of PCA
the Next Generation Airborne Visible-Infrared Imaging Spec-
components is 8 is 0.999 (Fig. 4). Additionally, since several
trometer (AVIRIS-NG)at theCuprite mining district, Nevada,
mixtures of minerals assigned with different labels are quite
an area known for its high mineralogical diversity [23]. This
similarandsomelabelsarenotactuallyused,theminerallabel
data assigns a unique reflectance spectrum across 97 spectral
dataset is further manually clustered from 215 to 14 with the
bands to every location (pixel) in the scene. Fig. 2 shows the
advice of experts. Exemplary representative minerals in these
examplespectracollectedatseveraldifferentlocations.Onthe
14 clusters include alunite, mica, and kaolinite. After these
otherhand,theminerallabeldataisconstructedbygeological
preprocessing steps, as shown in Fig. 5, K non-overlapping
experts and one of 215 labels are assigned to each pixel [24].
searchsitesareselected,eachwithdimensionsof200pixelsin
Fig. 3 represents the mineral map highlighted with arbitrary
width and 250 pixels in height, and the pairs of hyperspectral
colors. Note that these two maps are aligned so that the sizes
and mineral label data are combined as datasets. To train
of map images (2673 and 2389 pixels in height and width
directions) and pixels (3.9 m square) are the same.
3Notethatthetrueunderlyingstatisticsarenotnecessarilyrepresentedbya
linearsoftmaxmodel.Thismodelysimplyrepresentsthebestapproximation
2In this study, it is assumed that the total number of minerals present in theautonomousrobotcouldachieveusingalinearapproach,assumingithad
theentireregionisboundedbyafinitevalueF aswith[9]. accesstomoredataandgroundtruthlabels.
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 7
1.00
0.99
0.98
0.97
0.96
0.95
0.94
1 2 3 4 5 6 7 8
Number of Principle Components
oitaR
ecnairaV
denialpxE
evitalumuC
Fig.6. Examplesoftheconfusionmatricesconstructedfromthetestresults.
Fig. 4. Transition of the cumulative explained variance ratio after applying
PCAtotheAVIRIS-NGdataset.
k =2
Fig. 7. Examples histograms of the learned bias values; in mathematical
k =7
terms,whenabiastermb k,f ishighlynegative,thenumeratorinthesoftmax
likelihood function associated with this label f, i.e. ew⃗k T ,f⃗xk,t+bk,f, tends
towardszero,causingp(o
k,t
=f|Θ⃗
k
;⃗x
k,t
)toalsoapproachzero.
to provide a best fit baseline comparison [56].
Fig.5. SelectedsearchsitesoverlaidonanaerialimageoftheCupritemining
district,Nevada.
D. Simulation Setup
Withthesetofthetrainedgroundtruthsoftmaxparameters,
the true best-fit softmax parameters Θ⃗∗, the dataset is split
k the following option selection methods are considered and
into training (80%) and test sets (20%) and the softmax
compared in extensive Monte Carlo (MC) simulation: (i)
regression(i.e.multinomiallogisticregression)withtheAdam
best-fit optimal option selection, using the trained parameters
optimizer [59] is performed with PyTorch [60]. The average
(required for computing the cumulative regret); (ii) ε-greedy
accuracy (i.e. the proportion of correctly classified samples
(where ε=0.3 was found to work best after initial trials); (iii)
out of the total number of samples) over all search sites is
softmax method (where temperature τ was set as 0.1 after
76.7% (note that min/max accuracy is 62.3% and 93.1%,
initial trials); (iv) upper confidence bound (UCB) (where the
respectively). Despite having a relatively low accuracy as
exploration parameter c was set as 0.8 after initial trials); (v):
a classifier, it effectively captures the noise present in the
multicategorical Thompson sampling (TS); (vi): active infer-
measurement process as shown in Fig. 6. This is further
ence(AIF;whereprecisionγ wassetas30afterinitialtrials).
confirmed by examining the histograms of the learned bias
The option selection methods (v) and (vi) are paired with the
values.As depictedin Fig.7, eachsubplot exhibitssignificant
Laplace approximation for the measurement update [45]. 100
negative values (around −20). This observation indicates that
MCrunsareperformed,andthenumberofiterationsT ineach
the trained classifier discerns the absence of certain minerals
MC run is set to 100/150, which is much smaller compared
in these search sites4. Additionally, considering that other re-
to common MAB algorithm benchmarks [51] and reflects a
searchutilizingasimilardatasetalsodemonstratescomparable
practicalupperlimitforroboticlandersensordeployment[18].
accuracy values, it suggests that this classifier is satisfactory
Whentherobotisactuallydeployed,thehyperspectralcontex-
tual information at each site varies across decision instances
4For example, in Fig. 6, it can be observed that minerals of Classes 2
because the exact coordinates targeted by the spectrometer
and 13 are absent at sites 3 and 6. As the number of such absent minerals
increases,thefrequencyoflargenegativevaluesinFig.7alsoincreases. differ each time. To replicate this real-world stochasticity, at
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 8
Pyrophyllite Kaolinite Mica Smectite Pyrophyllite Kaolinite
・・・ 10.0 20 -greedy 20 Softmax
t 7.5
10 10
0 ≦ t < 20 20 ≦ t < 40 40 ≦ t < 60 60 ≦ t < 80 80 ≦ t < 100 100 ≦ t < 120 5.0
2.5 0 0
Fig. 8. Transition of the mineral of greatest interest to a scientist. In this
study,forsimplicity,itisassumedthattransitionsoccurevery20instances. 0.0 10 10
0 50 100 0 50 100 0 50 100
20 UCB 20 AIF 20 TS
every decision-making instance, a pixel is randomly selected
10 10 10
(corresponding to its coordinates) within each site, and the
PCA-processed hyperspectrum associated with it is used as 0 0 0
the context ⃗x ∈ RC. For the initial probability distribution
k,t
p(Θ⃗) used to estimate the hidden softmax parameter vector, a 10 0 50 100 10 0 50 100 10 0 50 100
Time steps
multivariate normal distribution is employed across all search
sites, with a mean vector where all elements are 0.5 and a
diagonal covariance matrix with a scaling factor of 5. Note
that the value of the scaling factor is determined after initial
trials. Finally, in the first simulation experiment intended to
validate the effectiveness of the proposed AIF-based option
selection method in real scientific missions, it is assumed
that a scientist holds the strongest and consistent/stationary
interest in observing pyropillite specimens (i.e. o = f ). p
Thus, the prior preference for observing pyropillite specimens
p (o = f ) is set to 0.8, while p (o ̸= f ) is set to
ev p ev p
0.2 divided by the 13 other possible outcomes. In contrast,
the second experiment assumes that the minerals of greatest
interest to scientists (often informed by insights gained up
to that point) dynamically changes as shown in Fig. 8 to
better align with real scientific missions, and verifies how the
proposed method adapts to this variability.
E. Results: Stationary Prior Preference
When the prior preference distribution is stationary, the
cumulative regrets of both the proposed AIF method (orange)
and the softmax method (yellow) outperform others as shown
inFig.9(upperleft).Interestingly,inthiscase,thereisnotable
variabilityincumulativeregretsacrossallmethodsasdepicted
in Fig. 9 (other subplots). Cumulative regret represents the
difference between the ideal cumulative reward, assuming
known hidden parameters, and the actual cumulative reward
obtainedfromfollowingaspecificpolicy.Assuch,itgenerally
remains non-negative. However, in this simulation study, dur-
ingthepreprocessingofthedataset,nonlineartransformations
were applied, such as significantly reducing the total number
of mineral labels used. Additionally, not all minerals were
necessarily present at each site, and the test accuracy was not
exceptionallyhigh.Therefore,evenwhenselectingsitesbased
on the best-fit optimal option selection strategy, there is no
guarantee that the obtained outcomes align with the outcome
observation a scientist is interested in. Consequently, in some
MC runs, alternative methods were found to yield lower
cumulative regrets5. This type of bimodality in cumulative
regrets can also be confirmed by observing the transitions of
5In this simulation experiment, agents are stuck in local minima or
continuedexploringsearchsitesthroughoutinstancesinapproximately35%
oftheMCruns(correspondingtotheturquoiselines).
sterger
evitalumuC
)retteb
=
rewol(
Cumulative regret (K=10, C=8, F=14, MC=100)
Fig. 9. Comparison of the cumulative regrets when the prior preference
is stationary (top left) and the cumulative regrets for each option selection
method(others).Inthesubplotsotherthanthetop-leftone,thereareturquoise
andsalmon-coloredlinesandshadedregions.Theserepresentthemeansand
1-σ boundsofthesetswherethecumulativeregretvalueatthefinalstepis
aboveandbelowtheoverallaverage,respectively.
Transitions of selected search sites
10 10
8 8
6 6
4 4
2 Best 2 Best
AIF Softmax
0 0
0 25 50 75 100 0 25 50 75 100
10 10
8 8
6 6
4 4
2 2
0 0
0 25 50 75 100 0 25 50 75 100
Time steps
)snoitpo(
setis
hcraeS
Fig. 10. Example transitions of selected search sites when the AIF (left
column)andsoftmax(rightcolumn)methodsareused.Thetransitionsshown
in the top row result in very small cumulative regrets, while those in the
bottomrowleadtoveryhighcumulativeregrets.
search sites selected by each method. As shown in the top
row of Fig. 10, in one MC run, it can be seen that the AIF
and softmax methods select the best search site (in this case,
k=8)morefrequentlythanwhenusingthebestpossibleoption
selection strategy. On the other hand, when stuck in local
minimaorcontinuingtoexplorethebestsearchsite,asshown
in the bottom row, the frequency with which these methods
select the best search site significantly decreases, resulting in
higher cumulative regrets.
F. Results: Dynamic Prior Preference
Fig. 11 (top left) illustrates the comparison of the cumu-
lative regrets when the prior preference distribution changes
dynamicallyasshowninFig.8.Inthisscenario,theproposed
AIF method demonstrates superior performance compared to
all conventional option selection methods such as softmax
and Thompson sampling. This superiority is stemmed from
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 9
50 50 -greedy 50 Softmax
40 40 40
30 30 30
20 20 20
10 10 10
0 0 0 0 50 100 150 0 50 100 150 0 50 100 150
50 UCB 50 AIF 50 TS
40 40 40
30 30 30
20 20 20
10 10 10
0 0 0
0 50 100 150 0 50 100 150 0 50 100 150
Time steps
sterger
evitalumuC
)retteb
=
rewol(
Cumulative regret (K=10, C=8, F=14, MC=100)
Fig.11. Comparisonofthecumulativeregretswhenthepriorpreferenceis
dynamically and periodically changed; the shaded regions represent the 1-σ
boundsofcumulativeregrets.
Transitions of selected search sites
10
8
6
4
2 Best
AIF
0 0 20 40 60 80 100 120 140
10
8
6
4
2 Best
TS
0
0 20 40 60 80 100 120 140
Time steps
)snoitpo(
setis
hcraeS
V. CONCLUSIONS
Inthisstudy,weappliedactiveinference(AIF)asanoption
selectionmethodforcontextualmulti-armedbandits(CMABs)
withtheobjectiveofvalidatingitsefficacyusingrealscientific
data. Previous studies primarily relied on synthetic data to
simulate true hidden parameters and contexts. In contrast, we
utilized actual hyperspectral data along with mineral labels
for these values. Additionally, we detailed the preprocessing
procedures and the methodology used to train the true hidden
parameters of search sites. Our research comprised two sets
ofMonteCarlosimulationexperiments.Thefirstsetprimarily
aimedtovalidatetheeffectivenessoftheproposedAIFmethod
under the assumption of stationary human prior preferences,
consistent with prior studies. As a result, AIF agents demon-
strated on par or superior performance compared to other
existing option selection methods. In the second set of exper-
iments, we introduced more realistic scenarios by assuming
dynamic changes in human prior preferences. Interestingly,
the proposed AIF method exhibited even greater performance
improvements in these dynamic settings. This enhancement is
attributedtotheuniquecharacteristicsofexpectedfreeenergy
(EFE), which underpin AIF’s ability to adapt and optimize
exploration-exploitation tradeoffs efficiently in response to
changing preferences.
ACKNOWLEDGMENTS
Work supported by the NASA COLDTech Program, grant
#80NSSC21K1031. S. Wakayama was also supported by the
Masason Foundation. Part of this research was carried out at
the Jet Propulsion Laboratory, California Institute of Technol-
ogy,underacontractwiththeNationalAeronauticsandSpace
Administration (80NM0018D0004).
Fig.12. ExampletransitionsofselectedsearchsiteswhentheAIF(top)and REFERENCES
TS(bottom)areused.Inthisscenario,humanpriorpreferencechangesevery
20decisioninstances(greendottedlines). [1] J.A.Grant,M.P.Golombek,S.A.Wilson,K.A.Farley,K.H.Williford,
andA.Chen,“Thescienceprocessforselectingthelandingsiteforthe
2020marsrover,”PlanetaryandSpaceScience,vol.164,pp.106–126,
2018.
[2] J.R.Johnson,“Practicingmars2020roveroperations,onearth,”2019,
EFE’s epistemic term efficiently assessing the uncertainties of https://www.planetary.org/articles/practicing-mars-2020-ops.
search sites, thereby identifying sites with a high likelihood [3] J. Foust, “Europa clipper passes key review,” https://spacenews.com/
europa-clipper-passes-key-review/.
of achieving desired outcomes at each time step, even as
[4] NASA, “Nasa’s mars 2020 project,” PDF, 2017, https://oig.nasa.gov/
scientists’desiredobservationaloutcomeschangedynamically. wp-content/uploads/2024/02/IG-17-009.pdf.
For instance, as shown in Fig. 12, during the initial 20 in- [5] B. K. Muirhead, A. Nicholas, and J. Umland, “Mars sample return
missionconceptstatus,”in2020IEEEAerospaceConference. IEEE,
stances, neither AIF nor TS agents identify the site to observe
2020,pp.1–8.
pyrophillite.However,bythetimewhenpyropyhillitebecomes [6] L. P. Kaelbling, M. L. Littman, and A. R. Cassandra, “Planning and
again a desired outcome (i.e. from 80 to 100 instances), the actinginpartiallyobservablestochasticdomains,”Artif.Intell.,vol.101,
no.1–2,p.99–134,may1998.
AIF agents are able to exploit the best site where pyrophylitte
[7] H. Kurniawati, “Partially observable markov decision processes and
is likely to be observed, influenced by the extrinsic term. In robotics,” Annual Review of Control, Robotics, and Autonomous
contrast, the TS agents still continue to explore sites other Systems,vol.5,no.1,pp.253–277,2022.
[8] A.Krause,A.Singh,andC.Guestrin,“Near-optimalsensorplacements
than the best site. Additionally, in this simulation experiment,
in gaussian processes: Theory, efficient algorithms and empirical stud-
unlike when the prior preference is stationary, the significant ies.”JournalofMachineLearningResearch,vol.9,no.2,2008.
variability in cumulative regrets is not observed. This is [9] A.Candela,K.Edelson,M.M.Gierach,D.R.Thompson,G.Woodward,
and D. Wettergreen, “Using remote sensing and in situ measurements
because the desired outcomes change regularly, so even if the
forefficientmappingandoptimalsamplingofcoralreefs,”Frontiersin
accuracy of the trained hidden softmax parameters utilized in MarineScience,vol.8,p.689489,2021.
the best option selection strategy is not very high, using this [10] C. E. Denniston, G. Salhotra, A. Kangaslahti, D. A. Caron, and G. S.
Sukhatme,“Learnedparameterselectionforroboticinformationgather-
allowsforobservingmoredesiredoutcomescomparedtoother
ing,”in2023IEEE/RSJInternationalConferenceonIntelligentRobots
strategies. andSystems(IROS),2023,pp.10519–10526.
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 10
[11] C.E.Rasmussen,“Gaussianprocessesinmachinelearning,”inSummer adultsusingimmersivevirtualreality,”ScientificReports,vol.11,no.1,
schoolonmachinelearning. Springer,2003,pp.63–71. p.20377,2021.
[12] A.West,I.Tsitsimpelis,M.Licata,A.Jazbec,L.Snoj,M.J.Joyce,and [36] T.Arthur,S.Vine,G.Buckingham,M.Brosnan,M.Wilson,andD.Har-
B. Lennox, “Use of gaussian process regression for radiation mapping ris,“Testingpredictivecodingtheoriesofautismspectrumdisorderusing
of a nuclear reactor with a mobile robot,” Scientific reports, vol. 11, models of active inference,” PLOS Computational Biology, vol. 19,
no.1,p.13975,2021. no.9,p.e1011473,2023.
[13] L. Li, W. Chu, J. Langford, and R. E. Schapire, “A contextual-bandit [37] L.Pio-Lopez,A.Nizard,K.Friston,andG.Pezzulo,“Activeinference
approach to personalized news article recommendation.” in WWW. androbotcontrol:acasestudy,”JournalofTheRoyalSocietyInterface,
ACM,2010,pp.661–670. vol.13,no.122,p.20160616,2016.
[14] L.Zhou,“Asurveyoncontextualmulti-armedbandits,”arXivpreprint [38] C.Pezzato,R.Ferrari,andC.H.Corbato,“Anoveladaptivecontroller
arXiv:1508.03326,2015. for robot manipulators based on active inference,” IEEE Robotics and
[15] D. Bouneffouf, I. Rish, and C. Aggarwal, “Survey on applications AutomationLetters,vol.5,no.2,pp.2973–2980,2020.
of multi-armed and contextual bandits,” in 2020 IEEE Congress on [39] M.Baioumy,P.Duckworth,B.Lacerda,andN.Hawes,“Activeinference
EvolutionaryComputation(CEC),2020,pp.1–8. for integrated state-estimation, control, and learning,” in 2021 IEEE
[16] S. Rudra, S. Goel, A. Santara, C. Gentile, L. Perron, F. Xia, V. Sind- International Conference on Robotics and Automation (ICRA), 2021,
hwani,C.Parada,andG.Aggarwal,“Acontextualbanditapproachfor pp.4665–4671.
learningtoplaninenvironmentswithprobabilisticgoalconfigurations,” [40] B. J. Julian, S. Karaman, and D. Rus, “On mutual information-
in 2023 IEEE International Conference on Robotics and Automation based control of range sensing robots for mapping applications,” The
(ICRA). IEEE,2023,pp.5645–5652. International Journal of Robotics Research, vol. 33, no. 10, pp. 1375–
[17] S. Wakayama and N. Ahmed, “Active inference for autonomous 1392,2014.
decision-making with contextual multi-armed bandits,” in 2023 IEEE [41] M. G. Jadidi, J. V. Miro, and G. Dissanayake, “Mutual information-
International Conference on Robotics and Automation (ICRA), 2023, based exploration on continuous occupancy maps,” in 2015 IEEE/RSJ
pp.7916–7922. International Conference on Intelligent Robots and Systems (IROS),
[18] ——, “Observation-augmented contextual multi-armed bandits for 2015,pp.6086–6092.
roboticsearchandexploration,”IEEERoboticsandAutomationLetters, [42] K.ChalonerandI.Verdinelli,“Bayesianexperimentaldesign:Areview,”
vol.9,no.10,pp.8531–8538,2024. Statisticalscience,pp.273–304,1995.
[19] H. H. Schmitt, “Apollo 17 report on the valley of taurus-littrow: A [43] X. Huan and Y. M. Marzouk, “Simulation-based optimal bayesian
geologicalinvestigationofthevalleyvisitedonthelastapollomission experimental design for nonlinear systems,” Journal of Computational
tothemoon,”Science,vol.182,111973. Physics,vol.232,no.1,pp.288–317,2013.
[20] R. Smith, K. J. Friston, and C. J. Whyte, “A step-by-step tutorial
[44] P. Amorese, S. Wakayama, N. Ahmed, and M. Lahijanian, “Online
on active inference and its application to empirical data,” Journal of
pareto-optimal decision-making for complex tasks using active infer-
mathematicalpsychology,vol.107,p.102632,2022.
ence,”2024.
[21] T. Parr, G. Pezzulo, and K. J. Friston,
[45] C.M.Bishop,PatternRecognitionandMachineLearning(Information
ActiveInference:TheFreeEnergyPrincipleinMind,Brain,andBehavior.
ScienceandStatistics). Berlin,Heidelberg:Springer-Verlag,2006.
The MIT Press, 03 2022. [Online]. Available:
[46] N. Ahmed, “Data-free/data-sparse softmax parameter estimation with
https://doi.org/10.7551/mitpress/12441.001.0001
structured class geometries,” IEEE Signal Processing Letters, vol. 25,
[22] P.Lanillos,C.Meo,C.Pezzato,A.A.Meera,M.Baioumy,W.Ohata,
pp.1–1,072018.
A. Tschantz, B. Millidge, M. Wisse, C. L. Buckley et al., “Active
[47] N.R.Ahmed,E.M.Sample,andM.Campbell,“Bayesianmulticategor-
inferenceinroboticsandartificialagents:Surveyandchallenges,”arXiv
icalsoftdatafusionforhuman–robotcollaboration,”IEEETransactions
preprintarXiv:2112.01871,2021.
onRobotics,vol.29,no.1,pp.189–206,2013.
[23] L.Hamlin,R.Green,P.Mouroulis,M.Eastwood,D.Wilson,M.Dudik,
[48] N.SweetandN.Ahmed,“Structuredsynthesisandcompressionofse-
and C. Paine, “Imaging spectrometer science measurements for ter-
mantichumansensormodelsforbayesianestimation,”in2016American
restrial ecology: Aviris and new developments,” in 2011 Aerospace
ControlConference(ACC),2016,pp.5479–5485.
conference. IEEE,2011,pp.1–7.
[49] R. Tse and M. Campbell, “Human–robot communications of proba-
[24] G. A. Swayze, R. N. Clark, A. F. Goetz, K. E. Livo, G. N. Breit,
bilistic beliefs via a dirichlet process mixture of statements,” IEEE
F. A. Kruse, S. J. Sutley, L. W. Snee, H. A. Lowers, J. L. Post et al.,
TransactionsonRobotics,vol.34,no.5,pp.1280–1298,2018.
“Mappingadvancedargillicalterationatcuprite,nevada,usingimaging
spectroscopy,”EconomicGeology,vol.109,no.5,pp.1179–1221,2014. [50] L. Burks, I. Loefgren, and N. R. Ahmed, “Optimal continuous state
[25] A. Mahajan and D. Teneketzis, “Multi-armed bandit problems,” in pomdp planning with semantic observations: A variational approach,”
Foundations and applications of sensor management. Springer, 2008, IEEETransactionsonRobotics,vol.35,no.6,pp.1488–1507,2019.
pp.121–151. [51] D. Markovic, H. Stojic, S. Schwobel, and S. Kiebel, J., “An empirical
[26] V. Kuleshov and D. Precup, “Algorithms for multi-armed bandit prob- evaluationofactiveinferenceinmulti-armedbandits,”NeuralNetworks;
lems,”JournalofMachineLearningResearch,vol.1,022014. 2021SpecialIssueonAIandBrainScience:AI-poweredBrainScience,
[27] P. Auer, N. Cesa-Bianchi, and P. Fischer, “Finite-time analysis of vol.144,p.229–246,may2021.
the multiarmed bandit problem,” Mach. Learn., vol. 47, no. 2–3, [52] K.Friston,F.Rigoli,D.Ognibene,C.Mathys,T.Fitzgerald,andG.Pez-
p. 235–256, may 2002. [Online]. Available: https://doi.org/10.1023/A: zulo, “Active inference and epistemic value,” Cognitive neuroscience,
1013689704352 vol.6,no.4,pp.187–214,2015.
[28] E. Kaufmann, “On bayesian index policies for sequential resource [53] S. Wakayama and N. Ahmed, “Probabilistic semantic data association
allocation,”TheAnnalsofStatistics,vol.46,no.2,pp.842–865,2018. forcollaborativehuman-robotsensing,”IEEETransactionsonRobotics,
[29] W. R. Thompson, “On the likelihood that one unknown probability vol.39,no.4,pp.3008–3023,2023.
exceeds another in view of the evidence of two samples,” Biometrika, [54] A.Galantai,“Thetheoryofnewton’smethod,”JournalofComputational
vol.25,pp.285–294,1933. andAppliedMathemathics,vol.124,pp.25–44,2000.
[30] S.AgrawalandN.Goyal,“Thompsonsamplingforcontextualbandits [55] F. F. Sabins, “Remote sensing for mineral exploration,” Ore geology
with linear payoffs,” in International conference on machine learning. reviews,vol.14,no.3-4,pp.157–183,1999.
PMLR,2013,pp.127–135. [56] A.Candela,D.Thompson,E.N.Dobrea,andD.Wettergreen,“Planetary
[31] K.Friston,J.Kilner,andL.Harrison,“Afreeenergyprincipleforthe roboticexplorationdrivenbysciencehypothesesforgeologicmapping,”
brain,”Journalofphysiology-Paris,vol.100,no.1-3,pp.70–87,2006. in 2017 IEEE/RSJ International Conference on Intelligent Robots and
[32] K.Friston,“Thefree-energyprinciple:aunifiedbraintheory?”Nature Systems(IROS),2017,pp.3811–3818.
reviewsneuroscience,vol.11,no.2,pp.127–138,2010. [57] A.Arora,P.M.Furlong,R.C.Fitch,S.Sukkarieh,andT.Fong,“Multi-
[33] K. Friston and S. Kiebel, “Predictive coding under the free-energy modalactiveperceptionforinformationgatheringinsciencemissions,”
principle,”PhilosophicaltransactionsoftheRoyalSocietyB:Biological AutonomousRobots,pp.1–27,2019.
sciences,vol.364,no.1521,pp.1211–1221,2009. [58] R. W. Zurek and S. E. Smrekar, “An overview of the mars reconnais-
[34] Y. Huang and R. P. Rao, “Predictive coding,” Wiley Interdisciplinary sanceorbiter(mro)sciencemission,”JournalofGeophysicalResearch:
Reviews:CognitiveScience,vol.2,no.5,pp.580–593,2011. Planets,vol.112,no.E5,2007.
[35] T. Arthur, D. Harris, G. Buckingham, M. Brosnan, M. Wilson, [59] D.P.KingmaandJ.Ba,“Adam:Amethodforstochasticoptimization,”
G.Williams,andS.Vine,“Anexaminationofactiveinferenceinautistic arXivpreprintarXiv:1412.6980,2014.
IEEETRANS.ROBOTICS,VOL.V,NO.N,NOVEMBER2024 11
[60] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga et al., “Pytorch: An
imperativestyle,high-performancedeeplearninglibrary,”Advancesin
neuralinformationprocessingsystems,vol.32,2019.
ShoheiWakayamareceivedtheB.Eng.inMechan-
ical Engineering from Kyushu University in 2018,
and the Ph.D. in Aerospace Engineering with the
Ann and H.J. Smead Aerospace Engineering Sci-
ences Department, University of Colorado Boulder
in2024.HisresearchinterestslieinBayesianstate
estimation and sequential decision making under
uncertainty,andhuman-robotinteractionforrobotic
explorationofunknownremoteenvironments.
AlbertoCandelaisaDataScientistintheArtificial
IntelligenceGroupattheJetPropulsionLaboratory,
California Institute of Technology. He received his
B.S. in Mechatronics Engineering from Instituto
Tecnolo´gico Auto´nomo de Me´xico, and his M.S.
andPh.D.inRoboticsfromCarnegieMellonUniver-
sity.Hisresearchinterestsincludeautonomoussci-
ence, information-theoretic planning, machine and
deep learning, probabilistic and statistical methods,
robotics,andremotesensing.
PaulHayneisanAssociateProfessorintheDepart-
ment of Astrophysical and Planetary Sciences, and
the Laboratory for Atmospheric and Space Physics
(LASP) at the University of Colorado Boulder. He
earnedhisB.S.andM.S.inGeophysicsfromStan-
ford University, and his Ph.D. in Geophysics and
SpacePhysicsfromUCLA.AtLASP,hedirectsthe
Exploration of Planetary Ices and Climates (EPIC)
group, which researches interactions between the
surfacesandatmospheresoficyplanetsandmoons
throughout the solar system using data from deep
spacemissions.
Nisar Ahmed is an Associate Professor and H.J.
Smead Faculty Fellow in the Smead Aerospace
Engineering Sciences Department at the University
of Colorado Boulder. He earned his B.S. in En-
gineering from Cooper Union in New York City
in 2006, and his Ph.D. in Mechanical Engineering
fromCornellUniversityinIthaca,NYin2012.He
directs the Cooperative Human-Robot Intelligence
(COHRINT) Lab, which researches probabilistic
modeling, estimation and control of autonomous
systems, human-robot/machine interaction, sensor
fusion,anddecision-makingunderuncertainty.

=== INSTRUCTIONS ===

0. PROFESSIONAL TONE REQUIREMENTS:
   - Begin directly with the paper title or content - NO conversational openings
   - Do NOT use phrases like: 'Okay, here's...', 'Here's a summary...',
     'Let me summarize...', 'I'll extract...', or similar conversational language
   - Start immediately with substantive content in formal academic tone
   - Example BAD: 'Okay, here's a summary of the paper...'
   - Example GOOD: 'This paper investigates [topic]...'

1. Start with exact title: "Active Inference in Contextual Multi-Armed Bandits for Autonomous Robotic Exploration"

2. EXTRACT QUOTES:
   - Extract 10-15 direct quotes from the paper that support key claims
   - QUOTE EXTRACTION AND FORMATTING:
     * Extract quotes VERBATIM from the paper text - do NOT modify or "correct" them
     * Extract quotes exactly as they appear in the source text
     * Preserve all aspects of the quote exactly as written, including spacing
     * Use proper quotation marks: "quote text" (double quotes)
     * CRITICAL: Only extract quotes that actually appear in the paper text
     * Do NOT generate, invent, or "fix" quotes - extract them exactly as written
   - QUOTE FORMATTING STANDARD:
     * Attribution format: 'The authors state: "quote text"' OR 'According to the paper: "quote text"'
     * Vary attribution phrases to avoid repetition (use: 'The authors state', 'They note',
       'The paper argues', 'According to the research', 'The study demonstrates')
     * Include section context when available: 'In the Introduction, the authors state: "quote text"'
     * Ensure proper spacing around quotes and punctuation
   - Search the full paper text to find relevant quotes
   - Each quote must be verbatim from the paper text (with spacing normalized)

3. IDENTIFY CLAIMS:
   - Identify the main claims and arguments made by the authors
   - State each claim clearly and support it with quotes from the paper
   - Distinguish between primary claims and supporting arguments

4. SUMMARIZE KEY FINDINGS:
   - Summarize the key findings with specific numbers, metrics, and results
   - Include quantitative data: percentages, statistics, measurements
   - Extract numerical results from the results section
   - Present findings with supporting evidence from the paper

5. DESCRIBE METHODS:
   - Describe the methodology, experimental setup, and approach used
   - Include details about: algorithms, procedures, experimental design
   - Explain how the research was conducted
   - Extract specific methodological details from the methods section

6. PRESENT RESULTS:
   - Present the results with quantitative data and statistical significance
   - Include specific numbers, tables, figures mentioned in the paper
   - Extract results from the results section with exact values
   - Support results with quotes or data from the paper

7. NO REPETITION - CRITICAL REQUIREMENT (ENHANCED):
   - CRITICAL: Before writing EACH sentence, check: 'Have I already said this exact idea?'
   - If you've already stated an idea, DO NOT repeat it - move to the next unique point
   - Each sentence must be COMPLETELY UNIQUE - no duplicate ideas, even with different words
   - Each claim appears EXACTLY ONCE - if you've stated it, move to the next unique point
   - Each paragraph must be COMPLETELY UNIQUE - no duplicate paragraphs
   - Do NOT repeat the same sentence, even with slight variations or word changes
   - Do NOT repeat paragraphs or sections - each section must have unique content
   - Each claim should appear only ONCE in the entire summary
   - Vary attribution phrases: use 'The authors state', 'They note', 'The paper argues',
     'According to the research', 'The study demonstrates' - do NOT repeat the same phrase
   - If you find yourself writing similar content, STOP immediately and write something completely different
   - Before each sentence, ask: 'Have I already said this?' If yes, write something new
   - Vary your language: use synonyms, different sentence structures, different perspectives
   - REPETITION CHECKLIST: After writing each sentence, verify it's not a duplicate of any previous sentence

   EXAMPLES OF WHAT NOT TO DO:
   ❌ BAD: 'The authors state: "X". The authors state: "Y". The authors state: "Z".'
   ✅ GOOD: 'The authors state: "X". They further note: "Y". The paper argues: "Z".'

   ❌ BAD: Repeating the same claim 3+ times with slight variations
   ✅ GOOD: State each claim once, then move to the next unique point

8. STRUCTURE:
   - Use markdown headers: ### Overview, ### Methodology, ### Results, ### Discussion
   - Target length: 1000-1500 words
   - Ensure all requested elements (quotes, claims, findings, methods, results) are included
