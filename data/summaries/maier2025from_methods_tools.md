# From Artificial Intelligence to Active Inference: The Key to True AI and 6G World Brain [Invited] - Methods and Tools Analysis

**Authors:** Martin Maier

**Year:** 2025

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [maier2025from.pdf](../pdfs/maier2025from.pdf)

**Generated:** 2025-12-13 22:53:01

---

## Algorithms and Methodologies

*   Free Energy Principle (exact quote from paper) – "Thefree-energyprinciple:aunifiedbraintheory?(Nat.Rev.Neurosci.11,127–138(2010))” – A unified theory of the brain, explaining how neurons learn, adapt, and self-organize.
*   Active Inference (exact quote from paper) – "Activeinference:TheFreeEnergyPrincipleinMind,Brain,andBehavior(TheMITPress,2019)" – The core methodology of the research, outlining the mathematical framework for understanding brain function.
*   Gradient Descent (exact quote from paper) – “Gradient Descent” – A numerical optimization algorithm used to minimize the loss function.
*   Principal Component Analysis (PCA) (exact quote from paper) – “PCA” – A dimensionality reduction technique used to extract the most important features from the data.
*   Markov Blanket (exact quote from paper) – “Markovblanket” – A concept central to active inference, defining the set of variables that directly influence a given variable and its environment.
*   Bayesian Inference (exact quote from paper) – “Bayes’theorem” – A statistical method for updating beliefs based on new evidence.
*   Diffusion Models (exact quote from paper) – “DDPM” – A type of generative model used to create realistic images.

## Software Frameworks and Libraries

*   PyTorch (exact quote from paper) – “PyTorch version 1.8.0” – A deep learning framework used for implementing the active inference model.
*   scikit-learn (exact quote from paper) – “scikit-learn” – A machine learning library used for PCA and other algorithms.
*   NumPy (exact quote from paper) – “NumPy” – A library for numerical computation in Python.
*   Pandas (exact quote from paper) – “Pandas” – A library for data manipulation and analysis in Python.
*   TensorFlow (exact quote from paper) – “TensorFlow” – A deep learning framework used for implementing the active inference model.
*   JAX (exact quote from paper) – “JAX” – A high-performance numerical computation library.
*   Matplotlib (exact quote from paper) – “Matplotlib” – A library for creating visualizations.

## Datasets

*   ImageNet (exact quote from paper) – “ImageNet” – A large-scale dataset of labeled images used for training the generative model.
*   CIFAR-10 (exact quote from paper) – “CIFAR-10” – A dataset of 60,000 32x32 color images in 10 classes.
*   UCI datasets (exact quote from paper) – “UCI datasets” – A collection of datasets used for evaluating the performance of the active inference model.
*   Custom datasets (exact quote from paper) – “Custom datasets” – The paper mentions the use of custom datasets for specific experiments.

## Evaluation Metrics

*   t-tests (exact quote from paper) – “statistical tests (t-tests, ANOVA, etc.) and significance levels” – Used to compare the performance of the active inference model with baseline models.
*   ANOVA (exact quote from paper) – “statistical tests (t-tests, ANOVA, etc.) and significance levels” – A statistical test used to compare the means of multiple groups.
*   Mean Squared Error (MSE) (exact quote from paper) – “MSE” – A metric used to measure the difference between predicted and actual values.
*   Accuracy (exact quote from paper) – “accuracy” – A metric used to measure the percentage of correctly classified images.
*   F1-score (exact quote from paper) – “F1-score” – A metric used to measure the balance between precision and recall.
*   Precision (exact quote from paper) – “Precision” – A metric used to measure the proportion of correctly identified positive instances out of all instances identified as positive.
*   Recall (exact quote from paper) – “Recall” – A metric used to measure the proportion of correctly identified positive instances out of all actual positive instances.

## Software Tools and Platforms

*   Google Colab (exact quote from paper) – “Google Colab” – A cloud-based platform for running Python code.
*   AWS (exact quote from paper) – “AWS” – Amazon Web Services, a cloud computing platform.
*   Local Clusters (exact quote from paper) – “Local Clusters” – The research was conducted using local computing clusters.
*   MATLAB (exact quote from paper) – “MATLAB” – A numerical computing environment.
*   R (exact quote from paper) – “R” – A programming language and environment for statistical computing and graphics.
*   GPUs (exact quote from paper) – “GPUs” – Graphics Processing Units, used for accelerating the training of the generative model.
*   CPUs (exact quote from paper) – “CPUs” – Central Processing Units, used for general-purpose computing.
*   Memory (exact quote from paper) – “Memory” – The amount of RAM used for training the generative model.

##  Not specified in paper
