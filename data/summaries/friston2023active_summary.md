# Active Inference and Intentional Behaviour

**Authors:** Karl J. Friston, Tommaso Salvatori, Takuya Isomura, Alexander Tschantz, Alex Kiefer, Tim Verbelen, Magnus Koudahl, Aswin Paul, Thomas Parr, Adeel Razi, Brett Kagan, Christopher L. Buckley, Maxwell J. D. Ramstead

**Year:** 2023

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [friston2023active.pdf](../pdfs/friston2023active.pdf)

**Generated:** 2025-12-14 09:38:37

**Validation Status:** âœ“ Accepted
**Quality Score:** 0.80

---

### OverviewThis paper investigates the emergence of self-organization and sentient behaviour through the lens of the free energy principle. It argues that neuronal cultures spontaneously learn structured behaviours in the absence of reward or reinforcement, and that this can be described as self-evidencing. The authors present a formal account of intentional behaviour, specifying agents as driven by a preferred endpoint or goal in latent state-spaces. They investigate these forms of (reactive, sentient, and intentional) behaviour using simulations, demonstrating how inductive planning can be used to solve complex problems.### MethodologyThe authors simulate the in vitro experiments reported in [1], using a generative model that implements nested, free energy minimising processes. The model is equipped with five paths, which are controllable, and is used to deconstruct the ensuing behaviour, distinguishing between merely reactive, sentient, and intentional behaviour. The simulations are then used to investigate the impact of inductive planning, and to demonstrate how it can be used to solve problems such as the Tower of Hanoi. The model is defined by a generative model that maps from latent states to outcomes, and is implemented using a Markov decision process. The model is characterised by a tensor that encodes the probability of transitioning between latent states. The model is also characterised by a likelihood mapping, which is used to learn the structure of the environment. The model is implemented using a variational free energy minimisation scheme, which is used to update the parameters of the model. The model is also characterised by a set of constraints, which are used to guide the agent's actions.### ResultsThe simulations demonstrate that the agent can learn to play Pong, and that this behaviour can be described as sentient. The simulations also show that the agent can solve the Tower of Hanoi problem, and that this behaviour can be described as intentional. The simulations show that the agent learns a likelihood mapping, which is used to guide its actions. 

The simulations show that the agent can solve the 

Tower
