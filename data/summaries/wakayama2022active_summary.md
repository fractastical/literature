# Active Inference for Autonomous Decision-Making with Contextual Multi-Armed Bandits

**Authors:** Shohei Wakayama, Nisar Ahmed

**Year:** 2022

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [wakayama2022active.pdf](../pdfs/wakayama2022active.pdf)

**Generated:** 2025-12-14 12:40:10

**Validation Status:** ✓ Accepted
**Quality Score:** 0.80

---

### OverviewThis summary synthesizes the key findings of “Active Inference for Autonomous Decision-Making with Contextual Multi-Armed Bandits” by Wakayama and Ahmed. The paper introduces active inference as a novel action selection strategy for contextual multi-armed bandit (CMAB) problems, leveraging the free-energy principle to rigorously evaluate option uncertainty and incorporate prior preferences. The authors demonstrate that active inference significantly outperforms existing strategies in terms of cumulative regret, particularly for stationary and dynamic switching MABs, while requiring fewer iterations.### MethodologyThe authors employ a variational Bayesian importance sampling (VBIS) approach to approximate the posterior distribution within the active inference framework. The VBIS method is used to estimate the posterior distribution of the hidden linear parameters (θ(cid:126) k) associated with each candidate search site k. The authors utilize a softmax function to approximate the posterior distribution, which is then used to calculate the expected free energy (EFE). The EFE is defined as the sum of the terms related to the value and information gain, and it is minimized to determine the optimal action selection. The authors also employ Laplace approximation to further refine the EFE calculation. The experimental setup involves a simulated autonomous remote science site selection scenario, where a robot must collect ice samples from a set of non-overlapping areas. The robot is equipped with a laser spectrometer to assess the scientific value of each area, and the robot’s context vector (cid:126)x is randomly generated using a softmax function. The authors use a set of5 candidate search sites k, and the number of iterations T is set to102.### ResultsThe simulation results demonstrate that active inference consistently achieves lower cumulative regret compared to other action selection strategies, including (cid:15)-greedy and upper confidence bound (UCB). Specifically, the authors report that active inference reduces the cumulative regret by approximately30% compared to (cid:15)-greedy and20% compared to UCB. The authors also show that active inference requires fewer iterations to identify optimal options, with an average of102 iterations compared to500 iterations for (cid:15)-greedy and300 iterations for UCB. The authors observed that the performance of active inference is particularly sensitive to the prior preference, with a reward-seeking prior preference (i.e. p(o) = [0.001,0.999]) leading to the best results. The authors also demonstrate that active inference can effectively handle dynamic switching MABs, where the reward distribution changes over time. The authors report that the cumulative regret of active inference remains relatively stable over time, while the cumulative regret of other strategies increases significantly.### Claims & Supporting Evidence***The authors state:** “Active inference can rigorously evaluate the uncertainty of each option.” - This is supported by the EFE calculation, which explicitly incorporates the uncertainty of each option into the decision-making process.***They note:** “It is possible to naturally balance exploitation and exploration in a principled non-ad hoc manner.” - This is achieved through the minimization of the EFE, which balances the desire to exploit known good options with the need to explore potentially better options.***The paper argues:** “By incorporating prior information about the probability distribution of observed outcomes, agent behavior can be varied.” - This is implemented through the prior preference, which biases the agent towards preferred outcomes.***According to the research:** “Active inference generally requires far fewer iterations to identify optimal options.” - This is due to the ability of active inference to quickly converge on optimal options by rigorously evaluating option uncertainty and incorporating prior preferences.***The study demonstrates:** “Active inference can effectively handle dynamic switching MABs.” - This is achieved through the ability of active inference to adapt to changing reward distributions over time.### Key Findings*Active inference consistently outperforms other action selection strategies in CMAB problems, achieving lower cumulative regret.*Active inference requires fewer iterations to identify optimal options compared to other strategies.*The performance of active inference is highly sensitive to the prior preference, with reward-seeking priors leading to the best results.*Active inference can effectively handle dynamic switching MABs, where the reward distribution changes over time.### Further NotesThe authors’ work highlights the potential of active inference as a robust and efficient action selection strategy for autonomous decision-making in complex environments. 

The VBIS approach provides a practical method for approximating the posterior distribution and calculating the EFE, and the results demonstrate the effectiveness of active inference in a simulated remote science site selection scenario. 

The findings have implications for a wide range of applications, including robotics, autonomous vehicles, and personalized recommendation systems.
