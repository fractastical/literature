# Cognitive Effort in the Two-Step Task: An Active Inference Drift-Diffusion Model Approach

**Authors:** Alvaro Garrido Perez, Viktor Lemoine, Amrapali Pednekar, Yara Khaluf, Pieter Simoens

**Year:** 2025

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [perez2025cognitive.pdf](../pdfs/perez2025cognitive.pdf)

**Generated:** 2025-12-13 22:25:57

**Validation Status:** ✓ Accepted
**Quality Score:** 0.80

---

=== IMPORTANT: ISOLATE THIS PAPER ===You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.Do NOT mix information from different papers. Only use information from THIS specific paper.Paper Title: Cognitive Effort in the Two-Step Task: An Active Inference Drift-Diffusion Model ApproachCitation Key: perez2025cognitiveAuthors: Alvaro Garrido Perez, Viktor Lemoine, Amrapali PednekarREMEMBER: Extract quotes, claims, and findings ONLY from the paper text.Year:2025Key Terms: task, approach, effort, university, drift, information, cognitive, step, inference, active=== FULL PAPER TEXT ===Cognitive Effort in the Two-Step Task: An ActiveInference Drift-Diffusion Model ApproachÁlvaro Garrido-Pérez1[0009−0003−5481−8166], Viktor Lemoine1, AmrapaliPednekar1[0009−0005−6194−3955], Yara Khaluf2[0000−0002−5590−9321], and PieterSimoens1[0000−0002−9569−9373]1 IDLab, Department of Information Technology, Ghent University - imec, Belgiumalvaro.garridoperez@ugent.be2 Wageningen University & Research, Wageningen, The NetherlandsAbstract. High-leveltheoriesrootedintheBayesianBrainHypothesisoften frame cognitive effort as the cost of resolving the conflict betweenhabits and optimal policies. In parallel, evidence accumulator models(EAMs)provideamechanisticaccountofhoweffortarisesfromcompeti-tionbetweenthesubjectivevaluesofavailableoptions.AlthoughEAMs have beencombined with frameworks like Reinforcement Learning to bridge the gap betweenhigh-leveltheoriesandprocess-levelmechanisms,relatively less attention hasbeen paid to their implications for a unified notion of cognitive effort.Here,wecombineActiveInference(AIF)withtheDrift-Diffusion Model (DDM) to investigatewhether the resulting AIF-DDM can simultaneously capture the effort arisingfrom bothhabit violation and value discriminability. To our knowledge, this is thefirst time AIF has been combined with an EAM. We tested the AIF-DDMon a behavioral dataset from the two-step task and compared its predictions toan information-theoretic definition of cognitive effort based on AIF.Themodel’spredictionssuccessfullyaccountedforsecond-stage reaction times but failed tocapture the dynamics of the first stage. We argue the latter discrepancy likelystems from the experimental design rather than a fundamental flaw in the model’sassumptionsaboutcognitiveeffort.Accordingly,wepropose severalmodificationsofthetwo-step task to better measure and isolate cognitive effort.Finally,wefoundthatintegratingtheDDM significantly improved parameter recovery, whichcould help future studies to obtain more reliable parameter estimates.Keywords: Active inference · Drift-diffusion model · Cognitive effort1 IntroductionBuilding upon the Bayesian Brain Hypothesis (BBH), numerous studies in thepast decade have tried to formalize cognitive effort using information-theoreticprinciples[25].AccordingtotheBBH,humansmaintainaninternalworldmodelencoded in prior beliefs, which they continuously update as they interact withthe environment. Within this context, cognitive effort arises from the conflict5202peS21]CN.oib-q[2v53440.8052:viXra2 A. Garrido-Pérez et al.between a pre-existing belief about how to act (a habit) and an updated beliefabout the optimal policy [10].In a decision-making task, cognitive effort may also arise from the competi-tion between the subjective values of the available choices. When these valuesare closer together—that is, when value discriminability is low—reaction times(RTs)tendtoincrease(e.g.,[7,3]).AlthoughRTsarenotadirectmeasureofcog-nitiveeffort,theyareoftenusedasaproy(e.g.,[24]),basedontheassumptionthat slower responses reflect more information processing.From an information-theoretic perspective, the effect of value discriminabil-ity on RTs can be understood as the additional cognitive effort required to re-solve increased choice uncertainty [13,8,6]. Yet, information theory provides noexplicit account of the underlying deliberation process, which complicates thetask of linking its predictions to specific neural signatures. In contrast, evidenceaccumulatormodels(EAMs)offeramechanisticexplanationforhowvaluecom-petition shapes decision speed, which may be empirically tested (e.g., [18]).A major limitation of using EAMs to study cognitive effort is that they areagnostic to how beliefs are formed. This limitation is often addressed by com-bining EAMs with Reinforcement Learning (RL) [11]. However, in recent years,Active Inference (AIF) has emerged as a powerful alternative to RL, offering afirst-principles perspective on perception, learning, and decision-making [5].Here, we investigate whether integrating a Drift Diffusion Model (DDM),a prominent class of EAM, with AIF can simultaneously capture the influenceof both value discriminability and habit violation on cognitive effort. To ourknowledge, this is the first attempt to combine AIF with an EAM to modelhumanbehaviour.WeevaluatetheintegratedAIF-DDMusingthetwo-steptask,a version of the multi-armed bandit in which participants must plan two stepsahead [2]. Furthermore, we compare its predictions with a recently proposeddefinition of cognitive effort in AIF [10].Our work builds directly on a recent study that developed an AIF model ofthe two-step task [4]. The study demonstrated that AIF outperformed a HybridReinforcement Learning (HRL) model (which combines model-free and model-based strategies [16]) in two out of four datasets, while achieving comparableperformance in the remaining two. Moreover, the authors provided compellingevidence for directed exploration—a key differentiator between AIF and HRL.Despite these achievements, the study could not determine which specific AIFlearningmechanismsparticipantswereusing.Givenpriorevidencethatintegrat-ingaDDMintoanHRLmodelimprovedthereliabilityofmodel-basedestimates[16], we tested whether the combined AIF–DDM could resolve this ambiguity.2 Methods2.1 Participants and behavioural taskIn this section, we will briefly describe the two-step task and the behaviouraldataset that we used to fit the computational models. For more details on theexperimental procedure, we encourage reading the paper that made the datasetpublicly available [17].As the name suggests, each trial of the two-step task consists of two stages(Fig.1). In the first stage, participants choose between two actions. Each actionleadstooneofthetwosecond-stage states through a probabilistic transition thatis either common (p =0.7) or rare (p =0.3). Importantly, the two first-stageactions have opposite most-likely transitions. These transition probabilities re-main constant throughout the task. After transitioning to a second-stage state,participants make a final choice between two actions. Each of these second-stage actions results in a monetary reward with a probability that fluctuatesover time, following Gaussian random walks.Fig.1: Abstract representation of the two-step task. At the first stage (top), achoice leads to one of two second-stage states (bottom). Transitions are eithercommon (p=0.7, thick arrows) or rare (p=0.3). The two initial actions haveopposing common transitions. A second-stage choice may result in a monetaryreward with a probability that fluctuates over time.We analysed data from the "Magic Carpet" dataset, which was made avail-ableby[17]andoriginallycomprised24participants.Inthisexperiment,partici-pantshada2-seconddeadlinetorespondateachstage.Everytimethisdeadlinewas surpassed, the trial was labelled as a missed trial and the participant movedon to the next stage or trial. Before conducting any analysis, we identified andremoved the trials. We also considered invalid trials with at least one RT smallerthan100ms (to exclude anticipatory responses that are too fast to reflect genuinedeliberation [9]). Finally, any participant with more than10% invalid trials wasremoved from the dataset. One participant was excluded under this criterion, with44.1% of their trials being either missed or too fast. Therefore, the originalsample size was reduced to n=23. In total,6.53% of the data was excluded fromthe analysis (including all the data from the removed participant).4 A.
