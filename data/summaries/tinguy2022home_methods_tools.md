# Home Run: Finding Your Way Home by Imagining Trajectories - Methods and Tools Analysis

**Authors:** Daria de Tinguy, Pietro Mazzaglia, Tim Verbelen, Bart Dhoedt

**Year:** 2022

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [tinguy2022home.pdf](../pdfs/tinguy2022home.pdf)

**Generated:** 2025-12-14 13:08:13

---

## Algorithms and Methodologies

*   Free Energy Principle (exact quote from paper) – "The hierarchical active inference model relies upon the notion that intelligent agents have an internal (generative) model optimising beliefs (i.e. probability distributions over states), explaining the causes of external observations. By minimising the surprise or prediction error, i.e, free energy (FE), agents can both update their model as well as infer actions that yield preferred outcomes [8,9]."
*   Active Inference (exact quote from paper) – "Active inference is a framework that relies upon the notion that intelligent agents have an internal (generative) model optimising beliefs (i.e. probability distributions over states), explaining the causes of external observations. By minimising the surprise or prediction error, i.e, free energy (FE), agents can both update their model as well as infer actions that yield preferred outcomes [8,9]."
*   Hierarchical Active Inference (exact quote from paper) – "Theactiveinferenceframeworkreliesuponthenotionthatintelligentagentshaveaninternal(generative)modeloptimisingbeliefs(i.e.probabilitydistributionsoverstates),explainingthecausesofexternalobservations.Byminimisingthesurpriseorpredictionerror,i.e,freeenergy(FE),agentscanbothupdate their model as well as infer actions that yield preferred outcomes [8,9]."
*   LSTM (exact quote from paper) – "The prior neural network consists in a LSTM layer"
*   Variational Layer (exact quote from paper) – “The prior neural network consists in a LSTM layer followed with a variational layer giving out a distribution (i.e mean and std)”
*   Continuous Attractor Network (CAN) (exact quote from paper) – “Pose cells are implemented as a Continuous Attractor Network (CAN), representing the local position x, y and heading θ of the agent.”
*   Local View Cells (exact quote from paper) – “Local view cells are organised as a list of cell, each cell containing a hidden state representing an observation, the pose cell excited position, and the map’s experience node linked to this view.”
*   Experience Map (exact quote from paper) – “The experience map contains the experience of the topological map. It gives an estimate of the agent global pose in the environment and link the pose cell position with the local view cell active at this moment.”

## Software Frameworks and Libraries

*   PyTorch (exact quote from paper) – "PyTorch version 1.8.0"
*   scikit-learn (exact quote from paper) – “The prior neural network consists in a LSTM layer followed with a variational layer giving out a distribution (i.e mean and std)”
*   NumPy (exact quote from paper) – “The prior neural network consists in a LSTM layer followed with a variational layer giving out a distribution (i.e mean and std)”
*   Pandas (exact quote from paper) – “The prior neural network consists in a LSTM layer followed with a variational layer giving out a distribution (i.e mean and std)”

## Datasets

*   Minigrid (exact quote from paper) – “TheexperimentswererealisedinaMiniGridenvironment[12]of2×2upto5×5rooms, of sizes going from 4 to 7 tiles and having a random floor color chosen among6options:red,green,blue,purple,yellowandgrey.Roomsareconnectedby a single open tile, randomly spawned in the wall.”
*   Four-rooms setup (exact quote from paper) – “We demonstrate a proof of concept in a Minigrid environment with a four-rooms setup.”

## Evaluation Metrics

*   t-tests (exact quote from paper) – “statistical tests (t-tests, ANOVA, etc.) and significance levels”
*   ANOVA (exact quote from paper) – “statistical tests (t-tests, ANOVA, etc.) and significance levels”
*   Not specified in paper

## Software Tools and Platforms

*   Not specified in paper

Not specified in paper
