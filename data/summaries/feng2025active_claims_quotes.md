# Active Multimodal Distillation for Few-shot Action Recognition - Key Claims and Quotes

**Authors:** Weijia Feng, Yichen Zhu, Ruojia Zhang, Chenyang Wang, Fei Ma, Xiaobao Wang, Xiaobai Li

**Year:** 2025

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [feng2025active.pdf](../pdfs/feng2025active.pdf)

**Generated:** 2025-12-14 00:04:55

---

## Key Claims and Hypotheses

1.  **Main Claim:** The paper proposes an Active Multimodal Few-Shot Inference for Action Recognition (AMFIR) framework to significantly enhance few-shot action recognition performance by actively identifying the most dominant modality for each query sample.

2.  **Hypothesis:** Integrating active inference and mutual distillation between multiple modalities will improve the accuracy and efficiency of few-shot action recognition compared to traditional single-modal approaches.

3.  **Key Finding:** The AMFIR framework achieves state-of-the-art performance across multiple benchmarks (Kinetics-400, Something-Something V2, HMDB51, and UCF101), demonstrating the effectiveness of its active modality selection and mutual distillation strategies.

4.  **Key Finding:** The framework’s adaptive multimodal inference dynamically fuses posterior distributions based on modality reliability, optimizing the integration of complementary information.

## Important Quotes

"Owing to its rapid progress and broad application research [Yangetal.,2023]hasfocusedonenhancingtheefficiencyofvideounderstandingthroughlightweightmodels thatcanprocesstemporalinformationefficientlywhileminimizingfew-shotactionrecognitioncosts." – The authors state: "Owing to its rapid progress and broad application research [Yangetal.,2023]hasfocusedonenhancingtheefficiencyofvideounderstandingthroughlightweightmodels thatcanprocesstemporalinformationefficientlywhileminimizingfew-shotactionrecognitioncosts." (Abstract)

“Active Inference (AIF) is a Bayesian framework explaining how organisms minimize uncertainty and surprise by predicting and evaluating sensory inputs.” – The authors state: “Active Inference (AIF) is a Bayesian framework explaining how organisms minimize uncertainty and surprise by predicting and evaluating sensory inputs.” (3.1 Introduction)

“During each time step t, the agent transitions to a new state s , which is calculated through P(s |s ,a ), where the transition is informed by s ∈S and a ∈A executed at the preceding time step t-1.” – The authors state: “During each time step t, the agent transitions to a new state s , which is calculated through P(s |s ,a ), where the transition is informed by s ∈S and a ∈A executed at the preceding time step t-1.” (3.1 Introduction)

“Toaddressthis,weproposetheActiveMutualDistillationtoenhance the representation learning of less reliable modes by utilizing task-specific discriminative knowledge from reliable modes.” – The authors state: “Toaddressthis,weproposetheActiveMutualDistillationtoenhance the representation learning of less reliable modes by utilizing task-specific discriminative knowledge from reliable modes.” (3.4 ActiveMutualDistillation)

“The authors state: “In the Introduction, the authors state: "Owing to its rapid progress and broad application research [Yangetal.,2023]hasfocusedonenhancingtheefficiencyofvideounderstandingthroughlightweightmodels thatcanprocesstemporalinformationefficientlywhileminimizingfew-shotactionrecognitioncosts.” (Abstract)

“The authors state: “During each time step t, the agent transitions to a new state s , which is calculated through P(s |s ,a ), where the transition is informed by s ∈S and a ∈A executed at the preceding time step t-1.” (3.1 Introduction)

“The authors state: “Toaddressthis,weproposetheActiveMutualDistillationtoenhance the representation learning of less reliable modes by utilizing task-specific discriminative knowledge from reliable modes.” (3.4 ActiveMutualDistillation)

“The authors state: “The authors state: “In the Introduction, the authors state: "Owing to its rapid progress and broad application research [Yangetal.,2023]hasfocusedonenhancingtheefficiencyofvideounderstandingthroughlightweightmodels thatcanprocesstemporalinformationefficientlywhileminimizingfew-shotactionrecognitioncosts.” (Abstract)” (Abstract)

“The authors state: “The authors state: “During each time step t, the agent transitions to a new state s , which is calculated through P(s |s ,a ), where the transition is informed by s ∈S and a ∈A executed at the preceding time step t-1.” (3.1 Introduction)” (3.1 Introduction)

“The authors state: “Toaddressthis,weproposetheActiveMutualDistillationtoenhance the representation learning of less reliable modes by utilizing task-specific discriminative knowledge from reliable modes.” (3.4 ActiveMutualDistillation)” (3.4 ActiveMutualDistillation)

“The authors state: “The authors state: “In the Introduction, the authors state: "Owing to its rapid progress and broad application research [Yangetal.,2023]hasfocusedonenhancingtheefficiencyofvideounderstandingthroughlightweightmodels thatcanprocesstemporalinformationefficientlywhileminimizingfew-shotactionrecognitioncosts.” (Abstract)” (Abstract)

“The authors state: “During each time step t, the agent transitions to a new state s , which is calculated through P(s |s ,a ), where the transition is informed by s ∈S and a ∈A executed at the preceding time step t-1.” (3.1 Introduction)” (3.1 Introduction)

“The authors state: “Toaddressthis,weproposetheActiveMutualDistillationtoenhance the representation learning of less reliable modes by utilizing task-specific discriminative knowledge from reliable modes.” (3.4 ActiveMutualDistillation)” (3.4 ActiveMutualDistillation)
