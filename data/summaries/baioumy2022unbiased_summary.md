# Unbiased Active Inference for Classical Control

**Authors:** Mohamed Baioumy, Corrado Pezzato, Riccardo Ferrari, Nick Hawes

**Year:** 2022

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [baioumy2022unbiased.pdf](../pdfs/baioumy2022unbiased.pdf)

**Generated:** 2025-12-14 12:51:33

**Validation Status:** ✓ Accepted
**Quality Score:** 0.80

---

=== IMPORTANT: ISOLATE THIS PAPER ===You are summarizing ONLY the paper below. Do NOT reference or use content from any other papers.Do NOT mix information from different papers. Only use information from THIS specific paper.Paper Title: Unbiased Active Inference for Classical ControlCitation Key: baioumy2022unbiasedAuthors: Mohamed Baioumy, Corrado Pezzato, Riccardo FerrariREMEMBER: Extract quotes, claims, and findings ONLY from the paper text provided below.Year:2022Key Terms: computational, state, active, neuroscience, inference, framework, control, classical, mathematical, goal=== FULL PAPER TEXT ===Unbiased Active Inference for Classical ControlMohamed Baioumy∗1, Corrado Pezzato∗2, Riccardo Ferrari3, Nick Hawes1Abstract—Active inference is a mathematical frameworkthat originated in computational neuroscience. Recently, it hasbeen demonstrated as a promising approach for constructinggoal-driven behavior in robotics. Specifically, the activeinference controller (AIC) has been successful on severalcontinuous control and state-estimation tasks. Despite itsrelative success, some established design choices lead to anumberofpracticallimitationsforrobotcontrol.Theseincludehaving a biased estimate of the state, and only an implicitmodel of control actions. In this paper, we highlight theselimitations and propose an extended version of the unbiasedactive inference controller (u-AIC). The u-AIC maintains allthe compelling benefits of the AIC and removes its limitations.Simulation results on a2-DOF arm and experiments on a real7-DOF manipulator show the improved performance of the Fig.1: Manipulation of delicate items in a human-sharedu-AICwithrespecttothestandardAIC.Thecodecanbefound store environment.at https://github.com/cpezzato/unbiased_aic.I. INTRODUCTION real7-DOF robot manipulator, which was previously onlyperformed in simulation.In this paper, we identify the drawbacks of the AICand connect them to two root causes. First, in the AICthe estimated state (or belief) is biased toward the currentgoal/target state through a goal prior. This leads to reducedquality in state-estimation [4] but also influences precisionlearning (learning the precision/covariance of the sensorymodel) making the model parameters converge to a biasedvalue[4],[5].Arangeofissuesalsoarisesinfaultdiagnosisand fault-tolerant control as a result of the goal prior, suchas false-positive fault detection [6], [3]. Second, the controlaction is not explicitly modeled as a random variable in thegenerative model of the AIC. This causes a range of issueson the control side. In real-world control applications, theintegral control law typical of the AIC can cause saturationproblems for the actuators when the agent fails to reach atarget. This can happen for instance because of a collision.Other limitations from a control perspective are that theAIC does not naturally allow for the incorporation of feed-forward control signals [3] which could improve the overallperformance of the system. Finally, the motion can be jerkyin practice.Interestingly, all these limitations are present in the AICbut are not intrinsically part of active inference as a generalframework. One can design different controllers that staytrue to the principles of active inference while mitigatingthe limitations. To this end, we present the u-AIC, initiallyintroduced in [3]. We demonstrate the properties of the u-AICin Section IV, as well as the convergence of both the stateestimation and the control which is still missing for theAIC [7].A. The generative modelActive Inference considers an agent in a dynamic envi-ronment that receives observations y about states x at everytime-step t. The generative model of the agent can then beexpressed as:p(x,y)= p(y|x) p(x). (1)(cid:124) (cid:123)(cid:122) (cid:125) (cid:124)(cid:123)(cid:122)(cid:125)observationmodel priorAvisualrepresentationofthismodelispresentedinfig.2(right).Theprobabilitydistributionp(y|x)hasameang(x),whichisamappingfromstatetoobservation.Thepriorp(x)has a mean f(x), which is a function that encodes the goalstate state µ . The agent aims to infer the posterior p(x|y)given a model of the agent’s world. This means finding thebelief µ over the state x given the observations. This can beachieved by minimizing the so-called variational free-energy.If all distributions in eq. (1) are Gaussian, the free energybecomes a sum of least square terms [7].B. Free-energyThe AIC performs joint state estimation and control byminimizing the free-energy F through a gradient descentscheme. F is defined as [7]:1n (cid:88)d−1(cid:104) (cid:105)F(y,µ)= ε(i)(cid:62)Σ−1 ε(i)+ε(i)(cid:62)Σ−1 ε(i) +K.2 y y(i) y µ µ(i) µi=0The free energy is a weighted sum of prediction errors upto a constant K resulting from the derivations [9]. Theterms Σ−1 and Σ−1 are precision matrices representingy q y q˙the confidence about sensory input and internal beliefs.Thesecan be seen as tuning parameters. The term represents thenumber of derivatives considered in the control problem. . Ifwe assume as in most cases [7], that n =2, thendstate estimation and control are performed on position andvelocity. These quantities are internally represented as thebeliefs µ(0) =µ for positions, and µ(1) =µ(cid:48) for velocities.The terms ε(i) = (µ(i+1) − f(i)(µ)) and ε(i) = (y(i) −µ(cid:48)are respectively the state and sensory prediction errors.The function g(µ) represents the mapping between statesand sensory observations. In case of robot control withposition and velocity sensors, this is the identity mapping.The function f(µ) = µ −µ specifies the desiredevolutionof the dynamicsofthesystem.Inthiscase, [7], the AIC willmake the system behave like a first-order linear system withdesired goal position µ . By definition, the terms ε(i) andε(i) are the prediction errors.II. PRELIMINARIESIn this section, we concisely report the AIC formulationused in previous work (e.g. [7], [4], [24], [10]), whichspecified the AIC for robot control according to the theory.A. Limitation #1: biased state estimationStateestimationintheAICisachievedbygradientdescenton the free-energy [9], [25], [7] with the update rule:d ∂F is represented by a circle, and each probability distributionµ˜˙ = µ˜−κ , (4)dt µ∂µ˜ by a black square. By inspecting this graph, we see that thestate x is connected to two distributions. The distributionwhere κ u and κ µ are the gradient descent step sizes. Theterm ∂Fgradient on control can be computed as:=Σ−1(µ −f∗(µ ,µ )) (18)∂µ u u x guLet us consider the generative model of the state dynamicsas a first order linear system with unitary time constant, sof(µ)=µ −µ,andsincethestateisobservable,g(µ)=µ.The function encodes the goal state µ . This term movesthe belief µ towards the goal state. The belief of the AICis thus always biased towards the goal state. This is bydesign. The benefit of this is that now we can also computea control action that movestheagenttothegoal(usingeq.(6)).However, the drawback is that state estimation is inaccurate.II. LIMITATIONS OF THEAICIn this section, we discuss the limitations of the AIC forrobot control. We note that these limitations are not inherentlypart of active inference as a general framework but rather in howthe AIC is constructed. In Section III-A we address Limitation #1:in AIC the belief over the current state is biased toward thetarget the agent aims to reach by means of goal prior. Thismeans that the agent’s belief is never accurate, except whenthe target is reached. In Section III-B we address Limitation#2:thecontrolactionisnotexplicitinthegenerativemodel.This means, that one cannot minimize the free energy withrespect to the actions directly and instead use the chain ruleas in
