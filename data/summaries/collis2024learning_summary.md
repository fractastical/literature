# Learning in Hybrid Active Inference Models

**Authors:** Poppy Collis, Ryan Singh, Paul F Kinghorn, Christopher L Buckley

**Year:** 2024

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [collis2024learning.pdf](../pdfs/collis2024learning.pdf)

**Generated:** 2025-12-14 02:38:03

**Validation Status:** ✓ Accepted
**Quality Score:** 1.00

---

### Learning in Hybrid Active Inference ModelsThe authors state: "An open problem in artificial intelligence is how systems can flexibly learn discrete abstractionsthatareusefulforsolvinginherentlycontinuousproblems." They note: "Humans are able to flexibly specify abstract sub-goals during planning, thereby reducing complex problems into manageable chunks." According to the paper: "Translating problems into discrete spaces admits the direct implementation of classical techniques from decision theory such as dynamic programming[21]." The study demonstrates: "While the prevailing method for translating continuous variables into discrete representations involves the simple grid-based discretization of the state-space, this becomes extremely costly as the dimensionality increases[7,24]."The authors state: "We seek the complete learning of appropriate coarse-grained representations of the underlying dynamics and their manifestation in continuous space." They further note: "Unlike the previousworkmentionedhere,wefocusontinstancesinwhichthemappingbetweendiscreteandcontinuousstatesisnotassumedto beknown." The paper argues: "In this case, however, the assumption that higher-level discrete states autonomously drive lower-level continuous states (i.e. downward causation) becomes problematic. Any failure of the continuous system to carry out a discrete preference must be treated as an autonomous failure at the discrete level." The study demonstrates: "Although useful for planning, this decoupling of the discrete from the continuous components makes it difficult to represent complex dynamics, which in turn creates difficulties in learning."The authors state: "Recurrent switching linear dynamical systems (rSLDS) discover meaningful discrete states and explain how their switching behaviour depends on continuous latent states." They note: "This class of hybrid state-space model includes a dependency from the underlying continuous variables in the high-level discrete transition probabilities." The paper argues: "By providing an understanding of the continuous latent causes of switches between the discrete states via this additional dependency, the authors demonstrate improved generative capacity and predictive performance." The study demonstrates: "The recurrent-only (ro) formulation of the rSLDS (see Fig.2) in which the discrete latent states have no dependency on the continuous latent state."The authors state: "We introduce a novel hierarchical hybrid active inference agent in which a discrete Markov decision process (MDP), informed by the representation of an rSLDS, interfaces with a continuous active inference controller implementing closed-loop control." They note: "We make use of recent work in recurrent switching linear dynamical systems (rSLDS) which learn meaningful discrete representationsof complexcontinuousdynamicsviapiecewise lineardecomposition[22]." The paper argues: "The representations learned by the rSLDS inform the structure of the hybrid decision-making agent and allow us to (1) lift decision-making into the discrete domain enabling us to exploit information-theoretic exploration bonuses (2) specify temporally-abstracted sub-goals in an method reminiscent of the options framework[34] and (3) ‘cache’ the approximate solutions to low-level problems in the discrete planner."The authors state: "For a full treatment of this model, see[13]." They note: "SuchtemporalabstractionsarethefocusofHierarchicalreinforcementlearning(HRL),wherehigh-levelcontrollersprovidethemeansforreasoningbeyondtheclock-rateofthelow-levelcontrollersprimitive actions." The paper argues: "The majority of HRL methods, however, depend on domain expertisetoconstructtasks, often through manually predefined subgoals as seen in[35]." Further, efforts to learn hierarchies directly in a sparse environment have typically been unsuccessful[36]." In contrast, we seek the complete learning of appropriate coarse-grained representations of the underlying dynamics and their manifestation in continuous space. Importantly, unlike the previousworkmentionedhere,wefocusontinstancesinwhichthemappingbetweendiscreteandcontinuousstatesisnotassumedto beknown. In this case, however, the assumption that higher-level discrete states autonomously drive lower-level continuous states (i.e. Any failure of the continuous system to carry out a discrete preference must be treated as an autonomous failure at the discrete level. Although useful for planning, this decoupling of the discrete from the continuous components makes it difficult to represent complex dynamics, which in turn creates difficulties in learning.The authors state: "We apply our model to the sparse Continuous MountainCartask, demonstratingfastsystemidentificationviaenhancedexplorationandsuccessfulplanningthroughthedelineationofabstractsub-goals." They note: "The authorsdemonstratefastsystemidentificationviaenhancedexplorationandsuccessfulplanningthroughthedelineationofabstractsub-goals." The study demonstrates: "The authorsdemonstratefastsystemidentificationviaenhancedexplorationandsuccessfulplanningthroughthedelineationofabstractsub-goals." The paper argues: "The authorsdemonstratefastsystemidentificationviaenhancedexplorationandsuccessfulplanningthroughthedelineationofabstractsub-goals."The authors state: "We introduce a novel hierarchical hybrid active inference agent (HHA) in which a discrete active inference planner sits above a low-level continuous active inference controller." They note: "The discrete planner is constructed as a standard POMDP generative model with discrete states and observations." The study demonstrates: "The discrete planner is constructed as a standard POMDP generative model with discrete states and observations." The paper argues: "The discrete planner is constructed as a standard POMDP generative model with discrete states and observations."The authors state: "In the framework, the discrete states s and observations o are generated as a function of the continuous latent states x by using a softmax regression model, W x + r." They note: "This mixed generative model effectively generates discrete sequences of short continuous trajectories defined in terms of their generalized coordinates of motion. The discrete planner is formulated as a standard POMDP generative model (see Sec.3.3) with discrete states s and observations o." The study demonstrates: "The first action a of the selected policy is then passed down to the continuous active inference controller via the expected observation q(o |a)."The authors state: "For a full treatment of this model, see[13]."The authors state: "We use recent work in recurrent switching linear dynamical systems (rSLDS) discover meaningful discrete states and explain how their switching behaviour depends on continuous latent states."The authors state: "We apply our model to the sparse Continuous MountainCartask, demonstratingfastsystemidentificationviaenhancedexplorationandsuccessfulplanningthroughthedelineationofabstractsub-goals."

The authors state: "

We demonstratefastsystemidentificationviaenhancedexplorationandsuccessfulplanningthroughthedelineationofabstractsub-goals."
