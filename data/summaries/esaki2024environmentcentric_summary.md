# Environment-Centric Active Inference

**Authors:** Kanako Esaki, Tadayuki Matsumura, Takeshi Kato, Shunsuke Minusa, Yang Shao, Hiroyuki Mizuno

**Year:** 2024

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [esaki2024environmentcentric.pdf](../pdfs/esaki2024environmentcentric.pdf)

**Generated:** 2025-12-14 03:03:16

**Validation Status:** ✓ Accepted
**Quality Score:** 0.80

---

### OverviewThis summary of “Environment-Centric Active Inference” details the investigation into a novel approach to active inference, shifting the focus from the agent to the environment. The authors propose a framework where the Markov Blanket of an agent is defined starting from the environment. In normal active inference, the Markov Blanket is defined starting from the agent. That is, first the agent was defined as the entity that performs the “action” such as a robot or a person, then the environment was defined as other people or objects that are directly affected by the agent’s “action,” and the boundary between the agent and the environment was defined as the Markov Blanket. This agent-centric definition does not allow the agent to respond to unintended changes in the environment caused by factors outside of the defined environment. In the proposed EC-AIF, there is no entity corresponding to an agent. The environment includes all observable things, including people and things conventionally considered to be the environment, as well as entities that perform “actions” such as robots and people. Accordingly, all states, including robots and people, are included in inference targets, eliminating unintended changes in the environment. The EC-AIF was applied to a robot arm and demonstrated in an object transport task. The results showed that the robot arm successfully transported objects while responding to changes in the target position of the object and to changes in the orientation of another robot arm.### MethodologyThe authors report: "The conventional active inference, which explains the intelligence of living organisms, has increased the intelligence of various agents." They note: "Defining the agent and the environment in active inference has been left to researchers [22,21,16,13,26]." In these studies, especially in systems with an embodiment such as a robot, the implicit guideline has been to define the robot as the agent and the surroundings as the environment. Defining the agent and the environment implies designing Markov Blanket of active inference. As long as the defined environment is maintained, the agent will outperform the human in some cases. However, changes in the environment that cannot be directly changed by the agent or in the presence of other agents can occur. The implicit guideline for designing Markov Blanket would be unable to respond to such changes in the environment that the agent does not intend.Design strategies for Markov Blanket are required that can accommodate unintended changes in the environment. It is not an implicit guideline, but a specific strategy that is independent of the system configuration, such as the robot and its surroundings. What are agents and environments. The design strategy should answer this essential question. Changes in the environment that are not intended by the agent originate from assuming an entity corresponding to the agent (e.g., a robot) and defining its surroundings as the environment. Instead of assuming the entity corresponding to the agent, considering all of the world as the environment, the changes in the environment must be under the intention of the agent. Therefore, defining a Markov Blanket based on the environmentbyassumingthateverythingintheworldistheenvironmentwouldallow the agent to respond to changes in the environment.We propose an environment-centric active inference EC-AIF that designs Markov Blanket based on the environment. The concept of Markov Blanket is shown in Fig.1. The conventional Markov Blanket has defined the agent as the entity that performs the “action”, such as a robot or a person, and the environment as the other people or objects, as shown in Fig.1(a). The state of the agent is fully known. In addition, the state of the environment within the definition is inferred with high precision, but the state of the environment outside the definition is not inferred at all. The proposed EC-AIF is completely different, as shown in Fig.1(b): there is no entity corresponding to an agent. In addition to the people and objects that have been considered the environment, theenvironmentincludes theentities thatperform“actions,” suchas robotsand people. The state of the environment is inferred with varying accuracy. The robot arm adapted to changes in the environment and successfully transported the object.2.1 Free Energy Principle and Active InferenceLiving organisms are said to follow the Free Energy Principle (FEP). Living organisms repeat a process of perception and action. Perception is the process of acquiring an observation o from the environment and inferring a hidden state s of the environment. Action is the process of inferring the appropriate policy πEnvironment-Centric Active Inference3Agent Environment Agent EnvironmentNoentityInference not inferred Inferencelevel level(a) (b)Fig.1. Concept of (a) conventional Markov Blanket (b) Markov Blanket of EC-AIF.### Results and Discussion3.1 Experimental SetupThe experiments were conducted with a scene of object transport by a robot.The object is mainly transferred by Universal Robots’6-axis robot arm UR5eand Robotiq’s adaptive gripper2F-140 attached to the end of the UR5e shownin Fig.3(a). In this scene, the world is composed of the robot arm UR5e and6 K. Esaki et al.Algorithm1 Process flow of EC-AIF1: for all whatc do2: Create generative model p(o,s,π)3: end for4: Acquire initial observation o05: for τ =0 to Timesteps T do6: for all whatc do7: Infer state sτ8: Infer policy πτ9: Choose action aτ10: if whatc in a thenτ11: Convert action a to control value uτ τ12: Send control value u to controllerτ13: Break14: end if15: end for16: end forDENSOWAVE’s6-axisrobotarmCOBOTTAshowninFig.3(b),andthetargetobject placed around UR5e. Accordingly, what in this scene is as follows:what={UR5e,COBOTTA,target object} (4)Furthermore, where is the grid points P1 to P15, including UO, the origin position of UR5e, CO, the origin position of COBOTTA, and Int., the intermediate position between the two robots.(a) (b)Fig.3. Robots in Experiment (a) UR5e (b) COBOTTA.We evaluated the proposed method in two scenarios that capture changes inthe environment in object transport:Environment-Centric Active Inference7Scenario1: The target position for object transport changes.Scenario2: Another robot’s orientation changes.Thefirstscenarioisanexampleofchangeintheenvironmentthatcannotbedirectly changed by the agent: the target position for object transport changes.Specifically,asshowninFig.4(a),thetargetpositionisinitiallyinfrontofrobotarm UR5e (P12) and then changes to the side of robot arm COBOTTA (P5).Before the target position changes, the target position is within the reach ofUR5e, allowing object transport by UR5e by itself. After the target positionchanges, the target position is outside the reach of UR5e and within the reachof COBOTTA, requiring UR5e to cooperate with COBOTTA to transport theobject.Thesecondscenarioisanexampleofachangeintheenvironmentwherethere is another robot, and the target position for object transport remains thesame, but the orientation of the other robot changes. Specifically, as shown inFig.4(b), the target position is in front of COBOTTA (P14), and COBOTTAinitially faces the other direction from the target position, and then changes tothedirectionofthetargetposition.BeforetheorientationofCOBOTTAchanges,UR5e does not have contact with COBOTTA when it places an object at thetarget position, allowing UR5e to transport the object on its own. After theCOBOTTA’s orientation changes, UR5e requires cooperation with COBOTTAto transport objects because UR5e will have contact with COBOTTA whenUR5eplacesobjectsatthetargetposition.Inbothscenarios,theinitialpositionof the target object was P7. The target position was given as the preferenceregarding the observation of the target object.TargetUR5e COBOTTA UR5e COBOTTA(after)ArmP1 UO Int. CO P5 P1 UO Int. CO P5 direction(before)Initial InitialP6 P7 P8 P9 P10 P6 P7 P8 P9 P10TargetP11 P12 P13 P14 P15 P11 P12 P13 P14 P15Target Armdirection(before) (after)(a) (b)Fig.4.Scenariosof(a)thetargetpositionforobjecttransportchanges,and(b)anotherrobot’sorientationchanges.Eachcirclerepresentsagridpointcomprisingwhere.UOis the origin position of UR5e, CO is the origin position of COBOTTA, and 

Int. isthe intermediate position between UR5e and COBOTTA. 

The
