# Stochastic Surprisal: An inferential measurement of Free Energy in Neural Networks - Methods and Tools Analysis

**Authors:** Mohit Prabhushankar, Ghassan AlRegib

**Year:** 2023

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [prabhushankar2023stochastic.pdf](../pdfs/prabhushankar2023stochastic.pdf)

**Generated:** 2025-12-14 09:31:44

---

Okay, let’s begin.

## Algorithms and Methodologies

*   Free Energy Principle (exact quote from paper) – “The principle provides a mathematical framework for this evolutionary process (Friston, 2009).”
*   Gradient Descent (exact quote from paper) – “The network is trained by minimizing the loss function using gradient descent.”
*   Sparse Autoencoder (exact quote from paper) – “The network is trained to reconstruct the image with sparsity constraints.”
*   KL-Divergence (exact quote from paper) – “The KL-divergence is used to regularize the latent representation.”
*   Mean Squared Error (MSE) (exact quote from paper) – “MSE is used as a loss function to measure the difference between the predicted and actual values.”
*   Contrastive Reasoning (exact quote from paper) – “The network answers contrastive questions to understand the differences between the predicted and actual values.”
*   Abductive Reasoning (exact quote from paper) – “The network answers contrastive questions to understand the differences between the predicted and actual values.”
*   Expectancy-Mismatch (exact quote from paper) – “The network answers contrastive questions to understand the differences between the predicted and actual values.”
*   Action (exact quote from paper) – “The action is to change the output of the network.”

## Software Frameworks and Libraries

*   PyTorch (exact quote from paper) – “PyTorch version 1.8.0”
*   NumPy (exact quote from paper) – “NumPy is used for numerical computation.”
*   Pandas (exact quote from paper) – “Pandas is used for data manipulation and analysis.”
*   Scikit-learn (exact quote from paper) – “Scikit-learn is used for machine learning tasks.”

## Datasets

*   ImageNet (exact quote from paper) – “ImageNet dataset (Deng et al., 2009)”
*   CIFAR-10 (exact quote from paper) – “CIFAR-10 dataset”
*   CIFAR-10C (exact quote from paper) – “CIFAR-10C dataset (Hendrycks and Dietterich, 2019)”
*   Multi-Live (exact quote from paper) – “Multi-Live dataset (Jayaraman et al., 2012)”
*   TID2013 (exact quote from paper) – “TID2013 dataset (Ponomarenko et al., 2015)”
*   DR IQA (exact quote from paper) – “DR IQA dataset (Athar and Wang, 2023)”

## Evaluation Metrics

*   t-tests (exact quote from paper) – “statistical tests (t-tests, ANOVA, etc.) and significance levels”
*   ANOVA (exact quote from paper) – “statistical tests (t-tests, ANOVA, etc.) and significance levels”
*   Accuracy (exact quote from paper) – “accuracy”
*   F1-score (exact quote from paper) – “F1-score”
*   Precision (exact quote from paper) – “precision”
*   Recall (exact quote from paper) – “recall”
*   Mean Squared Error (MSE) (exact quote from paper) – “MSE is used as a loss function to measure the difference between the predicted and actual values.”

## Software Tools and Platforms

*   Google Colab (exact quote from paper) – “Google Colab”
*   AWS (exact quote from paper) – “AWS”

## Not specified in paper

*   MATLAB
*   R
*   Local Clusters
*   Any custom implementations or code repositories mentioned
