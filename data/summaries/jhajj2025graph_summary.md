# Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning

**Authors:** Gaganpreet Jhajj, Fuhua Lin

**Year:** 2025

**Source:** arxiv

**Venue:** N/A

**DOI:** N/A

**PDF:** [jhajj2025graph.pdf](../pdfs/jhajj2025graph.pdf)

**Generated:** 2025-12-13 20:41:17

**Validation Status:** âœ“ Accepted
**Quality Score:** 1.00

---

### OverviewThis paper investigates the application of free energy minimization to knowledge graph reasoning, proposing that entities closer in graph distance exhibit lower surprise. The authors connect this approach to the Free Energy Principle (FEP) from neuroscience, where agents minimize surprise by maintaining accurate world models. The research formalizes surprise using shortest-path distance in directed graphs and provides a framework for KG-based agents. The core argument is that shorter distances within a knowledge graph correspond to higher probability under the agentâ€™s generative model, and that minimizing surprise drives the agent to ground entities effectively. The paperâ€™s central question is: given a KG serving as an agentâ€™s generative model, which entity groundings are plausible for a query in context?### MethodologyThe authors state: "The Free Energy Principle (FEP) suggests that biological systems minimize surprise by maintaining accurate world models [1,3,4]." They note: "Recently, Murphy et al. [2] demonstrated that syntactic operations minimize surprise through shallow tree structures." They quantify surprise via tree depth (geometric complexity) and Kolmogorov complexity (algorithmic complexity), approximated through Lempel-Ziv compression [5,6]. According to the paper, "In FEP, agents minimize variational free energyğ¹ = âˆ’logğ‘ƒ(ğ‘œ,ğ‘ )âˆ’ğ»[ğ‘„(ğ‘ )]", whereğ‘œ represents observations,ğ‘  hidden states,ğ‘ƒ the generative model, andğ‘„ the agentâ€™s beliefs [1]. They further explain that "The first term, âˆ’logğ‘ƒ(ğ‘œ,ğ‘ ), quantifies surprise: entities with high probability under the generative model (highğ‘ƒ(ğ‘œ,ğ‘ )) yield low surprise (low âˆ’logğ‘ƒ(ğ‘œ,ğ‘ ))."They state: "For syntactic trees, Murphyetal. [2]usedtreedepthto proxythisprobability;weextendthisprincipletogeneralgraphsusingshortest-pathdistance."The authors elaborate: "Inactiveinference, minimizingfreeenergydrivesbothperception(updatingbeliefsğ‘„(ğ‘ ))andaction(selecting policies that reduce uncertainty) [3]."They add: "We apply this principle to KG reasoning: entities at shorter graph distances have a higher probability under the agentâ€™s graph-based generative model."The paper describes the approach as using BFS to compute shortest path distances. They note: â€œGiven a KGğº = (â„°,ğ‘…,ğ‘‡) with entitiesâ„°, relationsğ‘…, and triplesğ‘‡âŠ†â„° Ã—ğ‘…Ã—â„°, geometric surprise is:ğ‘†geo(ğ‘’ |ğ¶) = minğ‘‘(ğ¶,ğ‘’) if path exists, elseğ›¼.â€They specify thatğ›¼ is a hyperparameter penalizing disconnection.The authors also utilize Kolmogorov complexity approximation via Lempel-Ziv compression. They state: "For each grounding, we estimate Kolmogorov complexity via relation path patterns."The paper describes the approach as using BFS to compute shortest path distances.### ResultsThe authors demonstrate free energy calculations using the Canadian Prime Minister knowledge graph from Figure1. They state: â€œWe compute geometric surpriseğ‘†geo(ğ‘’ |ğ¶) using BFS from Canada.â€ They show that "Trudeau and Harper exhibit low surprise because they are at short distances (1 hop) from the context Canada."They also state: â€œBiden has no path from Canada, which results in high surprise.â€The authors show that â€œEntities at shorter distances are more likely:ğ‘ƒ(observeğ‘’ |ğ¶) increases asğ‘†geo decreases, making low-distance entities preferred for goal-directed actions.â€ They state: â€œThe authors state: â€œTrudeau and Harper exhibit low surprise because they are at short distances (1 hop) from the context Canada.â€ They also state: â€œBiden has no path from Canada, which results in high surprise.â€### DiscussionThe authors conclude: â€œReal groundings (Trudeau, Harper) exhibit low surprise because they are at short distances (1 hop) from the context Canada.â€ They add: â€œBiden has no path from Canada, which results in high surprise.â€ They note: â€œEntities at shorter distances are more likely:ğ‘ƒ(observeğ‘’ |ğ¶) increases asğ‘†geo decreases, making low-distance entities preferred for goal-directed actions.â€ They state: â€œThe authors state: â€œTrudeau and Harper exhibit low surprise because they are at short distances (1 hop) from the context Canada.â€ They also state: â€œ

Biden has no path from 

Canada, which results in high surprise.â€
